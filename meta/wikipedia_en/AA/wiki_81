{"id": "9093", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=9093", "title": "De Havilland Mosquito", "text": "The de Havilland DH.98 Mosquito is a British twin-engined, multirole combat aircraft, introduced during the Second World War. Unusual in that its airframe was constructed mostly of wood, it was nicknamed the \"Wooden Wonder\", or \"Mossie\". In 1941, it was one of the fastest operational aircraft in the world.\nOriginally conceived as an unarmed fast bomber, the Mosquito's use evolved during the war into many roles, including low- to medium-altitude daytime tactical bomber, high-altitude night bomber, pathfinder, day or night fighter, fighter-bomber, intruder, maritime strike, and photo-reconnaissance aircraft. It was also used by the British Overseas Airways Corporation as a fast transport to carry small, high-value cargo to and from neutral countries through enemy-controlled airspace. The crew of two, pilot and navigator, sat side by side. A single passenger could ride in the aircraft's bomb bay when necessary.\nThe Mosquito FB Mk. VI was often flown in special raids, such as Operation Jericho (an attack on Amiens Prison in early 1944), and precision attacks against military intelligence, security, and police facilities (such as Gestapo headquarters). On 30 January 1943, the 10th anniversary of Hitler being made chancellor and the Nazis gaining power, a morning Mosquito attack knocked out the main Berlin broadcasting station while Hermann G\u00f6ring was speaking, taking his speech off the air.\nThe Mosquito flew with the Royal Air Force (RAF) and other air forces in the European, Mediterranean, and Italian theatres. The Mosquito was also operated by the RAF in the Southeast Asian theatre and by the Royal Australian Air Force based in the Halmaheras and Borneo during the Pacific War. During the 1950s, the RAF replaced the Mosquito with the jet-powered English Electric Canberra.\nDevelopment.\nBy the early to mid-1930s, de Havilland had built a reputation for innovative high-speed aircraft with the DH.88 Comet racer. Later, the DH.91 Albatross airliner pioneered the composite wood construction used for the Mosquito. The 22-passenger Albatross could cruise at at , faster than the Handley Page H.P.42 and other biplanes it was replacing. The wooden monocoque construction not only saved weight and compensated for the low power of the de Havilland Gipsy Twelve engines used by this aircraft, but also simplified production and reduced construction time.\nAir Ministry bomber requirements and concepts.\nOn 8 September 1936, the British Air Ministry issued Specification P.13/36, which called for a twin-engined medium bomber capable of carrying a bomb load of for with a maximum speed of at ; a maximum bomb load of carried over shorter ranges was also required. Aviation firms entered heavy designs with new high-powered engines and multiple defensive turrets, leading to the production of the Avro Manchester and Handley Page Halifax.\nIn May 1937, as a comparison to P.13/36, George Volkert, the chief designer of Handley Page, put forward the concept of a fast, unarmed bomber. In 20 pages, Volkert planned an aerodynamically clean, medium bomber to carry of bombs at a cruising speed of . Support existed in the RAF and Air Ministry; Captain R. N. Liptrot, Research Director Aircraft 3, appraised Volkert's design, calculating that its top speed would exceed that of the new Supermarine Spitfire, but counter-arguments held that although such a design had merit, it would not necessarily be faster than enemy fighters for long. The ministry was also considering using non-strategic materials for aircraft production, which, in 1938, had led to specification B.9/38 and the Armstrong Whitworth Albemarle medium bomber, largely constructed from spruce and plywood attached to a steel-tube frame. The idea of a small, fast bomber gained support at a much earlier stage than is sometimes acknowledged, though the Air Ministry likely envisaged it using light alloy components.\nInception of the de Havilland fast bomber.\nBased on his experience with the Albatross, Geoffrey de Havilland believed that a bomber with a good aerodynamic design and smooth, minimal skin area, would exceed the P.13/36 specification. Furthermore, adapting the Albatross principles could save time. In April 1938, performance estimates were produced for a twin Rolls-Royce Merlin-powered DH.91, with the Bristol Hercules (radial engine) and Napier Sabre (H-engine) as alternatives. On 7 July 1938, de Havilland wrote to Air Marshal Wilfrid Freeman, the Air Council's member for Research and Development, discussing the specification and arguing that in war, shortages of aluminium and steel would occur, but supplies of wood-based products were \"adequate.\" Although inferior in tension, the strength-to-weight ratio of wood is equal to or better than light alloys or steel, hence this approach was feasible. Lord Beaverbrook, Minister of Aircraft Production, nicknamed it \"Freeman's Folly\", alluding to Air Chief Marshal Sir Wilfrid Freeman, who defended Geoffrey de Havilland and his design concept against orders to scrap the project.\nA follow-up letter to Freeman on 27 July said that the P.13/36 specification could not be met by a twin Merlin-powered aircraft and either the top speed or load capacity would be compromised, depending on which was paramount. For example, a larger, slower, turret-armed aircraft would have a range of carrying a 4,000\u00a0lb bomb load, with a maximum of at , and a cruising speed of at . De Havilland believed that a compromise, including eliminating surplus equipment, would improve matters. On 4 October 1938, de Havilland projected the performance of another design based on the Albatross, powered by two Merlin\u00a0Xs, with a three-man crew and six or eight forward-firing guns, plus one or two manually operated guns and a tail turret. Based on a total loaded weight of , it would have a top speed of and cruising speed of at .\nStill believing this could be improved, and after examining more concepts based on the Albatross and the new all-metal DH.95 Flamingo, de Havilland settled on designing a new aircraft that would be aerodynamically clean, wooden, and powered by the Merlin, which offered substantial future development. The new design would be faster than foreseeable enemy fighter aircraft, and could dispense with defensive armament which would slow it and make interception or losses to antiaircraft guns more likely. Instead, high speed and good manoeuvrability would make evading fighters and ground fire easier. The lack of turrets simplified production, reduced drag, and reduced production time, with a delivery rate far in advance of competing designs. Without armament, the crew could be reduced to a pilot and navigator. Whereas contemporary RAF design philosophy favoured well-armed heavy bombers, this mode of design was more akin to the German philosophy of the \"Schnellbomber\". At a meeting in early October 1938 with Geoffrey de Havilland and Charles Walker (de Havilland's chief engineer), the Air Ministry showed little interest, and instead asked de Havilland to build wings for other bombers as a subcontractor.\nBy September 1939, de Havilland had produced preliminary estimates for single- and twin-engined variations of light-bomber designs using different engines, speculating on the effects of defensive armament on their designs. One design, completed on 6 September, was for an aircraft powered by a single Napier Sabre, with a wingspan of and capable of carrying a bomb load . On 20 September, in another letter to Wilfrid Freeman, de Havilland wrote \"...we believe that we could produce a twin-engine bomber which would have a performance so outstanding that little defensive equipment would be needed.\" By 4 October, work had progressed to a twin-engined light bomber with a wingspan of and powered by Merlin or Griffon engines, the Merlin favoured because of availability. On 7 October 1939, a month into the war, the nucleus of a design team under Eric Bishop moved to the security and secrecy of Salisbury Hall to work on what was later known as the DH.98. For more versatility, Bishop made provision for four 20\u00a0mm cannon in the forward half of the bomb bay, under the cockpit, firing via blast tubes and troughs under the fuselage.\nThe DH.98 was too radical for the ministry, which wanted a heavily armed, multirole aircraft, combining medium bomber, reconnaissance, and general-purpose roles, that was also capable of carrying torpedoes. With the outbreak of war, the ministry became more receptive, but was still sceptical about an unarmed bomber. They thought the Germans would produce fighters that were faster than had been expected. and suggested the incorporation of two forward- and two rear-firing machine guns for defence. The ministry also opposed a two-man bomber, wanting at least a third crewman to reduce the work of the others on long flights. The Air Council added further requirements such as remotely controlled guns, a top speed of at 15,000\u00a0ft on two-thirds engine power, and a range of with a 4,000-lb bomb load. To appease the ministry, de Havilland built mock-ups with a gun turret just aft of the cockpit, but apart from this compromise, de Havilland made no changes.\nOn 12 November, at a meeting considering fast-bomber ideas put forward by de Havilland, Blackburn, and Bristol, Air Marshal Freeman directed de Havilland to produce a fast aircraft, powered initially by Merlin engines, with options of using progressively more powerful engines, including the Rolls-Royce Griffon and the Napier Sabre. Although estimates were presented for a slightly larger Griffon-powered aircraft, armed with a four-gun tail turret, Freeman got the requirement for defensive weapons dropped, and a draft requirement was raised calling for a high-speed, light-reconnaissance bomber capable of at 18,000\u00a0ft.\nOn 12 December, the Vice-Chief of the Air Staff, Director General of Research and Development, and the Air Officer Commanding-in-Chief (AOC-in-C) of RAF Bomber Command met to finalise the design and decide how to fit it into the RAF's aims. The AOC-in-C would not accept an unarmed bomber, but insisted on its suitability for reconnaissance missions with F8 or F24 cameras. After company representatives, the ministry, and the RAF's operational commands examined a full-scale mock-up at Hatfield on 29 December 1939, the project received backing. This was confirmed on 1 January 1940, when Freeman chaired a meeting with Geoffrey de Havilland, John Buchanan (Deputy of Aircraft Production), and John Connolly (Buchanan's chief of staff). De Havilland claimed the DH.98 was the \"fastest bomber in the world\u00a0... it must be useful\". Freeman supported it for RAF service, ordering a single prototype for an unarmed bomber to specification B.1/40/dh, which called for a light bomber/reconnaissance aircraft powered by two Rolls-Royce RM3SM (an early designation for the Merlin 21) with ducted radiators, capable of carrying a bomb load. The aircraft was to have a speed of at and a cruising speed of at with a range of at on full tanks. Maximum service ceiling was to be .\nOn 1 March 1940, Air Marshal Roderic Hill issued a contract under Specification B.1/40, for 50 bomber-reconnaissance variants of the DH.98; this contract included the prototype, which was given the factory serial \"E-0234\". In May 1940, specification F.21/40 was issued, calling for a long-range fighter armed with four 20\u00a0mm cannon and four .303 machine guns in the nose, after which de Havilland was authorised to build a prototype of a fighter version of the DH.98. After debate, it was decided that this prototype, given the military serial number \"W4052\", was to carry aircraft interception (AI) Mk\u00a0IV radar equipment as both a day fighter and night fighter. By June 1940, the DH.98 had been named \"Mosquito\". Having the fighter variant kept the Mosquito project alive, as doubts remained within the government and Air Ministry regarding the usefulness of an unarmed bomber, even after the prototype had shown its capabilities.\nProject Mosquito.\nWith design of the DH.98 started, mock-ups were built, the most detailed at Salisbury Hall, where \"E-0234\" was later constructed. Initially, the concept was for the crew to be enclosed in the fuselage behind a transparent nose (similar to the Bristol Blenheim or Heinkel He 111H), but this was quickly altered to a more solid nose with a conventional canopy.\nWork was cancelled again after the evacuation of the British Army from France, when Lord Beaverbrook, as Minister of Aircraft Production, concentrating production on aircraft types for the defence of the UK decided no production capacity remained for aircraft like the DH.98, which was not expected to be in service until early 1942. Beaverbrook told Air Vice-Marshal Freeman that work on the project should stop, but he did not issue a specific instruction, and Freeman ignored the request. In June 1940, however, Lord Beaverbrook and the Air Staff ordered that production should concentrate on five existing types, namely the Supermarine Spitfire, Hawker Hurricane fighter, Vickers Wellington, Armstrong-Whitworth Whitley, and Bristol Blenheim bombers. Work on the DH.98 prototype stopped. Apparently, the project shut down when the design team were denied materials for the prototype.\nThe Mosquito was only reinstated as a priority in July 1940, after de Havilland's general manager, L.C.L. Murray, promised Lord Beaverbrook 50 Mosquitoes by December 1941. This was only after Beaverbrook was satisfied that Mosquito production would not hinder de Havilland's primary work of producing Tiger Moth and Airspeed Oxford trainers, repairing Hurricanes, and manufacturing Merlin engines under licence. In promising Beaverbrook such a number by the end of 1941, de Havilland was taking a gamble, because they were unlikely to be built in such a limited time. As it transpired, only 20 aircraft were built in 1941, but the other 30 were delivered by mid-March 1942. During the Battle of Britain, interruptions to production due to air raid warnings caused nearly a third of de Havilland's factory time to be lost. Nevertheless, work on the prototype went ahead quickly at Salisbury Hall since \"E-0234\" was completed by November 1940.\nIn the aftermath of the Battle of Britain, the original order was changed to 20 bomber variants and 30 fighters. Whether the fighter version should have dual or single controls, or should carry a turret, was still uncertain, so three prototypes were built: \"W4052\", \"W4053\", and \"W4073\". The second and third, both turret armed, were later disarmed, to become the prototypes for the T.III trainer. This caused some delays, since half-built wing components had to be strengthened for the required higher combat loading. The nose sections also had to be changed from a design with a clear perspex bomb-aimer's position, to one with a solid nose housing four .303 machine guns and their ammunition.\nPrototypes and test flights.\nOn 3 November 1940, the prototype aircraft, painted in \"prototype yellow\" and still coded \"E-0234\", was dismantled, transported by road to Hatfield and placed in a small, blast-proof assembly building. Two Merlin 21 two-speed, single-stage supercharged engines were installed, driving three-bladed de Havilland Hydromatic constant-speed controllable-pitch propellers. Engine runs were made on 19 November. On 24 November, taxiing trials were carried out by Geoffrey de Havilland Jr., the de Havilland test pilot. On 25 November, the aircraft made its first flight, piloted by de Havilland Jr., accompanied by John E. Walker, the chief engine installation designer.\nFor this maiden flight, \"E-0234\", weighing , took off from the grass airstrip at Hatfield. The takeoff was reported as \"straightforward and easy\" and the undercarriage was not retracted until a considerable altitude was attained. The aircraft reached , with the only problem being the undercarriage doors, which were operated by bungee cords attached to the main undercarriage legs, and remained open by some at that speed. This problem persisted for some time. The left wing of \"E-0234\" also had a tendency to drag slightly to port, so a slight change in the angle of the wing was carried out before further flights.\nOn 5 December 1940, the prototype, with the military serial number \"W4050\", experienced tail buffeting at speeds between . The pilot noticed this most in the control column, with handling becoming more difficult. During testing on 10 December, wool tufts were attached to suspect areas to investigate the direction of airflow. The conclusion was that the airflow separating from the rear section of the inner engine nacelles was disturbed, leading to a localised stall and the disturbed airflow was striking the tailplane, causing buffeting. To smooth the air flow and deflect it from forcefully striking the tailplane, nonretractable slots fitted to the inner engine nacelles and to the leading edge of the tailplane were tested. These slots and wing-root fairings fitted to the forward fuselage and leading edge of the radiator intakes stopped some of the vibration experienced, but did not cure the tailplane buffeting.\nIn February 1941, buffeting was eliminated by incorporating triangular fillets on the trailing edge of the wings and lengthening the nacelles, the trailing edge of which curved up to fair into the fillet some behind the wing's trailing edge; this meant the flaps had to be divided into inboard and outboard sections. With the buffeting problems largely resolved, John Cunningham flew \"W4050\" on 9 February 1941. He was greatly impressed by the \"lightness of the controls and generally pleasant handling characteristics\". Cunningham concluded that when the type was fitted with AI equipment, it might replace the Bristol Beaufighter night fighter.\nDuring its trials on 16 January 1941, \"W4050\" outpaced a Spitfire at . The original estimates were that as the Mosquito prototype had twice the surface area and over twice the weight of the Spitfire Mk.II, but also had twice its power, the Mosquito would be faster. Over the next few months, \"W4050\" surpassed this estimate, easily beating the Spitfire Mk.II in tests at RAF Boscombe Down in February 1941, reaching a top speed of at , compared to a top speed of at for the Spitfire.\nOn 19 February, official trials began at the Aeroplane and Armament Experimental Establishment (AAEE) based at Boscombe Down, although the de Havilland representative was surprised by a delay in starting the tests. On 24 February, as \"W4050\" taxied across the rough airfield, the tailwheel jammed leading to the fuselage fracturing. Repairs were made by early March, using part of the fuselage of the photo-reconnaissance prototype \"W4051\". In spite of this setback, the \"Initial Handling Report 767\" issued by the AAEE stated, \"The aeroplane is pleasant to fly ... aileron control light and effective...\" The maximum speed reached was at , with an estimated maximum ceiling of and a maximum rate of climb of at .\n\"W4050\" continued to be used for various test programmes, as the experimental \"workhorse\" for the Mosquito family. In late October 1941, it returned to the factory to be fitted with Merlin 61s, the first production Merlins fitted with a two-speed, two-stage supercharger. The first flight with the new engines was on 20 June 1942. \"W4050\" recorded a maximum speed of at (fitted with straight-through air intakes with snow guards, engines in full supercharger gear) and at without snow guards. In October 1942, in connection with development work on the NF Mk.XV, \"W4050\" was fitted with extended wingtips, increasing the span to , first flying in this configuration on 8 December. Fitted with high-altitude-rated, two-stage, two-speed Merlin\u00a077s, it reached in December 1943. Soon after these flights, \"W4050\" was grounded and scheduled to be scrapped, but instead served as an instructional airframe at Hatfield. In September 1958, \"W4050\" was returned to the Salisbury Hall hangar where it was built, restored to its original configuration, and became one of the primary exhibits of the de Havilland Aircraft Heritage Centre.\n\"W4051\", which was designed from the outset to be the prototype for the photo-reconnaissance versions of the Mosquito, was slated to make its first flight in early 1941. However, the fuselage fracture in \"W4050\" meant that \"W4051's\" fuselage was used as a replacement; \"W4051\" was then rebuilt using a production standard fuselage and first flew on 10 June 1941. This prototype continued to use the short engine nacelles, single-piece trailing-edge flaps, and the \"No. 1\" tailplane used by \"W4050\", but had production-standard wings and became the only Mosquito prototype to fly operationally.\nConstruction of the fighter prototype, \"W4052\", was also carried out at Salisbury Hall. It was powered by Merlin\u00a021s, and had an altered canopy structure with a flat, bullet-proof windscreen; the solid nose had mounted four .303 British Browning machine guns and their ammunition boxes, accessible by a large, sideways hinged panel. Four 20-mm Hispano\u00a0Mk.II cannon were housed in a compartment under the cockpit floor with the breeches projecting into the bomb bay and the automatic bomb bay doors were replaced by manually operated bay doors, which incorporated cartridge ejector chutes.\nAs a day and night fighter, prototype \"W4052\" was equipped with AI Mk\u00a0IV equipment, complete with an \"arrowhead\" transmission aerial mounted between the central Brownings and receiving aerials through the outer wing tips, and it was painted in black RDM2a \"Special Night\" finish. It was also the first prototype constructed with the extended engine nacelles. \"W4052\" was later tested with other modifications, including bomb racks, drop tanks, barrage balloon cable cutters in the leading edge of the wings, Hamilton airscrews and braking propellers, and drooping aileron systems that enabled steep approaches and a larger rudder tab. It continued to serve as a test machine until it was scrapped on 28 January 1946. \"4055\" flew the first operational Mosquito flight on 17 September 1941.\nDuring flight testing, the Mosquito prototypes were modified to test a number of configurations. \"W4050\" was fitted with a turret behind the cockpit for drag tests, after which the idea was abandoned in July 1941. \"W4052\" had the first version of the Youngman Frill airbrake fitted to the fighter prototype. The frill was mounted around the fuselage behind the wing and was opened by bellows and venturi effect to provide rapid deceleration during interceptions and was tested between January and August 1942, but was also abandoned when lowering the undercarriage was found to have the same effect with less buffeting.\nProduction plans and American interest.\nThe Air Ministry authorised mass production plans on 21 June 1941, by which time the Mosquito had become one of the world's fastest operational aircraft. It ordered 19 photo-reconnaissance (PR) models and 176 fighters. A further 50 were unspecified; in July 1941, these were confirmed to be unarmed fast bombers. By the end of January 1942, contracts had been awarded for 1,378 Mosquitoes of all variants, including 20 T.III trainers and 334 FB.VI bombers. Another 400 were to be built by de Havilland Canada.\nOn 20 April 1941, \"W4050\" was demonstrated to Lord Beaverbrook, the Minister of Aircraft Production. The Mosquito made a series of flights, including one rolling climb on one engine. Also present were US General Henry H. Arnold and his aide Major Elwood Quesada, who wrote \"I ... recall the first time I saw the Mosquito as being impressed by its performance, which we were aware of. We were impressed by the appearance of the airplane that looks fast usually is fast, and the Mosquito was, by the standards of the time, an extremely well-streamlined airplane, and it was highly regarded, highly respected.\"\nThe trials set up future production plans between Britain, Australia, and Canada. Six days later, Arnold returned to America with a full set of manufacturer's drawings. As a result of his report, five companies (Beech, Curtiss-Wright, Fairchild, Fleetwings, and Hughes) were asked to evaluate the de Havilland data. The report by Beech Aircraft summed up the general view: \"It appears as though this airplane has sacrificed serviceability, structural strength, ease of construction and flying characteristics in an attempt to use construction material which is not suitable for the manufacture of efficient airplanes.\" The Americans did not pursue the proposal for licensed production, the consensus arguing that the Lockheed P-38 Lightning could fulfill the same duties. However, Arnold urged the United States Army Air Forces (USAAF) to evaluate the design even if they would not adopt it. On 12 December 1941, after the attack on Pearl Harbor, the USAAF requested one airframe for this purpose.\nDesign and manufacture.\nOverview.\nWhile timber construction for aircraft was considered outmoded by some, de Havilland claimed that their successes with techniques used for the DH 91 Albatross could lead to a fast, light bomber using monocoque-sandwich shell construction. Arguments in favour of this included speed of prototyping, rapid development, minimisation of jig-building time, and employment of a separate category of workforce; many production facilities and skilled carpenters that previously manufactured furniture were repurposed to create components for the Mosquito, leveraging an existing workforce whose expertise was generally not being utilised during the war effort.\nThe ply-balsa-ply monocoque fuselage and one-piece wings with doped fabric covering would give excellent aerodynamic performance and low weight, combined with strength and stiffness. At the same time, the design team had to fight conservative Air Ministry views on defensive armament. Guns and gun turrets, favoured by the ministry, would impair the aircraft's aerodynamic properties and reduce speed and manoeuvrability, in the opinion of the designers. Whilst submitting these arguments, Geoffrey de Havilland funded his private venture until a very late stage. The project was a success beyond all expectations.\nAs a multi-role warplane, the Mosquito came in multiple versions: photo-reconnaissance (PR), bomber (B), fighter (F), night fighter (NF), fighter-bomber (FB), torpedo bomber (TR) with fold-up wings to fit more on a carrier, and trainer (T), each with varying modifications and weapon loadouts. Typical gun armament was four .303 caliber Browning machine guns and four 20\u00a0mm Hispano autocannons. Bomb load could be up to 4,000\u00a0lb (1,800\u00a0kg), allowing the Mosquito to carry a single \"Cookie\" blockbuster bomb, or a number of smaller ones.\nThe most-produced variant, designated the FB Mk. VI (Fighter-bomber Mark 6), was powered by two Merlin Mk.23 or Mk.25 engines driving three-bladed de Havilland hydromatic propellers. The typical fixed armament for an FB Mk. VI was four Browning .303 machine guns and four 20-mm Hispano cannons, while the offensive load consisted of up to of bombs, or eight RP-3 unguided rockets.\nPerformance.\nThe design was noted for light and effective control surfaces that provided good manoeuvrability, but required that the rudder not be used aggressively at high speeds. Poor aileron control at low speeds when landing and taking off was also a problem for inexperienced crews. For flying at low speeds, the flaps had to be set at 15\u00b0, speed reduced to , and rpm set to 2,650. The speed could be reduced to an acceptable for low-speed flying. For cruising, the optimum speed for obtaining maximum range was at weight.\nThe Mosquito had a high stalling speed of with undercarriage and flaps raised. When both were lowered, the stalling speed decreased from . Stall speed at normal approach angle and conditions was . Warning of the stall was given by buffeting and would occur before stall was reached. The conditions and impact of the stall were not severe. The wing did not drop unless the control column was pulled back. The nose drooped gently and recovery was easy.\nEarly on in the Mosquito's operational life, the intake shrouds that were to cool the exhausts on production aircraft overheated. Flame dampers prevented exhaust glow on night operations, but they had an effect on performance. Multiple ejector and open-ended exhaust stubs helped solve the problem and were used in the PR.VIII, B.IX, and B.XVI variants. This increased speed performance in the B.IX alone by .\nFuselage.\nThe oval-section fuselage was a frameless monocoque shell built in two vertically separate halves formed over a mahogany or concrete mould. Pressure was applied with band clamps. Some of the 1/2\u20143/4\" shell sandwich skins comprised 3/32\" birch three-ply outers, with 7/16\" cores of Ecuadorean balsa. In many generally smaller but vital areas, such as around apertures and attachment zones, stronger timbers, including aircraft-quality spruce, replaced the balsa core. The main areas of the sandwich skin were only thick. Together with various forms of wood reinforcement, often of laminated construction, the sandwich skin gave great stiffness and torsional resistance. The separate fuselage halves speeded construction, permitting access by personnel working in parallel with others, as the work progressed.\nWork on the separate half-fuselages included installation of control mechanisms and cabling. Screwed inserts into the inner skins that would be under stress in service were reinforced using round shear plates made from a fabric-Bakelite composite.\nTransverse bulkheads were also compositely built-up with several species of timber, plywood, and balsa. Seven vertically halved bulkheads were installed within each moulded fuselage shell before the main \"boxing up\" operation. Bulkhead number seven was especially strongly built, since it carried the fitments and transmitted the aerodynamic loadings for the tailplane and rudder. The fuselage had a large ventral section cut-out, strongly reinforced, that allowed the fuselage to be lowered onto the wing centre-section at a later stage of assembly.\nFor early production aircraft, the structural assembly adhesive was casein-based. At a later stage, this was replaced by \"Aerolite\", a synthetic urea-formaldehyde type, which was more durable. To provide for the edge joints for the fuselage halves, zones near the outer edges of the shells had their balsa sandwich cores replaced by much stronger inner laminations of birch plywood. For the bonding together of the two halves (\"boxing up\"), a longitudinal cut was machined into these edges. The profile of this cut was a form of V-groove. Part of the edge bonding process also included adding further longitudinal plywood lap strips on the outside of the shells. The half bulkheads of each shell were bonded to their corresponding pair in a similar way. Two laminated wooden clamps were used in the after portion of the fuselage to provide supports during this complex gluing work. The resulting large structural components had to be kept completely still and held in the correct environment until the glue cured.\nFor finishing, a covering of doped madapollam (a fine, plain-woven cotton) fabric was stretched tightly over the shell and several coats of red, followed by silver dope, were added, followed by the final camouflage paint.\nWing.\nThe all-wood wing pairs formed a single structural unit throughout the wingspan, with no central longitudinal joint. Instead, the spars ran from wingtip to wingtip. There was a single continuous main spar and another continuous rear spar. Because of the combination of dihedral with the forward sweep of the trailing edges of the wings, this rear spar was one of the most complex units to laminate and to finish machining after the bonding and curing. It had to produce the correct 3D tilt in each of two planes. Also, it was designed and made to taper from the wing roots towards the wingtips. Both principal spars were of ply box construction, using in general 0.25-in plywood webs with laminated spruce flanges, plus a number of additional reinforcements and special details.\nSpruce and plywood ribs were connected with gusset joints. Some heavy-duty ribs contained pieces of ash and walnut, as well as the special five ply that included veneers laid up at 45\u00b0. The upper skin construction was in two layers of 0.25-in five-ply birch, separated by Douglas fir stringers running in the span-wise direction. The wings were covered with madapollam fabric and doped in a similar manner to the fuselage. The wing was installed into the roots by means of four large attachment points. The engine radiators were fitted in the inner wing, just outboard of the fuselage on either side. These gave less drag. The radiators themselves were split into three sections: an oil cooler section outboard, the middle section forming the coolant radiator and the inboard section serving the cabin heater.\nThe wing contained metal-framed and -skinned ailerons, but the flaps were made of wood and were hydraulically controlled. The nacelles were mostly wood, although for strength, the engine mounts were all metal, as were the undercarriage parts. Engine mounts of welded steel tube were added, along with simple landing gear oleos filled with rubber blocks. Wood was used to carry only in-plane loads, with metal fittings used for all triaxially loaded components such as landing gear, engine mounts, control-surface mounting brackets, and the wing-to-fuselage junction. The outer leading wing edge had to be brought further forward to accommodate this design. The main tail unit was all wood built. The control surfaces, the rudder, and elevator were aluminium-framed and fabric-covered. The total weight of metal castings and forgings used in the aircraft was only .\nIn November 1944, several crashes occurred in the Far East. At first, these were thought to be a result of wing-structure failures. The casein glue, it was said, cracked when exposed to extreme heat and/or monsoon conditions. This caused the upper surfaces to lift from the main spar. An investigating team led by Major Hereward de Havilland travelled to India and produced a report in early December 1944 stating, \"the accidents were not caused by the deterioration of the glue, but by shrinkage of the airframe during the wet monsoon season\". However, a later inquiry by Cabot &amp; Myers firmly attributed the accidents to faulty manufacture and this was confirmed by a further investigation team by the Ministry of Aircraft Production at Defford, which found faults in six Mosquito marks (all built at de Havilland's Hatfield and Leavesden plants). The defects were similar, and none of the aircraft had been exposed to monsoon conditions or termite attack.\nThe investigators concluded that construction defects occurred at the two plants. They found that the \"...standard of glueing\u00a0... left much to be desired.\" Records at the time showed that accidents caused by \"loss of control\" were three times more frequent on Mosquitoes than on any other type of aircraft. The Air Ministry forestalled any loss of confidence in the Mosquito by holding to Major de Havilland's initial investigation in India that the accidents were caused \"largely by climate\" To solve the problem of seepage into the interior, a strip of plywood was set along the span of the wing to seal the entire length of the skin joint.\nSystems.\nThe fuel systems gave the Mosquito good range and endurance, using up to nine fuel tanks. Two outer wing tanks each contained of fuel. These were complemented by two inner wing fuel tanks, each containing , located between the wing root and engine nacelle. In the central fuselage were twin fuel tanks mounted between bulkhead number two and three aft of the cockpit. In the FB.VI, these tanks contained each, while in the B.IV and other unarmed Mosquitoes each of the two centre tanks contained . Both the inner wing, and fuselage tanks are listed as the \"main tanks\" and the total internal fuel load of was initially deemed appropriate for the type. In addition, the FB Mk. VI could have larger fuselage tanks, increasing the capacity to . Drop tanks of or could be mounted under each wing, increasing the total fuel load to .\nThe design of the Mk.VI allowed for a provisional long-range fuel tank to increase range for action over enemy territory, for the installation of bomb release equipment specific to depth charges for strikes against enemy shipping, or for the simultaneous use of rocket projectiles along with a drop tank under each wing supplementing the main fuel cells. The FB.VI had a wingspan of , a length (over guns) of . It had a maximum speed of at . Maximum take-off weight was and the range of the aircraft was with a service ceiling of .\nTo reduce fuel vaporisation at the high altitudes of photographic reconnaissance variants, the central and inner wing tanks were pressurised. The pressure venting cock located behind the pilot's seat controlled the pressure valve. As the altitude increased, the valve increased the volume applied by a pump. This system was extended to include field modifications of the fuel tank system.\nThe engine oil tanks were in the engine nacelles. Each nacelle contained a oil tank, including a air space. The oil tanks themselves had no separate coolant controlling systems. The coolant header tank was in the forward nacelle, behind the propeller. The remaining coolant systems were controlled by the coolant radiators shutters in the forward inner wing compartment, between the nacelle and the fuselage and behind the main engine cooling radiators, which were fitted in the leading edge. Electric-pneumatic operated radiator shutters directed and controlled airflow through the ducts and into the coolant valves, to predetermined temperatures.\nElectrical power came from a 24 volt DC generator on the starboard (No. 2) engine and an alternator on the port engine, which also supplied AC power for radios. The radiator shutters, supercharger gear change, gun camera, bomb bay, bomb/rocket release and all the other crew controlled instruments were powered by a 24 V battery. The radio communication devices included VHF and HF communications, GEE navigation, and IFF and G.P. devices. The electric generators also powered the fire extinguishers. Located on the starboard side of the cockpit, the switches would operate automatically in the event of a crash. In flight, a warning light would flash to indicate a fire, should the pilot not already be aware of it. In later models, to save liquids and engine clean up time in case of belly landing, the fire extinguisher was changed to semi-automatic triggers.\nThe main landing gear, housed in the nacelles behind the engines, were raised and lowered hydraulically. The main landing gear shock absorbers were de Havilland manufactured and used a system of rubber in compression, rather than hydraulic oleos, with twin pneumatic brakes for each wheel. The Dunlop-Marstrand anti-shimmy tailwheel was also retractable.\nOperational history.\nThe de Havilland Mosquito operated in many roles, performing medium bomber, reconnaissance, tactical strike, anti-submarine warfare, shipping attacks and night fighter duties, until the end of the war. In July 1941, the first production Mosquito \"W4051\" (a production fuselage combined with some prototype flying surfaces \u2013 see Prototypes and test flights) was sent to No. 1 Photographic Reconnaissance Unit (PRU), at RAF Benson. The secret reconnaissance flights of this aircraft were the first operational missions of the Mosquito. In 1944, the journal \"Flight\" gave 19 September 1941 as date of the first PR mission, at an altitude \"of some 20,000 ft\".\nOn 15 November 1941, 105 Squadron, RAF, took delivery at RAF Swanton Morley, Norfolk, of the first operational Mosquito Mk. B.IV bomber, serial no. \"W4064\". Throughout 1942, 105 Squadron, based next at RAF Horsham St. Faith, then from 29 September, RAF Marham, undertook daylight low-level and shallow dive attacks. Apart from the Oslo and Berlin raids, the strikes were mainly on industrial and infrastructure targets in occupied Netherlands and Norway, France and northern and western Germany. The crews faced deadly flak and fighters, particularly Focke-Wulf Fw 190s, which they called \"snappers\". Germany still controlled continental airspace and the Fw 190s were often already airborne and at an advantageous altitude. Collisions within the formations also caused casualties. It was the Mosquito's excellent handling capabilities, rather than pure speed, that facilitated successful evasions.\nThe Mosquito was first announced publicly on 26 September 1942 after the Oslo Mosquito raid of 25 September. It was featured in \"The Times\" on 28 September and the next day the newspaper published two captioned photographs illustrating the bomb strikes and damage. On 6 December 1942, Mosquitoes from Nos. 105 and 139 Squadrons made up part of the bomber force used in Operation Oyster, the large No. 2 Group raid against the Philips works at Eindhoven.\nFrom mid-1942 to mid-1943, Mosquito bombers flew high-speed, medium and low-altitude daylight missions against factories, railways and other pinpoint targets in Germany and German-occupied Europe. From June 1943, Mosquito bombers were formed into the Light Night Striking Force to guide RAF Bomber Command heavy bomber raids and as \"nuisance\" bombers, dropping Blockbuster bombs \u2013 \"cookies\" \u2013 in high-altitude, high-speed raids that German night fighters were almost powerless to intercept.\nAs a night fighter from mid-1942, the Mosquito intercepted \"Luftwaffe\" raids on Britain, notably those of Operation Steinbock in 1944. Starting in July 1942, Mosquito night-fighter units raided \"Luftwaffe\" airfields. As part of 100 Group, it was flown as a night fighter and as an intruder supporting Bomber Command heavy bombers that reduced losses during 1944 and 1945.\nThe Mosquito fighter-bomber served as a strike aircraft in the Second Tactical Air Force (2TAF) from its inception on 1 June 1943. The main objective was to prepare for the invasion of occupied Europe a year later. In Operation Overlord three Mosquito FB Mk. VI wings flew close air support for the Allied armies in co-operation with other RAF units equipped with the North American B-25 Mitchell medium bomber. In the months between the foundation of 2TAF and its duties from D day onwards, vital training was interspersed with attacks on V-1 flying bomb launch sites.\nIn another example of the daylight precision raids carried out by the Mosquitoes of Nos. 105 and 139 Squadrons, on 30 January 1943, the 10th anniversary of the Nazis' seizure of power, a morning Mosquito attack knocked out the main Berlin broadcasting station while \"Luftwaffe\" Chief Reichsmarschall Hermann G\u00f6ring was speaking, putting his speech off the air. A second sortie in the afternoon inconvenienced another speech, by Propaganda Minister Joseph Goebbels. Lecturing a group of German aircraft manufacturers, G\u00f6ring said:\nDuring this daylight-raiding phase, Nos. 105 and 139 Squadrons flew 139 combat operations and aircrew losses were high. Even the losses incurred in the squadrons' dangerous Blenheim era were exceeded in percentage terms. The Roll of Honour shows 51 aircrew deaths from the end of May 1942 to April 1943. In the corresponding period, crews gained three Mentions in Despatches, two DFMs and three DFCs. The low-level daylight attacks finished on 27 May 1943 with strikes on the Schott glass and Zeiss instrument works, both in Jena. Subsequently, when low-level precision attacks required Mosquitoes, they were allotted to squadrons operating the FB.IV version. Examples include the Aarhus air raid and Operation Jericho.\nSince the beginning of the year, the German fighter force had become seriously overstretched. In April 1943, in response to \"political humiliation\" caused by the Mosquito, G\u00f6ring ordered the formation of special \"Luftwaffe\" units (\"Jagdgeschwader 25\", commanded by \"Oberstleutnant\" Herbert Ihlefeld and \"Jagdgeschwader 50\", under \"Major\" Hermann Graf) to combat the Mosquito attacks, though these units, which were \"little more than glorified squadrons\", were unsuccessful against the elusive RAF aircraft. Post-war German histories also indicate that there was a belief within the Luftwaffe that Mosquito aircraft \"gave only a weak radar signal.\".\nThe first Mosquito Squadron to be equipped with the Oboe bomb aiming system was No. 109, based at RAF Wyton, after working as an experimental unit at RAF Boscombe Down. They used Oboe operationally for the first time on 31 December 1942 and 1 January 1943, target marking for a force of heavy bombers attacking D\u00fcsseldorf.. On 1 June, the two pioneering Squadrons joined No. 109 Squadron in the re-formed No. 8 Group RAF (Bomber Command). Initially they were engaged in moderately high altitude (about ) night bombing, with 67 trips during that summer, mainly to Berlin. Soon after, Nos. 105 and 139 Squadron bombers were widely used by the RAF Pathfinder Force, marking targets for the main night-time strategic bombing force.\nIn what were, initially, diversionary \"nuisance raids,\" Mosquito bombers dropped 4,000\u00a0lb Blockbuster bombs or \"Cookies.\" Particularly after the introduction of H2S (radar) in some Mosquitoes, these raids carrying larger bombs succeeded to the extent that they provided a significant additional form of attack to the large formations of \"heavies.\" Latterly in the war, there were a significant number of all-Mosquito raids on big German cities involving up to 100 or more aircraft. On the night of 20/21 February 1945, for example, Mosquitoes of No. 8 Group mounted the first of 36 consecutive night raids on Berlin.\nFrom 1943, Mosquitoes with RAF Coastal Command attacked \"Kriegsmarine\" U-boats and intercepted transport ship concentrations. After Operation Overlord, the U-boat threat in the Western Approaches decreased fairly quickly, but correspondingly the Norwegian and Danish waters posed greater dangers. Hence the RAF Coastal Command Mosquitoes were moved to Scotland to counter this threat. The Strike Wing at Banff stood up in September 1944 and comprised Mosquito aircraft of No's 143, 144, 235 and 248 Squadrons Royal Air Force and No.333 Squadron Royal Norwegian Air Force. Despite an initially high loss rate, the Mosquito bomber variants ended the war with the lowest losses of any aircraft in RAF Bomber Command service.\nThe Mosquito also proved a very capable night fighter. Some of the most successful RAF pilots flew these variants. For example, Wing Commander Branse Burbridge claimed 21 kills.\nMosquitoes of No. 100 Group RAF acted as night intruders operating at high level in support of the Bomber Command \"heavies\", to counter the enemy tactic of merging into the bomber stream, which, towards the end of 1943, was causing serious allied losses. These RCM (radio countermeasures) aircraft were fitted with a device called \"Serrate\" to allow them to track down German night fighters from their \"Lichtenstein B/C\" (low-UHF-band) and \"Lichtenstein SN-2\" (lower end of the VHF FM broadcast band) radar emissions, as well as a device named \"Perfectos\" that tracked German IFF signals. These methods were responsible for the destruction of 257 German aircraft from December 1943 to April 1945. Mosquito fighters from all units accounted for 487 German aircraft during the war, the vast majority of which were night fighters.\nNight fighter Mosquitos were often tasked with attacking German planes landing at airfields. In 1943, the Germans became acquainted with \"Moskitoschreck\", \"Mosquito terror,\" the constant fear of an unexpected Mosquito attack during a nighttime landing.\nOne Mosquito is listed as belonging to German secret operations unit \"Kampfgeschwader 200\", which tested, evaluated and sometimes clandestinely operated captured enemy aircraft during the war. The aircraft was listed on the order of battle of \"Versuchsverband OKL\"s, \"2 Staffel\", \"Stab Gruppe\" on 10 November and 31 December 1944. However, on both lists, the Mosquito is listed as unserviceable.\nThe Mosquito flew its last official European war mission on 21 May 1945, when Mosquitoes of 143 Squadron and 248 Squadron RAF were ordered to continue to hunt German submarines that might be tempted to continue the fight; instead of submarines all the Mosquitoes encountered were passive E-boats.\nThe last operational RAF Mosquitoes were the Mosquito TT.35's, which were finally retired from No. 3 Civilian Anti-Aircraft Co-Operation Unit (CAACU) in May 1963.\nIn 1947\u201349, up to 180 Canadian surplus Mosquitoes flew many operations for the Nationalist Chinese under Chiang Kai-shek in the civil war against Communist forces. Pilots from three squadrons of Mosquitoes claimed to have sunk or damaged 500 ships during one invasion attempt. As the Communists assumed control, the remaining aircraft were evacuated to Formosa, where they flew missions against shipping.\nVariants.\nUntil the end of 1942 the RAF always used Roman numerals (I, II, ...) for mark numbers; 1943\u20131948 was a transition period during which new aircraft entering service were given Arabic numerals (1, 2, ...) for mark numbers, but older aircraft retained their Roman numerals. From 1948 onwards, Arabic numerals were used exclusively.\nPrototypes.\nThree prototypes were built, each with a different configuration. The first to fly was \"W4050\" on 25 November 1940, followed by the fighter \"W4052\" on 15 May 1941 and the photo-reconnaissance prototype \"W4051\" on 10 June 1941. \"W4051\" later flew operationally with 1 Photographic Reconnaissance Unit (1 PRU).\nPhoto-reconnaissance.\nA total of 10 Mosquito PR Mk.Is were built, four of them \"long range\" versions equipped with a overload fuel tank in the fuselage. The contract called for 10 of the PR Mk.I airframes to be converted to B Mk.IV Series 1s. All of the PR Mk.Is, and the B Mk.IV Series 1s, had the original short engine nacelles and short span (19\u00a0ft 5.5 in) tailplanes. Their engine cowlings incorporated the original pattern of integrated exhaust manifolds, which, after relatively brief flight time, had a troublesome habit of burning and blistering the cowling panels. The first operational sortie by a Mosquito was made by a PR Mk.I, W4055, on 17 September 1941; during this sortie the unarmed Mosquito PR.I evaded three Messerschmitt Bf 109s at . Powered by two Merlin 21s, the PR Mk.I had a maximum speed of , a cruise speed of , a ceiling of , a range of , and a climb rate of per minute.\nOver 30 Mosquito B Mk.IV bombers were converted into the PR Mk.IV photo-reconnaissance aircraft. The first operational flight by a PR Mk.IV was made by \"DK284\" in April 1942.\nThe Mosquito PR Mk.VIII, built as a stopgap pending the introduction of the refined PR Mk.IX, was the next photo-reconnaissance version. The five VIIIs were converted from B Mk.IVs and became the first operational Mosquito version to be powered by two-stage, two-speed supercharged engines, using Rolls-Royce Merlin 61 engines in place of Merlin 21/22s. The first PR Mk.VIII, \"DK324\" first flew on 20 October 1942. The PR Mk.VIII had a maximum speed of , an economical cruise speed of at 20,000\u00a0ft, and at 30,000\u00a0ft, a ceiling of , a range of , and a climb rate of 2,500\u00a0ft per minute (760 m).\nThe Mosquito PR Mk.IX, 90 of which were built, was the first Mosquito variant with two-stage, two-speed engines to be produced in quantity; the first of these, \"LR405\", first flew in April 1943. The PR Mk.IX was based on the Mosquito B Mk.IX bomber and was powered by two Merlin 72/73 or 76/77 engines. It could carry either two , two or two droppable fuel tanks.\nThe Mosquito PR Mk.XVI had a pressurised cockpit and, like the Mk.IX, was powered by two Rolls-Royce Merlin 72/73 or 76/77 piston engines. This version was equipped with three overload fuel tanks, totalling in the bomb bay, and could also carry two or drop tanks. A total of 435 of the PR Mk.XVI were built. The PR Mk.XVI had a maximum speed of , a cruise speed of , ceiling of , a range of , and a climb rate of 2,900 feet per minute (884 m).\nThe Mosquito PR Mk.32 was a long-range, high-altitude, pressurised photo-reconnaissance version. It was powered by a pair of two-stage supercharged Rolls-Royce Merlin 113 and Merlin 114 piston engines, the Merlin 113 on the starboard side and the Merlin 114 on the port. First flown in August 1944, only five were built and all were conversions from PR.XVIs.\nThe Mosquito PR Mk.34 and PR Mk.34A was a very long-range unarmed high altitude photo-reconnaissance version. The fuel tank and cockpit protection armour were removed. Additional fuel was carried in a bulged bomb bay: 1,192 gallons\u2014the equivalent of . A further two 200-gallon (910-litre) drop tanks under the outer wings gave a range of cruising at . Powered by two Merlin 114s first used in the PR.32. The port Merlin 114 drove a Marshal cabin supercharger. A total of 181 were built, including 50 built by Percival Aircraft Company at Luton. The PR.34's maximum speed (TAS) was at sea level, at and at .\nAll PR.34s were installed with four split F52 vertical cameras, two forward, two aft of the fuselage tank and one F24 oblique camera. Sometimes a K-17 camera was used for air surveys. In August 1945, the PR.34A was the final photo-reconnaissance variant with one Merlin 113A and 114A each delivering .\nColonel Roy M. Stanley II, USAF (RET) wrote: \"I consider the Mosquito the best photo-reconnaissance aircraft of the war\".\nAfter the end of World War II Spartan Air Services used ten ex-RAF Mosquitoes, mostly B.35s plus one of only six PR.35s built, for high-altitude photographic survey work in Canada.\nBombers.\nOn 21 June 1941 the Air Ministry ordered that the last 10 Mosquitoes, ordered as photo-reconnaissance aircraft, should be converted to bombers. These 10 aircraft were part of the original 1 March 1940 production order and became the B Mk.IV Series 1. \"W4052\" was to be the prototype and flew for the first time on 8 September 1941.\nThe bomber prototype led to the B Mk.IV, of which 273 were built: apart from the 10 Series 1s, all of the rest were built as Series 2s with extended nacelles, revised exhaust manifolds, with integrated flame dampers, and larger tailplanes. Series 2 bombers also differed from the Series 1 in having an increased payload of four bombs, instead of the four bombs of Series 1. This was made possible by \"cropping\", or shortening the tail of the bomb so that these four heavier weapons could be carried (or a 2,000\u00a0lb (920\u00a0kg) total load). The B Mk.IV entered service in May 1942 with 105 Squadron.\nIn April 1943 it was decided to convert a B Mk.IV to carry a Blockbuster bomb (nicknamed a Cookie). The conversion, including modified bomb bay suspension arrangements, bulged bomb bay doors and fairings, was relatively straightforward and 54 B.IVs were modified and distributed to squadrons of the Light Night Striking Force. 27 B Mk.IVs were later converted for special operations with the Highball anti-shipping weapon, and were used by 618 Squadron, formed in April 1943 specifically to use this weapon. A B Mk.IV, \"DK290\" was initially used as a trials aircraft for the bomb, followed by \"DZ471,530 and 533\". The B Mk.IV had a maximum speed of , a cruising speed of , ceiling of , a range of , and a climb rate of 2,500\u00a0ft per minute (12.7\u00a0m/s).\nOther bomber variants of the Mosquito included the Merlin 21 powered B Mk.V high-altitude version. Trials with this configuration were made with \"W4057\", which had strengthened wings and two additional fuel tanks, or alternatively, two bombs. This design was not produced in Britain, but formed the basic design of the Canadian-built B.VII. Only \"W4057\" was built in prototype form. The Merlin 31 powered B Mk.VII was built by de Havilland Canada and first flown on 24 September 1942. It only saw service in Canada, 25 were built. Six were handed over to the United States Army Air Forces.\nB Mk.IX (54 built) was powered by the Merlin 72,73, 76 or 77. The two-stage Merlin variant was based on the PR.IX. The prototype \"DK 324\" was converted from a PR.VIII and first flew on 24 March 1943. In October 1943 it was decided that all B Mk.IVs and all B Mk.IXs then in service would be converted to carry the \"Cookie\", and all B Mk.IXs built after that date were designed to allow them to be converted to carry the weapon. The B Mk.IX had a maximum speed of , an economical cruise speed of at 20,000\u00a0ft, and at 30,000\u00a0ft, ceiling of , a range of , and a climb rate of 2,850 feet per minute (14.5\u00a0m/s). The IX could carry a maximum load of of bombs. A Mosquito B Mk.IX holds the record for the most combat operations flown by an Allied bomber in the Second World War. \"LR503\", known as \"F for Freddie\" (from its squadron code letters, GB*F), first served with No. 109 and subsequently, No. 105 RAF squadrons. It flew 213 sorties during the war, only to crash at Calgary airport during the Eighth Victory Loan Bond Drive on 10 May 1945, two days after Victory in Europe Day, killing both the pilot, Flt. Lt. Maurice Briggs, DSO, DFC, DFM and navigator Fl. Off. John Baker, DFC and Bar.\nThe B Mk.XVI was powered by the same variations as the B.IX. All B Mk.XVIs were capable of being converted to carry the \"Cookie\". The two-stage powerplants were added along with a pressurised cabin. \"DZ540\" first flew on 1 January 1944. The prototype was converted from a IV (402 built). The next variant, the B Mk.XX, was powered by Packard Merlins 31 and 33s. It was the Canadian version of the IV. Altogether, 245 were built. The B Mk.XVI had a maximum speed of , an economical cruise speed of at 20,000\u00a0ft, and at 30,000\u00a0ft, ceiling of , a range of , and a climb rate of 2,800\u00a0ft per minute (14\u00a0m/s). The type could carry of bombs.\nThe B.35 was powered by Merlin 113 and 114As. Some were converted to TT.35s (Target Tugs) and others were used as PR.35s (photo-reconnaissance). The B.35 had a maximum speed of , a cruising speed of , ceiling of , a range of , and a climb rate of 2,700\u00a0ft per minute (13.7\u00a0m/s). A total of 174 B.35s were delivered up to the end of 1945. A further 100 were delivered from 1946 for a grand total of 274, 65 of which were built by Airspeed Ltd.\nFighters.\nDeveloped during 1940, the first prototype of the Mosquito F Mk.II was completed on 15 May 1941. These Mosquitoes were fitted with four Hispano cannon in the fuselage belly and four .303 (7.7 mm) Browning machine guns mounted in the nose. On production Mk.IIs the machine guns and ammunition tanks were accessed via two centrally hinged, sideways opening doors in the upper nose section. To arm and service the cannon the bomb bay doors were replaced by manually operated bay doors: the F and NF Mk.IIs could not carry bombs. The type was also fitted with a gun camera in a compartment above the machine guns in the nose and was fitted with exhaust flame dampers to reduce the glare from the Merlin XXs.\nIn the summer of 1942, Britain experienced day-time incursions of the high-altitude reconnaissance bomber, the Junkers Ju 86P. Although the Ju 86P only carried a light bomb load, it overflew sensitive areas, including Bristol, Bedfordshire and Hertfordshire. Bombs were dropped on Luton and elsewhere, and this particular aircraft was seen from the main de Havilland offices and factory at Hatfield. An attempt to intercept it with a Spitfire from RAF Manston was unsuccessful. As a result of the potential threat, a decision was quickly taken to develop a high-altitude Mosquito interceptor, using the \"MP469\" prototype.\n\"MP469\" entered the experimental shop on 7 September and made its initial flight on 14 September, piloted by John de Havilland. The bomber nose was altered using a normal fighter nose, armed with four standard .303 (7.7 mm) Browning machine guns. The low pressure cabin retained a bomber canopy structure and a two-piece windscreen. The control wheel was replaced with a fighter control stick. The wingspan was increased to . The airframe was lightened by removing armour plating, some fuel tanks and other fitments. Smaller-diameter main wheels were fitted after the first few flights. At a loaded weight of this HA Mk.XV was lighter than a standard Mk.II. For this first conversion, the engines were a pair of Merlin 61s. On 15 September, John de Havilland reached an altitude of in this version. The aircraft was delivered to a High Altitude Flight which had been formed at RAF Northolt. However, the high-level German daylight intruders were no longer to be seen. It was subsequently revealed that only five Ju 86P aircraft had been built and they had only flown 12 sorties. Nevertheless, the general need for high altitude interceptors was recognised \u2013 but now the emphasis was to be upon night fighters.\nThe A&amp;AEE tested the climb and speed of night fighter conversion of MP469 in January 1943 for the Ministry of Aircraft Production. Wingspan had been increased to , the Brownings had been moved to a fairing below the fuselage. According to Birtles, an AI radar was mounted in the nose and the Merlins were upgraded to Mk76 type, although Boscombe Down reported Merlin 61s. In addition to MP469, four more B Mk.IVs were converted into NF MK XVs. The Fighter Interception Unit at RAF Ford carried out service trials, March 1943, and then these five aircraft went to 85 Squadron, Hunsdon, where they were flown from April until August of that year. The greatest height reached in service was .\nApart from the F Mk.XV, all Mosquito fighters and fighter bombers featured a modified canopy structure incorporating a flat, single piece armoured windscreen, and the crew entry/exit door was moved from the bottom of the forward fuselage to the right side of the nose, just forward of the wing leading edge.\nNight fighters.\nAt the end of 1940, the Air Staff's preferred turret-equipped night fighter design to Operational Requirement O.R. 95 was the Gloster F.18/40 (derived from their F.9/37). However, although in agreement as to the quality of the Gloster company's design, the Ministry of Aircraft Production was concerned that Gloster would not be able to work on the F.18/40 and also the jet fighter design, considered the greater priority. Consequently, in mid-1941 the Air Staff and MAP agreed that the Gloster aircraft would be dropped and the Mosquito, when fitted with a turret would be considered for the night fighter requirement.\nThe first production night fighter Mosquitoes \u2013 minus turrets \u2013 were designated NF Mk.II. A total of 466 were built with the first entering service with No. 157 Squadron in January 1942, replacing the Douglas Havoc. These aircraft were similar to the F Mk.II, but were fitted with the AI Mk.IV metric wavelength radar. The herring-bone transmitting antenna was mounted on the nose and the dipole receiving antennae were carried under the outer wings. A number of NF IIs had their radar equipment removed and additional fuel tanks installed in the bay behind the cannon for use as night intruders. These aircraft, designated NF II (Special) were first used by 23 Squadron in operations over Europe in 1942. 23 Squadron was then deployed to Malta on 20 December 1942, and operated against targets in Italy.\nNinety-seven NF Mk.IIs were upgraded with 3.3\u00a0GHz frequency, low-SHF-band AI Mk.VIII radar and these were designated NF Mk.XII. The NF Mk.XIII, of which 270 were built, was the production equivalent of the Mk.XII conversions. These \"centimetric\" radar sets were mounted in a solid \"thimble\" (Mk.XII / XIII) or universal \"bull nose\" (Mk.XVII / XIX) radome, which required the machine guns to be dispensed with.\nFour F Mk.XVs were converted to the NF Mk.XV. These were fitted with AI Mk.VIII in a \"thimble\" radome, and the .303 Brownings were moved into a gun pack fitted under the forward fuselage.\n NF Mk.XVII was the designation for 99 NF Mk.II conversions, with single-stage Merlin 21, 22, or 23 engines, but British AI.X (US SCR-720) radar.\nThe NF Mk.XIX was an improved version of the NF XIII. It could be fitted with American or British AI radars; 220 were built.\nThe NF Mk.30 was the final wartime variant and was a high-altitude version, powered by two Rolls-Royce Merlin 76s. The NF Mk.30 had a maximum speed of at . It also carried early electronic countermeasures equipment. 526 were built.\nOther Mosquito night fighter variants planned but never built included the NF Mk.X and NF Mk.XIV (the latter based on the NF Mk.XIII), both of which were to have two-stage Merlins. The NF Mk.31 was a variant of the NF Mk.30, but powered by Packard Merlins.\nAfter the war, two more night fighter versions were developed:\nThe NF Mk.36 was similar to the Mosquito NF Mk.30, but fitted with the American-built AI.Mk.X radar. Powered by two Rolls-Royce Merlin 113/114 piston engines; 266 built. Max level speeds (TAS) with flame dampers fitted were at sea level, at , and at .\nThe NF Mk.38, 101 of which were built, was also similar to the Mosquito NF Mk.30, but fitted with the British-built AI Mk.IX radar. This variant suffered from stability problems and did not enter RAF service: 60 were eventually sold to Yugoslavia. According to the Pilot's Notes and Air Ministry 'Special Flying Instruction TF/487', which posted limits on the Mosquito's maximum speeds, the NF Mk.38 had a VNE of 370 knots (425\u00a0mph), without under-wing stores, and within the altitude range of sea level to . However, from 10,000 to the maximum speed was 348 knots (400\u00a0mph). As the height increased other recorded speeds were; 15,000 to 320 knots (368\u00a0mph); 20,000 to , 295 knots (339\u00a0mph); 25,000 to , 260 knots (299\u00a0mph); 30,000 to , 235 knots (270\u00a0mph). With two added 100-gallon fuel tanks this performance fell; between sea level and 15,000 feet 330 knots (379\u00a0mph); between 15,000 and 320 knots (368\u00a0mph); 20,000 to , 295 knots (339\u00a0mph); 25,000 to , 260 knots (299\u00a0mph); 30,000 to , 235 knots (270\u00a0mph). Little difference was noted above .\nStrike (\"fighter-bomber\") variants.\nThe FB Mk. VI, which first flew on 1 June 1942, was powered by two, single-stage two-speed, Merlin 21s or Merlin 25s, and introduced a re-stressed and reinforced \"basic\" wing structure capable of carrying single bombs on racks housed in streamlined fairings under each wing, or up to eight RP-3 25lb or 60 lb rockets. In addition fuel lines were added to the wings to enable single or drop tanks to be carried under each wing. The usual fixed armament was four 20\u00a0mm Hispano Mk.II cannon and four .303 (7.7\u00a0mm) Browning machine guns, while two bombs could be carried in the bomb bay.\nUnlike the F Mk.II, the ventral bay doors were split into two pairs, with the forward pair being used to access the cannon, while the rear pair acted as bomb bay doors. The maximum fuel load was distributed between internal fuel tanks, plus two overload tanks, each of capacity, which could be fitted in the bomb bay, and two drop tanks. All-out level speed is often given as , although this speed applies to aircraft fitted with saxophone exhausts. The test aircraft (\"HJ679\") fitted with stub exhausts was found to be performing below expectations. It was returned to de Havilland at Hatfield where it was serviced. Its top speed was then tested and found to be , in line with expectations. 2,298 FB Mk. VIs were built, nearly one-third of Mosquito production. Two were converted to TR.33 carrier-borne, maritime strike prototypes.\nThe FB Mk. VI proved capable of holding its own against fighter aircraft, in addition to strike/bombing roles. For example, on 15 January 1945 Mosquito FB Mk. VIs of 143 Squadron were engaged by 30 Focke-Wulf Fw 190s from \"Jagdgeschwader 5\": the Mosquitoes sank an armed trawler and two merchant ships, but five Mosquitoes were lost (two reportedly to flak), while shooting down five Fw 190s.\nAnother fighter-bomber variant was the Mosquito FB Mk. XVIII (sometimes known as the \"Tsetse\") of which one was converted from a FB Mk. VI to serve as prototype and 17 were purpose-built. The Mk.XVIII was armed with a Molins \"6-pounder Class M\" cannon: this was a modified QF 6-pounder (57\u00a0mm) anti-tank gun fitted with an auto-loader to allow both semi- or fully automatic fire. 25 rounds were carried, with the entire installation weighing . In addition, of armour was added within the engine cowlings, around the nose and under the cockpit floor to protect the engines and crew from heavily armed U-boats, the intended primary target of the Mk.XVIII. Two or four .303 (7.7\u00a0mm) Browning machine guns were retained in the nose and were used to \"sight\" the main weapon onto the target.\nThe Air Ministry initially suspected that this variant would not work, but tests proved otherwise. Although the gun provided the Mosquito with yet more anti-shipping firepower for use against U-boats, it required a steady approach run to aim and fire the gun, making its wooden construction an even greater liability, in the face of intense anti-aircraft fire. The gun had a muzzle velocity of and an excellent range of some . It was sensitive to sidewards movement; an attack required a dive from at a 30\u00b0 angle with the turn and bank indicator on centre. A move during the dive could jam the gun. The prototype \"HJ732\" was converted from a FB.VI and was first flown on 8 June 1943.\nThe effect of the new weapon was demonstrated on 10 March 1944 when Mk.XVIIIs from 248 Squadron (escorted by four Mk.VIs) engaged a German convoy of one U-boat and four destroyers, protected by 10 Ju 88s. Three of the Ju 88s were shot down. Pilot Tony Phillips destroyed one Ju 88 with four shells, one of which tore an engine off the Ju 88. The U-boat was damaged. On 25 March, was sunk by Molins-equipped Mosquitoes. On 10 June, was abandoned in the face of intense air attack from No. 248 Squadron, and was later sunk by a Liberator of No. 206 Squadron. On 5 April 1945 Mosquitoes with Molins attacked five German surface ships in the Kattegat and again demonstrated their value by setting them all on fire and sinking them. A German \"Sperrbrecher\" (\"minefield breaker\") was lost with all hands, with some 200 bodies being recovered by Swedish vessels. Some 900 German soldiers died in total. On 9 April, German U-boats , and were spotted in formation heading for Norway. All were sunk with rockets. and followed on 19 April and 2 May 1945, also sunk by rockets.\nDespite the preference for rockets, a further development of the large gun idea was carried out using the even larger, 96\u00a0mm calibre QF 32-pounder, a gun based on the QF 3.7-inch AA gun designed for tank use, the airborne version using a novel form of muzzle brake. Developed to prove the feasibility of using such a large weapon in the Mosquito, this installation was not completed until after the war, when it was flown and fired in a single aircraft without problems, then scrapped.\nDesigns based on the Mk.VI were the FB Mk. 26, built in Canada, and the FB Mk.40, built in Australia, powered by Packard Merlins. The FB.26 improved from the FB.21 using single stage Packard Merlin 225s. Some 300 were built and another 37 converted to T.29 standard. 212 FB.40s were built by de Havilland Australia. Six were converted to PR.40; 28 to PR.41s, one to FB.42 and 22 to T.43 trainers. Most were powered by Packard-built Merlin 31 or 33s.\nTrainers.\nThe Mosquito was also built as the Mosquito T Mk.III two-seat trainer. This version, powered by two Rolls-Royce Merlin 21s, was unarmed and had a modified cockpit fitted with dual control arrangements. A total of 348 of the T Mk.III were built for the RAF and Fleet Air Arm. de Havilland Australia built 11 T Mk.43 trainers, similar to the Mk.III.\nTorpedo-bombers.\nTo meet specification N.15/44 for a navalised Mosquito for Royal Navy use as a torpedo bomber, de Havilland produced a carrier-borne variant. A Mosquito FB.VI was modified as a prototype designated Sea Mosquito TR Mk.33 with folding wings, arrester hook, thimble nose radome, Merlin 25 engines with four-bladed propellers and a new oleo-pneumatic landing gear rather than the standard rubber-in-compression gear. Initial carrier tests of the Sea Mosquito were carried out by Eric \"Winkle\" Brown aboard HMS \"Indefatigable\", the first landing-on taking place on 25 March 1944. An order for 100 TR.33s was placed although only 50 were built at Leavesden. Armament was four 20\u00a0mm cannon, two 500\u00a0lb bombs in the bomb bay (another two could be fitted under the wings), eight 60\u00a0lb rockets (four under each wing) and a standard torpedo under the fuselage. The first production TR.33 flew on 10 November 1945. This series was followed by six Sea Mosquito TR Mk.37s, which were built at Chester (Broughton) and differed in having ASV Mk.XIII radar instead of the TR.33's AN/APS-6.\nTarget tugs.\nThe RAF's target tug version was the Mosquito TT Mk.35, which were the last aircraft to remain in operational service with No 3 CAACU at Exeter, being finally retired in 1963. These aircraft were then featured in the film 633 Squadron.\nA number of B Mk.XVIs bombers were converted into TT Mk.39 target tug aircraft. The Royal Navy also operated the Mosquito TT Mk.39 for target towing.\nTwo ex-RAF FB.6s were converted to TT.6 standard at Manchester (Ringway) Airport by Fairey Aviation in 1953\u20131954, and delivered to the Belgian Air Force for use as towing aircraft from the Sylt firing ranges.\nCanadian-built.\nA total of 1,032 (wartime \n+ 2 afterwards) Mosquitoes were built by De Havilland Canada at Downsview Airfield in Downsview Ontario (now Downsview Park in Toronto Ontario).\nHighball.\nA number of Mosquito IVs were modified by Vickers-Armstrongs to carry Highball \"bouncing bombs\" and were allocated Vickers Type numbers:\nProduction.\nAbout 5,000 of the total of 7,781 Mosquitoes built had major structural components fabricated from wood in High Wycombe, Buckinghamshire, England. Fuselages, wings and tailplanes were made at furniture companies such as Ronson, E. Gomme, Parker Knoll, Parslow Furniture, Austinsuite and Styles &amp; Mealing. Wing spars were made by J. B. Heath and Dancer &amp; Hearne. Many of the other parts, including flaps, flap shrouds, fins, leading edge assemblies and bomb doors were also produced in the Buckinghamshire town. Dancer &amp; Hearne processed much of the wood from start to finish, receiving timber and transforming it into finished wing spars at their factory in Penn Street on the outskirts of High Wycombe.\nInitially much of the specialised yellow birch wood veneer and finished plywood used for the prototypes and early production aircraft was shipped from firms in Wisconsin, US. Prominent in this role were Roddis Plywood and Veneer Manufacturing in Marshfield. In conjunction with the USDA Forest Products Laboratory, Hamilton Roddis had developed new plywood adhesives and hot pressing technology. Later on, paper birch was logged in large quantities from the interior of British Columbia along the Fraser and Quesnel Rivers and processed in Quesnel and New Westminster by the Pacific Veneer Company. According to the Quesnel archives, BC paper birch supplied \u00bd of the wartime British Empire birch used for Mosquitoes and other aircraft.\nAs the supply of Ecuadorean balsa was threatened by the U-boats in the Atlantic Ocean, the Ministry of Aircraft Production approved a research effort to supplant the balsa with calcium alginate foam, made from local brown algae. By 1944 the foam was ready, but the U-boat threat had been reduced, the larger B-25 bombers were in sufficient supply to handle most of the bombing raids, and the foam was not used in Mosquito production.\nCanada.\nIn July 1941, it was decided that DH Canada would build Mosquitoes at Downsview, Ontario. This was to continue even if Germany invaded Great Britain. Packard Merlin engines produced under licence were bench-tested by August and the first two aircraft were built in September. Production was to increase to fifty per month by early 1942. Initially, the Canadian production was for bomber variants; later, fighters, fighter-bombers and training aircraft were also made. DH Chief Production Engineer, Harry Povey, was sent first, then W. D. Hunter followed on an extended stay, to liaise with materials and parts suppliers. As was the case with initial UK production, Tego-bonded plywood and birch veneer was obtained from firms in Wisconsin, principally Roddis Plywood and Veneer Manufacturing, Marshfield. Enemy action delayed the shipping of jigs and moulds and it was decided to build these locally. During 1942, production improved to over 80 machines per month, as sub-contractors and suppliers became established. A mechanised production line based in part on car building methods started in 1944. As the war progressed, Canadian Mosquitoes may have utilized paper birch supplied by the Pacific Veneer Company of New Westminster using birch logs from the Cariboo, although records only say this birch was shipped to England for production there. When flight testing could no longer keep up, this was moved to the Central Aircraft Company airfield, London, Ontario, where the approved Mosquitoes left for commissioning and subsequent ferry transfer to Europe.\nFerrying Mosquitoes and many other types of WWII aircraft from Canada to Europe was dangerous, resulting in losses of lives and machines, but in the exigencies of war it was regarded as the best option for twin-engine and multi-engine aircraft. In the parlance of the day, among RAF personnel, \"it was no piece of cake.\" Considerable efforts were made by de Havilland Canada to resolve problems with engine and oil systems and an additional five hours of flight testing were introduced before the ferry flight, but the actual cause of some of the losses was unknown. Nevertheless, by the end of the war, nearly 500 Mosquito bombers and fighter-bombers had been ferried successfully by the Canadian operation.\nAfter DH Canada had been established for the Mosquito, further manufacturing was set up at DH Australia, in Sydney. One of the DH staff who travelled there was the distinguished test pilot, Pat Fillingham. These production lines added totals of 1,133 aircraft of varying types from Canada plus 212 aircraft from Australia.\nExports.\nIn total, both during the war and after, de Havilland exported 46 FB.VIs and 29 PR. XVIs to Australia; two FB.VI and 18 NF.30s to Belgium; approximately 250 FB.26, T.29 and T.27s from Canada to Nationalist China. A significant number never went into service due to deterioration on the voyage and to crashes during Chinese pilot training; however, five were captured by the People's Liberation Army during the Chinese Civil War; 19 FB.VIs to Czechoslovakia in 1948; 6 FB.VIs to Dominica; a few B.IVs, 57 FB.VIs, 29 PR.XVIs and 23 NF.30s to France. Some T.IIIs were exported to Israel along with 60 FB.VIs, and at least five PR.XVIs and 14 naval versions. Four T.IIIs, 76 FB.VIs, one FB.40 and four T.43s were exported to New Zealand. Three T.IIIs were exported to Norway, and 18 FB.VIs, which were later converted to night fighter standard. South Africa received two F.II and 14 PR.XVI/XIs and Sweden received 60 NF.XIXs. Turkey received 96 FB.VIs and several T.IIIs, and Yugoslavia had 60 NF.38s, 80 FB.VIs and three T.IIIs delivered. At least a single de Havilland Mosquito was delivered to the Soviet Union marked 'DK 296'.\nSites.\nTotal Mosquito production was 7,781, of which 6,710 were built during the war.\nCivilian accidents and incidents.\nA number of Mosquitoes were lost in civilian airline service, mostly with British Overseas Airways Corporation during the Second World War.\nOn 21 July 1996, Mosquito G-ASKH, wearing the markings of RR299, crashed 1 mile west of Manchester Barton Airport. Pilot Kevin Moorhouse and engineer Steve Watson were both killed in the crash. At the time, this was the last airworthy Mosquito, a T.III.\nSurviving aircraft.\nThere are approximately 30 non-flying Mosquitoes around the world with five airworthy examples: three in the United States; one in Canada; and one in New Zealand. The largest collection of Mosquitoes is at the de Havilland Aircraft Museum in the United Kingdom, which owns three aircraft, including the first prototype, \"W4050\", the only initial prototype of a Second World War British aircraft design still in existence in the 21st century."}
{"id": "9097", "revid": "6917124", "url": "https://en.wikipedia.org/wiki?curid=9097", "title": "Devangari alphabet", "text": ""}
{"id": "9098", "revid": "1559905", "url": "https://en.wikipedia.org/wiki?curid=9098", "title": "Devanaagarii", "text": ""}
{"id": "9099", "revid": "1263653178", "url": "https://en.wikipedia.org/wiki?curid=9099", "title": "Dave Thomas (businessman)", "text": "Rex David Thomas (July 2, 1932 \u2013 January 8, 2002) was an American businessman, philanthropist, and fast-food tycoon who was the founder and chief executive officer of Wendy's, a fast-food restaurant chain specializing in hamburgers. In this role, Thomas appeared in more than 800 commercial advertisements for the chain from 1989 to 2002, more than any other company founder in television history.\nEarly life.\nRex David Thomas was born July 2, 1932, in Atlantic City, New Jersey. His biological father's name was Sam and his biological mother's name was Molly. Thomas was adopted between six weeks and six months later by Rex and Auleva Thomas, and as an adult became a well-known advocate for adoption, founding the Dave Thomas Foundation for Adoption. After his adoptive mother's death when he was five, his father moved around the country seeking work. Thomas spent some of his early childhood near Kalamazoo, Michigan, with his grandmother, Minnie Sinclair, whom he credited with teaching him the importance of service and treating others well and with respect, lessons that helped him in his future business life.\nAt age 12, Thomas had his first job at Regas Restaurant, a fine dining restaurant in downtown Knoxville, Tennessee, then lost it in a dispute with his boss. He vowed never to lose another job. Decades later, Regas Restaurant installed a large autographed poster of Thomas just inside their entrance, which remained until the business closed in 2010. By 15, he was moving with his father and working at the Hobby House Restaurant in Fort Wayne, Indiana. When his father prepared to move again, Thomas decided to stay in Fort Wayne, dropping out of high school to work full-time at the restaurant. Thomas, who considered ending his schooling the greatest mistake of his life, did not graduate from high school until 1993, when he obtained a GED.\nHe subsequently became an education advocate and founded the Dave Thomas Education Center in Coconut Creek, Florida, which offers GED classes to young adults.\nCareer.\nU.S. Army.\nAt the outbreak of the Korean War in 1950, rather than waiting for the draft, he volunteered for the U.S. Army at age 18 to have some choice in assignments. Having food production and service experience, Thomas requested the Cook's and Baker's School at Fort Benning, Georgia. He was sent to West Germany as a mess sergeant and was responsible for the daily meals of 2,000 soldiers, rising to the rank of staff sergeant. After his discharge in 1953, Thomas returned to Fort Wayne and the Hobby House.\nFast food career.\nKentucky Fried Chicken.\nIn the mid-1950s, Kentucky Fried Chicken founder Col. Harland Sanders came to Fort Wayne, hoping to find restaurateurs with established businesses to whom he could try to sell KFC franchises. At first, Thomas \u2013 who was the head cook at a restaurant \u2013 and the Clauss family declined Sanders' offer, but Sanders persisted, and the Clauss family franchised their restaurant with KFC; they also later owned many other KFC franchises in the Midwest. During this time, Thomas worked with Sanders on many projects to make KFC more profitable and give it brand recognition. Among other ideas for improvements, Thomas suggested that KFC reduce the number of items on its menu and instead focus on a signature dish; he also proposed that KFC make commercials in which Sanders would personally appear. Thomas was sent by the Clauss family in the mid-1960s to help turn around four of their failing KFC stores in Columbus, Ohio.\nBy 1968, Thomas had increased sales in the four fried chicken restaurants so much that he sold his share in them back to Sanders for more than $1.5 million. This experience would prove invaluable to Thomas when he began Wendy's about a year later.\nArthur Treacher's.\nAfter serving as a regional director for Kentucky Fried Chicken, Thomas became part of the investor group which founded Arthur Treacher's. His involvement with the new restaurant lasted less than a year before he went on to found Wendy's.\nWendy's.\nThomas opened his first Wendy's in Columbus, Ohio, November 15, 1969. This original restaurant remained operational until March 2, 2007, when it was closed due to lagging sales. Thomas named the restaurant after his eight-year-old daughter Melinda Lou, whose nickname was \"Wendy\", stemming from the child's inability to say her own name at a young age. According to \"Bio TV\", Dave claims that people nicknamed his daughter \"Wenda. Not Wendy, but Wenda. 'I'm going to call it Wendy's Old Fashioned Hamburgers'.\" Before his death in 2002, Thomas admitted regret for naming the franchise after his daughter, saying \"I should've just named it after myself, because it put a lot of pressure on [her].\"\nIn 1982, Thomas resigned from his day-to-day operations at Wendy's. However, by 1985, several company business decisions, including an awkward new breakfast menu and loss in brand awareness due to fizzled marketing efforts, led the company's new president to urge Thomas back into a more active role with Wendy's. Thomas began to visit franchises and espouse his hardworking, so-called \"mop-bucket attitude\". In 1989, he took on a significant role as the TV spokesperson in a series of commercials for the brand. Thomas was not a natural actor, and initially, his performances were criticized as stiff and ineffective by advertising critics.\nBy 1990, after efforts by Wendy's advertising agency, Backer Spielvolgel Bates, to get humor into the campaign, a decision was made to portray Thomas in a more self-deprecating and folksy manner, which proved much more popular with test audiences. Consumer brand awareness of Wendy's eventually regained levels it had not achieved since octogenarian Clara Peller's highly popular \"Where's the beef?\" campaign of 1984.\nWith his natural self-effacing style and his relaxed manner, Thomas quickly became a household name. A company survey during the 1990s, a decade during which Thomas starred in every Wendy's commercial that aired, found that 90% of Americans knew who Thomas was. After more than 800 commercials, it was clear that Thomas played a major role in Wendy's' status as the third most popular burger restaurant in the U.S.\nThe Wellington School.\nIn 1982, Thomas and a consortium of entrepreneurs created and launched The Wellington School in Upper Arlington, Ohio. The group of entrepreneurs spent three years refining plans, raising money, finding a property, and recruiting teachers and students.\nThe school opened with 137 students and 19 employees as the first co-ed independent school in the greater Columbus metropolitan area. The first graduating class was in 1989 with 32 students. In 2010, a new building opened. In 2012, the Little Jags preschool program for 3-year-olds began.\nPersonal life.\nThomas was a Christian. He was married for 47 years to Lorraine Thomas and started his family with her in Upper Arlington, Ohio. In addition to Melinda, they had three more daughters \u2013 Pam, Lori, and Molly \u2013 and a son, Kenny. After Kenny died in 2013, his sisters still continued to own and run multiple Wendy's locations. Thomas founded the chain Sisters Chicken and Biscuits in 1978, named in reference to his other three daughters.\nDeath.\nHe had been afflicted with a carcinoid neuroendocrine tumor for a decade, before it metastasized to his liver. Thomas died at his home in Fort Lauderdale, Florida on January 8, 2002, at the age of 69. He was buried in Union Cemetery in Columbus, Ohio. At the time of his death, there were more than 6,000 Wendy's restaurants operating in North America.\nHonors and memberships.\nIn 1979, Thomas received the Horatio Alger Award for his success with his restaurant chain Wendy's, which had reached annual sales of US$1 billion with franchises then.\nIn 1980, Thomas received the Golden Plate Award of the American Academy of Achievement.\nThomas, realizing that his success as a high school dropout might convince other teenagers to quit school (something he later claimed was a mistake), became a student at Coconut Creek High School. He earned a GED in 1993. Thomas was inducted into the Junior Achievement U.S. Business Hall of Fame in 1999.\nThomas was an honorary Kentucky colonel, as was former boss Harland Sanders.\nThomas was posthumously awarded the Presidential Medal of Freedom in 2003.\nThomas was raised a Master Mason in Sol. D. Bayless Lodge No. 359 of Fort Wayne, Indiana, and became a 32\u00b0 Mason, N.M.J., on November 16, 1961, in the Scottish Rite Bodies of Fort Wayne. He was unanimously elected to the Scottish Rite's highest honor, the Grand Cross, by The Supreme Council, 33\u00b0, in Executive Session on October 3, 1997, in Washington, D.C.\nA small triangular block and the surrounding streets and traffic pattern in the Northeast quadrant of Washington, D.C., is unofficially known in the D.C. area as Dave Thomas Circle, due to the longtime presence of a Wendy's franchise and its parking lot on that block."}
{"id": "9101", "revid": "169132", "url": "https://en.wikipedia.org/wiki?curid=9101", "title": "Device driver", "text": "In the context of an operating system, a device driver is a computer program that operates or controls a particular type of device that is attached to a computer or automaton. A driver provides a software interface to hardware devices, enabling operating systems and other computer programs to access hardware functions without needing to know precise details about the hardware being used.\nA driver communicates with the device through the computer bus or communications subsystem to which the hardware connects. When a calling program invokes a routine in the driver, the driver issues commands to the device (drives it). Once the device sends data back to the driver, the driver may invoke routines in the original calling program.\nDrivers are hardware dependent and operating-system-specific. They usually provide the interrupt handling required for any necessary asynchronous time-dependent hardware interface.\nPurpose.\nThe main purpose of device drivers is to provide abstraction by acting as a translator between a hardware device and the applications or operating systems that use it. Programmers can write higher-level application code independently of whatever specific hardware the end-user is using.\nFor example, a high-level application for interacting with a serial port may simply have two functions for \"send data\" and \"receive data\". At a lower level, a device driver implementing these functions would communicate to the particular serial port controller installed on a user's computer. The commands needed to control a 16550 UART are much different from the commands needed to control an FTDI serial port converter, but each hardware-specific device driver abstracts these details into the same (or similar) software interface.\nDevelopment.\nWriting a device driver requires an in-depth understanding of how the hardware and the software works for a given platform function. Because drivers require low-level access to hardware functions in order to operate, drivers typically operate in a highly privileged environment and can cause system operational issues if something goes wrong. In contrast, most user-level software on modern operating systems can be stopped without greatly affecting the rest of the system. Even drivers executing in user mode can crash a system if the device is erroneously programmed. These factors make it more difficult and dangerous to diagnose problems.\nThe task of writing drivers thus usually falls to software engineers or computer engineers who work for hardware-development companies. This is because they have better information than most outsiders about the design of their hardware. Moreover, it was traditionally considered in the hardware manufacturer's interest to guarantee that their clients can use their hardware in an optimal way. Typically, the Logical Device Driver (LDD) is written by the operating system vendor, while the Physical Device Driver (PDD) is implemented by the device vendor. However, in recent years, non-vendors have written numerous device drivers for proprietary devices, mainly for use with free and open source operating systems. In such cases, it is important that the hardware manufacturer provide information on how the device communicates. Although this information can instead be learned by reverse engineering, this is much more difficult with hardware than it is with software.\nMicrosoft has attempted to reduce system instability due to poorly written device drivers by creating a new framework for driver development, called Windows Driver Frameworks (WDF). This includes User-Mode Driver Framework (UMDF) that encourages development of certain types of drivers\u2014primarily those that implement a message-based protocol for communicating with their devices\u2014as user-mode drivers. If such drivers malfunction, they do not cause system instability. The Kernel-Mode Driver Framework (KMDF) model continues to allow development of kernel-mode device drivers but attempts to provide standard implementations of functions that are known to cause problems, including cancellation of I/O operations, power management, and plug-and-play device support.\nApple has an open-source framework for developing drivers on macOS, called I/O Kit.\nIn Linux environments, programmers can build device drivers as parts of the kernel, separately as loadable modules, or as user-mode drivers (for certain types of devices where kernel interfaces exist, such as for USB devices). Makedev includes a list of the devices in Linux, including ttyS (terminal), lp (parallel port), hd (disk), loop, and sound (these include mixer, sequencer, dsp, and audio).\nMicrosoft Windows .sys files and Linux .ko files can contain loadable device drivers. The advantage of loadable device drivers is that they can be loaded only when necessary and then unloaded, thus saving kernel memory.\nPrivilege levels.\nDepending on the operating system, device drivers may be permitted to run at various different privilege levels. The choice of which level of privilege the drivers are in is largely decided by the type of kernel an operating system uses. An operating system that uses a monolithic kernel, such as the Linux kernel, will typically run device drivers with the same privilege as all other kernel objects. By contrast, a system designed around microkernel, such as Minix, will place drivers as processes independent from the kernel but that use it for essential input-output functionalities and to pass messages between user programs and each other.\nOn Windows NT, a system with a hybrid kernel, it is common for device drivers to run in either kernel-mode or user-mode.\nThe most common mechanism for segregating memory into various privilege levels is via protection rings. On many systems, such as those with x86 and ARM processors, switching between rings imposes a performance penalty, a factor that operating system developers and embedded software engineers consider when creating drivers for devices which are preferred to be run with low latency, such as network interface cards. The primary benefit of running a driver in user mode is improved stability since a poorly written user-mode device driver cannot crash the system by overwriting kernel memory.\nApplications.\nBecause of the diversity of hardware and operating systems, drivers operate in many different environments. Drivers may interface with:\nCommon levels of abstraction for device drivers include:\nSo choosing and installing the correct device drivers for given hardware is often a key component of computer system configuration.\nVirtual device drivers.\nVirtual device drivers represent a particular variant of device drivers. They are used to emulate a hardware device, particularly in virtualization environments, for example when a DOS program is run on a Microsoft Windows computer or when a guest operating system is run on, for example, a Xen host. Instead of enabling the guest operating system to dialog with hardware, virtual device drivers take the opposite role and emulates a piece of hardware, so that the guest operating system and its drivers running inside a virtual machine can have the illusion of accessing real hardware. Attempts by the guest operating system to access the hardware are routed to the virtual device driver in the host operating system as e.g.,\u00a0function calls. The virtual device driver can also send simulated processor-level events like interrupts into the virtual machine.\nVirtual devices may also operate in a non-virtualized environment. For example, a virtual network adapter is used with a virtual private network, while a virtual disk device is used with iSCSI. A good example for virtual device drivers can be Daemon Tools.\nThere are several variants of virtual device drivers, such as VxDs, VLMs, and VDDs.\nOpen source drivers.\nSolaris descriptions of commonly used device drivers:\nIdentifiers.\nA device on the PCI bus or USB is identified by two IDs which consist of two bytes each. The vendor ID identifies the vendor of the device. The device ID identifies a specific device from that manufacturer/vendor.\nA PCI device has often an ID pair for the main chip of the device, and also a subsystem ID pair that identifies the vendor, which may be different from the chip manufacturer.\nSecurity.\nComputers often have many diverse and customized device drivers running in their operating system (OS) kernel which often contain various bugs and vulnerabilities, making them a target for exploits. A \"Bring Your Own Vulnerable Driver\" (BYOVD) attacker installs any signed, old third-party driver with known vulnerabilities that allow malicious code to be inserted into the kernel.&lt;ref name=\"arstechnica/microsoft-blunder\"&gt;&lt;/ref&gt;\nDrivers that may be vulnerable include those for WiFi and Bluetooth, gaming/graphics drivers, and drivers for printers.\nThere is a lack of effective kernel vulnerability detection tools, especially for closed-source OSes such as Microsoft Windows where the source code of the device drivers is mostly proprietary and not available to examine, and drivers often have many privileges.\nA group of security researchers considers the lack of isolation as one of the main factors undermining kernel security, and published an isolation framework to protect operating system kernels, primarily the monolithic Linux kernel whose drivers they say get ~80,000 commits per year. "}
{"id": "9103", "revid": "41526883", "url": "https://en.wikipedia.org/wiki?curid=9103", "title": "Dimona", "text": "Dimona (, ) is an Israeli city in the Negev desert, to the south-east of Beersheba and west of the Dead Sea above the Arava valley in the Southern District of Israel. In , its population was . The Shimon Peres Negev Nuclear Research Center, colloquially known as the Dimona Reactor, is located southeast of the city.\nEtymology.\nThe Negev Naming Committee chose the name based upon that of a biblical town, mentioned in Joshua 15:21-22, on the basis that \"the sound of this name had been preserved in the Arabic name Harabat Umm Dumna.\"\nHistory.\nDimona was one of the development towns created in the 1950s under the leadership of Israel's first Prime Minister, David Ben-Gurion. Dimona itself was conceived in 1953. The location chosen was close to the Dead Sea Works. It was established in 1955. The first residents were Jewish immigrants from North Africa, with an initial 36 families being the first to settle there. Its population in 1955 was about 300. The North African immigrants also constructed the city's houses. The population was composed mainly of North African, particularly Moroccan immigrants, though immigrants from Yemen and Eastern Europe also arrived, as did Bene Israel immigrants from India.\nWhen the Israeli nuclear program began in 1958, a location not far from the city was chosen for the Negev Nuclear Research Center due to its relative isolation in the desert and availability of housing. In the late 1950s and early 1960s, immigrants from Eastern Europe arrived. A textile factory was opened in 1958. That same year, Dimona became a local council. In 1961, it had a population of 5,000. The emblem of Dimona (as a local council), adopted 2 March 1961, appeared on a stamp issued on 24 March 1965. Dimona was declared a city in 1969. In 1971, it had a population of 23,700.\nIn spite of a gradual decrease during the 1980s, the city's population began to grow once again in the 1990s when it took in immigrants from the former Soviet Union and Ethiopia. Currently, Dimona is the third largest city in the Negev, with the population of almost 34,000. Due to projected rapid population growth in the Negev, the city is expected to triple in size by 2025.\nDemography.\nDimona is described as \"mini-India\" by many for its 7,500-strong Indian Jewish community. It is also home to Israel's Black Hebrew community, formerly governed by its founder and spiritual leader, Ben Ammi Ben-Israel, now deceased. The Black Hebrews number about 3,000 in Dimona, with additional families in Arad, Mitzpe Ramon and the Tiberias area. Their official status in Israel was an ongoing issue for many years, but in May 1990, the issue was resolved with the issuing of first B/1 visas, and a year later, issuing of temporary residency. Status was extended to August 2003, when the Israeli Ministry of Interior granted permanent residency.\nEconomy.\nIn the early 1980s, textile plants, such as Dimona Textiles Ltd., dominated the industrial landscape. Many plants have since closed. Dimona Silica Industries Ltd. manufactures precipitated silica and calcium carbonate fillers. About a third of the city's population works in industrial workplaces (chemical plants near the Dead Sea like the Dead Sea Works, high-tech companies and textile shops), and another third in the area of services. Due to the introduction of new technologies, many workers have been made redundant in the recent years, creating a total unemployment rate of about 10%. Dimona has taken part of Israel's solar transformation. The Rotem Industrial Complex outside of the city has dozens of solar mirrors that focus the sun's rays on a tower that in turn heats a water boiler to create steam, turning a turbine to create electricity. Luz II, Ltd. plans to use the solar array to test new technology for the three new solar plants to be built in California for Pacific Gas and Electric Company.\nGeography and climate.\nDimona is located in the Negev Desert. The city stands at an elevation of around above sea level.\nClimate.\nDimona has a semi-arid climate (K\u00f6ppen climate classification: \"BSh\"). The average annual temperature is , and around of precipitation falls annually.\nTransportation.\nIn the early 1950s, an extension to Dimona and south was constructed from the Railway to Beersheba, designed for freight traffic. A passenger service began in 2005, after pressure from Dimona's municipality. Dimona Railway Station is located in the southwestern part of the city. The main bus terminal is the Dimona Central Bus Station, with lines to Beersheba, Tel Aviv, Eilat, and nearby towns.\nTwin towns.\nDimona is twinned with:"}
{"id": "9105", "revid": "41283137", "url": "https://en.wikipedia.org/wiki?curid=9105", "title": "DC Comics", "text": "DC Comics, Inc. (later simply known as DC) is an American comic book publisher, a subsidiary of Warner Bros. Discovery. DC is an initialism for \"Detective Comics\", an American comic book series first published in 1937.\nDC Comics is one of the largest and oldest American comic book companies, the first comic under the DC banner being published in 1937. The majority of its publications are set in the fictional DC Universe and feature numerous culturally iconic heroic characters, such as Superman, Batman, Wonder Woman, Green Lantern, the Flash, Cyborg, Green Arrow, Black Canary, Zatanna, Blue Beetle, Static and Aquaman; as well as famous fictional teams, including the Justice League, the Justice Society of America, the Teen Titans, and the Suicide Squad. The universe contains an assortment of well-known supervillains, such as the Joker, Lex Luthor, the Cheetah, Deathstroke, the Reverse-Flash, Brainiac, Sinestro, Black Manta, Gorilla Grodd, Circe, the Penguin and Darkseid. The company has published non-DC Universe-related material, including \"Watchmen\", \"V for Vendetta\", \"Fables\", and many other titles, under the alternative imprint Vertigo and DC Black Label.\nOriginally at 432 Fourth Avenue in Manhattan, New York City, the company offices have been located at 480 and later 575 Lexington Avenue, 909 Third Avenue, 75 Rockefeller Plaza, 666 Fifth Avenue, and 1325 Avenue of the Americas. DC Comics was located at 1700 Broadway in Midtown Manhattan until April 2015, when DC Entertainment transferred its headquarters to Burbank, California.\nDC Comics books are distributed to the bookstore market by Penguin Random House Publisher Services. The comics shop direct market was supplied by Diamond Comic Distributors until June 2020, when Lunar Distribution and UCS Comic Distributors (who were by then dominating direct market distribution on account of the disruption to Diamond caused by the COVID-19 pandemic) replaced Diamond as the direct market distributor.\nIn 2017, approximately 70% of the American comic book market was shared by DC Comics and its long-time major competitor Marvel Comics (acquired in 2009 by Warner Bros. Discovery's main competitor, The Walt Disney Company), though this figure may be distorted by the fact that sales of graphic novels are excluded. When all book sales are included, DC is the second largest publisher of comic books, after Viz Media; and Marvel is third.\nHistory.\nNational Allied Publications.\nGolden Age.\nIn 1935, entrepreneur Major Malcolm Wheeler-Nicholson founded National Allied Publications, intended as an American comic book publishing company. Its debut publication was the tabloid-sized \"New Fun: The Big Comic Magazine\" #1 (the first of a comic series later called \"More Fun Comics\") with a February 1935 cover date. An anthology title, essentially for original stories not reprinted from newspaper strips, it was unlike many comic book series before it. While DC Comics is now primarily associated with superhero comics, the genres in the first anthology titles consisted of funnies, Western comics, and adventure-related stories. The character Doctor Occult\u2014created by Jerry Siegel and Joe Shuster in December 1935 and included in issue No.6 of \"New Fun Comics\"\u2014is considered to be the earliest recurring superhero created by DC that is still being used. The company created a second recurring title called \"New Comics\", first released in December 1935, which was the start of the long-running \"Adventure Comics\" series that also featured many anthology titles. By 1936, the group had become Nicholson Publishing.\nWheeler-Nicholson's next and final title, \"Detective Comics\", was advertised with a cover illustration dated December 1936 but eventually premiered three months late with a March 1937 cover date. The themed anthology that revolved originally around fictional detective stories became in modern times the longest-running ongoing comic series. A notable debut in the first issue was Slam Bradley, created in a collaboration between Wheeler-Nicholson, Siegel and Shuster. In 1937, in debt to printing-plant owner and magazine distributor Harry Donenfeld\u2014who also published pulp magazines and operated as a principal in the magazine distributorship Independent News\u2014Wheeler-Nicholson had to enter into partnership with Donenfeld to publish \"Detective Comics\" No.1, and Detective Comics, Inc. (which helped inspire the abbreviation DC) was formed, with Wheeler-Nicholson and Donenfeld's accountant Jack S. Liebowitz listed as owners. As the company continued to experience cash-flow problems, Wheeler-Nicholson was forced out after the first year. Shortly afterwards, Detective Comics, Inc. purchased the remains of National Allied (also known as Nicholson Publishing) at a bankruptcy auction and absorbed it.\nMeanwhile, Max Gaines formed the sister company All-American Publications in 1939. Detective Comics, Inc. soon launched a new anthology title called \"Action Comics\"; the first issue, cover dated June 1938, featured new characters such as Superman by Siegel and Shuster, Zatara by Fred Guardineer, and Tex Thompson by Ken Finch and Bernard Baily. Considered as the first comic book to feature the character archetype later known as the \"superhero\", \"Action Comics\" was a sales hit that brought to life a new age of comic books, now affectionately termed the \"Golden Age\". \"Action Comics\" #1 is credited as featuring the first appearance of Superman, both on the cover illustration and inside the issue, and is now one of the most valuable and sought-after comic book issues of all time. The first Superman tale included a superhero origin story with the reveal of an unnamed planet, later known as Krypton, where he is said to have originated. The issue also contained the first essential supporting character and one of the earliest female characters in any comic, with Lois Lane as Superman's first depicted romantic interest. The Green Hornet-inspired character known as the Crimson Avenger by Jim Chamber was featured in \"Detective Comics\" No.20 (October 1938). This character is known to be the first masked vigilante published by DC. An unnamed \"office boy\", retconned as Jimmy Olsen's first appearance, was revealed in a Superman story by Siegel and Shuster in \"Action Comics\" No.6 (November 1938).\nStarting in 1939, Siegel and Shuster's Superman was the first comic-derived character to appear in other formats, later featuring in his own newspaper comic strip, which first introduced his biological parents Jor-El and Lara. All-American Publications' debut comic series, \"All-American Comics\", was first published in April 1939. The series \"Detective Comics\" made history as being the first to feature Batman\u2014a Bob Kane and Bill Finger creation\u2014in issue No.27 (March 1939) with the request of more superhero titles. Batman was depicted as a masked vigilante who wore a caped suit known as the Batsuit and drove a car that was later referred to as the Batmobile. The Batman story also included a supporting character called James Gordon, the police commissioner of what would later become Gotham City Police Department. Despite being a parody, All-American Publications introduced the earliest female character who became the female superhero Red Tornado (though disguised as a male) in Ma Hunkel who first appeared in the \"Scribbly\" stories in \"All-American Comics\" No.3 (June 1939). Another important Batman debut was the introduction of the fictional mansion known as Wayne Manor first seen in \"Detective Comics\" No.28 (June 1939). The series \"Adventure Comics\" followed in the footsteps of \"Action Comics\" and \"Detective Comics\" by featuring a new recurring superhero called Sandman who first appeared in \"Adventure Comics\" No.40 (July 1939). \"Action Comics\" No.13 (June 1939) introduced the first recurring Superman enemy referred to as the Ultra-Humanite; created by Siegel and Shuster, this is commonly cited as one of the earliest supervillains in comic books. The Superman character had another breakthrough when he was given his own comic book series, which was previously unheard of. The first issue, published in June 1939, helped directly introduce Superman's adoptive parents, Jonathan and Martha Kent, also created by Siegel and Shuster. \"Detective Comics\" No.29 (July 1939) included the first mention of Batman's utility belt by Gardner Fox. Outside of DC's publishing, a character later integrated as DC was introduced by Fox Feature Syndicate named the Blue Beetle released in August 1939. Fictional cities were a common theme of DC; the first revealed city was Superman's home city of Metropolis, originally named in \"Action Comics\" No.16 (September 1939). \"Detective Comics\" No.31 (September 1939) by Gardner Fox, Bob Kane and Sheldon Moldoff introduced a romantic interest for Batman named Julie Madison, as well as the Batarang weapon that Batman commonly uses, and the fictional aircraft called the Batplane. The story of Batman's origin was first shown in \"Detective Comics\" No.33 (November 1939), which depicted the death of Thomas Wayne and Martha Wayne by a mugger. The origin story remained crucial for the fictional character after its inception.\nThe \"Daily Planet\" (a common setting of Superman) was first named in a Superman newspaper strip around November 1939. Doll Man was the first superhero to be produced by Quality Comics, which DC now owns. Fawcett Comics was formed around 1939 and became DC's original competitor company over the next decade. At the end of 1944, All-American titles began using its own logo to distinguish it from the National comics.\nAll-American Publications, an affiliate concern co-owned by Gaines and Liebowitz, merged with Detective Comics, Inc. on September 30, 1946, forming National Comics Publications. The previous year, in June 1945, Gaines had allowed Liebowitz to buy him out and had retained only \"Picture Stories from the Bible\" as the foundation of his own new company, EC Comics. At that point, \"Liebowitz promptly orchestrated the merger of All-American and Detective Comics into National Comics... Next he took charge of organizing National Comics, [the self-distributorship] Independent News, and their affiliated firms into a single corporate entity, National Periodical Publications\". National Periodical Publications became publicly traded on the stock market in 1961. Despite the official names \"National Comics\" and \"National Periodical Publications\", the company began branding itself as \"Superman-DC\" as early as 1940 and became known colloquially as DC Comics for years before the official adoption of that name in 1977.\nDC Comics began to move aggressively against what it saw as copyright-violating imitations from other companies, such as Fox Comics' Wonder Man, which (according to court testimony) Fox started as a copy of Superman. This extended to DC suing Fawcett Comics over Captain Marvel, who was at the time the top-selling comic character (see \"National Comics Publications, Inc. v. Fawcett Publications, Inc.\"). Faced with declining sales and the prospect of bankruptcy if it lost the lawsuit, Fawcett capitulated in 1953 and ceased publishing comics. Years later, Fawcett sold the rights for Captain Marvel to DC Comics, and in 1972 the character was revived in DC's new title \"Shazam!\", which featured artwork by Captain Marvel's creator C. C. Beck. In the meantime, the abandoned 'Marvel' trademark had been seized by Marvel Comics in 1967, with the creation of their Captain Marvel, preventing DC from using the name in the title of their own comic series. While DC's Captain Marvel failed to recapture his earlier popularity, he later appeared in a Saturday morning live action TV adaptation and gained a prominent position in the mainstream continuity of the DC Universe.\nAs the popularity of superheroes faded in the late 1940s, DC Comics focused on such genres as science fiction, Westerns, humor, and romance. The company also published crime and horror titles, although relatively tame contributions that avoided the mid-1950s backlash against such comic genres. A handful of the most popular superhero titles continued publication, including \"Action Comics\" and \"Detective Comics\", the medium's two longest-running titles.\nSilver Age.\nIn the mid-1950s, editorial director Irwin Donenfeld and publisher Liebowitz directed editor Julius Schwartz (whose roots lay in the science-fiction book market) to produce a one-shot Flash story in the try-out title \"Showcase\". Instead of reviving the old character, Schwartz had writers Robert Kanigher and John Broome, penciler Carmine Infantino, and inker Joe Kubert create an entirely new super-speedster, updating and modernizing the Flash's civilian identity, costume, and origin with a science-fiction bent. The Flash's reimagining in \"Showcase\" No.4 (October 1956) proved sufficiently popular that it soon led to a similar revamping of the Green Lantern character, the introduction of the modern all-star team Justice League of America (JLA), and many more superheroes, heralding what historians and fans call the Silver Age of Comic Books.\nNational radically overhauled its continuing characters\u2014primarily Superman, Batman, and Wonder Woman\u2014rather than just reimagining them. The Superman family of titles, under editor Mort Weisinger, introduced such enduring characters as Supergirl, Bizarro, and Brainiac. The Batman titles, under editor Jack Schiff, introduced the successful Batwoman, Bat-Girl, Ace the Bat-Hound, and Bat-Mite in an attempt to modernize the strip with non-science-fiction elements. Schwartz and Infantino then revitalized Batman in what the company promoted as the \"New Look\", with relatively down-to-earth stories re-emphasizing Batman as a detective. Meanwhile, editor Kanigher successfully introduced a whole family of Wonder Woman characters having fantastic adventures in a mythical realm.\nSince the 1940s, when Superman, Batman, and many of the company's other heroes began appearing in stories together, DC's characters have inhabited a shared continuity that was later dubbed the \"DC Universe\" by fans. With the story \"Flash of Two Worlds\", in \"Flash\" No.123 (September 1961), editor Schwartz (with writer Gardner Fox and artists Infantino and Joe Giella) presented a conceptual mechanism for slotting the 1930s and 1940s Golden Age heroes into this continuity using the explanation that they inhabited an other-dimensional \"Earth 2\", whilst the modern heroes exist on \"Earth 1\", consequently laying the foundations of what was later called the DC Multiverse.\nNational Periodical Publications.\nDC's introduction of the reimagined superheroes did not go unnoticed by their competitors. In 1961, with DC's JLA as the specific inducement, Marvel Comics' writer-editor Stan Lee and artist Jack Kirby ushered in the sub-Silver Age \"Marvel Age\" of comics with the debut issue of \"The Fantastic Four\". Reportedly, DC dismissed the initial success of Marvel's editorial change until its consistently strengthening sales\u2014albeit also benefiting DC's parent company Independent News, as Marvel's distributor\u2014made it impossible to ignore. This commercial situation was highlighted by Marvel's superior sell-through percentage numbers which were typically 70% to DC's roughly 50%, meaning that DC's publications were barely making a profit after returns from the distributors were factored in, while Marvel was making a healthy profit by comparison. Also in 1961, both DC and Marvel increased their cover price from ten cents to twelve cents, while the rival publisher Dell Comics was charging fifteen cents.\nAt this time, the senior DC staff were reportedly unable to explain how this small publishing house was achieving its increasingly threatening commercial strength. For instance, when Marvel's product was examined in a meeting, the emphasis on more sophisticated character-based narrative and artist-driven visual storytelling was apparently overlooked. Instead, superficial reasons were put forward to account for the brand's popularity, like the presence of the color red or word balloons on the cover, or that the perceived crudeness of the interior art was somehow more appealing to readers. When Lee learned about DC's subsequent experimental attempts to imitate these perceived details, he amused himself by arranging direct defiance of those assumptions in Marvel's publications as sales strengthened further to frustrate the competition.\nHowever, this ignorance of Marvel's true appeal did not extend to some of the writing talent during this period, and attempts were made to emulate Marvel's narrative approach. For instance, there was the \"Doom Patrol\" series by Arnold Drake (who had previously warned DC's management about Marvel's strength), a superhero team of outsiders who resented their freakish powers, which Drake later speculated was plagiarized by Stan Lee to create \"The X-Men\". There was also the young Jim Shooter who purposely emulated Marvel's writing when he wrote for DC after studying both companies' styles, such as for the \"Legion of Super-Heroes\" feature. In 1966, National Periodical Publications established its own television arm, led by Allen Ducovny, to develop and produce TV projects, with Superman TV Corporation handling the distribution of NPP's shows.\nA 1966 Batman TV show on the ABC network sparked a temporary spike in comic book sales and a brief fad for superheroes in Saturday morning animation (Filmation produced most of DC's initial cartoons) and other media. DC significantly lightened the tone of many of its comics\u2014particularly \"Batman\" and \"Detective Comics\"\u2014to better complement the \"camp\" tone of the TV series. This change in tone coincided with the prominent \"Go-Go Checks\" cover-dress that featured a black-and-white checkered strip at the top of each DC comic (all cover dates between February 1966 and August 1967), a misguided attempt by then-managing editor Irwin Donenfeld to make DC's output \"stand out on the newsracks\". In particular, DC artist Carmine Infantino complained that the distinctive cover made it easier for readers to spot DC's titles and avoid them in favor of Marvel's titles.\nIn 1967, Infantino (who had designed popular Silver Age characters Batgirl and the Phantom Stranger) rose from art director to become DC's editorial director. With the growing popularity of upstart rival Marvel Comics threatening to topple DC from its longtime number-one position in the comics industry, he tried to direct DC's focus towards marketing new and existing titles and characters with more adult sensibilities, aimed at an emerging older age group of superhero comic book fans; this was in response to Marvel's efforts to market their superhero line to college-aged adults. Infantino also recruited major talents such as ex-Marvel artist and Spider-Man co-creator Steve Ditko, and promising newcomers Neal Adams and Denny O'Neil, and he replaced some existing DC editors with artist-editors, including Joe Kubert and Dick Giordano, to give DC's output a more artistic critical eye.\nKinney National / Warner Communications (1967\u20131990).\nIn 1967, National Periodical Publications was purchased by Kinney National Company, which purchased Warner Bros.-Seven Arts in 1969. Kinney National spun off its non-entertainment assets in 1972 (as National Kinney Corporation) and changed its name to Warner Communications Inc.\nIn 1970, Jack Kirby moved from Marvel Comics to DC, at the end of the Silver Age of Comics, in which Kirby's contributions to Marvel played a large, integral role.\nAs artist Gil Kane described:\nJack was the single most influential figure in the turnaround in Marvel's fortunes from the time he rejoined the company ... It wasn't merely that Jack conceived most of the characters that are being done, but ... Jack's point of view and philosophy of drawing became the governing philosophy of the entire publishing company and, beyond the publishing company, of the entire field ... [Marvel took] Jack and use[d] him as a primer. They would get artists ... and they taught them the ABCs, which amounted to learning Jack Kirby ... Jack was like the Holy Scripture and they simply had to follow him without deviation. That's what was told to me ... It was how they taught everyone to reconcile all those opposing attitudes to one single master point of view.\nGiven \"carte blanche\" to write and illustrate his own stories, he created a handful of thematically-linked series he called collectively \"The Fourth World\". In the existing series \"Superman's Pal Jimmy Olsen\" and in his own, newly-launched series \"New Gods\", \"Mister Miracle\", and \"The Forever People\", Kirby introduced such enduring characters and concepts as arch-villain Darkseid and the other-dimensional realm Apokolips. Furthermore, Kirby intended their stories to be reprinted in collected editions, in a publishing format that was later called the trade paperback, which became a standard industry practice decades later. While sales were respectable, they did not meet DC management's initially high expectations, and also suffered from a lack of comprehension and internal support from Infantino. By 1973 the \"Fourth World\" was all cancelled, although Kirby's conceptions soon became integral to the broadening of the DC Universe, especially after the major toy-company, Kenner Products, judged them ideal for their action-figure adaptation of the DC Universe, the Super Powers Collection. Obligated by his contract, Kirby created other unrelated series for DC, including \"Kamandi\", \"The Demon\", and \"OMAC\", before ultimately returning to Marvel Comics in 1976.\nBronze Age.\nFollowing the science-fiction innovations of the Silver Age, the comics of the 1970s and 1980s became known as the Bronze Age, as fantasy gave way to more naturalistic and sometimes darker themes. Illegal drug use, banned by the Comics Code Authority, explicitly appeared in comics for the first time in Marvel Comics' story \"Green Goblin Reborn!\" in \"The Amazing Spider-Man\" No.96 (May 1971), and after the Code's updating in response, DC offered a drug-fueled storyline in writer Dennis O'Neil and artist Neal Adams' \"Green Lantern\", beginning with the story \"Snowbirds Don't Fly\" in the retitled \"Green Lantern / Green Arrow\" No.85 (September 1971), which depicted Speedy, the teen sidekick of superhero archer Green Arrow, as having become a heroin addict.\nJenette Kahn, a former children's magazine publisher, replaced Infantino as editorial director in January 1976. As it happened, her first task even before being formally hired, was to convince Bill Sarnoff, the head of Warner Publishing, to keep DC as a publishing concern, as opposed to simply managing their licensing of their properties. With that established, DC had attempted to compete with the now-surging Marvel by dramatically increasing its output and attempting to win the market by flooding it. This included launching series featuring such new characters as \"Firestorm\" and \"Shade, the Changing Man\", as well as an increasing array of non-superhero titles, in an attempt to recapture the pre-Wertham days of post-War comicdom.\nDC Comics.\nIn 1977, the company officially changed its name to DC Comics. It had used the brand \"Superman-DC\" since the 1950s, and was colloquially known as DC Comics for years.\nIn June 1978, five months before the release of the first Superman film, Kahn expanded the line further, increasing the number of titles and story pages, and raising the price from 35 cents to 50 cents. Most series received eight-page back-up features while some had full-length twenty-five-page stories. This was a move the company called the \"DC Explosion\". The move was not successful, however, and corporate parent Warner dramatically cut back on these largely unsuccessful titles, firing many staffers in what industry watchers dubbed \"the DC Implosion\". In September 1978, the line was dramatically reduced and standard-size books returned to 17-page stories but for a still increased 40 cents. By 1980, the books returned to 50 cents with a 25-page story count but the story pages replaced house ads in the books.\nSeeking new ways to boost market share, the new team of publisher Kahn, vice president Paul Levitz, and managing editor Giordano addressed the issue of talent instability. To that end\u2014and following the example of Atlas/Seaboard Comics and such independent companies as Eclipse Comics\u2014DC began to offer royalties in place of the industry-standard work-for-hire agreement in which creators worked for a flat fee and signed away all rights, giving talent a financial incentive tied to the success of their work. As it happened, the implementation of these incentives proved opportune considering Marvel Comics' Editor-in-Chief, Jim Shooter, was alienating much of his company's creative staff with his authoritarian manner and major talents there went to DC like Roy Thomas, Gene Colan, Marv Wolfman, and George P\u00e9rez.\nIn addition, emulating the era's new television form, the miniseries while addressing the matter of an excessive number of ongoing titles fizzling out within a few issues of their start, DC created the industry concept of the comic book limited series. This publishing format allowed for the deliberate creation of finite storylines within a more flexible publishing format that could showcase creations without forcing the talent into unsustainable open-ended commitments. The first such title was \"World of Krypton\" in 1979, and its positive results led to subsequent similar titles and later more ambitious productions like \"Camelot 3000\" for the direct market in 1982.\nThese changes in policy shaped the future of the medium as a whole, and in the short term allowed DC to entice creators away from rival Marvel, and encourage stability on individual titles. In November 1980 DC launched the ongoing series \"The New Teen Titans\", by writer Marv Wolfman and artist George P\u00e9rez, two popular talents with a history of success. Their superhero-team comic, superficially similar to Marvel's ensemble series \"X-Men\", but rooted in DC history, earned significant sales in part due to the stability of the creative team, who both continued with the title for six full years. In addition, Wolfman and P\u00e9rez took advantage of the limited-series option to create a spin-off title, \"Tales of the New Teen Titans\", to present origin stories of their original characters without having to break the narrative flow of the main series or oblige them to double their work load with another ongoing title.\nModern Age.\nThis successful revitalization of the Silver Age Teen Titans led DC's editors to seek the same for the wider DC Universe. The result, the Wolfman/P\u00e9rez 12-issue limited series \"Crisis on Infinite Earths\", gave the company an opportunity to realign and jettison some of the characters' complicated backstory and continuity discrepancies. A companion publication, two volumes entitled \"The History of the DC Universe\", set out the revised history of the major DC characters. \"Crisis\" featured many key deaths that shaped the DC Universe for the following decades, and it separated the timeline of DC publications into pre- and post-\"Crisis\".\nMeanwhile, a parallel update had started in the non-superhero and horror titles. Since early 1984, the work of British writer Alan Moore had revitalized the horror series \"The Saga of the Swamp Thing\", and soon numerous British writers, including Neil Gaiman and Grant Morrison, began freelancing for the company. The resulting influx of sophisticated horror-fantasy material led to DC in 1993 establishing the Vertigo mature-readers imprint, which did not subscribe to the Comics Code Authority.\nTwo DC limited series, \"\" by Frank Miller and \"Watchmen\" by Moore and artist Dave Gibbons, drew attention in the mainstream press for their dark psychological complexity and promotion of the antihero. These titles helped pave the way for comics to be more widely accepted in literary-criticism circles and to make inroads into the book industry, with collected editions of these series as commercially successful trade paperbacks.\nThe mid-1980s also saw the end of many long-running DC war comics, including series that had been in print since the 1960s. These titles, all with over 100 issues, included \"Sgt. Rock\", \"G.I. Combat\", \"The Unknown Soldier\", and \"Weird War Tales\".\nTime Warner / Time Warner Entertainment / AOL Time Warner (1990\u20132018).\nIn March 1989, Warner Communications merged with Time Inc., making DC Comics a subsidiary of Time Warner. In June, the first Tim Burton-directed Batman film was released, and DC began publishing its hardcover series of DC Archive Editions; these were collections of many of their early, key comics series, featuring rare and expensive stories previously unseen by the majority of modern fans. Much of the restoration work was handled by Rick Keene, with colour restoration performed by DC's long-time resident colourist Bob LeRose. The Archive Editions attempted to retroactively credit many of the writers and artists who had worked for DC without receiving much recognition during the early age of comic books when individual credits were rare.\nThe comics industry experienced a brief boom in the early 1990s, thanks to a combination of speculative purchasing\u2014mass purchase of the books as collectible items, with the intention to resell at a higher value (as the rising value of older issues was thought to imply that \"all\" comics would rise dramatically in price)\u2014and several storylines gaining attention from the mainstream media. DC's extended storylines in which Superman was killed, , and Green Lantern turned into the supervillain Parallax, resulted in dramatically increased sales. However, the increases were temporary, and sales dropped off as the industry went into a major slump, while manufactured \"collectables\" numbering in the millions replaced quality with quantity until fans and speculators alike deserted the medium in droves.\nDC's Piranha Press and other imprints (including the mature readers' line Vertigo, and Helix, a short-lived science fiction imprint) were introduced to facilitate compartmentalized diversification and allow for specialized marketing of individual product lines. They increased the use of non-traditional contractual arrangements, including the dramatic rise of creator-owned projects, leading to a significant increase in critically lauded work (much of it for Vertigo) and the licensing of material from other companies. DC also increased publication of book-store friendly formats, including trade paperback collections of individual serial comics, as well as original graphic novels.\nOne of the other imprints was Impact Comics from 1991 to 1992 in which the Archie Comics superheroes were licensed and revamped. The stories in the line were part of its own shared universe.\nDC entered into a publishing agreement with Milestone Media that gave DC a line of comics featuring a culturally and racially diverse range of superhero characters. Although the Milestone line ceased publication after a few years, it yielded the popular animated series \"Static Shock\". DC established Paradox Press to publish material such as the large-format \"Big Book of...\" series of multi-artist interpretations on individual themes, and such crime fiction as the graphic novel \"Road to Perdition\". In 1998, DC purchased WildStorm Comics, Jim Lee's imprint under the Image Comics banner, continuing it for many years as a wholly separate imprint (and fictional universe) with its own unique style and audience. As part of this purchase, DC also began to publish titles under the fledgling WildStorm sub-imprint America's Best Comics (ABC), a series of titles created by Alan Moore which included \"The League of Extraordinary Gentlemen\", \"Tom Strong\", and \"Promethea\". Moore strongly opposed this move, and DC eventually stopped publishing ABC.\nIn March 2003, DC acquired publishing and merchandising rights to the long-running fantasy series \"Elfquest\", previously self-published by creators Wendy and Richard Pini under their WaRP Graphics publication banner. This series then followed another non-DC title, Tower Comics' series T.H.U.N.D.E.R. Agents, in collection into DC Archive Editions. In 2004, DC temporarily acquired the North American publishing rights to graphic novels from European publishers 2000 AD and Humanoids. It also rebranded its younger-audience titles with the mascot Johnny DC and established the CMX imprint to reprint translated manga. In 2006, CMX took over from Dark Horse Comics' publication of the webcomic \"Megatokyo\" in print form. DC also took advantage of the demise of Kitchen Sink Press and acquired the rights to much of the work of Will Eisner, such as his \"The Spirit\" series and his graphic novels.\nIn 2004, DC began laying the groundwork for a full continuity-reshuffling sequel to \"Crisis on Infinite Earths\", promising substantial changes to the DC Universe (and side-stepping the 1994 \"Zero Hour\" event which similarly tried to ret-con the history of the DCU). In 2005, the critically lauded \"Batman Begins\" film was released; also, the company published several limited series establishing increasingly escalating conflicts among DC's heroes, with events climaxing in the \"Infinite Crisis\" limited series. Immediately after this event, DC's ongoing series jumped forward a full year in their in-story continuity, as DC launched a weekly series, \"52\", to gradually fill in the missing time. Concurrently, DC lost the copyright to \"Superboy\" (while retaining the trademark) when the heirs of Jerry Siegel used a provision of the 1976 revision to the copyright law to regain ownership.\nIn 2005, DC launched its \"All-Star\" line (evoking the title of the 1940s publication), designed to feature some of the company's best-known characters in stories that eschewed the long and convoluted continuity of the DC Universe. The line began with \"All-Star Batman &amp; Robin the Boy Wonder\" and \"All-Star Superman\", and \"All-Star Wonder Woman\" and \"All-Star Batgirl\" was announced in 2006, but neither of these stories had been released or scheduled as of the end of 2009.\nBy 2007, DC was licensing characters from the Archie Comics imprint Red Circle Comics. They appeared in the Red Circle line, based in the DC Universe, with a series of one-shots followed by a miniseries that led into two ongoing titles that each lasted for ten issues.\nDC Entertainment.\nIn 2011, DC rebooted all of its running titles following the Flashpoint storyline. The reboot called The New 52 gave new origin stories and costume designs to many of DC's characters.\nDC licensed pulp characters including Doc Savage and the Spirit which it then used, along with some DC heroes, as part of the First Wave comics line launched in 2010 and lasting through fall 2011.\nIn May 2011, DC announced it would begin releasing digital versions of their comics on the same day as paper versions.\nOn June 1, 2011, DC announced that it would end all ongoing series set in the DC Universe in August and relaunch its comic line with 52 issue #1s, starting with \"Justice League\" on August 31 (written by Geoff Johns and drawn by Jim Lee), with the rest to follow later on in September.\nOn June 4, 2013, DC unveiled two new digital comic innovations to enhance interactivity: \"DC2\" and \"DC2 Multiverse\". \"DC2\" layers dynamic artwork onto digital comic panels, adding a new level of dimension to digital storytelling, while \"DC2 Multiverse\" allows readers to determine a specific story outcome by selecting individual characters, storylines and plot developments while reading the comic, meaning one digital comic has multiple outcomes. \"DC2\" appeared in the digital-first title, \"Batman '66\", based on the 1960s television series and \"DC2 Multiverse\" appeared in \"\", a digital-first title based on the .\nIn 2014, DC announced an eight-issue miniseries titled \"Convergence\" which began in April 2015.\nIn 2016, DC announced a line-wide relaunch titled DC Rebirth. The new line would launch with an 80-page one-shot titled DC Universe: Rebirth, written by Geoff Johns, with art from Gary Frank, Ethan Van Sciver, and more. After that, many new series would launch with a twice-monthly release schedule and new creative teams for nearly every title. The relaunch was meant to bring back the legacy and heart many felt had been missing from DC characters since the launch of the New 52. Rebirth brought huge success, both financially and critically.\nWarnerMedia / Warner Bros. Discovery unit (2018\u2013present).\nOn February 21, 2020, the Co-Publisher of DC Comics, Dan DiDio stepped down after 10 years at that position. The company did not give a reason for the move, nor did it indicate whether it was his decision or the company's. The leadership change was the latest event in the company restructuring which began the previous month, as several top executives were laid off from the company. However, Bleeding Cool reported that he was fired.\nIn June 2020, Warner Bros. announced a separate DC-themed online-only convention. Known as DC FanDome, the free \"immersive virtual fan experience\" was a 24-hour-long event held on August 22, 2020. The main presentation, entitled \"DC FanDome: Hall of Heroes\", was held as scheduled on August 22. The remaining programming was provided through a one-day video on demand experience, \"DC FanDome: Explore the Multiverse\", on September 12.\nAs Warner Bros. and DC's response to San Diego Comic-Con's cancellation due to the COVID-19 pandemic, the convention featured information about DC-based content including the DC Extended Universe film franchise, the Arrowverse television franchise, comic books, and video games. The convention also returned for the virtual premiere of \"Wonder Woman 1984\" and returned once again on October 16, 2021.\nIn August 2020, roughly one-third of DC's editorial ranks were laid off, including the editor-in-chief, senior story editor, executive editor, and several senior VPs.\nIn March 2021, DC relaunched their entire line once again under the banner of Infinite Frontier. After the events of the storyline, the DC Multiverse was expanded into a larger \"Omniverse\" where everything is canon, effectively reversing the changes The New 52 introduced a decade prior.\nFurthermore, AT&amp;T spun off WarnerMedia to Discovery, forming Warner Bros. Discovery. This merger was completed on April 8, 2022.\nIn January 2023, DC relaunched their line under the banner of Dawn of DC following the conclusion of Dark Crisis on Infinite Earths and Lazarus Planet. Later that year, Jim Lee was promoted to President of DC in May."}
{"id": "9106", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9106", "title": "David Grinnell", "text": ""}
{"id": "9108", "revid": "21327649", "url": "https://en.wikipedia.org/wiki?curid=9108", "title": "Daimler-Chrysler", "text": ""}
{"id": "9109", "revid": "42056547", "url": "https://en.wikipedia.org/wiki?curid=9109", "title": "Diophantine equation", "text": "In mathematics, a Diophantine equation is an equation, typically a polynomial equation in two or more unknowns with integer coefficients, for which only integer solutions are of interest. A linear Diophantine equation equates to a constant the sum of two or more monomials, each of degree one. An exponential Diophantine equation is one in which unknowns can appear in exponents.\nDiophantine problems have fewer equations than unknowns and involve finding integers that solve simultaneously all equations. As such systems of equations define algebraic curves, algebraic surfaces, or, more generally, algebraic sets, their study is a part of algebraic geometry that is called \"Diophantine geometry\".\nThe word \"Diophantine\" refers to the Hellenistic mathematician of the 3rd century, Diophantus of Alexandria, who made a study of such equations and was one of the first mathematicians to introduce symbolism into algebra. The mathematical study of Diophantine problems that Diophantus initiated is now called Diophantine analysis.\nWhile individual equations present a kind of puzzle and have been considered throughout history, the formulation of general theories of Diophantine equations (beyond the case of linear and quadratic equations) was an achievement of the twentieth century.\nExamples.\nIn the following Diophantine equations, , and are the unknowns and the other letters are given constants:\nLinear Diophantine equations.\nOne equation.\nThe simplest linear Diophantine equation takes the form \nformula_1 \nwhere , and are given integers. The solutions are described by the following theorem:\nProof: If is this greatest common divisor, B\u00e9zout's identity asserts the existence of integers and such that . If is a multiple of , then for some integer , and is a solution. On the other hand, for every pair of integers and , the greatest common divisor of and divides . Thus, if the equation has a solution, then must be a multiple of . If and , then for every solution , we have \nformula_2 \nshowing that is another solution. Finally, given two solutions such that \nformula_3 \none deduces that formula_4 \nAs and are coprime, Euclid's lemma shows that divides , and thus that there exists an integer such that both \nformula_5 \nTherefore, \nformula_6\nwhich completes the proof.\nChinese remainder theorem.\nThe Chinese remainder theorem describes an important class of linear Diophantine systems of equations: let formula_7 be pairwise coprime integers greater than one, formula_8 be arbitrary integers, and be the product formula_9 The Chinese remainder theorem asserts that the following linear Diophantine system has exactly one solution formula_10 such that , and that the other solutions are obtained by adding to a multiple of :\nformula_11\nSystem of linear Diophantine equations.\nMore generally, every system of linear Diophantine equations may be solved by computing the Smith normal form of its matrix, in a way that is similar to the use of the reduced row echelon form to solve a system of linear equations over a field. Using matrix notation every system of linear Diophantine equations may be written\nformula_12\nwhere is an matrix of integers, is an column matrix of unknowns and is an column matrix of integers.\nThe computation of the Smith normal form of provides two unimodular matrices (that is matrices that are invertible over the integers and have \u00b11 as determinant) and of respective dimensions and , such that the matrix\nformula_13\nis such that is not zero for not greater than some integer , and all the other entries are zero. The system to be solved may thus be rewritten as\nformula_14\nCalling the entries of and those of , this leads to the system\nformula_15\nThis system is equivalent to the given one in the following sense: A column matrix of integers is a solution of the given system if and only if for some column matrix of integers such that .\nIt follows that the system has a solution if and only if divides for and for . If this condition is fulfilled, the solutions of the given system are\nformula_16\nwhere are arbitrary integers.\nHermite normal form may also be used for solving systems of linear Diophantine equations. However, Hermite normal form does not directly provide the solutions; to get the solutions from the Hermite normal form, one has to successively solve several linear equations. Nevertheless, Richard Zippel wrote that the Smith normal form \"is somewhat more than is actually needed to solve linear diophantine equations. Instead of reducing the equation to diagonal form, we only need to make it triangular, which is called the Hermite normal form. The Hermite normal form is substantially easier to compute than the Smith normal form.\"\nInteger linear programming amounts to finding some integer solutions (optimal in some sense) of linear systems that include also inequations. Thus systems of linear Diophantine equations are basic in this context, and textbooks on integer programming usually have a treatment of systems of linear Diophantine equations.\nHomogeneous equations.\nA homogeneous Diophantine equation is a Diophantine equation that is defined by a homogeneous polynomial. A typical such equation is the equation of Fermat's Last Theorem\nAs a homogeneous polynomial in indeterminates defines a hypersurface in the projective space of dimension , solving a homogeneous Diophantine equation is the same as finding the rational points of a projective hypersurface.\nSolving a homogeneous Diophantine equation is generally a very difficult problem, even in the simplest non-trivial case of three indeterminates (in the case of two indeterminates the problem is equivalent with testing if a rational number is the th power of another rational number). A witness of the difficulty of the problem is Fermat's Last Theorem (for , there is no integer solution of the above equation), which needed more than three centuries of mathematicians' efforts before being solved.\nFor degrees higher than three, most known results are theorems asserting that there are no solutions (for example Fermat's Last Theorem) or that the number of solutions is finite (for example Falting's theorem). \nFor the degree three, there are general solving methods, which work on almost all equations that are encountered in practice, but no algorithm is known that works for every cubic equation.\nDegree two.\nHomogeneous Diophantine equations of degree two are easier to solve. The standard solving method proceeds in two steps. One has first to find one solution, or to prove that there is no solution. When a solution has been found, all solutions are then deduced.\nFor proving that there is no solution, one may reduce the equation modulo. For example, the Diophantine equation\ndoes not have any other solution than the trivial solution . In fact, by dividing , and by their greatest common divisor, one may suppose that they are coprime. The squares modulo 4 are congruent to 0 and 1. Thus the left-hand side of the equation is congruent to 0, 1, or 2, and the right-hand side is congruent to 0 or 3. Thus the equality may be obtained only if , and are all even, and are thus not coprime. Thus the only solution is the trivial solution . This shows that there is no rational point on a circle of radius formula_19 centered at the origin.\nMore generally, the Hasse principle allows deciding whether a homogeneous Diophantine equation of degree two has an integer solution, and computing a solution if there exist. \nIf a non-trivial integer solution is known, one may produce all other solutions in the following way.\nGeometric interpretation.\nLet \nbe a homogeneous Diophantine equation, where formula_21 is a quadratic form (that is, a homogeneous polynomial of degree 2), with integer coefficients. The \"trivial solution\" is the solution where all formula_22 are zero. If formula_23 is a non-trivial integer solution of this equation, then formula_24 are the homogeneous coordinates of a rational point of the hypersurface defined by . Conversely, if formula_25 are homogeneous coordinates of a rational point of this hypersurface, where formula_26 are integers, then formula_27 is an integer solution of the Diophantine equation. Moreover, the integer solutions that define a given rational point are all sequences of the form \nwhere is any integer, and is the greatest common divisor of the formula_29\nIt follows that solving the Diophantine equation formula_20 is completely reduced to finding the rational points of the corresponding projective hypersurface.\nParameterization.\nLet now formula_31 be an integer solution of the equation formula_32 As is a polynomial of degree two, a line passing through crosses the hypersurface at a single other point, which is rational if and only if the line is rational (that is, if the line is defined by rational parameters). This allows parameterizing the hypersurface by the lines passing through , and the rational points are those that are obtained from rational lines, that is, those that correspond to rational values of the parameters.\nMore precisely, one may proceed as follows. \nBy permuting the indices, one may suppose, without loss of generality that formula_33 Then one may pass to the affine case by considering the affine hypersurface defined by \nwhich has the rational point\nIf this rational point is a singular point, that is if all partial derivatives are zero at , all lines passing through are contained in the hypersurface, and one has a cone. The change of variables \ndoes not change the rational points, and transforms into a homogeneous polynomial in variables. In this case, the problem may thus be solved by applying the method to an equation with fewer variables.\nIf the polynomial is a product of linear polynomials (possibly with non-rational coefficients), then it defines two hyperplanes. The intersection of these hyperplanes is a rational flat, and contains rational singular points. This case is thus a special instance of the preceding case.\nIn the general case, consider the parametric equation of a line passing through :\nSubstituting this in , one gets a polynomial of degree two in , that is zero for . It is thus divisible by . The quotient is linear in , and may be solved for expressing as a quotient of two polynomials of degree at most two in formula_38 with integer coefficients:\nSubstituting this in the expressions for formula_40 one gets, for ,\nwhere formula_42 are polynomials of degree at most two with integer coefficients.\nThen, one can return to the homogeneous case. Let, for , \nbe the homogenization of formula_44 These quadratic polynomials with integer coefficients form a parameterization of the projective hypersurface defined by :\nA point of the projective hypersurface defined by is rational if and only if it may be obtained from rational values of formula_46 As formula_47 are homogeneous polynomials, the point is not changed if all are multiplied by the same rational number. Thus, one may suppose that formula_48 are coprime integers. It follows that the integer solutions of the Diophantine equation are exactly the sequences formula_49 where, for ,\nwhere is an integer, formula_48 are coprime integers, and is the greatest common divisor of the integers formula_52\nOne could hope that the coprimality of the , could imply that . Unfortunately this is not the case, as shown in the next section.\nExample of Pythagorean triples.\nThe equation \nis probably the first homogeneous Diophantine equation of degree two that has been studied. Its solutions are the Pythagorean triples. This is also the homogeneous equation of the unit circle. In this section, we show how the above method allows retrieving Euclid's formula for generating Pythagorean triples.\nFor retrieving exactly Euclid's formula, we start from the solution , corresponding to the point of the unit circle. A line passing through this point may be parameterized by its slope:\nPutting this in the circle equation \none gets \nDividing by , results in\nwhich is easy to solve in :\nIt follows\nHomogenizing as described above one gets all solutions as \nwhere is any integer, and are coprime integers, and is the greatest common divisor of the three numerators. In fact, if and are both odd, and if one is odd and the other is even.\nThe \"primitive triples\" are the solutions where and .\nThis description of the solutions differs slightly from Euclid's formula because Euclid's formula considers only the solutions such that , and are all positive, and does not distinguish between two triples that differ by the exchange of and ,\nDiophantine analysis.\nTypical questions.\nThe questions asked in Diophantine analysis include:\nThese traditional problems often lay unsolved for centuries, and mathematicians gradually came to understand their depth (in some cases), rather than treat them as puzzles.\nTypical problem.\nThe given information is that a father's age is 1 less than twice that of his son, and that the digits making up the father's age are reversed in the son's age (i.e. ). This leads to the equation , thus . Inspection gives the result , , and thus equals 73 years and equals 37 years. One may easily show that there is not any other solution with and positive integers less than 10.\nMany well known puzzles in the field of recreational mathematics lead to diophantine equations. Examples include the cannonball problem, Archimedes's cattle problem and the monkey and the coconuts.\n17th and 18th centuries.\nIn 1637, Pierre de Fermat scribbled on the margin of his copy of \"Arithmetica\": \"It is impossible to separate a cube into two cubes, or a fourth power into two fourth powers, or in general, any power higher than the second into two like powers.\" Stated in more modern language, \"The equation has no solutions for any higher than 2.\" Following this, he wrote: \"I have discovered a truly marvelous proof of this proposition, which this margin is too narrow to contain.\" Such a proof eluded mathematicians for centuries, however, and as such his statement became famous as Fermat's Last Theorem. It was not until 1995 that it was proven by the British mathematician Andrew Wiles.\nIn 1657, Fermat attempted to solve the Diophantine equation (solved by Brahmagupta over 1000 years earlier). The equation was eventually solved by Euler in the early 18th century, who also solved a number of other Diophantine equations. The smallest solution of this equation in positive integers is , (see Chakravala method).\nHilbert's tenth problem.\nIn 1900, David Hilbert proposed the solvability of all Diophantine equations as the tenth of his fundamental problems. In 1970, Yuri Matiyasevich solved it negatively, building on work of Julia Robinson, Martin Davis, and Hilary Putnam to prove that a general algorithm for solving all Diophantine equations cannot exist.\nDiophantine geometry.\nDiophantine geometry, is the application of techniques from algebraic geometry which considers equations that also have a geometric meaning. The central idea of Diophantine geometry is that of a rational point, namely a solution to a polynomial equation or a system of polynomial equations, which is a vector in a prescribed field , when is \"not\" algebraically closed.\nModern research.\nThe oldest general method for solving a Diophantine equationor for proving that there is no solution is the method of infinite descent, which was introduced by Pierre de Fermat. Another general method is the Hasse principle that uses modular arithmetic modulo all prime numbers for finding the solutions. Despite many improvements these methods cannot solve most Diophantine equations.\nThe difficulty of solving Diophantine equations is illustrated by Hilbert's tenth problem, which was set in 1900 by David Hilbert; it was to find an algorithm to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. Matiyasevich's theorem implies that such an algorithm cannot exist.\nDuring the 20th century, a new approach has been deeply explored, consisting of using algebraic geometry. In fact, a Diophantine equation can be viewed as the equation of an hypersurface, and the solutions of the equation are the points of the hypersurface that have integer coordinates.\nThis approach led eventually to the proof by Andrew Wiles in 1994 of Fermat's Last Theorem, stated without proof around 1637. This is another illustration of the difficulty of solving Diophantine equations.\nInfinite Diophantine equations.\nAn example of an infinite Diophantine equation is:\nformula_61\nwhich can be expressed as \"How many ways can a given integer be written as the sum of a square plus twice a square plus thrice a square and so on?\" The number of ways this can be done for each forms an integer sequence. Infinite Diophantine equations are related to theta functions and infinite dimensional lattices. This equation always has a solution for any positive . Compare this to:\nformula_62\nwhich does not always have a solution for positive .\nExponential Diophantine equations.\nIf a Diophantine equation has as an additional variable or variables occurring as exponents, it is an exponential Diophantine equation. Examples include:\nA general theory for such equations is not available; particular cases such as Catalan's conjecture and Fermat's Last Theorem have been tackled. However, the majority are solved via ad-hoc methods such as St\u00f8rmer's theorem or even trial and error."}
{"id": "9110", "revid": "40552684", "url": "https://en.wikipedia.org/wiki?curid=9110", "title": "Diophantus", "text": "Diophantus of Alexandria (born ; died ) was a Greek mathematician, who was the author of two main works: \"On Polygonal Numbers\", which survives incomplete, and the \"Arithmetica\" in thirteen books, most of it extant, made up of arithmetical problems that are solved through algebraic equations. He has been referred to as \"the father of algebra\". \nHis \"Arithmetica\" influenced the development of algebra by Arabs, and his equations influenced modern work in both abstract algebra and computer science. The first five books of his work are purely algebraic. Furthermore, recent studies of Diophantus's work have revealed that the method of solution taught in his \"Arithmetica\" matches later medieval Arabic algebra in its concepts and overall procedure.\nDiophantus was among the earliest mathematicians who recognized positive rational numbers as numbers, by allowing fractions for coefficients and solutions. He coined the term \u03c0\u03b1\u03c1\u03b9\u03c3\u03cc\u03c4\u03b7\u03c2 (\"parisot\u0113s\") to refer to an approximate equality. This term was rendered as \"adaequalitas\" in Latin, and became the technique of adequality developed by Pierre de Fermat to find maxima for functions and tangent lines to curves. \nAlthough not the earliest, the \"Arithmetica\" has the best-known use of algebraic notation to solve arithmetical problems coming from Greek antiquity, and some of its problems served as inspiration for later mathematicians working in analysis and number theory. In modern use, Diophantine equations are algebraic equations with integer coefficients for which integer solutions are sought. Diophantine geometry and Diophantine approximations are two other subareas of number theory that are named after him.\nBiography.\nDiophantus was born into a Greek family and is known to have lived in Alexandria, Egypt, during the Roman era, between AD 200 and 214 to 284 or 298. Much of our knowledge of the life of Diophantus is derived from a 5th-century Greek anthology of number games and puzzles created by Metrodorus. One of the problems (sometimes called his epitaph) states:Here lies Diophantus, the wonder behold. Through art algebraic, the stone tells how old: 'God gave him his boyhood one-sixth of his life, One twelfth more as youth while whiskers grew rife; And then yet one-seventh ere marriage begun; In five years there came a bouncing new son. Alas, the dear child of master and sage After attaining half the measure of his father's life chill fate took him. After consoling his fate by the science of numbers for four years, he ended his life.'This puzzle implies that Diophantus' age can be expressed as\nwhich gives a value of 84 years. However, the accuracy of the information cannot be confirmed.\nIn popular culture, this puzzle was the Puzzle No.142 in \"Professor Layton and Pandora's Box\" as one of the hardest solving puzzles in the game, which needed to be unlocked by solving other puzzles first.\n\"Arithmetica\".\n\"Arithmetica\" is the major work of Diophantus and the most prominent work on premodern algebra in Greek mathematics. It is a collection of problems giving numerical solutions of both determinate and indeterminate equations. Of the original thirteen books of which \"Arithmetica\" consisted only six have survived, though there are some who believe that four Arabic books discovered in 1968 are also by Diophantus. Some Diophantine problems from \"Arithmetica\" have been found in Arabic sources.\nIt should be mentioned here that Diophantus never used general methods in his solutions. Hermann Hankel, renowned German mathematician made the following remark regarding Diophantus:Our author (Diophantos) not the slightest trace of a general, comprehensive method is discernible; each problem calls for some special method which refuses to work even for the most closely related problems. For this reason it is difficult for the modern scholar to solve the 101st problem even after having studied 100 of Diophantos's solutions.\nHistory.\nLike many other Greek mathematical treatises, Diophantus was forgotten in Western Europe during the Dark Ages, since the study of ancient Greek, and literacy in general, had greatly declined. The portion of the Greek \"Arithmetica\" that survived, however, was, like all ancient Greek texts transmitted to the early modern world, copied by, and thus known to, medieval Byzantine scholars. Scholia on Diophantus by the Byzantine Greek scholar John Chortasmenos (1370\u20131437) are preserved together with a comprehensive commentary written by the earlier Greek scholar Maximos Planudes (1260 \u2013 1305), who produced an edition of Diophantus within the library of the Chora Monastery in Byzantine Constantinople. In addition, some portion of the \"Arithmetica\" probably survived in the Arab tradition (see above). In 1463 German mathematician Regiomontanus wrote:No one has yet translated from the Greek into Latin the thirteen books of Diophantus, in which the very flower of the whole of arithmetic lies hidden.\"Arithmetica\" was first translated from Greek into Latin by Bombelli in 1570, but the translation was never published. However, Bombelli borrowed many of the problems for his own book \"Algebra\". The \"editio princeps\" of \"Arithmetica\" was published in 1575 by Xylander. The Latin translation of \"Arithmetica\" by Bachet in 1621 became the first Latin edition that was widely available. Pierre de Fermat owned a copy, studied it and made notes in the margins. A later 1895 Latin translation by Paul Tannery was said to be an improvement by Thomas L. Heath, who used it in the 1910 second edition of his English translation.\nMargin-writing by Fermat and Chortasmenos.\nThe 1621 edition of \"Arithmetica\" by Bachet gained fame after Pierre de Fermat wrote his famous \"Last Theorem\" in the margins of his copy: If an integer is greater than 2, then has no solutions in non-zero integers , , and . I have a truly marvelous proof of this proposition which this margin is too narrow to contain.Fermat's proof was never found, and the problem of finding a proof for the theorem went unsolved for centuries. A proof was finally found in 1994 by Andrew Wiles after working on it for seven years. It is believed that Fermat did not actually have the proof he claimed to have. Although the original copy in which Fermat wrote this is lost today, Fermat's son edited the next edition of Diophantus, published in 1670. Even though the text is otherwise inferior to the 1621 edition, Fermat's annotations\u2014including the \"Last Theorem\"\u2014were printed in this version.\nFermat was not the first mathematician so moved to write in his own marginal notes to Diophantus; the Byzantine scholar John Chortasmenos (1370\u20131437) had written \"Thy soul, Diophantus, be with Satan because of the difficulty of your other theorems and particularly of the present theorem\" next to the same problem.\nOther works.\nDiophantus wrote several other books besides \"Arithmetica\", but only a few of them have survived.\nThe \"Porisms\".\nDiophantus himself refers to a work which consists of a collection of lemmas called \"The Porisms\" (or \"Porismata\"), but this book is entirely lost.\nAlthough \"The Porisms\" is lost, we know three lemmas contained there, since Diophantus refers to them in the \"Arithmetica\". One lemma states that the difference of the cubes of two rational numbers is equal to the sum of the cubes of two other rational numbers, i.e. given any and , with , there exist , all positive and rational, such that\nPolygonal numbers and geometric elements.\nDiophantus is also known to have written on polygonal numbers, a topic of great interest to Pythagoras and Pythagoreans. Fragments of a book dealing with polygonal numbers are extant.\nA book called \"Preliminaries to the Geometric Elements\" has been traditionally attributed to Hero of Alexandria. It has been studied recently by Wilbur Knorr, who suggested that the attribution to Hero is incorrect, and that the true author is Diophantus.\nInfluence.\nDiophantus' work has had a large influence in history. Editions of \"Arithmetica\" exerted a profound influence on the development of algebra in Europe in the late sixteenth and through the 17th and 18th centuries. Diophantus and his works also influenced Arab mathematics and were of great fame among Arab mathematicians. Diophantus' work created a foundation for work on algebra and in fact much of advanced mathematics is based on algebra. How much he affected India is a matter of debate.\nDiophantus has been considered \"the father of algebra\" because of his contributions to number theory, mathematical notations and the earliest known use of syncopated notation in his book series \"Arithmetica\". However this is usually debated, because Al-Khwarizmi was also given the title as \"the father of algebra\", nevertheless both mathematicians were responsible for paving the way for algebra today.\nDiophantine analysis.\nToday, Diophantine analysis is the area of study where integer (whole-number) solutions are sought for equations, and Diophantine equations are polynomial equations with integer coefficients to which only integer solutions are sought. It is usually rather difficult to tell whether a given Diophantine equation is solvable. Most of the problems in \"Arithmetica\" lead to quadratic equations. Diophantus looked at 3 different types of quadratic equations: , , and . The reason why there were three cases to Diophantus, while today we have only one case, is that he did not have any notion for zero and he avoided negative coefficients by considering the given numbers , , to all be positive in each of the three cases above. Diophantus was always satisfied with a rational solution and did not require a whole number which means he accepted fractions as solutions to his problems. Diophantus considered negative or irrational square root solutions \"useless\", \"meaningless\", and even \"absurd\". To give one specific example, he calls the equation 'absurd' because it would lead to a negative value for . One solution was all he looked for in a quadratic equation. There is no evidence that suggests Diophantus even realized that there could be two solutions to a quadratic equation. He also considered simultaneous quadratic equations.\nMathematical notation.\nDiophantus made important advances in mathematical notation, becoming the first person known to use algebraic notation and symbolism. Before him everyone wrote out equations completely. Diophantus introduced an algebraic symbolism that used an abridged notation for frequently occurring operations, and an abbreviation for the unknown and for the powers of the unknown. Mathematical historian Kurt Vogel states:The symbolism that Diophantus introduced for the first time, and undoubtedly devised himself, provided a short and readily comprehensible means of expressing an equation... Since an abbreviation is also employed for the word 'equals', Diophantus took a fundamental step from verbal algebra towards symbolic algebra.Although Diophantus made important advances in symbolism, he still lacked the necessary notation to express more general methods. This caused his work to be more concerned with particular problems rather than general situations. Some of the limitations of Diophantus' notation are that he only had notation for one unknown and, when problems involved more than a single unknown, Diophantus was reduced to expressing \"first unknown\", \"second unknown\", etc. in words. He also lacked a symbol for a general number . Where we would write , Diophantus has to resort to constructions like: \"... a sixfold number increased by twelve, which is divided by the difference by which the square of the number exceeds three\". Algebra still had a long way to go before very general problems could be written down and solved succinctly."}
{"id": "9111", "revid": "1254181173", "url": "https://en.wikipedia.org/wiki?curid=9111", "title": "Dong", "text": "Dong or DONG may refer to:"}
{"id": "9112", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9112", "title": "Dr. Doom", "text": ""}
{"id": "9118", "revid": "39498865", "url": "https://en.wikipedia.org/wiki?curid=9118", "title": "Duke Kahanamoku", "text": "Duke Paoa Kahinu Mokoe Hulikohola Kahanamoku (August 24, 1890 \u2013 January 22, 1968) was a Hawaiian competition swimmer, lifeguard, and popularizer of the sport of surfing. A Native Hawaiian, he was born three years before the overthrow of the Hawaiian Kingdom. He lived to see the territory's admission as a state and became a United States citizen. He was a five-time Olympic medalist in swimming, winning medals in 1912, 1920 and 1924.\nKahanamoku joined fraternal organizations: he was a Scottish Rite Freemason in the Honolulu lodge, and a Shriner. He worked as a law enforcement officer, an actor, a beach volleyball player, and a businessman.\nFamily background.\nAccording to Kahanamoku, he was born in Honolulu at Hale\u02bb\u0101kala, the home of Bernice Pauahi Bishop, which was later converted into the Arlington Hotel.\nHe was born into a family of Native Hawaiians headed by Duke Halapu Kahanamoku and Julia Pa\u02bbakonia Lonokahikina Paoa. He had five brothers, and three sisters. His brothers were Sargent, Samuel, David, William and Louis, all of whom participated in competitive aquatic sports. His sisters were Bernice, Kapiolani and Maria.\n\"Duke\" was not a title or a nickname, but a given name. He was named after his father, Duke Halapu Kahanamoku, who was christened by Bernice Pauahi Bishop in honor of Prince Alfred, Duke of Edinburgh, who was visiting Hawaii at the time. His father was a policeman. His mother Julia Paakonia Lonokahikina Paoa was a deeply religious woman with a strong sense of family ancestry.\nHis parents were from prominent Hawaiian \"ohana\" (families). The Kahanamoku and the Paoa ohana were considered to be lower-ranking nobles, who were in service to the \"ali\u02bbi nui\", or royalty. His paternal grandfather was Kahanamoku and his grandmother, Kapiolani Kaoeha (sometimes spelled \"Kahoea\"), a descendant of Alapainui. They were \"kahu\", retainers and trusted advisors of the Kamehamehas, to whom they were related. His maternal grandparents Paoa, son of Paoa Hoolae and Hiikaalani, and Mele Uliama, were also of ali\u02bbi descent.\nIn 1893, his family moved to K\u0101lia, Waikiki (near the present site of Hilton Hawaiian Village), to be closer to his mother's parents and family. Kahanamoku grew up with his siblings and 31 Paoa cousins. He attended the Waikiki Grammar School, Kaahumanu School, and the Kamehameha Schools, although he never graduated because he had to quit to help support the family.\nEarly years.\nGrowing up on the outskirts of Waikiki, Kahanamoku spent much of his youth at the beach, where he developed his surfing and swimming skills. In his youth, Kahanamoku preferred a traditional surf board, which he called his \"papa nui\", constructed after the fashion of ancient Hawaiian olo boards. Made from the wood of a koa tree, it was long and weighed . The board was without a skeg, which had yet to be invented. In his later surfing career, he would often use smaller boards but always preferred those made of wood.\nKahanamoku was a powerful swimmer. On August 11, 1911, he was timed at 55.4 seconds in the freestyle, beating the existing world record by 4.6 seconds, in the salt water of Honolulu Harbor. He broke the record in the and equaled it in the . But the Amateur Athletic Union (AAU), in disbelief, would not recognize these feats until many years later. The AAU initially claimed that the judges must have been using alarm clocks rather than stopwatches and later claimed that ocean currents aided Kahanamoku.\nCareer.\nKahanamoku easily qualified for the U.S. Olympic swimming team in 1912. At the 1912 Summer Olympics in Stockholm, he won a gold medal in the 100-meter freestyle, and a silver medal with the second-place U.S. team in the men's 4\u00d7200-meter freestyle relay.\nDuring the 1920 Olympics in Antwerp, Kahanamoku won gold medals in both the 100 meters (bettering fellow Hawaiian Pua Kealoha) and in the relay. He finished the 100 meters with a silver medal during the 1924 Olympics in Paris, with the gold going to Johnny Weissmuller and the bronze to Kahanamoku's brother, Samuel. By then age 34, Kahanamoku won no more Olympic medals. But he served as an alternate for the U.S. water polo team at the 1932 Summer Olympics.\nPost-Olympic career.\nBetween Olympic competitions, and after retiring from the Olympics, Kahanamoku traveled internationally to give swimming exhibitions. It was during this period that he popularized the sport of surfing, previously known only in Hawaii, by incorporating surfing exhibitions into his touring exhibitions as well. He attracted people to surfing in mainland America first in 1912 while in Southern California. He trained and loaned equipment to new surfers, such as Dorothy Becker.\nHis surfing exhibition at Sydney, Australia's Freshwater Beach on December 24, 1914, is widely regarded as a seminal event in the development of surfing in Australia. The board that Kahanamoku built from a piece of pine from a local hardware store is retained by the Freshwater Surf Life Saving Club. A statue of Kahanamoku was erected in his honor on the Northern headland of Freshwater Lake, New South Wales.\nDuring his time living in Southern California, Kahanamoku performed in Hollywood as a background actor and a character actor in several films. He made connections in this way with people who could further publicize the sport of surfing. Kahanamoku was involved with the Los Angeles Athletic Club, acting as a lifeguard and competing in both swimming and water polo teams.\nWhile living in Newport Beach, California, on June 14, 1925, Kahanamoku rescued eight men from a fishing vessel that capsized in heavy surf while it was attempting to enter the city's harbor. Using his surfboard, Kahanamoku made repeated trips from shore to the capsized ship, and helped rescue several people. Two other surfers saved four more fishermen, while five succumbed to the seas before they could be rescued. At the time the Newport Beach police chief called Kahanamoku's efforts \"The most superhuman surfboard rescue act the world has ever seen.\" The widespread publicity surrounding the rescue influenced lifeguards across the US to begin the use of surfboards as standard equipment for water rescues.\nKahanamoku was the first person to be inducted into both the Swimming Hall of Fame and the Surfing Hall of Fame. The Duke Kahanamoku Invitational Surfing Championships in Hawaii, the first major professional surfing contest event ever held in the huge surf on the North Shore of Oahu, was named in his honor. He is a member of the U.S. Olympic Hall of Fame.\nLater Kahanamoku was elected to serve as the Sheriff of Honolulu, Hawaii from 1932 to 1961, completing 13 consecutive terms. During World War II, he served as a military police officer for the United States; Hawai'i was not yet a state and was administered.\nIn the postwar period, Kahanamoku appeared in a number of television programs and films, including \"Mister Roberts\" (1955). He was well-liked throughout the Hollywood community.\nKahanamoku became a friend and surfing companion of heiress Doris Duke. She built a home (now a museum) on Oahu named Shangri-la. Kahanamoku gave private surfing lessons to Franklin D. Roosevelt Jr. and John Aspinwall Roosevelt, the children of Franklin D. Roosevelt.\n\"Duncan v. Kahanamoku\".\nIn 1946, Kahanamoku was the \"pro forma\" defendant in the landmark Supreme Court case \"Duncan v. Kahanamoku\". While Kahanamoku was a military police officer during World War II, he arrested Duncan, a civilian shipfitter, for public intoxication.\nAt the time, Hawaii, not yet a state, was being administered by the United States under the Hawaiian Organic Act. This effectively instituted martial law on the island. After Duncan was tried by a military tribunal, he appealed to the Supreme Court. In a \"post hoc\" ruling, the court ruled that trial by military tribunal for the civilian was, in this case, unconstitutional.\nPersonal life.\nOn August 2, 1940, Kahanamoku married dance instructor Nadine Alexander, who had relocated to Hawaii from Cleveland, Ohio, after she had been hired to teach at the Royal Hawaiian Hotel. Duke was 50 years old, Nadine was 35.\nHe was initiated, passed and raised to the degree of Master Mason in Hawaiian Lodge Masonic Lodge No 21\n and was also a Noble (member) of the Shriners fraternal organization. He was a Republican.\nDeath and legacy.\nKahanamoku died of a heart attack on January 22, 1968, at age 77. For his burial at sea, a long motorcade of mourners, accompanied by a 30-man police escort, traveled in procession across town to Waikiki Beach. Reverend Abraham Akaka, the pastor of Kawaiahao Church, performed the service. A group of beach boys sang Hawaiian songs, including \"Aloha Oe\", and Kahanamoku's ashes were scattered into the ocean.\nStatues and monuments.\nIn 1994, a statue of Kahanamoku by Barry Donohoo was inaugurated in Freshwater, NSW, Australia. It is the showpiece of the Australian Surfers Walk of Fame.\nOn February 28, 2015, a monument featuring a replica of Kahanamoku's surfboard was unveiled at New Brighton beach, Christchurch, New Zealand in honor of the 100th anniversary of Kahanamoku's visit to New Brighton.\nA statue of Kahanamoku was installed in Huntington Beach, California. A nearby restaurant is named for him and is close to Huntington Beach pier. The City of Huntington Beach identifies with the legacy of surfing, and a museum dedicated to that sport is located here.\nIn April 2022, NSW Heritage announced that Kahanamoku would be included in the first batch of Blue Plaques to be issued, to recognize his contribution to recreation and surfing.\nA sculpture of Kahanamoku flanked by a male knee paddler and a female prone paddler commemorating the Catalina Classic Paddleboard Race was installed on the Manhattan Beach Pier in 2023.\nAdditional tributes.\nHawaii music promoter Kimo Wilder McVay capitalized on Kahanamoku's popularity by naming his Waikiki showroom \"Duke Kahanamoku's\" at the International Market Place and giving Kahanamoku a financial interest in the showroom in exchange for the use of his name. It was a major Waikiki showroom in the 1960s and is remembered as the home of Don Ho &amp; The Aliis from 1964 through 1969. The showroom continued to be known as Duke Kahanamoku's until Hawaii showman Jack Cione bought it in the mid-1970s and renamed it Le Boom Boom.\nThe Duke Kahanamoku Aquatic Complex (DKAC) serves as the home for the University of Hawai\u2018i's swimming and diving and women's water polo teams. The facility, located on the university's lower campus, includes a 50-meter training pool and a separate 25-yard competition and diving pool. The long course pool is four feet at both ends, seven feet in the middle, and an average depth of six feet.\nKahanamoku's name is also used by Duke's Canoe Club &amp; Barefoot Bar, known as Duke's Waikiki, a beachfront bar and restaurant in the Outrigger Waikiki on the Beach Hotel. There is a chain of restaurants named after him in California, Florida and Hawaii called Duke's.\nOn August 24, 2002, the 112th anniversary of Kahanamoku's birth, the U.S. Postal Service issued a first-class commemorative stamp with Duke's picture on it. The First Day Ceremony was held at the Hilton Hawaiian Village in Waikiki and was attended by thousands. At this ceremony, attendees could attach the Duke stamp to an envelope and get it canceled with a First Day of Issue postmark. These first day covers are very collectible.\nOn August 24, 2015, a Google Doodle honored the 125th anniversary of Duke Kahanamoku's birthday.\nIn 2021, a 88-minute feature film was made about Kahanamoku's life.\n It was later broadcast by PBS as part of their American Masters series."}
{"id": "9119", "revid": "6169056", "url": "https://en.wikipedia.org/wiki?curid=9119", "title": "Distinguished Service Medal (U.S. Army)", "text": "The Distinguished Service Medal (DSM) is a military decoration of the United States Army that is presented to soldiers who have distinguished themselves by exceptionally meritorious service to the government in a duty of great responsibility. The performance must be such as to merit recognition for service that is clearly exceptional. The exceptional performance of normal duty will not alone justify an award of this decoration.\nThe Army's Distinguished Service Medal is equivalent to the Naval Service's Navy Distinguished Service Medal, Air and Space Forces' Distinguished Service Medal, and the Coast Guard Distinguished Service Medal. Prior to the creation of the Air Force's Distinguished Service Medal in 1960, United States Air Force airmen were awarded the Army's Distinguished Service Medal.\nCriteria.\nThe Distinguished Service Medal is awarded to any person - effectively, general officers - who, while serving in any capacity with the United States Army, has distinguished themselves by exceptionally meritorious service to the Government in a duty of great responsibility.\nThe performance must be such as to merit recognition for service which is clearly exceptional. Exceptional performance of normal duty will not alone justify an award of this decoration. For service not related to actual war, the term \"duty of a great responsibility\" applies to a narrower range of positions than in time of war and requires evidence of a conspicuously significant achievement. However, justification of the award may accrue by virtue of exceptionally meritorious service in a succession of high positions of great importance. Awards may be made to persons other than members of the Armed Forces of the United States for wartime services only, and only then under exceptional circumstances with the express approval of the president in each case.\nHistory of the Distinguished Service Medal.\nThe Distinguished Service Medal was authorized by Presidential Order dated January 2, 1918, and confirmed by Congress on July 9, 1918. It was announced by War Department General Order No. 6, 1918-01-12, with the following information concerning the medal: \"A bronze medal of appropriate design and a ribbon to be worn in lieu thereof, to be awarded by the President to any person who, while serving in any capacity with the Army shall hereafter distinguish himself or herself, or who, since 04-06-1917, has distinguished himself or herself by exceptionally meritorious service to the Government in a duty of great responsibility in time of war or in connection with military operations against an armed enemy of the United States.\" The Act of Congress on July 9, 1918, recognized the need for different types and degrees of heroism and meritorious service and included such provisions for award criteria. The current statutory authorization for the Distinguished Service Medal is Title 10, United States Code, Section 3743.\nRecipients.\nMore than 2,000 awards were made during World War I, and by the time the United States entered World War II, approximately 2,800 awards had been made. From July 1, 1941, to June 6, 1969, when the Department of the Army stopped publishing awards of the DSM in Department of the Army General Orders, over 2,800 further awards were made.\nPrior to World War II the DSM was the only decoration for non-combat service in the U.S. Army. As a result, before World War II the DSM was awarded to a wider range of recipients than during and after World War II. During World War I awards of the DSM to officers below the rank of brigadier general were fairly common but became rare once the Legion of Merit was established in 1942.\nUntil the first award of the Air Force Distinguished Service Medal in 1965, United States Air Force personnel received this award as well, as was the case with several other Department of the Army decorations until the Department of the Air Force fully established its own system of decorations.\nNotable recipients.\nBecause the Army Distinguished Service Medal is principally awarded to general officers, a list of notable recipients would include nearly every general, and some admirals, since 1918, many of whom received multiple awards, as well as a few civilians and sergeants major prominent for their contributions to national defense.\nGeneral Martin Dempsey, former chairman of the Joint Chiefs of Staff, holds the record for receiving the greatest number of awards of the Army Distinguished Service Medal, at six. He also received three awards of the Defense Distinguished Service Medal as well as one award each of the Navy Distinguished Service Medal, the Air Force Distinguished Service Medal, and the Coast Guard Distinguished Service Medal, for a total of twelve Distinguished Service Medals.\nGenerals of the Army Douglas MacArthur and Dwight Eisenhower are tied with five awards each received of the Army Distinguished Service Medal. They also each received one award of the Navy Distinguished Service Medal, for a total of six DSMs each.\nGeneral Lucius D. Clay (Four Star) received three Army DSM awards for his service that included Commanding General, U.S. Army Forces (European Theater) and Military Governor of Germany. During his tenure, Gen. Clay solved his greatest challenge: the Soviet Blockade of Berlin, which was imposed in June 1948. Gen. Clay triggered the Berlin Airlift, which served the city residents during the harsh winter of 1948\u20131949. He is also a recipient of the Legion of Merit.\nGeneral Norman Schwarzkopf received two awards of the Army DSM and one award each of the Defense DSM, Navy DSM, the Air Force DSM and the Coast Guard DSM, for a total of six DSMs.\nGeneral Lloyd Austin received four awards of the Army DSM and five awards of the Defense DSM for a total of nine DSMs.\nAmong notable recipients below flag rank are: X-1 test pilot Chuck Yeager and X-15 test pilot Robert M. White, who both received the DSM as U.S. Air Force majors; director Frank Capra, decorated in 1945 as an army colonel; actor James Stewart, decorated in 1945 as an Army Air Forces colonel (later Air Force Brigadier General); Colonel Wendell Fertig, who led Filipino guerrillas behind Japanese lines; Colonel (later Major General) John K. Singlaub, who led partisan forces in the Korean War; and Major Maude C. Davison, who led the \"Angels of Bataan and Corregidor\" during their imprisonment by the Japanese, and Colonel William S. Taylor, Program Manager Multiple Launch Rocket System. Among notable civilian recipients are Harry L. Hopkins, Robert S. McNamara and Henry L. Stimson.\nSamuel W. Koster received a DSM, but this was rescinded due to his involvement in covering up the My Lai massacre\nNotable American and foreign recipients include:\nUnited States Air Force.\nNote \u2013 includes Army Air Service, Army Air Corps and Army Air Forces\nReferences.\nMajor General Franklin L McKean - https://ocsalumni.org/at_biz_dir/franklin-l-mckean/"}
{"id": "9120", "revid": "1248323169", "url": "https://en.wikipedia.org/wiki?curid=9120", "title": "Defense Distinguished Service Medal", "text": "The Defense Distinguished Service Medal is a military decoration of the United States Department of Defense, which is presented to United States Armed Forces service members for exceptionally distinguished performance of duty contributing to the national security or defense of the United States. The medal was created on July 9, 1970, by President Richard Nixon in . President Nixon awarded the first medal, on the day the Executive Order was signed, to General Earle Wheeler, who was retiring from the US Army after serving as Chief of Staff of the United States Army and then Chairman of the Joint Chiefs of Staff.\nIt is equivalent to the United States Department of Homeland Security's Homeland Security Distinguished Service Medal.\nCriteria.\nThe Defense Distinguished Service Medal is the United States Department of Defense's highest non-combat related military award and it is the highest joint service decoration. The Defense Distinguished Service Medal is awarded only while assigned to a joint activity. Normally, such responsibilities deserving of the Defense Distinguished Service Medal are held by the most senior officers such as the Chairman and Vice Chairman of the Joint Chiefs of Staff, the chiefs and vice chiefs of the military services, and commanders and deputy commanders of the Combatant Commands, the Director of the Joint Staff, and others whose duties bring them frequently into direct contact with the Secretary of Defense, the Deputy Secretary of Defense, and other senior government officials. In addition, the medal may also be awarded to other service members whose direct and individual contributions to national security or national defense are recognized as being so exceptional in scope and value as to be equivalent to contributions normally associated with positions encompassing broader responsibilities.\nThis decoration takes precedence over the Distinguished Service Medals of the services and is not to be awarded to any individual for a period of service for which an Army, Navy, Air Force or Coast Guard Distinguished Service Medal is awarded.\nAppearance.\nThe medal is gold in color and on the obverse it features a medium blue enameled pentagon (point up). Superimposed on this is an American bald eagle with wings outspread facing left grasping three crossed arrows in its talons and on its breast is a shield of the United States. The pentagon and eagle are enclosed within a gold pieced circle consisting, in the upper half of 13 five-pointed stars and in the lower half, a wreath of laurel on the left and olive on the right. At the top is a suspender of five graduated gold rays. The reverse of the medal has the inscription \"For Distinguished Service\" at the top in raised letters, and within the pentagon the inscription \"FROM THE SECRETARY OF DEFENSE TO\", all in raised letters.\nAdditional awards of the Defense Distinguished Service Medal are denoted by oak leaf clusters.\nNotable recipients.\n- John Zirkelbach (two awards)"}
{"id": "9121", "revid": "48371163", "url": "https://en.wikipedia.org/wiki?curid=9121", "title": "Dacoity", "text": "Dacoity is a term used for \"banditry\" in the Indian subcontinent. The spelling is the anglicised version of the Hindi word \u0921\u093e\u0915\u0942 (\u1e0d\u0101k\u016b); \"dacoit\" is a colloquial Indian English word with this meaning. It appears in the \"Glossary of Colloquial Anglo-Indian Words and Phrases\" (1903). Banditry is a criminal activity involving robbery by groups of armed bandits. The East India Company established the Thuggee and Dacoity Department in 1830, and the Thuggee and Dacoity Suppression Acts, 1836\u20131848 were enacted in British India under East India Company rule. Areas with ravines or forests, such as Chambal and Chilapata Forests, were once known for dacoits.\nEtymology.\nThe word \"dacoity\" is an anglicized version of the Hindi word \"\u1e0dakait\u012b\" (historically transliterated \"dakaitee\"). Hindi \u0921\u0915\u0948\u0924\u0940 comes from \"\u1e0d\u0101k\u016b\" (historically transliterated \"dakoo\", Hindi: \u0921\u093e\u0915\u0942, meaning \"armed robber\").\nThe term dacoit (Hindi: \u0921\u0915\u0948\u0924 \"\u1e0dakait\") means \"a bandit\" according to the \"OED\" (\"A member of a class of robbers in India and Burma, who plunder in armed bands\").\nHistory.\nBandits of Bhind-Morena of Chambal.\nThe dacoity have had a large impact in the Bhind and Morena of Chambal regions in Madhya Pradesh, Rajasthan, Haryana and Uttar Pradesh in north-central India. The exact reasons for the emergence of dacoity in the Chambal valley have been disputed. Most explanations have suggested feudal exploitation as the cause that provoked many people in this region to take arms. The area was also underdeveloped and poor, so banditry posed great economic incentives. However, the fact that many gangs operating in this valley were composed of higher castes and wealthy people appears to suggest that feudalism may only be a partial explanation of dacoity in Chambal Valley (Bhaduri, 1972; Khan, 1981; Jatar, 1980; Katare, 1972). Furthermore, traditional honour codes and blood feuds would drive some into criminality.\nIn Chambal, India, organized crime controlled much of the countryside from the time of the British Raj up to the early 2000s, with the police offering high rewards for the most notorious bandit chiefs. The criminals regularly targeted local businesses, though they preferred to kidnap wealthy people and demand ransom from their relatives \u2013 cutting off fingers, noses, and ears to pressure them into paying high sums. Many dacoity also posed as social bandits toward the local poor, paying medical bills and funding weddings. One ex-dacoit described his criminal past by claiming that \"I was a rebel. I fought injustice.\" Following intense anti-banditry campaigns by the Indian Police, highway robbery was almost completely eradicated in the early 2000s. Nevertheless, Chambal is still popularly believed to be unsafe and bandit-infested by many Indians. One police officer noted that the fading of dacoity was also due to social changes, as few young people were any longer willing to endure the harsh life of highway robbers in the countryside. Instead, they prefer to join crime groups in the city, where life is easier.\nDacoits in Bengal.\nWhile thugs and dacoits operating in northern and central India are more popularly known and referenced in books, films, and academic journals, a significant number of accounts also come from Bengal. Writing about the dacoits of Bengal, the colonial official CH Keighly mentions the \u201cgreat difference between gangs of hereditary dacoits or thugs in other parts of India and the dacoits of Bengal\u201d. It is notable that, unlike the rest of India, dacoits in Bengal did not come from a particular social class, caste, or creed.\nThe Gangs of Nadia and Hooghly.\nDacoit gangs in Nadia and Hooghly were mainly known for their ceremonial practices before the night of dacoity. Before setting off for their mission, the members would assemble to perform \u201ckalipuja\u201d led by the Sirdar (leader). The dacoits would form a straight line, and a pot of liquor, torches, and weapons to be used in the dacoity would be laid down in a clear space. The Sirdar would then dip his finger in oil and touch the forehead of all the dacoits, making them promise never to confess. Even during the raid, when dacoits opened chests and discovered a good fortune, they would shout \u201cKali, Jai Kali\u201d.\nDacoits of Birbhum.\nDacoity was prevalent in 19th century West Bengal. One of the gangs, led by a charismatic leader named Bhabani Pathak, was known for its loyalty to their leader. After the British captured Bhabani, the inner workings and social factors that led to the construction of this gang were revealed. Leaders such as Bhabani were known as Sirdars and had a symbiotic relationship with their followers. Among other benefits, a Sirdar would lend loans to members and provide them protection. This allowed for the formation of a special bond between Sirdar and his followers, which meant that cases of desertion and exiting the gang were virtually unheard of.\nTales of Burdwan.\nIn Burdwan, dacoities were heavily planned, and considerable thought was put into their seamless execution. Sirdars in Burdwan employed several informants who kept them updated about prospective targets. When a target was finalized, the Sirdar and relevant gang members were constantly made aware of his whereabouts. The informants were always on the lookout for wealthy business people and kept a close watch on those who exchanged bank notes of considerable value or received a shipment of merchandise they would store in their houses.\nOther dacoity.\nThe term is also applied, according to the \"OED\", to \"pirates who formerly infested the Ganges between Calcutta and Burhampore\".\nDacoits existed in Burma as well\u2014Rudyard Kipling's fictional Private Mulvaney hunted Burmese dacoits in \"The Taking of Lungtungpen.\" Sax Rohmer 's criminal mastermind Dr. Fu Manchu also employed Burmese dacoits as his henchmen.\nIndian police forces use \"Known Dacoit\" (K.D.) as a label to classify criminals.\nThuggee and Dacoity Suppression Acts.\nIntroduced in 1836, the Thuggee and Dacoity Suppression Acts brought about several legislative measures, including establishing special courts, authorization for using rewards for informants, and the power to arrest suspects. These acts were primarily intended to counter the activities of the thuggee, groups of criminals who allegedly moved along the highways of India murdering and robbing unaware travellers. According to academic Mark Brown, the prevalence of the thuggee across India during the early 19th century and the East India Company's response to it \"might best be viewed in light of anxieties in both British ruling and Indian subordinate groups produced by the rapid and far-reaching [British] colonial expansion\" across South Asia.\nNotable dacoits.\nNotable dacoits include:\nProtection measures.\nIn Madhya Pradesh, women belonging to a village defence group have been issued firearm permits to fend off dacoity. The Chief minister of the state, Shivraj Singh Chouhan, recognised the role the women had played in defending their villages without guns. He stated that he wanted to enable these women to better defend both themselves and their villages, and issued the gun permits to advance this goal.\nIn popular culture.\nDacoit films.\nAs the dacoits flourished through the 1940s\u20131970s, they were the subject of various Hindi films made during this era, leading to the emergence of the dacoit film genre in Hindi Film Industry. The genre began with Mehboob Khan's \"Aurat\" (1940), which he remade as \"Mother India\" (1957). \"Mother India\" received an Academy Award nomination, and defined the dacoit film genre, along with Dilip Kumar's \"Gunga Jumna\" (1961). Other popular films in this genre included Raj Kapoor\u2019s \"Jis Desh Mein Ganga Behti Hai\" (1961) and Moni Bhattacharjee's \"Mujhe Jeene Do\" (1963).\nPakistani actor Akmal Khan had two dacoit films, \"Malangi\" (1965) and \"Imam Din Gohavia\" (1967). Other films in this genre included \"Khote Sikkay\" (1973), \"Mera Gaon Mera Desh\" (1971), and \"Kuchhe Dhaage\" (1973) both by Raj Khosla.\nThe most famous dacoit film is \"Sholay\" (1975), written by Salim\u2013Javed, and starring Dharmendra, Amitabh Bachchan, and Amjad Khan as the dacoit character Gabbar Singh. It was a masala film that combined the dacoit film conventions of \"Mother India\" and \"Gunga Jumna\" with that of Spaghetti Westerns, spawning the \"Dacoit Western\" genre, also known as the \"Curry Western\" genre. The film also borrowed elements from Akira Kurosawa's \"Seven Samurai\". \"Sholay\" became a classic in the genre, and its success led to a surge of films in this genre, including \"Ganga Ki Saugandh\" (1978), once again starring Amitabh Bachchan and Amjad Khan.\nAn internationally acclaimed example of the genre is \"Bandit Queen\" (1994).\nThe Tamil movie starring Karthi, \"Theeran Adhigaaram Ondru\" (2017) deals elaborately with bandits. The film reveals the real dacoity incidents which held in Tamil Nadu between 1995 and 2005. Director Vinoth did a two-year research about bandits to develop the script.\nA related genre of crime films are Mumbai underworld films.\nOther media.\nBengali novel \"Devi Chowdhurani\" by author Bankim Chandra Chatterjee in 1867.\nBengali poem \"Birpurush\" by Rabindranath Tagore in 1903.\nA Hindi novel named \"Painstth Lakh ki Dacoity\" (1977) was written by Surender Mohan Pathak; it was translated as \"The 65 Lakh Heist\".\nDacoits armed with pistols and swords appear in \"\".\nThey frequently appeared in the French language \"Bob Morane\" series of novels by Henri Vernes, principally as the main thugs or assassins of the hero's recurring villain, Mr. Ming and in English as the agents of Sax Rohmer's Fu Manchu."}
{"id": "9123", "revid": "372290", "url": "https://en.wikipedia.org/wiki?curid=9123", "title": "Davis, California", "text": "Davis is the most populous city in Yolo County, California, United States. Located in the Sacramento Valley region of Northern California, the city had a population of 66,850 in 2020, not including the on-campus population of the University of California, Davis, which was over 9,400 (not including students' families) in 2016. there were 40,850 students enrolled at the university, and is known as the biking capital of America.\nHistory.\nDavis sits on land that was historically inhabited by Indigenous people associated with the Clovis culture. At a later point, the Patwin, a southern branch of Wintun people, displaced existing Indigenous tribes. The Patwin were killed or forced from their lands by the 1830s as part of the California Genocide through a combination of mass murders, smallpox and other diseases, and both Mexican and American systems of Indigenous slavery. Patwin burial grounds have been found across Davis, including on the site of the UC Davis Mondavi Center. After the killing and expulsion of the Patwin, territory that eventually became Davis emerged from one of California's most complicated ranchos, Laguna de Santos Call\u00e9. The 1852 Land Commission concurred with US Attorneys who argued that the grant was \"fraudulent in all its parts,\" and in his 1860 District Court ruling Justice Ogden Hoffman observed that \"It is impossible to contemplate without disgust the series of perjuries which compose the record\" of the land grant. Nevertheless, Jerome C. Davis, a prominent farmer and one of the early claimants to land in Laguna de Santos Call\u00e9, lobbied all the way to the United States Congress in order to retain the land that eventually became Davis. Davis became a depot on the Southern Pacific Railroad in 1868, when it was named Davisville after Jerome C. Davis. The post office at Davisville shortened the town name to \"Davis\" in 1907. The name stuck, and the city of Davis was incorporated on March 28, 1917.\nFrom its inception as a farming community, Davis is known primarily for its contributions to agricultural policy along with veterinary care and animal husbandry. Following the passage of the University Farm Bill in 1905 by the California State Legislature, Governor George Pardee selected Davis out of 50 other sites as the future home to the University of California's University Farm, officially opening to students in 1908. The farm, later renamed the Northern Branch of the College of Agriculture in 1922, was upgraded to become the seventh UC general campus, the University of California, Davis, in 1959.\nGeography and environment.\nLocation.\nDavis is located in Yolo County, California, west of Sacramento, northeast of San Francisco, north of Los Angeles, at the intersection of Interstate 80 and State Route 113. Neighboring towns include Dixon, Winters, Woodland, and West Sacramento.\nDavis lies in the Sacramento Valley, the northern portion of the Central Valley, in Northern California, at an elevation of about above sea level.\nAccording to the United States Census Bureau, the city has a total area of . of it is land and of it, or 0.19%, is water.\nThe topography is flat, which has helped Davis to become known as a haven for bicyclists.\nClimate.\nThe Davis climate resembles that of nearby Sacramento and is typical of California's Central Valley Mediterranean climate region: warm and dry in the spring, summer and autumn, and cool and wet in the winter. It is classified as a K\u00f6ppen \"Csa\" climate. Summer days are hot, ranging from , but the nights turn pleasantly cool, almost always dropping below . The Delta Breeze, a flow of cool marine air originating from the Pacific Ocean via San Francisco Bay and the Sacramento\u2013San Joaquin River Delta, frequently provides relief in the evening. Winter temperatures generally reach between in the afternoon; nights average at about , but occasionally fall below freezing.\nAverage temperatures range from in December and January to in July and August. Thick ground fog called tule fog settles into Davis during late fall and winter. This fog can be dense, with near zero visibility. As in other areas of Northern California, the tule fog is a leading cause of road accidents in the winter season.\nMean rainfall per annum is about . The bulk of the rainfall occurs between about mid-November to mid-March, with typically no precipitation falling from mid-June to mid-September.\nRecord temperatures range from a high of on July 17, 1925, to a low of on December 11, 1932.\nNeighborhoods.\nDavis is internally divided by two freeways (Interstate 80 and State Route 113), a north\u2013south railroad (California Northern), an east\u2013west mainline (Union Pacific) and several major streets. The city is unofficially divided into six main districts made up of smaller neighborhoods (often originally named as housing subdivisions):\nThe University of California, Davis is located south of Russell Boulevard and west of A Street and then south of 1st Street. The land occupied by the university is not incorporated within the boundaries of the city of Davis and lies within both Yolo and Solano Counties.\nEnvironment.\nLocal energy planning began in Davis after the energy crisis of 1973. A new building code promoted energy efficiency. Energy use in buildings decreased dramatically and in 1981 Davis citizens won a $100,000 prize from utility PG&amp;E, for cutting electricity use during the summer peak.\nOn November 14, 1984, the Davis City Council declared the city to be a nuclear-free zone. In 1998, the City passed a \"Dark Skies\" ordinance in an effort to reduce light pollution in the night sky.\nIn 2013, Davis became part of the state Cool Roof Initiative with the \"CoolDavis\" campaign, requiring all new roofing projects to meet Cool Roof Rating Council (CRRC) requirements, including the installation of light-colored roofs. The aim is to reflect more sunlight back into space via the albedo effect, and reduce the amount of heat absorbed in hopes of limiting climate change.\nDemographics.\nDavis is part of the Sacramento metropolitan area.\n2020.\nAccording to the 2020 Census the population of Davis was 66,850 people.\nIn 2020 the racial demographics were as follows:\n53.6% White\n2.3% Black\n13.8% Hispanic or Latino\n23.3% Asian\n1.1% Native American\n9.6% two or more races\n2010.\nThe 2010 United States census reported that Davis had a population of 65,622. The population density was . The racial makeup of Davis was 42,571 (64.9%) White, 1,528 (2.3%) African American, 339 (0.5%) Native American, 14,355 (21.9%) Asian, 136 (0.2%) Pacific Islander, 3,121 (4.8%) from other races, and 3,572 (5.4%) from two or more races. Hispanic or Latino of any race were 8,172 persons (12.5%).\nDavis' Asian population of 14,355 was apportioned among 1,631 Indian Americans, 6,395 Chinese Americans, 1,560 Korean Americans, 1,185 Vietnamese Americans, 1,033 Filipino Americans, 953 Japanese Americans, and 1,598 other Asian Americans.\nDavis' Hispanic and Latino population of 8,172 was apportioned among 5,618 Mexican American, 221 Puerto Rican American, 80 Cuban American, and 2,253 other Hispanic and Latino.\nThe census reported that 63,522 people (96.8% of the population) lived in households, 1,823 (2.8%) lived in non-institutionalized group quarters, and 277 (0.4%) were institutionalized.\nThere were 24,873 households, of which 6,119 (24.6%) had children under the age of 18 living in them, 9,343 (37.6%) were opposite-sex married couples living together, 1,880 (7.6%) had a female householder with no husband present, and 702 (2.8%) had a male householder with no wife present. There were 1,295 (5.2%) unmarried opposite-sex partnerships, and 210 (0.8%) same-sex married couples or partnerships. 5,952 households (23.9%) were made up of individuals, and 1,665 (6.7%) had someone living alone who was 65 years of age or older. The average household size was 2.55. There were 11,925 families (47.9% of all households); the average family size was 2.97.\nThe population age and sex distribution was 10,760 people (16.4%) under the age of 18, 21,757 people (33.2%) aged 18 to 24, 14,823 people (22.6%) aged 25 to 44, 12,685 people (19.3%) aged 45 to 64, and 5,597 people (8.5%) who were 65 years of age or older. The median age was 25.2 years. For every 100 females, there were 90.5 males. For every 100 females age 18 and over, there were 88.0 males.\nThere were 25,869 housing units, with an average density of , of which 10,699 (43.0%) were owner-occupied, and 14,174 (57.0%) were occupied by renters. The homeowner vacancy rate was 0.9%; the rental vacancy rate was 3.5%. 27,594 people (42.0% of the population) lived in owner-occupied housing units and 35,928 people (54.7%) lived in rental housing units.\n2000.\nAs of the 2000 United States census, there were 60,308 people, 22,948 households, and 11,290 families residing in the city. The population density was . There were 23,617 housing units at an average density of . The racial composition of the city was 70.07% White, 2.35% Black or African American, 0.67% Native American, 17.5% Asian, 0.24% Pacific Islander, 4.26% from other races, and 4.87% from two or more races. 9.61% of the population were Hispanic or Latino of any race.\nThere were 22,948 households, of which 26.4% had children under the age of 18 living with them, 38.3% were married couples living together, 8.2% had a female householder with no husband present, and 50.8% were non-families. 25.0% of all households were composed of individuals, and 5.2% had someone living alone who was 65 years of age or older. The average household size was 2.50 and the average family size was 3.00.\nIn the city, the population age distribution was 18.6% under the age of 18, 30.9% from 18 to 24, 27.1% from 25 to 44, 16.7% from 45 to 64, and 6.6% who were 65 years of age or older. The median age was 25 years. For every 100 females, there were 91.2 males. For every 100 females age 18 and over, there were 87.8 males.\nThe median income for a household in the city was $42,454, and the median income for a family was $74,051. Males had a median income of $51,189 versus $36,082 for females. The per capita income for the city was $22,937. About 5.4% of families and 24.5% of the population were below the poverty line, including 6.8% of those under age 18 and 2.8% of those age 65 or over.\nThis city of approximately 62,000 people abuts a university campus of 32,000 students. Although the university's land is not incorporated within the city, many students live off-campus in the city.\nEconomy.\nTop employers.\nAccording to the city's 2020 Comprehensive Annual Financial Report, the top employers in the city are:\nDavis Dollars.\nA community currency scheme was in use in Davis, called \"Davis Dollars\".\nBicycling.\nBicycling has been one of the most popular modes of transportation in Davis for decades, particularly among school-age children and UC Davis students. In 2010, Davis became the new home of the United States Bicycling Hall of Fame.\nBicycle infrastructure became a political issue in the 1960s, culminating in the election of a pro-bicycle majority to the City Council in 1966. By the early 1970s, Davis had become a pioneer in the implementation of cycling facilities. As the city expands, new facilities are usually mandated. As a result, Davis residents today enjoy an extensive network of bike lanes, bike paths, and grade-separated bicycle crossings. The flat terrain and temperate climate are also conducive to bicycling.\nIn 2005, the Bicycle-Friendly Community program of the League of American Bicyclists recognized Davis as the first Platinum Level city in the US Bicycling appears to be declining among Davis residents: from 1990 to 2000, the US Census Bureau reported a decline in the fraction of commuters traveling by bicycle, from 22 percent to 15 percent. This resulted in the reestablishment of the city's Bicycle Advisory Commission and creation of advocate groups such as \"Davis Bicycles!\". In 2016, Fifth Street, a main road in Davis, was converted from four lanes to two lanes to allow for bicycle lanes and encourage more bicycling.\nIn 1996, 2001, 2006, and 2009, the UC Davis \"Cal Aggie Cycling\" Team won the national road cycling competition. The team also competes off-road and on the track, and has competed in the national competitions of these disciplines. In 2007, UC Davis also organized a record-breaking bicycle parade numbering 822 bicycles.\nSights and culture.\nWhole Earth Festival.\nA continuous stream of bands, speakers and various workshops occurs throughout Mother's Day weekend on each of Whole Earth Festival's (WEF) three stages and other specialty areas. The WEF is organized entirely by UC Davis students, in association with the Associated Students of UC Davis and the university.\nCelebrate Davis.\nCelebrate Davis is the annual free festival held by the Davis Chamber of Commerce. It features booths by Davis businesses, live music, food vendors, live animals, activities like rock climbing and zip-lining. It concludes with fireworks after dark. Parking is problematic, so most people ride their bikes and use the free valet parking.\nPicnic Day.\nPicnic Day is an annual event at the University of California, Davis and is always held on the third Saturday in April. It is the largest student-run event in the US. Picnic Day starts off with a parade, which features the UC Davis California Aggie Marching Band-uh!, and runs through campus and around downtown Davis and ends with the Battle of the Bands, which lasts until the last band stops playing (sometimes until 2\u00a0am). There are over 150 free events and over 50,000 attend every year. Other highlights include: the Dachshund races, a.k.a. the Doxie Derby, held in the Pavilion; the Davis Rock Challenge, the Chemistry Magic Show, and the sheep dog trials. Many departments have exhibits and demonstrations, such as the Cole Facility, which until recently showed a fistulated cow (a cow that has been fitted with a plastic portal (a \"fistula\") into its digestive system to observe digestion processes). Its name was \"Hole-y Cow\".\nDavis Transmedia Art Walk.\nThe Davis Transmedia Art Walk is a free\u2014self-guided\u2014public art tour includes 23 public murals, 16 sculptures, and 15 galleries and museums all in downtown Davis and the University of Davis campus. A free Davis Art Walk map serves as a detailed guide to the entire collection. The art pieces are all within walking distance of each other. The walk is a roughly circuitous path that can be completed within an hour or two. Every piece of art on the Art Walk has been embedded with an RFID chip. Using a cellphone that supports this technology, you access multimedia files that relate to each work. You can even leave a comment or \"burn your own message\" for other visitors to see. Artist hosted tours are held on the weekend by appointment only. To pick up a copy of the Davis Art Walk map, visit the Yolo County Visitors Bureau (132 E St., Suite 200; (530) 297\u20131900) or the John Natsoulas Center for the Arts (521 1st St.; (530) 756\u20133938).\nManetti Shrem Museum of Art.\nThe Manetti Shrem Museum of Art, located on the UC Davis campus, opened on November 13, 2016, and carries on the legacy of the university's world-renowned first generation art faculty, which contributed to innovations in conceptual, performance and video art in the 1960s and 70s. The museum has generated nationwide attention with exhibits by artists such as Wayne Thiebaud, Bruce Nauman, John Cage, and Robert Arneson as well as its striking architecture, featuring a 50,000 square-foot \u201cGrand Canopy\u201d of perforated aluminum triangular beams, supported by 40 steel columns. Every year the museum exhibits works by graduating art students. The museum is free and hosts lecture series and events throughout the year, as well as weekend art studio activities for all ages.\nMondavi Center.\nThe Mondavi Center, located on the UC Davis campus, is one of the biggest non-seasonal attractions in Davis. The Mondavi Center is a theater which hosts many world-class touring acts, including star performers such as Yo-Yo Ma, Yitzhak Perlman and Wynton Marsalis, and draws a large audience from Sacramento.\nUC Davis Arboretum.\nThe UC Davis Arboretum is an arboretum and botanical garden. Plants from all over the world grow in different sections of the park. There are notable oak and native plant collections and a small redwood grove. A small waterway spans the arboretum along the bed of the old North Fork of Putah Creek. Occasionally herons, kingfishers, and cormorants can be seen around the waterways, as well as the ever-present ducks. Tours of the arboretum led by volunteer naturalists are often held for grade-school children.\nThe Domes.\nThe Domes (AKA Baggins End Innovative Housing) is an on-campus cooperative housing community designed by project manager Ron Swenson and future student-residents in 1972. Consisting of 14 polyurethane foam-insulated fiberglass domes and located in the Sustainable Research Area at the western end of Orchard Road, it is governed by its 26 UCD student residents. It is one of the few student co-housing cooperative communities in the US, and is an early example of the modern-day growing tiny house movement. The community has successfully resisted several threats to its continuation over the years.\nFarmers Market.\nThe Davis Farmers Market is held every Wednesday evening and Saturday morning. Participants sell a range of fruits and vegetables, baked goods, dairy and meat products (often from certified organic farms), crafts, and plants and flowers. From April to October, the market hosts \"Picnic in the Park\", with musical events and food sold from restaurant stands.\nMedia.\nDavis has one newspaper, \"The Davis Enterprise\", a thrice-weekly newspaper founded in 1897. UC Davis also has a weekly newspaper called \"The California Aggie\" that covers campus, local and national news. Davis Media Access, a community media center, is the umbrella organization of television station DCTV. There are also numerous commercial stations broadcasting from nearby Sacramento. Davis has two community radio stations: KDVS 90.3 FM, on the University of California campus, and KDRT 95.7 FM, a subsidiary of Davis Media Access and one of the first low-power FM radio stations in the United States. Davis has the world's largest English-language local wiki, DavisWiki. In 2006, \"The People's Vanguard of Davis\" began news reporting about the city of Davis, the Davis Joint Unified School District, the county of Yolo, and the Sacramento area.\nToad Tunnel.\nDavis' Toad Tunnel is a wildlife crossing that was constructed in 1995 and has drawn much attention over the years, including a mention on \"The Daily Show\". Due to the construction of an overpass, animal lovers worried about toads being killed by cars commuting from South Davis to North Davis, since the toads traveled from one side of a dirt lot (which the overpass replaced) to the reservoir at the other end. After much controversy, a decision was made to build a toad tunnel, which runs beneath the Pole Line Road overpass which crosses Interstate 80. The project cost $14,000, . The tunnel is wide and high.\nEducation.\nUniversity of California.\nThe University of California, Davis, or UC Davis, a campus of the University of California, had a 2019 Fall enrollment of 38,369 students. UC Davis has a dominant influence on the social and cultural life of the town.\nOther colleges.\nAn off-campus branch of Sacramento City College is located in Davis. The satellite is located in West Village, an area built by UC Davis to house students and others affiliated with the university.\nPublic schools.\nDavis' public school system is administrated by the Davis Joint Unified School District.\nThe city has nine public elementary schools (North Davis, Birch Lane, Pioneer Elementary, Patwin, Cesar Chavez, Robert E. Willett, Marguerite Montgomery, Fred T. Korematsu at Mace Ranch, and Fairfield Elementary (which is outside the city limits but opened in 1866 and is Davis Joint Unified School District's oldest public school)). Davis has one school for independent study (Davis School for Independent Study), four public junior high schools (Ralph Waldo Emerson, Oliver Wendell Holmes, Frances Harper, and Leonardo da Vinci Junior High), one main high school (Davis Senior High School), one alternative high school (Martin Luther King High School), and a small project based high school (Leonardo da Vinci High School). Cesar Chavez is a Spanish immersion school, with no English integration until the third grade. The junior high schools contain grades 7 through 9. Due to a decline in the school-age population in Davis, two of the elementary schools in south Davis may have their district boundaries changed, or magnet programs may be moved to equalize enrollment. Valley Oak was closed after the 2007\u201308 school year, and their campus was granted to Da Vinci High (which had formerly been located in the back of Davis Senior High's campus) and a special-ed preschool. On average, class size is about 25 students for every teacher.\nAt one time, Chavez and Willett were incorporated together to provide elementary education K\u20136 to both English-speaking and Spanish immersion students in West Davis. C\u00e9sar Ch\u00e1vez served grades K\u20133 and was called West Davis Elementary, and Robert E. Willett (named for a long-time teacher at the school, now deceased) served grades 4\u20136 and was known as West Davis Intermediate. Willett now serves K\u20136 English-speaking students, and Chavez supports the Spanish immersion program for K\u20136.\nNotable people.\nThese are some notable Davis residents, other than UC Davis faculty who were not previously from Davis.\nSister cities.\nDavis' sister cities are:"}
{"id": "9124", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9124", "title": "Descending chain condition", "text": ""}
{"id": "9125", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9125", "title": "Descending Chain Condition", "text": ""}
{"id": "9127", "revid": "1117839213", "url": "https://en.wikipedia.org/wiki?curid=9127", "title": "Double boiler", "text": ""}
{"id": "9128", "revid": "24361832", "url": "https://en.wikipedia.org/wiki?curid=9128", "title": "Damon Runyon", "text": "Alfred Damon Runyon (October 4, 1880 \u2013 December 10, 1946) was an American journalist and short-story writer.\nHe was best known for his short stories celebrating the world of Broadway in New York City that grew out of the Prohibition era. To New Yorkers of his generation, a \"Damon Runyon character\" evoked a distinctive social type from Brooklyn or Midtown Manhattan. The adjective \"Runyonesque\" refers to this type of character and the type of situations and dialog that Runyon depicts. He spun humorous and sentimental tales of gamblers, hustlers, actors, and gangsters, few of whom go by \"square\" names, preferring instead colorful monikers such as \"Nathan Detroit\", \"Benny Southstreet\", \"Big Jule\", \"Harry the Horse\", \"Good Time Charley\", \"Dave the Dude\", or \"The Seldom Seen Kid\".\nHis distinctive vernacular style is known as \"Runyonese\": a mixture of formal speech and colorful slang, almost always in the present tense, and always devoid of contractions. He is credited with coining the phrase \"Hooray Henry\", a term now used in British English to describe the upper-class version of a loud-mouthed, arrogant twit.\nRunyon's fictional world is also known to the general public through the musical \"Guys and Dolls\" based on two of his stories, \"The Idyll of Miss Sarah Brown\" and \"Blood Pressure\". The musical additionally borrows characters and story elements from a few other Runyon stories, most notably \"Pick The Winner\". The film \"Little Miss Marker\" (and its three remakes, \"Sorrowful Jones\", \"40 Pounds of Trouble\" and the 1980 \"Little Miss Marker\") grew from his short story of the same name.\nRunyon was also a newspaper reporter, covering sports and general news for decades for various publications and syndicates owned by William Randolph Hearst. Already known for his fiction, he wrote a noted \"present tense\" article on Franklin Delano Roosevelt's Presidential inauguration in 1933 for the Universal Service, a Hearst syndicate, which was merged with the co-owned International News Service in 1937.\nEarly life.\nDamon Runyon was born Alfred Damon Runyan to Alfred Lee and Elizabeth (Damon) Runyan. His relatives in his birthplace of Manhattan, Kansas, included several newspapermen. His grandfather was a newspaper printer from New Jersey who had relocated to Manhattan, Kansas, in 1855, and his father was the editor of his newspaper in the town. In 1882 Runyon's father was forced to sell his newspaper, and the family moved westward. The family eventually settled in Pueblo, Colorado, in 1887, where Runyon spent the rest of his youth. By most accounts, he attended school only through the fourth grade. He began to work in the newspaper trade under his father in Pueblo. In present-day Pueblo, Runyon Field, the Damon Runyon Repertory Theater Company, and Runyon Lake are named in his honor.\nEnlistment in the military.\nIn 1898, when still in his teens, Runyon enlisted in the US Army to fight in the Spanish\u2013American War. While in the service, he was assigned to write for the \"Manila Freedom\" and \"Soldier's Letter\".\nNewspaper reporter.\nAfter military service, he worked for Colorado newspapers, beginning in Pueblo. His first job as a reporter was in September 1900, when he was hired by the \"Pueblo Star\"; he then worked in the Rocky Mountain area during the first decade of the 1900s: at the \"Denver Daily News\", he served as \"sporting editor\" (today a \"sports editor\") and then as a staff writer. His expertise was in covering the semi-professional teams in Colorado. He briefly managed a semi-pro team in Trinidad, Colorado. At one of the newspapers where he worked, the spelling of his last name was changed from \"Runyan\" to \"Runyon\", a change he let stand.\nAfter failing in an attempt to organize a Colorado minor baseball league, which lasted less than a week, Runyon moved to New York City in 1910. In his first New York byline, the \"American\" editor dropped the \"Alfred\" and the name \"Damon Runyon\" appeared for the first time. For the next ten years, he covered the New York Giants and professional boxing for the \"New York American\".\nHe was the Hearst newspapers' baseball columnist for many years, beginning in 1911, and his knack for spotting the eccentric and the unusual, on the field or in the stands, is credited with revolutionizing the way baseball was covered. Perhaps as confirmation, Runyon was voted 1967 J. G. Taylor Spink Award by the Baseball Writers' Association of America (BBWAA), for which he was honored at ceremonies at the National Baseball Hall of Fame in July 1968. He is also a member of the International Boxing Hall Of Fame and is known for dubbing heavyweight champion James J. Braddock the \"Cinderella Man\". Runyon frequently contributed sports poems to the \"American\" on boxing and baseball themes and wrote numerous short stories and essays. \nGambling.\nGambling, particularly on craps or horse races, was a common theme of Runyon's works, and he was a notorious gambler. One of his paraphrases from a line in Ecclesiastes ran: \"The race is not always to the swift, nor the battle to the strong, but that's how the smart money bets.\"\nA heavy drinker as a young man, he seems to have quit drinking soon after arriving in New York, after his drinking nearly cost him the courtship of the woman who became his first wife, Ellen Egan. He remained a heavy smoker.\nHis best friend was mobster accountant Otto Berman, and he incorporated Berman into several of his stories under the alias \"Regret, the horse player\". When Berman was killed in a hit on Berman's boss, Dutch Schultz, Runyon quickly assumed the role of damage control for his deceased friend, mostly by correcting erroneous press releases, including one that stated Berman was one of Schultz's gunmen, to which Runyon replied, \"Otto would have been as effective a bodyguard as a two-year-old.\"\nPersonal life.\nWhile in New York City, Runyon courted and eventually married Ellen Egan. Their marriage produced two children, Mary and Damon Jr. A modern writer remarks that \"by contemporary standards, Runyon was a marginal husband and father.\" In 1928, Egan separated from Runyon permanently and moved to Bronxville with their children after hearing persistent rumors about her husband's infidelities. As it became subsequently known, Runyon, in 1916, was covering the border raids of Mexican bandit Pancho Villa as a reporter for the \"American\" newspaper owned by William Randolph Hearst. He had first met Villa in Texas while covering spring training of the state's teams. While in Mexico, Runyon visited one afternoon the Ciudad Ju\u00e1rez racetrack where Villa was present and placed a bet through a young messenger girl in Villa's entourage. The 14-year-old girl, whose name was Patrice Amati del Grande, erroneously placed Runyon's bet on a different horse that nonetheless won the race. She confided to the lucky bettor that she wanted to be a dancer when she grew up and Runyon told her that if, instead, she would attend school, for which he would pay, she could come after her graduation to see him in New York and he would get her a dancing job in the city; Runyon did indeed pay for her enrollment in the local convent school.\nIn 1925, 19-year-old Grande came to New York City looking for Runyon and found him through the \"American\"s receptionist. The two became lovers and he found her work at local speakeasies. In 1928, after the separation between Runyon and Ellen Egan turned into a divorce, Runyon and Grande were married by his friend, city mayor Jimmy Walker. His former wife became an alcoholic and died in 1931 from a heart attack. In 1946, some time after Grande began an affair with a younger man, the couple got divorced.\nDeath.\nIn late 1946, the same year he and his second wife were divorced, Runyon died, at age 66, in New York City from the throat cancer that had been diagnosed two years earlier, in 1944, when he underwent an unsuccessful operation that left him practically unable to speak. \nHis body was cremated, and his ashes were scattered from a DC-3 airplane over Broadway in Manhattan by Eddie Rickenbacker on December 18, 1946. This was an infringement of the law but widely approved. The family plot of Damon Runyon is located at Woodlawn Cemetery in The Bronx, New York.\nRunyon, in his will, left to his former second wife his house in Florida, his racing stables, and the money from his insurance. He split in half the royalties from his works to his children and Grande. His daughter Mary was eventually institutionalized for alcoholism while his son Damon Jr., after working as a journalist in Washington, D.C., died by suicide in 1968.\nLiterary style \u2013 the \"Broadway\" stories.\nThe English comedy writer Frank Muir comments that Runyon's plots were, in the manner of O. Henry, neatly constructed with professionally wrought endings, but their distinction lay in the manner of their telling, as the author invented a peculiar argot for his characters to speak. Runyon almost totally avoids the past tense (English humorist E. C. Bentley thought there was only one instance and was willing to \"lay plenty of 6 to 5 that it is nothing but a misprint\"), and makes little use of the future tense, using the present for both. He also avoided the conditional, using instead the future indicative in situations that would normally require conditional. An example: \"Now most any doll on Broadway will be very glad indeed to have Handsome Jack Madigan give her a tumble\" (\"Guys and Dolls\", \"Social error\"). Bentley comments that \"there is a sort of ungrammatical purity about it [Runyon's resolute avoidance of the past tense], an almost religious exactitude.\" There is an homage to Runyon that makes use of this peculiarity (\"Chronic Offender\" by Spider Robinson), which involves a time machine and a man going by the name \"Harry the Horse\".\nHe uses many slang terms (which go unexplained in his stories), such as:\nThere are many recurring composite phrases such as:\nBentley notes that Runyon's \"telling use of the recurrent phrase and fixed epithet\" demonstrates a debt to Homer.\nRunyon's stories also employ occasional rhyming slang, similar to the cockney variety but native to New York (e.g.: \"Miss Missouri Martin makes the following crack one night to her: 'Well, I do not see any Simple Simon on your lean and linger.' This is Miss Missouri Martin's way of saying she sees no diamond on Miss Billy Perry's finger.\" (from \"Romance in the Roaring Forties\")).\nThe comic effect of his style results partly from the juxtaposition of broad slang with mock pomposity. Women, when not \"dolls\", \"Judies\", \"pancakes\", \"tomatoes\", or \"broads\", may be \"characters of a female nature\", for example. He typically avoided contractions such as \"don't\" in the example above, which also contributes significantly to the humorously pompous effect. In one sequence, a gangster tells another character to do as he is told, or else \"find another world in which to live\".\nIn a contemporary introduction to \"The Damon Runyon Omnibus\", the journalist Heywood Broun says that Runyon's prose style is based on a real dialect spoken in 1930s New York City: \"He has caught with a high degree of insight the actual tone and phrase of the gangsters and racketeers of the town. Their talk is put down almost literally... Runyon has exercised the privilege of selectivity. But he has not heightened or burlesqued the speech of the people who come alive in his short stories.\"\nRunyon's short stories are told in the first person by a protagonist who is never named and whose role is unclear; he knows many gangsters and does not appear to have a job, but he does not admit to any criminal involvement, and seems to be largely a bystander. He describes himself as \"being known to one and all as a guy who is just around\". The radio program \"The Damon Runyon Theatre\" dramatized 52 of Runyon's works in 1949, and for these the protagonist was given the name \"Broadway\", although it was admitted that this was not his real name, much in the way \"Harry the Horse\" and \"Sorrowful Jones\" are aliases.\nLiterary works.\nStories.\nThere are many collections of Runyon's stories, in particular \"Runyon on Broadway\" and \"Runyon from First to Last\". A publisher's note in the latter claims that collection contains all of Runyon's short stories not included in \"Runyon on Broadway\", but two Broadway stories originally published in \"Collier's Weekly\" are not in either collection: \"Maybe a Queen\" and \"Leopard's Spots\", both collected in \"More Guys And Dolls\" (1950). The radio show, in addition, has a story, \"Joe Terrace\", that appears in 'More Guys and Dolls' and the August 29, 1936, issue of \"Colliers\". It is one of his \"Our Town\" stories that does not appear in the \"In Our Town\" book, and the only episode of the show which is not a Broadway' story, however, the action is changed in the show from Our Town to Broadway.\nThe \"Our Town\" stories are short vignettes of life in a small town, largely based on Runyon's experiences. They are written in a simple, descriptive style and contain twists and odd endings based on the personalities of the people involved. Each story's title is the name of the principal character. Twenty-seven of them were published in the 1946 book \"In Our Town\".\n\"Runyon on Broadway\" contains the following stories:\nMore Than Somewhat\nFurthermore\nTake It Easy\n\"Runyon from First to Last\" includes the following stories and sketches:\nThe First Stories (early non-Broadway stories):\nStories \u00e0 la Carte (Broadway stories written in Runyonese):\nThe Last Stories (Broadway stories written in Runyonese):\nWritten in Sickness (sketches):\n\"In Our Town\" contains the following stories:\nThe following \"Our Town\" stories were not included in \"In Our Town\":\nFilm.\nTwenty of his stories became motion pictures.\nIn 1938, his unproduced play \"Saratoga Chips\" became the basis of The Ritz Brothers film \"Straight, Place and Show\".\nRadio.\n\"The Damon Runyon Theater\" radio series dramatized 52 of Runyon's short stories in weekly broadcasts running from October 1948 to September 1949 (with reruns until 1951). The series was produced by Alan Ladd's Mayfair Transcription Company for syndication to local radio stations. John Brown played the character \"Broadway\", who doubled as host and narrator. The cast also comprised Alan Reed, Luis Van Rooten, Joseph Du Val, Gerald Mohr, Frank Lovejoy, Herb Vigran, Sheldon Leonard, William Conrad, Jeff Chandler, Lionel Stander, Sidney Miller, Olive Deering and Joe De Santis. Pat O'Brien was initially engaged for the role of \"Broadway\". The original stories were adapted for the radio by Russell Hughes.\n\"Broadway's New York had a crisis each week, though the streets had a rose-tinged aura\", wrote radio historian John Dunning. \"The sad shows then were all the sadder; plays like \"For a Pal\" had a special poignance. The bulk of Runyon's work had been untapped by radio, and the well was deep.\"\nTelevision.\n\"Damon Runyon Theatre\" aired on CBS-TV from 1955 to 1956.\nMike McShane told Runyon stories as monologues on British TV in 1994, and an accompanying book was released, both titled \"Broadway Stories\".\n\"Three Wise Guys\" was a 2005 TV movie."}
{"id": "9129", "revid": "36986459", "url": "https://en.wikipedia.org/wiki?curid=9129", "title": "Don Tennant", "text": "Donald G. Tennant (November 23, 1922 \u2013 December 8, 2001) was an American advertising agency executive.\nHe worked at the Leo Burnett agency in Chicago, Illinois. The agency placed anthropomorphic faces of 'critters' on packaged goods. Tennant was in charge of the Marlboro account and invented the Marlboro Man."}
{"id": "9130", "revid": "27640924", "url": "https://en.wikipedia.org/wiki?curid=9130", "title": "Devo", "text": "Devo is an American new wave band from Akron, Ohio, formed in 1973. Their classic line-up consisted of two sets of brothers, the Mothersbaughs (Mark and Bob) and the Casales (Gerald and Bob), along with Alan Myers. The band had a No. 14 \"Billboard\" chart hit in 1980 with the single \"Whip It\", the song that gave the band mainstream popularity.\nDevo's music and visual presentation (including stage shows and costumes) mingle kitsch science fiction themes, deadpan surrealist humor and mordantly satirical social commentary. The band's namesake, the tongue-in-cheek social theory of \"de-evolution\", was an integral concept in their early work, which was marked by experimental and dissonant art punk that merged rock music with electronics. Their output in the 1980s embraced synth-pop and a more mainstream, less conceptual style, though the band's satirical and quirky humor remained intact. Their music has proven influential on subsequent movements, particularly on new wave, industrial, and alternative rock artists. Devo (most enthusiastically Gerald Casale) was also a pioneer of the music video format.\nHistory.\n1973\u20131978: Formation.\nThe name \"Devo\" comes from the concept of \"de-evolution\" and the band's related idea that instead of continuing to evolve, mankind had begun to regress, as evidenced by the dysfunction and herd mentality of American society. In the late 1960s, this idea was developed as a joke by Kent State University art students Gerald Casale and Bob Lewis, who created a number of satirical art pieces in a devolution vein. At this time, Casale had also performed with the local band 15-60-75 (The Numbers Band). They met Mark Mothersbaugh around 1970, a talented keyboardist who had been playing with the band Flossy Bobbitt. Mothersbaugh brought a more humorous feel to the band, introducing them to material like the pamphlet \"Jocko Homo Heavenbound\", which includes an illustration of a winged devil labelled \"D-EVOLUTION\" and would later inspire the song \"Jocko Homo\". The \"joke\" about de-evolution became serious following the Kent State massacre of May 4, 1970. This event would be cited multiple times as the impetus for forming the band Devo. Throughout the band's career, they have often been considered a \"joke band\" by the music press.\nThe first form of Devo was the \"Sextet Devo\" which performed at the 1973 Kent State performing arts festival. It included Casale, Lewis and Mothersbaugh, as well as Gerald's brother Bob Casale on guitar, and friends Rod Reisman and Fred Weber on drums and vocals, respectively. This performance was filmed and an excerpt was later included on the home video release \"The Complete Truth About De-Evolution\". This lineup performed only once. Devo returned to perform in the Student Governance Center (featured prominently in the film) at the 1974 Creative Arts Festival with a lineup including the Casale brothers, Bob Lewis, Mark Mothersbaugh, and Jim Mothersbaugh on drums.\nThe band continued to perform, generally as a quartet, but with a fluid lineup including Mark's brothers Bob Mothersbaugh and Jim Mothersbaugh. Bob played electric guitar, and Jim provided percussion using a set of home-made electronic drums. Their first two music videos, \"Secret Agent Man\" and \"Jocko Homo\", which both appeared in \"The Truth About De-Evolution\", were filmed in Akron, and Cuyahoga Falls, Ohio, the hometown of most members. This lineup of Devo lasted until late 1975 when Jim left the band. Lewis would sometimes play guitar during this period, but mainly stayed in a managerial role. In concert, Devo would often perform in the guise of theatrical characters, such as Booji Boy and the Chinaman. A recording of an early Devo performance from 1975 with the quartet lineup appears on \"\" (1992), ending with the promoters unplugging Devo's equipment.\nFollowing Jim Mothersbaugh's departure, Bob Mothersbaugh found a new drummer, Alan Myers, who played on a conventional, acoustic drum kit. Casale re-recruited his brother Bob Casale, and the lineup of Devo remained the same for nearly ten years.\nDevo gained some fame in 1976 when their short film \"The Truth About De-Evolution\", directed by Chuck Statler, won a prize at the Ann Arbor Film Festival. This attracted the attention of David Bowie, who began work to get the band a recording contract with Warner Music Group. In 1977, Devo were asked by Neil Young to participate in the making of his film \"Human Highway\". Released in 1982, the film featured the band as \"nuclear garbagemen\". The band members were asked to write their own parts and Mark Mothersbaugh scored and recorded much of the soundtrack, his first of many.\nIn March 1977, Devo released their first single, \"Mongoloid\" backed with \"Jocko Homo\", the B-side of which came from the soundtrack to \"The Truth About De-Evolution\", on their independent label Booji Boy. This was followed by a cover of the Rolling Stones' \"(I Can't Get No) Satisfaction\".\nIn 1978, the \"B Stiff\" EP was released by British independent label Stiff, which included the single \"Be Stiff\" plus two previous Booji Boy releases. \"Mechanical Man\", a 4-track 7-inch extended play (EP) of demos, an apparent bootleg, but actually put out by the band, was also released that year.\n1978\u20131980: Recording contract, \"Q: Are We Not Men? A: We Are Devo!\", and \"Duty Now for the Future\".\nRecommendations from David Bowie and Iggy Pop enabled Devo to secure a recording contract with Warner Bros. in 1978. After Bowie backed out of the business deal due to previous commitments, their first album, \"Q: Are We Not Men? A: We Are Devo!\", was produced by Brian Eno and featured rerecordings of their previous singles \"Mongoloid\" and \"(I Can't Get No) Satisfaction\". On October 14, 1978, Devo gained national exposure with an appearance on the late-night show \"Saturday Night Live\", a week after the Rolling Stones, performing \"(I Can't Get No) Satisfaction\" and \"Jocko Homo\".\nThe band followed up with \"Duty Now for the Future\" in 1979, which moved the band more towards electronic instrumentation. While not as successful as their first album, it did produce some fan favorites with the songs \"Blockhead\" and \"The Day My Baby Gave Me a Surprize\" , as well as a cover of the Johnny Rivers hit \"Secret Agent Man\". \"Secret Agent Man\" had been recorded first in 1974 for Devo's first film and performed live as early as 1976. In 1979, Devo traveled to Japan for the first time, and a live show from this tour was partially recorded. Devo appeared on \"Don Kirshner's Rock Concert\" in 1979, performing \"Blockhead\", \"Secret Agent Man\", \"Uncontrollable Urge\", and \"Mongoloid\". Also in 1979, Rhino, in conjunction with the Los Angeles radio station KROQ-FM, released \"Devotees\", a tribute album. It contained a set of covers of Devo songs interspersed with renditions of popular songs in Devo's style.\nDevo actively embraced the parody religion Church of the SubGenius. In concert, Devo sometimes performed as their own opening act, pretending to be a Christian soft rock band called \"Dove (the Band of Love)\", which is an anagram of \"Devo\". They appeared as Dove in the 1980 televangelism spoof film \"Pray TV\".\n1980\u20131982: Mainstream breakthrough, \"Freedom of Choice\", and \"New Traditionalists\".\nDevo gained a new level of visibility with 1980's \"Freedom of Choice\". This album included their best-known hit, \"Whip It\", which quickly became a Top 40 hit. The album moved to an almost completely electronic sound, with the exception of acoustic drums and Bob Mothersbaugh's guitar. The tour for \"Freedom of Choice\" was ambitious for the band, including dates in Japan, the United Kingdom, France, Germany, Italy, the Netherlands, and Canada. The band used a minimalist set including large custom light boxes which could be laid on their back to form a second, smaller stage during the second half of the set. Other popular songs from \"Freedom of Choice\" were \"Girl U Want\", the title-track, and \"Gates of Steel\". The band released popular music videos for \"Whip It\" and \"Girl U Want\". Devo made three appearances on the TV show \"Fridays\" in 1980 and 1981, as well as on \"Don Kirshner's Rock Concert\", \"American Bandstand\", and other shows. The band members often wore red, terraced energy dome hats as part of its stage outfit. The dome was first worn during the band's \"Freedom of Choice\" campaign of 1980. It reappeared in the 1981, 1982, and 1988 tours, as well as in most of their performances since 1997. Devo also recorded two albums of their own songs as elevator music for their fan club, Club Devo, released on cassette in 1981 and 1984. These were later re-released on the album \"E-Z Listening Disc\" (1987), with all but two of the original Club Devo songs. These songs were often played as house music before Devo concerts.\nIn August 1981, the band's \"DEV-O Live\" EP spent three weeks at the top of the Australian charts. In 1982, they toured Australia and appeared on the TV show \"Countdown\". Devo enjoyed continued popularity in Australia, where the nationally broadcast 1970s\u20131980s pop TV show \"Countdown\" was one of the first programs in the world to broadcast their video clips. They were given consistent radio support by Sydney-based non-commercial rock station Double Jay (2JJ) and Brisbane-based independent community station Triple Zed (4ZZZ), two of the first rock stations outside America to play their recordings. The late-night music program \"Nightmoves\" aired \"The Truth About De-Evolution\".\nIn 1981, Devo contributed a cover of \"Working in the Coal Mine\", recorded during the \"Freedom of Choice\" sessions, to the film \"Heavy Metal\". They offered the song to be used in the film when Warner Bros. refused to include it on the album. Warner then included it as an independent bonus single accompanying their 1981 release, \"New Traditionalists\". For this album Devo wore self-described \"Utopian Boy Scout uniforms\" topped with a \"New Traditionalist Pomp\"\u2014a plastic half-wig modeled on the hairstyle of John F. Kennedy. Among the singles from the album was \"Through Being Cool\", written as a reaction to their new-found fame from \"Whip It\" and seen as a response to new fans who had misinterpreted the message behind the hit song. The album's accompanying tour featured the band performing an intensely physical show with treadmills and a large Greek temple set. That same year they served as Toni Basil's backing band on \"Word of Mouth\", her debut album, which included versions of three Devo songs, recorded with Basil singing lead.\n1982\u20131987: \"Oh, No! It's Devo\", \"Shout\", and Myers' departure.\n\"Oh, No! It's Devo\" followed in 1982. Produced by Roy Thomas Baker, the album featured a more synth-pop-oriented sound than its predecessors. According to Gerald Casale, the album's sound was inspired by reviewers alternately describing them as both \"fascists\" and \"clowns\". The album's tour featured the band performing seven songs in front of a 12-foot high rear-projection screen with synchronized video, an image recreated using blue screen effects in the album's accompanying music videos. Devo also contributed two songs, \"Theme from Doctor Detroit\" and \"Luv-Luv\", to the 1983 Dan Aykroyd film \"Doctor Detroit\", and produced a music video for \"Theme from Doctor Detroit\" featuring clips from the film interspersed with live-action segments.\nThe band's sixth studio album, \"Shout\" (1984), which featured extensive use of the Fairlight CMI digital sampling synthesizer, was received poorly, and the expensive music video they'd produced for their cover of the Jimi Hendrix Experience's \"Are You Experienced?\" was criticized by some as being \"disrespectful\", all of which caused Warner Bros. to buy out the remainder of Devo's contract. Shortly thereafter, Myers left the band, citing creative unfulfillment.\nIn the interim, Mark Mothersbaugh began composing music for the TV show \"Pee-wee's Playhouse\" and released an elaborately packaged solo cassette, \"Musik for Insomniaks\", which was later expanded and released as two CDs in 1988.\n1987\u20131991: \"Total Devo\", \"Smooth Noodle Maps\", and breakup.\nIn 1987, Devo re-formed with former Sparks drummer David Kendrick to replace Myers. Their first project was a soundtrack for the horror film \"Slaughterhouse Rock\" (1988), starring Toni Basil. The band released the album \"Total Devo\" in 1988, on Enigma Records. This album included two songs used in the \"Slaughterhouse Rock\" soundtrack. The song \"Baby Doll\" was used that same year in the comedy film \"Tapeheads\", with newly recorded Swedish lyrics, and was credited to (and shown in a music video by) a fictitious Swedish band called Cube-Squared. Devo followed this up with a world tour, and released the live album \"\" in 1989. However, \"Total Devo\" was not a commercial success and received poor critical reviews.\nIn 1989, members of Devo were involved in the project Visiting Kids, releasing a self-titled EP on the New Rose label in 1990. The band featured Mark's then-wife Nancye Ferguson, as well as David Kendrick, Bob Mothersbaugh, and Bob's daughter Alex Mothersbaugh. Their record was produced by Bob Casale and Mark Mothersbaugh, and Mark also co-wrote some of the songs. Visiting Kids appeared on the soundtrack to the film \"Rockula\", as well as on \"Late Night with David Letterman\". A promotional video was filmed for the song \"Trilobites\".\nIn 1990, \"Smooth Noodle Maps\", Devo's last album for twenty years, was released. It too was a critical and commercial failure which, along with its two singles \"Stuck in a Loop\" and \"Post Post-Modern Man\", were Devo's worst-selling efforts; all failed to appear on the U.S. charts. Devo launched a concert tour in support of the album, but poor ticket sales and the bankruptcy and dissolution of Enigma Records, which was responsible for organizing and financing the tour, caused it to be cancelled part way through.\nIn 1990, the members of Devo, bar Bob Mothersbaugh, appeared in the film \"The Spirit of '76\". Two albums of demo recordings from 1974 to 1977, namely ' (1990) and ' (1991), were released on Rykodisc, as well as an album of early live recordings, \"Devo Live: The Mongoloid Years\" (1992).\nThe band played one final show in March 1991 before breaking up. In an interview with Mark Mothersbaugh concerning their 1996 computer game \"Devo Presents Adventures of the Smart Patrol\", he explained, \"Around '88, '89, '90 maybe, we did our last tour in Europe, and it was kind of at that point, We were watching \"This Is Spinal Tap\" on the bus and said, 'Oh my God, that's our life.' And we just said, 'Things have to change.' So we kind of agreed from there that we wouldn't do live shows anymore.\"\n1991\u20131996: Hiatus.\nFollowing the split, Mark Mothersbaugh established Mutato Muzika, a commercial music production studio, along with Bob Mothersbaugh and Bob Casale. Mothersbaugh meant to further a career as a composer, and the latter worked as an audio engineer. Mothersbaugh has had considerable success writing and producing music for television programs, including \"Pee-wee's Playhouse\" and \"Rugrats\", video games, cartoons, and films, where he worked alongside director Wes Anderson. David Kendrick also worked at Mutato for a period during the early 1990s. Gerald Casale began a career as a director of music videos and commercials, working with bands including Rush, Soundgarden, Silverchair and the Foo Fighters. In the wake of Devo's dissolution, Bob Mothersbaugh attempted to start a solo career with The Bob I Band, recording an album that was never released. The tapes for this are now lost, though a bootleg recording of the band in concert exists and can be obtained through the bootleg aggregator Booji Boy's Basement.\nWhile they did not release any studio albums during this period, Devo sporadically reconvened to record a number of songs for various films and compilations, including a new recording of \"Girl U Want\" on the soundtrack to the 1995 film \"Tank Girl\" and a cover of the Nine Inch Nails hit \"Head Like a Hole\" for the 1996 North American version of the film \"Supercop\".\n1996\u20132007: Reunion.\nIn January 1996, Devo performed a reunion concert at the Sundance Film Festival in Park City, Utah. The band performed on part of the 1996 Lollapalooza tour in the rotating Mystery Spot. On these tours and most subsequent tours, Devo performed a set-list mostly composed of material from between 1978 and 1982, ignoring their Enigma Records-era material. Also in 1996, Devo released a multimedia CD-ROM adventure game, \"Adventures of the Smart Patrol\" with Inscape. The game was not a success, but the Lollapalooza tour was received well enough to allow Devo to return in 1997 as a headliner. Devo performed sporadically from 1997 onwards.\nIn 1999, the \"Oh, No! It's Devo\" era outtakes \"Faster and Faster\" and \"One Dumb Thing\", as well as the \"Shout\" era outtake \"Modern Life\", were restored, completed and used in the video game \"Interstate '82\", developed by Activision and released. Also that year, Mothersbaugh started the Devo side-project The Wipeouters, after their band in junior high, featuring himself (keyboards, organ), Bob Mothersbaugh (guitar), Bob Casale (guitar), and Mutato Muzika composer Josh Mancell (drums). The Wipeouters performed the theme song to the Nickelodeon animated series \"Rocket Power\", and in 2001 they released an album of surf rock material, titled \"P'Twaaang!!!\".\nAround this same time, Devo's online fandom continued to grow, leading to 'Devotional', a Devo fan convention held annually in Cleveland, Ohio. The festival was most recently held in September 2022.\nIn 2005, Devo recorded a new version of \"Whip It\" to be used in Swiffer television commercials, a decision they have said they regretted. During an interview with the \"Dallas Observer\", Gerald Casale said, \"It's just aesthetically offensive. It's got everything a commercial that turns people off has.\" The song \"Beautiful World\" was also used in a re-recorded form for an advertisement for Target stores. Due to rights issues with their back catalog, Devo has re-recorded songs for films and advertisements.\nIn 2005, Gerald Casale announced his \"solo\" project, Jihad Jerry &amp; the Evildoers (the Evildoers, including the other members of Devo), and released the first EP, \"Army Girls Gone Wild\" in 2006. A full-length album, \"Mine Is Not a Holy War\", was released on September 12, 2006, after a several-month delay. It featured mostly new material, plus re-recordings of four obscure Devo songs: \"I Need a Chick\" and \"I Been Refused\" (from \"\"), \"Find Out\" (which appeared on the single and EP of \"Peek-a-Boo!\" in 1982), and \"Beehive\" (which was recorded by the band in 1974, whereupon it was apparently abandoned, with the exception of one appearance at a special show in 2001). Devo continued to tour actively in 2005 and 2006, unveiling a new stage show at appearances in October 2006, with the Jihad Jerry character performing \"Beautiful World\" as an encore.\nAlso in 2006, Devo worked on a project with Disney known as Devo 2.0. A band of child performers was assembled and re-recorded Devo songs. A quote from the \"Akron Beacon Journal\" stated, \"Devo recently finished a new project in cahoots with Disney called Devo 2.0, which features the band playing old songs and two new ones with vocals provided by children. Their debut album, a two disc CD/DVD combo entitled \"DEV2.0\", was released on March 14, 2006. The lyrics of some of the songs were changed for family-friendly airplay, which has been claimed by the band to be a play on irony of the messages of their classic hits.\"\nIn an April 2007 interview, Gerald Casale mentioned a tentative project for a biographical film about Devo's early days. According to Casale, a script was supposedly in development, called \"The Beginning Was the End\". Devo played their first European tour since 1990 in the summer of 2007, including a performance at Festival Internacional de Benic\u00e0ssim.\n2007\u20132013: \"Something for Everybody\".\nIn December 2007, Devo released their first new single since 1990, \"Watch Us Work It\", which was featured in a commercial for Dell. The song features a sampled drum track from the \"New Traditionalists\" song \"The Super Thing\". Casale said that the song was chosen from a batch that the band was working on, and that it was the closest the band had been to releasing a new album.\nDevo performed at the South by Southwest (SXSW) festival in March 2009, unveiling a new stage show with synchronized video backdrops (similar to the 1982 tour), new costumes, and three new songs: \"Don't Shoot, I'm a Man!\", \"What We Do\", and \"Fresh\". On September 16, Warner Bros. and Devo announced rereleases of \"Q: Are We Not Men? A: We Are Devo!\" and \"Freedom of Choice\", as well as a subsequent tour, where they would perform both albums in their entirety.\nA new album, \"Something for Everybody\", was eventually released on June 15, 2010, preceded by a 12-inch single of \"Fresh\"/\"What We Do\" on June 10. Devo was awarded the first Moog Innovator Award on October 29, during Moogfest 2010 in Asheville, North Carolina. The Moog Innovator Award has been said to celebrate \"pioneering artists whose genre-defying work exemplifies the bold, innovative spirit of Bob Moog\". Devo was scheduled to perform at Moogfest, but Bob Mothersbaugh severely injured his hand three days prior, and the band was forced to cancel. Mark Mothersbaugh and Gerald Casale collaborated with Austin-based band the Octopus Project to perform \"Girl U Want\" and \"Beautiful World\" at the event instead.\nThe band split from Warner Bros in 2012 and launched a new \"post-Warner Brothers\" website that would offer \"new protective gear\" and \"unreleased material from the archives in vinyl disc format\". In August of that year, the band released a single called \"Don't Roof Rack Me, Bro (Seamus Unleashed)\", dedicated to the Republican Party presidential candidate Mitt Romney's former pet dog Seamus. The title refers to the Mitt Romney dog incident of 1983, when Romney travelled twelve hours with the dog in a crate on his car's roof rack.\nOn June 24, 2013, the group's former drummer Alan Myers died of stomach cancer in Los Angeles, California. He was 58. News reports at the time of his death incorrectly cited brain cancer as the cause. One month later, Devo released their \"Something Else for Everybody\" album, which collected \"Unreleased Demos and Focus Group Rejects\" from 2006\u20132009. Gerald Casale had earlier teased the album in a 2012 interview with \"Billboard\" magazine.\n2014: Hardcore Devo Tour, Bob Casale's death.\nOn February 17, 2014, founding member Bob Casale died of heart failure at age 61. Shortly afterwards, the group, a quartet for the first time in 38 years, embarked on their Hardcore Devo Tour, a ten-show tour across the US and Canada between June 18 and July 2, 2014. The tour focused on material the group had written before the release of their first album, which was largely written when the group were a quartet. Partial proceeds for the ten shows went to support Bob Casale's family after his sudden death. The show featured the group performing material written during 1974\u20131977. The June 28 Oakland show was filmed and later released as the concert film \"Hardcore Devo Live!\", released on Blu-ray, DVD, and Video on Demand on February 10, 2015, accompanied by CD and double-vinyl audio releases.\n2014\u2013present: Current activities.\nImmediately following from the Hardcore tour, Devo continued to tour a 'greatest hits' style show. Josh Hager joined the band at this time, playing guitar and keyboards. On April 29, 2016, Devo performed at Will Ferrell and Chad Smith's Red Hot Benefit.\nOn May 22, Robert Mothersbaugh Sr., father of Mark, Bob, and Jim Mothersbaugh, died. Robert portrayed General Boy in various Devo films.\nIn 2017, the official Twitter account for the \"Are We Not Men?\" documentary film, which had been in production since 2009, stated that \"the film was finished years ago\" and that \"mm [Mark Mothersbaugh] is blocking its release\". Jeff Winner, who was consulting producer for the Devo documentary, went on to state that he and director Tony Pemberton had \"delivered the film that was contracted, and on schedule. It's now in the hands of the band to decide when/how it's released/distributed.\"\nDevo headlined the Burger Boogaloo festival in Oakland, California, on June 30, 2018, with comedian and former Trenchmouth drummer Fred Armisen on drums. On October 12, 2020, Devo performed at the Desert Daze festival, with Jeff Friedl on drums.\nIn January 2021, Funko released two Devo Funko Pops inspired by the group's \"Whip It\" and \"Satisfaction\" music videos. One month later, the band starred in \"Devolution: A Devo Theory\", a television documentary based entirely on their theory of devolution, which had been completed in 2020. In September, Devo performed a short three-date tour of the USA, including a show at Riot Fest. These performances marked the return of Josh Freese on drums, who had not played live with Devo in over five years.\nShortly afterwards, Gerald Casale announced the release of an official Devo potato-based vodka through the Trust Me Vodka brand. The packaging for the drink was themed around Devo imagery and featured original artwork. It was signed by the group's co-founders Gerald Casale and Mark Mothersbaugh, as well as Bob Mothersbaugh.\nOn October 24, 2021, John Hinckley Jr posted on Twitter that he had not received any royalties for Devo's song \"I Desire\" in 35 years. \"I Desire\" had been written by Mark Mothersbaugh and Gerald Casale for their 1982 album \"Oh, No! It's Devo\", inspired by a poem written by Hinckley that was published in a tabloid newspaper, following his attempt to assassinate then-current president Ronald Reagan. Hinckley had been adequately credited for his contributions through a co-writing credit on all releases. Casale claimed that Devo were not at fault, as it was the publishing company's duty to pay him, not the band's.\nDevotional 2021, an annual convention for Devo fans, was held on November 5\u20136, with the annual 5KDEVO race taking place on the 7th. On November 15, it was announced that Devo would perform a one-off show at the Rooftop at Pier 17 on May 18, 2022, in order to make up for their cancelled Radio City Music Hall gig in September 2021. Tickets went on sale on the 18th.\nIn December, it was announced that rare images of Devo would feature in a book of rock photography from 1977\u20131980 titled \"HARD + FAST\", to be released on February 1, 2022. The book will also include a 7-inch single of live recordings from the band, which were also released on SoundCloud prior to the book's release. The recordings were dated 1977, but the performances are identical to those found on an audience bootleg recorded on October 10, 1978.\nDevo were nominated for induction into the Rock and Roll Hall of Fame in 2018, 2021 and 2022.\nOn May 14 and 15, 2022, Devo performed at the Cruel World Festival at the Rose Bowl's Brookside golf course in Pasadena, California, followed three days later by their performance at The Rooftop at Pier 17.\nIn a February 20, 2023, article by the \"Akron Beacon Journal\" promoting the film \"Cocaine Bear\", Mothersbaugh announced that the group would celebrate the year as their 50th anniversary, and that he had plans for Devo to remain active for 50 more years. He also stated that he, Gerald Casale and Bob Mothersbaugh were all interested in touring. This was followed by the announcement of a European tour, taking place between August 8th and 19th of 2023, with shows at London's Eventim Apollo, \u00d8yafestivalen in Norway, Way Out West festival in Sweden, Flow Festival in Finland, Green Man Festival in Wales, and Luna Fest in Portugal. This was followed in November and December by a string of shows in the USA and Australia.On January 21st, 2024, \"Devo,\" a Chris Smith directed documentary on the band premiered at Sundance Film Festival, with the group performing at the event. The film was produced and financed by BMG, Fremantle Documentaries, and Warner Music Entertainment, and according to a statement by the band \"explores Devo's evolution from hippie artistes to art-rockers with a message, to their unexpected mainstream success as a hit rock band and the pioneers of the MTV age,\" following the group's career arc up to its status as \"elder statesmen\". Smith was executive producer on \"Tiger King\", which had been scored by Mark Mothersbaugh, with Bob Mothersbaugh co-scoring its first season.\nBetween May 4th and 26th, Devo underwent another short US tour, including a show at the Andy Warhol Museum and at this same time, Mothersbaugh released an art book titled \"Apotropaic Beatnik Graffiti.\" On the June 5th, 2024, a collaboration between David Byrne and Devo was released. The recording was an early version of Byrne's song \"Empire,\" recorded during the sessions for his 1997 \"Feelings\" album, seven years before the song appeared on his \"Grown Backwards\" album\nBand members.\nCurrent members\nFormer members\nTouring members\nDiscography.\nStudio albums"}
{"id": "9131", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=9131", "title": "Djinn", "text": ""}
{"id": "9132", "revid": "183471", "url": "https://en.wikipedia.org/wiki?curid=9132", "title": "Dale Chihuly", "text": "Dale Chihuly ( ; born September 20, 1941) is an American glass artist and entrepreneur. He is well known in the field of blown glass, \"moving it into the realm of large-scale sculpture\".\nEarly life.\nDale Patrick Chihuly was born on September 20, 1941, in Tacoma, Washington. His parents were George and Viola Chihuly; his paternal grandfather was born in Slovakia. In 1957, his older brother and only sibling George died in a Navy aviation training accident in Pensacola, Florida. In 1958, Chihuly's father died of a heart attack at the age of 51.\nChihuly had no interest in continuing his formal education after graduating from Woodrow Wilson High School in 1959. However, at his mother's urging, he enrolled at the College of Puget Sound. A year later, he transferred to the University of Washington in Seattle to study interior design. In 1961, he joined the Delta Kappa Epsilon fraternity (Kappa Epsilon chapter), and the same year he learned how to melt and fuse glass. In 1962, Chihuly dropped out of the university to study art in Florence. He later traveled to the Middle East where he met architect Robert Landsman. Their meeting and his time abroad spurred Chihuly to return to his studies. In 1963, he took a weaving class where he incorporated glass shards into tapestries. He received an award for his work from the Seattle Weavers Guild in 1964. Chihuly graduated from the University of Washington in 1965 with a Bachelor of Arts degree in interior design.\nChihuly began experimenting with glassblowing in 1965, and in 1966 he received a full scholarship to attend the University of Wisconsin\u2013Madison. He studied under Harvey Littleton, who had established the first glass program in the United States at the university. In 1967, Chihuly received a Master of Science degree in sculpture. After graduating, he enrolled at the Rhode Island School of Design, where he met and became close friends with Italo Scanga. Chihuly earned a Master of Fine Arts degree in sculpture from the RISD in 1968. That same year, he was awarded a Louis Comfort Tiffany Foundation grant for his work in glass, as well as a Fulbright Fellowship. He traveled to Venice to work at the Venini factory on the island of Murano, where he first saw the team approach to blowing glass. After returning to the United States, Chihuly spent the first of four consecutive summers teaching at the Haystack Mountain School of Crafts in Deer Isle, Maine. In 1969, he traveled to Europe, in part to meet Erwin Eisch in Germany and Stanislav Libensk\u00fd and Jaroslava Brychtov\u00e1 in Czechoslovakia.\nChihuly donated a portion of a large exhibit to his alma mater, the University of Wisconsin, in 1997 and it is on permanent display in the Kohl Center. In 2013 the university awarded him an Honorary Doctorate of Fine Arts.\nCareer.\nIn 1971, with the support of John Hauberg and Anne Gould Hauberg, Chihuly co-founded the Pilchuck Glass School near Stanwood, Washington. Chihuly also founded the HillTop Artists program in Tacoma, Washington at Hilltop Heritage Middle School and Wilson High School.\nIn 1976, while Chihuly was in England, he was involved in a head-on car accident that propelled him through the windshield. His face was severely cut by glass and he was blinded in his left eye. After recovering, he continued to blow glass until he dislocated his right shoulder in 1979 while bodysurfing.\nIn 1983, Chihuly returned to his native Pacific Northwest where he continued to develop his own work at the Pilchuck Glass School, which he had helped to found in 1971. No longer able to hold the glassblowing pipe, he hired others to do the work. Chihuly explained the change in a 2006 interview, saying \"Once I stepped back, I liked the view\", and said that it allowed him to see the work from more perspectives, enabling him to anticipate problems earlier. Chihuly's role has been described as \"more choreographer than dancer, more supervisor than participant, more director than actor\". \"San Diego Union-Tribune\" reporter Erin Glass wrote that she \"wonders at the vision of not just the artist Chihuly, but the very successful entrepreneur Chihuly, whose estimated sales by 2004 was reported by \"The Seattle Times\" as $29 million.\"\nChihuly and his team of artists were the subjects of the documentary \".\" They were also featured in the documentary \"Chihuly in the Hotshop,\" syndicated to public television stations by American Public Television starting on November 1, 2008.\nIn 2010, the Space Needle Corporation submitted a proposal for an exhibition of Chihuly's work at a site in the Seattle Center, in competition with proposals for other uses from several other groups. The project, which sees the new Chihuly exhibition hall occupy the site of the former Fun Forest amusement park in the Seattle Center park and entertainment complex, received the final approval from the Seattle City Council on April 25, 2011. Called Chihuly Garden and Glass, it opened May 21, 2012.\n2006 lawsuit.\nIn 2006, Chihuly filed a lawsuit against his former longtime employee, glassblower Bryan Rubino, and businessman Robert Kaindl, claiming copyright and trademark infringement. Kaindl's pieces used titles Chihuly had employed for his own works, such as Seaforms and Ikebana, and resembled the construction of Chihuly's pieces. Legal experts stated that influence on art style did not constitute copyright infringement. Chihuly settled the lawsuit with Rubino initially, and later with Kaindl as well.\nWorks.\nRegina Hackett, a \"Seattle Post-Intelligencer\" art critic, provided a chronology of Chihuly's work during the 1970s, 1980s, and 1990s:\nFor his exhibition in Jerusalem, in 1999\u20132000, in addition to the glass pieces, he had enormous blocks of transparent ice brought in from an Alaskan artesian well and formed a wall, echoing the stones of the nearby Citadel. Lights with color gels were set up behind them for illumination. Chihuly said the melting wall represented the \"dissolution of barriers\" between people. This exhibit holds the world record for most visitors to a temporary exhibit with more than 1.3 million visitors.\nIn 1999, Chihuly's \"Millenium Tree\" was present in the East Wing of the Clinton White House during a Millenium celebration. The tree now resides in the William J. Clinton Presidential Library and Museum.\nTwo of Chihuly's pieces can also be found at two casino resorts owned by MGM Resorts International: one in the reception area of the Bellagio on the Las Vegas Strip, and the other in the VIP lobby of the MGM Macau in Macau, China. The piece at the Bellagio, titled \"Fiori di Como\", holds the Guinness World Record for largest glass sculpture. In July 2001, in response to positive feedback from guests who viewed the installation at Bellagio, Chihuly partnered with Bellagio to open a store that sold some of the artist's original works, as well as books and videos about the artist. However, the store has since been marked permanently closed on Google Maps. \nThere is also one piece titled Blue River in the Casino of the Sky at Mohegan Sun: Casino and Resort in Uncasville, CT. The distinctive cobalt blue, silver and clear colored glass sculpture, measuring fourteen feet in width, soars twenty-five feet above visitors, creating a spectacular centerpiece.\nExhibitions.\nPermanent collections.\nChihuly's art appears in over 400 permanent collections all over the world, including in the United States, Canada, England, Israel, China, Singapore, the United Arab Emirates, and Australia. Chihuly's largest permanent exhibit is at the Oklahoma City Museum of Art. Other large collections can be found at the Morean Arts Center in St. Petersburg, Florida, and Chihuly Garden and Glass in Seattle, Washington. Four large-scale installations are on permanent display at the Baker Museum in Naples, Florida. "}
{"id": "9133", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=9133", "title": "Dean Kamen", "text": "Dean Lawrence Kamen (; born April 5, 1951) is an American engineer, inventor, and businessman. He is known for his invention of the Segway and iBOT, as well as founding the non-profit organization FIRST with Woodie Flowers. Kamen holds over 1,000 patents.\nEarly life and family.\nKamen was born on Long Island, New York, to a Jewish family. \nHis father was Jack Kamen, an illustrator for \"Mad\", \"Weird Science\" and other EC Comics publications. During his teenage years, Kamen was already being paid for his ideas; local bands and museums paid him to build light and sound systems. His annual earnings reached $60,000 before his high school graduation.\nHe attended Worcester Polytechnic Institute, but in 1976 quit before graduating, after five years of private advanced research for the insulin pump AutoSyringe.\nCareer.\nInventions.\nKamen is known best for inventing the product that eventually became known as the Segway PT, an electric, self-balancing human transporter with a computer-controlled gyroscopic stabilization and control system. The device is balanced on two parallel wheels and is controlled by moving body weight. The machine's development was the object of much speculation and hype after segments of a book quoting Steve Jobs and other notable information technology visionaries espousing its society-revolutionizing potential were leaked in December 2001.\nKamen was already a successful inventor: his company \"Auto Syringe\" manufactures and markets the first drug infusion pump. His company DEKA also holds patents for the technology used in portable dialysis machines, an insulin pump (based on the drug infusion pump technology), and an all-terrain electric wheelchair known as the iBOT, using many of the same gyroscopic balancing technologies that later made their way into the Segway.\nKamen has worked extensively on a project involving Stirling engine designs, attempting to create two machines: one that would generate power, and the Slingshot that would serve as a water purification system. He hopes the project will help improve living standards in developing countries. Kamen has a patent on his water purifier, and other patents pending. In 2014, the film \"SlingShot\" was released, detailing Kamen's quest to use his vapor compression distiller to fix the world's water crisis.\nKamen is also the co-inventor of a compressed air device that would launch a human into the air in order to quickly launch SWAT teams or other emergency workers to the roofs of tall, inaccessible buildings.\nIn 2009 Kamen stated that his company DEKA was now working on solar powered inventions.\nKamen and DEKA also developed the DEKA Arm System or \"Luke\", a prosthetic arm replacement that offers its user much more fine motor control than traditional prosthetic limbs. It was approved for use by the US Food and Drug Administration (FDA) in May 2014, and DEKA is looking for partners to mass-produce the prosthesis.\nFIRST.\nIn 1989, Kamen founded FIRST (For Inspiration and Recognition of Science and Technology), an organization intended to build students' interests in science, technology, engineering, and mathematics (STEM). In 1992, working with MIT Professor Emeritus Woodie Flowers, Kamen created the FIRST Robotics Competition (FRC), which evolved into an international competition that by 2020 had drawn 3,647 teams and more than 91,000 students.\nFIRST organizes robotics competition leagues for students in grades K-12, including FIRST LEGO League Discover for ages 4\u20136, FIRST LEGO League Explore for younger elementary school students, FIRST LEGO League Challenge for older elementary school and middle school students, FIRST Tech Challenge (FTC) for middle and high school students, and FIRST Robotics Competition (FRC) for high school students. In 2017, FIRST held its first Olympics-style competition \u2013 FGC (FIRST Global Challenge) \u2013 in Washington, D.C.\nIn 2010, Kamen called FIRST the invention he is most proud of, and said that 1 million students had taken part in the contests.\nAdvanced Regenerative Manufacturing Institute.\nIn 2017, Kamen founded the Advanced Regenerative Manufacturing Institute (ARMI) and launched BioFabUSA, a Manufacturing USA Innovation Institute with an $80 million grant from the Department of Defense. BioFabUSA's mission is to \"...\"make practical the large-scale manufacturing of engineered tissues and tissue-related technologies, to benefit existing industries and grow new ones\"\" In addition to DoD funding, Kamen brought together a consortium of private sector entities to form a public-private partnership which pledged $214M additional private dollars.\nIn early 2020, ARMI was awarded a grant from the Department of Health and Human Services to establish the first Foundry for American Biotechnology, known as NextFab \"to produce technological solutions that help the United States protect against and respond to health security threats, enhance daily medical care, and add to the U.S. bioeconomy\".\nAwards.\nKamen has won numerous awards. He was elected to the National Academy of Engineering in 1997 for inventing and commercializing biomedical devices and fluid measurement and control systems, and for popularizing engineering among young people. In 1999 he was awarded the 5th Annual Heinz Award in Technology, the Economy and Employment, and in 2000 received the National Medal of Technology from then President Clinton for inventions that have advanced medical care worldwide. In April 2002, Kamen was awarded the Lemelson-MIT Prize for inventors, for his invention of the Segway and of an infusion pump for diabetics. In 2003 his \"Project Slingshot\", an inexpensive portable water purification system, was named a runner-up for \"coolest invention of 2003\" by \"Time\" magazine.\nIn 2005 he was inducted into the National Inventors Hall of Fame for his invention of the AutoSyringe. In 2006 Kamen was awarded the \"Global Humanitarian Action Award\" by the United Nations. In 2007 he received the ASME Medal, the highest award from the American Society of Mechanical Engineers, in 2008 he was the recipient of the IRI Achievement Award from the Industrial Research Institute, and in 2011 Kamen was awarded the Benjamin Franklin Medal in Mechanical Engineering of the Franklin Institute.\nKamen received an honorary Doctor of Engineering degree from Worcester Polytechnic Institute in 1992, Rensselaer Polytechnic Institute May 17, 1996, a Doctor of Engineering degree from Kettering University in 2001, an honorary Doctor of Science degree from Clarkson University on May 13, 2001, an honorary \"Doctor of Science\" degree from the University of Arizona on May 16, 2009, and an honorary doctorate from the Wentworth Institute of Technology when he spoke at the college's centennial celebration in 2004, and other honorary doctorates from North Carolina State University in 2005, Bates College in 2007, the Georgia Institute of Technology in 2008, the Illinois Institute of Technology in 2008 the Plymouth State University in May 2008 and Rose-Hulman Institute of Technology in 2012. In 2015, Kamen received an honorary Doctor of Engineering and Technology degree from Yale University. In 2017, Kamen was honored with an institutional honorary degree from Universit\u00e9 de Sherbrooke.\nKamen received the Stevens Honor Award on November 6, 2009, given by the Stevens Institute of Technology and the Stevens Alumni Association. On November 14, 2013, he received the James C. Morgan Global Humanitarian Award.\nKamen received the 2018 Public Service Award from the National Science Board, honoring his exemplary public service and contributions to the public's understanding of science and engineering.\nTrivia.\nIn 2007, his residence was a hexagonal, shed style mansion he dubbed Westwind, located in Bedford, New Hampshire, just outside Manchester. The house has at least four levels and is very eclectically conceived, with such things as: hallways resembling mine shafts; 1960s novelty furniture; a collection of vintage wheelchairs; spiral staircases; at least one secret passage; an observation tower; a fully equipped machine shop; and a huge cast iron steam engine which once belonged to Henry Ford (built into the multi-story center atrium of the house) which Kamen is working to convert into a Stirling engine-powered kinetic sculpture. Kamen owns and pilots an Embraer Phenom 300 light jet aircraft and three Enstrom helicopters, including a 280FX, a 480, and a 480B. He regularly commutes to work via his helicopters and had a hangar built into his house. In 2016 he flew as a passenger in a B-2 Spirit bomber at Whiteman AFB, marking the opening of the 2016 FRC World Championship in St. Louis.\nHe is the main subject of \"Code Name Ginger: the Story Behind Segway and Dean Kamen's Quest to Invent a New World\", a nonfiction narrative book by journalist Steve Kemper published by Harvard Business School Press in 2003 (released in paperback as \"Reinventing the Wheel\").\nHis company, DEKA, annually creates intricate mechanical presents for him. The company has created a robotic chess player, which is a mechanical arm attached to a chess board, and a vintage-looking computer with antique wood, and a converted typewriter as a keyboard. In addition, DEKA has received funding from DARPA to work on a brain-controlled prosthetic limb called the Luke Arm.\nKamen is a member of the USA Science and Engineering Festival's Advisory Board and is also a member of the Xconomists, an ad hoc team of editorial advisors for the tech news and media company, Xconomy. He is also on the Board of Trustees of the X Prize Foundation.\n\"Dean of Invention\", a TV show on Planet Green, premiered on October 22, 2010. It starred Kamen and correspondent Joanne Colan, in which they investigate new technologies,\nKamen was a keynote speaker at the 2015 Congress of Future Science and Technology Leaders.\nIn the 2016 United States Senate election in New Hampshire, Kamen endorsed Kelly Ayotte, appearing in an ad supporting her."}
{"id": "9135", "revid": "45940103", "url": "https://en.wikipedia.org/wiki?curid=9135", "title": "Derivative (finance)", "text": "In finance, a derivative is a contract between a buyer and a seller. The derivative can take various forms, depending on the transaction, but every derivative has the following four elements: \nA derivative's value depends on the performance of the underlier, which can be a commodity (for example, corn or oil), a financial instrument (e.g. a stock or a bond), a price index, a currency, or an interest rate. \nDerivatives can be used to insure against price movements (hedging), increase exposure to price movements for speculation, or get access to otherwise hard-to-trade assets or markets. Most derivatives are price guarantees. But some are based on an event or performance of an act rather than a price. Agriculture, natural gas, electricity and oil businesses use derivatives to mitigate risk from adverse weather. Derivatives can be used to protect lenders against the risk of borrowers defaulting on an obligation. \nSome of the more common derivatives include forwards, futures, options, swaps, and variations of these such as synthetic collateralized debt obligations and credit default swaps. Most derivatives are traded over-the-counter (off-exchange) or on an exchange such as the Chicago Mercantile Exchange, while most insurance contracts have developed into a separate industry. In the United States, after the 2007\u20132008 financial crisis, there has been increased pressure to move derivatives to trade on exchanges.\nDerivatives are one of the three main categories of financial instruments, the other two being equity (i.e., stocks or shares) and debt (i.e., bonds and mortgages). The oldest example of a derivative in history, attested to by Aristotle, is thought to be a contract transaction of olives, entered into by ancient Greek philosopher Thales, who made a profit in the exchange. However, Aristotle did not define this arrangement as a derivative but as a monopoly (Aristotle's Politics, Book I, Chapter XI). Bucket shops, outlawed in 1936 in the US, are a more recent historical example.\nBasics.\nDerivatives are contracts between two parties that specify conditions (especially the dates, resulting values and definitions of the underlying variables, the parties' contractual obligations, and the notional amount) under which payments are to be made between the parties. The assets include commodities, stocks, bonds, interest rates and currencies, but they can also be other derivatives, which adds another layer of complexity to proper valuation. The components of a firm's capital structure, e.g., bonds and stock, can also be considered derivatives, more precisely options, with the underlying being the firm's assets, but this is unusual outside of technical contexts.\nFrom the economic point of view, financial derivatives are cash flows that are conditioned stochastically and discounted to present value. The market risk inherent in the underlying asset is attached to the financial derivative through contractual agreements and hence can be traded separately. The underlying asset does not have to be acquired. Derivatives therefore allow the breakup of ownership and participation in the market value of an asset. This also provides a considerable amount of freedom regarding the contract design. That contractual freedom allows derivative designers to modify the participation in the performance of the underlying asset almost arbitrarily. Thus, the participation in the market value of the underlying can be effectively weaker, stronger (leverage effect), or implemented as inverse. Hence, specifically the market price risk of the underlying asset can be controlled in almost every situation.\nThere are two groups of derivative contracts: the privately traded over-the-counter (OTC) derivatives such as swaps that do not go through an exchange or other intermediary, and exchange-traded derivatives (ETD) that are traded through specialized derivatives exchanges or other exchanges.\nDerivatives are more common in the modern era, but their origins trace back several centuries. One of the oldest derivatives is rice futures, which have been traded on the Dojima Rice Exchange since the eighteenth century. Derivatives are broadly categorized by the relationship between the underlying asset and the derivative (such as forward, option, swap); the type of underlying asset (such as equity derivatives, foreign exchange derivatives, interest rate derivatives, commodity derivatives, or credit derivatives); the market in which they trade (such as exchange-traded or over-the-counter); and their pay-off profile.\nDerivatives may broadly be categorized as \"lock\" or \"option\" products. Lock products (such as swaps, futures, or forwards) obligate the contractual parties to the terms over the life of the contract. Option products (such as interest rate swaps) provide the buyer the right, but not the obligation to enter the contract under the terms specified.\nDerivatives can be used either for risk management (i.e. to \"hedge\" by providing offsetting compensation in case of an undesired event, a kind of \"insurance\") or for speculation (i.e. making a financial \"bet\"). This distinction is important because the former is a prudent aspect of operations and financial management for many firms across many industries; the latter offers managers and investors a risky opportunity to increase profit, which may not be properly disclosed to stakeholders.\nAlong with many other financial products and services, derivatives reform is an element of the Dodd\u2013Frank Wall Street Reform and Consumer Protection Act of 2010. The Act delegated many rule-making details of regulatory oversight to the Commodity Futures Trading Commission (CFTC) and those details are not finalized nor fully implemented as of late 2012.\nSize of market.\nTo give an idea of the size of the derivative market, \"The Economist\" has reported that as of June 2011, the over-the-counter (OTC) derivatives market amounted to approximately $700 trillion, and the size of the market traded on exchanges totaled an additional $83 trillion. For the fourth quarter 2017 the European Securities Market Authority estimated the size of European derivatives market at a size of \u20ac660 trillion with 74 million outstanding contracts.\nHowever, these are \"notional\" values, and some economists say that these aggregated values greatly exaggerate the market value and the true credit risk faced by the parties involved. For example, in 2010, while the aggregate of OTC derivatives exceeded $600 trillion, the value of the market was estimated to be much lower, at $21 trillion. The credit-risk equivalent of the derivative contracts was estimated at $3.3 trillion.\nStill, even these scaled-down figures represent huge amounts of money. For perspective, the budget for total expenditure of the United States government during 2012 was $3.5 trillion, and the total current value of the U.S. stock market is an estimated $23 trillion. Meanwhile, the global annual Gross Domestic Product is about $65 trillion.\nAt least for one type of derivative, credit default swaps (CDS), for which the inherent risk is considered high , the higher, nominal value remains relevant. It was this type of derivative that investment magnate Warren Buffett referred to in his famous 2002 speech in which he warned against \"financial weapons of mass destruction\". CDS notional value in early 2012 amounted to $25.5 trillion, down from $55 trillion in 2008.\nUsage.\nDerivatives are used for the following:\nMechanics and valuation.\nLock products are theoretically valued at zero at the time of execution and thus do not typically require an up-front exchange between the parties. Based upon movements in the underlying asset over time, however, the value of the contract will fluctuate, and the derivative may be either an asset (i.e., \"in the money\") or a liability (i.e., \"out of the money\") at different points throughout its life. Importantly, either party is therefore exposed to the credit quality of its counterparty and is interested in protecting itself in an event of default.\nOption products have immediate value at the outset because they provide specified protection (intrinsic value) over a given time period (time value). One common form of option product familiar to many consumers is insurance for homes and automobiles. The insured would pay more for a policy with greater liability protections (intrinsic value) and one that extends for a year rather than six months (time value). Because of the immediate option value, the option purchaser typically pays an up front premium. Just like for lock products, movements in the underlying asset will cause the option's intrinsic value to change over time while its time value deteriorates steadily until the contract expires. An important difference between a lock product is that, after the initial exchange, the option purchaser has no further liability to its counterparty; upon maturity, the purchaser will execute the option if it has positive value (i.e., if it is \"in the money\") or expire at no cost (other than to the initial premium) (i.e., if the option is \"out of the money\").\nHedging.\nDerivatives allow risk related to the price of the underlying asset to be transferred from one party to another. For example, a wheat farmer and a miller could sign a futures contract to exchange a specified amount of cash for a specified amount of wheat in the future. Both parties have reduced a future risk: for the wheat farmer, the uncertainty of the price, and for the miller, the availability of wheat. However, there is still the risk that no wheat will be available because of events unspecified by the contract, such as the weather, or that one party will renege on the contract. Although a third party, called a clearing house, insures a futures contract, not all derivatives are insured against counter-party risk.\nFrom another perspective, the farmer and the miller both reduce a risk and acquire a risk when they sign the futures contract: the farmer reduces the risk that the price of wheat will fall below the price specified in the contract and acquires the risk that the price of wheat will rise above the price specified in the contract (thereby losing additional income that he could have earned). The miller, on the other hand, acquires the risk that the price of wheat will fall below the price specified in the contract (thereby paying more in the future than he otherwise would have) and reduces the risk that the price of wheat will rise above the price specified in the contract. In this sense, one party is the insurer (risk taker) for one type of risk, and the counter-party is the insurer (risk taker) for another type of risk.\nHedging also occurs when an individual or institution buys an asset (such as a commodity, a bond that has coupon payments, a stock that pays dividends, and so on) and sells it using a futures contract. The individual or institution has access to the asset for a specified amount of time, and can then sell it in the future at a specified price according to the futures contract. Of course, this allows the individual or institution the benefit of holding the asset, while reducing the risk that the future selling price will deviate unexpectedly from the market's current assessment of the future value of the asset.\nDerivatives trading of this kind may serve the financial interests of certain particular businesses. For example, a corporation borrows a large sum of money at a specific interest rate. The interest rate on the loan reprices every six months. The corporation is concerned that the rate of interest may be much higher in six months. The corporation could buy a forward rate agreement (FRA), which is a contract to pay a fixed rate of interest six months after purchases on a notional amount of money. If the interest rate after six months is above the contract rate, the seller will pay the difference to the corporation, or FRA buyer. If the rate is lower, the corporation will pay the difference to the seller. The purchase of the FRA serves to reduce the uncertainty concerning the rate increase and stabilize earnings.\nSpeculation.\nDerivatives can be used to acquire risk, rather than to hedge against risk. Thus, some individuals and institutions will enter into a derivative contract to speculate on the value of the underlying asset. Speculators look to buy an asset in the future at a low price according to a derivative contract when the future market price is high, or to sell an asset in the future at a high price according to a derivative contract when the future market price is less.\nSpeculative trading in derivatives gained a great deal of notoriety in 1995 when Nick Leeson, a trader at Barings Bank, made poor and unauthorized investments in futures contracts. Through a combination of poor judgment, lack of oversight by the bank's management and regulators, and unfortunate events like the Kobe earthquake, Leeson incurred a $1.3 billion loss that bankrupted the centuries-old institution.\nArbitrage.\nIndividuals and institutions may also look for arbitrage opportunities, as when the current buying price of an asset falls below the price specified in a futures contract to sell the asset.\nProportion used for hedging and speculation.\nThe true proportion of derivatives contracts used for hedging purposes is unknown, but it appears to be relatively small. Also, derivatives contracts account for only 3\u20136% of the median firms' total currency and interest rate exposure. Nonetheless, we know that many firms' derivatives activities have at least some speculative component for a variety of reasons.\nTypes.\nIn broad terms, there are two groups of derivative contracts, which are distinguished by the way they are traded in the market:\nOver-the-counter derivatives.\nOver-the-counter (OTC) derivatives are contracts that are traded (and privately negotiated) directly between two parties, without going through an exchange or other intermediary. Products such as swaps, forward rate agreements, exotic options \u2013 and other exotic derivatives \u2013 are almost always traded in this way. The OTC derivative market is the largest market for derivatives, and is largely unregulated with respect to disclosure of information between the parties, since the OTC market is made up of banks and other highly sophisticated parties, such as hedge funds. Reporting of OTC amounts is difficult because trades can occur in private, without activity being visible on any exchanges\nAccording to the Bank for International Settlements, who first surveyed OTC derivatives in 1995, reported that the \"gross market value, which represent the cost of replacing all open contracts at the prevailing market prices,\u00a0... increased by 74% since 2004, to $11 trillion at the end of June 2007 (BIS 2007:24).\" Positions in the OTC derivatives market increased to $516 trillion at the end of June 2007, 135% higher than the level recorded in 2004. The total outstanding notional amount is US$708 trillion (as of June 2011). Of this total notional amount, 67% are interest rate contracts, 8% are credit default swaps (CDS), 9% are foreign exchange contracts, 2% are commodity contracts, 1% are equity contracts, and 12% are other. Because OTC derivatives are not traded on an exchange, there is no central counter-party. Therefore, they are subject to counterparty risk, like an ordinary contract, since each counter-party relies on the other to perform.\nExchange-traded derivatives.\nExchange-traded derivatives (ETD) are those derivatives instruments that are traded via specialized derivatives exchanges or other exchanges. A derivatives exchange is a market where individuals trade standardized contracts that have been defined by the exchange. A derivatives exchange acts as an intermediary to all related transactions, and takes initial margin from both sides of the trade to act as a guarantee. The world's largest derivatives exchanges (by number of transactions) are the Korea Exchange (which lists KOSPI Index Futures &amp; Options), Eurex (which lists a wide range of European products such as interest rate &amp; index products), and CME Group (made up of the 2007 merger of the Chicago Mercantile Exchange and the Chicago Board of Trade and the 2008 acquisition of the New York Mercantile Exchange). According to BIS, the combined turnover in the world's derivatives exchanges totaled US$344 trillion during Q4 2005. By December 2007 the Bank for International Settlements reported that \"derivatives traded on exchanges surged 27% to a record $681 trillion.\"\nInverse ETFs and leveraged ETFs.\nInverse exchange-traded funds (IETFs) and leveraged exchange-traded funds (LETFs) are two special types of exchange traded funds (ETFs) that are available to common traders and investors on major exchanges like the NYSE and Nasdaq. To maintain these products' net asset value, these funds' administrators must employ more sophisticated financial engineering methods than what's usually required for maintenance of traditional ETFs. These instruments must also be regularly rebalanced and re-indexed each day.\nCommon derivative contract.\nSome of the common variants of derivative contracts are as follows:\nSome common examples of these derivatives are the following:\nCollateralized debt obligation.\nA collateralized debt obligation (CDO) is a type of structured asset-backed security (ABS). An \"asset-backed security\" is used as an umbrella term for a type of security backed by a pool of assetsincluding collateralized debt obligations and mortgage-backed securities (MBS) (Example: \"The capital market in which asset-backed securities are issued and traded is composed of three main categories: ABS, MBS and CDOs\".)and sometimes for a particular type of that securityone backed by consumer loans (example: \"As a rule of thumb, securitization issues backed by mortgages are called MBS, and securitization issues backed by debt obligations are called CDO, [and] Securitization issues backed by consumer-backed productscar loans, consumer loans and credit cards, among othersare called ABS.) Originally developed for the corporate debt markets, over time CDOs evolved to encompass the mortgage and mortgage-backed security (MBS) markets.\nLike other private-label securities backed by assets, a CDO can be thought of as a promise to pay investors in a prescribed sequence, based on the cash flow the CDO collects from the pool of bonds or other assets it owns. The CDO is \"sliced\" into \"tranches\", which \"catch\" the cash flow of interest and principal payments in sequence based on seniority. If some loans default and the cash collected by the CDO is insufficient to pay all of its investors, those in the lowest, most \"junior\" tranches suffer losses first. The last to lose payment from default are the safest, most senior tranches. Consequently, coupon payments (and interest rates) vary by tranche with the safest/most senior tranches paying the lowest and the lowest tranches paying the highest rates to compensate for higher default risk. As an example, a CDO might issue the following tranches in order of safeness: Senior AAA (sometimes known as \"super senior\"); Junior AAA; AA; A; BBB; Residual.\nSeparate special-purpose entitiesrather than the parent investment bankissue the CDOs and pay interest to investors. As CDOs developed, some sponsors repackaged tranches into yet another iteration called \"CDO-Squared\" or the \"CDOs of CDOs\". \nIn the early 2000s, CDOs were generally diversified, but by 2006\u20132007when the CDO market grew to hundreds of billions of dollarsthis changed. CDO collateral became dominated not by loans, but by lower level (BBB or A) tranches recycled from other asset-backed securities, whose assets were usually non-prime mortgages. These CDOs have been called \"the engine that powered the mortgage supply chain\" for nonprime mortgages, and are credited with giving lenders greater incentive to make non-prime loans leading up to the 2007\u201309 subprime mortgage crisis.\nCredit default swap.\nA credit default swap (CDS) is a financial swap agreement that the seller of the CDS will compensate the buyer (the creditor of the reference loan) in the event of a loan default (by the debtor) or other credit event. The buyer of the CDS makes a series of payments (the CDS \"fee\" or \"spread\") to the seller and, in exchange, receives a payoff if the loan defaults. It was invented by Blythe Masters from JP Morgan in 1994.\nIn the event of default the buyer of the CDS receives compensation (usually the face value of the loan), and the seller of the CDS takes possession of the defaulted loan. However, anyone with sufficient collateral to trade with a bank or hedge fund can purchase a CDS, even buyers who do not hold the loan instrument and who have no direct insurable interest in the loan (these are called \"naked\" CDSs). If there are more CDS contracts outstanding than bonds in existence, a protocol exists to hold a credit event auction; the payment received is usually substantially less than the face value of the loan.\nCredit default swaps have existed since the early 1990s, and increased in use after 2003. By the end of 2007, the outstanding CDS amount was $62.2\u00a0trillion, falling to $26.3\u00a0trillion by mid-year 2010 but reportedly $25.5\u00a0trillion in early 2012. CDSs are not traded on an exchange and there is no required reporting of transactions to a government agency. During the 2007\u20132008 financial crisis, the lack of transparency in this large market became a concern to regulators as it could pose a systemic risk.\n In March 2010, the [DTCC] Trade Information Warehouse announced it would give regulators greater access to its credit default swaps database.\nCDS data can be used by financial professionals, regulators, and the media to monitor how the market views credit risk of any entity on which a CDS is available, which can be compared to that provided by credit rating agencies. U.S. courts may soon be following suit.\nMost CDSs are documented using standard forms drafted by the International Swaps and Derivatives Association (ISDA), although there are many variants. In addition to the basic, single-name swaps, there are basket default swaps (BDSs), index CDSs, funded CDSs (also called credit-linked notes), as well as loan-only credit default swaps (LCDS). In addition to corporations and governments, the reference entity can include a special-purpose vehicle issuing asset-backed securities.\nSome claim that derivatives such as CDS are potentially dangerous in that they combine priority in bankruptcy with a lack of transparency. A CDS can be unsecured (without collateral) and be at higher risk for a default.\nForwards.\nIn finance, a forward contract or simply a forward is a non-standardized contract between two parties to buy or to sell an asset at a specified future time at an amount agreed upon today, making it a type of derivative instrument. This is in contrast to a spot contract, which is an agreement to buy or sell an asset on its spot date, which may vary depending on the instrument, for example most of the FX contracts have Spot Date two business days from today. The party agreeing to buy the underlying asset in the future assumes a long position, and the party agreeing to sell the asset in the future assumes a short position. The price agreed upon is called the delivery price, which is equal to the forward price at the time the contract is entered into.\nThe price of the underlying instrument, in whatever form, is paid before control of the instrument changes. This is one of the many forms of buy/sell orders where the time and date of trade is not the same as the value date where the securities themselves are exchanged.\nThe forward price of such a contract is commonly contrasted with the spot price, which is the price at which the asset changes hands on the spot date. The difference between the spot and the forward price is the forward premium or forward discount, generally considered in the form of a profit, or loss, by the purchasing party. Forwards, like other derivative securities, can be used to hedge risk (typically currency or exchange rate risk), as a means of speculation, or to allow a party to take advantage of a quality of the underlying instrument which is time-sensitive.\nA closely related contract is a futures contract; they differ in certain respects. Forward contracts are very similar to futures contracts, except they are not exchange-traded, or defined on standardized assets. Forwards also typically have no interim partial settlements or \"true-ups\" in margin requirements like futuressuch that the parties do not exchange additional property securing the party at gain and the entire unrealized gain or loss builds up while the contract is open. However, being traded over the counter (OTC), forward contracts specification can be customized and may include mark-to-market and daily margin calls. Hence, a forward contract arrangement might call for the loss party to pledge collateral or additional collateral to better secure the party at gain. In other words, the terms of the forward contract will determine the collateral calls based upon certain \"trigger\" events relevant to a particular counterparty such as among other things, credit ratings, value of assets under management or redemptions over a specific time frame (e.g., quarterly, annually).\nFutures.\nIn finance, a 'futures contract' (more colloquially, futures) is a standardized contract between two parties to buy or sell a specified asset of standardized quantity and quality for a price agreed upon today (the \"futures price\") with delivery and payment occurring at a specified future date, the \"delivery date\", making it a derivative product (i.e. a financial product that is derived from an underlying asset). The contracts are negotiated at a futures exchange, which acts as an intermediary between buyer and seller. The party agreeing to buy the underlying asset in the future, the \"buyer\" of the contract, is said to be \"long\", and the party agreeing to sell the asset in the future, the \"seller\" of the contract, is said to be \"short\".\nWhile the futures contract specifies a trade taking place in the future, the purpose of the futures exchange is to act as intermediary and mitigate the risk of default by either party in the intervening period. For this reason, the futures exchange requires both parties to put up an initial amount of cash (performance bond), the margin. Margins, sometimes set as a percentage of the value of the futures contract, need to be proportionally maintained at all times during the life of the contract to underpin this mitigation because the price of the contract will vary in keeping with supply and demand and will change daily and thus one party or the other will theoretically be making or losing money. To mitigate risk and the possibility of default by either party, the product is marked to market on a daily basis whereby the difference between the prior agreed-upon price and the actual daily futures price is settled on a daily basis. This is sometimes known as the variation margin where the futures exchange will draw money out of the losing party's margin account and put it into the other party's thus ensuring that the correct daily loss or profit is reflected in the respective account. If the margin account goes below a certain value set by the Exchange, then a margin call is made and the account owner must replenish the margin account. This process is known as \"marking to market\". Thus on the delivery date, the amount exchanged is not the specified price on the contract but the spot value (i.e., the original value agreed upon, since any gain or loss has already been previously settled by marking to market). Upon marketing the strike price is often reached and creates much income for the \"caller\".\nA closely related contract is a forward contract. A forward is like a futures in that it specifies the exchange of goods for a specified price at a specified future date. However, a forward is not traded on an exchange and thus does not have the interim partial payments due to marking to market. Nor is the contract standardized, as on the exchange.\nUnlike an option, both parties of a futures contract must fulfill the contract on the delivery date. The seller delivers the underlying asset to the buyer, or, if it is a cash-settled futures contract, then cash is transferred from the futures trader who sustained a loss to the one who made a profit. To exit the commitment prior to the settlement date, the holder of a futures position can close out its contract obligations by taking the opposite position on another futures contract on the same asset and settlement date. The difference in futures prices is then a profit or loss.\nMortgage-backed securities.\nA mortgage-backed security (MBS) is an asset-backed security that is secured by a mortgage, or more commonly a collection (\"pool\") of sometimes hundreds of mortgages. The mortgages are sold to a group of individuals (a government agency or investment bank) that \"securitizes\", or packages, the loans together into a security that can be sold to investors. The mortgages of an MBS may be residential or commercial, depending on whether it is an Agency MBS or a Non-Agency MBS; in the United States they may be issued by structures set up by government-sponsored enterprises like Fannie Mae or Freddie Mac, or they can be \"private-label\", issued by structures set up by investment banks. The structure of the MBS may be known as \"pass-through\", where the interest and principal payments from the borrower or homebuyer pass through it to the MBS holder, or it may be more complex, made up of a pool of other MBSs. Other types of MBS include collateralized mortgage obligations (CMOs, often structured as real estate mortgage investment conduits) and collateralized debt obligations (CDOs).\nThe shares of subprime MBSs issued by various structures, such as CMOs, are not identical but rather issued as tranches (French for \"slices\"), each with a different level of priority in the debt repayment stream, giving them different levels of risk and reward. Tranchesespecially the lower-priority, higher-interest tranchesof an MBS are/were often further repackaged and resold as collaterized debt obligations. These subprime MBSs issued by investment banks were a major issue in the subprime mortgage crisis of 2006\u20132008\nThe total face value of an MBS decreases over time, because like mortgages, and unlike bonds, and most other fixed-income securities, the principal in an MBS is not paid back as a single payment to the bond holder at maturity but rather is paid along with the interest in each periodic payment (monthly, quarterly, etc.). This decrease in face value is measured by the MBS's \"factor\", the percentage of the original \"face\" that remains to be repaid.\nOptions.\nIn finance, an option is a contract which gives the \"buyer\" (the owner) the right, but not the obligation, to buy or sell an underlying asset or instrument at a specified strike price on or before a specified date. The \"seller\" has the corresponding obligation to fulfill the transactionthat is to sell or buyif the buyer (owner) \"exercises\" the option. The buyer pays a premium to the seller for this right. An option that conveys to the owner the right to buy something at a certain price is a \"call option\"; an option that conveys the right of the owner to sell something at a certain price is a \"put option\". Both are commonly traded, but for clarity, the call option is more frequently discussed.\nOptions valuation is a topic of ongoing research in academic and practical finance. In basic terms, the value of an option is commonly decomposed into two parts:\nAlthough options valuation has been studied since the 19th century, the contemporary approach is based on the Black\u2013Scholes model, which was first published in 1973.\nOptions contracts have been known for many centuries. However, both trading activity and academic interest increased when, as from 1973, options were issued with standardized terms and traded through a guaranteed clearing house at the Chicago Board Options Exchange. Today, many options are created in a standardized form and traded through clearing houses on regulated options exchanges, while other over-the-counter options are written as bilateral, customized contracts between a single buyer and seller, one or both of which may be a dealer or market-maker. Options are part of a larger class of financial instruments known as derivative products or simply derivatives.\nSwaps.\nA swap is a derivative in which two counterparties exchange cash flows of one party's financial instrument for those of the other party's financial instrument. The benefits in question depend on the type of financial instruments involved. For example, in the case of a swap involving two bonds, the benefits in question can be the periodic interest (coupon) payments associated with such bonds. Specifically, two counterparties agree to the exchange one stream of cash flows against another stream. These streams are called the swap's \"legs\". The swap agreement defines the dates when the cash flows are to be paid and the way they are accrued and calculated. Usually at the time when the contract is initiated, at least one of these series of cash flows is determined by an uncertain variable such as a floating interest rate, foreign exchange rate, equity price, or commodity price.\nThe cash flows are calculated over a notional principal amount. Contrary to a future, a forward or an option, the notional amount is usually not exchanged between counterparties. Consequently, swaps can be in cash or collateral.\nSwaps can be used to hedge certain risks such as interest rate risk, or to speculate on changes in the expected direction of underlying prices.\nSwaps were first introduced to the public in 1981 when IBM and the World Bank entered into a swap agreement. Today, swaps are among the most heavily traded financial contracts in the world: the total amount of interest rates and currency swaps outstanding is more than $348 trillion in 2010, according to the Bank for International Settlements (BIS). The five generic types of swaps, in order of their quantitative importance, are: interest rate swaps, currency swaps, credit swaps, commodity swaps and equity swaps (there are many other types).\nEconomic function of the derivative market.\nSome of the salient economic functions of the derivative market include:\nIn a nutshell, there is a substantial increase in savings and investment in the long run due to augmented activities by derivative market participant.\nValuation.\nMarket and arbitrage-free prices.\nTwo common measures of value are:\nDetermining the market price.\nFor exchange-traded derivatives, market price is usually transparent (often published in real time by the exchange, based on all the current bids and offers placed on that particular contract at any one time). Complications can arise with OTC or floor-traded contracts though, as trading is handled manually, making it difficult to automatically broadcast prices. In particular with OTC contracts, there is no central exchange to collate and disseminate prices.\nDetermining the arbitrage-free price.\nThe arbitrage-free price for a derivatives contract can be complex, and there are many different variables to consider. Arbitrage-free pricing is a central topic of financial mathematics. For futures/forwards the arbitrage free price is relatively straightforward, involving the price of the underlying together with the cost of carry (income received less interest costs), although there can be complexities.\nHowever, for options and more complex derivatives, pricing involves developing a complex pricing model: understanding the stochastic process of the price of the underlying asset is often crucial. A key equation for the theoretical valuation of options is the Black\u2013Scholes formula, which is based on the assumption that the cash flows from a European stock option can be replicated by a continuous buying and selling strategy using only the stock. A simplified version of this valuation technique is the binomial options model.\nOTC represents the biggest challenge in using models to price derivatives. Since these contracts are not publicly traded, no market price is available to validate the theoretical valuation. Most of the model's results are input-dependent (meaning the final price depends heavily on how we derive the pricing inputs).\nTherefore, it is common that OTC derivatives are priced by Independent Agents that both counterparties involved in the deal designate upfront (when signing the contract).\nRisks.\nDerivatives are often subject to the following criticisms; particularly since the 2007\u20132008 financial crisis, the discipline of Risk management has developed attempting to address the below and other risks \u2013 see .\nHidden tail risk.\nAccording to Raghuram Rajan, a former chief economist of the International Monetary Fund (IMF), \"...\u00a0it may well be that the managers of these firms [investment funds] have figured out the correlations between the various instruments they hold and believe they are hedged. Yet as Chan and others (2005) point out, the lessons of summer 1998 following the default on Russian government debt is that correlations that are zero or negative in normal times can turn overnight to one \u2013 a phenomenon they term \"phase lock-in\". A hedged position \"can become unhedged at the worst times, inflicting substantial losses on those who mistakenly believe they are protected\".\nSee the FRTB framework, which seeks to address this to some extent.\nLeverage.\nThe use of derivatives can result in large losses because of the use of leverage, or borrowing. Derivatives allow investors to earn large returns from small movements in the underlying asset's price. However, investors could lose large amounts if the price of the underlying moves against them significantly. There have been several instances of massive losses in derivative markets, such as the following:\nDerivatives typically have a large notional value. As such, there is the danger that their use could result in losses for which the investor would be unable to compensate. The possibility that this could lead to a chain reaction ensuing in an economic crisis was pointed out by famed investor Warren Buffett in Berkshire Hathaway's 2002 annual report. Buffett called them 'financial weapons of mass destruction.' A potential problem with derivatives is that they comprise an increasingly larger notional amount of assets which may lead to distortions in the underlying capital and equities markets themselves. Investors begin to look at the derivatives markets to make a decision to buy or sell securities and so what was originally meant to be a market to transfer risk now becomes a leading indicator.(See Berkshire Hathaway Annual Report for 2002)\nCounterparty risk.\nSome derivatives (especially swaps) expose investors to counterparty risk, or risk arising from the other party in a financial transaction. Counterparty risk results from the differences in the current price versus the expected future settlement price. Different types of derivatives have different levels of counter party risk. For example, standardized stock options by law require the party at risk to have a certain amount deposited with the exchange, showing that they can pay for any losses; banks that help businesses swap variable for fixed rates on loans may do credit checks on both parties. However, in private agreements between two companies, for example, there may not be benchmarks for performing due diligence and risk analysis.\nFinancial reform and government regulation.\nUnder US law and the laws of most other developed countries, derivatives have special legal exemptions that make them a particularly attractive legal form to extend credit. The strong creditor protections afforded to derivatives counterparties, in combination with their complexity and lack of transparency however, can cause capital markets to underprice credit risk. This can contribute to credit booms, and increase systemic risks. Indeed, the use of derivatives to conceal credit risk from third parties while protecting derivative counterparties contributed to the 2007\u20132008 financial crisis in the United States.\nIn the context of a 2010 examination of the ICE Trust, an industry self-regulatory body, Gary Gensler, the chairman of the Commodity Futures Trading Commission which regulates most derivatives, was quoted saying that the derivatives marketplace as it functions now \"adds up to higher costs to all Americans\". More oversight of the banks in this market is needed, he also said. Additionally, the report said, \"[t]he Department of Justice is looking into derivatives, too. The department's antitrust unit is actively investigating 'the possibility of anticompetitive practices in the credit derivatives clearing, trading and information services industries', according to a department spokeswoman.\"\nFor legislators and committees responsible for financial reform related to derivatives in the United States and elsewhere, distinguishing between hedging and speculative derivatives activities has been a nontrivial challenge. The distinction is critical because regulation should help to isolate and curtail speculation with derivatives, especially for \"systemically significant\" institutions whose default could be large enough to threaten the entire financial system. At the same time, the legislation should allow for responsible parties to hedge risk without unduly tying up working capital as collateral that firms may better employ elsewhere in their operations and investment. \nIn this regard, it is important to distinguish between financial (e.g. banks) and non-financial end-users of derivatives (e.g. real estate development companies) because these firms' derivatives usage is inherently different. More importantly, the reasonable collateral that secures these different counterparties can be very different. The distinction between these firms is not always straight forward (e.g., hedge funds or even some private equity firms do not neatly fit either category). Finally, even financial users must be differentiated, as 'large' banks may classified as \"systemically significant\" whose derivatives activities must be more tightly monitored and restricted than those of smaller, local and regional banks.\nOver-the-counter dealing will be less common as the Dodd\u2013Frank Wall Street Reform and Consumer Protection Act comes into effect. The law mandated the clearing of certain swaps at registered exchanges and imposed various restrictions on derivatives. To implement Dodd-Frank, the CFTC developed new rules in at least 30 areas. The Commission determines which swaps are subject to mandatory clearing and whether a derivatives exchange is eligible to clear a certain type of swap contract.\nNonetheless, the above and other challenges of the rule-making process have delayed full enactment of aspects of the legislation relating to derivatives. The challenges are further complicated by the necessity to orchestrate globalized financial reform among the nations that comprise the world's major financial markets, a primary responsibility of the Financial Stability Board whose progress is ongoing.\nIn the U.S., by February 2012 the combined effort of the SEC and CFTC had produced over 70 proposed and final derivatives rules. However, both of them had delayed adoption of a number of derivatives regulations because of the burden of other rule-making, litigation and opposition to the rules, and many core definitions (such as the terms \"swap\", \"security-based swap\", \"swap dealer\", \"security-based swap dealer\", \"major swap participant\" and \"major security-based swap participant\") had still not been adopted. SEC Chairman Mary Schapiro opined: \"At the end of the day, it probably does not make sense to harmonize everything [between the SEC and CFTC rules] because some of these products are quite different and certainly the market structures are quite different.\" On February 11, 2015, the Securities and Exchange Commission (SEC) released two final rules toward establishing a reporting and public disclosure framework for security-based swap transaction data. The two rules are not completely harmonized with the requirements with CFTC requirements.\nIn November 2012, the SEC and regulators from Australia, Brazil, the European Union, Hong Kong, Japan, Ontario, Quebec, Singapore, and Switzerland met to discuss reforming the OTC derivatives market, as had been agreed by leaders at the 2009 G-20 Pittsburgh summit in September 2009. In December 2012, they released a joint statement to the effect that they recognized that the market is a global one and \"firmly support the adoption and enforcement of robust and consistent standards in and across jurisdictions\", with the goals of mitigating risk, improving transparency, protecting against market abuse, preventing regulatory gaps, reducing the potential for arbitrage opportunities, and fostering a level playing field for market participants. They also agreed on the need to reduce regulatory uncertainty and provide market participants with sufficient clarity on laws and regulations by avoiding, to the extent possible, the application of conflicting rules to the same entities and transactions, and minimizing the application of inconsistent and duplicative rules. At the same time, they noted that \"complete harmonization \u2013 perfect alignment of rules across jurisdictions\" would be difficult, because of jurisdictions' differences in law, policy, markets, implementation timing, and legislative and regulatory processes.\nOn December 20, 2013, the CFTC provided information on its swaps regulation \"comparability\" determinations. The release addressed the CFTC's cross-border compliance exceptions. Specifically it addressed which entity level and in some cases transaction-level requirements in six jurisdictions (Australia, Canada, the European Union, Hong Kong, Japan, and Switzerland) it found comparable to its own rules, thus permitting non-US swap dealers, major swap participants, and the foreign branches of US Swap Dealers and major swap participants in these jurisdictions to comply with local rules in lieu of Commission rules.\nReporting.\nMandatory reporting regulations are being finalized in a number of countries, such as Dodd Frank Act in the US, the European Market Infrastructure Regulations (EMIR) in Europe, as well as regulations in Hong Kong, Japan, Singapore, Canada, and other countries. The OTC Derivatives Regulators Forum (ODRF), a group of over 40 worldwide regulators, provided trade repositories with a set of guidelines regarding data access to regulators, and the Financial Stability Board and CPSS IOSCO also made recommendations in with regard to reporting.\nDTCC, through its \"Global Trade Repository\" (GTR) service, manages global trade repositories for interest rates, and commodities, foreign exchange, credit, and equity derivatives. It makes global trade reports to the CFTC in the U.S., and plans to do the same for ESMA in Europe and for regulators in Hong Kong, Japan, and Singapore. It covers cleared and uncleared OTC derivatives products, whether or not a trade is electronically processed or bespoke."}
{"id": "9136", "revid": "32904124", "url": "https://en.wikipedia.org/wiki?curid=9136", "title": "Disney (disambiguation)", "text": "Disney is a name colloquially given to The Walt Disney Company, an American diversified multinational mass media and entertainment conglomerate.\nDisney may also refer to:"}
{"id": "9137", "revid": "1269335364", "url": "https://en.wikipedia.org/wiki?curid=9137", "title": "Divine right of kings", "text": "Divine right of kings, divine right, or God's mandation, is a political and religious doctrine of political legitimacy of a monarchy in Western Christianity up until the Enlightenment. It is also known as the divine-right theory of kingship.\nThe doctrine asserts that a monarch is not accountable to any earthly authority (such as a parliament or the Pope) because their right to rule is derived from divine authority. Thus, the monarch is not subject to the will of the people, of the aristocracy, or of any other estate of the realm. It follows that only divine authority can judge a monarch, and that any attempt to depose, dethrone, resist or restrict their powers runs contrary to God's will and may constitute a sacrilegious act. It does not imply that their power is absolute.\nIn its full-fledged form, the Divine Right of Kings is associated with Henry VIII of England (and the Acts of Supremacy), James VI and I of Scotland and England, Louis XIV of France, and their successors. \nIn contrast, the conception of human rights started being developed during the Middle Ages by scholars such as St. Thomas Aquinas (see Natural Law) and were systematised by the thinkers of the Age of Enlightenment, e.g. John Locke. Liberty, dignity, freedom and equality are examples of important human rights.\nConcept.\nDivine right has been a key element of the self-legitimization of many absolute monarchies, connected with their authority and right to rule. Related but distinct notions include Caesaropapism (the complete subordination of bishops etc. to the secular power), Supremacy (the legal sovereignty of the civil laws over the laws of the Church), Absolutism (a form of monarchical or despotic power that is unrestrained by all other institutions, such as churches, legislatures, or social elites) or Tyranny (an absolute ruler who is unrestrained even by moral law). \nHistorically, many notions of rights have been authoritarian and hierarchical, with different people granted different rights and some having more rights than others. For instance, the right of a father to receive respect from his son did not indicate a right for the son to receive a return from that respect. Analogously, the divine right of kings, which permitted absolute power over subjects, provided few rights for the subjects themselves.\nIt is sometimes signified by the phrase \"by the Grace of God\" or its Latin equivalent, \"Dei Gratia\", which has historically been attached to the titles of certain reigning monarchs. Note, however, that such accountability only to God does not \"per se\" make the monarch a sacred king.\nReligious traditions.\nHinduism.\nThe Hindu text Mahabharata contains several concepts of kingship, especially underscoring its divine origins. The king is considered an embodiment of Indra, and fealty to him is considered as submitting to divine authority. In the Rajadharmanusasana Parva, Bhishma talks of the period before men had kings, and there was chaos all around - \nThe Mahabharata also mentions that in a land without king or royal authority, Vedic rituals are ineffectual and Agni does not convey sacrificial libations to the gods.\nZoroastrianism (Iranian world).\nKhvarenah (also spelled \"khwarenah\" or \"xwarra(h)\": \"\"; ) is an Iranian and Zoroastrian concept, which literally means \"glory\", about divine right of the kings. This may stem from early Mesopotamian culture, where kings were often regarded as deities after their death. Shulgi of Ur was among the first Mesopotamian rulers to declare himself to be divine. In the Iranian view, kings would never rule, unless Khvarenah is with them, and they will never fall unless Khvarenah leaves them. For example, according to the \"Kar-namag of Ardashir,\" when Ardashir I of Persia and Artabanus V of Parthia fought for the throne of Iran, on the road Artabanus and his contingent are overtaken by an enormous ram, which is also following Ardashir. Artabanus's religious advisors explain to him that the ram is the manifestation of the \"khwarrah\" of the ancient Iranian kings, which is leaving Artabanus to join Ardashir.\nJudaism.\nWhile the earliest references to kingship among Israel in the Hebrew Bible proclaim that 14.When you come to the land that the Lord your God is giving you, and you possess it and dwell in it and then say, 'I will set a king over me, like all the nations that are around me'. \n15. You may indeed set a king over you whom the Lord your God will choose. One from among your brothers you shall set as king over you. You may not put a foreigner over you, who is not your brother.(Deut 17:14-15). Significant debate on the legitimacy of kingship has persisted in Rabbinical Judaism until Maimonides, though many mainstream currents continue to reject the notion. \nThe controversy is highlighted by the instructions to the Israelites in the above-quoted passage, as well as the passages in 1 Samuel 8 and 12, concerning the dispute over kingship; and \"Perashat Shoftim.\" It is from 1 Samuel 8 that the people of Israel receive \"mishpat ha-melech,\" the \"ius regium\", or the law of kingship, and from this passage that Maimonides finally concludes that Judaism supports the institution of monarchy, stating that the Israelites had been given three commandments upon entering the Promised Land - to designate a king for themselves, to wipe out the memory of Amalek, and to build the Temple. \nThe debate has primarily centered around the problem of being told to \"designate\" a king, which some rabbinical sources have argued is an invocation \"against\" a divine right of kings, and a call to elect a leader, in opposition to a notion of a divine right. Other rabbinical arguments have put forward an idea that it is through the collective decision of the people that God's will is made manifest, and that the king does therefore have a divine right - once appointed by the nation, he is God's emissary. \nJewish law requires one to recite a special blessing upon seeing a monarch: \"Blessed are You, L\u2011rd our G\u2011d, King of the universe, Who has given from His glory to flesh and blood\".\nChristianity.\nThe Christian notion of a divine right of kings is traced to a story found in 1 Samuel, where the prophet Samuel anoints Saul and then David as \"Messiah\" (\"anointed one\")\u2014king over Israel. In Jewish traditions, the lack of a divine leadership represented by an anointed king, beginning shortly after the death of Joshua, left the people of Israel vulnerable, and the promise of the \"promised land\" was not fully fulfilled until a king was anointed by a prophet on behalf of God.\nThe effect of anointing was seen to be that the monarch became inviolable, so that even when Saul sought to kill David, David would not raise his hand against him because \"he was the Lord's anointed\". Raising a hand to a king was therefore considered to be as sacrilegious as raising a hand against God and stood on equal footing as blasphemy. In essence, the king stood in place of God and was never to be challenged \"without the challenger being accused of blasphemy\" \u2013 except by a prophet, which under Christianity was replaced by the church.\nPre-Modern history.\nWith the rise of firearms, nation-states and the Protestant Reformation in the late 16th century, the theory of divine right justified the king's absolute authority in both political and spiritual matters. Henry VIII of England declared himself the Supreme Head of the Church of England and exerted the power of the throne more than any of his predecessors. \nAs a political theory, it was further developed by James VI of Scotland (1567\u20131625) and came to the fore in England under his reign as James I of England (1603\u20131625). Louis XIV of France (1643\u20131715) strongly promoted the theory as well.\nHistorian J. P. Sommerville stresses the theory was polemic: \"Absolutists magnified royal power. They did this to protect the state against anarchy and to refute the ideas of resistance theorists\", those being in Britain Catholic and Presbyterian theorists.\nThe concept of divine right incorporates, but exaggerates, the ancient Christian concept of \"royal God-given rights\", which teach that \"the right to rule is anointed by God\", although this idea is found in many other cultures, including Aryan and Egyptian traditions. \nMedieval Era.\nOutside of Christianity, kings were often seen as ruling with the backing of heavenly powers. \nEarly Middle Ages.\nAlthough the later Roman Empire had developed the European concept of a divine regent in Late Antiquity, Adomnan of Iona provides one of the earliest written examples of a Western medieval concept of kings ruling with divine right. He wrote of the Irish King Diarmait mac Cerbaill's assassination and claimed that divine punishment fell on his assassin for the act of violating the monarch. \nAdomnan also recorded a story about Saint Columba supposedly being visited by an angel carrying a glass book, who told him to ordain Aedan mac Gabrain as King of Dal Riata. Columba initially refused, and the angel answered by whipping him and demanding that he perform the ordination because God had commanded it. The same angel visited Columba on three successive nights. Columba finally agreed, and Aedan came to receive ordination. At the ordination, Columba told Aedan that so long as he obeyed God's laws, then none of his enemies would prevail against him, but the moment he broke them, this protection would end, and the same whip with which Columba had been struck would be turned against the king. \nAdomnan's writings most likely influenced other Irish writers, who in turn influenced continental ideas as well. Pepin the Short's coronation may have also come from the same influence. The Byzantine Empire can be seen as the progenitor of this concept (which began with Constantine I). This in turn inspired the Carolingian dynasty and the Holy Roman Emperors, whose lasting impact on Western and Central Europe further inspired all subsequent Western ideas of kingship.\nHigh Middle Ages.\nIn the Middle Ages, the idea that God had granted certain earthly powers to the monarch, just as he had given spiritual authority and power to the church, especially to the Pope, was already a well-known concept long before later writers coined the term \"divine right of kings\" and employed it as a theory in political science. \nHowever, the dividing line for the authority and power was a subject of frequent contention: notably in England with the murder of Archbishop Thomas Beckett (1170). For example, Richard I of England declared at his trial during the diet at Speyer in 1193: \", and it was Richard who first used the motto \" (\"God and my right\") which is still the motto of the Monarch of the United Kingdom.\nThomas Aquinas condoned extra-legal tyrannicide in the worst of circumstances:\nOn the other hand, Aquinas forbade the overthrow of any morally, Christianly and spiritually legitimate king by his subjects. The only human power capable of deposing the king was the pope. The reasoning was that if a subject may overthrow his superior for some bad law, who was to be the judge of whether the law was bad? If the subject could so judge his own superior, then all lawful superior authority could lawfully be overthrown by the arbitrary judgement of an inferior, and thus all law was under constant threat.\nAccording to John of Paris, kings had their jurisdictions and bishops (and the pope) had theirs, but kings derived their supreme, non-absolute temporal jurisdiction from popular consent.\nLate Middle Ages and Renaissance.\nThe Church was the final guarantor that Christian kings would follow the laws and constitutional traditions of their ancestors and the laws of God and of justice.\nRadical English theologian John Wycliffe's theory of Dominium meant that injuries inflicted on someone personally by a king should be born by them submissively, a conventional idea, but that injuries by a king against God should be patiently resisted even to death; gravely sinful kings and popes forfeited their (divine) right to obedience and ownership, though the political order should be maintained. More aggressive versions of this were taken up by Lollards and Hussites.\nFor Erasmus of Rotterdam it was the consent of the people which gives and takes away \"the purple\", not an unchangeable divine mandate.\nCatholic limits.\nCatholic jurisprudence holds that the monarch is always subject to natural and divine law, which are regarded as superior to the monarch. \nThe possibility of monarchy declining morally, overturning natural law, and degenerating into a tyranny oppressive of the general welfare was answered theologically with the Catholic concept of the spiritual superiority of the Pope (there is no \"Catholic concept of extra-legal tyrannicide\", as some falsely suppose, the same being expressly condemned by St Thomas Aquinas in chapter 7 of his \"De Regno\"). \nCatholic thought justified limited submission to the monarchy by reference to the following:\nConceptions in the early modern period.\nReformation Era.\nThe divine right of kings, or divine-right theory of kingship, is a political and religious doctrine of royal and political legitimacy. It asserts that a monarch is subject to no earthly authority, deriving his right to rule directly from the will of God. The king is thus not subject to the will of his people, the aristocracy, or any other estate of the realm, including (in the view of some, especially in Protestant countries) the church.\nA weaker or more moderate form of this political theory does hold, however, that the king is subject to the church and the pope, although completely irreproachable in other ways; but according to this doctrine in its strong form, only God can judge an unjust king. \nThe doctrine implies that any attempt to depose the king or to restrict his powers runs contrary to the will of God and may constitute a sacrilegious act.\nBefore the Reformation the anointed king was, within his realm, the accredited vicar of God for secular purposes (see the Investiture Controversy); after the Reformation he (or she if queen regnant) became this in Protestant states for religious purposes also.\nKingdom of Scotland.\nThe Scots textbooks of the divine right of kings were written in 1597\u20131598 by James VI of Scotland. His \"Basilikon Doron\", a manual on the powers of a king, was written to edify his four-year-old son Henry Frederick that a king \"acknowledgeth himself ordained for his people, having received from God a burden of government, whereof he must be countable\". \nThe conception of ordination brought with it largely unspoken parallels with the Anglican and Catholic priesthood, but the overriding metaphor in James VI's 'Basilikon Doron' was that of a father's relation to his children. \"Just as no misconduct on the part of a father can free his children from obedience to the fifth commandment.\"\nKingdom of England.\nJames, after becoming James I of England, also had printed his \"Defense of the Right of Kings\" in the face of English theories of inalienable popular and clerical rights. \nHe based his theories in part on his understanding of the Bible, as noted by the following quote from a speech to parliament delivered in 1610 as James I of England:\nJames's reference to \"God's lieutenants\" is apparently a reference to the text in Romans 13 where Paul refers to \"God's ministers\".\nCeremonial conflation.\nSome of the symbolism within the coronation ceremony for British monarchs, in which they are anointed with holy oils by the Archbishop of Canterbury, thereby \"ordaining\" them to monarchy, perpetuates the ancient Roman Catholic monarchical ideas and ceremonial (although few Protestants realize this, the ceremony is nearly entirely based upon that of the Coronation of the Holy Roman Emperor). However, in the UK, the symbolism ends there since the real governing authority of the monarch was all but extinguished by the Whig revolution of 1688\u201389 (see Glorious Revolution). The king or queen of the United Kingdom is one of the last monarchs still to be crowned in the traditional Christian ceremonial, which in most other countries has been replaced by an inauguration or other declaration.\nIn England, it is not without significance that the sacerdotal vestments, generally discarded by the clergy \u2013 dalmatic, alb and stole \u2013 continued to be among the insignia of the sovereign (see Coronation of the British monarch). Moreover, this sacrosanct character he acquired not by virtue of his \"sacring\", but by hereditary right; the coronation, anointing and vesting were but the outward and visible symbol of a divine grace adherent in the sovereign by virtue of his title. Even Roman Catholic monarchs, like Louis XIV, would never have admitted that their coronation by the archbishop constituted any part of their title to reign; it was no more than the consecration of their title.\nKingdom of France.\nThe French prelate Jacques-B\u00e9nigne Bossuet made a classic statement of the doctrine of divine right in a sermon preached before King Louis XIV:\nThe French Huguenot nobles and clergy, having rejected the pope and the Catholic Church, were left only with the supreme power of the king who, they taught, could not be gainsaid or judged by anyone. Since there was no longer the countervailing power of the papacy and since the Church of England was a creature of the state and had become subservient to it, this meant that there was nothing to regulate the powers of the king, and he became an absolute power. In theory, divine, natural, customary, and constitutional law still held sway over the king, but, absent a superior spiritual power, it was difficult to see how they could be enforced since the king could not be tried by any of his own courts.\nHoly Roman Empire.\nOne passage in scripture supporting the idea of the divine right of kings was used by Martin Luther, when urging the secular authorities to crush the Peasant Rebellion of 1525 in Germany in his \"Against the Murderous, Thieving Hordes of Peasants\", basing his argument on Paul's Epistle to the Romans.\nIt is related to the ancient Catholic philosophies regarding monarchy, in which the monarch is God's vicegerent upon the earth and therefore subject to no inferior power.\nReligious Opposition.\nIn the sixteenth century, both Catholic and Protestant political thinkers alike challenged the idea of a monarch's \"divine right\".\nCatholic.\nThe Spanish Catholic historian Juan de Mariana put forward the argument in his book \"De rege et regis institutione\" (1598) that since society was formed by a \"pact\" among all its members, \"there can be no doubt that they are able to call a king to account\". Mariana thus challenged divine right theories by stating in certain circumstances, tyrannicide could be justified. \nCardinal Robert Bellarmine also \"did not believe that the institute of monarchy had any divine sanction\" and shared Mariana's belief that there were times where Catholics could lawfully remove a monarch.\nProtestant.\nAmong groups of English Protestant exiles fleeing from Queen Mary I, some of the earliest anti-monarchist publications emerged. \"Weaned off uncritical royalism by the actions of Queen Mary ... The political thinking of men like Ponet, Knox, Goodman and Hales.\"\nIn 1553, Mary I, a Roman Catholic, succeeded her Protestant half-brother, Edward VI, to the English throne. Mary set about trying to restore Roman Catholicism by making sure that: Edward's religious laws were abolished in the Statute of Repeal Act (1553); the Protestant religious laws passed in the time of Henry VIII were repealed; and the Revival of the Heresy Acts were passed in late 1554. \nWhen Thomas Wyatt the Younger instigated what became known as Wyatt's rebellion in early 1554, John Ponet, the highest-ranking ecclesiastic among the exiles, allegedly participated in the uprising. He escaped to Strasbourg after the Rebellion's defeat and, the following year, he published \"A Shorte Treatise of Politike Power\", in which he put forward a theory of justified opposition to secular rulers.\nPonet's pamphlet was republished on the eve of King Charles I's execution.\nPeak and decline.\nPre-Enlightenment.\nIn England the doctrine of the divine right of kings was developed to its most extreme logical conclusions during the political controversies of the 17th century; its most famous exponent was Sir Robert Filmer. It was the main issue to be decided by the English Civil War, the Royalists holding that \"all Christian kings, princes and governors\" derive their authority direct from God, the Parliamentarians that this authority is the outcome of a contract, actual or implied, between sovereign and people.\nIn one case the king's power would be unlimited, according to the famous saying misattributed to Louis XIV: \"L' \u00e9tat, c'est moi\", or limited only by his own free act; in the other his actions would be governed by the advice and consent of the people, to whom he would be ultimately responsible. The victory of this latter principle was proclaimed to all the world by the execution of Charles I. \nThe doctrine of divine right, indeed, for a while drew nourishment from the blood of the royal \"martyr\"; it was the guiding principle of the Anglican Church of the Restoration; but it suffered a rude blow when James II of England made it impossible for the clergy to obey both their conscience and their king. \nThe Glorious Revolution of 1688 made an end of it as a great political force. This has led to the constitutional development of the Crown in Britain, as held by descent modified and modifiable by parliamentary action.\nEnlightenment era.\nU.S. Founding Father John Adams considered John Ponet's work to have contained \"all the essential principles of liberty, which were afterward dilated on by Sidney and Locke\", including the idea of a three-branched government.\nOver time, opposition to the divine right of kings came from a number of sources, including poet John Milton in his pamphlet \"The Tenure of Kings and Magistrates\", and Thomas Paine in his pamphlet \"Common Sense\". By 1700 an Anglican \nArchbishop was prepared to assert that Kings hold their Crowns by \nlaw alone, and the law may forfeit them. \nProbably the two most famous declarations of a right to revolution against tyranny in the English language are John Locke's \"Essay concerning The True Original, Extent, and End of Civil-Government\" and Thomas Jefferson's formulation in the United States Declaration of Independence that \"all men are created equal\"."}
{"id": "9138", "revid": "1271801930", "url": "https://en.wikipedia.org/wiki?curid=9138", "title": "Davros", "text": "Davros () is a fictional character from the long-running British science fiction television series \"Doctor Who\". He was created by screenwriter Terry Nation, originally for the 1975 serial \"Genesis of the Daleks\". Davros is a major enemy of the series' protagonist, the Doctor, and is the creator of the Doctor's deadliest enemies, the Daleks. Davros is a genius who has mastered many areas of science, but also a megalomaniac who believes that through his creations he can become the supreme being and ruler of the Universe. The character has been compared to the infamous dictator Adolf Hitler several times, including by the actor Terry Molloy, while Julian Bleach defined him as a cross between Hitler and the renowned scientist Stephen Hawking.\nDavros is from the planet Skaro, whose people, the Kaleds, were engaged in a bitter thousand-year war of attrition with their enemies, the Thals. He is horribly scarred and disabled, a condition that various spin-off media attribute to his laboratory being attacked by a Thal shell. He has one functioning hand and one cybernetic eye mounted on his forehead to take the place of his real eyes, which he is not able to open for long; for much of his existence he depends completely upon a self-designed mobile life-support chair in place of his lower body. It would become an obvious inspiration for his eventual design of the Dalek. The lower half of his body is absent and he is physically incapable of leaving the chair for more than a few minutes without dying. Davros' voice, like those of the Daleks, is electronically distorted. His manner of speech is generally soft and contemplative, but when angered or excited he is prone to ranting outbursts that resemble the hysterical, staccatissimo speech of the Daleks.\nConcept.\nDavros first appeared in the 1975 serial \"Genesis of the Daleks\", written by Terry Nation. Nation, creator of the Dalek concept, had deliberately modelled elements of the Daleks' character on Nazi ideology, and conceived of their creator as a scientist with strong fascist tendencies. The physical appearance of Davros was developed by visual effects designer Peter Day and sculptor John Friedlander, who based Davros' chair on the lower half of a Dalek. Producer Philip Hinchcliffe told Friedlander to consider a design similar to the Mekon from the \"Eagle\" comic \"Dan Dare\", with a large dome-like head and a withered body.\nCast in the role of Davros was Michael Wisher, who had previously appeared in several different roles on \"Doctor Who\" and had provided Dalek voices in the serials \"Frontier in Space\", \"Planet of the Daleks\" and \"Death to the Daleks\". Wisher based his performance as Davros on the philosopher Bertrand Russell. In order to prepare for filming under the heavy mask, Wisher rehearsed wearing a paper bag over his head. Friedlander's mask was cast in hard latex, with only the mouth revealing Wisher's features; make-up artist Sylvia James shaded the mask's tones and blackened Wisher's lips and teeth to hide the transition.\nIn the serial \"Destiny of the Daleks\", Davros is played by David Gooderson using the mask Friedlander made for Wisher after it was split into intersecting sections to get as good a fit as possible. When Terry Molloy took over the role in \"Resurrection of the Daleks\", a new mask was designed by Stan Mitchell.\nIn 2023, Julian Bleach, who played the character in four episodes of the revived series, reprised the role of Davros for a minisode aired during \"Children in Need\", informally titled \"Destination: Skaro\", in which Davros is depicted as non-disabled and without scarring. In an interview for \"\", executive producer Russell T. Davies said that this is how Davros will be depicted in future appearances, to avoid contributing to harmful tropes of disabled villains in media.\nThe decision to portray Davros as an able-bodied character received a divisive reception from fans.\nCharacter history.\nEncounters with the Fourth Doctor.\nThe Fourth Doctor (Tom Baker) first encountered Davros (Michael Wisher) in \"Genesis of the Daleks\" when he and his companions were sent to Skaro to avert the creation of the Daleks. As chief scientist of the Kaleds and leader of their elite scientific division, Davros devised new military strategies in order to win his people's thousand-year war against the Thal race that also occupies Skaro. When Davros learned his people were evolving from exposure to nuclear weapons, chemical weapons and biological weapons used in the war, he artificially accelerates the process to his design and stores the resulting tentacled creatures in tank-like \"Mark III travel machines\" partly based on the design of his wheelchair. He later names these creatures \"Daleks\", an anagram of Kaleds.\nDavros quickly becomes obsessed with his creations, considering them to be the ultimate form of life compared to others. When other Kaleds attempted to thwart his project, Davros arranges the extinction of his own people by using the Thals, whom he mostly killed with the Daleks later. Davros then weeds out those in elite scientific division who are loyal to him so he can have the Daleks eliminate the rest. However, the Daleks ultimately turn on Davros, killing his supporters before shooting him when he tries to halt the Dalek production line.\nIn \"Destiny of the Daleks\", it is revealed that Davros (now played by David Gooderson) was not killed, but placed in suspended animation and buried underground in the destruction of his bunker. The Daleks unearth their creator to help them break a logical impasse in their war against the android Movellans. However, the Dalek force is destroyed by the Doctor, and Davros is captured and imprisoned in suspended animation by the humans, before being taken to Earth to face trial.\nThe Dalek Civil War.\nIn the Fifth Doctor story \"Resurrection of the Daleks\", Davros (Terry Molloy) is released from his space station prison by a small Dalek force aided by human mercenaries and Dalek duplicates. The Daleks require Davros to find an antidote for a Movellan-created virus that has all but wiped them out. Believing his creations to be treacherous, Davros begins using a syringe-like mind control device hidden in a secret compartment in his wheelchair on Daleks and humans; he ultimately releases a sample of the virus to kill off the Daleks before they can exterminate him. Davros expresses a desire to build a new and improved race of Daleks, but he apparently succumbs to the virus himself, his physiology being close enough to that of the Daleks for the virus to affect him.\nIn the Sixth Doctor story \"Revelation of the Daleks\", it is revealed that Davros managed to escape at the end of \"Resurrection\" and has gone into hiding as \"The Great Healer\" of the funeral and cryogenic preservation centre Tranquil Repose on the planet Necros. There, creating a clone of his head to serve as a decoy while modifying his body so that it can fire electric bolts and his chair is able to hover, Davros uses the more intelligent frozen bodies to engineer a new variety of white armoured Daleks loyal to him (while using the lesser intellects as food for the galaxy, ending a galaxy-wide famine), but he is captured by the original Daleks and taken to Skaro to face trial.\nDavros' final classic appearance is as the Emperor Dalek in \"Remembrance of the Daleks\", with his white and gold Daleks now based on Skaro and termed \"Imperial Daleks\", fighting against the grey \"Renegade Dalek\" faction, who answer to the Dalek Supreme. By this time, Davros has been physically transplanted into a customised Dalek casing. He is only revealed to be the Emperor in the final episode. Both Skaro and the Imperial Dalek mothership are apparently destroyed (in the future) when the Seventh Doctor tricks Davros into using the Time Lord artefact known as the Hand of Omega, which makes Skaro's Sun go supernova, before homing in on their mothership. Davros flees into an escape pod as the ship explodes.\nThe Time War and the Reality Bomb.\nDuring the revived series, Davros was referred to in the episode \"Dalek\" (2005) by the Ninth Doctor (Christopher Eccleston), who explains to Henry Van Statten that the Daleks were created by \"a genius... a man who was king of his own little world\", and again by the Tenth Doctor (David Tennant) in the episode \"Evolution of the Daleks\" (2007), where he refers to the Daleks' creator as believing that \"removing emotions makes you stronger\". Davros makes his first physical appearance in the episode \"The Stolen Earth\" (2008), portrayed by Julian Bleach. The episode reveals that Davros was thought to have died during the first year of the Time War, when his command ship \"flew into the jaws of the Nightmare Child\" at the Gates of Elysium, despite the Doctor's failed efforts to save him. But Davros was pulled out of the time lock of the war by Dalek Caan (voiced by Nicholas Briggs), using his own flesh to create a \"new empire\" of Daleks who place him in the Vault as their prisoner to make use of his knowledge. Under Davros' guidance, the Daleks steal 27 planets, including Earth, and hide them in the Medusa Cascade, one second out of sync with the rest of the universe.\nIn the follow-up episode \"Journey's End\" (2008), it is revealed that the stolen planets are required as a power source for Davros' ideal final solution: the Reality Bomb, which produces a wavelength that would cancel out the electrical field binding atoms to reduce all life outside the Crucible into nothingness in both his universe and countless other realities. But Davros learns too late that Dalek Caan, who came to the realisation of his race's atrocities as a consequence of saving his creator, used his prophecies and influence to ensure the Daleks' destruction while manipulating events to bring the Tenth Doctor and Donna Noble (Catherine Tate) together for the role the latter would play. Though the Doctor attempts to save him, having earlier taunted the Doctor for turning his companions into killers and being the cause of the deaths of countless people during his travels, Davros furiously refuses the Doctor's help and accuses him of being responsible for the destruction while screaming: \"Never forget, Doctor, you did this! I name you forever: \"You\" are the Destroyer of Worlds!\" Thus the Doctor is forced to leave Davros to his supposed fate as the Crucible self-destructs.\nRemembering the Twelfth Doctor.\nDavros returns in the two-part Series 9 opening \"The Magician's Apprentice\" and \"The Witch's Familiar\" (2015), having escaped the Crucible's destruction and ending up on a restored Skaro with his life being prolonged by the Daleks. But when the aged Davros' health begins to fail, he remembers his childhood self, played by Joey Price, meeting the Twelfth Doctor (Peter Capaldi) during the Kaleds' thousand-year war prior to \"Genesis of the Daleks\". The young Davros finds himself lost on the battlefield and surrounded by handmines, with the Doctor throwing his sonic screwdriver to the boy with the intent to save him before learning his name and leaving the child to his fate. Davros, seeking a final revenge on the Doctor, employs the snake-like Colony Sarff (Jami Reid-Quarrell) to bring him to Skaro. When it appears that the Doctor has lost his companion Clara Oswald (Jenna Coleman) to the Daleks, Davros manages to trick the Doctor into using his regeneration energy to heal him, extending his own life while infusing every Dalek on Skaro with the energy. But the Doctor reveals Davros' scheme has also revitalised the decomposing-yet-still-alive Daleks left to rot in Skaro's sewers, causing them to revolt and destroy the city. The Doctor then discovers the Daleks have a concept of mercy and are allowed to have the word in their vocabulary when he encounters Clara, having been placed in a Dalek casing by Missy (Michelle Gomez). The Doctor and Clara escape, the former having an epiphany as to how Davros somehow put a sliver of compassion into the Daleks. He then returns to the battlefield in Davros' childhood, using a Dalek gun to destroy the handmines with the one bit of compassion in Davros' life instilled in the Daleks' design to ensure Clara being saved.\nThe Fourteenth Doctor.\nIn the \"Children in Need\" sketch \"\" (2023) (which takes place during an earlier time in the Kaled-Thal war), Davros (Julian Bleach) (who has not yet become disfigured or received the cybernetic eye) is seen presenting a Dalek prototype featuring a robotic claw to his assistant, Castavillian. When he briefly departs to attend to an urgent matter, the Fourteenth Doctor lands in the TARDIS, accidentally destroying the robotic claw. He inadvertently suggests the name \"Dalek\" for the prototype, mentions its catchphrase of \"exterminate\" and gives Castavillian a plunger-tipped arm as a replacement for the broken claw. Once he realises that he has accidentally assisted with the creation of his greatest enemy, he quickly departs saying that he was \"never here\". Davros returns and approves of the new plunger arm.\nOther appearances.\nComic strips.\n\"Doctor Who Magazine\" printed several comics stories involving Davros. The first, \"Nemesis of the Daleks\" (#152\u2013155), with the Seventh Doctor, features an appearance of a Dalek Emperor. Speaking with the Emperor, the Doctor addresses him as Davros, but the Emperor responds \"Who is Davros?\" The Doctor initially assumes Davros' personality has been totally subsumed, but in the later strip \"Emperor of the Daleks\" (#197\u2013202) this Emperor is shown as a different entity from Davros. Set prior to \"Remembrance of the Daleks\" in Davros' timeline, but after in the timeline of the Doctor, the latter, accompanied by Bernice Summerfield, together with help from the Sixth Doctor, ensures that Davros will survive the wrath of the Daleks so that he can assume the title of Emperor, allowing history to take its course. \"Up Above the Gods\" (#227), a vignette following up on this, features the Sixth Doctor and Davros having a conversation in the TARDIS.\nAudio plays.\nTerry Molloy has reprised his role as Davros in the spin-off audio plays produced by Big Finish Productions, mostly notably \"Davros\" (taking place during the Sixth Doctor's era), which, through flashbacks, explored the scientist's life prior to his crippling injury, which is attributed to a Thal nuclear attack (an idea that first appeared in Terrance Dicks' novelisation of \"Genesis of the Daleks\").\n\"Davros\", which does not feature the Daleks, apparently fills in the gaps between \"Resurrection of the Daleks\" and \"Revelation of the Daleks\", and has the scientist trying to manipulate the galaxy's economy into a war footing similar to Skaro's. The Sixth Doctor manages to defeat his plans, and Davros is last heard when his ship explodes, an event obliquely mentioned in \"Revelation\". However the Doctor thinks he has survived. Davros also mentions he will work on a plan to combat famine, tying into \"Revelation of the Daleks\".\n\"The Davros Mission\" is an original audio adventure (without the Doctor) available on \"The Complete Davros Collection\" DVD box set. It takes place directly after the television story \"Revelation\", while leaving the planet Necros and beginning Davros' trial. At the end of \"Davros Mission\", he turns the tables on the Daleks, forcing them to do his bidding. The Big Finish miniseries \"I, Davros\", also features trial scenes, but mostly explores his early life. In those four stories, his journey is seen from his boyhood, to just before \"Genesis of the Daleks\".\n\"The Curse of Davros\" begins with Davros and the Daleks working together to try and alter the outcome of the Battle of Waterloo using technology that Davros has created that allows him to swap peoples' minds, allowing him to switch various soldiers in Napoleon's army with his own Daleks, ultimately intending to replace Napoleon with a Dalek after Waterloo is won so that he can change history and lead humanity in a direction where they may ally with the Daleks. The plan is complicated when the Sixth Doctor arrives and uses the device to swap bodies with Davros in an attempt to subvert the Daleks' plans from the inside, but Davros-in-the-Doctor is eventually able to convince the Daleks of his true identity, planning to remain in the Doctor's healthy body while leaving the Doctor trapped in his original form. At the end, Davros and the Doctor are returned to their original bodies with the aid of the Doctor's new companion Flip Jackson, the Doctor exposes Davros's true agenda to Napoleon, and Davros is left with an army of Daleks who have had their minds wiped. These Daleks presumably become the \"Imperial Daleks\", first seen in \"Remembrance of the Daleks\".\nIn \"The Juggernauts\", Davros is on the run from the original Daleks. He hatches a plan to add human tissue to robotic Mechanoids, using them, along with his own Daleks, to destroy the originals, but the Doctor learns the truth about this plan, and his companion Mel Bush\u2014who unwittingly assisted in the programming of the new Mechanoids\u2014uses a backdoor she installed in their programming to turn them against Davros. At the end of the story, the self-destruct mechanism of Davros' life-support chair explodes after he is attacked by the Mechanoids, destroying an entire human colony. It is not clear how Davros survives to become the Dalek Emperor as seen in \"Remembrance\". However, in the DVD documentary \"Davros Connections\", director Gary Russell points out that the explosion of Davros' life-support chair leaves the listener to believe there is little of Davros left. This fits chronologically the fact that \"Remembrance\" depicts Davros as just a head inside the Emperor Dalek.\nIn \"Daleks Among Us\", set after \"Remembrance\", Davros returns to Azimuth, a planet that was invaded by the Daleks long ago, presenting himself as a victim of Dalek enslavement to infiltrate an underground movement against the repressive government- so desperate to prevent riots about individual actions during the Dalek occupation that official policy is now that the Dalek invasion never happened- seeking the remnants of an old experiment he carried out on the planet. This experiment is revealed to be Falkus, a clone of Davros's original body that was intended to be a new host for his mind, with Falkus having evolved an independent personality since the Daleks left Azimuth. Falkus attempts to acquire the Persuasion Machine, a dangerous device that the Seventh Doctor has been tracking with his companions Elizabeth Elizabeth Klein and Will Arrowsmith, but the Doctor is able to trick Falkus into using the reprogrammed Persuasion Machine to destroy himself and his Daleks, while Davros flees in an escape pod. Davros is last shown trapped on the planet Lamuria, faced with the spectral former residents of the planet who sought to punish all criminals in the universe.\nBy the time of the Eighth Doctor audio play \"Terror Firma\" (set after \"Remembrance\"), Davros is commanding a Dalek army which has successfully conquered the Earth. His mental instability has grown to the point where \"Davros\" and \"the Emperor\" exist within him as different personalities. His Daleks recognise this instability and rebel against Davros. By the story's end the Emperor personality is dominant, and the Daleks agree to follow him and leave Earth.\nIn the fourth volume of the \"\" series, looking at the Eighth Doctor's role in the Time War, after The Valeyard uses a Dalek weapon to erase the Daleks from history, the Dalek Time Strategist escapes the erasure by travelling into a parallel universe where the Kaleds and Thals have been at peace for centuries, with Davros still fully human and married to a Thal woman. The Dalek Time Strategist manipulates this alternate Davros into using his dimensional portal technology to merge various alternate Skaros together to recreate the Daleks in the prime universe, convincing Davros that the Doctor is an enemy of the \"Kaleds\" rather than the Thals. Reference is made to the 'prime' Davros having been killed in the first year of the War (as mentioned in \"The Stolen Earth\"). The process of merging with his alternate selves causes the alternate Davros to gain the injuries and memories of his counterparts, to the extent that he forgets his wife and the peace with the Thals. Eventually his presence restores the Daleks in the prime universe, but the Dalek Emperor has Davros put into stasis to prevent his influence causing another civil war by causing the Daleks to become divided between loyalty to the Emperor and Davros.\nNovels.\n\"Terror Firma\" may contradict the events of the Eighth Doctor Adventures novel \"War of the Daleks\" by John Peel, in which an unmerged Davros is placed on trial by the Dalek Prime, a combination of the Dalek Emperor and the Dalek Supreme. In the novel the Dalek Prime claimed that the planet Antalin had been terraformed to resemble Skaro and was destroyed in its place. A subterfuge to destroy Daleks aligned to Davros; both on Skaro (Antalin) and those that remained hidden within Dalek ranks on Skaro (original). Despite finding evidence of threat to Skaro via evidence found on 22nd century earth of Davros' mission to 1960s Earth and seeing the event via time-tracking equipment, the Dalek Prime allowed the destruction of Skaro to destroy Daleks allied to Davros. Dalek Prime also claimed that the Dalek/Movellan war (and indeed most of Dalek history before the destruction of \"Skaro\") was actually faked for Davros' benefit; in fact another ruse designed to bait Davros into giving evidence against himself (as he does in his trial.) Skaro is later seen to be intact and undamaged, and one character notes that it is quite possible the Dalek Prime is lying in order to weaken Davros' claim to leadership of the Daleks, while using foreknowledge of events to destroy and entrap Davros and his allies.\nAt the conclusion of \"War\", Davros was seemingly disintegrated by a Spider Dalek on the order of the Dalek Prime. However, Davros had previously recruited one of the Spider Daleks as a sleeper agent for just such an eventuality, and even he was not certain in the end if he was being disintegrated or being teleported away to safety, leaving the possibility open for his return.\nShort fiction.\nPaul Cornell's dark vignette in the \"Doctor Who Magazine\" Brief Encounters series, \"An Incident Concerning the Bombardment of the Phobos Colony\" occurs sometime between \"Resurrection of the Daleks\" and his assumption of the role of Emperor.\nTheatre.\nIn 1993, Michael Wisher, the original Davros, with Peter Miles, who had played his confederate, Nyder, reprised the role in an unlicensed one-off amateur stage production, \"The Trial of Davros\". The plot of the play involved the Time Lords putting Davros on trial, with Nyder as a witness.\nTerry Molloy played Davros in the remounting of the play, again with Miles, for another one-off production in 2005. During the production, specially shot footage portrayed Dalek atrocities.\nIn 2008, Julian Bleach appeared live as Davros at the Doctor Who Prom, announcing that the Royal Albert Hall would become his new palace, and the audience his \"obedient slaves\".\nUnofficial BBC representation.\nBBC staff have traditionally created parodies of its own programming to be shown to colleagues at Christmas events and parties. The BBC's 1993 Christmas tape parodied the allegedly robotic, dictatorial and ruthless management style of its then Director-General, John Birt, by portraying him as Davros taking over the BBC, carrying out bizarre mergers of departments, awarding himself a bonus and singing a song to the tune of \"I Wan'na Be Like You (The Monkey Song)\" describing his plans.\nList of appearances.\nAudio plays.\nPlayed by Terry Molloy, except where noted.\nOther media.\nOn 26 November 2007, a DVD box set was released featuring all of the Davros stories from the shows original run, including \"Genesis of the Daleks\", \"Destiny of the Daleks\", \"Resurrection of the Daleks\", \"Revelation of the Daleks\", and \"Remembrance of the Daleks\"."}
{"id": "9139", "revid": "191757", "url": "https://en.wikipedia.org/wiki?curid=9139", "title": "DreamCast", "text": ""}
{"id": "9140", "revid": "40700684", "url": "https://en.wikipedia.org/wiki?curid=9140", "title": "Dalek", "text": "The Daleks ( ) are a fictional extraterrestrial race of extremely xenophobic mutants principally portrayed in the British science fiction television programme \"Doctor Who\". They were conceived by writer Terry Nation and first appeared in the 1963 \"Doctor Who\" serial \"The Daleks\", in casings designed by Raymond Cusick.\nDrawing inspiration from the Nazis, Nation portrayed the Daleks as violent, merciless and pitiless cyborg aliens, completely absent of any emotion other than hate, who demand total conformity to the will of the Dalek with the highest authority, and are bent on the conquest of the universe and the extermination of any other forms of life, including other \"impure\" Daleks which are deemed inferior for being different to them. Collectively, they are the greatest enemies of \"Doctor Who\"s protagonist, the Time Lord known as \"the Doctor\". During the second year of the original \"Doctor Who\" programme (1963\u20131989), the Daleks developed their own form of time travel. At the beginning of the second \"Doctor Who\" TV series that debuted in 2005, it was established that the Daleks had engaged in a Time War against the Time Lords that affected much of the universe and altered parts of history.\nIn the programme's narrative, the planet Skaro suffered a thousand-year war between two societies: the Kaleds and the Thals. During this time-period, many natives of Skaro became badly mutated by fallout from nuclear weapons and chemical warfare. The Kaled government believed in genetic purity and swore to \"exterminate the Thals\" for being inferior. Believing his own society was becoming weak and that it was his duty to create a new master race from the ashes of his people, the Kaled scientist Davros genetically modified several Kaleds into squid-like life-forms he called Daleks, removing \"weaknesses\" such as mercy and sympathy while increasing aggression and survival-instinct. He then integrated them with tank-like robotic shells equipped with advanced technology based on the same life-support system he himself had used since being burned and blinded by a nuclear attack. His creations became intent on dominating the universe by enslaving or purging all \"inferior\" non-Dalek life.\nThe Daleks are the series' most popular and famous villains and their returns to television over the decades have often gained media attention. Their battle cry, a staccato \"Exterminate!\" has entered common usage as a popular catchphrase.\nCreation and development.\nThe Daleks were created by Terry Nation and designed by the BBC designer Raymond Cusick. They were introduced in December 1963 in the second \"Doctor Who\" serial, \"The Daleks\".\nWishing to create an alien creature that did not look like a \"man in a suit\", Terry Nation stated in his script for the first Dalek serial that they should have no legs. He was also inspired by a performance by the Georgian National Ballet, in which dancers in long skirts appeared to glide across the stage. For many of the shows the Daleks were operated by retired ballet dancers wearing black socks while sitting inside the Dalek. Raymond Cusick was given the task of designing the Daleks when Ridley Scott, then a designer for the BBC, proved unavailable after having been initially assigned to their debut serial. According to Jeremy Bentham's \"Doctor Who\u2014The Early Years\" (1986), after Nation wrote the script, Cusick was given only an hour to come up with the design for the Daleks and was inspired in his initial sketches by a pepper pot on a table. Cusick himself, however, states that he based it on a man seated in a chair, and used the pepper pot only to demonstrate how it might move.\nIn 1964, Nation told a \"Daily Mirror\" reporter that the Dalek name came from a dictionary or encyclopaedia volume, the spine of which read \"Dal \u2013 Lek\" (or, according to another version, \"Dal \u2013 Eks\"). He later admitted that this book and the associated origin of the Dalek name were completely fictitious, and that anyone bothering to check out his story would have found him out. The name had simply rolled off his typewriter. Later, Nation was pleasantly surprised to discover that in Serbo-Croatian the word \"dalek\" means \"far\" or \"distant\".\nNation grew up during the Second World War and remembered the fear caused by German bombings. He consciously based the Daleks on the Nazis, conceiving the species as faceless, authoritarian figures dedicated to conquest, racial purity and complete conformity. The allusion is most obvious in the Dalek stories written by Nation, in particular \"The Dalek Invasion of Earth\" (1964) and \"Genesis of the Daleks\" (1975).\nBefore he wrote the first Dalek serial, Nation was a scriptwriter for the comedian Tony Hancock. The two men had a falling out and Nation either resigned or was fired. Hancock worked on several series proposals, one of which was called \"From Plip to Plop\", a comedic history of the world that would have ended with a nuclear apocalypse, the survivors being reduced to living in dustbin-like robot casings and eating radiation to stay alive. According to Hancock's biographer Cliff Goodwin, when Hancock saw the Daleks he allegedly shouted at the screen, \"That bloody Nation \u2014 he's stolen my robots!\"\nThe titling of early \"Doctor Who\" stories is complex and sometimes controversial. The first Dalek serial is called, variously, \"The Survivors\" (the pre-production title and on-screen title used for the serial's second episode), \"The Mutants\" (its official title at the time of production and broadcast, later taken by another unrelated story), \"Beyond the Sun\" (used on some production documentation), \"The Dead Planet\" (the on-screen title of the serial's first episode), or simply \"The Daleks\".\nThe instant appeal of the Daleks caught the BBC off-guard, and transformed \"Doctor Who\" into a national phenomenon. Children were both frightened and fascinated by the alien look of the monsters, and the idea of \"hiding behind the sofa\" became a popular, if inaccurate or exaggerated, meme. The \"Doctor Who\" production office was inundated with letters and calls asking about the creatures. Newspaper articles focused attention on the series and the Daleks, further enhancing their popularity.\nNation jointly owned the intellectual property rights to the Daleks with the BBC, and the money-making concept proved nearly impossible to sell to anyone else, so he was dependent on the BBC wanting to produce stories featuring the creatures. Several attempts to market the Daleks outside the series were unsuccessful. Since Nation's death in 1997, his share of the rights is now administered by his former agent, Tim Hancock.\nEarly plans for what eventually became the 1996 \"Doctor Who\" television movie included radically redesigned Daleks whose cases unfolded like spiders' legs. The concept for these \"Spider Daleks\" was abandoned, but it was picked up again in several \"Doctor Who\" spin-offs.\nWhen the new series was announced, many fans hoped that the Daleks would return once more to the programme. The Nation estate, however, demanded levels of creative control over the Daleks' appearances and scripts that were unacceptable to the BBC. Eventually the Daleks were cleared to appear in the first series. In 2014, \"Doctor Who\" showrunner Steven Moffat denied their numerous appearances since was as a result of a contractual obligation.\nPhysical characteristics.\nExternally, Daleks resemble human-sized pepper pots with a single mechanical eyestalk mounted on a rotating dome, a gun-mount containing an energy-weapon (\"gunstick\" or \"death ray\") resembling an egg-whisk, and a telescopic manipulator arm usually tipped by an appendage resembling a sink-plunger. Daleks have been known to use their plungers to interface with technology, crush a man's skull by suction, measure the intelligence of a subject, and extract information from a man's mind. Dalek casings are made of a bonded polycarbide material called \"Dalekanium\" by a member of the human resistance in \"The Dalek Invasion of Earth\" and the Dalek comics, as well as by the Cult of Skaro in \"Daleks in Manhattan\".\nThe lower half of a Dalek's shell is covered with hemispherical protrusions, or 'Dalek-bumps', which are shown in the episode \"Dalek\" to be spheres embedded in the casing. Both the BBC-licensed \"Dalek Book\" (1964) and \"The Doctor Who Technical Manual\" (1983) describe these items as being part of a sensory array, while in the 2005 series episode \"Dalek\" they are integral to a Dalek's forcefield mechanism, which evaporates most bullets and resists most types of energy weapons. The forcefield seems to be concentrated around the Dalek's midsection (where the mutant is located), as normally ineffective firepower can be concentrated on the eyestalk to blind a Dalek. In 2019 episode \"Resolution\" the bumps give way to reveal missile launchers capable of wiping out a military tank with ease. Daleks have a very limited visual field, with no peripheral sight at all, and are relatively easy to hide from in fairly exposed places. Their own energy weapons are capable of destroying them. Their weapons fire a beam that has electrical tendencies, is capable of propagating through water, and may be a form of plasma or electrolaser. The eyepiece is a Dalek's most vulnerable spot; impairing its vision often leads to a blind, panicked firing of its weapon while exclaiming \"My vision is impaired; I cannot see!\" Russell T Davies subverted the catchphrase in his 2008 episode \"The Stolen Earth\", in which a Dalek vaporises a paintball that has blocked its vision while proclaiming, \"My vision is \"not\" impaired!\"\nThe creature inside the mechanical casing is soft and repulsive in appearance, and vicious in temperament. The first-ever glimpse of a Dalek mutant, in \"The Daleks\", was a claw peeking out from under a Thal cloak after it had been removed from its casing. The mutants' actual appearance has varied, but often adheres to the Doctor's description of the species in \"Remembrance of the Daleks\" as \"little green blobs in bonded polycarbide armour\". In \"Resurrection of the Daleks\" a Dalek creature, separated from its casing, attacks and severely injures a human soldier; in \"Remembrance of the Daleks\" there are two Dalek factions (Imperial and Renegade), and the creatures inside have a different appearance in each case, one resembling the amorphous creature from \"Resurrection\", the other the crab-like creature from the original Dalek serial. As the creature inside is rarely seen on screen there is a common misconception that Daleks are wholly mechanical robots. In the new series Daleks are retconned to be squid-like in appearance, with small tentacles, one or two eyes, and an exposed brain. In the new series, a Dalek creature separated from its casing is shown capable of inserting a tentacle into the back of a human's neck and controlling them.\nDaleks' voices are electronic; when out of its casing the mutant is only able to squeak. Once the mutant is removed the casing itself can be entered and operated by humanoids; for example, in \"The Daleks\", Ian Chesterton (William Russell) enters a Dalek shell to masquerade as a guard as part of an escape plan.\nFor many years it was assumed that, due to their design and gliding motion, Daleks were unable to climb stairs, and that this provided a simple way of escaping them. A cartoon from \"Punch\" pictured a group of Daleks at the foot of a flight of stairs with the caption, \"Well, this certainly buggers our plan to conquer the Universe\". In a scene from the serial \"Destiny of the Daleks\", the Doctor and companions escape from Dalek pursuers by climbing into a ceiling duct. The Fourth Doctor calls down, \"If you're supposed to be the superior race of the universe, why don't you try climbing after us?\" The Daleks generally make up for their lack of mobility with overwhelming firepower; a joke among \"Doctor Who\" fans is that \"Real Daleks don't climb stairs; they level the building.\" Dalek mobility has improved over the history of the series: in their first appearance, in \"The Daleks\", they were capable of movement only on the conductive metal floors of their city; in \"The Dalek Invasion of Earth\" a Dalek emerges from the waters of the River Thames, indicating not only that they had become freely mobile, but that they are amphibious; \"Planet of the Daleks\" showed that they could ascend a vertical shaft by means of an external anti-gravity mat placed on the floor; \"Revelation of the Daleks\" showed Davros in his life-support chair and one of his Daleks hovering and \"Remembrance of the Daleks\" depicted them as capable of hovering up a flight of stairs. Despite this, journalists covering the series frequently refer to the Daleks' supposed inability to climb stairs; characters escaping up a flight of stairs in the 2005 episode \"Dalek\" made the same joke and were shocked when the Dalek began to hover up the stairs after uttering the phrase \"ELEVATE\", in a similar manner to their normal phrase \"EXTERMINATE\". The new series depicts the Daleks as fully capable of flight, even space flight.\nProp details.\nOverview.\nThe non-humanoid shape of the Dalek did much to enhance the creatures' sense of menace. A lack of familiar reference points differentiated them from the traditional \"bug-eyed monster\" of science fiction, which \"Doctor Who\" creator Sydney Newman had wanted the show to avoid. The unsettling Dalek form, coupled with their alien voices, made many believe that the props were wholly mechanical and operated by remote control.\nThe Daleks were actually controlled from inside by short operators, who had to manipulate their eyestalks, domes, and arms; as well as flashing the lights on their heads in-sync with the actors supplying their voices. The Dalek cases were built in two pieces; an operator would step into the lower section, and then the top would be secured. The operators looked out between the cylindrical louvres just beneath the dome, which were lined with mesh to conceal their faces.\nIn addition to being hot and cramped, the Dalek casings also muffled external sounds, making it difficult for operators to hear the director or dialogue. John Scott Martin, a Dalek operator from the original series, said that Dalek operation was a challenge: \"You had to have about six hands: one to do the eyestalk, one to do the lights, one for the gun, another for the smoke canister underneath, yet another for the sink plunger. If you were related to an octopus then it helped.\"\nFor \"Doctor Who\"'s 21st-century revival the Dalek casings retain the same overall shape and dimensional proportions of previous Daleks, although many details have been redesigned to give the Dalek a heavier and more solid look. Changes include a larger, more pointed base; a glowing eyepiece; an all-over metallic-brass finish (specified by Davies); thicker, nailed strips on the \"neck\" section; a housing for the eyestalk pivot; and significantly larger dome-lights. The new prop made its on-screen debut in the 2005 episode \"Dalek\". These Dalek casings use a short operator inside the housing while the 'head' and eyestalk are operated via remote control. A third person, Nicholas Briggs, supplies the voice in their various appearances. A new, larger model appeared during the 2010 series in several colours; each representing different parts of the Dalek command hierarchy.\nMovement.\nTerry Nation's original plan was for the Daleks to glide across the floor. Early versions of the Daleks rolled on nylon castors, propelled by the operator's feet. Although castors were adequate for the Daleks' debut serial, which was shot entirely at the BBC's Lime Grove Studios, for \"The Dalek Invasion of Earth\" Terry Nation wanted the Daleks to be filmed on the streets of London. To enable the Daleks to travel smoothly on location, designer Spencer Chapman built the new Dalek shells around miniature tricycles with sturdier wheels, which were hidden by enlarged fenders fitted below the original base. The uneven flagstones of Central London caused the Daleks to rattle as they moved and it was not possible to remove this noise from the final soundtrack. A small parabolic dish was added to the rear of the prop's casing to explain why these Daleks, unlike the ones in their first serial, were not dependent on static electricity drawn up from the floors of the Dalek city for their motive power.\nLater versions of the prop had more efficient wheels and were once again simply propelled by the seated operators' feet, but they remained so heavy that when going up ramps they often had to be pushed by stagehands out of camera shot. The difficulty of operating all the prop's parts at once contributed to the occasionally jerky Dalek movements. This problem has largely been eradicated with the advent of the \"new series\" version, as its remotely controlled dome and eyestalk allow the operator to concentrate on the smooth movement of the Dalek and its arms.\nVoices.\nThe staccato delivery, harsh tone and rising inflection of the Dalek voice were initially developed by two voice actors, Peter Hawkins and David Graham, who varied the pitch and speed of the lines according to the emotion needed. Their voices were further processed electronically by Brian Hodgson at the BBC Radiophonic Workshop. The sound-processing devices used have varied over the decades. In 1963 Hodgson and his colleagues used equalisation to boost the mid-range of the actor's voice, then subjected it to ring modulation with a 30\u00a0Hz sine wave. The distinctive harsh, grating vocal timbre this produced has remained the pattern for all Dalek voices since (with the exception of those in the 1985 serial \"Revelation of the Daleks\", for which the director, Graeme Harper, deliberately used less distortion).\nBesides Hawkins and Graham, other voice actors for the Daleks have included Roy Skelton, who first voiced the Daleks in the 1967 story \"The Evil of the Daleks\" and provided voices for five additional Dalek serials including \"Planet of the Daleks\", and for the one-off anniversary special \"The Five Doctors\". Michael Wisher, the actor who originated the role of Dalek creator Davros in \"Genesis of the Daleks\", provided Dalek voices for that same story, as well as for \"Frontier in Space\", \"Planet of the Daleks\", and \"Death to the Daleks\". Other Dalek voice actors include Royce Mills (three stories), Brian Miller (two stories), and Oliver Gilbert and Peter Messaline (one story). John Leeson, who performed the voice of K9 in several \"Doctor Who\" stories, and Davros actors Terry Molloy and David Gooderson also contributed supporting voices for various Dalek serials.\nSince 2005 the Dalek voice in the television series has been provided by Nicholas Briggs, speaking into a microphone connected to a voice modulator. Briggs had previously provided Dalek and other alien voices for Big Finish Productions audio plays, and continues to do so. In a 2006 BBC Radio interview, Briggs said that when the BBC asked him to do the voice for the new television series, they instructed him to bring his own analogue ring modulator that he had used in the audio plays. The BBC's sound department had changed to a digital platform and could not adequately create the distinctive Dalek sound with their modern equipment. Briggs went as far as to bring the voice modulator to the actors' readings of the scripts.\nConstruction.\nManufacturing the props was expensive. In scenes where many Daleks had to appear, some of them would be represented by wooden replicas (\"Destiny of the Daleks\") or life-size photographic enlargements in the early black-and-white episodes (\"The Daleks\", \"The Dalek Invasion of Earth\", and \"The Power of the Daleks\"). In stories involving armies of Daleks, the BBC effects team even turned to using commercially available toy Daleks, manufactured by Louis Marx &amp; Co and Herts Plastic Moulders Ltd. Examples of this can be observed in the serials \"The Power of the Daleks\", \"The Evil of the Daleks\", and \"Planet of the Daleks\". Judicious editing techniques also gave the impression that there were more Daleks than were actually available, such as using a split screen in \"The Parting of the Ways\".\nFour fully functioning props were commissioned for the first serial \"The Daleks\" in 1963, and were constructed from BBC plans by Shawcraft Engineering. These became known in fan circles as \"Mk I Daleks\". Shawcraft were also commissioned to construct approximately 20 Daleks for the two Dalek movies in 1965 and 1966 (see below). Some of these movie props filtered back to the BBC and were seen in the televised serials, notably \"The Chase\", which was aired before the first movie's debut. The remaining props not bought by the BBC were either donated to charity or given away as prizes in competitions.\nThe BBC's own Dalek props were reused many times, with components of the original Shawcraft \"Mk I Daleks\" surviving right through to their final classic series appearance in 1988. But years of storage and repainting took their toll. By the time of the Sixth Doctor's \"Revelation of the Daleks\" new props were being manufactured out of fibreglass. These models were lighter and more affordable to construct than their predecessors. These newer models were slightly bulkier in appearance around the mid-shoulder section, and also had a redesigned skirt section which was more vertical at the back. Other minor changes were made to the design due to these new construction methods, including altering the fender and incorporating the arm boxes, collars, and slats into a single fibreglass moulding. These props were repainted in grey for the Seventh Doctor serial \"Remembrance of the Daleks\" and designated as \"Renegade Daleks\"; another redesign, painted in cream and gold, became the \"Imperial Dalek\" faction.\nNew Dalek props were built for the 21st-century version of \"Doctor Who\". The first, which appeared alone in the 2005 episode \"Dalek\", was built by modelmaker Mike Tucker. Additional Dalek props based on Tucker's master were subsequently built out of fibreglass by Cardiff-based Specialist Models.\nEntry into popular culture.\nThe Daleks became an immediate hit with viewers, returning for subsequent appearances throughout the 1960s. As early as one year after first appearing on \"Doctor Who\", the Daleks had become popular enough to be recognized even by non-viewers. In December 1964 editorial cartoonist Leslie Gilbert Illingworth published a cartoon in the \"Daily Mail\" captioned \"THE DEGAULLEK\", caricaturing French President Charles de Gaulle arriving at a NATO meeting as a Dalek with de Gaulle's prominent nose.\nThe Daleks have become as synonymous with \"Doctor Who\" as the Doctor himself, and their behaviour and catchphrases are now part of British popular culture. \"Hiding behind the sofa whenever the Daleks appear\" has been cited as an element of British cultural identity, and a 2008 survey indicated that nine out of ten British children were able to identify a Dalek correctly. In 1999 a Dalek photographed by Lord Snowdon appeared on a postage stamp celebrating British popular culture. In 2010, readers of science fiction magazine \"SFX\" voted the Dalek as the all-time greatest monster, beating competition including Japanese movie monster Godzilla and J. R. R. Tolkien's Gollum, of \"The Lord of the Rings\".\nThe word \"Dalek\" has entered major dictionaries, including the \"Oxford English Dictionary\", which defines \"Dalek\" as \"In the BBC television science-fiction series Doctor Who: a member of a race of aggressive alien mutants in mobile armoured casings. Frequently in extended, allusive, or similative use.\" English-speakers sometimes use the term metaphorically to describe people, usually authority figures, who act like robots unable to break from their programming. For example, John Birt, the Director-General of the BBC from 1992 to 2000, was called a \"croak-voiced Dalek\" by playwright Dennis Potter in the MacTaggart Lecture at the 1993 Edinburgh Television Festival.\nFictional history.\nDalek in-universe history has seen many retroactive changes, which have caused continuity problems. When the Daleks first appeared, they were presented as the descendants of the Dals, mutated after a brief nuclear war between the Dal and Thal races 500 years ago. This race of Daleks is destroyed when their power supply is wrecked. However, when they reappear in \"The Dalek Invasion of Earth\", they have conquered Earth in the 22nd century. Later stories saw them develop time travel and a space empire. In 1975, Terry Nation revised the Daleks' origins in \"Genesis of the Daleks\", where the Dals were now called Kaleds (of which \"Daleks\" is an anagram), and the Dalek design was attributed to one man, the paralyzed Kaled chief scientist and evil genius, Davros. Later Big Finish Productions audio plays attempted to explain this retcon by saying that the Skaro word \"dal\" simply means warrior, which is how the Kaleds described themselves, while \"dal-ek\" means \"god.\" According to \"Genesis of the Daleks\", instead of a short nuclear exchange, the Kaled-Thal war was a thousand-year-long war of attrition, fought with nuclear, biological and chemical weapons which caused widespread mutations among the life forms of Skaro. Davros experimented on living Kaled cells to find the ultimate mutated form of the Kaled species, believing his own people had become weak and needed to be replaced by a greater life form. He placed his new Dalek creations in tank-like \"travel machines\" of advanced technology whose design was based on his own life-support chair.\n\"Genesis of the Daleks\" marked a new era for the depiction of the species, with most of their previous history either forgotten or barely referred to again. Future stories in the original \"Doctor Who\" series, which followed a rough story arc, would also focus more on Davros, much to the dissatisfaction of some fans who felt that the Daleks should take centre stage rather than merely becoming minions of their creator. Davros made his last televised appearance for 20 years in \"Remembrance of the Daleks\", which depicted a civil war between two factions of Daleks. One faction, the \"Imperial Daleks\", were loyal to Davros, who had become their Emperor, whilst the other, the \"Renegade Daleks\", followed a black Supreme Dalek. By the end of the story, armies of both factions have been wiped out and the Doctor has tricked them into destroying Skaro. However, Davros escapes and based on the fact that Daleks possess time travel and were spread throughout the universe, there was still a possibility that many had survived these events.\nThe original \"classic\" \"Doctor Who\" series ended in 1989. In the 1996 \"Doctor Who\" TV-movie (which introduced the Eighth Doctor), Skaro has seemingly been recreated and the Daleks are shown to still rule it. Though the aliens are never seen on-screen, the story shows the Time Lord villain the Master being executed on Skaro as Dalek voices chant \"Exterminate.\" In Eighth Doctor audio plays produced by Big Finish from 2000 to 2005, Paul McGann reprised his role. The audio play \"The Time of the Daleks\" featured the Daleks without Davros and nearly removing William Shakespeare from history. In \"Terror Firma\", the Eighth Doctor met a Dalek faction led by Davros who was devolving more into a Dalek-like life form himself while attempting to create new Daleks from mutated humans of Earth. The audio dramas \"The Apocalypse Element\" and \"Dalek Empire\" also depicted the alien villains invading Gallifrey and then creating their own version of the Time Lord power source known as the Eye of Harmony, allowing the Daleks to rebuild an empire and become a greater threat against the Time Lords and other races that possess time travel.\nA new \"Doctor Who\" series premiered in 2005, introducing the Ninth Doctor and revealing that the \"Last Great Time War\" had just ended, resulting in the seeming destruction of the Time Lord society. The episode \"Dalek\", written by Robert Shearman, was broadcast on BBC One on 30 April 2005 and confirmed that the Time War had mainly involved the Daleks fighting the Time Lords, with the Doctor ending the conflict by seemingly destroying both sides, remarking that his own survival was \"not by choice.\" The episode featured a single Dalek who appeared to be the sole survivor of his race from the Time War. Later audio plays by Big Finish Productions expanded on the Time War in different audio drama series such as \"Gallifrey: Time War, The Eighth Doctor: Time War, The War Doctor,\" and \"The War Master.\"\nA Dalek Emperor returned at the end of the 2005 series, having survived the Time War and then rebuilt the Dalek race with genetic material harvested from human subjects. It saw itself as a god, and the new human-based Daleks were shown worshipping it. The Emperor and this Dalek fleet were destroyed in \"The Parting of the Ways\". The 2006 season finale \"Army of Ghosts\"/\"Doomsday\" featured a squad of four pure-bred Dalek survivors from the old Empire, known as the Cult of Skaro, composed of Daleks who were tasked with developing imagination to better predict and combat enemies. These Daleks took on names: Jast, Thay, Caan, and their black Dalek leader Sec. The Cult had survived the Time War by escaping into the Void between dimensions. They emerged along with the Genesis Ark, a Time Lord prison vessel containing millions of pure Daleks, at Canary Wharf due to the actions of the Torchwood Institute and Cybermen from a parallel world. This resulted in a Cyberman-Dalek clash in London, which was resolved when the Tenth Doctor caused both groups to be suckedunprotectedinto the Void. The Cult of Skaro survived by utilising an \"emergency temporal shift\" to escape.\nThe four-Dalek Cult of Skaro returned in the two-part story \"Daleks in Manhattan\"/\"Evolution of the Daleks\", in which whilst stranded in 1930s New York, they set up a base in the partially built Empire State Building and attempt to rebuild the Dalek race. To this end, Dalek Sec merges with a human being to become a Human/Dalek hybrid. The Cult then set about creating \"Human Daleks\" by \"formatting\" the brains of a few thousand captured humans so they can have Dalek minds. Dalek Sec, however, becomes more human in personality and alters the plan so the hybrids will be more human like him. The rest of the Cult mutinies. Sec is killed, while Thay and Jast are later wiped out with the hybrids. Dalek Caan, believing it may be the last of its kind now, escapes once more via an emergency temporal shift.\nThe Daleks returned in the 2008 season's two-part finale, \"The Stolen Earth\"/\"Journey's End\", accompanied once again by their creator Davros. The story reveals that Caan's temporal shift sent him into the Time War, despite the War being \"Time-Locked\". The experience of piercing the Time-Lock resulted in Caan seeing parts of several futures, destroying his sanity in the process. Caan rescued many pure-bred Time War era Daleks and Davros, who created new pure Dalek troops using his own body's cells (his Kaled DNA, as all pure Daleks were originally Kaleds). A red Supreme Dalek leads the new army while keeping Caan and Davros imprisoned on the Dalek flagship, the \"Crucible\". Davros and the Daleks plan to destroy reality itself with a \"reality bomb\". The plan fails due to the interference of Donna Noble, a companion of the Doctor, and Caan, who has been manipulating events to destroy the Daleks after realising the severity of the atrocities they have committed.\nThe Daleks returned in the 2010 episode \"Victory of the Daleks\", wherein it is revealed that some Daleks survived the destruction of their army in \"Journey's End\" and retrieved the \"Progenitor\", a tiny apparatus containing 'original' Dalek DNA. The activation of the Progenitor results in the creation of New Paradigm Daleks who deem the Time War era Daleks to be inferior. The new Daleks are organised into different roles (drone, scientist, strategists, supreme and eternal), which are identifiable with colour-coded armour instead of the identification plates under the eyestalk used by their predecessors. They escape the Doctor at the end of the episode via time travel with the intent to rebuild their Empire.\nThe Daleks appeared, only briefly, in subsequent finales \"The Pandorica Opens\"/\"The Big Bang\" (2010) and \"The Wedding of River Song\" (2011) as Steven Moffat decided to \"give them a rest\" and stated, \"There's a problem with the Daleks. They are the most famous of the Doctor's adversaries and the most frequent, which means they are the most reliably defeatable enemies in the universe.\" These episodes also reveal that Skaro has been recreated yet again. They next appear in \"Asylum of the Daleks\" (2012), where the Daleks are shown to have greatly increased numbers and now have a Parliament; in addition to the traditional \"modern\" Daleks, several designs from both the original and new series appear, all co-existing rather than judging each other as inferior or outdated (except for those Daleks whose personalities deem them \"insane\" or can no longer battle). All record of the Doctor is removed from their collective consciousness at the end of the episode.\nThe Daleks then appear in the 50th Anniversary special \"The Day of the Doctor\" (2013), where they are seen being defeated in the Time War. The same special reveals that many Time Lords survived the war since the Doctor found a way to transfer planet Gallifrey out of phase with reality and into a pocket dimension. In \"The Time of the Doctor\" (2013), the Daleks are one of the races that besieges Trenzalore in an attempt to stop the Doctor from releasing the Time Lords from the pocket dimension. After converting Tasha Lem into a Dalek puppet, they regain knowledge of the Doctor.\nThe Twelfth Doctor's first encounter with the Daleks is in his second full episode, \"Into the Dalek\" (2014), where he encounters a damaged Dalek he names 'Rusty.' Connecting to the Doctor's love of the universe and his hatred of the Daleks, Rusty assumes a mission to destroy other Daleks. In \"The Magician's Apprentice\"/\"The Witch's Familiar\" (2015), the Doctor is summoned to Skaro where he learns Davros has rebuilt the Dalek Empire. In \"The Pilot\" (2017), the Doctor briefly visits a battle during the Dalek-Movellan war.\nThe Thirteenth Doctor encountered a Dalek in a New Year's Day episode, \"Resolution\" (2019), when a Dalek mutant, separated from its armoured casing, takes control of a human in order to build a new travel device for itself and summon more Daleks to conquer Earth. This Dalek is cloned by a scientist in \"Revolution of the Daleks\" (2021), and attempts to take over Earth using further clones, but they are killed by other Daleks for perceived genetic impurity. The Dalek army is later sent by the Doctor into the \"void\" between worlds to be destroyed, using a spare TARDIS she recently acquired on Gallifrey. After cameo appearances depicting them as one of several villains trying to take advantage of \"the Flux\" event tearing through space-time in series 13, the Daleks returned in the first 2022 special, \"Eve of the Daleks\". In the episode, a team of Dalek Executioners are dispatched by High Command to avenge the Dalek War Fleet destroyed by the Doctor in the series 13 finale \"The Vanquishers\", only for a time loop established by the TARDIS to save the Doctor's life and give her a chance to destroy the executioners instead. The Daleks later appeared alongside the Cybermen as allies to the Master in \"The Power of the Doctor\" as part of a plot to finally destroy their nemesis, but the alliance is defeated by the Doctor and new and old companions.\nIn a video short for the 2023 \"Children in Need\" telethon, the origin of the iconic plunger-like appendages used by Daleks was retroactively established as being from the Fourteenth Doctor's TARDIS, while also establishing an unintentional hint by that Doctor, given to a Kaled military officer, for the creation of the name \"Dalek\".\nDalek culture.\nDaleks have little, if any, individual personality, ostensibly no emotions other than hatred and anger, and a strict command structure in which they are conditioned to obey superiors' orders without question. Dalek speech is characterised by repeated phrases, and by orders given to themselves and to others. Unlike the stereotypical emotionless robots often found in science fiction, Daleks are often angry; author Kim Newman has described the Daleks as behaving \"like toddlers in perpetual hissy fits\", gloating when in power and flying into a rage when thwarted. They tend to be excitable and will repeat the same word or phrase over and over again in heightened emotional states, most famously \"Exterminate! Exterminate!\"\nDaleks are extremely aggressive, and seem driven by an instinct to attack. This instinct is so strong that Daleks have been depicted fighting the urge to kill or even attacking when unarmed. The Fifth Doctor characterises this impulse by saying, \"However you respond [to Daleks] is seen as an act of provocation.\" The fundamental feature of Dalek culture and psychology is an unquestioned belief in the superiority of the Dalek race, and their default directive is to destroy all non-Dalek life-forms. Other species are either to be exterminated immediately or enslaved and then exterminated once they are no longer useful.\nThe Dalek obsession with their own superiority is illustrated by the schism between the Renegade and Imperial Daleks seen in \"Revelation of the Daleks\" and \"Remembrance of the Daleks\": the two factions each consider the other to be a perversion despite the relatively minor differences between them. This intolerance of any \"contamination\" within themselves is also shown in \"Dalek\", \"The Evil of the Daleks\" and in the Big Finish Productions audio play \"The Mutant Phase\". This superiority complex is the basis of the Daleks' ruthlessness and lack of compassion. This is shown in extreme in \"Victory of the Daleks\", where the new, pure Daleks destroy their creators, impure Daleks, with the latter's consent. It is nearly impossible to negotiate or reason with a Dalek, a single-mindedness that makes them dangerous and not to be underestimated. The Eleventh Doctor (Matt Smith) is later puzzled in the \"Asylum of the Daleks\" as to why the Daleks don't just kill the sequestered ones that have \"gone wrong\". Although the Asylum is subsequently obliterated, the Prime Minister of the Daleks explains that \"it is offensive to us to destroy such divine hatred\", and the Doctor is sickened at the revelation that hatred is actually considered beautiful by the Daleks.\nDalek society is depicted as one of extreme scientific and technological advancement; the Third Doctor states that \"it was their inventive genius that made them one of the greatest powers in the universe.\" However, their reliance on logic and machinery is also a strategic weakness which they recognise, and thus use more emotion-driven species as agents to compensate for these shortcomings.\nAlthough the Daleks are not known for their regard for due process, they have taken at least two enemies back to Skaro for a \"trial\", rather than killing them immediately. The first was their creator, Davros, in \"Revelation of the Daleks\", and the second was the renegade Time Lord known as the Master in the 1996 television movie. The reasons for the Master's trial, and why the Doctor would be allowed to retrieve the Master's remains, have never been explained on screen. The \"Doctor Who Annual 2006\" implies that the trial may have been due to a treaty signed between the Time Lords and the Daleks. The framing device for the ' audio plays is a Dalek trial to determine if Davros should be the Daleks' leader once more.\nSpin-off novels contain several tongue-in-cheek mentions of Dalek poetry, and an anecdote about an opera based upon it, which was lost to posterity when the entire cast was exterminated on the opening night. Two stanzas are given in the novel \"The Also People\" by Ben Aaronovitch. In an alternative timeline portrayed in the Big Finish Productions audio adventure \"The Time of the Daleks\", the Daleks show a fondness for the works of Shakespeare. A similar idea was satirised by comedian Frankie Boyle in the BBC comedy quiz programme \"Mock the Week\"; he gave the fictional Dalek poem \"Daffodils; EXTERMINATE DAFFODILS!\" as an \"unlikely line to hear in \"Doctor Who\"\".\nBecause the Doctor has defeated the Daleks so often, he has become their collective arch-enemy and they have standing orders to capture or exterminate him on sight. In later fiction, the Daleks know the Doctor as \"Ka Faraq Gatri\" (\"Bringer of Darkness\" or \"Destroyer of Worlds\"), and \"The Oncoming Storm\". Both the Ninth Doctor (Christopher Eccleston) and Rose Tyler (Billie Piper) suggest that the Doctor is one of the few beings the Daleks fear. In \"Doomsday\", Rose notes that while the Daleks see the extermination of five million Cybermen as \"pest control\", \"one Doctor\" visibly un-nerves them (to the point they physically recoil). To his indignant surprise, in \"Asylum of the Daleks\", the Eleventh Doctor (Matt Smith) learns that the Daleks have designated him as \"The Predator\".\nLicensing.\nCopyright for the Daleks was maintained by Terry Nation rather than the BBC and has passed to his estate after his death. A number of licensed usages have been made over the years.\nTwo \"Doctor Who\" movies starring Peter Cushing featured the Daleks as the main villains: \"Dr. Who and the Daleks\", and \"Daleks - Invasion Earth 2150 AD\", based on the television serials \"The Daleks\" and \"The Dalek Invasion of Earth\", respectively. The movies were not direct remakes; for example, the Doctor in the Cushing films was a human inventor called \"Dr. Who\" who built a time-travelling device named \"Tardis\", instead of a mysterious alien who stole a device called \"the TARDIS\".\nFour books focusing on the Daleks were published in the 1960s. \"The Dalek Book\" (1964, written by Terry Nation and David Whitaker), \"The Dalek World\" (1965, written by Nation and Whitaker) and \"The Dalek Outer Space Book\" (1966, by Nation and Brad Ashton) were all hardcover books formatted like annuals, containing text stories and comics about the Daleks, along with fictional information (sometimes based on the television serials, other times made up for the books). Nation also published \"The Dalek Pocketbook and Space-Travellers Guide\", which collected articles and features treating the Daleks as if they were real. Four more annuals were published in the 1970s by World Distributors under the title \"Terry Nation's Dalek Annual\" (with cover dates 1976\u20131979, but published 1975\u20131978). Two original novels by John Peel, \"War of the Daleks\" (1997) and \"Legacy of the Daleks\" (1998), were released as part of the Eighth Doctor Adventures series of \"Doctor Who\" novels. A novella, \"The Dalek Factor\" by Simon Clark, was published in 2004, and two books featuring the Daleks and the Tenth Doctor (\"I am a Dalek\" by Gareth Roberts, 2006, and \"Prisoner of the Daleks\" by Trevor Baxendale, 2009) have been released as part of the New Series Adventures.\nNation authorised the publication of the comic strip \"The Daleks\" in the comic \"TV Century 21\" in 1965. The weekly one-page strip, written by Whitaker but credited to Nation, featured the Daleks as protagonists and \"heroes\", and continued for two years, from their creation of the mechanised Daleks by the humanoid Dalek scientist, Yarvelling, to their eventual discovery in the ruins of a crashed space-liner of the co-ordinates for Earth, which they proposed to invade. Although much of the material in these strips was directly contradicted by what was later shown on television, some concepts like the Daleks using humanoid duplicates and the design of the Dalek Emperor did show up later on in the programme.\nAt the same time, a \"Doctor Who\" strip was also being published in \"TV Comic\". Initially, the strip did not have the rights to use the Daleks, so the First Doctor battled the \"Trods\" instead, cone-shaped robotic creatures that ran on static electricity. By the time the Second Doctor appeared in the strip in 1967 the rights issues had been resolved, and the Daleks began making appearances starting in \"The Trodos Ambush\" (TVC #788-#791), where they massacred the Trods. The Daleks also made appearances in the Third Doctor-era \"Dr. Who\" comic strip that featured in the combined \"Countdown/TV Action\" comic during the early 1970s.\nAn animated series called \"Daleks!\", which consists of five 10-minute long episodes, was released on the official \"Doctor Who\" YouTube channel in 2020.\nOther licensed appearances have included a number of stage plays (see Stage plays below) and television adverts for Wall's \"Sky Ray\" ice lollies (1966), Weetabix breakfast cereal (1977), Kit Kat chocolate bars (2001), and the ANZ Bank (2005). In 2003, Daleks also appeared in UK billboard ads for Energizer batteries, alongside the slogan \"Are You Power Mad?\"\nMerchandising.\nThe BBC approached Walter Tuckwell, a New Zealand-born entrepreneur who was handling product merchandising for other BBC shows, and asked him to do the same for the Daleks and \"Doctor Who\". Tuckwell created a glossy sales brochure that sparked off a Dalek craze, dubbed \"Dalekmania\" by the press, which peaked in 1965.\nToys and models.\nThe first Dalek toys were released in 1965 as part of the \"Dalekmania\" craze. These included battery-operated, friction drive and \"Rolykins\" Daleks from Louis Marx &amp; Co., as well as models from Cherilea, Herts Plastic Moulders Ltd and Cowan, de Groot Ltd, and \"Bendy\" Daleks made by Newfeld Ltd. At the height of the Daleks' popularity, in addition to toy replicas, there were Dalek board games and activity sets, slide projectors for children and even Dalek playsuits made from PVC. Collectible cards, stickers, toy guns, music singles, punching bags and many other items were also produced in this period. Dalek toys released in the 1970s included a new version of Louis Marx's battery-operated Dalek (1974), a \"talking Dalek\" from Palitoy (1975) and a Dalek board game (1975) and Dalek action figure (1977), both from Denys Fisher. From 1988 to 2002, Dapol released a line of Dalek toys in conjunction with its \"Doctor Who\" action figure series.\nBeginning in 2000, Product Enterprise (who later operated under the names \"Iconic Replicas\" and \"Sixteen 12 Collectibles\") produced various Dalek toys. These included Dalek \"Rolykins\" (based on the Louis Marx toy from 1965); push-along \"talking\" Daleks; Dalek \"Rollamatics\" with a pull back and release mechanism; and a remote control Dalek.\nIn 2005 Character Options was granted the \"Master Toy License\" for the revived \"Doctor Who\" series, including the Daleks. Their product lines have included static/push-along and radio controlled Daleks, radio controlled versions and radio controlled / 1:3 scale variants. The 12-inch remote control Dalek won the 2005 award for Best Electronic Toy of the Year from the Toy Retailers Association. Some versions of the 18-inch model included semi-autonomous and voice command-features. In 2008, the company acquired a license to produce Daleks of the various \"classic series\" variants.\nFull-size reproductions.\nDalek fans have been building life-size reproduction Daleks for many years. The BBC and Terry Nation estate officially disapprove of self-built Daleks, but usually intervene only if attempts are made to trade unlicensed Daleks and Dalek components commercially, or if it is considered that actual or intended use may damage the BBC's reputation or the Doctor Who/Dalek brand. The Crewe-based company \"This Planet Earth\" is the only business which has been licensed by the BBC and the Terry Nation Estate to produce full-size TV Dalek replicas, and by Canal+ Image UK Ltd. to produce full size Movie Dalek replicas commercially.\nOther appearances.\nNon\u2013\"Doctor Who\" television and film.\nDaleks have made cameo appearances in television programmes and films unrelated to \"Doctor Who\" from the 1960s to the present day.\nMusic.\nDaleks have been referred to or associated in many musical compositions.\nVideo games.\nLicensed \"Doctor Who\" games featuring Daleks include 1984's \"The Key to Time\", a text adventure game for the ZX Spectrum. The first graphical game to feature daleks was the eponymous, turn-based title released by Johan Strandberg for the Macintosh in the same year. Daleks also appeared in minor roles or as thinly disguised versions in other, minor games throughout the 80s, but did not feature as central adversaries in a licensed game until 1992, when Admiral Software published \"Dalek Attack\". The game allowed the player to play various Doctors or companions, running them through several environments to defeat the Daleks. In 1997 the BBC released a PC game entitled \"Destiny of the Doctors\" which also featured the Daleks, among other adversaries.\nOne authorised online game is \"The Last Dalek\", a Flash game created by New Media Collective for the BBC. It is based on the 2005 episode \"Dalek\" and can be played at the official BBC \"Doctor Who\" website. The \"Doctor Who\" website also features another game, \"Daleks vs Cybermen\" (also known as \"Cyber Troop Control Interface\"), based on the 2006 episode \"Doomsday\"; in this game, the player controls troops of Cybermen which must fight Daleks as well as Torchwood Institute members.\nOn 5 June 2010, the BBC released the first of four official computer games on its website, \"Doctor Who: The Adventure Games\", which are intended as part of the official TV series adventures. In the first of these, 'The City of the Daleks', the Doctor in his 11th incarnation and Amy Pond must stop the Daleks re-writing time and reviving Skaro, their homeland.\nThey also appear in the Nintendo DS and Wii games ' and '.\nThe Daleks also appear in \"Lego Dimensions\" where they ally themselves with Lord Vortech and possess the size-altering scale keystone. When Batman, Gandalf, and Wyldstyle encounter them, they assume that they are allies of the Doctor and attack the trio. The main characters continue to fight the Daleks until they call the Doctor to save them. A Dalek saucer also appears in the level based on Metropolis, in which the top of it serves as the stage for the boss battle against Sauron and includes Daleks among the various enemies summoned to attack the player. A Dalek is also among the elements summoned by the player to deal with the obstacles in the \"Portal 2\" story level of Lego Dimensions.\nThe Daleks also appear in \"Doctor Who: The Edge of Time\", a Virtual Reality Game for the PlayStation VR, Oculus Rift, Oculus Quest, HTC Vive, and Vive Cosmos, which was released in September 2019.\nThe Daleks are a licensed costume in \"Fall Guys\".\nPolitics.\nAt the 1966 Conservative Party conference in Blackpool, delegate Hugh Dykes publicly compared the Labour government's Defence Secretary Denis Healey to the creatures. \"Mr. Healey is the Dalek of defence, pointing a metal finger at the armed forces and saying 'I will eliminate you'.\"\nIn a British Government Parliamentary Debate in the House of Commons on 12 February 1968, the then Minister of Technology Tony Benn mentioned the Daleks during a reply to a question from the Labour MP Hugh Jenkins concerning the Concorde aircraft project. In the context of the dangers of solar flares, he said, \"Because we are exploring the frontiers of technology, some people think Concorde will be avoiding solar flares like Dr. Who avoiding Daleks. It is not like this at all.\"\nAustralian Labor Party luminary Robert Ray described his right wing Labor Unity faction successor, Victorian Senator Stephen Conroy, and his Socialist Left faction counterpart, Kim Carr, as \"factional Daleks\" during a 2006 Australian Fabian Society lunch in Sydney.\nDuring a 2021 House of Commons debate about the retention of dentists in rural areas of the United Kingdom during the COVID-19 pandemic, the voice of Conservative MP Scott Mann of North Cornwall, while on a video link, became distorted due to a malfunction with his audio feed. Deputy Speaker of the House Nigel Evans interrupted his broadcast, amidst the chuckles from other MPs; by saying, \"Scott, you sound like a Dalek and I don't mean that unkindly. There's clearly a communications problem.\" Mann later returned to apologise.\nDaleks have been used in political cartoons to caricature: Douglas Hurd, as the 'Douglek', in Private Eye's Dan Dire \u2013 Pilot of the Future; Tony Benn, John Birt, Tony Blair, Alec Douglas-Home, Charles de Gaulle, Mark Thompson.\nMagazine covers.\nDaleks have appeared on magazine covers promoting \"Doctor Who\" since the \"Dalekmania\" fad of the 1960s. \"Radio Times\" has featured the Daleks on its cover several times, beginning with the 21\u201327 November 1964 issue which promoted \"The Dalek Invasion of Earth\". Other magazines also used Daleks to attract readers' attention, including \"Girl Illustrated\".\nIn April 2005, \"Radio Times\" created a special cover to commemorate both the return of the Daleks to the screen in \"Dalek\" and the forthcoming general election. This cover recreated a scene from \"The Dalek Invasion of Earth\" in which the Daleks were seen crossing Westminster Bridge, with the Houses of Parliament in the background. The cover text read \"VOTE DALEK!\" In a 2008 contest sponsored by the Periodical Publishers Association, this cover was voted the best British magazine cover of all time. In 2013 it was voted \"Cover of the century\" by the Professional Publishers Association. The 2010 United Kingdom general election campaign also prompted a collector's set of three near-identical covers of the \"Radio Times\" on 17 April with exactly the same headline but with the newly redesigned Daleks in their primary colours representing the three main political parties, Red being Labour, Blue as Conservative and Yellow as Liberal Democrats.\nParodies.\nDaleks have been the subject of many parodies, including Spike Milligan's \"Pakistani Dalek\" sketch in his comedy series \"Q\", and Victor Lewis-Smith's \"Gay Daleks\". Occasionally the BBC has used the Daleks to parody other subjects: in 2002, BBC Worldwide published the \"Dalek Survival Guide\", a parody of \"The Worst-Case Scenario Survival Handbooks\". Comedian Eddie Izzard has an extended stand-up routine about Daleks, which was included in her 1993 stand-up show \"Live at the Ambassadors\". The Daleks made two brief appearances in a pantomime version of \"Aladdin\" at the Birmingham Hippodrome which starred \"Torchwood\" star John Barrowman in the lead role. A joke-telling robot, possessing a Dalek-like boom, and loosely modelled after the Dalek, also appeared in the \"South Park\" episode \"Funnybot\", even spouting out \"exterminate\". A Dalek can also be seen in the background at timepoints 1:13 and 1:17 in the Sam &amp; Max episode \"The Trouble with Gary\". In the \"Community\" parody of \"Doctor Who\" called \"Inspector Spacetime\", they are referred to as Blorgons."}
{"id": "9141", "revid": "48887646", "url": "https://en.wikipedia.org/wiki?curid=9141", "title": "Davy Jones (musician)", "text": "David Thomas Jones (30 December 1945 \u2013 29 February 2012) was an English actor, singer, and songwriter. Best known as a member of the band the Monkees and a co-star of the TV series \"The Monkees\" (1966\u20131968), Jones was considered a teen idol.\nAside from his work on \"The Monkees\" TV show, Jones's acting credits include a Tony-nominated performance as the Artful Dodger in the original London and Broadway productions of \"Oliver!\" and a guest-starring role in a notable episode of \"The Brady Bunch\" television show and a later reprised parody film.\nEarly life.\nDavid Thomas Jones was born on 30 December 1945 in Longsight, England, to Harry and Doris Jones. He had three sisters: Hazel, Lynda and Beryl. Jones' mother died from emphysema when he was 14 years of age.\nCareer as actor and singer.\nEarly days (1961\u20131965).\nJones' television acting debut was in the British television soap opera \"Coronation Street\", in which he appeared as Colin Lomax, grandson of the regular character Ena Sharples, for one episode on 6 March 1961. He also appeared in the BBC police series \"Z-Cars\". Following the death of his mother, Jones rejected acting in favour of becoming a jockey, commencing an apprenticeship with Newmarket trainer Basil Foster. He dropped out of secondary school to begin working in that field, but this career was short-lived. Even though Foster believed Jones would be successful as a jockey, he encouraged his young prot\u00e9g\u00e9 to take a role as the Artful Dodger in a production of \"Oliver!\" in London's West End. When approached by a friend who worked in a West End theatre during the show's casting, Foster replied, \"I've got the kid.\" Jones's portrayal brought him great acclaim. He played the role in London and then on Broadway, and was nominated for a Tony Award.\nOn 9 February 1964, Jones appeared on \"The Ed Sullivan Show\" with Georgia Brown, who was playing Nancy in the Broadway production of \"Oliver!\". It was the episode of the show in which the Beatles made their first appearance on U.S. television. Jones said of that night, \"I watched the Beatles from the side of the stage, I saw the girls going crazy, and I said to myself, this is it, I want a piece of that.\" Jones also appeared with Georgia Brown on the Merv Griffin Show around the same time.\nFollowing his \"Ed Sullivan\" appearance, Jones signed a contract with Ward Sylvester of Screen Gems (at that time the television division of Columbia Pictures). A pair of U.S. television appearances followed, as Jones received screen time in episodes of \"Ben Casey\" and \"The Farmer's Daughter\".\nJones debuted on the Billboard Hot 100 in the week of 14 August 1965, with the single \"What Are We Going To Do?\", which peaked at number 93. The 19-year-old singer was signed to Colpix Records, a label owned by Columbia. His debut album, \"David Jones\", on the same label, followed soon afterward (CP493).\nThe Monkees (1966\u20131970).\nFrom 1966 to 1970, Jones was a member of the Monkees, a pop-rock band formed expressly for a television show of the same name. With Screen Gems producing the series, Jones was shortlisted for auditions, as he was the only Monkee who was signed to a deal with the studio, but still had to meet the standards of producers Bob Rafelson and Bert Schneider. Jones sang lead vocals on many of the Monkees' recordings, including \"I Wanna Be Free\" and \"Daydream Believer\". The DVD release of the first season of the show contained commentary from the various bandmates. In Peter Tork's commentary, he stated that Jones was a good drummer and had the live performance line-up been based solely on playing ability, it ought to have been Tork on guitar, Mike Nesmith on bass, and Jones on drums, with Micky Dolenz taking the fronting role, rather than as it was done (with Nesmith on guitar, Tork on bass, and Dolenz on drums). Like Peter Tork, Jones, despite playing mostly tambourine or maracas, was a multi-instrumentalist and would fill in for Tork on bass when he played keyboards and vice versa and for Dolenz on drums when the Monkees performed live concerts.\nThe Monkees officially disbanded in 1970. The NBC television series \"The Monkees\" was popular and remained in syndication.\nPost-Monkees career (1970\u20132012).\nBell Records, then having a string of hits with \"The Partridge Family\", signed Jones to a somewhat inflexible solo record contract in 1971. Jones was not allowed to choose his songs or producer, resulting in several lacklustre and aimless records. His second solo album, \"Davy Jones\" (1971) was notable for the song \"Rainy Jane\", which reached No. 52 in the \"Billboard\" charts. To promote the album, Jones performed \"Girl\" on an episode of \"The Brady Bunch\" entitled \"Getting Davy Jones\". Although the single sold poorly, the popularity of Jones' appearance on the show resulted in \"Girl\" becoming his best-remembered solo hit, even though it was not included in the album. The final single, \"I'll Believe In You\"/\"Road to Love\", was poorly received.\nDolenz, Jones, Boyce &amp; Hart (1976).\nThanks in part to reruns of \"The Monkees\" on Saturday mornings and in syndication, \"The Monkees Greatest Hits\" charted in 1976. The LP, issued by Arista (a subsidiary of Screen Gems), was actually a repackaging of a 1972 compilation LP called \"Refocus\" that had been issued by Arista's previous label imprint, Bell Records, also owned by Screen Gems.\nDolenz and Jones took advantage of this, joining ex-Monkees songwriters Tommy Boyce and Bobby Hart to tour the United States. From 1975 to 1977, as the \"Golden Hits of The Monkees\" show (\"The Guys who Wrote 'Em and the Guys who Sang 'Em!\"), they successfully performed in smaller venues such as state fairs and amusement parks as well as making stops in Japan, Thailand, and Singapore (although they were forbidden from using the \"Monkees\" name, as it was owned by Screen Gems at the time). They also released an album of new material appropriately as \"Dolenz, Jones, Boyce &amp; Hart\"; a live album entitled \"Concert in Japan\" was also recorded in 1976, but was not released until 1996.\nFurther stage and screen appearances (1977\u20131999).\nDespite his initial high-profile after the Monkees disbanded, Jones struggled to establish himself as a solo music artist. Glenn A. Baker, author of \"Monkeemania: The True Story of the Monkees\", commented in 1986 that \"for an artist as versatile and confident as (Davy) Jones, the relative failure of his post-Monkees activities is puzzling. For all his cocky predictions to the press about his future plans, Davy fell into a directionless heap when left to his own devices.\"\nJones returned to theatre several times after the Monkees disbanded. In 1977, he performed with former bandmate Micky Dolenz in a stage production of the Harry Nilsson musical \"The Point!\" in London at the Mermaid Theatre, playing and singing the starring role of \"Oblio\" to Dolenz' roles as the \"Count's Kid\" and the \"Leafman\", (according to the CD booklet). An original cast recording was made and released. The comedic chemistry of Jones and Dolenz proved so strong that the show was revived in 1978 with Nilsson inserting additional comedy for the two, plus two more songs, with one of them (\"Gotta Get Up\") being sung by Jones and Dolenz. The show was considered so good that it was planned to be revived again in 1979 but it proved cost prohibitive (source CD booklet \"Harry Nilsson's The Point\"). Jones also appeared in several productions of \"Oliver!\" as the Artful Dodger, and in 1989 toured the US portraying \"Fagin\".\nJones appeared in two episodes each of \"Love, American Style\" and \"My Two Dads\". Jones also appeared in animated form as himself in 1972 in an hour-long episode of \"The New Scooby-Doo Movies\".\nA \"Monkees\" television show marathon (\"Pleasant Valley Sunday\") broadcast on 23 February 1986 by MTV resulted in a wave of Monkeemania not seen since the band's heyday. Jones reunited with Dolenz and Peter Tork from 1986 to 1989 to celebrate the band's renewed success and promote the 20th anniversary of the band. A new top 20 hit, \"That Was Then, This Is Now\" was released (though Jones did not perform on the song) as well as an album, \"Pool It!\"\nIn 1996, Jones reunited with Dolenz, Tork and Michael Nesmith to celebrate the 30th anniversary of the Monkees. The band released a new album entitled \"Justus\", the first album since 1967's \"Headquarters\" that featured the band members performing all instrumental duties. It was the last time all four Monkees performed together.\nOther television appearances include \"Sledge Hammer!\", \"Boy Meets World\", \"Hey Arnold!\", \"The Single Guy\" (where he is mistaken for Dudley Moore) and \"Sabrina, the Teenage Witch\" in which he sang \"Daydream Believer\" to Sabrina Spellman (played by Melissa Joan Hart) as well as (I'll) Love You Forever.\nIn 1995, Jones acted in a notable episode of the sitcom \"Boy Meets World\".\nThe continued popularity of Jones' 1971 \"Brady Bunch\" appearance led to his being cast as himself in \"The Brady Bunch Movie\" (1995). Jones sang his signature solo hit \"Girl\", with a grunge band providing backing, this time with middle-aged women swooning over him. Micky Dolenz and Peter Tork also appeared alongside Jones as judges.\nOn 2 August 1996, while The Monkees were on their 30th-anniversary tour in New England, Jones was interviewed on the \"Sports Break\" radio show on WBPS 890-AM in Boston by host Roland Regan about his early days as a jockey and amateur boxer back in England as a youth, and now how he stays in shape by jogging and playing in celebrity tennis tournaments.\nOn 21 June 1997, during a concert at the Los Angeles Coliseum, Jones joined U2's The Edge onstage for a karaoke performance of \"Daydream Believer\", which had become a fixture of the band's set during that year's PopMart Tour.\nLater career (2000\u20132012).\nIn 2001, Jones released \"Just Me\", an album of his own songs, some written for the album and others originally on Monkees releases. In the early 2000s he was performing in the Flower Power Concert Series during Epcot's Flower and Garden Festival, a yearly gig he would continue until his death.\nIn April 2006, Jones recorded the single \"Your Personal Penguin\", written by children's author Sandra Boynton, as a companion piece to her new board book of the same title.\nIn 2007, Jones performed the theme song for the film \"Sexina: Popstar P.I.\". On 1 November 2007, the Boynton book and CD titled \"Blue Moo\" was released and Jones is featured in both the book and CD, singing \"Your Personal Penguin\". In 2009, Jones released a collection of classics and standards from the 1940s through the 1970s entitled \"She\".\nIn December 2008, \"Yahoo! Music\" named Jones the \"Number 1 teen idol of all time\". In 2009, Jones was rated second in a list of 10\u00a0best teen idols compiled by Fox News.\nIn 2009, Jones made a cameo appearance as himself in the \"SpongeBob SquarePants\" episode \"SpongeBob SquarePants vs. The Big One\" (his appearance was meant as a pun on the phrase \"Davy Jones' Locker\").\nIn February 2011, Jones confirmed rumours of another Monkees reunion. \"There's even talk of putting the Monkees back together again in the next year or so for a U.S. and UK tour,\" he told Disney's Backstage Pass newsletter. \"You're always hearing all those great songs on the radio, in commercials, movies, almost everywhere.\" The tour (Jones' last) came to fruition and was entitled \".\"\nOther ventures.\nIn 1967, Jones opened his first store, called Zilch, at 217 Thompson Street in the Greenwich Village section of New York City. The store sold \"hip\" clothing and accessories, and also allowed customers to design their own clothes.\nAfter the Monkees disbanded in 1970, Jones kept himself busy by establishing a New York City-style street market in Los Angeles, called \"The Street\", which cost approximately $40,000. He also collaborated with musical director Doug Trevor on a one-hour ABC television special titled \"Pop Goes Davy Jones\", which featured new artists The Jackson 5 and the Osmonds.\nHorse racing.\nIn addition to his career as an entertainer, Jones' other great love was horses. Having trained as a jockey in his teens in the UK, he had at first intended to pursue a career as a professional race jockey. He held an amateur rider's licence, and rode in his first race at Newbury in Berkshire for renowned trainer Toby Balding.\nOn 1 February 1996, Jones won his first race, on Digpast, in the one-mile Ontario Amateur Riders Handicap at Lingfield in Surrey. Jones also had horse ownership interests in both the US and the UK, and served as a commercial spokesman for Colonial Downs racetrack in Virginia. Following Jones' death, Lingfield announced that the first two races on the racecard for 3 March 2012 would be renamed the \"Hey Hey We're The Monkees Handicap\" and the \"In Memory of Davy Jones Selling Stakes\", with successful horses in those races accompanied into the winners' enclosure by some of the Monkees' biggest hits. Plans were also announced to erect a plaque to commemorate Jones next to a Monkey Puzzle tree on the course.\nPersonal life.\nJones was married three times and had four children. In December 1967, he married Dixie Linda Haines, with whom he had been living. Their relationship had been kept out of the public eye until after the birth of their first child in October 1968. It caused a considerable backlash for Jones from his fans when it was finally made public. Jones later stated in \"Tiger Beat\" magazine, \"I kept my marriage a secret because I believe stars should be allowed a private life.\" Jones and Haines had two daughters, Talia Elizabeth Jones (2 October 1968) and Sarah Lee Jones (3 July 1971). The marriage ended in 1975.\nJones married his second wife, Anita Pollinger, on 24 January 1981, and also had two daughters. Jessica Lillian Jones (4 September 1981) and Annabel Charlotte Jones (26 June 1988). The couple divorced in 1996 during the Monkees' 30th-anniversary reunion tour.\nJones married Jessica Pacheco in 2009. Jones and his wife appeared on the \"Dr. Phil\" show in April 2011. On 28 July 2011, Pacheco filed to divorce Jones in Miami-Dade County, Florida, but dropped the suit in October. They were still married when he died in February 2012. Pacheco was omitted from Jones' will, which he had made before their marriage. His oldest daughter, whom he named his executrix, was granted by the court the unusual request that her father's will be sealed, on the basis that \"planning documents and financial affairs as public opinion could have a material effect on his copyrights, royalties and ongoing goodwill\".\"\nDeath.\nOn the morning of 29 February 2012, Jones went to tend his 14 horses at a farm in Indiantown, Florida. After riding one of his favourite horses around the track, he complained of chest pains and difficulty breathing and was given antacid pills. He got in his car to go home. Just after 8:00\u00a0a.m., a ranch-hand found him unconscious and an ambulance was called but Jones could not be revived. He was taken to Martin Memorial South Hospital in Stuart, Florida, where he died of a heart attack resulting from arteriosclerosis. He was 66.\nOn 7 March, a private funeral service was held at Holy Cross Catholic parish church in Indiantown. To avoid drawing attention to the grieving family, the three surviving Monkees did not attend. Instead, the bandmates attended memorial services in New York City and organised their own private memorial in Los Angeles along with Jones' family and close friends. A public memorial service was held on 10 March in Beavertown, Pennsylvania, near a church Jones had purchased for future renovation.\nOn 12 March, a private memorial service was held in Jones' hometown of Openshaw, Manchester, at Lees Street Congregational Church, where Jones performed as a child in church plays. Jones' wife and daughters travelled to England to join his relatives based there for the service, and placed his ashes on his parents' graves for a time.\nReaction.\nThe news of Jones' death triggered a surge of Internet traffic, causing sales of the Monkees' music to increase dramatically.\nGuitarist Michael Nesmith stated that Jones' \"spirit and soul live well in my heart, among all the lovely people, who remember with me the good times, and the healing times, that were created for so many, including us. I have fond memories. I wish him safe travels.\" In an 8 March 2012 interview with \"Rolling Stone\" magazine, Nesmith commented, \"For me, David was the Monkees. They were his band. We were his side men.\" Bassist Peter Tork said, \"Adios to the Manchester Cowboy\", and speaking to CNN, drummer/singer Micky Dolenz said, \"He was the brother I never had and this leaves a gigantic hole in my heart.\" Dolenz claimed that he knew that something bad was about to happen and said \"Can't believe it.. Still in shock.. had bad dreams all night long.\" Dolenz was gratified by the public affection expressed for both Jones and the Monkees in the wake of his bandmate's death. \"He was a very well-known and well-loved character and person. There are a lot of people who are grieving pretty hard. The Monkees obviously had a following, and so did (Jones) on his own. So I'm not surprised, but I was flattered and honored to be considered one of his friends and a cohort in Monkee business.\"\n\"The Monkees\" co-creator Bob Rafelson commented that Jones \"deserves a lot of credit, let me tell you. He may not have lived as long as we wanted him to, but he survived about seven lifetimes, including being perhaps the biggest rock star of his time.\"\n\"Brady Bunch\" co-star Maureen McCormick commented that \"Davy was a beautiful soul,\" and that he \"spread love and goodness around the world. He filled our lives with happiness, music, and joy. He will live on in our hearts forever. May he rest in peace.\"\nYahoo Music commented that Jones' death \"hit so many people so hard\" because \"Monkees nostalgia cuts across generations: from the people who discovered the band during their original 1960s run; to the kids who came of age watching 1970s reruns; to the 20- and 30-somethings who discovered the Monkees when MTV (a network that owes much to the Monkees' influence) began airing old episodes in 1986.\"\n\"Time\" contributor James Poniewozik praised the Monkees' classic sitcom, and Jones in particular, saying, \"even if the show never meant to be more than entertainment and a hit-single generator, we shouldn't sell \"The Monkees\" short. It was far better television than it had to be; during an era of formulaic domestic sitcoms and wacky comedies, it was a stylistically ambitious show, with a distinctive visual style, absurdist sense of humor and unusual story structure. Whatever Jones and the Monkees were meant to be, they became creative artists in their own right, and Jones' chipper Brit-pop presence was a big reason they were able to produce work that was commercial, wholesome, and yet impressively weird.\"\nMediaite columnist Paul Levinson noted, \"The Monkees were the first example of something created in a medium\u00a0\u2013 in this case, a rock band on television\u00a0\u2013 that jumped off the screen to have big impact in the real world.\""}
{"id": "9142", "revid": "10863197", "url": "https://en.wikipedia.org/wiki?curid=9142", "title": "Discharge", "text": "The word discharge has a number of applications, including:"}
{"id": "9145", "revid": "47188643", "url": "https://en.wikipedia.org/wiki?curid=9145", "title": "Druzism", "text": ""}
{"id": "9146", "revid": "237572", "url": "https://en.wikipedia.org/wiki?curid=9146", "title": "Dolly (sheep)", "text": "Dolly (5 July 1996 \u2013 14 February 2003) was a female Finn-Dorset sheep and the first mammal that was cloned from an adult somatic cell. She was cloned by associates of the Roslin Institute in Scotland, using the process of nuclear transfer from a cell taken from a mammary gland. Her cloning proved that a cloned organism could be produced from a mature cell from a specific body part. Contrary to popular belief, she was not the first animal to be cloned.\nThe employment of adult somatic cells in lieu of embryonic stem cells for cloning emerged from the foundational work of John Gurdon, who cloned African clawed frogs in 1958 with this approach. The successful cloning of Dolly led to widespread advancements within stem cell research, including the discovery of induced pluripotent stem cells.\nDolly lived at the Roslin Institute throughout her life and produced several lambs. She was euthanized at the age of six years due to a progressive lung disease. No cause which linked the disease to her cloning was found.\nDolly's body was preserved and donated by the Roslin Institute in Scotland to the National Museum of Scotland, where it has been regularly exhibited since 2003.\nGenesis.\nDolly was cloned by Keith Campbell, Ian Wilmut and colleagues at the Roslin Institute, part of the University of Edinburgh, Scotland, and the biotechnology company PPL Therapeutics, based near Edinburgh. The funding for Dolly's cloning was provided by PPL Therapeutics and the Ministry of Agriculture. She was born on 5 July 1996. She has been called \"the world's most famous sheep\" by sources including BBC News and \"Scientific American\".\nThe cell used as the donor for the cloning of Dolly was taken from a mammary gland, and the production of a healthy clone, therefore, proved that a cell taken from a specific part of the body could recreate a whole individual. On Dolly's name, Wilmut stated \"Dolly is derived from a mammary gland cell and we couldn't think of a more impressive pair of glands than Dolly Parton's.\"\nBirth.\nDolly was born on 5 July 1996 and had three mothers: one provided the egg, another the DNA, and a third carried the cloned embryo to term. She was created using the technique of somatic cell nuclear transfer, where the cell nucleus from an adult cell is transferred into an unfertilized oocyte (developing egg cell) that has had its cell nucleus removed. The hybrid cell is then stimulated to divide by an electric shock, and when it develops into a blastocyst it is implanted in a surrogate mother. Dolly was the first clone produced from a cell taken from an adult mammal. The production of Dolly showed that genes in the nucleus of such a mature differentiated somatic cell are still capable of reverting to an embryonic totipotent state, creating a cell that can then go on to develop into any part of an animal.\nDolly's existence was announced to the public on 22 February 1997. It gained much attention in the media. A commercial with Scottish scientists playing with sheep was aired on TV, and a special report in \"Time\" magazine featured Dolly. \"Science\" featured Dolly as the breakthrough of the year. Even though Dolly was not the first animal cloned, she received media attention because she was the first cloned from an adult cell.\nLife.\nDolly lived her entire life at the Roslin Institute in Midlothian. There she was bred with a Welsh Mountain ram and produced six lambs in total. Her first lamb, named Bonnie, was born in April 1998. The next year, Dolly produced twin lambs Sally and Rosie; further, she gave birth to triplets Lucy, Darcy and Cotton in 2000. In late 2001, at the age of four, Dolly developed arthritis and started to have difficulty walking. This was treated with anti-inflammatory drugs.\nDeath.\nOn 14 February 2003, Dolly was euthanised because she had a progressive lung disease and severe arthritis. A Finn Dorset such as Dolly has a life expectancy of around 11 to 12 years, but Dolly lived 6.5 years. A post-mortem examination showed she had a form of lung cancer called ovine pulmonary adenocarcinoma, also known as Jaagsiekte, which is a fairly common disease of sheep and is caused by the retrovirus JSRV. Roslin scientists stated that they did not think there was a connection with Dolly being a clone, and that other sheep in the same flock had died of the same disease. Such lung diseases are a particular danger for sheep kept indoors, and Dolly had to sleep inside for security reasons.\nSome in the press speculated that a contributing factor to Dolly's death was that she could have been born with a genetic age of six years, the same age as the sheep from which she was cloned. One basis for this idea was the finding that Dolly's telomeres were short, which is typically a result of the aging process. The Roslin Institute stated that intensive health screening did not reveal any abnormalities in Dolly that could have come from advanced aging.\nIn 2016, scientists reported no defects in thirteen cloned sheep, including four from the same cell line as Dolly. The first study to review the long-term health outcomes of cloning, the authors found no evidence of late-onset, non-communicable diseases other than some minor examples of osteoarthritis and concluded \"We could find no evidence, therefore, of a detrimental long-term effect of cloning by SCNT on the health of aged offspring among our cohort.\"\nAfter her death Dolly's body was preserved via taxidermy and is currently on display at the National Museum of Scotland in Edinburgh.\nLegacy.\nAfter cloning was successfully demonstrated through the production of Dolly, many other large mammals were cloned, including pigs, deer, horses and bulls. The attempt to clone argali (mountain sheep) did not produce viable embryos. The attempt to clone a banteng bull was more successful, as were the attempts to clone mouflon (a form of wild sheep), both resulting in viable offspring. The reprogramming process that cells need to go through during cloning is not perfect and embryos produced by nuclear transfer often show abnormal development. Making cloned mammals was highly inefficientin 1996, Dolly was the only lamb that survived to adulthood from 277 attempts. By 2014, Chinese scientists were reported to have 70\u201380% success rates cloning pigs, and in 2016, a Korean company, Sooam Biotech, was producing 500 cloned embryos a day. Wilmut, who led the team that created Dolly, announced in 2007 that the nuclear transfer technique may never be sufficiently efficient for use in humans.\nCloning may have uses in preserving endangered species, and may become a viable tool for reviving extinct species. In January 2009, scientists from the Centre of Food Technology and Research of Aragon in northern Spain announced the cloning of the Pyrenean ibex, a form of wild mountain goat, which was officially declared extinct in 2000. Although the newborn ibex died shortly after birth due to physical defects in its lungs, it is the first time an extinct animal has been cloned, and may open doors for saving endangered and newly extinct species by resurrecting them from frozen tissue.\nIn July 2016, four identical clones of Dolly (Daisy, Debbie, Dianna, and Denise) were alive and healthy at nine years old.\n\"Scientific American\" concluded in 2016 that the main legacy of Dolly has not been cloning of animals but in advances into stem cell research. Gene targeting was added in 2000, when researchers cloned female lamb Diana from sheep DNA altered to contain the human gene for alpha 1-antitrypsin. The human gene was specifically activated in the ewe\u2019s mammary gland, so Diana produced milk containing human alpha 1-antitrypsin. After Dolly, researchers realised that ordinary cells could be reprogrammed to induced pluripotent stem cells, which can be grown into any tissue.\nThe first successful cloning of a primate species was reported in January 2018, using the same method which produced Dolly. Two identical clones of a macaque monkey, Zhong Zhong and Hua Hua, were created by researchers in China and were born in late 2017.\nIn January 2019, scientists in China reported the creation of five identical cloned gene-edited monkeys, again using this method, and the gene-editing CRISPR-Cas9 technique allegedly used by He Jiankui in creating the first ever gene-modified human babies Lulu and Nana. The monkey clones were made in order to study several medical diseases.\nDolly in popular culture.\nIn 2003, the Belgian artist Dominique Goblet published a short comic strip about Dolly the cloned sheep with the title: \u201c2004 Apparition de Dolly dans la campagne anglaise\u201d\n\"Dolly The Sheep\" was initially released on November 13, 2012, as a flash game developed by the small game development company Pozirk Games, in which Dolly the cloned sheep is being chased by evil scientists. For some time the game was available to play online as well as on mobile devices. As of June 14, 2023, it is only available online for desktop/laptop computers."}
{"id": "9151", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=9151", "title": "Didjeridoo", "text": ""}
{"id": "9152", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=9152", "title": "Diablo II Lord of Destruction", "text": ""}
{"id": "9154", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=9154", "title": "Dakar Rallye", "text": ""}
{"id": "9156", "revid": "1843750", "url": "https://en.wikipedia.org/wiki?curid=9156", "title": "Dolores Fuller", "text": "Dolores Agnes Fuller ( Eble, later Chamberlin; March 10, 1923 \u2013 May 9, 2011) was an American actress and songwriter known as the one-time girlfriend of the low-budget film director Ed Wood. She played the protagonist's girlfriend in \"Glen or Glenda\", co-starred in Wood's \"Jail Bait\", and had a minor role in his \"Bride of the Monster\". After she broke up with Wood in 1955, she relocated to New York and had a very successful career there as a songwriter. Elvis Presley recorded a number of her songs written for his films.\nFilm career.\nHer first screen appearance was at the age of 10, when she appeared briefly in Frank Capra's \"It Happened One Night\". According to Fuller, the female lead in \"Bride of the Monster\" was written for her but Wood gave it to Loretta King instead.\nIn August 1954, Fuller was cast in Wood's \"The Vampire's Tomb\", intended to star Bela Lugosi. Frank Yaconelli was named as her co-star and 'comic killer'. The film was never made. She ended up making an appearance in \"Bride of the Monster\" (1956), also with Lugosi. Fuller hosted a benefit for Lugosi which preceded the showing of \"Bride of the Atom\" (early working title of \"Bride of the Monster\") on May 11, 1955. A cocktail party was held at the Gardens Restaurant at 4311 Magnolia Avenue in Burbank, California. Vampira attended and was escorted by Paul Marco. A single screening of the film was presented at the Hollywood Paramount.\nAccording to Fuller, as quoted in Wood biography \"Nightmare of Ecstasy\" (1992), she first met Ed Wood when she attended a casting call with a friend for a movie he was supposed to direct called \"Behind Locked Doors\" (which he did not go on to direct); it has also been stated that they met in a restaurant.\nShe became his girlfriend shortly thereafter and began acting in his films. Her movie career included a bit part in \"It Happened One Night\" (1934) and roles in \"Outlaw Women\" (1952), \"Glen or Glenda\" (1953), \"Body Beautiful\" (1953), \"The Blue Gardenia\" (1953), \"Count the Hours\" (1953), \"Mesa of Lost Women\" (1953), \"College Capers\" (1954), \"Jail Bait\" (1954), \"The Raid\" (1954), \"This Is My Love\" (1954), \"The Opposite Sex\" (1956), and many years later appearances in \"The Ironbound Vampire\" (1997) and \"Dimensions in Fear\" (1998).\nTelevision performer and songwriter.\nFuller had already had earlier experience on television in \"Queen for a Day\" and \"The Dinah Shore Show\".\nShe also appeared on an episode of \"It's a Great Life\" as \"the blonde in the mink coat.\"\nFuller's ability as a songwriter manifested itself through the intervention of her friend, producer Hal Wallis; Fuller had wanted to get an acting role in the Elvis Presley movie \"Blue Hawaii\", which Wallis was producing, but instead he put her in touch with Hill &amp; Range, the publisher that provided Presley with songs. Fuller went into a collaborative partnership with composer Ben Weisman and co-wrote one song, \"Rock-A-Hula Baby\", for the film. Over time, this led to Presley recording a dozen of her songs, including \"I Got Lucky\" and \"Spinout\", primarily for his film soundtracks, though he also recorded \"Cindy, Cindy\" for his 1971 album \"Love Letters From Elvis\". Fuller's music was also recorded by Nat 'King' Cole, Peggy Lee, and other leading talents of the time. Toward the end of her life, Dolores helped edit and score a short western film Ed Wood had begun, but never completed, in the 1940s called \"Crossroads of Laredo\"\nPrivate life.\nDolores married Donald Fuller in 1941, with whom she had two children. At the time she met Ed Wood, she was in the process of divorcing her husband (they finally divorced in 1955). She and Wood shared an apartment together for several years. Wood biographer Rudolph Grey quotes Fuller as saying of the period before her success, He [Ed Wood] begged me to marry him. I loved him in a way, but I couldn't handle the transvestism. I'm a very normal person. It's hard for me to deviate! I wanted a man that was all man\u2026 After we broke up, he would stand outside my home in Burbank and cry. \"Let me in, I love you!\" What good would I have done if I had married him? We would have starved together\u2026 I bettered myself. I had to uplift myself. She has also been quoted as saying that \"His dressing up didn't bother me\u2014we all have our little queer habits\" and giving Wood's drinking as the reason for their breakup.\nDolores remarried in 1988 at age 65, to Philip Chamberlin, and they remained married until her death in 2011. Fuller's autobiography, \"A Fuller Life: Hollywood, Ed Wood and Me\", co-authored by Stone Wallace and Philip Chamberlin, was published in 2008.\nPortrayal in \"Ed Wood\".\nFuller was portrayed by Sarah Jessica Parker in Tim Burton's 1994 Wood biographical film \"Ed Wood\", a portrayal of which she disapproved due to the fact that she was depicted smoking in the film, while Fuller said she herself was a lifelong non-smoker. She also complained that she was only portrayed as \"sort of as an actress\" and did not feel she was given credit for her other accomplishments and contributions towards Wood's career. However, she stated that she liked the film overall, praising Johnny Depp's performance in the title role.\nDiscography.\nSongs recorded by Elvis Presley with lyrics by Dolores Fuller:\nAccording to AllMusic, other songs co-written by her include \"I'll Touch a Star\" by Terry Stafford, \"Lost Summer Love\" by Shelley Fabares and \"Someone to Tell It To\" by Nat King Cole."}
{"id": "9158", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9158", "title": "Dr Strangelove", "text": ""}
{"id": "9160", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=9160", "title": "De jure", "text": "In law and government, de jure (; ; ) describes practices that are officially recognized by laws or other formal norms, regardless of whether the practice exists in reality. The phrase is often used in contrast with \"de facto\" ('in fact'), which describes situations that exist in reality, even if not formally recognized.\nDefinition.\n\"De jure\" is a Latin expression composed of the words \"de\" (from) and \"jure\" (adjective form of \"jus\", meaning 'law').\nUsage.\nJurisprudence and \"de jure\" law.\nIn U.S. law, particularly after \"Brown v. Board of Education\" (1954), the difference between \"de facto\" segregation (that existed because of voluntary associations and neighborhoods) and \"de jure\" segregation (that existed because of local laws) became important distinctions for court-mandated remedial purposes.\nGovernment and culture.\nBetween 1805 and 1914, the ruling dynasty of Egypt was subject to the rulers of the Ottoman Empire but acted as \"de facto\" independent rulers who maintained the polite fiction of Ottoman suzerainty. However, starting from around 1882, the rulers had only \"de jure\" rule over Egypt, as it had by then become a British puppet state. Thus, by Ottoman law, Egypt was \"de jure\" a province of the Ottoman Empire, but \"de facto\" was part of the British Empire.\nBorders.\nThe \"de jure\" borders of a country are defined by the area its government claims, but not necessarily controls. Modern examples include Taiwan (claimed but not controlled by China) and Kashmir (claimed by multiple countries)."}
{"id": "9163", "revid": "1273002360", "url": "https://en.wikipedia.org/wiki?curid=9163", "title": "Des Moines, Iowa", "text": "Des Moines ( ) is the capital and most populous city in the U.S. state of Iowa. It is the county seat of Polk County with parts extending into Warren County. It was incorporated on September 22, 1851, as Fort Des Moines, which was shortened to \"Des Moines\" in 1857. It is located on, and named after, the Des Moines River, which likely was adapted from the early French name, \"Rivi\u00e8re des Moines,\" meaning \"River of the Monks\". The city's population was 214,133 as of the 2020 census. The six-county metropolitan area is ranked 81st in terms of population in the United States, with 709,466 residents according to the 2020 census by the United States Census Bureau, and is the largest metropolitan area fully located within the state.\nDes Moines is a major center of the United States insurance industry and has a sizable financial-services and publishing business base. The city is the headquarters for the Principal Financial Group and Wellmark Blue Cross Blue Shield. Other major corporations such as Wells Fargo, Cognizant, Voya Financial, Nationwide Mutual Insurance Company, ACE Limited, Bayer, and Corteva have large operations in or near the metropolitan area. In recent years, Microsoft, Hewlett-Packard, and Facebook have built data-processing and logistical facilities in the Des Moines area.\nDes Moines is an important city in U.S. presidential politics; as the state's capital, it is the site of the first caucuses of the presidential primary cycle. Many presidential candidates set up campaign headquarters in Des Moines. A 2007 article in \"The New York Times\" said, \"If you have any desire to witness presidential candidates in the most close-up and intimate of settings, there is arguably no better place to go than Des Moines.\"\nHistory.\nEtymology.\nDes Moines takes its name from Fort Des Moines (1843\u201346), which was named for the Des Moines River. This was adopted from the name given by French colonists. \"Des Moines\" (; formerly ) translates literally to either \"from the monks\" or \"of the monks\".\nOne popular interpretation of \"Des Moines\" concludes that it refers to a group of French Trappist monks, who in the 17th century lived in huts built on top of what is now known as the ancient Monks Mound at Cahokia, the major center of Mississippian culture, which developed in what is present-day Illinois, east of the Mississippi River and the city of St. Louis. This was some from the Des Moines River.\nPrehistoric inhabitants of early Des Moines.\nBased on archaeological evidence, the junction of the Des Moines and Raccoon Rivers has attracted humans for at least 7,000 years. Several prehistoric occupation areas have been identified by archaeologists in downtown Des Moines. Discovered in December 2010, the \"Palace\" is an expansive 7,000-year-old site found during excavations prior to construction of the new wastewater treatment plant in southeast Des Moines. It contains well-preserved house deposits and numerous graves. More than 6,000 artifacts were found at this site. State of Iowa archaeologist John Doershuk was assisted by University of Iowa archaeologists at this dig.\nAt least three villages, dating from about AD 1300 to 1700, stood in or near what developed later as downtown Des Moines. In addition, 15 to 18 prehistoric Native American mounds were observed in the area by early settlers. All have been destroyed during development of the city.\nOrigin of Fort Des Moines.\nDes Moines traces its origins to May 1843, when Captain James Allen supervised the construction of a fort on the site where the Des Moines and Raccoon Rivers merge. Allen wanted to use the name Fort Raccoon; however, the U.S. War Department preferred Fort Des Moines. The fort was built to control the Sauk and Meskwaki peoples, whom the government had moved to the area from their traditional lands in eastern Iowa. The fort was abandoned in 1846 after the Sauk and Meskwaki were removed from the state and shifted to the Indian Territory.\nThe Sauk and Meskwaki did not fare well in Des Moines. The illegal whiskey trade, combined with the destruction of traditional lifeways, led to severe problems for their society. One newspaper reported:\n\"It is a fact that the location of Fort Des Moines among the Sac and Fox Indians (under its present commander) for the last two years, had corrupted them more and lowered them deeper in the scale of vice and degradation, than all their intercourse with the whites for the ten years previous\".After official removal, the Meskwaki continued to return to Des Moines until around 1857.\nArchaeological excavations have shown that many fort-related features survived under what is now Martin Luther King Jr. Parkway and First Street. Soldiers stationed at Fort Des Moines opened the first coal mines in the area, mining coal from the riverbank for the fort's blacksmith.\nEarly settlement.\nSettlers occupied the abandoned fort and nearby areas. On May 25, 1846, the state legislature designated Fort Des Moines as the seat of Polk County. Arozina Perkins, a school teacher who spent the winter of 1850\u20131851 in the town of Fort Des Moines, was not favorably impressed:\nThis is one of the strangest looking \"cities\" I ever saw... This town is at the juncture of the Des Moines and Raccoon Rivers. It is mostly a level prairie with a few swells or hills around it. We have a court house of \"brick\" and one church, a plain, framed building belonging to the Methodists. There are two taverns here, one of which has a most important little bell that rings together some fifty boarders. I cannot tell you how many dwellings there are, for I have not counted them; some are of logs, some of brick, some framed, and some are the remains of the old dragoon houses... The people support two papers and there are several dry goods shops. I have been into but four of them... Society is as varied as the buildings are. There are people from nearly every state, and Dutch, Swedes, etc.\nIn May 1851, much of the town was destroyed during the Flood of 1851. \"The Des Moines and Raccoon Rivers rose to an unprecedented height, inundating the entire country east of the Des Moines River. Crops were utterly destroyed, houses and fences swept away.\" The city started to rebuild from scratch.\nEra of growth.\nOn September 22, 1851, Des Moines was incorporated as a city; the charter was approved by voters on October 18. In 1857, the name \"Fort Des Moines\" was shortened to \"Des Moines\", and it was designated as the second state capital, previously at Iowa City. Growth was slow during the Civil War period, but the city exploded in size and importance after a railroad link was completed in 1866.\nIn 1864, the Des Moines Coal Company was organized to begin the first systematic mining in the region. Its first mine, north of town on the river's west side, was exhausted by 1873. The Black Diamond mine, near the south end of the West Seventh Street Bridge, sank a mine shaft to reach a coal bed. By 1876, this mine employed 150 men and shipped 20 carloads of coal per day. By 1885, numerous mine shafts were within the city limits, and mining began to spread into the surrounding countryside. By 1893, 23 mines were in the region. By 1908, Des Moines' coal resources were largely exhausted. In 1912, Des Moines still had eight locals of the United Mine Workers union, representing 1,410 miners. This was about 1.7% of the city's population in 1910.\nBy 1880, Des Moines had a population of 22,408, making it Iowa's largest city. It displaced the three Mississippi River ports: Burlington, Dubuque, and Davenport, that had alternated holding the position since the territorial period. Des Moines has remained Iowa's most populous city. In 1910, the Census Bureau reported Des Moines' population as 97.3% white and 2.7% black, reflecting its early settlement pattern primarily by ethnic Europeans.\n\"City Beautiful\" project, decline and rebirth.\nAt the turn of the 20th century, encouraged by the Civic Committee of the Des Moines Women's Club, Des Moines undertook a \"City Beautiful\" project in which large Beaux Arts public buildings and fountains were constructed along the Des Moines River. The former Des Moines Public Library building (now the home of the World Food Prize); the United States central Post Office, built by the federal government (now the Polk County Administrative Building, with a newer addition); and the City Hall are surviving examples of the 1900\u20131910 buildings. They form the Civic Center Historic District.\nThe ornate riverfront balustrades that line the Des Moines and Raccoon Rivers were built by the federal Civilian Conservation Corps in the mid-1930s, during the Great Depression under Democratic President Franklin D. Roosevelt, as a project to provide local employment and improve infrastructure. The ornamental fountains that stood along the riverbank were buried in the 1950s when the city began a postindustrial decline that lasted until the late 1980s. The city has since rebounded, transforming from a blue-collar industrial city to a white-collar professional city.\nIn 1907, the city adopted a city commission government known as the Des Moines Plan, comprising an elected mayor and four commissioners, all elected at-large, who were responsible for public works, public property, public safety, and finance. Considered progressive at the time, it diluted the votes of ethnic and national minorities, who generally could not command a majority to elect a candidate of their choice.\nThat form of government was scrapped in 1950 in favor of a council-manager government, with the council members elected at-large. In 1967, the city changed its government to elect four of the seven city council members from single-member districts or wards, rather than at-large. This enabled a broader representation of voters. As with many major urban areas, the city core began losing population to the suburbs in the 1960s (the peak population of 208,982 was recorded in 1960), as highway construction led to new residential construction outside the city. The population was 198,682 in 2000 and grew slightly to 200,538 in 2009. The growth of the outlying suburbs has continued, and the overall metropolitan-area population is over 700,000 today.\nDuring the Great Flood of 1993, heavy rains throughout June and early July caused the Des Moines and Raccoon Rivers to rise above flood stage levels. The Des Moines Water Works was submerged by floodwaters during the early morning hours of July 11, 1993, leaving an estimated 250,000 people without running water for 12 days and without drinking water for 20 days. Des Moines suffered major flooding again in June 2008 with a major levee breach. The Des Moines River is controlled upstream by Saylorville Reservoir. In both 1993 and 2008, the flooding river overtopped the reservoir spillway.\nToday, Des Moines is a member of ICLEI Local Governments for Sustainability USA. Through ICLEI, Des Moines has implemented \"The Tomorrow Plan\", a regional plan focused on developing central Iowa in a sustainable fashion, centrally-planned growth, and resource consumption to manage the local population.\nGeography.\nAccording to the United States Census Bureau, the city has an area of , of which is land and is covered by water. It is above sea level at the confluence of the Raccoon and Des Moines Rivers.\nIn November 2005, Des Moines voters approved a measure that allowed the city to annex parcels of land in the northeast, southeast, and southern corners of Des Moines without agreement by local residents, particularly areas bordering the Iowa Highway 5/U.S. 65 bypass. The annexations became official on June 26, 2009, as and around 868 new residents were added to the city of Des Moines. An additional were voluntarily annexed to the city over that same period.\nCityscape.\nThe skyline of Des Moines changed in the 1970s and the 1980s, when several new skyscrapers were built. Additional skyscrapers were built in the 1990s, including Iowa's tallest. Before then, the 19-story Equitable Building, from 1924, was the tallest building in the city and the tallest building in Iowa. The 25-story Financial Center was completed in 1973 and the 36-story Ruan Center was completed in 1974. They were later joined by the 33-story Des Moines Marriott Hotel (1981), the 25-story HUB Tower and 25-story Plaza Building (1985). Iowa's tallest building, Principal Financial Group's 45-story tower at 801 Grand was built in 1991, and the 19-story EMC Insurance Building was erected in 1997.\nDuring this time period, the Civic Center of Greater Des Moines (1979) was developed; it hosts Broadway shows and special events. Also constructed were the Greater Des Moines Botanical Garden (1979), a large city botanical garden/greenhouse on the east side of the river; the Polk County Convention Complex (1985), and the State of Iowa Historical Museum (1987). The Des Moines skywalk also began to take shape during the 1980s. The skywalk system is long and connects many downtown buildings.\nIn the early 21st century, the city has had more major construction in the downtown area. The new Science Center of Iowa and Blank IMAX Dome Theater and the Iowa Events Center opened in 2005. The new central branch of the Des Moines Public Library, designed by renowned architect David Chipperfield of London, opened on April 8, 2006.\nThe World Food Prize Foundation, which is based in Des Moines, completed adaptation and restoration of the former Des Moines Public Library building in October 2011. The former library now serves as the home and headquarters of the Norman Borlaug/World Food Prize Hall of Laureates.\nClimate.\nAt the center of North America and far removed from large bodies of water, the Des Moines area has a hot summer type humid continental climate (K\u00f6ppen \"Dfa\"), with warm to hot, humid summers and cold, dry winters. Summer temperatures can often climb into the range, occasionally reaching . Humidity can be high in spring and summer, with frequent afternoon thunderstorms. Fall brings pleasant temperatures and colorful fall foliage. Winters vary from moderately cold to bitterly cold, with low temperatures venturing below quite often. Snowfall averages per season, and annual precipitation averages , with a peak in the warmer months. Winters are slightly colder than Chicago, but still warmer than Minneapolis, with summer temperatures being very similar between the Upper Midwest metropolitan areas.\nDemographics.\nThe city has the largest African American population in Iowa.\n2020 census.\nThe 2020 United States census counted 214,133 people, 87,958 households, and 48,599 families in Des Moines. The population density was 2,428.4 per square mile (937.6/km). There were 95,082 housing units at an average density of 1,078.3 per square mile (416.3/km).\nThe racial makeup (including Hispanics in the racial counts) was 64.54% (138,200) white or European American (60.99% non-Hispanic white), 11.68% (25,011) black or African-American, 0.69% (1,474) Native American or Alaska Native, 6.76% (14,474) Asian, 0.06% (135) Pacific Islander or Native Hawaiian, 6.62% (14,178) from other races, and 9.65% (20,661) from two or more races.\nThe racial and ethnic makeup (where Hispanics are excluded from the racial counts and placed in their own category) was 60.99% (130,599) White alone (non-Hispanic), 11.46% (24,538) Black alone (non-Hispanic), 0.28% (597) Native American alone (non-Hispanic), 6.70% (14,348) Asian alone (non-Hispanic), 0.06% (124) Pacific Islander alone (non-Hispanic), 0.38% (817) Other Race alone (non-Hispanic), 4.50% (9,630) Multiracial or Mixed Race (non-Hispanic), and 15.64% (33,480) Hispanic or Latino.\nThe 2020 census population of the city included 252 people incarcerated in adult correctional facilities and 2,378 people in student housing.\nOf the 87,958 households, 28.0% had children under the age of 18; 35.5% were married couples living together; 31.3% had a female householder with no spouse or partner present. 35.3% of households consisted of individuals and 11.0% had someone living alone who was 65 years of age or older. The average household size was 2.5 and the average family size was 3.3. The percent of those with a bachelor's degree or higher was estimated to be 19.9% of the population. Of the population age 25 and over, 86.7% were high school graduates or higher and 27.9% had a bachelor's degree or higher.\n23.5% of the population was under the age of 18, 10.4% from 18 to 24, 29.6% from 25 to 44, 23.1% from 45 to 64, and 13.5% were 65 years of age or older. The median age was 34.8 years. For every 100 females, there were 102.7 males. For every 100 females ages 18 and older, there were 104.4 males.\nThe 2016-2020 5-year American Community Survey estimates show that the median household income was $54,843 (with a margin of error of +/- $1,544) and the median family income was $66,420 (+/- $1,919). Males had a median income of $38,326 (+/- $1,405) versus $29,855 (+/- $1,327) for females. The median income for those above 16 years old was $33,699 (+/- $740). Approximately, 12.1% of families and 16.0% of the population were below the poverty line, including 24.3% of those under the age of 18 and 9.8% of those ages 65 or over.\n2010 census.\nAs of the census of 2010, there were 203,433 people, 81,369 households, and 47,491 families residing in the city. Population density was . There were 88,729 housing units at an average density of . The racial makeup of the city for unincorporated areas not merged with the city proper was 66.2% White, 15.5% African Americans, 0.5% Native American, 4.0% Asian, and 2.6% from Two or more races. People of Hispanic or Latino origin, of any race, made up 12.1% of the population. The city's racial make up during the 2010 census was 76.4% White, 10.2% African American, 0.5% Native American, 4.4% Asian (1.2% Vietnamese, 0.9% Laotian, 0.4% Burmese, 0.3% Asian Indian, 0.3% Thai, 0.2% Chinese, 0.2% Cambodian, 0.2% Filipino, 0.1% Hmong, 0.1% Korean, 0.1% Nepalese), 0.1% Pacific Islander, 5.0% from other races, and 3.4% from two or more races. People of Hispanic or Latino origin, of any race, formed 12.0% of the population (9.4% Mexican, 0.7% Salvadoran, 0.3% Guatemalan, 0.3% Puerto Rican, 0.1% Honduran, 0.1% Ecuadorian, 0.1% Cuban, 0.1% Spaniard, 0.1% Spanish). Non-Hispanic Whites were 70.5% of the population in 2010. Des Moines also has a sizeable South Sudanese community.\nThere were 81,369 households, of which 31.6% had children under the age of 18 living with them, 38.9% were married couples living together, 14.2% had a female householder with no husband present, 5.3% had a male householder with no wife present, and 41.6% were non-families. 32.5% of all households were made up of individuals, and 9.4% had someone living alone who was 65 years of age or older. The average household size was 2.43 and the average family size was 3.11.\nThe median age in the city was 33.5 years. 24.8% of residents were under the age of 18; 10.9% were between the ages of 18 and 24; 29.4% were from 25 to 44; 23.9% were from 45 to 64; and 11% were 65 years of age or older. The gender makeup of the city was 48.9% male and 51.1% female.\n2000 census.\nAs of the 2000 census, there were 198,682 people, 80,504 households, and 48,704 families in the city. The population density was . There were 85,067 housing units at an average density of . The racial makeup of the city was 82.3% white, 8.07% Black, 0.35% American Indian, 3.50% Asian, 0.05% Pacific Islander, 3.52% from other races, and 2.23% from two or more races. 6.61% of the population were Hispanic or Latino of any race. 20.9% were of German, 10.3% Irish, 9.1% \"American\" and 8.0% English ancestry, according to Census 2000.\nThere were 80,504 households, out of which 29.5% had children under the age of 18 living with them, 43.7% were married couples living together, 12.6% had a female householder with no husband present, and 39.5% were non-families. 31.9% of all households were made up of individuals, and 10.2% had someone living alone who was 65 years of age or older. The average household size was 2.39 and the average family size was 3.04.\nThe age distribution was 24.8% under the age of 18, 10.6% from 18 to 24, 31.8% from 25 to 44, 20.4% from 45 to 64, and 12.4% who were 65 years of age or older. The median age was 34 years. For every 100 females, there were 93.8 males. For every 100 females age 18 and over, there were 90.5 males.\nThe median income for a household in the city was $38,408, and the median income for a family was $46,590. Males had a median income of $31,712 versus $25,832 for females. The per capita income for the city was $19,467. About 7.9% of families and 11.4% of the population were below the poverty line, including 14.9% of those under age 18 and 7.6% of those ages 65 or over.\nEconomy.\nMany insurance companies are headquartered in Des Moines, including the Principal Financial Group, Fidelity &amp; Guaranty Life, Allied Insurance, GuideOne Insurance, Wellmark Blue Cross Blue Shield of Iowa and FBL Financial Group. Iowa has one of the lowest insurance premium taxes in the nation at 1%, and does not charge any premium taxes on qualified life insurance plans, making the state attractive to insurance business. Des Moines has been referred to as the \"Hartford of the West\" and \"Insurance Capital\" because of this. Principal is one of two Fortune 500 companies with headquarters in Iowa (the other being Casey's General Stores), ranking 201st on the magazine's list in 2020.\nAs a center of financial and insurance services, other major corporations headquartered outside of Iowa have a presence in the Des Moines Metro area, including Wells Fargo, Voya Financial, and Electronic Data Systems (EDS). The Meredith Corporation, a leading publishing and marketing company, was also based in Des Moines prior to its acquisition by IAC and merger with Dotdash in 2021. Meredith published \"Better Homes and Gardens\", one of the most widely circulated publications in the United States. Des Moines was also the headquarters of \"Golf Digest\" magazine.\nOther major employers in Des Moines include UnityPoint Health, Mercy Medical Center, MidAmerican Energy Company, CDS Global, UPS, Firestone, Lumen Technologies, Drake University, Titan Tire, \"The Des Moines Register\", Anderson Erickson, EMCO.\nThe Brotherhood of American Yeomen, headquartered in Des Moines, went through various mergers before it became AmerUs, which was purchased by Aviva in 2006, for $2.9 billion. In 2017, Kemin Industries opened a state-of-the-art worldwide headquarters building in Des Moines.\nArts and culture.\nArts and theater.\nThe City of Des Moines is a cultural center for Iowa and home to several art and history museums and performing arts groups. The Des Moines Performing Arts routinely hosts touring Broadway shows and other live professional theater. The Temple for Performing Arts and Des Moines Playhouse are other venues for live theater, comedy, and performance arts.\nThe Des Moines Metro Opera has been a cultural resource in Des Moines since 1973. The Opera offers educational and outreach programs and is one of the largest performing arts organizations in the state. Ballet Des Moines was established in 2002. Performing three productions each year, the Ballet also provides opportunities for education and outreach.\nThe Des Moines Symphony performs frequently at different venues. In addition to performing seven pairs of classical concerts each season, the Symphony also entertains with New Year's Eve Pops and its annual Yankee Doodle Pops concerts.\n\"Jazz in July\" is an annual event founded in 1969 that performs free jazz shows daily at venues throughout the city during July.\nWells Fargo Arena is the Des Moines area's primary venue for sporting events and concerts since its opening in 2005. Named for title sponsor Wells Fargo Financial Services, Wells Fargo Arena holds 16,980 and books large, national touring acts for arena concert performances, while several smaller venues host local, regional, and national bands. It is the home of the Iowa Wolves of the NBA G League, the Iowa Wild of the American Hockey League, and the Iowa Barnstormers of the Indoor Football League.\nThe Simon Estes Riverfront Amphitheater is an outdoor concert venue on the east bank of the Des Moines River which hosts music events such as the Alive Concert Series.\nThe Des Moines Art Center, with wings designed by architects I.M. Pei and Richard Meier, presents art exhibitions and educational programs as well as studio art classes. The Center houses a collection of artwork from the 19th century to the present. An extension of the art center is downtown in an urban museum space, featuring three or four exhibitions each year.\nThe Pappajohn Sculpture Park was established in 2009. It showcases a collection of 24 sculptures donated by Des Moines philanthropists John and Mary Pappajohn. Nearby is the Temple for Performing Arts, a cultural center for the city. Next to the Temple is the Central Library, designed by renowned English architect David Chipperfield.\nSalisbury House and Gardens is a 42-room historic house museum on of woodlands in the South of Grand neighborhood of Des Moines. It is named after\u2014and loosely inspired by\u2014King's House in Salisbury, England. Built in the 1920s by cosmetics magnate Carl Weeks and his wife, Edith, the Salisbury House contains authentic 16th-century English oak and rafters dating to Shakespeare's days, numerous other architectural features re-purposed from other historic English homes, and an internationally significant collection of original fine art, tapestries, decorative art, furniture, musical instruments, and rare books and documents. The Salisbury House is listed on the National Register of Historic Places, and has been featured on A&amp;E's \"America's Castles\" and PBS's \"Antiques Roadshow\". Prominent artists in the Salisbury House collection include Joseph Stella, Lillian Genth, Anthony van Dyck and Lawrence Alma-Tadema.\nBuilt in 1877 by prominent pioneer businessman Hoyt Sherman, Hoyt Sherman Place mansion was Des Moines' first public art gallery and houses a distinctive collection of 19th and 20th century artwork. Its restored 1,250-seat theater features an intricate rococo plaster ceiling and excellent acoustics and is used for a variety of cultural performances and entertainment.\nAttractions.\nArising in the east and facing westward toward downtown, the Iowa State Capitol building with its , 23-karat gold leafed dome towering above the city is a favorite of sightseers. Four smaller domes flank the main dome. The Capitol houses the governor's offices, legislature, and the old Supreme Court Chambers. The ornate interior also features a grand staircase, mural \"Westward\", five-story law library, scale model of the USS \"Iowa\", and collection of first lady dolls. Guided tours are available.\nThe Capitol grounds include a World War II memorial with sculpture and Wall of Memories, the 1894 Soldiers and Sailors Monument of the Civil War and memorials honoring those who served in the Spanish\u2013American, Korean, and Vietnam Wars.\nThe West Capitol Terrace provides the entrance from the west to the state's grandest building, the State Capitol Building. The \"people's park\" at the foot of the Capitol complex includes a promenade and landscaped gardens, in addition to providing public space for rallies and special events. A granite map of Iowa depicting all 99 counties rests at the base of the terrace and has become an attraction for in-state visitors, many of whom walk over the map to find their home county.\nIowa's history lives on in the State of Iowa Historical Museum. This modern granite and glass structure at the foot of the State Capitol Building houses permanent and temporary exhibits exploring the people, places, events, and issues of Iowa's past. The showcase includes native wildlife, American Indian and pioneer artifacts, and political and military items. The museum features a genealogy and Iowa history library, museum gift shop, and cafe.\nTerrace Hill, a National Historic Landmark and Iowa Governor's Residence, is among the best examples of American Victorian Second Empire architecture. This opulent 1869 home was built by Iowa's first millionaire, Benjamin F. Allen, and restored to the late 19th century period. It overlooks downtown Des Moines and is situated on with a re-created Victorian formal garden. Tours are conducted Tuesdays through Saturdays from March through December.\nThe Science Center of Iowa and Blank IMAX Dome Theater offers seven interactive learning areas, live programs, and hands-on activities encouraging learning and fun for all ages. Among its three theaters include the 216-seat Blank IMAX Dome Theater, 175-seat John Deere Adventure Theater featuring live performances, and a domed Star Theater.\nThe Greater Des Moines Botanical Garden, an indoor conservatory of over 15,000 exotic plants, is one of the largest collections of tropical, subtropical, and desert-growing plants in the Midwest. The Center blooms with thousands of flowers year-round. Nearby are the Robert D. Ray Asian Gardens and Pavilion, named in honor of the former governor whose influence helped relocate thousands of Vietnamese refugees to Iowa homes in the 1970s and 1980s. Developed by the city's Asian community, the Gardens include a three-story Chinese pavilion, bonsai landscaping, and granite sculptures to highlight the importance of diversity and recognize Asian American contributions in Iowa.\nBlank Park Zoo is a landscaped zoological park on the south side. Among the exhibits include a tropical rain forest, Australian Outback, and Africa. The Zoo offers education classes, tours, and rental facilities.\nThe Iowa Primate Learning Sanctuary was established as a scientific research facility with a campus housing bonobos and orangutans for the noninvasive interdisciplinary study of their cognitive and communicative capabilities.\nThe East Village, on the east side of the Des Moines River, begins at the river and extends about five blocks east to the State Capitol Building, offering an eclectic blend of historic buildings, hip eateries, boutiques, art galleries, and a wide variety of other retail establishments mixed with residences.\nAdventureland Park is an amusement park in neighboring Altoona, just northeast of Des Moines. The park boasts more than 100 rides, shows, and attractions, including six rollercoasters. A hotel and campground is just outside the park. Also in Altoona is Prairie Meadows Racetrack and Casino, an entertainment venue for gambling and horse racing. Open 24 hours a day, year-round, the racetrack and casino features live racing, plus over 1,750 slot machines, table games, and concert and show entertainment. The racetrack hosts two Grade III races annually, the Iowa Oaks and the Cornhusker Handicap.\nLiving History Farms in suburban Urbandale tells the story of Midwestern agriculture and rural life in a open-air museum with interpreters dressed in period costume who recreate the daily routines of early Iowans. Open daily from May through October, the Living History Farms include a 1700 Ioway Indian village, 1850 pioneer farm, 1875 frontier town, 1900 horse-powered farm, and a modern crop center.\nWallace House was the home of the first Henry Wallace, a national leader in agriculture and conservation and the first editor of \"Wallaces' Farmer\" farm journal. This restored 1883 Italianate Victorian houses exhibits, artifacts, and information covering four generations of Henry Wallaces and other family members.\nHistoric Jordan House in West Des Moines is a stately Victorian home built in 1850 and added to in 1870 by the first white settler in West Des Moines, James C. Jordan. Completely refurbished, this mansion was part of the Underground Railroad and today houses 16 period rooms, a railroad museum, West Des Moines community history, and a museum dedicated to the Underground Railroad in Iowa. In 1893 Jordan's daughter Eda was sliding down the banister when she fell off and broke her neck. She died two days later, and her ghost is reputed to haunt the house.\nThe \"Chicago Tribune\" wrote that Iowa's capital city has \"walker-friendly downtown streets and enough outdoor sculpture, sleek buildings, storefronts and cafes to delight the most jaded stroller\".\nFestivals and events.\nDes Moines plays host to a growing number of nationally acclaimed cultural events, including the annual Des Moines Arts Festival in June, Metro Arts Jazz in July, Iowa State Fair in August, and the World Food &amp; Music Festival in September. On Saturdays from May through October, the Downtown Farmers' Market draws visitors from across the state. Local parades include Saint Patrick's Day Parade, Drake Relays Parade, Capitol City Pride Parade, Iowa State Fair Parade, Labor Day Parade, and Beaverdale Fall Festival Parade.\nOther annual festivals and events include: Des Moines Beer Week, 80/35 Music Festival, 515 Alive Music Festival, ArtFest Midwest, Blue Ribbon Bacon Fest, CelebrAsian Heritage Festival, Des Moines Pride Festival, Des Moines Renaissance Faire, Festa Italiana, Festival of Trees and Lights, World Food &amp; Music Festival, I'll Make Me a World Iowa, Latino Heritage Festival, Oktoberfest, Winefest, ImaginEve!, Iowa's Premier Beer, Wine &amp; Food Show, and Wild Rose Film Festival.\nSports.\nDes Moines hosts professional minor league teams in several sports \u2014 baseball, basketball, hockey, indoor football, and soccer \u2014 and is home to the sports teams of Drake University which play in NCAA Division I.\nThe Des Moines Menace soccer club, a member of USL League Two, play their home games at Valley Stadium in West Des Moines. Des Moines United FC of the National Premier Soccer League also utilize Valley Stadium.\nDes Moines is home to the Iowa Cubs baseball team of the Triple-A East. The I-Cubs, which are the Triple-A affiliate of the major league Chicago Cubs, play their home games at Principal Park near the confluence of the Des Moines and Raccoon Rivers.\nWells Fargo Arena of the Iowa Events Center is home to the Iowa Barnstormers of the Indoor Football League, the Iowa Wild of the American Hockey League, and the Iowa Wolves of the NBA G League. The Barnstormers relaunched as an af2 club in 2008 before joining a relaunched Arena Football League in 2010 and the Indoor Football League in 2015; the Barnstormers had previously played in the Arena Football League from 1994 to 2000 (featuring future NFL Hall of Famer and Super Bowl MVP quarterback Kurt Warner) before relocating to New York. The Iowa Energy, a D-League team, began play in 2007. They were bought by the Minnesota Timberwolves in 2017 and were renamed the Iowa Wolves to reflect the new ownership. The Wild, the AHL affiliate of the National Hockey League's Minnesota Wild have played at Wells Fargo Arena since 2013; previously, the Iowa Chops played four seasons in Des Moines (known as the Iowa Stars for three of those seasons.)\nAdditionally, the Des Moines Buccaneers of the United States Hockey League play at Buccaneer Arena in suburban Urbandale.\nDes Moines is also home to the Drake University Bulldogs, an NCAA Division I member of the Missouri Valley Conference, primarily playing northwest of downtown at the on-campus Drake Stadium and Knapp Center. Drake Stadium is home to the famed Drake Relays each April. In addition to the Drake Relays, Drake Stadium has hosted multiple NCAA Outdoor Track and Field Championships and USA Outdoor Track and Field Championships.\nThe Vikings of Grand View University also compete in intercollegiate athletics in Des Moines. A member of the Heart of America Athletic Conference, within the NAIA, they field 21 varsity athletic teams. They were NAIA National Champions in football in 2013.\nThe Principal Charity Classic, a Champions Tour golf event, is held at Wakonda Club in late May or early June. The IMT Des Moines Marathon is held throughout the city each October.\nParks and recreation.\nDes Moines has 76 city parks and three golf courses, as well as three family aquatic centers, five community centers and three swimming pools. The city has of trails. The first major park was Greenwood Park. The park commissioners purchased the land on April 21, 1894.\nThe Principal Riverwalk is a riverwalk park district being constructed along the banks of the Des Moines River in the downtown. Primarily funded by the Principal Financial Group, the Riverwalk is a multi-year jointly funded project also funded by the city and state. Upon completion, it will feature a recreational trail connecting the east and west sides of downtown via two pedestrian bridges. A landscaped promenade along the street level is planned. The Riverwalk includes the downtown Brenton Skating Plaza, open from November through March.\nGray's Lake, part of the of Gray's Lake Park, features a boat rental facility, fishing pier, floating boardwalks, and a park resource center. Located just south of the downtown, the centerpiece of the park is a lighted Kruidenier Trail, encircling it entirely.\nFrom downtown Des Moines primarily along the east bank of the Des Moines River, the Neil Smith and John Pat Dorrian Trails are paved recreational trails that connect Gray's Lake northward to the east shore of Saylorville Lake, Big Creek State Park, and the recreational trails of Ankeny including the High Trestle Trail. These trails are near several recreational facilities including the Pete Crivaro Park, Principal Park, the Principal Riverwalk, the Greater Des Moines Botanical Garden, Union Park and its Heritage Carousel of Des Moines, Birdland Park and the Birdland Marina/Boatramp on the Des Moines River, Riverview Park, McHenry Park, and River Drive Park. Although outside of Des Moines, Jester Park has of land along the western shore of Saylorville Lake and can be reached from the Neil Smith Trail over the Saylorville Dam.\nJust west of Gray's Lake are the of the Des Moines Water Works Park. The Water Works Park is along the banks of the Raccoon River immediately upstream from where the Raccoon River empties into the Des Moines River. The Des Moines Water Works Facility, which obtains the city's drinking water from the Raccoon River, is entirely within the Water Works Park. A bridge in the park crosses the Raccoon River. The Water Works Park recreational trails link to downtown Des Moines by travelling past Gray's Lake and back across the Raccoon River via either along the Meredith Trail near Principal Park, or along the Martin Luther King Jr. Parkway. The Water Works Park trails connect westward to Valley Junction and the recreational trails of the western suburbs: Windsor Heights, Urbandale, Clive, and Waukee. Also originating from Water Works Park, the Great Western Trail is an journey southward from Des Moines to Martensdale through the Willow Creek Golf Course, Orilla, and Cumming. Often, the location for summer music festivals and concerts, Water Works Park was the overnight campground for thousands of bicyclists on Tuesday, July 23, 2013, during RAGBRAI XLI.\nHeadquartered in Des Moines.\nGold and Silver investment news- Investment Advisor of Gold &amp; Silver Investment News of Investors, Retirement Planners, Retirees of IRA Company In USA\nGovernment.\nDes Moines operates under a council\u2013manager form of government. The council consists of a mayor who is elected in citywide vote, two at-large members, and four members representing each of the city's four wards. In 2014, Jonathan Gano was appointed as the new Public Works Director. In 2015, Dana Wingert was appointed as Police Chief. In 2018, Steven L. Naber was appointed as the new City Engineer.\nThe council members include:\nA plan to merge the governments of Des Moines and Polk County was rejected by voters during the November 2, 2004, election. The consolidated city-county government would have had a full-time mayor and a 15-member council that would have been divided among the city and its suburbs. Each suburb would still have retained its individual government but with the option to join the consolidated government at any time. Although a full merger was soundly rejected, several city and county departments and programs have been consolidated.\nEducation.\nThe Des Moines Public Schools district is the largest community school district in Iowa with 32,062 enrolled students as of the 2012\u20132013 school year. The district consists of 63 schools: 38 elementary schools, eleven middle schools, five high schools (East, Hoover, Lincoln, North, and Roosevelt), and ten special schools and programs. Small parts of the city are instead served by Carlisle Community Schools, Johnston Community School District, the Southeast Polk Community School District and the Saydel School District Grand View Christian School is the only private school in the city, although Des Moines Christian School (in Des Moines from 1947 to 2006) in Urbandale, Dowling Catholic High School in West Des Moines, and Ankeny Christian Academy on the north side of the metro area serve some city residents.\nDes Moines is also home to the main campuses of three four-year private colleges: Drake University, Grand View University, and Mercy College of Health Sciences. The University of Iowa has a satellite facility in the city's Western Gateway Park, while Iowa State University hosts Master of Business Administration classes downtown. Des Moines Area Community College is the area's community college with campuses in Ankeny, Des Moines, and West Des Moines. The city is also home to Des Moines University, an osteopathic medical school.\nMedia.\nThe Des Moines market, which originally consisted of Polk, Dallas, Story, and Warren counties, was ranked 91st by Arbitron as of the fall of 2007 with a population of 512,000 aged 12 and older. In June 2011 it moved up to 72nd with the addition of Boone, Clarke, Greene, Guthrie, Jasper, Lucas, Madison and Marion counties.\nRadio.\nCommercial stations.\niHeartMedia owns five radio stations in the area, including WHO 1040\u00a0AM, a 50,000-watt AM news/talk station that has the highest ratings in the area and once employed future President Ronald Reagan as a sportscaster. In addition to WHO, iHeartMedia owns KDRB 100.3 FM (adult hits), KKDM 107.5 FM (contemporary hits), KXNO-FM 106.3, and KXNO 1460\u00a0AM (sports radio). They also own news/talk station KASI 1430\u00a0AM and hot adult contemporary station KCYZ 105.1 FM, both of which broadcast from Ames.\nCumulus Media owns five stations that broadcast from facilities in Urbandale: KBGG 1700\u00a0AM (sports), KGGO 94.9 FM (classic rock), KHKI 97.3 FM (country music), KJJY 92.5 FM (country music), and KWQW 98.3 FM (contemporary hits).\nSaga Communications owns nine stations in the area: KAZR 103.3 FM (rock), KAZR-HD2 (oldies), KIOA 93.3 FM (oldies), KIOA-HD2 99.9FM &amp; 93.3 HD2 (Rhythmic Top 40), KOEZ 104.1 FM (soft adult contemporary), KPSZ 940\u00a0AM (contemporary Christian music, religious teaching, and conservative talk), KRNT 1350\u00a0AM (ESPN Radio), KSTZ 102.5 FM (adult contemporary hits), and KSTZ-HD2 (classic country).\nOther stations in the Des Moines area include religious stations KWKY 1150\u00a0AM, and KPUL 101.7 FM.\nNon-commercial stations.\nNon-commercial radio stations in the Des Moines area include KDPS 88.1 FM, a station operated by the Des Moines Public Schools; KWDM 88.7 FM, a station operated by Valley High School; KJMC 89.3 FM, an urban contemporary station; K213DV 90.5 FM, the contemporary Christian K-Love affiliate for the area; and KDFR 91.3 FM, operated by Family Radio. Iowa Public Radio broadcasts several stations in the Des Moines area, all of which are owned by Iowa State University and operated on campus. WOI 640\u00a0AM, the network's flagship station, and WOI-FM 90.1, the network's flagship \"Studio One\" station, are both based out of Ames and serve as the area's National Public Radio outlets. The network also operates classical stations KICG, KICJ, KICL and KICP. The University of Northwestern \u2013 St. Paul operates Contemporary Christian simulcasts of KNWI-FM at 107.1 Osceola/Des Moines, KNWM-FM at 96.1 Madrid/Ames/Des Moines, and K264CD at 100.7 in downtown Des Moines. Low-power FM stations include KFMG-LP 99.1, a community radio station broadcasting from the Hotel Fort Des Moines and also webstreamed.\nTelevision.\nThe Des Moines-Ames media market consists of 35 central Iowa counties: Adair, Adams, Appanoose, Audubon, Boone, Calhoun, Carroll, Clarke, Dallas, Decatur, Franklin, Greene, Guthrie, Hamilton, Hardin, Humboldt, Jasper, Kossuth, Lucas, Madison, Mahaska, Marion, Marshall, Monroe, Pocahontas, Polk, Poweshiek, Ringgold, Story, Taylor, Union, Warren, Wayne, Webster, and Wright. It was ranked 71st by Nielsen Media Research for the 2008\u20132009 television season with 432,410 television households.\nCommercial television stations serving Des Moines include CBS affiliate KCCI channel 8, NBC affiliate WHO-DT channel 13, and Fox affiliate KDSM-TV channel 17. ABC affiliate WOI-TV channel 5 and CW affiliate KCWI-TV channel 23 are both licensed to Ames and broadcast from studios in West Des Moines. KFPX-TV channel 39, the local ION affiliate, is licensed to Newton. Two non-commercial stations are also licensed to Des Moines: KDIN channel 11, the local PBS member station and flagship of the Iowa Public Television network, and KDMI channel 19, a TCT affiliate. Mediacom is the Des Moines area's cable television provider.\nPrint.\n\"The Des Moines Register\" is the city's primary daily newspaper. As of March 31, 2007, the \"Register\" ranked 71st in circulation among daily newspapers in the United States according to the Audit Bureau of Circulations with 146,050 daily and 233,229 Sunday subscribers. Weekly newspapers include \"Juice\", a publication aimed at the 25\u201334 demographic published by the \"Register\" on Wednesdays; \"Cityview\", an alternative weekly published on Thursdays; and the \"Des Moines Business Record\", a business journal published on Sundays, along with the West Des Moines Register, the Johnston Register, and the Waukee Register on Tuesdays, Wednesdays, or Thursdays depending on the address of the subscriber. Additionally, magazine publisher Meredith Corporation was based in Des Moines prior to its acquisition by IAC and merger with Dotdash in 2021.\nMusic.\nDes Moines is the birthplace of many famously known bands and artists today. Slipknot, a popular American heavy metal band, was founded in 1995 by percussionist Shawn Crahan, former vocalist Anders Colsefni and bassist Paul Gray; the band would be also founded by Joey Jordison. The band was signed to RoadRunner Records and has become one of the biggest bands in the metal world. The band is still very popular to this day, and is known worldwide for their unique sound and their traumatic upbringing in their early days.\nStone Sour, an American rock band, was founded in 1992 by Corey Taylor and former drummer Joel Ekman. Corey would later go on to become the lead singer for Slipknot. The band has since been on an indefinite hiatus since 2020.\nVended, an American heavy metal band, was founded in 2018 by Griffin Taylor and Simon Crahan, who are the sons of popular Corey Taylor and Shawn \"Clown\" Crahan from Slipknot. They are currently an independent band that has released one studio album in 2024 called \"Vended\" and several singles and one EP. The band has seen growing success in the past few years, including their 2022 Vended tour in the United States with Jinjer and P.O.D.\nInfrastructure.\nTransportation.\nDes Moines has an extensive skywalk system within its downtown core. With over four miles of enclosed walkway, it is one of the largest of such systems in the United States. The Des Moines Skywalk System has been criticized for hurting street-level business, though a recent initiative has been made to make street-level Skywalk entrances more visible.\nInterstate 235 (I-235) cuts through the city, and I-35 and I-80 both pass through the Des Moines metropolitan area, as well as the city of Des Moines. On the northern side of the city of Des Moines and passing through the cities of Altoona, Clive, Johnston, Urbandale and West Des Moines, I-35 and I-80 converge into a long concurrency while I-235 takes a direct route through Des Moines, Windsor Heights, and West Des Moines before meeting up with I-35 and I-80 on the western edge of the metro. The Des Moines Bypass passes south and east of the city. Other routes in and around the city include US\u00a06, US\u00a069, Iowa\u00a028, Iowa\u00a0141, Iowa\u00a0163, Iowa\u00a0330, Iowa\u00a0415, and Iowa\u00a0160.\nDes Moines's public transit system, operated by DART (Des Moines Area Regional Transit), which was the Des Moines Metropolitan Transit Authority until October 2006, consists entirely of buses, including regular in-city routes and express and commuter buses to outlying suburban areas.\nCharacteristics of household ownership of cars in Des Moines are similar to national averages. In 2015, 8.5 percent of Des Moines households lacked a car, and that number increased to 9.6 percent in 2016. The national average was 8.7 percent in 2016. Des Moines averaged 1.71 cars per household in 2016, compared to a national average of 1.8.\nBurlington Trailways and Jefferson Lines run long-distance, intercity bus routes through Des Moines. The bus station is located north of downtown. \nAlthough Des Moines was historically a train hub, it does not have direct passenger train service. For east\u2013west traffic it was served at the Rock Island Depot by the \"Corn Belt Rocket\" express from Omaha to the west, to Chicago in the east. The Rock Island also offered the \"Rocky Mountain Rocket\" from Colorado Springs in the west, to Chicago, and the \"Twin Star Rocket\" to Minneapolis to the north and Dallas and Houston to the south. The last train was an unnamed service ending at Council Bluffs, and it was discontinued on May 31, 1970. Today, this line constitutes the mainline of the Iowa Interstate Railroad.\nOther railroads used the East Des Moines Union Station. Northward and northwest bound, there were Chicago and North Western trains to destinations including Minneapolis. The Wabash Railroad ran service to the southeast to St. Louis. These lines remain in use but are now operated by Union Pacific and BNSF.\nThe nearest Amtrak station is in Osceola, about south of Des Moines. The Osceola station is served by the Chicago\u2013San Francisco \"California Zephyr\"; there is no Osceola\u2013Des Moines Amtrak Thruway connecting service. There have been proposals to extend Amtrak's planned Chicago\u2013Moline \"Quad City Rocket\" to Des Moines via the Iowa Interstate Railroad.\nThe Des Moines International Airport (DSM), on Fleur Drive in the southern part of Des Moines, offers nonstop service to destinations within the United States. The only international service is cargo service, but there have been discussions about adding an international terminal.\nSister cities.\nThe Greater Des Moines Sister City Commission, with members from the City of Des Moines and the suburbs of Cumming, Norwalk, Windsor Heights, Johnston, Urbandale, and Ankeny, maintains sister city relationships with:"}
{"id": "9164", "revid": "1271411157", "url": "https://en.wikipedia.org/wiki?curid=9164", "title": "Donald Campbell", "text": "Donald Malcolm Campbell, (23 March 1921\u00a0\u2013 4 January 1967) was a British speed record breaker who broke eight absolute world speed records on water and on land in the 1950s and 1960s. He remains the only person to set both world land and water speed records in the same year (1964). He died during a water speed record attempt at Coniston Water in the Lake District, England.\nFamily and personal life.\nDonald Malcolm Campbell was born at Canbury House, Kingston upon Thames, Surrey, the son of Malcolm, later Sir Malcolm Campbell, holder of 13 world speed records in the 1920s and 1930s in the \"Bluebird\" cars and boats, and his second wife, Dorothy Evelyn (n\u00e9e Whittall).\nCampbell attended St Peter's School, Seaford in East Sussex, and Uppingham School in Rutland. At the outbreak of the Second World War he volunteered for the Royal Air Force, but was unable to serve because of a case of childhood rheumatic fever. He joined Briggs Motor Bodies Ltd in West Thurrock, where he became a maintenance engineer. Subsequently, he was a shareholder in a small engineering company called Kine Engineering, producing machine tools. Following his father's death on 31 December 1948 and aided by Malcolm's chief engineer, Leo Villa, the younger Campbell strove to set speed records first on water and then land.\nHe married three times\u00a0\u2014 to Daphne Harvey in 1945, producing daughter Georgina (Gina) Campbell, born on 19 September 1946; to Dorothy McKegg (1928\u20132008) in 1952; and to Tonia Bern (1928\u20132021) in December 1958, which union lasted until his death in 1967. Campbell was intensely superstitious, hating the colour green, the number thirteen and believing nothing good ever happened on a Friday. He also had some interest in the paranormal, which he nurtured as a member of the Ghost Club.\nWater speed records.\nCampbell began his speed record attempts in the summer of 1949, using his father's old boat, \"Blue Bird K4\", which he renamed \"Bluebird K4\". His initial attempts that summer were unsuccessful, although he did come close to raising his father's existing record. The team returned to Coniston Water, Lancashire in 1950 for further trials. While there, they heard that an American, Stanley Sayres, had raised the record from , beyond K4's capabilities without substantial modification.\nIn late 1950 and 1951, \"Bluebird K4\" was modified to make it a \"prop-rider\" as opposed to her original immersed propeller configuration. This greatly reduced hydrodynamic drag: The third planing point would now be the propeller hub, meaning one of the two propeller blades was always out of the water at high speed. She now sported two cockpits, the second one being for Leo Villa.\n\"Bluebird K4\" now had a chance of exceeding Sayres' record and also enjoyed success as a circuit racer, winning the Oltranza Cup in Italy in the spring of that year. Returning to Coniston in September, they finally got \"Bluebird\" up to 170\u00a0mph after further trials, only to suffer a structural failure at which wrecked the boat. Sayres raised the record the following year to in Slo-Mo-Shun IV.\nAlong with Campbell, Britain had another potential contender for water speed record honours\u00a0\u2014 John Cobb. He had commissioned the world's first purpose-built turbojet Hydroplane, \"Crusader\", with a target speed of over , and began trials on Loch Ness in autumn 1952. Cobb was killed later that year, when Crusader broke up, during an attempt on the record. Campbell was devastated at Cobb's loss, but he resolved to build a new \"Bluebird\" boat to bring the water speed record back to Britain.\nIn early 1953, Campbell began development of his own advanced all-metal jet-powered \"Bluebird K7\" hydroplane to challenge the record, by now held by the American prop rider hydroplane Slo-Mo-Shun IV.[1] Designed by Ken and Lew Norris, the K7 was a steel-framed, aluminium-bodied, three-point hydroplane with a Metropolitan-Vickers Beryl axial-flow turbojet engine, producing 3,500-pound-force (16\u00a0kN) of thrust.\nLike Slo-Mo-Shun, but unlike Cobb's tricycle Crusader, the three planing points were arranged with two forward, on outrigged sponsons and one aft, in a \"pickle-fork\" layout, prompting \"Bluebird\"s early comparison to a blue lobster. K7 was of very advanced design and construction, and its load bearing steel space frame ultra rigid and stressed to 25 g (exceeding contemporary military jet aircraft). It had a design speed of and remained the only successful jet-boat in the world until the late 1960s.\nThe designation \"K7\" was derived from its Lloyd's unlimited rating registration. It was carried on a prominent white roundel on each sponson, underneath an infinity symbol. \"Bluebird K7\" was the seventh boat registered at Lloyds in the \"Unlimited\" series.\nCampbell set seven world water speed records in K7 between July 1955 and December 1964. The first of these marks was set at Ullswater on 23 July 1955, where he achieved a speed of but only after many months of trials and a major redesign of \"Bluebird\"s forward sponson attachments points. Campbell achieved a steady series of subsequent speed-record increases with the boat during the rest of the decade, beginning with a mark of in 1955 on Lake Mead in Nevada. Subsequently, four new marks were registered on Coniston Water, where Campbell and \"Bluebird\" became an annual fixture in the latter half of the 1950s, enjoying significant sponsorship from the Mobil oil company and then subsequently BP.\nCampbell also made an attempt in the summer of 1957 at Canandaigua, New York, which failed due to lack of suitable calm water conditions. \"Bluebird K7\" became a well known and popular attraction, and as well as her annual Coniston appearances, \"K7\" was displayed extensively in the UK, United States, Canada and Europe, and then subsequently in Australia during Campbell's prolonged attempt on the land speed record in 1963\u20131964.\nTo extract more speed, and endow the boat with greater high-speed stability, in both pitch and yaw, \"K7\" was subtly modified in the second half of the 1950s to incorporate more effective streamlining with a blown Perspex cockpit canopy and fluting to the lower part of the main hull. In 1958, a small wedge shaped tail fin, housing an arrester parachute, modified sponson fairings, that gave a significant reduction in forward aerodynamic lift, and a fixed hydrodynamic stabilising fin, attached to the transom to aid directional stability, and exert a marginal down-force on the nose were incorporated into the design to increase the safe operating envelope of the hydroplane. Thus she reached in 1956, where an unprecedented peak speed of was achieved on one run, in 1957, in 1958 and in 1959.\nCampbell was named as a Commander of the British Empire (CBE) in January 1957 for his water speed record breaking, and in particular his record at Lake Mead in the United States which earned him and Britain very positive acclaim.\nOn 23 November 1964, Campbell achieved the Australian water speed record of on Lake Bonney Riverland in South Australia, although he was unable to break the world record on that attempt.\nLand speed record attempt.\nIt was after the Lake Mead water speed record success in 1955 that the seeds of Campbell's ambition to hold the land speed record as well were planted. The following year, the serious planning was under way\u00a0\u2014 to build a car to break the land speed record, which then stood at set by John Cobb in 1947. The Norris brothers designed \"Bluebird-Proteus CN7\" with in mind.\nThe British motor industry, in the guise of Dunlop, BP, Smiths Industries, Lucas Automotive, Rubery Owen as well as many others, became heavily involved in the project to build the most advanced car the world had yet seen. CN7 was powered by a specially modified Bristol-Siddeley Proteus free-turbine engine of driving all four wheels. \"Bluebird CN7\" was designed to achieve 475\u2013500\u00a0mph and was completed by the spring of 1960.\nFollowing low-speed tests conducted at the Goodwood motor racing circuit in Sussex, in July, the \"CN7\" was taken to the Bonneville Salt Flats in Utah, United States, scene of his father's last land speed record triumph, some 25 years earlier in September 1935. The trials initially went well, and various adjustments were made to the car. On the sixth run in CN7, Campbell lost control at over 360\u00a0mph and crashed. It was the car's tremendous structural integrity that saved his life. He was hospitalised with a fractured skull and a burst eardrum, as well as minor cuts and bruises, but \"CN7\" was a write-off. Almost immediately, Campbell announced he was determined to have another go. Sir Alfred Owen, whose Rubery Owen industrial group had built CN7, offered to rebuild it for him. That single decision was to have a profound influence on the rest of Campbell's life. His original plan had been to break the land speed record at over 400\u00a0mph in 1960, return to Bonneville the following year to really bump up the speed to something near to 500\u00a0mph, get his seventh water speed record with K7 and then retire.\nCampbell decided not to go back to Utah for the new trials. He felt the Bonneville course was too short at and the salt surface was in poor condition. BP offered to find another venue and eventually after a long search, Lake Eyre, in South Australia, was chosen. It hadn't rained there for nine years and the vast dry bed of the salt lake offered a course of up to . By the summer of 1962, \"Bluebird CN7\" was rebuilt, some nine months later than Campbell had hoped. It was essentially the same car, but with the addition of a large stabilising tail fin and a reinforced fibreglass cockpit cover. At the end of 1962, \"CN7\" was shipped out to Australia ready for the new attempt. Low-speed runs had just started when the rains came. The course was compromised and further rain meant, that by May 1963, Lake Eyre was flooded to a depth of 3 inches, causing the attempt to be abandoned. Campbell was heavily criticised in the press for alleged time wasting and mismanagement of the project, despite the fact that he could hardly be held responsible for the unprecedented weather.\nTo make matters worse for Campbell, American Craig Breedlove drove his pure thrust jet car \"Spirit of America\" to a speed of at Bonneville in July 1963. Although the \"car\" did not conform to FIA (Federation Internationale de L'Automobile) regulations, that stipulated it had to be wheel-driven and have a minimum of four wheels, in the eyes of the world, Breedlove was now the fastest man on Earth.\nCampbell returned to Australia in March 1964, but the Lake Eyre course failed to fulfil the early promise it had shown in 1962 and there were further spells of rain. BP pulled out as his main sponsor after a dispute, but he was able to secure backing from Australian oil company Ampol.\nThe track never properly dried out and Campbell was forced to make the best of the conditions. Finally, in July 1964, he was able to post some speeds that approached the record. On the 17th of that month, he took advantage of a break in the weather and made two courageous runs along the shortened and still damp track, posting a new land speed record of . The surreal moment was captured in a number of well-known images by photographers, including Australia's Jeff Carter.\nCampbell was bitterly disappointed with the record as the vehicle had been designed for much higher speeds. \"CN7\" covered the final third of the measured mile at an average of , peaking as it left the measured distance at over . He resented the fact that it had all been so difficult. \"We've made it\u00a0\u2014 we got the bastard at last,\" was his reaction to the success. Campbell's 403.1\u00a0mph represented the official land speed record.\nIn 1969, after Campbell's fatal accident, his widow, Tonia Bern-Campbell negotiated a deal with Lynn Garrison, president of Craig Breedlove and Associates, that would see Craig Breedlove run \"Bluebird\" on Bonneville's Salt Flats. This concept was cancelled when the parallel Spirit of America supersonic car project failed to find support.\nDouble records.\nCampbell now planned to go after the water speed record one more time with \"Bluebird K7\"\u00a0\u2014 to do what he had aimed for so many years earlier, during the initial planning stages of CN7\u00a0\u2014 break both records in the same year. After more delays, he finally achieved his seventh water speed record at Lake Dumbleyung near Perth, Western Australia, on the last day of 1964, at a speed of . He had become the first, and so far only, person to set both land and water speed records in the same year.\nCampbell's land speed record was short-lived, because FIA rule changes meant that pure jet cars would be eligible to set records from October 1964. Campbell's speed on his final Lake Eyre run remained the highest speed achieved by a wheel-driven car until 2001; \"Bluebird CN7\" is now on display at the National Motor Museum at Beaulieu in Hampshire, England, its potential only partly realised.\nRocket car plans and final water speed record attempt.\nBluebird Mach 1.1.\nCampbell decided a massive jump in speed was called for following his successful 1964 land speed record attempt in \"Bluebird CN7\". His vision was of a supersonic rocket car with a potential maximum speed of . Norris Brothers were requested to undertake a design study. \"Bluebird Mach 1.1\" was a design for a rocket-powered supersonic land speed record car. Campbell chose a lucky date to hold a press conference at the Charing Cross Hotel on 7 July 1965 to announce his future record breaking plans:\n\"Bluebird Mach 1.1\" was to be rocket-powered. Ken Norris had calculated using rocket motors would result in a vehicle with very low frontal area, greater density, and lighter weight than if he were to employ a jet engine. \"Bluebird Mach 1.1\" would also be a relatively compact and simple design. Norris specified two off-the-shelf Bristol Siddeley BS.605 rocket engines. The 605 had been developed as a rocket-assisted take-off engine for military aircraft and was fuelled with kerosene, using hydrogen peroxide as the oxidiser. Each engine was rated at thrust. In \"Bluebird Mach 1.1\" application, the combined thrust would be equivalent of 36,000\u00a0bhp (27,000\u00a0kW; 36,000 PS) at .\nFinal record attempt.\nTo increase publicity for his rocket car venture, in the spring of 1966, Campbell decided to try once more for a water speed record. This time the target was . \"Bluebird K7\" was fitted with a lighter and more powerful Bristol Orpheus engine, taken from a Folland Gnat jet aircraft, which developed of thrust. The modified boat was taken back to Coniston in the first week of November 1966. The trials did not go well. The weather was very poor, and \"K7\" suffered an engine failure when her air intakes collapsed and debris was drawn into the engine. By the middle of December, some high-speed runs were made, in excess of but still well below Campbell's existing record. Problems with \"Bluebird\"s fuel system meant that the engine could not reach full speed, and so would not develop maximum power. Eventually, by the end of December, after further modifications to her fuel system, and the replacement of a fuel pump, the fuel starvation problem was fixed, and Campbell awaited better weather to mount an attempt.\nDeath.\nOn 4 January 1967, weather conditions were finally suitable for an attempt. Campbell commenced the first run of his last record attempt at just after 8:45\u00a0am. \"Bluebird\" moved slowly out towards the middle of the lake, where she paused briefly as Campbell lined her up. With a deafening blast of power, Campbell now applied full throttle and \"Bluebird\" began to surge forward. Clouds of spray issued from the jet-pipe, water poured over the rear spar and after a few hundred yards, at , \"Bluebird\" unstuck from the surface and rocketed off towards the southern end of the lake, producing her characteristic comet's tail of spray. She entered the measured kilometre at 8:46\u00a0am. Leo Villa witnessed her passing the first marker buoy at about in perfect steady planing trim, her nose slightly down, still accelerating. 7.525 seconds later, Keith Harrison saw her leave the measured kilometre at a speed of over .\nThe average speed for the first run was . Campbell lifted his foot from the throttle about 3/10 of a second before passing the southern kilometre marker. As \"Bluebird\" left the measured kilometre, Keith Harrison and Eric Shaw in a course boat at the southern end of the measured kilometre both noticed that she was very light around the bows, riding on her front stabilising fins. Her planing trim was no worse than she had exhibited when equipped with the Beryl engine, but it was markedly different from that observed by Leo Villa at the northern end of the kilometre, when she was under full acceleration. Campbell had made his usual commentary throughout the run.\nCampbell's words on his first run were, via radio intercom:\nInstead of refuelling and waiting for the wash of this run to subside, Campbell decided to make the return run immediately. This was not an unprecedented diversion from normal practice, as Campbell had used the advantage presented; i.e., no encroachment of water disturbances on the measured kilometre by the quick turnaround in many previous runs. The second run was even faster once severe tramping subsided on the run-up from Peel Island (caused by the water-brake disturbance). Once smooth water was reached some or so from the start of the kilometre, K7 demonstrated cycles of ground effect hovering before accelerating hard at 0.63 g to a peak speed of some 200 metres or so from the southern marker buoy. \"Bluebird\" was now experiencing bouncing episodes of the starboard sponson with increasing ferocity.\nAt the peak speed, the most intense and long-lasting bounce precipitated a severe decelerating episode \u2014 to , -1.86g \u2014 as \"K7\" dropped back onto the water. Engine flame-out then occurred and, shorn of thrust nose-down momentum, K7 experienced a gliding episode in strong ground effect with increasing angle-of-attack, before completely leaving the water at her static stability pitch-up limit of 5.2\u00b0. \"Bluebird\" then executed an almost complete backflip (~ 320\u00b0 and slightly off-axis) before plunging into the water (port sponson marginally in advance of the starboard), approximately 230 metres from the end of the measured kilometre. The boat then cartwheeled across the water before coming to rest. The impact killed Campbell instantly and broke \"K7\" forward of the air intakes (where Campbell was sitting), and the main hull sank shortly afterwards.\nMr Whoppit, Campbell's teddy bear mascot, was found among the floating debris and the pilot's helmet was recovered. Royal Navy divers made efforts to find and recover the body but, although the wreck of \"K7\" was found, they called off the search, after two weeks, without locating his body. Campbell's body was finally located in 2001.\nCampbell's last words, during a 31-second transmission, on his final run were, via radio intercom:\nThe cause of the crash has been variously attributed to several possible causes (or a combination of these causes):\nOn 28 January 1967, Campbell was posthumously awarded the Queen's Commendation for Brave Conduct \"for courage and determination in attacking the world water speed record.\"\nRecovery of \"Bluebird K7\" and Campbell's body.\nFrom 1996 to 2001, Bill Smith, an underwater surveyor and amateur diver, rediscovered the crash site and as a result of discussions with Gina Campbell, the daughter of Donald Campbell, and the wider Campbell family, a decision was taken to raise K7 to the surface. The wreckage of Campbell's craft was recovered by a diving team led by Bill Smith in association with Gilgeous Diving Services (GDS Extreme Engineering, Liverpool) Lifting K7 was run with GDS Extreme Engineering under Smith's team's lead. The main section/hull first raised in March 2001 and later in May 2001, when Campbell's body was recovered. The largest section, comprising approximately two-thirds of the centre hull, was raised on 8 March 2001. The project began when Smith was inspired to look for the wreck after hearing the Marillion song \"Out of This World\" (from the album \"Afraid of Sunlight\"), which was written about Campbell and \"Bluebird\".\nThe remains of Campbell's body were located just over two months later and recovered from the lake on 28 May 2001, still wearing his blue nylon overalls. On the night before his death, while playing cards he had drawn the queen and the ace of spades. Reflecting upon the fact that Mary, Queen of Scots had drawn the same two cards the night before she was beheaded, he told his mechanics, who were playing cards with him, that he had a fearful premonition that he was going to \"get the chop\". It was not possible to determine the cause of Campbell's death, though a consultant engineer giving evidence to the inquest said that the force of the impact could have caused him to be decapitated.\nCampbell was buried in Coniston Cemetery on 12 September 2001 after his coffin was carried down the lake, and through the measured kilometre, on a launch, one last time. A funeral service was then held at St Andrew's Church in Coniston, after an earlier, and positive DNA examination had been carried out. The funeral was attended by his widow, Tonia, daughter Gina, other members of his family, members of his former team and admirers. The funeral was overshadowed in the media by coverage of the 9/11 attacks in the United States.\nCampbell's sister, Jean Wales, had been against the recovery of her brother's body out of respect for his stated wish that, in the event of something going wrong, \"Skipper and boat stay together\".\nWhen Campbell was buried in Coniston Cemetery on 12 September 2001 she did not attend the service. Steve Hogarth, lead singer for Marillion, was present at the funeral and performed the song \"Out of This World\" solo.\nLegacy.\nBetween them, Campbell and his father had set 11 speed records on water and 10 on land.\nThe story of Campbell's last attempt at the water speed record on Coniston Water was told in the BBC television film \"Across the Lake\" in 1988, with Anthony Hopkins as Campbell. Nine years earlier, Robert Hardy had played Campbell's father, Sir Malcolm Campbell, in the \"BBC2 Playhouse\" television drama \"Speed King\"; both were written by Roger Milner and produced by Innes Lloyd. In 2003, the BBC showed a documentary reconstruction of Campbell's fateful water-speed record attempt in an episode of \"Days That Shook the World\". It featured a mixture of modern reconstruction and original film footage. All of the original colour clips were taken from a film capturing the event, \"Campbell at Coniston\" by John Lomax, a local amateur filmmaker from Wallasey, England. Lomax's film won awards worldwide in the late 1960s for recording the final weeks of Campbell's life.\nIn 1956, Campbell was surprised by Eamonn Andrews for the seventh episode of the new television show \"This Is Your Life\".\nAn English Heritage blue plaque commemorates Campbell and his father at Canbury School, Kingston Hill, Kingston upon Thames, where they lived.\nIn the village of Coniston, the Ruskin Museum has a display of Campbell memorabilia, and the Bristol Orpheus engine recovered in 2001 is also displayed. The engine's casing is mostly missing, having acted as a sacrificial anode in its time underwater, but the internals are preserved. Campbell's helmet from the ill-fated run is also on display.\nCampbell's legendary BLUEBIRD K7 is now also on display at the Coniston Ruskin Museum."}
{"id": "9165", "revid": "45807063", "url": "https://en.wikipedia.org/wiki?curid=9165", "title": "Directed set", "text": "In mathematics, a directed set (or a directed preorder or a filtered set) is a nonempty set formula_1 together with a reflexive and transitive binary relation formula_2 (that is, a preorder), with the additional property that every pair of elements has an upper bound. In other words, for any formula_3 and formula_4 in formula_1 there must exist formula_6 in formula_1 with formula_8 and formula_9 A directed set's preorder is called a direction.\nThe notion defined above is sometimes called an '. A ' is defined analogously, meaning that every pair of elements is bounded below. \nSome authors (and this article) assume that a directed set is directed upward, unless otherwise stated. Other authors call a set directed if and only if it is directed both upward and downward.\nDirected sets are a generalization of nonempty totally ordered sets. That is, all totally ordered sets are directed sets (contrast ordered sets, which need not be directed). Join-semilattices (which are partially ordered sets) are directed sets as well, but not conversely. Likewise, lattices are directed sets both upward and downward.\nIn topology, directed sets are used to define nets, which generalize sequences and unite the various notions of limit used in analysis. Directed sets also give rise to direct limits in abstract algebra and (more generally) category theory.\nEquivalent definition.\nIn addition to the definition above, there is an equivalent definition. A directed set is a set formula_1 with a preorder such that every finite subset of formula_1 has an upper bound. In this definition, the existence of an upper bound of the empty subset implies that formula_1 is nonempty.\nExamples.\nThe set of natural numbers formula_13 with the ordinary order formula_2 is one of the most important examples of a directed set. Every totally ordered set is a directed set, including formula_15 formula_16 formula_17 and formula_18\nA (trivial) example of a partially ordered set that is directed is the set formula_19 in which the only order relations are formula_20 and formula_21 A less trivial example is like the following example of the \"reals directed towards formula_22\" but in which the ordering rule only applies to pairs of elements on the same side of formula_22 (that is, if one takes an element formula_3 to the left of formula_25 and formula_4 to its right, then formula_3 and formula_4 are not comparable, and the subset formula_29 has no upper bound).\nProduct of directed sets.\nLet formula_30 and formula_31 be directed sets. Then the Cartesian product set formula_32 can be made into a directed set by defining formula_33 if and only if formula_34 and formula_35 In analogy to the product order this is the product direction on the Cartesian product. For example, the set formula_36 of pairs of natural numbers can be made into a directed set by defining formula_37 if and only if formula_38 and formula_39\nDirected towards a point.\nIf formula_22 is a real number then the set formula_41 can be turned into a directed set by defining formula_42 if formula_43 (so \"greater\" elements are closer to formula_22). We then say that the reals have been directed towards formula_45 This is an example of a directed set that is partially ordered nor totally ordered. This is because antisymmetry breaks down for every pair formula_3 and formula_4 equidistant from formula_25 where formula_3 and formula_4 are on opposite sides of formula_45 Explicitly, this happens when formula_52 for some real formula_53 in which case formula_42 and formula_55 even though formula_56 Had this preorder been defined on formula_57 instead of formula_58 then it would still form a directed set but it would now have a (unique) greatest element, specifically formula_22; however, it still wouldn't be partially ordered. This example can be generalized to a metric space formula_60 by defining on formula_61 or formula_62 the preorder formula_63 if and only if formula_64\nMaximal and greatest elements.\nAn element formula_65 of a preordered set formula_66 is a \"maximal element\" if for every formula_67 formula_68 implies formula_69\nIt is a \"greatest element\" if for every formula_67 formula_69\nAny preordered set with a greatest element is a directed set with the same preorder. \nFor instance, in a poset formula_72 every lower closure of an element; that is, every subset of the form formula_73 where formula_74 is a fixed element from formula_72 is directed.\nEvery maximal element of a directed preordered set is a greatest element. Indeed, a directed preordered set is characterized by equality of the (possibly empty) sets of maximal and of greatest elements.\nSubset inclusion.\nThe subset inclusion relation formula_76 along with its dual formula_77 define partial orders on any given family of sets. \nA non-empty family of sets is a directed set with respect to the partial order formula_78 (respectively, formula_79) if and only if the intersection (respectively, union) of any two of its members contains as a subset (respectively, is contained as a subset of) some third member. \nIn symbols, a family formula_80 of sets is directed with respect to formula_78 (respectively, formula_79) if and only if \nor equivalently, \nMany important examples of directed sets can be defined using these partial orders. \nFor example, by definition, a or is a non-empty family of sets that is a directed set with respect to the partial order formula_78 and that also does not contain the empty set (this condition prevents triviality because otherwise, the empty set would then be a greatest element with respect to formula_78). \nEvery -system, which is a non-empty family of sets that is closed under the intersection of any two of its members, is a directed set with respect to formula_95 Every \u03bb-system is a directed set with respect to formula_96 Every filter, topology, and \u03c3-algebra is a directed set with respect to both formula_78 and formula_96\nTails of nets.\nBy definition, a is a function from a directed set and a sequence is a function from the natural numbers formula_99 Every sequence canonically becomes a net by endowing formula_13 with formula_101\nIf formula_102 is any net from a directed set formula_66 then for any index formula_104 the set formula_105 is called the tail of formula_66 starting at formula_107 The family formula_108 of all tails is a directed set with respect to formula_109 in fact, it is even a prefilter.\nNeighborhoods.\nIf formula_110 is a topological space and formula_22 is a point in formula_112 the set of all neighbourhoods of formula_22 can be turned into a directed set by writing formula_114 if and only if formula_115 contains formula_116 For every formula_117 formula_118 and formula_119:\nFinite subsets.\nThe set formula_133 of all finite subsets of a set formula_80 is directed with respect to formula_79 since given any two formula_136 their union formula_137 is an upper bound of formula_1 and formula_139 in formula_140 This particular directed set is used to define the sum formula_141 of a generalized series of an formula_80-indexed collection of numbers formula_143 (or more generally, the sum of elements in an abelian topological group, such as vectors in a topological vector space) as the limit of the net of partial sums formula_144 that is:\nformula_145\nLogic.\nLet formula_146 be a formal theory, which is a set of sentences with certain properties (details of which can be found in the article on the subject). For instance, formula_146 could be a first-order theory (like Zermelo\u2013Fraenkel set theory) or a simpler zeroth-order theory. The preordered set formula_148 is a directed set because if formula_149 and if formula_150 denotes the sentence formed by logical conjunction formula_151 then formula_152 and formula_153 where formula_154 \nIf formula_155 is the Lindenbaum\u2013Tarski algebra associated with formula_146 then formula_157 is a partially ordered set that is also a directed set.\nContrast with semilattices.\nDirected set is a more general concept than (join) semilattice: every join semilattice is a directed set, as the join or least upper bound of two elements is the desired formula_158 The converse does not hold however, witness the directed set {1000,0001,1101,1011,1111} ordered bitwise (e.g. formula_159 holds, but formula_160 does not, since in the last bit 1 &gt; 0), where {1000,0001} has three upper bounds but no upper bound, cf. picture. (Also note that without 1111, the set is not directed.)\nDirected subsets.\nThe order relation in a directed set is not required to be antisymmetric, and therefore directed sets are not always partial orders. However, the term is also used frequently in the context of posets. In this setting, a subset formula_1 of a partially ordered set formula_162 is called a directed subset if it is a directed set according to the same partial order: in other words, it is not the empty set, and every pair of elements has an upper bound. Here the order relation on the elements of formula_1 is inherited from formula_164; for this reason, reflexivity and transitivity need not be required explicitly.\nA directed subset of a poset is not required to be downward closed; a subset of a poset is directed if and only if its downward closure is an ideal. While the definition of a directed set is for an \"upward-directed\" set (every pair of elements has an upper bound), it is also possible to define a downward-directed set in which every pair of elements has a common lower bound. A subset of a poset is downward-directed if and only if its upper closure is a filter.\nDirected subsets are used in domain theory, which studies directed-complete partial orders. These are posets in which every upward-directed set is required to have a least upper bound. In this context, directed subsets again provide a generalization of convergent sequences."}
{"id": "9166", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9166", "title": "EncycloPedia", "text": ""}
{"id": "9167", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9167", "title": "EuroCurrency", "text": ""}
{"id": "9172", "revid": "9374339", "url": "https://en.wikipedia.org/wiki?curid=9172", "title": "EquivalenceRelation", "text": ""}
{"id": "9173", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9173", "title": "EsperantujO", "text": ""}
{"id": "9174", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9174", "title": "EastGermany", "text": ""}
{"id": "9175", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9175", "title": "EsperantoLanguage", "text": ""}
{"id": "9177", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9177", "title": "EcheloN", "text": ""}
{"id": "9181", "revid": "3188090", "url": "https://en.wikipedia.org/wiki?curid=9181", "title": "EconomicS", "text": ""}
{"id": "9182", "revid": "66", "url": "https://en.wikipedia.org/wiki?curid=9182", "title": "EdwinAustinAbbey", "text": ""}
{"id": "9183", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9183", "title": "EricHoffer", "text": ""}
{"id": "9185", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9185", "title": "ErnestHemingway", "text": ""}
{"id": "9186", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9186", "title": "EnroN", "text": ""}
{"id": "9187", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9187", "title": "ExistencE", "text": ""}
{"id": "9188", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9188", "title": "EpistemOlogy", "text": ""}
{"id": "9191", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9191", "title": "ErnestHemingway/FromBoytoManHemingwaysFirstWorldWar", "text": ""}
{"id": "9192", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9192", "title": "ErnestHemingway/FromRealitytoFictionAFarewelltoArms", "text": ""}
{"id": "9193", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9193", "title": "ErnestHemingway/TheTimeinBetween", "text": ""}
{"id": "9195", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9195", "title": "ErnestHemingway/ForWhomtheBellTolls", "text": ""}
{"id": "9196", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=9196", "title": "ErnestHemingway/FredericHenry", "text": ""}
{"id": "9197", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=9197", "title": "ErnestHemingway/RobertJordan", "text": ""}
{"id": "9198", "revid": "1078", "url": "https://en.wikipedia.org/wiki?curid=9198", "title": "ErnestHemingway/YoungandInnocent", "text": ""}
{"id": "9199", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9199", "title": "ErnestHemingway/ThingsTurnSour", "text": ""}
{"id": "9200", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9200", "title": "ErnestHemingway/TheEndlessDarkNothingness", "text": ""}
{"id": "9201", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9201", "title": "ErnestHemingway/SureShotsTheSecondWorldWar", "text": ""}
{"id": "9202", "revid": "15907106", "url": "https://en.wikipedia.org/wiki?curid=9202", "title": "ErnestHemingway/TheDownwardSpiral", "text": ""}
{"id": "9203", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9203", "title": "ErnestHemingway/ViolenceandRedemption", "text": ""}
{"id": "9204", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9204", "title": "ErnestHemingway/WhyItWentWrong", "text": ""}
{"id": "9205", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=9205", "title": "ErnestHemingway/BibliographY", "text": ""}
{"id": "9208", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=9208", "title": "EthicalNaturalism", "text": ""}
{"id": "9209", "revid": "49128594", "url": "https://en.wikipedia.org/wiki?curid=9209", "title": "Edward Bellamy", "text": "Edward Bellamy (March 26, 1850 \u2013 May 22, 1898) was an American author, journalist, and political activist most famous for his utopian novel \"Looking Backward\". Bellamy's vision of a harmonious future world inspired the formation of numerous \"Nationalist Clubs\" dedicated to the propagation of his political ideas.\nAfter working as a journalist and writing several novels, Bellamy published \"Looking Backward\" in 1888. It was the third best-selling novel of the 19th century in the United States, and it especially appealed to a generation of intellectuals alienated from the alleged dark side of the Gilded Age. In the early 1890s, Bellamy established a newspaper known as \"The New Nation\" and began to promote united action between the various Nationalist Clubs and the emerging Populist Party. He published \"Equality\", a sequel to \"Looking Backward\", in 1897, and died the following year.\nBiography.\nEarly life.\nEdward Bellamy was born in Chicopee, Massachusetts. His father was Rufus King Bellamy (1816\u20131886), a Baptist minister and a descendant of Joseph Bellamy. His mother, Maria Louisa Putnam Bellamy, was a Calvinist. She was the daughter of a Baptist minister named Benjamin Putnam, who was forced to withdraw from the ministry in Salem, Massachusetts, following objections to his becoming a Freemason.\nBellamy attended public school at Chicopee Falls before leaving for Union College of Schenectady, New York, where he studied for just two semesters. Upon leaving school, he made his way to Europe for a year, spending extensive time in Germany. He briefly studied law but abandoned that field without ever having practiced as a lawyer, instead entering the world of journalism. In this capacity Bellamy briefly served on the staff of the \"New York Post\" before returning to his native Massachusetts to take a position at the \"Springfield Union\".\nAt the age of 25, Bellamy developed tuberculosis, the disease that would ultimately kill him. He suffered with its effects throughout his adult life. In an effort to regain his health, Bellamy spent a year in the Hawaiian Islands (1877 to 1878). Returning to the United States, he decided to abandon the daily grind of journalism in favor of literary work, which put fewer demands upon his time and his health.\nBellamy married Emma Augusta Sanderson in 1882. The couple had two children.\nLiterary career.\nBellamy's early novels, including \"Six to One\" (1878), \"Dr. Heidenhoff's Process\" (1880), and \"Miss Ludington's Sister\" (1885), were unremarkable works, making use of standard psychological plots.\nA turn to utopian science fiction with \"Looking Backward, 2000\u20131887,\" published in January 1888, captured the public imagination and catapulted Bellamy to literary fame. Its publisher could scarcely keep up with demand. Within a year it had sold some 200,000 copies, and by the end of the 19th century had sold more copies than any other book published in America up to that time except for \"Uncle Tom's Cabin\" by Harriet Beecher Stowe and \"\" by Lew Wallace. The book gained an extensive readership in the United Kingdom as well, more than 235,000 copies being sold there between 1890 and 1935.\nIn \"Looking Backward\", a non-violent revolution had transformed the American economy and thereby society; private property had been abolished in favor of state ownership of capital and the elimination of social classes and the ills of society that he thought inevitably followed from them. In the new world of the year 2000, there was no longer war, poverty, crime, prostitution, corruption, money, or taxes. Neither did there exist such occupations seen by Bellamy as of dubious worth to society, such as politicians, lawyers, merchants, or soldiers. Instead, Bellamy's utopian society of the future was based upon the voluntary employment of all citizens between the ages of 21 and 45, after which time all would retire. Work was simple, aided by machine production, working hours short and vacation time long. The new economic basis of society effectively remade human nature itself in Bellamy's idyllic vision, with greed, maliciousness, untruthfulness, and insanity all relegated to the past.\nBellamyite movement.\nBellamy's book inspired legions of readers to establish so-called Nationalist Clubs, beginning in Boston late in 1888. His vision of a country relieved of its social ills through abandonment of the principle of competition and establishment of state ownership of industry proved an appealing panacea to a generation of intellectuals alienated from the dark side of Gilded Age America. By 1891 it was reported that no fewer than 162 Nationalist Clubs were in existence.\nBellamy's use of the term \"Nationalism\" rather than \"socialism\" as a descriptor of his governmental vision was calculated, as he did not want to limit either sales of his novel or the potential influence of its political ideas. In an 1888 letter to literary critic William Dean Howells, Bellamy wrote:\nBellamy himself came to actively participate in the political movement which emerged around his book, particularly after 1891 when he founded his own magazine, \"The New Nation,\" and began to promote united action between the various Nationalist Clubs and the emerging People's Party. For the next three and a half years, Bellamy gave his all to politics, publishing his magazine, working to influence the platform of the People's Party, and publicizing the Nationalist movement in the popular press. This phase of his life came to an end in 1894, when \"The New Nation\" was forced to suspend publication owing to financial difficulties.\nWith the key activists of the Nationalist Clubs largely absorbed into the apparatus of the People's Party (although a Nationalist Party did run three candidates for office in Wisconsin as late as 1896), Bellamy abandoned politics for a return to literature. He set to work on a sequel to \"Looking Backward\" titled \"Equality,\" attempting to deal with the ideal society of the post-revolutionary future in greater detail. In this final work, he addressed the question of feminism, dealing with the taboo subject of female reproductive rights in a future, post-revolutionary America. Other subjects overlooked in \"Looking Backward,\" such as animal rights and wilderness preservation, were dealt with in a similar context. The book saw print in 1897 and would prove to be Bellamy's final creation.\nSeveral short stories of Bellamy's were published in 1898, and \"The Duke of Stockbridge; a Romance of Shays' Rebellion\" was published in 1900.\nDeath and legacy.\nEdward Bellamy died of tuberculosis in Chicopee Falls, Massachusetts ten years after the publication of his most famous book. He was 48 years old.\nHis lifelong home in Chicopee Falls, built by his father, was designated a National Historic Landmark in 1971.\nBellamy was the cousin of Francis Bellamy, famous for writing the original version of the Pledge of Allegiance.\nBellamy Road, a residential road in Toronto, is named for the author."}
{"id": "9212", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=9212", "title": "ElectricalEngineering", "text": ""}
{"id": "9213", "revid": "37982659", "url": "https://en.wikipedia.org/wiki?curid=9213", "title": "EuleR", "text": ""}
{"id": "9215", "revid": "17287", "url": "https://en.wikipedia.org/wiki?curid=9215", "title": "EartH", "text": ""}
{"id": "9220", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9220", "title": "EduCation", "text": ""}
{"id": "9221", "revid": "13054498", "url": "https://en.wikipedia.org/wiki?curid=9221", "title": "EiffelTower", "text": ""}
{"id": "9222", "revid": "5128741", "url": "https://en.wikipedia.org/wiki?curid=9222", "title": "E", "text": "E, or e, is the fifth letter and the second vowel letter of the Latin alphabet, used in the modern English alphabet, the alphabets of other western European languages and others worldwide. Its name in English is \"e\" (pronounced ); plural \"es\", \"Es\", or \"E's\".\nIt is the most commonly used letter in many languages, including Czech, Danish, Dutch, English, French, German, Hungarian, Latin, Latvian, Norwegian, Spanish, and Swedish.\nName.\nIn English, the name of the letter is the \"long E\" sound, pronounced . In most other languages, its name matches the letter's pronunciation in open syllables.\nHistory.\nThe Latin letter 'E' differs little from its source, the Greek letter epsilon, '\u0395'. This in turn comes from the Semitic letter \"h\u00ea\", which has been suggested to have started as a praying or calling human figure (\"hillul\", 'jubilation'), and was most likely based on a similar Egyptian hieroglyph that indicated a different pronunciation.\nIn Semitic, the letter represented (and in foreign words); in Greek, \"h\u00ea\" became the letter epsilon, used to represent . The various forms of the Old Italic script and the Latin alphabet followed this usage.\nUse in writing systems.\nEnglish.\nAlthough Middle English spelling used to represent long and short , the Great Vowel Shift changed long (as in \"me\" or \"bee\") to while short (as in \"met\" or \"bed\") remained a mid vowel. In unstressed syllables, this letter is usually pronounced either as or . In other cases, the letter is silent, generally at the end of words like \"queue\".\nOther languages.\nIn the orthography of many languages, it represents either , , , or some variation (such as a nasalized version) of these sounds, often with diacritics (as: ) to indicate contrasts. Less commonly, as in French, German, or Saanich, represents a mid-central vowel . Digraphs with are common to indicate either diphthongs or monophthongs, such as or for or in English, for in German, and for in French or in German.\nOther systems.\nThe International Phonetic Alphabet uses for the close-mid front unrounded vowel or the mid front unrounded vowel.\nFrequency.\nE is the most common (or highest-frequency) letter in the English language alphabet and several other European languages, which has implications in both cryptography and data compression. This makes it a harder letter to use when writing lipograms.\nOther representations.\nOther.\nIn British Sign Language (BSL), the letter 'e' is signed by extending the index finger of the right hand touching the tip of index on the left hand, with all fingers of left hand open."}
{"id": "9223", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=9223", "title": "Economics", "text": "Economics () is a social science that studies the production, distribution, and consumption of goods and services.\nEconomics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyses what is viewed as basic elements within economies, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyses economies as systems where production, distribution, consumption, savings, and investment expenditure interact, and factors affecting it: factors of production, such as labour, capital, land, and enterprise, inflation, economic growth, and public policies that have impact on these elements. It also seeks to analyse and describe the global economy.\nOther broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.\nEconomic analysis can be applied throughout society, including business, finance, cybersecurity, health care, engineering and government. It is also applied to such diverse subjects as crime, education, the family, feminism, law, philosophy, politics, religion, social institutions, war, science, and the environment.\nDefinitions of economics.\nThe earlier term for the discipline was \"political economy\", but since the late 19th century, it has commonly been called \"economics\". The term is ultimately derived from Ancient Greek (\"oikonomia\") which is a term for the \"way (nomos) to run a household (oikos)\", or in other words the know-how of an (\"oikonomikos\"), or \"household or homestead manager\". Derived terms such as \"economy\" can therefore often mean \"frugal\" or \"thrifty\". By extension then, \"political economy\" was the way to manage a polis or state.\nThere are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists. Scottish philosopher Adam Smith (1776) defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as:\nJean-Baptiste Say (1803), distinguishing the subject matter from its public-policy uses, defined it as the science \"of\" production, distribution, and consumption of wealth. On the satirical side, Thomas Carlyle (1849) coined \"the dismal science\" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798). John Stuart Mill (1844) delimited the subject matter further:\nAlfred Marshall provided a still widely cited definition in his textbook \"Principles of Economics\" (1890) that extended analysis beyond wealth and from the societal to the microeconomic level:\nLionel Robbins (1932) developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":\nRobbins described the definition as not \"classificatory\" in \"pick[ing] out certain \"kinds\" of behaviour\" but rather \"analytical\" in \"focus[ing] attention on a particular \"aspect\" of behaviour, the form imposed by the influence of scarcity.\" He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow. But he said that economics can be used to study other things, such as war, that are outside its usual focus. This is because war has as the goal winning it (as a sought after \"end\"), generates both cost and benefits; and, \"resources\" (human life and other costs) are used to attain the goal. If the war is not winnable or if the expected costs outweigh the benefits, the deciding \"actors\" (assuming they are rational) may never go to war (a \"decision\") but rather explore other alternatives. Economics cannot be defined as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought after end).\nSome subsequent comments criticised the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields. There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.\nGary Becker, a contributor to the expansion of economics into new areas, described the approach he favoured as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\" One commentary characterises the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.\nMany economists including nobel prize winners James M. Buchanan and Ronald Coase reject the method-based definition of Robbins and continue to prefer definitions like those of Say, in terms of its subject matter. Ha-Joon Chang has for example argued that the definition of Robbins would make economics very peculiar because all other sciences define themselves in terms of the area of inquiry or object of inquiry rather than the methodology. In the biology department, it is not said that all biology should be studied with DNA analysis. People study living organisms in many different ways, so some people will perform DNA analysis, others might analyse anatomy, and still others might build game theoretic models of animal behaviour. But they are all called biology because they all study living organisms. According to Ha Joon Chang, this view that the economy can and should be studied in only one way (for example by studying only rational choices), and going even one step further and basically redefining economics as a theory of everything, is peculiar.\nHistory of economic thought.\nFrom antiquity through the physiocrats.\nQuestions regarding distribution of resources are found throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod as the \"first economist\". However, the word Oikos, the Greek word from which the word economy derives, was used for issues regarding how to manage a household (which was understood to be the landowner, his family, and his slaves) rather than to refer to some normative societal system of distribution of resources, which is a more recent phenomenon. Xenophon, the author of the Oeconomicus, is credited by philologues for being the source of the word economy. Joseph Schumpeter described 16th and 17th century scholastic writers, including Tom\u00e1s de Mercado, Luis de Molina, and Juan de Lugo, as \"coming nearer than any other group to being the 'founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.\nTwo groups, who later were called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing inexpensive raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.\nPhysiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of \"laissez-faire\", which called for minimal government intervention in the economy.\nAdam Smith (1723\u20131790) was an early economic theorist. Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.\nClassical political economy.\nThe publication of Adam Smith's \"The Wealth of Nations\" in 1776, has been described as \"the effective birth of economics as a separate discipline.\" The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive.\nSmith discusses potential benefits of specialisation by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries. His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\" To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory\u2014that, under competition, resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in equilibrium (adjusted for apparent differences arising from such factors as training and unemployment).\nIn an argument that includes \"one of the most famous passages in all economics,\" Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society, and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce. In this:\nThe Reverend Thomas Robert Malthus (1798) used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level. Economist Julian Simon has criticised Malthus's conclusions.\nWhile Adam Smith emphasised production and income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was also the first to state and prove the principle of comparative advantage, according to which each country should specialise in producing and exporting goods in that it has a lower \"relative\" cost of production, rather relying only on its own production. It has been termed a \"fundamental analytical explanation\" for gains from trade.\nComing at the end of the classical tradition, John Stuart Mill (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.\nValue theory was important in classical theory. Smith wrote that the \"real price of every thing\u00a0... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity. Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth (capital) and a constant population size.\nMarxian economics.\nMarxist (later, Marxian) economics descends from classical economics and it derives from the work of Karl Marx. The first volume of Marx's major work, , was published in 1867. Marx focused on the labour theory of value and theory of surplus value. Marx wrote that they were mechanisms used by capital to exploit labour. The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production, and the theory of surplus value demonstrated how workers were only paid a proportion of the value their work had created.\nMarxian economics was further developed by Karl Kautsky (1854\u20131938)'s \"The Economic Doctrines of Karl Marx\" and \"The Class Struggle (Erfurt Program)\", Rudolf Hilferding's (1877\u20131941) \"Finance Capital\", Vladimir Lenin (1870\u20131924)'s \"The Development of Capitalism in Russia\" and \"Imperialism, the Highest Stage of Capitalism\", and Rosa Luxemburg (1871\u20131919)'s \"The Accumulation of Capital\".\nNeoclassical economics.\nAt its inception as a social science, \"economics\" was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his \"Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth\" (1803). These three items were considered only in relation to the increase or diminution of wealth, and not in reference to their processes of execution. Say's definition has survived in part up to the present, modified by substituting the word \"wealth\" for \"goods and services\" meaning that wealth may include non-material objects as well. One hundred and thirty years later, Lionel Robbins noticed that this definition no longer sufficed, because many economists were making theoretical and philosophical inroads in other areas of human activity. In his \"Essay on the Nature and Significance of Economic Science\", he proposed a definition of economics as a study of human behaviour, subject to and constrained by scarcity, which forces people to choose, allocate scarce resources to competing ends, and economise (seeking the greatest welfare while avoiding the wasting of scarce resources). According to Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\". Robbins' definition eventually became widely accepted by mainstream economists, and found its way into current textbooks. Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition.\nA body of theory later termed \"neoclassical economics\" formed from about 1870 to 1910. The term \"economics\" was popularised by such neoclassical economists as Alfred Marshall and Mary Paley Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\". This corresponded to the influence on the subject of mathematical methods used in the natural sciences.\nNeoclassical economics systematically integrated supply and demand as joint determinants of both price and quantity in market equilibrium, influencing the allocation of output and income distribution. It rejected the classical economics' labour theory of value in favour of a marginal utility theory of value on the demand side and a more comprehensive theory of costs on the supply side. In the 20th century, neoclassical theorists departed from an earlier idea that suggested measuring total utility for a society, opting instead for ordinal utility, which posits behaviour-based relations across individuals.\nIn microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded. In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.\nNeoclassical economics is occasionally referred as \"orthodox economics\" whether by its critics or sympathisers. Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalise earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.\nNeoclassical economics studies the behaviour of individuals, households, and organisations (called economic actors, players, or agents), when they manage or use scarce resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice. There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more players to attain the best possible outcome.\nKeynesian economics.\nKeynesian economics derives from John Maynard Keynes, in particular his book \"The General Theory of Employment, Interest and Money\" (1936), which ushered in contemporary macroeconomics as a distinct field. The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.\nDuring the following decades, many economists followed Keynes' ideas and expanded on his works. John Hicks and Alvin Hansen developed the IS\u2013LM model which was a simple formalisation of some of Keynes' insights on the economy's short-run equilibrium. Franco Modigliani and James Tobin developed important theories of private consumption and investment, respectively, two major components of aggregate demand. Lawrence Klein built the first large-scale macroeconometric model, applying the Keynesian thinking systematically to the US economy.\nPost-WWII economics.\nImmediately after World War II, Keynesian was the dominant economic view of the United States establishment and its allies, Marxian economics was the dominant economic view of the Soviet Union nomenklatura and its allies.\nMonetarism.\nMonetarism appeared in the 1950s and 1960s, its intellectual leader being Milton Friedman. Monetarists contended that monetary policy and other monetary shocks, as represented by the growth in the money stock, was an important cause of economic fluctuations, and consequently that monetary policy was more important than fiscal policy for purposes of stabilisation. Friedman was also skeptical about the ability of central banks to conduct a sensible active monetary policy in practice, advocating instead using simple rules such as a steady rate of money growth.\nMonetarism rose to prominence in the 1970s and 1980s, when several major central banks followed a monetarist-inspired policy, but was later abandoned because the results were unsatisfactory.\nNew classical economics.\nA more fundamental challenge to the prevailing Keynesian paradigm came in the 1970s from new classical economists like Robert Lucas, Thomas Sargent and Edward Prescott. They introduced the notion of rational expectations in economics, which had profound implications for many economic discussions, among which were the so-called Lucas critique and the presentation of real business cycle models.\nNew Keynesians.\nDuring the 1980s, a group of researchers appeared being called New Keynesian economists, including among others George Akerlof, Janet Yellen, Gregory Mankiw and Olivier Blanchard. They adopted the principle of rational expectations and other monetarist or new classical ideas such as building upon models employing micro foundations and optimizing behaviour, but simultaneously emphasised the importance of various market failures for the functioning of the economy, as had Keynes. Not least, they proposed various reasons that potentially explained the empirically observed features of price and wage rigidity, usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.\nNew neoclassical synthesis.\nAfter decades of often heated discussions between Keynesians, monetarists, new classical and new Keynesian economists, a synthesis emerged by the 2000s, often given the name \"the new neoclassical synthesis\". It integrated the rational expectations and optimizing framework of the new classical theory with a new Keynesian role for nominal rigidities and other market imperfections like imperfect information in goods, labour and credit markets. The monetarist importance of monetary policy in stabilizing the economy and in particular controlling inflation was recognised as well as the traditional Keynesian insistence that fiscal policy could also play an influential role in affecting aggregate demand. Methodologically, the synthesis led to a new class of applied models, known as dynamic stochastic general equilibrium or DSGE models, descending from real business cycles models, but extended with several new Keynesian and other features. These models proved useful and influential in the design of modern monetary policy and are now standard workhorses in most central banks.\nAfter the financial crisis.\nAfter the 2007\u20132008 financial crisis, macroeconomic research has put greater emphasis on understanding and integrating the financial system into models of the general economy and shedding light on the ways in which problems in the financial sector can turn into major macroeconomic recessions. In this and other research branches, inspiration from behavioural economics has started playing a more important role in mainstream economic theory. Also, heterogeneity among the economic agents, e.g. differences in income, plays an increasing role in recent economic research.\nOther schools and approaches.\nOther schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Freiburg School, the School of Lausanne, the Stockholm school and the Chicago school of economics. During the 1970s and 1980s mainstream economics was sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago school approach.\nWithin macroeconomics there is, in general order of their historical appearance in the literature; classical economics, neoclassical economics, Keynesian economics, the neoclassical synthesis, monetarism, new classical economics, New Keynesian economics and the new neoclassical synthesis.\nBeside the mainstream development of economic thought, various alternative or heterodox economic theories have evolved over time, positioning themselves in contrast to mainstream theory. These include:\nAdditionally, alternative developments include Marxian economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, econodynamics, feminist economics and biophysical economics.\nFeminist economics emphasises the role that gender plays in economies, challenging analyses that render gender invisible or support gender-oppressive economic systems. The goal is to create economic research and policy analysis that is inclusive and gender-aware to encourage gender equality and improve the well-being of marginalised groups.\nMethodology.\nTheoretical research.\nMainstream economic theory relies upon analytical economic models. When creating theories, the objective is to find assumptions which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories. While neoclassical economic theory constitutes both the dominant or orthodox theoretical as well as methodological framework, economic theory can also take the form of other schools of thought such as in heterodox economic theories.\nIn microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm. Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models with microfoundations, in which microeconomic concepts play a major part.\nSometimes an economic hypothesis is only \"qualitative\", not \"quantitative\".\nExpositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, mathematical economics is the application of mathematical methods to represent theories and analyse problems in economics. Paul Samuelson's treatise \"Foundations of Economic Analysis\" (1947) exemplifies the method, particularly as to maximizing behavioural relations of agents reaching equilibrium. The book focused on examining the class of statements called \"operationally meaningful theorems\" in economics, which are theorems that can conceivably be refuted by empirical data.\nEmpirical research.\nEconomic theories are frequently tested empirically, largely through the use of econometrics using economic data. The controlled experiments common to the physical sciences are difficult and uncommon in economics, and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments.\nStatistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance (\"signal strength\") of the hypothesised relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs.\nExperimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms. In some cases these have found that the axioms are not entirely correct.\nIn behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences. These techniques have led some to argue that economics is a \"genuine science\".\nMicroeconomics.\nMicroeconomics examines how entities, forming a market structure, interact within a market to create a market system. These entities include private and public players with various classifications, typically operating under scarcity of tradable units and regulation. The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment.\nVarious market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition.\nForms of imperfect competition include monopoly (in which there is only one seller of a good), duopoly (in which there are only two sellers of a good), oligopoly (in which there are few sellers of a good), monopolistic competition (in which there are many sellers producing highly differentiated goods), monopsony (in which there is only one buyer of a good), and oligopsony (in which there are few buyers of a good). Firms under imperfect competition have the potential to be \"price makers\", which means that they can influence the prices of their products.\nIn partial equilibrium method of analysis, it is assumed that activity in the market being analysed does not affect other markets. This method aggregates (the sum of all activity) in only one market. General-equilibrium theory studies various markets and their behaviour. It aggregates (the sum of all activity) across \"all\" markets. This method studies both changes in markets and their interactions leading towards equilibrium.\nProduction, cost, and efficiency.\nIn microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption (food, haircuts, etc.) vs. investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods, and \"guns\" vs \"butter\".\nInputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources). Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car.\nEconomic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off.\nThe production\u2013possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case, an economy can produce just two goods (say \"guns\" and \"butter\"). The PPF is a table or graph (as at the right) that shows the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.\nScarcity is represented in the figure by people being willing but unable in the aggregate to consume \"beyond the PPF\" (such as at \"X\") and by the negative slope of the curve. If production of one good \"increases\" along the curve, production of the other good \"decreases\", an inverse relationship. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.\nThe slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a \"real opportunity cost\". Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. \"Along the PPF\", scarcity implies that choosing \"more\" of one good in the aggregate entails doing with \"less\" of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents.\nBy construction, each point on the curve shows \"productive efficiency\" in maximizing output for given total inputs. A point \"inside\" the curve (as at \"A\"), is feasible but represents \"production inefficiency\" (wasteful use of inputs), in that output of \"one or both goods\" could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high unemployment during a business-cycle recession or economic organisation of a country that discourages full use of resources. Being on the curve might still not fully satisfy allocative efficiency (also called Pareto efficiency) if it does not produce a mix of goods that consumers prefer over other points.\nMuch applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organise society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"\nSpecialisation.\nSpecialisation is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus \"relatively\" cheaper, input.\nEven if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialise in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.\nIt has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialisation in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.\nThe general theory of specialisation applies to trade among individuals, farms, manufacturers, service providers, and economies. Among each of these production systems, there may be a corresponding \"division of labour\" with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.\nAn example that combines features above is a country that specialises in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.\nTheory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs. In the process, aggregate output may increase as a by-product or by design. Such specialisation of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the \"increased income levels\" that trade may facilitate.\nSupply and demand.\nPrices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy. The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.\nFor a given market of a commodity, \"demand\" is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximisation\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesised relation of each individual consumer for ranking different commodity bundles as more or less preferred.\nThe law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.\n\"Supply\" is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesised to be \"profit maximisers\", meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.\nThat is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.\nMarket equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilise at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.\nFirms.\nPeople frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through \"firms\". The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organise their production in firms when the costs of doing business becomes lower than doing it on the market. Firms combine labour and capital, and can achieve far greater economies of scale (when the average cost per unit declines as more units are produced) than individual market trading.\nIn perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organisation generalises from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.\nManagerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimise business decisions, including unit-cost minimisation and profit maximisation, given the firm's objectives and constraints imposed by technology and market conditions.\nUncertainty and game theory.\nUncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not. Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry. Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.\nGame theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organisation, discussed above, to model different types of firm behaviour, for example in a solipsistic industry (few sellers), but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other. In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.\nIn this, it generalises maximisation approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic \"Theory of Games and Economic Behavior\" by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as the formulation of nuclear strategies, ethics, political science, and evolutionary biology.\nRisk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets, financial crises, and related government policy or regulation.\nSome market organisations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be. Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are adverse selection, such that those at most risk are most likely to insure (say reckless drivers), and moral hazard, such that insurance results in riskier behaviour (say more reckless driving).\nBoth problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market (\"incomplete markets\"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care. Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.\nMarket failure.\nThe term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorise market failures differently, the following categories emerge in the main texts.\nInformation asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.\nNatural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of \"failure of competition\" as a restraint on producers. Extreme economies of scale are one possible cause.\nPublic goods are goods which are under-supplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.\nExternalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidise or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities. Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.\nIn many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesised long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.\nSome specialised fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\".\nPolicy options include regulations that reflect cost\u2013benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.\nWelfare.\nWelfare economics uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium. It analyses \"social welfare\", however measured, in terms of economic activities of the individuals that compose the theoretical society considered. Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no \"social welfare\" apart from the \"welfare\" associated with its individual units.\nMacroeconomics.\nMacroeconomics, another branch of economics, examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory. Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy.\nSince at least the 1960s, macroeconomics has been characterised by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition. This has addressed a long-standing concern about inconsistent developments of the same subject.\nMacroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.\nGrowth.\n\"Growth economics\" studies factors that explain economic growth\u00a0\u2013 the increase in output \"per capita\" of a country over a long period of time. The same factors are used to explain differences in the \"level\" of output \"per capita\" \"between\" countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth.\nMuch-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms (as in the neoclassical and endogenous growth models) and in growth accounting.\nBusiness cycle.\nThe economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled \"The General Theory of Employment, Interest and Money\" outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.\nHe therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilise output over the business cycle. Thus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of \"The General Theory\".\nOver the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with classical economics, stating that Keynesianism is correct in the short run but qualified by classical-like considerations in the intermediate and long run.\nNew classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory, led by Robert Lucas, and real business cycle theory.\nIn contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures. In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.\nThus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long.\nUnemployment.\nThe amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.\nClassical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.\nStructural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs. Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.\nWhile some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth. The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.\nMoney and monetary policy.\nMoney is a \"means of final payment\" for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" (\"Money is \"that\" money does\" in the original).\nAs a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter (non-monetary exchange). Given a diverse array of produced goods and specialised producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.\nMonetary policy is the policy that central banks conduct to accomplish their broader objectives. Most central banks in developed countries follow inflation targeting, whereas the main objective for many central banks in development countries is to uphold a fixed exchange rate system. The primary monetary tool is normally the adjustment of interest rates, either directly via administratively changing the central bank's own interest rates or indirectly via open market operations. Via the monetary transmission mechanism, interest rate changes affect investment, consumption and net export, and hence aggregate demand, output and employment, and ultimately the development of wages and inflation.\nFiscal policy.\nGovernments implement fiscal policy to influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.\nFor example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.\nThe effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.\nSceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes.\nInequality.\nEconomic inequality includes income inequality, measured using the distribution of income (the amount of money people receive), and wealth inequality measured using the distribution of wealth (the amount of wealth people own), and other measures such as consumption, land ownership, and human capital. Inequality exists at different extents between countries or states, groups of people, and individuals. There are many methods for measuring inequality, the Gini coefficient being widely used for income differences among individuals. An example measure of inequality between countries is the Inequality-adjusted Human Development Index, a composite index that takes inequality into account. Important concepts of equality include equity, equality of outcome, and equality of opportunity.\nResearch has linked economic inequality to political and social instability, including revolution, democratic breakdown and civil conflict. Research suggests that greater inequality hinders economic growth and macroeconomic stability, and that land and human capital inequality reduce growth more than inequality of income. Inequality is at the centre stage of economic policy debate across the globe, as government tax and spending policies have significant effects on income distribution. In advanced economies, taxes and transfers decrease income inequality by one-third, with most of this being achieved via public social spending (such as pensions and family benefits.)\nOther branches of economics.\nPublic economics.\nPublic economics is the field of economics that deals with economic activities of a public sector, usually government. The subject addresses such matters as tax incidence (who really pays a particular tax), cost\u2013benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.\nMuch of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies ought to be like.\nWelfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it. It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.\nInternational economics.\nInternational trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalisation.\nLabour economics.\nLabour economics seeks to understand the functioning and dynamics of the markets for wage labour. \"Labour markets\" function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers), the demands of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. In economics, \"labour\" is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.\nDevelopment economics.\nDevelopment economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth. Approaches in development economics frequently incorporate social and political factors.\nRelated subjects.\nEconomics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, , family economics and institutional economics.\nLaw and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be. A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.\nPolitical economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system (capitalist, socialist, mixed) influence each other. It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy. Historians have employed \"political economy\" to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.\nEnergy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.\nThe sociological subfield of economic sociology arose, primarily through the work of \u00c9mile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. modernity). Classic works include Max Weber's \"The Protestant Ethic and the Spirit of Capitalism\" (1905) and Georg Simmel's \"The Philosophy of Money\" (1900). More recently, the works of James S. Coleman, Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field.\nGary Becker in 1974 presented an economic theory of social interactions, whose applications included the family, charity, merit goods and multiperson interactions, and envy and hatred. He and Kevin Murphy authored a book in 2001 that analysed market behaviour in a social environment.\nProfession.\nThe professionalisation of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\". Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study. See Bachelor of Economics and Master of Economics.\nIn the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national treasury, central bank or National Bureau of Statistics. See Economic analyst.\nThere are dozens of prizes awarded to economists each year for outstanding intellectual contributions to the field, the most prominent of which is the Nobel Memorial Prize in Economic Sciences, though it is not a Nobel Prize.\nContemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science. Professional economists are expected to be familiar with these tools, while a minority specialise in econometrics and mathematical methods.\nWomen in economics.\nHarriet Martineau (1802\u20131876) was a widely-read populariser of classical economic thought. Mary Paley Marshall (1850\u20131944), the first women lecturer at a British economics faculty, wrote \"The Economics of Industry\" with her husband Alfred Marshall. Joan Robinson (1903\u20131983) was an important post-Keynesian economist. The economic historian Anna Schwartz (1915\u20132012) coauthored \"A Monetary History of the United States, 1867\u20131960\" with Milton Friedman. Three women have received the Nobel Prize in Economics: Elinor Ostrom (2009), Esther Duflo (2019) and Claudia Goldin (2023). Five have received the John Bates Clark Medal: Susan Athey (2007), Esther Duflo (2010), Amy Finkelstein (2012), Emi Nakamura (2019) and Melissa Dell (2020).\nWomen's authorship share in prominent economic journals reduced from 1940 to the 1970s, but has subsequently risen, with different patterns of gendered coauthorship. Women remain globally under-represented in the profession (19% of authors in the RePEc database in 2018), with national variation."}
{"id": "9225", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=9225", "title": "Electronic paper", "text": "Electronic paper or intelligent paper, is a display device that reflects ambient light, mimicking the appearance of ordinary ink on paper \u2013 unlike conventional flat-panel displays which need additional energy to emit their own light. This may make them more comfortable to read, and provide a wider viewing angle than most light-emitting displays. The contrast ratio in electronic displays available as of 2008 approaches newspaper, and newly developed displays are slightly better. An ideal e-paper display can be read in direct sunlight without the image appearing to fade.\nTechnologies include Gyricon, electrophoretics, electrowetting, interferometry, and plasmonics.\nMany electronic paper technologies hold static text and images indefinitely without electricity. Flexible electronic paper uses plastic substrates and plastic electronics for the display backplane. Applications of e-paper include electronic shelf labels and digital signage, bus station time tables, electronic billboards, smartphone displays, and e-readers able to display digital versions of books and magazines.\nTechnologies.\nGyricon.\nElectronic paper was first developed in the 1970s by Nick Sheridon at Xerox's Palo Alto Research Center. The first electronic paper, called Gyricon, consisted of polyethylene spheres between 75 and 106 micrometers across. Each sphere is a Janus particle composed of negatively charged black plastic on one side and positively charged white plastic on the other (each bead is thus a dipole). The spheres are embedded in a transparent silicone sheet, with each sphere suspended in a bubble of oil so that it can rotate freely. The polarity of the voltage applied to each pair of electrodes then determines whether the white or black side is face-up, thus giving the pixel a white or black appearance.\nAt the FPD 2008 exhibition, Japanese company Soken demonstrated a wall with electronic wall-paper using this technology. In 2007, the Estonian company Visitret Displays was developing this kind of display using polyvinylidene fluoride (PVDF) as the material for the spheres, dramatically improving the video speed and decreasing the control voltage needed.\nElectrophoretic.\nAn electrophoretic display (EPD) forms images by rearranging charged pigment particles with an applied electric field.\nIn the simplest implementation of an EPD, titanium dioxide (titania) particles approximately one micrometer in diameter are dispersed in a hydrocarbon oil. A dark-colored dye is also added to the oil, along with surfactants and charging agents that cause the particles to take on an electric charge. This mixture is placed between two parallel, conductive plates separated by a gap of 10 to 100 micrometres. When a voltage is applied across the two plates, the particles migrate electrophoretically to the plate that bears the opposite charge from that on the particles. When the particles are located at the front (viewing) side of the display, it appears white, because the light is scattered back to the viewer by the high-index titania particles. When the particles are located at the rear side of the display, it appears dark, because the light is absorbed by the colored dye. If the rear electrode is divided into a number of small picture elements (pixels), then an image can be formed by applying the appropriate voltage to each region of the display to create a pattern of reflecting and absorbing regions.\nEPDs are typically addressed using MOSFET-based thin-film transistor (TFT) technology. TFTs are often used to form a high-density image in an EPD.\nA common application for TFT-based EPDs are e-readers. Electrophoretic displays are considered prime examples of the electronic paper category, because of their paper-like appearance and low power consumption. Examples of commercial electrophoretic displays include the high-resolution active matrix displays used in the Amazon Kindle, Barnes &amp; Noble Nook, Sony Reader, Kobo eReader, and iRex iLiad e-readers. These displays are constructed from an electrophoretic imaging film manufactured by E Ink Corporation. A mobile phone that used the technology is the Motorola Fone.\nElectrophoretic Display technology has also been developed by SiPix and Bridgestone/Delta. SiPix is now part of E Ink Corporation. The SiPix design uses a flexible 0.15\u00a0mm Microcup architecture, instead of E Ink's 0.04\u00a0mm diameter microcapsules. Bridgestone Corp.'s Advanced Materials Division cooperated with Delta Optoelectronics Inc. in developing Quick Response Liquid Powder Display technology.\nElectrophoretic displays can be manufactured using the Electronics on Plastic by Laser Release (EPLaR) process, developed by Philips Research, to enable existing AM-LCD manufacturing plants to create flexible plastic displays.\nMicroencapsulated electrophoretic display.\nIn the 1990s another type of electronic ink based on a microencapsulated electrophoretic display was conceived and prototyped by a team of undergraduates at MIT as described in their Nature paper. J.D. Albert, Barrett Comiskey, Joseph Jacobson, Jeremy Rubin and Russ Wilcox co-founded E Ink Corporation in 1997 to commercialize the technology. E Ink subsequently formed a partnership with Philips Components two years later to develop and market the technology. In 2005, Philips sold the electronic paper business as well as its related patents to Prime View International. \"It has for many years been an ambition of researchers in display media to create a flexible low-cost system that is the electronic analog of paper. In this context, microparticle-based displays have long intrigued researchers. Switchable contrast in such displays is achieved by the electromigration of highly scattering or absorbing microparticles (in the size range 0.1\u20135 \u03bcm), quite distinct from the molecular-scale properties that govern the behavior of the more familiar liquid-crystal displays. Micro-particle-based displays possess intrinsic bistability, exhibit extremely low power d.c. field addressing and have demonstrated high contrast and reflectivity. These features, combined with a near-lambertian viewing characteristic, result in an 'ink on paper' look. But such displays have to date suffered from short lifetimes and difficulty in manufacture. Here we report the synthesis of an electrophoretic ink based on the microencapsulation of an electrophoretic dispersion. The use of a microencapsulated electrophoretic medium solves the lifetime issues and permits the fabrication of a bistable electronic display solely by means of printing. This system may satisfy the practical requirements of electronic paper.\"\nThis used tiny microcapsules filled with electrically charged white particles suspended in a colored oil. In early versions, the underlying circuitry controlled whether the white particles were at the top of the capsule (so it looked white to the viewer) or at the bottom of the capsule (so the viewer saw the color of the oil). This was essentially a reintroduction of the well-known electrophoretic display technology, but microcapsules meant the display could be made on flexible plastic sheets instead of glass.\nOne early version of the electronic paper consists of a sheet of very small transparent capsules, each about 40 micrometers across. Each capsule contains an oily solution containing black dye (the electronic ink), with numerous white titanium dioxide particles suspended within. The particles are slightly negatively charged, and each one is naturally white.\nThe screen holds microcapsules in a layer of liquid polymer, sandwiched between two arrays of electrodes, the upper of which is transparent. The two arrays are aligned to divide the sheet into pixels, and each pixel corresponds to a pair of electrodes situated on either side of the sheet. The sheet is laminated with transparent plastic for protection, resulting in an overall thickness of 80 micrometers, or twice that of ordinary paper.\nThe network of electrodes connects to display circuitry, which turns the electronic ink 'on' and 'off' at specific pixels by applying a voltage to specific electrode pairs. A negative charge to the surface electrode repels the particles to the bottom of local capsules, forcing the black dye to the surface and turning the pixel black. Reversing the voltage has the opposite effect. It forces the particles to the surface, turning the pixel white. A more recent implementation of this concept requires only one layer of electrodes beneath the microcapsules. These are commercially referred to as Active Matrix Electrophoretic Displays (AMEPD).\nReflective LCD.\nThis technology is similar to common LCD while the backlight panel is substituted by a reflective surface.\nA comparable technology is also obtainable in backlight LCDs by software or hardware deactivating the backlight control.\nElectrowetting.\nElectrowetting display (EWD) is based on controlling the shape of a confined water/oil interface by an applied voltage. With no voltage applied, the (colored) oil forms a flat film between the water and a hydrophobic (water-repellent) insulating coating of an electrode, resulting in a colored pixel. When a voltage is applied between the electrode and the water, the interfacial tension between the water and the coating changes. As a result, the stacked state is no longer stable, causing the water to move the oil aside. This makes a partly transparent pixel, or, if a reflective white surface is under the switchable element, a white pixel. Because of the small pixel size, the user only experiences the average reflection, which provides a high-brightness, high-contrast switchable element.\nDisplays based on electrowetting provide several attractive features. The switching between white and colored reflection is fast enough to display video content. It is a low-power, low-voltage technology, and displays based on the effect can be made flat and thin. The reflectivity and contrast are better than or equal to other reflective display types and approach the visual qualities of paper. In addition, the technology offers a unique path toward high-brightness full-color displays, leading to displays that are four times brighter than reflective LCDs and twice as bright as other emerging technologies. Instead of using red, green, and blue (RGB) filters or alternating segments of the three primary colors, which effectively result in only one-third of the display reflecting light in the desired color, electrowetting allows for a system in which one sub-pixel can switch two different colors independently.\nThis results in the availability of two-thirds of the display area to reflect light in any desired color. This is achieved by building up a pixel with a stack of two independently controllable colored oil films plus a color filter.\nThe colors are cyan, magenta, and yellow, which is a subtractive system, comparable to the principle used in inkjet printing. Compared to LCD, brightness is gained because no polarisers are required.\nElectrofluidic.\nElectrofluidic display is a variation of an electrowetting display that place an aqueous pigment dispersion inside a tiny reservoir. The reservoir comprises less than 5-10% of the viewable pixel area and therefore the pigment is substantially hidden from view. Voltage is used to electromechanically pull the pigment out of the reservoir and spread it as a film directly behind the viewing substrate. As a result, the display takes on color and brightness similar to that of conventional pigments printed on paper. When voltage is removed liquid surface tension causes the pigment dispersion to rapidly recoil into the reservoir. The technology can potentially provide greater than 85% white state reflectance for electronic paper.\nThe core technology was invented at the Novel Devices Laboratory at the University of Cincinnati and there are working prototypes developed by collaboration with Sun Chemical, Polymer Vision and Gamma Dynamics.\nIt has a wide margin in critical aspects such as brightness, color saturation and response time.\nBecause the optically active layer can be less than 15 micrometres thick, there is strong potential for rollable displays.\nInterferometric modulator (Mirasol).\nThe technology used in electronic visual displays that can create various colors via interference of reflected light. The color is selected with an electrically switched light modulator comprising a microscopic cavity that is switched on and off using driver integrated circuits similar to those used to address liquid-crystal displays (LCD).\nPlasmonic electronic display.\nPlasmonic nanostructures with conductive polymers have also been suggested as one kind of electronic paper. The material has two parts. The first part is a highly reflective metasurface made by metal-insulator-metal films tens of nanometers in thickness including nanoscale holes. The metasurfaces can reflect different colors depending on the thickness of the insulator. The standard RGB color schema can be used as pixels for full-color displays. The second part is a polymer with optical absorption controllable by an electrochemical potential. After growing the polymer on the plasmonic metasurfaces, the reflection of the metasurfaces can be modulated by the applied voltage. This technology presents broad range colors, high polarization-independent reflection (&gt;50 %), strong contrast (&gt;30 %), the fast response time (hundreds of ms), and long-term stability. In addition, it has ultralow power consumption (&lt; 0.5\u00a0mW/cm2) and potential for high resolution (&gt;10000 dpi). Since the ultrathin metasurfaces are flexible and the polymer is soft, the whole system can be bent. Desired future improvements for this technology include bistability, cheaper materials and implementation with TFT arrays.\nOther technologies.\nOther research efforts into e-paper have involved using organic transistors embedded into flexible substrates, including attempts to build them into conventional paper.\nSimple color e-paper consists of a thin colored optical filter added to the monochrome technology described above. The array of pixels is divided into triads, typically consisting of the standard cyan, magenta and yellow, in the same way as CRT monitors (although using subtractive primary colors as opposed to additive primary colors). The display is then controlled like any other electronic color display.\nHistory.\nE Ink Corporation of E Ink Holdings Inc. released the first colored E Ink displays to be used in a marketed product. The Ectaco jetBook Color was released in 2012 as the first colored electronic ink device, which used E Ink's Triton display technology. E Ink in early 2015 also announced another color electronic ink technology called Prism. This new technology is a color changing film that can be used for e-readers, but Prism is also marketed as a film that can be integrated into architectural design such as \"wall, ceiling panel, or entire room instantly.\" The disadvantage of these current color displays is that they are considerably more expensive than standard E Ink displays. The jetBook Color costs roughly nine times more than other popular e-readers such as the Amazon Kindle. As of January 2015, Prism had not been announced to be used in the plans for any e-reader devices.\nApplications.\nSeveral companies are simultaneously developing electronic paper and ink. While the technologies used by each company provide many of the same features, each has its own distinct technological advantages. All electronic paper technologies face the following general challenges:\nElectronic ink can be applied to flexible or rigid materials. For flexible displays, the base requires a thin, flexible material tough enough to withstand considerable wear, such as extremely thin plastic. The method of how the inks are encapsulated and then applied to the substrate is what distinguishes each company from others. These processes are complex and are carefully guarded industry secrets. Nevertheless, making electronic paper is less complex and costly than LCDs.\nThere are many approaches to electronic paper, with many companies developing technology in this area. Other technologies being applied to electronic paper include modifications of liquid-crystal displays, electrochromic displays, and the electronic equivalent of an Etch A Sketch at Kyushu University. Advantages of electronic paper include low power usage (power is only drawn when the display is updated), flexibility and better readability than most displays. Electronic ink can be printed on any surface, including walls, billboards, product labels and T-shirts. The ink's flexibility would also make it possible to develop rollable displays for electronic devices.\nWristwatches.\nIn December 2005, Seiko released the first electronic ink based watch called the Spectrum SVRD001 wristwatch, which has a flexible electrophoretic display and in March 2010 Seiko released a second generation of this famous electronic ink watch with an active matrix display. The Pebble smart watch (2013) uses a low-power memory LCD manufactured by Sharp for its e-paper display.\nIn 2019, Fossil launched a hybrid smartwatch called the Hybrid HR, integrating an always on electronic ink display with physical hands and dial to simulate the look of a traditional analog watch.\nE-book readers.\nIn 2004, Sony released the Libri\u00e9 in Japan, the first e-book reader with an electronic paper E Ink display. In September 2006, Sony released the PRS-500 Sony Reader e-book reader in the USA. On October 2, 2007, Sony announced the PRS-505, an updated version of the Reader. In November 2008, Sony released the PRS-700BC, which incorporated a backlight and a touchscreen.\nMobile phones.\nMotorola's low-cost mobile phone, the Motorola F3, uses an alphanumeric black-and-white electrophoretic display.\nThe Samsung Alias 2 mobile phone incorporates electronic ink from E Ink into the keypad, which allows the keypad to change character sets and orientation while in different display modes.\nSmartphones.\nOn December 12, 2012, Yota Devices announced the first \"YotaPhone\" prototype and was later released in December 2013, a unique double-display smartphone. It has a 4.3-inch, HD LCD on the front and an electronic ink display on the back.\nOn May and June 2020, Hisense released the Hisense A5c and A5 pro cc, the first color electronic ink smartphones. With a single color display, with a togglable front light running android 9 and Android 10.\nComputer monitors.\nElectronic paper is used on computer monitors like the 13.3 inch Dasung Paperlike 3 HD and 25.3 inch Paperlike 253.\nLaptop.\nSome laptops like Lenovo ThinkBook Plus use e-paper as a secondary screen.\nOther common laptops use reflective LCD panels with no backlight.\nFurthermore, some operating systems e.g. Xubuntu, Kali Linux provide a control to dim backlight LCD brightness to 0% in internal monitors, while crystals keep working so that the display is lighted by ambient light as it was paper.\nIn late 2007, Amazon began producing and marketing the Amazon Kindle, an e-book reader with an e-paper display. In February 2009, Amazon released the Kindle 2 and in May 2009 the larger Kindle DX was announced. In July 2010 the third-generation Kindle was announced, with notable design changes. The fourth generation of Kindle, called Touch, was announced in September 2011 that was the Kindle's first departure from keyboards and page turn buttons in favor of touchscreens. In September 2012, Amazon announced the fifth generation of the Kindle called the Paperwhite, which incorporates a LED frontlight and a higher contrast display.\nIn November 2009, Barnes and Noble launched the Barnes &amp; Noble Nook, running an Android operating system. It differs from other e-readers in having a replaceable battery, and a separate touch-screen color LCD below the main electronic paper reading screen.\nIn 2017, Sony and reMarkable offered e-books tailored for writing with a smart stylus.\nIn 2020, Onyx released the first frontlit 13.3 inch electronic paper Android tablet, the Boox Max Lumi. At the end of the same year, Bigme released the first 10.3 inch color electronic paper Android tablet, the Bigme B1 Pro. This was also the first large electronic paper tablet to support 4g cellular data.\nNewspapers.\nIn February 2006, the Flemish daily \"De Tijd\" distributed an electronic version of the paper to select subscribers in a limited marketing study, using a pre-release version of the iRex iLiad. This was the first recorded application of electronic ink to newspaper publishing.\nThe French daily \"Les \u00c9chos\" announced the official launch of an electronic version of the paper on a subscription basis in September 2007. Two offers were available, combining a one-year subscription and a reading device. The offer included either a light (176g) reading device (adapted for Les Echos by Ganaxa) or the iRex iLiad. Two different processing platforms were used to deliver readable information of the daily, one based on the newly developed GPP electronic ink platform from \"Ganaxa\", and the other one developed internally by Les Echos.\nDisplays embedded in smart cards.\nFlexible display cards enable financial payment cardholders to generate a one-time password to reduce online banking and transaction fraud. Electronic paper offers a flat and thin alternative to existing key fob tokens for data security. The world's first ISO compliant smart card with an embedded display was developed by Innovative Card Technologies and nCryptone in 2005. The cards were manufactured by Nagra ID.\nStatus displays.\nSome devices, like USB flash drives, have used electronic paper to display status information, such as available storage space. Once the image on the electronic paper has been set, it requires no power to maintain, so the readout can be seen even when the flash drive is not plugged in.\nElectronic shelf labels.\nE-paper based electronic shelf labels (ESL) are used to digitally display the prices of goods at retail stores. Electronic-paper-based labels are updated via two-way infrared or radio technology and powered by a rechargeable coin cell.\nSome variants use ZBD (zenithal bistable display) which is more similar to LCD but does not need power to retain an image.\nPublic transport timetables.\nE-paper displays at bus or trams stops can be remotely updated. Compared to LED or liquid-crystal displays (LCDs), they consume lower energy and the text or graphics stays visible during a power failure. Compared to LCDs, it easily visible under full sunshine.\nDigital signage.\nBecause of its energy-saving properties, electronic paper has proved a technology suited to digital signage applications.\nElectronic tags.\nTypically, e-paper electronic tags integrate e-ink technology with wireless interfaces like NFC or UHF. They are most commonly used as employees' ID cards or as production labels to track manufacturing changes and status. E-paper tags are also increasingly being used as shipping labels, especially in the case of reusable boxes. \nAn interesting feature provided by some e-paper Tags manufacturers is batteryless design. This means that the power needed for a display's content update is provided wirelessly and the module itself doesn't contain any battery.\nOther.\nOther proposed applications include clothes, digital photo frames, information boards, and keyboards. Keyboards with dynamically changeable keys are useful for less represented languages, non-standard keyboard layouts such as Dvorak, or for special non-alphabetical applications such as video editing or games.\nThe reMarkable is a writer tablet for reading and taking notes."}
{"id": "9228", "revid": "38005489", "url": "https://en.wikipedia.org/wiki?curid=9228", "title": "Earth", "text": "Earth is the third planet from the Sun and the only astronomical object known to harbor life. This is enabled by Earth being an ocean world, the only one in the Solar System sustaining liquid surface water. Almost all of Earth's water is contained in its global ocean, covering 70.8% of Earth's crust. The remaining 29.2% of Earth's crust is land, most of which is located in the form of continental landmasses within Earth's land hemisphere. Most of Earth's land is at least somewhat humid and covered by vegetation, while large sheets of ice at Earth's polar deserts retain more water than Earth's groundwater, lakes, rivers, and atmospheric water combined. Earth's crust consists of slowly moving tectonic plates, which interact to produce mountain ranges, volcanoes, and earthquakes. Earth has a liquid outer core that generates a magnetosphere capable of deflecting most of the destructive solar winds and cosmic radiation.\nEarth has a dynamic atmosphere, which sustains Earth's surface conditions and protects it from most meteoroids and UV-light at entry. It has a composition of primarily nitrogen and oxygen. Water vapor is widely present in the atmosphere, forming clouds that cover most of the planet. The water vapor acts as a greenhouse gas and, together with other greenhouse gases in the atmosphere, particularly carbon dioxide (CO2), creates the conditions for both liquid surface water and water vapor to persist via the capturing of energy from the Sun's light. This process maintains the current average surface temperature of , at which water is liquid under normal atmospheric pressure. Differences in the amount of captured energy between geographic regions (as with the equatorial region receiving more sunlight than the polar regions) drive atmospheric and ocean currents, producing a global climate system with different climate regions, and a range of weather phenomena such as precipitation, allowing components such as nitrogen to cycle.\nEarth is rounded into an ellipsoid with a circumference of about 40,000\u00a0km. It is the densest planet in the Solar System. Of the four rocky planets, it is the largest and most massive. Earth is about eight light-minutes away from the Sun and orbits it, taking a year (about 365.25 days) to complete one revolution. Earth rotates around its own axis in slightly less than a day (in about 23 hours and 56 minutes). Earth's axis of rotation is tilted with respect to the perpendicular to its orbital plane around the Sun, producing seasons. Earth is orbited by one permanent natural satellite, the Moon, which orbits Earth at 384,400\u00a0km (1.28 light seconds) and is roughly a quarter as wide as Earth. The Moon's gravity helps stabilize Earth's axis, causes tides and gradually slows Earth's rotation. Tidal locking has made the Moon always face Earth with the same side.\nEarth, like most other bodies in the Solar System, formed 4.5\u00a0billion years ago from gas and dust in the early Solar System. During the first billion years of Earth's history, the ocean formed and then life developed within it. Life spread globally and has been altering Earth's atmosphere and surface, leading to the Great Oxidation Event two billion years ago. Humans emerged 300,000 years ago in Africa and have spread across every continent on Earth. Humans depend on Earth's biosphere and natural resources for their survival, but have increasingly impacted the planet's environment. Humanity's current impact on Earth's climate and biosphere is unsustainable, threatening the livelihood of humans and many other forms of life, and causing widespread extinctions.\nEtymology.\nThe Modern English word \"Earth\" developed, via Middle English, from an Old English noun most often spelled '. It has cognates in every Germanic language, and their ancestral root has been reconstructed as *\"er\u00fe\u014d\". In its earliest attestation, the word \"eor\u00f0e\" was used to translate the many senses of Latin ' and Greek \u03b3\u1fc6 \"g\u0113\": the ground, its soil, dry land, the human world, the surface of the world (including the sea), and the globe itself. As with Roman Terra/Tell\u016bs and Greek Gaia, Earth may have been a personified goddess in Germanic paganism: late Norse mythology included J\u00f6r\u00f0 (\"Earth\"), a giantess often given as the mother of Thor.\nHistorically, \"Earth\" has been written in lowercase. Beginning with the use of Early Middle English, its definite sense as \"the globe\" was expressed as \"the earth\". By the era of Early Modern English, capitalization of nouns began to prevail, and \"the earth\" was also written \"the Earth\", particularly when referenced along with other heavenly bodies. More recently, the name is sometimes simply given as \"Earth\", by analogy with the names of the other planets, though \"earth\" and forms with \"the earth\" remain common. House styles now vary: Oxford spelling recognizes the lowercase form as the more common, with the capitalized form an acceptable variant. Another convention capitalizes \"Earth\" when appearing as a name, such as a description of the \"Earth's atmosphere\", but employs the lowercase when it is preceded by \"the\", such as \"the atmosphere of the earth\". It almost always appears in lowercase in colloquial expressions such as \"what on earth are you doing?\"\nThe name \"Terra\" occasionally is used in scientific writing and especially in science fiction to distinguish humanity's inhabited planet from others, while in poetry \"Tellus\" has been used to denote personification of the Earth. \"Terra\" is also the name of the planet in some Romance languages, languages that evolved from Latin, like Italian and Portuguese, while in other Romance languages the word gave rise to names with slightly altered spellings, like the Spanish \"Tierra\" and the French \"Terre\". The Latinate form \"G\u00e6a\" or \"Gaea\" () of the Greek poetic name \"Gaia\" (; or ) is rare, though the alternative spelling \"Gaia\" has become common due to the Gaia hypothesis, in which case its pronunciation is rather than the more classical English .\nThere are a number of adjectives for the planet Earth. The word \"earthly\" is derived from \"Earth\". From the Latin \"Terra\" comes \"terran\" , \"terrestrial\" , and (via French) \"terrene\" , and from the Latin \"Tellus\" comes \"tellurian\" and \"telluric\".\nNatural history.\nFormation.\nThe oldest material found in the Solar System is dated to Ga (billion years) ago. By the primordial Earth had formed. The bodies in the Solar System formed and evolved with the Sun. In theory, a solar nebula partitions a volume out of a molecular cloud by gravitational collapse, which begins to spin and flatten into a circumstellar disk, and then the planets grow out of that disk with the Sun. A nebula contains gas, ice grains, and dust (including primordial nuclides). According to nebular theory, planetesimals formed by accretion, with the primordial Earth being estimated as likely taking anywhere from 70 to 100 million years to form.\nEstimates of the age of the Moon range from 4.5 Ga to significantly younger. A leading hypothesis is that it was formed by accretion from material loosed from Earth after a Mars-sized object with about 10% of Earth's mass, named Theia, collided with Earth. It hit Earth with a glancing blow and some of its mass merged with Earth. Between approximately 4.0 and , numerous asteroid impacts during the Late Heavy Bombardment caused significant changes to the greater surface environment of the Moon and, by inference, to that of Earth.\nAfter formation.\nEarth's atmosphere and oceans were formed by volcanic activity and outgassing. Water vapor from these sources condensed into the oceans, augmented by water and ice from asteroids, protoplanets, and comets. Sufficient water to fill the oceans may have been on Earth since it formed. In this model, atmospheric greenhouse gases kept the oceans from freezing when the newly forming Sun had only 70% of its current luminosity. By , Earth's magnetic field was established, which helped prevent the atmosphere from being stripped away by the solar wind.\nAs the molten outer layer of Earth cooled it formed the first solid crust, which is thought to have been mafic in composition. The first continental crust, which was more felsic in composition, formed by the partial melting of this mafic crust. The presence of grains of the mineral zircon of Hadean age in Eoarchean sedimentary rocks suggests that at least some felsic crust existed as early as , only after Earth's formation. There are two main models of how this initial small volume of continental crust evolved to reach its current abundance: (1) a relatively steady growth up to the present day, which is supported by the radiometric dating of continental crust globally and (2) an initial rapid growth in the volume of continental crust during the Archean, forming the bulk of the continental crust that now exists, which is supported by isotopic evidence from hafnium in zircons and neodymium in sedimentary rocks. The two models and the data that support them can be reconciled by large-scale recycling of the continental crust, particularly during the early stages of Earth's history.\nNew continental crust forms as a result of plate tectonics, a process ultimately driven by the continuous loss of heat from Earth's interior. Over the period of hundreds of millions of years, tectonic forces have caused areas of continental crust to group together to form supercontinents that have subsequently broken apart. At approximately , one of the earliest known supercontinents, Rodinia, began to break apart. The continents later recombined to form Pannotia at , then finally Pangaea, which also began to break apart at .\nThe most recent pattern of ice ages began about , and then intensified during the Pleistocene about . High- and middle-latitude regions have since undergone repeated cycles of glaciation and thaw, repeating about every 21,000, 41,000 and 100,000 years. The Last Glacial Period, colloquially called the \"last ice age\", covered large parts of the continents, to the middle latitudes, in ice and ended about 11,700 years ago.\nOrigin of life and evolution.\nChemical reactions led to the first self-replicating molecules about four billion years ago. A half billion years later, the last common ancestor of all current life arose. The evolution of photosynthesis allowed the Sun's energy to be harvested directly by life forms. The resultant molecular oxygen () accumulated in the atmosphere and due to interaction with ultraviolet solar radiation, formed a protective ozone layer () in the upper atmosphere. The incorporation of smaller cells within larger ones resulted in the development of complex cells called eukaryotes. True multicellular organisms formed as cells within colonies became increasingly specialized. Aided by the absorption of harmful ultraviolet radiation by the ozone layer, life colonized Earth's surface. Among the earliest fossil evidence for life is microbial mat fossils found in 3.48\u00a0billion-year-old sandstone in Western Australia, biogenic graphite found in 3.7\u00a0billion-year-old metasedimentary rocks in Western Greenland, and remains of biotic material found in 4.1\u00a0billion-year-old rocks in Western Australia. The earliest direct evidence of life on Earth is contained in 3.45\u00a0billion-year-old Australian rocks showing fossils of microorganisms.During the Neoproterozoic, , much of Earth might have been covered in ice. This hypothesis has been termed \"Snowball Earth\", and it is of particular interest because it preceded the Cambrian explosion, when multicellular life forms significantly increased in complexity. Following the Cambrian explosion, , there have been at least five major mass extinctions and many minor ones. Apart from the proposed current Holocene extinction event, the most recent was , when an asteroid impact triggered the extinction of non-avian dinosaurs and other large reptiles, but largely spared small animals such as insects, mammals, lizards and birds. Mammalian life has diversified over the past , and several million years ago, an African ape species gained the ability to stand upright. This facilitated tool use and encouraged communication that provided the nutrition and stimulation needed for a larger brain, which led to the evolution of humans. The development of agriculture, and then civilization, led to humans having an influence on Earth and the nature and quantity of other life forms that continues to this day.\nFuture.\nEarth's expected long-term future is tied to that of the Sun. Over the next , solar luminosity will increase by 10%, and over the next by 40%. Earth's increasing surface temperature will accelerate the inorganic carbon cycle, possibly reducing concentration to levels lethally low for current plants ( for C4 photosynthesis) in approximately . A lack of vegetation would result in the loss of oxygen in the atmosphere, making current animal life impossible. Due to the increased luminosity, Earth's mean temperature may reach in 1.5\u00a0billion years, and all ocean water will evaporate and be lost to space, which may trigger a runaway greenhouse effect, within an estimated 1.6 to 3\u00a0billion years. Even if the Sun were stable, a fraction of the water in the modern oceans will descend to the mantle, due to reduced steam venting from mid-ocean ridges.\nThe Sun will evolve to become a red giant in about . Models predict that the Sun will expand to roughly , about 250 times its present radius. Earth's fate is less clear. As a red giant, the Sun will lose roughly 30% of its mass, so, without tidal effects, Earth will move to an orbit from the Sun when the star reaches its maximum radius, otherwise, with tidal effects, it may enter the Sun's atmosphere and be vaporized.\nPhysical characteristics.\nSize and shape.\nEarth has a rounded shape, through hydrostatic equilibrium, with an average diameter of , making it the fifth largest planetary sized and largest terrestrial object of the Solar System.\nDue to Earth's rotation it has the shape of an ellipsoid, bulging at its equator; its diameter is longer there than at its poles. Earth's shape also has local topographic variations; the largest local variations, like the Mariana Trench ( below local sea level), shortens Earth's average radius by 0.17% and Mount Everest ( above local sea level) lengthens it by 0.14%. Since Earth's surface is farthest out from its center of mass at its equatorial bulge, the summit of the volcano Chimborazo in Ecuador () is its farthest point out. Parallel to the rigid land topography the ocean exhibits a more dynamic topography.\nTo measure the local variation of Earth's topography, geodesy employs an idealized Earth producing a geoid shape. Such a shape is gained if the ocean is idealized, covering Earth completely and without any perturbations such as tides and winds. The result is a smooth but irregular geoid surface, providing a mean sea level as a reference level for topographic measurements.\nSurface.\nEarth's surface is the boundary between the atmosphere, and the solid Earth and oceans. Defined in this way, it has an area of about . Earth can be divided into two hemispheres: by latitude into the polar Northern and Southern hemispheres; or by longitude into the continental Eastern and Western hemispheres.\nMost of Earth's surface is ocean water: 70.8% or . This vast pool of salty water is often called the \"world ocean\", and makes Earth with its dynamic hydrosphere a water world or ocean world. Indeed, in Earth's early history the ocean may have covered Earth completely. The world ocean is commonly divided into the Pacific Ocean, Atlantic Ocean, Indian Ocean, Antarctic or Southern Ocean, and Arctic Ocean, from largest to smallest. The ocean covers Earth's oceanic crust, with the shelf seas covering the shelves of the continental crust to a lesser extent. The oceanic crust forms large oceanic basins with features like abyssal plains, seamounts, submarine volcanoes, oceanic trenches, submarine canyons, oceanic plateaus, and a globe-spanning mid-ocean ridge system. At Earth's polar regions, the ocean surface is covered by seasonally variable amounts of sea ice that often connects with polar land, permafrost and ice sheets, forming polar ice caps.\nEarth's land covers 29.2%, or of Earth's surface. The land surface includes many islands around the globe, but most of the land surface is taken by the four continental landmasses, which are (in descending order): Africa-Eurasia, America (landmass), Antarctica, and Australia (landmass). These landmasses are further broken down and grouped into the continents. The terrain of the land surface varies greatly and consists of mountains, deserts, plains, plateaus, and other landforms. The elevation of the land surface varies from a low point of at the Dead Sea, to a maximum altitude of at the top of Mount Everest. The mean height of land above sea level is about .\nLand can be covered by surface water, snow, ice, artificial structures or vegetation. Most of Earth's land hosts vegetation, but considerable amounts of land are ice sheets (10%, not including the equally large area of land under permafrost) or deserts (33%).\nThe pedosphere is the outermost layer of Earth's land surface and is composed of soil and subject to soil formation processes. Soil is crucial for land to be arable. Earth's total arable land is 10.7% of the land surface, with 1.3% being permanent cropland. Earth has an estimated of cropland and of pastureland.\nThe land surface and the ocean floor form the top of Earth's crust, which together with parts of the upper mantle form Earth's lithosphere. Earth's crust may be divided into oceanic and continental crust. Beneath the ocean-floor sediments, the oceanic crust is predominantly basaltic, while the continental crust may include lower density materials such as granite, sediments and metamorphic rocks. Nearly 75% of the continental surfaces are covered by sedimentary rocks, although they form about 5% of the mass of the crust.\nEarth's surface topography comprises both the topography of the ocean surface, and the shape of Earth's land surface. The submarine terrain of the ocean floor has an average bathymetric depth of 4\u00a0km, and is as varied as the terrain above sea level. Earth's surface is continually being shaped by internal plate tectonic processes including earthquakes and volcanism; by weathering and erosion driven by ice, water, wind and temperature; and by biological processes including the growth and decomposition of biomass into soil.\nTectonic plates.\nEarth's mechanically rigid outer layer of Earth's crust and upper mantle, the lithosphere, is divided into tectonic plates. These plates are rigid segments that move relative to each other at one of three boundaries types: at convergent boundaries, two plates come together; at divergent boundaries, two plates are pulled apart; and at transform boundaries, two plates slide past one another laterally. Along these plate boundaries, earthquakes, volcanic activity, mountain-building, and oceanic trench formation can occur. The tectonic plates ride on top of the asthenosphere, the solid but less-viscous part of the upper mantle that can flow and move along with the plates.\nAs the tectonic plates migrate, oceanic crust is subducted under the leading edges of the plates at convergent boundaries. At the same time, the upwelling of mantle material at divergent boundaries creates mid-ocean ridges. The combination of these processes recycles the oceanic crust back into the mantle. Due to this recycling, most of the ocean floor is less than old. The oldest oceanic crust is located in the Western Pacific and is estimated to be old. By comparison, the oldest dated continental crust is , although zircons have been found preserved as clasts within Eoarchean sedimentary rocks that give ages up to , indicating that at least some continental crust existed at that time.\nThe seven major plates are the Pacific, North American, Eurasian, African, Antarctic, Indo-Australian, and South American. Other notable plates include the Arabian Plate, the Caribbean Plate, the Nazca Plate off the west coast of South America and the Scotia Plate in the southern Atlantic Ocean. The Australian Plate fused with the Indian Plate between . The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of and the Pacific Plate moving . At the other extreme, the slowest-moving plate is the South American Plate, progressing at a typical rate of .\nInternal structure.\nEarth's interior, like that of the other terrestrial planets, is divided into layers by their chemical or physical (rheological) properties. The outer layer is a chemically distinct silicate solid crust, which is underlain by a highly viscous solid mantle. The crust is separated from the mantle by the Mohorovi\u010di\u0107 discontinuity. The thickness of the crust varies from about under the oceans to for the continents. The crust and the cold, rigid, top of the upper mantle are collectively known as the lithosphere, which is divided into independently moving tectonic plates.\nBeneath the lithosphere is the asthenosphere, a relatively low-viscosity layer on which the lithosphere rides. Important changes in crystal structure within the mantle occur at below the surface, spanning a transition zone that separates the upper and lower mantle. Beneath the mantle, an extremely low viscosity liquid outer core lies above a solid inner core. Earth's inner core may be rotating at a slightly higher angular velocity than the remainder of the planet, advancing by 0.1\u20130.5\u00b0 per year, although both somewhat higher and much lower rates have also been proposed. The radius of the inner core is about one-fifth of that of Earth. The density increases with depth. Among the Solar System's planetary-sized objects, Earth is the object with the highest density.\nChemical composition.\nEarth's mass is approximately (). It is composed mostly of iron (32.1% by mass), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%), with the remaining 1.2% consisting of trace amounts of other elements. Due to gravitational separation, the core is primarily composed of the denser elements: iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements. The most common rock constituents of the crust are oxides. Over 99% of the crust is composed of various oxides of eleven elements, principally oxides containing silicon (the silicate minerals), aluminium, iron, calcium, magnesium, potassium, or sodium.\nInternal heat.\nThe major contributors to Earth's internal heat are primordial heat (heat left over from Earth's formation) and radiogenic heat (heat produced by radioactive decay). The major heat-producing isotopes within Earth are potassium-40, uranium-238, and thorium-232. At the center, the temperature may be up to , and the pressure could reach . Because much of the heat is provided by radioactive decay, scientists postulate that early in Earth's history, before isotopes with short half-lives were depleted, Earth's heat production was much higher. At approximately , twice the present-day heat would have been produced, increasing the rates of mantle convection and plate tectonics, and allowing the production of uncommon igneous rocks such as komatiites that are rarely formed today.\nThe mean heat loss from Earth is , for a global heat loss of . A portion of the core's thermal energy is transported toward the crust by mantle plumes, a form of convection consisting of upwellings of higher-temperature rock. These plumes can produce hotspots and flood basalts. More of the heat in Earth is lost through plate tectonics, by mantle upwelling associated with mid-ocean ridges. The final major mode of heat loss is through conduction through the lithosphere, the majority of which occurs under the oceans.\nGravitational field.\nThe gravity of Earth is the acceleration that is imparted to objects due to the distribution of mass within Earth. Near Earth's surface, gravitational acceleration is approximately . Local differences in topography, geology, and deeper tectonic structure cause local and broad regional differences in Earth's gravitational field, known as gravity anomalies.\nMagnetic field.\nThe main part of Earth's magnetic field is generated in the core, the site of a dynamo process that converts the kinetic energy of thermally and compositionally driven convection into electrical and magnetic field energy. The field extends outwards from the core, through the mantle, and up to Earth's surface, where it is, approximately, a dipole. The poles of the dipole are located close to Earth's geographic poles. At the equator of the magnetic field, the magnetic-field strength at the surface is , with a magnetic dipole moment of at epoch 2000, decreasing nearly 6% per century (although it still remains stronger than its long time average). The convection movements in the core are chaotic; the magnetic poles drift and periodically change alignment. This causes secular variation of the main field and field reversals at irregular intervals averaging a few times every million years. The most recent reversal occurred approximately 700,000 years ago.\nThe extent of Earth's magnetic field in space defines the magnetosphere. Ions and electrons of the solar wind are deflected by the magnetosphere; solar wind pressure compresses the day-side of the magnetosphere, to about 10 Earth radii, and extends the night-side magnetosphere into a long tail. Because the velocity of the solar wind is greater than the speed at which waves propagate through the solar wind, a supersonic bow shock precedes the day-side magnetosphere within the solar wind. Charged particles are contained within the magnetosphere; the plasmasphere is defined by low-energy particles that essentially follow magnetic field lines as Earth rotates. The ring current is defined by medium-energy particles that drift relative to the geomagnetic field, but with paths that are still dominated by the magnetic field, and the Van Allen radiation belts are formed by high-energy particles whose motion is essentially random, but contained in the magnetosphere. During magnetic storms and substorms, charged particles can be deflected from the outer magnetosphere and especially the magnetotail, directed along field lines into Earth's ionosphere, where atmospheric atoms can be excited and ionized, causing an aurora.\nOrbit and rotation.\nRotation.\nEarth's rotation period relative to the Sun\u2014its mean solar day\u2014is of mean solar time (). Because Earth's solar day is now slightly longer than it was during the 19th century due to tidal deceleration, each day varies between longer than the mean solar day.\nEarth's rotation period relative to the fixed stars, called its \"stellar day\" by the International Earth Rotation and Reference Systems Service (IERS), is of mean solar time (UT1), or Earth's rotation period relative to the precessing or moving mean March equinox (when the Sun is at 90\u00b0 on the equator), is of mean solar time (UT1) . Thus the sidereal day is shorter than the stellar day by about 8.4\u00a0ms.\nApart from meteors within the atmosphere and low-orbiting satellites, the main apparent motion of celestial bodies in Earth's sky is to the west at a rate of 15\u00b0/h = 15'/min. For bodies near the celestial equator, this is equivalent to an apparent diameter of the Sun or the Moon every two minutes; from Earth's surface, the apparent sizes of the Sun and the Moon are approximately the same.\nOrbit.\nEarth orbits the Sun, making Earth the third-closest planet to the Sun and part of the inner Solar System. Earth's average orbital distance is about , which is the basis for the astronomical unit (AU) and is equal to roughly 8.3 light minutes or 380 times Earth's distance to the Moon. Earth orbits the Sun every 365.2564 mean solar days, or one sidereal year. With an apparent movement of the Sun in Earth's sky at a rate of about 1\u00b0/day eastward, which is one apparent Sun or Moon diameter every 12\u00a0hours. Due to this motion, on average it takes 24\u00a0hours\u2014a solar day\u2014for Earth to complete a full rotation about its axis so that the Sun returns to the meridian.\nThe orbital speed of Earth averages about , which is fast enough to travel a distance equal to Earth's diameter, about , in seven minutes, and the distance from Earth to the Moon, , in about 3.5 hours.\nThe Moon and Earth orbit a common barycenter every 27.32\u00a0days relative to the background stars. When combined with the Earth\u2013Moon system's common orbit around the Sun, the period of the synodic month, from new moon to new moon, is 29.53\u00a0days. Viewed from the celestial north pole, the motion of Earth, the Moon, and their axial rotations are all counterclockwise. Viewed from a vantage point above the Sun and Earth's north poles, Earth orbits in a counterclockwise direction about the Sun. The orbital and axial planes are not precisely aligned: Earth's axis is tilted some 23.44 degrees from the perpendicular to the Earth\u2013Sun plane (the ecliptic), and the Earth-Moon plane is tilted up to \u00b15.1 degrees against the Earth\u2013Sun plane. Without this tilt, there would be an eclipse every two weeks, alternating between lunar eclipses and solar eclipses.\nThe Hill sphere, or the sphere of gravitational influence, of Earth is about in radius. This is the maximum distance at which Earth's gravitational influence is stronger than that of the more distant Sun and planets. Objects must orbit Earth within this radius, or they can become unbound by the gravitational perturbation of the Sun. Earth, along with the Solar System, is situated in the Milky Way and orbits about 28,000\u00a0light-years from its center. It is about 20\u00a0light-years above the galactic plane in the Orion Arm.\nAxial tilt and seasons.\nThe axial tilt of Earth is approximately 23.439281\u00b0 with the axis of its orbit plane, always pointing towards the Celestial Poles. Due to Earth's axial tilt, the amount of sunlight reaching any given point on the surface varies over the course of the year. This causes the seasonal change in climate, with summer in the Northern Hemisphere occurring when the Tropic of Cancer is facing the Sun, and in the Southern Hemisphere when the Tropic of Capricorn faces the Sun. In each instance, winter occurs simultaneously in the opposite hemisphere.\nDuring the summer, the day lasts longer, and the Sun climbs higher in the sky. In winter, the climate becomes cooler and the days shorter. Above the Arctic Circle and below the Antarctic Circle there is no daylight at all for part of the year, causing a polar night, and this night extends for several months at the poles themselves. These same latitudes also experience a midnight sun, where the sun remains visible all day.\nBy astronomical convention, the four seasons can be determined by the solstices\u2014the points in the orbit of maximum axial tilt toward or away from the Sun\u2014and the equinoxes, when Earth's rotational axis is aligned with its orbital axis. In the Northern Hemisphere, winter solstice currently occurs around 21 December; summer solstice is near 21 June, spring equinox is around 20 March and autumnal equinox is about 22 or 23 September. In the Southern Hemisphere, the situation is reversed, with the summer and winter solstices exchanged and the spring and autumnal equinox dates swapped.\nThe angle of Earth's axial tilt is relatively stable over long periods of time. Its axial tilt does undergo nutation; a slight, irregular motion with a main period of 18.6\u00a0years. The orientation (rather than the angle) of Earth's axis also changes over time, precessing around in a complete circle over each 25,800-year cycle; this precession is the reason for the difference between a sidereal year and a tropical year. Both of these motions are caused by the varying attraction of the Sun and the Moon on Earth's equatorial bulge. The poles also migrate a few meters across Earth's surface. This polar motion has multiple, cyclical components, which collectively are termed quasiperiodic motion. In addition to an annual component to this motion, there is a 14-month cycle called the Chandler wobble. Earth's rotational velocity also varies in a phenomenon known as length-of-day variation.\nEarth's annual orbit is elliptical rather than circular, and its closest approach to the Sun is called perihelion. In modern times, Earth's perihelion occurs around 3 January, and its aphelion around 4 July. These dates shift over time due to precession and changes to the orbit, the latter of which follows cyclical patterns known as Milankovitch cycles. The annual change in the Earth\u2013Sun distance causes an increase of about 6.8% in solar energy reaching Earth at perihelion relative to aphelion. Because the Southern Hemisphere is tilted toward the Sun at about the same time that Earth reaches the closest approach to the Sun, the Southern Hemisphere receives slightly more energy from the Sun than does the northern over the course of a year. This effect is much less significant than the total energy change due to the axial tilt, and most of the excess energy is absorbed by the higher proportion of water in the Southern Hemisphere.\nEarth\u2013Moon system.\nMoon.\nThe Moon is a relatively large, terrestrial, planet-like natural satellite, with a diameter about one-quarter of Earth's. It is the largest moon in the Solar System relative to the size of its planet, although Charon is larger relative to the dwarf planet Pluto. The natural satellites of other planets are also referred to as \"moons\", after Earth's. The most widely accepted theory of the Moon's origin, the giant-impact hypothesis, states that it formed from the collision of a Mars-size protoplanet called Theia with the early Earth. This hypothesis explains the Moon's relative lack of iron and volatile elements and the fact that its composition is nearly identical to that of Earth's crust. Computer simulations suggest that two blob-like remnants of this protoplanet could be inside the Earth.\nThe gravitational attraction between Earth and the Moon causes lunar tides on Earth. The same effect on the Moon has led to its tidal locking: its rotation period is the same as the time it takes to orbit Earth. As a result, it always presents the same face to the planet. As the Moon orbits Earth, different parts of its face are illuminated by the Sun, leading to the lunar phases. Due to their tidal interaction, the Moon recedes from Earth at the rate of approximately . Over millions of years, these tiny modifications\u2014and the lengthening of Earth's day by about 23\u00a0\u03bcs/yr\u2014add up to significant changes. During the Ediacaran period, for example, (approximately ) there were 400\u00b17 days in a year, with each day lasting 21.9\u00b10.4 hours.\nThe Moon may have dramatically affected the development of life by moderating the planet's climate. Paleontological evidence and computer simulations show that Earth's axial tilt is stabilized by tidal interactions with the Moon. Some theorists think that without this stabilization against the torques applied by the Sun and planets to Earth's equatorial bulge, the rotational axis might be chaotically unstable, exhibiting large changes over millions of years, as is the case for Mars, though this is disputed.\nViewed from Earth, the Moon is just far enough away to have almost the same apparent-sized disk as the Sun. The angular size (or solid angle) of these two bodies match because, although the Sun's diameter is about 400 times as large as the Moon's, it is also 400 times more distant. This allows total and annular solar eclipses to occur on Earth.\nAsteroids and artificial satellites.\nEarth's co-orbital asteroids population consists of quasi-satellites, objects with a horseshoe orbit and trojans. There are at least seven quasi-satellites, including 469219 Kamo\u02bboalewa, ranging in diameter from 10 m to 5000 m. A trojan asteroid companion, , is librating around the leading Lagrange triangular point, L4, in Earth's orbit around the Sun. The tiny near-Earth asteroid makes close approaches to the Earth\u2013Moon system roughly every twenty years. During these approaches, it can orbit Earth for brief periods of time.\n, there are 4,550 operational, human-made satellites orbiting Earth. There are also inoperative satellites, including Vanguard 1, the oldest satellite currently in orbit, and over 16,000 pieces of tracked space debris. Earth's largest artificial satellite is the International Space Station (ISS).\nHydrosphere.\nEarth's hydrosphere is the sum of Earth's water and its distribution. Most of Earth's hydrosphere consists of Earth's global ocean. Earth's hydrosphere also consists of water in the atmosphere and on land, including clouds, inland seas, lakes, rivers, and underground waters. The mass of the oceans is approximately 1.35\u00a0metric tons or about 1/4400 of Earth's total mass. The oceans cover an area of with a mean depth of , resulting in an estimated volume of .\nIf all of Earth's crustal surface were at the same elevation as a smooth sphere, the depth of the resulting world ocean would be . About 97.5% of the water is saline; the remaining 2.5% is fresh water. Most fresh water, about 68.7%, is present as ice in ice caps and glaciers. The remaining 30% is ground water, 1% surface water (covering only 2.8% of Earth's land) and other small forms of fresh water deposits such as permafrost, water vapor in the atmosphere, biological binding, etc.\nIn Earth's coldest regions, snow survives over the summer and changes into ice. This accumulated snow and ice eventually forms into glaciers, bodies of ice that flow under the influence of their own gravity. Alpine glaciers form in mountainous areas, whereas vast ice sheets form over land in polar regions. The flow of glaciers erodes the surface, changing it dramatically, with the formation of U-shaped valleys and other landforms. Sea ice in the Arctic covers an area about as big as the United States, although it is quickly retreating as a consequence of climate change.\nThe average salinity of Earth's oceans is about 35\u00a0grams of salt per kilogram of seawater (3.5% salt). Most of this salt was released from volcanic activity or extracted from cool igneous rocks. The oceans are also a reservoir of dissolved atmospheric gases, which are essential for the survival of many aquatic life forms. Sea water has an important influence on the world's climate, with the oceans acting as a large heat reservoir. Shifts in the oceanic temperature distribution can cause significant weather shifts, such as the El Ni\u00f1o\u2013Southern Oscillation.\nThe abundance of water, particularly liquid water, on Earth's surface is a unique feature that distinguishes it from other planets in the Solar System. Solar System planets with considerable atmospheres do partly host atmospheric water vapor, but they lack surface conditions for stable surface water. Despite some moons showing signs of large reservoirs of extraterrestrial liquid water, with possibly even more volume than Earth's ocean, all of them are large bodies of water under a kilometers thick frozen surface layer.\nAtmosphere.\nThe atmospheric pressure at Earth's sea level averages , with a scale height of about . A dry atmosphere is composed of 78.084% nitrogen, 20.946% oxygen, 0.934% argon, and trace amounts of carbon dioxide and other gaseous molecules. Water vapor content varies between 0.01% and 4% but averages about 1%. Clouds cover around two-thirds of Earth's surface, more so over oceans than land. The height of the troposphere varies with latitude, ranging between at the poles to at the equator, with some variation resulting from weather and seasonal factors.\nEarth's biosphere has significantly altered its atmosphere. Oxygenic photosynthesis evolved , forming the primarily nitrogen\u2013oxygen atmosphere of today. This change enabled the proliferation of aerobic organisms and, indirectly, the formation of the ozone layer due to the subsequent conversion of atmospheric into. The ozone layer blocks ultraviolet solar radiation, permitting life on land. Other atmospheric functions important to life include transporting water vapor, providing useful gases, causing small meteors to burn up before they strike the surface, and moderating temperature. This last phenomenon is the greenhouse effect: trace molecules within the atmosphere serve to capture thermal energy emitted from the surface, thereby raising the average temperature. Water vapor, carbon dioxide, methane, nitrous oxide, and ozone are the primary greenhouse gases in the atmosphere. Without this heat-retention effect, the average surface temperature would be , in contrast to the current , and life on Earth probably would not exist in its current form.\nWeather and climate.\nEarth's atmosphere has no definite boundary, gradually becoming thinner and fading into outer space. Three-quarters of the atmosphere's mass is contained within the first of the surface; this lowest layer is called the troposphere. Energy from the Sun heats this layer, and the surface below, causing expansion of the air. This lower-density air then rises and is replaced by cooler, higher-density air. The result is atmospheric circulation that drives the weather and climate through redistribution of thermal energy.\nThe primary atmospheric circulation bands consist of the trade winds in the equatorial region below 30\u00b0 latitude and the westerlies in the mid-latitudes between 30\u00b0 and 60\u00b0. Ocean heat content and currents are also important factors in determining climate, particularly the thermohaline circulation that distributes thermal energy from the equatorial oceans to the polar regions.\nEarth receives 1361\u00a0W/m2 of\u00a0solar irradiance. The amount of solar energy that reaches Earth's surface decreases with increasing latitude. At higher latitudes, the sunlight reaches the surface at lower angles, and it must pass through thicker columns of the atmosphere. As a result, the mean annual air temperature at sea level decreases by about per degree of latitude from the equator. Earth's surface can be subdivided into specific latitudinal belts of approximately homogeneous climate. Ranging from the equator to the polar regions, these are the tropical (or equatorial), subtropical, temperate and polar climates.\nFurther factors that affect a location's climates are its proximity to oceans, the oceanic and atmospheric circulation, and topology. Places close to oceans typically have colder summers and warmer winters, due to the fact that oceans can store large amounts of heat. The wind transports the cold or the heat of the ocean to the land. Atmospheric circulation also plays an important role: San Francisco and Washington DC are both coastal cities at about the same latitude. San Francisco's climate is significantly more moderate as the prevailing wind direction is from sea to land. Finally, temperatures decrease with height causing mountainous areas to be colder than low-lying areas.\nWater vapor generated through surface evaporation is transported by circulatory patterns in the atmosphere. When atmospheric conditions permit an uplift of warm, humid air, this water condenses and falls to the surface as precipitation. Most of the water is then transported to lower elevations by river systems and usually returned to the oceans or deposited into lakes. This water cycle is a vital mechanism for supporting life on land and is a primary factor in the erosion of surface features over geological periods. Precipitation patterns vary widely, ranging from several meters of water per year to less than a millimeter. Atmospheric circulation, topographic features, and temperature differences determine the average precipitation that falls in each region.\nThe commonly used K\u00f6ppen climate classification system has five broad groups (humid tropics, arid, humid middle latitudes, continental and cold polar), which are further divided into more specific subtypes. The K\u00f6ppen system rates regions based on observed temperature and precipitation. Surface air temperature can rise to around in hot deserts, such as Death Valley, and can fall as low as in Antarctica.\nUpper atmosphere.\nThe upper atmosphere, the atmosphere above the troposphere, is usually divided into the stratosphere, mesosphere, and thermosphere. Each layer has a different lapse rate, defining the rate of change in temperature with height. Beyond these, the exosphere thins out into the magnetosphere, where the geomagnetic fields interact with the solar wind. Within the stratosphere is the ozone layer, a component that partially shields the surface from ultraviolet light and thus is important for life on Earth. The K\u00e1rm\u00e1n line, defined as above Earth's surface, is a working definition for the boundary between the atmosphere and outer space.\nThermal energy causes some of the molecules at the outer edge of the atmosphere to increase their velocity to the point where they can escape from Earth's gravity. This causes a slow but steady loss of the atmosphere into space. Because unfixed hydrogen has a low molecular mass, it can achieve escape velocity more readily, and it leaks into outer space at a greater rate than other gases. The leakage of hydrogen into space contributes to the shifting of Earth's atmosphere and surface from an initially reducing state to its current oxidizing one. Photosynthesis provided a source of free oxygen, but the loss of reducing agents such as hydrogen is thought to have been a necessary precondition for the widespread accumulation of oxygen in the atmosphere. Hence the ability of hydrogen to escape from the atmosphere may have influenced the nature of life that developed on Earth. In the current, oxygen-rich atmosphere most hydrogen is converted into water before it has an opportunity to escape. Instead, most of the hydrogen loss comes from the destruction of methane in the upper atmosphere.\nLife on Earth.\nEarth is the only known place that has ever been habitable for life. Earth's life developed in Earth's early bodies of water some hundred million years after Earth formed. Earth's life has been shaping and inhabiting many particular ecosystems on Earth and has eventually expanded globally forming an overarching biosphere.\nTherefore, life has impacted Earth, significantly altering Earth's atmosphere and surface over long periods of time, causing changes like the Great Oxidation Event. Earth's life has also over time greatly diversified, allowing the biosphere to have different biomes, which are inhabited by comparatively similar plants and animals. The different biomes developed at distinct elevations or water depths, planetary temperature latitudes and on land also with different humidity. Earth's species diversity and biomass reaches a peak in shallow waters and with forests, particularly in equatorial, warm and humid conditions. While freezing polar regions and high altitudes, or extremely arid areas are relatively barren of plant and animal life.\nEarth provides liquid water\u2014an environment where complex organic molecules can assemble and interact, and sufficient energy to sustain a metabolism. Plants and other organisms take up nutrients from water, soils and the atmosphere. These nutrients are constantly recycled between different species.\nExtreme weather, such as tropical cyclones (including hurricanes and typhoons), occurs over most of Earth's surface and has a large impact on life in those areas. From 1980 to 2000, these events caused an average of 11,800 human deaths per year. Many places are subject to earthquakes, landslides, tsunamis, volcanic eruptions, tornadoes, blizzards, floods, droughts, wildfires, and other calamities and disasters. Human impact is felt in many areas due to pollution of the air and water, acid rain, loss of vegetation (overgrazing, deforestation, desertification), loss of wildlife, species extinction, soil degradation, soil depletion and erosion. Human activities release greenhouse gases into the atmosphere which cause global warming. This is driving changes such as the melting of glaciers and ice sheets, a global rise in average sea levels, increased risk of drought and wildfires, and migration of species to colder areas.\nHuman geography.\nOriginating from earlier primates in Eastern Africa 300,000years ago humans have since been migrating and with the advent of agriculture in the 10th millennium BC increasingly settling Earth's land. In the 20th century Antarctica had been the last continent to see a first and until today limited human presence.\nHuman population has since the 19th century grown exponentially to seven billion in the early 2010s, and is projected to peak at around ten billion in the second half of the 21st century. Most of the growth is expected to take place in sub-Saharan Africa.\nDistribution and density of human population varies greatly around the world with the majority living in south to eastern Asia and 90% inhabiting only the Northern Hemisphere of Earth, partly due to the hemispherical predominance of the world's land mass, with 68% of the world's land mass being in the Northern Hemisphere. Furthermore, since the 19th century humans have increasingly converged into urban areas with the majority living in urban areas by the 21st century.\nBeyond Earth's surface humans have lived on a temporary basis, with only a few special-purpose deep underground and underwater presences and a few space stations. The human population virtually completely remains on Earth's surface, fully depending on Earth and the environment it sustains. Since the second half of the 20th century, some hundreds of humans have temporarily stayed beyond Earth, a tiny fraction of whom have reached another celestial body, the Moon.\nEarth has been subject to extensive human settlement, and humans have developed diverse societies and cultures. Most of Earth's land has been territorially claimed since the 19th century by sovereign states (countries) separated by political borders, and 205 such states exist today, with only parts of Antarctica and a few small regions remaining unclaimed. Most of these states together form the United Nations, the leading worldwide intergovernmental organization, which extends human governance over the ocean and Antarctica, and therefore all of Earth.\nNatural resources and land use.\nEarth has resources that have been exploited by humans. Those termed non-renewable resources, such as fossil fuels, are only replenished over geological timescales. Large deposits of fossil fuels are obtained from Earth's crust, consisting of coal, petroleum, and natural gas. These deposits are used by humans both for energy production and as feedstock for chemical production. Mineral ore bodies have also been formed within the crust through a process of ore genesis, resulting from actions of magmatism, erosion, and plate tectonics. These metals and other elements are extracted by mining, a process which often brings environmental and health damage.\nEarth's biosphere produces many useful biological products for humans, including food, wood, pharmaceuticals, oxygen, and the recycling of organic waste. The land-based ecosystem depends upon topsoil and fresh water, and the oceanic ecosystem depends on dissolved nutrients washed down from the land. In 2019, of Earth's land surface consisted of forest and woodlands, was shrub and grassland, were used for animal feed production and grazing, and were cultivated as croplands. Of the 1214% of ice-free land that is used for croplands, 2 percentage points were irrigated in 2015. Humans use building materials to construct shelters.\nHumans and the environment.\nHuman activities have impacted Earth's environments. Through activities such as the burning of fossil fuels, humans have been increasing the amount of greenhouse gases in the atmosphere, altering Earth's energy budget and climate. It is estimated that global temperatures in the year 2020 were warmer than the preindustrial baseline. This increase in temperature, known as global warming, has contributed to the melting of glaciers, rising sea levels, increased risk of drought and wildfires, and migration of species to colder areas.\nThe concept of planetary boundaries was introduced to quantify humanity's impact on Earth. Of the nine identified boundaries, five have been crossed: Biosphere integrity, climate change, chemical pollution, destruction of wild habitats and the nitrogen cycle are thought to have passed the safe threshold. As of 2018, no country meets the basic needs of its population without transgressing planetary boundaries. It is thought possible to provide all basic physical needs globally within sustainable levels of resource use.\nCultural and historical viewpoint.\nHuman cultures have developed many views of the planet. The standard astronomical symbols of Earth are a quartered circle, , representing the four corners of the world, and a globus cruciger, . Earth is sometimes personified as a deity. In many cultures it is a mother goddess that is also the primary fertility deity. Creation myths in many religions involve the creation of Earth by a supernatural deity or deities. The Gaia hypothesis, developed in the mid-20th century, compared Earth's environments and life as a single self-regulating organism leading to broad stabilization of the conditions of habitability.\nImages of Earth taken from space, particularly during the Apollo program, have been credited with altering the way that people viewed the planet that they lived on, called the overview effect, emphasizing its beauty, uniqueness and apparent fragility. In particular, this caused a realization of the scope of effects from human activity on Earth's environment. Enabled by science, particularly Earth observation, humans have started to take action on environmental issues globally, acknowledging the impact of humans and the interconnectedness of Earth's environments.\nScientific investigation has resulted in several culturally transformative shifts in people's view of the planet. Initial belief in a flat Earth was gradually displaced in Ancient Greece by the idea of a spherical Earth, which was attributed to both the philosophers Pythagoras and Parmenides. Earth was generally believed to be the center of the universe until the 16th century, when scientists first concluded that it was a moving object, one of the planets of the Solar System.\nIt was only during the 19th century that geologists realized Earth's age was at least many millions of years. Lord Kelvin used thermodynamics to estimate the age of Earth to be between 20 million and 400\u00a0million years in 1864, sparking a vigorous debate on the subject; it was only when radioactivity and radioactive dating were discovered in the late 19th and early 20th centuries that a reliable mechanism for determining Earth's age was established, proving the planet to be billions of years old.\nNotes.\n&lt;/math&gt;, where \"m\" is the mass of Earth, \"a\" is an astronomical unit, and \"M\" is the mass of the Sun. So the radius in AU is about formula_1.&lt;/ref&gt;"}
{"id": "9229", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9229", "title": "EnglishChannel", "text": ""}
{"id": "9230", "revid": "937895", "url": "https://en.wikipedia.org/wiki?curid=9230", "title": "English Channel", "text": "The English Channel, also known as the Channel, is an arm of the Atlantic Ocean that separates Southern England from northern France. It links to the southern part of the North Sea by the Strait of Dover at its northeastern end. It is the busiest shipping area in the world.\nIt is about long and varies in width from at its widest to at its narrowest in the Strait of Dover. It is the smallest of the shallow seas around the continental shelf of Europe, covering an area of some .\nThe Channel aided the United Kingdom in becoming a naval superpower, serving as a natural defence against invasions, such as in the Napoleonic Wars and in the Second World War.\nThe northern, English coast of the Channel is more populous than the southern, French coast. The major languages spoken in this region are English and French.\nNames.\nRoman sources as (or , meaning the Ocean, or the Sea, of the Britons or \"Britann\u012b\"). Variations of this term were used by influential writers such as Ptolemy, and remained popular with British and continental authors well into the modern era. Other Latin names for the sea include (the Gaulish Ocean) which was used by Isidore of Seville in the sixth century.\nThe term \"British Sea\" is still used by speakers of Cornish and Breton, with the sea known to them as and respectively. While it is likely that these names derive from the Latin term, it is possible that they predate the arrival of the Romans in the area. The modern Welsh is often given as (the Lord's or Prince's Sea); however, this name originally described both the Channel and the North Sea combined.\nAnglo-Saxon texts make reference to the sea as (South Sea), but this term fell out of favour, as later English authors followed the same conventions as their Latin and Norman contemporaries. One English name that did persist was the \"Narrow Seas\", a collective term for the channel and North Sea. As England (followed by Great Britain and the United Kingdom) claimed sovereignty over the sea, a Royal Navy Admiral was appointed with maintaining duties in the two seas. The office was maintained until 1822, when several European nations (including the United Kingdom) adopted a limit to territorial waters.\nEnglish Channel.\nThe word \"channel\" was first recorded in Middle English in the 13th century and was borrowed from the Old French word (a variant form of 'canal'). By the middle of the fifteenth century, an Italian map based on Ptolemy's description named the sea as \"Britanicus Oceanus nunc Canalites Anglie\" (Ocean of the Britons but now English Channel). The map is possibly the first recorded use of the term \"English Channel\" and the description suggests the name had recently been adopted.\nIn the sixteenth century, Dutch maps referred to the sea as the (English Channel) and by the 1590s, William Shakespeare used the word \"Channel\" in his history plays of Henry VI, suggesting that by that time, the name was popularly understood by English people.\nBy the eighteenth century, the name \"English Channel\" was in common usage in England. Following the Acts of Union 1707, this was replaced in official maps and documents with \"British Channel\" or \"British Sea\" for much of the next century. However, the term English Channel remained popular and was finally in official usage by the nineteenth century.\nThe French name has been used since at least the 17th century. The name is usually said to refer to the sleeve () shape of the Channel. Folk etymology has derived it from a Celtic word meaning 'channel' that is also the source of the name for the Minch in Scotland, but this name is not attested before the 17th century, and French and British sources of that time are clear about its etymology. The name in French has been directly adapted in other languages as either a calque, such as in Italian or the \"\u00c4rmelkanal\" in German, or a direct borrowing, such as in Spanish.\nNature.\nGeography.\nThe International Hydrographic Organization defines the limits of the English Channel as:\nThe Strait of Dover (), at the Channel's eastern end, is its narrowest point, while its widest point lies between Lyme Bay and the Gulf of Saint Malo, near its midpoint. Well on the continental shelf, it has an average depth of about at its widest; yet averages about between Dover and Calais, its notable sandbank hazard being Goodwin Sands. Eastwards from there the adjoining North Sea reduces to about across the Broad Fourteens (14 fathoms) where it lies over the southern cusp of the former land bridge between East Anglia and the Low Countries. The North Sea reaches much greater depths east of northern Britain. The Channel descends briefly to in the submerged valley of Hurd's Deep, west-northwest of Guernsey.\nThere are several major islands in the Channel, the most notable being the Isle of Wight off the English coast, and the Channel Islands, British Crown Dependencies off the coast of France. The coastline, particularly on the French shore, is deeply indented, with several small islands close to the coastline, including Chausey and Mont-Saint-Michel. The Cotentin Peninsula on the French coast juts out into the Channel, with the wide Bay of the Seine () to its east. On the English side there is a small parallel strait, the Solent, between the Isle of Wight and the mainland. The Celtic Sea is to the west of the Channel.\nThe Channel acts as a funnel that amplifies the tidal range from less than a metre at sea in eastern places to more than 6 metres in the Channel Islands, the west coast of the Cotentin Peninsula and the north coast of Brittany in monthly spring tides. The time difference of about six hours between high water at the eastern and western limits of the Channel is indicative of the tidal range being amplified further by resonance. Amphidromic points are the Bay of Biscay and varying more in precise location in the far south of the North Sea, meaning both those associated eastern coasts repel the tides effectively, leaving the Strait of Dover as every six hours the natural bottleneck short of its consequent gravity-induced repulsion of the southward tide (surge) of the North Sea (equally from the Atlantic). The Channel does not experience, but its existence is necessary to explain the extent of North Sea storm surges, such as necessitate the Thames Barrier, Delta Works, Zuiderzee works (Afsluitdijk and other dams).\nIn the UK Shipping Forecast the Channel is divided into the following areas, from the east:\nGeological origins.\nThe full English Channel connecting the North Sea to the Western Atlantic via the Strait of Dover is of geologically recent origin, having formed late in the Pleistocene period. The English Channel first developed as an arm of the Atlantic Ocean during the Pliocene period (5.3-2.6 million years ago) as a result of differential tectonic uplift along pre-existing tectonic weaknesses during the Oligocene and Miocene periods. During this early period, the Channel did not connect to the North Sea, with Britain and Ireland remaining part of continental Europe, linked by an unbroken Weald\u2013Artois anticline, a ridge running between the Dover and Calais regions. During Pleistocene glacial periods this ridge acted as a natural dam holding back a large freshwater pro-glacial lake in the Doggerland region, now submerged under the North Sea. During this period, the North Sea and almost all of the British Isles were covered by ice. The lake was fed by meltwater from the Baltic and from the Caledonian and Scandinavian ice sheets that joined to the north, blocking its exit. The sea level was about lower than it is today. Then, between 450,000 and 180,000\u00a0years ago, at least two catastrophic glacial lake outburst floods breached the Weald\u2013Artois anticline. These contributed to creating some of the deepest parts of the channel such as Hurd's Deep.\nThe first flood of 450,000 years ago would have lasted for several months, releasing as much as one million cubic metres of water per second. The flood started with large but localised waterfalls over the ridge, which excavated depressions now known as the \"Fosses Dangeard\". The flow eroded the retaining ridge, causing the rock dam to fail and releasing lake water into the Atlantic. After multiple episodes of changing sea level, during which the \"Fosses Dangeard\" were largely infilled by various layers of sediment, another catastrophic flood some 180,000 years ago carved a large bedrock-floored valley, the Lobourg Channel, some 500 m wide and 25 m deep, from the southern North Sea basin through the centre of the Straits of Dover and into the English Channel. It left streamlined islands, longitudinal erosional grooves, and other features characteristic of catastrophic megaflood events, still present on the sea floor and now revealed by high-resolution sonar. Through the scoured channel passed a river, the Channel River, which drained the combined Rhine and Thames westwards to the Atlantic.\nThe flooding destroyed the ridge that connected Britain to continental Europe, although a land connection across the southern North Sea would have existed intermittently at later times when periods of glaciation resulted in lowering of sea levels.\nDuring interglacial periods (when sea levels were high) between the initial flooding 450,000 years ago until around 180,000 years ago, the Channel would still have been separated from the North Sea by a land bridge to the north of the Strait of Dover (the Strait of Dover at this time formed part of a estuary fed by the Thames and Scheldt), restricting interchange of marine fauna between the Channel and the North Sea (except perhaps by occasional overtopping). During the Last Interglacial/Eemian (115\u2013130,000 years ago) the connection between the North Sea and the English Channel was fully open as it is today, resulting in Britain being an island during this interval, before lowered sea levels reconnected it to the continent during the Last Glacial Period. From the end of the Last Glacial Period, to the beginning of the Holocene rising sea levels again resulted in the unimpeded connection between the North Sea and the English Channel resuming due to the sinking of Doggerland, with Britain again becoming an island.\nEcology.\nAs a busy shipping lane, the Channel experiences environmental problems following accidents involving ships with toxic cargo and oil spills. Indeed, over 40% of the UK incidents threatening pollution occur in or very near the Channel. One occurrence was the MSC \"Napoli\", which on 18 January 2007 was beached with nearly 1700\u00a0tonnes of dangerous cargo in Lyme Bay, a protected World Heritage Site coastline. The ship had been damaged and was en route to Portland Harbour.\nThe English Channel, despite being a busy shipping lane, remains in part a haven for wildlife. Atlantic oceanic species are more common in the westernmost parts of the channel, particularly to the west of Start Point, Devon, but can sometimes be found further east towards Dorset and the Isle of Wight. Seal sightings are becoming more common along the English Channel, with both grey seal and harbour seal recorded frequently.\nHuman history.\nThe Channel is thought to have prevented Neanderthals from colonising Britain during the Last Interglacial/Eemian, though they returned to Britain during the Last Glacial Period when sea levels were lower. The Channel has in historic times been both an easy entry for seafaring people and a key natural defence, halting invading armies while in conjunction with control of the North Sea allowing Britain to blockade the continent. The most significant failed invasion threats came when the Dutch and Belgian ports were held by a major continental power, e.g. from the Spanish Armada in 1588, Napoleon during the Napoleonic Wars, and Nazi Germany during World War II. Successful invasions include the Roman conquest of Britain, the Norman Conquest in 1066 and the Glorious Revolution of 1688, while the concentration of excellent harbours in the Western Channel on Britain's south coast made possible the largest amphibious invasion in history, the Normandy Landings in 1944. Channel naval battles include the Battle of the Downs (1639), Battle of Dover (1652), the Battle of Portland (1653) and the Battle of La Hougue (1692).\nIn more peaceful times, the Channel served as a link joining shared cultures and political structures, particularly the huge Angevin Empire from 1135 to 1217. For nearly a thousand years, the Channel also provided a link between the Modern Celtic regions and languages of Cornwall and Brittany. Brittany was founded by Britons who fled Cornwall and Devon after Anglo-Saxon encroachment. In Brittany, there is a region known as \"Cornouaille\" (Cornwall) in French and \"Kernev\" in Breton. In ancient times there was also a \"Domnonia\" (Devon) in Brittany as well.\nIn February 1684, ice formed on the sea in a belt wide off the coast of Kent and wide on the French side.\nRoute to Britain.\nRemnants of a mesolithic boatyard have been found on the Isle of Wight. Wheat was traded across the Channel about 8,000 years ago. \"... Sophisticated social networks linked the Neolithic front in southern Europe to the Mesolithic peoples of northern Europe.\" The Ferriby Boats, Hanson Log Boats and the later Dover Bronze Age Boat could carry a substantial cross-Channel cargo.\nDiodorus Siculus and Pliny both suggest trade between the rebel Celtic tribes of Armorica and Iron Age Britain flourished. In 55 BC Julius Caesar invaded, claiming that the Britons had aided the Veneti against him the previous year. He was more successful in 54 BC, but Britain was not fully established as part of the Roman Empire until Aulus Plautius's 43 AD invasion. A brisk and regular trade began between ports in Roman Gaul and those in Britain. This traffic continued until the end of Roman rule in Britain in 410 AD, after which the early Anglo-Saxons left less clear historical records.\nIn the power vacuum left by the retreating Romans, the Germanic Angles, Saxons, and Jutes began the next great migration across the North Sea. Having already been used as mercenaries in Britain by the Romans, many people from these tribes crossed during the Migration Period, conquering and perhaps displacing the native Celtic populations.\nNorsemen and Normans.\nThe attack on Lindisfarne in 793 is generally considered the beginning of the Viking Age. For the next 250\u00a0years the Scandinavian raiders of Norway, Sweden, and Denmark dominated the North Sea, raiding monasteries, homes, and towns along the coast and along the rivers that ran inland. According to the \"Anglo-Saxon Chronicle\" they began to settle in Britain in 851. They continued to settle in the British Isles and the continent until around 1050, with some raids recorded along the channel coast of England, including at Wareham, Portland, near Weymouth and along the river Teign in Devon.\nThe fiefdom of Normandy was created for the Viking leader Rollo (also known as Robert of Normandy). Rollo had besieged Paris but in 911 entered vassalage to the king of the West Franks Charles the Simple through the Treaty of St.-Claire-sur-Epte. In exchange for his homage and fealty, Rollo legally gained the territory he and his Viking allies had previously conquered. The name \"Normandy\" reflects Rollo's Viking (i.e. \"Northman\") origins.\nThe descendants of Rollo and his followers adopted the local Gallo-Romance language and intermarried with the area's inhabitants and became the Normans \u2013 a Norman French-speaking mixture of Scandinavians, Hiberno-Norse, Orcadians, Anglo-Danish, and indigenous Franks and Gauls.\nRollo's descendant William, Duke of Normandy became king of England in 1066 in the Norman Conquest beginning with the Battle of Hastings, while retaining the fiefdom of Normandy for himself and his descendants. In 1204, during the reign of King John, mainland Normandy was taken from England by France under Philip II, while insular Normandy (the Channel Islands) remained under English control. In 1259, Henry III of England recognised the legality of French possession of mainland Normandy under the Treaty of Paris. His successors, however, often fought to regain control of mainland Normandy.\nWith the rise of William the Conqueror, the North Sea and Channel began to lose some of their importance. The new order oriented most of England and Scandinavia's trade south, toward the Mediterranean and the Orient.\nAlthough the British surrendered claims to mainland Normandy and other French possessions in 1801, the monarch of the United Kingdom retains the title Duke of Normandy in respect to the Channel Islands. The Channel Islands (except for Chausey) are Crown Dependencies of the British Crown. Thus the Loyal toast in the Channel Islands is \"Le roi, notre Duc\" (\"The King, our Duke\"). The British monarch is understood to \"not\" be the Duke of Normandy in regards of the French region of Normandy described herein, by virtue of the Treaty of Paris of 1259, the surrender of French possessions in 1801, and the belief that the rights of succession to that title are subject to Salic Law which excludes inheritance through female heirs.\nFrench Normandy was occupied by English forces during the Hundred Years' War in 1346\u20131360 and again in 1415\u20131450.\nEngland and Britain: Naval superpower.\nFrom the reign of Elizabeth I, English foreign policy concentrated on preventing invasion across the Channel by ensuring no major European power controlled the potential Dutch and Flemish invasion ports. Her climb to the pre-eminent sea power of the world began in 1588 as the attempted invasion of the Spanish Armada was defeated by the combination of outstanding naval tactics by the English and the Dutch under command of Charles Howard, 1st Earl of Nottingham with Sir Francis Drake second in command, and the following stormy weather. Over the centuries the Royal Navy slowly grew to be the most powerful in the world.\nThe building of the British Empire was possible only because the Royal Navy eventually managed to exercise unquestioned control over the seas around Europe, especially the Channel and the North Sea. During the Seven Years' War, France attempted to launch an invasion of Britain. To achieve this France needed to gain control of the Channel for several weeks, but was thwarted following the British naval victory at the Battle of Quiberon Bay in 1759 and was unsuccessful (The last French landing on English soil being in 1690 with a raid on Teignmouth, although the last French raid on British soil was a raid on Fishguard, Wales in 1797).\nAnother significant challenge to British domination of the seas came during the Napoleonic Wars. The Battle of Trafalgar took place off the coast of Spain against a combined French and Spanish fleet and was won by Admiral Horatio Nelson, ending Napoleon's plans for a cross-Channel invasion and securing British dominance of the seas for over a century.\nFirst World War.\nThe exceptional strategic importance of the Channel as a tool for blockading was recognised by the First Sea Lord Admiral Fisher in the years before World War I. \"Five keys lock up the world! Singapore, the Cape, Alexandria, Gibraltar, Dover.\" However, on 25 July 1909 Louis Bl\u00e9riot made the first Channel crossing from Calais to Dover in an aeroplane. Bl\u00e9riot's crossing signalled a change in the function of the Channel as a barrier-moat for England against foreign enemies.\nBecause the \"Kaiserliche Marine\" surface fleet could not match the British Grand Fleet, the Germans developed submarine warfare, which was to become a far greater threat to Britain. The Dover Patrol, set up just before the war started, escorted cross-Channel troopships and prevented submarines from sailing in the Channel, obliging them to travel to the Atlantic via the much longer route around Scotland.\nOn land, the German army attempted to capture French Channel ports in the Race to the Sea but although the trenches are often said to have stretched \"from the frontier of Switzerland to the English Channel\", they reached the coast at the North Sea. Much of the British war effort in Flanders was a bloody but successful strategy to prevent the Germans reaching the Channel coast.\nAt the outset of the war, an attempt was made to block the path of U-boats through the Dover Strait with naval minefields. By February 1915, this had been augmented by a stretch of light steel netting called the Dover Barrage, which it was hoped would ensnare submerged submarines. After initial success, the Germans learned how to pass through the barrage, aided by the unreliability of British mines. On 31 January 1917, the Germans resumed unrestricted submarine warfare leading to dire Admiralty predictions that submarines would defeat Britain by November, the most dangerous situation Britain faced in either world war.\nThe Battle of Passchendaele in 1917 was fought to reduce the threat by capturing the submarine bases on the Belgian coast, though it was the introduction of convoys and not capture of the bases that averted defeat. In April 1918 the Dover Patrol carried out the Zeebrugge Raid against the U-boat bases. During 1917, the Dover Barrage was re-sited with improved mines and more effective nets, aided by regular patrols by small warships equipped with powerful searchlights. A German attack on these vessels resulted in the Battle of Dover Strait in 1917. A much more ambitious attempt to improve the barrage, by installing eight massive concrete towers across the strait was called the Admiralty M-N Scheme but only two towers were nearing completion at the end of the war and the project was abandoned.\nThe naval blockade in the Channel and North Sea was one of the decisive factors in the German defeat in 1918.\nSecond World War.\nDuring the Second World War, naval activity in the European theatre was primarily limited to the Atlantic. During the Battle of France in May 1940, the German forces succeeded in capturing both Boulogne and Calais, thereby threatening the line of retreat for the British Expeditionary Force. By a combination of hard fighting and German indecision, the port of Dunkirk was kept open allowing 338,000 Allied troops to be evacuated in Operation Dynamo. More than 11,000 were evacuated from Le Havre during Operation Cycle and a further 192,000 were evacuated from ports further down the coast in Operation Aerial in June 1940. The early stages of the Battle of Britain featured German air attacks on Channel shipping and ports; despite these early successes against shipping the Germans did not win the air supremacy necessary for Operation Sealion, the projected cross-Channel invasion.\nThe Channel subsequently became the stage for an intensive coastal war, featuring submarines, minesweepers, and Fast Attack Craft.\nThe narrow waters of the Channel were considered too dangerous for major warships until the Normandy Landings with the exception, for the German Kriegsmarine, of the Channel Dash (Operation Cerberus) in February 1942, and this required the support of the Luftwaffe in Operation Thunderbolt.\nDieppe was the site of an ill-fated Dieppe Raid by Canadian and British armed forces. More successful was the later Operation Overlord (D-Day), a massive invasion of German-occupied France by Allied troops. Caen, Cherbourg, Carentan, Falaise and other Norman towns endured many casualties in the fight for the province, which continued until the closing of the so-called Falaise gap between Chambois and Montormel, then liberation of Le Havre.\nThe Channel Islands were the only part of the British Commonwealth occupied by Germany (excepting the part of Egypt occupied by the Afrika Korps at the time of the Second Battle of El Alamein, which was a protectorate and not part of the Commonwealth). The German occupation of 1940\u20131945 was harsh, with some island residents being taken for slave labour on the Continent; native Jews sent to concentration camps; partisan resistance and retribution; accusations of collaboration; and slave labour (primarily Russians and eastern Europeans) being brought to the islands to build fortifications. The Royal Navy blockaded the islands from time to time, particularly following the liberation of mainland Normandy in 1944. Intense negotiations resulted in some Red Cross humanitarian aid, but there was considerable hunger and privation during the occupation, particularly in the final months, when the population was close to starvation. The German troops on the islands surrendered on 9 May 1945, a day after the final surrender in mainland Europe.\nEnglish Channel migrant crossings (2018\u2013present).\nThere is significant public concern in the UK about illegal immigrants coming on small boats from France. Since 2018, the English Channel has seen a major increase in number of crossing.\nPopulation.\nThe English Channel coast is far more densely populated on the English shore. The most significant towns and cities along both the English and French sides of the Channel (each with more than 20,000 inhabitants, ranked in descending order; populations are the urban area populations from the 1999 French census, 2001 UK census, and 2001 Jersey census) are as follows:\nCulture and languages.\nThe two dominant cultures are English on the north shore of the Channel, French on the south. However, there are also a number of minority languages that are or were found on the shores and islands of the English Channel, which are listed here, with the Channel's name in the specific language following them.\nMost other languages tend towards variants of the French and English forms, but notably Welsh has .\nEconomy.\nShipping.\nThe Channel has traffic on both the UK\u2013Europe and North Sea\u2013Atlantic routes, and is the world's busiest seaway, with over 500 ships per day. Following an accident in January 1971 and a series of disastrous collisions with wreckage in February, the Dover TSS, the world's first radar-controlled traffic separation scheme, was set up by the International Maritime Organization. The scheme mandates that vessels travelling north must use the French side, travelling south the English side. There is a separation zone between the two lanes.\nIn December 2002 the MV \"Tricolor\", carrying \u00a330m of luxury cars, sank northwest of Dunkirk after collision in fog with the container ship \"Kariba\". The cargo ship \"Nicola\" ran into the wreckage the next day. There was no loss of life.\nThe shore-based long-range traffic control system was updated in 2003 and there is a series of traffic separation systems in operation. Though the system is inherently incapable of reaching the levels of safety obtained from aviation systems such as the traffic collision avoidance system, it has reduced accidents to one or two per year.\nMarine GPS systems allow ships to be preprogrammed to follow navigational channels accurately and automatically, further avoiding risk of running aground, but following the fatal collision between Dutch Aquamarine and Ash in October 2001, Britain's Marine Accident Investigation Branch (MAIB) issued a safety bulletin saying it believed that in these most unusual circumstances GPS use had actually contributed to the collision. The ships were maintaining a very precise automated course, one directly behind the other, rather than making use of the full width of the traffic lanes as a human navigator would.\nA combination of radar difficulties in monitoring areas near cliffs, a failure of a CCTV system, incorrect operation of the anchor, the inability of the crew to follow standard procedures of using a GPS to provide early warning of the ship dragging the anchor and reluctance to admit the mistake and start the engine led to the MV \"Willy\" running aground in Cawsand Bay, Cornwall, in January 2002. The MAIB report makes it clear that the harbour controllers were informed of impending disaster by shore observers before the crew were themselves aware. The village of Kingsand was evacuated for three days because of the risk of explosion, and the ship was stranded for 11 days.\nFerry.\nThe ferry routes crossing the English Channel, include (have included):-\nChannel Tunnel.\nMany travellers cross beneath the Channel using the Channel Tunnel, first proposed in the early 19th century and finally opened in 1994, connecting the UK and France by rail. It is now routine to travel between Paris or Brussels and London on the Eurostar train. Freight trains also use the tunnel. Cars, coaches and lorries are carried on Eurotunnel Shuttle trains between Folkestone and Calais.\nTourism.\nThe coastal resorts of the Channel, such as Brighton and Deauville, inaugurated an era of aristocratic tourism in the early 19th century. Short trips across the Channel for leisure purposes are often referred to as Channel Hopping.\nRenewable energy.\nThe Rampion Wind Farm is an offshore wind farm located in the Channel, off the coast of West Sussex. Other offshore wind farms planned on the French side of the Channel.\nHistory of Channel crossings.\nAs one of the narrowest and most well-known international waterways lacking dangerous currents, the Channel has been the first objective of numerous innovative sea, air, and human powered crossing technologies.\nPre-historic people sailed from the mainland to England for millennia. At the end of the last Ice Age, lower sea levels even permitted walking across.\nBy boat.\nPierre Andriel crossed the English Channel aboard the \"\u00c9lise\", ex the Scottish p.s. \"Margery\" in March 1816, one of the earliest seagoing voyages by steam ship.\nThe paddle steamer \"Defiance\", Captain William Wager, was the first steamer to cross the Channel to Holland, arriving there on 9 May 1816.\nOn 10 June 1821, English-built paddle steamer \"Rob Roy\" was the first passenger ferry to cross channel. The steamer was purchased subsequently by the French postal administration and renamed \"Henri IV\" and put into regular passenger service a year later. It was able to make the journey across the Straits of Dover in around three hours.\nIn June 1843, because of difficulties with Dover harbour, the South Eastern Railway company developed the Boulogne-sur-Mer-Folkestone route as an alternative to Calais-Dover. The first ferry crossed under the command of Captain Hayward.\nIn 1974 a Welsh coracle piloted by Bernard Thomas of Llechryd crossed the English Channel to France in 13 hours. The journey was undertaken to demonstrate how the Bull Boats of the Mandan Indians of North Dakota could have been copied from coracles introduced by Prince Madog in the 12th century.\nThe Mountbatten class hovercraft (MCH) entered commercial service in August 1968, initially between Dover and Boulogne but later also Ramsgate (Pegwell Bay) to Calais. The journey time Dover to Boulogne was roughly 35\u00a0minutes, with six trips per day at peak times. The fastest crossing of the English Channel by a commercial car-carrying hovercraft was 22\u00a0minutes, recorded by the \"Princess Anne\" MCH SR-N4 Mk3 on 14 September 1995,\nBy air.\nThe first aircraft to cross the Channel was a balloon in 1785, piloted by Jean Pierre Fran\u00e7ois Blanchard (France) and John Jeffries (US).\nLouis Bl\u00e9riot (France) piloted the first aeroplane to cross in 1909.\nOn 26 September 2008, Swiss Yves Rossy aka \"Jetman\" became the first person to cross the English Channel with a Jet Powered Wing,\nHe jumped from a Pilatus Porter over Calais, France, Rossy crossed the English Channel where he deployed his parachute and landed in Dover\nThe first flying car to have crossed the English Channel is a P\u00e9gase designed by the French company Vaylon on 14 June 2017. It was piloted by a Franco-Italian pilot Bruno Vezzoli. This crossing was carried out as part of the first road and air trip from Paris to London in a flying car. Pegase is a 2 seats road approved dune buggy and a powered paraglider. The takeoff was at 8:03\u00a0a.m. from Ambleteuse in the North of France and landing was at East Studdal, near Dover. The flight was completed in 1 hour and 15 minutes for a total distance covered of including over the English Channel at an altitude of .\nOn 12 June 1979, the first human-powered aircraft to cross the English Channel was the \"Gossamer Albatross\", built by American aeronautical engineer Dr. Paul B. MacCready's company AeroVironment, and piloted by Bryan Allen. The crossing was completed in 2 hours and 49 minutes.\nOn 4 August 2019, Frenchman Franky Zapata became the first person to cross the English Channel on a jet-powered Flyboard Air. The board was powered by a kerosene-filled backpack. Zapata made the journey in 22 minutes, having landed on a boat half-way across to refuel.\nBy swimming.\nThe sport of Channel swimming traces its origins to the latter part of the 19th century when Captain Matthew Webb made the first observed and unassisted swim across the Strait of Dover, swimming from England to France on 24\u201325 August 1875 in 21\u00a0hours 45\u00a0minutes.\nUp to 1927, fewer than ten swimmers (including the first woman, Gertrude Ederle in 1926) had managed to successfully swim the English Channel, and many dubious claims had been made. The Channel Swimming Association (CSA) was founded to authenticate and ratify swimmers' claims to have swum the Channel and to verify crossing times. The CSA was dissolved in 1999 and was succeeded by two separate organisations: CSA Ltd (CSA) and the Channel Swimming and Piloting Federation (CSPF), both observe and authenticate cross-Channel swims in the Strait of Dover. The Channel Crossing Association was also set up to cater for unorthodox crossings.\nThe team with the most Channel swims to its credit is the Serpentine Swimming Club in London, followed by the international Sri Chinmoy Marathon Team.\nAs of 2023, 1,881 people had completed 2,428 verified solo crossings under the rules of the CSA and the CSPF. This includes 24 two-way crossings and three three-way crossings.\nThe Strait of Dover is the busiest stretch of water in the world. It is governed by International Law as described in \"Unorthodox Crossing of the Dover Strait Traffic Separation Scheme\". It states: \"[In] exceptional cases the French Maritime Authorities may grant authority for unorthodox craft to cross French territorial waters within the Traffic Separation Scheme when these craft set off from the British coast, on condition that the request for authorisation is sent to them with the opinion of the British Maritime Authorities.\"\nThe fastest verified swim of the Channel was by the Australian Trent Grimsey on 8 September 2012, in 6 hours 55 minutes, beating a swim of 2007. The female record is held by Yvetta Hlavacova of Czechia, on 7 hours, 25 minutes on 5 August 2006. Both records were from England to France.\nThere may have been some unreported swims of the Channel, by people intent on entering Britain in circumvention of immigration controls. A failed attempt to cross the Channel by two Syrian refugees in October 2014 came to light when their bodies were discovered on the shores of the North Sea in Norway and the Netherlands.\nBy car.\nOn 16 September 1965, two Amphicars crossed from Dover to Calais.\nOther types.\nPLUTO was war-time fuel delivery project of \"pipelines under the ocean\" from England to France. Though plagued with technical difficulties during the Battle of Normandy, the pipelines delivered about 8% of the fuel requirements of the allied forces between D-Day and VE-Day."}
{"id": "9232", "revid": "3236687", "url": "https://en.wikipedia.org/wiki?curid=9232", "title": "Eiffel Tower", "text": "The Eiffel Tower ( ; ) is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower from 1887 to 1889.\nLocally nicknamed \"La dame de fer\" (French for \"Iron Lady\"), it was constructed as the centerpiece of the 1889 World's Fair, and to crown the centennial anniversary of the French Revolution. Although initially criticised by some of France's leading artists and intellectuals for its design, it has since become a global cultural icon of France and one of the most recognisable structures in the world. The tower received 5,889,000 visitors in 2022. The Eiffel Tower is the most visited monument with an entrance fee in the world: 6.91\u00a0million people ascended it in 2015. It was designated a in 1964, and was named part of a UNESCO World Heritage Site (\"Paris, Banks of the Seine\") in 1991.\nThe tower is tall, about the same height as an 81- building, and the tallest structure in Paris. Its base is square, measuring on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest human-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure in the world to surpass both the 200-metre and 300-metre mark in height. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by . Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\nThe tower has three levels for visitors, with restaurants on the first and second levels. The top level's upper platform is above the ground\u2014the highest observation deck accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second, making the entire ascent a 600-step climb. Although there is a staircase to the top level, it is usually accessible only by lift. On this top, third level is a private apartment built for Gustave Eiffel's personal use. He decorated it with furniture by Jean Lachaise and invited friends such as Thomas Edison.\nHistory.\nOrigin.\nThe design of the Eiffel Tower is attributed to Maurice Koechlin and \u00c9mile Nouguier, two senior engineers working for the Compagnie des \u00c9tablissements Eiffel. It was envisioned after discussion about a suitable centerpiece for the proposed 1889 Exposition Universelle, a world's fair to celebrate the centennial of the French Revolution. In May 1884, working at home, Koechlin made a sketch of their idea, described by him as \"a great pylon, consisting of four lattice girders standing apart at the base and coming together at the top, joined together by metal trusses at regular intervals\". Eiffel initially showed little enthusiasm, but he did approve further study, and the two engineers then asked Stephen Sauvestre, the head of the company's architectural department, to contribute to the design. Sauvestre added decorative arches to the base of the tower, a glass pavilion to the first level, and other embellishments.\nThe new version gained Eiffel's support: he bought the rights to the patent on the design which Koechlin, Nouguier, and Sauvestre had taken out, and the design was put on display at the Exhibition of Decorative Arts in the autumn of 1884 under the company name. On 30 March 1885, Eiffel presented his plans to the ; after discussing the technical problems and emphasising the practical uses of the tower, he finished his talk by saying the tower would symbolise \nLittle progress was made until 1886, when Jules Gr\u00e9vy was re-elected as president of France and \u00c9douard Lockroy was appointed as minister for trade. A budget for the exposition was passed and, on 1 May, Lockroy announced an alteration to the terms of the open competition being held for a centrepiece to the exposition, which effectively made the selection of Eiffel's design a foregone conclusion, as entries had to include a study for a four-sided metal tower on the Champ de Mars. (A 300-metre tower was then considered a herculean engineering effort.) On 12 May, a commission was set up to examine Eiffel's scheme and its rivals, which, a month later, decided that all the proposals except Eiffel's were either impractical or lacking in details.\nAfter some debate about the exact location of the tower, a contract was signed on 8 January 1887. Eiffel signed it acting in his own capacity rather than as the representative of his company, the contract granting him 1.5 million francs toward the construction costs: less than a quarter of the estimated 6.5 million francs. Eiffel was to receive all income from the commercial exploitation of the tower during the exhibition and for the next 20 years. He later established a separate company to manage the tower, putting up half the necessary capital himself.\nA French bank, the \"Cr\u00e9dit Industriel et Commercial\" (CIC), helped finance the construction of the Eiffel Tower. During the period of the tower's construction, the CIC was acquiring funds from predatory loans to the National Bank of Haiti, some of which went towards the financing of the tower. These loans were connected to an indemnity controversy that saw France force Haiti's government to financially compensate French slaveowners for lost income as a result of the Haitian Revolution, and required Haiti to pay the CIC and its partner nearly half of all taxes collected on exports, \"effectively choking off the nation's primary source of income\". According to \"The New York Times\", \"[at] a time when the [CIC] was helping finance one of the world's best-known landmarks, the Eiffel Tower, as a monument to French liberty, it was choking Haiti's economy, taking much of the young nation's income back to Paris and impairing its ability to start schools, hospitals and the other building blocks of an independent country.\"\nArtists' protest.\nThe proposed tower had been a subject of controversy, drawing criticism from those who did not believe it was feasible and those who objected on artistic grounds. Prior to the Eiffel Tower's construction, no structure had ever been constructed to a height of 300 m, or even 200 m for that matter, and many people believed it was impossible. These objections were an expression of a long-standing debate in France about the relationship between architecture and engineering. It came to a head as work began at the Champ de Mars: a \"Committee of Three Hundred\" (one member for each metre of the tower's height) was formed, led by the prominent architect Charles Garnier and including some of the most important figures of the arts, such as William-Adolphe Bouguereau, Guy de Maupassant, Charles Gounod and Jules Massenet. A petition called \"Artists against the Eiffel Tower\" was sent to the Minister of Works and Commissioner for the Exposition, Adolphe Alphand, and it was published by \"Le Temps\" on 14 February 1887:\nGustave Eiffel responded to these criticisms by comparing his tower to the Egyptian pyramids: \"My tower will be the tallest edifice ever erected by man. Will it not also be grandiose in its way? And why would something admirable in Egypt become hideous and ridiculous in Paris?\" These criticisms were also dealt with by \u00c9douard Lockroy in a letter of support written to Alphand, sardonically saying, \"Judging by the stately swell of the rhythms, the beauty of the metaphors, the elegance of its delicate and precise style, one can tell this protest is the result of collaboration of the most famous writers and poets of our time\", and he explained that the protest was irrelevant since the project had been decided upon months before, and construction on the tower was already under way.\nGarnier was a member of the Tower Commission that had examined the various proposals, and had raised no objection. Eiffel pointed out to a journalist that it was premature to judge the effect of the tower solely on the basis of the drawings, that the Champ de Mars was distant enough from the monuments mentioned in the protest for there to be little risk of the tower overwhelming them, and putting the aesthetic argument for the tower: \"Do not the laws of natural forces always conform to the secret laws of harmony?\"\nSome of the protesters changed their minds when the tower was built; others remained unconvinced. Guy de Maupassant supposedly ate lunch in the tower's restaurant every day because it was the one place in Paris where the tower was not visible.\nBy 1918, it had become a symbol of Paris and of France after Guillaume Apollinaire wrote a nationalist poem in the shape of the tower (a calligram) to express his feelings about the war against Germany. Today, it is widely considered to be a remarkable piece of structural art, and is often featured in films and literature.\nConstruction.\nWork on the foundations started on 28 January 1887. Those for the east and south legs were straightforward, with each leg resting on four concrete slabs, one for each of the principal girders of each leg. The west and north legs, being closer to the river Seine, were more complicated: each slab needed two piles installed by using compressed-air caissons long and in diameter driven to a depth of to support the concrete slabs, which were thick. Each of these slabs supported a block of limestone with an inclined top to bear a supporting shoe for the ironwork.\nEach shoe was anchored to the stonework by a pair of bolts in diameter and long. The foundations were completed on 30 June, and the erection of the ironwork began. The visible work on-site was complemented by the enormous amount of exacting preparatory work that took place behind the scenes: the drawing office produced 1,700 general drawings and 3,629 detailed drawings of the 18,038 different parts needed. The task of drawing the components was complicated by the complex angles involved in the design and the degree of precision required: the position of rivet holes was specified to within and angles worked out to one second of arc. The finished components, some already riveted together into sub-assemblies, arrived on horse-drawn carts from a factory in the nearby Parisian suburb of Levallois-Perret and were first bolted together, with the bolts being replaced with rivets as construction progressed. No drilling or shaping was done on site: if any part did not fit, it was sent back to the factory for alteration. In all, 18,038 pieces were joined using 2.5\u00a0million rivets.\nAt first, the legs were constructed as cantilevers, but about halfway to the first level construction was paused to create a substantial timber scaffold. This renewed concerns about the structural integrity of the tower, and sensational headlines such as \"Eiffel Suicide!\" and \"Gustave Eiffel Has Gone Mad: He Has Been Confined in an Asylum\" appeared in the tabloid press. Multiple famous artists of that time, Charles Garnier and Alexander Dumas, thought poorly of the newly made tower. Charles Garnier thought it was a \"truly tragic street lamp\". Alexander Dumas said that it was like \"Odius shadow of the odious column built of rivets and iron plates extending like a black blot\". There were multiple protests over the style and the reasoning of placing it in the middle of Paris. At this stage, a small \"creeper\" crane designed to move up the tower was installed in each leg. They made use of the guides for the lifts which were to be fitted in the four legs. The critical stage of joining the legs at the first level was completed by the end of March 1888. Although the metalwork had been prepared with the utmost attention to detail, provision had been made to carry out small adjustments to precisely align the legs; hydraulic jacks were fitted to the shoes at the base of each leg, capable of exerting a force of 800 tonnes, and the legs were intentionally constructed at a slightly steeper angle than necessary, being supported by sandboxes on the scaffold. Although construction involved 300 on-site employees, due to Eiffel's safety precautions and the use of movable gangways, guardrails and screens, only one person died.\nInauguration and the 1889 exposition.\nThe main structural work was completed at the end of March 1889 and, on 31 March, Eiffel celebrated by leading a group of government officials, accompanied by representatives of the press, to the top of the tower. Because the lifts were not yet in operation, the ascent was made by foot, and took over an hour, with Eiffel stopping frequently to explain various features. Most of the party chose to stop at the lower levels, but a few, including the structural engineer, \u00c9mile Nouguier, the head of construction, Jean Compagnon, the President of the City Council, and reporters from \"Le Figaro\" and \"Le Monde Illustr\u00e9\", completed the ascent. At 2:35\u00a0pm, Eiffel hoisted a large Tricolour to the accompaniment of a 25-gun salute fired at the first level.\nThere was still work to be done, particularly on the lifts and facilities, and the tower was not opened to the public until nine days after the opening of the exposition on 6 May; even then, the lifts had not been completed. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May. Tickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays, and by the end of the exhibition there had been 1,896,987 visitors.\nAfter dark, the tower was lit by hundreds of gas lamps, and a beacon sent out three beams of red, white and blue light. Two searchlights mounted on a circular rail were used to illuminate various buildings of the exposition. The daily opening and closing of the exposition were announced by a cannon at the top.\nOn the second level, the French newspaper \"Le Figaro\" had an office and a printing press, where a special souvenir edition, \"Le Figaro de la Tour\", was made.\nAt the top, there was a post office where visitors could send letters and postcards as a memento of their visit. Graffitists were also catered for: sheets of paper were mounted on the walls each day for visitors to record their impressions of the tower. Gustave Eiffel described the collection of responses as \"truly curious\".\nFamous visitors to the tower included the Prince of Wales, Sarah Bernhardt, \"Buffalo Bill\" Cody (his Wild West show was an attraction at the exposition) and Thomas Edison. Eiffel invited Edison to his private apartment at the top of the tower, where Edison presented him with one of his phonographs, a new invention and one of the many highlights of the exposition. Edison signed the guestbook with this message on September 10, 1889: \nEiffel made use of his apartment at the top of the tower to carry out meteorological observations, and also used the tower to perform experiments on the action of air resistance on falling bodies.\nSubsequent events.\nEiffel had a permit for the tower to stand for 20 years. It was to be dismantled in 1909, when its ownership would revert to the City of Paris. The city had planned to tear it down (part of the original contest rules for designing a tower was that it should be easy to dismantle) but as the tower proved to be valuable for many innovations in the early 20th century, particularly radio telegraphy, it was allowed to remain after the expiry of the permit, and from 1910 it also became part of the International Time Service.\nFor the 1900 \"Exposition Universelle\", the lifts in the east and west legs were replaced by lifts running as far as the second level constructed by the French firm Fives-Lille. These had a compensating mechanism to keep the floor level as the angle of ascent changed at the first level, and were driven by a similar hydraulic mechanism as the Otis lifts, although this was situated at the base of the tower. Hydraulic pressure was provided by pressurised accumulators located near this mechanism. At the same time the lift in the north pillar was removed and replaced by a staircase to the first level. The layout of both first and second levels was modified, with the space available for visitors on the second level. The original lift in the south pillar was removed 13 years later.\nOn 19 October 1901, Alberto Santos-Dumont, flying his No.6 airship, won a 100,000-franc prize offered by Henri Deutsch de la Meurthe for the first person to make a flight from St. Cloud to the Eiffel Tower and back in less than half an hour.\nIn 1910, Father Theodor Wulf measured radiant energy at the top and bottom of the tower. He found more at the top than expected, incidentally discovering what are known today as cosmic rays. Two years later, on 4 February 1912, Austrian tailor Franz Reichelt died after jumping from the first level of the tower (a height of 57 m) to demonstrate his parachute design. In 1914, at the outbreak of World War\u00a0I, a radio transmitter located in the tower jammed German radio communications, seriously hindering their advance on Paris and contributing to the Allied victory at the First Battle of the Marne. \nDuring World War I, the Eiffel Tower's wireless station played a crucial role in intercepting enemy communications from Berlin. In 1914, French forces successfully launched a counter-attack during the Battle of the Marne after gaining critical intelligence on the German Army's movements. In 1917, the station intercepted a coded message between Germany and Spain that referenced 'Operative H-21.' This information contributed to the arrest, conviction, and execution of Mata Hari, the famous spy accused of working for Germany.\nFrom 1925 to 1934, illuminated signs for Citro\u00ebn adorned three of the tower's sides, making it the tallest advertising space in the world at the time. In April 1935, the tower was used to make experimental low-resolution television transmissions, using a shortwave transmitter of 200 watts power. On 17 November, an improved 180-line transmitter was installed.\nOn two separate but related occasions in 1925, the con artist Victor Lustig \"sold\" the tower for scrap metal. A year later, in February 1926, pilot Leon Collet was killed trying to fly under the tower. His aircraft became entangled in an aerial belonging to a wireless station. A bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg on 2 May 1929. In 1930, the tower lost the title of the world's tallest structure when the Chrysler Building in New York City was completed. In 1938, the decorative arcade around the first level was removed.\nUpon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was restricted to German visitors during the occupation and the lifts were not repaired until 1946. In 1940, German soldiers had to climb the tower to hoist a swastika-centered Reichskriegsflagge, but the flag was so large it blew away just a few hours later, and was replaced by a smaller one. When visiting Paris, Hitler chose to stay on the ground. When the Allies were nearing Paris in August 1944, Hitler ordered General Dietrich von Choltitz, the military governor of Paris, to demolish the tower along with the rest of the city. Von Choltitz disobeyed the order. On 25 August, before the Germans had been driven out of Paris, the German flag was replaced with a Tricolour by two men from the French Naval Museum, who narrowly beat three men led by Lucien Sarniguet, who had lowered the Tricolour on 13 June 1940 when Paris fell to the Germans.\nA fire started in the television transmitter on 3 January 1956, damaging the top of the tower. Repairs took a year, and in 1957, the present radio aerial was added to the top. In 1964, the Eiffel Tower was officially declared to be a historical monument by the Minister of Cultural Affairs, Andr\u00e9 Malraux. A year later, an additional lift system was installed in the north pillar.\nAccording to interviews, in 1967, Montreal Mayor Jean Drapeau negotiated a secret agreement with Charles de Gaulle for the tower to be dismantled and temporarily relocated to Montreal to serve as a landmark and tourist attraction during Expo 67. The plan was allegedly vetoed by the company operating the tower out of fear that the French government could refuse permission for the tower to be restored in its original location.\nIn 1982, the original lifts between the second and third levels were replaced after 97 years in service. These had been closed to the public between November and March because the water in the hydraulic drive tended to freeze. The new cars operate in pairs, with one counterbalancing the other, and perform the journey in one stage, reducing the journey time from eight minutes to less than two minutes. At the same time, two new emergency staircases were installed, replacing the original spiral staircases. In 1983, the south pillar was fitted with an electrically driven Otis lift to serve the Jules Verne restaurant. The Fives-Lille lifts in the east and west legs, fitted in 1899, were extensively refurbished in 1986. The cars were replaced, and a computer system was installed to completely automate the lifts. The motive power was moved from the water hydraulic system to a new electrically driven oil-filled hydraulic system, and the original water hydraulics were retained solely as a counterbalance system. A service lift was added to the south pillar for moving small loads and maintenance personnel three years later.\nRobert Moriarty flew a Beechcraft Bonanza under the tower on 31 March 1984. In 1987, A. J. Hackett made one of his first bungee jumps from the top of the Eiffel Tower, using a special cord he had helped develop. Hackett was arrested by the police. On 27 October 1991, Thierry Devaux, along with mountain guide Herv\u00e9 Calvayrac, performed a series of acrobatic figures while bungee jumping from the second floor of the tower. Facing the Champ de Mars, Devaux used an electric winch between figures to go back up to the second floor. When firemen arrived, he stopped after the sixth jump.\nFor its \"Countdown to the Year 2000\" celebration on 31 December 1999, flashing lights and high-powered searchlights were installed on the tower. During the last three minutes of the year, the lights were turned on starting from the base of the tower and continuing to the top to welcome 2000 with a huge fireworks show. An exhibition above a cafeteria on the first floor commemorates this event. The searchlights on top of the tower made it a beacon in Paris's night sky, and 20,000 flashing bulbs gave the tower a sparkly appearance for five minutes every hour on the hour.\nThe lights sparkled blue for several nights to herald the new millennium on 31 December 2000. The sparkly lighting continued for 18 months until July 2001. The sparkling lights were turned on again on 21 June 2003, and the display was planned to last for 10 years before they needed replacing.\nThe tower received its th guest on 28 November 2002. The tower has operated at its maximum capacity of about 7\u00a0million visitors per year since 2003. In 2004, the Eiffel Tower began hosting a seasonal ice rink on the first level. A glass floor was installed on the first level during the 2014 refurbishment.\nDesign.\nMaterial.\nThe puddle iron (wrought iron) of the Eiffel Tower weighs 7,300 tonnes, and the addition of lifts, shops and antennae have brought the total weight to approximately 10,100\u00a0tonnes. As a demonstration of the economy of design, if the 7,300\u00a0tonnes of metal in the structure were melted down, it would fill the square base, on each side, to a depth of only assuming the density of the metal to be 7.8\u00a0tonnes per cubic metre. Additionally, a cubic box surrounding the tower (324\u00a0m\u00a0\u00d7\u00a0125\u00a0m\u00a0\u00d7\u00a0125\u00a0m) would contain \u00a0tonnes of air, weighing almost as much as the iron itself. Depending on the ambient temperature, the top of the tower may shift away from the sun by up to due to thermal expansion of the metal on the side facing the sun.\nWind and weather considerations.\nWhen it was built, Eiffel was accused of trying to create something artistic with no regard to the principles of engineering. However, Eiffel and his team were experienced bridge builders. In an interview with the newspaper \"Le Temps\" published on 14 February 1887, Eiffel said:\nHe used graphical methods to determine the strength of the tower and empirical evidence to account for the effects of wind, rather than a mathematical formula. Close examination of the tower reveals a basically exponential shape. All parts of the tower were overdesigned to ensure maximum resistance to wind forces. The top half was assumed to have no gaps in the latticework. After it was completed, some have put forward various mathematical hypotheses in an attempt to explain the success of the design. A one devised in 2004 after letters sent by Eiffel to the French Society of Civil Engineers in 1885 were translated into English described it as a non-linear integral equation based on counteracting the wind pressure on any point of the tower with the tension between the construction elements at that point.\nThe Eiffel Tower sways by up to in the wind.\nFloors.\nGround floor.\nThe four columns of the tower each house access stairs and elevators to the first two floors, while at the south column only the elevator to the second floor restaurant is publicly accessible.\n1st floor.\nThe first floor is publicly accessible by elevator or stairs. When originally built, the first level contained three restaurants\u2014one French, one Russian and one Flemish\u2014and an \"Anglo-American Bar\". After the exposition closed, the Flemish restaurant was converted to a 250-seat theatre. Today there is the restaurant and other facilities.\n2nd floor.\nThe second floor is publicly accessible by elevator or stairs and has a restaurant called , a gourmet restaurant with its own lift going up from the south column to the second level. This restaurant has one star in the Michelin Red Guide. It was run by the multi-Michelin star chef Alain Ducasse from 2007 to 2017. As of May 2019, it is managed by three-star chef Fr\u00e9d\u00e9ric Anton. It owes its name to the famous science-fiction writer Jules Verne.\n3rd floor.\nThe third floor is the top floor, publicly accessible by elevator.\nOriginally there were laboratories for various experiments, and a small apartment reserved for Gustave Eiffel to entertain guests, which is now open to the public, complete with period decorations and lifelike mannequins of Eiffel and some of his notable guests.\nFrom 1937 until 1981, there was a restaurant near the top of the tower. It was removed due to structural considerations; engineers had determined it was too heavy and was causing the tower to sag. This restaurant was sold to an American restaurateur and transported to New York and then New Orleans. It was rebuilt on the edge of New Orleans' Garden District as a restaurant and later event hall. Today there is a champagne bar.\nLifts.\nThe arrangement of the lifts has been changed several times during the tower's history. Given the elasticity of the cables and the time taken to align the cars with the landings, each lift, in normal service, takes an average of 8 minutes and 50 seconds to do the round trip, spending an average of 1 minute and 15 seconds at each level. The average journey time between levels is 1 minute. The original hydraulic mechanism is on public display in a small museum at the base of the east and west legs. Because the mechanism requires frequent lubrication and maintenance, public access is often restricted. The rope mechanism of the north tower can be seen as visitors exit the lift.\nEquipping the tower with adequate and safe passenger lifts was a major concern of the government commission overseeing the Exposition. Although some visitors could be expected to climb to the first level, or even the second, lifts had to be the main means of ascent.\nConstructing lifts to reach the first level was done by making the legs wide enough at the bottom and so nearly straight that they could contain a straight track. A contract was given to the French company Roux, Combaluzier &amp; Lepape for two lifts to be fitted in the east and west legs. Roux, Combaluzier &amp; Lepape used a pair of endless chains with rigid, articulated links to which the car was attached. Lead weights on some links of the upper or return sections of the chains counterbalanced most of the car's weight. The car was pushed up from below, not pulled up from above: to prevent the chain buckling, it was enclosed in a conduit. At the bottom of the run, the chains passed around diameter sprockets. Smaller sprockets at the top guided the chains.\nInstalling lifts to the second level was more of a challenge because a straight track was impossible. No French company wanted to undertake the work. The European branch of Otis Brothers &amp; Company submitted a proposal, but this was rejected: the fair's charter ruled out the use of any foreign material in the construction of the tower. The deadline for bids was extended, but still no French companies put themselves forward, and eventually the contract was given to Otis in July 1887. Otis were confident they would eventually be given the contract and had already started creating designs.\nThe car was divided into two superimposed compartments, each holding 25 passengers, with the lift operator occupying an exterior platform on the first level. Motive power was provided by an inclined hydraulic ram long and in diameter in the tower leg with a stroke of : this moved a carriage carrying six sheaves. Five fixed sheaves were mounted higher up the leg, producing an arrangement similar to a block and tackle but acting in reverse, multiplying the stroke of the piston rather than the force generated. The hydraulic pressure in the driving cylinder was produced by a large open reservoir on the second level. After being exhausted from the cylinder, the water was pumped back up to the reservoir by two pumps in the machinery room at the base of the south leg. This reservoir also provided power to the lifts to the first level.\nThe original lifts for the journey between the second and third levels were supplied by L\u00e9on Edoux. A pair of hydraulic rams were mounted on the second level, reaching nearly halfway up to the third level. One lift car was mounted on top of these rams: cables ran from the top of this car up to sheaves on the third level and back down to a second car. Each car travelled only half the distance between the second and third levels and passengers were required to change lifts halfway by means of a short gangway. The 10-ton cars each held 65 passengers.\nEngraved names.\nGustave Eiffel engraved on the building of the tower the names of 72 French scientists, engineers and mathematicians as a recognition of their contributions. Eiffel chose this \"invocation of science\" because of his concern over the artists' protest. At the beginning of the 20th century, the engravings were painted over, but they were restored in 1986\u201387 by the , a company operating the tower.\nAesthetics.\nThe tower is painted in three shades: lighter at the top, getting progressively darker towards the bottom to complement the Parisian sky. It was originally reddish brown; this changed in 1968 to a bronze colour known as \"Eiffel Tower Brown\". In what is expected to be a temporary change, the tower was painted gold in commemoration of the 2024 Summer Olympics in Paris.\nFollowing the 2024 Summer Olympics held in Paris, Mayor Anne Hidalgo proposed keeping the Olympic rings on the tower permanently. The rings, which measure wide and high, were initially installed for the Games and were scheduled for removal after the Paralympics. Hidalgo's decision faced criticism from the Eiffel family and some residents concerned about altering the protected monument. The original 30-ton rings would be replaced with lighter versions for long-term display.\nThe only non-structural elements are the four decorative grill-work arches, added in Sauvestre's sketches, which served to make the tower look more substantial and to make a more impressive entrance to the exposition.\nA pop-culture movie clich\u00e9 is that the view from a Parisian window always includes the tower. In reality, since zoning restrictions limit the height of most buildings in Paris to seven storeys, only a small number of tall buildings have a clear view of the tower.\nMaintenance.\nMaintenance of the tower includes applying 60\u00a0tons of paint every 7 years to prevent it from rusting. The tower has been completely repainted at least 19 times since it was built, with the most recent being in 2010. Lead paint was still being used as recently as 2001 when the practice was stopped out of concern for the environment.\nCommunications.\nThe tower has been used for making radio transmissions since the beginning of the 20th century. Until the 1950s, sets of aerial wires ran from the cupola to anchors on the Avenue de Suffren and Champ de Mars. These were connected to longwave transmitters in small bunkers. In 1909, a permanent underground radio centre was built near the south pillar, which still exists today. On 20 November 1913, the Paris Observatory, using the Eiffel Tower as an aerial, exchanged wireless signals with the United States Naval Observatory, which used an aerial in Arlington County, Virginia. The object of the transmissions was to measure the difference in longitude between Paris and Washington, D.C. Today, radio and digital television signals are transmitted from the Eiffel Tower.\nDigital television.\nA television antenna was first installed on the tower in 1957, increasing its height by . Work carried out in 2000 added a further , giving the current height of . Analogue television signals from the Eiffel Tower ceased on 8 March 2011.\nDimensions.\nHeight changes.\nThe pinnacle height of the Eiffel Tower has changed multiple times over the years as described in the chart below.\nTaller structures.\nThe Eiffel Tower was the world's tallest structure when completed in 1889, a distinction it retained until 1929 when the Chrysler Building in New York City was topped out. The tower also lost its standing as the world's tallest tower to the Tokyo Tower in 1958 but retains its status as the tallest freestanding (non-guyed) structure in France.\nTourism.\nTransport.\nThe nearest Paris M\u00e9tro station is Bir-Hakeim and the nearest RER station is Champ de Mars-Tour Eiffel. The tower itself is located at the intersection of the quai Branly and the Pont d'I\u00e9na.\nPopularity.\nMore than 300\u00a0million people have visited the tower since it was completed in 1889. In 2015, there were 6.91\u00a0million visitors. The tower is the most-visited paid monument in the world. An average of 25,000 people ascend the tower every day (which can result in long queues).\nIllumination copyright.\nThe tower and its image have been in the public domain since 1993, 70 years after Eiffel's death. In June 1990, a French court ruled that a special lighting display on the tower in 1989 to mark the tower's 100th anniversary was an \"original visual creation\" protected by copyright. The Court of Cassation, France's judicial court of last resort, upheld the ruling in March 1992. The (SETE) now considers any illumination of the tower to be a separate work of art that falls under copyright. As a result, the SNTE alleges that it is illegal to publish contemporary photographs of the lit tower at night without permission in France and some other countries for commercial use. For this reason, it is often rare to find images or videos of the lit tower at night on stock image sites, and media outlets rarely broadcast images or videos of it.\nThe imposition of copyright has been controversial. The Director of Documentation for what was then called the (SNTE), St\u00e9phane Dieu, commented in 2005: \"It is really just a way to manage commercial use of the image, so that it isn't used in ways [of which] we don't approve\". SNTE made over \u20ac1\u00a0million from copyright fees in 2002. However, it could also be used to restrict the publication of tourist photographs of the tower at night, as well as hindering non-profit and semi-commercial publication of images of the illuminated tower.\nThe copyright claim itself has never been tested in courts to date, according to a 2014 article in the \"Art Law Journal\", and there has never been an attempt to track down millions of people who have posted and shared their images of the illuminated tower on the Internet worldwide. However, the article adds that commercial uses of such images, like in a magazine, on a film poster, or on product packaging, may require prior permission.\nFrench doctrine and jurisprudence allows pictures incorporating a copyrighted work as long as their presence is incidental or accessory to the subject being represented, a reasoning akin to the \"de minimis\" rule. Therefore, SETE may be unable to claim copyright on photographs of Paris which happen to include the lit tower.\nReplicas.\nAs one of the most famous landmarks in the world, the Eiffel Tower has been the inspiration for the creation of many replicas and similar towers. An early example is Blackpool Tower in England. The mayor of Blackpool, Sir John Bickerstaffe, was so impressed on seeing the Eiffel Tower at the 1889 exposition that he commissioned a similar tower to be built in his town. It opened in 1894 and is tall. Tokyo Tower in Japan, built as a communications tower in 1958, was also inspired by the Eiffel Tower. Well known is the Pet\u0159\u00edn Lookout Tower in Prague too. \nThere are various scale models of the tower in the United States, including a half-scale version at the Paris Las Vegas, Nevada, one in Paris, Texas built in 1993, and two 1:3 scale models at Kings Island, located in Mason, Ohio, and Kings Dominion, Virginia, amusement parks opened in 1972 and 1975 respectively. Two 1:3 scale models can be found in China, one in Durango, Mexico that was donated by the local French community, and several across Europe.\nIn 2011, the TV show \"Pricing the Priceless\" on the National Geographic Channel speculated that a full-size replica of the tower would cost approximately US$480\u00a0million to build. This would be more than ten times the cost of the original (nearly 8 million in 1890 francs; around US$40\u00a0million in 2018 dollars)."}
{"id": "9235", "revid": "16686361", "url": "https://en.wikipedia.org/wiki?curid=9235", "title": "Ethical egoism", "text": "In ethical philosophy, ethical egoism is the normative position that moral agents \"ought\" to act in their own self-interest. It differs from psychological egoism, which claims that people \"can only\" act in their self-interest. Ethical egoism also differs from rational egoism, which holds that it is \"rational\" to act in one's self-interest.\nEthical egoism holds, therefore, that actions whose consequences will benefit the doer are ethical.\nEthical egoism contrasts with ethical altruism, which holds that moral agents have an obligation to help others. Egoism and altruism both contrast with ethical utilitarianism, which holds that a moral agent should treat one's self (also known as the subject) with no higher regard than one has for others (as egoism does, by elevating self-interests and \"the self\" to a status not granted to others). But it also holds that one is not obligated to sacrifice one's own interests (as altruism does) to help others' interests, so long as one's own interests (i.e., one's own desires or well-being) are substantially equivalent to the others' interests and well-being, but they have the choice to do so. Egoism, utilitarianism, and altruism are all forms of consequentialism, but egoism and altruism contrast with utilitarianism, in that egoism and altruism are both agent-focused forms of consequentialism (i.e., subject-focused or subjective). However, utilitarianism is held to be agent-neutral (i.e., objective and impartial): it does not treat the subject's (i.e., the self's, i.e., the moral \"agent's\") own interests as being more or less important than the interests, desires, or well-being of others.\nEthical egoism does not, however, require moral agents to harm the interests and well-being of others when making moral deliberation; e.g., what is in an agent's self-interest may be incidentally detrimental, beneficial, or neutral in its effect on others. Individualism allows for others' interest and well-being to be disregarded or not, as long as what is chosen is efficacious in satisfying the self-interest of the agent. Nor does ethical egoism necessarily entail that, in pursuing self-interest, one ought always to do what one wants to do; e.g., in the long term, the fulfillment of short-term desires may prove detrimental to the self. Fleeting pleasure, then, takes a back seat to protracted eudaimonia. In the words of James Rachels, \"Ethical egoism ... endorses selfishness, but it doesn't endorse foolishness.\"\nEthical egoism is often used as the philosophical basis for support of right-libertarianism and individualist anarchism. These are political positions based partly on a belief that individuals should not coercively prevent others from exercising freedom of action.\nForms.\nEthical egoism can be broadly divided into three categories: individual, personal, and universal. An \"individual ethical egoist\" would hold that all people should do whatever benefits \"my\" (\"the individual's\")\" \"self-interest; a \"personal ethical egoist\" would hold that they should act in \"their\" self-interest, but would make no claims about what anyone else ought to do; a \"universal ethical egoist\" would argue that everyone should act in ways that are in their self-interest.\nHistory.\nEthical egoism was introduced by the philosopher Henry Sidgwick in his book \"The Methods of Ethics\", written in 1874. Sidgwick compared egoism to the philosophy of utilitarianism, writing that whereas utilitarianism sought to maximize overall pleasure, egoism focused only on maximizing individual pleasure.\nPhilosophers before Sidgwick have also retroactively been identified as ethical egoists. One ancient example is the philosophy of Yang Zhu (4th century BC), Yangism, who views \"wei wo\", or \"everything for myself\", as the only virtue necessary for self-cultivation. Ancient Greek philosophers like Plato, Aristotle and the Stoics were exponents of virtue ethics, and \"did not accept the formal principle that whatever the good is, we should seek only our own good, or prefer it to the good of others.\" However, the beliefs of the Cyrenaics have been referred to as a \"form of egoistic hedonism\", and while some refer to Epicurus' hedonism as a form of virtue ethics, others argue his ethics are more properly described as ethical egoism.\nJustifications.\nPhilosopher James Rachels, in an essay that takes as its title the theory's name, outlines the three arguments most commonly touted in its favor:\nCriticism.\nIt has been argued that extreme ethical egoism is self-defeating. Faced with a situation of limited resources, egoists would consume as much of the resource as they could, making the overall situation worse for everybody. Egoists may respond that if the situation becomes worse for everybody, that would include the egoist, so it is not, in fact, in their rational self-interest to take things to such extremes. However, the (unregulated) tragedy of the commons and the (one off) prisoner's dilemma are cases in which, on the one hand, it is rational for an individual to seek to take as much as possible \"even though\" that makes things worse for everybody, and on the other hand, those cases are not self-refuting since that behaviour remains rational \"even though\" it is ultimately self-defeating, i.e. self-defeating does not imply self-refuting. Egoists might respond that a tragedy of the commons, however, assumes some degree of public land. That is, a commons forbidding homesteading requires regulation. Thus, an argument against the tragedy of the commons, in this belief system, is fundamentally an argument for private property rights and the system that recognizes both property rights and rational self-interest\u2014capitalism. More generally, egoists might say that an increasing respect for individual rights uniquely allows for increasing wealth creation and increasing usable resources despite a fixed amount of raw materials (e.g. the West pre-1776 versus post-1776, East versus West Germany, Hong Kong versus mainland China, North versus South Korea, etc.).\nIt is not clear how to apply a private ownership model to many examples of \"commons\", however. Examples include large fisheries, the atmosphere and the ocean.\nSome perhaps decisive problems with ethical egoism have been pointed out.\nOne is that an ethical egoist would not want ethical egoism to be universalized: as it would be in the egoist's best self-interest if others acted altruistically towards them, they wouldn't want them to act egoistically; however, that is what they consider to be morally binding. Their moral principles would demand of others not to follow them, which can be considered self-defeating and leads to the question: \"How can ethical egoism be considered morally binding if its advocates do not want it to be universally applied?\"\nAnother objection (e.g. by James Rachels) states that the distinction ethical egoism makes between \"yourself\" and \"the rest\" \u2013 demanding to view the interests of \"yourself\" as more important \u2013 is arbitrary, as no justification for it can be offered; considering that the merits and desires of \"the rest\" are comparable to those of \"yourself\" while lacking a justifiable distinction, Rachels concludes that \"the rest\" should be given the same moral consideration as \"yourself\".\nDerek Parfit argues against ethical egoism in the book \"Reasons and Persons\". Parfit argues that ethical egoism is collectively self-defeating due to the prisoner's dilemma. Parfit also poses thought experiments such as the teletransportation paradox, which challenge the idea of an objective future self and a continuous personal identity.\nDaniel Kolak argues that the entire concepts of the \"self\" and the \"ego\" are incoherent. In his book \"I am You\", Kolak uses the terms \"closed individualism\", \"empty individualism\", and \"open individualism\" to describe three contrasting philosophical views of the self. Kolak argues that closed individualism, the idea that one's personal identity consist of a line persisting from moment to moment, is incoherent, and there is no basis for the belief that one is the \"same\" person from moment to moment. Empty individualism is the idea that personal identity exists, but one's identity only exists as a \"time slice\" existing for an infinitesimally small amount of time. Open individualism is the view advocated by Kolak, in which the self in reality does not actually exist at all, similar to anatt\u0101 in Buddhist philosophy. Thus, according to open individualism, it could be argued that ethical egoism is incoherent, since the ego in its entirety is an illusion.\nNotable proponents.\nThe term \"ethical egoism\" has been applied retroactively to philosophers such as Bernard de Mandeville and to many other materialists of his generation, although none of them declared themselves to be egoists. Note that materialism does not necessarily imply egoism, as indicated by Karl Marx, and the many other materialists who espoused forms of collectivism. It has been argued that ethical egoism can lend itself to individualist anarchism such as that of Benjamin Tucker, or the combined anarcho-communism and egoism of Emma Goldman, both of whom were proponents of many egoist ideas put forward by Max Stirner. In this context, egoism is another way of describing the sense that the common good should be enjoyed by all. However, most notable anarchists in history have been less radical, retaining altruism and a sense of the importance of the individual that is appreciable but does not go as far as egoism. Recent trends to greater appreciation of egoism within anarchism tend to come from less classical directions such as post-left anarchy or Situationism (e.g. Raoul Vaneigem). Egoism has also been referenced by anarcho-capitalists, such as Murray Rothbard.\nPhilosopher Max Stirner, in his book \"The Ego and Its Own\", was the first philosopher to call himself an egoist, though his writing makes clear that he desired not a new idea of morality (ethical egoism), but rather a rejection of morality (amoralism), as a nonexistent and limiting \"spook\"; for this, Stirner has been described as the first individualist anarchist. Other philosophers, such as Thomas Hobbes and David Gauthier, have argued that the conflicts which arise when people each pursue their own ends can be resolved for the best of each individual only if they all voluntarily forgo some of their aims\u2014that is, one's self-interest is often best pursued by allowing others to pursue their self-interest as well so that liberty is equal among individuals. Sacrificing one's short-term self-interest to maximize one's long-term self-interest is one form of \"rational self-interest\" which is the idea behind most philosophers' advocacy of ethical egoism. Egoists have also argued that one's actual interests are not immediately obvious, and that the pursuit of self-interest involves more than merely the acquisition of some good, but the \"maximizing\" of one's chances of survival and/or happiness.\nPhilosopher Friedrich Nietzsche suggested that egoistic or \"life-affirming\" behavior stimulates jealousy or \"ressentiment\" in others, and that this is the psychological motive for the altruism in Christianity. Sociologist Helmut Schoeck similarly considered envy the motive of collective efforts by society to reduce the disproportionate gains of successful individuals through moral or legal constraints, with altruism being primary among these. In addition, Nietzsche (in \"Beyond Good and Evil\") and Alasdair MacIntyre (in \"After Virtue\") have pointed out that the ancient Greeks did not associate morality with altruism in the way that post-Christian Western civilization has done.\nAristotle's view is that we have duties to ourselves as well as to other people (e.g. friends) and to the \"polis\" as a whole. The same is true for Thomas Aquinas, Christian Wolff and Immanuel Kant, who claim that there are duties to ourselves as Aristotle did, although it has been argued that, for Aristotle, the duty to one's self is primary.\nAyn Rand argued that there is a positive harmony of interests among free, rational humans, such that no moral agent can rationally coerce another person consistently with their own long-term self-interest. Rand argued that other people are an enormous value to an individual's well-being (through education, trade and affection), but also that this value could be fully realized only under conditions of political and economic freedom. According to Rand, voluntary trade alone can assure that human interaction is \"mutually\" beneficial. Rand's student, Leonard Peikoff has argued that the identification of one's interests itself is impossible absent the use of principles, and that self-interest cannot be consistently pursued absent a consistent adherence to certain ethical principles. Recently, Rand's position has also been defended by such writers as Tara Smith, Tibor Machan, Allan Gotthelf, David Kelley, Douglas Rasmussen, Nathaniel Branden, Harry Binswanger, Andrew Bernstein, and Craig Biddle.\nPhilosopher David L. Norton identified himself as an \"ethical individualist\", and, like Rand, saw a harmony between an individual's fidelity to their own self-actualization, or \"personal destiny\", and the achievement of society's well-being."}
{"id": "9236", "revid": "18515189", "url": "https://en.wikipedia.org/wiki?curid=9236", "title": "Evolution", "text": "Evolution is the change in the heritable characteristics of biological populations over successive generations. It occurs when evolutionary processes such as natural selection and genetic drift act on genetic variation, resulting in certain characteristics becoming more or less common within a population over successive generations. The process of evolution has given rise to biodiversity at every level of biological organisation.\nThe scientific theory of evolution by natural selection was conceived independently by two British naturalists, Charles Darwin and Alfred Russel Wallace, in the mid-19th century as an explanation for why organisms are adapted to their physical and biological environments. The theory was first set out in detail in Darwin's book \"On the Origin of Species\". Evolution by natural selection is established by observable facts about living organisms: (1) more offspring are often produced than can possibly survive; (2) traits vary among individuals with respect to their morphology, physiology, and behaviour; (3) different traits confer different rates of survival and reproduction (differential fitness); and (4) traits can be passed from generation to generation (heritability of fitness). In successive generations, members of a population are therefore more likely to be replaced by the offspring of parents with favourable characteristics for that environment.\nIn the early 20th century, competing ideas of evolution were refuted and evolution was combined with Mendelian inheritance and population genetics to give rise to modern evolutionary theory. In this synthesis the basis for heredity is in DNA molecules that pass information from generation to generation. The processes that change DNA in a population include natural selection, genetic drift, mutation, and gene flow.\nAll life on Earth\u2014including humanity\u2014shares a last universal common ancestor (LUCA), which lived approximately 3.5\u20133.8\u00a0billion years ago. The fossil record includes a progression from early biogenic graphite to microbial mat fossils to fossilised multicellular organisms. Existing patterns of biodiversity have been shaped by repeated formations of new species (speciation), changes within species (anagenesis), and loss of species (extinction) throughout the evolutionary history of life on Earth. Morphological and biochemical traits tend to be more similar among species that share a more recent common ancestor, which historically was used to reconstruct phylogenetic trees, although direct comparison of genetic sequences is a more common method today.\nEvolutionary biologists have continued to study various aspects of evolution by forming and testing hypotheses as well as constructing theories based on evidence from the field or laboratory and on data generated by the methods of mathematical and theoretical biology. Their discoveries have influenced not just the development of biology but also other fields including agriculture, medicine, and computer science.\nHeredity.\nEvolution in organisms occurs through changes in heritable characteristics\u2014the inherited characteristics of an organism. In humans, for example, eye colour is an inherited characteristic and an individual might inherit the \"brown-eye trait\" from one of their parents. Inherited traits are controlled by genes and the complete set of genes within an organism's genome (genetic material) is called its \"genotype\".\nThe complete set of observable traits that make up the structure and behaviour of an organism is called its \"phenotype\". Some of these traits come from the interaction of its genotype with the environment while others are neutral. Some observable characteristics are not inherited. For example, suntanned skin comes from the interaction between a person's genotype and sunlight; thus, suntans are not passed on to people's children. The phenotype is the ability of the skin to tan when exposed to sunlight. However, some people tan more easily than others, due to differences in genotypic variation; a striking example are people with the inherited trait of albinism, who do not tan at all and are very sensitive to sunburn.\nHeritable characteristics are passed from one generation to the next via DNA, a molecule that encodes genetic information. DNA is a long biopolymer composed of four types of bases. The sequence of bases along a particular DNA molecule specifies the genetic information, in a manner similar to a sequence of letters spelling out a sentence. Before a cell divides, the DNA is copied, so that each of the resulting two cells will inherit the DNA sequence. Portions of a DNA molecule that specify a single functional unit are called genes; different genes have different sequences of bases. Within cells, each long strand of DNA is called a chromosome. The specific location of a DNA sequence within a chromosome is known as a locus. If the DNA sequence at a locus varies between individuals, the different forms of this sequence are called alleles. DNA sequences can change through mutations, producing new alleles. If a mutation occurs within a gene, the new allele may affect the trait that the gene controls, altering the phenotype of the organism. However, while this simple correspondence between an allele and a trait works in some cases, most traits are influenced by multiple genes in a quantitative or epistatic manner.\nSources of variation.\nEvolution can occur if there is genetic variation within a population. Variation comes from mutations in the genome, reshuffling of genes through sexual reproduction and migration between populations (gene flow). Despite the constant introduction of new variation through mutation and gene flow, most of the genome of a species is very similar among all individuals of that species. However, discoveries in the field of evolutionary developmental biology have demonstrated that even relatively small differences in genotype can lead to dramatic differences in phenotype both within and between species.\nAn individual organism's phenotype results from both its genotype and the influence of the environment it has lived in. The modern evolutionary synthesis defines evolution as the change over time in this genetic variation. The frequency of one particular allele will become more or less prevalent relative to other forms of that gene. Variation disappears when a new allele reaches the point of fixation\u2014when it either disappears from the population or replaces the ancestral allele entirely.\nMutation.\nMutations are changes in the DNA sequence of a cell's genome and are the ultimate source of genetic variation in all organisms. When mutations occur, they may alter the product of a gene, or prevent the gene from functioning, or have no effect. \nAbout half of the mutations in the coding regions of protein-coding genes are deleterious \u2014 the other half are neutral. A small percentage of the total mutations in this region confer a fitness benefit. Some of the mutations in other parts of the genome are deleterious but the vast majority are neutral. A few are beneficial.\nMutations can involve large sections of a chromosome becoming duplicated (usually by genetic recombination), which can introduce extra copies of a gene into a genome. Extra copies of genes are a major source of the raw material needed for new genes to evolve. This is important because most new genes evolve within gene families from pre-existing genes that share common ancestors. For example, the human eye uses four genes to make structures that sense light: three for colour vision and one for night vision; all four are descended from a single ancestral gene.\nNew genes can be generated from an ancestral gene when a duplicate copy mutates and acquires a new function. This process is easier once a gene has been duplicated because it increases the redundancy of the system; one gene in the pair can acquire a new function while the other copy continues to perform its original function. Other types of mutations can even generate entirely new genes from previously noncoding DNA, a phenomenon termed \"de novo\" gene birth.\nThe generation of new genes can also involve small parts of several genes being duplicated, with these fragments then recombining to form new combinations with new functions (exon shuffling). When new genes are assembled from shuffling pre-existing parts, domains act as modules with simple independent functions, which can be mixed together to produce new combinations with new and complex functions. For example, polyketide synthases are large enzymes that make antibiotics; they contain up to 100 independent domains that each catalyse one step in the overall process, like a step in an assembly line.\nOne example of mutation is wild boar piglets. They are camouflage coloured and show a characteristic pattern of dark and light longitudinal stripes. However, mutations in the \"melanocortin 1 receptor\" (\"MC1R\") disrupt the pattern. The majority of pig breeds carry MC1R mutations disrupting wild-type colour and different mutations causing dominant black colouring.\nSex and recombination.\nIn asexual organisms, genes are inherited together, or \"linked\", as they cannot mix with genes of other organisms during reproduction. In contrast, the offspring of sexual organisms contain random mixtures of their parents' chromosomes that are produced through independent assortment. In a related process called homologous recombination, sexual organisms exchange DNA between two matching chromosomes. Recombination and reassortment do not alter allele frequencies, but instead change which alleles are associated with each other, producing offspring with new combinations of alleles. Sex usually increases genetic variation and may increase the rate of evolution.\nThe two-fold cost of sex was first described by John Maynard Smith. The first cost is that in sexually dimorphic species only one of the two sexes can bear young. This cost does not apply to hermaphroditic species, like most plants and many invertebrates. The second cost is that any individual who reproduces sexually can only pass on 50% of its genes to any individual offspring, with even less passed on as each new generation passes. Yet sexual reproduction is the more common means of reproduction among eukaryotes and multicellular organisms. The Red Queen hypothesis has been used to explain the significance of sexual reproduction as a means to enable continual evolution and adaptation in response to coevolution with other species in an ever-changing environment. Another hypothesis is that sexual reproduction is primarily an adaptation for promoting accurate recombinational repair of damage in germline DNA, and that increased diversity is a byproduct of this process that may sometimes be adaptively beneficial.\nGene flow.\nGene flow is the exchange of genes between populations and between species. It can therefore be a source of variation that is new to a population or to a species. Gene flow can be caused by the movement of individuals between separate populations of organisms, as might be caused by the movement of mice between inland and coastal populations, or the movement of pollen between heavy-metal-tolerant and heavy-metal-sensitive populations of grasses.\nGene transfer between species includes the formation of hybrid organisms and horizontal gene transfer. Horizontal gene transfer is the transfer of genetic material from one organism to another organism that is not its offspring; this is most common among bacteria. In medicine, this contributes to the spread of antibiotic resistance, as when one bacteria acquires resistance genes it can rapidly transfer them to other species. Horizontal transfer of genes from bacteria to eukaryotes such as the yeast \"Saccharomyces cerevisiae\" and the adzuki bean weevil \"Callosobruchus chinensis\" has occurred. An example of larger-scale transfers are the eukaryotic bdelloid rotifers, which have received a range of genes from bacteria, fungi and plants. Viruses can also carry DNA between organisms, allowing transfer of genes even across biological domains.\nLarge-scale gene transfer has also occurred between the ancestors of eukaryotic cells and bacteria, during the acquisition of chloroplasts and mitochondria. It is possible that eukaryotes themselves originated from horizontal gene transfers between bacteria and archaea.\nEpigenetics.\nSome heritable changes cannot be explained by changes to the sequence of nucleotides in the DNA. These phenomena are classed as epigenetic inheritance systems. DNA methylation marking chromatin, self-sustaining metabolic loops, gene silencing by RNA interference and the three-dimensional conformation of proteins (such as prions) are areas where epigenetic inheritance systems have been discovered at the organismic level. Developmental biologists suggest that complex interactions in genetic networks and communication among cells can lead to heritable variations that may underlay some of the mechanics in developmental plasticity and canalisation. Heritability may also occur at even larger scales. For example, ecological inheritance through the process of niche construction is defined by the regular and repeated activities of organisms in their environment. This generates a legacy of effects that modify and feed back into the selection regime of subsequent generations. Other examples of heritability in evolution that are not under the direct control of genes include the inheritance of cultural traits and symbiogenesis.\nEvolutionary forces.\nFrom a neo-Darwinian perspective, evolution occurs when there are changes in the frequencies of alleles within a population of interbreeding organisms, for example, the allele for black colour in a population of moths becoming more common. Mechanisms that can lead to changes in allele frequencies include natural selection, genetic drift, and mutation bias.\nNatural selection.\nEvolution by natural selection is the process by which traits that enhance survival and reproduction become more common in successive generations of a population. It embodies three principles:\nMore offspring are produced than can possibly survive, and these conditions produce competition between organisms for survival and reproduction. Consequently, organisms with traits that give them an advantage over their competitors are more likely to pass on their traits to the next generation than those with traits that do not confer an advantage. This teleonomy is the quality whereby the process of natural selection creates and preserves traits that are seemingly fitted for the functional roles they perform. Consequences of selection include nonrandom mating and genetic hitchhiking.\nThe central concept of natural selection is the evolutionary fitness of an organism. Fitness is measured by an organism's ability to survive and reproduce, which determines the size of its genetic contribution to the next generation. However, fitness is not the same as the total number of offspring: instead fitness is indicated by the proportion of subsequent generations that carry an organism's genes. For example, if an organism could survive well and reproduce rapidly, but its offspring were all too small and weak to survive, this organism would make little genetic contribution to future generations and would thus have low fitness.\nIf an allele increases fitness more than the other alleles of that gene, then with each generation this allele has a higher probability of becoming common within the population. These traits are said to be \"selected \"for\".\" Examples of traits that can increase fitness are enhanced survival and increased fecundity. Conversely, the lower fitness caused by having a less beneficial or deleterious allele results in this allele likely becoming rarer\u2014they are \"selected \"against\".\" \nImportantly, the fitness of an allele is not a fixed characteristic; if the environment changes, previously neutral or harmful traits may become beneficial and previously beneficial traits become harmful. However, even if the direction of selection does reverse in this way, traits that were lost in the past may not re-evolve in an identical form. However, a re-activation of dormant genes, as long as they have not been eliminated from the genome and were only suppressed perhaps for hundreds of generations, can lead to the re-occurrence of traits thought to be lost like hindlegs in dolphins, teeth in chickens, wings in wingless stick insects, tails and additional nipples in humans etc. \"Throwbacks\" such as these are known as atavisms.\nNatural selection within a population for a trait that can vary across a range of values, such as height, can be categorised into three different types. The first is directional selection, which is a shift in the average value of a trait over time\u2014for example, organisms slowly getting taller. Secondly, disruptive selection is selection for extreme trait values and often results in two different values becoming most common, with selection against the average value. This would be when either short or tall organisms had an advantage, but not those of medium height. Finally, in stabilising selection there is selection against extreme trait values on both ends, which causes a decrease in variance around the average value and less diversity. This would, for example, cause organisms to eventually have a similar height.\nNatural selection most generally makes nature the measure against which individuals and individual traits, are more or less likely to survive. \"Nature\" in this sense refers to an ecosystem, that is, a system in which organisms interact with every other element, physical as well as biological, in their local environment. Eugene Odum, a founder of ecology, defined an ecosystem as: \"Any unit that includes all of the organisms...in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity, and material cycles (i.e., exchange of materials between living and nonliving parts) within the system...\" Each population within an ecosystem occupies a distinct niche, or position, with distinct relationships to other parts of the system. These relationships involve the life history of the organism, its position in the food chain and its geographic range. This broad understanding of nature enables scientists to delineate specific forces which, together, comprise natural selection.\nNatural selection can act at different levels of organisation, such as genes, cells, individual organisms, groups of organisms and species. Selection can act at multiple levels simultaneously. An example of selection occurring below the level of the individual organism are genes called transposons, which can replicate and spread throughout a genome. Selection at a level above the individual, such as group selection, may allow the evolution of cooperation.\nGenetic drift.\nGenetic drift is the random fluctuation of allele frequencies within a population from one generation to the next. When selective forces are absent or relatively weak, allele frequencies are equally likely to \"drift\" upward or downward in each successive generation because the alleles are subject to sampling error. This drift halts when an allele eventually becomes fixed, either by disappearing from the population or by replacing the other alleles entirely. Genetic drift may therefore eliminate some alleles from a population due to chance alone. Even in the absence of selective forces, genetic drift can cause two separate populations that begin with the same genetic structure to drift apart into two divergent populations with different sets of alleles.\nAccording to the neutral theory of molecular evolution most evolutionary changes are the result of the fixation of neutral mutations by genetic drift. In this model, most genetic changes in a population are thus the result of constant mutation pressure and genetic drift. This form of the neutral theory has been debated since it does not seem to fit some genetic variation seen in nature. A better-supported version of this model is the nearly neutral theory, according to which a mutation that would be effectively neutral in a small population is not necessarily neutral in a large population. Other theories propose that genetic drift is dwarfed by other stochastic forces in evolution, such as genetic hitchhiking, also known as genetic draft. Another concept is constructive neutral evolution (CNE), which explains that complex systems can emerge and spread into a population through neutral transitions due to the principles of excess capacity, presuppression, and ratcheting, and it has been applied in areas ranging from the origins of the spliceosome to the complex interdependence of microbial communities.\nThe time it takes a neutral allele to become fixed by genetic drift depends on population size; fixation is more rapid in smaller populations. The number of individuals in a population is not critical, but instead a measure known as the effective population size. The effective population is usually smaller than the total population since it takes into account factors such as the level of inbreeding and the stage of the lifecycle in which the population is the smallest. The effective population size may not be the same for every gene in the same population.\nIt is usually difficult to measure the relative importance of selection and neutral processes, including drift. The comparative importance of adaptive and non-adaptive forces in driving evolutionary change is an area of current research.\nMutation bias.\nMutation bias is usually conceived as a difference in expected rates for two different kinds of mutation, e.g., transition-transversion bias, GC-AT bias, deletion-insertion bias. This is related to the idea of developmental bias. Haldane and Fisher argued that, because mutation is a weak pressure easily overcome by selection, tendencies of mutation would be ineffectual except under conditions of neutral evolution or extraordinarily high mutation rates. This opposing-pressures argument was long used to dismiss the possibility of internal tendencies in evolution, until the molecular era prompted renewed interest in neutral evolution.\nNoboru Sueoka and Ernst Freese proposed that systematic biases in mutation might be responsible for systematic differences in genomic GC composition between species. The identification of a GC-biased \"E. coli\" mutator strain in 1967, along with the proposal of the neutral theory, established the plausibility of mutational explanations for molecular patterns, which are now common in the molecular evolution literature.\nFor instance, mutation biases are frequently invoked in models of codon usage. Such models also include effects of selection, following the mutation-selection-drift model, which allows both for mutation biases and differential selection based on effects on translation. Hypotheses of mutation bias have played an important role in the development of thinking about the evolution of genome composition, including isochores. Different insertion vs. deletion biases in different taxa can lead to the evolution of different genome sizes. The hypothesis of Lynch regarding genome size relies on mutational biases toward increase or decrease in genome size.\nHowever, mutational hypotheses for the evolution of composition suffered a reduction in scope when it was discovered that (1) GC-biased gene conversion makes an important contribution to composition in diploid organisms such as mammals and (2) bacterial genomes frequently have AT-biased mutation.\nContemporary thinking about the role of mutation biases reflects a different theory from that of Haldane and Fisher. More recent work showed that the original \"pressures\" theory assumes that evolution is based on standing variation: when evolution depends on events of mutation that introduce new alleles, mutational and developmental biases in the introduction of variation (arrival biases) can impose biases on evolution without requiring neutral evolution or high mutation rates.\nSeveral studies report that the mutations implicated in adaptation reflect common mutation biases though others dispute this interpretation.\nGenetic hitchhiking.\nRecombination allows alleles on the same strand of DNA to become separated. However, the rate of recombination is low (approximately two events per chromosome per generation). As a result, genes close together on a chromosome may not always be shuffled away from each other and genes that are close together tend to be inherited together, a phenomenon known as linkage. This tendency is measured by finding how often two alleles occur together on a single chromosome compared to expectations, which is called their linkage disequilibrium. A set of alleles that is usually inherited in a group is called a haplotype. This can be important when one allele in a particular haplotype is strongly beneficial: natural selection can drive a selective sweep that will also cause the other alleles in the haplotype to become more common in the population; this effect is called genetic hitchhiking or genetic draft. Genetic draft caused by the fact that some neutral genes are genetically linked to others that are under selection can be partially captured by an appropriate effective population size.\nSexual selection.\nA special case of natural selection is sexual selection, which is selection for any trait that increases mating success by increasing the attractiveness of an organism to potential mates. Traits that evolved through sexual selection are particularly prominent among males of several animal species. Although sexually favoured, traits such as cumbersome antlers, mating calls, large body size and bright colours often attract predation, which compromises the survival of individual males. This survival disadvantage is balanced by higher reproductive success in males that show these hard-to-fake, sexually selected traits.\nNatural outcomes.\nEvolution influences every aspect of the form and behaviour of organisms. Most prominent are the specific behavioural and physical adaptations that are the outcome of natural selection. These adaptations increase fitness by aiding activities such as finding food, avoiding predators or attracting mates. Organisms can also respond to selection by cooperating with each other, usually by aiding their relatives or engaging in mutually beneficial symbiosis. In the longer term, evolution produces new species through splitting ancestral populations of organisms into new groups that cannot or will not interbreed. These outcomes of evolution are distinguished based on time scale as macroevolution versus microevolution. Macroevolution refers to evolution that occurs at or above the level of species, in particular speciation and extinction, whereas microevolution refers to smaller evolutionary changes within a species or population, in particular shifts in allele frequency and adaptation. Macroevolution is the outcome of long periods of microevolution. Thus, the distinction between micro- and macroevolution is not a fundamental one\u2014the difference is simply the time involved. However, in macroevolution, the traits of the entire species may be important. For instance, a large amount of variation among individuals allows a species to rapidly adapt to new habitats, lessening the chance of it going extinct, while a wide geographic range increases the chance of speciation, by making it more likely that part of the population will become isolated. In this sense, microevolution and macroevolution might involve selection at different levels\u2014with microevolution acting on genes and organisms, versus macroevolutionary processes such as species selection acting on entire species and affecting their rates of speciation and extinction.\nA common misconception is that evolution has goals, long-term plans, or an innate tendency for \"progress\", as expressed in beliefs such as orthogenesis and evolutionism; realistically, however, evolution has no long-term goal and does not necessarily produce greater complexity. Although complex species have evolved, they occur as a side effect of the overall number of organisms increasing, and simple forms of life still remain more common in the biosphere. For example, the overwhelming majority of species are microscopic prokaryotes, which form about half the world's biomass despite their small size and constitute the vast majority of Earth's biodiversity. Simple organisms have therefore been the dominant form of life on Earth throughout its history and continue to be the main form of life up to the present day, with complex life only appearing more diverse because it is more noticeable. Indeed, the evolution of microorganisms is particularly important to evolutionary research since their rapid reproduction allows the study of experimental evolution and the observation of evolution and adaptation in real time.\nAdaptation.\nAdaptation is the process that makes organisms better suited to their habitat. Also, the term adaptation may refer to a trait that is important for an organism's survival. For example, the adaptation of horses' teeth to the grinding of grass. By using the term \"adaptation\" for the evolutionary process and \"adaptive trait\" for the product (the bodily part or function), the two senses of the word may be distinguished. Adaptations are produced by natural selection. The following definitions are due to Theodosius Dobzhansky:\nAdaptation may cause either the gain of a new feature, or the loss of an ancestral feature. An example that shows both types of change is bacterial adaptation to antibiotic selection, with genetic changes causing antibiotic resistance by both modifying the target of the drug, or increasing the activity of transporters that pump the drug out of the cell. Other striking examples are the bacteria \"Escherichia coli\" evolving the ability to use citric acid as a nutrient in a long-term laboratory experiment, \"Flavobacterium\" evolving a novel enzyme that allows these bacteria to grow on the by-products of nylon manufacturing, and the soil bacterium \"Sphingobium\" evolving an entirely new metabolic pathway that degrades the synthetic pesticide pentachlorophenol. An interesting but still controversial idea is that some adaptations might increase the ability of organisms to generate genetic diversity and adapt by natural selection (increasing organisms' evolvability).\nAdaptation occurs through the gradual modification of existing structures. Consequently, structures with similar internal organisation may have different functions in related organisms. This is the result of a single ancestral structure being adapted to function in different ways. The bones within bat wings, for example, are very similar to those in mice feet and primate hands, due to the descent of all these structures from a common mammalian ancestor. However, since all living organisms are related to some extent, even organs that appear to have little or no structural similarity, such as arthropod, squid and vertebrate eyes, or the limbs and wings of arthropods and vertebrates, can depend on a common set of homologous genes that control their assembly and function; this is called deep homology.\nDuring evolution, some structures may lose their original function and become vestigial structures. Such structures may have little or no function in a current species, yet have a clear function in ancestral species, or other closely related species. Examples include pseudogenes, the non-functional remains of eyes in blind cave-dwelling fish, wings in flightless birds, the presence of hip bones in whales and snakes, and sexual traits in organisms that reproduce via asexual reproduction. Examples of vestigial structures in humans include wisdom teeth, the coccyx, the vermiform appendix, and other behavioural vestiges such as goose bumps and primitive reflexes.\nHowever, many traits that appear to be simple adaptations are in fact exaptations: structures originally adapted for one function, but which coincidentally became somewhat useful for some other function in the process. One example is the African lizard \"Holaspis guentheri\", which developed an extremely flat head for hiding in crevices, as can be seen by looking at its near relatives. However, in this species, the head has become so flattened that it assists in gliding from tree to tree\u2014an exaptation. Within cells, molecular machines such as the bacterial flagella and protein sorting machinery evolved by the recruitment of several pre-existing proteins that previously had different functions. Another example is the recruitment of enzymes from glycolysis and xenobiotic metabolism to serve as structural proteins called crystallins within the lenses of organisms' eyes.\nAn area of current investigation in evolutionary developmental biology is the developmental basis of adaptations and exaptations. This research addresses the origin and evolution of embryonic development and how modifications of development and developmental processes produce novel features. These studies have shown that evolution can alter development to produce new structures, such as embryonic bone structures that develop into the jaw in other animals instead forming part of the middle ear in mammals. It is also possible for structures that have been lost in evolution to reappear due to changes in developmental genes, such as a mutation in chickens causing embryos to grow teeth similar to those of crocodiles. It is now becoming clear that most alterations in the form of organisms are due to changes in a small set of conserved genes.\nCoevolution.\nInteractions between organisms can produce both conflict and cooperation. When the interaction is between pairs of species, such as a pathogen and a host, or a predator and its prey, these species can develop matched sets of adaptations. Here, the evolution of one species causes adaptations in a second species. These changes in the second species then, in turn, cause new adaptations in the first species. This cycle of selection and response is called coevolution. An example is the production of tetrodotoxin in the rough-skinned newt and the evolution of tetrodotoxin resistance in its predator, the common garter snake. In this predator-prey pair, an evolutionary arms race has produced high levels of toxin in the newt and correspondingly high levels of toxin resistance in the snake.\nCooperation.\nNot all co-evolved interactions between species involve conflict. Many cases of mutually beneficial interactions have evolved. For instance, an extreme cooperation exists between plants and the mycorrhizal fungi that grow on their roots and aid the plant in absorbing nutrients from the soil. This is a reciprocal relationship as the plants provide the fungi with sugars from photosynthesis. Here, the fungi actually grow inside plant cells, allowing them to exchange nutrients with their hosts, while sending signals that suppress the plant immune system.\nCoalitions between organisms of the same species have also evolved. An extreme case is the eusociality found in social insects, such as bees, termites and ants, where sterile insects feed and guard the small number of organisms in a colony that are able to reproduce. On an even smaller scale, the somatic cells that make up the body of an animal limit their reproduction so they can maintain a stable organism, which then supports a small number of the animal's germ cells to produce offspring. Here, somatic cells respond to specific signals that instruct them whether to grow, remain as they are, or die. If cells ignore these signals and multiply inappropriately, their uncontrolled growth causes cancer.\nSuch cooperation within species may have evolved through the process of kin selection, which is where one organism acts to help raise a relative's offspring. This activity is selected for because if the \"helping\" individual contains alleles which promote the helping activity, it is likely that its kin will \"also\" contain these alleles and thus those alleles will be passed on. Other processes that may promote cooperation include group selection, where cooperation provides benefits to a group of organisms.\nSpeciation.\nSpeciation is the process where a species diverges into two or more descendant species.\nThere are multiple ways to define the concept of \"species\". The choice of definition is dependent on the particularities of the species concerned. For example, some species concepts apply more readily toward sexually reproducing organisms while others lend themselves better toward asexual organisms. Despite the diversity of various species concepts, these various concepts can be placed into one of three broad philosophical approaches: interbreeding, ecological and phylogenetic. The Biological Species Concept (BSC) is a classic example of the interbreeding approach. Defined by evolutionary biologist Ernst Mayr in 1942, the BSC states that \"species are groups of actually or potentially interbreeding natural populations, which are reproductively isolated from other such groups.\" Despite its wide and long-term use, the BSC like other species concepts is not without controversy, for example, because genetic recombination among prokaryotes is not an intrinsic aspect of reproduction; this is called the species problem. Some researchers have attempted a unifying monistic definition of species, while others adopt a pluralistic approach and suggest that there may be different ways to logically interpret the definition of a species.\nBarriers to reproduction between two diverging sexual populations are required for the populations to become new species. Gene flow may slow this process by spreading the new genetic variants also to the other populations. Depending on how far two species have diverged since their most recent common ancestor, it may still be possible for them to produce offspring, as with horses and donkeys mating to produce mules. Such hybrids are generally infertile. In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct. However, viable hybrids are occasionally formed and these new species can either have properties intermediate between their parent species, or possess a totally new phenotype. The importance of hybridisation in producing new species of animals is unclear, although cases have been seen in many types of animals, with the gray tree frog being a particularly well-studied example.\nSpeciation has been observed multiple times under both controlled laboratory conditions and in nature. In sexually reproducing organisms, speciation results from reproductive isolation followed by genealogical divergence. There are four primary geographic modes of speciation. The most common in animals is allopatric speciation, which occurs in populations initially isolated geographically, such as by habitat fragmentation or migration. Selection under these conditions can produce very rapid changes in the appearance and behaviour of organisms. As selection and drift act independently on populations isolated from the rest of their species, separation may eventually produce organisms that cannot interbreed.\nThe second mode of speciation is peripatric speciation, which occurs when small populations of organisms become isolated in a new environment. This differs from allopatric speciation in that the isolated populations are numerically much smaller than the parental population. Here, the founder effect causes rapid speciation after an increase in inbreeding increases selection on homozygotes, leading to rapid genetic change.\nThe third mode is parapatric speciation. This is similar to peripatric speciation in that a small population enters a new habitat, but differs in that there is no physical separation between these two populations. Instead, speciation results from the evolution of mechanisms that reduce gene flow between the two populations. Generally this occurs when there has been a drastic change in the environment within the parental species' habitat. One example is the grass \"Anthoxanthum odoratum\", which can undergo parapatric speciation in response to localised metal pollution from mines. Here, plants evolve that have resistance to high levels of metals in the soil. Selection against interbreeding with the metal-sensitive parental population produced a gradual change in the flowering time of the metal-resistant plants, which eventually produced complete reproductive isolation. Selection against hybrids between the two populations may cause reinforcement, which is the evolution of traits that promote mating within a species, as well as character displacement, which is when two species become more distinct in appearance.\nFinally, in sympatric speciation species diverge without geographic isolation or changes in habitat. This form is rare since even a small amount of gene flow may remove genetic differences between parts of a population. Generally, sympatric speciation in animals requires the evolution of both genetic differences and nonrandom mating, to allow reproductive isolation to evolve.\nOne type of sympatric speciation involves crossbreeding of two related species to produce a new hybrid species. This is not common in animals as animal hybrids are usually sterile. This is because during meiosis the homologous chromosomes from each parent are from different species and cannot successfully pair. However, it is more common in plants because plants often double their number of chromosomes, to form polyploids. This allows the chromosomes from each parental species to form matching pairs during meiosis, since each parent's chromosomes are represented by a pair already. An example of such a speciation event is when the plant species \"Arabidopsis thaliana\" and \"Arabidopsis arenosa\" crossbred to give the new species \"Arabidopsis suecica\". This happened about 20,000 years ago, and the speciation process has been repeated in the laboratory, which allows the study of the genetic mechanisms involved in this process. Indeed, chromosome doubling within a species may be a common cause of reproductive isolation, as half the doubled chromosomes will be unmatched when breeding with undoubled organisms.\nSpeciation events are important in the theory of punctuated equilibrium, which accounts for the pattern in the fossil record of short \"bursts\" of evolution interspersed with relatively long periods of stasis, where species remain relatively unchanged. In this theory, speciation and rapid evolution are linked, with natural selection and genetic drift acting most strongly on organisms undergoing speciation in novel habitats or small populations. As a result, the periods of stasis in the fossil record correspond to the parental population and the organisms undergoing speciation and rapid evolution are found in small populations or geographically restricted habitats and therefore rarely being preserved as fossils.\nExtinction.\nExtinction is the disappearance of an entire species. Extinction is not an unusual event, as species regularly appear through speciation and disappear through extinction. Nearly all animal and plant species that have lived on Earth are now extinct, and extinction appears to be the ultimate fate of all species. These extinctions have happened continuously throughout the history of life, although the rate of extinction spikes in occasional mass extinction events. The Cretaceous\u2013Paleogene extinction event, during which the non-avian dinosaurs became extinct, is the most well-known, but the earlier Permian\u2013Triassic extinction event was even more severe, with approximately 96% of all marine species driven to extinction. The Holocene extinction event is an ongoing mass extinction associated with humanity's expansion across the globe over the past few thousand years. Present-day extinction rates are 100\u20131000 times greater than the background rate and up to 30% of current species may be extinct by the mid 21st century. Human activities are now the primary cause of the ongoing extinction event; global warming may further accelerate it in the future. Despite the estimated extinction of more than 99% of all species that ever lived on Earth, about 1\u00a0trillion species are estimated to be on Earth currently with only one-thousandth of 1% described.\nThe role of extinction in evolution is not very well understood and may depend on which type of extinction is considered. The causes of the continuous \"low-level\" extinction events, which form the majority of extinctions, may be the result of competition between species for limited resources (the competitive exclusion principle). If one species can out-compete another, this could produce species selection, with the fitter species surviving and the other species being driven to extinction. The intermittent mass extinctions are also important, but instead of acting as a selective force, they drastically reduce diversity in a nonspecific manner and promote bursts of rapid evolution and speciation in survivors.\nApplications.\nConcepts and models used in evolutionary biology, such as natural selection, have many applications.\nArtificial selection is the intentional selection of traits in a population of organisms. This has been used for thousands of years in the domestication of plants and animals. More recently, such selection has become a vital part of genetic engineering, with selectable markers such as antibiotic resistance genes being used to manipulate DNA. Proteins with valuable properties have evolved by repeated rounds of mutation and selection (for example modified enzymes and new antibodies) in a process called directed evolution.\nUnderstanding the changes that have occurred during an organism's evolution can reveal the genes needed to construct parts of the body, genes which may be involved in human genetic disorders. For example, the Mexican tetra is an albino cavefish that lost its eyesight during evolution. Breeding together different populations of this blind fish produced some offspring with functional eyes, since different mutations had occurred in the isolated populations that had evolved in different caves. This helped identify genes required for vision and pigmentation.\nEvolutionary theory has many applications in medicine. Many human diseases are not static phenomena, but capable of evolution. Viruses, bacteria, fungi and cancers evolve to be resistant to host immune defences, as well as to pharmaceutical drugs. These same problems occur in agriculture with pesticide and herbicide resistance. It is possible that we are facing the end of the effective life of most of available antibiotics and predicting the evolution and evolvability of our pathogens and devising strategies to slow or circumvent it is requiring deeper knowledge of the complex forces driving evolution at the molecular level.\nIn computer science, simulations of evolution using evolutionary algorithms and artificial life started in the 1960s and were extended with simulation of artificial selection. Artificial evolution became a widely recognised optimisation method as a result of the work of Ingo Rechenberg in the 1960s. He used evolution strategies to solve complex engineering problems. Genetic algorithms in particular became popular through the writing of John Henry Holland. Practical applications also include automatic evolution of computer programmes. Evolutionary algorithms are now used to solve multi-dimensional problems more efficiently than software produced by human designers and also to optimise the design of systems.\nEvolutionary history of life.\nOrigin of life.\nThe Earth is about 4.54\u00a0billion years old. The earliest undisputed evidence of life on Earth dates from at least 3.5\u00a0billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon. Microbial mat fossils have been found in 3.48\u00a0billion-year-old sandstone in Western Australia. Other early physical evidence of a biogenic substance is graphite in 3.7\u00a0billion-year-old metasedimentary rocks discovered in Western Greenland as well as \"remains of biotic life\" found in 4.1\u00a0billion-year-old rocks in Western Australia. Commenting on the Australian findings, Stephen Blair Hedges wrote: \"If life arose relatively quickly on Earth, then it could be common in the universe.\" In July 2016, scientists reported identifying a set of 355 genes from the last universal common ancestor (LUCA) of all organisms living on Earth.\nMore than 99% of all species, amounting to over five billion species, that ever lived on Earth are estimated to be extinct. Estimates on the number of Earth's current species range from 10\u00a0million to 14\u00a0million, of which about 1.9\u00a0million are estimated to have been named and 1.6\u00a0million documented in a central database to date, leaving at least 80% not yet described.\nHighly energetic chemistry is thought to have produced a self-replicating molecule around 4\u00a0billion years ago, and half a billion years later the last common ancestor of all life existed. The current scientific consensus is that the complex biochemistry that makes up life came from simpler chemical reactions. The beginning of life may have included self-replicating molecules such as RNA and the assembly of simple cells.\nCommon descent.\nAll organisms on Earth are descended from a common ancestor or ancestral gene pool. Current species are a stage in the process of evolution, with their diversity the product of a long series of speciation and extinction events. The common descent of organisms was first deduced from four simple facts about organisms: First, they have geographic distributions that cannot be explained by local adaptation. Second, the diversity of life is not a set of completely unique organisms, but organisms that share morphological similarities. Third, vestigial traits with no clear purpose resemble functional ancestral traits. Fourth, organisms can be classified using these similarities into a hierarchy of nested groups, similar to a family tree.\nDue to horizontal gene transfer, this \"tree of life\" may be more complicated than a simple branching tree, since some genes have spread independently between distantly related species. To solve this problem and others, some authors prefer to use the \"Coral of life\" as a metaphor or a mathematical model to illustrate the evolution of life. This view dates back to an idea briefly mentioned by Darwin but later abandoned.\nPast species have also left records of their evolutionary history. Fossils, along with the comparative anatomy of present-day organisms, constitute the morphological, or anatomical, record. By comparing the anatomies of both modern and extinct species, palaeontologists can infer the lineages of those species. However, this approach is most successful for organisms that had hard body parts, such as shells, bones or teeth. Further, as prokaryotes such as bacteria and archaea share a limited set of common morphologies, their fossils do not provide information on their ancestry.\nMore recently, evidence for common descent has come from the study of biochemical similarities between organisms. For example, all living cells use the same basic set of nucleotides and amino acids. The development of molecular genetics has revealed the record of evolution left in organisms' genomes: dating when species diverged through the molecular clock produced by mutations. For example, these DNA sequence comparisons have revealed that humans and chimpanzees share 98% of their genomes and analysing the few areas where they differ helps shed light on when the common ancestor of these species existed.\nEvolution of life.\nProkaryotes inhabited the Earth from approximately 3\u20134\u00a0billion years ago. No obvious changes in morphology or cellular organisation occurred in these organisms over the next few billion years. The eukaryotic cells emerged between 1.6 and 2.7\u00a0billion years ago. The next major change in cell structure came when bacteria were engulfed by eukaryotic cells, in a cooperative association called endosymbiosis. The engulfed bacteria and the host cell then underwent coevolution, with the bacteria evolving into either mitochondria or hydrogenosomes. Another engulfment of cyanobacterial-like organisms led to the formation of chloroplasts in algae and plants.\nThe history of life was that of the unicellular eukaryotes, prokaryotes and archaea until about 610\u00a0million years ago when multicellular organisms began to appear in the oceans in the Ediacaran period. The evolution of multicellularity occurred in multiple independent events, in organisms as diverse as sponges, brown algae, cyanobacteria, slime moulds and myxobacteria. In January 2016, scientists reported that, about 800\u00a0million years ago, a minor genetic change in a single molecule called GK-PID may have allowed organisms to go from a single cell organism to one of many cells.\nSoon after the emergence of these first multicellular organisms, a remarkable amount of biological diversity appeared over approximately 10\u00a0million years, in an event called the Cambrian explosion. Here, the majority of types of modern animals appeared in the fossil record, as well as unique lineages that subsequently became extinct. Various triggers for the Cambrian explosion have been proposed, including the accumulation of oxygen in the atmosphere from photosynthesis.\nAbout 500\u00a0million years ago, plants and fungi colonised the land and were soon followed by arthropods and other animals. Insects were particularly successful and even today make up the majority of animal species. Amphibians first appeared around 364\u00a0million years ago, followed by early amniotes and birds around 155\u00a0million years ago (both from \"reptile\"-like lineages), mammals around 129\u00a0million years ago, Homininae around 10\u00a0million years ago and modern humans around 250,000 years ago. However, despite the evolution of these large animals, smaller organisms similar to the types that evolved early in this process continue to be highly successful and dominate the Earth, with the majority of both biomass and species being prokaryotes.\nHistory of evolutionary thought.\nClassical antiquity.\nThe proposal that one type of organism could descend from another type goes back to some of the first pre-Socratic Greek philosophers, such as Anaximander and Empedocles. Such proposals survived into Roman times. The poet and philosopher Lucretius followed Empedocles in his masterwork \"De rerum natura\" ().\nMiddle Ages.\nIn contrast to these materialistic views, Aristotelianism had considered all natural things as actualisations of fixed natural possibilities, known as forms. This became part of a medieval teleological understanding of nature in which all things have an intended role to play in a divine cosmic order. Variations of this idea became the standard understanding of the Middle Ages and were integrated into Christian learning, but Aristotle did not demand that real types of organisms always correspond one-for-one with exact metaphysical forms and specifically gave examples of how new types of living things could come to be.\nA number of Arab Muslim scholars wrote about evolution, most notably Ibn Khaldun, who wrote the book \"Muqaddimah\" in 1377 AD, in which he asserted that humans developed from \"the world of the monkeys\", in a process by which \"species become more numerous\".\nPre-Darwinian.\nThe \"New Science\" of the 17th century rejected the Aristotelian approach. It sought to explain natural phenomena in terms of physical laws that were the same for all visible things and that did not require the existence of any fixed natural categories or divine cosmic order. However, this new approach was slow to take root in the biological sciences: the last bastion of the concept of fixed natural types. John Ray applied one of the previously more general terms for fixed natural types, \"species\", to plant and animal types, but he strictly identified each type of living thing as a species and proposed that each species could be defined by the features that perpetuated themselves generation after generation. The biological classification introduced by Carl Linnaeus in 1735 explicitly recognised the hierarchical nature of species relationships, but still viewed species as fixed according to a divine plan.\nOther naturalists of this time speculated on the evolutionary change of species over time according to natural laws. In 1751, Pierre Louis Maupertuis wrote of natural modifications occurring during reproduction and accumulating over many generations to produce new species. Georges-Louis Leclerc, Comte de Buffon, suggested that species could degenerate into different organisms, and Erasmus Darwin proposed that all warm-blooded animals could have descended from a single microorganism (or \"filament\"). The first full-fledged evolutionary scheme was Jean-Baptiste Lamarck's \"transmutation\" theory of 1809, which envisaged spontaneous generation continually producing simple forms of life that developed greater complexity in parallel lineages with an inherent progressive tendency, and postulated that on a local level, these lineages adapted to the environment by inheriting changes caused by their use or disuse in parents. (The latter process was later called Lamarckism.) These ideas were condemned by established naturalists as speculation lacking empirical support. In particular, Georges Cuvier insisted that species were unrelated and fixed, their similarities reflecting divine design for functional needs. In the meantime, Ray's ideas of benevolent design had been developed by William Paley into the \"Natural Theology or Evidences of the Existence and Attributes of the Deity\" (1802), which proposed complex adaptations as evidence of divine design and which was admired by Charles Darwin.\nDarwinian revolution.\nThe crucial break from the concept of constant typological classes or types in biology came with the theory of evolution through natural selection, which was formulated by Charles Darwin and Alfred Wallace in terms of variable populations. Darwin used the expression \"descent with modification\" rather than \"evolution\". Partly influenced by \"An Essay on the Principle of Population\" (1798) by Thomas Robert Malthus, Darwin noted that population growth would lead to a \"struggle for existence\" in which favourable variations prevailed as others perished. In each generation, many offspring fail to survive to an age of reproduction because of limited resources. This could explain the diversity of plants and animals from a common ancestry through the working of natural laws in the same way for all types of organism. Darwin developed his theory of \"natural selection\" from 1838 onwards and was writing up his \"big book\" on the subject when Alfred Russel Wallace sent him a version of virtually the same theory in 1858. Their separate papers were presented together at an 1858 meeting of the Linnean Society of London. At the end of 1859, Darwin's publication of his \"abstract\" as \"On the Origin of Species\" explained natural selection in detail and in a way that led to an increasingly wide acceptance of Darwin's concepts of evolution at the expense of alternative theories. Thomas Henry Huxley applied Darwin's ideas to humans, using paleontology and comparative anatomy to provide strong evidence that humans and apes shared a common ancestry. Some were disturbed by this since it implied that humans did not have a special place in the universe.\nOthniel C. Marsh, America\u2019s first paleontologist, was the first to provide solid fossil evidence to support Darwin\u2019s theory of evolution by unearthing the ancestors of the modern horse. In 1877, Marsh delivered a very influential speech before the annual meeting of the American Association for the Advancement of Science, providing a demonstrative argument for evolution. For the first time, Marsh traced the evolution of vertebrates from fish all the way through humans. Sparing no detail, he listed a wealth of fossil examples of past life forms. The significance of this speech was immediately recognized by the scientific community, and it was printed in its entirety in several scientific journals.\nIn 1880, Marsh caught the attention of the scientific world with the publication of \"Odontornithes: a Monograph on Extinct Birds of North America,\" which included his discoveries of birds with teeth. These skeletons helped bridge the gap between dinosaurs and birds, and provided invaluable support for Darwin's theory of evolution. Darwin wrote to Marsh saying, \"Your work on these old birds &amp; on the many fossil animals of N. America has afforded the best support to the theory of evolution, which has appeared within the last 20 years\" (since Darwin's publication of \"Origin of Species).\nPangenesis and heredity.\nThe mechanisms of reproductive heritability and the origin of new traits remained a mystery. Towards this end, Darwin developed his provisional theory of pangenesis. In 1865, Gregor Mendel reported that traits were inherited in a predictable manner through the independent assortment and segregation of elements (later known as genes). Mendel's laws of inheritance eventually supplanted most of Darwin's pangenesis theory. August Weismann made the important distinction between germ cells that give rise to gametes (such as sperm and egg cells) and the somatic cells of the body, demonstrating that heredity passes through the germ line only. Hugo de Vries connected Darwin's pangenesis theory to Weismann's germ/soma cell distinction and proposed that Darwin's pangenes were concentrated in the cell nucleus and when expressed they could move into the cytoplasm to change the cell's structure. De Vries was also one of the researchers who made Mendel's work well known, believing that Mendelian traits corresponded to the transfer of heritable variations along the germline. To explain how new variants originate, de Vries developed a mutation theory that led to a temporary rift between those who accepted Darwinian evolution and biometricians who allied with de Vries. In the 1930s, pioneers in the field of population genetics, such as Ronald Fisher, Sewall Wright and J. B. S. Haldane set the foundations of evolution onto a robust statistical philosophy. The false contradiction between Darwin's theory, genetic mutations, and Mendelian inheritance was thus reconciled.\nThe 'modern synthesis'.\nIn the 1920s and 1930s, the modern synthesis connected natural selection and population genetics, based on Mendelian inheritance, into a unified theory that included random genetic drift, mutation, and gene flow. This new version of evolutionary theory focused on changes in allele frequencies in population. It explained patterns observed across species in populations, through fossil transitions in palaeontology.\nFurther syntheses.\nSince then, further syntheses have extended evolution's explanatory power in the light of numerous discoveries, to cover biological phenomena across the whole of the biological hierarchy from genes to populations.\nThe publication of the structure of DNA by James Watson and Francis Crick with contribution of Rosalind Franklin in 1953 demonstrated a physical mechanism for inheritance. Molecular biology improved understanding of the relationship between genotype and phenotype. Advances were also made in phylogenetic systematics, mapping the transition of traits into a comparative and testable framework through the publication and use of evolutionary trees. In 1973, evolutionary biologist Theodosius Dobzhansky penned that \"nothing in biology makes sense except in the light of evolution\", because it has brought to light the relations of what first seemed disjointed facts in natural history into a coherent explanatory body of knowledge that describes and predicts many observable facts about life on this planet.\nOne extension, known as evolutionary developmental biology and informally called \"evo-devo\", emphasises how changes between generations (evolution) act on patterns of change within individual organisms (development). Since the beginning of the 21st century, some biologists have argued for an extended evolutionary synthesis, which would account for the effects of non-genetic inheritance modes, such as epigenetics, parental effects, ecological inheritance and cultural inheritance, and evolvability.\nSocial and cultural responses.\nIn the 19th century, particularly after the publication of \"On the Origin of Species\" in 1859, the idea that life had evolved was an active source of academic debate centred on the philosophical, social and religious implications of evolution. Today, the modern evolutionary synthesis is accepted by a vast majority of scientists. However, evolution remains a contentious concept for some theists.\nWhile various religions and denominations have reconciled their beliefs with evolution through concepts such as theistic evolution, there are creationists who believe that evolution is contradicted by the creation myths found in their religions and who raise various objections to evolution. As had been demonstrated by responses to the publication of \"Vestiges of the Natural History of Creation\" in 1844, the most controversial aspect of evolutionary biology is the implication of human evolution that humans share common ancestry with apes and that the mental and moral faculties of humanity have the same types of natural causes as other inherited traits in animals. In some countries, notably the United States, these tensions between science and religion have fuelled the current creation\u2013evolution controversy, a religious conflict focusing on politics and public education. While other scientific fields such as cosmology and Earth science also conflict with literal interpretations of many religious texts, evolutionary biology experiences significantly more opposition from religious literalists.\nThe teaching of evolution in American secondary school biology classes was uncommon in most of the first half of the 20th century. The Scopes Trial decision of 1925 caused the subject to become very rare in American secondary biology textbooks for a generation, but it was gradually re-introduced later and became legally protected with the 1968 \"Epperson v. Arkansas\" decision. Since then, the competing religious belief of creationism was legally disallowed in secondary school curricula in various decisions in the 1970s and 1980s, but it returned in pseudoscientific form as intelligent design (ID), to be excluded once again in the 2005 \"Kitzmiller v. Dover Area School District\" case. The debate over Darwin's ideas did not generate significant controversy in China."}
{"id": "9238", "revid": "32736747", "url": "https://en.wikipedia.org/wiki?curid=9238", "title": "Ernst Mayr", "text": "Ernst Walter Mayr ( , ; 5 July 1904 \u2013 3 February 2005) was a German-American evolutionary biologist. He was also a renowned taxonomist, tropical explorer, ornithologist, philosopher of biology, and historian of science. His work contributed to the conceptual revolution that led to the modern evolutionary synthesis of Mendelian genetics, systematics, and Darwinian evolution, and to the development of the biological species concept.\nAlthough Charles Darwin and others posited that multiple species could evolve from a single common ancestor, the mechanism by which this occurred was not understood, creating the \"species problem\". Ernst Mayr approached the problem with a new definition for species. In his book \"Systematics and the Origin of Species\" (1942) he wrote that a species is not just a group of morphologically similar individuals, but a group that can breed only among themselves, excluding all others. When populations within a species become isolated by geography, feeding strategy, mate choice, or other means, they may start to differ from other populations through genetic drift and natural selection, and over time may evolve into new species. The most significant and rapid genetic reorganization occurs in extremely small populations that have been isolated (as on islands).\nHis theory of peripatric speciation (a more precise form of allopatric speciation which he advanced), based on his work on birds, is still considered a leading mode of speciation, and was the theoretical underpinning for the theory of punctuated equilibrium, proposed by Niles Eldredge and Stephen Jay Gould. Mayr is sometimes credited with inventing modern philosophy of biology, particularly the part related to evolutionary biology, which he distinguished from physics due to its introduction of (natural) history into science.\nBiography.\nMayr was the second son of Helene Pusinelli and Otto Mayr. His father was a district prosecuting attorney at W\u00fcrzburg but took an interest in natural history and took the children out on field trips. Mayr learnt all the local birds in W\u00fcrzburg from his elder brother Otto. He also had access to a natural history magazine for amateurs, \"Kosmos\". His father died just before he was thirteen. The family then moved to Dresden, where he studied at the Staatsgymnasium in Dresden-Neustadt and completed his high school education. In April 1922, while still in high school, he joined the newly founded Saxony Ornithologists' Association. There he met Rudolf Zimmermann, who became his ornithological mentor. In February 1923, Mayr passed his high school examination (Abitur) and his mother rewarded him with a pair of binoculars.\nOn 23 March 1923 on one of the lakes of Moritzburg, the Frauenteich, he spotted what he identified as a red-crested pochard. The species had not been seen in Saxony since 1845 and the local club argued about the identity. Raimund Schelcher (1891\u20131979) of the club then suggested that Mayr visit his classmate Erwin Stresemann on his way to Greifswald, where Mayr was to begin his medical studies. After a tough interrogation, Stresemann accepted and published the sighting as authentic. Stresemann was very impressed and suggested that, between semesters, Mayr could work as a volunteer in the ornithological section of the museum. Mayr wrote about this event, \"It was as if someone had given me the key to heaven.\" He entered the University of Greifswald in 1923 and, according to Mayr himself, \"took the medical curriculum (to satisfy a family tradition) but after only a year, he decided to leave medicine and enrolled at the Faculty of Biological Sciences.\" Mayr was endlessly interested in ornithology and \"chose Greifswald at the Baltic for my studies for no other reason than that ... it was situated in the ornithologically most interesting area.\" Although he ostensibly planned to become a physician, he was \"first and foremost an ornithologist.\" During the first semester break Stresemann gave him a test to identify treecreepers and Mayr was able to identify most of the specimens correctly. Stresemann declared that Mayr \"was a born systematist\". In 1925, Stresemann suggested that he give up his medical studies, in fact he should leave the faculty of medicine and enrol into the faculty of Biology and then join the Berlin Museum with the prospect of bird-collecting trips to the tropics, on the condition that he completed his doctoral studies in 16 months. Mayr completed his doctorate in ornithology at the University of Berlin under Dr. Carl Zimmer, who was a full professor (Ordentlicher Professor), on 24 June 1926 at the age of 21. On 1 July he accepted the position offered to him at the museum for a monthly salary of 330.54 Reichsmark.\nAt the International Zoological Congress at Budapest in 1927, Mayr was introduced by Stresemann to banker and naturalist Walter Rothschild, who asked him to undertake an expedition to New Guinea on behalf of himself and the American Museum of Natural History in New York. In New Guinea, Mayr collected several thousand bird skins (he named 38 new bird species during his lifetime) and, in the process also named 38 new orchid species. During his stay in New Guinea, he was invited to accompany the Whitney South Sea Expedition to the Solomon Islands. Also, while in New Guinea, he visited the Lutheran missionaries Otto Thiele and Christian Keyser, in the Finschhafen district; there, while in conversation with his hosts, he uncovered the discrepancies in Hermann Detzner's popular book \"Four Years among Cannibals: New Guinea\", in which Detzner claimed to have seen the interior, discovered several species of flora and fauna, while remaining only steps ahead of the Australian patrols sent to capture him. He returned to Germany in 1930.\nMayr moved to the United States in 1931 to take up a curatorial position at the American Museum of Natural History, where he played the important role of brokering and acquiring the Walter Rothschild collection of bird skins, which was being sold in order to pay off a blackmailer. During his time at the museum he produced numerous publications on bird taxonomy, and in 1942 his first book \"Systematics and the Origin of Species\", which completed the evolutionary synthesis started by Darwin.\nAfter Mayr was appointed at the American Museum of Natural History, he influenced American ornithological research by mentoring young birdwatchers. Mayr was surprised at the differences between American and German birding societies. He noted that the German society was \"far more scientific, far more interested in life histories and breeding bird species, as well as in reports on recent literature.\"\nMayr organized a monthly seminar under the auspices of the Linnean Society of New York. Under the influence of J.A. Allen, Frank Chapman, and Jonathan Dwight, the society concentrated on taxonomy and later became a clearing house for bird banding and sight records.\nMayr encouraged his Linnaean Society seminar participants to take up a specific research project of their own. Under Mayr's influence one of them, Joseph Hickey, went on to write \"A Guide to Birdwatching\" (1943). Hickey remembered later, \"Mayr was our age and invited on all our field trips. The heckling of this German foreigner was tremendous, but he gave tit for tat, and any modern picture of Dr E. Mayr as a very formal person does not square with my memory of the 1930s. He held his own.\" A group of eight young birdwatchers from The Bronx later became the Bronx County Bird Club, led by Ludlow Griscom. \"Everyone should have a problem\" was the way one Bronx County Bird Club member recalled Mayr's refrain. Mayr said of his own involvement with the local birdwatchers: \"In those early years in New York when I was a stranger in a big city, it was the companionship and later friendship which I was offered in the Linnean Society that was the most important thing in my life.\"\nMayr also greatly influenced the American ornithologist Margaret Morse Nice. Mayr encouraged her to correspond with European ornithologists and helped her in her landmark study on song sparrows. Nice wrote to Joseph Grinnell in 1932, trying to get foreign literature reviewed in the \"Condor\": \"Too many American ornithologists have despised the study of the living bird; the magazines and books that deal with the subject abound in careless statements, anthropomorphic interpretations, repetition of ancient errors, and sweeping conclusions from a pitiful array of facts.\u00a0 ... in Europe the study of the living bird is taken seriously. We could learn a great deal from their writing.\" Mayr ensured that Nice could publish her two-volume \"Studies in the Life History of the Song Sparrow\". He found her a publisher, and her book was reviewed by Aldo Leopold, Joseph Grinnell, and Jean Delacour. Nice dedicated her book to \"My Friend Ernst Mayr.\"\nMayr joined the faculty of Harvard University in 1953, where he also served as director of the Museum of Comparative Zoology from 1961 to 1970. He retired in 1975 as emeritus professor of zoology, showered with honors. Following his retirement, he went on to publish more than 200 articles, in a variety of journals\u2014more than some reputable scientists publish in their entire careers; 14 of his 25 books were published after he was 65. Even as a centenarian, he continued to write books. On his 100th birthday, he was interviewed by \"Scientific American\" magazine.\nMayr died on 3 February 2005 in his retirement home in Bedford, Massachusetts, after a short illness. He had married fellow German Margarete \"Gretel\" Simon in May 1935 (they had met at a party in Manhattan in 1932), and she assisted Mayr in some of his work.\nMargarete died in 1990. He was survived by two daughters (Christa Menzel and Susanne Harrison), five grandchildren and 10 great-grandchildren.\nThe awards that Mayr received include the National Medal of Science, the Balzan Prize, the Sarton Medal of the History of Science Society, the International Prize for Biology, the Loye and Alden Miller Research Award, and the Lewis Thomas Prize for Writing about Science. In 1939 he was elected a Corresponding Member of the Royal Australasian Ornithologists Union. He was awarded the 1946 Leidy Award from the Academy of Natural Sciences of Philadelphia. He was awarded the Linnean Society of London's prestigious Darwin-Wallace Medal in 1958 and the Linnaean Society of New York's inaugural Eisenmann Medal in 1983. For his work, \"Animal Species and Evolution\", he was awarded the Daniel Giraud Elliot Medal from the National Academy of Sciences in 1967. Mayr was elected a Foreign Member of the Royal Society (ForMemRS) in 1988. In 1995 he received the Benjamin Franklin Medal for Distinguished Achievement in the Sciences of the American Philosophical Society, of which he was already a member.\nMayr never won a Nobel Prize, but he noted that there is no prize for evolutionary biology and that Darwin would not have received one, either. (In fact, there is no Nobel Prize for biology.) Mayr did win a 1999 Crafoord Prize. It honors basic research in fields that do not qualify for Nobel Prizes and is administered by the same organization as the Nobel Prize. In 2001, Mayr received the Golden Plate Award of the American Academy of Achievement. Since winning Balzan Prize, Crafoord Prize and the International Prize for Biology, are usually regarded as a \"Triple Crown in Biology,\" he won this crown too.\nMayr was co-author of six global reviews of bird species new to science (listed below).\nMayr said he was an atheist in regards to \"the idea of a personal God\" because \"there is nothing that supports [it]\".\nIdeas.\nAs a traditionally-trained biologist, Mayr was often highly critical of early mathematical approaches to evolution, such as those of J.B.S. Haldane, and famously called such approaches \"beanbag genetics\" in 1959. He maintained that factors such as reproductive isolation had to be taken into account. In a similar fashion, Mayr was also quite critical of molecular evolution studies such as those of Carl Woese. Current molecular studies in evolution and speciation indicate that although allopatric speciation is the norm, there are numerous cases of sympatric speciation in groups with greater mobility, such as birds. The precise mechanisms of sympatric speciation, however, are usually a form of microallopatry enabled by variations in niche occupancy among individuals within a population.\nIn many of his writings, Mayr rejected reductionism in evolutionary biology, arguing that evolutionary pressures act on the whole organism, not on single genes, and that genes can have different effects depending on the other genes present. He advocated a study of the whole genome, rather than of only isolated genes. After articulating the biological species concept in 1942, Mayr played a central role in the species problem debate over what was the best species concept. He staunchly defended the biological species concept against the many definitions of \"species\" that others proposed.\nMayr was an outspoken defender of the scientific method and was known to critique sharply science on the edge. As a notable example, in 1995, he criticized the Search for Extra-Terrestrial Intelligence (SETI), as conducted by fellow Harvard professor Paul Horowitz, as being a waste of university and student resources for its inability to address and answer a scientific question. Over 60 eminent scientists, led by Carl Sagan, rebutted the criticism.\nMayr rejected the idea of a gene-centered view of evolution and starkly but politely criticised Richard Dawkins's ideas:\nMayr insisted that the entire genome should be considered as the target of selection, rather than individual genes:\nSummary of Darwin's theory.\nDarwin's theory of evolution is based on key facts and the inferences drawn from them, which Mayr summarised as follows:\nIn relation to the publication of Darwin's \"Origins of Species\", Mayr identified philosophical implications of evolution:"}
{"id": "9239", "revid": "2790592", "url": "https://en.wikipedia.org/wiki?curid=9239", "title": "Europe", "text": "Europe is a continent located entirely in the Northern Hemisphere and mostly in the Eastern Hemisphere. It is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, the Mediterranean Sea to the south, and Asia to the east. Europe shares the landmass of Eurasia with Asia, and of Afro-Eurasia with both Africa and Asia. Europe is commonly considered to be separated from Asia by the watershed of the Ural Mountains, the Ural River, the Caspian Sea, the Greater Caucasus, the Black Sea, and the waterway of the Bosporus Strait.\nEurope covers approx. , or 2% of Earth's surface (6.8% of Earth's land area), making it the second-smallest continent (using the seven-continent model). Politically, Europe is divided into about fifty sovereign states, of which Russia is the largest and most populous, spanning 39% of the continent and comprising 15% of its population. Europe had a total population of about million (about 10% of the world population) in ; the third-largest after Asia and Africa. The European climate is affected by warm Atlantic currents, such as the Gulf Stream, which produce a temperate climate, tempering winters and summers, on much of the continent. Further from the sea, seasonal differences are more noticeable producing more continental climates.\nThe culture of Europe consists of a range of national and regional cultures, which form the central roots of the wider Western civilisation, and together commonly reference ancient Greece and ancient Rome, particularly through their Christian successors, as crucial and shared roots. Beginning with the fall of the Western Roman Empire in 476 CE, Christian consolidation of Europe in the wake of the Migration Period marked the European post-classical Middle Ages. The Italian Renaissance spread in the continent a new humanist interest in art and science which led to the modern era. Since the Age of Discovery, led by Spain and Portugal, Europe played a predominant role in global affairs with multiple explorations and conquests around the world. Between the 16th and 20th centuries, European powers colonised at various times the Americas, almost all of Africa and Oceania, and the majority of Asia.\nThe Age of Enlightenment, the French Revolution, and the Napoleonic Wars shaped the continent culturally, politically, and economically from the end of the 17th century until the first half of the 19th century. The Industrial Revolution, which began in Great Britain at the end of the 18th century, gave rise to radical economic, cultural, and social change in Western Europe and eventually the wider world. Both world wars began and were fought to a great extent in Europe, contributing to a decline in Western European dominance in world affairs by the mid-20th century as the Soviet Union and the United States took prominence and competed over dominance in Europe and globally. The resulting Cold War divided Europe along the Iron Curtain, with NATO in the West and the Warsaw Pact in the East. This divide ended with the Revolutions of 1989, the fall of the Berlin Wall, and the dissolution of the Soviet Union, which allowed European integration to advance significantly.\nEuropean integration has been advanced institutionally since 1948 with the founding of the Council of Europe, and significantly through the realisation of the European Union (EU), which represents today the majority of Europe. The European Union is a supranational political entity that lies between a confederation and a federation and is based on a system of European treaties. The EU originated in Western Europe but has been expanding eastward since the dissolution of the Soviet Union in 1991. A majority of its members have adopted a common currency, the euro, and participate in the European single market and a customs union. A large bloc of countries, the Schengen Area, have also abolished internal border and immigration controls. Regular popular elections take place every five years within the EU; they are considered to be the second-largest democratic elections in the world after India's. The EU is the third-largest economy in the world.\nName.\nThe place name Evros was first used by the ancient Greeks to refer to their northernmost province, which bears the same name today. The principal river there \u2013 Evros (today's Maritsa) \u2013 flows through the fertile valleys of Thrace, which itself was also called Europe, before the term meant the continent.\nIn classical Greek mythology, Europa (, ) was a Phoenician princess. One view is that her name derives from the Ancient Greek elements () 'wide, broad', and (, , ) 'eye, face, countenance', hence their composite would mean 'wide-gazing' or 'broad of aspect'. \"Broad\" has been an epithet of Earth herself in the reconstructed Proto-Indo-European religion and the poetry devoted to it. An alternative view is that of Robert Beekes, who has argued in favour of a pre-Indo-European origin for the name, explaining that a derivation from would yield a different toponym than Europa. Beekes has located toponyms related to that of Europa in the territory of ancient Greece, and localities such as that of Europos in ancient Macedonia.\nThere have been attempts to connect to a Semitic term for \"west\", this being either Akkadian meaning 'to go down, set' (said of the sun) or Phoenician 'evening, west', which is at the origin of Arabic and Hebrew . Martin Litchfield West stated that \"phonologically, the match between Europa's name and any form of the Semitic word is very poor\", while Beekes considers a connection to Semitic languages improbable.\nMost major world languages use words derived from or \"Europa\" to refer to the continent. Chinese, for example, uses the word (/), which is an abbreviation of the transliterated name () ( means \"continent\"); a similar Chinese-derived term is also sometimes used in Japanese such as in the Japanese name of the European Union, , despite the katakana being more commonly used. In some Turkic languages, the originally Persian name (\"land of the Franks\") is used casually in referring to much of Europe, besides official names such as or .\nDefinition.\nContemporary definition.\nThe prevalent definition of Europe as a geographical term has been in use since the mid-19th century.\nEurope is taken to be bounded by large bodies of water to the north, west and south; Europe's limits to the east and north-east are usually taken to be the Ural Mountains, the Ural River, and the Caspian Sea; to the south-east, the Caucasus Mountains, the Black Sea, and the waterways connecting the Black Sea to the Mediterranean Sea.\nIslands are generally grouped with the nearest continental landmass, hence Iceland is considered to be part of Europe, while the nearby island of Greenland is usually assigned to North America, although politically belonging to Denmark. Nevertheless, there are some exceptions based on sociopolitical and cultural differences. Cyprus is closest to Anatolia (or Asia Minor), but is considered part of Europe politically and it is a member state of the EU. Malta was considered an island of North-western Africa for centuries, but now it is considered to be part of Europe as well. \"Europe\", as used specifically in British English, may also refer to Continental Europe exclusively.\nThe term \"continent\" usually implies the physical geography of a large land mass completely or almost completely surrounded by water at its borders. Prior to the adoption of the current convention that includes mountain divides, the border between Europe and Asia had been redefined several times since its first conception in classical antiquity, but always as a series of rivers, seas and straits that were believed to extend an unknown distance east and north from the Mediterranean Sea without the inclusion of any mountain ranges. Cartographer Herman Moll suggested in 1715 Europe was bounded by a series of partly-joined waterways directed towards the Turkish straits, and the Irtysh River draining into the upper part of the Ob River and the Arctic Ocean. In contrast, the present eastern boundary of Europe partially adheres to the Ural and Caucasus Mountains, which is somewhat arbitrary and inconsistent compared to any clear-cut definition of the term \"continent\".\nThe current division of Eurasia into two continents now reflects East-West cultural, linguistic and ethnic differences which vary on a spectrum rather than with a sharp dividing line. The geographic border between Europe and Asia does not follow any state boundaries and now only follows a few bodies of water. Turkey is generally considered a transcontinental country divided entirely by water, while Russia and Kazakhstan are only partly divided by waterways. France, the Netherlands, Portugal and Spain are also transcontinental (or more properly, intercontinental, when oceans or large seas are involved) in that their main land areas are in Europe while pockets of their territories are located on other continents separated from Europe by large bodies of water. Spain, for example, has territories south of the Mediterranean Sea\u2014namely, Ceuta and Melilla\u2014which are parts of Africa and share a border with Morocco. According to the current convention, Georgia and Azerbaijan are transcontinental countries where waterways have been completely replaced by mountains as the divide between continents.\nHistory of the concept.\nEarly history.\nThe first recorded usage of \"Eur\u1e53p\u0113\" as a geographic term is in the Homeric Hymn to Delian Apollo, in reference to the western shore of the Aegean Sea. As a name for a part of the known world, it is first used in the 6th century BCE by Anaximander and Hecataeus. Anaximander placed the boundary between Asia and Europe along the Phasis River (the modern Rioni River on the territory of Georgia) in the Caucasus, a convention still followed by Herodotus in the 5th century BCE. Herodotus mentioned that the world had been divided by unknown persons into three parts\u2014Europe, Asia, and Libya (Africa)\u2014with the Nile and the Phasis forming their boundaries\u2014though he also states that some considered the River Don, rather than the Phasis, as the boundary between Europe and Asia. Europe's eastern frontier was defined in the 1st century by geographer Strabo at the River Don. The \"Book of Jubilees\" described the continents as the lands given by Noah to his three sons; Europe was defined as stretching from the Pillars of Hercules at the Strait of Gibraltar, separating it from Northwest Africa, to the Don, separating it from Asia.\nThe convention received by the Middle Ages and surviving into modern usage is that of the Roman era used by Roman-era authors such as Posidonius, Strabo, and Ptolemy, who took the Tanais (the modern Don River) as the boundary.\nThe Roman Empire did not attach a strong identity to the concept of continental divisions. However, following the fall of the Western Roman Empire, the culture that developed in its place, linked to Latin and the Catholic church, began to associate itself with the concept of \"Europe\". The term \"Europe\" is first used for a cultural sphere in the Carolingian Renaissance of the 9th century. From that time, the term designated the sphere of influence of the Western Church, as opposed to both the Eastern Orthodox churches and to the Islamic world.\nA cultural definition of Europe as the lands of Latin Christendom coalesced in the 8th century, signifying the new cultural condominium created through the confluence of Germanic traditions and Christian-Latin culture, defined partly in contrast with Byzantium and Islam, and limited to northern Iberia, the British Isles, France, Christianised western Germany, the Alpine regions and northern and central Italy. The concept is one of the lasting legacies of the Carolingian Renaissance: \"Europa\" often figures in the letters of Charlemagne's court scholar, Alcuin. The transition of Europe to being a cultural term as well as a geographic one led to the borders of Europe being affected by cultural considerations in the East, especially relating to areas under Byzantine, Ottoman, and Russian influence. Such questions were affected by the positive connotations associated with the term Europe by its users. Such cultural considerations were not applied to the Americas, despite their conquest and settlement by European states. Instead, the concept of \"Western civilisation\" emerged as a way of grouping together Europe and these colonies.\nModern definitions.\nThe question of defining a precise eastern boundary of Europe arises in the Early Modern period, as the eastern extension of Muscovy began to include North Asia. Throughout the Middle Ages and into the 18th century, the traditional division of the landmass of Eurasia into two continents, Europe and Asia, followed Ptolemy, with the boundary following the Turkish Straits, the Black Sea, the Kerch Strait, the Sea of Azov and the Don (ancient Tanais). But maps produced during the 16th to 18th centuries tended to differ in how to continue the boundary beyond the Don bend at Kalach-na-Donu (where it is closest to the Volga, now joined with it by the Volga\u2013Don Canal), into territory not described in any detail by the ancient geographers.\nAround 1715, Herman Moll produced a map showing the northern part of the Ob River and the Irtysh River, a major tributary of the Ob, as components of a series of partly-joined waterways taking the boundary between Europe and Asia from the Turkish Straits, and the Don River all the way to the Arctic Ocean. In 1721, he produced a more up to date map that was easier to read. However, his proposal to adhere to major rivers as the line of demarcation was never taken up by other geographers who were beginning to move away from the idea of water boundaries as the only legitimate divides between Europe and Asia.\nFour years later, in 1725, Philip Johan von Strahlenberg was the first to depart from the classical Don boundary. He drew a new line along the Volga, following the Volga north until the Samara Bend, along Obshchy Syrt (the drainage divide between the Volga and Ural Rivers), then north and east along the latter waterway to its source in the Ural Mountains. At this point he proposed that mountain ranges could be included as boundaries between continents as alternatives to nearby waterways. Accordingly, he drew the new boundary north along Ural Mountains rather than the nearby and parallel running Ob and Irtysh rivers. This was endorsed by the Russian Empire and introduced the convention that would eventually become commonly accepted. However, this did not come without criticism. Voltaire, writing in 1760 about Peter the Great's efforts to make Russia more European, ignored the whole boundary question with his claim that neither Russia, Scandinavia, northern Germany, nor Poland were fully part of Europe. Since then, many modern analytical geographers like Halford Mackinder have declared that they see little validity in the Ural Mountains as a boundary between continents.\nThe mapmakers continued to differ on the boundary between the lower Don and Samara well into the 19th century. The published by the Russian Academy of Sciences has the boundary follow the Don beyond Kalach as far as Serafimovich before cutting north towards Arkhangelsk, while other 18th- to 19th-century mapmakers such as John Cary followed Strahlenberg's prescription. To the south, the Kuma\u2013Manych Depression was identified by a German naturalist, Peter Simon Pallas, as a valley that once connected the Black Sea and the Caspian Sea, and subsequently was proposed as a natural boundary between continents.\nBy the mid-19th century, there were three main conventions, one following the Don, the Volga\u2013Don Canal and the Volga, the other following the Kuma\u2013Manych Depression to the Caspian and then the Ural River, and the third abandoning the Don altogether, following the Greater Caucasus watershed to the Caspian. The question was still treated as a \"controversy\" in geographical literature of the 1860s, with Douglas Freshfield advocating the Caucasus crest boundary as the \"best possible\", citing support from various \"modern geographers\".\nIn Russia and the Soviet Union, the boundary along the Kuma\u2013Manych Depression was the most commonly used as early as 1906. In 1958, the Soviet Geographical Society formally recommended that the boundary between the Europe and Asia be drawn in textbooks from Baydaratskaya Bay, on the Kara Sea, along the eastern foot of Ural Mountains, then following the Ural River until the Mugodzhar Hills, and then the Emba River; and Kuma\u2013Manych Depression, thus placing the Caucasus entirely in Asia and the Urals entirely in Europe. The \"Flora Europaea\" adopted a boundary along the Terek and Kuban rivers, so southwards from the Kuma and the Manych, but still with the Caucasus entirely in Asia. However, most geographers in the Soviet Union favoured the boundary along the Caucasus crest, and this became the common convention in the later 20th century, although the Kuma\u2013Manych boundary remained in use in some 20th-century maps.\nSome view the separation of Eurasia into Asia and Europe as a residue of Eurocentrism: \"In physical, cultural and historical diversity, China and India are comparable to the entire European landmass, not to a single European country. [...].\"\nHistory.\nPrehistory.\nDuring the 2.5 million years of the Pleistocene, numerous cold phases called glacials (Quaternary ice age), or significant advances of continental ice sheets, in Europe and North America, occurred at intervals of approximately 40,000 to 100,000 years. The long glacial periods were separated by more temperate and shorter interglacials which lasted about 10,000\u201315,000 years. The last cold episode of the last glacial period ended about 10,000 years ago. Earth is currently in an interglacial period of the Quaternary, called the Holocene.\n\"Homo erectus georgicus\", which lived roughly 1.8 million years ago in Georgia, is the earliest hominin to have been discovered in Europe. Other hominin remains, dating back roughly 1 million years, have been discovered in Atapuerca, Spain. Neanderthal man (named after the Neandertal valley in Germany) appeared in Europe 150,000 years ago (115,000 years ago it is found already in the territory of present-day Poland) and disappeared from the fossil record about 40,000 years ago, with their final refuge being the Iberian Peninsula. The Neanderthals were supplanted by modern humans (Cro-Magnons), who seem to have appeared in Europe around 43,000 to 40,000 years ago. However, there is also evidence that Homo sapiens arrived in Europe around 54,000 years ago, some 10,000 years earlier than previously thought. The earliest sites in Europe dated 48,000 years ago are Riparo Mochi (Italy), Geissenkl\u00f6sterle (Germany) and Isturitz (France).\nThe European Neolithic period\u2014marked by the cultivation of crops and the raising of livestock, increased numbers of settlements and the widespread use of pottery\u2014began around 7000 BCE in Greece and the Balkans, probably influenced by earlier farming practices in Anatolia and the Near East. It spread from the Balkans along the valleys of the Danube and the Rhine (Linear Pottery culture), and along the Mediterranean coast (Cardial culture). Between 4500 and 3000 BCE, these central European neolithic cultures developed further to the west and the north, transmitting newly acquired skills in producing copper artifacts. In Western Europe the Neolithic period was characterised not by large agricultural settlements but by field monuments, such as causewayed enclosures, burial mounds and megalithic tombs. The Corded Ware cultural horizon flourished at the transition from the Neolithic to the Chalcolithic. During this period giant megalithic monuments, such as the Megalithic Temples of Malta and Stonehenge, were constructed throughout Western and Southern Europe.\nThe modern native populations of Europe largely descend from three distinct lineages: Mesolithic hunter-gatherers, descended from populations associated with the Paleolithic Epigravettian culture; Neolithic Early European Farmers who migrated from Anatolia during the Neolithic Revolution 9,000 years ago; and Yamnaya Steppe herders who expanded into Europe from the Pontic\u2013Caspian steppe of Ukraine and southern Russia in the context of Indo-European migrations 5,000 years ago. The European Bronze Age began c. 3200 BCE in Greece with the Minoan civilisation on Crete, the first advanced civilisation in Europe. The Minoans were followed by the Myceneans, who collapsed suddenly around 1200 BCE, ushering the European Iron Age. Iron Age colonisation by the Greeks and Phoenicians gave rise to early Mediterranean cities. Early Iron Age Italy and Greece from around the 8th century BCE gradually gave rise to historical Classical antiquity, whose beginning is sometimes dated to 776 BCE, the year of the first Olympic Games.\nClassical antiquity.\nAncient Greece was the founding culture of Western civilisation. Western democratic and rationalist culture are often attributed to Ancient Greece. The Greek city-state, the polis, was the fundamental political unit of classical Greece. In 508 BCE, Cleisthenes instituted the world's first democratic system of government in Athens. The Greek political ideals were rediscovered in the late 18th century by European philosophers and idealists. Greece also generated many cultural contributions: in philosophy, humanism and rationalism under Aristotle, Socrates and Plato; in history with Herodotus and Thucydides; in dramatic and narrative verse, starting with the epic poems of Homer; in drama with Sophocles and Euripides; in medicine with Hippocrates and Galen; and in science with Pythagoras, Euclid, and Archimedes. In the course of the 5th century BCE, several of the Greek city states would ultimately check the Achaemenid Persian advance in Europe through the Greco-Persian Wars, considered a pivotal moment in world history, as the 50 years of peace that followed are known as Golden Age of Athens, the seminal period of ancient Greece that laid many of the foundations of Western civilisation.\nGreece was followed by Rome, which left its mark on law, politics, language, engineering, architecture, government, and many more key aspects in western civilisation. By 200 BCE, Rome had conquered Italy and over the following two centuries it conquered Greece, Hispania (Spain and Portugal), the North African coast, much of the Middle East, Gaul (France and Belgium), and Britannia (England and Wales).\nExpanding from their base in central Italy beginning in the third century BCE, the Romans gradually expanded to eventually rule the entire Mediterranean basin and Western Europe by the turn of the millennium. The Roman Republic ended in 27 BCE, when Augustus proclaimed the Roman Empire. The two centuries that followed are known as the \"pax romana\", a period of unprecedented peace, prosperity and political stability in most of Europe. The empire continued to expand under emperors such as Antoninus Pius and Marcus Aurelius, who spent time on the Empire's northern border fighting Germanic, Pictish and Scottish tribes. Christianity was legalised by Constantine I in 313 CE after three centuries of imperial persecution. Constantine also permanently moved the capital of the empire from Rome to the city of Byzantium (modern-day Istanbul) which was renamed Constantinople in his honour in 330 CE. Christianity became the sole official religion of the empire in 380 CE, and in 391\u2013392 CE the emperor Theodosius outlawed pagan religions. This is sometimes considered to mark the end of antiquity; alternatively antiquity is considered to end with the fall of the Western Roman Empire in 476 CE; the closure of the pagan Platonic Academy of Athens in 529 CE; or the rise of Islam in the early 7th century CE. During most of its existence, the Byzantine Empire was one of the most powerful economic, cultural, and military forces in Europe.\nEarly Middle Ages.\nDuring the decline of the Roman Empire, Europe entered a long period of change arising from what historians call the \"Age of Migrations\". There were numerous invasions and migrations amongst the Ostrogoths, Visigoths, Goths, Vandals, Huns, Franks, Angles, Saxons, Slavs, Avars, Bulgars, Vikings, Pechenegs, Cumans, and Magyars. Renaissance thinkers such as Petrarch would later refer to this as the \"Dark Ages\".\nIsolated monastic communities were the only places to safeguard and compile written knowledge accumulated previously; apart from this, very few written records survive. Much literature, philosophy, mathematics, and other thinking from the classical period disappeared from Western Europe, though they were preserved in the east, in the Byzantine Empire.\nWhile the Roman empire in the west continued to decline, Roman traditions and the Roman state remained strong in the predominantly Greek-speaking Eastern Roman Empire, also known as the Byzantine Empire. During most of its existence, the Byzantine Empire was the most powerful economic, cultural, and military force in Europe. Emperor Justinian I presided over Constantinople's first golden age: he established a legal code that forms the basis of many modern legal systems, funded the construction of the Hagia Sophia and brought the Christian church under state control.\nFrom the 7th century onwards, as the Byzantines and neighbouring Sasanid Persians were severely weakened due to the protracted, centuries-lasting and frequent Byzantine\u2013Sasanian wars, the Muslim Arabs began to make inroads into historically Roman territory, taking the Levant and North Africa and making inroads into Asia Minor. In the mid-7th century, following the Muslim conquest of Persia, Islam penetrated into the Caucasus region. Over the next centuries Muslim forces took Cyprus, Malta, Crete, Sicily, and parts of southern Italy. Between 711 and 720, most of the lands of the Visigothic Kingdom of Iberia were brought under Muslim rule\u2014save for small areas in the northwest (Asturias) and largely Basque regions in the Pyrenees. This territory, under the Arabic name Al-Andalus, became part of the expanding Umayyad Caliphate. The unsuccessful second siege of Constantinople (717) weakened the Umayyad dynasty and reduced their prestige. The Umayyads were then defeated by the Frankish leader Charles Martel at the Battle of Poitiers in 732, which ended their northward advance. In the remote regions of north-western Iberia and the middle Pyrenees the power of the Muslims in the south was scarcely felt. It was here that the foundations of the Christian kingdoms of Asturias, Leon, and Galicia were laid and from where the reconquest of the Iberian Peninsula would start. However, no coordinated attempt would be made to drive the Moors out. The Christian kingdoms were mainly focused on their own internal power struggles. As a result, the Reconquista took the greater part of eight hundred years, in which period a long list of Alfonsos, Sanchos, Ordo\u00f1os, Ramiros, Fernandos, and Bermudos would be fighting their Christian rivals as much as the Muslim invaders.\nDuring the Dark Ages, the Western Roman Empire fell under the control of various tribes. The Germanic and Slav tribes established their domains over Western and Eastern Europe, respectively. Eventually the Frankish tribes were united under Clovis I. Charlemagne, a Frankish king of the Carolingian dynasty who had conquered most of Western Europe, was anointed \"Holy Roman Emperor\" by the Pope in 800. This led in 962 to the founding of the Holy Roman Empire, which eventually became centred in the German principalities of central Europe.\nEast Central Europe saw the creation of the first Slavic states and the adoption of Christianity (. The powerful West Slavic state of Great Moravia spread its territory all the way south to the Balkans, reaching its largest territorial extent under Svatopluk I and causing a series of armed conflicts with East Francia. Further south, the first South Slavic states emerged in the late 7th and 8th century and adopted Christianity: the First Bulgarian Empire, the Serbian Principality (later Kingdom and Empire), and the Duchy of Croatia (later Kingdom of Croatia). To the east, Kievan Rus' expanded from its capital in Kiev to become the largest state in Europe by the 10th century. In 988, Vladimir the Great adopted Orthodox Christianity as the religion of state. Further east, Volga Bulgaria became an Islamic state in the 10th century, but was eventually absorbed into Russia several centuries later.\nHigh and Late Middle Ages.\nThe period between the year 1000 and 1250 is known as the High Middle Ages, followed by the Late Middle Ages until c. 1500.\nDuring the High Middle Ages the population of Europe experienced significant growth, culminating in the Renaissance of the 12th century. Economic growth, together with the lack of safety on the mainland trading routes, made possible the development of major commercial routes along the coast of the Mediterranean and Baltic Seas. The growing wealth and independence acquired by some coastal cities gave the Maritime Republics a leading role in the European scene.\nThe Middle Ages on the mainland were dominated by the two upper echelons of the social structure: the nobility and the clergy. Feudalism developed in France in the Early Middle Ages, and soon spread throughout Europe. A struggle for influence between the nobility and the monarchy in England led to the writing of Magna Carta and the establishment of a parliament. The primary source of culture in this period came from the Roman Catholic Church. Through monasteries and cathedral schools, the Church was responsible for education in much of Europe.\nThe Papacy reached the height of its power during the High Middle Ages. An East-West Schism in 1054 split the former Roman Empire religiously, with the Eastern Orthodox Church in the Byzantine Empire and the Roman Catholic Church in the former Western Roman Empire. In 1095 Pope Urban II called for a crusade against Muslims occupying Jerusalem and the Holy Land. In Europe itself, the Church organised the Inquisition against heretics. In the Iberian Peninsula, the Reconquista concluded with the fall of Granada in 1492, ending over seven centuries of Islamic rule in the south-western peninsula.\nIn the east, a resurgent Byzantine Empire recaptured Crete and Cyprus from the Muslims, and reconquered the Balkans. Constantinople was the largest and wealthiest city in Europe from the 9th to the 12th centuries, with a population of approximately 400,000. The Empire was weakened following the defeat at Manzikert, and was weakened considerably by the sack of Constantinople in 1204, during the Fourth Crusade. Although it would recover Constantinople in 1261, Byzantium fell in 1453 when Constantinople was taken by the Ottoman Empire.\nIn the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Pechenegs and the Cuman-Kipchaks, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north, and temporarily halted the expansion of the Rus' state to the south and east. Like many other parts of Eurasia, these territories were overrun by the Mongols. The invaders, who became known as Tatars, were mostly Turkic-speaking peoples under Mongol suzerainty. They established the state of the Golden Horde with headquarters in Crimea, which later adopted Islam as a religion, and ruled over modern-day southern and central Russia for more than three centuries. After the collapse of Mongol dominions, the first Romanian states (principalities) emerged in the 14th century: Moldavia and Walachia. Previously, these territories were under the successive control of Pechenegs and Cumans. From the 12th to the 15th centuries, the Grand Duchy of Moscow grew from a small principality under Mongol rule to the largest state in Europe, overthrowing the Mongols in 1480, and eventually becoming the Tsardom of Russia. The state was consolidated under Ivan III the Great and Ivan the Terrible, steadily expanding to the east and south over the next centuries.\nThe Great Famine of 1315\u20131317 was the first crisis that would strike Europe in the late Middle Ages. The period between 1348 and 1420 witnessed the heaviest loss. The population of France was reduced by half. Medieval Britain was afflicted by 95 famines, and France suffered the effects of 75 or more in the same period. Europe was devastated in the mid-14th century by the Black Death, one of the most deadly pandemics in human history which killed an estimated 25\u00a0million people in Europe alone\u2014a third of the European population at the time.\nThe plague had a devastating effect on Europe's social structure; it induced people to live for the moment as illustrated by Giovanni Boccaccio in \"The Decameron\" (1353). It was a serious blow to the Roman Catholic Church and led to increased persecution of Jews, beggars and lepers. The plague is thought to have returned every generation with varying virulence and mortalities until the 18th century. During this period, more than 100 plague epidemics swept across Europe.\nEarly modern period.\nThe Renaissance was a period of cultural change originating in Florence, and later spreading to the rest of Europe. The rise of a new humanism was accompanied by the recovery of forgotten classical Greek and Arabic knowledge from monastic libraries, often translated from Arabic into Latin. The Renaissance spread across Europe between the 14th and 16th centuries: it saw the flowering of art, philosophy, music, and the sciences, under the joint patronage of royalty, the nobility, the Catholic Church and an emerging merchant class. Patrons in Italy, including the Medici family of Florentine bankers and the popes in Rome, funded prolific quattrocento and cinquecento artists such as Raphael, Michelangelo and Leonardo da Vinci.\nPolitical intrigue within the Church in the mid-14th century caused the Western Schism. During this 40-year period, two popes\u2014one in Avignon and one in Rome\u2014claimed rulership over the Church. Although the schism was eventually healed in 1417, the papacy's spiritual authority had suffered greatly. In the 15th century, Europe started to extend itself beyond its geographic frontiers. Spain and Portugal, the greatest naval powers of the time, took the lead in exploring the world. Exploration reached the Southern Hemisphere in the Atlantic and the southern tip of Africa. Christopher Columbus reached the New World in 1492, and Vasco da Gama opened the ocean route to the East, linking the Atlantic and Indian Oceans in 1498. The Portuguese-born explorer Ferdinand Magellan reached Asia westward across the Atlantic and the Pacific Oceans in a Spanish expedition, resulting in the first circumnavigation of the globe, completed by the Spaniard Juan Sebasti\u00e1n Elcano (1519\u20131522). Soon after, the Spanish and Portuguese began establishing large global empires in the Americas, Asia, Africa and Oceania. France, the Netherlands and England soon followed in building large colonial empires with vast holdings in Africa, the Americas and Asia. In 1588, the Spanish Armada failed to invade England. A year later, England tried unsuccessfully to invade Spain, allowing Philip II of Spain to maintain his dominant war capacity in Europe. This English disaster also allowed the Spanish fleet to retain its capability to wage war for the next decades. However, two more Spanish armadas failed to invade England (2nd Spanish Armada and 3rd Spanish Armada).\nThe Church's power was further weakened by the Reformation, which began in 1517 when German theologian Martin Luther nailed his \"Ninety-five Theses\" criticising the selling of indulgences to the church door. He was subsequently excommunicated in the papal bull \"Exsurge Domine\" in 1520 and his followers were condemned in the 1521 Diet of Worms, which divided German princes between Protestant and Catholic faiths. Religious fighting and warfare spread with Protestantism. The plunder of the empires of the Americas allowed Spain to finance religious persecution in Europe for over a century. The Thirty Years' War (1618\u20131648) crippled the Holy Roman Empire and devastated much of Germany, killing between 25 and 40 percent of its population. In the aftermath of the Peace of Westphalia, France rose to predominance within Europe. The defeat of the Ottoman Turks at the Battle of Vienna in 1683 marked the historic end of Ottoman expansion into Europe.\nIn much of Central and Eastern Europe, the 17th century was a period of general decline; the region experienced more than 150 famines in a 200-year period between 1501 and 1700. From the Union of Krewo (1385) east-central Europe was dominated by the Kingdom of Poland and the Grand Duchy of Lithuania. The hegemony of the vast Polish\u2013Lithuanian Commonwealth had ended with the devastation brought by the Northern War of 1655\u20131660 (Deluge) and subsequent conflicts; the state itself was partitioned and ceased to exist at the end of the 18th century.\nFrom the 15th to 18th centuries, when the disintegrating khanates of the Golden Horde were conquered by Russia, Tatars from the Crimean Khanate frequently raided Eastern Slavic lands to capture slaves. Further east, the Nogai Horde and Kazakh Khanate frequently raided the Slavic-speaking areas of contemporary Russia and Ukraine for hundreds of years, until the Russian expansion and conquest of most of northern Eurasia (i.e. Eastern Europe, Central Asia and Siberia).\nThe Renaissance and the New Monarchs marked the start of an Age of Discovery, a period of exploration, invention and scientific development. Important figures of the Scientific Revolution during the 16th and 17th centuries included Copernicus, Kepler, Galileo, and Isaac Newton. According to Peter Barrett, \"It is widely accepted that 'modern science' arose in the Europe of the 17th century (towards the end of the Renaissance), introducing a new understanding of the natural world.\"\n18th and 19th centuries.\nThe Seven Years' War brought to an end the \"Old System\" of alliances in Europe. Consequently, when the American Revolutionary War turned into a global war between 1778 and 1783, Britain found itself opposed by a strong coalition of European powers, and lacking any substantial ally.\nThe Age of Enlightenment was a powerful intellectual movement during the 18th century promoting scientific and reason-based thoughts. Discontent with the aristocracy and clergy's monopoly on political power in France resulted in the French Revolution, and the establishment of the First Republic as a result of which the monarchy and many of the nobility perished during the initial reign of terror. Napoleon Bonaparte rose to power in the aftermath of the French Revolution, and established the First French Empire that, during the Napoleonic Wars, grew to encompass large parts of Europe before collapsing in 1815 with the Battle of Waterloo. Napoleonic rule resulted in the further dissemination of the ideals of the French Revolution, including that of the nation state, as well as the widespread adoption of the French models of administration, law and education. The Congress of Vienna, convened after Napoleon's downfall, established a new balance of power in Europe centred on the five \"great powers\": the UK, France, Prussia, Austria, and Russia. This balance would remain in place until the Revolutions of 1848, during which liberal uprisings affected all of Europe except for Russia and the UK. These revolutions were eventually put down by conservative elements and few reforms resulted. The year 1859 saw the unification of Romania, as a nation state, from smaller principalities. In 1867, the Austro-Hungarian empire was formed; 1871 saw the unifications of both Italy and Germany as nation-states from smaller principalities.\nIn parallel, the Eastern Question grew more complex ever since the Ottoman defeat in the Russo-Turkish War (1768\u20131774). As the dissolution of the Ottoman Empire seemed imminent, the Great Powers struggled to safeguard their strategic and commercial interests in the Ottoman domains. The Russian Empire stood to benefit from the decline, whereas the Habsburg Empire and Britain perceived the preservation of the Ottoman Empire to be in their best interests. Meanwhile, the Serbian Revolution (1804) and Greek War of Independence (1821) marked the beginning of the end of Ottoman rule in the Balkans, which ended with the Balkan Wars in 1912\u20131913. Formal recognition of the \"de facto\" independent principalities of Montenegro, Serbia and Romania ensued at the Congress of Berlin in 1878.\nThe Industrial Revolution started in Great Britain in the last part of the 18th century and spread throughout Europe. The invention and implementation of new technologies resulted in rapid urban growth, mass employment and the rise of a new working class. Reforms in social and economic spheres followed, including the first laws on child labour, the legalisation of trade unions, and the abolition of slavery. In Britain, the Public Health Act of 1875 was passed, which significantly improved living conditions in many British cities. Europe's population increased from about 100 million in 1700 to 400 million by 1900. The last major famine recorded in Western Europe, the Great Famine of Ireland, caused death and mass emigration of millions of Irish people. In the 19th century, 70\u00a0million people left Europe in migrations to various European colonies abroad and to the United States. The industrial revolution also led to large population growth, and the reached a peak of slightly above 25% around the year 1913.\n20th century to the present.\nTwo world wars and an economic depression dominated the first half of the 20th century. The First World War was fought between 1914 and 1918. It started when Archduke Franz Ferdinand of Austria was assassinated by the Yugoslav nationalist Gavrilo Princip. Most European nations were drawn into the war, which was fought between the Entente Powers (France, Belgium, Serbia, Portugal, Russia, the United Kingdom, and later Italy, Greece, Romania, and the United States) and the Central Powers (Austria-Hungary, Germany, Bulgaria, and the Ottoman Empire). The war left more than 16\u00a0million civilians and military dead. Over 60\u00a0million European soldiers were mobilised from 1914 to 1918.\nRussia was plunged into the Russian Revolution, which threw down the Tsarist monarchy and replaced it with the communist Soviet Union, leading also to the independence of many former Russian governorates, such as Finland, Estonia, Latvia and Lithuania, as new European countries. Austria-Hungary and the Ottoman Empire collapsed and broke up into separate nations, and many other nations had their borders redrawn. The Treaty of Versailles, which officially ended the First World War in 1919, was harsh towards Germany, upon whom it placed full responsibility for the war and imposed heavy sanctions. Excess deaths in Russia over the course of the First World War and the Russian Civil War (including the postwar famine) amounted to a combined total of 18 million. In 1932\u20131933, under Stalin's leadership, confiscations of grain by the Soviet authorities contributed to the second Soviet famine which caused millions of deaths; surviving kulaks were persecuted and many sent to Gulags to do forced labour. Stalin was also responsible for the Great Purge of 1937\u201338 in which the NKVD executed 681,692 people; millions of people were deported and exiled to remote areas of the Soviet Union.\nThe social revolutions sweeping through Russia also affected other European nations following The Great War: in 1919, with the Weimar Republic in Germany and the First Austrian Republic; in 1922, with Mussolini's one-party fascist government in the Kingdom of Italy and in Atat\u00fcrk's Turkish Republic, adopting the Western alphabet and state secularism.\nEconomic instability, caused in part by debts incurred in the First World War and 'loans' to Germany played havoc in Europe in the late 1920s and 1930s. This, and the Wall Street crash of 1929, brought about the worldwide Great Depression. Helped by the economic crisis, social instability and the threat of communism, fascist movements developed throughout Europe placing Adolf Hitler in power of what became Nazi Germany.\nIn 1933, Hitler became the leader of Germany and began to work towards his goal of building Greater Germany. Germany re-expanded and took back the Saarland and Rhineland in 1935 and 1936. In 1938, Austria became a part of Germany following the Anschluss. Following the Munich Agreement signed by Germany, France, the United Kingdom, and Italy, later in 1938 Germany annexed the Sudetenland, which was a part of Czechoslovakia inhabited by ethnic Germans. In early 1939, the remainder of Czechoslovakia was split into the Protectorate of Bohemia and Moravia, controlled by Germany and the Slovak Republic. At the time, the United Kingdom and France preferred a policy of appeasement.\nWith tensions mounting between Germany and Poland over the future of Danzig, the Germans turned to the Soviets and signed the Molotov\u2013Ribbentrop Pact, which allowed the Soviets to invade the Baltic states and parts of Poland and Romania. Germany invaded Poland on 1 September 1939, prompting France and the United Kingdom to declare war on Germany on 3 September, opening the European Theatre of the Second World War. The Soviet invasion of Poland started on 17 September and Poland fell soon thereafter. On 24 September, the Soviet Union attacked the Baltic countries and, on 30 November, Finland, the latter of which was followed by the devastating Winter War for the Red Army. The British hoped to land at Narvik and send troops to aid Finland, but their primary objective in the landing was to encircle Germany and cut the Germans off from Scandinavian resources. Around the same time, Germany moved troops into Denmark. The Phoney War continued.\nIn May 1940, Germany attacked France through the Low Countries. France capitulated in June 1940. By August, Germany had begun a bombing offensive against the United Kingdom but failed to convince the Britons to give up. In 1941, Germany invaded the Soviet Union in Operation Barbarossa. On 7 December 1941 Japan's attack on Pearl Harbor drew the United States into the conflict as allies of the British Empire, and other allied forces.\nAfter the staggering Battle of Stalingrad in 1943, the German offensive in the Soviet Union turned into a continual fallback. The Battle of Kursk, which involved the largest tank battle in history, was the last major German offensive on the Eastern Front. In June 1944, British and American forces invaded France in the D-Day landings, opening a new front against Germany. Berlin finally fell in 1945, ending the Second World War in Europe. The war was the largest and most destructive in human history, with 60\u00a0million dead across the world. More than 40\u00a0million people in Europe had died as a result of the Second World War, including between 11 and 17\u00a0million people who perished during the Holocaust. The Soviet Union lost around 27\u00a0million people (mostly civilians) during the war, about half of all Second World War casualties. By the end of the Second World War, Europe had more than 40\u00a0million refugees. Several post-war expulsions in Central and Eastern Europe displaced a total of about 20\u00a0million people.\nThe First World War, and especially the Second World War, diminished the eminence of Western Europe in world affairs. After the Second World War the map of Europe was redrawn at the Yalta Conference and divided into two blocs, the Western countries and the communist Eastern bloc, separated by what was later called by Winston Churchill an \"Iron Curtain\". The United States and Western Europe established the NATO alliance and, later, the Soviet Union and Central Europe established the Warsaw Pact. Particular hot spots after the Second World War were Berlin and Trieste, whereby the Free Territory of Trieste, founded in 1947 with the UN, was dissolved in 1954 and 1975, respectively. The Berlin blockade in 1948 and 1949 and the construction of the Berlin Wall in 1961 were one of the great international crises of the Cold War.\nThe two new superpowers, the United States and the Soviet Union, became locked in a fifty-year-long Cold War, centred on nuclear proliferation. At the same time decolonisation, which had already started after the First World War, gradually resulted in the independence of most of the European colonies in Asia and Africa.\nIn the 1980s the reforms of Mikhail Gorbachev and the Solidarity movement in Poland weakened the previously rigid communist system. The opening of the Iron Curtain at the Pan-European Picnic then set in motion a peaceful chain reaction, at the end of which the Eastern bloc, the Warsaw Pact and other communist states collapsed, and the Cold War ended. Germany was reunited, after the symbolic fall of the Berlin Wall in 1989 and the maps of Central and Eastern Europe were redrawn once more. This made old previously interrupted cultural and economic relationships possible, and previously isolated cities such as Berlin, Prague, Vienna, Budapest and Trieste were now again in the centre of Europe.\nEuropean integration also grew after the Second World War. In 1949 the Council of Europe was founded, following a speech by Sir Winston Churchill, with the idea of unifying Europe to achieve common goals. It includes all European states except for Belarus, Russia, and Vatican City. The Treaty of Rome in 1957 established the European Economic Community between six Western European states with the goal of a unified economic policy and common market. In 1967 the EEC, European Coal and Steel Community, and Euratom formed the European Community, which in 1993 became the European Union. The EU established a parliament, court and central bank, and introduced the euro as a unified currency. Between 2004 and 2013, more Central European countries began joining, expanding the EU to 28 European countries and once more making Europe a major economical and political centre of power. However, the United Kingdom withdrew from the EU on 31 January 2020, as a result of a June 2016 referendum on EU membership. The Russo-Ukrainian conflict, which has been ongoing since 2014, steeply escalated when Russia launched a full-scale invasion of Ukraine on 24 February 2022, marking the largest humanitarian and refugee crisis in Europe since the Second World War and the Yugoslav Wars.\nGeography.\nEurope makes up the western fifth of the Eurasian landmass. It has a higher ratio of coast to landmass than any other continent or subcontinent. Its maritime borders consist of the Arctic Ocean to the north, the Atlantic Ocean to the west and the Mediterranean, Black and Caspian Seas to the south.\nLand relief in Europe shows great variation within relatively small areas. The southern regions are more mountainous, while moving north the terrain descends from the high Alps, Pyrenees and Carpathians, through hilly uplands, into broad, low northern plains, which are vast in the east. This extended lowland is known as the Great European Plain and at its heart lies the North German Plain. An arc of uplands also exists along the north-western seaboard, which begins in the western parts of the islands of Britain and Ireland, and then continues along the mountainous, fjord-cut spine of Norway.\nThis description is simplified. Subregions such as the Iberian Peninsula and the Italian Peninsula contain their own complex features, as does mainland Central Europe itself, where the relief contains many plateaus, river valleys and basins that complicate the general trend. Sub-regions like Iceland, Britain and Ireland are special cases. The former is a land unto itself in the northern ocean that is counted as part of Europe, while the latter are upland areas that were once joined to the mainland until rising sea levels cut them off.\nClimate.\nEurope lies mainly in the temperate climate zone of the northern hemisphere, where the prevailing wind direction is from the west. The climate is milder in comparison to other areas of the same latitude around the globe due to the influence of the Gulf Stream, an ocean current which carries warm water from the Gulf of Mexico across the Atlantic Ocean to Europe. The Gulf Stream is nicknamed \"Europe's central heating\", because it makes Europe's climate warmer and wetter than it would otherwise be. The Gulf Stream not only carries warm water to Europe's coast but also warms up the prevailing westerly winds that blow across the continent from the Atlantic Ocean.\nTherefore, the average temperature throughout the year of Aveiro is , while it is only in New York City which is almost on the same latitude, bordering the same ocean. Berlin, Germany; Calgary, Canada; and Irkutsk, in far south-eastern Russia, lie on around the same latitude; January temperatures in Berlin average around higher than those in Calgary and they are almost higher than average temperatures in Irkutsk.\nThe large water masses of the Mediterranean Sea, which equalise the temperatures on an annual and daily average, are also of particular importance. The water of the Mediterranean extends from the Sahara desert to the Alpine arc in its northernmost part of the Adriatic Sea near Trieste.\nIn general, Europe is not just colder towards the north compared to the south, but it also gets colder from the west towards the east. The climate is more oceanic in the west and less so in the east. This can be illustrated by the following table of average temperatures at locations roughly following the 64th, 60th, 55th, 50th, 45th and 40th latitudes. None of them is located at high altitude; most of them are close to the sea.\nIt is notable how the average temperatures for the coldest month, as well as the annual average temperatures, drop from the west to the east. For instance, Edinburgh is warmer than Belgrade during the coldest month of the year, although Belgrade is around 10\u00b0 of latitude farther south.\nGeology.\nThe geological history of Europe traces back to the formation of the Baltic Shield (Fennoscandia) and the Sarmatian craton, both around 2.25\u00a0billion years ago, followed by the Volgo\u2013Uralia shield, the three together leading to the East European craton (\u2248 Baltica) which became a part of the supercontinent Columbia. Around 1.1\u00a0billion years ago, Baltica and Arctica (as part of the Laurentia block) became joined to Rodinia, later resplitting around 550\u00a0million years ago to reform as Baltica. Around 440\u00a0million years ago Euramerica was formed from Baltica and Laurentia; a further joining with Gondwana then leading to the formation of Pangea. Around 190\u00a0million years ago, Gondwana and Laurasia split apart due to the widening of the Atlantic Ocean. Finally and very soon afterwards, Laurasia itself split up again, into Laurentia (North America) and the Eurasian continent. The land connection between the two persisted for a considerable time, via Greenland, leading to interchange of animal species. From around 50\u00a0million years ago, rising and falling sea levels have determined the actual shape of Europe and its connections with continents such as Asia. Europe's present shape dates to the late Tertiary period about five million years ago.\nThe geology of Europe is hugely varied and complex and gives rise to the wide variety of landscapes found across the continent, from the Scottish Highlands to the rolling plains of Hungary. Europe's most significant feature is the dichotomy between highland and mountainous Southern Europe and a vast, partially underwater, northern plain ranging from Ireland in the west to the Ural Mountains in the east. These two halves are separated by the mountain chains of the Pyrenees and Alps/Carpathians. The northern plains are delimited in the west by the Scandinavian Mountains and the mountainous parts of the British Isles. Major shallow water bodies submerging parts of the northern plains are the Celtic Sea, the North Sea, the Baltic Sea complex and Barents Sea.\nThe northern plain contains the old geological continent of Baltica and so may be regarded geologically as the \"main continent\", while peripheral highlands and mountainous regions in the south and west constitute fragments from various other geological continents. Most of the older geology of western Europe existed as part of the ancient microcontinent Avalonia.\nFlora.\nHaving lived side by side with agricultural peoples for millennia, Europe's animals and plants have been profoundly affected by the presence and activities of humans. With the exception of Fennoscandia and northern Russia, few areas of untouched wilderness are currently found in Europe, except for various national parks.\nThe main natural vegetation cover in Europe is mixed forest. The conditions for growth are very favourable. In the north, the Gulf Stream and North Atlantic Drift warm the continent. Southern Europe has a warm but mild climate. There are frequent summer droughts in this region. Mountain ridges also affect the conditions. Some of these, such as the Alps and the Pyrenees, are oriented east\u2013west and allow the wind to carry large masses of water from the ocean in the interior. Others are oriented south\u2013north (Scandinavian Mountains, Dinarides, Carpathians, Apennines) and because the rain falls primarily on the side of mountains that is oriented towards the sea, forests grow well on this side, while on the other side, the conditions are much less favourable. Few corners of mainland Europe have not been grazed by livestock at some point in time, and the cutting down of the preagricultural forest habitat caused disruption to the original plant and animal ecosystems.\nPossibly 80 to 90 percent of Europe was once covered by forest. It stretched from the Mediterranean Sea to the Arctic Ocean. Although over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the broadleaf and mixed forests, taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European forest dwelling species which require a mixture of tree species and diverse forest structure. The amount of natural forest in Western Europe is just 2\u20133% or less, while in its Western Russia its 5\u201310%. The European country with the smallest percentage of forested area is Iceland (1%), while the most forested country is Finland (77%).\nIn temperate Europe, mixed forest with both broadleaf and coniferous trees dominate. The most important species in central and western Europe are beech and oak. In the north, the taiga is a mixed spruce\u2013pine\u2013birch forest; further north within Russia and extreme northern Scandinavia, the taiga gives way to tundra as the Arctic is approached. In the Mediterranean, many olive trees have been planted, which are very well adapted to its arid climate; Mediterranean Cypress is also widely planted in southern Europe. The semi-arid Mediterranean region hosts much scrub forest. A narrow east\u2013west tongue of Eurasian grassland (the steppe) extends westwards from Ukraine and southern Russia and ends in Hungary and traverses into taiga to the north.\nFauna.\nGlaciation during the most recent ice age and the presence of humans affected the distribution of European fauna. As for the animals, in many parts of Europe most large animals and top predator species have been hunted to extinction. The woolly mammoth was extinct before the end of the Neolithic period. Today wolves (carnivores) and bears (omnivores) are endangered. Once they were found in most parts of Europe. However, deforestation and hunting caused these animals to withdraw further and further. By the Middle Ages the bears' habitats were limited to more or less inaccessible mountains with sufficient forest cover. Today, the brown bear lives primarily in the Balkan peninsula, Scandinavia and Russia; a small number also persist in other countries across Europe (Austria, Pyrenees etc.), but in these areas brown bear populations are fragmented and marginalised because of the destruction of their habitat. In addition, polar bears may be found on Svalbard, a Norwegian archipelago far north of Scandinavia. The wolf, the second-largest predator in Europe after the brown bear, can be found primarily in Central and Eastern Europe and in the Balkans, with a handful of packs in pockets of Western Europe (Scandinavia, Spain, etc.).\nOther carnivores include the European wildcat, red fox and arctic fox, the golden jackal, different species of martens, the European hedgehog, different species of reptiles (like snakes such as vipers and grass snakes) and amphibians, as well as different birds (owls, hawks and other birds of prey).\nImportant European herbivores are snails, larvae, fish, different birds and mammals, like rodents, deer and roe deer, boars and living in the mountains, marmots, steinbocks, chamois among others. A number of insects, such as the small tortoiseshell butterfly, add to the biodiversity.\nSea creatures are also an important part of European flora and fauna. The sea flora is mainly phytoplankton. Important animals that live in European seas are zooplankton, molluscs, echinoderms, different crustaceans, squids and octopuses, fish, dolphins and whales.\nBiodiversity is protected in Europe through the Council of Europe's Bern Convention, which has also been signed by the European Community as well as non-European states.\nPolitics.\nThe political map of Europe is substantially derived from the re-organisation of Europe following the Napoleonic Wars in 1815. The prevalent form of government in Europe is parliamentary democracy, in most cases in the form of republic; in 1815, the prevalent form of government was still the monarchy. Europe's remaining eleven monarchies are constitutional.\nEuropean integration is the process of political, legal, economic (and in some cases social and cultural) integration of European states as it has been pursued by the powers sponsoring the Council of Europe since the end of the Second World War. The European Union has been the focus of economic integration on the continent since its foundation in 1993. More recently, the Eurasian Economic Union has been established as a counterpart comprising former Soviet states.\n27 European states are members of the politico-economic European Union, 26 of the border-free Schengen Area and 20 of the monetary union Eurozone. Among the smaller European organisations are the Nordic Council, the Benelux, the Baltic Assembly, and the Visegr\u00e1d Group.\nThe least democratic countries in Europe are Belarus, Russia, and Turkey in 2024 according to the V-Dem Democracy indices.\nList of states and territories.\nThis list includes all internationally recognised sovereign countries falling even partially under any common geographical or political definitions of Europe.\nWithin the above-mentioned states are several de facto independent countries with limited to no international recognition. None of them are members of the UN:\nSeveral dependencies and similar territories with broad autonomy are also found within or close to Europe. This includes \u00c5land (an autonomous county of Finland), two autonomous territories of the Kingdom of Denmark (other than Denmark proper), three Crown Dependencies and two British Overseas Territories. Svalbard is also included due to its unique status within Norway, although it is not autonomous. Not included are the three countries of the United Kingdom with devolved powers and the two Autonomous Regions of Portugal, which despite having a unique degree of autonomy, are not largely self-governing in matters other than international affairs. Areas with little more than a unique tax status, such as the Canary Islands and Heligoland, are also not included for this reason.\nEconomy.\nAs a continent, the economy of Europe is currently the largest on Earth and it is the richest region as measured by assets under management with over $32.7\u00a0trillion compared to North America's $27.1\u00a0trillion in 2008. In 2009 Europe remained the wealthiest region. Its $37.1 trillion in assets under management represented one-third of the world's wealth. It was one of several regions where wealth surpassed its precrisis year-end peak. As with other continents, Europe has a large wealth gap among its countries. The richer states tend to be in the Northwest and West in general, followed by Central Europe, while most economies of Eastern and Southeastern Europe are still reemerging from the collapse of the Soviet Union and the breakup of Yugoslavia.\nThe model of the Blue Banana was designed as an economic geographic representation of the respective economic power of the regions, which was further developed into the Golden Banana or Blue Star. The trade between East and West, as well as towards Asia, which had been disrupted for a long time by the two world wars, new borders and the Cold War, increased sharply after 1989. In addition, there is new impetus from the Chinese Belt and Road Initiative across the Suez Canal towards Africa and Asia.\nThe European Union, a political entity composed of 27 European states, comprises the largest single economic area in the world. Nineteen EU countries share the euro as a common currency.\nFive European countries rank in the top ten of the world's largest national economies in GDP (PPP). This includes (ranks according to the CIA): Germany (6), Russia (7), the United Kingdom (10), France (11) and Italy (13).\nSome European countries are much richer than others. The richest in terms of nominal GDP is Monaco with its US$185,829 per capita (2018) and the poorest is Ukraine with its US$3,659 per capita (2019).\nAs a whole, Europe's GDP per capita is US$21,767 according to a 2016 International Monetary Fund assessment.\nEconomic history.\nCapitalism has been dominant in the Western world since the end of feudalism. From Britain, it gradually spread throughout Europe. The Industrial Revolution started in Europe, specifically the United Kingdom in the late 18th century, and the 19th century saw Western Europe industrialise. Economies were disrupted by the First World War, but by the beginning of the Second World War, they had recovered and were having to compete with the growing economic strength of the United States. The Second World War, again, damaged much of Europe's industries.\nAfter the Second World War the economy of the UK was in a state of ruin, and continued to suffer relative economic decline in the following decades. Italy was also in a poor economic condition but regained a high level of growth by the 1950s. West Germany recovered quickly and had doubled production from pre-war levels by the 1950s. France also staged a remarkable comeback enjoying rapid growth and modernisation; later on Spain, under the leadership of Franco, also recovered and the nation recorded huge unprecedented economic growth beginning in the 1960s in what is called the Spanish miracle. The majority of Central and Eastern European states came under the control of the Soviet Union and thus were members of the Council for Mutual Economic Assistance (COMECON).\nThe states which retained a free-market system were given a large amount of aid by the United States under the Marshall Plan. The western states moved to link their economies together, providing the basis for the EU and increasing cross border trade. This helped them to enjoy rapidly improving economies, while those states in COMECON were struggling in a large part due to the cost of the Cold War. Until 1990, the European Community was expanded from 6 founding members to 12. The emphasis placed on resurrecting the West German economy led to it overtaking the UK as Europe's largest economy.\nWith the fall of communism in Central and Eastern Europe in 1991, the post-socialist states underwent shock therapy measures to liberalise their economies and implement free market reforms.\nAfter East and West Germany were reunited in 1990, the economy of West Germany struggled as it had to support and largely rebuild the infrastructure of East Germany, while the latter experienced sudden mass unemployment and plummeting of industrial production.\nBy the millennium change, the EU dominated the economy of Europe, comprising the five largest European economies of the time: Germany, the United Kingdom, France, Italy, and Spain. In 1999, 12 of the 15 members of the EU joined the Eurozone, replacing their national currencies by the euro.\nFigures released by Eurostat in 2009 confirmed that the Eurozone had gone into recession in 2008. It impacted much of the region. In 2010, fears of a sovereign debt crisis developed concerning some countries in Europe, especially Greece, Ireland, Spain and Portugal. As a result, measures were taken, especially for Greece, by the leading countries of the Eurozone. The EU-27 unemployment rate was 10.3% in 2012. For those aged 15\u201324 it was 22.4%.\nDemographics.\nThe population of Europe was about 742 million in 2023 according to UN estimates. This is slightly more than one ninth of the world's population. The population density of Europe (the number of people per area) is the second highest of any continent, behind Asia. The population of Europe is currently slowly decreasing, by about 0.2% per year, because there are fewer births than deaths. This natural decrease in population is reduced by the fact that more people migrate to Europe from other continents than vice versa.\nSouthern Europe and Western Europe are the regions with the highest average number of elderly people in the world. In 2021, the percentage of people over 65 years old was 21% in Western Europe and Southern Europe, compared to 19% in all of Europe and 10% in the world. Projections suggest that by 2050 Europe will reach 30%. This is caused by the fact that the population has been having children below replacement level since the 1970s. The United Nations predicts that Europe will decline in population between 2022 and 2050 by \u22127 per cent, without changing immigration movements.\nAccording to a population projection of the UN Population Division, Europe's population may fall to between 680 and 720 million people by 2050, which would be 7% of the world population at that time. Within this context, significant disparities exist between regions in relation to fertility rates. The average number of children per female of child-bearing age is 1.52, far below the replacement rate. The UN predicts a steady population decline in Central and Eastern Europe as a result of emigration and low birth rates.\nEthnic groups.\nPan and Pfeil (2004) count 87 distinct \"peoples of Europe\", of which 33 form the majority population in at least one sovereign state, while the remaining 54 constitute ethnic minorities.\nMigration.\nEurope is home to the highest number of migrants of all global regions at nearly 87 million people in 2020, according to the International Organisation for Migration. In 2005, the EU had an overall net gain from immigration of 1.8\u00a0million people. This accounted for almost 85% of Europe's total population growth. In 2021, 827,000 persons were given citizenship of an EU member state, an increase of about 14% compared with 2020. 2.3 million immigrants from non-EU countries entered the EU in 2021.\nEarly modern emigration from Europe began with Spanish and Portuguese settlers in the 16th century, and French and English settlers in the 17th century. But numbers remained relatively small until waves of mass emigration in the 19th century, when millions of poor families left Europe.\nToday, large populations of European descent are found on every continent. European ancestry predominates in North America and to a lesser degree in South America (particularly in Uruguay, Argentina, Chile and Brazil, while most of the other Latin American countries also have a considerable population of European origins). Australia and New Zealand have large European-derived populations. Africa has no countries with European-derived majorities (or with the exception of Cape Verde and probably S\u00e3o Tom\u00e9 and Pr\u00edncipe, depending on context), but there are significant minorities, such as the White South Africans in South Africa. In Asia, European-derived populations, specifically Russians, predominate in North Asia and some parts of Northern Kazakhstan. Also in Asia, Europeans, especially the Spanish are an influential minority population in the Philippines.\nLanguages.\nEurope has about 225 indigenous languages, mostly falling within three Indo-European language groups: the Romance languages, derived from the Latin of the Roman Empire; the Germanic languages, whose ancestor language came from southern Scandinavia; and the Slavic languages. Slavic languages are mostly spoken in Southern, Central and Eastern Europe. Romance languages are spoken primarily in Western and Southern Europe, as well as in Switzerland in Central Europe and Romania and Moldova in Eastern Europe. Germanic languages are spoken in Western, Northern and Central Europe as well as in Gibraltar and Malta in Southern Europe. Languages in adjacent areas show significant overlaps (such as in English, for example). Other Indo-European languages outside the three main groups include the Baltic group (Latvian and Lithuanian), the Celtic group (Irish, Scottish Gaelic, Manx, Welsh, Cornish and Breton), Greek, Armenian and Albanian.\nA distinct non-Indo-European family of Uralic languages (Estonian, Finnish, Hungarian, Erzya, Komi, Mari, Moksha and Udmurt) is spoken mainly in Estonia, Finland, Hungary and parts of Russia. Turkic languages include Azerbaijani, Kazakh and Turkish, in addition to smaller languages in Eastern and Southeast Europe (Balkan Gagauz Turkish, Bashkir, Chuvash, Crimean Tatar, Karachay-Balkar, Kumyk, Nogai and Tatar). Kartvelian languages (Georgian, Mingrelian and Svan) are spoken primarily in Georgia. Two other language families reside in the North Caucasus (termed Northeast Caucasian, most notably including Chechen, Avar and Lezgin; and Northwest Caucasian, most notably including Adyghe). Maltese is the only Semitic language that is official within the EU, while Basque is the only European language isolate.\nMultilingualism and the protection of regional and minority languages are recognised political goals in Europe today. The Council of Europe Framework Convention for the Protection of National Minorities and the Council of Europe's European Charter for Regional or Minority Languages set up a legal framework for language rights in Europe.\nReligion.\nThe largest religion in Europe is Christianity, with 76.2% of Europeans considering themselves Christians, including Catholic, Eastern Orthodox and various Protestant denominations. Among Protestants, the most popular are Lutheranism, Anglicanism and the Reformed faith. Smaller Protestant denominations include Anabaptists as well as denominations centred in the United States such as Pentecostalism, Methodism, and Evangelicalism. Although Christianity originated in the Middle East, its centre of mass shifted to Europe when it became the official religion of the Roman Empire in the late 4th century. Christianity played a prominent role in the development of the European culture and identity. Today, just over 25% of the world's Christians live in Europe.\nIslam is the second most popular religion in Europe. Over 25 million, or roughly 5% of the population, adhere to it. In Albania and Bosnia and Herzegovina, two countries in the Balkan peninsula in Southeastern Europe, Islam instead of Christianity is the majority religion. This is also the case in Turkey and in certain parts of Russia, as well as in Azerbaijan and Kazakhstan, all of which are at the border to Asia. Many countries in Europe are home to a sizeable Muslim minority, and immigration to Europe has increased the number of Muslim people in Europe in recent years.\nThe Jewish population in Europe was about 1.4 million people in 2020 (about 0.2% of the population). There is a long history of Jewish life in Europe, beginning in antiquity. During the late 19th and early 20th centuries, the Russian Empire had the majority of the world's Jews living within its borders. In 1897, according to Russian census of 1897, the total Jewish population of Russia was 5.1 million people, which was 4.13% of total population. Of this total, the vast majority lived within the Pale of Settlement. In 1933, there were about 9.5 million Jewish people in Europe, representing 1.7% of the population, but most were killed, and most of the rest displaced, during The Holocaust. In the 21st century, France has the largest Jewish population in Europe, followed by the United Kingdom, Germany and Russia.\nOther religions practiced in Europe include Hinduism and Buddhism, which are minority religions, except in Russia's Republic of Kalmykia, where Tibetan Buddhism is the majority religion.\nA large and increasing number of people in Europe are irreligious, atheist and agnostic. They are estimated to make up about 18.3% of Europe's population currently.\nMajor cities and urban areas.\nThe three largest urban areas of Europe are Moscow, London and Paris. All have over 10 million residents, and as such have been described as megacities. While Istanbul has the highest total city population, it lies partly in Asia. 64.9% of the residents live on the European side and 35.1% on the Asian side.\nThe next largest cities in order of population are Madrid, Saint Petersburg, Milan, Barcelona, Berlin, and Rome each having over three million residents.\nWhen considering the commuter belts or metropolitan areas within Europe (for which comparable data is available), Moscow covers the largest population, followed in order by Istanbul, London, Paris, Madrid, Milan, Ruhr Area, Saint Petersburg, Rhein-S\u00fcd, Barcelona and Berlin.\nCulture.\n\"Europe\" as a cultural concept is substantially derived from the shared heritage of ancient Greece and the Roman Empire and its cultures. The boundaries of Europe were historically understood as those of Christendom (or more specifically Latin Christendom), as established or defended throughout the medieval and early modern history of Europe, especially against Islam, as in the Reconquista and the Ottoman wars in Europe.\nThis shared cultural heritage is combined by overlapping indigenous national cultures and folklores, roughly divided into Slavic, Latin (Romance) and Germanic, but with several components not part of either of these groups (notably Greek, Basque and Celtic). Historically, special examples with overlapping cultures are Strasbourg with Latin (Romance) and Germanic, or Trieste with Latin, Slavic and Germanic roots.\nCultural contacts and mixtures shape a large part of the regional cultures of Europe. Europe is often described as \"maximum cultural diversity with minimal geographical distances\".\nDifferent cultural events are organised in Europe, with the aim of bringing different cultures closer together and raising awareness of their importance, such as the European Capital of Culture, the European Region of Gastronomy, the European Youth Capital and the European Capital of Sport.\nSport.\nSport in Europe tends to be highly organised with many sports having professional leagues. The origins of many of the world's most popular sports today lie in the codification of many traditional games, especially in the United Kingdom. However, a paradoxical feature of European sport is the extent to which local, regional and national variations continue to exist, and even in some instances to predominate.\nSocial dimension.\nIn Europe many people are unable to access basic social conditions, which makes it harder for them to thrive and flourish. Access to basic necessities can be compromised, for example 10% of Europeans spend at least 40% of household income on housing. 75 million Europeans feel socially isolated. From the 1980s income inequality has been rising and wage shares have been falling. In 2016, the richest 20% of households earned over five times more than the poorest 20%. Many workers experience stagnant real wages and precarious work is common even for essential workers.\nExternal links.\nHistorical maps"}
{"id": "9240", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=9240", "title": "Europa", "text": "Europa may refer to:"}
{"id": "9241", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9241", "title": "Euglenozoa", "text": "Euglenozoa are a large group of flagellate Discoba. They include a variety of common free-living species, as well as a few important parasites, some of which infect humans. Euglenozoa are represented by four major groups, \"i.e.,\" Kinetoplastea, Diplonemea, Euglenida, and Symbiontida. Euglenozoa are unicellular, mostly around in size, although some euglenids get up to long.\nStructure.\nMost euglenozoa have two flagella, which are inserted parallel to one another in an apical or subapical pocket. In some these are associated with a cytostome or mouth, used to ingest bacteria or other small organisms. This is supported by one of three sets of microtubules that arise from the flagellar bases; the other two support the dorsal and ventral surfaces of the cell.\nSome other euglenozoa feed through absorption, and many euglenids possess chloroplasts, the only eukaryotes outside Diaphoretickes to do so without performing kleptoplasty, and so obtain energy through photosynthesis. These chloroplasts are surrounded by three membranes and contain chlorophylls \"A\" and \"B\", along with other pigments, so are probably derived from a green alga, captured long ago in an endosymbiosis by a basal euglenozoan. Reproduction occurs exclusively through cell division. During mitosis, the nuclear membrane remains intact, and the spindle microtubules form inside of it.\nThe group is characterized by the ultrastructure of the flagella. In addition to the normal supporting microtubules or axoneme, each contains a rod (called \"paraxonemal\"), which has a tubular structure in one flagellum and a latticed structure in the other. Based on this, two smaller groups have been included here: the diplonemids and \"Postgaardi\".\nClassification.\nHistorically, euglenozoans have been treated as either plants or animals, depending on whether they belong to largely photosynthetic groups or not. Hence they have names based on either the International Code of Nomenclature for algae, fungi, and plants (ICNafp) or the International Code of Zoological Nomenclature (ICZN). For example, one family has the name Euglenaceae under the ICNafp and the name Euglenidae under the ICZN. As another example, the genus name \"Dinema\" is acceptable under the ICZN, but illegitimate under the ICNafp, as it is a later homonym of an orchid genus, so that the synonym \"Dinematomonas\" must be used instead.\nThe Euglenozoa are generally accepted as monophyletic. They are related to Percolozoa; the two share mitochondria with disk-shaped cristae, which only occurs in a few other groups.\nBoth probably belong to a larger group of eukaryotes called the Excavata. This grouping, though, has been challenged.\nPhylogeny.\nThe phylogeny based on the work of Cavalier-Smith (2016):\nA consensus phylogeny following the review by Kostygov \"et al.\" (2021): \nTaxonomy.\nCavalier-Smith (2016/2017).\nThe following classification of Euglenozoa is as described by Cavalier-Smith in 2016, modified to include the new subphylum Plicomonada according to Cavalier-Smith \"et al\" (2017).\nPhylum Euglenozoa [Euglenobionta]\nKostygov \"et al.\" (2021).\nPhylum Euglenozoa "}
{"id": "9242", "revid": "4370711", "url": "https://en.wikipedia.org/wiki?curid=9242", "title": "EigenVectors", "text": ""}
{"id": "9243", "revid": "4370711", "url": "https://en.wikipedia.org/wiki?curid=9243", "title": "EigenValue", "text": ""}
{"id": "9244", "revid": "4370711", "url": "https://en.wikipedia.org/wiki?curid=9244", "title": "EigenVector", "text": ""}
{"id": "9246", "revid": "4370711", "url": "https://en.wikipedia.org/wiki?curid=9246", "title": "Eigen Vectors", "text": ""}
{"id": "9247", "revid": "40347300", "url": "https://en.wikipedia.org/wiki?curid=9247", "title": "Epistemology", "text": "Epistemology is the branch of philosophy that examines the nature, origin, and limits of knowledge. Also called theory of knowledge, it explores different types of knowledge, such as propositional knowledge about facts, practical knowledge in the form of skills, and knowledge by acquaintance as a familiarity through experience. Epistemologists study the concepts of belief, truth, and justification to understand the nature of knowledge. To discover how knowledge arises, they investigate sources of justification, such as perception, introspection, memory, reason, and testimony.\nThe school of skepticism questions the human ability to attain knowledge while fallibilism says that knowledge is never certain. Empiricists hold that all knowledge comes from sense experience, whereas rationalists believe that some knowledge does not depend on it. Coherentists argue that a belief is justified if it coheres with other beliefs. Foundationalists, by contrast, maintain that the justification of basic beliefs does not depend on other beliefs. Internalism and externalism disagree about whether justification is determined solely by mental states or also by external circumstances.\nSeparate branches of epistemology are dedicated to knowledge found in specific fields, like scientific, mathematical, moral, and religious knowledge. Naturalized epistemology relies on empirical methods and discoveries, whereas formal epistemology uses formal tools from logic. Social epistemology investigates the communal aspect of knowledge and historical epistemology examines its historical conditions. Epistemology is closely related to psychology, which describes the beliefs people hold, while epistemology studies the norms governing the evaluation of beliefs. It also intersects with fields such as decision theory, education, and anthropology.\nEarly reflections on the nature, sources, and scope of knowledge are found in ancient Greek, Indian, and Chinese philosophy. The relation between reason and faith was a central topic in the medieval period. The modern era was characterized by the contrasting perspectives of empiricism and rationalism. Epistemologists in the 20th century examined the components, structure, and value of knowledge while integrating insights from the natural sciences and linguistics.\nDefinition.\nEpistemology is the philosophical study of knowledge. Also called \"theory of knowledge\", it examines what knowledge is and what types of knowledge there are. It further investigates the sources of knowledge, like perception, inference, and testimony, to determine how knowledge is created. Another topic is the extent and limits of knowledge, confronting questions about what people can and cannot know. Other central concepts include belief, truth, justification, evidence, and reason. Epistemology is one of the main branches of philosophy besides fields like ethics, logic, and metaphysics. The term is also used in a slightly different sense to refer not to the branch of philosophy but to the positions of particular philosophers within that branch, as in Plato's epistemology and Immanuel Kant's epistemology.\nAs a normative field of inquiry, epistemology explores how people should acquire beliefs. It determines which beliefs or forms of belief acquisition fulfill the standards or epistemic goals of knowledge and which ones fail, thereby providing an evaluation of beliefs. Descriptive fields of inquiry, like psychology and cognitive sociology, are also interested in beliefs and related cognitive processes. Unlike epistemology, they study the beliefs people have and how people acquire them instead of examining the evaluative norms of these processes. Epistemology is relevant to many descriptive and normative disciplines, such as the other branches of philosophy and the sciences, by exploring the principles of how they may arrive at knowledge.\nThe word \"epistemology\" comes from the ancient Greek terms (episteme, meaning \"knowledge\" or \"understanding\") and (logos, meaning \"study of\" or \"reason\"), literally, the study of knowledge. The word was only coined in the 19th century to label this field and conceive it as a distinct branch of philosophy.\nCentral concepts.\nEpistemologists examine several foundational concepts to understand their essences and rely on them to formulate theories. Various epistemological disagreements have their roots in disputes about the nature and function of these concepts, like the controversies surrounding the definition of knowledge and the role of justification in it.\nKnowledge.\nKnowledge is an awareness, familiarity, understanding, or skill. Its various forms all involve a cognitive success through which a person establishes epistemic contact with reality. Epistemologists typically understand knowledge as an aspect of individuals, generally as a cognitive mental state that helps them understand, interpret, and interact with the world. While this core sense is of particular interest to epistemologists, the term also has other meanings. For example, the epistemology of groups examines knowledge as a characteristic of a group of people who share ideas. The term can also refer to information stored in documents and computers.\nKnowledge contrasts with ignorance, which is often simply defined as the absence of knowledge. Knowledge is usually accompanied by ignorance since people rarely have complete knowledge of a field, forcing them to rely on incomplete or uncertain information when making decisions. Even though many forms of ignorance can be mitigated through education and research, there are certain limits to human understanding that are responsible for inevitable ignorance. Some limitations are inherent in the human cognitive faculties themselves, such as the inability to know facts too complex for the human mind to conceive. Others depend on external circumstances when no access to the relevant information exists. \nEpistemologists disagree on how much people know, for example, whether fallible beliefs can amount to knowledge or whether absolute certainty is required. The most stringent position is taken by radical skeptics, who argue that there is no knowledge at all.\nTypes.\nEpistemologists distinguish between different types of knowledge. Their primary interest is in knowledge of facts, called \"propositional knowledge\". It is theoretical knowledge that can be expressed in declarative sentences using a that-clause, like \"Ravi knows that kangaroos hop\". For this reason, it is also called \"knowledge-that\". Epistemologists often understand it as a relation between a knower and a known proposition, in the case above between the person Ravi and the proposition \"kangaroos hop\". It is use-independent since it is not tied to one specific purpose, unlike practical knowledge. It is a mental representation that embodies concepts and ideas to reflect reality. Because of its theoretical nature, it is often held that only creatures with highly developed minds, such as humans, possess propositional knowledge.\nPropositional knowledge contrasts with non-propositional knowledge in the form of knowledge-how and knowledge by acquaintance. Knowledge-how is a practical ability or skill, like knowing how to read or how to prepare lasagna. It is usually tied to a specific goal and not mastered in the abstract without concrete practice. To know something by acquaintance means to have an immediate familiarity with or awareness of it, usually as a result of direct experiential contact. Examples are \"familiarity with the city of Perth\", \"knowing the taste of tsampa\", and \"knowing Marta Vieira da Silva personally\".\nAnother influential distinction in epistemology is between \"a posteriori\" and \"a priori\" knowledge. \"A posteriori\" knowledge is knowledge of empirical facts based on sensory experience, like \"seeing that the sun is shining\" and \"smelling that a piece of meat has gone bad\". Knowledge belonging to the empirical science and knowledge of everyday affairs belongs to \"a posteriori\" knowledge. \"A priori\" knowledge is knowledge of non-empirical facts and does not depend on evidence from sensory experience, like knowing that formula_1. It belongs to fields such as mathematics and logic. The contrast between \"a posteriori\" and \"a priori\" knowledge plays a central role in the debate between empiricists and rationalists on whether all knowledge depends on sensory experience.\nA closely related contrast is between analytic and synthetic truths. A sentence is analytically true if its truth depends only on the meaning of the words it uses. For instance, the sentence \"all bachelors are unmarried\" is analytically true because the word \"bachelor\" already includes the meaning \"unmarried\". A sentence is synthetically true if its truth depends on additional facts. For example, the sentence \"snow is white\" is synthetically true because its truth depends on the color of snow in addition to the meanings of the words \"snow\" and \"white\". \"A priori\" knowledge is primarily associated with analytic sentences while \"a posteriori\" knowledge is primarily associated with synthetic sentences. However, it is controversial whether this is true for all cases. Some philosophers, such as Willard Van Orman Quine, reject the distinction, saying that there are no analytic truths.\nAnalysis.\nThe analysis of knowledge is the attempt to identify the essential components or conditions of all and only propositional knowledge states. According to the so-called \"traditional analysis\", knowledge has three components: it is a belief that is justified and true. In the second half of the 20th century, this view was put into doubt by a series of thought experiments that aimed to show that some justified true beliefs do not amount to knowledge. In one of them, a person is unaware of all the fake barns in their area. By coincidence, they stop in front of the only real barn and form a justified true belief that it is a real barn. Many epistemologists agree that this is not knowledge because the justification is not directly relevant to the truth. More specifically, this and similar counterexamples involve some form of epistemic luck, that is, a cognitive success that results from fortuitous circumstances rather than competence.\nFollowing these thought experiments, philosophers proposed various alternative definitions of knowledge by modifying or expanding the traditional analysis. According to one view, the known fact has to cause the belief in the right way. Another theory states that the belief is the product of a reliable belief formation process. Further approaches require that the person would not have the belief if it was false, that the belief is not inferred from a falsehood, that the justification cannot be undermined, or that the belief is infallible. There is no consensus on which of the proposed modifications and reconceptualizations is correct. Some philosophers, such as Timothy Williamson, reject the basic assumption underlying the analysis of knowledge by arguing that propositional knowledge is a unique state that cannot be dissected into simpler components.\nValue.\nThe value of knowledge is the worth it holds by expanding understanding and guiding action. Knowledge can have instrumental value by helping a person achieve their goals. For example, knowledge of a disease helps a doctor cure their patient. The usefulness of a known fact depends on the circumstances. Knowledge of some facts may have little to no uses, like memorizing random phone numbers from an outdated phone book. Being able to assess the value of knowledge matters in choosing what information to acquire and transmit to others. It affects decisions like which subjects to teach at school and how to allocate funds to research projects.\nOf particular interest to epistemologists is the question of whether knowledge is more valuable than a mere opinion that is true. Knowledge and true opinion often have a similar usefulness since both are accurate representations of reality. For example, if a person wants to go to Larissa, a true opinion about how to get there may help them in the same way as knowledge does. Considering this problem, Plato proposed that knowledge is better because it is more stable. Another suggestion focuses on practical reasoning. It proposes that people put more trust in knowledge than in mere true opinions when drawing conclusions and deciding what to do. A different response says that, unlike mere true opinion, knowledge has intrinsic value in addition to instrumental value. This view asserts that knowledge is always valuable, while true opinion is only valuable in circumstances where it is useful.\nBelief and truth.\nBeliefs are mental states about what is the case, like believing that snow is white or that God exists. In epistemology, they are often understood as subjective attitudes that affirm or deny a proposition, which can be expressed in a declarative sentence. For instance, to believe that snow is white is to affirm the proposition \"snow is white\". According to this view, beliefs are representations of what the universe is like. They are kept in memory and can be retrieved when actively thinking about reality or when deciding how to act. A different view understands beliefs as behavioral patterns or dispositions to act rather than as representational items stored in the mind. According to this view, to believe that there is mineral water in the fridge is nothing more than a group of dispositions related to mineral water and the fridge. Examples are the dispositions to answer questions about the presence of mineral water affirmatively and to go to the fridge when thirsty. Some theorists deny the existence of beliefs, saying that this concept borrowed from folk psychology is an oversimplification of much more complex psychological or neurological processes. Beliefs play a central role in various epistemological debates, which cover their status as a component of propositional knowledge, the question of whether people have control over and are responsible for their beliefs, and the issue of whether there are degrees of beliefs, called credences.\nAs propositional attitudes, beliefs are true or false depending on whether they affirm a true or a false proposition. According to the correspondence theory of truth, to be true means to stand in the right relation to the world by accurately describing what it is like. This means that truth is objective: a belief is true if it corresponds to a fact. The coherence theory of truth says that a belief is true if it belongs to a coherent system of beliefs. A result of this view is that truth is relative since it depends on other beliefs. Further theories of truth include pragmatist, semantic, pluralist, and deflationary theories. Truth plays a central role in epistemology as a goal of cognitive processes and an attribute of propositional knowledge.\nJustification.\nIn epistemology, justification is a property of beliefs that fulfill certain norms about what a person should believe. According to a common view, this means that the person has sufficient reasons for holding this belief because they have information that supports it. Another view states that a belief is justified if it is formed by a reliable belief formation process, such as perception. The terms \"reasonable\", \"warranted\", and \"supported\" are closely related to the idea of justification and are sometimes used as synonyms. Justification is what distinguishes justified beliefs from superstition and lucky guesses. However, justification does not guarantee truth. For example, if a person has strong but misleading evidence, they may form a justified belief that is false.\nEpistemologists often identify justification as one component of knowledge. Usually, they are not only interested in whether a person has a sufficient reason to hold a belief, known as \"propositional justification\", but also in whether the person holds the belief because or based on this reason, known as \"doxastic justification\". For example, if a person has sufficient reason to believe that a neighborhood is dangerous but forms this belief based on superstition then they have propositional justification but lack doxastic justification.\nSources.\nSources of justification are ways or cognitive capacities through which people acquire justification. Often-discussed sources include perception, introspection, memory, reason, and testimony, but there is no universal agreement to what extent they all provide valid justification. Perception relies on sensory organs to gain empirical information. There are various forms of perception corresponding to different physical stimuli, such as visual, auditory, haptic, olfactory, and gustatory perception. Perception is not merely the reception of sense impressions but an active process that selects, organizes, and interprets sensory signals. Introspection is a closely related process focused not on external physical objects but on internal mental states. For example, seeing a bus at a bus station belongs to perception while feeling tired belongs to introspection.\nRationalists understand reason as a source of justification for non-empirical facts. It is often used to explain how people can know about mathematical, logical, and conceptual truths. Reason is also responsible for inferential knowledge, in which one or several beliefs are used as premises to support another belief. Memory depends on information provided by other sources, which it retains and recalls, like remembering a phone number perceived earlier. Justification by testimony relies on information one person communicates to another person. This can happen by talking to each other but can also occur in other forms, like a letter, a newspaper, and a blog.\nOther concepts.\nRationality is closely related to justification and the terms \"rational belief\" and \"justified belief\" are sometimes used as synonyms. However, rationality has a wider scope that encompasses both a theoretical side, covering beliefs, and a practical side, covering decisions, intentions, and actions. There are different conceptions about what it means for something to be rational. According to one view, a mental state is rational if it is based on or responsive to good reasons. Another view emphasizes the role of coherence, stating that rationality requires that the different mental states of a person are consistent and support each other. A slightly different approach holds that rationality is about achieving certain goals. Two goals of theoretical rationality are accuracy and comprehensiveness, meaning that a person has as few false beliefs and as many true beliefs as possible.\nEpistemic norms are criteria to assess the cognitive quality of beliefs, like their justification and rationality. Epistemologists distinguish between deontic norms, which are prescriptions about what people should believe or which beliefs are correct, and axiological norms, which identify the goals and values of beliefs. Epistemic norms are closely related to intellectual or epistemic virtues, which are character traits like open-mindedness and conscientiousness. Epistemic virtues help individuals form true beliefs and acquire knowledge. They contrast with epistemic vices and act as foundational concepts of virtue epistemology.\nEvidence for a belief is information that favors or supports it. Epistemologists understand evidence primarily in terms of mental states, for example, as sensory impressions or as other propositions that a person knows. But in a wider sense, it can also include physical objects, like bloodstains examined by forensic analysts or financial records studied by investigative journalists. Evidence is often understood in terms of probability: evidence for a belief makes it more likely that the belief is true. A defeater is evidence against a belief or evidence that undermines another piece of evidence. For instance, witness testimony connecting a suspect to a crime is evidence of their guilt while an alibi is a defeater. Evidentialists analyze justification in terms of evidence by saying that to be justified, a belief needs to rest on adequate evidence.\nThe presence of evidence usually affects doubt and certainty, which are subjective attitudes toward propositions that differ regarding their level of confidence. Doubt involves questioning the validity or truth of a proposition. Certainty, by contrast, is a strong affirmative conviction, meaning that the person is free of doubt that the proposition is true. In epistemology, doubt and certainty play central roles in skeptical projects aiming to establish that no belief is immune to doubt, such as ancient Greek skepticism, and in attempts to find a secure foundation of all knowledge, such as Ren\u00e9 Descartes' foundationalist epistemology.\nWhile propositional knowledge is the main topic in epistemology, some theorists focus on understanding instead. Understanding is a more holistic notion that involves a wider grasp of a subject. To understand something, a person requires awareness of how different things are connected and why they are the way they are. For example, knowledge of isolated facts memorized from a textbook does not amount to understanding. According to one view, understanding is a special epistemic good that, unlike propositional knowledge, is always intrinsically valuable. Wisdom is similar in this regard and is sometimes considered the highest epistemic good. It encompasses a reflective understanding with practical applications. It helps people grasp and evaluate complex situations and lead a good life.\nSchools of thought.\nSkepticism, fallibilism, and relativism.\nPhilosophical skepticism questions the human ability to arrive at knowledge. Some skeptics limit their criticism to certain domains of knowledge. For example, religious skeptics say that it is impossible to have certain knowledge about the existence of deities or other religious doctrines. Similarly, moral skeptics challenge the existence of moral knowledge and metaphysical skeptics say that humans cannot know ultimate reality.\nGlobal skepticism is the widest form of skepticism, asserting that there is no knowledge in any domain. In ancient philosophy, this view was accepted by academic skeptics while Pyrrhonian skeptics recommended the suspension of belief to achieve a state of tranquility. Overall, not many epistemologists have explicitly defended global skepticism. The influence of this position derives mainly from attempts by other philosophers to show that their theory overcomes the challenge of skepticism. For example, Ren\u00e9 Descartes used methodological doubt to find facts that cannot be doubted.\nOne consideration in favor of global skepticism is the dream argument. It starts from the observation that, while people are dreaming, they are usually unaware of this. This inability to distinguish between dream and regular experience is used to argue that there is no certain knowledge since a person can never be sure that they are not dreaming. Some critics assert that global skepticism is a self-refuting idea because denying the existence of knowledge is itself a knowledge claim. Another objection says that the abstract reasoning leading to skepticism is not convincing enough to overrule common sense.\nFallibilism is another response to skepticism. Fallibilists agree with skeptics that absolute certainty is impossible. Most fallibilists disagree with skeptics about the existence of knowledge, saying that there is knowledge since it does not require absolute certainty. They emphasize the need to keep an open and inquisitive mind since doubt can never be fully excluded, even for well-established knowledge claims like thoroughly tested scientific theories.\nEpistemic relativism is related to skepticism but differs since it does not question the existence of knowledge in general. Instead, epistemic relativists only reject the idea that there are universal epistemic standards or absolute principles that apply equally to everyone. This means that what a person knows depends on the subjective criteria or social conventions used to assess epistemic status.\nEmpiricism and rationalism.\nThe debate between empiricism and rationalism centers on the origins of human knowledge. Empiricism emphasizes that sense experience is the primary source of all knowledge. Some empiricists express this view by describing the mind as a blank slate that only develops ideas about the external world through the sense data it receives from the sensory organs. According to them, the mind can arrive at various additional insights by comparing impressions, combining them, generalizing to arrive at more abstract ideas, and deducing new conclusions from them. Empiricists say that all these mental operations depend on material from the senses and do not function on their own.\nEven though rationalists usually accept sense experience as one source of knowledge, they also say that important forms of knowledge are directly possessed by reason without sense experience, like knowledge of mathematical and logical truths. According to some rationalists, the mind possesses inborn ideas, which it can access without the help of the senses. Others hold that there is an additional cognitive faculty, sometimes called rational intuition, through which people acquire nonempirical knowledge. Some rationalists limit their discussion to the origin of concepts, saying that the mind relies on inborn categories to understand the world and organize experience.\nFoundationalism and coherentism.\nFoundationalists and coherentists disagree about the structure of knowledge. Foundationalism distinguishes between basic and non-basic beliefs. A belief is basic if it is justified directly, meaning that its validity does not depend on the support of other beliefs. A belief is non-basic if it is justified by another belief. For example, the belief that it rained last night is a non-basic belief if it is inferred from the observation that the street is wet. According to foundationalism, basic beliefs are the foundation on which all other knowledge is built while non-basic beliefs act as the superstructure resting on this foundation.\nCoherentists reject the distinction between basic and non-basic beliefs, saying that the justification of any belief depends on other beliefs. They assert that a belief must be in tune with other beliefs to amount to knowledge. This is the case if the beliefs are consistent and support each other. According to coherentism, justification is a holistic aspect determined by the whole system of beliefs, which resembles an interconnected web.\nThe view of foundherentism is an intermediary position combining elements of both foundationalism and coherentism. It accepts the distinction between basic and non-basic beliefs while asserting that the justification of non-basic beliefs depends on coherence with other beliefs.\nInfinitism presents another approach to the structure of knowledge. It agrees with coherentism that there are no basic beliefs while rejecting the view that beliefs can support each other in a circular manner. Instead, it argues that beliefs form infinite justification chains, in which each link of the chain supports the belief following it and is supported by the belief preceding it.\nInternalism and externalism.\nThe disagreement between internalism and externalism is about the sources of justification. Internalists say that justification depends only on factors within the individual. Examples of such factors include perceptual experience, memories, and the possession of other beliefs. This view emphasizes the importance of the cognitive perspective of the individual in the form of their mental states. It is commonly associated with the idea that the relevant factors are accessible, meaning that the individual can become aware of their reasons for holding a justified belief through introspection and reflection.\nEvidentialism is an influential internalist view. It says that justification depends on the possession of evidence. In this context, evidence for a belief is any information in the individual's mind that supports the belief. For example, the perceptual experience of rain is evidence for the belief that it is raining. Evidentialists have suggested various other forms of evidence, including memories, intuitions, and other beliefs. According to evidentialism, a belief is justified if the individual's evidence supports the belief and they hold the belief on the basis of this evidence.\nExternalism, by contrast, asserts that at least some relevant factors of knowledge are external to the individual. For instance, when considering the belief that a cup of coffee stands on the table, externalists are not primarily interested in the subjective perceptual experience that led to this belief. Instead, they focus on objective factors, like the quality of the person's eyesight, their ability to differentiate coffee from other beverages, and the circumstances under which they observed the cup. A key motivation of many forms of externalism is that justification makes it more likely that a belief is true. Based on this view, justification is external to the extent that some factors contributing to this likelihood are not part of the believer's cognitive perspective.\nReliabilism is an externalist theory asserting that a reliable connection between belief and truth is required for justification. Some reliabilists explain this in terms of reliable processes. According to this view, a belief is justified if it is produced by a reliable belief-formation process, like perception. A belief-formation process is reliable if most of the beliefs it causes are true. A slightly different view focuses on beliefs rather than belief-formation processes, saying that a belief is justified if it is a reliable indicator of the fact it presents. This means that the belief tracks the fact: the person believes it because it is a fact but would not believe it otherwise.\nVirtue epistemology is another type of externalism and is sometimes understood as a form of reliabilism. It says that a belief is justified if it manifests intellectual virtues. Intellectual virtues are capacities or traits that perform cognitive functions and help people form true beliefs. Suggested examples include faculties like vision, memory, and introspection.\nOthers.\nIn the epistemology of perception, direct and indirect realists disagree about the connection between the perceiver and the perceived object. Direct realists say that this connection is direct, meaning that there is no difference between the object present in perceptual experience and the physical object causing this experience. According to indirect realism, the connection is indirect since there are mental entities, like ideas or sense data, that mediate between the perceiver and the external world. The contrast between direct and indirect realism is important for explaining the nature of illusions.\nConstructivism in epistemology is the theory that how people view the world is not a simple reflection of external reality but an invention or a social construction. This view emphasizes the creative role of interpretation while undermining objectivity since social constructions may differ from society to society.\nAccording to contrastivism, knowledge is a comparative term, meaning that to know something involves distinguishing it from relevant alternatives. For example, if a person spots a bird in the garden, they may know that it is a sparrow rather than an eagle but they may not know that it is a sparrow rather than an indistinguishable sparrow hologram.\nEpistemic conservatism is a view about belief revision. It gives preference to the beliefs a person already has, asserting that a person should only change their beliefs if they have a good reason to. One motivation for adopting epistemic conservatism is that the cognitive resources of humans are limited, meaning that it is not feasible to constantly reexamine every belief.\nPragmatist epistemology is a form of fallibilism that emphasizes the close relation between knowing and acting. It sees the pursuit of knowledge as an ongoing process guided by common sense and experience while always open to revision. It reinterprets some core epistemological notions, for example, by conceptualizing beliefs as habits that shape actions rather then as representations that mirror the world.\nBayesian epistemology is a formal approach based on the idea that people have degrees of belief representing how certain they are. It uses probability theory to define norms of rationality that govern how certain people should be about their beliefs.\nPhenomenological epistemology emphasizes the importance of first-person experience. It distinguishes between the natural and the phenomenological attitudes. The natural attitude focuses on objects belonging to common sense and natural science. The phenomenological attitude focuses on the experience of objects and aims to provide a presuppositionless description of how objects appear to the observer.\nParticularism and generalism disagree about the right method of conducting epistemological research. Particularists start their inquiry by looking at specific cases. For example, to find a definition of knowledge, they rely on their intuitions about concrete instances of knowledge and particular thought experiments. They use these observations as methodological constraints that any theory of more general principles needs to follow. Generalists proceed in the opposite direction. They give preference to general epistemic principles, saying that it is not possible to accurately identify and describe specific cases without a grasp of these principles. Other methods in contemporary epistemology aim to extract philosophical insights from ordinary language or look at the role of knowledge in making assertions and guiding actions.\nPostmodern epistemology criticizes the conditions of knowledge in advanced societies. This concerns in particular the metanarrative of a constant progress of scientific knowledge leading to a universal and foundational understanding of reality. Similarly, feminist epistemology adopts a critical perspective with its main focus on the effect of gender on knowledge. Among other topics, it explores how preconceptions about gender influence who has access to knowledge, how knowledge is produced, and which types of knowledge are valued in society. A related critical approach, found in decolonial scholarship, opposes the global influence of Western knowledge systems. It seeks to undermine Western hegemony and decolonize knowledge.\nVarious schools of epistemology are found in traditional Indian philosophy. Many of them focus on the different sources of knowledge, called . Perception, inference, and testimony are sources discussed by most schools. Other sources only considered by some schools are non-perception, which leads to knowledge of absences, and presumption. Buddhist epistemology tends to focus on immediate experience, understood as the presentation of unique particulars without the involvement of secondary cognitive processes, like thought and desire. Ny\u0101ya epistemology is a causal theory of knowledge, understanding sources of knowledge as reliable processes that cause episodes of truthful awareness. It sees perception as the primary source of knowledge and emphasizes its importance for successful action. M\u012bm\u0101\u1e43s\u0101 epistemology understands the holy scriptures known as the Vedas as a key source of knowledge while discussing the problem of their right interpretation. Jain epistemology states that reality is many-sided, meaning that no single viewpoint can capture the entirety of truth.\nAfrican epistemology is rooted in African ontology. It emphasizes the interconnectedness of reality in the form of a continuum between knowing subject and known object. It understands knowledge as a holistic phenomenon that includes sensory, emotional, intuitive, and rational aspects and is not limited to the physical domain.\nBranches.\nSome branches of epistemology focus on the problems of knowledge within specific academic disciplines. The epistemology of science examines how scientific knowledge is generated and what problems arise in the process of validating, justifying, and interpreting scientific claims. A key issue concerns the problem of how individual observations can support universal scientific laws. Further topics include the nature of scientific evidence and the aims of science. The epistemology of mathematics studies the origin of mathematical knowledge. In exploring how mathematical theories are justified, it investigates the role of proofs and whether there are empirical sources of mathematical knowledge.\nEpistemological problems are found in most areas of philosophy. The epistemology of logic examines how people know that an argument is valid. For example, it explores how logicians justify that modus ponens is a correct rule of inference or that all contradictions are false. Epistemologists of metaphysics investigate whether knowledge of the basic structure of reality is possible and what sources this knowledge could have. Knowledge of moral statements, like the claim that lying is wrong, belongs to the epistemology of ethics. It studies the role of ethical intuitions, coherence among moral beliefs, and the problem of moral disagreement. The ethics of belief is a closely related field covering the interrelation between epistemology and ethics. It examines the norms governing belief formation and asks whether violating them is morally wrong.\nReligious epistemology studies the role of knowledge and justification for religious doctrines and practices. It evaluates the weight and reliability of evidence from religious experience and holy scriptures while also asking whether the norms of reason should be applied to religious faith. Social epistemology focuses on the social dimension of knowledge. While traditional epistemology is mainly interested in the knowledge possessed by individuals, social epistemology covers knowledge acquisition, transmission, and evaluation within groups, with specific emphasis on how people rely on each other when seeking knowledge. Historical epistemology examines how the understanding of knowledge and related concepts has changed over time. It asks whether the main issues in epistemology are perennial and to what extent past epistemological theories are relevant to contemporary debates. It is particularly concerned with scientific knowledge and practices associated with it. It contrasts with the history of epistemology, which presents, reconstructs, and evaluates epistemological theories of philosophers in the past. \nNaturalized epistemology is closely associated with the natural sciences, relying on their methods and theories to examine knowledge. Naturalistic epistemologists focus on empirical observation to formulate their theories and are often critical of approaches to epistemology that proceed by \"a priori\" reasoning. Evolutionary epistemology is a naturalistic approach that understands cognition as a product of evolution, examining knowledge and the cognitive faculties responsible for it from the perspective of natural selection. Epistemologists of language explore the nature of linguistic knowledge. One of their topics is the role of tacit knowledge, for example, when native speakers have mastered the rules of grammar but are unable to explicitly articulate those rules. Epistemologists of modality examine knowledge about what is possible and necessary. Epistemic problems that arise when two people have diverging opinions on a topic are covered by the epistemology of disagreement. Epistemologists of ignorance are interested in epistemic faults and gaps in knowledge.\nThere are distinct areas of epistemology dedicated to specific sources of knowledge. Examples are the epistemology of perception, the epistemology of memory, and the epistemology of testimony.\nSome branches of epistemology are characterized by their research method. Formal epistemology employs formal tools found in logic and mathematics to investigate the nature of knowledge. Experimental epistemologists rely in their research on empirical evidence about common knowledge practices. Applied epistemology focuses on the practical application of epistemological principles to diverse real-world problems, like the reliability of knowledge claims on the internet, how to assess sexual assault allegations, and how racism may lead to epistemic injustice.\nMetaepistemologists examine the nature, goals, and research methods of epistemology. As a metatheory, it does not directly defend a position about which epistemological theories are correct but examines their fundamental concepts and background assumptions.\nRelated fields.\nEpistemology and psychology were not defined as distinct fields until the 19th century; earlier investigations about knowledge often do not fit neatly into today's academic categories. Both contemporary disciplines study beliefs and the mental processes responsible for their formation and change. One important contrast is that psychology describes what beliefs people have and how they acquire them, thereby explaining why someone has a specific belief. The focus of epistemology is on evaluating beliefs, leading to a judgment about whether a belief is justified and rational in a particular case. Epistemology has a similar intimate connection to cognitive science, which understands mental events as processes that transform information. Artificial intelligence relies on the insights of epistemology and cognitive science to implement concrete solutions to problems associated with knowledge representation and automatic reasoning. \nLogic is the study of correct reasoning. For epistemology, it is relevant to inferential knowledge, which arises when a person reasons from one known fact to another. This is the case, for example, if a person does not know directly that formula_2 but comes to infer it based on their knowledge that formula_3, formula_4, and formula_5. Whether an inferential belief amounts to knowledge depends on the form of reasoning used, in particular, that the process does not violate the laws of logic. Another overlap between the two fields is found in the epistemic approach to fallacies. Fallacies are faulty arguments based on incorrect reasoning. The epistemic approach to fallacies explains why they are faulty, stating that arguments aim to expand knowledge. According to this view, an argument is a fallacy if it fails to do so. A further intersection is found in epistemic logic, which uses formal logical devices to study epistemological concepts like \"knowledge\" and \"belief\".\nBoth decision theory and epistemology are interested in the foundations of rational thought and the role of beliefs. Unlike many approaches in epistemology, the main focus of decision theory lies less in the theoretical and more in the practical side, exploring how beliefs are translated into action. Decision theorists examine the reasoning involved in decision-making and the standards of good decisions. They identify beliefs as a central aspect of decision-making. One of their innovations is to distinguish between weaker and stronger beliefs. This helps them take the effect of uncertainty on decisions into consideration.\nEpistemology and education have a shared interest in knowledge, with one difference being that education focuses on the transmission of knowledge, exploring the roles of both learner and teacher. Learning theory examines how people acquire knowledge. Behavioral learning theories explain the process in terms of behavior changes, for example, by associating a certain response with a particular stimulus. Cognitive learning theories study how the cognitive processes that affect knowledge acquisition transform information. Pedagogy looks at the transmission of knowledge from the teacher's side, exploring the teaching methods they may employ. In teacher-centered methods, the teacher takes the role of the main authority delivering knowledge and guiding the learning process. In student-centered methods, the teacher mainly supports and facilitates the learning process while the students take a more active role. The beliefs students have about knowledge, called \"personal epistemology\", affect their intellectual development and learning success.\nThe anthropology of knowledge examines how knowledge is acquired, stored, retrieved, and communicated. It studies the social and cultural circumstances that affect how knowledge is reproduced and changes, covering the role of institutions like university departments and scientific journals as well as face-to-face discussions and online communications. It understands knowledge in a wide sense that encompasses various forms of understanding and culture, including practical skills. Unlike epistemology, it is not interested in whether a belief is true or justified but in how understanding is reproduced in society. The sociology of knowledge is a closely related field with a similar conception of knowledge. It explores how physical, demographic, economic, and sociocultural factors impact knowledge. It examines in what sociohistorical contexts knowledge emerges and the effects it has on people, for example, how socioeconomic conditions are related to the dominant ideology in a society.\nHistory.\nEarly reflections on the nature and sources of knowledge are found in ancient history. In ancient Greek philosophy, Plato (427\u2013347 BCE) studied what knowledge is, examining how it differs from true opinion by being based on good reasons. According to him, the process of learning something is a form of recollection in which the soul remembers what it already knew before. Plato's student Aristotle (384\u2013322 BCE) was particularly interested in scientific knowledge, exploring the role of sensory experience and how to make inferences from general principles. Aristotle's ideas influenced discussions in the Hellenistic schools of philosophy, which began to arise in the 4th century BCE and included Epicureanism, Stoicism, and skepticism. The Epicureans had an empiricist outlook, stating that sensations are always accurate and act as the supreme standard of judgments. The Stoics defended a similar position but limited themselves to lucid and specific sensations, which they regarded as true. The skepticists questioned that knowledge is possible, recommending instead suspension of judgment to arrive at a state of tranquility. Emerging in the 3rd century CE and inspired by Plato's philosophy, Neoplatonism distinguished knowledge from true belief, arguing that knowledge is infallible and limited to the realm of immaterial forms.\nThe Upanishads, philosophical scriptures composed in ancient India between 700 and 300 BCE, examined how people acquire knowledge, including the role of introspection, comparison, and deduction. In the 6th century BCE, the school of Aj\u00f1ana developed a radical skepticism questioning the possibility and usefulness of knowledge. By contrast, the school of Nyaya, which emerged in the 2nd century BCE, asserted that knowledge is possible. It provided a systematic treatment of how people acquire knowledge, distinguishing between valid and invalid sources. When Buddhist philosophers later became interested in epistemology, they relied on concepts developed in Nyaya and other traditions. Buddhist philosopher Dharmakirti (6th or 7th century CE) analyzed the process of knowing as a series of causally related events.\nAncient Chinese philosophers understood knowledge as an interconnected phenomenon fundamentally linked to ethical behavior and social involvement. Many saw wisdom as the goal of attaining knowledge. Mozi (470\u2013391 BCE) proposed a pragmatic approach to knowledge using historical records, sensory evidence, and practical outcomes to validate beliefs. Mencius () explored analogical reasoning as another source of knowledge and employed this method to criticize Mozi. Xunzi () aimed to combine empirical observation and rational inquiry. He emphasized the importance of clarity and standards of reasoning without excluding the role of feeling and emotion.\nThe relation between reason and faith was a central topic in the medieval period. In Arabic\u2013Persian philosophy, al-Farabi () and Averroes (1126\u20131198) discussed how philosophy and theology interact and which is the better vehicle to truth. Al-Ghazali () criticized many of the core teachings of previous Islamic philosophers, saying that they rely on unproven assumptions that do not amount to knowledge. Similarly in Western philosophy, Anselm of Canterbury (1033\u20131109) proposed that theological teaching and philosophical inquiry are in harmony and complement each other. Formulating a more critical approach, Peter Abelard (1079\u20131142) argued against unquestioned theological authorities and said that all things are open to rational doubt. Influenced by Aristotle, Thomas Aquinas (1225\u20131274) developed an empiricist theory, stating that \"nothing is in the intellect unless it first appeared in the senses\". According to an early form of direct realism proposed by William of Ockham (), perception of mind-independent objects happens directly without intermediaries. Meanwhile, in 14th-century India, Ga\u1e45ge\u015ba developed a reliabilist theory of knowledge and considered the problems of testimony and fallacies. In China, Wang Yangming (1472\u20131529) explored the unity of knowledge and action, holding that moral knowledge is inborn and can be attained by overcoming self-interest.\nThe course of modern philosophy was shaped by Ren\u00e9 Descartes (1596\u20131650), who claimed that philosophy must begin from a position of indubitable knowledge of first principles. Inspired by skepticism, he aimed to find absolutely certain knowledge by encountering truths that cannot be doubted. He thought that this is the case for the assertion \"I think, therefore I am\", from which he constructed the rest of his philosophical system. Descartes, together with Baruch Spinoza (1632\u20131677) and Gottfried Wilhelm Leibniz (1646\u20131716), belonged to the school of rationalism, which asserts that the mind possesses innate ideas independent of experience. John Locke (1632\u20131704) rejected this view in favor of an empiricism according to which the mind is a blank slate. This means that all ideas depend on sense experience, either as \"ideas of sense\", which are directly presented through the senses, or as \"ideas of reflection\", which the mind creates by reflecting on ideas of sense. David Hume (1711\u20131776) used this idea to explore the limits of what people can know. He said that knowledge of facts is never certain, adding that knowledge of relations between ideas, like mathematical truths, can be certain but contains no information about the world. Immanuel Kant (1724\u20131804) tried to find a middle position between rationalism and empiricism by identifying a type of knowledge that Hume had missed. For Kant, this is knowledge about principles that underlie all experience and structure it, such as spatial and temporal relations and fundamental categories of understanding. \nIn the 19th century and influenced by Kant's philosophy, Georg Wilhelm Friedrich Hegel (1770\u20131831) rejected empiricism by arguing that sensory impressions on their own cannot amount to knowledge since all knowledge is actively structured by the knowing subject. John Stuart Mill (1806\u20131873), by contrast, defended a wide-sweeping form of empiricism and explained knowledge of general truths through inductive reasoning. Charles Peirce (1839\u20131914) thought that all knowledge is fallible, emphasizing that knowledge seekers should always be ready to revise their beliefs if new evidence is encountered. He used this idea to argue against Cartesian foundationalism seeking absolutely certain truths.\nIn the 20th century, fallibilism was further explored by J. L. Austin (1911\u20131960) and Karl Popper (1902\u20131994). In continental philosophy, Edmund Husserl (1859\u20131938) applied the skeptic idea of suspending judgment to the study of experience. By not judging whether an experience is accurate or not, he tried to describe the internal structure of experience instead. Influenced by earlier empiricists, logical positivists, like A. J. Ayer (1910\u20131989), said that all knowledge is either empirical or analytic. Bertrand Russell (1872\u20131970) developed an empiricist sense-datum theory, distinguishing between direct knowledge by acquaintance of sense data and indirect knowledge by description, which is inferred from knowledge by acquaintance. Common sense had a central place in G. E. Moore's (1873\u20131958) epistemology. He used trivial observations, like the fact that he has two hands, to argue against abstract philosophical theories that deviate from common sense. Ordinary language philosophy, as practiced by the late Ludwig Wittgenstein (1889\u20131951), is a similar approach that tries to extract epistemological insights from how ordinary language is used.\nEdmund Gettier (1927\u20132021) conceived counterexamples against the idea that knowledge is the same as justified true belief. These counterexamples prompted many philosophers to suggest alternative definitions of knowledge. Developed by philosophers such as Alvin Goldman (1938\u20132024), reliabilism emerged as one of the alternatives, asserting that knowledge requires reliable sources and shifting the focus away from justification. Virtue epistemology, a closely related response, analyses belief formation in terms of the intellectual virtues or cognitive competencies involved in the process. Naturalized epistemology, as conceived by Willard Van Orman Quine (1908\u20132000), employs concepts and ideas from the natural sciences to formulate its theories. Other developments in late 20th-century epistemology were the emergence of social, feminist, and historical epistemology."}
