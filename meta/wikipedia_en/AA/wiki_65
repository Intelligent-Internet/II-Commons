{"id": "7398", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=7398", "title": "Computer security", "text": "Computer security (also cybersecurity, digital security, or information technology (IT) security) is the protection of computer software, systems and networks from threats that can lead to unauthorized information disclosure, theft or damage to hardware, software, or data, as well as from the disruption or misdirection of the services they provide.\nThe significance of the field stems from the expanded reliance on computer systems, the Internet, and wireless network standards. Its importance is further amplified by the growth of smart devices, including smartphones, televisions, and the various devices that constitute the Internet of things (IoT). Cybersecurity has emerged as one of the most significant new challenges facing the contemporary world, due to both the complexity of information systems and the societies they support. Security is particularly crucial for systems that govern large-scale systems with far-reaching physical effects, such as power distribution, elections, and finance.\nAlthough many aspects of computer security involve digital security, such as electronic passwords and encryption, physical security measures such as metal locks are still used to prevent unauthorized tampering. IT security is not a perfect subset of information security, therefore does not completely align into the security convergence schema.\nVulnerabilities and attacks.\nA vulnerability refers to a flaw in the structure, execution, functioning, or internal oversight of a computer or system that compromises its security. Most of the vulnerabilities that have been discovered are documented in the Common Vulnerabilities and Exposures (CVE) database. An \"exploitable\" vulnerability is one for which at least one working attack or \"exploit\" exists. Actors maliciously seeking vulnerabilities are known as \"threats\". Vulnerabilities can be researched, reverse-engineered, hunted, or exploited using automated tools or customized scripts.\nVarious people or parties are vulnerable to cyber attacks; however, different groups are likely to experience different types of attacks more than others.\nIn April 2023, the United Kingdom Department for Science, Innovation &amp; Technology released a report on cyber attacks over the previous 12 months. They surveyed 2,263 UK businesses, 1,174 UK registered charities, and 554 education institutions. The research found that \"32% of businesses and 24% of charities overall recall any breaches or attacks from the last 12 months.\" These figures were much higher for \"medium businesses (59%), large businesses (69%), and high-income charities with \u00a3500,000 or more in annual income (56%).\" Yet, although medium or large businesses are more often the victims, since larger companies have generally improved their security over the last decade, small and midsize businesses (SMBs) have also become increasingly vulnerable as they often \"do not have advanced tools to defend the business.\" SMBs are most likely to be affected by malware, ransomware, phishing, man-in-the-middle attacks, and Denial-of Service (DoS) Attacks.\nNormal internet users are most likely to be affected by untargeted cyberattacks. These are where attackers indiscriminately target as many devices, services, or users as possible. They do this using techniques that take advantage of the openness of the Internet. These strategies mostly include phishing, ransomware, water holing and scanning.\nTo secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of the following categories:\nBackdoor.\nA backdoor in a computer system, a cryptosystem, or an algorithm is any secret method of bypassing normal authentication or security controls. These weaknesses may exist for many reasons, including original design or poor configuration. Due to the nature of backdoors, they are of greater concern to companies and databases as opposed to individuals.\nBackdoors may be added by an authorized party to allow some legitimate access or by an attacker for malicious reasons. Criminals often use malware to install backdoors, giving them remote administrative access to a system. Once they have access, cybercriminals can \"modify files, steal personal information, install unwanted software, and even take control of the entire computer.\"\nBackdoors can be very hard to detect and are usually discovered by someone who has access to the application source code or intimate knowledge of the operating system of the computer.\nDenial-of-service attack.\nDenial-of-service attacks (DoS) are designed to make a machine or network resource unavailable to its intended users. Attackers can deny service to individual victims, such as by deliberately entering a wrong password enough consecutive times to cause the victim's account to be locked, or they may overload the capabilities of a machine or network and block all users at once. While a network attack from a single IP address can be blocked by adding a new firewall rule, many forms of distributed denial-of-service (DDoS) attacks are possible, where the attack comes from a large number of points. In this case, defending against these attacks is much more difficult. Such attacks can originate from the zombie computers of a botnet or from a range of other possible techniques, including distributed reflective denial-of-service (DRDoS), where innocent systems are fooled into sending traffic to the victim. With such attacks, the amplification factor makes the attack easier for the attacker because they have to use little bandwidth themselves. To understand why attackers may carry out these attacks, see the 'attacker motivation' section.\nPhysical access attacks.\nA direct-access attack is when an unauthorized user (an attacker) gains physical access to a computer, most likely to directly copy data from it or steal information. Attackers may also compromise security by making operating system modifications, installing software worms, keyloggers, covert listening devices or using wireless microphones. Even when the system is protected by standard security measures, these may be bypassed by booting another operating system or tool from a CD-ROM or other bootable media. Disk encryption and the Trusted Platform Module standard are designed to prevent these attacks.\nDirect service attackers are related in concept to direct memory attacks which allow an attacker to gain direct access to a computer's memory. The attacks \"take advantage of a feature of modern computers that allows certain devices, such as external hard drives, graphics cards, or network cards, to access the computer's memory directly.\"\nEavesdropping.\nEavesdropping is the act of surreptitiously listening to a private computer conversation (communication), usually between hosts on a network. It typically occurs when a user connects to a network where traffic is not secured or encrypted and sends sensitive business data to a colleague, which, when listened to by an attacker, could be exploited. Data transmitted across an \"open network\" allows an attacker to exploit a vulnerability and intercept it via various methods.\nUnlike malware, direct-access attacks, or other forms of cyber attacks, eavesdropping attacks are unlikely to negatively affect the performance of networks or devices, making them difficult to notice. In fact, \"the attacker does not need to have any ongoing connection to the software at all. The attacker can insert the software onto a compromised device, perhaps by direct insertion or perhaps by a virus or other malware, and then come back some time later to retrieve any data that is found or trigger the software to send the data at some determined time.\"\nUsing a virtual private network (VPN), which encrypts data between two points, is one of the most common forms of protection against eavesdropping. Using the best form of encryption possible for wireless networks is best practice, as well as using HTTPS instead of an unencrypted HTTP.\nPrograms such as Carnivore and NarusInSight have been used by the Federal Bureau of Investigation (FBI) and NSA to eavesdrop on the systems of internet service providers. Even machines that operate as a closed system (i.e., with no contact with the outside world) can be eavesdropped upon by monitoring the faint electromagnetic transmissions generated by the hardware. TEMPEST is a specification by the NSA referring to these attacks.\nMalware.\nMalicious software (malware) is any software code or computer program \"intentionally written to harm a computer system or its users.\" Once present on a computer, it can leak sensitive details such as personal information, business information and passwords, can give control of the system to the attacker, and can corrupt or delete data permanently. Another type of malware is ransomware, which is when \"malware installs itself onto a victim's machine, encrypts their files, and then turns around and demands a ransom (usually in Bitcoin) to return that data to the user.\"\nTypes of malware include some of the following:\nMan-in-the-middle attacks.\nMan-in-the-middle attacks (MITM) involve a malicious attacker trying to intercept, surveil or modify communications between two parties by spoofing one or both party's identities and injecting themselves in-between. Types of MITM attacks include:\nMulti-vector, polymorphic attacks.\nSurfacing in 2017, a new class of multi-vector, polymorphic cyber threats combine several types of attacks and change form to avoid cybersecurity controls as they spread.\nMulti-vector polymorphic attacks, as the name describes, are both multi-vectored and polymorphic. Firstly, they are a singular attack that involves multiple methods of attack. In this sense, they are \"multi-vectored (i.e. the attack can use multiple means of propagation such as via the Web, email and applications.\" However, they are also multi-staged, meaning that \"they can infiltrate networks and move laterally inside the network.\" The attacks can be polymorphic, meaning that the cyberattacks used such as viruses, worms or trojans \"constantly change (\"morph\") making it nearly impossible to detect them using signature-based defences.\"\nPhishing.\nPhishing is the attempt of acquiring sensitive information such as usernames, passwords, and credit card details directly from users by deceiving the users. Phishing is typically carried out by email spoofing, instant messaging, text message, or on a phone call. They often direct users to enter details at a fake website whose look and feel are almost identical to the legitimate one. The fake website often asks for personal information, such as login details and passwords. This information can then be used to gain access to the individual's real account on the real website.\nPreying on a victim's trust, phishing can be classified as a form of social engineering. Attackers can use creative ways to gain access to real accounts. A common scam is for attackers to send fake electronic invoices to individuals showing that they recently purchased music, apps, or others, and instructing them to click on a link if the purchases were not authorized. A more strategic type of phishing is spear-phishing which leverages personal or organization-specific details to make the attacker appear like a trusted source. Spear-phishing attacks target specific individuals, rather than the broad net cast by phishing attempts.\nPrivilege escalation.\nPrivilege escalation describes a situation where an attacker with some level of restricted access is able to, without authorization, elevate their privileges or access level. For example, a standard computer user may be able to exploit a vulnerability in the system to gain access to restricted data; or even become \"root\" and have full unrestricted access to a system. The severity of attacks can range from attacks simply sending an unsolicited email to a ransomware attack on large amounts of data. Privilege escalation usually starts with social engineering techniques, often phishing.\nPrivilege escalation can be separated into two strategies, horizontal and vertical privilege escalation:\nSide-channel attack.\nAny computational system affects its environment in some form. This effect it has on its environment can range from electromagnetic radiation, to residual effect on RAM cells which as a consequence make a Cold boot attack possible, to hardware implementation faults that allow for access or guessing of other values that normally should be inaccessible. In Side-channel attack scenarios, the attacker would gather such information about a system or network to guess its internal state and as a result access the information which is assumed by the victim to be secure. The target information in a side channel can be challenging to detect due to its low amplitude when combined with other signals \nSocial engineering.\nSocial engineering, in the context of computer security, aims to convince a user to disclose secrets such as passwords, card numbers, etc. or grant physical access by, for example, impersonating a senior executive, bank, a contractor, or a customer. This generally involves exploiting people's trust, and relying on their cognitive biases. A common scam involves emails sent to accounting and finance department personnel, impersonating their CEO and urgently requesting some action. One of the main techniques of social engineering are phishing attacks.\nIn early 2016, the FBI reported that such business email compromise (BEC) scams had cost US businesses more than $2 billion in about two years.\nIn May 2016, the Milwaukee Bucks NBA team was the victim of this type of cyber scam with a perpetrator impersonating the team's president Peter Feigin, resulting in the handover of all the team's employees' 2015 W-2 tax forms.\nSpoofing.\nSpoofing is an act of pretending to be a valid entity through the falsification of data (such as an IP address or username), in order to gain access to information or resources that one is otherwise unauthorized to obtain. Spoofing is closely related to phishing. There are several types of spoofing, including:\nIn 2018, the cybersecurity firm Trellix published research on the life-threatening risk of spoofing in the healthcare industry.\nTampering.\nTampering describes a malicious modification or alteration of data. It is an intentional but unauthorized act resulting in the modification of a system, components of systems, its intended behavior, or data. So-called Evil Maid attacks and security services planting of surveillance capability into routers are examples.\nHTML smuggling.\nHTML smuggling allows an attacker to \"smuggle\" a malicious code inside a particular HTML or web page. HTML files can carry payloads concealed as benign, inert data in order to defeat content filters. These payloads can be reconstructed on the other side of the filter.\nWhen a target user opens the HTML, the malicious code is activated; the web browser then \"decodes\" the script, which then unleashes the malware onto the target's device.\nInformation security practices.\nEmployee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness toward information security within an organization. Information security culture is the \"...totality of patterns of behavior in an organization that contributes to the protection of information of all kinds.\"\nAndersson and Reimers (2014) found that employees often do not see themselves as part of their organization's information security effort and often take actions that impede organizational changes. Indeed, the Verizon Data Breach Investigations Report 2020, which examined 3,950 security breaches, discovered 30% of cybersecurity incidents involved internal actors within a company. Research shows information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change\", authors commented, \"It's a never-ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nComputer protection (countermeasures).\nIn computer security, a countermeasure is an action, device, procedure or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.\nSome common countermeasures are listed in the following sections:\nSecurity by design.\nSecurity by design, or alternately secure by design, means that the software has been designed from the ground up to be secure. In this case, security is considered a main feature.\nThe UK government's National Cyber Security Centre separates secure cyber design principles into five sections:\nThese design principles of security by design can include some of the following techniques:\nSecurity architecture.\nSecurity architecture can be defined as the \"practice of designing computer systems to achieve security goals.\" These goals have overlap with the principles of \"security by design\" explored above, including to \"make initial compromise of the system difficult,\" and to \"limit the impact of any compromise.\" In practice, the role of a security architect would be to ensure the structure of a system reinforces the security of the system, and that new changes are safe and meet the security requirements of the organization.\nSimilarly, Techopedia defines security architecture as \"a unified security design that addresses the necessities and potential risks involved in a certain scenario or environment. It also specifies when and where to apply security controls. The design process is generally reproducible.\" The key attributes of security architecture are:\nPracticing security architecture provides the right foundation to systematically address business, IT and security concerns in an organization.\nSecurity measures.\nA state of computer security is the conceptual ideal, attained by the use of three processes: threat prevention, detection, and response. These processes are based on various policies and system components, which include the following:\nToday, computer security consists mainly of preventive measures, like firewalls or an exit procedure. A firewall can be defined as a way of filtering network data between a host or a network and another network, such as the Internet. They can be implemented as software running on the machine, hooking into the network stack (or, in the case of most UNIX-based operating systems such as Linux, built into the operating system kernel) to provide real-time filtering and blocking. Another implementation is a so-called \"physical firewall\", which consists of a separate machine filtering network traffic. Firewalls are common amongst machines that are permanently connected to the Internet.\nSome organizations are turning to big data platforms, such as Apache Hadoop, to extend data accessibility and machine learning to detect advanced persistent threats.\nIn order to ensure adequate security, the confidentiality, integrity and availability of a network, better known as the CIA triad, must be protected and is considered the foundation to information security. To achieve those objectives, administrative, physical and technical security measures should be employed. The amount of security afforded to an asset can only be determined when its value is known.\nVulnerability management.\nVulnerability management is the cycle of identifying, fixing or mitigating vulnerabilities, especially in software and firmware. Vulnerability management is integral to computer security and network security.\nVulnerabilities can be discovered with a vulnerability scanner, which analyzes a computer system in search of known vulnerabilities, such as open ports, insecure software configuration, and susceptibility to malware. In order for these tools to be effective, they must be kept up to date with every new update the vendor release. Typically, these updates will scan for the new vulnerabilities that were introduced recently.\nBeyond vulnerability scanning, many organizations contract outside security auditors to run regular penetration tests against their systems to identify vulnerabilities. In some sectors, this is a contractual requirement.\nReducing vulnerabilities.\nThe act of assessing and reducing vulnerabilities to cyber attacks is commonly referred to as information technology security assessments. They aim to assess systems for risk and to predict and test for their vulnerabilities. While formal verification of the correctness of computer systems is possible, it is not yet common. Operating systems formally verified include seL4, and SYSGO's PikeOS \u2013 but these make up a very small percentage of the market.\nIt is possible to reduce an attacker's chances by keeping systems up to date with security patches and updates and by hiring people with expertise in security. Large companies with significant threats can hire Security Operations Centre (SOC) Analysts. These are specialists in cyber defences, with their role ranging from \"conducting threat analysis to investigating reports of any new issues and preparing and testing disaster recovery plans.\"\nWhilst no measures can completely guarantee the prevention of an attack, these measures can help mitigate the damage of possible attacks. The effects of data loss/damage can be also reduced by careful backing up and insurance.\nOutside of formal assessments, there are various methods of reducing vulnerabilities. Two factor authentication is a method for mitigating unauthorized access to a system or sensitive information. It requires \"something you know:\" a password or PIN, and \"something you have\": a card, dongle, cellphone, or another piece of hardware. This increases security as an unauthorized person needs both of these to gain access.\nProtecting against social engineering and direct computer access (physical) attacks can only happen by non-computer means, which can be difficult to enforce, relative to the sensitivity of the information. Training is often involved to help mitigate this risk by improving people's knowledge of how to protect themselves and by increasing people's awareness of threats. However, even in highly disciplined environments (e.g. military organizations), social engineering attacks can still be difficult to foresee and prevent.\nInoculation, derived from inoculation theory, seeks to prevent social engineering and other fraudulent tricks and traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.\nHardware protection mechanisms.\nHardware-based or assisted computer security also offers an alternative to software-only computer security. Using devices and methods such as dongles, trusted platform modules, intrusion-aware cases, drive locks, disabling USB ports, and mobile-enabled access may be considered more secure due to the physical access (or sophisticated backdoor access) required in order to be compromised. Each of these is covered in more detail below.\nSecure operating systems.\nOne use of the term \"computer security\" refers to technology that is used to implement secure operating systems. Using secure operating systems is a good way of ensuring computer security. These are systems that have achieved certification from an external security-auditing organization, the most popular evaluations are Common Criteria (CC).\nSecure coding.\nIn software engineering, secure coding aims to guard against the accidental introduction of security vulnerabilities. It is also possible to create software designed from the ground up to be secure. Such systems are \"secure by design\". Beyond this, formal verification aims to prove the correctness of the algorithms underlying a system;\nimportant for cryptographic protocols for example.\nCapabilities and access control lists.\nWithin computer systems, two of the main security models capable of enforcing privilege separation are access control lists (ACLs) and role-based access control (RBAC).\nAn access-control list (ACL), with respect to a computer file system, is a list of permissions associated with an object. An ACL specifies which users or system processes are granted access to objects, as well as what operations are allowed on given objects.\nRole-based access control is an approach to restricting system access to authorized users, used by the majority of enterprises with more than 500 employees, and can implement mandatory access control (MAC) or discretionary access control (DAC).\nA further approach, capability-based security has been mostly restricted to research operating systems. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open-source project in the area is the E language.\nUser security training.\nThe end-user is widely recognized as the weakest link in the security chain and it is estimated that more than 90% of security incidents and breaches involve some kind of human error. Among the most commonly recorded forms of errors and misjudgment are poor password management, sending emails containing sensitive data and attachments to the wrong recipient, the inability to recognize misleading URLs and to identify fake websites and dangerous email attachments. A common mistake that users make is saving their user id/password in their browsers to make it easier to log in to banking sites. This is a gift to attackers who have obtained access to a machine by some means. The risk may be mitigated by the use of two-factor authentication.\nAs the human component of cyber risk is particularly relevant in determining the global cyber risk an organization is facing, security awareness training, at all levels, not only provides formal compliance with regulatory and industry mandates but is considered essential in reducing cyber risk and protecting individuals and companies from the great majority of cyber threats.\nThe focus on the end-user represents a profound cultural change for many security practitioners, who have traditionally approached cybersecurity exclusively from a technical perspective, and moves along the lines suggested by major security centers to develop a culture of cyber awareness within the organization, recognizing that a security-aware user provides an important line of defense against cyber attacks.\nDigital hygiene.\nRelated to end-user training, digital hygiene or cyber hygiene is a fundamental principle relating to information security and, as the analogy with personal hygiene shows, is the equivalent of establishing simple routine measures to minimize the risks from cyber threats. The assumption is that good cyber hygiene practices can give networked users another layer of protection, reducing the risk that one vulnerable node will be used to either mount attacks or compromise another node or network, especially from common cyberattacks. Cyber hygiene should also not be mistaken for proactive cyber defence, a military term.\nThe most common acts of digital hygiene can include updating malware protection, cloud back-ups, passwords, and ensuring restricted admin rights and network firewalls. As opposed to a purely technology-based defense against threats, cyber hygiene mostly regards routine measures that are technically simple to implement and mostly dependent on discipline or education. It can be thought of as an abstract list of tips or measures that have been demonstrated as having a positive effect on personal or collective digital security. As such, these measures can be performed by laypeople, not just security experts.\nCyber hygiene relates to personal hygiene as computer viruses relate to biological viruses (or pathogens). However, while the term \"computer virus\" was coined almost simultaneously with the creation of the first working computer viruses, the term \"cyber hygiene\" is a much later invention, perhaps as late as 2000 by Internet pioneer Vint Cerf. It has since been adopted by the Congress and Senate of the United States, the FBI, EU institutions and heads of state.\nDifficulty of responding to breaches.\nResponding to attempted security breaches is often very difficult for a variety of reasons, including:\nWhere an attack succeeds and a breach occurs, many jurisdictions now have in place mandatory security breach notification laws.\nSystems at risk.\nThe growth in the number of computer systems and the increasing reliance upon them by individuals, businesses, industries, and governments means that there are an increasing number of systems at risk.\nFinancial systems.\nThe computer systems of financial regulators and financial institutions like the U.S. Securities and Exchange Commission, SWIFT, investment banks, and commercial banks are prominent hacking targets for cybercriminals interested in manipulating markets and making illicit gains. Websites and apps that accept or store credit card numbers, brokerage accounts, and bank account information are also prominent hacking targets, because of the potential for immediate financial gain from transferring money, making purchases, or selling the information on the black market. In-store payment systems and ATMs have also been tampered with in order to gather customer account data and PINs.\nThe UCLA Internet Report: Surveying the Digital Future (2000) found that the privacy of personal data created barriers to online sales and that more than nine out of 10 internet users were somewhat or very concerned about credit card security.\nThe most common web technologies for improving security between browsers and websites are named SSL (Secure Sockets Layer), and its successor TLS (Transport Layer Security), identity management and authentication services, and domain name services allow companies and consumers to engage in secure communications and commerce. Several versions of SSL and TLS are commonly used today in applications such as web browsing, e-mail, internet faxing, instant messaging, and VoIP (voice-over-IP). There are various interoperable implementations of these technologies, including at least one implementation that is open source. Open source allows anyone to view the application's source code, and look for and report vulnerabilities.\nThe credit card companies Visa and MasterCard cooperated to develop the secure EMV chip which is embedded in credit cards. Further developments include the Chip Authentication Program where banks give customers hand-held card readers to perform online secure transactions. Other developments in this arena include the development of technology such as Instant Issuance which has enabled shopping mall kiosks acting on behalf of banks to issue on-the-spot credit cards to interested customers.\nUtilities and industrial equipment.\nComputers control functions at many utilities, including coordination of telecommunications, the power grid, nuclear power plants, and valve opening and closing in water and gas networks. The Internet is a potential attack vector for such machines if connected, but the Stuxnet worm demonstrated that even equipment controlled by computers not connected to the Internet can be vulnerable. In 2014, the Computer Emergency Readiness Team, a division of the Department of Homeland Security, investigated 79 hacking incidents at energy companies.\nAviation.\nThe aviation industry is very reliant on a series of complex systems which could be attacked. A simple power outage at one airport can cause repercussions worldwide, much of the system relies on radio transmissions which could be disrupted, and controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore. There is also potential for attack from within an aircraft.\nImplementing fixes in aerospace systems poses a unique challenge because efficient air transportation is heavily affected by weight and volume. Improving security by adding physical devices to airplanes could increase their unloaded weight, and could potentially reduce cargo or passenger capacity.\nIn Europe, with the (Pan-European Network Service) and NewPENS, and in the US with the NextGen program, air navigation service providers are moving to create their own dedicated networks.\nMany modern passports are now biometric passports, containing an embedded microchip that stores a digitized photograph and personal information such as name, gender, and date of birth. In addition, more countries are introducing facial recognition technology to reduce identity-related fraud. The introduction of the ePassport has assisted border officials in verifying the identity of the passport holder, thus allowing for quick passenger processing. Plans are under way in the US, the UK, and Australia to introduce SmartGate kiosks with both retina and fingerprint recognition technology. The airline industry is moving from the use of traditional paper tickets towards the use of electronic tickets (e-tickets). These have been made possible by advances in online credit card transactions in partnership with the airlines. Long-distance bus companies are also switching over to e-ticketing transactions today.\nThe consequences of a successful attack range from loss of confidentiality to loss of system integrity, air traffic control outages, loss of aircraft, and even loss of life.\nConsumer devices.\nDesktop computers and laptops are commonly targeted to gather passwords or financial account information or to construct a botnet to attack another target. Smartphones, tablet computers, smart watches, and other mobile devices such as quantified self devices like activity trackers have sensors such as cameras, microphones, GPS receivers, compasses, and accelerometers which could be exploited, and may collect personal information, including sensitive health information. WiFi, Bluetooth, and cell phone networks on any of these devices could be used as attack vectors, and sensors might be remotely activated after a successful breach.\nThe increasing number of home automation devices such as the Nest thermostat are also potential targets.\nHealthcare.\nToday many healthcare providers and health insurance companies use the internet to provide enhanced products and services. Examples are the use of tele-health to potentially offer better quality and access to healthcare, or fitness trackers to lower insurance premiums. Patient records are increasingly being placed on secure in-house networks, alleviating the need for extra storage space.\nLarge corporations.\nLarge corporations are common targets. In many cases attacks are aimed at financial gain through identity theft and involve data breaches. Examples include the loss of millions of clients' credit card and financial details by Home Depot, Staples, Target Corporation, and Equifax.\nMedical records have been targeted in general identify theft, health insurance fraud, and impersonating patients to obtain prescription drugs for recreational purposes or resale. Although cyber threats continue to increase, 62% of all organizations did not increase security training for their business in 2015.\nNot all attacks are financially motivated, however: security firm HBGary Federal had a serious series of attacks in 2011 from hacktivist group Anonymous in retaliation for the firm's CEO claiming to have infiltrated their group, and Sony Pictures was hacked in 2014 with the apparent dual motive of embarrassing the company through data leaks and crippling the company by wiping workstations and servers.\nAutomobiles.\nVehicles are increasingly computerized, with engine timing, cruise control, anti-lock brakes, seat belt tensioners, door locks, airbags and advanced driver-assistance systems on many models. Additionally, connected cars may use WiFi and Bluetooth to communicate with onboard consumer devices and the cell phone network. Self-driving cars are expected to be even more complex. All of these systems carry some security risks, and such issues have gained wide attention.\nSimple examples of risk include a malicious compact disc being used as an attack vector, and the car's onboard microphones being used for eavesdropping. However, if access is gained to a car's internal controller area network, the danger is much greater \u2013 and in a widely publicized 2015 test, hackers remotely carjacked a vehicle from 10 miles away and drove it into a ditch.\nManufacturers are reacting in numerous ways, with Tesla in 2016 pushing out some security fixes \"over the air\" into its cars' computer systems. In the area of autonomous vehicles, in September 2016 the United States Department of Transportation announced some initial safety standards, and called for states to come up with uniform policies.\nAdditionally, e-Drivers' licenses are being developed using the same technology. For example, Mexico's licensing authority (ICV) has used a smart card platform to issue the first e-Drivers' licenses to the city of Monterrey, in the state of Nuevo Le\u00f3n.\nShipping.\nShipping companies have adopted RFID (Radio Frequency Identification) technology as an efficient, digitally secure, tracking device. Unlike a barcode, RFID can be read up to 20 feet away. RFID is used by FedEx and UPS.\nGovernment.\nGovernment and military computer systems are commonly attacked by activists and foreign powers. Local and regional government infrastructure such as traffic light controls, police and intelligence agency communications, personnel records, as well as student records.\nThe FBI, CIA, and Pentagon, all utilize secure controlled access technology for any of their buildings. However, the use of this form of technology is spreading into the entrepreneurial world. More and more companies are taking advantage of the development of digitally secure controlled access technology. GE's ACUVision, for example, offers a single panel platform for access control, alarm monitoring and digital recording.\nInternet of things and physical vulnerabilities.\nThe Internet of things (IoT) is the network of physical objects such as devices, vehicles, and buildings that are embedded with electronics, software, sensors, and network connectivity that enables them to collect and exchange data. Concerns have been raised that this is being developed without appropriate consideration of the security challenges involved.\nWhile the IoT creates opportunities for more direct integration of the physical world into computer-based systems,\nit also provides opportunities for misuse. In particular, as the Internet of Things spreads widely, cyberattacks are likely to become an increasingly physical (rather than simply virtual) threat. If a front door's lock is connected to the Internet, and can be locked/unlocked from a phone, then a criminal could enter the home at the press of a button from a stolen or hacked phone. People could stand to lose much more than their credit card numbers in a world controlled by IoT-enabled devices. Thieves have also used electronic means to circumvent non-Internet-connected hotel door locks.\nAn attack aimed at physical infrastructure or human lives is often called a cyber-kinetic attack. As IoT devices and appliances become more widespread, the prevalence and potential damage of cyber-kinetic attacks can increase substantially.\nMedical systems.\nMedical devices have either been successfully attacked or had potentially deadly vulnerabilities demonstrated, including both in-hospital diagnostic equipment and implanted devices including pacemakers and insulin pumps. There are many reports of hospitals and hospital organizations getting hacked, including ransomware attacks, Windows XP exploits, viruses, and data breaches of sensitive data stored on hospital servers. On 28 December 2016 the US Food and Drug Administration released its recommendations for how medical device manufacturers should maintain the security of Internet-connected devices \u2013 but no structure for enforcement.\nEnergy sector.\nIn distributed generation systems, the risk of a cyber attack is real, according to \"Daily Energy Insider\". An attack could cause a loss of power in a large area for a long period of time, and such an attack could have just as severe consequences as a natural disaster. The District of Columbia is considering creating a Distributed Energy Resources (DER) Authority within the city, with the goal being for customers to have more insight into their own energy use and giving the local electric utility, Pepco, the chance to better estimate energy demand. The D.C. proposal, however, would \"allow third-party vendors to create numerous points of energy distribution, which could potentially create more opportunities for cyber attackers to threaten the electric grid.\"\nTelecommunications.\nPerhaps the most widely known digitally secure telecommunication device is the SIM (Subscriber Identity Module) card, a device that is embedded in most of the world's cellular devices before any service can be obtained. The SIM card is just the beginning of this digitally secure environment.\nThe Smart Card Web Servers draft standard (SCWS) defines the interfaces to an HTTP server in a smart card. Tests are being conducted to secure OTA (\"over-the-air\") payment and credit card information from and to a mobile phone. \nCombination SIM/DVD devices are being developed through Smart Video Card technology which embeds a DVD-compliant optical disc into the card body of a regular SIM card.\nOther telecommunication developments involving digital security include mobile signatures, which use the embedded SIM card to generate a legally binding electronic signature.\nCost and impact of security breaches.\nSerious financial damage has been caused by security breaches, but because there is no standard model for estimating the cost of an incident, the only data available is that which is made public by the organizations involved. \"Several computer security consulting firms produce estimates of total worldwide losses attributable to virus and worm attacks and to hostile digital acts in general. The 2003 loss estimates by these firms range from $13 billion (worms and viruses only) to $226 billion (for all forms of covert attacks). The reliability of these estimates is often challenged; the underlying methodology is basically anecdotal.\"\nHowever, reasonable estimates of the financial cost of security breaches can actually help organizations make rational investment decisions. According to the classic Gordon-Loeb Model analyzing the optimal investment level in information security, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).\nAttacker motivation.\nAs with physical security, the motivations for breaches of computer security vary between attackers. Some are thrill-seekers or vandals, some are activists, others are criminals looking for financial gain. State-sponsored attackers are now common and well resourced but started with amateurs such as Markus Hess who hacked for the KGB, as recounted by Clifford Stoll in \"The Cuckoo's Egg\".\nAttackers motivations can vary for all types of attacks from pleasure to political goals. For example, hacktivists may target a company or organization that carries out activities they do not agree with. This would be to create bad publicity for the company by having its website crash.\nHigh capability hackers, often with larger backing or state sponsorship, may attack based on the demands of their financial backers. These attacks are more likely to attempt more serious attack. An example of a more serious attack was the 2015 Ukraine power grid hack, which reportedly utilised the spear-phising, destruction of files, and denial-of-service attacks to carry out the full attack.\nAdditionally, recent attacker motivations can be traced back to extremist organizations seeking to gain political advantage or disrupt social agendas. The growth of the internet, mobile technologies, and inexpensive computing devices have led to a rise in capabilities but also to the risk to environments that are deemed as vital to operations. All critical targeted environments are susceptible to compromise and this has led to a series of proactive studies on how to migrate the risk by taking into consideration motivations by these types of actors. Several stark differences exist between the hacker motivation and that of nation state actors seeking to attack based on an ideological preference.\nA key aspect of threat modeling for any system is identifying the motivations behind potential attacks and the individuals or groups likely to carry them out. The level and detail of security measures will differ based on the specific system being protected. For instance, a home personal computer, a bank, and a classified military network each face distinct threats, despite using similar underlying technologies.\nComputer security incident management.\nComputer security incident management is an organized approach to addressing and managing the aftermath of a computer security incident or compromise with the goal of preventing a breach or thwarting a cyberattack. An incident that is not identified and managed at the time of intrusion typically escalates to a more damaging event such as a data breach or system failure. The intended outcome of a computer security incident response plan is to contain the incident, limit damage and assist recovery to business as usual. Responding to compromises quickly can mitigate exploited vulnerabilities, restore services and processes and minimize losses.\nIncident response planning allows an organization to establish a series of best practices to stop an intrusion before it causes damage. Typical incident response plans contain a set of written instructions that outline the organization's response to a cyberattack. Without a documented plan in place, an organization may not successfully detect an intrusion or compromise and stakeholders may not understand their roles, processes and procedures during an escalation, slowing the organization's response and resolution.\nThere are four key components of a computer security incident response plan:\nNotable attacks and breaches.\nSome illustrative examples of different types of computer security breaches are given below.\nRobert Morris and the first computer worm.\nIn 1988, 60,000 computers were connected to the Internet, and most were mainframes, minicomputers and professional workstations. On 2 November 1988, many started to slow down, because they were running a malicious code that demanded processor time and that spread itself to other computers \u2013 the first internet computer worm. The software was traced back to 23-year-old Cornell University graduate student Robert Tappan Morris who said \"he wanted to count how many machines were connected to the Internet\".\nRome Laboratory.\nIn 1994, over a hundred intrusions were made by unidentified crackers into the Rome Laboratory, the US Air Force's main command and research facility. Using trojan horses, hackers were able to obtain unrestricted access to Rome's networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of National Aeronautics and Space Administration's Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as a trusted Rome center user.\nTJX customer credit card details.\nIn early 2007, American apparel and home goods company TJX announced that it was the victim of an unauthorized computer systems intrusion and that the hackers had accessed a system that stored data on credit card, debit card, check, and merchandise return transactions.\nStuxnet attack.\nIn 2010, the computer worm known as Stuxnet reportedly ruined almost one-fifth of Iran's nuclear centrifuges. It did so by disrupting industrial programmable logic controllers (PLCs) in a targeted attack. This is generally believed to have been launched by Israel and the United States to disrupt Iran's nuclear program \u2013 although neither has publicly admitted this.\nGlobal surveillance disclosures.\nIn early 2013, documents provided by Edward Snowden were published by \"The Washington Post\" and \"The Guardian\" exposing the massive scale of NSA global surveillance. There were also indications that the NSA may have inserted a backdoor in a NIST standard for encryption. This standard was later withdrawn due to widespread criticism. The NSA additionally were revealed to have tapped the links between Google's data centers.\nTarget and Home Depot breaches.\nA Ukrainian hacker known as Rescator broke into Target Corporation computers in 2013, stealing roughly 40 million credit cards, and then Home Depot computers in 2014, stealing between 53 and 56 million credit card numbers. Warnings were delivered at both corporations, but ignored; physical security breaches using self checkout machines are believed to have played a large role. \"The malware utilized is absolutely unsophisticated and uninteresting,\" says Jim Walter, director of threat intelligence operations at security technology company McAfee \u2013 meaning that the heists could have easily been stopped by existing antivirus software had administrators responded to the warnings. The size of the thefts has resulted in major attention from state and Federal United States authorities and the investigation is ongoing.\nOffice of Personnel Management data breach.\nIn April 2015, the Office of Personnel Management discovered it had been hacked more than a year earlier in a data breach, resulting in the theft of approximately 21.5\u00a0million personnel records handled by the office. The Office of Personnel Management hack has been described by federal officials as among the largest breaches of government data in the history of the United States. Data targeted in the breach included personally identifiable information such as Social Security numbers, names, dates and places of birth, addresses, and fingerprints of current and former government employees as well as anyone who had undergone a government background check. It is believed the hack was perpetrated by Chinese hackers.\nAshley Madison breach.\nIn July 2015, a hacker group is known as The Impact Team successfully breached the extramarital relationship website Ashley Madison, created by Avid Life Media. The group claimed that they had taken not only company data but user data as well. After the breach, The Impact Team dumped emails from the company's CEO, to prove their point, and threatened to dump customer data unless the website was taken down permanently. When Avid Life Media did not take the site offline the group released two more compressed files, one 9.7GB and the second 20GB. After the second data dump, Avid Life Media CEO Noel Biderman resigned; but the website remained to function.\nColonial Pipeline ransomware attack.\nIn June 2021, the cyber attack took down the largest fuel pipeline in the U.S. and led to shortages across the East Coast.\nLegal issues and global regulation.\nInternational legal issues of cyber attacks are complicated in nature. There is no global base of common rules to judge, and eventually punish, cybercrimes and cybercriminals - and where security firms or agencies do locate the cybercriminal behind the creation of a particular piece of malware or form of cyber attack, often the local authorities cannot take action due to lack of laws under which to prosecute. Proving attribution for cybercrimes and cyberattacks is also a major problem for all law enforcement agencies. \"Computer viruses switch from one country to another, from one jurisdiction to another \u2013 moving around the world, using the fact that we don't have the capability to globally police operations like this. So the Internet is as if someone [had] given free plane tickets to all the online criminals of the world.\" The use of techniques such as dynamic DNS, fast flux and bullet proof servers add to the difficulty of investigation and enforcement.\nRole of government.\nThe role of the government is to make regulations to force companies and organizations to protect their systems, infrastructure and information from any cyberattacks, but also to protect its own national infrastructure such as the national power-grid.\nThe government's regulatory role in cyberspace is complicated. For some, cyberspace was seen as a virtual space that was to remain free of government intervention, as can be seen in many of today's libertarian blockchain and bitcoin discussions.\nMany government officials and experts think that the government should do more and that there is a crucial need for improved regulation, mainly due to the failure of the private sector to solve efficiently the cybersecurity problem. R. Clarke said during a panel discussion at the RSA Security Conference in San Francisco, he believes that the \"industry only responds when you threaten regulation. If the industry doesn't respond (to the threat), you have to follow through.\" On the other hand, executives from the private sector agree that improvements are necessary, but think that government intervention would affect their ability to innovate efficiently. Daniel R. McCarthy analyzed this public-private partnership in cybersecurity and reflected on the role of cybersecurity in the broader constitution of political order.\nOn 22 May 2020, the UN Security Council held its second ever informal meeting on cybersecurity to focus on cyber challenges to international peace. According to UN Secretary-General Ant\u00f3nio Guterres, new technologies are too often used to violate rights.\nInternational actions.\nMany different teams and organizations exist, including:\nEurope.\nOn 14 April 2016, the European Parliament and the Council of the European Union adopted the General Data Protection Regulation (GDPR). The GDPR, which came into force on 25 May 2018, grants individuals within the European Union (EU) and the European Economic Area (EEA) the right to the protection of personal data. The regulation requires that any entity that processes personal data incorporate data protection by design and by default. It also requires that certain organizations appoint a Data Protection Officer (DPO).\nNational actions.\nComputer emergency response teams.\nMost countries have their own computer emergency response team to protect network security.\nCanada.\nSince 2010, Canada has had a cybersecurity strategy. This functions as a counterpart document to the National Strategy and Action Plan for Critical Infrastructure. The strategy has three main pillars: securing government systems, securing vital private cyber systems, and helping Canadians to be secure online. There is also a Cyber Incident Management Framework to provide a coordinated response in the event of a cyber incident.\nThe Canadian Cyber Incident Response Centre (CCIRC) is responsible for mitigating and responding to threats to Canada's critical infrastructure and cyber systems. It provides support to mitigate cyber threats, technical support to respond &amp; recover from targeted cyber attacks, and provides online tools for members of Canada's critical infrastructure sectors. It posts regular cybersecurity bulletins &amp; operates an online reporting tool where individuals and organizations can report a cyber incident.\nTo inform the general public on how to protect themselves online, Public Safety Canada has partnered with STOP.THINK.CONNECT, a coalition of non-profit, private sector, and government organizations, and launched the Cyber Security Cooperation Program. They also run the GetCyberSafe portal for Canadian citizens, and Cyber Security Awareness Month during October.\nPublic Safety Canada aims to begin an evaluation of Canada's cybersecurity strategy in early 2015.\nAustralia.\nAustralian federal government announced an $18.2 million investment to fortify the cybersecurity resilience of small and medium enterprises (SMEs) and enhance their capabilities in responding to cyber threats. This financial backing is an integral component of the soon-to-be-unveiled 2023-2030 Australian Cyber Security Strategy, slated for release within the current week. A substantial allocation of $7.2 million is earmarked for the establishment of a voluntary cyber health check program, facilitating businesses in conducting a comprehensive and tailored self-assessment of their cybersecurity upskill.\nThis avant-garde health assessment serves as a diagnostic tool, enabling enterprises to ascertain the robustness of Australia's cyber security regulations. Furthermore, it affords them access to a repository of educational resources and materials, fostering the acquisition of skills necessary for an elevated cybersecurity posture. This groundbreaking initiative was jointly disclosed by Minister for Cyber Security Clare O'Neil and Minister for Small Business Julie Collins.\nIndia.\nSome provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000.\nThe National Cyber Security Policy 2013 is a policy framework by the Ministry of Electronics and Information Technology (MeitY) which aims to protect the public and private infrastructure from cyberattacks, and safeguard \"information, such as personal information (of web users), financial and banking information and sovereign data\". CERT- In is the nodal agency which monitors the cyber threats in the country. The post of National Cyber Security Coordinator has also been created in the Prime Minister's Office (PMO).\nThe Indian Companies Act 2013 has also introduced cyber law and cybersecurity obligations on the part of Indian directors. Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000 Update in 2013.\nSouth Korea.\nFollowing cyberattacks in the first half of 2013, when the government, news media, television stations, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed its northern counterpart for these attacks, as well as incidents that occurred in 2009, 2011, and 2012, but Pyongyang denies the accusations.\nUnited States.\nCyber Plan.\nThe United States has its first fully formed cyber plan in 15 years, as a result of the release of this National Cyber plan. In this policy, the US says it will: Protect the country by keeping networks, systems, functions, and data safe; Promote American wealth by building a strong digital economy and encouraging strong domestic innovation; Peace and safety should be kept by making it easier for the US to stop people from using computer tools for bad things, working with friends and partners to do this; and increase the United States' impact around the world to support the main ideas behind an open, safe, reliable, and compatible Internet.\nThe new U.S. cyber strategy seeks to allay some of those concerns by promoting responsible behavior in cyberspace, urging nations to adhere to a set of norms, both through international law and voluntary standards. It also calls for specific measures to harden U.S. government networks from attacks, like the June 2015 intrusion into the U.S. Office of Personnel Management (OPM), which compromised the records of about 4.2 million current and former government employees. And the strategy calls for the U.S. to continue to name and shame bad cyber actors, calling them out publicly for attacks when possible, along with the use of economic sanctions and diplomatic pressure.\nLegislation.\nThe 1986 , the Computer Fraud and Abuse Act is the key legislation. It prohibits unauthorized access or damage of \"protected computers\" as defined in . Although various other measures have been proposed \u2013 none have succeeded.\nIn 2013, executive order \"Improving Critical Infrastructure Cybersecurity\" was signed, which prompted the creation of the NIST Cybersecurity Framework.\nIn response to the Colonial Pipeline ransomware attack President Joe Biden signed Executive Order 14028 on May 12, 2021, to increase software security standards for sales to the government, tighten detection and security on existing systems, improve information sharing and training, establish a Cyber Safety Review Board, and improve incident response.\nStandardized government testing services.\nThe General Services Administration (GSA) has standardized the \"penetration test\" service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS).\nAgencies.\nThe Department of Homeland Security has a dedicated division responsible for the response system, risk management program and requirements for cybersecurity in the United States called the National Cyber Security Division. The division is home to US-CERT operations and the National Cyber Alert System. The National Cybersecurity and Communications Integration Center brings together government organizations responsible for protecting computer networks and networked infrastructure.\nThe third priority of the FBI is to: \"Protect the United States against cyber-based attacks and high-technology crimes\", and they, along with the National White Collar Crime Center (NW3C), and the Bureau of Justice Assistance (BJA) are part of the multi-agency task force, The Internet Crime Complaint Center, also known as IC3.\nIn addition to its own specific duties, the FBI participates alongside non-profit organizations such as InfraGard.\nThe Computer Crime and Intellectual Property Section (CCIPS) operates in the United States Department of Justice Criminal Division. The CCIPS is in charge of investigating computer crime and intellectual property crime and is specialized in the search and seizure of digital evidence in computers and networks. In 2017, CCIPS published A Framework for a Vulnerability Disclosure Program for Online Systems to help organizations \"clearly describe authorized vulnerability disclosure and discovery conduct, thereby substantially reducing the likelihood that such described activities will result in a civil or criminal violation of law under the Computer Fraud and Abuse Act (18 U.S.C. \u00a7 1030).\"\nThe United States Cyber Command, also known as USCYBERCOM, \"has the mission to direct, synchronize, and coordinate cyberspace planning and operations to defend and advance national interests in collaboration with domestic and international partners.\" It has no role in the protection of civilian networks.\nThe U.S. Federal Communications Commission's role in cybersecurity is to strengthen the protection of critical communications infrastructure, to assist in maintaining the reliability of networks during disasters, to aid in swift recovery after, and to ensure that first responders have access to effective communications services.\nThe Food and Drug Administration has issued guidance for medical devices, and the National Highway Traffic Safety Administration is concerned with automotive cybersecurity. After being criticized by the Government Accountability Office, and following successful attacks on airports and claimed attacks on airplanes, the Federal Aviation Administration has devoted funding to securing systems on board the planes of private manufacturers, and the Aircraft Communications Addressing and Reporting System. Concerns have also been raised about the future Next Generation Air Transportation System.\nThe US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc.\nComputer emergency readiness team.\n\"Computer emergency response team\" is a name given to expert groups that handle computer security incidents. In the US, two distinct organizations exist, although they do work closely together.\nU.S. NRC, 10 CFR 73.54 Cybersecurity.\nIn the context of U.S. nuclear power plants, the U.S. Nuclear Regulatory Commission (NRC) outlines cybersecurity requirements under 10 CFR Part 73, specifically in \u00a773.54.\nNEI 08-09: Cybersecurity Plan for Nuclear Power Plants.\nThe Nuclear Energy Institute's NEI 08-09 document, \"Cyber Security Plan for Nuclear Power Reactors\", outlines a comprehensive framework for cybersecurity in the nuclear power industry. Drafted with input from the U.S. NRC, this guideline is instrumental in aiding licensees to comply with the Code of Federal Regulations (CFR), which mandates robust protection of digital computers and equipment and communications systems at nuclear power plants against cyber threats.\nModern warfare.\nThere is growing concern that cyberspace will become the next theater of warfare. As Mark Clayton from \"The Christian Science Monitor\" wrote in a 2015 article titled \"The New Cyber Arms Race\":\nThis has led to new terms such as \"cyberwarfare\" and \"cyberterrorism\". The United States Cyber Command was created in 2009 and many other countries have similar forces.\nThere are a few critical voices that question whether cybersecurity is as significant a threat as it is made out to be.\nCareers.\nCybersecurity is a fast-growing field of IT concerned with reducing organizations' risk of hack or data breaches. According to research from the Enterprise Strategy Group, 46% of organizations say that they have a \"problematic shortage\" of cybersecurity skills in 2016, up from 28% in 2015. Commercial, government and non-governmental organizations all employ cybersecurity professionals. The fastest increases in demand for cybersecurity workers are in industries managing increasing volumes of consumer data such as finance, health care, and retail. However, the use of the term \"cybersecurity\" is more prevalent in government job descriptions.\nTypical cybersecurity job titles and descriptions include:\nSecurity Consultant/Specialist/Intelligence.\nStudent programs are also available for people interested in beginning a career in cybersecurity. Meanwhile, a flexible and effective option for information security professionals of all experience levels to keep studying is online security training, including webcasts. A wide range of certified courses are also available.\nIn the United Kingdom, a nationwide set of cybersecurity forums, known as the U.K Cyber Security Forum, were established supported by the Government's cybersecurity strategy in order to encourage start-ups and innovation and to address the skills gap identified by the U.K Government.\nIn Singapore, the Cyber Security Agency has issued a Singapore Operational Technology (OT) Cybersecurity Competency Framework (OTCCF). The framework defines emerging cybersecurity roles in Operational Technology. The OTCCF was endorsed by the Infocomm Media Development Authority (IMDA). It outlines the different OT cybersecurity job positions as well as the technical skills and core competencies necessary. It also depicts the many career paths available, including vertical and lateral advancement opportunities.\nTerminology.\nThe following terms used with regards to computer security are explained below:\nHistory.\nSince the Internet's arrival and with the digital transformation initiated in recent years, the notion of cybersecurity has become a familiar subject in both our professional and personal lives. Cybersecurity and cyber threats have been consistently present for the last 60 years of technological change. In the 1970s and 1980s, computer security was mainly limited to academia until the conception of the Internet, where, with increased connectivity, computer viruses and network intrusions began to take off. After the spread of viruses in the 1990s, the 2000s marked the institutionalization of organized attacks such as distributed denial of service. This led to the formalization of cybersecurity as a professional discipline.\nThe April 1967 session organized by Willis Ware at the Spring Joint Computer Conference, and the later publication of the Ware Report, were foundational moments in the history of the field of computer security. Ware's work straddled the intersection of material, cultural, political, and social concerns.\nA 1977 NIST publication introduced the \"CIA triad\" of confidentiality, integrity, and availability as a clear and simple way to describe key security goals. While still relevant, many more elaborate frameworks have since been proposed.\nHowever, in the 1970s and 1980s, there were no grave computer threats because computers and the internet were still developing, and security threats were easily identifiable. More often, threats came from malicious insiders who gained unauthorized access to sensitive documents and files. Although malware and network breaches existed during the early years, they did not use them for financial gain. By the second half of the 1970s, established computer firms like IBM started offering commercial access control systems and computer security software products.\nOne of the earliest examples of an attack on a computer network was the computer worm Creeper written by Bob Thomas at BBN, which propagated through the ARPANET in 1971. The program was purely experimental in nature and carried no malicious payload. A later program, Reaper, was created by Ray Tomlinson in 1972 and used to destroy Creeper.\nBetween September 1986 and June 1987, a group of German hackers performed the first documented case of cyber espionage. The group hacked into American defense contractors, universities, and military base networks and sold gathered information to the Soviet KGB. The group was led by Markus Hess, who was arrested on 29 June 1987. He was convicted of espionage (along with two co-conspirators) on 15 Feb 1990.\nIn 1988, one of the first computer worms, called the Morris worm, was distributed via the Internet. It gained significant mainstream media attention.\nNetscape started developing the protocol SSL, shortly after the National Center for Supercomputing Applications (NCSA) launched Mosaic 1.0, the first web browser, in 1993. Netscape had SSL version 1.0 ready in 1994, but it was never released to the public due to many serious security vulnerabilities. However, in 1995, Netscape launched Version 2.0.\nThe National Security Agency (NSA) is responsible for the protection of U.S. information systems and also for collecting foreign intelligence. The agency analyzes commonly used software and system configurations to find security flaws, which it can use for offensive purposes against competitors of the United States.\nNSA contractors created and sold \"click-and-shoot\" attack tools to US agencies and close allies, but eventually, the tools made their way to foreign adversaries. In 2016, NSAs own hacking tools were hacked, and they have been used by Russia and North Korea. NSA's employees and contractors have been recruited at high salaries by adversaries, anxious to compete in cyberwarfare. In 2007, the United States and Israel began exploiting security flaws in the Microsoft Windows operating system to attack and damage equipment used in Iran to refine nuclear materials. Iran responded by heavily investing in their own cyberwarfare capability, which it began using against the United States."}
{"id": "7400", "revid": "1412854", "url": "https://en.wikipedia.org/wiki?curid=7400", "title": "Chris Cunningham", "text": "Chris Cunningham (born 15 October 1970) is a British video artist and music video director who directed music videos for electronic musicians such as Autechre, Squarepusher, and Aphex Twin and Bj\u00f6rk. Early in his career he worked as a comic book artist. He has created art installations and directed short movies. In the mid 2000s, Cunningham began doing music production work, and has also designed album artwork for a variety of musicians. Cunningham worked on a never completed movie adaptation of William Gibson's cyberpunk novel \"Neuromancer.\"\nHis style is noted for its use of robotics, body horror and Mickey mousing (syncing action with music).\nBiography.\nEarly work - comic books and film special effects.\nBetween circa 1990 and 1992, he worked as a comic book artist for 2000 AD working under the pseudonym \"Chris Halls\" (Halls is his stepfather's surname). He worked on comics including \"Aliens\" and \"Judge Dredd Megazine.\" His contributions included cover paintings and strips\".\"\nAlso from around 1990, he worked on films including model-making, prosthetic make-up and concept illustrations. He worked on films including \"Hardware\" (1990) and \"Dust Devil\" (1992) for Richard Stanley, \"Nightbreed\" (1990) for Clive Barker, and \"Alien3\" (1992) for David Fincher.\nAfter seeing Cunningham's work on the 1995 film version of \"Judge Dredd\", Stanley Kubrick head-hunted Cunningham to work on \"A.I. Artificial Intelligence\". For Kubrick, Cunningham designed and supervised animatronic prototypes of David; the central robot child character. Cunningham worked for over a year on the film. However, around this time Kubrick put the film on hold, with Cunningham going on to pursue a career as a director.\nMusic videos.\nCunningham has had close ties to Warp Records since his first video for Autechre, \"Second Bad Vilbel\" in 1995 and Squarepusher's \"Come On My Selector\" in 1998, which received airplay on MTV's \"Amp\" and MTV's Chill Out Zone in Europe. Videos for Aphex Twin's \"Come to Daddy\" and \"Windowlicker\" are perhaps his best known. His video for Bj\u00f6rk's \"All Is Full of Love\" won multiple awards, including an MTV music video award for Breakthrough Video and was nominated for a Grammy for Best Short Form Music Video. It was also the first ever music video to win a Gold Pencil at the D&amp;AD Awards. It can still be seen at the Museum of Modern Art in New York. His video for Aphex Twin's \"Windowlicker\" was nominated for the \"Best Video\" award at the Brit Awards 2000. He also directed Madonna's \"Frozen\" video which became an international hit and won the award for Best Special Effects at the 1998 MTV Music Video Awards. Cunningham also came out of a seven-year hiatus from making music videos to direct the video for \"Sheena Is a Parasite\" by the Horrors.\nVideo art.\nHis video installation \"Flex\" was first shown in 2000 at the Royal Academy of Arts, and subsequently at the Anthony d'Offay Gallery and other art galleries. \"Flex\" was commissioned by the Anthony d'Offay Gallery for the exhibition curated by Norman Rosenthal and Max Wigram at the Royal Academy of Arts in 2000.\nThe Anthony d'Offay Gallery also commissioned \"Monkey Drummer\", a 2\u00bd minute piece intended for exhibition as a companion to \"Flex\" at the 2000 \"Apocalypse\" exhibition at the Royal Academy of Arts: however, the piece was not finished in time. In it an automaton with nine appendages and the head of a monkey plays the drums to \"Mt Saint Michel + Saint Michaels Mount\", the 10th track on Aphex Twin's 2001 album \"drukqs\". \"Monkey Drummer\" debuted as part of Cunningham's installation at the 49th International Exhibition of Art at the 2001 Venice Biennale, which consisted of a loop of \"Monkey Drummer\", \"Flex\", and his video for Bj\u00f6rk's \"All Is Full of Love\". In 2002 both \"Flex\" and \"Monkey Drummer\" were exhibited by 5th Gallery in Dublin, Ireland, in an exhibition curated by Artist/Curator Paul Murnaghan,\n\"Neuromancer\".\nIn an August 1999 \"Spike Magazine\" interview, cyberpunk author William Gibson stated \"He (Chris) was brought to my attention by someone else. We were told, third-hand, that he was extremely wary of the Hollywood process, and wouldn't return calls. But someone else told us that \"Neuromancer\" had been his \"The Wind in the Willows\", that he'd read it when he was a kid. I went to London and we met.\" Gibson is also quoted in the article as saying \"Chris is my own 100 percent personal choice...My only choice. The only person I've met who I thought might have a hope in hell of doing it right. I went back to see him in London just after he'd finished the Bjork video, and I sat on a couch beside this dead sex little Bjork robot, except it was wearing Aphex Twin's head. We talked.\"\nIn 2000, Cunningham and William Gibson began work on the script for Gibson's 1984 novel \"Neuromancer\". However, because \"Neuromancer\" was due to be a big budget studio film, it is rumoured that Cunningham pulled out due to being a first time director without final cut approval. He also felt that too much of the original book's ideas had been cannibalised by other recent films.\nMusic production, 'live' and short films (2004 - present).\nBy 18 November 2004, the Neuromancer film project had been canned. On the FAQ on the William Gibson Board, Gibson stated about the adaptation \"... The most recently rumoured version, to have been directed by Chris Cunningham, is now definitely not happening.\"\nCunningham took a sabbatical from filmmaking to learn about music production and recording and to develop his own music projects.\nIn 2005, Cunningham released the short film \"Rubber Johnny\" as a DVD accompanied by a book of photographs and drawings. \"Rubber Johnny\", a six-minute experimental short film cut to a soundtrack by Aphex Twin remixed by Cunningham, was shot between 2001 and 2004. Shot on DV night-vision, it was made in Cunningham's own time as a home movie of sorts, and took three and half years of weekends to complete. \"The Telegraph\" called it \"like a Looney Tunes short for a generation raised on video nasties and rave music\".\nIn 2005, Cunningham played a 45-minute audio visual piece performed live in Tokyo and Osaka in front of 30,000+ fans over the two nights at the Japanese electronic music festival . These performances evolved into \"Chris Cunningham Live\", a 55-minute long performance piece combining original and remixed music and film. It features remixed, unreleased and brand new videos and music dynamically edited together into a new live piece spread over three screens. The sound accompanying these images includes Cunningham's first publicly performed compositions interspersed with his remixes of other artist's work. \"Chris Cunningham Live\" debuted as one of the headline attractions at Warp 20 in Paris on 8 May 2009 with other performances scheduled at festivals in UK, and a number of European cities later in the year. \"Chris Cunningham Live\" continued in June 2011, with performances in London, Barcelona, and Sydney, Australia.\nDuring this period Cunningham also made another short film for Warp Films, \"Spectral Musicians\", which remains unreleased. The short film was set to Squarepusher's \"My Fucking Sound\" from his album \"Go Plastic\"; and to a piece called \"Mutilation Colony\" which was written especially for the short, and was released on the studio album \"Do You Know Squarepusher\".\nIn 2007, an excerpt from \"Flex\" was shown in the Barbican's exhibition Seduced: Art and Sex from Antiquity to Now curated by Martin Kemp, Marina Wallace and Joanne Bernstein. alongside other pieces by Bacon, Klimt, Rembrandt, Rodin and Picasso.\nIn December 2007 Cunningham produced two tracks, \"Three Decades\" and \"Primary Colours\", for \"Primary Colours\", the second album by the Horrors. In the summer of 2008, due to scheduling conflicts with his feature film script writing he could not work on the rest of the album which was subsequently recorded by Geoff Barrow from Portishead.\nIn 2008, he produced and arranged a new version of 'I Feel Love' for the Gucci commercial that he also directed. He travelled to Nashville to work with Donna Summer to record a brand new vocal for it.\nIn 2008, Cunningham produced a fashion shoot for \"Dazed &amp; Confused\" using Grace Jones as a model to create \"Nubian versions\" of Rubber Johnny. In an interview for BBC's \"The Culture Show\", it was suggested that the collaboration may expand into a video project. In regards to the collaboration, Cunningham stated \"For me, Grace has the strongest iconography of any artist in music. She\u2019s definitely the most inspiring person I\u2019ve worked with so far\".\nIn November 2008, Cunningham followed on with another photoshoot for \"Vice Magazine\".\nPersonal life.\nCunningham was married to Warpaint's bassist Jenny Lee Lindberg in 2010. By 2016, they were currently no longer together.\nPhotography.\nCunningham has created photography and cover artwork for various people including Bj\u00f6rk's \"All Is Full of Love\", Aphex Twin's \"Windowlicker\" and \"Come to Daddy\".\nVideography.\nCunningham has directed music videos, commercials and short films. His commercials for companies and brands, include Gucci, Sony (PlayStation), Levi's, Telecom Italia, Nissan, and Orange. The video collection \"The Work of Director Chris Cunningham\" was released in November 2004 as part of the Directors Label set. This DVD includes selected highlights from 1995 to 2000."}
{"id": "7401", "revid": "43066271", "url": "https://en.wikipedia.org/wiki?curid=7401", "title": "Centaur", "text": "A centaur ( ; ; ), occasionally hippocentaur, also called Ixionidae (), is a creature from Greek mythology with the upper body of a human and the lower body and legs of a horse that was said to live in the mountains of Thessaly. In one version of the myth, the centaurs were named after Centaurus, and, through his brother Lapithes, were kin to the legendary tribe of the Lapiths.\nCentaurs are thought of in many Greek myths as being as wild as untamed horses, and were said to have inhabited the region of Magnesia and Mount Pelion in Thessaly, the Foloi oak forest in Elis, and the Malean peninsula in southern Laconia. Centaurs are subsequently featured in Roman mythology, and were familiar figures in the medieval bestiary. They remain a staple of modern fantastic literature.\nEtymology.\nThe Greek word \"kentauros\" is generally regarded as being of obscure origin. The etymology from \"ken\" + \"tauros\", 'piercing bull', was a euhemerist suggestion in Palaephatus' rationalizing text on Greek mythology, \"On Incredible Tales\" (\u03a0\u03b5\u03c1\u1f76 \u1f00\u03c0\u03af\u03c3\u03c4\u03c9\u03bd), which included mounted archers from a village called \"Nephele\" eliminating a herd of bulls that were the scourge of Ixion's kingdom. Another possible related etymology can be \"bull-slayer\".\nMythology.\nCreation of centaurs.\nThe centaurs were usually said to have been born of Ixion and Nephele. As the story goes, Nephele was a cloud made into the likeness of Hera in a plot to trick Ixion into revealing his lust for Hera to Zeus. Ixion seduced Nephele and from that relationship centaurs were created. Another version, however, makes them children of Centaurus, a man who mated with the Magnesian mares. Centaurus was either himself the son of Ixion and Nephele (inserting an additional generation) or of Apollo and the nymph Stilbe. In the latter version of the story, Centaurus's twin brother was Lapithes, ancestor of the Lapiths.\nAnother tribe of centaurs was said to have lived on Cyprus. According to Nonnus, the Cyprian Centaurs were fathered by Zeus, who, in frustration after Aphrodite had eluded him, spilled his seed on the ground of that land. Unlike those of mainland Greece, the Cyprian centaurs were ox-horned.\nThere were also the Lamian Pheres, twelve rustic daimones (spirits) of the Lamos river. They were set by Zeus to guard the infant Dionysos, protecting him from the machinations of Hera, but the enraged goddess transformed them into ox-horned Centaurs unrelated to the Cyprian Centaurs. The Lamian Pheres later accompanied Dionysos in his campaign against the Indians.\nThe centaur's half-human, half-horse composition has led many writers to treat them as liminal beings, caught between the two natures they embody in contrasting myths; they are both the embodiment of untamed nature, as in their battle with the Lapiths (their kin), and conversely, teachers like Chiron.\nCentauromachy.\nThe Centaurs are best known for their fight with the Lapiths who, according to one origin myth, would have been cousins to the centaurs. The battle, called the Centauromachy, was caused by the centaurs' attempt to carry off Hippodamia and the rest of the Lapith women on the day of Hippodamia's marriage to Pirithous, who was the king of the Lapithae and a son of Ixion. Theseus, a hero and founder of cities, who happened to be present, threw the balance in favour of the Lapiths by assisting Pirithous in the battle. The Centaurs were driven off or destroyed. Another Lapith hero, Caeneus, who was invulnerable to weapons, was beaten into the earth by Centaurs wielding rocks and the branches of trees. In her article \"The Centaur: Its History and Meaning in Human Culture\", Elizabeth Lawrence claims that the contests between the centaurs and the Lapiths typify the struggle between civilization and barbarism.\nThe Centauromachy is most famously portrayed in the metopes of the Parthenon by Phidias and in the \"Battle of the Centaurs\", a relief by Michelangelo.\nOrigin of the myth.\nThe most common theory holds that the idea of centaurs came from the first reaction of a non-riding culture, as in the Minoan Aegean world, to nomads who were mounted on horses. The theory suggests that such riders would appear as half-man, half-animal. Bernal D\u00edaz del Castillo reported that the Aztecs also had this misapprehension about Spanish cavalrymen. The Lapith tribe of Thessaly, who were the kinsmen of the Centaurs in myth, were described as the inventors of horse-riding by Greek writers. The Thessalian tribes also claimed their horse breeds were descended from the centaurs.\nRobert Graves (relying on the work of Georges Dum\u00e9zil, who argued for tracing the centaurs back to the Indian Gandharva), speculated that the centaurs were a dimly remembered, pre-Hellenic fraternal earth cult who had the horse as a totem. A similar theory was incorporated into Mary Renault's \"The Bull from the Sea.\"\nVariations.\nFemale centaurs.\nThough female centaurs, called centaurides or centauresses, are not mentioned in early Greek literature and art, they do appear occasionally in later antiquity. A Macedonian mosaic of the 4th century BC is one of the earliest examples of the centauress in art. Ovid also mentions a centauress named Hylonome who committed suicide when her husband Cyllarus was killed in the war with the Lapiths.\nIndia.\nThe Kalibangan cylinder seal, dated to be around 2600\u20131900 BC, found at the site of Indus-Valley civilization shows a battle between men in the presence of centaur-like creatures. Other sources claim the creatures represented are actually half human and half tigers, later evolving into the Hindu Goddess of War. These seals are also evidence of Indus-Mesopotamia relations in the 3rd millennium BC.\nIn a popular legend associated with Pazhaya Sreekanteswaram Temple in Thiruvananthapuram, the curse of a saintly Brahmin transformed a handsome Yadava prince into a creature having a horse's body and the prince's head, arms, and torso in place of the head and neck of the horse.\nKinnaras, another half-man, half-horse mythical creature from Indian mythology, appeared in various ancient texts, arts, and sculptures from all around India. It is shown as a horse with the torso of a man where the horse's head would be, and is similar to a Greek centaur.\nRussia.\nA centaur-like half-human, half-equine creature called \"Polkan\" appeared in Russian folk art and lubok prints of the 17th\u201319th centuries. Polkan is originally based on \"Pulicane\", a half-dog from Andrea da Barberino's poem \"I Reali di Francia\", which was once popular in the Slavonic world in prosaic translations.\nArtistic representations.\nClassical art.\nThe extensive Mycenaean pottery found at Ugarit included two fragmentary Mycenaean terracotta figures which have been tentatively identified as centaurs. This finding suggests a Bronze Age origin for these creatures of myth. A painted terracotta centaur was found in the \"Hero's tomb\" at Lefkandi, and by the Geometric period, centaurs figure among the first representational figures painted on Greek pottery. An often-published Geometric period bronze of a warrior face-to-face with a centaur is at the Metropolitan Museum of Art.\nIn Greek art of the Archaic period, centaurs are depicted in three different forms.\nThere are also paintings and motifs on \"amphorae\" and Dipylon cups which depict winged centaurs.\nCentaurs were also frequently depicted in Roman art. One example is the pair of centaurs drawing the chariot of Constantine the Great and his family in the Great Cameo of Constantine (\"circa\" AD 314\u201316), which embodies wholly pagan imagery, and contrasts sharply with the popular image of Constantine as the patron of early Christianity.\nMedieval art.\nCentaurs preserved a Dionysian connection in the 12th-century Romanesque carved capitals of Mozac Abbey in the Auvergne. Other similar capitals depict harvesters, boys riding goats (a further Dionysiac theme), and griffins guarding the chalice that held the wine. Centaurs are also shown on a number of Pictish carved stones from north-east Scotland erected in the 8th\u20139th centuries AD (e.g., at Meigle, Perthshire). Though outside the limits of the Roman Empire, these depictions appear to be derived from Classical prototypes.\nModern art.\nThe John C. Hodges library at The University of Tennessee hosts a permanent exhibit of a \"Centaur from Volos\" in its library. The exhibit, made by sculptor Bill Willers by combining a study human skeleton with the skeleton of a Shetland pony, is entitled \"Do you believe in Centaurs?\". According to the exhibitors, it was meant to mislead students in order to make them more critically aware.\nCartography.\nDepictions of centaurs in a mythical land located south beyond the world's known continents appear on a map by Urbano Monti from 1587, sometimes called Monti's Planisphere.\nIn heraldry.\nCentaurs are common in European heraldry, although more frequent in continental than in British arms. A centaur holding a bow is referred to as a sagittarius.\nLiterature.\nClassical literature.\nJerome's version of the \"Life\" of St Anthony the Great, written by Athanasius of Alexandria about the hermit monk of Egypt, was widely disseminated in the Middle Ages; it relates Anthony's encounter with a centaur who challenged the saint, but was forced to admit that the old gods had been overthrown. The episode was often depicted in \"The Meeting of St Anthony Abbot and St Paul the Hermit\" by the painter Stefano di Giovanni, who was known as \"Sassetta\". Of the two episodic depictions of the hermit Anthony's travel to greet the hermit Paul, one is his encounter with the demonic figure of a centaur along the pathway in a wood.\nLucretius, in his first-century BC philosophical poem \"On the Nature of Things,\" denied the existence of centaurs, based on the differing rates of growth of human and equine anatomies. Specifically, he states that at the age of three years, horses are in the prime of their life while humans at the same age are still little more than babies, making hybrid animals impossible.\nMedieval literature.\nCentaurs are among the creatures which 14th-century Italian poet Dante placed as guardians in his \"Inferno\". In Canto XII, Dante and his guide Virgil meet a band led by Chiron and Pholus, guarding the bank of Phlegethon in the seventh circle of Hell, a river of boiling blood in which the violent against their neighbours are immersed, shooting arrows into any who move to a shallower spot than their allotted station. The two poets are treated with courtesy, and Nessus guides them to a ford. In Canto XXIV, in the eighth circle, in Bolgia 7, a ditch where thieves are confined, they meet but do not converse with Cacus (who is a giant in the ancient sources), wreathed in serpents and with a fire-breathing dragon on his shoulders, arriving to punish a sinner who has just cursed God. In his \"Purgatorio\", an unseen spirit on the sixth terrace cites the centaurs (\"the drunken double-breasted ones who fought Theseus\") as examples of the sin of gluttony.\nModern day literature.\nC.S. Lewis' \"The Chronicles of Narnia\" series depicts centaurs as the wisest and noblest of creatures. Narnian Centaurs are gifted at stargazing, prophecy, healing, and warfare; a fierce and valiant race always faithful to the High King Aslan the Lion.\nIn J.K. Rowling's \"Harry Potter\" series, centaurs live in the Forbidden Forest close to Hogwarts, preferring to avoid contact with humans. They live in societies called herds and are skilled at archery, healing, and astrology, but like in the original myths, they are known to have some wild and barbarous tendencies.\nWith the exception of Chiron, the centaurs in Rick Riordan's \"Percy Jackson &amp; the Olympians\" are seen as wild party-goers who use a lot of American slang. Chiron retains his mythological role as a trainer of heroes and is skilled in archery. In Riordan's subsequent series, \"Heroes of Olympus\", another group of centaurs are depicted with more animalistic features (such as horns) and appear as villains, serving the Gigantes.\nPhilip Jose Farmer's \"World of Tiers\" series (1965) includes centaurs, called Half-Horses or Hoi Kentauroi. His creations address several of the metabolic problems of such creatures\u2014how could the human mouth and nose intake sufficient air to sustain both itself and the horse body and, similarly, how could the human ingest sufficient food to sustain both parts.\nBrandon Mull's \"Fablehaven\" series features centaurs that live in an area called Grunhold. The centaurs are portrayed as a proud, elitist group of beings that consider themselves superior to all other creatures. The fourth book also has a variation on the species called an Alcetaur, which is part man, part moose.\nThe myth of the centaur appears in John Updike's novel \"The Centaur\". The author depicts a rural Pennsylvanian town as seen through the optics of the myth of the centaur. An unknown and marginalized local school teacher, just like the mythological Chiron did for Prometheus, gave up his life for the future of his son who had chosen to be an independent artist in New York.\nSee also.\nOther hybrid creatures appear in Greek mythology, always with some liminal connection that links Hellenic culture with archaic or non-Hellenic cultures:\nAlso,\nAdditionally, \"Bucentaur\", the name of several historically important Venetian vessels, was linked to a posited ox-centaur or \"\u03b2\u03bf\u03c5\u03ba\u03ad\u03bd\u03c4\u03b1\u03c5\u03c1\u03bf\u03c2\" \"(boukentauros)\" by fanciful and likely spurious folk-etymology."}
{"id": "7403", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=7403", "title": "Chemotaxis", "text": "Chemotaxis (from \"chemo-\" + \"taxis\") is the movement of an organism or entity in response to a chemical stimulus. Somatic cells, bacteria, and other single-cell or multicellular organisms direct their movements according to certain chemicals in their environment. This is important for bacteria to find food (e.g., glucose) by swimming toward the highest concentration of food molecules, or to flee from poisons (e.g., phenol). In multicellular organisms, chemotaxis is critical to early development (e.g., movement of sperm towards the egg during fertilization) and development (e.g., migration of neurons or lymphocytes) as well as in normal function and health (e.g., migration of leukocytes during injury or infection). In addition, it has been recognized that mechanisms that allow chemotaxis in animals can be subverted during cancer metastasis, and the aberrant change of the overall property of these networks, which control chemotaxis, can lead to carcinogenesis. The aberrant chemotaxis of leukocytes and lymphocytes also contribute to inflammatory diseases such as atherosclerosis, asthma, and arthritis. Sub-cellular components, such as the polarity patch generated by mating yeast, may also display chemotactic behavior.\n\"Positive\" chemotaxis occurs if the movement is toward a higher concentration of the chemical in question; \"negative\" chemotaxis if the movement is in the opposite direction. Chemically prompted kinesis (randomly directed or nondirectional) can be called chemokinesis.\nHistory of chemotaxis research.\nAlthough migration of cells was detected from the early days of the development of microscopy by Leeuwenhoek, a Caltech lecture regarding chemotaxis propounds that 'erudite description of chemotaxis was only first made by T. W. Engelmann (1881) and W. F. Pfeffer (1884) in bacteria, and H. S. Jennings (1906) in ciliates'. The Nobel Prize laureate I. Metchnikoff also contributed to the study of the field during 1882 to 1886, with investigations of the process as an initial step of phagocytosis. The significance of chemotaxis in biology and clinical pathology was widely accepted in the 1930s, and the most fundamental definitions underlying the phenomenon were drafted by this time. The most important aspects in quality control of chemotaxis assays were described by H. Harris in the 1950s. In the 1960s and 1970s, the revolution of modern cell biology and biochemistry provided a series of novel techniques that became available to investigate the migratory responder cells and subcellular fractions responsible for chemotactic activity. The availability of this technology led to the discovery of C5a, a major chemotactic factor involved in acute inflammation. The pioneering works of J. Adler modernized Pfeffer's capillary assay and represented a significant turning point in understanding the whole process of intracellular signal transduction of bacteria.\nBacterial chemotaxis\u2014general characteristics.\nSome bacteria, such as \"E. coli\", have several flagella per cell (4\u201310 typically). These can rotate in two ways:\nThe directions of rotation are given for an observer outside the cell looking down the flagella toward the cell.\nBehavior.\nThe overall movement of a bacterium is the result of alternating tumble and swim phases, called run-and-tumble motion. As a result, the trajectory of a bacterium swimming in a uniform environment will form a random walk with relatively straight swims interrupted by random tumbles that reorient the bacterium. Bacteria such as \"E. coli\" are unable to choose the direction in which they swim, and are unable to swim in a straight line for more than a few seconds due to rotational diffusion; in other words, bacteria \"forget\" the direction in which they are going. By repeatedly evaluating their course, and adjusting if they are moving in the wrong direction, bacteria can direct their random walk motion toward favorable locations.\nIn the presence of a chemical gradient bacteria will chemotax, or direct their overall motion based on the gradient. If the bacterium senses that it is moving in the correct direction (toward attractant/away from repellent), it will keep swimming in a straight line for a longer time before tumbling; however, if it is moving in the wrong direction, it will tumble sooner. Bacteria like \"E. coli\" use temporal sensing to decide whether their situation is improving or not, and in this way, find the location with the highest concentration of attractant, detecting even small differences in concentration.\nThis biased random walk is a result of simply choosing between two methods of random movement; namely tumbling and straight swimming. The helical nature of the individual flagellar filament is critical for this movement to occur. The protein structure that makes up the flagellar filament, flagellin, is conserved among all flagellated bacteria. Vertebrates seem to have taken advantage of this fact by possessing an immune receptor (TLR5) designed to recognize this conserved protein.\nAs in many instances in biology, there are bacteria that do not follow this rule. Many bacteria, such as \"Vibrio\", are monoflagellated and have a single flagellum at one pole of the cell. Their method of chemotaxis is different. Others possess a single flagellum that is kept inside the cell wall. These bacteria move by spinning the whole cell, which is shaped like a corkscrew.\nSignal transduction.\nChemical gradients are sensed through multiple transmembrane receptors, called methyl-accepting chemotaxis proteins (MCPs), which vary in the molecules that they detect. Thousands of MCP receptors are known to be encoded across the bacterial kingdom. These receptors may bind attractants or repellents directly or indirectly through interaction with proteins of periplasmatic space. The signals from these receptors are transmitted across the plasma membrane into the cytosol, where \"Che proteins\" are activated. The Che proteins alter the tumbling frequency, and alter the receptors.\nFlagellum regulation.\nThe proteins CheW and CheA bind to the receptor. The absence of receptor activation results in autophosphorylation in the histidine kinase, CheA, at a single highly conserved histidine residue. CheA, in turn, transfers phosphoryl groups to conserved aspartate residues in the response regulators CheB and CheY; CheA is a histidine kinase and it does not actively transfer the phosphoryl group, rather, the response regulator CheB takes the phosphoryl group from CheA. This mechanism of signal transduction is called a two-component system, and it is a common form of signal transduction in bacteria. CheY induces tumbling by interacting with the flagellar switch protein FliM, inducing a change from counter-clockwise to clockwise rotation of the flagellum. Change in the rotation state of a single flagellum can disrupt the entire flagella bundle and cause a tumble.\nReceptor regulation.\nCheB, when activated by CheA, acts as a methylesterase, removing methyl groups from glutamate residues on the cytosolic side of the receptor; it works antagonistically with CheR, a methyltransferase, which adds methyl residues to the same glutamate residues. If the level of an attractant remains high, the level of phosphorylation of CheA (and, therefore, CheY and CheB) will remain low, the cell will swim smoothly, and the level of methylation of the MCPs will increase (because CheB-P is not present to demethylate). The MCPs no longer respond to the attractant when they are fully methylated; therefore, even though the level of attractant might remain high, the level of CheA-P (and CheB-P) increases and the cell begins to tumble. The MCPs can be demethylated by CheB-P, and, when this happens, the receptors can once again respond to attractants. The situation is the opposite with regard to repellents: fully methylated MCPs respond best to repellents, while least-methylated MCPs respond worst to repellents. This regulation allows the bacterium to 'remember' chemical concentrations from the recent past, a few seconds, and compare them to those it is currently experiencing, thus 'know' whether it is traveling up or down a gradient.\n that bacteria have to chemical gradients, other mechanisms are involved in increasing the absolute value of the sensitivity on a given background. Well-established examples are the ultra-sensitive response of the motor to the CheY-P signal, and the clustering of chemoreceptors.\nChemoattractants and chemorepellents.\nChemoattractants and chemorepellents are inorganic or organic substances possessing chemotaxis-inducer effect in motile cells. These chemotactic ligands create chemical concentration gradients that organisms, prokaryotic and eukaryotic, move toward or away from, respectively.\nEffects of chemoattractants are elicited via chemoreceptors such as methyl-accepting chemotaxis proteins (MCP). MCPs in E.coli include Tar, Tsr, Trg and Tap. Chemoattracttants to Trg include ribose and galactose with phenol as a chemorepellent. Tap and Tsr recognize dipeptides and serine as chemoattractants, respectively.\nChemoattractants or chemorepellents bind MCPs at its extracellular domain; an intracellular signaling domain relays the changes in concentration of these chemotactic ligands to downstream proteins like that of CheA which then relays this signal to flagellar motors via phosphorylated CheY (CheY-P). CheY-P can then control flagellar rotation influencing the direction of cell motility.\nFor \"E.coli\", \"S. meliloti\", and \"R. spheroides,\" the binding of chemoattractants to MCPs inhibit CheA and therefore CheY-P activity, resulting in smooth runs, but for \"B. substilis\", CheA activity increases. Methylation events in \"E.coli\" cause MCPs to have lower affinity to chemoattractants which causes increased activity of CheA and CheY-P resulting in tumbles. In this way cells are able to adapt to the immediate chemoattractant concentration and detect further changes to modulate cell motility.\nChemoattractants in eukaryotes are well characterized for immune cells. Formyl peptides, such as fMLF, attract leukocytes such as neutrophils and macrophages, causing movement toward infection sites. Non-acylated methioninyl peptides do not act as chemoattractants to neutrophils and macrophages. Leukocytes also move toward chemoattractants C5a, a complement component, and pathogen-specific ligands on bacteria.\nMechanisms concerning chemorepellents are less known than chemoattractants. Although chemorepellents work to confer an avoidance response in organisms, \"Tetrahymena thermophila\" adapt to a chemorepellent, Netrin-1 peptide, within 10 minutes of exposure; however, exposure to chemorepellents such as GTP, PACAP-38, and nociceptin show no such adaptations. GTP and ATP are chemorepellents in micro-molar concentrations to both \"Tetrahymena\" and \"Paramecium\". These organisms avoid these molecules by producing avoiding reactions to re-orient themselves away from the gradient.\nEukaryotic chemotaxis.\nThe mechanism of chemotaxis that eukaryotic cells employ is quite different from that in the bacteria \"E. coli\"; however, sensing of chemical gradients is still a crucial step in the process. Due to their small size and other biophysical constraints, \"E. coli\" cannot directly detect a concentration gradient. Instead, they employ temporal gradient sensing, where they move over larger distances several times their own width and measure the rate at which perceived chemical concentration changes.\nEukaryotic cells are much larger than prokaryotes and have receptors embedded uniformly throughout the cell membrane. Eukaryotic chemotaxis involves detecting a concentration gradient spatially by comparing the asymmetric activation of these receptors at the different ends of the cell. Activation of these receptors results in migration towards chemoattractants, or away from chemorepellants. In mating yeast, which are non-motile, patches of polarity proteins on the cell cortex can relocate in a chemotactic fashion up pheromone gradients.\nIt has also been shown that both prokaryotic and eukaryotic cells are capable of chemotactic memory. In prokaryotes, this mechanism involves the methylation of receptors called methyl-accepting chemotaxis proteins (MCPs). This results in their desensitization and allows prokaryotes to \"remember\" and adapt to a chemical gradient. In contrast, chemotactic memory in eukaryotes can be explained by the Local Excitation Global Inhibition (LEGI) model. LEGI involves the balance between a fast excitation and delayed inhibition which controls downstream signaling such as Ras activation and PIP3 production.\nLevels of receptors, intracellular signalling pathways and the effector mechanisms all represent diverse, eukaryotic-type components. In eukaryotic unicellular cells, amoeboid movement and cilium or the eukaryotic flagellum are the main effectors (e.g., Amoeba or Tetrahymena). Some eukaryotic cells of higher vertebrate origin, such as immune cells also move to where they need to be. Besides immune competent cells (granulocyte, monocyte, lymphocyte) a large group of cells\u2014considered previously to be fixed into tissues\u2014are also motile in special physiological (e.g., mast cell, fibroblast, endothelial cells) or pathological conditions (e.g., metastases). Chemotaxis has high significance in the early phases of embryogenesis as development of germ layers is guided by gradients of signal molecules.\nDetection of a gradient of chemoattractant.\nThe specific molecule/s that allow a eukaryotic cells detect a gradient of chemoattractant ligands (that is, a sort of the molecular compass that detects the direction of a chemoattractant) seems to change depending on the cell and chemoattractant receptor involved or even the concentration of the chemoattractant. However, these molecules apparently are activated independently of the motility of the cell. That is, even an immnobilized cell is still able to detect the direction of a chemoattractant. There appear to be mechanisms by which an external chemotactic gradient is sensed and turned into an intracellular Ras and PIP3 gradients, which results in a gradient and the activation of a signaling pathway, culminating in the polymerisation of actin filaments. The growing distal end of actin filaments develops connections with the internal surface of the plasma membrane via different sets of peptides and results in the formation of anterior pseudopods and posterior uropods.\nCilia of eukaryotic cells can also produce chemotaxis; in this case, it is mainly a Ca2+-dependent induction of the microtubular system of the basal body and the beat of the 9\u00a0+\u00a02 microtubules within cilia. The orchestrated beating of hundreds of cilia is synchronized by a submembranous system built between basal bodies.\nThe details of the signaling pathways are still not totally clear.\nChemotaxis-related migratory responses.\nChemotaxis refers to the directional migration of cells in response to chemical gradients; several variations of chemical-induced migration exist as listed below. \nReceptors.\nIn general, eukaryotic cells sense the presence of chemotactic stimuli through the use of 7-transmembrane (or serpentine) heterotrimeric G-protein-coupled receptors, a class representing a significant portion of the genome. Some members of this gene superfamily are used in eyesight (rhodopsins) as well as in olfaction (smelling). The main classes of chemotaxis receptors are triggered by:\nHowever, induction of a wide set of membrane receptors (e.g., cyclic nucleotides, amino acids, insulin, vasoactive peptides) also elicit migration of the cell.\nChemotactic selection.\nWhile some chemotaxis receptors are expressed in the surface membrane with long-term characteristics, as they are determined genetically, others have short-term dynamics, as they are assembled \"ad hoc\" in the presence of the ligand. The diverse features of the chemotaxis receptors and ligands allows for the possibility of selecting chemotactic responder cells with a simple chemotaxis assay By chemotactic selection, we can determine whether a still-uncharacterized molecule acts via the long- or the short-term receptor pathway. The term \"chemotactic selection\" is also used to designate a technique that separates eukaryotic or prokaryotic cells according to their chemotactic responsiveness to selector ligands.\nChemotactic ligands.\nThe number of molecules capable of eliciting chemotactic responses is relatively high, and we can distinguish primary and secondary chemotactic molecules. The main groups of the primary ligands are as follows:\nChemotactic range fitting.\nChemotactic responses elicited by ligand-receptor interactions vary with the concentration of the ligand. Investigations of ligand families (e.g. amino acids or oligopeptides) demonstrates that chemoattractant activity occurs over a wide range, while chemorepellent activities have narrow ranges.\nClinical significance.\nA changed migratory potential of cells has relatively high importance in the development of several clinical symptoms and syndromes.\nAltered chemotactic activity of extracellular (e.g., Escherichia coli) or intracellular (e.g., Listeria monocytogenes) pathogens itself represents a significant clinical target. Modification of endogenous chemotactic ability of these microorganisms by pharmaceutical agents can decrease or inhibit the ratio of infections or spreading of infectious diseases.\nApart from infections, there are some other diseases wherein impaired chemotaxis is the primary etiological factor, as in Ch\u00e9diak\u2013Higashi syndrome, where giant intracellular vesicles inhibit normal migration of cells.\nMathematical models.\nSeveral mathematical models of chemotaxis were developed depending on the type of\nAlthough interactions of the factors listed above make the behavior of the solutions of mathematical models of chemotaxis rather complex, it is possible to describe the basic phenomenon of chemotaxis-driven motion in a straightforward way. Indeed, let us denote with formula_1 the spatially non-uniform concentration of the chemo-attractant and formula_2 as its gradient. Then the chemotactic cellular flow (also called current) formula_3 that is generated by the chemotaxis is linked to the above gradient by the law:where formula_4 is the spatial density of the cells and formula_5 is the so-called 'Chemotactic coefficient' - formula_6 is often not constant, but a decreasing function of the chemo-attractant. For some quantity formula_7 that is subject to total flux formula_8 and generation/destruction term formula_9, it is possible to formulate a continuity equation:\nwhere formula_11 is the divergence. This general equation applies to both the cell density and the chemo-attractant. Therefore, incorporating a diffusion flux into the total flux term, the interactions between these quantities are governed by a set of coupled reaction-diffusion partial differential equations describing the change in formula_12 and formula_13: &amp;= f(C) + \\nabla\\cdot \\left[D_{C}\\nabla C - C\\chi(\\varphi)\\nabla\\varphi \\right ] \\\\\n\\end{aligned} &lt;/math&gt;|border colour=#0073CF|background colour=#F5FFFA}}where formula_14 describes the growth in cell density, formula_15 is the kinetics/source term for the chemo-attractant, and the diffusion coefficients for cell density and the chemo-attractant are respectively formula_16 and formula_17.\nSpatial ecology of soil microorganisms is a function of their chemotactic sensitivities towards substrate and fellow organisms. The chemotactic behavior of the bacteria was proven to lead to non-trivial population patterns even in the absence of environmental heterogeneities. The presence of structural pore scale heterogeneities has an extra impact on the emerging bacterial patterns.\nMeasurement of chemotaxis.\nA wide range of techniques is available to evaluate chemotactic activity of cells or the chemoattractant and chemorepellent character of ligands.\nThe basic requirements of the measurement are as follows:\nDespite the fact that an ideal chemotaxis assay is still not available, there are several protocols and pieces of equipment that offer good correspondence with the conditions described above. The most commonly used are summarised in the table below:\nArtificial chemotactic systems.\n\"Chemical robots\" that use artificial chemotaxis to navigate autonomously have been designed. Applications include targeted delivery of drugs in the body. More recently, enzyme molecules have also shown positive chemotactic behavior in the gradient of their substrates. The thermodynamically favorable binding of enzymes to their specific substrates is recognized as the origin of enzymatic chemotaxis. Additionally, enzymes in cascades have also shown substrate-driven chemotactic aggregation.\nApart from active enzymes, non-reacting molecules also show chemotactic behavior. This has been demonstrated by using dye molecules that move directionally in gradients of polymer solution through favorable hydrophobic interactions."}
{"id": "7405", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7405", "title": "Crimean war", "text": ""}
{"id": "7406", "revid": "1005449", "url": "https://en.wikipedia.org/wiki?curid=7406", "title": "Cheshire", "text": "Cheshire ( ) is a ceremonial county in North West England. It is bordered by Merseyside to the north-west, Greater Manchester to the north-east, Derbyshire to the east, Staffordshire to the south-east, and Shropshire to the south; to the west it is bordered by the Welsh counties of Flintshire and Wrexham, and has a short coastline on the Dee Estuary. Warrington is the largest settlement, and the city of Chester is the county town.\nThe county has an area of and had a population of 1,095,500 at the 2021 census. The north and west are relatively urbanised, and contain the settlements of Warrington, Chester, Runcorn, Widnes, and Ellesmere Port. The south and east of the county are primarily rural, and the largest settlement is Crewe. For local government purposes Cheshire comprises four unitary authority areas: Cheshire East, Cheshire West and Chester, Halton, and Warrington. The county historically included all of the Wirral Peninsula and parts of southern Greater Manchester and northern Derbyshire, but excluded Widnes and Warrington.\nThe landscape of the county is dominated by the Cheshire Plain, an area of relatively flat land divided by the Mid-Cheshire Ridge. To the west, Cheshire contains the south of the Wirral Peninsula, and to the east the landscape rises to the Pennines, where the county contains part of the Peak District. The River Mersey runs through the north of Cheshire before broadening into its wide estuary; the River Dee forms part of the county's border with Wales, then fully enters England and flows through the city of Chester before re-entering Wales upstream of its estuary. Red Triassic sandstone forms the bedrock of much of the county, and was used in the construction of many of its buildings.\nThe culture of Cheshire has affected global pop culture by producing actors such as Daniel Craig, Tim Curry, and Pete Postlethwaite; athletes such as Shauna Coxsey, Tyson Fury, and Paula Radcliffe; authors such as Lewis Carroll; comedians such as John Bishop and Ben Miller; and musicians such as Gary Barlow, Ian Curtis, and Harry Styles. Most places are involved in agriculture and chemistry, leading to Cheshire's reputation for the production of chemicals, Cheshire cheese, salt, and silk.\nToponymy.\nCheshire's name was originally derived from an early name for Chester, and was first recorded as \"Legeceasterscir\" in the \"Anglo-Saxon Chronicle\", meaning \"the shire of the city of legions\". Although the name first appears in 980, it is thought that the county was created by Edward the Elder around 920. In the Domesday Book, Chester was recorded as having the name \"Cestrescir\" (Chestershire), derived from the name for Chester at the time. Through the next few centuries a series of changes that occurred in the English language, which have included simplifications and elision, has resulted in the name Cheshire.\nBecause of the historically close links with the land bordering Cheshire to the west, which became modern Wales, there is a history of interaction between Cheshire and North Wales. The Domesday Book records Cheshire as having two complete Hundreds (Atiscross and Exestan) that later became the principal part of Flintshire. Additionally, another large portion of the Duddestan Hundred later became known as English Maelor (Maelor Saesneg) when it was transferred to North Wales. For this and other reasons, the Welsh language name for Cheshire, , is sometimes used.\nHistory.\nEarldom.\nAfter the Norman conquest of 1066 by William I, dissent and resistance continued for many years after the invasion. In 1069 local resistance in Cheshire was finally put down using draconian measures as part of the Harrying of the North. The ferocity of the campaign against the English populace was enough to end all future resistance. Examples were made of major landowners such as Earl Edwin of Mercia, their properties confiscated and redistributed amongst Norman barons.\nThe earldom was sufficiently independent from the kingdom of England that the 13th-century Magna Carta did not apply to the shire of Chester, so the earl wrote up his own Chester Charter at the petition of his barons.\nCounty Palatine.\nWilliam I made Cheshire a county palatine and gave Gerbod the Fleming the new title of Earl of Chester. When Gerbod returned to Normandy in about 1070, the king used his absence to declare the earldom forfeit and gave the title to Hugh d'Avranches (nicknamed Hugh Lupus, or \"wolf\"). Because of Cheshire's strategic location on the Welsh Marches, the Earl had complete autonomous powers to rule on behalf of the king in the county palatine.\nHundreds.\nCheshire in the Domesday Book (1086) is recorded as a much larger county than it is today. It included two hundreds, Atiscross and Exestan, that later became part of North Wales. At the time of the Domesday Book, it also included as part of Duddestan Hundred the area of land later known as English Maelor (which used to be a detached part of Flintshire) in Wales. The area between the Mersey and Ribble (referred to in the Domesday Book as \"Inter Ripam et Mersam\") formed part of the returns for Cheshire. Although this has been interpreted to mean that at that time south Lancashire was part of Cheshire, more exhaustive research indicates that the boundary between Cheshire and what was to become Lancashire remained the River Mersey. With minor variations in spelling across sources, the complete list of hundreds of Cheshire at this time are: Atiscross, Bochelau, Chester, Dudestan, Exestan, Hamestan, Middlewich, Riseton, Roelau, Tunendune, Warmundestrou and Wilaveston.\nFeudal baronies.\nThere were 8 feudal baronies in Chester, the barons of Kinderton, Halton, Malbank, Mold, Shipbrook, Dunham-Massey, and the honour of Chester itself. Feudal baronies or baronies by tenure were granted by the Earl as forms of feudal land tenure within the palatinate in a similar way to which the king granted English feudal baronies within England proper. An example is the barony of Halton. One of Hugh d'Avranche's barons has been identified as Robert Nicholls, Baron of Halton and Montebourg.\nNorth Mersey to Lancashire.\nIn 1182, the land north of the Mersey became administered as part of the new county of Lancashire, resolving any uncertainty about the county in which the land \"Inter Ripam et Mersam\" was. Over the years, the ten hundreds consolidated and changed names to leave just seven\u2014Broxton, Bucklow, Eddisbury, Macclesfield, Nantwich, Northwich and Wirral.\nPrincipality: Merging of Palatine and Earldom.\nIn 1397 the county had lands in the march of Wales added to its territory, and was promoted to the rank of principality. This was because of the support the men of the county had given to King Richard II, in particular by his standing armed force of about 500 men called the \"Cheshire Guard\". As a result, the King's title was changed to \"King of England and France, Lord of Ireland, and Prince of Chester\". No other English county has been honoured in this way, although it lost the distinction on Richard's fall in 1399.\nLieutenancy: North split-off.\nDistrict.\nThrough the Local Government Act 1972, which came into effect on 1 April 1974, some areas in the north became part of the metropolitan counties of Greater Manchester and Merseyside. Stockport (previously a county borough), Altrincham, Hyde, Dukinfield and Stalybridge in the north-east became part of Greater Manchester. Much of the Wirral Peninsula in the north-west, including the county boroughs of Birkenhead and Wallasey, joined Merseyside as the Metropolitan Borough of Wirral. At the same time the Tintwistle Rural District was transferred to Derbyshire. The area of south Lancashire not included within either the Merseyside or Greater Manchester counties, including Widnes and the county borough of Warrington, was added to the new non-metropolitan county of Cheshire.\nDistrict and Unitary.\nHalton and Warrington became unitary authorities independent of Cheshire County Council on 1 April 1998, but remain part of Cheshire for ceremonial purposes and also for fire and policing. Halton is part of Liverpool City Region combined authority, which also includes the five metropolitan boroughs of Merseyside.\nA referendum for a further local government reform connected with an elected regional assembly was planned for 2004, but was abandoned.\nUnitary.\nAs part of the local government restructuring in April 2009, Cheshire County Council and the Cheshire districts were abolished and replaced by two new unitary authorities, Cheshire East and Cheshire West and Chester. The existing unitary authorities of Halton and Warrington were not affected by the change.\nGovernance.\nCurrent.\nCheshire has no county-wide elected local council, but it does have a Lord Lieutenant under the Lieutenancies Act 1997 and a High Sheriff under the Sheriffs Act 1887.\nLocal government functions apart from the Police and Fire/Rescue services are carried out by four smaller unitary authorities: Cheshire East, Cheshire West and Chester, Halton, and Warrington. All four unitary authority areas have borough status.\nPolicing and fire and rescue services are still provided across the county as a whole. The Cheshire Fire Authority consist of members of the four councils, while governance of Cheshire Constabulary is performed by the elected Cheshire Police and Crime Commissioner.\nWinsford is a major administrative hub for Cheshire with the Police and Fire &amp; Rescue Headquarters based in the town as well as a majority of Cheshire West and Chester Council. It was also home to the former Vale Royal Borough Council and Cheshire County Council.\nDevolution talks for the county are scheduled for Autumn 2024.\nTransition into a lieutenancy.\nFrom 1 April 1974 the area under the control of the county council was divided into eight local government districts; Chester, Congleton, Crewe and Nantwich, Ellesmere Port and Neston, Halton, Macclesfield, Vale Royal and Warrington. Halton (which includes the towns of Runcorn and Widnes) and Warrington became unitary authorities in 1998. The remaining districts and the county were abolished as part of local government restructuring on 1 April 2009. The Halton and Warrington boroughs were not affected by the 2009 restructuring.\nOn 25 July 2007, the Secretary of State Hazel Blears announced she was 'minded' to split Cheshire into two new unitary authorities, Cheshire West and Chester, and Cheshire East. She confirmed she had not changed her mind on 19 December 2007 and therefore the proposal to split two-tier Cheshire into two would proceed. Cheshire County Council leader Paul Findlow, who attempted High Court legal action against the proposal, claimed that splitting Cheshire would only disrupt excellent services while increasing living costs for all. On 31 January 2008 \"The Standard\", Cheshire and district's newspaper, announced that the legal action had been dropped. Members against the proposal were advised that they may be unable to persuade the court that the decision of Hazel Blears was \"manifestly absurd\".\nThe Cheshire West and Chester unitary authority covers the area formerly occupied by the City of Chester and the boroughs of Ellesmere Port and Neston and Vale Royal; Cheshire East now covers the area formerly occupied by the boroughs of Congleton, Crewe and Nantwich, and Macclesfield. The changes were implemented on 1 April 2009.\nCongleton Borough Council pursued an appeal against the judicial review it lost in October 2007. The appeal was dismissed on 4 March 2008.\nGeography.\nPhysical.\nA plain of glacial till and other glacio-fluvial sediments extends across much of Cheshire, separating the hills of North Wales and the Pennines. Known as the Cheshire Plain, it was formed following the retreat of a Quaternary ice sheet which left the area dotted with kettle holes, those which hold water being referred to as meres. The bedrock of this region is almost entirely Triassic sandstone, outcrops of which have long been quarried, notably at Runcorn, providing the distinctive red stone for Liverpool Cathedral and Chester Cathedral.\nThe eastern half of the county is Upper Triassic Mercia Mudstone laid down with large salt deposits which were mined for hundreds of years around Winsford. Separating this area from Lower Triassic Sherwood Sandstone to the west is a prominent sandstone ridge known as the Mid Cheshire Ridge. A footpath, the Sandstone Trail, follows this ridge from Frodsham to Whitchurch passing Delamere Forest, Beeston Castle and earlier Iron Age forts.\nThe western fringes of the Peak District - the southernmost extent of the Pennine range - form the eastern part of the county. The highest point (county top) in the historic county of Cheshire was Black Hill () near Crowden in the Cheshire Panhandle, a long eastern projection of the county which formerly stretched along the northern side of Longdendale and on the border with the West Riding of Yorkshire. Black Hill is now the highest point in the ceremonial county of West Yorkshire.\nWithin the current ceremonial county and the unitary authority of Cheshire East the highest point is Shining Tor on the Derbyshire/Cheshire border between Macclesfield and Buxton, at above sea level. After Shining Tor, the next highest point in Cheshire is Shutlingsloe, at above sea level. Shutlingsloe lies just to the south of Macclesfield Forest and is sometimes humorously referred to as the \"Matterhorn of Cheshire\" thanks to its distinctive steep profile.\nHuman.\nGreen belt.\nCheshire contains portions of two green belt areas surrounding the large conurbations of Merseyside and Greater Manchester (North Cheshire Green Belt, part of the North West Green Belt) and Stoke-on-Trent (South Cheshire Green Belt, part of the Stoke-on-Trent Green Belt), these were first drawn up from the 1950s. Contained primarily within Cheshire East and Chester West &amp; Chester, with small portions along the borders of the Halton and Warrington districts, towns and cities such as Chester, Macclesfield, Alsager, Congleton, Northwich, Ellesmere Port, Knutsford, Warrington, Poynton, Disley, Neston, Wilmslow, Runcorn, and Widnes are either surrounded wholly, partially enveloped by, or on the fringes of the belts. The North Cheshire Green Belt is contiguous with the Peak District Park boundary inside Cheshire.\nBorders.\nThe ceremonial county borders Merseyside, Greater Manchester, Derbyshire, Staffordshire and Shropshire in England along with Flintshire and Wrexham in Wales, arranged by compass directions as shown in the table. below. Cheshire also forms part of the North West England region.\nFlora and fauna.\nIn July 2022, beavers bred in Cheshire for the first time in 400 years, following a reintroduction scheme.\nDemography.\nPopulation.\nBased on the Census of 2001, the overall population of Cheshire East and Cheshire West and Chester is 673,781, of which 51.3% of the population were male and 48.7% were female. Of those aged between 0\u201314 years, 51.5% were male and 48.4% were female; and of those aged over 75 years, 62.9% were female and 37.1% were male. This increased to 699,735 at the 2011 Census. The population for 2021 is forecast to be 708,000.\nIn 2001, the population density of Cheshire East and Cheshire West and Chester was 32 people per km2, lower than the North West average of 42 people/km2 and the England and Wales average of 38 people/km2. Ellesmere Port and Neston had a greater urban density than the rest of the county with 92 people/km2.\nEthnicity.\nIn 2001, ethnic white groups accounted for 98% (662,794) of the population, and 10,994 (2%) in ethnic groups other than white.\nOf the 2% in non-white ethnic groups:\nReligion.\nIn the 2001 Census, 81% of the population (542,413) identified themselves as Christian; 124,677 (19%) did not identify with any religion or did not answer the question; 5,665 (1%) identified themselves as belonging to other major world religions; and 1,033 belonged to other religions.\nThe boundary of the Church of England Diocese of Chester follows most closely the pre-1974 county boundary of Cheshire, so it includes all of Wirral, Stockport, and the Cheshire panhandle that included Tintwistle Rural District council area. In terms of Roman Catholic church administration, most of Cheshire falls into the Roman Catholic Diocese of Shrewsbury.\nEconomy.\nCheshire has a diverse economy with significant sectors including agriculture, automotive, bio-technology, chemical, financial services, food and drink, ICT, and tourism. The county is famous for the production of Cheshire cheese, salt and silk. The county has seen a number of inventions and firsts in its history.\nA mainly rural county, Cheshire has a high concentration of villages. Agriculture is generally based on the dairy trade, and cattle are the predominant livestock. Land use given to agriculture has fluctuated somewhat, and in 2005 totalled 1558\u00a0km2 over 4,609 holdings. Based on holdings by EC farm type in 2005, 8.51\u00a0km2 was allocated to dairy farming, with another 11.78\u00a0km2 allocated to cattle and sheep.\nThe chemical industry in Cheshire was founded in Roman times, with the mining of salt in Winsford, Middlewich and Northwich. Salt is still mined in the area by British Salt. The salt mining has led to a continued chemical industry around Northwich, with Brunner Mond based in the town. Other chemical companies, including Ineos (formerly ICI), have plants at Runcorn. The Essar Refinery (formerly Shell Stanlow Refinery) is at Ellesmere Port. The oil refinery has operated since 1924 and has a capacity of 12\u00a0million tonnes per year.\nCrewe was once the centre of the British railway industry, and remains a major railway junction. The Crewe railway works, built in 1840, employed 20,000 people at its peak, although the workforce is now less than 1,000. Crewe is also the home of Bentley cars. Also within Cheshire are manufacturing plants for Jaguar and Vauxhall Motors in Ellesmere Port.\nThe county also has an aircraft industry, with the BAE Systems facility at Woodford Aerodrome, part of BAE System's Military Air Solutions division. The facility designed and constructed Avro Lancaster and Avro Vulcan bombers and the Hawker-Siddeley Nimrod. On the Cheshire border with Flintshire is the Broughton aircraft factory, more recently associated with Airbus.\nTourism in Cheshire from within the UK and overseas continues to perform strongly. Over 8\u00a0million nights of accommodation (both UK and overseas) and over 2.8\u00a0million visits to Cheshire were recorded during 2003.\nAt the start of 2003, there were 22,020 VAT-registered enterprises in Cheshire, an increase of 7% since 1998, many in the business services (31.9%) and wholesale/retail (21.7%) sectors. Between 2002 and 2003 the number of businesses grew in four sectors: public administration and other services (6.0%), hotels and restaurants (5.1%), construction (1.7%), and business services (1.0%). The county saw the largest proportional reduction between 2001 and 2002 in employment in the energy and water sector and there was also a significant reduction in the manufacturing sector. The largest growth during this period was in the other services and distribution, hotels and retail sectors.\nCheshire is considered to be an affluent county. However, towns such as Crewe and Winsford have significant deprivation. The county's proximity to the cities of Manchester and Liverpool means counter urbanisation is common. Cheshire West has a fairly large proportion of residents who work in Liverpool and Manchester, while the town of Northwich and area of Cheshire East falls more within Manchester's sphere of influence.\nEducation.\nAll four local education authorities in Cheshire operate only comprehensive state school systems. When Altrincham, Sale and Bebington were moved from Cheshire to Trafford and Merseyside in 1974, they took some former Cheshire selective schools. There are two universities based in the county, the University of Chester and the Chester campus of The University of Law. The Crewe campus of Manchester Metropolitan University was scheduled to close in 2019.\nCulture.\nArts and entertainment.\nCheshire has produced musicians such as Joy Division members Ian Curtis and Stephen Morris, One Direction member Harry Styles, the members of The 1975, Take That member Gary Barlow, The Cult member Ian Astbury, Catfish and the Bottlemen member Van McCann, Girls Aloud member Nicola Roberts, Stephen Hough, John Mayall, The Charlatans member Tim Burgess, and Nigel Stonier.\nActors from Cheshire include Russ Abbot, Warren Brown, Julia Chan, Ray Coulthard, Daniel Craig, Tim Curry, Wendy Hiller, Tom Hughes, Tim McInnerny, Ben Miller, Pete Postlethwaite, Adam Rickitt, John Steiner, and Ann Todd. The most famous author from the county is Lewis Carroll, who wrote \"Alice's Adventures in Wonderland\" and named the Cheshire Cat character after it. Other notable Cheshire writers include Hall Caine, Alan Garner, and Elizabeth Gaskell. Artists from Cheshire include ceramic artist Emma Bossons and sculptor/photographer Andy Goldsworthy.\nLocal news and television programmes are provided by BBC North West and ITV Granada. Television signals are received from the Winter Hill TV transmitter.\nLocal radio stations in the county include Chester's Dee Radio, Capital North West and Wales, Smooth Wales, Cheshire's Silk Radio and Hits Radio Staffordshire &amp; Cheshire. It is one of only four counties in the country (along with County Durham, Dorset, and Rutland) that does not have its own designated BBC radio station; the south and parts of the east are covered by BBC Radio Stoke, while BBC Radio Merseyside tends to cover the west, and BBC Radio Manchester covers the north and parts of the east. The BBC directs readers to Stoke and Staffordshire when Cheshire is selected on their website. There were plans to launch BBC Radio Cheshire, but those were shelved in 2007 after the BBC license fee settlement was lower than expected.\nSports.\nAthletes native to Cheshire include sailor Ben Ainslie, cricketer Ian Botham, rock climber Shauna Coxsey, boxer Tyson Fury, oarsman Matt Langridge, mountaineer George Mallory, marathon runner Paula Radcliffe, cyclist Sarah Storey, and hurdler Shirley Strong. It has also been home to numerous athletes from outside the county. Many Premier League footballers have relocated there over the years upon joining nearby teams such as Manchester United FC, Manchester City FC, Everton FC, and Liverpool FC. These include Dean Ashton, Seth Johnson, Jesse Lingard and Michael Owen, The \"Cheshire Golden Triangle\" is the collective name for a group of adjacent Cheshire villages where the number of footballers, actors, and entrepreneurs moving in over the years led to the average house prices becoming some of the most expensive in the UK.\nCheshire has one Football League team, Crewe Alexandra, which plays in . The next highest-placed teams are Chester and Warrington Town, who both compete in the National League North, the sixth tier of English football. Northwich Victoria, another ex-League team which was a founding member of the Football League Division Two in 1892/1893, now represents Cheshire in the Northern Premier League along with Nantwich Town. Macclesfield Town another former League club, went into liquidation in 2020; a phoenix club, Macclesfield, was formed in 2021.\nThe Warrington Wolves and Widnes Vikings are the premier rugby league teams in Cheshire; the former plays in the Super League, while the latter plays in the Championship. There are also numerous junior clubs in the county, including Chester Gladiators. Cheshire County Cricket Club is one of the clubs that make up the minor counties of English and Welsh cricket. Cheshire also is represented in the highest level basketball league in the UK, the BBL, by Cheshire Phoenix (formerly Cheshire Jets). Europe's largest motorcycle event, the Thundersprint, is held in Northwich every May.\nOther.\nThe Royal Cheshire Show, an annual agricultural show, has taken place since the 1800s.\nCheshire also produced a military hero in Norman Cyril Jones, a World War I flying ace who won the Distinguished Flying Cross.\nUnofficial county flower.\nAs part of a 2002 marketing campaign, the plant conservation charity Plantlife chose the cuckooflower as the county flower. Previously, a sheaf of golden wheat was the county emblem, a reference to the Earl of Chester's arms in use from the 12th century.\nLandmarks.\nPrehistoric burial grounds have been discovered at The Bridestones near Congleton (Neolithic) and Robin Hood's Tump near Alpraham (Bronze Age). The remains of Iron Age hill forts are found on sandstone ridges at several locations in Cheshire. Examples include Maiden Castle on Bickerton Hill, Helsby Hillfort and Woodhouse Hillfort at Frodsham. The Roman fortress and walls of Chester, perhaps the earliest building works in Cheshire remaining above ground, are constructed from purple-grey sandstone.\nThe distinctive local red sandstone has been used for many monumental and ecclesiastical buildings throughout the county: for example, the medieval Beeston Castle, Chester Cathedral and numerous parish churches. Occasional residential and industrial buildings, such as Helsby railway station (1849), are also in this sandstone.\nMany surviving buildings from the 15th to 17th centuries are timbered, particularly in the southern part of the county. Notable examples include the moated manor house Little Moreton Hall, dating from around 1450, and many commercial and residential buildings in Chester, Nantwich and surrounding villages.\nEarly brick buildings include Peover Hall near Macclesfield (1585), Tattenhall Hall (pre-1622), and the Pied Bull Hotel in Chester (17th-century). From the 18th century, orange, red or brown brick became the predominant building material used in Cheshire, although earlier buildings are often faced or dressed with stone. Examples from the Victorian period onwards often employ distinctive brick detailing, such as brick patterning and ornate chimney stacks and gables. Notable examples include Arley Hall near Northwich, Willington Hall near Chester (both by Nantwich architect George Latham) and Overleigh Lodge, Chester. From the Victorian era, brick buildings often incorporate timberwork in a mock Tudor style, and this hybrid style has been used in some modern residential developments in the county. Industrial buildings, such as the Macclesfield silk mills (for example, Waters Green New Mill), are also usually in brick.\nSettlements.\nThe county is home to some of the most affluent areas of northern England, including Alderley Edge, Wilmslow, Prestbury, Tarporley and Knutsford, named in 2006 as the most expensive place to buy a house in the north of England. The former Cheshire town of Altrincham was in second place. The area is sometimes referred to as The Golden Triangle on account of the area in and around the aforementioned towns and villages. Holmes Chapel has increasingly become a sought out tourist destination due to being the former hometown of celebrity Harry Styles, and is also undergoing a planned population increase.\nThingwall, currently in the county of Merseyside but historically part of Cheshire until 1974, is known for having once been the base of a Viking parliament established by Norse settlers in the area.\nThere is currently one city in the county officially, Chester. However, it remains a disputed piece of folklore that the village of Thelwall (today administratively paired with its neighbour Grappenhall in a civil parish) was at one time considered a city. Warrington is currently the largest urban settlement in the county overall despite its town status, and was one of the third wave of post-Second World War UK new towns designated for expansion. Other core settlements across Cheshire are:\nSome settlements which were historically part of the county now fall under the ceremonial counties of Derbyshire, Merseyside and Greater Manchester:\nTransport.\nRailways.\nThe main railway line through the county is the West Coast Main Line. Trains on the main London to Scotland line call at Crewe (in the south of the county) and Warrington Bank Quay (in the north of the county). Trains stop at Crewe and Runcorn on the Liverpool branch of the WCML; Crewe and Macclesfield are each hourly stops on the two Manchester branches. The major interchanges are:\nIn the east of Cheshire, Macclesfield station is served by Avanti West Coast, CrossCountry and Northern, on the Manchester\u2013London line. Services from Manchester to the south coast frequently stop at Macclesfield. Neston on the Wirral Peninsula is served by a railway station on the Borderlands line between Bidston and Wrexham.\nRoadways.\nCheshire has of roads, including of the M6, M62, M53 and M56 motorways; there are 23 interchanges and four service areas. It also has the A580 \"East Lancashire Road\" at its border with Greater Manchester at Leigh. The M6 motorway at the Thelwall Viaduct carries 140,000 vehicles every 24 hours.\nBus transport in Cheshire is provided by various operators. The major bus operator in the Cheshire area is D&amp;G Bus. Other operators in Cheshire include Stagecoach Chester &amp; Wirral and Network Warrington.\nThere are also several operators based outside of Cheshire, who either run services wholly within the area or services which start from outside the area. Companies include Arriva Buses Wales, Aimee's Travel, High Peak, First Greater Manchester, D&amp;G bus and Stagecoach Manchester.\nSome services are run under contract to Cheshire West and Chester, Cheshire East, Borough of Halton and Warrington Councils.\nWaterways.\nThe Cheshire canal system includes several canals originally used to transport the county's industrial products (mostly chemicals). Nowadays they are mainly used for tourist traffic. The Cheshire Ring is formed from the Rochdale, Ashton, Peak Forest, Macclesfield, Trent and Mersey and Bridgewater canals.\nThe Manchester Ship Canal is a wide, stretch of water opened in 1894. It consists of the rivers Irwell and Mersey made navigable to Manchester for seagoing ships leaving the Mersey estuary. The canal passes through the north of the county via Runcorn and Warrington. Rivers and canals in the county are:"}
{"id": "7407", "revid": "1269036364", "url": "https://en.wikipedia.org/wiki?curid=7407", "title": "County town", "text": "In Great Britain and Ireland, a county town is usually the location of administrative or judicial functions within a county, and the place where public representatives are elected to parliament. Following the establishment of county councils in England in 1889, the headquarters of the new councils were usually established in the county town of each county; however, the concept of a county town pre-dates these councils.\nThe concept of a county town is ill-defined and unofficial. Some counties in Great Britain have their administrative bodies housed elsewhere. For example, Lancaster is the county town of Lancashire, but the county council is in Preston. Owing to the creation of unitary authorities, some county towns in Great Britain are administratively separate from the county. For example, Nottingham is separated from the rest of Nottinghamshire, and Brighton and Hove is separate from East Sussex. On a ceremonial level, both are in their own respective counties geographically.\nGreat Britain, historic.\nEngland.\nThis list shows towns or cities which held county functions at various points in time.\nWales.\nFollowing the Norman invasion of Wales, the Cambro-Normans created the historic shire system (also known as ancient counties). Many of these counties were named for the centre of Norman power within the new county (Caernarfonshire named for Caernarfon, Monmouthshire named for Monmouth) others were named after the previous medieval Welsh kingdoms (Ceredigon becomes Cardigan, Morgannwg becomes Glamorgan). The 1535 Laws in Wales Act established the historic counties in English law, but in Wales they were later replaced with eight preserved counties for ceremonial purposes and the twenty two principal areas are used for administrative purposes. Neither of these subdivisions use official county towns, although their administrative headquarters and ceremonial centres are often located in the historic county town.\nGreat Britain, post 19th-century reforms.\nWith the creation of elected county councils in 1889, the administrative headquarters in some cases moved away from the traditional county town. Furthermore, in 1965 and 1974 there were major boundary changes in England and Wales and administrative counties were replaced with new metropolitan and non-metropolitan counties. The boundaries underwent further alterations between 1995 and 1998 to create unitary authorities, and some of the ancient counties and county towns were restored. (Note: not all headquarters are or were called County Halls or Shire Halls e.g.: Cumbria County Council's HQ up until 2016 was called \"The Courts\" and has since moved to Cumbria House.) Before 1974, many of the county halls were in towns and cities that had the status of a county borough i.e. a borough outside the county council's jurisdiction.\nIreland and Northern Ireland.\nRepublic of Ireland.\nThe follow lists the location of the administration of each of the 31 local authorities in the Republic of Ireland, with 26 of the traditional counties.\nNorthern Ireland.\nNote \u2013 Despite the fact that Belfast is the capital of Northern Ireland, it is not the county town of any county. Greater Belfast straddles two counties \u2013 Antrim and Down.\nJamaica.\nJamaica's three counties were established in 1758 to facilitate the holding of courts along the lines of the British county court system, with each county having a county town. The counties have no current administrative relevance."}
{"id": "7411", "revid": "8729451", "url": "https://en.wikipedia.org/wiki?curid=7411", "title": "Constitution of Canada", "text": "The Constitution of Canada () is the supreme law in Canada. It outlines Canada's system of government and the civil and human rights of those who are citizens of Canada and non-citizens in Canada. Its contents are an amalgamation of various codified acts, treaties between the Crown and Indigenous Peoples (both historical and modern), uncodified traditions and conventions. Canada is one of the oldest constitutional monarchies in the world.\nThe Canadian constitution includes core written documents and provisions that are constitutionally entrenched, take precedence over all other laws and place substantive limits on government action; these include the \"Constitution Act, 1867\" (formerly the \"British North America Act, 1867)\" and the \"Canadian Charter of Rights and Freedoms.\" The \"Constitution Act\", \"1867\" provides for a constitution \"similar in principle\" to the largely unwritten constitution of the United Kingdom, recognizes Canada as a constitutional monarchy and federal state, and outlines the legal foundations of Canadian federalism.\nThe Constitution of Canada includes written and unwritten components. Section 52 of the \"Constitution Act, 1982\" states that \"the Constitution of Canada is the supreme law of Canada\" and that any inconsistent law is of no force or effect. It further lists written documents which are included in the Constitution of Canada; these are the \"Canada Act 1982\" (which includes the \"Constitution Act, 1982\"), the acts and orders referred to in its schedule (including in particular the \"Constitution Act, 1867\"), and any amendments to these documents.\nThe Supreme Court of Canada has held that this list is not exhaustive and that the Constitution of Canada includes a number of pre-confederation acts and unwritten components as well. The Canadian constitution also includes the fundamental principles of federalism, democracy, constitutionalism and the rule of law, and respect for minorities. See list of Canadian constitutional documents for details.\nHistory of the constitution.\nThe first semblance of a constitution for Canada was the Royal Proclamation of 1763. The act renamed the northeasterly portion of the former French province of New France as the Province of Quebec, roughly coextensive with the southern third of contemporary Quebec. The proclamation, which established an appointed colonial government, was the constitution of Quebec until 1774 when the British parliament passed the Quebec Act, which expanded the province's boundaries to the Ohio and Mississippi Rivers (one of the grievances listed in the United States Declaration of Independence). Significantly, the Quebec Act also replaced French criminal law with the English common law system; but the French civil law system was retained for non-criminal matters.\nThe Treaty of Paris of 1783 ended the American War of Independence and sent a wave of British loyalist refugees northward to Quebec and Nova Scotia. In 1784, the two provinces were divided: Nova Scotia was split into Nova Scotia, Cape Breton Island (rejoined to Nova Scotia in 1820), Prince Edward Island, and New Brunswick, while Quebec was split into Lower Canada (southern Quebec) and Upper Canada (southern through lower northern Ontario). The winter of 1837\u201338 saw rebellion in both Canadas, contributing to their re-union as the Province of Canada in 1841.\nThe \"British North America Act, 1867\" established the Dominion of Canada as a federation of provinces. Initially, on July 1, 1867, four provinces entered into confederation as \"One dominion under the name of Canada\": Canada West (former Upper Canada, now Ontario), Canada East (former Lower Canada, now Quebec), Nova Scotia, and New Brunswick. Title to the Northwest Territories was transferred by the Hudson's Bay Company in 1870, out of which the province of Manitoba (the first to be established by the Parliament of Canada) was created. British Columbia joined Confederation in 1871, followed by Prince Edward Island in 1873. The Yukon Territory was created by Parliament in 1898, followed by Alberta and Saskatchewan in 1905 (all out of parts of the Northwest Territories). Newfoundland, Britain's oldest colony in the Americas and by then also a Dominion, joined Confederation in 1949. Nunavut was created in 1999 from the Northwest Territories.\nAn Imperial Conference in 1926 that included the leaders of all Dominions and representatives from India (which then included Burma, Bangladesh, and Pakistan), led to the eventual enactment of the Statute of Westminster 1931. The statute, an essential transitory step from the British Empire to the Commonwealth of Nations, provided that existing Dominions became fully sovereign of the United Kingdom and any new Dominions would be fully sovereign upon the grant of Dominion status. Although listed, Newfoundland never ratified the statute so was still subject to imperial authority when its entire system of government and economy collapsed in the mid-1930s. Canada did ratify the statute but with a requested exception\u2014the Canadian federal and provincial governments could not agree on an amending formula for the Canadian constitution. It would be another 50 years before this was achieved. In the interim, the British parliament periodically passed constitutional amendments when requested by the government of Canada. This was never anything but a rubber stamp.\nThe patriation of the Canadian constitution was achieved in 1982 when the British parliament, with the request and assent of the Canadian parliament, passed the \"Canada Act 1982\", which included in its schedules the \"Constitution Act, 1982\". The United Kingdom thus renounced any remaining responsibility for, or jurisdiction over, Canada. In a formal ceremony on Parliament Hill in Ottawa, Queen Elizabeth II proclaimed the \"Constitution Act, 1982\" into law on April 17, 1982.\nThe \"Constitution Act, 1982\", includes the \"Canadian Charter of Rights and Freedoms\". Before the Charter, various statutes protected an assortment of civil rights and obligations but nothing was enshrined in the constitution until 1982. The Charter has thus placed a strong focus upon individual and collective rights of the people of Canada. The enactment of the Charter of Rights and Freedoms has fundamentally changed much of Canadian constitutional law. The act also codified many previously oral constitutional conventions and made amendment of the constitution in general significantly more difficult. Previously, the Canadian constitution could be formally amended by an act of the British parliament, or by informal agreement between the federal and provincial governments, or even simply by adoption as the custom of an oral convention or performance that shows precedential but unwritten tradition. Since the act, textual amendments must now conform to certain specified provisions in the written portion of the Canadian constitution.\n\"Constitution Act, 1867\".\nThis was an Act of the British parliament, originally called the \"British North America Act, 1867\". It outlined Canada's system of government, which combines Britain's Westminster model of parliamentary government with the division of sovereignty (federalism). Although it is the first of 20 \"British North America Acts\", it is the most famous as the primary document of Canadian Confederation. With the patriation of the Constitution in 1982, this Act was renamed \"Constitution Act, 1867\". In recent years, the 1867 document has mainly served as the basis on which the division of powers between the provinces and the federal government is analyzed.\n\"Constitution Act, 1982\".\nEndorsed by all provincial governments except that of Quebec, this was the formal Act of Parliament that effected Canada's full legislative independence from the United Kingdom. Part V of this act established an amending formula for the Canadian constitution, the lack of which (due to more than 50 years of disagreement between the federal and provincial governments) meant Canada's constitutional amendments still required enactment by the British parliament after Statute of Westminster in 1931.\nThe \"Constitution Act, 1982\" was enacted as a schedule to the \"Canada Act 1982\", a British Act of Parliament which was introduced at the request of a joint address to Queen Elizabeth II by the Senate and House of Commons of Canada. The version of the \"Canada Act 1982\" which is in force in Britain is in English only, but the version of the act in force in Canada is bilingual, English and French. In addition to enacting the \"Constitution Act, 1982\", the \"Canada Act 1982\" provides that no further British acts of Parliament will apply to Canada as part of its law, finalizing Canada's legislative independence.\nCanadian Charter of Rights and Freedoms.\nAs noted above, this is Part I of the \"Constitution Act, 1982\". The Charter is the constitutional guarantee of the civil rights and liberties of every citizen in Canada, such as freedom of expression, of religion, and of mobility. Part II addresses the rights of Aboriginal peoples in Canada.\nIt is written in plain language to ensure accessibility to the average citizen. It applies only to government and government actions to prevent the government from creating unconstitutional laws.\nAmending formula.\nInstead of the usual parliamentary procedure, which includes the monarch's formal royal assent for enacting legislation, amendments to any of the acts that collectively form the constitution must be done in accordance with Part V of the \"Constitution Act, 1982\", which provides for five different amending formulae. Amendments can be brought forward under section 46(1) by any province or the federal legislature. The general formula set out in section 38(1), known as the \"7/50 formula,\" requires: (a) assent from both the House of Commons and the Senate; (b) the approval of two-thirds of the provincial legislatures (at least seven provinces) representing at least 50 per cent of the population of the provinces (effectively, this would include at least Quebec or Ontario, as they contain more than half of the population of Canada). This formula specifically applies to amendments related to the proportionate representation in Parliament, powers, selection, and composition of the Senate, the Supreme Court, and the addition of provinces or territories.\nThe other amendment formulae are for particular cases as provided by the act. An amendment related to the Office of the King, the use of either official language (subject to section 43), the amending formula itself, or the composition of the Supreme Court, must be adopted by unanimous consent of all the provinces in accordance with section 41. In the case of an amendment related to provincial boundaries or the use of an official language within a province alone, the amendment must be passed by the legislatures affected by the amendment (section 43). In the case of an amendment that affects the federal government only, the amendment does not need the approval of the provinces (section 44). Similarly, amendments affecting a provincial government alone (section 45) do not need the approval of the parliament or the other provinces.\nSources of the constitution.\nCanada's constitution has roots going back to the thirteenth century, including England's Magna Carta and the first English Parliament of 1275. Canada's constitution is composed of several individual statutes. There are three general methods by which a statute becomes entrenched in the Constitution:\nUnwritten or uncodified sources.\nThe existence of unwritten constitutional components was reaffirmed in 1998 by the Supreme Court in \"Reference re Secession of Quebec\".\nThe Constitution is more than a written text. It embraces the entire global system of rules and principles which govern the exercise of constitutional authority. A superficial reading of selected provisions of the written constitutional enactment, without more, may be misleading.\nIn practice, there have been three sources of unwritten constitutional law:\nProvincial constitutions.\nUnlike in most federations, Canadian provinces do not have written provincial constitutions. Provincial constitutions are instead a combination of uncodified constitution, provisions of the Constitution of Canada, and provincial statutes.\nOverall structures of provincial governments (like the legislature and cabinet) are described in parts of the Constitution of Canada. Governmental structure of the original four provinces (Nova Scotia, New Brunswick, Quebec, and Ontario) is described in Part V of the \"Constitution Act, 1867\". The three colonies that joined Canada after Confederation (British Columbia, Prince Edward Island, and Newfoundland and Labrador) had existing UK legislation which described their governmental structure, and this was affirmed in each colony's \"Terms of Union\", which now form part of Canada's Constitution. The remaining three provinces (Manitoba, Saskatchewan, and Alberta) were created by federal statute. Their constitutional structures are described in those statutes, which now form part of Canada's Constitution.\nAll provinces have enacted legislation that establishes other rules for the structure of government. For example, every province (and territory) has an act governing elections to the legislature, and another governing procedure in the legislature. Two provinces have explicitly listed such acts as being part of their provincial constitution; see \"Constitution of Quebec\" and \"Constitution Act\" (British Columbia). However, these acts do not, generally, supersede other legislation and do not require special procedures to amend, and so they function as regular statutes rather than constitutional statutes.\nA small number of non-constitutional provincial laws do supersede all other provincial legislation, as a constitution would. This is referred to as quasi-constitutionality. Quasi-constitutionality is often applied to human rights laws, allowing those laws to act as a \"de facto\" constitutional charter of rights. For example, laws preventing discrimination in employment, housing, and services have clauses making them quasi-constitutional in ten of thirteen jurisdictions.\nAmending provincial constitutions.\nSection\u00a045 of the \"Constitution Act, 1982\" allows each province to amend its own constitution. This applies, for example, to provincial statute laws like \"Constitution of Quebec\" and \"Constitution Act (British Columbia)\". However, if the desired change would require an amendment to any documents that form part of the Constitution of Canada, it would require the consent of the Senate and House of Commons under section\u00a043. This was done, for example, by the \"Constitution Amendment, 1998\", when Newfoundland asked the federal government to amend the \"Terms of Union of Newfoundland\" to allow it to end denominational quotas for religion classes.\nA small number of statutes within provincial constitutions cannot be amended by a simple majority of the legislative assembly, despite section\u00a045. For example, section\u00a07 of the \"Constitution of Alberta Amendment Act, 1990\" requires plebiscites of M\u00e9tis settlement members before that Act can be amended. Courts have not yet ruled about whether this kind of language really would bind future legislatures, but it might do so if the higher bar was met when creating the law.\nThree amendments to provincial constitutions in the 2020s have been controversially framed as amendments to the \"Constitution Act 1867\". These are Quebec statutes purporting to add sections\u00a090Q and 128Q and a Saskatchewan statute purporting to add section\u00a090S. Because the Senate and House of Commons did not authorise these amendments, they would only have effect if they are amendments to provincial constitutions under the section\u00a045 amending procedure. Constitutional scholars are divided on the validity of an amendment to a provincial constitution framed as an addition to part of the Constitution of Canada.\nVandalism of the proclamation paper.\nIn 1983, Peter Greyson, an art student, entered Ottawa's National Archives (known today as Library and Archives Canada) and poured red paint mixed with glue over a copy of the proclamation of the 1982 constitutional amendment. He said he was displeased with the federal government's decision to allow United States missile testing in Canada and had wanted to \"graphically illustrate to Canadians\" how wrong he believed the government to be. Greyson was charged with public mischief and sentenced to 89 days in jail, 100 hours of community work, and two years of probation. A grapefruit-sized stain remains on the original document; restoration specialists opted to leave most of the paint intact, fearing that removal attempts would only cause further damage."}
{"id": "7412", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=7412", "title": "Constitution of Canada/1867 Preamble", "text": ""}
{"id": "7413", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=7413", "title": "Constitution of Canada/1867 I Preliminary", "text": ""}
{"id": "7414", "revid": "290432", "url": "https://en.wikipedia.org/wiki?curid=7414", "title": "Constitution of Canada/1867 II Union", "text": ""}
{"id": "7415", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7415", "title": "Constitution of Canada/1867 III Executive Power", "text": ""}
{"id": "7416", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7416", "title": "Constitution of Canada/1867 IV Legislative Power", "text": ""}
{"id": "7417", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7417", "title": "Constitution of Canada/1867 V Provincial Constitutions", "text": ""}
{"id": "7418", "revid": "290432", "url": "https://en.wikipedia.org/wiki?curid=7418", "title": "Constitution of Canada/1867 VI Distribution of Legislative Powers", "text": ""}
{"id": "7419", "revid": "290432", "url": "https://en.wikipedia.org/wiki?curid=7419", "title": "Constitution of Canada/1867 VII Judicature", "text": ""}
{"id": "7420", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7420", "title": "Constitution of Canada/1867 VIII Revenues Debts Assets Taxation", "text": ""}
{"id": "7421", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7421", "title": "Constitution of Canada/1867 IX Miscellaneous Provisions", "text": ""}
{"id": "7422", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7422", "title": "Constitution of Canada/1867 X Intercolonial Railway", "text": ""}
{"id": "7423", "revid": "108", "url": "https://en.wikipedia.org/wiki?curid=7423", "title": "Constitution of Canada/1867 XI Admission of Other Colonies", "text": ""}
{"id": "7424", "revid": "33842945", "url": "https://en.wikipedia.org/wiki?curid=7424", "title": "Crochet", "text": "Crochet (; ) is a process of creating textiles by using a crochet hook to interlock loops of yarn, thread, or strands of other materials. The name is derived from the French term \"crochet\", which means 'hook'. Hooks can be made from different materials (aluminum, steel, metal, wood, bamboo, bone, etc.), sizes, and types (in-line, tapered, ergonomic, etc.). The key difference between crochet and knitting, beyond the implements used for their production, is that each stitch in crochet is completed before you begin the next one, while knitting keeps many stitches open at a time. Some variant forms of crochet, such as Tunisian crochet and Broomstick lace, do keep multiple crochet stitches open at a time.\nEtymology.\nThe word crochet is derived from the French word , a diminutive of \"croche\", in turn from the Germanic \"croc\", both meaning \"hook\". It was used in 17th-century French lace-making, where the term \"Crochetage\" designated a stitch used to join separate pieces of lace. The word \"crochet\" subsequently came to describe both the specific type of textile, and the hooked needle used to produce it.\nIn 1567, the tailor of Mary, Queen of Scots, Jehan de Compiegne, supplied her with silk thread for sewing and crochet, \"soye \u00e0 coudre et crochetz\".\nOrigins.\nKnitted textiles survive from as early as the 11th century CE, but the first substantive evidence of crocheted fabric emerges in Europe during the 19th century. Earlier work identified as crochet was commonly made by n\u00e5lebinding, a different looped yarn technique.\nThe first known published instructions for crochet explicitly using that term to describe the craft in its present sense appeared in the Dutch magazine \"Pen\u00e9lop\u00e9\" in 1823. This includes a colour plate showing five styles of purse, of which three were intended to be crocheted with silk thread. The first is \"simple open crochet\" (\"crochet simple ajour\"), a mesh of chain-stitch arches. The second (illustrated here) starts in a semi-open form (\"demi jour\"), where chain-stitch arches alternate with equally long segments of slip-stitch crochet, and closes with a star made with \"double-crochet stitches\" (\"dubbelde hekelsteek\": double-crochet in British terminology; single-crochet in US). The third purse is made entirely in double-crochet. The instructions prescribe the use of a tambour needle (as illustrated below) and introduce a number of decorative techniques.\nThe earliest dated reference in English to garments made of cloth produced by looping yarn with a hook\u2014\"shepherd's knitting\"\u2014is in \"The Memoirs of a Highland Lady\" by Elizabeth Grant (1797\u20131830). The journal entry, itself, is dated 1812 but was not recorded in its subsequently published form until some time between 1845 and 1867, and the actual date of publication was first in 1898. Nonetheless, the 1833 volume of \"Pen\u00e9lop\u00e9\" describes and illustrates a shepherd's hook, and recommends its use for crochet with coarser yarn.\nIn 1844, one of the numerous books discussing crochet that began to appear in the 1840s states:\nTwo years later, the same author writes:\nAn instruction book from 1846 describes \"Shepherd or single crochet\" as what in current international terminology is either called single crochet or slip-stitch crochet, with U.S. terminology always using the latter (reserving single crochet for use as noted above). It similarly equates \"Double\" and \"French crochet\".\nNotwithstanding the categorical assertion of a purely British origin, there is solid evidence of a connection between French tambour embroidery, french passementerie and crochet. A form of hook known as crochet was used to create 'chains in the air' as part of passementerie back in the 17th century. This is confirmed by a patent issued to the passementiers by Louis XIV in 1653, and there are earlier decorative examples of this technique. The patent lists various items, including \"thread for embroidery, enhanced and embellished as done with a needle, on thimbles, on the fingers, on a crochet, and on a bobbin.\" Similarly, chain stitch appears in Queen Elizabeth I's wardrobe accounts, starting in 1558, with further references to garments bordered with 'cheyne lace' in other inventories. One example from 1588 describes \"a long cloak of murry velvet, with a border of small cheyne lace of Venice silver.\" While the exact design of the 1653 crochet is unclear, a 1723 French dictionary by Jacques Savary des Br\u00fblons describes a crochet as a small iron instrument, three or four inches long, with a pointed, curved end and a wooden handle, used by passementiers for tasks like creating hat seams and attaching flowers to mesh. It's most likely that the hook used in crochet came from the ones used by the french pessamenterie industry.\nFrench tambour embroidery and the crochet needle used for it was illustrated in detail in 1763 in Diderot's Encyclopedia. The tip of the needle shown there is indistinguishable from that of a present-day inline crochet hook and the chain stitch separated from a cloth support is a fundamental element of the latter technique. The 1823 \"Pen\u00e9lop\u00e9\" instructions unequivocally state that the tambour tool was used for crochet and the first of the 1840s instruction books uses the terms \"tambour\" and \"crochet\" as synonyms. This equivalence is retained in the 4th edition of that work, 1847.\nThe strong taper of the shepherd's hook eases the production of slip-stitch crochet but is less amenable to stitches that require multiple loops on the hook at the same time. Early yarn hooks were also continuously tapered but gradually enough to accommodate multiple loops. The design with a cylindrical shaft that is commonplace today was largely reserved for tambour-style steel needles. Both types gradually merged into the modern form that appeared toward the end of the 19th century, including both tapered and cylindrical segments, and the continuously tapered bone hook remained in industrial production until World War II.\nThe early instruction books make frequent reference to the alternative use of 'ivory, bone, or wooden hooks' and 'steel needles in a handle', as appropriate to the stitch being made. Taken with the synonymous labeling of shepherd's- and single crochet, and the similar equivalence of French- and double crochet, there is a strong suggestion that crochet is rooted both in tambour embroidery and shepherd's knitting, leading to thread and yarn crochet respectively; a distinction that is still made. The locus of the fusion of all these elements\u2014the \"invention\" noted above\u2014has yet to be determined, as does the origin of shepherd's knitting.\nShepherd's hooks are still being made for local slip-stitch crochet traditions. The form in the accompanying photograph is typical for contemporary production. A longer continuously tapering design intermediate between it and the 19th-century tapered hook was also in earlier production, commonly being made from the handles of forks and spoons.\nIrish crochet.\nIn the 19th century, as Ireland was facing the Great Irish Famine (1845\u20131849), crochet lace work was introduced as a form of famine relief (the production of crocheted lace being an alternative way of making money for impoverished Irish workers). Men, women, children joined a co-operative in order to crochet and produce products to help with famine relief during the Great Irish Famine. Schools to teach crocheting were started. Teachers were trained and sent across Ireland to teach this craft. When the Irish immigrated to the Americas, they were able to take with them crocheting. Mademoiselle Riego de la Branchardiere is generally credited with the invention of Irish Crochet, publishing the first book of patterns in 1846. Irish lace became popular in Europe and America, and was made in quantity until the first World War.\nModern practice and culture.\nFashions in crochet changed with the end of the Victorian era in the 1890s. Crocheted laces in the new Edwardian era, peaking between 1910 and 1920, became even more elaborate in texture and complicated stitching.\nThe strong Victorian colors disappeared, though, and new publications called for white or pale threads, except for fancy purses, which were often crocheted of brightly colored silk and elaborately beaded. After World War I, far fewer crochet patterns were published, and most of them were simplified versions of the early 20th-century patterns. After World War II, from the late 1940s until the early 1960s, there was a resurgence in interest in home crafts, particularly in the United States, with many new and imaginative crochet designs published for colorful doilies, potholders, and other home items, along with updates of earlier publications. These patterns called for thicker threads and yarns than in earlier patterns and included variegated colors. The craft remained primarily a homemaker's art until the late 1960s and early 1970s, when the new generation picked up on crochet and popularized granny squares, a motif worked in the round and incorporating bright colors.\nAlthough crochet underwent a subsequent decline in popularity, the early 21st century has seen a revival of interest in handcrafts and DIY, as well as improvement of the quality and varieties of yarn. As well as books and classes, there are YouTube tutorials and TikTok videos to help people who may need a clearer explanation to learn how to crochet.\nFilet crochet, Tunisian crochet, tapestry crochet, broomstick lace, hairpin lace, cro-hooking, and Irish crochet are all variants of the basic crochet method.\nCrochet has experienced a revival on the catwalk as well. Christopher Kane's Fall 2011 Ready-to-Wear collection makes intensive use of the granny square, one of the most basic of crochet motifs. Websites such as Etsy and Ravelry have made it easier for individual hobbyists to sell and distribute their patterns or projects across the internet.\nCreating crocheted items has become a way to make sustainable fashion. Fast fashion brands like Shein have created products that resemble crocheted items.\nMaterials.\nBasic materials required for crochet are hook, scissors (to cut yarn) and some type of material that will be crocheted, most commonly used are yarn or thread. Alternatively, some choose to crochet with their hands, especially for large yarns. Yarn, one of the most commonly used materials for crocheting, has varying weights which need to be taken into consideration when following patterns. The weight of the yarn can affect not only the look of the product but also the feeling. Acrylic can also be used when crocheting, as it is synthetic and an alternative for wool. Additional tools are convenient for making related accessories. Examples of such tools include cardboard cutouts, which can be used to make tassels, fringe, and many other items; a pom-pom circle, used to make pom-poms; a tape measure and a gauge measure, both used for measuring crocheted work and counting stitches; a row counter; and occasionally plastic rings, which are used for special projects. In recent years, yarn selections have moved beyond synthetic and plant and animal-based fibers to include bamboo, qiviut, hemp, and banana stalks, to name a few. Many advanced crocheters have also incorporated recycled materials into their work in an effort to \"go green\" and experiment with new textures by using items such as plastic bags, old t-shirts or sheets, VCR or Cassette tape, and ribbon.\nCrochet hook.\nThe crochet hook comes in many sizes and materials. Because sizing is categorized by the diameter of the hook's shaft, a crafter aims to create stitches of a certain size in order to reach a particular gauge specified in a given pattern. If gauge is not reached with one hook, another is used until the stitches made are the needed size. Crafters may have a preference for one type of hook material over another due to aesthetic appeal, yarn glide, or hand disorders such as arthritis, where bamboo or wood hooks are favored over metal for the perceived warmth and flexibility during use. Hook grips and ergonomic hook handles are also available to assist crafters.\nAluminum, bamboo, and plastic crochet hooks are available from 2.25 to 30 millimeters in size, or from B-1 to T/X in American sizing. Artisan-made hooks are often made of hand-turned woods, sometimes decorated with semi-precious stones or beads.\nSteel crochet hooks are sized in a reverse manner \u2013 the higher the number, the smaller the hook. They range in size from 0.9 to 2.7 millimeters, or from 14 to 00 in American sizing. These hooks are used for fine crochet work such as doilies and lace.\nCrochet hooks used for Tunisian crochet are elongated and have a stopper at the end of the handle, while double-ended crochet hooks have a hook on both ends of the handle. Tunisian crochet hooks are shaped without a fat thumb grip and thus can hold many loops on the hook at a time without stretching some to different heights than others (Solovan). There is also a double hooked tool called a Cro-hook. While this is not in itself a hook, it is a device used in conjunction with a crochet hook to produce stitches.\nYarn.\nYarn for crochet is usually sold as balls, or skeins (hanks), although it may also be wound on spools or cones. Skeins and balls are generally sold with a \"yarn band\", a label that describes the yarn's weight, length, dye lot, fiber content, washing instructions, suggested needle size, likely gauge, etc. It is a common practice to save the yarn band for future reference, especially if additional skeins must be purchased. Crocheters generally ensure that the yarn for a project comes from a single dye lot. The dye lot specifies a group of skeins that were dyed together and thus have precisely the same color; skeins from different dye lots, even if very similar in color, are usually slightly different and may produce a visible stripe when added onto existing work. If insufficient yarn of a single dye lot is bought to complete a project, additional skeins of the same dye lot can sometimes be obtained from other yarn stores or online.\nThe thickness or weight of the yarn is a significant factor in determining how many stitches and rows are required to cover a given area for a given stitch pattern. This is also termed the gauge. Thicker yarns generally require large-diameter crochet hooks, whereas thinner yarns may be crocheted with thick or thin hooks. Hence, thicker yarns generally require fewer stitches, and therefore less time, to work up a given project. The recommended gauge for a given ball of yarn can be found on the label that surrounds the skein when buying in stores. Patterns and motifs are coarser with thicker yarns and produce bold visual effects, whereas thinner yarns are best for refined or delicate pattern-work. Yarns are standardly grouped by thickness into six categories: superfine, fine, light, medium, bulky and superbulky. Quantitatively, thickness is measured by the number of wraps per inch (WPI). The related \"weight per unit length\" is usually measured in tex or denier.\nBefore use, hanks are wound into balls in which the yarn emerges from the center, making crocheting easier by preventing the yarn from becoming easily tangled. The winding process may be performed by hand or done with a ball winder and swift.\nA yarn's usefulness is judged by several factors, such as its \"loft\" (its ability to trap air), its \"resilience\" (elasticity under tension), its washability and colorfastness, its \"hand\" (its feel, particularly softness vs. scratchiness), its durability against abrasion, its resistance to pilling, its \"hairiness\" (fuzziness), its tendency to twist or untwist, its overall weight and drape, its blocking and felting qualities, its comfort (breathability, moisture absorption, wicking properties) and its appearance, which includes its color, sheen, smoothness and ornamental features. Other factors include allergenicity, speed of drying, resistance to chemicals, moths, and mildew, melting point and flammability, retention of static electricity, and the propensity to accept dyes. Desirable properties may vary for different projects, so there is no one \"best\" yarn.\nAlthough crochet may be done with ribbons, metal wire or more exotic filaments, most yarns are made by spinning fibers. In spinning, the fibers are twisted so that the yarn resists breaking under tension; the twisting may be done in either direction, resulting in a Z-twist or S-twist yarn. If the fibers are first aligned by combing them and the spinner uses a worsted type drafting method such as the short forward draw, the yarn is smoother and called a \"worsted\"; by contrast, if the fibers are carded but not combed and the spinner uses a woolen drafting method such as the long backward draw, the yarn is fuzzier and called \"woolen-spun\". The fibers making up a yarn may be continuous \"filament\" fibers such as silk and many synthetics, or they may be \"staples\" (fibers of an average length, typically a few inches); naturally filament fibers are sometimes cut up into staples before spinning. The strength of the spun yarn against breaking is determined by the amount of twist, the length of the fibers and the thickness of the yarn. In general, yarns become stronger with more twist (also called \"worst\"), longer fibers and thicker yarns (more fibers); for example, thinner yarns require more twist than do thicker yarns to resist breaking under tension. The thickness of the yarn may vary along its length; a \"slub\" is a much thicker section in which a mass of fibers is incorporated into the yarn.\nThe spun fibers are generally divided into animal fibers, plant and synthetic fibers. These fiber types are chemically different, corresponding to proteins, carbohydrates and synthetic polymers, respectively. Animal fibers include silk, but generally are long hairs of animals such as sheep (wool), goat (angora, or cashmere goat), rabbit (angora), llama, alpaca, dog, cat, camel, yak, and muskox (qiviut). Plants used for fibers include cotton, flax (for linen), bamboo, ramie, hemp, jute, nettle, raffia, yucca, coconut husk, banana trees, soy and corn. Rayon and acetate fibers are also produced from cellulose mainly derived from trees. Common synthetic fibers include acrylics, polyesters such as dacron and ingeo, nylon and other polyamides, and olefins such as polypropylene. Of these types, wool is generally favored for crochet, chiefly owing to its superior elasticity, warmth and (sometimes) felting; however, wool is generally less convenient to clean and some people are allergic to it. It is also common to blend different fibers in the yarn, e.g., 85% alpaca and 15% silk. Even within a type of fiber, there can be great variety in the length and thickness of the fibers; for example, Merino wool and Egyptian cotton are favored because they produce exceptionally long, thin (fine) fibers for their type.\nA single spun yarn may be crochet as is, or braided or plied with another. In plying, two or more yarns are spun together, almost always in the opposite sense from which they were spun individually; for example, two Z-twist yarns are usually plied with an S-twist. The opposing twist relieves some of the yarns' tendency to curl up and produces a thicker, \"balanced\" yarn. Plied yarns may themselves be plied together, producing \"cabled yarns\" or \"multi-stranded yarns\". Sometimes, the yarns being plied are fed at different rates, so that one yarn loops around the other, as in boucl\u00e9. The single yarns may be dyed separately before plying, or afterwards to give the yarn a uniform look.\nThe dyeing of yarns is a complex art. Yarns need not be dyed; or they may be dyed one color, or a great variety of colors. Dyeing may be done industrially, by hand or even hand-painted onto the yarn. A great variety of synthetic dyes have been developed since the synthesis of indigo dye in the mid-19th century; however, natural dyes are also possible, although they are generally less brilliant. The color-scheme of a yarn is sometimes called its colorway. Variegated yarns can produce interesting visual effects, such as diagonal stripes.\nProcess.\nCrocheted fabric is begun by placing a slip-knot loop on the hook (though other methods, such as a magic ring or simple folding over of the yarn may be used), pulling another loop through the first loop, and repeating this process to create a chain of a suitable length. The chain is either turned and worked in rows, or joined to the beginning of the row with a slip stitch and worked in rounds. Rounds can also be created by working many stitches into a single loop. Stitches are made by pulling one or more loops through each loop of the chain. At any one time at the end of a stitch, there is only one loop left on the hook. Tunisian crochet, however, draws all of the loops for an entire row onto a long hook before working them off one at a time. Like knitting, crochet can be worked either flat (back and forth in rows) or in the round (in spirals, such as when making tubular pieces). \nTypes of stitches.\nThere are six main types of basic stitches (the following description uses international crochet terminology with US variants noted in backets).\nWhile the horizontal distance covered by these basic stitches is the same, they differ in height and can be replaced with a length of ch when required, e.g. 1 tr = 3 ch.\nThe more advanced stitches are often combinations of these basic stitches, or are made by inserting the hook into the work in unusual locations. More advanced stitches include the \"shell stitch\", \"V stitch\", \"spike stitch\", \"Afghan stitch\", \"butterfly stitch\", \"popcorn stitch\", \"cluster stitch\", and \"crocodile stitch\".\nInternational crochet terms and notations.\nThere are two main notations of basic stitches, one used across Europe, Australia, India and other crocheting nations, the other in the US and Canada. (In America, international terminology is often erroneously called British or UK terminology.)\nCrochet is traditionally worked from a written pattern using standard abbreviations or from a diagram, thus enabling non-English speakers to use English-based patterns. To help counter confusion when reading patterns, a diagramming system using a standard international notation has come into use (illustration, left). In the United States, crochet terminology and sizing guidelines, as well as standards for yarn and hook labeling, are primarily regulated by the Craft Yarn Council.\nAnother terminological difference is known as \"tension\" (international) and \"gauge\" (US). Individual crocheters work yarn with a loose or a tight hold and, if unmeasured, these differences can lead to significant size changes in finished garments that have the same number of stitches. In order to control for this inconsistency, printed crochet instructions include a standard for the number of stitches across a standard swatch of fabric. An individual crocheter begins work by producing a test swatch and compensating for any discrepancy by changing to a smaller or larger hook.\nDifferences from and similarities to knitting.\nOne of the more obvious differences is that crochet uses one hook while much knitting uses two needles. In most crochet, the artisan usually has only one live stitch on the hook (with the exception being Tunisian crochet), while a knitter keeps an entire row of stitches active simultaneously. Dropped stitches, which can unravel a knitted fabric, rarely interfere with crochet work, due to a second structural difference between knitting and crochet. In knitting, each stitch is supported by the corresponding stitch in the row above and it supports the corresponding stitch in the row below, whereas crochet stitches are only supported by and support the stitches on either side of it. If a stitch in a finished crocheted item breaks, the stitches above and below remain intact, and because of the complex looping of each stitch, the stitches on either side are unlikely to come loose unless heavily stressed.\nRound or cylindrical patterns are simple to produce with a regular crochet hook, but cylindrical knitting requires either a set of circular needles or three to five special double-ended needles. Many crocheted items are composed of individual motifs which are then joined, either by sewing or crocheting, whereas knitting is usually composed of one fabric, such as entrelac.\nFreeform crochet is a technique that can create interesting shapes in three dimensions because new stitches can be made independently of previous stitches almost anywhere in the crocheted piece. It is generally accomplished by building shapes or structural elements onto existing crocheted fabric at any place the crafter desires.\nKnitting can be accomplished by machine, while many crochet stitches can only be crafted by hand. The height of knitted and crocheted stitches is also different: a single crochet stitch is twice the height of a knit stitch in the same yarn size and comparable diameter tools, and a double crochet stitch is about four times the height of a knit stitch.\nWhile most crochet is made with a hook, there is also a method of crocheting with a knitting loom. This is called \"loomchet\". Slip stitch crochet is very similar to knitting. Each stitch in slip stitch crochet is formed the same way as a knit or purl stitch which is then bound off. A person working in slip stitch crochet can follow a knitted pattern with knits, purls, and cables, and get a similar result.\nIt is a common perception that crochet produces a thicker fabric than knitting, tends to have less \"give\" than knitted fabric, and uses approximately a third more yarn for a comparable project than knitted items. Although this is true when comparing a single crochet swatch with a stockinette swatch, both made with the same size yarn and needle/hook, it is not necessarily true for crochet in general. Most crochet uses far less than 1/3 more yarn than knitting for comparable pieces, and a crocheter can get similar feel and drape to knitting by using a larger hook or thinner yarn. Tunisian crochet and slip stitch crochet can in some cases use less yarn than knitting for comparable pieces. According to sources claiming to have tested the 1/3 more yarn assertion, a single crochet stitch (sc) uses approximately the same amount of yarn as knit garter stitch, but more yarn than stockinette stitch. Any stitch using yarnovers uses less yarn than single crochet to produce the same amount of fabric. Cluster stitches, which are in fact multiple stitches worked together, will use the most length.\nStandard crochet stitches like sc and dc also produce a thicker fabric, more like knit garter stitch. This is part of why they use more yarn. Slip stitch can produce a fabric much like stockinette that is thinner and therefore uses less yarn.\nAny yarn can be either knitted or crocheted, provided needles or hooks of the correct size are used, but the cord's properties should be taken into account. For example, lofty, thick woolen yarns tend to function better when knitted, which does not crush their airy structure, while thin and tightly spun yarn helps to achieve the firm texture required for Amigurumi crochet.\nCharity and activism.\nIt has been very common for people and groups to crochet clothing and other garments and then donate them to soldiers during war. People have also crocheted clothing and then donated it to hospitals, for sick patients and also for newborn babies. Sometimes groups will crochet for a specific charity purpose, such as crocheting for homeless shelters, nursing homes, etc.\nIt is becoming increasingly popular to crochet hats (commonly referred to as \"chemo caps\") and donate them to cancer treatment centers, for those undergoing chemotherapy and therefore losing hair. During October pink hats and scarves are made and proceeds are donated to breast cancer funds. Organizations dedicated to using crochet as a way to help others include Knots of Love, Crochet for Cancer, and Soldiers' Angels. These organizations offer warm useful items for people in need.\nIn 2020, people around the world banded together to help save the wildlife affected by the Australian bushfires by crocheting kangaroo pouches, koala mittens and wildlife nests. This was an international effort to help during the particularly bad bushfire season which devastated local ecological systems.\nA group started in 2005 to create crochet versions of coral reefs grew by 2022 to over 20,000 contributors in what became the Crochet Coral Reef Project. To promote awareness of the effects of global warming, their creations have been displayed in galleries and museums by an estimated 2 million people. Many creations apply hyperbolic (curved) geometric shapes\u2014distinguished from Euclidean (flat) geometry\u2014to emulate natural structures. Extending hyperbolic crochet for activism and education with color, a group of South African crafters created \"The Abundance Crochet Coral Reef\", an eco-art installation in Cape Town's Two Oceans Aquarium, to juxtapose hyperbolic shapes crocheted in variations of white on one side of a display with fiber coral shapes crocheted in various colors to illustrate coral bleaching due to oceanic warming and climate change. \nFeminist scholar-activists have argued for crochet as an embodied method of inquiry aimed at uncovering entangled, relational, and situated ways being and knowing inclusive of the more-than-human co-creation of worlds. In \"Staying with the Trouble\", Donna Haraway argues for the methodological use of crochet to model ecological and mathematical phenomena as \"a kind of lure to an affective cognitive ecology stitched in fiber arts\" that works \"not by mimicry, but by open-ended, exploratory process.\"\nYarn bombing.\nIn recent years, a practice called yarn bombing, or the use of knitted or crocheted cloth to modify and beautify one's (usually outdoor) surroundings, emerged in the US and spread worldwide. Yarn bombers sometimes target existing pieces of graffiti for beautification. In 2010, an entity dubbed \"the Midnight Knitter\" hit West Cape May. Residents awoke to find knit cozies hugging tree branches and sign poles. In September 2015, Grace Brett was named \"The World's Oldest Yarn Bomber\". She is part of a group of yarn graffiti-artists called the Souter Stormers, who beautify their local town in Scotland.\nMathematics and hyperbolic crochet.\nCrochet has been used to illustrate shapes in hyperbolic space that are difficult to reproduce using other media or are difficult to understand when viewed two-dimensionally. Mathematician Daina Taimi\u0146a first used crochet in 1997 to create strong, durable models of hyperbolic space after finding paper models were delicate and hard to create. These models enable one to turn, fold, and otherwise manipulate space to more fully grasp ideas such as how a line can appear curved in hyperbolic space yet actually be straight. Her work received an exhibition by the Institute For Figuring.\nExamples in nature of organisms that show hyperbolic structures include lettuces, sea slugs, flatworms and coral. Margaret Wertheim and Christine Wertheim of the Institute For Figuring created a traveling art installation of a coral reef using Taimina's method. Local artists are encouraged to create their own \"satellite reefs\" to be included alongside the original display. As hyperbolic and mathematics-based crochet has become more popular, there have been several events highlighting work from various fiber artists. Two shows were \"Sant Ocean Hall\" at the Smithsonian in Washington, D.C., and \"Sticks, Hooks, and the Mobius: Knit and Crochet Go Cerebral\" at Lafayette College in Pennsylvania.\nArchitecture.\nIn \"Style in the technical arts\", Gottfried Semper looks at the textile with great promise and historical precedent. In Section 53, he writes of the \"loop stitch, or Noeud Coulant: a knot that, if untied, causes the whole system to unravel.\" In the same section, Semper confesses his ignorance of the subject of crochet but believes strongly that it is a technique of great value as a textile technique and possibly something more.\nThere are a small number of architects currently interested in the subject of crochet as it relates to architecture. The following publications, explorations and thesis projects can be used as a resource to see how crochet is being used within the capacity of architecture."}
{"id": "7425", "revid": "41724601", "url": "https://en.wikipedia.org/wiki?curid=7425", "title": "Electromagnetic coil", "text": "An electromagnetic coil is an electrical conductor such as a wire in the shape of a coil (spiral or helix). Electromagnetic coils are used in electrical engineering, in applications where electric currents interact with magnetic fields, in devices such as electric motors, generators, inductors, electromagnets, transformers, sensor coils such as in medical MRI imaging machines. Either an electric current is passed through the wire of the coil to generate a magnetic field, or conversely, an external \"time-varying\" magnetic field through the interior of the coil generates an EMF (voltage) in the conductor.\nA current through any conductor creates a circular magnetic field around the conductor due to Ampere's law. The advantage of using the coil shape is that it increases the strength of the magnetic field produced by a given current. The magnetic fields generated by the separate turns of wire all pass through the center of the coil and add (superpose) to produce a strong field there. The greater the number of turns of wire, the stronger the field produced. Conversely, a \"changing\" external magnetic flux induces a voltage in a conductor such as a wire, due to Faraday's law of induction. The induced voltage can be increased by winding the wire into a coil because the field lines intersect the circuit multiple times.\nThe direction of the magnetic field produced by a coil can be determined by the right hand grip rule. If the fingers of the right hand are wrapped around the magnetic core of a coil in the direction of conventional current through the wire, the thumb will point in the direction the magnetic field lines pass through the coil. The end of a magnetic core from which the field lines emerge is defined to be the North pole.\nThere are many different types of coils used in electric and electronic equipment.\nWindings and taps.\nThe wire or conductor which constitutes the coil is called the winding. The hole in the center of the coil is called the core area or \"magnetic axis\". Each loop of wire is called a turn. In windings in which the turns touch, the wire must be insulated with a coating of nonconductive insulation such as plastic or enamel to prevent the current from passing between the wire turns. The winding is often wrapped around a \"coil form\" made of plastic or other material to hold it in place. The ends of the wire are brought out and attached to an external circuit. Windings may have additional electrical connections along their length; these are called taps. A winding that has a single tap in the center of its length is called center-tapped.\nCoils can have more than one winding, insulated electrically from each other. When there are two or more windings around a common magnetic axis, the windings are said to be inductively coupled or magnetically coupled. A time-varying current through one winding will create a time-varying magnetic field that passes through the other winding, which will induce a time-varying voltage in the other windings. This is called a transformer. The winding to which current is applied, which creates the magnetic field, is called the \"primary winding\". The other windings are called \"secondary windings\".\nMagnetic core.\nMany electromagnetic coils have a magnetic core, a piece of ferromagnetic material like iron in the center to increase the magnetic field. The current through the coil magnetizes the iron, and the field of the magnetized material adds to the field produced by the wire. This is called a ferromagnetic-core or iron-core coil. A ferromagnetic core can increase the magnetic field and inductance of a coil by hundreds or thousands of times over what it would be without the core. A ferrite core coil is a variety of coil with a core made of ferrite, a ferrimagnetic ceramic compound. Ferrite coils have lower core losses at high frequencies.\nA coil without a ferromagnetic core is called an air-core coil. This includes coils wound on plastic or other nonmagnetic forms, as well as coils which actually have empty air space inside their windings.\nTypes of coils.\nCoils can be classified by the frequency of the current they are designed to operate with:\nCoils can be classified by their function:\nElectromagnets.\nElectromagnets are coils that generate a magnetic field for some external use, often to exert a mechanical force on something. or remove existing background fields. A few specific types:\nInductors.\nInductors or reactors are coils which generate a magnetic field which interacts with the coil itself, to induce a back EMF which opposes changes in current through the coil. Inductors are used as circuit elements in electrical circuits, to temporarily store energy or resist changes in current. A few types:\nTransformers.\nA transformer is a device with two or more magnetically coupled windings (or sections of a single winding). A time varying current in one coil (called the primary winding) generates a magnetic field which induces a voltage in the other coil (called the secondary winding). A few types:\nElectric machines.\nElectric machines such as motors and generators have one or more windings which interact with moving magnetic fields to convert electrical energy to mechanical energy. Often a machine will have one winding through which passes most of the power of the machine (the \"armature\"), and a second winding which provides the magnetic field of the rotating element ( the \"field winding\") which may be connected by brushes or slip rings to an external source of electric current. In an induction motor, the \"field\" winding of the rotor is energized by the slow relative motion between the rotating winding and the rotating magnetic field produced by the stator winding, which induces the necessary exciting current in the rotor.\nTransducer coils.\nThese are coils used to translate time-varying magnetic fields to electric signals, and vice versa. A few types:\nThere are also types of coil which don't fit into these categories."}
{"id": "7426", "revid": "45733435", "url": "https://en.wikipedia.org/wiki?curid=7426", "title": "Charles I of England", "text": "Charles I (19 November 1600 \u2013 30 January 1649) was King of England, Scotland, and Ireland from 27 March 1625 until his execution in 1649.\nCharles was born into the House of Stuart as the second son of King James VI of Scotland, but after his father inherited the English throne in 1603, he moved to England, where he spent much of the rest of his life. He became heir apparent to the kingdoms of England, Scotland, and Ireland in 1612 upon the death of his elder brother, Henry Frederick, Prince of Wales. An unsuccessful and unpopular attempt to marry him to Infanta Maria Anna of Spain culminated in an eight-month visit to Spain in 1623 that demonstrated the futility of the marriage negotiation. Two years later, shortly after his accession, he married Henrietta Maria of France.\nAfter his succession in 1625, Charles quarrelled with the English Parliament, which sought to curb his royal prerogative. He believed in the divine right of kings, and was determined to govern according to his own conscience. Many of his subjects opposed his policies, in particular the levying of taxes without Parliamentary consent, and perceived his actions as those of a tyrannical absolute monarch. His religious policies, coupled with his marriage to a Roman Catholic, generated antipathy and mistrust from Reformed religious groups such as the English Puritans and Scottish Covenanters, who thought his views too Catholic. He supported high church Anglican ecclesiastics and failed to aid continental Protestant forces successfully during the Thirty Years' War. His attempts to force the Church of Scotland to adopt high Anglican practices led to the Bishops' Wars, strengthened the position of the English and Scottish parliaments, and helped precipitate his own downfall.\nFrom 1642, Charles fought the armies of the English and Scottish parliaments in the English Civil War. After his defeat in 1645 at the hands of the Parliamentarian New Model Army, he fled north from his base at Oxford. Charles surrendered to a Scottish force and after lengthy negotiations between the English and Scottish parliaments he was handed over to the Long Parliament in London. Charles refused to accept his captors' demands for a constitutional monarchy, and temporarily escaped captivity in November 1647. Re-imprisoned on the Isle of Wight, he forged an alliance with Scotland, but by the end of 1648, the New Model Army had consolidated its control over England. Charles was tried, convicted, and executed for high treason in January 1649. The monarchy was abolished and the Commonwealth of England was established as a republic. The monarchy was restored in 1660, with Charles's son Charles II as king.\nEarly life.\nThe second son of King James VI of Scotland and Anne of Denmark, Charles was born in Dunfermline Palace, Fife, on 19 November 1600. At a Protestant ceremony in the Chapel Royal of Holyrood Palace in Edinburgh on 23 December 1600, he was baptised by David Lindsay, Bishop of Ross, and created Duke of Albany, the traditional title of the second son of the king of Scotland, with the subsidiary titles of Marquess of Ormond, Earl of Ross and Lord Ardmannoch.\nJames VI was the first cousin twice removed of Queen Elizabeth I of England, and when she died childless in March 1603, he became king of England as James I. Charles was a weak and sickly infant, and while his parents and older siblings left for England in April and early June that year, due to his fragile health, he remained in Scotland with his father's friend Lord Fyvie appointed as his guardian.\nBy 1604, when Charles was three-and-a-half, he was able to walk the length of the great hall at Dunfermline Palace without assistance, and it was decided that he was strong enough to journey to England to be reunited with his family. In mid-July 1604, he left Dunfermline for England, where he was to spend most of the rest of his life. In England, Charles was placed under the charge of Elizabeth, Lady Carey, the wife of courtier Sir Robert Carey, who put him in boots made of Spanish leather and brass to help strengthen his weak ankles. His speech development was also slow, and he had a stammer for the rest of his life.\nIn January 1605, Charles was created Duke of York, as is customary in the case of the English sovereign's second son, and made a Knight of the Bath. Thomas Murray, a presbyterian Scot, was appointed as a tutor. Charles learnt the usual subjects of classics, languages, mathematics and religion. In 1611, he was made a Knight of the Garter.\nEventually, Charles apparently conquered his physical infirmity, which might have been caused by rickets. He became an adept horseman and marksman, and took up fencing. Even so, his public profile remained low in contrast to that of his physically stronger and taller elder brother, Henry Frederick, Prince of Wales, whom Charles adored and attempted to emulate. But in early November 1612, Henry died at the age of 18 of what is suspected to have been typhoid (or possibly porphyria). Charles, who turned 12 two weeks later, became heir apparent. As the eldest surviving son of the sovereign, he automatically gained several titles, including Duke of Cornwall and Duke of Rothesay. In November 1616, he was created Prince of Wales and Earl of Chester.\nHeir apparent.\nIn 1613, Charles's sister Elizabeth married Frederick V, Elector Palatine, and moved to Heidelberg. In 1617, the Habsburg Archduke Ferdinand of Austria, a Catholic, was elected king of Bohemia. The next year, the Bohemians rebelled, defenestrating the Catholic governors. In August 1619, the Bohemian Diet chose Frederick, who led the Protestant Union, as their monarch, while Ferdinand was elected Holy Roman Emperor in the imperial election. Frederick's acceptance of the Bohemian crown in defiance of the Emperor marked the beginning of the turmoil that would develop into the Thirty Years' War. The conflict, originally confined to Bohemia, spiralled into a wider European war, which the English Parliament and public quickly grew to see as a polarised continental struggle between Catholics and Protestants. In 1620, King Frederick was defeated at the Battle of White Mountain near Prague and his hereditary lands in the Electoral Palatinate were invaded by a Habsburg force from the Spanish Netherlands. James, however, had been seeking marriage between Prince Charles and Ferdinand's niece, Infanta Maria Anna of Spain, and began to see the Spanish match as a possible diplomatic means of achieving peace in Europe.\nUnfortunately for James, negotiation with Spain proved unpopular with both the public and James's court. The English Parliament was actively hostile towards Spain and Catholicism, and thus, when called by James in 1621, the members hoped for an enforcement of recusancy laws, a naval campaign against Spain, and a Protestant marriage for the Prince of Wales. James's Lord Chancellor, Francis Bacon, was impeached before the House of Lords for corruption. The impeachment was the first since 1459 without the King's official sanction in the form of a bill of attainder. The incident set an important precedent as the process of impeachment would later be used against Charles and his supporters George Villiers, 1st Duke of Buckingham, Archbishop William Laud, and Thomas Wentworth, 1st Earl of Strafford. James insisted that the House of Commons be concerned exclusively with domestic affairs, while the members protested that they had the privilege of free speech within the Commons' walls, demanding war with Spain and a Protestant princess of Wales. Like his father, Charles considered discussion of his marriage in the Commons impertinent and an infringement of his father's royal prerogative. In January 1622, James dissolved Parliament, angry at what he perceived as the members' impudence and intransigence.\nCharles and Buckingham, James's favourite and a man who had great influence over the prince, travelled incognito to Spain in February 1623 to try to reach agreement on the long-pending Spanish match. The trip was an embarrassing failure. The \"infanta\" thought Charles little more than an infidel, and the Spanish at first demanded that he convert to Catholicism as a condition of the match. They insisted on toleration of Catholics in England and the repeal of the English penal laws, which Charles knew Parliament would not agree to, and that the \"infanta\" remain in Spain for a year after any wedding to ensure that England complied with all the treaty's terms. A personal quarrel erupted between Buckingham and Gaspar de Guzm\u00e1n, Count-Duke of Olivares, the Spanish chief minister, and so Charles conducted the ultimately futile negotiations personally. When he returned to London in October, without a bride and to a rapturous and relieved public welcome, he and Buckingham pushed the reluctant James to declare war on Spain.\nWith the encouragement of his Protestant advisers, James summoned the English Parliament in 1624 to request subsidies for a war. Charles and Buckingham supported the impeachment of the Lord Treasurer, Lionel Cranfield, 1st Earl of Middlesex, who opposed war on grounds of cost and quickly fell in much the same manner Bacon had. James told Buckingham he was a fool, and presciently warned Charles that he would live to regret the revival of impeachment as a parliamentary tool. An underfunded makeshift army under Ernst von Mansfeld set off to recover the Palatinate, but it was so poorly provisioned that it never advanced beyond the Dutch coast.\nBy 1624, the increasingly ill James was finding it difficult to control Parliament. By the time of his death in March 1625, Charles and Buckingham had already assumed \"de facto\" control of the kingdom.\nEarly reign.\nWith the failure of the Spanish match, Charles and Buckingham turned their attention to France. On 1 May 1625 Charles was married by proxy to the 15-year-old French princess Henrietta Maria in front of the doors of Notre Dame de Paris. He had seen her in Paris while en route to Spain. They met in person on 13 June 1625 in Canterbury. Charles delayed the opening of his first Parliament until after the marriage was consummated, to forestall any opposition. Many members of the Commons opposed his marriage to a Catholic, fearing that he would lift restrictions on Catholic recusants and undermine the official establishment of the reformed Church of England. Charles told Parliament that he would not relax religious restrictions, but promised to do exactly that in a secret marriage treaty with his brother-in-law Louis XIII of France. Moreover, the treaty loaned to the French seven English naval ships that were used to suppress the Protestant Huguenots at La Rochelle in September 1625. Charles was crowned on 2 February 1626 at Westminster Abbey, but without his wife at his side, because she refused to participate in a Protestant religious ceremony.\nDistrust of Charles's religious policies increased with his support of a controversial anti-Calvinist ecclesiastic, Richard Montagu, who was in disrepute among the Puritans. In his pamphlet \"A New Gag for an Old Goose\" (1624), a reply to the Catholic pamphlet \"A New Gag for the New Gospel\", Montagu argued against Calvinist predestination, the doctrine that God preordained salvation and damnation. Anti-Calvinistsknown as Arminiansbelieved that people could accept or reject salvation by exercising free will. Arminian divines had been one of the few sources of support for Charles's proposed Spanish marriage. With King James's support, Montagu produced another pamphlet, \"Appello Caesarem\", published in 1625 shortly after James's death and Charles's accession. To protect Montagu from the stricture of Puritan members of Parliament, Charles made him a royal chaplain, heightening many Puritans' suspicions that Charles favoured Arminianism as a clandestine attempt to aid Catholicism's resurgence.\nRather than direct involvement in the European land war, the English Parliament preferred a relatively inexpensive naval attack on Spanish colonies in the New World, hoping for the capture of the Spanish treasure fleets. Parliament voted to grant a subsidy of \u00a3140,000, an insufficient sum for Charles's war plans. Moreover, the House of Commons limited its authorisation for royal collection of tonnage and poundage (two varieties of customs duties) to a year, although previous sovereigns since Henry VI had been granted the right for life. In this manner, Parliament could delay approval of the rates until after a full-scale review of customs revenue. The bill made no progress in the House of Lords past its first reading. Although no act of Parliament for the levy of tonnage and poundage was obtained, Charles continued to collect the duties.\nA poorly conceived and executed naval expedition against Spain under Buckingham's leadership went badly, and the House of Commons began proceedings for the impeachment of the Duke. In May 1626, Charles nominated Buckingham as Chancellor of Cambridge University in a show of support, and had two members who had spoken against BuckinghamDudley Digges and Sir John Eliotarrested at the door of the House. The Commons was outraged by the imprisonment of two of their members, and after about a week in custody, both were released. On 12 June 1626, the Commons launched a direct protestation attacking Buckingham, stating, \"We protest before your Majesty and the whole world that until this great person be removed from intermeddling with the great affairs of state, we are out of hope of any good success; and do fear that any money we shall or can give will, through his misemployment, be turned rather to the hurt and prejudice of this your kingdom than otherwise, as by lamentable experience we have found those large supplies formerly and lately given.\" Despite the protests, Charles refused to dismiss his friend, dismissing Parliament instead.\nMeanwhile, domestic quarrels between Charles and Henrietta Maria were souring the early years of their marriage. Disputes over her jointure, appointments to her household, and the practice of her religion culminated in the King expelling the vast majority of her French attendants in August 1626. Despite Charles's agreement to provide the French with English ships as a condition of marrying Henrietta Maria, in 1627 he launched an attack on the French coast to defend the Huguenots at La Rochelle. The action, led by Buckingham, was ultimately unsuccessful. Buckingham's failure to protect the Huguenotsand his retreat from Saint-Martin-de-R\u00e9spurred Louis XIII's siege of La Rochelle and furthered the English Parliament's and people's detestation of the Duke.\nCharles provoked further unrest by trying to raise money for the war through a \"forced loan\": a tax levied without parliamentary consent. In November 1627, the test case in the King's Bench, the \"Five Knights' Case\", found that the King had a prerogative right to imprison without trial those who refused to pay the forced loan. Summoned again in March 1628, Parliament adopted a Petition of Right on 26 May, calling upon Charles to acknowledge that he could not levy taxes without Parliament's consent, impose martial law on civilians, imprison them without due process, or quarter troops in their homes. Charles assented to the petition on 7 June, but by the end of the month he had prorogued Parliament and reasserted his right to collect customs duties without authorisation from Parliament.\nOn 23 August 1628, Buckingham was assassinated. Charles was deeply distressed. According to Edward Hyde, 1st Earl of Clarendon, he \"threw himself upon his bed, lamenting with much passion and with abundance of tears\". He remained grieving in his room for two days. In contrast, the public rejoiced at Buckingham's death, accentuating the gulf between the court and the nation and between the Crown and the Commons. Buckingham's death effectively ended the war with Spain and eliminated his leadership as an issue, but it did not end the conflicts between Charles and Parliament. It did, however, coincide with an improvement in Charles's relationship with his wife, and by November 1628 their old quarrels were at an end. Perhaps Charles's emotional ties were transferred from Buckingham to Henrietta Maria. She became pregnant for the first time, and the bond between them grew stronger. Together, they embodied an image of virtue and family life, and their court became a model of formality and morality.\nPersonal rule.\nParliament prorogued.\nIn January 1629, Charles opened the second session of the English Parliament, which had been prorogued in June 1628, with a moderate speech on the tonnage and poundage issue. Members of the House of Commons began to voice opposition to Charles's policies in light of the case of John Rolle, a Member of Parliament whose goods had been confiscated for failing to pay tonnage and poundage. Many MPs viewed the imposition of the tax as a breach of the Petition of Right. When Charles ordered a parliamentary adjournment on 2 March, members held the Speaker, Sir John Finch, down in his chair so that the session could be prolonged long enough for resolutions against Catholicism, Arminianism, and tonnage and poundage to be read out and acclaimed by the chamber. The provocation was too much for Charles, who dissolved Parliament and had nine parliamentary leaders, including Sir John Eliot, imprisoned over the matter, thereby turning the men into martyrs and giving popular cause to their protest.\nPersonal rule necessitated peace. Without the means in the foreseeable future to raise funds from Parliament for a European war, or Buckingham's help, Charles made peace with France and Spain. The next 11 years, during which Charles ruled England without a Parliament, are known as the Personal Rule or the \"eleven years' tyranny\". Ruling without Parliament was not exceptional, and was supported by precedent. But only Parliament could legally raise taxes, and without it Charles's capacity to acquire funds for his treasury was limited to his customary rights and prerogatives.\nFinances.\nA large fiscal deficit had arisen during the reigns of Elizabeth I and James I. Notwithstanding Buckingham's short-lived campaigns against both Spain and France, Charles had little financial capacity to wage wars overseas. Throughout his reign, he was obliged to rely primarily on volunteer forces for defence and on diplomatic efforts to support his sister Elizabeth and his foreign policy objective for the restoration of the Palatinate. England was still the least taxed country in Europe, with no official excise and no regular direct taxation. To raise revenue without reconvening Parliament, Charles resurrected an all-but-forgotten law called the \"Distraint of Knighthood\", in abeyance for over a century, which required any man who earned \u00a340 or more from land each year to present himself at the king's coronation to be knighted. Relying on this old statute, Charles fined those who had failed to attend his coronation in 1626.\nThe chief tax Charles imposed was a feudal levy known as ship money, which proved even more unpopular, and lucrative, than tonnage and poundage before it. Previously, collection of ship money had been authorised only during wars, and only on coastal regions. But Charles argued that there was no legal bar to collecting the tax for defence during peacetime and throughout the whole of the kingdom. Ship money, paid directly to the Treasury of the Navy, provided between \u00a3150,000 to \u00a3200,000 annually between 1634 and 1638, after which yields declined. Opposition to ship money steadily grew, but England's 12 common law judges ruled the tax within the King's prerogative, though some of them had reservations. The prosecution of John Hampden for non-payment in 1637\u201338 provided a platform for popular protest, and the judges found against Hampden only by the narrow margin of 7\u20135.\nCharles also derived money by granting monopolies, despite a statute forbidding such action, which, though inefficient, raised an estimated \u00a3100,000 a year in the late 1630s. One such monopoly was for soap, pejoratively referred to as \"popish soap\" because some of its backers were Catholics. Charles also raised funds from the Scottish nobility, at the price of considerable acrimony, by the Act of Revocation (1625), whereby all gifts of royal or church land made to the nobility since 1540 were revoked, with continued ownership being subject to an annual rent. In addition, the boundaries of the royal forests in England were restored to their ancient limits as part of a scheme to maximise income by exploiting the land and fining land users within the reasserted boundaries for encroachment. The programme's focus was disafforestation and sale of forest lands for conversion to pasture and arable farming, or in the case of the Forest of Dean, development for the iron industry. Disafforestation frequently caused riots and disturbances, including those known as the Western Rising.\nAgainst the background of this unrest, Charles faced bankruptcy in mid-1640. The City of London, preoccupied with its own grievances, refused to make any loans to him, as did foreign powers. In this extremity, in July Charles seized silver bullion worth \u00a3130,000 held in trust at the mint in the Tower of London, promising its later return at 8% interest to its owners. In August, after the East India Company refused to grant a loan, Lord Cottington seized the company's stock of pepper and spices and sold it for \u00a360,000 (far below its market value), promising to refund the money with interest later.\nReligious conflicts.\nThroughout Charles's reign, the English Reformation was in the forefront of political debate. Arminian theology emphasised clerical authority and the individual's ability to reject or accept salvation, which opponents viewed as heretical and a potential vehicle for the reintroduction of Catholicism. Puritan reformers considered Charles too sympathetic to Arminianism, and opposed his desire to move the Church of England in a more traditional and sacramental direction. In addition, his Protestant subjects followed the European war closely and grew increasingly dismayed by Charles's diplomacy with Spain and his failure to support the Protestant cause abroad effectively.\nIn 1633, Charles appointed William Laud Archbishop of Canterbury. They initiated a series of reforms to promote religious uniformity by restricting non-conformist preachers, insisting the liturgy be celebrated as prescribed by the \"Book of Common Prayer\", organising the internal architecture of English churches to emphasise the sacrament of the altar, and reissuing King James's Declaration of Sports, which permitted secular activities on the sabbath. The Feoffees for Impropriations, an organisation that bought benefices and advowsons so that Puritans could be appointed to them, was dissolved. Laud prosecuted those who opposed his reforms in the Court of High Commission and the Star Chamber, the two most powerful courts in the land. The courts became feared for their censorship of opposing religious views and unpopular among the propertied classes for inflicting degrading punishments on gentlemen. For example, in 1637 William Prynne, Henry Burton and John Bastwick were pilloried, whipped and mutilated by cropping and imprisoned indefinitely for publishing anti-episcopal pamphlets.\nWhen Charles attempted to impose his religious policies in Scotland he faced numerous difficulties. Although born in Scotland, Charles had become estranged from it; his first visit since early childhood was for his Scottish coronation in 1633. To the dismay of the Scots, who had removed many traditional rituals from their liturgical practice, Charles insisted that the coronation be conducted using the Anglican rite. In 1637, he ordered the use of a new prayer book in Scotland that was almost identical to the English \"Book of Common Prayer\", without consulting either the Scottish Parliament or the Kirk. Although it had been written, under Charles's direction, by Scottish bishops, many Scots resisted it, seeing it as a vehicle to introduce Anglicanism to Scotland. On 23 July, riots erupted in Edinburgh upon the first Sunday of the prayer book's usage, and unrest spread throughout the Kirk. The public began to mobilise around a reaffirmation of the National Covenant, whose signatories pledged to uphold the reformed religion of Scotland and reject any innovations not authorised by Kirk and Parliament. When the General Assembly of the Church of Scotland met in November 1638, it condemned the new prayer book, abolished episcopal church government, and adopted presbyterian government by elders and deacons.\nBishops' Wars.\nCharles perceived the unrest in Scotland as a rebellion against his authority, precipitating the First Bishops' War in 1639. He did not seek subsidies from the English Parliament to wage war, instead raising an army without parliamentary aid and marching to Berwick-upon-Tweed, on the Scottish border. The army did not engage the Covenanters, as the King feared the defeat of his forces, whom he believed to be significantly outnumbered by the Scots. In the Treaty of Berwick, Charles regained custody of his Scottish fortresses and secured the dissolution of the Covenanters' interim government, albeit at the decisive concession that both the Scottish Parliament and General Assembly of the Scottish Church were called.\nThe military failure in the First Bishops' War caused a financial and diplomatic crisis for Charles that deepened when his efforts to raise funds from Spain while simultaneously continuing his support for his Palatine relatives led to the public humiliation of the Battle of the Downs, where the Dutch destroyed a Spanish bullion fleet off the coast of Kent in sight of the impotent English navy.\nCharles continued peace negotiations with the Scots in a bid to gain time before launching a new military campaign. Because of his financial weakness, he was forced to call Parliament into session in an attempt to raise funds for such a venture. Both the English and Irish parliaments were summoned in the early months of 1640. In March 1640, the Irish Parliament duly voted in a subsidy of \u00a3180,000 with the promise to raise an army 9,000 strong by the end of May. But in the English general election in March, court candidates fared badly, and Charles's dealings with the English Parliament in April quickly reached stalemate. The earls of Northumberland and Strafford attempted to broker a compromise whereby the King would agree to forfeit ship money in exchange for \u00a3650,000 (although the cost of the coming war was estimated at \u00a31\u00a0million). Nevertheless, this alone was insufficient to produce consensus in the Commons. The Parliamentarians' calls for further reforms were ignored by Charles, who still retained the support of the House of Lords. Despite the protests of the Earl of Northumberland, the Short Parliament (as it came to be known) was dissolved in May 1640, less than a month after it assembled.\nBy this stage the Earl of Strafford, Lord Deputy of Ireland since 1632, had emerged as Charles's right-hand man and, together with Archbishop Laud, pursued a policy that he termed \"Thorough\", which aimed to make central royal authority more efficient and effective at the expense of local or anti-government interests. Although originally a critic of the King, Strafford defected to royal service in 1628, in part due to the Duke of Buckingham's persuasion, and had since emerged, alongside Laud, as the most influential of Charles's ministers.\nBolstered by the failure of the English Short Parliament, the Scottish Parliament declared itself capable of governing without the King's consent, and in August 1640 the Covenanter army moved into the English county of Northumberland. Following the illness of Lord Northumberland, who was the King's commander-in-chief, Charles and Strafford went north to command the English forces, despite Strafford being ill himself with a combination of gout and dysentery. The Scottish soldiery, many of whom were veterans of the Thirty Years' War, had far greater morale and training than their English counterparts. They met virtually no resistance until reaching Newcastle upon Tyne, where they defeated the English forces at the Battle of Newburn and occupied the city, as well as the neighbouring County Palatine of Durham.\nAs demands for a parliament grew, Charles took the unusual step of summoning a great council of peers. By the time it met, on 24 September at York, Charles had resolved to follow the almost universal advice to call a parliament. After informing the peers that a parliament would convene in November, he asked them to consider how he could acquire funds to maintain his army against the Scots in the meantime. They recommended making peace. A cessation of arms was negotiated in the humiliating Treaty of Ripon, signed in October 1640. This stated that the Scots would continue to occupy Northumberland and Durham and be paid \u00a3850 per day indefinitely until a final settlement was negotiated and the English Parliament recalled, which would be required to raise sufficient funds to pay the Scottish forces. Consequently, Charles summoned what later became known as the Long Parliament. Once again, his supporters fared badly at the polls. Of the 493 members of the Commons returned in November, over 350 were opposed to the King.\nLong Parliament.\nTensions escalate.\nThe Long Parliament proved just as difficult for Charles as had the Short Parliament. It assembled on 3 November 1640 and quickly began proceedings to impeach the King's leading counsellors for high treason. Strafford was taken into custody on 10 November; Laud was impeached on 18 December; Finch, now Lord Keeper of the Great Seal, was impeached the next day, and consequently fled to The Hague with Charles's permission on 21 December. To prevent the King from dissolving it at will, Parliament passed the Triennial Act, which required Parliament to be summoned at least every three years, and permitted the Lord Keeper and 12 peers to summon Parliament if the King failed to do so. The Act was coupled with a subsidy bill, and to secure the latter, Charles grudgingly granted royal assent in February 1641.\nStrafford had become the principal target of the Parliamentarians, particularly John Pym, and he went on trial for high treason on 22 March 1641. But the key allegation by Sir Henry Vane that Strafford had threatened to use the Irish army to subdue England was not corroborated, and on 10 April Pym's case collapsed. Pym and his allies immediately launched a bill of attainder, which simply declared Strafford guilty and pronounced the sentence of death.\nCharles assured Strafford that \"upon the word of a king you shall not suffer in life, honour or fortune\", and the attainder could not succeed if Charles withheld assent. Furthermore, many members and most peers opposed the attainder, not wishing, in the words of one, to \"commit murder with the sword of justice\". But increased tensions and an attempted coup by royalist army officers in support of Strafford and in which Charles was involved began to sway the issue. The Commons passed the bill on 20 April by a large margin (204 in favour, 59 opposed, and 230 abstained), and the Lords acquiesced (by 26 votes to 19, with 79 absent) in May. On 3 May, Parliament's Protestation attacked the \"wicked counsels\" of Charles's \"arbitrary and tyrannical government\". While those who signed the petition undertook to defend the King's \"person, honour and estate\", they also swore to preserve \"the true reformed religion\", Parliament, and the \"rights and liberties of the subjects\". Fearing for his family's safety in the face of unrest, Charles reluctantly assented to Strafford's attainder on 9 May after consulting his judges and bishops. Strafford was beheaded three days later.\nAlso in early May, Charles assented to an unprecedented Act that forbade the dissolution of the English Parliament without its consent. In the following months, ship money, fines in distraint of knighthood and excise without parliamentary consent were declared unlawful, and the Courts of Star Chamber and High Commission were abolished. All remaining forms of taxation were legalised and regulated by the Tonnage and Poundage Act. The House of Commons also launched bills attacking bishops and episcopacy, but these failed in the Lords.\nCharles had made important concessions in England, and temporarily improved his position in Scotland by signing a final settlement of the Bishops' Wars, then securing the Scots' favour on a visit from August to November 1641 during which he conceded to the official establishment of presbyterianism in Scotland. But after an attempted royalist coup in Scotland, known as the Incident, Charles's credibility was significantly undermined.\nIrish rebellion.\nIreland's population was split into three main sociopolitical groups: the Gaelic Irish, who were Catholic; the Old English, who were descended from medieval Normans and also predominantly Catholic; and the New English, who were Protestant settlers from England and Scotland aligned with the English Parliament and the Covenanters. Strafford's administration had improved the Irish economy and boosted tax revenue, but had done so by heavy-handedly imposing order. He had trained up a large Catholic army in support of the King and weakened the Irish Parliament's authority, while continuing to confiscate land from Catholics for Protestant settlement at the same time as promoting a Laudian Anglicanism that was anathema to presbyterians. As a result, all three groups had become disaffected. Strafford's impeachment provided a new departure for Irish politics whereby all sides joined to present evidence against him. In a similar manner to the English Parliament, the Old English members of the Irish Parliament argued that while opposed to Strafford they remained loyal to Charles. They argued that the King had been led astray by malign counsellors, and that, moreover, a viceroy such as Strafford could emerge as a despotic figure instead of ensuring that the King was directly involved in governance.\nStrafford's fall from power weakened Charles's influence in Ireland. The dissolution of the Irish army was unsuccessfully demanded three times by the English Commons during Strafford's imprisonment, until lack of money eventually forced Charles to disband the army at the end of Strafford's trial. Disputes over the transfer of land ownership from native Catholic to settler Protestant, particularly in relation to the plantation of Ulster, coupled with resentment at moves to ensure the Irish Parliament was subordinate to the Parliament of England, sowed the seeds of rebellion. When armed conflict arose between the Gaelic Irish and New English in late October 1641, the Old English sided with the Gaelic Irish while simultaneously professing their loyalty to the King.\nIn November 1641, the House of Commons passed the Grand Remonstrance, a long list of grievances against actions by Charles's ministers committed since the beginning of his reign (that were asserted to be part of a grand Catholic conspiracy of which the King was an unwitting member), but it was in many ways a step too far by Pym and passed by only 11 votes, 159 to 148. Furthermore, the Remonstrance had very little support in the House of Lords, which the Remonstrance attacked. The tension was heightened by news of the Irish rebellion, coupled with inaccurate rumours of Charles's complicity. Throughout November, a series of alarmist pamphlets published stories of atrocities in Ireland, including massacres of New English settlers by the native Irish who could not be controlled by the Old English lords. Rumours of \"papist\" conspiracies circulated in England, and English anti-Catholic opinion was strengthened, damaging Charles's reputation and authority. The English Parliament distrusted Charles's motivations when he called for funds to put down the Irish rebellion; many members of the Commons suspected that forces he raised might later be used against Parliament itself. Pym's Militia Bill was intended to wrest control of the army from the King, but it did not have the support of the Lords, let alone Charles. Instead, the Commons passed the bill as an ordinance, which they claimed did not require royal assent. The Militia Ordinance appears to have prompted more members of the Lords to support the King. In an attempt to strengthen his position, Charles generated great antipathy in London, which was already fast falling into lawlessness, when he placed the Tower of London under the command of Colonel Thomas Lunsford, an infamous, albeit efficient, career officer. When rumours reached Charles that Parliament intended to impeach his wife for supposedly conspiring with the Irish rebels, he decided to take drastic action.\nFive members.\nCharles suspected, probably correctly, that some members of the English Parliament had colluded with the invading Scots. On 3 January 1642, Charles directed Parliament to give up five specific members of the Commons\u2014Pym, John Hampden, Denzil Holles, William Strode and Sir Arthur Haselrig\u2014and one peer, Lord Mandeville, on the grounds of high treason. When Parliament refused, it was possibly Henrietta Maria who persuaded Charles to arrest the five members by force, which he resolved to do personally. But news of the warrant reached Parliament ahead of him, and the wanted men slipped away by boat shortly before Charles entered the House of Commons with an armed guard on 4 January. Having displaced Speaker William Lenthall from his chair, the King asked him where the MPs had fled. Lenthall, on his knees, famously replied, \"May it please your Majesty, I have neither eyes to see nor tongue to speak in this place but as the House is pleased to direct me, whose servant I am here.\" Charles abjectly declared \"all my birds have flown\", and was forced to retire empty-handed.\nThe botched arrest attempt was politically disastrous for Charles. No English sovereign had ever entered the House of Commons, and his unprecedented invasion of the chamber to arrest its members was considered a grave breach of parliamentary privilege. In one stroke Charles destroyed his supporters' efforts to portray him as a defence against innovation and disorder.\nParliament quickly seized London, and Charles fled the capital for Hampton Court Palace on 10 January, moving two days later to Windsor Castle. After sending his wife and eldest daughter to safety abroad in February, he travelled northwards, hoping to seize the military arsenal at Hull. To his dismay, he was rebuffed by the town's Parliamentary governor, Sir John Hotham, who refused him entry in April, and Charles was forced to withdraw.\nEnglish Civil War.\nIn mid-1642, both sides began to arm. Charles raised an army using the medieval method of commission of array, and Parliament called for volunteers for its militia. The negotiations proved futile, and Charles raised the royal standard in Nottingham on 22 August 1642. By then, his forces controlled roughly the Midlands, Wales, the West Country and northern England. He set up his court at Oxford. Parliament controlled London, the south-east and East Anglia, as well as the English navy.\nAfter a few skirmishes, the opposing forces met in earnest at Edgehill, on 23 October 1642. Charles's nephew Prince Rupert of the Rhine disagreed with the battle strategy of the royalist commander Robert Bertie, 1st Earl of Lindsey, and Charles sided with Rupert. Lindsey resigned, leaving Charles to assume overall command assisted by Patrick Ruthven, 1st Earl of Forth. Rupert's cavalry successfully charged through the parliamentary ranks, but instead of swiftly returning to the field, rode off to plunder the parliamentary baggage train. Lindsey, acting as a colonel, was wounded and bled to death without medical attention. The battle ended inconclusively as the daylight faded.\nIn his own words, the experience of battle had left Charles \"exceedingly and deeply grieved\". He regrouped at Oxford, turning down Rupert's suggestion of an immediate attack on London. After a week, he set out for the capital on 3 November, capturing Brentford on the way while simultaneously continuing to negotiate with civic and parliamentary delegations. At Turnham Green on the outskirts of London, the royalist army met resistance from the city militia, and faced with a numerically superior force, Charles ordered a retreat. He overwintered in Oxford, strengthening the city's defences and preparing for the next season's campaign. Peace talks between the two sides collapsed in April.\nThe war continued indecisively over the next couple of years, and Henrietta Maria returned to Britain for 17 months from February 1643. After Rupert captured Bristol in July 1643, Charles visited the port city and laid siege to Gloucester, further up the river Severn. His plan to undermine the city walls failed due to heavy rain, and on the approach of a parliamentary relief force, Charles lifted the siege and withdrew to Sudeley Castle. The parliamentary army turned back towards London, and Charles set off in pursuit. The two armies met at Newbury, Berkshire, on 20 September. Just as at Edgehill, the battle stalemated at nightfall, and the armies disengaged. In January 1644, Charles summoned a Parliament at Oxford, which was attended by about 40 peers and 118 members of the Commons; all told, the Oxford Parliament, which sat until March 1645, was supported by the majority of peers and about a third of the Commons. Charles became disillusioned by the assembly's ineffectiveness, calling it a \"mongrel\" in private letters to his wife.\nIn 1644, Charles remained in the southern half of England while Rupert rode north to relieve Newark and York, which were under threat from parliamentary and Scottish Covenanter armies. Charles was victorious at the Battle of Cropredy Bridge in late June, but the royalists in the north were defeated at the Battle of Marston Moor just a few days later. The King continued his campaign in the south, encircling and disarming the parliamentary army of Robert Devereux, 3rd Earl of Essex. Returning northwards to his base at Oxford, he fought at Newbury for a second time before the winter closed in; the battle ended indecisively. Attempts to negotiate a settlement over the winter, while both sides rearmed and reorganised, were again unsuccessful.\nAt the Battle of Naseby on 14 June 1645, Rupert's horsemen again mounted a successful charge against the flank of Parliament's New Model Army, but elsewhere on the field, opposing forces pushed Charles's troops back. Attempting to rally his men, Charles rode forward, but as he did so, Robert Dalzell, 1st Earl of Carnwath seized his bridle and pulled him back, fearing for the King's safety. The royalist soldiers misinterpreted Carnwath's action as a signal to move back, leading to a collapse of their position. The military balance tipped decisively in favour of Parliament. There followed a series of defeats for the royalists, and then the siege of Oxford, from which Charles escaped (disguised as a servant) in April 1646. He put himself into the hands of the Scottish Presbyterian army besieging Newark, and was taken northwards to Newcastle upon Tyne. After nine months of negotiations, the Scots finally arrived at an agreement with the English Parliament: in exchange for \u00a3100,000, and the promise of more money in the future, the Scots withdrew from Newcastle and delivered Charles to the parliamentary commissioners in January 1647.\nCaptivity.\nParliament held Charles under house arrest at Holdenby House in Northamptonshire until Cornet George Joyce took him by threat of force from Holdenby on 3 June in the name of the New Model Army. By this time, mutual suspicion had developed between Parliament, which favoured army disbandment and presbyterianism, and the New Model Army, which was primarily officered by congregationalist Independents, who sought a greater political role. Charles was eager to exploit the widening divisions, and apparently viewed Joyce's actions as an opportunity rather than a threat. He was taken first to Newmarket, at his own suggestion, and then transferred to Oatlands and subsequently Hampton Court, while more fruitless negotiations took place. By November, he determined that it would be in his best interests to escape\u2014perhaps to France, Southern England or Berwick-upon-Tweed, near the Scottish border. He fled Hampton Court on 11 November, and from the shores of Southampton Water made contact with Colonel Robert Hammond, Parliamentary Governor of the Isle of Wight, whom he apparently believed to be sympathetic. But Hammond confined Charles in Carisbrooke Castle and informed Parliament that Charles was in his custody.\nFrom Carisbrooke, Charles continued to try to bargain with the various parties. In direct contrast to his previous conflict with the Scottish Kirk, on 26 December 1647 he signed a secret treaty with the Scots. Under the agreement, called the \"Engagement\", the Scots undertook to invade England on Charles's behalf and restore him to the throne on condition that Presbyterianism be established in England for three years.\nThe royalists rose in May 1648, igniting the Second Civil War, and as agreed with Charles, the Scots invaded England. Uprisings in Kent, Essex, and Cumberland, and a rebellion in South Wales, were put down by the New Model Army, and with the defeat of the Scots at the Battle of Preston in August 1648, the royalists lost any chance of winning the war.\nCharles's only recourse was to return to negotiations, which were held at Newport on the Isle of Wight. On 5 December 1648, Parliament voted 129 to 83 to continue negotiating with the King, but Oliver Cromwell and the army opposed any further talks with someone they viewed as a bloody tyrant and were already taking action to consolidate their power. Hammond was replaced as Governor of the Isle of Wight on 27 November, and placed in the custody of the army the following day. In Pride's Purge on 6 and 7 December, the members of Parliament out of sympathy with the military were arrested or excluded by Colonel Thomas Pride, while others stayed away voluntarily. The remaining members formed the Rump Parliament. It was effectively a military coup.\nTrial.\nCharles was moved to Hurst Castle at the end of 1648, and thereafter to Windsor Castle. In January 1649, the Rump Parliament House of Commons indicted him for treason, however the House of Lords rejected the charge. The idea of trying a king was novel. The Chief Justices of the three common law courts of England\u2014Henry Rolle, Oliver St John and John Wilde\u2014all opposed the indictment as unlawful. \nThe Rump Commons declared itself capable of legislating alone, passed a bill creating a separate court for Charles's trial, and declared the bill an act without the need for royal assent. The High Court of Justice established by the Act consisted of 135 commissioners, but many either refused to serve or chose to stay away. Only 68 (all firm Parliamentarians) attended Charles's trial on charges of high treason and \"other high crimes\" that began on 20 January 1649 in Westminster Hall. John Bradshaw acted as President of the Court, and the prosecution was led by Solicitor General John Cook.\nCharles was accused of treason against England by using his power to pursue his personal interest rather than the good of the country. The charge stated that he was devising \"a wicked design to erect and uphold in himself an unlimited and tyrannical power to rule according to his will, and to overthrow the rights and liberties of the people\". In carrying this out he had \"traitorously and maliciously levied war against the present Parliament, and the people therein represented\", and that the \"wicked designs, wars, and evil practices of him, the said Charles Stuart, have been, and are carried on for the advancement and upholding of a personal interest of will, power, and pretended prerogative to himself and his family, against the public interest, common right, liberty, justice, and peace of the people of this nation.\" \nPresaging the modern concept of command responsibility, the indictment held him \"guilty of all the treasons, murders, rapines, burnings, spoils, desolations, damages and mischiefs to this nation, acted and committed in the said wars, or occasioned thereby.\" An estimated 300,000 people, or 6% of the population, died during the war.\nOver the first three days of the trial, whenever Charles was asked to plead, he refused, stating his objection with the words: \"I would know by what power I am called hither, by what lawful authority...?\" He claimed that no court had jurisdiction over a monarch, that his own authority to rule had been given to him by God and by the traditional laws of England, and that the power wielded by those trying him was only that of force of arms. Charles insisted that the trial was illegal, explaining that, The court, by contrast, challenged the doctrine of sovereign immunity and proposed that \"the King of England was not a person, but an office whose every occupant was entrusted with a limited power to govern 'by and according to the laws of the land and not otherwise'.\"\nAt the end of the third day, Charles was removed from the court, which then heard over 30 witnesses against him in his absence over the next two days, and on 26 January condemned him to death. The next day, the King was brought before a public session of the commission, declared guilty, and sentenced. The judgement read, \"For all which treasons and crimes this court doth adjudge that he, the said Charles Stuart, as a tyrant, traitor, murderer, and public enemy to the good people of this nation, shall be put to death by the severing of his head from his body.\" Fifty-nine of the commissioners signed Charles's death warrant.\nExecution.\nCharles's execution was scheduled for Tuesday, 30 January 1649. Two of his children remained in England under the control of the Parliamentarians: Elizabeth and Henry. They were permitted to visit him on 29 January, and he bade them a tearful farewell. The next morning, he called for two shirts to prevent the cold weather causing any noticeable shivers that the crowd could have mistaken for fear: \"the season is so sharp as probably may make me shake, which some observers may imagine proceeds from fear. I would have no such imputation.\"\nHe walked under guard from St James's Palace, where he had been confined, to the Palace of Whitehall, where an execution scaffold had been erected in front of the Banqueting House. Charles was separated from spectators by large ranks of soldiers, and his last speech reached only those with him on the scaffold. He blamed his fate on his failure to prevent the execution of his loyal servant Strafford: \"An unjust sentence that I suffered to take effect, is punished now by an unjust sentence on me.\" He declared that he had desired the liberty and freedom of the people as much as any, \"but I must tell you that their liberty and freedom consists in having government\u00a0... It is not their having a share in the government; that is nothing appertaining unto them. A subject and a sovereign are clean different things.\" He continued, \"I shall go from a corruptible to an incorruptible Crown, where no disturbance can be.\"\nAt about 2:00\u00a0p.m., Charles put his head on the block after saying a prayer and signalled the executioner when he was ready by stretching out his hands; he was then beheaded in one clean stroke. According to observer Philip Henry, a moan \"as I never heard before and desire I may never hear again\" rose from the assembled crowd, some of whom then dipped their handkerchiefs in the King's blood as a memento.\nThe executioner was masked and disguised, and there is debate over his identity. The commissioners approached Richard Brandon, the common hangman of London, but he refused, at least at first, despite being offered \u00a3200 \u2013 a considerably large sum for the time. It is possible he relented and undertook the commission after being threatened with death, but others have been named as potential candidates, including George Joyce, William Hulet and Hugh Peters. The clean strike, confirmed by an examination of the King's body at Windsor in 1813, suggests that the execution was carried out by an experienced headsman.\nIt was common practice for the severed head of a traitor to be held up and exhibited to the crowd with the words \"Behold the head of a traitor!\" Charles's head was exhibited, but those words were not used, possibly because the executioner did not want his voice recognised. On the day after the execution, the King's head was sewn back onto his body, which was then embalmed and placed in a lead coffin.\nThe commission refused to allow Charles's burial at Westminster Abbey, so his body was conveyed to Windsor on the night of 7 February. He was buried in private on 9 February 1649 in the Henry VIII vault in the chapel's quire, alongside the coffins of Henry VIII and Henry's third wife, Jane Seymour, in St George's Chapel, Windsor Castle. The King's son, Charles II, later planned for an elaborate royal mausoleum to be erected in Hyde Park, London, but it was never built.\nLegacy.\nTen days after Charles's execution, on the day of his interment, a memoir purportedly written by him appeared for sale. This book, the \"Eikon Basilike\" (Greek for the \"Royal Portrait\"), contained an \"apologia\" for royal policies, and proved an effective piece of royalist propaganda. John Milton wrote a Parliamentary rejoinder, the \"Eikonoklastes\" (\"The Iconoclast\"), but the response made little headway against the pathos of the royalist book. Anglicans and royalists fashioned an image of martyrdom, and in the Convocations of Canterbury and York of 1660 King Charles the Martyr was added to the Church of England's liturgical calendar. High church Anglicans held special services on the anniversary of his death. Churches, such as those at Falmouth and Tunbridge Wells, and Anglican devotional societies such as the Society of King Charles the Martyr, were founded in his honour.\nWith the monarchy overthrown, England became a republic or \"Commonwealth\". The House of Lords was abolished by the Rump Commons, and executive power was assumed by a Council of State. All significant military opposition in Britain and Ireland was extinguished by the forces of Oliver Cromwell in the Anglo-Scottish War and the Cromwellian conquest of Ireland. Cromwell forcibly disbanded the Rump Parliament in 1653, thereby establishing the Protectorate with himself as Lord Protector. Upon his death in 1658, he was briefly succeeded by his ineffective son, Richard. Parliament was reinstated, and the monarchy was restored to Charles I's eldest son, Charles II, in 1660.\nCharles's unprecedented 1642 invasion of the House of Commons' chamber, a grave violation of the liberties of Parliament, and his unsuccessful attempt to arrest five Members of Parliament is commemorated annually at the State Opening of Parliament.\nArt.\nPartly inspired by his visit to the Spanish court in 1623, Charles became a passionate and knowledgeable art collector, amassing one of the finest art collections ever assembled. In Spain, he sat for a sketch by Vel\u00e1zquez, and acquired works by Titian and Correggio, among others. In England, his commissions included the ceiling of the Banqueting House, Whitehall, by Peter Paul Rubens and paintings by other artists from the Low Countries such as Gerard van Honthorst, Daniel Mytens, and Anthony van Dyck. His close associates, including the Duke of Buckingham and Thomas Howard, 21st Earl of Arundel, shared his interest and have been dubbed the Whitehall Group. In 1627 and 1628, Charles purchased the entire collection of the Duke of Mantua, which included work by Titian, Correggio, Raphael, Caravaggio, Andrea del Sarto and Andrea Mantegna. His collection grew further to encompass Gian Lorenzo Bernini, Pieter Bruegel the Elder, Leonardo da Vinci, Hans Holbein the Younger, Wenceslaus Hollar, Tintoretto and Veronese, and self-portraits by both Albrecht D\u00fcrer and Rembrandt. By Charles's death, there were an estimated 1,760 paintings, most of which were sold and dispersed by Parliament.\nAssessments.\nIn the words of John Philipps Kenyon, \"Charles Stuart is a man of contradictions and controversy\". Revered by high Tories who considered him a saintly martyr, he was condemned by Whig historians, such as Samuel Rawson Gardiner, who thought him duplicitous and delusional. In recent decades, most historians have criticised him, the main exception being Kevin Sharpe, who offered a more sympathetic view that has not been widely adopted. Sharpe argued that the King was a dynamic man of conscience, but Barry Coward thought Charles \"the most incompetent monarch of England since Henry VI\", a view shared by Ronald Hutton, who called him \"the worst king we have had since the Middle Ages\".\nArchbishop William Laud, whom Parliament beheaded during the war, described Charles as \"A mild and gracious prince who knew not how to be, or how to be made, great.\" Charles was more sober and refined than his father, but he was intransigent. He deliberately pursued unpopular policies that brought ruin on himself. Both Charles and James were advocates of the divine right of kings, but while James's ambitions concerning absolute prerogative were tempered by compromise and consensus with his subjects, Charles believed he had no need to compromise or even to explain his actions. He thought he was answerable only to God. \"Princes are not bound to give account of their actions,\" he wrote, \"but to God alone\".\nTitles, styles, honours and arms.\nTitles and styles.\nThe official style of Charles I as king in England was \"Charles, by the Grace of God, King of England, Scotland, France and Ireland, Defender of the Faith, etc.\" The style \"of France\" was only nominal, and was used by every English monarch from Edward III to George III, regardless of the amount of French territory actually controlled. The authors of his death warrant called him \"Charles Stuart, King of England\".\nArms.\nAs Duke of York, Charles bore the royal arms of the kingdom differenced by a label Argent of three points, each bearing three torteaux Gules. As the Prince of Wales, he bore the royal arms differenced by a plain label Argent of three points. As king, Charles bore the royal arms undifferenced: Quarterly, I and IV Grandquarterly, Azure three fleurs-de-lis Or (for France) and Gules three lions passant guardant in pale Or (for England); II Or a lion rampant within a tressure flory-counter-flory Gules (for Scotland); III Azure a harp Or stringed Argent (for Ireland). In Scotland, the Scottish arms were placed in the first and fourth quarters with the English and French arms in the second quarter.\nIssue.\nCharles had nine children, five of whom reached adulthood. Two of his sons eventually succeeded as king, and two children died at or shortly after birth."}
{"id": "7428", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=7428", "title": "Cuzco (disambiguation)", "text": ""}
{"id": "7430", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=7430", "title": "Crowley on egolessness", "text": ""}
{"id": "7431", "revid": "19921271", "url": "https://en.wikipedia.org/wiki?curid=7431", "title": "Counter-Strike (video game)", "text": "Counter-Strike (also known as Half-Life: Counter-Strike or Counter-Strike 1.6) is a tactical first-person shooter game developed by Valve. It was initially developed and released as a \"Half-Life\" modification by Minh \"Gooseman\" Le and Jess Cliffe in 1999, before Le and Cliffe were hired and the game's intellectual property acquired. \"Counter-Strike\" was released by Valve for Microsoft Windows in November 2000, and is the first installment in the \"Counter-Strike\" series. Several remakes and ports were released on Xbox, as well as OS X and Linux.\nSet in various locations around the globe, players assume the roles of counter-terrorist forces and terrorist militants opposing them. During each round of gameplay, the two teams are tasked with defeating the other by the means of either achieving the map's objectives or eliminating all of the enemy combatants. Each player may customize their arsenal of weapons and accessories at the beginning of every match, with currency being earned after the end of each round.\nGameplay.\n\"Counter-Strike\" is a team-based multiplayer first-person shooter video game in which players can join either the terrorists (T) or the counter-terrorists (CT). If one team has more players than the other, the server settings may automatically balance. Each game begins with both teams spawning simultaneously as one of eight possible default character models (four each for counter-terrorist and terrorist). Each player begins with $800, two magazines of ammo, a knife, and a handgun: a Heckler &amp; Koch USP for the counter-terrorists or a Glock 18c for the terrorists. Players are usually allowed a few seconds before the round starts, known as freeze time to purchase equipment but not move. Players may purchase equipment whenever they are in a buy zone for their team, some of which can be shared by both sides and the round has not been in session for more than a certain duration, which is 90 seconds by default. Surviving players keep their equipment for the following game, while those who die start again with a handgun and knife. \nThe scoreboard displays team results as well as information about each player, including their name, score, deaths, and ping/latency (ms) on the map, it also displays if each player is dead, carrying a bomb (in bomb defusal maps), or a VIP (in assassination maps), albeit the player must be killed during the round to gain this information about opposing team members. Players that are killed become \"ghosts\" for the rest of the round; they are unable to alter their names or receive chat/voice messages from live players, unless the console command sv_alltalk is set to 1. They may typically watch the rest of the round from a variety of chosen observer modes (free-look mode, locked chasecam and free chase chasecam), but some servers limit some of these views to prevent dead players from conveying information about surviving players to their teammates via alternate media (most notably voice in Internet caf\u00e9s). Many players believe the practice known as \"ghosting\" to be cheating. Players receive standard bonuses, such as $3500 for winning a round, $1500 for losing one, and $300 for killing an enemy. They can have up to $16000 via earning and can be fined (e.g. killing a teammate fines the perpetrator $3300).\nCurrently, there are three objectives depending on the map:\nFormerly, there was a fourth objective called Escape. The scenario is that the terrorist team must \"escape\" to one of the designated escape points after beginning their mission in a protected area. Before they can flee, the counter-terrorist team needs to kill them. Once half of the team has managed to escape, the terrorists win the round. Following each of the eight rounds of play, the two sides will trade roles. If one team eliminates the other, both teams can also win the scenario.\nThree categories exist for weapons: Melee (knife), Secondary (handguns), and Primary (rifles, shotguns, machine and submachine guns). There is a separate category for equipment like defusing kits and hand grenades. With the exception of equipment, which may hold many items at once, players are only allowed to carry one item in each of these categories at a time.\nDevelopment.\n\"Counter-Strike\" began as a mod of \"Half-Life\"s engine GoldSrc. Minh Le, the mod's co-creator, had started his last semester at university, and wanted to do something in game development to help give him better job prospects. Throughout university, Le had worked on mods with the \"Quake\" engine, and on looking for this latest project, wanted to try something new and opted for GoldSrc. At the onset, Valve had not yet released the software development kit (SDK) for GoldSrc but affirmed it would be available in a few months, allowing Le to work on the character models in the interim. Once the GoldSrc SDK was available, Le estimated it took him about a month and a half to complete the programming and integrate his models for \"Beta One\" of \"Counter-Strike\". To assist, Le had help from Jess Cliffe who managed the game's website and community, and had contacts within level map making community to help build some of the levels for the game. The theme of countering terrorists was inspired by Le's own interest in guns and the military, and from games like \"Rainbow Six\" and \"Spec Ops\".\nLe and Cliffe continued to release Betas on a frequent basis for feedback. The initial few Betas, released starting in June 1999, had limited audiences but by the fifth one, interest in the project dramatically grew. The interest in the game drew numerous players to the website, which helped Le and Cliffe to make revenue from ads hosted on the site. Around 2000 at the time of Beta 5's release, the two were approached by Valve, offering to buy the \"Counter-Strike\" intellectual property and offering both jobs to continue its development. Both accepted the offer, and by September 2000, Valve released the first non-beta version of the game. While Cliffe stayed with Valve, Le did some additional work towards a \"Counter-Strike 2.0\" based on Valve's upcoming Source engine, but left to start his own studio after Valve opted to shelve the sequel.\n\"Counter-Strike\" itself is a mod, and it has developed its own community of script writers and mod creators. Some mods add bots, while others remove features of the game, and others create different modes of play. Some mods, often called \"admin plugins\", give server administrators more flexible and efficient control over their servers. There are some mods which affect gameplay heavily, such as Gun Game, where players start with a basic pistol and must score kills to receive better weapons, and Zombie Mod, where one team consists of zombies and must \"spread the infection\" by killing the other team (using only the knife). There are also Superhero mods which mix the first-person gameplay of \"Counter-Strike\" with an experience system, allowing a player to become more powerful as they continue to play. The game is highly customizable on the player's end, allowing the user to install or even create their own custom skins, HUDs, spray graphics, sprites, and sound effects, given the proper tools.\nValve Anti-Cheat.\n\"Counter-Strike\" has been a target for cheating in online games since its release. In-game, cheating is often referred to as \"hacking\" in reference to programs or \"hacks\" executed by the client. Valve has implemented an anti-cheat system called Valve Anti-Cheat (VAC). Players cheating on a VAC-enabled server risk having their account permanently banned from all VAC-secured servers.\nWith the first version of VAC, a ban took hold almost instantly after being detected and the cheater had to wait two years to have the account unbanned. Since VAC's second version, cheaters are not banned automatically. With the second version, Valve instituted a policy of 'delayed bans', the theory being that if a new hack is developed which circumvents the VAC system, it will spread amongst the 'cheating' community. By delaying the initial ban, Valve hopes to identify and ban as many cheaters as possible. Like any software detection system, some cheats are not detected by VAC. To remedy this, some servers implement a voting system, in which case players can call for a vote to kick or ban the accused cheater. VAC's success at identifying cheats and banning those who use them has also provided a boost in the purchasing of private cheats. These cheats are updated frequently to minimize the risk of detection, and are generally only available to a trusted list of recipients who collectively promise not to reveal the underlying design. Even with private cheats however, some servers have alternative anticheats to coincide with VAC itself. This can help with detecting some cheaters, but most paid for cheats are designed to bypass these alternative server-based anticheats.\nRelease.\nWhen \"Counter-Strike\" was published by Sierra Studios, it was bundled with \"Team Fortress Classic\", \"\" multiplayer, and the \"Wanted\", \"Half-Life: Absolute Redemption\" and \"Firearms\" mods.\nOn March 24, 1999, Planet Half-Life opened its \"Counter-Strike\" section. Within two weeks, the site had received 10,000 hits. On June 19, 1999, the first public beta of \"Counter-Strike\" was released, followed by numerous further \"beta\" releases. On April 12, 2000, Valve announced that the \"Counter-Strike\" developers and Valve had teamed up. In January 2013, Valve began testing a version of \"Counter-Strike\" for OS X and Linux, eventually releasing the update to all users in April 2013.\nAn unofficial browser version was released in 2023 on a Russian website.\nReception.\nUpon its retail release, \"Counter-Strike\" received highly favorable reviews. In 2003, \"Counter-Strike\" was inducted into GameSpot's list of the greatest games of all time. \"The New York Times\" reported that E-Sports Entertainment ESEA League started the first professional fantasy e-sports league in 2004 with the game \"Counter-Strike\". Some credit the move into professional competitive team play with prizes as a major factor in \"Counter-Strike\" longevity and success.\nGlobal retail sales of \"Counter-Strike\" surpassed 250,000 units by July 2001. The game sold 1.5 million by February 2003 and generated $40 million in revenue. In the United States, its retail version sold 550,000 copies and earned $15.7 million by August 2006, after its release in November 2000. It was the country's 22nd best-selling PC game between January 2000 and August 2006.\nThe Xbox version sold 1.5 million copies in total.\nBrazilian sale ban.\nOn January 17, 2008, a Brazilian federal court order prohibiting all sales of \"Counter-Strike\" and \"EverQuest\" began to be enforced. The federal Brazilian judge Carlos Alberto Sim\u00f5es de Tomaz ordered the ban in October 2007 because, as argued by the judge, the games \"bring imminent stimulus to the subversion of the social order, attempting against the democratic state and the law and against public security.\" As of June 18, 2009, a regional federal court order lifting the prohibition on the sale of \"Counter-Strike\" was published. The game is now being sold again in Brazil.\nCompetitive play.\nThe original \"Counter-Strike\" has been played in tournaments since 2000 with the first major being hosted in 2001 at the Cyberathlete Professional League Winter Championship. The first official sequel was \"\", released on November 1, 2004. The game was criticized by the competitive community, who believed the game's skill ceiling was significantly lower than that of CS 1.6. This caused a divide in the competitive community as to which game to play competitively.\nSequels.\nFollowing the success of the first \"Counter-Strike\", Valve went on to make multiple sequels to the game. ', a game using \"Counter-Strike\"s GoldSrc engine, was released in 2004. ', a remake of the original \"Counter-Strike\", was the first in the series to use Valve's Source engine and was also released in 2004, eight months after the release of \"Counter-Strike: Condition Zero\". The next game in the \"Counter-Strike\" series to be developed primarily by Valve was \"\", released for Windows, OS X, Linux, PlayStation 3, and Xbox 360 in 2012. \"Counter-Strike 2\", an updated version of \"Global Offensive\", was released in 2023.\nThe game spawned multiple spin-offs for the Asian gaming market. The first, \"Counter-Strike Neo\", was an arcade game developed by Namco and released in Japan in 2003. In 2008, Nexon Corporation released \"Counter-Strike Online\", a free-to-play instalment in the series monetized via microtransactions. \"Counter-Strike Online\" was followed by \"Counter-Strike Online 2\" in 2013. In 2014, Nexon released \"\" worldwide via Steam."}
{"id": "7434", "revid": "1018034", "url": "https://en.wikipedia.org/wiki?curid=7434", "title": "Camille Pissarro", "text": "Jacob Abraham Camille Pissarro ( ; ; 10 July 1830\u00a0\u2013 13 November 1903) was a Danish-French Impressionist and Neo-Impressionist painter born on the island of St Thomas (now in the US Virgin Islands, but then in the Danish West Indies). His importance resides in his contributions to both Impressionism and Post-Impressionism. Pissarro studied from great forerunners, including Gustave Courbet and Jean-Baptiste-Camille Corot. He later studied and worked alongside Georges Seurat and Paul Signac when he took on the Neo-Impressionist style at the age of 54.\nIn 1873 he helped establish a collective society of fifteen aspiring artists, becoming the \"pivotal\" figure in holding the group together and encouraging the other members. Art historian John Rewald called Pissarro the \"dean of the Impressionist painters\", not only because he was the oldest of the group, but also \"by virtue of his wisdom and his balanced, kind, and warmhearted personality\". Paul C\u00e9zanne said \"he was a father for me. A man to consult and a little like the good Lord\", and he was also one of Paul Gauguin's masters. Pierre-Auguste Renoir referred to his work as \"revolutionary\", through his artistic portrayals of the \"common man\", as Pissarro insisted on painting individuals in natural settings without \"artifice or grandeur\".\nPissarro is the only artist to have shown his work at all eight Paris Impressionist exhibitions, from 1874 to 1886. He \"acted as a father figure not only to the Impressionists\" but to all four of the major Post-Impressionists, C\u00e9zanne, Seurat, Gauguin, and van Gogh.\nEarly years.\nJacob Abraham Camille Pissarro was born on 10 July 1830 on the island of St. Thomas to Frederick Abraham Gabriel Pissarro and Rachel Manzano-Pomi\u00e9. His father was of Portuguese Jewish descent and held French nationality. His mother was from a French-Jewish family from St. Thomas with Proven\u00e7al Jewish roots. His father was a merchant who came to the island from France to deal with the hardware store of a deceased uncle, Isaac Petit, and married his widow. The marriage caused a stir within St. Thomas's small Jewish community because she was previously married to Frederick's uncle and according to Jewish law a man is forbidden from marrying his aunt. In subsequent years his four children attended the all-black primary school. Upon his death, his will specified that his estate be split equally between the synagogue and St. Thomas' Protestant church.\nWhen Pissarro was twelve his father sent him to boarding school in France. He studied at the Savary Academy in Passy near Paris. While a young student, he developed an early appreciation of the French art masters. Monsieur Savary himself gave him a strong grounding in drawing and painting and suggested he draw from nature when he returned to St. Thomas.\nAfter his schooling, Pissarro returned to St. Thomas at the age of sixteen or seventeen, where his father advocated Pissarro to work in his business as a port clerk. Nevertheless, Pissarro took every opportunity during those next five years at the job to practice drawing during breaks and after work.\nVisual theorist Nicholas Mirzoeff claims that the young Pissarro was inspired by the artworks of James Gay Sawkins, a British painter and geologist who lived in Charlotte Amalie, St. Thomas circa 1847. Pissarro may have attended art classes taught by Sawkins and seen Sawkins's paintings of Mitla, Mexico. Mirzoeff states, \"A formal analysis suggests that [Sawkins's] work influenced the young Pissarro, who had just returned to the island from his school in France. Soon afterward, Pissarro began his own drawings of the local African population in apparent imitation of Sawkins,\" creating \"sketches for a postslavery imagination.\"\nWhen Pissarro turned twenty-one, Danish artist Fritz Melbye, then living on St. Thomas, inspired him to take on painting as a full-time profession, becoming his teacher and friend. Pissarro then chose to leave his family and job and live in Venezuela, where he and Melbye spent the next two years working as artists in Caracas and La Guaira. He drew everything he could, including landscapes, village scenes, and numerous sketches, enough to fill up multiple sketchbooks.\nLife in France.\nIn 1855, Pissarro moved back to Paris where he began working as an assistant to Anton Melbye, Fritz Melbye's brother and also a painter. He also studied paintings by other artists whose style impressed him: Courbet, Charles-Fran\u00e7ois Daubigny, Jean-Fran\u00e7ois Millet, and Corot. He also enrolled in various classes taught by masters, at schools such as \u00c9cole des Beaux-Arts and Acad\u00e9mie Suisse. But Pissarro eventually found their teaching methods \"stifling,\" states art historian John Rewald. This prompted him to search for alternative instruction, which he requested and received from Corot.\nParis Salon and Corot's influence.\nHis initial paintings were in accord with the standards at the time to be displayed at the Paris Salon, the official body whose academic traditions dictated the kind of art that was acceptable. The Salon's annual exhibition was essentially the only marketplace for young artists to gain exposure. As a result, Pissarro worked in the traditional and prescribed manner to satisfy the tastes of its official committee.\nIn 1859 his first painting was accepted and exhibited. His other paintings during that period were influenced by Camille Corot, who tutored him. He and Corot shared a love of rural scenes painted from nature. It was by Corot that Pissarro was inspired to paint outdoors, also called \"plein air\" painting. Pissarro found Corot, along with the work of Gustave Courbet, to be \"statements of pictorial truth,\" writes Rewald. He discussed their work often. Jean-Fran\u00e7ois Millet was another whose work he admired, especially his \"sentimental renditions of rural life\".\nUse of natural outdoor settings.\nDuring this period Pissarro began to understand and appreciate the importance of expressing on canvas the beauties of nature without adulteration. After a year in Paris, he therefore began to leave the city and paint scenes in the countryside to capture the daily reality of village life. He found the French countryside to be \"picturesque,\" and worthy of being painted. It was still mostly agricultural and sometimes called the \"golden age of the peasantry\". Pissarro later explained the technique of painting outdoors to a student:\nCorot would complete his paintings back in his studio, often revising them according to his preconceptions. Pissarro, however, preferred to finish his paintings outdoors, often at one sitting, which gave his work a more realistic feel. As a result, his art was sometimes criticised as being \"vulgar,\" because he painted what he saw: \"rutted and edged hodgepodge of bushes, mounds of earth, and trees in various stages of development.\" According to one source, such details were equivalent to today's art showing garbage cans or beer bottles on the side of a street. This difference in style created disagreements between Pissarro and Corot.\nWith Monet, C\u00e9zanne, and Guillaumin.\nIn 1859, while attending the free school, the Acad\u00e9mie Suisse, Pissarro became friends with a number of younger artists who likewise chose to paint in the more realistic style. Among them were Claude Monet, Armand Guillaumin and Paul C\u00e9zanne. What they shared in common was their dissatisfaction with the dictates of the Salon. C\u00e9zanne's work had been mocked at the time by the others in the school, and, writes Rewald, in his later years C\u00e9zanne \"never forgot the sympathy and understanding with which Pissarro encouraged him.\" As a part of the group, Pissarro was comforted from knowing he was not alone, and that others similarly struggled with their art.\nPissarro agreed with the group about the importance of portraying individuals in natural settings, and expressed his dislike of any artifice or grandeur in his works, despite what the Salon demanded for its exhibits. In 1863 almost all of the group's paintings were rejected by the Salon, and French Emperor Napoleon III instead decided to place their paintings in a separate exhibit hall, the Salon des Refus\u00e9s. However, only works of Pissarro and C\u00e9zanne were included, and the separate exhibit brought a hostile response from both the officials of the Salon and the public.\nIn subsequent Salon exhibits of 1865 and 1866, Pissarro acknowledged his influences from Melbye and Corot, whom he listed as his masters in the catalogue. But in the exhibition of 1868 he no longer credited other artists as an influence, in effect declaring his independence as a painter. This was noted at the time by art critic and author \u00c9mile Zola, who offered his opinion:\nAnother writer tries to describe elements of Pissarro's style:\nAnd though, on orders from the hanging Committee and the Marquis de Chennevi\u00e8res, Pissarro's paintings of Pontoise for example had been skyed, hung near the ceiling, this did not prevent Jules-Antoine Castagnary from noting that the qualities of his paintings had been observed by art lovers. At the age of thirty-eight, Pissarro had begun to win himself a reputation as a landscapist to rival Corot and Daubigny.\nIn the late 1860s or early 1870s, Pissarro became fascinated with Japanese prints, which influenced his desire to experiment in new compositions. He described the art to his son Lucien:\nMarriage and children.\nIn 1871 in Croydon, England, he married his mother's maid, Julie Vellay, a vineyard grower's daughter, with whom he had seven children, six of whom would become painters: Lucien Pissarro (1863\u20131944), Georges Henri Manzana Pissarro (1871\u20131961), F\u00e9lix Pissarro (1874\u20131897), (1878\u20131952), (1881\u20131948), and Paul-\u00c9mile Pissarro (1884\u20131972). They lived outside Paris in Pontoise and later in Louveciennes, both of which places inspired many of his paintings including scenes of village life, along with rivers, woods, and people at work. He also kept in touch with the other artists of his earlier group, especially Monet, Renoir, C\u00e9zanne, and Fr\u00e9d\u00e9ric Bazille.\nPolitical thought.\nPissarro was involved in anarchist circles and held strong views of egalitarianism. Pissarro was a subscriber to the radical anarchist publication Le R\u00e9volt\u00e9 and was in consistent communication with leading anarchist theorizer Jean Grave as well as fellow anarchist artists such as Paul Signac and Henri-Edmond Cross. His political philosophies also motivated some of his art. For instance, in 1889, Pissarro created an album of 30 drawings titled Turpitudes Sociales, using a style of caricature and allegory to critique modern societal issues. The purpose of the album was political, Pissarro created the album as a gift for his niece aiming to solidify her anarchist tendencies.\nThe London years.\nAfter the outbreak of the Franco-Prussian War of 1870\u201371, having only Danish nationality and being unable to join the army, he moved his family to Norwood, then a village on the edge of London. However, his style of painting, which was a forerunner of what was later called \"Impressionism\", did not do well. He wrote to his friend, Th\u00e9odore Duret, that \"my painting doesn't catch on, not at all\u00a0...\"\nPissarro met the Paris art dealer Paul Durand-Ruel, in London, who became the dealer who helped sell his art for most of his life. Durand-Ruel put him in touch with Monet who was likewise in London during this period. They both viewed the work of British landscape artists John Constable and J. M. W. Turner, which confirmed their belief that their style of open air painting gave the truest depiction of light and atmosphere, an effect that they felt could not be achieved in the studio alone. Pissarro's paintings also began to take on a more spontaneous look, with loosely blended brushstrokes and areas of impasto, giving more depth to the work.\nPaintings.\nThrough the paintings Pissarro completed at this time, he records Sydenham and the Norwoods at a time when they were just recently connected by railways, but prior to the expansion of suburbia. One of the largest of these paintings is a view of \"St. Bartholomew's Church\" at Lawrie Park Avenue, commonly known as \"\", in the collection of the National Gallery in London. Twelve oil paintings date from his stay in Upper Norwood and are listed and illustrated in the catalogue raisonn\u00e9 prepared jointly by his fifth child Ludovic-Rodolphe Pissarro and Lionello Venturi and published in 1939. These paintings include \"Lower Norwood Under Snow\", and \"Lordship Lane Station\", views of The Crystal Palace relocated from Hyde Park, \"Dulwich College\", \"Sydenham Hill\", \"All Saints Church Upper Norwood\", and a lost painting of St. Stephen's Church.\nReturning to France, Pissarro lived in Pontoise from 1872 to 1884. In 1890 he again visited England and painted some ten scenes of central London. He came back again in 1892, painting in Kew Gardens and Kew Green, and also in 1897, when he produced several oils described as being of Bedford Park, Chiswick, but in fact all being of the nearby Stamford Brook area except for one of Bath Road, which runs from Stamford Brook along the south edge of Bedford Park.\nFrench Impressionism.\nWhen Pissarro returned to his home in France after the war, he discovered that of the 1,500 paintings he had done over 20 years, which he was forced to leave behind when he moved to London, only 40 remained. The rest had been damaged or destroyed by the soldiers, who often used them as floor mats outside in the mud to keep their boots clean. It is assumed that many of those lost were done in the Impressionist style he was then developing, thereby \"documenting the birth of Impressionism.\" Armand Silvestre, a critic, went so far as to call Pissarro \"basically the inventor of this [Impressionist] painting\"; however, Pissarro's role in the Impressionist movement was \"less that of the great man of ideas than that of the good counselor and appeaser\u00a0...\" \"Monet\u00a0... could be seen as the guiding force.\"\nHe soon reestablished his friendships with the other Impressionist artists of his earlier group, including C\u00e9zanne, Monet, Manet, Renoir, and Degas. Pissarro now expressed his opinion to the group that he wanted an alternative to the Salon so their group could display their own unique styles.\nTo assist in that endeavour, in 1873 he helped establish a separate collective, called the \"Soci\u00e9t\u00e9 Anonyme des Artistes, Peintres, Sculpteurs et Graveurs,\" which included fifteen artists. Pissarro created the group's first charter and became the \"pivotal\" figure in establishing and holding the group together. One writer noted that with his prematurely grey beard, the forty-three-year-old Pissarro was regarded as a \"wise elder and father figure\" by the group. Yet he was able to work alongside the other artists on equal terms due to his youthful temperament and creativity. Another writer said of him that \"he has unchanging spiritual youth and the look of an ancestor who remained a young man\".\nImpressionist exhibitions that shocked the critics.\nThe following year, in 1874, the group held their First Impressionist Exhibition, which shocked and \"horrified\" the critics, who primarily appreciated only scenes portraying religious, historical, or mythological settings. They found fault with the Impressionist paintings on many grounds:\nA \"revolutionary\" style.\nPissarro showed five of his paintings, all landscapes, at the exhibit, and again \u00c9mile Zola praised his art and that of the others. In the Impressionist exhibit of 1876, however, art critic Albert Wolff complained in his review, \"Try to make M. Pissarro understand that trees are not violet, that sky is not the color of fresh butter\u00a0...\" Journalist and art critic Octave Mirbeau on the other hand, writes, \"Camille Pissarro has been a revolutionary through the revitalized working methods with which he has endowed painting\".\nAccording to Rewald, Pissarro had taken on an attitude more simple and natural than the other artists. He writes:\nIn later years, C\u00e9zanne also recalled this period and referred to Pissarro as \"the first Impressionist\". In 1906, a few years after Pissarro's death, C\u00e9zanne, then 67 and a role model for the new generation of artists, paid Pissarro a debt of gratitude by having himself listed in an exhibition catalogue as \"Paul C\u00e9zanne, pupil of Pissarro\".\nPissarro, Degas, and American impressionist Mary Cassatt planned a journal of their original prints in the late 1870s, a project that nevertheless came to nothing when Degas withdrew. Art historian and the artist's great-grandson Joachim Pissarro notes that they \"professed a passionate disdain for the Salons and refused to exhibit at them.\" Together they shared an \"almost militant resolution\" against the Salon, and through their later correspondences it is clear that their mutual admiration \"was based on a kinship of ethical as well as aesthetic concerns\".\nCassatt had befriended Degas and Pissarro years earlier when she joined Pissarro's newly formed French Impressionist group and gave up opportunities to exhibit in the United States. She and Pissarro were often treated as \"two outsiders\" by the Salon since neither were French or had become French citizens. However, she was \"fired up with the cause\" of promoting Impressionism and looked forward to exhibiting \"out of solidarity with her new friends\". Towards the end of the 1890s she began to distance herself from the Impressionists, avoiding Degas at times as she did not have the strength to defend herself against his \"wicked tongue\". Instead, she came to prefer the company of \"the gentle Camille Pissarro\", with whom she could speak frankly about the changing attitudes toward art. She once described him as a teacher \"that could have taught the stones to draw correctly.\"\nOther mediums.\nPissarro was also known to experiment with lithographs, woodblock engravings, and original techniques in multicolor etching and monotype. Art historian Cora Michael notes that \u201cof the Impressionists, Pissarro was perhaps the one most devoted to printmaking and\u2026approached prints from the point of view of an avant-garde artist.\u201d In the 1880s to early 1890s, Pissarro returned to his studio in Pontoise, where he worked with many different print mediums to produce works such as \u201cVegetable Market at Pontoise\u201d and \u201cThe Road to Rouen: The Hills of Pontoise\".\nNeo-Impressionist period.\nBy the 1880s, Pissarro began to explore new themes and methods of painting to break out of what he felt was an artistic \"mire\". As a result, Pissarro went back to his earlier themes by painting the life of country people, which he had done in Venezuela in his youth. Degas described Pissarro's subjects as \"peasants working to make a living\".\nHowever, this period also marked the end of the Impressionist period due to Pissarro's leaving the movement. As Joachim Pissarro points out:\n\"Once such a die-hard Impressionist as Pissarro had turned his back on Impressionism, it was apparent that Impressionism had no chance of surviving\u00a0...\"\nIt was Pissarro's intention during this period to help \"educate the public\" by painting people at work or at home in realistic settings, without idealising their lives. Pierre-Auguste Renoir, in 1882, referred to Pissarro's work during this period as \"revolutionary,\" in his attempt to portray the \"common man.\" Pissarro himself did not use his art to overtly preach any kind of political message, however, although his preference for painting humble subjects was intended to be seen and purchased by his upper class clientele. He also began painting with a more unified brushwork along with pure strokes of color.\nStudying with Seurat and Signac.\nIn 1885 he met Georges Seurat and Paul Signac, both of whom relied on a more \"scientific\" theory of painting by using very small patches of pure colours to create the illusion of blended colours and shading when viewed from a distance. Pissarro then spent the years from 1885 to 1888 practising this more time-consuming and laborious technique, referred to as pointillism. The paintings that resulted were distinctly different from his Impressionist works, and were on display in the 1886 Impressionist Exhibition, but under a separate section, along with works by Seurat, Signac, and his son Lucien.\nAll four works were considered an \"exception\" to the eighth exhibition. Joachim Pissarro notes that virtually every reviewer who commented on Pissarro's work noted \"his extraordinary capacity to change his art, revise his position and take on new challenges.\" One critic writes:\nPissarro explained the new art form as a \"phase in the logical march of Impressionism\", but he was alone among the other Impressionists with this attitude, however. Joachim Pissarro states that Pissarro thereby became the \"only artist who went from Impressionism to Neo-Impressionism\".\nIn 1884, art dealer Theo van Gogh asked Pissarro if he would take in his older brother, Vincent, as a boarder in his home. Lucien Pissarro wrote that his father was impressed by Van Gogh's work and had \"foreseen the power of this artist\", who was 23 years younger. Although Van Gogh never boarded with him, Pissarro did explain to him the various ways of finding and expressing light and color, ideas which he later used in his paintings, notes Lucien.\nAbandoning Neo-Impressionism.\nPissarro eventually turned away from Neo-Impressionism, claiming its system was too artificial. He explains in a letter to a friend:\nHowever, after reverting to his earlier style, his work became, according to Rewald, \"more subtle, his color scheme more refined, his drawing firmer\u00a0... So it was that Pissarro approached old age with an increased mastery.\"\nBut the change also added to Pissarro's continual financial hardship which he felt until his 60s. His \"headstrong courage and a tenacity to undertake and sustain the career of an artist\", writes Joachim Pissarro, was due to his \"lack of fear of the immediate repercussions\" of his stylistic decisions. In addition, his work was strong enough to \"bolster his morale and keep him going\", he writes. His Impressionist contemporaries, however, continued to view his independence as a \"mark of integrity\", and they turned to him for advice, referring to him as \"P\u00e8re Pissarro\" (father Pissarro).\nLater years.\nIn his older age Pissarro suffered from a recurring eye infection that prevented him from working outdoors except in warm weather. As a result of this disability, he began painting outdoor scenes while sitting by the window of hotel rooms. He often chose hotel rooms on upper levels to get a broader view. He moved around northern France and painted from hotels in Rouen, Paris, Le Havre and Dieppe. On his visits to London, he would do the same.\nPissarro died in Paris on 13 November 1903 and was buried in P\u00e8re Lachaise Cemetery.\nLegacy and influence.\nDuring the period Pissarro exhibited his works, art critic Armand Silvestre had called Pissarro the \"most real and most naive member\" of the Impressionist group. His work has also been described by art historian Diane Kelder as expressing \"the same quiet dignity, sincerity, and durability that distinguished his person.\" She adds that \"no member of the group did more to mediate the internecine disputes that threatened at times to break it apart, and no one was a more diligent proselytizer of the new painting.\"\nAccording to Pissarro's son, Lucien, his father painted regularly with C\u00e9zanne beginning in 1872. He recalls that C\u00e9zanne walked a few miles to join Pissarro at various settings in Pontoise. While they shared ideas during their work, the younger C\u00e9zanne wanted to study the countryside through Pissarro's eyes, as he admired Pissarro's landscapes from the 1860s. C\u00e9zanne, although only nine years younger than Pissarro, said that \"he was a father for me. A man to consult and a little like the good Lord.\"\nLucien Pissarro was taught painting by his father, and described him as a \"splendid teacher, never imposing his personality on his pupil.\" Gauguin, who also studied under him, referred to Pissarro \"as a force with which future artists would have to reckon\". Art historian Diane Kelder notes that it was Pissarro who introduced Gauguin, who was then a young stockbroker studying to become an artist, to Degas and C\u00e9zanne. Gauguin, near the end of his career, wrote a letter to a friend in 1902, shortly before Pissarro's death:\nThe American impressionist Mary Cassatt, who at one point lived in Paris to study art, and joined his Impressionist group, noted that he was \"such a teacher that he could have taught the stones to draw correctly.\"\nCaribbean author and scholar Derek Walcott based his book-length poem, \"Tiepolo's Hound\" (2000), on Pissarro's life.\nCamille Pissarro is a pivotal character in the historical fiction novels, The Dream Collector, Books I &amp; II by R.w. Meek, depicting his major role among the Impressionists and his open-mindedness toward the Post-Impressionist art of George Seurat, Paul Gauguin and Vincent van Gogh.\nThe legacy of Nazi-looted Pissarros.\nDuring the early 1930s throughout Europe, Jewish owners of numerous fine art masterpieces found themselves forced to give up or sell off their collections for minimal prices due to anti-Jewish laws created by the new Nazi regime. Many Jews were forced to flee Germany starting in 1933, and then, as the Nazis expanded their hold over all of Europe, Austria, France, Holland, Poland, Italy and other countries. The Nazis created special looting organizations like the Reichsleiter Rosenberg Taskforce whose mission it was to seize Jewish property notably valuable artworks. When those forced into exile or deported to extermination camps owned valuables, including artwork, they were often sold to finance the Nazi war effort, sent to Hitler's personal museum, traded or seized by officials for personal gain. Several artworks by Pissarro were looted from their Jewish owners in Germany, France and elsewhere by the Nazis.\nPissarro's \"Shepherdess Bringing Home the Sheep\" (La Berg\u00e8re Rentrant des Moutons\") was looted from the Jewish art collectors Yvonne et Raoul Meyer in France in 1941 and transited via Switzerland and New York before entering the Fred Jones Jr Museum at the University of Oklahoma. In 2014, Meyer's daughter, L\u00e9onie-No\u00eblle Meyer filed a restitution claim which resulted in years of court battle. The lawsuit resulted in the recognition of Meyer's ownership and its transfer to France for five years, coupled with an agreement to shuttle the painting back and forth between Paris and Oklahoma every three years after that. However, in 2020 Meyer filed suit in a French court to challenge the accord. After Fred Jones Jr Museum sued Meyer requesting heavy financial penalties, the Holocaust survivor abandoned her effort to recover the Pissarro, saying, \"I have no other choice.\nPissarro's Picking Peas (La Cueillette) was looted from Jewish businessman Simon Bauer, in addition to 92 other artworks seized in 1943 by the Vichy collaborationist regime in France.\nPissarro's \"Sower And Ploughman\", was owned by Dr Henri Hinrichsen, a Jewish music publisher from Leipzig, until 11 January 1940, when he was forced to relinquish the painting to Hildebrand Gurlitt in Nazi-occupied Brussels, before being murdered in Auschwitz in September 1942.\nPissarro's \"Le Quai Malaquais, Printemps\", owned by German Jewish publisher Samuel Fischer, founder of the famous S. Fischer Verlag, passed through the hands of infamous Nazi art looter Bruno Lohse.\nPissarro's \"Le Boulevard de Montmartre, Matin\u00e9e de Printemps\", owned by Max Silberberg, a German Jewish industrialist whose renowned art collection was considered \"one of the best in pre-war Germany\", was seized and sold in a forced auction before Silberberg and his wife Johanna were murdered in Auschwitz.\nIn the decades after World War II, many art masterpieces were found on display in various galleries and museums in Europe and the United States, often with false provenances and labels missing. Some, as a result of legal action, were later returned to the families of the original owners. Many of the recovered paintings were then donated to the same or other museums as a gift.\nOne such lost piece, Pissarro's 1897 oil painting, \"Rue St. Honor\u00e9, Apres Midi, Effet de Pluie\", was discovered hanging at Madrid's government-owned museum, the Museo Thyssen-Bornemisza. In January 2011 the Spanish government denied a request by the US ambassador to return the painting. At the subsequent trial in Los Angeles, the court ruled that the Thyssen-Bornemisza Collection Foundation was the rightful owner. In 1999, Pissarro's 1897 \"Le Boulevard de Montmartre, Matin\u00e9e de Printemps\" appeared in the Israel Museum in Jerusalem, its donor having been unaware of its pre-war provenance. In January 2012, \"Le March\u00e9 aux Poissons\" (The Fish Market), a color monotype, was returned after 30 years.\nDuring his lifetime, Camille Pissarro sold few of his paintings. By the 21st century, however, his paintings were selling for millions. An auction record for the artist was set on 6 November 2007 at Christie's in New York, where a group of four paintings, \"Les Quatre Saisons\" (the Four Seasons), sold for $14,601,000 (estimate $12,000,000 \u2013 $18,000,000). In November 2009 \"Le Pont Boieldieu et la Gare d'Orl\u00e9ans, Rouen, Soleil\" sold for $7,026,500 at Sotheby's in New York.\nIn February 2014 the 1897 \"Le Boulevard de Montmartre, Matin\u00e9e de Printemps\", originally owned by the German industrialist and Holocaust victim Max Silberberg (), sold at Sotheby's in London for \u00a319.9M, nearly five times the previous record.\nIn October 2021 Berlin's Alte Nationalgalerie restituted Pissarro's \"A Square in La Roche-Guyon\" (1867) to the heirs of Armand Dorville, a French Jewish art collector whose family was persecuted by the Nazis and whose paintings had been sold at a 1942 auction in Nice that was overseen by the Commissariat G\u00e9n\u00e9ral aux Questions Juives. The museum then purchased the Pissarro back.\nA family of painters.\nCamille's son Lucien was an Impressionist and Neo-impressionist painter as were his second and third sons Georges Henri Manzana Pissarro and F\u00e9lix Pissarro. Lucien's daughter Orovida Pissarro was also a painter. Camille's great-grandson, Joachim Pissarro, became Head Curator of Drawing and Painting at the Museum of Modern Art in New York City and a professor in Hunter College's Art Department. Camille's great-granddaughter, L\u00e9lia Pissarro, has had her work exhibited alongside her great-grandfather. Another great-granddaughter, Julia Pissarro, a Barnard College graduate, is also active in the art scene. From the only daughter of Camille, Jeanne Pissarro, other painters include Henri Bonin-Pissarro (1918\u20132003) and Claude Bonin-Pissarro (born 1921), who is the father of the Abstract artist Fr\u00e9d\u00e9ric Bonin-Pissarro (born 1964).\nThe grandson of Camille Pissarro, Hugues Claude Pissarro (dit Pomi\u00e9), was born in 1935 in the western section of Paris, Neuilly-sur-Seine, and began to draw and paint as a young child under his father's tutelage. During his adolescence and early twenties he studied the works of the great masters at the Louvre. His work has been featured in exhibitions in Europe and the United States, and he was commissioned by the White House in 1959 to paint a portrait of U.S. President Dwight Eisenhower. He now lives and paints in Donegal, Ireland, with his wife Corinne also an accomplished artist and their children."}
{"id": "7435", "revid": "7758382", "url": "https://en.wikipedia.org/wiki?curid=7435", "title": "Cardiology diagnostic tests and procedures", "text": "The diagnostic tests in cardiology are methods of identifying heart conditions associated with healthy vs. unhealthy, pathologic heart function.\nBedside.\nHistory.\nObtaining a medical history is always the first \"test\", part of understanding the likelihood of significant disease, as detectable within the current limitations of clinical medicine. Yet heart problems often produce no symptoms until very advanced, and many symptoms, such as palpitations and sensations of extra or missing heart beats correlate poorly with relative heart health \"vs\" disease. Hence, a history alone is rarely sufficient to diagnose a heart condition.\nAuscultation.\n\"Auscultation\" employs a stethoscope to more easily hear various normal and abnormal sounds, such as normal heart beat sounds and the usual heart beat sound changes associated with breathing versus heart murmurs.\nLaboratory.\nBlood tests.\nA variety of \"blood tests\" are available for analyzing cholesterol transport behavior, HDL, LDL, triglycerides, lipoprotein little a, homocysteine, C-reactive protein, blood sugar control: fasting, after eating or averages using glycated albumen or hemoglobin, myoglobin, creatine kinase, troponin, brain-type natriuretic peptide, etc. to assess the evolution of coronary artery disease and evidence of existing damage. A great many more physiologic markers related to atherosclerosis and heart function are used and being developed and evaluated in research.\n(*) due to the high cost, LDL is usually calculated instead of being measured directly&lt;br&gt;\nsource: Beyond Cholesterol, Julius Torelli MD, 2005 \nElectrophysiology.\nElectrocardiogram.\n\"Electrocardiography\" (ECG/EKG in German vernacular. Elektrokardiogram) monitors electrical activity of the heart, primarily as recorded from the skin surface. A 12 lead recording, recording the electrical activity in three planes, anterior, posterior, and lateral is the most commonly used form. The ECG allows observation of the heart electrical activity by visualizing waveform beat origin (typically from the sinoatrial or SA node) following down the bundle of HIS and ultimately stimulating the ventricles to contract forcing blood through the body. Much can be learned by observing the QRS morphology (named for the respective portions of the polarization/repolarization waveform of the wave, P,Q,R,S,T wave). Rhythm abnormalities can also be visualized as in slow heart rate bradycardia, or fast heart rate tachycardia.\nFasegram.\nA \"Fasegraphy\" allows expanding the system of Electrocardiography diagnostic features, based on the evaluation of the speed characteristics of the process, and thereby increasing the sensitivity and specificity of ECG-diagnostics.\nFasegraphy allows determining the initial features of changes in the cardiac muscle, even on a single-channel ECG, which are underestimated in traditional ECG diagnostics.\nHolter monitor.\nA \"Holter monitor\" records a continuous EKG rhythm pattern (rarely a full EKG) for 24\u00a0hours or more. These monitors are used for suspected frequent rhythm abnormalities, especially ones the wearer may not recognize by symptoms. They are more expensive than event monitors.\nEvent monitor.\nAn \"event monitor\" records short term EKG rhythm patterns, generally storing the last 2 to 5\u00a0minutes, adding in new and discarding old data, for 1 to 2 weeks or more. There are several different types with different capabilities. When the wearer presses a button on the monitor, it quits discarding old and continues recording for a short additional period. The wearer then plays the recording, via a standard phone connection, to a center with compatible receiving and rhythm printing equipment, after which the monitor is ready to record again. These monitors are used for suspected infrequent rhythm abnormalities, especially ones the wearer does recognize by symptoms. They are less expensive than Holter monitors.\nCardiac stress testing.\n\"Cardiac stress testing\" is used to determine to assess cardiac function and to disclose evidence of exertion-related cardiac hypoxia. Radionuclide testing using thallium or technetium can be used to demonstrate areas of perfusion abnormalities. With a maximal stress test the level of exercise is increased until the person's heart rate will not increase any higher, despite increased exercise. A fairly accurate estimate of the target heart rate, based on extensive clinical research, can be estimated by the formula 220 beats per minute minus patient's age. This linear relation is accurate up to about age 30, after which it mildly underestimates typical maximum attainable heart rates achievable by healthy individuals. Other formulas exist, such as that by Miller (217 - (0.85 \u00d7 Age)) and others. Achieving a high enough heart rate at the end of exercise is critical to improving the sensitivity of the test to detect high grade heart artery stenosis. High frequency analysis of the QRS complex may be useful for detection of coronary artery disease during an exercise stress test.\nElectrophysiology study.\nThe electrophysiology study or EP study is the end all of electrophysiological tests of the heart. It involves a catheter with electrodes probing the endocardium, the inside of the heart, and testing the conduction pathways and electrical activity of individual areas of the heart.\nMedical imaging.\nCardiac imaging techniques include coronary catheterization, echocardiogram, intravascular ultrasound, retinal vessel analysis and the coronary calcium scan."}
{"id": "7437", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=7437", "title": "Carlo Collodi", "text": "Carlo Lorenzini (; 24 November 1826 \u2013 26 October 1890), better known by the pen name Carlo Collodi ( ; ), was an Italian author, humourist, and journalist, widely known for his fairy tale novel \"The Adventures of Pinocchio\".\nEarly life.\nCollodi was born in Florence on 24 November 1826. His mother Angiolina Orzali Lorenzini was a seamstress from Collodi, the town from which he later took the pen name, and his father Domenico Lorenzini was a cook. Both parents worked for the ' Ginori Lisci. Carlo was the eldest child in the family and he had ten siblings; seven died at a young age. He spent most of his childhood in the town of Collodi where his mother was born. He lived there with his maternal grandmother. After attending primary school, he was sent to study at a theological seminary in Colle Val d'Elsa. An account at the seminary shows that the ' had offered financial aid, but the boy found that he did not want to be a priest so he continued his education at the College of the Scolopi Fathers in Florence. In 1844, he started working at the Florentine bookstore Libreria Piatti, where he assisted Giuseppe Aiazzi, a prominent Italian manuscript specialist.\nCareer.\nDuring the Italian Wars of Independence in 1848 and 1860, Collodi served as a volunteer with the Tuscan Army. His active interest in political matters can be seen in his earliest literary works, as well as in the founding of the satirical newspaper in 1853. This newspaper was censored by order of the Grand Duke of Tuscany. In 1854, he published his second newspaper, ' (\"The Controversy\"). Lorenzini's first publications were in his periodicals. A debut came in 1856 with the play ' and parodic guidebook , both in 1856. By 1860, he published his first notable work called \"\" (Mr. Alberi Is Right!), which outlined his political and cultural vision of Italy. This is the text where Lorenzini started using the Collodi pseudonym, which was taken from his mother's hometown.\nCollodi had also begun intense activity on other political newspapers such as '; at the same time he was employed by the Censorship Commission for the Theatre. During this period he composed various satirical sketches and stories (sometimes simply by collating earlier articles), including ' (1880), ' (1881), and ' (1887).\nCollodi became disenchanted with Italian politics afterwards, so he turned to children's literature and his first works involved translating French fairy tales into Italian. In 1875, for instance, he completed ', a translation of French fairy tales by Charles Perrault. In 1876, Collodi wrote ' (inspired by Alessandro Luigi Parravicini's \"Giannetto\"), the ', and ', a pedagogic series which explored the unification of Italy through the ironic thoughts and actions of the character Giannettino.\nLorenzini became fascinated by the idea of using an amiable, rascally character as a means of expressing his own convictions through allegory. In 1880, he began writing ' (\"Story of a Marionette\"), also called \"Le avventure di Pinocchio\", which was published weekly in '. \"Pinocchio\" was adapted into a 1940 film by Disney that is considered to be one of Disney's greatest films.\nCollodi died suddenly in Florence on 26 October 1890 at the age of 63 and is interred at Cimitero Monumentale Delle Porte Sante in Florence. The National Carlo Collodi Foundation was established in 1962 to promote education and the works of Collodi, and Pinocchio Park, which was opened in 1956 in the town of Collodi and remains a popular attraction today."}
{"id": "7439", "revid": "44862818", "url": "https://en.wikipedia.org/wiki?curid=7439", "title": "Constructible number", "text": "In geometry and algebra, a real number formula_1 is constructible if and only if, given a line segment of unit length, a line segment of length formula_2 can be constructed with compass and straightedge in a finite number of steps. Equivalently, formula_1 is constructible if and only if there is a closed-form expression for formula_1 using only integers and the operations for addition, subtraction, multiplication, division, and square roots.\nThe geometric definition of constructible numbers motivates a corresponding definition of constructible points, which can again be described either geometrically or algebraically. A point is constructible if it can be produced as one of the points of a compass and straightedge construction (an endpoint of a line segment or crossing point of two lines or circles), starting from a given unit length segment. Alternatively and equivalently, taking the two endpoints of the given segment to be the points (0, 0) and (1, 0) of a Cartesian coordinate system, a point is constructible if and only if its Cartesian coordinates are both constructible numbers. Constructible numbers and points have also been called ruler and compass numbers and ruler and compass points, to distinguish them from numbers and points that may be constructed using other processes.\nThe set of constructible numbers forms a field: applying any of the four basic arithmetic operations to members of this set produces another constructible number. This field is a field extension of the rational numbers and in turn is contained in the field of algebraic numbers. It is the Euclidean closure of the rational numbers, the smallest field extension of the rationals that includes the square roots of all of its positive numbers.\nThe proof of the equivalence between the algebraic and geometric definitions of constructible numbers has the effect of transforming geometric questions about compass and straightedge constructions into algebra, including several famous problems from ancient Greek mathematics. The algebraic formulation of these questions led to proofs that their solutions are not constructible, after the geometric formulation of the same problems previously defied centuries of attack.\nGeometric definitions.\nGeometrically constructible points.\nLet formula_5 and formula_6 be two given distinct points in the Euclidean plane, and define formula_7 to be the set of points that can be constructed with compass and straightedge starting with formula_5 and formula_6. Then the points of formula_7 are called constructible points. formula_5 and formula_6 are, by definition, elements of formula_7. To more precisely describe the remaining elements of formula_7, make the following two definitions:\nThen, the points of formula_7, besides formula_5 and formula_6 are:\nAs an example, the midpoint of constructed segment formula_22 is a constructible point. One construction for it is to construct two circles with formula_22 as radius, and the line through the two crossing points of these two circles. Then the midpoint of segment formula_22 is the point where this segment is crossed by the constructed line.\nGeometrically constructible numbers.\nThe starting information for the geometric formulation can be used to define a Cartesian coordinate system in which the point formula_5 is associated to the origin having coordinates formula_26 and in which the point formula_6 is associated with the coordinates formula_28. The points of formula_7 may now be used to link the geometry and algebra by defining a constructible number to be a coordinate of a constructible point.\nEquivalent definitions are that a constructible number is the formula_30-coordinate of a constructible point formula_31 or the length of a constructible line segment. In one direction of this equivalence, if a constructible point has coordinates formula_32, then the point formula_31 can be constructed as its perpendicular projection onto the formula_30-axis, and the segment from the origin to this point has length formula_30. In the reverse direction, if formula_30 is the length of a constructible line segment, then intersecting the formula_30-axis with a circle centered at formula_5 with radius formula_30 gives the point formula_31. It follows from this equivalence that every point whose Cartesian coordinates are geometrically constructible numbers is itself a geometrically constructible point. For, when formula_30 and formula_42 are geometrically constructible numbers, point formula_32 can be constructed as the intersection of lines through formula_31 and formula_45, perpendicular to the coordinate axes.\nAlgebraic definitions.\nAlgebraically constructible numbers.\nThe algebraically constructible real numbers are the subset of the real numbers that can be described by formulas that combine integers using the operations of addition, subtraction, multiplication, multiplicative inverse, and square roots of positive numbers. Even more simply, at the expense of making these formulas longer, the integers in these formulas can be restricted to be only 0 and 1. For instance, the square root of 2 is constructible, because it can be described by the formulas formula_46 or formula_47.\nAnalogously, the algebraically constructible complex numbers are the subset of complex numbers that have formulas of the same type, using a more general version of the square root that is not restricted to positive numbers but can instead take arbitrary complex numbers as its argument, and produces the principal square root of its argument. Alternatively, the same system of complex numbers may be defined as the complex numbers whose real and imaginary parts are both constructible real numbers. For instance, the complex number formula_48 has the formulas formula_49 or formula_50, and its real and imaginary parts are the constructible numbers 0 and 1 respectively.\nThese two definitions of the constructible complex numbers are equivalent. In one direction, if formula_51 is a complex number whose real part formula_30 and imaginary part formula_42 are both constructible real numbers, then replacing formula_30 and formula_42 by their formulas within the larger formula formula_56 produces a formula for formula_57 as a complex number. In the other direction, any formula for an algebraically constructible complex number can be transformed into formulas for its real and imaginary parts, by recursively expanding each operation in the formula into operations on the real and imaginary parts of its arguments, using the expansions\nAlgebraically constructible points.\nThe algebraically constructible points may be defined as the points whose two real Cartesian coordinates are both algebraically constructible real numbers. Alternatively, they may be defined as the points in the complex plane given by algebraically constructible complex numbers. By the equivalence between the two definitions for algebraically constructible complex numbers, these two definitions of algebraically constructible points are also equivalent.\nEquivalence of algebraic and geometric definitions.\nIf formula_64 and formula_65 are the non-zero lengths of geometrically constructed segments then elementary compass and straightedge constructions can be used to obtain constructed segments of lengths formula_66, formula_67, formula_68, and formula_69. The latter two can be done with a construction based on the intercept theorem. A slightly less elementary construction using these tools is based on the geometric mean theorem and will construct a segment of length formula_70 from a constructed segment of length formula_64. It follows that every algebraically constructible number is geometrically constructible, by using these techniques to translate a formula for the number into a construction for the number.\nIn the other direction, a set of geometric objects may be specified by algebraically constructible real numbers: coordinates for points, slope and formula_42-intercept for lines, and center and radius for circles. It is possible (but tedious) to develop formulas in terms of these values, using only arithmetic and square roots, for each additional object that might be added in a single step of a compass-and-straightedge construction. It follows from these formulas that every geometrically constructible number is algebraically constructible.\nAlgebraic properties.\nThe definition of algebraically constructible numbers includes the sum, difference, product, and multiplicative inverse of any of these numbers, the same operations that define a field in abstract algebra. Thus, the constructible numbers (defined in any of the above ways) form a field. More specifically, the constructible real numbers form a Euclidean field, an ordered field containing a square root of each of its positive elements. Examining the properties of this field and its subfields leads to necessary conditions on a number to be constructible, that can be used to show that specific numbers arising in classical geometric construction problems are not constructible.\nIt is convenient to consider, in place of the whole field of constructible numbers, the subfield formula_73 generated by any given constructible number formula_74, and to use the algebraic construction of formula_74 to decompose this field. If formula_74 is a constructible real number, then the values occurring within a formula constructing it can be used to produce a finite sequence of real numbers formula_77 such that, for each formula_48, formula_79 is an extension of formula_80 of degree 2. Using slightly different terminology, a real number is constructible if and only if it lies in a field at the top of a finite tower of real quadratic extensions,\nformula_81\nstarting with the rational field formula_82 where formula_74 is in formula_84 and for all formula_85, formula_86. It follows from this decomposition that the degree of the field extension formula_87 is formula_88, where formula_1 counts the number of quadratic extension steps.\nAnalogously to the real case, a complex number is constructible if and only if it lies in a field at the top of a finite tower of complex quadratic extensions. More precisely, formula_74 is constructible if and only if there exists a tower of fields\nformula_91\nwhere formula_74 is in formula_93, and for all formula_94, formula_95. The difference between this characterization and that of the real constructible numbers is only that the fields in this tower are not restricted to being real. Consequently, if a complex number a complex number formula_74 is constructible, then the above characterization implies that formula_87 is a power of two. However, this condition is not sufficient - there exist field extensions whose degree is a power of two, but which cannot be factored into a sequence of quadratic extensions. \nTo obtain a sufficient condition for constructibility, one must instead consider the splitting field formula_98 obtained by adjoining all roots of the minimal polynomial of formula_74. If the degree of extension is a power of two, then its Galois group formula_100 is a 2-group, and thus admits a descending sequence of subgroups\nformula_101\nwith formula_102 for formula_103 By the fundamental theorem of Galois theory, there is a corresponding tower of quadratic extensions\nformula_104\nwhose topmost field contains formula_105 and from this it follows that formula_74 is constructible.\nThe fields that can be generated from towers of quadratic extensions of formula_82 are called \"\" of formula_82. The fields of real and complex constructible numbers are the unions of all real or complex iterated quadratic extensions of formula_82.\nTrigonometric numbers.\nTrigonometric numbers are the cosines or sines of angles that are rational multiples of formula_110. These numbers are always algebraic, but they may not be constructible. The cosine or sine of the angle formula_111 is constructible only for certain special numbers formula_112:\nThus, for example, formula_113 is constructible because 15 is the product of the Fermat primes 3 and 5; but formula_114 is not constructible (not being the product of Fermat primes) and neither is formula_115 (being a non-Fermat prime).\nImpossible constructions.\nThe ancient Greeks thought that certain problems of straightedge and compass construction they could not solve were simply obstinate, not unsolvable. However, the non-constructibility of certain numbers proves that these constructions are logically impossible to perform. (The problems themselves, however, are solvable using methods that go beyond the constraint of working only with straightedge and compass, and the Greeks knew how to solve them in this way. One such example is Archimedes' Neusis construction solution of the problem of Angle trisection.)\nIn particular, the algebraic formulation of constructible numbers leads to a proof of the impossibility of the following construction problems:\nHistory.\nThe birth of the concept of constructible numbers is inextricably linked with the history of the three impossible compass and straightedge constructions: doubling the cube, trisecting an angle, and squaring the circle. The restriction of using only compass and straightedge in geometric constructions is often credited to Plato due to a passage in Plutarch. According to Plutarch, Plato gave the duplication of the cube (Delian) problem to Eudoxus and Archytas and Menaechmus, who solved the problem using mechanical means, earning a rebuke from Plato for not solving the problem using pure geometry. However, this attribution is challenged, due, in part, to the existence of another version of the story (attributed to Eratosthenes by Eutocius of Ascalon) that says that all three found solutions but they were too abstract to be of practical value. Proclus, citing Eudemus of Rhodes, credited Oenopides ( 450 BCE) with two ruler and compass constructions, leading some authors to hypothesize that Oenopides originated the restriction. The restriction to compass and straightedge is essential to the impossibility of the classic construction problems. Angle trisection, for instance, can be done in many ways, several known to the ancient Greeks. The Quadratrix of Hippias of Elis, the conics of Menaechmus, or the marked straightedge (neusis) construction of Archimedes have all been used, as has a more modern approach via paper folding.\nAlthough not one of the classic three construction problems, the problem of constructing regular polygons with straightedge and compass is often treated alongside them. The Greeks knew how to construct regular with formula_146 (for any integer formula_147), 3, 5, or the product of any two or three of these numbers, but other regular eluded them. In 1796 Carl Friedrich Gauss, then an eighteen-year-old student, announced in a newspaper that he had constructed a regular 17-gon with straightedge and compass. Gauss's treatment was algebraic rather than geometric; in fact, he did not actually construct the polygon, but rather showed that the cosine of a central angle was a constructible number. The argument was generalized in his 1801 book \"Disquisitiones Arithmeticae\" giving the condition for the construction of a regular Gauss claimed, but did not prove, that the condition was also necessary and several authors, notably Felix Klein, attributed this part of the proof to him as well. Alhazen's problem is also not one of the classic three problems, but despite being named after Ibn al-Haytham (Alhazen), a medieval Islamic mathematician, it already appears in Ptolemy's work on optics from the second century.\nPierre Wantzel proved algebraically that the problems of doubling the cube and trisecting the angle are impossible to solve using only compass and straightedge. In the same paper he also solved the problem of determining which regular polygons are constructible:\na regular polygon is constructible if and only if the number of its sides is the product of a power of two and any number of distinct Fermat primes (i.e., the sufficient conditions given by Gauss are also necessary). An attempted proof of the impossibility of squaring the circle was given by James Gregory in \"\" (The True Squaring of the Circle and of the Hyperbola) in 1667. Although his proof was faulty, it was the first paper to attempt to solve the problem using algebraic properties of . It was not until 1882 that Ferdinand von Lindemann rigorously proved its impossibility, by extending the work of Charles Hermite and proving that is a transcendental number. Alhazen's problem was not proved impossible to solve by compass and straightedge until the work of Jack Elkin.\nThe study of constructible numbers, per se, was initiated by Ren\u00e9 Descartes in La G\u00e9om\u00e9trie, an appendix to his book \"Discourse on the Method\" published in 1637. Descartes associated numbers to geometrical line segments in order to display the power of his philosophical method by solving an ancient straightedge and compass construction problem put forth by Pappus."}
{"id": "7441", "revid": "794857", "url": "https://en.wikipedia.org/wiki?curid=7441", "title": "Carson City, Nevada", "text": "Carson City, officially the Consolidated Municipality of Carson City, is an independent city and the capital of the U.S. state of Nevada. As of the 2020 census, the population was 58,639, making it the 6th most populous city in the state. The majority of the city's population lives in Eagle Valley, on the eastern edge of the Carson Range, a branch of the Sierra Nevada, about south of Reno. The city is named after the mountain man Kit Carson (1809-1868). The town began as a stopover for California-bound immigrants, but developed into a city with the Comstock Lode, a silver strike in the mountains to the northeast. The city has served as Nevada's capital since statehood in 1864; for much of its history it was a hub for the Virginia and Truckee Railroad, although the tracks were removed in 1950.\nBefore 1969, Carson City was the county seat of Ormsby County. That year, after a referendum approved merging the city and the county, the state legislature issued a revised city charter that merged them into the Consolidated Municipality of Carson City. With the consolidation, the city limits extend west across the Sierra Nevada to the California-Nevada state line in the middle of Lake Tahoe. Like other independent cities in the United States, it is treated as a county-equivalent for census purposes.\nHistory.\nThe Washoe people have inhabited the valley and surrounding areas for about 6,000 years.\nThe first European Americans to arrive in what is now known as Eagle Valley were John C. Fr\u00e9mont and his exploration party in January 1843. Fremont named the river flowing through the valley Carson River in honor of Kit Carson,(1809-1868), the mountain man, explorer and scout he had hired for his expedition. Later, settlers named the area Washoe, in reference to the indigenous people.\nBy 1851, the Eagle Station ranch along the Carson River was a trading post and stop-over for westbound travelers and wagons on the California Trail's Carson Branch, which ran through Eagle Valley. The valley and trading post received their name from a bald eagle that was hunted and killed by one of the early settlers and was featured pinned on a wall inside the post.\nAs the area was part of the larger Utah Territory (1850-1896), it was governed from the territorial (and later state) capital of Salt Lake City on the eastern shore of the Great Salt Lake, where the territorial government was headquartered there several hundred miles further east with Mormon (The Church of Jesus Christ of Latter-day Saints) patriarch of Brigham Young (1801-1877), as first Governor of Utah. Early settlers bristled at the control by Mormon-influenced officials and desired the creation of the provisional Nevada Territory with Isaac Roop (1822-1869, served 1859-1861), as provisional Governor. A vigilante group of influential settlers, headed by Abraham Curry (1815-1873), sought a site for a capital city for the envisioned future separate territory. In 1858, Abraham Curry bought Eagle Station and the settlement was thereafter renamed Carson City. Curry and several other partners had Eagle Valley surveyed for development. Curry decided Carson City would someday serve as the capital city and left a plot in the center of town for a capitol building.\nAfter gold and silver ore were discovered in 1859 on the nearby newly-named Comstock Lode, Carson City's population began to grow. Curry built the Warm Springs Hotel a mile to the east of the town center. When new territorial governor James W. Nye (1815-1876, served 1861-1864), traveled east to Nevada, he chose Carson City as the territorial capital instead of earlier Genoa, which had functioned temporarily as such for the past few years. Influenced by Carson City lawyer William M. Stewart (1827-1909), who escorted him from the port of San Francisco, California where he arrived onboard a passenger steamboat liner, then journeying uphill past Sacramento to Nevada. As such, Carson City bested Virginia City and American Flat. Curry loaned the Warm Springs Hotel to the territorial Legislature as a temporary meeting hall. The Legislature named Carson City to be the county seat of Ormsby County and also selected the hotel as the territorial prison, with Curry serving as its first warden. Today, the property is still part of the state prison.\nWhen Nevada became the 36th state in 1864 during the American Civil War (1861-1865), Carson City was confirmed as Nevada's permanent state capital. Carson City's development was no longer dependent on the mining industry and instead became a thriving commercial center. The Virginia and Truckee Railroad was built between Virginia City and Carson City. A log flume was also built from the Sierra Nevada mountains range into Carson City. The current Nevada State Capitol building was constructed from 1869 to 1871. The United States Mint also operated its branch of the Carson City Mint between the years of 1870 and 1893, which struck gold and silver coins of United States currency. People came from China during that time, many to work on the transcontinental railroad being constructed. Some of them owned businesses and taught school. By 1880, almost a thousand Chinese people, \"one for every five Caucasians\", lived in Carson City.\nCarson City's population and transportation traffic decreased when the Central Pacific Railroad built a branch line through Donner Pass to connect with the Carson and Colorado Railroad. The new branch also bypassed the Virginia &amp; Truckee line, and ran too far to the north to benefit Carson City. The city was slightly revitalized with the mining booms in nearby Tonopah and Goldfield. The United States federal building (now renamed the Paul Laxalt Building) was completed in 1890 as was the Stewart Indian School. Even these developments could not prevent its population from dropping to just over 1,500 people by 1930. Carson City resigned itself to small city status, advertising itself as \"America's smallest capital\". The city slowly grew after World War II (1939/1941-1945); by 1960, it had reached its former 1880 mining boom-town era population size of 80 years before.\n20th-century revitalization and growth.\nAs early as the late 1940s, discussions began about merging Ormsby County and Carson City. By this time, the county was little more than Carson City and a few hamlets to the west. By the 1960 census, all but 2,900 of the county's residents lived in Carson City. However, the effort did not pay off until 1966, when a statewide referendum approved the merger. The required constitutional amendment was passed in 1968. On April 1, 1969, Ormsby County and Carson City officially merged as the Consolidated Municipality of Carson City. With this consolidation, Carson City absorbed former town sites such as Empire City, which had grown up in the 1860s as a milling center along the Carson River and current U.S. Route 50. Carson City could now advertise itself as one of America's largest state capitals with its of city limits.\nIn 1991, the city adopted a downtown master plan, specifying no building within of the capitol would surpass it in height. This plan effectively prohibited future high-rise development in the center of downtown. The Ormsby House is the tallest building in downtown Carson City, at a height of . The structure was completed in 1972.\nGeography.\nMost of the city proper resides in the Eagle Valley. The Carson River flows from Douglas County through the southwestern edge of both the valley and Carson City. Since the consolidation, the city limits today include several small populated areas outside of this valley. Today the city limits include several peaks in the Sierra Nevada, small portions of both the Virginia Range and the Pine Nut Mountains and portions of Marlette Lake and Lake Tahoe. The highest elevation in city limits is Snow Valley Peak at an elevation of . Carson City is one of two state capitals that border another state, the other being Trenton, New Jersey.\nClimate.\nCarson City features a cold semi-arid climate (K\u00f6ppen: \"BSk\", Trewartha: \"BSak\") with cold winters and hot summers. The city is in a high desert river valley approximately above sea level. There are four fairly distinct seasons. Winters see typically light to moderate snowfall, with an average of , with the most snowfall being from July 1951 to June 1952 and the least from July 2002 to June 2003. Most precipitation occurs in winter and spring, with summer and fall being fairly dry, drier than neighboring California. The wettest \u201crain year\u201d was from July 1937 to June 1938 with and the driest from July 1971 to June 1972 with . The most precipitation in one month occurred in December 1955 when fell and the most snowfall in March 1952. The most precipitation in one day has been on November 19 of 1950.\nThere are 39.5 afternoons of + highs annually, with + temperatures occurring 1.2 afternoons per year. The hottest month has been July 2021 with an average of , the hottest temperature on July 19, 1931, and the highest minimum on August 1, 2022.\nThere are 125 mornings with lows below freezing, but afternoon maxima top on all but 52 days, and top freezing on all but five. Temperatures below are very rare, occurring about twice per winter and frequently not occurring at all. The coldest temperature in Carson City has been on January 21, 1937, the lowest maximum on December 12, 1932, and December 22, 1990, and the coldest month January 1949 with a mean temperature of , although January 1937 at is the only other month below .\nThe average temperature in Carson City increased by between 1984 and 2014, a greater change than in any other city in the United States.\nDemographics.\nCarson City is the smallest of the United States' 366 metropolitan statistical areas.\nAs of the 2010 census, there were 55,274 people, 20,171 households, and 13,252 families residing in the city. The population density was . There were 21,283 housing units at an average density of . The racial makeup of the city was 81.1% White, 1.9% Black or African American, 2.4% Native American, 2.1% Asian, 0.2% Pacific Islander, 9.4% from other races, and 2.9% from two or more races. 21% of the population were Hispanic or Latino of any race.\nAs of the 2000 census, there were 20,171 households, out of which 29.8% had children under the age of 18 living with them, 50.0% were married couples living together, 11.0% had a female householder with no husband present, and 34.3% were non-families. 27.8% of all households were made up of individuals, and 11.00% had someone living alone who was 65\u00a0years of age or older. The average household size was 2.44 and the average family size was 2.97. The city's age distribution was: 23.4% under the age of 18, 7.9% from 18 to 24, 28.9% from 25 to 44, 24.9% from 45 to 64, and 14.9% who were 65\u00a0years of age or older. The median age was 39\u00a0years. For every 100 females, there were 106.9 males. For every 100 females age 18 and over, there were 108.2 males.\nData from the 2000 census indicates the median income for a household in the city was $41,809, and the median income for a family was $49,570. Males had a median income of $35,296 versus $27,418 for females. The per capita income for the city was $20,943. 10.0% of the population and 6.9% of families were below the poverty line. Out of the total population, 13.7% of those under the age of 18 and 5.8% of those 65 and older were living below the poverty line.\nLanguages.\nAs of 2010, 82.3% (42,697) of Carson City residents age 5 and older spoke English at home as a first language, while 14.1% (7,325) spoke Spanish, 0.6% (318) French, and numerous Indo-Aryan languages were spoken as a main language by 0.5% (261) of the population over the age of five. In total, 17.7% (9,174) of Carson City's population age 5 and older spoke a first language other than English.\nGovernment and politics.\nOrmsby County consolidated with Carson City in 1969, and the county simultaneously dissolved. The city is now governed by a five-member board of supervisors, consisting of a mayor and four supervisors. All members are elected at-large, but each of the four supervisors must reside in respective wards, numbered 1 through 4. The mayor and supervisors serve four year terms. Elections are staggered so the mayor and the supervisors from Wards 2 and Ward 4 are elected in presidential election years, and the supervisors from Wards 1 and 3 are elected in the even-numbered years in between (i.e., the same year as gubernatorial elections).\nThe city is generally considered a Republican stronghold, often voting for Republicans by wide margins. In 2004, George W. Bush defeated John Kerry 57\u201340%. In 2008, however, Barack Obama became the first Democrat since 1964 to win Ormsby County/Carson City, defeating John McCain 49\u201348%, by 204 votes, a margin of under 1%.\nCarson City, being the state capital, has seen many political protests and demonstrations.\nIn an attempt to either make a proposed spent nuclear fuel storage facility at Yucca Mountain prohibitively expensive (by raising property tax rates to the maximum allowed) or to allow the state to collect the potential federal payments of property taxes on the facility, the state government in 1987 carved Yucca Mountain out of Nye County and created a new county with no residents out of the area surrounding Yucca called Bullfrog County. Carson City became the county seat of Bullfrog County, even though it was not in Bullfrog County and is more than from Yucca Mountain. A state judge found the process unconstitutional in 1989, and Bullfrog County's territory was retroceded to Nye County.\nCulture.\nSports and recreation.\nCarson City has never hosted any professional team sports. However, a variety of sports are offered at parks and recreation. Many neighborhood parks offer a wide variety of features including picnic tables, beaches, restrooms, fishing, softball, basketball hoops, ponds, tennis, and volleyball. The largest park is Mills Park, which has a total land area of and includes the narrow-gauge Carson &amp; Mills Park Railroad.\nWhile there are no ski slopes within Carson City, the city is near the Heavenly Mountain Resort, Diamond Peak and Mount Rose Ski Tahoe skiing areas.\nNotable people.\nCarson City has served as one of the state's centers for politics and business. Every state governor since Denver S. Dickerson has resided in the Governor's Mansion in Carson City. The following personalities took up residence in Carson City at some point in their lives.\nEconomy and infrastructure.\nThe following is a list of notable employers in Carson City from the fourth quarter of 2012:\n1,000\u20131,499 employees\n500\u2013999 employees\n200\u2013499 employees\n100\u2013199 employees\nTransportation.\nThere are four highways in the city: Nevada State Route 28, U.S. Route 395, U.S. Route 50, and Interstate 580, its only freeway. Phase 1 of the Carson City Freeway Project from US 395, just north of the city, to US 50 was completed in February 2006, and Phase 2A, extending from Rt. 50 to Fairview Drive, was officially opened on September 24, 2009. Phase 2B, Fairview Drive to Rt. 50, was completed in August 2017. Prior to 2012, Carson City was one of only five state capitals not directly served by an interstate highway; the city lost this distinction when I-580 was extended into the city limits.\nCarson City's first modern bus system, Jump Around Carson, or JAC, opened to the public in October 2005. JAC uses a smaller urban bus ideal for Carson City. Tahoe Transportation District connects Gardnerville with Carson City.\nHowever, there is virtually no ground public transportation to other destinations. Passenger trains have not served Carson City since 1950, when the Virginia and Truckee Railroad was shut down. Greyhound Lines stopped their bus services to the town in 2006 and Amtrak discontinued their connecting thruway bus to Sacramento, California, in 2008. There is now only a limited Monday \u2013 Friday RTC bus service, to Reno which is still served by both Greyhound and Amtrak, as well as Eastern Sierra Transit Authority service from Lone Pine to Reno.\nCarson City is also served by the Carson Airport, which is a regional airport in the northern part of the city. Reno\u2013Tahoe International Airport, which is away, handles domestic commercial flights.\nEducation.\nThe Carson City School District, the sole public school district of the city, operates ten schools there. The six elementary schools are Bordewich-Bray Elementary School, Empire Elementary School, Fremont Elementary School, Fritsch Elementary School, Mark Twain Elementary School, and Al Seeliger Elementary School. The two middle schools are Carson Middle School and Eagle Valley Middle School. Carson High School and the alternative Pioneer High School serve high school students. Carson High is on Saliman Road.\nThe district sponsors Carson Montessori School, a public charter school serving grades K-6. Students residing in any Nevada county may enroll. Carson Montessori School is the only school in district operating with a balanced budget. In 2019 Carson Montessori School received the Governor's STEM Schools Designation, an official recognition given to 25 schools statewide which causes a short ceremony attended by the governor during which receiving schools are assigned a 10-foot banner.\nWestern Nevada College (WNC) is a regionally accredited, two-year and four-year institution which is part of the Nevada System of Higher Education. The college offers many programs including education, arts and science.\nCarson City has a public library, the Carson City Library."}
{"id": "7442", "revid": "8259432", "url": "https://en.wikipedia.org/wiki?curid=7442", "title": "Clark Kent", "text": ""}
{"id": "7445", "revid": "49920", "url": "https://en.wikipedia.org/wiki?curid=7445", "title": "Classification of finite simple groups", "text": "In mathematics, the classification of finite simple groups (popularly called the enormous theorem) is a result of group theory stating that every finite simple group is either cyclic, or alternating, or belongs to a broad infinite class called the groups of Lie type, or else it is one of twenty-six exceptions, called sporadic (the Tits group is sometimes regarded as a sporadic group because it is not strictly a group of Lie type, in which case there would be 27 sporadic groups). The proof consists of tens of thousands of pages in several hundred journal articles written by about 100 authors, published mostly between 1955 and 2004. \nSimple groups can be seen as the basic building blocks of all finite groups, reminiscent of the way the prime numbers are the basic building blocks of the natural numbers. The Jordan\u2013H\u00f6lder theorem is a more precise way of stating this fact about finite groups. However, a significant difference from integer factorization is that such \"building blocks\" do not necessarily determine a unique group, since there might be many non-isomorphic groups with the same composition series or, put in another way, the extension problem does not have a unique solution.\nDaniel Gorenstein (1923-1992), Richard Lyons, and Ronald Solomon are gradually publishing a simplified and revised version of the proof.\nStatement of the classification theorem.\nThe classification theorem has applications in many branches of mathematics, as questions about the structure of finite groups (and their action on other mathematical objects) can sometimes be reduced to questions about finite simple groups. Thanks to the classification theorem, such questions can sometimes be answered by checking each family of simple groups and each sporadic group.\nDaniel Gorenstein announced in 1983 that the finite simple groups had all been classified, but this was premature as he had been misinformed about the proof of the classification of quasithin groups. The completed proof of the classification was announced by after Aschbacher and Smith published a 1221-page proof for the missing quasithin case.\nOverview of the proof of the classification theorem.\n wrote two volumes outlining the low rank and odd characteristic part of the proof, and \nwrote a 3rd volume covering the remaining characteristic 2 case. The proof can be broken up into several major pieces as follows:\nGroups of small 2-rank.\nThe simple groups of low 2-rank are mostly groups of Lie type of small rank over fields of odd characteristic, together with five alternating and seven characteristic 2 type and nine sporadic groups.\nThe simple groups of small 2-rank include:\nThe classification of groups of small 2-rank, especially ranks at most 2, makes heavy use of ordinary and modular character theory, which is almost never directly used elsewhere in the classification.\nAll groups not of small 2 rank can be split into two major classes: groups of component type and groups of characteristic 2 type. This is because if a group has sectional 2-rank at least 5 then MacWilliams showed that its Sylow 2-subgroups are connected, and the balance theorem implies that any simple group with connected Sylow 2-subgroups is either of component type or characteristic 2 type. (For groups of low 2-rank the proof of this breaks down, because theorems such as the signalizer functor theorem only work for groups with elementary abelian subgroups of rank at least 3.)\nGroups of component type.\nA group is said to be of component type if for some centralizer \"C\" of an involution, \"C\"/\"O\"(\"C\") has a component (where \"O\"(\"C\") is the core of \"C\", the maximal normal subgroup of odd order).\nThese are more or less the groups of Lie type of odd characteristic of large rank, and alternating groups, together with some sporadic groups.\nA major step in this case is to eliminate the obstruction of the core of an involution. This is accomplished by the B-theorem, which states that every component of \"C\"/\"O\"(\"C\") is the image of a component of \"C\".\nThe idea is that these groups have a centralizer of an involution with a component that is a smaller quasisimple group, which can be assumed to be already known by induction. So to classify these groups one takes every central extension of every known finite simple group, and finds all simple groups with a centralizer of involution with this as a component. This gives a rather large number of different cases to check: there are not only 26 sporadic groups and 16 families of groups of Lie type and the alternating groups, but also many of the groups of small rank or over small fields behave differently from the general case and have to be treated separately, and the groups of Lie type of even and odd characteristic are also quite different.\nGroups of characteristic 2 type.\nA group is of characteristic 2 type if the generalized Fitting subgroup \"F\"*(\"Y\") of every 2-local subgroup \"Y\" is a 2-group.\nAs the name suggests these are roughly the groups of Lie type over fields of characteristic 2, plus a handful of others that are alternating or sporadic or of odd characteristic. Their classification is divided into the small and large rank cases, where the rank is the largest rank of an odd abelian subgroup normalizing a nontrivial 2-subgroup, which is often (but not always) the same as the rank of a Cartan subalgebra when the group is a group of Lie type in characteristic 2.\nThe rank 1 groups are the thin groups, classified by Aschbacher, and the rank 2 ones are the notorious quasithin groups, classified by Aschbacher and Smith. These correspond roughly to groups of Lie type of ranks 1 or 2 over fields of characteristic 2.\nGroups of rank at least 3 are further subdivided into 3 classes by the trichotomy theorem, proved by Aschbacher for rank 3 and by Gorenstein and Lyons for rank at least 4.\nThe three classes are groups of GF(2) type (classified mainly by Timmesfeld), groups of \"standard type\" for some odd prime (classified by the Gilman\u2013Griess theorem and work by several others), and groups of uniqueness type, where a result of Aschbacher implies that there are no simple groups.\nThe general higher rank case consists mostly of the groups of Lie type over fields of characteristic 2 of rank at least 3 or 4.\nExistence and uniqueness of the simple groups.\nThe main part of the classification produces a characterization of each simple group. It is then necessary to check that there exists a simple group for each characterization and that it is unique. This gives a large number of separate problems; for example, the original proofs of existence and uniqueness of the monster group totaled about 200 pages, and the identification of the Ree groups by Thompson and Bombieri was one of the hardest parts of the classification. Many of the existence proofs and some of the uniqueness proofs for the sporadic groups originally used computer calculations, most of which have since been replaced by shorter hand proofs.\nHistory of the proof.\nGorenstein's program.\nIn 1972 announced a program for completing the classification of finite simple groups, consisting of the following 16 steps:\nTimeline of the proof.\nMany of the items in the table below are taken from . The date given is usually the publication date of the complete proof of a result, which is sometimes several years later than the proof or first announcement of the result, so some of the items appear in the \"wrong\" order.\nSecond-generation classification.\nThe proof of the theorem, as it stood around 1985 or so, can be called \"first generation\". Because of the extreme length of the first generation proof, much effort has been devoted to finding a simpler proof, called a second-generation classification proof. This effort, called \"revisionism\", was originally led by Daniel Gorenstein.\n, ten volumes of the second generation proof have been published (Gorenstein, Lyons &amp; Solomon 1994, 1996, 1998, 1999, 2002, 2005, 2018a, 2018b; &amp; Capdeboscq, 2021, 2023). In 2012 Solomon estimated that the project would need another 5 volumes, but said that progress on them was slow. It is estimated that the new proof will eventually fill approximately 5,000 pages. (This length stems in part from the second generation proof being written in a more relaxed style.) However, with the publication of volume 9 of the GLS series, and including the Aschbacher\u2013Smith contribution, this estimate was already reached, with several more volumes still in preparation (the rest of what was originally intended for volume 9, plus projected volumes 10 and 11). Aschbacher and Smith wrote their two volumes devoted to the quasithin case in such a way that those volumes can be part of the second generation proof.\nGorenstein and his collaborators have given several reasons why a simpler proof is possible.\n has called the work on the classification problem by Ulrich Meierfrankenfeld, Bernd Stellmacher, Gernot Stroth, and a few others, a third generation program. One goal of this is to treat all groups in characteristic 2 uniformly using the amalgam method.\nLength of proof.\nGorenstein has discussed some of the reasons why there might not be a short proof of the classification similar to the classification of compact Lie groups.\nConsequences of the classification.\nThis section lists some results that have been proved using the classification of finite simple groups."}
{"id": "7446", "revid": "2340490", "url": "https://en.wikipedia.org/wiki?curid=7446", "title": "Chalcolithic", "text": "The Chalcolithic ( ) (also called the Copper Age and Eneolithic) was an archaeological period characterized by the increasing use of smelted copper. It followed the Neolithic and preceded the Bronze Age. It occurred at different periods in different areas, but was absent in some parts of the world, such as Russia, where there was no well-defined Copper Age between the Stone and Bronze Ages. Stone tools were still predominantly used during this period.\nThe Chalcolithic covers both the early cold working (hammering) of near pure copper ores, as exhibited by the likes of North American Great Lakes Old Copper complex, from around 6,500 BC, through the later copper smelting cultures. The archaeological site of Belovode, on Rudnik mountain in Serbia, has the world's oldest securely dated evidence of copper smelting at high temperature, from . The transition from Copper Age to Bronze Age in Europe occurred between the late 5th and the late In the Ancient Near East the Copper Age covered about the same period, beginning in the late and lasting for about a millennium before it gave rise to the Early Bronze Age.\nA study in the journal \"Antiquity\" from 2013 reporting the discovery of a tin bronze foil from the Plo\u010dnik archaeological site dated to , as well as 14 other artefacts from Bulgaria and Serbia dated to before 4,000 BC, showed that early tin bronze was more common than previously thought and developed independently in Europe 1,500 years before the first tin bronze alloys in the Near East. In Britain, the Chalcolithic is a short period between about 2,500 and 2,200 BC, characterized by the first appearance of objects of copper and gold, a new ceramic culture and the immigration of Beaker culture people, heralding the end of the local late Neolithic.\nTerminology.\nThe multiple names result from multiple definitions of the period. Originally, the term Bronze Age meant that either copper or bronze was being used as the chief hard substance for the manufacture of tools and weapons. Ancient writers, who provided the essential cultural references for educated people during the 19th\u00a0century, used the same name for both copper- and bronze-using ages.\nThe concept of the Copper Age was put forward by Hungarian scientist Ferenc Pulszky in the 1870s, when, on the basis of the significant number of large copper objects unearthed within the Carpathian Basin, he suggested that the previous threefold division of the Prehistoric Age \u2013 the Stone, Bronze and Iron Ages \u2013 should be further divided with the introduction of the Copper Age.\nIn 1881, John Evans recognized that use of copper often preceded the use of bronze, and distinguished between a \"transitional Copper Age\" and the \"Bronze Age proper\". He did not include the transitional period in the Bronze Age, but described it separately from the customary stone / bronze / iron system, at the Bronze Age's beginning. He did not, however, present it as a fourth age but chose to retain the tripartite system.\nIn 1884, Gaetano Chierici, perhaps following the lead of Evans, renamed it in Italian as the \"eneo-litica\", or \"bronze\u2013stone\" transition. The phrase was never intended to mean that the period was the only one in which both bronze and stone were used. The Copper Age features the use of copper, excluding bronze; moreover, stone continued to be used throughout both the Bronze Age and the Iron Age. The part \"-litica\" simply names the Stone Age as the point from which the transition began and is not another \"-lithic\" age.\nSubsequently, British scholars used either Evans's \"Copper Age\" or the term \"Eneolithic\" (or \u00c6neolithic), a translation of Chierici's \"eneo-litica\". After several years, a number of complaints appeared in the literature that \"Eneolithic\" seemed to the untrained eye to be produced from \"e-neolithic\", \"outside the Neolithic\", clearly not a definitive characterization of the Copper Age. Around 1900, many writers began to substitute \"Chalcolithic\" for Eneolithic, to avoid the false segmentation. The term chalcolithic is a combination of two words- Chalco+Lithic, derived from the Greek words \"khalkos\" meaning \"copper\", and \"l\u00edthos\" meaning \"stone\".\nBut \"chalcolithic\" could also mislead: For readers unfamiliar with the Italian language, \"chalcolithic\" seemed to suggest another \"-lithic\" age, paradoxically part of the Stone Age despite the use of copper. Today, \"Copper Age\", \"Eneolithic\", and \"Chalcolithic\" are used synonymously to mean Evans's original definition of Copper Age.\nRegions.\nNear East.\nThe emergence of metallurgy may have occurred first in the Fertile Crescent.\nLead may have been the first ore that humans smelted, since it can be easily obtained by heating galena.\nPossible early examples of lead smelting, supported by the extreme rarity of native lead, include: lead beads, found on Level IX of Chatal/\u00c7atal H\u00fcy\u00fck in central Anatolia, though they might be made of galena, cerussite, or metallic lead, and accordingly might or might not be evidence of early smelting; a lead bead, found in a GK59 group test square in the 4th level of Jarmo, dated to the 7th millennium BCE, though it is small enough that its human usage is doubtful; a lead bracelet, found in level XII of Yarim Tepe I, dated to the 6th millennium BC; a small cone-shaped piece of lead, found in the \"Burnt House\" in TT6 at Arpachiyah, dated to the Halaf period or slightly later than the Yarim Tepe bracelet; and more.\nCopper smelting is also documented at this site at about the same time period (soon after 6000\u00a0BC). However, the use of lead seems to precede copper smelting. Early metallurgy is also documented at the nearby site of Tell Maghzaliyah, which seems to be dated even earlier, and completely lacks pottery.\nThe Timna Valley contains evidence of copper mining in 7000\u20135000\u00a0BC. The process of transition from Neolithic to Chalcolithic in the Middle East is characterized in archaeological stone tool assemblages by a decline in high quality raw material procurement and use. This dramatic shift is seen throughout the region, including the Tehran Plain, Iran. Here, analysis of six archaeological sites determined a marked downward trend in not only material quality, but also in aesthetic variation in the lithic artefacts. Fazeli &amp; Coningham use these results as evidence of the loss of craft specialisation caused by increased use of copper tools.\nThe Tehran Plain findings illustrate the effects of the introduction of copper working technologies on the in-place systems of lithic craft specialists and raw materials. Networks of exchange and specialized processing and production that had evolved during the Neolithic seem to have collapsed by the Middle Chalcolithic () and been replaced by the use of local materials by a primarily household-based production of stone tools.\nArsenical copper or bronze was produced in eastern Turkey (Malatya Province) at two ancient sites, Nor\u015funtepe and De\u011firmentepe, around 4200 BC. According to Boscher (2016), hearths or natural draft furnaces, slag, ore, and pigment had been recovered throughout these sites. This was in the context of Ubaid period architectural complexes typical of southern Mesopotamian architecture. Nor\u015funtepe site demonstrates that some form of arsenic alloying was indeed taking place by the 4th millennium BC. Since the slag identified at Nor\u015funtepe contains no arsenic, this means that arsenic in some form was added separately.\nEurope.\nA copper axe found at Prokuplje, Serbia contains the oldest securely dated evidence of copper-making, (7,500\u00a0years ago). The find in June\u00a02010 extends the known record of copper smelting by about 800 years, and suggests that copper smelting may have been invented in separate parts of Asia and Europe at that time rather than spreading from a single source.\nKnowledge of the use of copper was far more widespread than the metal itself. The European Battle Axe culture used stone axes modeled on copper axes, even with moulding carved in the stone. \u00d6tzi the Iceman, who was found in the \u00d6tztal Alps in 1991 and whose remains have been dated to about 3300\u00a0BC, was found with a Mondsee copper axe.\nExamples of Chalcolithic cultures in Europe include Vila Nova de S\u00e3o Pedro and Los Millares on the Iberian Peninsula. Pottery of the Beaker people has been found at both sites, dating to several centuries after copper-working began there. The Beaker culture appears to have spread copper and bronze technologies in Europe, along with Indo-European languages. In Britain, copper was used between the 25th and , but some archaeologists do not recognise a British Chalcolithic because production and use was on a small scale.\nSouth Asia.\nCeramic similarities between the Indus Valley civilisation, southern Turkmenistan, and northern Iran during 4300\u20133300\u00a0BC of the Chalcolithic period suggest considerable mobility and trade.\nThe term \"Chalcolithic\" has also been used in the context of the South Asian Stone Age.\nIn Bhirrana, the earliest Indus civilization site, copper bangles and arrowheads were found. The inhabitants of Mehrgarh in present-day Pakistan fashioned tools with local copper ore between 7000 and 3300\u00a0BC.\nThe Nausharo site was a pottery workshop in province of Balochistan, Pakistan, that dates to 4,500\u00a0years ago; 12\u00a0blades and blade fragments were excavated there. These blades are long, wide, and relatively thin. Archaeological experiments show that these blades were made with a copper indenter and functioned as a potter's tool to trim and shape unfired pottery. Petrographic analysis indicates local pottery manufacturing, but also reveals the existence of a few exotic black-slipped pottery items from the Indus Valley.\nIn India, Chalcolithic culture flourished in mainly four farming communities \u2013 Ahar or Banas, Kayatha, Malwa, and Jorwe. These communities had some common traits like painted pottery and use of copper, but they had a distinct ceramic design tradition. Banas culture (2000\u20131600\u00a0BC) had ceramics with red, white, and black design. Kayatha culture (2450\u20131700\u00a0BC) had ceramics painted with brown colored design. Malwa culture (1900\u20131400\u00a0BC) had profusely decorated pottery with red or black colored design. Jorwe culture (1500\u2013900\u00a0BC) had ceramics with matte surface and black-on-red design.\nPandu Rajar Dhibi (2000\u20131600\u00a0BC) is a Chalcolithic site in the eastern part of the Indian subcontinent. It is located on the south bank of Ajay River in West Bengal. Blackware, painted Koshi ware, pottery, various ornaments made of pearl and copper, various types of tools, pieces of fabric woven from Shimul cotton thread, human and various animal skeletons, burnt clay fragments have been found at the site.\nIn March\u00a02018, archaeologists had discovered three carts and copper artifacts including weapons dating to 1800\u00a0BC in Sanauli village of Uttar Pradesh. The artifacts belongs to Ochre Coloured Pottery culture.\nPre-Columbian Americas.\nIn the Archaeology of the Americas, a five-period system is conventionally used which does not include metal ages, though metalworking technology did precede European contact in some areas.\nAndean civilizations in South America appear to have independently invented copper smelting.\nThe term \"Chalcolithic\" is also applied to American civilizations that already used copper and copper alloys thousands of years before Europeans immigrated. Besides cultures in the Andes and Mesoamerica, the Old Copper complex mined and fabricated copper as tools, weapons, and personal ornaments in an area centered in the upper Great Lakes region (present-day Michigan and Wisconsin).\nThe evidence of smelting or alloying that has been found in North America is subject to some dispute and a common assumption by archaeologists is that objects were cold-worked into shape. Artifacts from some of these sites have been dated to 6500\u20131000\u00a0BC, making them some of the oldest Chalcolithic sites in the world. Some archaeologists find artifactual and structural evidence of casting by Hopewellian and Mississippian peoples to be demonstrated in the archaeological record.\nEast Asia.\nIn the 5th millennium BC copper artifacts start to appear in East Asia, such as in the Jiangzhai and Hongshan cultures, but those metal artifacts were not widely used during this early stage.\nCopper manufacturing gradually appeared in the Yangshao period (5000\u20133000\u00a0BC). Jiangzhai is the only site where copper artifacts were found in the Banpo culture. Archaeologists have found remains of copper metallurgy in various cultures from the late fourth to the early third millennia BC. These include the copper-smelting remains and copper artifacts of the Hongshan culture (4700\u20132900) and copper slag at the Yuanwozhen site. This indicates that inhabitants of the Yellow River valley had already learned how to make copper artifacts by the later Yangshao period.\nSub-Saharan Africa.\nIn the region of the A\u00efr Mountains, Niger, independent copper smelting developed between 3000 and 2500\u00a0BC. The process was not in a developed state, indicating smelting was not foreign. It became mature about 1500\u00a0BC."}
{"id": "7447", "revid": "19091282", "url": "https://en.wikipedia.org/wiki?curid=7447", "title": "Circumcision and law", "text": "Laws restricting, regulating, or banning circumcision, some dating back to ancient times, have been enacted in many countries and communities. In the case of non-therapeutic circumcision of children, proponents of laws in favor of the procedure often point to the rights of the parents or practitioners, namely the right of freedom of religion. Those against the procedure point to the boy's right of freedom from religion. In several court cases, judges have pointed to the irreversible nature of the act, the grievous harm to the boy's body, and the right to self-determination, and bodily integrity.\nHistory.\nJudaism.\nThere are ancient religious requirements for circumcision. The Hebrew Bible commands Jews to circumcise their male children on the eighth day of life, and to circumcise their male slaves.\nLaws which ban circumcision are also ancient. The ancient Greeks prized the foreskin and disapproved of the Jewish custom of circumcision. 1 Maccabees, 1:60\u201361 states that King Antiochus IV of Syria, the occupying power of Judea in 170 BCE, outlawed circumcision on penalty of death, one of the grievances leading to the Maccabean Revolt.\nAccording to the \"Historia Augusta\", the Roman emperor Hadrian issued a decree which banned circumcision in the empire, and some modern scholars argue that this was a main cause of the Jewish Bar Kokhba revolt of 132 CE. The Roman historian Cassius Dio, however, made no mention of such a law, instead, he blamed the Jewish uprising on Hadrian's decision to rebuild Jerusalem and rename it Aelia Capitolina, a city dedicated to Jupiter.\nAntoninus Pius permitted Jews to circumcise their own sons. However, he forbade the circumcision of non-Jewish males who were either foreign-born slaves of Jews and the circumcision of non-Jewish males who were members of Jewish households, in violation of Genesis 17:12. He also banned non-Jewish men from converting to Judaism. Antoninus Pius exempted the Egyptian priesthood from the otherwise universal ban on circumcision.\nConstantine the Great made it illegal to circumcise Christian slaves, and punished the owners who allowed it by freeing the Christian from slavery.\nEcclesiastical canon law in Christianity.\nCircumcision has also played a major role in Christian history and theology. The Council of Jerusalem in the early Christian Church declared that circumcision was not necessary for Christians; covenant theology largely views the Christian sacrament of baptism as fulfilling the Israelite practice of circumcision, both being signs and seals of the covenant of grace. Though mainstream Christian denominations maintain a neutral position on routine circumcision, it is widely practiced in many Christian communities.\nHistorically, the Lutheran Churches have also not practiced circumcision among their communicants. Currently the Catholic Church maintains a neutral position on the practice of non-religious circumcision. Today, many Christian denominations are neutral about ritual male circumcision, not requiring it for religious observance, but neither forbidding it for cultural or other reasons.\nOn the other hand, in Oriental Christianity, the Coptic Orthodox Church and Ethiopian Orthodox Church and Eritrean Orthodox Church require that their male members undergo circumcision.\nSoviet Union.\nBefore glasnost, according to an article in \"The Jewish Press\", Jewish ritual circumcision was forbidden in the Soviet Union. However, David E. Fishman, professor of Jewish History at the Jewish Theological Seminary of America, states that, whereas the \"heder\" and \"yeshiva\", the organs of Jewish education, \"were banned by virtue of the law separating church and school, and subjected to tough police and administrative actions\", circumcision was not proscribed by law or suppressed by executive measures.\nJehoshua A. Gilboa writes that while circumcision was not officially or explicitly banned, pressure was exerted to make it difficult. \"Mohels\" in particular were concerned that they could be punished for any health issue that might develop, even if it arose some time after the circumcision.\nAlbania.\nIn 1967, all religion in Communist Albania was banned, along with the practice of circumcision. The practice was driven underground and many boys were secretly circumcised.\nInternational law.\nCouncil of Europe.\nOn 1 October 2013, the Parliamentary Assembly of the Council of Europe adopted a non-binding resolution in which they state they are \"particularly worried about a category of violation of the physical integrity of children\", and included in this category \"circumcision of young boys for religious reasons\". On 7 October, Israel's president Shimon Peres wrote a personal missive to the Secretary General of the Council of Europe, Thorbj\u00f8rn Jagland, to stop the \"ban\", arguing: \"The Jewish communities across Europe would be greatly afflicted to see their cultural and religious freedom impeded upon by the Council of Europe, an institution devoted to the protection of these very rights.\" Two days later, Jagland clarified that the resolution was non-binding and that \"Nothing in the body of our legally binding standards would lead us to put on equal footing the issue of female genital mutilation and the circumcision of young boys for religious reasons.\"\nEuropean Union.\nA study commissioned by the European Parliament Committee on Civil Liberties, Justice and Home Affairs published in February 2013 stated that \"Male circumcision for non-therapeutic reasons appears to be practiced with relative regularity and frequency throughout Europe,\" and said it was \"the only scenario, among the topics discussed in the present chapter, in which the outcome of the balancing between the right to physical integrity and religious freedom is in favour of the latter.\" The study recommended that \"the best interests of children should be paramount, while acknowledging the relevance of this practice for Muslims and Jews. Member States should ensure that circumcision of underage children is performed according to the medical profession's art and under conditions that do not put the health of minors at risk. The introduction of regulations by the Member States in order to set the conditions and the appropriate medical training for those called to perform it is warranted.\"\n2013 Nordic ombudsmen statement.\nOn 30 September 2013, the children's ombudsmen of all five Nordic countries \u2013 Denmark, Finland, Iceland, Norway, and Sweden \u2013 together with the children's spokesperson from Greenland and representatives of associations of Nordic paediatricians and paediatric surgeons, gathered in Oslo to discuss the issue, and released a joint declaration proposing a ban on non-therapeutic circumcision of male minors:\nModern laws by country.\nAs of February 2018, no European country has a ban on male circumcision.\nWhereas child custody regulations have been applied to cases involving circumcision, there seems to be no state which currently unequivocally bans infant male circumcision for non-therapeutic reasons, albeit the legality of such circumcision is disputed in some legislations.\nThe present table provides a non-exhaustive overview comparing legal restrictions and requirements on non-therapeutic infant circumcision in several countries. Some countries require one or both parents to consent to the operation; some of these (Finland, United Kingdom) have experienced legal battles between parents when one of them had their son's circumcision carried out or planned without the other's consent. Some countries require the procedure to be performed by or supervised by a qualified physician (or a qualified nurse in Sweden), and with (local) anaesthesia applied to the boy or man.\nAustralia.\nThe Royal Australasian College of Physicians (RACP) finds that routine infant circumcision is not warranted in Australia and New Zealand and that, since circumcision involves physical injury, physicians ought to raise and consider with parents and considered the option of leaving circumcision until later, when the boy is old enough to make a decision for himself:\nIn 1993, a non-binding research paper of the Queensland Law Reform Commission (\"Circumcision of Male Infants\") concluded that \"On a strict interpretation of the assault provisions of the Queensland Criminal Code, routine circumcision of a male infant could be regarded as a criminal act,\" and that doctors who perform circumcision on male infants may be liable to civil claims by that child at a later date. No prosecutions have occurred in Queensland, and circumcisions continue to be performed.\nIn 1999, a Perth man won A$360,000 in damages after a doctor admitted he botched a circumcision operation at birth which left the man with a badly deformed penis.\nIn 2002, Queensland police charged a father with grievous bodily harm for having his two sons, then aged nine and five, circumcised without the knowledge and against the wishes of the mother. The mother and father were in a family court dispute. The charges were dropped when the police prosecutor revealed that he did not have all family court paperwork in court and the magistrate refused to grant an adjournment.\nCosmetic circumcision for newborn males is currently banned in all Australian public hospitals, South Australia being the last state to adopt the ban in 2007; the procedure was not forbidden from being performed in private hospitals. In the same year, the Tasmanian President of the Australian Medical Association, Haydn Walters, stated that they would support a call to ban circumcision for non-medical, non-religious reasons. In 2009, the Tasmanian Law Reform Institute released its Issues Paper investigating the law relating to male circumcision in Tasmania, it \"highlights the uncertainty in relation to whether doctors can legally perform circumcision on infant males\".\nThe Tasmania Law Reform Institute released its recommendations for reform of Tasmanian law relative to male circumcision on 21 August 2012. The report makes fourteen recommendations for reform of Tasmanian law relative to male circumcision.\nBelgium.\nThe Belgian Advisory Committee on Bioethics finds that circumcision is a radical operation, and that physical integrity of the child takes precedence over parents' belief systems.\nIn 2012, \"Le Soir\" reported a 21% increase in the amount of circumcisions in Belgium from 2006 and 2011. In the previous 25 years, one in three Belgian-born boys had allegedly been circumcised. A questionnaire to hospitals in Wallonia and Brussels showed that about 80 to 90% of the procedures had religious or cultural motives. The Ministry of Health stressed the importance of safe circumstances, physicians warned that \"no surgical procedure is without risk\" and that circumcision was \"not a necessary procedure\".\nIn 2017, it was estimated that about 15% of Belgian men were circumcised. The incidence has been gradually rising: in 2002, about 17,800 boys or men underwent circumcision, which increased to almost 26,200 in 2016. The expenses of undergoing circumcision are covered by the National Institute for Disease and Disability Insurance (RIZIV/INAMI), costing about 2.7 million euros in 2016. After inquiries were submitted to the Belgian Bioethics Advisory Committee in early 2014, an ethics commission was set up to review the morality of covering the costs of medically unnecessary surgery through taxpayer money, especially considering that many taxpayers regard the practice as immoral. By July 2017, the commission reportedly reached consensus on discontinuing the financial coverage of non-medical circumcision, but was still debating whether to advise the government to institute a total ban of the practice. The commission's final (non-binding) recommendation, presented on 19 September 2017, was to cease public funding for non-medical circumcision, and to not circumcise anyone underage until they can consent or reject the procedure after being properly informed. This was in line with the 1990 Convention on the Rights of the Child, and mirrors the 2013 non-binding Parliamentary Assembly of the Council of Europe's resolution against underage non-therapeutic circumcision. However, Health Minister Maggie De Block rejected the commission's advice, arguing the RIZIV \"cannot know whether there is a medical motive or not\" when parents request a circumcision, and when they are denied a professional procedure, chances are parents will have a non-expert perform it, leading to worse results for the children. The Health Minister's response was received with mixed reactions.\nCanada.\nThe Canadian Paediatric Society does not recommend routine circumcision, finding that medical necessity has not been clearly established, and as such, that it should be deferred until the individual concerned is able to make his own choices.\nAccording to the College of Physicians and Surgeons of British Columbia:\nDenmark.\nCircumcision is legal in Denmark, and each year 1,000 to 2,000 boys are circumcised for non-medical reasons, the Danish Health Authority estimated in 2013, with most circumcisions being performed on Muslim or Jewish boys in private clinics or private homes. For boys below the age of 15, circumcision requires consent from the parents, while the boy can consent when he is 15 years or older. Circumcision is classified as an operation and reserved for doctors, though the responsible doctor can delegate the actual operation to non-medical person, as long as the doctor is present. The operation requires \"sufficient pain relief (analgesic) and sedation (Anesthesia)\" The doctor is responsible for having the necessary qualifications (both for the operation and the pain relief) and for being informed about the newest scientific developments in the area.\nThe current guidelines for non-medical circumcision are from 2013, and , a committee under the Danish Patient Health Authority are in the process of updating them. In August 2020, the Danish Society of Anaesthesiology and Intensive Care Medicine withdrew from the committee, because they disagreed with the Authority's opinion that local anaesthesia was sufficient, instead saying the scientific literature showed that general anaesthesia was necessary. Other professional organizations followed them, and according to DR, only the Authority and two private clinics that perform circumcisions remain in the committee.\nThe Danish population overwhelmingly support a ban on non-medical circumcision of boys below the age of 18. A 2020 survey measured the support at 86%, while surveys in 2018, 2016 and 2014 measured the support at 83%, 87% and 74%, respectively In 2018, a citizen's initiative calling for such a ban reached the threshold of 50.000 signatures to be put forward in the Folketing. It was subsequently found compliant with the Danish Constitution, in particularly \u00a767 on religious freedom. The Danish Medical Association believes boys should decide for themselves after they turn 18 years old, but does not call for a ban. Politicians are hesitant in supporting a ban, with protection of religious freedom, in particular the Jewish practice of circumcision, and potential foreign policy and national security ramifications mentioned as some of the reasons. , the Social Democrats and Venstre, who together hold a majority in the Folketing, oppose a ban, while the Danish People's Party, the Socialist People's Party, Red-Green Alliance, The Alternative, The New Right and Liberal Alliance favour a ban. The Conservative and the Social Liberal Party have no official opinion on the question.\nWith a two-thirds majority against, the Folketing voted against a ban on circumcision in May 2021.\nFinland.\nThe Finnish Ombudsman for Equality finds that circumcising young boys without a medical reason is legally highly questionable, The Finnish Supreme Court found that non-therapeutic circumcision of boys is assault, and the Finnish Ombudsman for Children proposed that Finland should ban non-therapeutic circumcision of young boys: \nIn August 2006, a Finnish court ruled that the circumcision of a four-year-old boy arranged by his mother, who is Muslim, to be an illegal assault. The boy's father, who had not been consulted, reported the incident to the police. A local prosecutor stated that the prohibition of circumcision is not gender-specific in Finnish law. A lawyer for the Ministry of Social Affairs and Health stated that there is neither legislation nor prohibition on male circumcision, and that \"the operations have been performed on the basis of common law.\" The case was appealed and in October 2008 the Finnish Supreme Court ruled that the circumcision, \"carried out for religious and social reasons and in a medical manner, did not have the earmarks of a criminal offence. It pointed out in its ruling that the circumcision of Muslim boys is an established tradition and an integral part of the identity of Muslim men\". In 2008, the Finnish government was reported to be considering a new law to legalise circumcision if the practitioner is a doctor and if the child consents. In December 2011, Helsinki District Court said that the Supreme Court's decision does not mean that circumcision is legal for any non-medical reasons. The court referred to the Convention on Human rights and Biomedicine of the Council of Europe, which was ratified in Finland in 2010.\nIn February 2010, a Jewish couple were fined for causing bodily harm to their then infant son who was circumcised in 2008 by a mohel brought in from the UK. Normal procedure for persons of Jewish faith in Finland is to have a locally certified mohel who works in Finnish healthcare perform the operation. In the 2008 case, the infant was not anesthetized and developed complications that required immediate hospital care. The parents were ordered to pay 1500 euros in damages to their child.\nIn November 2020, the Finnish Parliament passed a new law on female genital mutilation. An earlier version of the draft law could also have criminalised nonmedical infant circumcision, but due to intense lobbying by several Islamic and Jewish organisations including the Central Council of Finnish Jewish Communities, Milah UK, and the European Jewish Congress, the wording was changed and instead, the law passed in Parliament now states that the issue of circumcision of boys should be \"clarified\" in the future.\nGermany.\nThe German Association of Pediatricians (BVKJ) finds no medical reason for non-therapeutic circumcision and that the AAP (2012) recommendation scientifically unsustainable, and that boys should have the same constitutional legal right to physical integrity as girls:\nIn October 2006, a Turkish national who performed ritual circumcisions on seven boys was convicted of causing dangerous bodily harm by the state court in D\u00fcsseldorf.\nIn September 2007, a Frankfurt am Main appeals court found that the circumcision of an 11-year-old boy without his approval was an unlawful personal injury. The boy, whose parents were divorced, was visiting his Muslim father during a vacation when his father forced him to be ritually circumcised. The boy had planned to sue his father for .\nIn May 2012, the Cologne regional appellate court ruled that religious circumcision of male children amounts to bodily injury, and is a criminal offense in the area under its jurisdiction. The decision based on the article \"Criminal Relevance of Circumcising Boys. A Contribution to the Limitation of Consent in Cases of Care for the Person of the Child\" published by Holm Putzke, a German law professor at the University of Passau. The court arrived at its judgment by application of the human rights provisions of the Basic Law, a section of the Civil Code, and some sections of the Criminal Code to non-therapeutic circumcision of male children. Some observers said it could set a legal precedent that criminalizes the practice. Jewish and Muslim groups were outraged by the ruling, viewing it as trampling on freedom of religion.\nThe German ambassador to Israel, Andreas Michaelis, told Israeli lawmakers that Germany was working to resolve the issue and that it does not apply at a national level, but instead only to the local jurisdiction of the court in Cologne. The Council of the Coordination of Muslims in Germany condemned the ruling, stating that it is \"a serious attack on religious freedom\". Ali Kizilkaya, a spokesman of the council, stated that, \"The ruling does not take everything into account, religious practice concerning circumcision of young Muslims and Jews has been carried out over the millennia on a global level.\" The Roman Catholic archbishop of Aachen, Heinrich Mussinghoff, said that the ruling was \"very surprising\", and the contradiction between \"basic rights on freedom of religion and the well-being of the child brought up by the judges is not convincing in this very case\". Hans Ulrich Anke, the head of the Protestant Church in Germany, said the ruling should be appealed since it did not \"sufficiently\" consider the religious significance of the rite. A spokesman, Steffen Seibert, for German Chancellor Angela Merkel stated that Jewish and Muslim communities will be free to practice circumcision responsibly, and the government would find a way around the local ban in Cologne. The spokesman stated \"For everyone in the government it is absolutely clear that we want to have Jewish and Muslim religious life in Germany. Circumcision carried out in a responsible manner must be possible in this country without punishment.\"\nIn July 2012, a group of rabbis, imams, and others said that they view the ruling against circumcision \"an affront on our basic religious and human rights\". The joint statement was signed by leaders of groups including Germany's Turkish-Islamic Union for Religious Affairs, the Islamic Center Brussels, the Rabbinical Centre of Europe, the European Jewish Parliament and the European Jewish Association, who met with members of European Parliament from Germany, Finland, Belgium, Italy, and Poland. European rabbis, who urged Jews to continue circumcision, planned further talks with Muslim and Christian leaders to determine how they can oppose the ban together. The Jewish Hospital of Berlin suspended the practice of male circumcision. On 19 July 2012, a joint resolution of the CDU/CSU, SPD and FDP factions in the Bundestag requesting the executive branch to draft a law permitting circumcision of boys to be performed without unnecessary pain in accordance with best medical practice carried with a broad majority.\n\"The New York Times\" reported that the German Medical Association \"condemned the ruling for potentially putting children at risk by taking the procedure out of the hands of doctors, but it also warned surgeons note to perform circumcisions for religious reasons until legal clarity was established\". The ruling was supported by Deutsche Kinderhilfe, a German child rights organization, which asked for a two-year moratorium to discuss the issue and pointed out that religious circumcision may contravene the Convention on the Rights of the Child (Article 24.3: \"States Parties shall take all effective and appropriate measures with a view to abolishing traditional practices prejudicial to the health of children.\").\nThe German Academy for Pediatric and Adolescent Medicine (Deutsche Akademie f\u00fcr Kinder- und Jugendmedizin e.V., DAKJ), the German Association for Pediatric Surgery (Deutsche Gesellschaft f\u00fcr Kinderchirurgie, DGKCH) and the Professional Association of Pediatric and Adolescent Physicians (Berufsverband der Kinder- und Jugend\u00e4rzte) took a firm stand against non-medical routine infant circumcision.\nIn July, in Berlin, a criminal complaint was lodged against Rabbi Yitshak Ehrenberg for \"causing bodily harm\" by performing religious circumcision, and for vocal support of the continuation of the practice. In September, the prosecutors dismissed the complaint, concluding that \"there is no proof to establish that the rabbi's conduct met the 'condition of a criminal' violation\".\nIn September, Reuters reported \"Berlin's senate said doctors could legally circumcise infant boys for religious reasons in its region, given certain conditions.\"\nOn 12 December 2012, following a series of hearings and consultations, the Bundestag adopted the proposed law explicitly permitting non-therapeutic circumcision to be performed under certain conditions; it is now \u00a71631(d) in the German Civil Code. The vote tally was 434 ayes, 100 noes, and 46 abstentions. Following approval by the Bundesrat and signing by the Bundespr\u00e4sident, the new law became effective on 28 December 2012 a day after its publication in the Federal Gazette.\nIceland.\nIn May 2005, Iceland amended its General Penal Code to criminalise female genital mutilation\nIn February 2018, the Progressive Party proposed a bill that would change the words \"girl child\" to \"child\" and \"her sexual organs\" to \"[their] sexual organs\", thereby making Iceland the first European country to ban male circumcision for non-medical reasons. The bill was ultimately put on hold later that year following pressure from the United States, Israel, and various lobbyist groups.\nIreland.\nThe legality of non-therapeutic circumcision of infants is unclear in Ireland. In 2003, an expert in medical law suggested that the Constitution of Ireland's guarantees of family autonomy would probably trump concern for the child's bodily autonomy. Until the 1990s the practice was largely confined to the brit milah of the small Jewish community, generally performed by a mohel travelling from Great Britain and certified there by the Initiation Society, with no concern from law enforcement. The increased immigration beginning in the Celtic Tiger period included people with Muslim or African traditions of circumcision. \nIn August 2003 in Waterford, the 29-day-old son of a Nigerian father and Irish mother died from hemorrhage and shock after an attempted circumcision by a Nigerian \"fourth-generation circumcisionist\", who was charged with reckless endangerment. The boy's parents had enquired about circumcision within the health service, but such requests were routinely declined by the local health board until a review after the death. At the 2005 trial, the prosecution argued that \"the carrying out of a circumcision by a non-medical person was not an offence in Ireland\", but that the accused had failed to provide aftercare support and advice, so that the parents had waited too long (12 hours) before taking the infant to hospital. The judge instructed the jury 'not to bring their \"white Western values\" to bear upon their deliberations'; the accused was found not guilty. Kevin Myers commented, 'May you ineptly circumcise an Irish boy-child and cause him to die if you are African because of your \"culture\", but not if you are Irish?' Jurist M\u00e1ir\u00e9ad Enright questioned the judge's \"radical cultural relativism\" and felt as a Circuit Court case it had \"limited precedential value\".\nWhile the Waterford case was pending, the Minister for Health established an advisory committee on \"cultural male circumcision\". Its 2006 report recommended that circumcision be provided within the health service as an outpatient procedure by trained surgeons and anaesthetists. Circumcisions carried out by \"untrained people\" should be investigated by the Health Service Executive and might be prosecuted as child abuse. In 2020 another Nigerian traditional circumcisionist was jailed for 3 years after pleading guilty to reckless endangerment of a 10-month-old, who spent two weeks in hospital after a 2015 procedure without anaesthetic or proper sterilisation. The judge called it \"a barbaric act of cruelty\" and said the man should abide by Irish cultural norms. \nOn 30 July 2024 a London-based rabbi was arrested after performing a circumcision in a Dublin house with the parents' consent. He was charged with carrying out a surgical procedure without being a registered medical practitioner, contrary to the Medical Practitioners Act 2007. The accused is a mohel registered with the Initiation Society. The Chief Rabbi of Ireland said that the client family was not Jewish, but the Jewish community would be offering assistance to the mohel. \"The Jewish Chronicle\" suggested the reason the case was singled out for prosecution was because it was a \"non-religious circumcision\"; \"The Times of Israel\" linked it to an alleged increase in Irish antisemitism due to the Israel\u2013Hamas war. On 6 August he was remanded for a further two weeks in anticipation of \"multiple further charges\" from the Director of Public Prosecutions. On 22 August he was granted bail at a hearing which was told no mohel had previously been prosecuted in such a case.\nIsrael.\nIn Israel, Jewish circumcision is entirely legal. The circumcision rate is very high in Israel, although some limited data suggests the practice is slowly declining. According to an online survey by the parents' portal Mamy in 2006, the rate was 95%, while earlier estimates put it at 98\u201399%. Ben Shalem, an organisation dedicated to the abolition of circumcision, petitioned the Supreme Court in 1999 on the grounds that circumcision violated human dignity, children's rights and criminal law. The petition was rejected. In 2013, a Rabbinical court in Israel ordered a mother in the midst of divorce proceedings to circumcise her son in accordance with the father's wishes, or pay a fine of 500 Israeli Shekel for every day that the child is not circumcised. She appealed against the Rabbinical court ruling and the High Court ruled in her favour stating, among other considerations, the basic right of freedom from religion.\nNetherlands.\nThe Royal Dutch Medical Association (KNMG) finds non-therapeutic circumcision of male minors to be in conflict with children's right to autonomy and physical integrity, and that there are good reasons for its legal prohibition, as exists for female genital mutilation: \nIn May 2008 a father who had his two sons, aged 3 and 6, circumcised against the will of their mother was found not guilty of abuse as the circumcision was performed by a physician and due to the court's restraint in setting a legal precedent; instead he was given a 6-week suspended jail sentence for taking the boys away from their mother against her will.\nThe parquet of the Supreme Court of the Netherlands made an elaborate statement on the legal status of circumcision on 5 July 2011 in the course of a criminal case. First, the parquet notes that there is no law that specifically prohibits the circumcision of boys, nor that the practice falls under the more general crime of \"(zware) mishandeling\" ('(grave) assault'). \"Genital mutilation of girls in any case undoubtedly falls under \"(zware) mishandeling\" (Art. 300\u2013303 Dutch Criminal Code). Whereas most forms of genital cutting of girls are generally marked as genital mutilation, a similar communis opinio regarding genital cutting of boys does not yet exist so far.\" The Supreme Court acknowledged that society's attitudes on genital cutting of boys had been gradually shifting over the course of years, and that \"the increasing concern [in the medical world] about the harm and the risk of complications during a circumcision is indeed relevant\", but that overall there were not enough reasons yet to proceed to criminalisation. Neither could intentional infliction of grave bodily harm (Art. 82 Dutch Criminal Code) be applied to the normal circumstances of a competently and hygienically performed circumcision in a clinic. And because young children are incapable of exercising the right to self-determination, parents ought to do this on their behalf. They can both request a circumcision to be performed, as well as consent to it being performed, on the grounds of their parental authority. However, it is important that both parents consent to the procedure.\nNorway.\nThe Norwegian Ombudsman for Children (\"Barneombudet\") opposes circumcising children, and stated on 29 September 2013 that it is right to wait until children are old enough to decide for themselves: \nIn June 2012, the centre-right Centre Party proposed a ban on circumcision on males under eighteen, after an Oslo infant died in May following a circumcision.\nA bill on ritual circumcision of boys was passed (against two votes) in the Norwegian Parliament in June 2014, with the new law going into effect on 1 January 2015. This law explicitly allows Jews to practice brit milah and obligates the Norwegian Health Care regions to offer the Muslim minority a safe and affordable procedure. Local anaesthesia needs to be applied and a licensed physician needs to be present at the circumcision, which hospitals started to perform in March 2015.\nIn May 2017, the right-wing Progress Party proposed to ban circumcision for males under sixteen.\nSouth Africa.\nThe Children's Act 2005 makes the circumcision of male children under 16 unlawful except for religious or medical reasons. In the Eastern Cape province the Application of Health Standards in Traditional Circumcision Act, 2001, regulates traditional circumcision, which causes the death or mutilation of many youths by traditional surgeons each year. Among other provisions, the minimum age for circumcision is age 18.\nIn 2004, a 22-year-old Rastafarian convert was forcibly circumcised by a group of Xhosa tribal elders and relatives. When he first fled, two police returned him to those who had circumcised him. In another case, a medically circumcised Xhosa man was forcibly recircumcised by his father and community leaders. He laid a charge of unfair discrimination on the grounds of his religious beliefs, seeking an apology from his father and the Congress of Traditional Leaders of South Africa. According to South African newspapers, the subsequent trial became \"a landmark case around forced circumcision\". In October 2009, the Eastern Cape High Court at Bhisho (sitting as an Equality Court) clarified that circumcision is unlawful unless done with the full consent of the initiate.\nSlovenia.\nThe Slovenian Human Rights Ombudsman found in February 2012, after consulting various relevant expert bodies and studying relevant constitutional and legal stipulations, that circumcision for non-medical reasons is a violation of children's rights, that ritual circumcision for religious reasons is unacceptable in Slovenia for both legal and ethical reasons and should not be performed by doctors:\nSweden.\nIn 2001, the Parliament of Sweden enacted a law allowing only persons certified by the National Board of Health to circumcise infants. It requires a medical doctor or an anesthesia nurse to accompany the circumciser and for anaesthetic to be applied beforehand. After the first two months of life circumcisions can only be performed by a physician. The stated purpose of the law was to increase the safety of the procedure.\nSwedish Jews and Muslims objected to the law, and in 2001, the World Jewish Congress called it \"the first legal restriction on Jewish religious practice in Europe since the Nazi era\". The requirement for an anaesthetic to be administered by a medical professional is a major issue, and the low degree of availability of certified professionals willing to conduct circumcision has also been subject to criticism. According to a survey, two out of three paediatric surgeons said they refuse to perform non-therapeutic circumcision, and less than half of all county councils offer it in their hospitals. However, in 2006, the U.S. State Department stated, in a report on Sweden, that most Jewish mohels had been certified under the law and 3000 Muslim and 40\u201350 Jewish boys were circumcised each\nyear. An estimated 2000 of these are performed by persons who are neither physicians nor have officially recognised certification.\nThe Swedish National Board of Health and Welfare reviewed the law in 2005 and recommended that it be maintained, but found that the law had failed with regard to the intended consequence of increasing the safety of circumcisions. A later report by the Board criticised the low level of availability of legal circumcisions, partly due to reluctance among health professionals. To remedy this, the report suggested a new law obliging all county councils to offer non-therapeutic circumcision in their hospitals, but this was later abandoned in favour of a non-binding recommendation.\nIn January 2014, the Swedish Medical Association (SLF) found no known medical benefits to circumcision of children, and thus strong reasons to wait until the boy is old and mature enough (12 or 13 years old) to give informed consent, aiming at ceasing all non-medically justified circumcision without prior consent:\nIn October 2018, the right-wing populist Sweden Democrats party submitted a draft motion to parliament calling for a ban. At the annual conference of the Centre Party in September 2019, 314 to 166 commissioners voted in favor of prohibiting boys' circumcision. Several Jewish and Islamic organisations voiced their opposition to a potential ban. The Left Party has also expressed support for a prohibition on circumcising boys before the age of 18; other parties have so far not backed a potential ban, though the Green Party found the practice \"problematic\".\nSwitzerland.\nAccording to a July 2012 survey by \"20 Minuten\" involving 8,000 participants, 64% of the Swiss population wanted religious circumcision to be banned. 67% of men and 56% of women were in favour. 93% of Muslim respondents and 75% of Jewish respondents opposed a ban. Over 25% of male respondents were themselves circumcised; 96% of Muslim men and 89% of Jewish men in the survey said they were circumcised, while 20% of circumcised men belonged to neither religion. Almost a third of circumcised men favoured a ban, with 12% wishing in hindsight that they had not been circumcised.\nUnited Kingdom.\nMale circumcision has traditionally been presumed to be legal under British law, however some authors have argued that there is no solid foundation for this view in English law.\nWhile legal, the British Medical Association finds it ethically unacceptable to circumcise a child or young person, either with or without competence, who refuses the procedure, irrespective of the parents' wishes, and that parental preference alone does not constitute sufficient grounds for performing NTMC on a child unable to express his own view:\nThe passage of the Human Rights Act 1998 has led to some speculation that the lawfulness of the circumcision of male children is unclear.\nOne 1999 case, \"Re \"J\" (child's religious upbringing and circumcision)\" said that circumcision in Britain required the consent of all those with parental responsibility (however this comment was not part of the reason for the judgement and therefore is not legally binding), or the permission of the court, acting for the best interests of the child, and issued an order prohibiting the circumcision of a male child of a non-practicing Muslim father and non-practicing Christian mother with custody. The reasoning included evidence that circumcision carried some medical risk; that the operation would be likely to weaken the relationship of the child with his mother, who strongly objected to circumcision without medical necessity; that the child may be subject to ridicule by his peers as the odd one out and that the operation might irreversibly reduce sexual pleasure, by permanently removing some sensory nerves, even though cosmetic foreskin restoration might be possible. The court did not rule out circumcision against the consent of one parent. It cited a hypothetical case of a Jewish mother and an agnostic father with a number of sons, all of whom, by agreement, had been circumcised as infants in accordance with Jewish laws; the parents then have another son who is born after they have separated; the mother wishes him to be circumcised like his brothers; the father for no good reason, refuses his agreement. In such a case, a decision in favor of circumcision was said to be likely.\nIn 2001 the General Medical Council had found a doctor who had botched circumcision operations guilty of abusing his professional position and that he had acted \"inappropriately and irresponsibly\", and struck him off the register. A doctor who had referred patients to him, and who had pressured a mother into agreeing to the surgery, was also condemned. He was put on an 18-month period of review and retraining, and was allowed to resume unrestricted practice as a doctor in March 2003, after a committee found that he had complied with conditions it placed on him. According to the \"Northern Echo\", he \"told the committee he has now changed his approach to circumcision referrals, accepting that most cases can be treated without the need for surgery\".\nFox and Thomson (2005) argue that consent cannot be given for non-therapeutic circumcision. They say there is \"no compelling legal authority for the common view that circumcision is lawful\".\nIn 2005 a Muslim man had his son circumcised against the wishes of the child's mother who was the custodial parent.\nIn 2009 it was reported that a 20-year-old man whose father had him ritually circumcised as a baby is preparing to sue the doctor who circumcised him. This is believed to be the first time a person who was circumcised as an infant has made a claim in the UK. The case is expected to be heard in 2010.\nIn a 2015 case regarding female circumcision, a judge concluded that non-therapeutic circumcision of male children is a \"significant harm\". In 2016, the Family Court in Exeter ruled that a Muslim father could not have his two sons (aged 6 and 4) circumcised after their mother disagreed. Mrs Justice Roberts declared that the boys should first grow old enough \"to the point where each of the boys themselves will make their individual choices once they have the maturity and insight to appreciate the consequences and longer-term effects of the decisions which they reach\".\nNottingham case.\nIn June 2017, Nottinghamshire Police arrested three people on suspicion of \"conspiracy to commit grievous bodily harm\". The alleged victim was purportedly circumcised while in its Muslim father's care at his grandparents' in July 2013 without the consent of his mother (a non-religious white British woman who conceived the child after a casual affair with the man, whom she had separated from after the incident). The mother first contacted social services and eventually the police in November 2014. The police initially dismissed the complaint, but after the mother got help from the anti-circumcision group Men Do Complain and leading human rights lawyer Saimo Chahal QC, they reopened the case, and ended up arresting three suspects involved. In November 2017, the Crown Prosecution Service explained to the mother in a letter they were not going to prosecute the doctor, who claimed he was unaware of the mother's non-consent. However, Chahal appealed this decision, which she said \"lacks any semblance of a considered and reasoned decision and is flawed and irrational\", and threatened to bring the case to court. The by then 29-year-old mother finally sued the doctor in April 2018. Niall McCrae, mental health expert from King's College London, argued that this case could mean \"the end of ritual male circumcision in the UK\", drawing comparisons with earlier rulings against female genital mutilation.\nUnited States.\nCircumcision of adults who grant personal informed consent for the surgical operation is legal.\nIn the United States, non-therapeutic circumcision of male children has long been assumed to be lawful in every jurisdiction provided that one parent grants surrogate informed consent. Adler (2013) has recently challenged the validity of this assumption. As with every country, doctors who circumcise children must take care that all applicable rules regarding informed consent and safety are satisfied.\nWhile anti-circumcision groups have occasionally proposed legislation banning non-therapeutic child circumcision, it has not been supported in any legislature. After a failed attempt to adopt a local ordinance banning circumcision on a San Francisco ballot, the state of California enacted in October 2011 a law protecting circumcision from local attempts to ban the practice.\nIn 2012, New York City required those performing \"metzitzah b'peh\", the oral suction of the open circumcision wound required by Hasidim, to obey stringent consent requirements, including documentation. Agudath Israel of America and other Jewish groups have planned to sue the city in response.\nDisputes between parents\nOccasionally the courts are asked to make a ruling when parents cannot agree on whether or not to circumcise a child.\nIn January 2001 a dispute between divorcing parents in New Jersey was resolved when the mother, who sought to have the boy circumcised withdrew her request. The boy had experienced two instances of foreskin inflammation and she wanted to have him circumcised. The father, who had experienced a traumatic circumcision as a child, objected and they turned to the courts for a decision. The Medical Society of New Jersey and the Urological Society of New Jersey both opposed any court ordered medical treatment. As the parties came to an agreement, no precedent was set. In June 2001 a Nevada court settled a dispute over circumcision between two parents but put a strict gag order on the terms of the settlement. In July 2001 a dispute between parents in Kansas over circumcision was resolved when the mother's request to have the infant circumcised was withdrawn. In this case the father opposed circumcision while the mother asserted that not circumcising the child was against her religious beliefs. (The woman's pastor had stated that circumcision was \"important\" but was not necessary for salvation.) On 24 July 2001 the parents reached agreement that the infant would not be circumcised.\nOn 14 July 2004 a mother appealed to the Missouri Supreme Court to prevent the circumcision of her son after a county court and the Court of Appeals had denied her a writ of prohibition. However, in early August 2004, before the Supreme Court had given its ruling, the father, who had custody of the boy, had him circumcised.\nIn October 2006 a judge in Chicago granted an injunction blocking the circumcision of a 9-year-old boy. In granting the injunction the judge stated that \"the boy could decide for himself whether to be circumcised when he turns 18.\"\nIn November 2007, the Oregon Supreme Court heard arguments from a divorced Oregon couple over the circumcision of their son. The father wanted his son, who turned 13 on 2 March 2008, to be circumcised in accordance with the father's religious views; the child's mother opposes the procedure. The parents dispute whether the boy is in favor of the procedure. A group opposed to circumcision filed briefs in support of the mother's position, while some Jewish groups filed a brief in support of the father. On 25 January 2008, the Court returned the case to the trial court with instructions to determine whether the child agrees or objects to the proposed circumcision. The father appealed to the US Supreme Court to allow him to have his son circumcised but his appeal was rejected. The case then returned to the trial court. When the trial court interviewed the couple's son, now 14 years old, the boy stated that he did not want to be circumcised. This also provided the necessary circumstances to allow the boy to change residence to live with his mother. The boy was not circumcised.\nOther disputes\nIn September 2004 the North Dakota Supreme Court rejected a mother's attempt to prosecute her doctor for circumcising her child without fully informing her of the consequences of the procedure. The judge and jury found that the plaintiffs were adequately informed of possible complications, and the jury further found that it is not incumbent on the doctors to describe every \"insignificant\" risk.\nIn March 2009 a Fulton County, GA, State Court jury awarded $2.3 million in damages to a 4-year-old boy and his mother for a botched circumcision in which too much tissue was removed causing permanent disfigurement.\nIn August 2010 an eight-day-old boy was circumcised in a Florida hospital against the stated wishes of the parents. The hospital admitted that the boy was circumcised by mistake; the mother has sued the hospital and the doctor involved in the case."}
{"id": "7448", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7448", "title": "Churches Uniting In Christ", "text": ""}
{"id": "7449", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=7449", "title": "Called to Common Mission", "text": "Called to Common Mission (CCM) is an agreement between The Episcopal Church (ECUSA) and the Evangelical Lutheran Church in America (ELCA) in the United States, establishing full communion between them. It was ratified by the ELCA in 1999, the ECUSA in 2000, after the narrow failure of a previous agreement. Its principal author on the Episcopal side was theological professor J. Robert Wright. Under the agreement, they recognize the validity of each other's baptisms and ordinations. The agreement provided that the ELCA would accept the historical episcopate and the \"threefold ministry\" of bishop - priest (or pastor) - deacon with respect to ministers of communicant churches serving ELCA congregations; the installation of the ELCA presiding bishop was performed through the laying on of hands by Lutheran bishops in the historic episcopate. This provision was opposed by some in the ELCA, which after its founding merger in 1988, held a lengthy study of the ministry which was undertaken with divided opinions. In response to concerns about the meaning of the CCM, synod bishops in the ELCA drafted the Tucson resolution which presented the official ELCA position. It made clear that there is no requirement to ordain deacons or accept their ministry. It also provided assurance that the ELCA did not and was not required by CCM to change its own theological stance.\nLutheran churches of Scandinavian origin, such as the Church of Sweden and Church in Kenya, affirm apostolic succession and are in the historical episcopate; nevertheless, some within the ELCA argued that the historical episcopate would contradict the doctrine that the church exists wherever the Word of God is preached and sacraments are practiced. The traditional ELCA doctrine is affirmed by the Tucson resolution. Others objected on the grounds that adopting the Episcopalian / Anglican view on priestly orders and hierarchical structure was contrary to the Evangelical Lutheran concept of the \"priesthood of all believers\", which holds that all Christians stand on equal footing before God. They argued that the Old Covenant required a priest to mediate between God and humanity, but that New Covenant explicitly abolishes the need for priestly role by making every Christian a priest with direct access to God's grace. The Tucson resolution explained that the ELCA had not adopted the Episcopal view, but ECUSA or Reformed ordinands accepted by ELCA congregations would follow ELCA practice. Still others objected because of the implied directive that the use of a lay presidency would be abolished. This was a particular issue for rural congregations that periodically \"called\" a congregation member to conduct communion services consecrating the elements (of bread and wine for service) in the interim period or with the absence of ordained clergy (pastor). The Tucson resolution explicitly affirmed the continued use of lay ministry."}
{"id": "7450", "revid": "18513760", "url": "https://en.wikipedia.org/wiki?curid=7450", "title": "Context menu", "text": "A context menu (also called contextual, shortcut, and pop up or pop-up menu) is a menu in a graphical user interface (GUI) that appears upon user interaction, such as a right-click mouse operation. A context menu offers a limited set of choices that are available in the current state, or context, of the operating system or application to which the menu belongs. Usually the available choices are actions related to the selected object. From a technical point of view, such a context menu is a graphical control element.\nHistory.\nContext menus first appeared in the Smalltalk environment on the Xerox Alto computer, where they were called \"pop-up menus\"; they were invented by Dan Ingalls in the mid-1970s.\nMicrosoft Office v3.0 introduced the context menu for copy and paste functionality in 1990. Borland demonstrated extensive use of the context menu in 1991 at the Second Paradox Conference in Phoenix Arizona. Lotus 1-2-3/G for OS/2 v1.0 added additional formatting options in 1991. Borland Quattro Pro for Windows v1.0 introduced the Properties context menu option in 1992.\nImplementation.\nContext menus are opened via various forms of user interaction that target a region of the GUI that supports context menus. The specific form of user interaction and the means by which a region is targeted vary:\nWindows mouse click behavior is such that the context menu doesn't open while the mouse button is pressed, but only opens the menu when the button is released, so the user has to click again to select a context menu item. This behavior differs from that of macOS and most free software GUIs.\nContext menus are sometimes hierarchically organized, allowing navigation through different levels of the menu structure. The implementations differ: Microsoft Word was one of the first applications to only show sub-entries of some menu entries after clicking an arrow icon on the context menu, otherwise executing an action associated with the parent entry. This makes it possible to quickly repeat an action with the parameters of the previous execution, and to better separate options from actions.\nX Window Managers.\nThe following window managers provide context menu functionality:\nUsability.\nContext menus have received some criticism from usability analysts when improperly used, as some applications make certain features \"only\" available in context menus, which may confuse even experienced users (especially when the context menus can only be activated in a limited area of the application's client window).\nContext menus usually open in a fixed position under the pointer, but when the pointer is near a screen edge the menu will be displaced - thus reducing consistency and impeding use of muscle memory. If the context menu is being triggered by keyboard, such as by using Shift + F10, the context menu appears near the focused widget instead of the position of the pointer, to save recognition efforts.\nIn documentation.\nMicrosoft's guidelines call for always using the term \"context menu\", and explicitly deprecate \"shortcut menu\"."}
{"id": "7451", "revid": "49047223", "url": "https://en.wikipedia.org/wiki?curid=7451", "title": "Jews as the chosen people", "text": "In Judaism, the concept of the Jews as chosen people ( \"h\u0101\u02bf\u0101m han\u012bv\u1e25ar\") is the belief that the Jews as a people, via descent from the ancient Israelites, are a chosen people, i.e. selected to be in a covenant with God. Israelites being properly the chosen people of God is found directly in the Book of Deuteronomy 7:6 as the verb \"ba\u1e25ar\" (\u05d1\u05b8\u05bc\u05d7\u05b7\u05e8), and is alluded to elsewhere in the Hebrew Bible using other terms such as \"holy people\" as \"goy\" or gentile, Book of Exodus 19:6. Much is written about these topics in rabbinic literature. The three largest Jewish denominations\u2014Orthodox Judaism, Conservative Judaism and Reform Judaism\u2014maintain the belief that the Jews have been chosen by God for a purpose. Sometimes this choice is seen by believers as charging the Jewish people with a specific mission\u2014to be a light unto the nations, and to exemplify the covenant with God as described in the Torah. Isaiah and Jeremiah viewed God's loving choice of Israel as a means to teaching monotheism, combatting idolatry, curbing human arrogance, ending violence, lust, greed, extreme chauvinism and warfare, and ushering in a new society.\nWhile the concept of \"chosenness\" may be understood by some to connote ethnic supremacy, the status as a \"chosen people\" within Judaism does not preclude a belief that God has a relationship with other peoples\u2014rather, Judaism holds that God had entered into a covenant with \"all\" humankind, and that Jews and non-Jews alike have a relationship with God. Biblical references as well as rabbinic literature support this view: Moses refers to the \"God of the spirits of all flesh\", the Tanakh (Hebrew Bible) also identifies prophets outside the community of Israel and the prophet Jonah is explicitly told to go prophesize to the non-Jewish people of Nineveh. Jewish tradition is clear that there were interactions of non-Jewish prophets with God which are not recounted in the Torah. Based on these statements and stories, some rabbis theorized that, in the words of Natan'el al-Fayyumi, a Yemenite Jewish theologian of the 12th century, \"God permitted to some people that which he forbade to others ... [and] God sends a prophet to every people according to their own language.\" (Levine, 1907/1966) The Mishnah states that \"Humanity was produced from one man, Adam, to show God's greatness. When a man mints a coin in a press, each coin is identical. But when the King of Kings, the Holy One, blessed be He, creates people in the form of Adam not one is similar to any other\" (Mishnah Sanhedrin 4:5).\nAccording to the Israel Democracy Institute, approximately two thirds of Israeli Jews believe that Jews are the \"chosen people\".\nEtymological background.\nThe term \"chosen people\" is free translated from the biblical terms \u02bf\"am\" \"segullah\" (\u201ctreasure people\u201d) and \u02bf\"am\" \"nahallah\" (\u201cheritage people\u201d).\nIn religious texts.\nAccording to the Torah, the nations which inhabited Can'an after Jacob left there, violated God's laws and were to be vomited out of the land as a result, however their iniquity was not sufficiently great to deserve that result until a few hundred years later, which was when God then brought Jacob's descendants back to the land, with a warning that they too would be cast out if they violated God's rules regarding idolatry and other 'abominations'. In Deuteronomy, the Torah states: \"when the Lord delivers the Israelites to the land, the other nations will be cast out, and \"thou shalt make no covenant with them, nor show mercy unto them\" Deuteronomy 7:5-7:6,\nA similar passage speaking of Israel as the chosen people follows prohibitions on baldness and cutting yourself in mourning, \"For thou art a holy people\".\nThe Torah also says,\nGod promises that he will never exchange his people with any other:\nOther Torah verses about chosenness,\nThe obligation imposed upon the Israelites was emphasized by the prophet Amos:\nRabbinic views.\nMost Jewish texts do not state that \"God chose the Jews\" by itself. Rather, this is usually linked with a mission or purpose, such as proclaiming God's message among all the nations, even though Jews cannot become \"unchosen\" if they shirk their mission. This implies a special duty, which evolves from the belief that Jews have been pledged by the covenant which God concluded with the biblical patriarch Abraham, their ancestor, and again with the entire Jewish nation at Mount Sinai. In this view, Jews are charged with living a holy life as God's priest-people.\nIn the Jewish prayerbook (the Siddur), chosenness is referred to in a number of ways. The blessing for reading the Torah reads, \"Praised are You, Lord our God, King of the Universe, Who has chosen us out of all the nations and bestowed upon us His Torah.\" In the \"Kiddush\", a prayer of sanctification, in which the Sabbath is inaugurated over a cup of wine, the text reads, \"For you have chosen us and sanctified us out of all the nations, and have given us the Sabbath as an inheritance in love and favour. Praised are you, Lord, who hallows the Sabbath.\" In the \"Kiddush\" recited on festivals it reads, \"Blessed are You ... who have chosen us from among all nations, raised us above all tongues, and made us holy through His commandments.\" The Aleinu prayer refers to the concept of Jews as a chosen people: \"It is our duty to praise the Master of all, to exalt the Creator of the Universe, who has not made us like the nations of the world and has not placed us like the families of the earth; who has not designed our destiny to be like theirs, nor our lot like that of all their multitude. We bend the knee and bow and acknowledge before the Supreme King of Kings, the Holy One, blessed be he, that it is he who stretched forth the heavens and founded the earth. His seat of glory is in the heavens above; his abode of majesty is in the lofty heights.\nSometimes this choice is seen as charging the Jewish people with a specific mission\u2014to be a light unto the nations, and to exemplify the covenant with God as described in the Torah. This view, however, does not always preclude a belief that God has a relationship with other peoples\u2014rather, Judaism held that God had entered into a covenant with all humankind, and that Jews and non-Jews alike have a relationship with God.\nBiblical references as well as rabbinic literature support this view: Moses refers to the \"God of the spirits of all flesh\", and the Tanakh also identifies prophets outside the community of Israel. Based on these statements, some rabbis theorized that, in the words of Natan'el al-Fayyumi, a Yemenite Jewish theologian of the 12th century, \"God permitted to every people something he forbade to others...[and] God sends a prophet to every people according to their own language.\" The Mishnah states that \"Humanity was produced from one man, Adam, to show God's greatness. When a man mints a coin in a press, each coin is identical. But when the King of Kings, the Holy One, blessed be He, creates people in the form of Adam not one is similar to any other.\" The Tosefta, a collection of important post-Talmudic discourses, also states: \"Righteous people of all nations have a share in the world to come.\"\nFurther interpretations.\nAccording to the Rabbis, \"Israel is of all nations the most willful or headstrong one, and the Torah was to give it the right scope and power of resistance, or else the world could not have withstood its fierceness.\"\n\"The Lord offered the Law to all nations; but all refused to accept it except Israel.\"\nHow do we understand \"A Gentile who consecrates his life to the study and observance of the Law ranks as high as the high priest\", says R. Me\u00efr, by deduction from Lev. xviii. 5; II Sam. vii. 19; Isa. xxvi. 2; Ps. xxxiii. 1, cxviii. 20, cxxv. 4, where all stress is laid not on Israel, but on man or the righteous one.\nMaimonides states: \"It is now abundantly clear that the pledges Hashem made to Avraham and his descendants would be fulfilled exclusively first in Yitzchak and then in Yaakov, Yitzchak son. This is confirmed by a passage that states, \"He is ever mindful of His covenant ... that He made with Avraham, swore to Yitzchak, and confirmed in a decree for Yaakov, for Yisrael, as an eternal covenant.\"\"\nThe Gemara states this regarding a non-Jew who studies Torah [his 7 mitzvot] and regarding this, see Shita Mekubetzes, Bava Kama 38a who says that this is an exaggeration. In any case, this statement was not extolling the non-Jew. The Rishonim explain that it is extolling the Torah.\nTosfos explains that it uses the example of a \"kohen gadol\" (high priest), because this statement is based on the verse, \"y'kara hi mipnimim\" (it is more precious than pearls). This is explained elsewhere in the Gemara to mean that the Torah is more precious \"pnimim\" (translated here as \"inside\" instead of as \"pearls\"; thus that the Torah is introspectively absorbed into the person), which refers to \"lifnai v'lifnim\" (translated as \"the most inner of places\"), that is the Holy of Holies where the \"kahon gadol\" went.\nIn any case, in Midrash Rabba this statement is made with an important addition: a non-Jew who converts and studies Torah etc.\nThe Nation of Israel is likened to the olive. Just as this fruit yields its precious oil only after being much pressed and squeezed, so Israel's destiny is one of great oppression and hardship, in order that it may thereby give forth its illuminating wisdom. Poverty is the quality most befitting Israel as the chosen people. Only on account of its good works is Israel among the nations \"as the lily among thorns\", or \"as wheat among the chaff.\"\nModern Orthodox views.\nRabbi Lord Immanuel Jakobovits, former Chief Rabbi of the United Synagogue of Great Britain (Modern Orthodox Judaism), described chosenness in this way: \"Yes, I do believe that the chosen people concept as affirmed by Judaism in its holy writ, its prayers, and its millennial tradition. In fact, I believe that every people\u2014and indeed, in a more limited way, every individual\u2014is \"chosen\" or destined for some distinct purpose in advancing the designs of Providence. Only, some fulfill their mission and others do not. Maybe the Greeks were chosen for their unique contributions to art and philosophy, the Romans for their pioneering services in law and government, the British for bringing parliamentary rule into the world, and the Americans for piloting democracy in a pluralistic society. The Jews were chosen by God to be 'peculiar unto Me' as the pioneers of religion and morality; that was and is their national purpose.\"\nModern Orthodox theologian Michael Wyschogrod wrote:\n\"[T]he initial election of Abraham himself was not earned. ... We are simply told that God commanded Abraham to leave his place of birth and go to a land that God would show him. He is also promised that his descendants will become a numerous people. But nowhere does the Bible tell us why Abraham rather than someone else was chosen. The implication is that God chooses whom He wishes and that He owes no accounting to anyone for His choices.\"\nRabbi Norman Lamm, a leader of Modern Orthodox Judaism, wrote: \"The chosenness of Israel relates exclusively to its spiritual vocation embodied in the Torah; the doctrine, indeed, was announced at Sinai. Whenever it is mentioned in our liturgy\u2014such as the blessing immediately preceding the Shema...it is always related to Torah or Mitzvot (\"commandments\"). This spiritual vocation consists of two complementary functions, described as \"Goy Kadosh\", that of a holy nation, and \"Mamlekhet Kohanim\", that of a kingdom of priests. The first term denotes the development of communal separateness or differences in order to achieve a collective self-transcendence. ... The second term implies the obligation of this brotherhood of the spiritual elite toward the rest of mankind; priesthood is defined by the prophets as fundamentally a teaching vocation.\"\nConservative views.\nConservative Judaism views the concept of chosenness in this way: \"Few beliefs have been subject to as much misunderstanding as the 'Chosen People' doctrine. The Torah and the Prophets clearly stated that this does not imply any innate Jewish superiority. In the words of Amos (3:2) 'You alone have I singled out of all the families of the earth\u2014that is why I will call you to account for your iniquities.' The Torah tells us that we are to be \"a kingdom of priests and a holy nation\" with obligations and duties which flowed from our willingness to accept this status. Far from being a license for special privilege, it entailed additional responsibilities not only toward God but to our fellow human beings. As expressed in the blessing at the reading of the Torah, our people have always felt it to be a privilege to be selected for such a purpose. For the modern traditional Jew, the doctrine of the election and the covenant of Israel offers a purpose for Jewish existence which transcends its own self interests. It suggests that because of our special history and unique heritage we are in a position to demonstrate that a people that takes seriously the idea of being covenanted with God can not only thrive in the face of oppression, but can be a source of blessing to its children and its neighbors. It obligates us to build a just and compassionate society throughout the world and especially in the land of Israel where we may teach by example what it means to be a 'covenant people, a light unto the nations.'\"\nRabbi Reuven Hammer comments on the excised sentence in the Aleinu prayer mentioned above:\n\"Originally the text read that God has not made us like the nations who \"bow down to nothingness and vanity, and pray to an impotent god\", ... In the Middle Ages these words were censored, since the church believed they were an insult to Christianity. Omitting them tends to give the impression that the Aleinu teaches that we are both different and better than others. The actual intent is to say that we are thankful that God has enlightened us so that, unlike the pagans, we worship the true God and not idols. There is no inherent superiority in being Jewish, but we do assert the superiority of monotheistic belief over paganism. Although paganism still exists today, we are no longer the only ones to have a belief in one God.\"\nReform views.\nReform Judaism views the concept of chosenness as follows: \"Throughout the ages it has been Israel's mission to witness to the Divine in the face of every form of paganism and materialism. We regard it as our historic task to cooperate with all men in the establishment of the kingdom of God, of universal brotherhood, Justice, truth and peace on earth. This is our Messianic goal.\" In 1999 the Reform movement stated, \"We affirm that the Jewish people are bound to God by an eternal covenant, as reflected in our varied understandings of Creation, Revelation and Redemption. ... We are Israel, a people aspiring to holiness, singled out through our ancient covenant and our unique history among the nations to be witnesses to God's presence. We are linked by that covenant and that history to all Jews in every age and place.\"\nAlternative views.\nEquality of souls.\nMany Kabbalistic sources, notably the Tanya, contain statements to the effect that the Jewish soul is qualitatively different from the non-Jewish soul. A number of known Chabad rabbis offered alternative readings of the Tanya, did not take this teaching literally, and even managed to reconcile it with the leftist ideas of internationalism and class struggle. The original text of the Tanya refers to the \"idol worshippers\" and does not mention the \"nations of the world\" at all, although such interpretation was endorsed by Menachem Mendel Schneerson and is popular in contemporary Chabad circles. Hillel Paricher, an early Tanya commentator, wrote that the souls of righteous Gentiles are more similar to the Jewish souls, and are generally good and not egoistic. This teaching was accepted by Schneerson and is considered normative in Chabad.\nDifferent in character but not different in value.\nAccording to the author of the Tanya himself, a righteous non-Jew can achieve a high level of spirituality, similar to an angel, although his soul is still fundamentally different in character, but not value, from a Jewish one. Tzemach Tzedek, the third rebbe of Chabad, wrote that the Muslims are naturally good-hearted people. Rabbi Yosef Jacobson, a popular contemporary Chabad lecturer, teaches that in today's world most non-Jews belong to the category of righteous Gentiles, effectively rendering the Tanya's attitude anachronistic.\nAltruism.\nAn anti-Zionist interpretation of Tanya was offered by Abraham Yehudah Khein, a prominent Ukrainian Chabad rabbi, who supported anarchist communism and considered Peter Kropotkin a great Tzaddik. Khein basically read the Tanya backwards; since the souls of idol worshipers are known to be evil, according to the Tanya, while the Jewish souls are known to be good, he concluded that truly altruistic people are really Jewish, in a spiritual sense, while Jewish nationalists and class oppressors are not. By this logic, he claimed that Vladimir Solovyov and Rabindranath Tagore probably have Jewish souls, while Leon Trotsky and other totalitarians do not, and many Zionists, whom he compared to apes, are merely \"Jewish by birth certificate\".\nRighteous non-Jews.\nNachman of Breslov also believed that Jewishness is a level of consciousness, and not an intrinsic inborn quality. He wrote that, according to the Book of Malachi, one can find \"potential Jews\" among all nations, whose souls are illuminated by the leap of \"holy faith\", which \"activated\" the Jewishness in their souls. These people would otherwise convert to Judaism, but prefer not to do so. Instead, they recognize the Divine unity within their pagan religions.\nIsaac Arama, an influential philosopher and mystic of the 15th century, believed that righteous non-Jews are spiritually identical to the righteous Jews. Rabbi Menachem Meiri, a famous Catalan Talmudic commentator and Maimonidian philosopher, considered all people, who sincerely profess an ethical religion, to be part of a greater \"spiritual Israel\". He explicitly included Christians and Muslims in this category. Meiri rejected all Talmudic laws that discriminate between the Jews and non-Jews, claiming that they only apply to the ancient idolators, who had no sense of morality. The only exceptions are a few laws related directly or indirectly to intermarriage, which Meiri did recognize.\nMeiri applied his idea of \"spiritual Israel\" to the Talmudic statements about unique qualities of the Jewish people. For example, he believed that the famous saying that Israel is above astrological predestination (\"Ein Mazal le-Israel\") also applied to the followers of other ethical faiths. He also considered countries, inhabited by decent moral non-Jews, such as Languedoc, as a spiritual part of the Holy Land.\nSpinoza.\nOne Jewish critic of chosenness was the philosopher Baruch Spinoza. In the third chapter of his \"Theologico-Political Treatise\", Spinoza mounts an argument against a naive interpretation of God's choice of the Jews. Bringing evidence from the Bible itself, he argues that God's choice of Israel was not unique (he had chosen other nations before choosing the Hebrew nation) and that the choice of the Jews is neither inclusive (it does not include all of the Jews, but only the 'pious' ones) nor exclusive (it also includes 'true gentile prophets'). Finally, he argues that God's choice is not unconditional. Recalling the numerous times God threatened the complete destruction of the Hebrew nation, he asserts that this choice is neither absolute, nor eternal, nor necessary.\nEinstein.\nIn a German-language letter to philosopher Eric Gutkind, dated 3 January 1954, the physicist Albert Einstein wrote:\nThe word God is for me nothing more than the expression and product of human weaknesses, the Bible a collection of honorable, but still primitive legends which are nevertheless pretty childish. No interpretation no matter how subtle can (for me) change this... For me the Jewish religion like all other religions is an incarnation of the most childish superstitions. And the Jewish people to whom I gladly belong and with whose mentality I have a deep affinity have no different quality for me than all other people... I cannot see anything \u201cchosen\u201d about them.\nReconstructionist criticism.\nReconstructionist Judaism rejects the concept of chosenness. Its founder, Rabbi Mordecai Kaplan, said that the idea that God chose the Jewish people leads to racist beliefs among Jews, thus, it must be excised from Jewish theology. This rejection of chosenness is made explicit in the movement's siddurim (prayer books). For example, the original blessing recited before reading from the Torah contains the phrase, \"asher bahar banu mikol ha\u2019amim\"\u2014\"Praised are you Lord our God, ruler of the Universe, \"who has chosen us from among all peoples\" by giving us the Torah.\" The Reconstructionist version is rewritten as \"asher kervanu la\u2019avodato\", \"Praised are you Lord our God, ruler of the Universe, \"who has drawn us to your service\" by giving us the Torah.\" In the mid-1980s, the Reconstructionist movement issued its \"Platform on Reconstructionism\". It states that the idea of chosenness is \"morally untenable\", because anyone who has such beliefs \"implies the superiority of the elect community and the rejection of others.\"\nNot all Reconstructionists accept this view. The newest siddur of the movement, \"Kol Haneshamah\", includes the traditional blessings as an option, and some modern Reconstructionist writers have opined that the traditional formulation should be embraced because it is not racist.\nAn original prayer book by the Reconstructionist feminist poet Marcia Falk, \"The Book of Blessings\", has been accepted by many Reform and Reconstructionist Jews. Falk rejects all concepts which are related to hierarchy or distinction; she sees any distinction as leading to the acceptance of other kinds of distinctions, thus leading to prejudice. She writes that as a politically liberal feminist, she must reject distinctions made between men and women, homosexuals and heterosexuals, Jews and non-Jews, and to some extent even distinctions between the Sabbath and the other six days of the week. She thus rejects the idea of chosenness as unethical. She also rejects Jewish theology in general, and instead holds to a form of religious humanism. Falk writes: \"The idea of Israel as God's chosen people ... is a key concept in rabbinic Judaism. Yet it is particularly problematic for many Jews today, in that it seems to fly in the face of monotheistic belief that all humanity is created in the divine image\u2014and hence, all humanity is equally loved and valued by God. ... I find it difficult to conceive of a feminist Judaism that would incorporate it in its teaching: the valuing of one people \"over and above\" others is all too analogous to the privileging of one sex over another.\" Reconstructionist author Judith Plaskow also criticises the idea of chosenness, for many of the same reasons as Falk. A politically liberal lesbian, Plaskow rejects most distinctions made between men and women, homosexuals and heterosexuals, and Jews and non-Jews. In contrast to Falk, Plaskow does not reject all concepts of difference as inherently leading to unethical beliefs, and holds to a more classical form of Jewish theism than Falk.\nA number of responses to these views have been made by Reform and Conservative Jews; they hold the view that these criticisms are against teachings that do not exist within liberal forms of Judaism, and such teachings are rare in Orthodox Judaism (outside certain Haredi communities, such as Chabad). A separate criticism stems from the very existence of feminist forms of Judaism in all denominations of Judaism, which do not have a problem with the concept of chosenness.\nViews of other religions.\nIslam.\nThe children of Israel enjoy a special status in the Islamic holy book, the Quran (2:47 and 2:122). However, Muslim scholars point out that this status did not confer upon Israelites any racial superiority, and was only valid so long as the Israelites maintain their covenant with God.\nChristianity.\nSome Christians believe that the Jews were God's chosen people, but because of Jewish rejection of Jesus, the Christians in turn received that special status. This doctrine is known as Supersessionism.\nOther Christians, such as the Christadelphians, believe that God has not rejected Israel as his chosen people and that the Jews will in fact accept Jesus as their Messiah at his Second Coming, resulting in their salvation. The view that the Jews still retain their status as the chosen people is also associated with Dispensational theology, promoted by John Nelson Darby and Cyrus Scofield.\nAugustine criticized Jewish chosenness as \"carnal.\" He reasoned that Israel was chosen \"according to the flesh.\"\nThe Jamieson-Fausset-Brown Bible Commentary similarly argues that God made Israel the \"holy nation\" to exclusively uphold the promises made to their \"pious forefathers\". They argue that Jewish supremacist views are unsound, with Jews being frequently described as a small people that engaged in \"perverse\" moral conduct in the Bible.\nThe Catechism of the Catholic Church describes the \"People of God\" as referring to all people who have faith in Christ and are baptized. They have characteristics \"that distinguish it from all other religious, ethnic, political, or cultural groups found in history\".\nInfluence on Judaism's relationship with other religions.\nAvi Beker, an Israeli scholar and former Secretary General of the World Jewish Congress, regarded the idea of the chosen people as Judaism's defining concept and \"the central unspoken psychological, historical, and theological problem which is at the heart of Jewish-Gentile relations.\" In his book \"The Chosen: The History of an Idea, and the Anatomy of an Obsession\", Beker expresses the view that the concept of chosenness is the driving force behind Jewish-Gentile relations, explaining both the admiration and, more pointedly, the envy and the hatred which the world has felt towards the Jews in both religious and secular terms. Beker argues that while Christianity has modified its doctrine on the displacement of the Jews, Islam has neither reversed nor reformed its theology concerning the succession of both the Jews and the Christians. According to Beker, this presents a major barrier to conflict resolution in the Arab-Israeli conflict.\nEthnocentrism.\nThe Israeli philosopher Ze'ev Levy writes that chosenness can be \"(partially) justified only from the historical angle\" with respect to its spiritual and moral contribution to Jewish life through the centuries as \"a powerful agent of consolation and hope\". He points out, however, that modern anthropological theories \"do not merely proclaim the inherent universal equality of all people [as] human beings; they also stress the \"equivalence\" [emphasis in original] of all human cultures.\" He continues that \"there are no inferior and superior people or cultures but only different, \"other\", ones.\" He concludes that the concept of chosenness entails ethnocentrism, \"which does not go hand in hand with otherness, that is, with unconditional respect of otherness\".\nSome people have said that Judaism's chosen people concept is racist because it implies that Jews are superior to non-Jews."}
{"id": "7452", "revid": "73738", "url": "https://en.wikipedia.org/wiki?curid=7452", "title": "Cross-compilation", "text": ""}
{"id": "7453", "revid": "1272866745", "url": "https://en.wikipedia.org/wiki?curid=7453", "title": "Christian persecution", "text": "Christian persecution may refer to:"}
{"id": "7455", "revid": "2788753", "url": "https://en.wikipedia.org/wiki?curid=7455", "title": "Chaparral", "text": "Chaparral ( ) is a shrubland plant community found primarily in California, in southern Oregon and in the northern portion of the Baja California Peninsula in Mexico. It is shaped by a Mediterranean climate (mild wet winters and hot dry summers) and infrequent, high-intensity crown fires.\nMany chaparral shrubs have hard sclerophyllous evergreen leaves, as contrasted with the associated soft-leaved, drought-deciduous, scrub community of coastal sage scrub, found often on drier, southern facing slopes.\nThree other closely related chaparral shrubland systems occur in southern Arizona, western Texas, and along the eastern side of central Mexico's mountain chains, all having summer rains in contrast to the Mediterranean climate of other chaparral formations. Chaparral comprises 9% of California's wildland vegetation and contains 20% of its plant species.\nEtymology.\nThe name comes from the Spanish word , which translates to \"place of the scrub oak\".\nIntroduction.\nIn its natural state, chaparral is characterized by infrequent fires, with natural fire return intervals ranging between 30 years and over 150 years. Mature chaparral (at least 60 years since time of last fire) is characterized by nearly impenetrable, dense thickets (except the more open desert chaparral). These plants are flammable during the late summer and autumn months when conditions are characteristically hot and dry. They grow as woody shrubs with thick, leathery, and often small leaves, contain green leaves all year (are evergreen), and are typically drought resistant (with some exceptions). After the first rains following a fire, the landscape is dominated by small flowering herbaceous plants, known as fire followers, which die back with the summer dry period.\nSimilar plant communities are found in the four other Mediterranean climate regions around the world, including the Mediterranean Basin (where it is known as ), central Chile (where it is called ), the South African Cape Region (known there as ), and in Western and Southern Australia (as ). According to the California Academy of Sciences, Mediterranean shrubland contains more than 20 percent of the world's plant diversity. The word \"chaparral\" is a loanword from Spanish , meaning place of the scrub oak, which itself comes from a Basque word, , that has the same meaning.\nConservation International and other conservation organizations consider chaparral to be a biodiversity hotspot \u2013 a biological community with a large number of different species \u2013 that is under threat by human activity.\nCalifornia chaparral.\nCalifornia chaparral and woodlands ecoregion.\nThe California chaparral and woodlands ecoregion, of the Mediterranean forests, woodlands, and scrub biome, has three sub-ecoregions with ecosystem\u2013plant community subdivisions:\nChaparral and woodlands biota.\nFor the numerous individual plant and animal species found within the California chaparral and woodlands ecoregion, see:\nSome of the indicator plants of the California chaparral and woodlands ecoregion include:\nChaparral soils and nutrient composition\nChaparral characteristically is found in areas with steep topography and shallow stony soils, while adjacent areas with clay soils, even where steep, tend to be colonized by annual plants and grasses. Some chaparral species are adapted to nutrient-poor soils developed over serpentine and other ultramafic rock, with a high ratio of magnesium and iron to calcium and potassium, that are also generally low in essential nutrients such as nitrogen.\nCalifornia cismontane and transmontane chaparral subdivisions.\nAnother phytogeography system uses two California chaparral and woodlands subdivisions: the cismontane chaparral and the transmontane (desert) chaparral.\nCalifornia cismontane chaparral.\nCismontane chaparral (\"this side of the mountain\") refers to the chaparral ecosystem in the Mediterranean forests, woodlands, and scrub biome in California, growing on the western (and coastal) sides of large mountain range systems, such as the western slopes of the Sierra Nevada in the San Joaquin Valley foothills, western slopes of the Peninsular Ranges and California Coast Ranges, and south-southwest slopes of the Transverse Ranges in the Central Coast and Southern California regions.\nCismontane chaparral plant species.\nIn Central and Southern California chaparral forms a dominant habitat. Members of the chaparral biota native to California, all of which tend to regrow quickly after fires, include:\nCismontane chaparral bird species.\nThe complex ecology of chaparral habitats supports a very large number of animal species. The following is a short list of birds which are an integral part of the cismontane chaparral ecosystems.\nCalifornia transmontane (desert) chaparral.\nTransmontane chaparral or desert chaparral\u2014\"transmontane\" (\"the other side of the mountain\") \"chaparral\"\u2014refers to the desert shrubland habitat and chaparral plant community growing in the rainshadow of these ranges. Transmontane chaparral features xeric desert climate, not Mediterranean climate habitats, and is also referred to as desert chaparral. Desert chaparral is a regional ecosystem subset of the deserts and xeric shrublands biome, with some plant species from the California chaparral and woodlands ecoregion. Unlike cismontane chaparral, which forms dense, impenetrable stands of plants, desert chaparral is often open, with only about 50 percent of the ground covered. Individual shrubs can reach up to in height.\nTransmontane chaparral or desert chaparral is found on the eastern slopes of major mountain range systems on the western sides of the deserts of California. The mountain systems include the southeastern Transverse Ranges (the San Bernardino and San Gabriel Mountains) in the Mojave Desert north and northeast of the Los Angeles basin and Inland Empire; and the northern Peninsular Ranges (San Jacinto, Santa Rosa, and Laguna Mountains), which separate the Colorado Desert (western Sonoran Desert) from lower coastal Southern California. It is distinguished from the cismontane chaparral found on the coastal side of the mountains, which experiences higher winter rainfall. Naturally, desert chaparral experiences less winter rainfall than cismontane chaparral. Plants in this community are characterized by small, hard (sclerophyllic) evergreen (non-deciduous) leaves. Desert chaparral grows above California's desert cactus scrub plant community and below the pinyon-juniper woodland. It is further distinguished from the deciduous sub-alpine scrub above the pinyon-juniper woodlands on the same side of the Peninsular ranges.\nDue to the lower annual rainfall (resulting in slower plant growth rates) when compared to cismontane chaparral, desert chaparral is more vulnerable to biodiversity loss and the invasion of non-native weeds and grasses if disturbed by human activity and frequent fire.\nTransmontane chaparral distribution.\nTransmontane (desert) chaparral typically grows on the lower ( elevation) northern slopes of the southern Transverse Ranges (running east to west in San Bernardino and Los Angeles counties) and on the lower () eastern slopes of the Peninsular Ranges (running south to north from lower Baja California to Riverside and Orange counties and the Transverse Ranges). It can also be found in higher-elevation sky islands in the interior of the deserts, such as in the upper New York Mountains within the Mojave National Preserve in the Mojave Desert.\nThe California transmontane (desert) chaparral is found in the rain shadow deserts of the following:\nTransmontane chaparral animals.\nThere is overlap of animals with those of the adjacent desert and pinyon-juniper communities.\nFire.\nChaparral is a coastal biome with hot, dry summers and mild, rainy winters. The chaparral area receives about of precipitation a year. This makes the chaparral most vulnerable to fire in the late summer and fall.\nThe chaparral ecosystem as a whole is adapted to be able to recover from naturally infrequent, high-intensity fire (fires occurring between 30 and 150 years or more apart); indeed, chaparral regions are known culturally and historically for their impressive fires. (This does create a conflict with human development adjacent to and expanding into chaparral systems.) Additionally, Native Americans burned chaparral near villages on the coastal plain to promote plant species for textiles and food. Before a major fire, typical chaparral plant communities are dominated by manzanita, chamise \"Adenostoma fasciculatum\" and \"Ceanothus\" species, toyon (which can sometimes be interspersed with scrub oaks), and other drought-resistant shrubs with hard (sclerophyllous) leaves; these plants resprout (see resprouter) from underground burls after a fire.\nPlants that are long-lived in the seed bank or serotinous with induced germination after fire include chamise\", Ceanothus,\" and fiddleneck\".\" Some chaparral plant communities may grow so dense and tall that it becomes difficult for large animals and humans to penetrate, but may be teeming with smaller fauna in the understory. The seeds of many chaparral plant species are stimulated to germinate by some fire cue (heat or the chemicals from smoke or charred wood). During the time shortly after a fire, chaparral communities may contain soft-leaved herbaceous, fire following annual wildflowers and short-lived perennials that dominate the community for the first few years \u2013 until the burl resprouts and seedlings of chaparral shrub species create a mature, dense overstory. Seeds of annuals and shrubs lie dormant until the next fire creates the conditions needed for germination.\nSeveral shrub species such as \"Ceanothus\" fix nitrogen, increasing the availability of nitrogen compounds in the soil.\nBecause of the hot, dry conditions that exist in the California summer and fall, chaparral is one of the most fire-prone plant communities in North America. Some fires are caused by lightning, but these are usually during periods of high humidity and low winds and are easily controlled. Nearly all of the very large wildfires are caused by human activity during periods of hot, dry easterly Santa Ana winds. These human-caused fires are commonly ignited by power line failures, vehicle fires and collisions, sparks from machinery, arson, or campfires.\nThreatened by high fire frequency.\nThough adapted to infrequent fires, chaparral plant communities can be eliminated by frequent fires. A high frequency of fire (less than 10-15 years apart) will result in the loss of obligate seeding shrub species such as \"Manzanita\" spp. This high frequency disallows seeder plants to reach their reproductive size before the next fire and the community shifts to a sprouter-dominance. If high frequency fires continue over time, obligate resprouting shrub species can also be eliminated by exhausting their energy reserves below-ground. Today, frequent accidental ignitions can convert chaparral from a native shrubland to non-native annual grassland and drastically reduce species diversity, especially under drought brought about by climate change.\nWildfire debate.\nThere are two older hypotheses relating to California chaparral fire regimes that caused considerable debate in the past within the fields of wildfire ecology and land management. Research over the past two decades have rejected these hypotheses:\nThe perspective that older chaparral is unhealthy or unproductive may have originated during the 1940s when studies were conducted measuring the amount of forage available to deer populations in chaparral stands. However, according to recent studies, California chaparral is extraordinarily resilient to very long periods without fire and continues to maintain productive growth throughout pre-fire conditions. Seeds of many chaparral plants actually require 30 years or more worth of accumulated leaf litter before they will successfully germinate (e.g., scrub oak, \"Quercus berberidifolia\"; toyon, \"Heteromeles arbutifolia\"; and holly-leafed cherry, \"Prunus ilicifolia\"). When intervals between fires drop below 10 to 15 years, many chaparral species are eliminated and the system is typically replaced by non-native, invasive, weedy grassland.\nThe idea that older chaparral is responsible for causing large fires was originally proposed in the 1980s by comparing wildfires in Baja California and southern California. It was suggested that fire suppression activities in southern California allowed more fuel to accumulate, which in turn led to larger fires. This is similar to the observation that fire suppression and other human-caused disturbances in dry, ponderosa pine forests in the Southwest of the United States has unnaturally increased forest density. Historically, mixed-severity fires likely burned through these forests every decade or so, burning understory plants, small trees, and downed logs at low-severity, and patches of trees at high-severity. However, chaparral has a high-intensity crown-fire regime, meaning that fires consume nearly all the above ground growth whenever they burn, with a historical frequency of 30 to 150 years or more. A detailed analysis of historical fire data concluded that fire suppression activities have been ineffective at excluding fire from southern California chaparral, unlike in ponderosa pine forests. In addition, the number of fires is increasing in step with population growth and exacerbated by climate change. Chaparral stand age does not have a significant correlation to its tendency to burn.\nLarge, infrequent, high-intensity wildfires are part of the natural fire regime for California chaparral. Extreme weather conditions (low humidity, high temperature, high winds), drought, and low fuel moisture are the primary factors in determining how large a chaparral fire becomes."}
{"id": "7456", "revid": "43791626", "url": "https://en.wikipedia.org/wiki?curid=7456", "title": "CJD", "text": "CJD can mean:"}
{"id": "7457", "revid": "35107032", "url": "https://en.wikipedia.org/wiki?curid=7457", "title": "Cl", "text": ""}
{"id": "7460", "revid": "11995480", "url": "https://en.wikipedia.org/wiki?curid=7460", "title": "Clinker", "text": "Clinker may refer to:\nClinker may also refer to:"}
{"id": "7461", "revid": "19093512", "url": "https://en.wikipedia.org/wiki?curid=7461", "title": "Clipper", "text": "A clipper was a type of mid-19th-century merchant sailing vessel, designed for speed. The term was also retrospectively applied to the Baltimore clipper, which originated in the late 18th century.\nClippers were generally narrow for their length, small by later 19th-century standards, could carry limited bulk freight, and had a large total sail area. \"Clipper\" does not refer to a specific sailplan; clippers may be schooners, brigs, brigantines, etc., as well as full-rigged ships. Clippers were mostly constructed in British and American shipyards, although France, Brazil, the Netherlands, and other nations also produced some. Clippers sailed all over the world, primarily on the trade routes between the United Kingdom and China, in transatlantic trade, and on the New York-to-San Francisco route around Cape Horn during the California gold rush. Dutch clippers were built beginning in the 1850s for the tea trade and passenger service to Java.\nThe boom years of the clipper era began in 1843 in response to a growing demand for faster delivery of tea from China and continued with the demand for swift passage to gold fields in California and Australia beginning in 1848 and 1851, respectively. The era ended with the opening of the Suez Canal in 1869.\nOrigin and usage of \"clipper\".\nThe etymological origin of the word clipper is uncertain, but is believed to be derived from the English language verb \"to clip\", which at the time meant \"to run or fly swiftly\".\nThe first application of the term \"clipper\", in a nautical sense, is likewise uncertain. The type known as the Baltimore clipper originated at the end of the 18th century on the eastern seaboard of the USA. At first, these fast sailing vessels were referred to as \"Virginia-built\" or \"pilot-boat model\", with the name \"Baltimore-built\" appearing during the War of 1812. In the final days of the slave trade (\"circa\" 1835\u20131850)just as the type was dying outthe term, Baltimore clipper, became common. The common retrospective application of the word \"clipper\" to this type of vessel has caused confusion.\nThe Oxford English Dictionary's earliest quote (referring to the Baltimore clipper) is from 1824. The dictionary cites Royal Navy officer and novelist Frederick Marryat as using the term in 1830. British newspaper usage of the term can be found as early as 1832 and in shipping advertisements from 1835. A US court case of 1834 has evidence that discusses a clipper being faster than a brig.\nDefinitions.\nA clipper is a sailing vessel designed for speed, a priority that takes precedence over cargo-carrying capacity or building or operating costs. It is not restricted to any one rig (while many were fully rigged ships, others were barques, brigs, or schooners), nor was the term restricted to any one hull type. Howard Chapelle lists three basic hull types for clippers. The first was characterised by the sharp and ends found in the Baltimore clipper. The second was a hull with a full midsection and modest deadrise, but sharp endsthis was a development of the hull form of transatlantic packets. The third was more experimental, with deadrise and sharpness being balanced against the need to carry a profitable quantity of cargo. A clipper carried a large sail area and a fast hull; by the standards of any other type of sailing ship, a clipper was greatly over-canvassed. The last defining feature of a clipper, in the view of maritime historian David MacGregor, was a captain who had the courage, skill, and determination to get the fastest speed possible out of her.\nIn assessing the hull of a clipper, different maritime historians use different criteria to measure \"sharpness\", \"fine lines\" or \"fineness\", a concept which is explained by comparing a rectangular cuboid with the underwater shape of a vessel's hull. The more material one has to carve off the cuboid to achieve the hull shape, the sharper the hull. Ideally, a maritime historian would be able to look at either the block coefficient of fineness or the prismatic coefficient of various clippers, but measured drawings or accurate half models may not exist to calculate either of these figures. An alternative measure of sharpness for hulls of a broadly similar shape is the coefficient of underdeck tonnage, as used by David MacGregor in comparing tea clippers. This could be calculated from the measurements taken to determine the registered tonnage, so can be applied to more vessels.\nAn extreme clipper has a hull of great fineness, as judged either by the prismatic coefficient, the coefficient of underdeck tonnage, or some other technical assessment of hull shape. This term has been misapplied in the past, without reference to hull shape. As commercial vessels, these are totally reliant on speed to generate a profit for their owners, as their sharpness limits their cargo-carrying capacity.\nA medium clipper has a cargo-carrying hull that has some sharpness. In the right conditions and with a capable captain, some of these achieved notable quick passages. They were also able to pay their way when the high freight rates often paid to a fast sailing ship were not available (in a fluctuating market).\nThe term \"clipper\" applied to vessels between these two categories. They often made passages as fast as extreme clippers, but had less difficulty in making a living when freight rates were lower.\nHistory.\nThe first ships to which the term \"clipper\" seems to have been applied were the Baltimore clippers, developed in the Chesapeake Bay before the American Revolution, and reached their zenith between 1795 and 1815. They were small, rarely exceeding 200 tons OM. Their hulls were sharp ended and displayed much deadrise. They were rigged as schooners, brigs, or brigantines.\nIn the War of 1812, some were lightly armed, sailing under letters of marque and reprisal, when the typeexemplified by \"Chasseur\", launched at Fells Point, Baltimore in 1814became known for her incredible speed; the deep draft enabled the Baltimore clipper to sail close to the wind. Clippers, running the British blockade of Baltimore, came to be recognized for speed rather than cargo space.\nThe type existed as early as 1780. A 1789 drawing of purchased by the Royal Navy in 1780 in the West Indiesrepresents the earliest draught of what became known as the Baltimore clipper.\nVessels of the Baltimore clipper type continued to be built for the slave trade, being useful for escaping enforcement of the British and American legislation prohibiting the trans-Atlantic slave trade. Some of these Baltimore clippers were captured when working as slavers, condemned by the appropriate court, and sold to owners who then used them as opium clippersmoving from one illegal international trade to another.\n\"Ann McKim\", built in Baltimore in 1833 by the Kennard &amp; Williamson shipyard, is considered by some to be the original clipper ship. (Maritime historians Howard I. Chapelle and David MacGregor decry the concept of the \"first\" clipper, preferring a more evolutionary, multiple-step development of the type.) She measured 494 tons OM, and was built on the enlarged lines of a Baltimore clipper, with sharply raked stem, counter stern, and square rig. Although \"Ann McKim\" was the first large clipper ship ever constructed, she cannot be said to have founded the clipper ship era, or even that she directly influenced shipbuilders, since no other ship was built like her, but she may have suggested the clipper design in vessels of ship rig. She did, however, influence the building of \"Rainbow\" in 1845, the first extreme clipper ship.\nIn Aberdeen, Scotland, shipbuilders Alexander Hall and Sons developed the \"Aberdeen\" clipper bow in the late 1830s; the first was \"Scottish Maid\" launched in 1839. \"Scottish Maid\", 150 tons OM, was the first British clipper ship. \"\"Scottish Maid\" was intended for the Aberdeen-London trade, where speed was crucial to compete with steamships. The Hall brothers tested various hulls in a water tank and found the clipper design most effective. The design was influenced by tonnage regulations. Tonnage measured a ship's cargo capacity and was used to calculate tax and harbour dues. The new 1836 regulations measured depth and breadth with length measured at half midship depth. Extra length above this level was tax-free and became a feature of clippers. \"Scottish Maid\" proved swift and reliable and the design was widely copied.\" The earliest British clipper ships were built for trade within the British Isles (\"Scottish Maid\" was built for the Aberdeen to London trade). Then followed the vast clipper trade of tea, opium, spices, and other goods from the Far East to Europe, and the ships became known as \"tea clippers\".\nFrom 1839, larger American clipper ships started to be built beginning with \"Akbar\", 650 tons OM, in 1839, and including the 1844-built \"Houqua\", 581 tons OM. These larger vessels were built predominantly for use in the China tea trade and known as \"tea clippers\".\nThen in 1845 \"Rainbow\", 757 tons OM, the first extreme clipper, was launched in New York. These American clippers were larger vessels designed to sacrifice cargo capacity for speed. They had a bow lengthened above the water, a drawing out and sharpening of the forward body, and the greatest breadth further aft. Extreme clippers were built in the period 1845 to 1855.\nIn 1851, shipbuilders in Medford, Massachusetts, built what is sometimes called one of the first medium clippers, the \"Antelope\", often called the \"Antelope of Boston\" to distinguish her from other ships of the same name. A contemporary ship-design journalist noted that \"the design of her model was to combine large stowage capacity with good sailing qualities.\" \"Antelope\" was relatively flat-floored and had only an 8-inch deadrise at half-floor.\nThe medium clipper, though still very fast, could carry more cargo. After 1854, extreme clippers were replaced in American shipbuilding yards by medium clippers.\nThe \"Flying Cloud\" was a clipper ship built in 1851 that established the fastest passage between New York and San Francisco within weeks of her launching, then broke her own records three years later, which stood at 89 days 8 hours until 1989. (The other contender for this \"blue ribbon\" title was the medium clipper \"Andrew Jackson\"an unresolvable argument exists over timing these voyages \"from pilot to pilot\"). \"Flying Cloud\" was the most famous of the clippers built by Donald McKay. She was known for her extremely close race with the \"Hornet\" in 1853; for having a woman navigator, Eleanor Creesy, wife of Josiah Perkins Creesy, who skippered the \"Flying Cloud\" on two record-setting voyages from New York to San Francisco; and for sailing in the Australia and timber trades.\nClipper ships largely ceased being built in American shipyards in 1859 when, unlike the earlier boom years, only four clipper ships were built; a few were built in the 1860s. \nBritish clipper ships continued to be built after 1859. From 1859, a new design was developed for British clipper ships that was nothing like the American clippers; these ships continued to be called extreme clippers. The new design had a sleek, graceful appearance, less sheer, less freeboard, lower bulwarks, and smaller breadth. They were built for the China tea trade, starting with \"Falcon\" in 1859, and continuing until 1870. The earlier ships were made from wood, though some were made from iron, just as some British clippers had been made from iron prior to 1859. In 1863, the first tea clippers of composite construction were brought out, combining the best of both worlds. Composite clippers had the strength of an iron hull framework but with wooden planking that, with properly insulated fastenings, could use copper sheathing without the problem of galvanic corrosion. Copper sheathing prevented fouling and teredo worm, but could not be used on iron hulls. The iron framework of composite clippers was less bulky and lighter, so allowing more cargo in a hull of the same external shape.\nAfter 1869, with the opening of the Suez Canal that greatly advantaged steam vessels (see Decline below), the tea trade collapsed for clippers. From the late 1860s until the early 1870s, the clipper trade increasingly focused on the Britain to Australia and New Zealand route, carrying goods and immigrants, services that had begun earlier with the Australian Gold Rush of the 1850s. British-built clipper ships and many American-built, British-owned ships were used. Even in the 1880s, sailing ships were still the main carriers of cargo between Britain, and Australia and New Zealand. This trade eventually became unprofitable, and the ageing clipper fleet became unseaworthy.\nOpium clippers.\nBefore the early 18th century, the East India Company paid for its tea mainly in silver. When the Chinese emperor chose to embargo European-manufactured commodities and demand payment for all Chinese goods in silver, the price rose, restricting trade. The East India Company began to produce opium in India, something desired by the Chinese as much as tea was by the British. This had to be smuggled into China on smaller, fast-sailing ships, called \"opium clippers\". Some of these were built specifically for the purposemostly in India and Britain, such as the 1842-built \"Ariel\", 100 tons OM. Some fruit schooners were bought for this trade, as were some Baltimore clippers.\nChina clippers and the apogee of sail.\nAmong the most notable clippers were the China clippers, also called tea clippers, designed to ply the trade routes between Europe and the East Indies. The last example of these still in reasonable condition is \"Cutty Sark\", preserved in dry dock at Greenwich, United Kingdom. Damaged by fire on 21 May 2007 while undergoing conservation, the ship was permanently elevated 3.0 m above the dry dock floor in 2010 as part of a plan for long-term preservation.\nClippers were built for seasonal trades such as tea, where an early cargo was more valuable, or for passenger routes. One passenger ship survives, the \"City of Adelaide\" designed by William Pile of Sunderland. The fast ships were ideally suited to low-volume, high-profit goods, such as tea, opium, spices, people, and mail. The return could be spectacular. The \"Challenger\" returned from Shanghai with \"the most valuable cargo of tea and silk ever to be laden in one bottom\". Competition among the clippers was public and fierce, with their times recorded in the newspapers.\nThe last China clippers had peak speeds over , but their average speeds over a whole voyage were substantially less. The joint winner of the Great Tea Race of 1866 logged about 15,800 nautical miles on a 99-day trip. This gives an average speed slightly over . The key to a fast passage for a tea clipper was getting across the China Sea against the monsoon winds that prevailed when the first tea crop of the season was ready. These difficult sailing conditions (light and/or contrary winds) dictated the design of tea clippers. The US clippers were designed for the strong winds encountered on their route around Cape Horn.\nDonald McKay's \"Sovereign of the Seas\" reported the highest speed ever achieved by a sailing ship of the era, , made while running her easting down to Australia in 1854. (John Griffiths' first clipper, the \"Rainbow\", had a top speed of 14 knots.) Eleven other instances are reported of a ship's logging or over. Ten of these were recorded by American clippers.\nBesides the breath-taking day's run of the \"Champion of the Seas\", 13 other cases are known of a ship's sailing over in 24 hours.\nWith few exceptions, though, all the port-to-port sailing records are held by the American clippers.\nThe 24-hour record of the \"Champion of the Seas\", set in 1854, was not broken until 1984 (by a multihull), or 2001 (by another monohull).\nDecline.\nThe American clippers sailing from the East Coast to the California goldfields were working in a booming market. Freight rates were high everywhere in the first years of the 1850s. This started to fade in late 1853. The ports of California and Australia reported that they were overstocked with goods that had been shipped earlier in the year. This gave an accelerating fall in freight rates that was halted, however, by the start of the Crimean War in March 1854, as many ships were now being chartered by the French and British governments. The end of the Crimean War in April 1856 released all this capacity back on the world shipping marketsthe result being a severe slump. The next year had the Panic of 1857, with effects on both sides of the Atlantic. The United States was just starting to recover from this in 1861 when the American Civil War started, causing significant disruption to trade in both Union and Confederate states.\nAs the economic situation deteriorated in 1853, American shipowners either did not order new vessels, or specified an ordinary clipper or a medium clipper instead of an extreme clipper. No extreme clipper was launched in an American shipyard after the end of 1854 and only a few medium clippers after 1860.\nBy contrast, British trade recovered well at the end of the 1850s. Tea clippers had continued to be launched during the depressed years, apparently little affected by the economic downturn. The long-distance route to China was not realistically challenged by steamships in the early part of the 1860s. No true steamer (as opposed to an auxiliary steamship) had the fuel efficiency to carry sufficient cargo to make a profitable voyage. The auxiliary steamships struggled to make any profit.\nThe situation changed in 1866 when the Alfred Holt-designed and owned SS \"Agamemnon\" made her first voyage to China. Holt had persuaded the Board of Trade to allow higher steam pressures in British merchant vessels. Running at 60\u00a0psi instead of the previously permitted 25\u00a0psi, and using an efficient compound engine, \"Agamemnon\" had the fuel efficiency to steam at 10\u00a0knots to China and back, with coaling stops at Mauritius on the outward and return legscrucially carrying sufficient cargo to make a profit.\nIn 1869, the Suez Canal opened, giving steamships a route about shorter than that taken by sailing ships round the Cape of Good Hope. Despite initial conservatism by tea merchants, by 1871, tea clippers found strong competition from steamers in the tea ports of China. A typical passage time back to London for a steamer was 58 days, while the fastest clippers could occasionally make the trip in less than 100 days; the average was 123 days in the 1867\u201368 tea season. The freight rate for a steamer in 1871 was roughly double that paid to a sailing vessel. Some clipper owners were severely caught out by this; several extreme clippers had been launched in 1869, including \"Cutty Sark\", \"Norman Court\" and \"Caliph\".\nSurviving ships.\nOf the many clipper ships built during the mid-19th century, only two are known to survive. The only intact survivor is \"Cutty Sark\", which was preserved as a museum ship in 1954 at Greenwich for public display. The other known survivor is \"City of Adelaide\"; unlike \"Cutty Sark\", she was reduced to a hulk over the years. She eventually sank at her moorings in 1991, but was raised the following year, and remained on dry land for years. \"Adelaide\" (or S.V. \"Carrick\") is the older of the two survivors, and was transported to Australia for conservation.\nIn popular culture.\nThe clipper legacy appears in collectible cards and in the name of a basketball team.\nSailing cards.\nDepartures of clipper ships, mostly from New York and Boston to San Francisco, were advertised by clipper-ship sailing cards. These cards, slightly larger than today's postcards, were produced by letterpress and wood engraving on coated card stock. Most clipper cards were printed in the 1850s and 1860s, and represented the first pronounced use of color in American advertising art. Perhaps 3,500 cards survive. With their rarity and importance as artifacts of nautical, Western, and printing history, clipper cards are valued by both private collectors and institutions.\nBasketball team.\nThe Los Angeles Clippers of the National Basketball Association take their name from the type of ship. After the Buffalo Braves moved to San Diego, California in 1978, a contest was held to choose a new name. The winning name highlighted the city's connection with the clippers that frequented San Diego Bay. The team retained the name in its 1984 move to Los Angeles.\nAirliners.\nThe airline Pan Am named its aircraft beginning with the word 'Clipper' and used Clipper as its callsign. This was intended to evoke an image of speed and glamour."}
{"id": "7462", "revid": "7609619", "url": "https://en.wikipedia.org/wiki?curid=7462", "title": "Clive Anderson", "text": "Clive Stuart Anderson (born 10 December 1952) is an English television and radio presenter, comedian, writer and former barrister. Winner of a British Comedy Award in 1991, Anderson began experimenting with comedy and writing comedic scripts during his 15-year legal career. He then became host of \"Whose Line Is It Anyway?\", initially a radio show on BBC Radio 4 in 1988, before moving to television on Channel 4 from 1988 to 1999. He was also host of his own chat show \"Clive Anderson Talks Back\", which changed its name to \"Clive Anderson All Talk\" in 1996, from 1989 to 1999. He has also hosted many radio programmes and made guest appearances on \"Have I Got News for You\", \"Mock the Week\" and \"QI\".\nEarly life.\nAnderson's mother was English and his parents met while serving in the RAF. He was educated at Stanburn Primary School and Harrow County School for Boys then a grammar school which closed in 1975. His group of contemporaries included Geoffrey Perkins and Michael Portillo. His Scottish father originally from Glasgow was promoted to manager of the Bradford &amp; Bingley Building Society, Wembley branch. Anderson attended Selwyn College, Cambridge, where, from 1974 to 1975, he was President of the Cambridge Footlights. He was called to the bar at the Middle Temple in 1976 and became a practising barrister, specialising in criminal law. While still practising law, he continued performing, including taking a show to the Edinburgh Fringe in 1981 with Griff Rhys Jones.\nCareer.\nTelevision.\nAnderson was involved in the fledgling alternative comedy scene in the early 1980s and was the first act to appear at The Comedy Store when it opened in 1979. He made his name as host of the original UK version of the improvised television comedy show \"Whose Line Is It Anyway?\", which ran for 10 series on Channel 4 from 1988 to 1999.\nAnderson hosted his own chat show \"Clive Anderson Talks Back\", which ran for 10 series on Channel 4 from 1989 to 1996. The show then moved to the BBC, with the name changed to \"Clive Anderson All Talk\", running for 4 series from 1996 to 1999. In one incident in 1997, Anderson was deserted by his guests, the Bee Gees, after he made several digs at them and their music. He once had a glass of water poured over his head by a perturbed Richard Branson, to which he replied, \"I'm used to that; I've flown Virgin.\" When singer and actress Cher appeared on the show, Anderson alluded to her alleged cosmetic surgery, asking her \"You look like a million dollars \u2013 is that how much it cost?\" He also said to author and politician Jeffrey Archer, in response to his derogatory comment about the show, \"You're a critic too... there's no beginning to your talents.\" Archer retorted that \"The old ones are always the best\" for Anderson to reply \"Yes, I've read your books.\"\nHe has made ten appearances on \"Have I Got News for You\". In 1996, a heated exchange occurred on the show when he joked to fellow guest Piers Morgan that the \"Daily Mirror\" was now, thanks to Morgan (then its editor), almost as good as \"The Sun\". When asked by Morgan, \"What do you know about editing newspapers?\" he swiftly replied \"About as much as you do\". Anderson has also frequently appeared on \"QI\". In 2007, he featured as a regular panellist on the ITV comedy show \"News Knight\". From 2019 to 2020 he co-hosted the television series \"Mystic Britain\" on the Sky television channel Smithsonian. \nIn 2005, he presented the short-lived quiz \"Back in the Day\" for Channel 4. On 25 February 2008, he started to present \"Brainbox Challenge\", a new game show, for BBC Two. Later that year, he presented a talent show-themed reality TV series produced by the BBC entitled \"Maestro\", starring eight celebrities. In 2009, Anderson was the television host of the BBC's \"Last Night of the Proms\".\nIn November 2023, Anderson appeared on TV game show \"Richard Osman's House of Games\", winning the show by one point.\nRadio.\nAnderson presents legal show \"Unreliable Evidence\" on BBC Radio 4. He also covered the Sunday morning 11\u00a0a.m. to 1\u00a0p.m. show on BBC Radio 2 until the end of January 2008.\nIn early 1988, Anderson hosted the original radio version of \"Whose Line Is It Anyway?\", which ran for 6 episodes on BBC Radio 4 before the show moved to television later that year.\nIt was announced in April 2008 that Anderson, who had previously filled in for host Ned Sherrin from 2006 until Sherrin's death in 2007, would be taking over as permanent host of \"Loose Ends\". He also hosted six series of \"Clive Anderson's Chat Room\" on BBC Radio 2 from 2004 to 2009. Anderson has appeared on BBC Radio 4's \"The Unbelievable Truth\" hosted by David Mitchell.\nAnderson also presented the radio show \"The Guessing Game\" on BBC Radio Scotland. Anderson has also appeared on BBC Radio 5 Live's \"Fighting Talk\".\nComedy and newspaper writing.\nAnderson is a comedy sketch writer who has written for Frankie Howerd, \"Not the Nine O'Clock News\", and Griff Rhys Jones and Mel Smith. One of his early comedy writing projects was \"Black Cinderella Two Goes East\" with Rory McGrath for BBC Radio 4 in 1978. As well as writing comedy, Anderson is also a frequent contributor to newspapers and was a regular columnist for \"The Sunday Correspondent\".\nPersonal life.\nAnderson lives in Highbury, north London, with his consultant wife, Jane Anderson, a physician who has spent her career in managing HIV/AIDS. The couple have three children.\nHe supports Arsenal, and Rangers football teams. He is President of the Woodland Trust and became Vice Patron of the Solicitors' Benevolent Association, a registered charity.\nAwards.\nThe show \"Whose Line is it Anyway?\" won a BAFTA award in 1990. Later, Anderson won both the \"Top Entertainment Presenter\" and \"Top Radio Comedy Personality\" at the British Comedy Awards in 1991. In 2023 he was made an Honorary Fellow of Selwyn College, Cambridge."}
{"id": "7463", "revid": "169132", "url": "https://en.wikipedia.org/wiki?curid=7463", "title": "Cold fusion", "text": "Cold fusion is a hypothesized type of nuclear reaction that would occur at, or near, room temperature. It would contrast starkly with the \"hot\" fusion that is known to take place naturally within stars and artificially in hydrogen bombs and prototype fusion reactors under immense pressure and at temperatures of millions of degrees, and be distinguished from muon-catalyzed fusion. There is currently no accepted theoretical model that would allow cold fusion to occur.\nIn 1989, two electrochemists at the University of Utah, Martin Fleischmann and Stanley Pons, reported that their apparatus had produced anomalous heat (\"excess heat\") of a magnitude they asserted would defy explanation except in terms of nuclear processes. They further reported measuring small amounts of nuclear reaction byproducts, including neutrons and tritium. The small tabletop experiment involved electrolysis of heavy water on the surface of a palladium (Pd) electrode. The reported results received wide media attention and raised hopes of a cheap and abundant source of energy.\nMany scientists tried to replicate the experiment with the few details available. Expectations diminished as a result of numerous failed replications, the retraction of several previously reported positive replications, the identification of methodological flaws and experimental errors in the original study, and, ultimately, the confirmation that Fleischmann and Pons had not observed the expected nuclear reaction byproducts. By late 1989, most scientists considered cold fusion claims dead, and cold fusion subsequently gained a reputation as pathological science. In 1989 the United States Department of Energy (DOE) concluded that the reported results of excess heat did not present convincing evidence of a useful source of energy and decided against allocating funding specifically for cold fusion. A second DOE review in 2004, which looked at new research, reached similar conclusions and did not result in DOE funding of cold fusion. Presently, since articles about cold fusion are rarely published in peer-reviewed mainstream scientific journals, they do not attract the level of scrutiny expected for mainstream scientific publications.\nNevertheless, some interest in cold fusion has continued through the decades\u2014for example, a Google-funded failed replication attempt was published in a 2019 issue of \"Nature\". A small community of researchers continues to investigate it, often under the alternative designations \"low-energy nuclear reactions\" (\"LENR\") or \"condensed matter nuclear science\" (\"CMNS\").\nHistory.\nNuclear fusion is normally understood to occur at temperatures in the tens of millions of degrees. This is called \"thermonuclear fusion\". Since the 1920s, there has been speculation that nuclear fusion might be possible at much lower temperatures by catalytically fusing hydrogen absorbed in a metal catalyst. In 1989, a claim by Stanley Pons and Martin Fleischmann (then one of the world's leading electrochemists) that such cold fusion had been observed caused a brief media sensation before the majority of scientists criticized their claim as incorrect after many found they could not replicate the excess heat. Since the initial announcement, cold fusion research has continued by a small community of researchers who believe that such reactions happen and hope to gain wider recognition for their experimental evidence.\nEarly research.\nThe ability of palladium to absorb hydrogen was recognized as early as the nineteenth century by Thomas Graham. In the late 1920s, two Austrian-born scientists, Friedrich Paneth and Kurt Peters, originally reported the transformation of hydrogen into helium by nuclear catalysis when hydrogen was absorbed by finely divided palladium at room temperature. However, the authors later retracted that report, saying that the helium they measured was due to background from the air.\nIn 1927, Swedish scientist John Tandberg reported that he had fused hydrogen into helium in an electrolytic cell with palladium electrodes. On the basis of his work, he applied for a Swedish patent for \"a method to produce helium and useful reaction energy\". Due to Paneth and Peters's retraction and his inability to explain the physical process, his patent application was denied. After deuterium was discovered in 1932, Tandberg continued his experiments with heavy water. The final experiments made by Tandberg with heavy water were similar to the original experiment by Fleischmann and Pons. Fleischmann and Pons were not aware of Tandberg's work.\nThe term \"cold fusion\" was used as early as 1956 in an article in \"The New York Times\" about Luis Alvarez's work on muon-catalyzed fusion. Paul Palmer and then Steven Jones of Brigham Young University used the term \"cold fusion\" in 1986 in an investigation of \"geo-fusion\", the possible existence of fusion involving hydrogen isotopes in a planetary core. In his original paper on this subject with Clinton Van Siclen, submitted in 1985, Jones had coined the term \"piezonuclear fusion\".\nFleischmann\u2013Pons experiment.\nThe most famous cold fusion claims were made by Stanley Pons and Martin Fleischmann in 1989. After a brief period of interest by the wider scientific community, their reports were called into question by nuclear physicists. Pons and Fleischmann never retracted their claims, but moved their research program from the US to France after the controversy erupted.\nEvents preceding announcement.\nMartin Fleischmann of the University of Southampton and Stanley Pons of the University of Utah hypothesized that the high compression ratio and mobility of deuterium that could be achieved within palladium metal using electrolysis might result in nuclear fusion. To investigate, they conducted electrolysis experiments using a palladium cathode and heavy water within a calorimeter, an insulated vessel designed to measure process heat. Current was applied continuously for many weeks, with the heavy water being renewed at intervals. Some deuterium was thought to be accumulating within the cathode, but most was allowed to bubble out of the cell, joining oxygen produced at the anode. For most of the time, the power input to the cell was equal to the calculated power leaving the cell within measurement accuracy, and the cell temperature was stable at around 30\u00a0\u00b0C. But then, at some point (in some of the experiments), the temperature rose suddenly to about 50\u00a0\u00b0C without changes in the input power. These high temperature phases would last for two days or more and would repeat several times in any given experiment once they had occurred. The calculated power leaving the cell was significantly higher than the input power during these high temperature phases. Eventually the high temperature phases would no longer occur within a particular cell.\nIn 1988, Fleischmann and Pons applied to the United States Department of Energy for funding towards a larger series of experiments. Up to this point they had been funding their experiments using a small device built with $100,000 out-of-pocket. The grant proposal was turned over for peer review, and one of the reviewers was Steven Jones of Brigham Young University. Jones had worked for some time on muon-catalyzed fusion, a known method of inducing nuclear fusion without high temperatures, and had written an article on the topic entitled \"Cold nuclear fusion\" that had been published in \"Scientific American\" in July 1987. Fleischmann and Pons and co-workers met with Jones and co-workers on occasion in Utah to share research and techniques. During this time, Fleischmann and Pons described their experiments as generating considerable \"excess energy\", in the sense that it could not be explained by chemical reactions alone. They felt that such a discovery could bear significant commercial value and would be entitled to patent protection. Jones, however, was measuring neutron flux, which was not of commercial interest. To avoid future problems, the teams appeared to agree to publish their results simultaneously, though their accounts of their 6 March meeting differ.\nAnnouncement.\nIn mid-March 1989, both research teams were ready to publish their findings, and Fleischmann and Jones had agreed to meet at an airport on 24 March to send their papers to \"Nature\" via FedEx. Fleischmann and Pons, however, pressured by the University of Utah, which wanted to establish priority on the discovery, broke their apparent agreement, disclosing their work at a press conference on 23 March (they claimed in the press release that it would be published in \"Nature\" but instead submitted their paper to the \"Journal of Electroanalytical Chemistry\"). Jones, upset, faxed in his paper to \"Nature\" after the press conference.\nFleischmann and Pons' announcement drew wide media attention, as well as attention from the scientific community. The 1986 discovery of high-temperature superconductivity had made scientists more open to revelations of unexpected but potentially momentous scientific results that could be replicated reliably even if they could not be explained by established theories. Many scientists were also reminded of the M\u00f6ssbauer effect, a process involving nuclear transitions in a solid. Its discovery 30 years earlier had also been unexpected, though it was quickly replicated and explained within the existing physics framework.\nThe announcement of a new purported clean source of energy came at a crucial time: adults still remembered the 1973 oil crisis and the problems caused by oil dependence, anthropogenic global warming was starting to become notorious, the anti-nuclear movement was labeling nuclear power plants as dangerous and getting them closed, people had in mind the consequences of strip mining, acid rain, the greenhouse effect and the Exxon Valdez oil spill, which happened the day after the announcement. In the press conference, Chase N. Peterson, Fleischmann and Pons, backed by the solidity of their scientific credentials, repeatedly assured the journalists that cold fusion would solve environmental problems, and would provide a limitless inexhaustible source of clean energy, using only seawater as fuel. They said the results had been confirmed dozens of times and they had no doubts about them. In the accompanying press release Fleischmann was quoted saying: \"What we have done is to open the door of a new research area, our indications are that the discovery will be relatively easy to make into a usable technology for generating heat and power, but continued work is needed, first, to further understand the science and secondly, to determine its value to energy economics.\"\nResponse and fallout.\nAlthough the experimental protocol had not been published, physicists in several countries attempted, and failed, to replicate the excess heat phenomenon. The first paper submitted to \"Nature\" reproducing excess heat, although it passed peer review, was rejected because most similar experiments were negative and there were no theories that could explain a positive result; this paper was later accepted for publication by the journal \"Fusion Technology\".\nNathan Lewis, professor of chemistry at the California Institute of Technology, led one of the most ambitious validation efforts, trying many variations on the experiment without success, while CERN physicist Douglas R. O. Morrison said that \"essentially all\" attempts in Western Europe had failed. Even those reporting success had difficulty reproducing Fleischmann and Pons' results. On 10 April 1989, a group at Texas A&amp;M University published results of excess heat and later that day a group at the Georgia Institute of Technology announced neutron production\u2014the strongest replication announced up to that point due to the detection of neutrons and the reputation of the lab. On 12 April Pons was acclaimed at an ACS meeting. But Georgia Tech retracted their announcement on 13 April, explaining that their neutron detectors gave false positives when exposed to heat.\nAnother attempt at independent replication, headed by Robert Huggins at Stanford University, which also reported early success with a light water control, became the only scientific support for cold fusion in 26 April US Congress hearings. But when he finally presented his results he reported an excess heat of only one degree Celsius, a result that could be explained by chemical differences between heavy and light water in the presence of lithium. He had not tried to measure any radiation and his research was derided by scientists who saw it later. For the next six weeks, competing claims, counterclaims, and suggested explanations kept what was referred to as \"cold fusion\" or \"fusion confusion\" in the news.\nIn April 1989, Fleischmann and Pons published a \"preliminary note\" in the \"Journal of Electroanalytical Chemistry\". This paper notably showed a gamma peak without its corresponding Compton edge, which indicated they had made a mistake in claiming evidence of fusion byproducts. Fleischmann and Pons replied to this critique, but the only thing left clear was that no gamma ray had been registered and that Fleischmann refused to recognize any mistakes in the data. A much longer paper published a year later went into details of calorimetry but did not include any nuclear measurements.\nNevertheless, Fleischmann and Pons and a number of other researchers who found positive results remained convinced of their findings. The University of Utah asked Congress to provide $25\u00a0million to pursue the research, and Pons was scheduled to meet with representatives of President Bush in early May.\nOn 30 April 1989, cold fusion was declared dead by \"The New York Times\". The \"Times\" called it a circus the same day, and the \"Boston Herald\" attacked cold fusion the following day.\nOn 1 May 1989, the American Physical Society held a session on cold fusion in Baltimore, including many reports of experiments that failed to produce evidence of cold fusion. At the end of the session, eight of the nine leading speakers stated that they considered the initial Fleischmann and Pons claim dead, with the ninth, Johann Rafelski, abstaining. Steven E. Koonin of Caltech called the Utah report a result of \"the incompetence and delusion of Pons and Fleischmann,\" which was met with a standing ovation. Douglas R. O. Morrison, a physicist representing CERN, was the first to call the episode an example of pathological science. On 4 May, due to all this new criticism, the meetings with various representatives from Washington were cancelled.\nFrom 8 May, only the A&amp;M tritium results kept cold fusion afloat.\nIn July and November 1989, \"Nature\" published papers critical of cold fusion claims. Negative results were also published in several other scientific journals including \"Science\", \"Physical Review Letters\", and \"Physical Review C\" (nuclear physics). In August 1989, in spite of this trend, the state of Utah invested $4.5\u00a0million to create the National Cold Fusion Institute.\nThe United States Department of Energy organized a special panel to review cold fusion theory and research. The panel issued its report in November 1989, concluding that results as of that date did not present convincing evidence that useful sources of energy would result from the phenomena attributed to cold fusion. The panel noted the large number of failures to replicate excess heat and the greater inconsistency of reports of nuclear reaction byproducts expected by established conjecture. Nuclear fusion of the type postulated would be inconsistent with current understanding and, if verified, would require established conjecture, perhaps even theory itself, to be extended in an unexpected way. The panel was against special funding for cold fusion research, but supported modest funding of \"focused experiments within the general funding system\".\nCold fusion supporters continued to argue that the evidence for excess heat was strong, and in September 1990 the National Cold Fusion Institute listed 92 groups of researchers from 10 countries that had reported corroborating evidence of excess heat, but they refused to provide any evidence of their own arguing that it could endanger their patents. However, no further DOE nor NSF funding resulted from the panel's recommendation. By this point, however, academic consensus had moved decidedly toward labeling cold fusion as a kind of \"pathological science\".\nIn March 1990, Michael H. Salamon, a physicist from the University of Utah, and nine co-authors reported negative results. University faculty were then \"stunned\" when a lawyer representing Pons and Fleischmann demanded the Salamon paper be retracted under threat of a lawsuit. The lawyer later apologized; Fleischmann defended the threat as a legitimate reaction to alleged bias displayed by cold-fusion critics.\nIn early May 1990, one of the two A&amp;M researchers, Kevin Wolf, acknowledged the possibility of spiking, but said that the most likely explanation was tritium contamination in the palladium electrodes or simply contamination due to sloppy work. In June 1990 an article in \"Science\" by science writer Gary Taubes destroyed the public credibility of the A&amp;M tritium results when it accused its group leader John Bockris and one of his graduate students of spiking the cells with tritium. In October 1990 Wolf finally said that the results were explained by tritium contamination in the rods. An A&amp;M cold fusion review panel found that the tritium evidence was not convincing and that, while they couldn't rule out spiking, contamination and measurements problems were more likely explanations, and Bockris never got support from his faculty to resume his research.\nOn 30 June 1991, the National Cold Fusion Institute closed after it ran out of funds; it found no excess heat, and its reports of tritium production were met with indifference.\nOn 1 January 1991, Pons left the University of Utah and went to Europe. In 1992, Pons and Fleischmann resumed research with Toyota Motor Corporation's IMRA lab in France. Fleischmann left for England in 1995, and the contract with Pons was not renewed in 1998 after spending $40\u00a0million with no tangible results. The IMRA laboratory stopped cold fusion research in 1998 after spending \u00a312\u00a0million. Pons has made no public declarations since, and only Fleischmann continued giving talks and publishing papers.\nMostly in the 1990s, several books were published that were critical of cold fusion research methods and the conduct of cold fusion researchers. Over the years, several books have appeared that defended them. Around 1998, the University of Utah had already dropped its research after spending over $1\u00a0million, and in the summer of 1997, Japan cut off research and closed its own lab after spending $20\u00a0million.\nLater research.\nA 1991 review by a cold fusion proponent had calculated \"about 600 scientists\" were still conducting research. After 1991, cold fusion research only continued in relative obscurity, conducted by groups that had increasing difficulty securing public funding and keeping programs open. These small but committed groups of cold fusion researchers have continued to conduct experiments using Fleischmann and Pons electrolysis setups in spite of the rejection by the mainstream community. \"The Boston Globe\" estimated in 2004 that there were only 100 to 200 researchers working in the field, most suffering damage to their reputation and career. Since the main controversy over Pons and Fleischmann had ended, cold fusion research has been funded by private and small governmental scientific investment funds in the United States, Italy, Japan, and India. For example, it was reported in \"Nature\", in May, 2019, that Google had spent approximately $10 million on cold fusion research. A group of scientists at well-known research labs (e.g., MIT, Lawrence Berkeley National Lab, and others) worked for several years to establish experimental protocols and measurement techniques in an effort to re-evaluate cold fusion to a high standard of scientific rigor. Their reported conclusion: no cold fusion.\nIn 2021, following \"Nature's\" 2019 publication of anomalous findings that might only be explained by some localized fusion, scientists at the Naval Surface Warfare Center, Indian Head Division announced that they had assembled a group of scientists from the Navy, Army and National Institute of Standards and Technology to undertake a new, coordinated study. With few exceptions, researchers have had difficulty publishing in mainstream journals. The remaining researchers often term their field Low Energy Nuclear Reactions (LENR), Chemically Assisted Nuclear Reactions (CANR), Lattice Assisted Nuclear Reactions (LANR), Condensed Matter Nuclear Science (CMNS) or Lattice Enabled Nuclear Reactions; one of the reasons being to avoid the negative connotations associated with \"cold fusion\". The new names avoid making bold implications, like implying that fusion is actually occurring.\nThe researchers who continue their investigations acknowledge that the flaws in the original announcement are the main cause of the subject's marginalization, and they complain of a chronic lack of funding and no possibilities of getting their work published in the highest impact journals. University researchers are often unwilling to investigate cold fusion because they would be ridiculed by their colleagues and their professional careers would be at risk. In 1994, David Goodstein, a professor of physics at Caltech, advocated increased attention from mainstream researchers and described cold fusion as:\nUnited States.\nUnited States Navy researchers at the Space and Naval Warfare Systems Center (SPAWAR) in San Diego have been studying cold fusion since 1989. In 2002 they released a two-volume report, \"Thermal and nuclear aspects of the Pd/D2O system\", with a plea for funding. This and other published papers prompted a 2004 Department of Energy (DOE) review.\n2004 DOE panel.\nIn August 2003, the U.S. Secretary of Energy, Spencer Abraham, ordered the DOE to organize a second review of the field. This was thanks to an April 2003 letter sent by MIT's Peter L. Hagelstein, and the publication of many new papers, including the Italian ENEA and other researchers in the 2003 International Cold Fusion Conference, and a two-volume book by U.S. SPAWAR in 2002. Cold fusion researchers were asked to present a review document of all the evidence since the 1989 review. The report was released in 2004. The reviewers were \"split approximately evenly\" on whether the experiments had produced energy in the form of heat, but \"most reviewers, even those who accepted the evidence for excess power production, 'stated that the effects are not repeatable, the magnitude of the effect has not increased in over a decade of work, and that many of the reported experiments were not well documented'\". In summary, reviewers found that cold fusion evidence was still not convincing 15 years later, and they did not recommend a federal research program. They only recommended that agencies consider funding individual well-thought studies in specific areas where research \"could be helpful in resolving some of the controversies in the field\". They summarized its conclusions thus:\nCold fusion researchers placed a \"rosier spin\" on the report, noting that they were finally being treated like normal scientists, and that the report had increased interest in the field and caused \"a huge upswing in interest in funding cold fusion research\". However, in a 2009 BBC article on an American Chemical Society's meeting on cold fusion, particle physicist Frank Close was quoted stating that the problems that plagued the original cold fusion announcement were still happening: results from studies are still not being independently verified and inexplicable phenomena encountered are being labelled as \"cold fusion\" even if they are not, in order to attract the attention of journalists.\nIn February 2012, millionaire Sidney Kimmel, convinced that cold fusion was worth investing in by a 19 April 2009 interview with physicist Robert Duncan on the US news show \"60 Minutes\", made a grant of $5.5\u00a0million to the University of Missouri to establish the Sidney Kimmel Institute for Nuclear Renaissance (SKINR). The grant was intended to support research into the interactions of hydrogen with palladium, nickel or platinum under extreme conditions. In March 2013 Graham K. Hubler, a nuclear physicist who worked for the Naval Research Laboratory for 40 years, was named director. One of the SKINR projects is to replicate a 1991 experiment in which a professor associated with the project, Mark Prelas, says bursts of millions of neutrons a second were recorded, which was stopped because \"his research account had been frozen\". He claims that the new experiment has already seen \"neutron emissions at similar levels to the 1991 observation\".\nIn May 2016, the United States House Committee on Armed Services, in its report on the 2017 National Defense Authorization Act, directed the Secretary of Defense to \"provide a briefing on the military utility of recent U.S. industrial base LENR advancements to the House Committee on Armed Services by September 22, 2016\".\nItaly.\nSince the Fleischmann and Pons announcement, the Italian national agency for new technologies, energy and sustainable economic development (ENEA) has funded Franco Scaramuzzi's research into whether excess heat can be measured from metals loaded with deuterium gas. Such research is distributed across ENEA departments, CNR laboratories, INFN, universities and industrial laboratories in Italy, where the group continues to try to achieve reliable reproducibility (i.e. getting the phenomenon to happen in every cell, and inside a certain frame of time). In 2006\u20132007, the ENEA started a research program which claimed to have found excess power of up to 500 percent, and in 2009, ENEA hosted the 15th cold fusion conference.\nJapan.\nBetween 1992 and 1997, Japan's Ministry of International Trade and Industry sponsored a \"New Hydrogen Energy (NHE)\" program of US$20\u00a0million to research cold fusion. Announcing the end of the program in 1997, the director and one-time proponent of cold fusion research Hideo Ikegami stated \"We couldn't achieve what was first claimed in terms of cold fusion. (...) We can't find any reason to propose more money for the coming year or for the future.\" In 1999 the Japan C-F Research Society was established to promote the independent research into cold fusion that continued in Japan. The society holds annual meetings. Perhaps the most famous Japanese cold fusion researcher was Yoshiaki Arata, from Osaka University, who claimed in a demonstration to produce excess heat when deuterium gas was introduced into a cell containing a mixture of palladium and zirconium oxide, a claim supported by fellow Japanese researcher Akira Kitamura of Kobe University and Michael McKubre at SRI.\nIndia.\nIn the 1990s, India stopped its research in cold fusion at the Bhabha Atomic Research Centre because of the lack of consensus among mainstream scientists and the US denunciation of the research. Yet, in 2008, the National Institute of Advanced Studies recommended that the Indian government revive this research. Projects were commenced at Chennai's Indian Institute of Technology, the Bhabha Atomic Research Centre and the Indira Gandhi Centre for Atomic Research. However, there is still skepticism among scientists and, for all practical purposes, research has stalled since the 1990s. A special section in the Indian multidisciplinary journal \"Current Science\" published 33 cold fusion papers in 2015 by major cold fusion researchers including several Indian researchers.\nReported results.\nA cold fusion experiment usually includes:\nElectrolysis cells can be either open cell or closed cell. In open cell systems, the electrolysis products, which are gaseous, are allowed to leave the cell. In closed cell experiments, the products are captured, for example by catalytically recombining the products in a separate part of the experimental system. These experiments generally strive for a steady state condition, with the electrolyte being replaced periodically. There are also \"heat-after-death\" experiments, where the evolution of heat is monitored after the electric current is turned off.\nThe most basic setup of a cold fusion cell consists of two electrodes submerged in a solution containing palladium and heavy water. The electrodes are then connected to a power source to transmit electricity from one electrode to the other through the solution. Even when anomalous heat is reported, it can take weeks for it to begin to appear\u2014this is known as the \"loading time,\" the time required to saturate the palladium electrode with hydrogen (see \"Loading ratio\" section).\nThe Fleischmann and Pons early findings regarding helium, neutron radiation and tritium were never replicated satisfactorily, and its levels were too low for the claimed heat production and inconsistent with each other. Neutron radiation has been reported in cold fusion experiments at very low levels using different kinds of detectors, but levels were too low, close to background, and found too infrequently to provide useful information about possible nuclear processes.\nExcess heat and energy production.\nAn excess heat observation is based on an energy balance. Various sources of energy input and output are continuously measured. Under normal conditions, the energy input can be matched to the energy output to within experimental error. In experiments such as those run by Fleischmann and Pons, an electrolysis cell operating steadily at one temperature transitions to operating at a higher temperature with no increase in applied current. If the higher temperatures were real, and not an experimental artifact, the energy balance would show an unaccounted term. In the Fleischmann and Pons experiments, the rate of inferred excess heat generation was in the range of 10\u201320% of total input, though this could not be reliably replicated by most researchers. Researcher Nathan Lewis discovered that the excess heat in Fleischmann and Pons's original paper was not measured, but estimated from measurements that didn't have any excess heat.\nUnable to produce excess heat or neutrons, and with positive experiments being plagued by errors and giving disparate results, most researchers declared that heat production was not a real effect and ceased working on the experiments. In 1993, after their original report, Fleischmann reported \"heat-after-death\" experiments\u2014where excess heat was measured after the electric current supplied to the electrolytic cell was turned off. This type of report has also become part of subsequent cold fusion claims.\nHelium, heavy elements, and neutrons.\nKnown instances of nuclear reactions, aside from producing energy, also produce nucleons and particles on readily observable ballistic trajectories. In support of their claim that nuclear reactions took place in their electrolytic cells, Fleischmann and Pons reported a neutron flux of 4,000 neutrons per second, as well as detection of tritium. The classical branching ratio for previously known fusion reactions that produce tritium would predict, with 1 watt of power, the production of 1012 neutrons per second, levels that would have been fatal to the researchers. In 2009, Mosier-Boss et al. reported what they called the first scientific report of highly energetic neutrons, using CR-39 plastic radiation detectors, but the claims cannot be validated without a quantitative analysis of neutrons.\nSeveral medium and heavy elements like calcium, titanium, chromium, manganese, iron, cobalt, copper and zinc have been reported as detected by several researchers, like Tadahiko Mizuno or George Miley. The report presented to the United States Department of Energy (DOE) in 2004 indicated that deuterium-loaded foils could be used to detect fusion reaction products and, although the reviewers found the evidence presented to them as inconclusive, they indicated that those experiments did not use state-of-the-art techniques.\nIn response to doubts about the lack of nuclear products, cold fusion researchers have tried to capture and measure nuclear products correlated with excess heat. Considerable attention has been given to measuring 4He production. However, the reported levels are very near to background, so contamination by trace amounts of helium normally present in the air cannot be ruled out. In the report presented to the DOE in 2004, the reviewers' opinion was divided on the evidence for 4He, with the most negative reviews concluding that although the amounts detected were above background levels, they were very close to them and therefore could be caused by contamination from air.\nOne of the main criticisms of cold fusion was that deuteron-deuteron fusion into helium was expected to result in the production of gamma rays\u2014which were not observed and were not observed in subsequent cold fusion experiments. Cold fusion researchers have since claimed to find X-rays, helium, neutrons and nuclear transmutations. Some researchers also claim to have found them using only light water and nickel cathodes. The 2004 DOE panel expressed concerns about the poor quality of the theoretical framework cold fusion proponents presented to account for the lack of gamma rays.\nProposed mechanisms.\nResearchers in the field do not agree on a theory for cold fusion. One proposal considers that hydrogen and its isotopes can be absorbed in certain solids, including palladium hydride, at high densities. This creates a high partial pressure, reducing the average separation of hydrogen isotopes. However, the reduction in separation is not enough to create the fusion rates claimed in the original experiment, by a factor of ten. It was also proposed that a higher density of hydrogen inside the palladium and a lower potential barrier could raise the possibility of fusion at lower temperatures than expected from a simple application of Coulomb's law. Electron screening of the positive hydrogen nuclei by the negative electrons in the palladium lattice was suggested to the 2004 DOE commission, but the panel found the theoretical explanations not convincing and inconsistent with current physics theories.\nCriticism.\nCriticism of cold fusion claims generally take one of two forms: either pointing out the theoretical implausibility that fusion reactions have occurred in electrolysis setups or criticizing the excess heat measurements as being spurious, erroneous, or due to poor methodology or controls. There are several reasons why known fusion reactions are an unlikely explanation for the excess heat and associated cold fusion claims.\nRepulsion forces.\nBecause nuclei are all positively charged, they strongly repel one another. Normally, in the absence of a catalyst such as a muon, very high kinetic energies are required to overcome this charged repulsion. Extrapolating from known fusion rates, the rate for uncatalyzed fusion at room-temperature energy would be 50 orders of magnitude lower than needed to account for the reported excess heat. In muon-catalyzed fusion there are more fusions because the presence of the muon causes deuterium nuclei to be 207 times closer than in ordinary deuterium gas. But deuterium nuclei inside a palladium lattice are further apart than in deuterium gas, and there should be fewer fusion reactions, not more.\nPaneth and Peters in the 1920s already knew that palladium can absorb up to 900 times its own volume of hydrogen gas, storing it at several thousands of times the atmospheric pressure. This led them to believe that they could increase the nuclear fusion rate by simply loading palladium rods with hydrogen gas. Tandberg then tried the same experiment but used electrolysis to make palladium absorb more deuterium and force the deuterium further together inside the rods, thus anticipating the main elements of Fleischmann and Pons' experiment. They all hoped that pairs of hydrogen nuclei would fuse together to form helium, which at the time was needed in Germany to fill zeppelins, but no evidence of helium or of increased fusion rate was ever found.\nThis was also the belief of geologist Palmer, who convinced Steven Jones that the helium-3 occurring naturally in Earth perhaps came from fusion involving hydrogen isotopes inside catalysts like nickel and palladium. This led their team in 1986 to independently make the same experimental setup as Fleischmann and Pons (a palladium cathode submerged in heavy water, absorbing deuterium via electrolysis). Fleischmann and Pons had much the same belief, but they calculated the pressure to be of 1027 atmospheres, when cold fusion experiments achieve a loading ratio of only one to one, which has only between 10,000 and 20,000 atmospheres. John R. Huizenga says they had misinterpreted the Nernst equation, leading them to believe that there was enough pressure to bring deuterons so close to each other that there would be spontaneous fusions.\nLack of expected reaction products.\nConventional deuteron fusion is a two-step process, in which an unstable high-energy intermediary is formed:\nExperiments have shown only three decay pathways for this excited-state nucleus, with the branching ratio showing the probability that any given intermediate follows a particular pathway. The products formed via these decay pathways are:\nOnly about one in a million of the intermediaries take the third pathway, making its products very rare compared to the other paths. This result is consistent with the predictions of the Bohr model. If 1 watt (6.242 \u00d7 10 eV/s) were produced from ~2.2575 \u00d7 10 deuteron fusions per second, with the known branching ratios, the resulting neutrons and tritium (H) would be easily measured. Some researchers reported detecting He but without the expected neutron or tritium production; such a result would require branching ratios strongly favouring the third pathway, with the actual rates of the first two pathways lower by at least five orders of magnitude than observations from other experiments, directly contradicting both theoretically predicted and observed branching probabilities. Those reports of He production did not include detection of gamma rays, which would require the third pathway to have been changed somehow so that gamma rays are no longer emitted.\nThe known rate of the decay process together with the inter-atomic spacing in a metallic crystal makes heat transfer of the 24 MeV excess energy into the host metal lattice prior to the intermediary's decay inexplicable by conventional understandings of momentum and energy transfer, and even then there would be measurable levels of radiation. Also, experiments indicate that the ratios of deuterium fusion remain constant at different energies. In general, pressure and chemical environment cause only small changes to fusion ratios. An early explanation invoked the Oppenheimer\u2013Phillips process at low energies, but its magnitude was too small to explain the altered ratios.\nSetup of experiments.\nCold fusion setups utilize an input power source (to ostensibly provide activation energy), a platinum group electrode, a deuterium or hydrogen source, a calorimeter, and, at times, detectors to look for byproducts such as helium or neutrons. Critics have variously taken issue with each of these aspects and have asserted that there has not yet been a consistent reproduction of claimed cold fusion results in either energy output or byproducts. Some cold fusion researchers who claim that they can consistently measure an excess heat effect have argued that the apparent lack of reproducibility might be attributable to a lack of quality control in the electrode metal or the amount of hydrogen or deuterium loaded in the system. Critics have further taken issue with what they describe as mistakes or errors of interpretation that cold fusion researchers have made in calorimetry analyses and energy budgets.\nReproducibility.\nIn 1989, after Fleischmann and Pons had made their claims, many research groups tried to reproduce the Fleischmann-Pons experiment, without success. A few other research groups, however, reported successful reproductions of cold fusion during this time. In July 1989, an Indian group from the Bhabha Atomic Research Centre (P. K. Iyengar and M. Srinivasan) and in October 1989, John Bockris' group from Texas A&amp;M University reported on the creation of tritium. In December 1990, professor Richard Oriani of the University of Minnesota reported excess heat.\nGroups that did report successes found that some of their cells were producing the effect, while other cells that were built exactly the same and used the same materials were not. Researchers who continued to work on the topic have claimed over the years that many successful replications had been made, but still had problems getting reliable replications. Reproducibility is one of the main principles of the scientific method, and its lack led most physicists to believe that the few positive reports could be attributed to experimental error. The DOE 2004 report said among its conclusions and recommendations:\nLoading ratio.\nCold fusion researchers (McKubre since 1994, ENEA in 2011) have speculated that a cell that is loaded with a deuterium/palladium ratio lower than 100% (or 1:1) will not produce excess heat. Since most of the negative replications from 1989 to 1990 did not report their ratios, this has been proposed as an explanation for failed reproducibility. This loading ratio is hard to obtain, and some batches of palladium never reach it because the pressure causes cracks in the palladium, allowing the deuterium to escape. Fleischmann and Pons never disclosed the deuterium/palladium ratio achieved in their cells; there were no longer any batches of the palladium used by Fleischmann and Pons because the supplier changed the manufacturing process, and researchers still had problems finding batches of palladium that achieved heat production reliably.\nMisinterpretation of data.\nSome research groups initially reported that they had replicated the Fleischmann and Pons results but later retracted their reports and offered an alternative explanation for their original positive results. A group at Georgia Tech found problems with their neutron detector, and Texas A&amp;M discovered bad wiring in their thermometers. These retractions, combined with negative results from some famous laboratories, led most scientists to conclude, as early as 1989, that no positive result should be attributed to cold fusion.\nCalorimetry errors.\nThe calculation of excess heat in electrochemical cells involves certain assumptions. Errors in these assumptions have been offered as non-nuclear explanations for excess heat.\nOne assumption made by Fleischmann and Pons is that the efficiency of electrolysis is nearly 100%, meaning nearly all the electricity applied to the cell resulted in electrolysis of water, with negligible resistive heating and substantially all the electrolysis product leaving the cell unchanged. This assumption gives the amount of energy expended converting liquid D2O into gaseous D2 and O2. The efficiency of electrolysis is less than one if hydrogen and oxygen recombine to a significant extent within the calorimeter. Several researchers have described potential mechanisms by which this process could occur and thereby account for excess heat in electrolysis experiments.\nAnother assumption is that heat loss from the calorimeter maintains the same relationship with measured temperature as found when calibrating the calorimeter. This assumption ceases to be accurate if the temperature distribution within the cell becomes significantly altered from the condition under which calibration measurements were made. This can happen, for example, if fluid circulation within the cell becomes significantly altered. Recombination of hydrogen and oxygen within the calorimeter would also alter the heat distribution and invalidate the calibration.\nPublications.\nThe ISI identified cold fusion as the scientific topic with the largest number of published papers in 1989, of all scientific disciplines. The Nobel Laureate Julian Schwinger declared himself a supporter of cold fusion in the fall of 1989, after much of the response to the initial reports had turned negative. He tried to publish his theoretical paper \"Cold Fusion: A Hypothesis\" in \"Physical Review Letters\", but the peer reviewers rejected it so harshly that he felt deeply insulted, and he resigned from the American Physical Society (publisher of \"PRL\") in protest.\nThe number of papers sharply declined after 1990 because of two simultaneous phenomena: first, scientists abandoned the field; second, journal editors declined to review new papers. Consequently, cold fusion fell off the ISI charts. Researchers who got negative results turned their backs on the field; those who continued to publish were simply ignored. A 1993 paper in \"Physics Letters A\" was the last paper published by Fleischmann, and \"one of the last reports [by Fleischmann] to be formally challenged on technical grounds by a cold fusion skeptic.\"\nThe \"Journal of Fusion Technology\" (FT) established a permanent feature in 1990 for cold fusion papers, publishing over a dozen papers per year and giving a mainstream outlet for cold fusion researchers. When editor-in-chief George H. Miley retired in 2001, the journal stopped accepting new cold fusion papers. This has been cited as an example of the importance of sympathetic influential individuals to the publication of cold fusion papers in certain journals.\nThe decline of publications in cold fusion has been described as a \"failed information epidemic\". The sudden surge of supporters until roughly 50% of scientists support the theory, followed by a decline until there is only a very small number of supporters, has been described as a characteristic of pathological science. The lack of a shared set of unifying concepts and techniques has prevented the creation of a dense network of collaboration in the field; researchers perform efforts in their own and in disparate directions, making the transition to \"normal\" science more difficult.\nCold fusion reports continued to be published in a few journals like \"Journal of Electroanalytical Chemistry\" and \"Il Nuovo Cimento\". Some papers also appeared in \"Journal of Physical Chemistry\", \"Physics Letters A\", \"International Journal of Hydrogen Energy\", and a number of Japanese and Russian journals of physics, chemistry, and engineering. Since 2005, \"Naturwissenschaften\" has published cold fusion papers; in 2009, the journal named a cold fusion researcher to its editorial board. In 2015 the Indian multidisciplinary journal \"Current Science\" published a special section devoted entirely to cold fusion related papers.\nIn the 1990s, the groups that continued to research cold fusion and their supporters established (non-peer-reviewed) periodicals such as \"Fusion Facts\", \"Cold Fusion Magazine\", \"Infinite Energy Magazine\" and \"New Energy Times\" to cover developments in cold fusion and other fringe claims in energy production that were ignored in other venues. The internet has also become a major means of communication and self-publication for CF researchers.\nConferences.\nCold fusion researchers were for many years unable to get papers accepted at scientific meetings, prompting the creation of their own conferences. The International Conference on Cold Fusion (ICCF) was first held in 1990 and has met every 12 to 18 months since. Attendees at some of the early conferences were described as offering no criticism to papers and presentations for fear of giving ammunition to external critics, thus allowing the proliferation of crackpots and hampering the conduct of serious science. Critics and skeptics stopped attending these conferences, with the notable exception of Douglas Morrison, who died in 2001. With the founding in 2004 of the International Society for Condensed Matter Nuclear Science (ISCMNS), the conference was renamed the International Conference on Condensed Matter Nuclear Science\u2014for reasons that are detailed in the subsequent research section above\u2014but reverted to the old name in 2008. Cold fusion research is often referenced by proponents as \"low-energy nuclear reactions\", or LENR, but according to sociologist Bart Simon the \"cold fusion\" label continues to serve a social function in creating a collective identity for the field.\nSince 2006, the American Physical Society (APS) has included cold fusion sessions at their semiannual meetings, clarifying that this does not imply a softening of skepticism. Since 2007, the American Chemical Society (ACS) meetings also include \"invited symposium(s)\" on cold fusion. An ACS program chair, Gopal Coimbatore, said that without a proper forum the matter would never be discussed and, \"with the world facing an energy crisis, it is worth exploring all possibilities.\"\nOn 22\u201325 March 2009, the American Chemical Society meeting included a four-day symposium in conjunction with the 20th anniversary of the announcement of cold fusion. Researchers working at the U.S. Navy's Space and Naval Warfare Systems Center (SPAWAR) reported detection of energetic neutrons using a heavy water electrolysis setup and a CR-39 detector, a result previously published in \"Naturwissenschaften\". The authors claim that these neutrons are indicative of nuclear reactions. Without quantitative analysis of the number, energy, and timing of the neutrons and exclusion of other potential sources, this interpretation is unlikely to find acceptance by the wider scientific community.\nPatents.\nAlthough details have not surfaced, it appears that the University of Utah forced the 23 March 1989 Fleischmann and Pons announcement to establish priority over the discovery and its patents before the joint publication with Jones. The Massachusetts Institute of Technology (MIT) announced on 12 April 1989 that it had applied for its own patents based on theoretical work of one of its researchers, Peter L. Hagelstein, who had been sending papers to journals from 5 to 12 April. An MIT graduate student applied for a patent but was reportedly rejected by the USPTO in part by the citation of the \"negative\" MIT Plasma Fusion Center's cold fusion experiment of 1989. On 2 December 1993 the University of Utah licensed all its cold fusion patents to ENECO, a new company created to profit from cold fusion discoveries, and in March 1998 it said that it would no longer defend its patents.\nThe U.S. Patent and Trademark Office (USPTO) now rejects patents claiming cold fusion. Esther Kepplinger, the deputy commissioner of patents in 2004, said that this was done using the same argument as with perpetual motion machines: that they do not work. Patent applications are required to show that the invention is \"useful\", and this utility is dependent on the invention's ability to function. In general USPTO rejections on the sole grounds of the invention's being \"inoperative\" are rare, since such rejections need to demonstrate \"proof of total incapacity\", and cases where those rejections are upheld in a Federal Court are even rarer: nevertheless, in 2000, a rejection of a cold fusion patent was appealed in a Federal Court and it was upheld, in part on the grounds that the inventor was unable to establish the utility of the invention.\nA U.S. patent might still be granted when given a different name to disassociate it from cold fusion, though this strategy has had little success in the US: the same claims that need to be patented can identify it with cold fusion, and most of these patents cannot avoid mentioning Fleischmann and Pons' research due to legal constraints, thus alerting the patent reviewer that it is a cold-fusion-related patent. David Voss said in 1999 that some patents that closely resemble cold fusion processes, and that use materials used in cold fusion, have been granted by the USPTO. The inventor of three such patents had his applications initially rejected when they were reviewed by experts in nuclear science; but then he rewrote the patents to focus more on the electrochemical parts so they would be reviewed instead by experts in electrochemistry, who approved them. When asked about the resemblance to cold fusion, the patent holder said that it used nuclear processes involving \"new nuclear physics\" unrelated to cold fusion. Melvin Miles was granted in 2004 a patent for a cold fusion device, and in 2007 he described his efforts to remove all instances of \"cold fusion\" from the patent description to avoid having it rejected outright.\nAt least one patent related to cold fusion has been granted by the European Patent Office.\nA patent only legally prevents others from using or benefiting from one's invention. However, the general public perceives a patent as a stamp of approval, and a holder of three cold fusion patents said the patents were very valuable and had helped in getting investments.\nCultural references.\nA 1990 Michael Winner film \"Bullseye!\", starring Michael Caine and Roger Moore, referenced the Fleischmann and Pons experiment. The film \u2013 a comedy \u2013 concerned conmen trying to steal scientists' purported findings. However, the film had a poor reception, described as \"appallingly unfunny\".\nIn \"Undead Science\", sociologist Bart Simon gives some examples of cold fusion in popular culture, saying that some scientists use cold fusion as a synonym for outrageous claims made with no supporting proof, and courses of ethics in science give it as an example of pathological science. It has appeared as a joke in \"Murphy Brown\" and \"The Simpsons\". It was adopted as a software product name Adobe ColdFusion and a brand of protein bars (Cold Fusion Foods). It has also appeared in advertising as a synonym for impossible science, for example a 1995 advertisement for Pepsi Max.\nThe plot of \"The Saint\", a 1997 action-adventure film, parallels the story of Fleischmann and Pons, although with a different ending. In \"Undead Science\", Simon posits that film might have affected the public perception of cold fusion, pushing it further into the science fiction realm.\nSimilarly, the tenth episode of 2000 science fiction TV drama \"Life Force\" (\"Paradise Island\") is also based around cold fusion, specifically the efforts of eccentric scientist Hepzibah McKinley (Amanda Walker), who is convinced she has perfected it based on her father's incomplete research into the subject. The episode explores its potential benefits and viability within the ongoing post-apocalyptic global warming scenario of the series.\nIn the 2023 video game \"Atomic Heart\", cold fusion is responsible for nearly all of the technological advances."}
{"id": "7466", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7466", "title": "Coal tar", "text": "Coal tar is a thick dark liquid which is a by-product of the production of coke and coal gas from coal. It is a type of creosote. It has both medical and industrial uses. Medicinally it is a topical medication applied to skin to treat psoriasis and seborrheic dermatitis (dandruff). It may be used in combination with ultraviolet light therapy. Industrially it is a railroad tie preservative and used in the surfacing of roads. Coal tar was listed as a known human carcinogen in the first Report on Carcinogens from the U.S. Federal Government, issued in 1980.\nCoal tar was discovered circa 1665 and used for medical purposes as early as the 1800s. Circa 1850, the discovery that it could be used as the main raw material for the synthesis of dyes engendered an entire industry. It is on the World Health Organization's List of Essential Medicines. Coal tar is available as a generic medication and over the counter.\nSide effects include skin irritation, sun sensitivity, allergic reactions, and skin discoloration. It is unclear if use during pregnancy is safe for the baby and use during breastfeeding is not typically recommended. The exact mechanism of action is unknown. It is a complex mixture of phenols, polycyclic aromatic hydrocarbons (PAHs), and heterocyclic compounds. It demonstrates antifungal, anti-inflammatory, anti-itch, and antiparasitic properties.\nComposition.\nCoal tar is produced through thermal destruction (pyrolysis) of coal. Its composition varies with the process and type of coal used \u2013 lignite, bituminous or anthracite.\nCoal tar is a mixture of approximately 10,000 chemicals, of which only about 50% have been identified. Most of the chemical compounds are polycyclic aromatic hydrocarbon:\nOthers: benzene, toluene, xylenes, cumenes, coumarone, indene, benzofuran, naphthalene and methyl-naphthalenes, acenaphthene, fluorene, phenol, cresols, pyridine, picolines, phenanthracene, carbazole, quinolines, fluoranthene. Many of these constituents are known carcinogens.\nDerivatives.\nVarious phenolic coal tar derivatives have analgesic (pain-killer) properties. These included acetanilide, phenacetin, and paracetamol aka acetaminophen. Paracetamol may be the only coal-tar derived analgesic still in use today. Industrial phenol is now usually synthesized from crude oil rather than coal tar.\nCoal tar derivatives are contra-indicated for people with the inherited red cell blood disorder glucose-6-phosphate dehydrogenase deficiency (G6PD deficiency), as they can cause oxidative stress leading to red blood cell breakdown.\nMechanism of action.\nThe exact mechanism of action is unknown. Coal tar is a complex mixture of phenols, polycyclic aromatic hydrocarbons (PAHs), and heterocyclic compounds.\nIt is a keratolytic agent, which reduces the growth rate of skin cells and softens the skin's keratin.\nUses.\nMedicinal.\nCoal tar is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system. Coal tar is generally available as a generic medication and over the counter.\nCoal tar is used in medicated shampoo, soap and ointment. It demonstrates antifungal, anti-inflammatory, anti-itch, and antiparasitic properties. It may be applied topically as a treatment for dandruff and psoriasis, and to kill and repel head lice. It may be used in combination with ultraviolet light therapy.\nCoal tar may be used in two forms: crude coal tar () or a coal tar solution () also known as liquor carbonis detergens (LCD). Named brands include Denorex, Balnetar, Psoriasin, Tegrin, T/Gel, and Neutar. When used in the extemporaneous preparation of topical medications, it is supplied in the form of coal tar topical solution USP, which consists of a 20% w/v solution of coal tar in alcohol, with an additional 5% w/v of polysorbate 80\u00a0USP; this must then be diluted in an ointment base, such as petrolatum.\nConstruction.\nCoal tar was a component of the first sealed roads. In its original development by Edgar Purnell Hooley, tarmac was tar covered with granite chips. Later the filler used was industrial slag. Today, petroleum derived binders and sealers are more commonly used. These sealers are used to extend the life and reduce maintenance cost associated with asphalt pavements, primarily in asphalt road paving, car parks and walkways.\nCoal tar is incorporated into some parking-lot sealcoat products used to protect the structural integrity of the underlying pavement. Sealcoat products that are coal-tar based typically contain 20 to 35 percent coal-tar pitch. Research shows it is used throughout the United States of America, however several areas have banned its use in sealcoat products, including the District of Columbia; the city of Austin, Texas; Dane County, Wisconsin; the state of Washington; and several municipalities in Minnesota and others.\nIndustry.\nIn modern times, coal tar is mostly traded as fuel and an application for tar, such as roofing. The total value of the trade in coal tar is around US$20 billion each year.\nSafety.\nSide effects of coal tar products include skin irritation, sun sensitivity, allergic reactions, and skin discoloration. It is unclear if use during pregnancy is safe for the baby and use during breastfeeding is not typically recommended.\nAccording to the National Psoriasis Foundation, coal tar is a valuable, safe and inexpensive treatment option for millions of people with psoriasis and other scalp or skin conditions. According to the FDA, coal tar concentrations between 0.5% and 5% are considered safe and effective for psoriasis.\nCancer.\nLong-term, consistent exposure to coal tar likely increases the risk of non-melanoma skin cancers. Evidence is inconclusive whether medical coal tar, which does not remain on the skin for the long periods seen in occupational exposure, causes cancer, because there is insufficient data to make a judgment. While coal tar consistently causes cancer in cohorts of workers with chronic occupational exposure, animal models, and mechanistic studies, the data on short-term use as medicine in humans has so far failed to show any consistently significant increase in rates of cancer.\nCoal tar contains many polycyclic aromatic hydrocarbons, and it is believed that their metabolites bind to DNA, damaging it. The PAHs found in coal tar and air pollution induce immunosenescence and cytotoxicity in epidermal cells. It's possible that the skin can repair itself from this damage after short-term exposure to PAHs but not after long-term exposure. Long-term skin exposure to these compounds can produce \"tar warts\", which can progress to squamous cell carcinoma.\nCoal tar was one of the first chemical substances proven to cause cancer from occupational exposure, during research in 1775 on the cause of chimney sweeps' carcinoma. Modern studies have shown that working with coal tar pitch, such as during the paving of roads or when working on roofs, increases the risk of cancer.\nThe International Agency for Research on Cancer lists coal tars as Group 1 carcinogens, meaning they directly cause cancer. The U.S. Department of Health and Human Services lists coal tars as known human carcinogens.\nIn response to public health concerns regarding the carcinogenicity of PAHs some municipalities, such as the city of Milwaukee, have banned the use of common coal tar-based road and driveway sealants citing concerns of elevated PAH content in groundwater.\nOther.\nCoal tar causes increased sensitivity to sunlight, so skin treated with topical coal tar preparations should be protected from sunlight.\nThe residue from the distillation of high-temperature coal tar, primarily a complex mixture of three or more membered condensed ring aromatic hydrocarbons, was listed on 13 January 2010 as a substance of very high concern by the European Chemicals Agency.\nRegulation.\nExposure to coal tar pitch volatiles can occur in the workplace by breathing, skin contact, or eye contact. The Occupational Safety and Health Administration (OSHA) has set the permissible exposure limit) to 0.2\u00a0mg/m3 benzene-soluble fraction over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of 0.1\u00a0mg/m3 cyclohexane-extractable fraction over an 8-hour workday. At levels of 80\u00a0mg/m3, coal tar pitch volatiles are immediately dangerous to life and health.\nWhen used as a medication in the United States, coal tar preparations are considered over-the-counter drug pharmaceuticals and are subject to regulation by the Food and Drug Administration (FDA)."}
{"id": "7467", "revid": "407237", "url": "https://en.wikipedia.org/wiki?curid=7467", "title": "Cobbler", "text": "Cobbler(s) may refer to:"}
{"id": "7470", "revid": "421426", "url": "https://en.wikipedia.org/wiki?curid=7470", "title": "Computer Film Company", "text": ""}
{"id": "7471", "revid": "46809087", "url": "https://en.wikipedia.org/wiki?curid=7471", "title": "Catherine of Siena", "text": "Caterina di Jacopo di Benincasa, TOSD (25 March 1347 \u2013 29 April 1380), known as Catherine of Siena (), was an Italian Catholic mystic and pious laywoman who engaged in papal and Italian politics through extensive letter-writing and advocacy. Canonized in 1461, she is revered as a saint and as a Doctor of the Church due to her extensive theological authorship. She is also considered to have influenced Italian literature.\nBorn and raised in Siena, Catherine wanted from an early age to devote herself to God, which was against the will of her parents. She joined the \"mantellates\", a group of pious women, primarily widows, informally devoted to Dominican spirituality; later these types of urban pious groups would be formalized as the Third Order of the Dominicans, but not until after Catherine's death. She dictated to secretaries her set of spiritual treatises, \"The Dialogue of Divine Providence\".\nHer influence on Pope Gregory XI played a role in his 1376 decision to leave Avignon for Rome. The Pope then sent Catherine to negotiate peace with the Florentine Republic. After Gregory XI's death (March 1378) and the conclusion of peace (July 1378), she returned to Siena. The Great Schism of the West led Catherine of Siena to go to Rome with the pope. She sent numerous letters to princes and cardinals to promote obedience to Pope Urban VI and to defend what she calls the \"vessel of the Church\". She died on 29 April 1380, exhausted by her rigorous fasting. Urban VI celebrated her funeral and burial in the Basilica of Santa Maria sopra Minerva in Rome.\nDevotion to Catherine of Siena developed rapidly after her death. Pope Pius II canonized her in 1461; she was declared a patron saint of Rome in 1866 by Pope Pius IX, and of Italy (together with Francis of Assisi) in 1939 by Pope Pius XII. She was the second woman to be declared a Doctor of the Church, on 4 October 1970 by Pope Paul VI \u2013 only days after Teresa of \u00c1vila. In 1999 Pope John Paul II proclaimed her a Patron Saint of Europe.\nEarly life.\nCaterina di Jacopo di Benincasa was born on 25 March 1347 (shortly before the Black Death ravaged Europe) in Siena, Republic of Siena (today Italy), to Lapa Piagenti, the daughter of a local poet, and Jacopo di Benincasa, a cloth dyer who ran his enterprise with the help of his sons. The house where Catherine grew up still exists.\nLapa was about 40 years old when she gave birth prematurely to her 23rd and 24th children, twin daughters, named Catherine and Giovanna. After birth, Giovanna was handed over to a wet nurse and died soon after. Catherine was nursed by her mother and developed into a healthy child. She was two years old when Lapa had her 25th child, another daughter named Giovanna. As a child, Catherine was so merry that the family gave her the pet name of \"Euphrosyne\", which is Greek for \"joy\", and the name of an Euphrosyne of Alexandria.\nCatherine is said by her confessor and biographer Raymond of Capua's \"Life\" to have had her first vision of Christ when she was five or six years old: she and a brother were on the way home from visiting a married sister when she is said to have experienced a vision of Christ seated in glory with the Apostles Peter, Paul, and John. Raymond continues that at age seven, Catherine vowed to give her whole life to God.\nWhen Catherine was 16, her older sister Bonaventura died in childbirth; already anguished by this, Catherine soon learned that her parents wanted her to marry Bonaventura's widower. She was absolutely opposed and started a strict fast. She had learned this from Bonaventura, whose husband had been far from considerate, but his wife had changed his attitude by refusing to eat until he showed better manners. Besides fasting, Catherine further disappointed her mother by cutting off her long hair in protest of being encouraged to improve her appearance to attract a husband.\nCatherine would later advise Raymond of Capua to do during times of trouble what she did now as a teenager: \"Build a cell inside your mind, from which you can never flee.\" In this inner cell, she made her father into a representation of Christ, her mother into the Blessed Virgin Mary, and her brothers into the Apostles in the New Testament. Serving them humbly became an opportunity for spiritual growth. Catherine resisted the accepted course of marriage and motherhood on the one hand, or a nun's veil on the other. She chose to live an active and prayerful life outside a convent's walls, following the model of the Dominicans. Eventually, her parents gave up and permitted her to live as she pleased and stay unmarried.\nA vision of Dominic de Guzm\u00e1n gave strength to Catherine, but her wish to join his order was no comfort to Lapa, who took her daughter with her to the baths in Bagno Vignoni to improve her health. Catherine fell seriously ill with a violent rash, fever and pain, which conveniently made her mother accept her wish to join the \"Mantellate\", the local association of devout women. The Mantellate taught Catherine how to read, and she lived in almost total silence and solitude in the family home.\nIt was customary for Catherine to give away clothing and food without asking anyone's permission, which cost her family significantly. However, she requested nothing for herself and by staying in their midst, she could live out her rejection of them more strongly. She did not want their food, referring to the table laid for her in Heaven with her real family. Shortly after joining the Mantellate, Catherine started to fast for longer but found it challenging. While tending to a woman with cancerous breast sores, she was disgusted. Intending to overcome that disgust, she gathered the sore pus into a ladle and drank it all. That night, she was visited by Jesus who invited her to drink the blood gushing out of his pierced side. It was with this visitation that her stomach \"no longer had need of food and no longer could digest.\"\nLater life.\nAccording to Raymond of Capua, at the age of 21 (), Catherine experienced what she described in her letters as a \"Mystical Marriage\" with Jesus, later a popular subject in art as the \"Mystic marriage of Saint Catherine\". Caroline Walker Bynum imagines one surprising and controversial aspect of this marriage: \"Underlining the extent to which the marriage was a fusion with Christ's physicality[...] Catherine received, not the ring of gold and jewels that her biographer reports in his bowdlerized version, but the ring of Christ's foreskin.\" Catherine herself mentions the ring \u2018of flesh\u2019 motif in one of her letters (#221), equating the wedding ring of a virgin with the flesh of Jesus; she typically claimed that her own wedding ring to Christ was simply invisible. She wrote in a letter (to encourage a nun who seems to have been undergoing a prolonged period of spiritual trial and torment): \"Bathe in the blood of Christ crucified. See that you don't look for or want anything but the crucified, as a true bride ransomed by the blood of Christ crucified \u2013 for that is my wish. You see very well that you are a bride and that he has espoused you \u2013 you and everyone else \u2013 and not with a ring of silver but with a ring of his own flesh.\" Raymond of Capua also records that Catherine was told by Christ to leave her withdrawn life and enter the public life of the world. Catherine rejoined her family and began helping the ill and the poor, where she took care of them in hospitals or homes. Her early pious activities in Siena attracted a group of followers, women and men, who gathered around her.\nBetween the years 1367 and 1374, Catherine devoted herself to helping the sick and incarcerated of Siena. With her help in the Hospital of Santa Maria della Scala and within the neighborhood that she was living, Catherine's acts of charity became well known. This led to her being known as , or a holy woman. This reputation of holiness eventually led to her involvement in politics and a hearing with the pope.\nAs social and political tensions mounted in Siena, Catherine found herself drawn to intervene in wider politics. She made her first journey to Florence in 1374, probably to be interviewed by the Dominican authorities at the General Chapter held in Florence in May 1374, though this is disputed (if she was interviewed, then the absence of later evidence suggests she was deemed sufficiently orthodox). It seems that at this time she acquired Raymond of Capua as her confessor and spiritual director.\nAfter this visit, she began travelling with her followers throughout northern and central Italy advocating reform of the clergy and advising people that repentance and renewal could be done through \"the total love for God.\" In Pisa, in 1375, she used what influence she had to sway that city and Lucca away from alliance with the anti-papal league whose force was gaining momentum and strength. She also lent her enthusiasm toward promoting the launch of a new crusade. It was during this time in Pisa, according to Raymond of Capua's biography, that she received the stigmata (visible, at Catherine's request, only to herself).\nHer physical travels were not the only way in which Catherine made her views known. From 1375 onward, she began dictating letters to scribes. These letters were intended to reach men and women of her circle, increasingly widening her audience to include figures in authority as she begged for peace between the republics and principalities of Italy and for the return of the Papacy from Avignon to Rome. She carried on a long correspondence with Pope Gregory XI, asking him to reform the clergy and the administration of the Papal States.\nIn June 1376 Catherine went to Avignon as ambassador of the Republic of Florence to make peace with the Papal States (on 31\u00a0March 1376 Gregory XI had placed Florence under interdict). She was unsuccessful and was disowned by the Florentine leaders, who sent ambassadors to negotiate on their own terms as soon as Catherine's work had paved the way for them. Catherine sent an appropriately scorching letter back to Florence in response. While in Avignon, Catherine also tried to convince Pope Gregory XI, the last Avignon Pope, to return to Rome. Gregory did indeed return his administration to Rome in January 1377; to what extent this was due to Catherine's influence is a topic of much modern debate.\nCatherine returned to Siena and spent the early months of 1377 founding a women's monastery of strict observance outside the city in the old fortress of Belcaro. She spent the rest of 1377 at Rocca d'Orcia, about from Siena, on a local mission of peace-making and preaching. During this period, in autumn 1377, she had the experience which led to the writing of her \"Dialogue\" and learned to write, although she still seems to have chiefly relied upon her secretaries for her correspondence.\nLate in 1377 or early in 1378 Catherine again travelled to Florence, at the order of Gregory XI, to seek peace between Florence and Rome. Following Gregory's death in March 1378 riots, the revolts of the Ciompi broke out in Florence on June 18, and in the ensuing violence Catherine was nearly assassinated. Eventually, in July 1378, peace was agreed between Florence and Rome and Catherine returned quietly to Florence.\nIn late November 1378, with the outbreak of the Western Schism, the new Pope, Urban VI, summoned her to Rome. She stayed at Pope Urban VI's court and tried to convince nobles and cardinals of his legitimacy, both meeting with individuals at court and writing letters to persuade others.\nFor many years she had accustomed herself to a rigorous abstinence. She received the Holy Eucharist almost daily. This extreme fasting appeared unhealthy in the eyes of the clergy and her own sisterhood. Her confessor, Raymond, ordered her to eat properly. But Catherine replied that she was unable to, describing her inability to eat as an (illness). From the beginning of 1380, Catherine could neither eat nor swallow water. On February 26, she lost the use of her legs. She was said to have levitated while in prayer, and a priest claimed to have seen the consecrated host flying from his hand straight to Catherine's tongue.\nCatherine died in Rome on April 29, 1380, at the age of 33, eight days after suffering a massive stroke, which paralyzed her from the waist down. Her last words were \"Father, into Your Hands I commend my soul and my spirit.\"\nWorks.\nThree genres of work by Catherine survive:\nThe University of Alcal\u00e1 conserves a unique handwritten Spanish manuscript, while other available texts are printed copies collected by the National Library of France.&lt;ref name=\"10.1093/fh/crt047\"&gt; At section VI.&lt;/ref&gt;\nTheology.\nCatherine's theology can be described as mystical, and was employed toward practical ends for her own spiritual life or those of others. She used the language of medieval scholastic philosophy to elaborate her experiential mysticism. Interested mainly with achieving an incorporeal union with God, Catherine practiced extreme fasting and asceticism, eventually to the extent of living solely on the Eucharist every day. For Catherine, this practice was the means to fully realize her love of Christ in her mystical experience, with a large proportion of her ecstatic visions relating to the consumption or rejection of food during her life. She viewed Christ as a \"bridge\" between the soul and God and transmitted that idea, along with her other teachings, in her book \"The Dialogue\". \"The Dialogue\" is highly systematic and explanatory in its presentation of her mystical ideas; however, these ideas themselves are not so much based on reason or logic as they are based in her ecstatic mystical experience. Her work was widely read across Europe, and survives in a Middle English translation called \"The Orchard of Syon\".\nIn one of her letters she sent to her confessor, Raymond of Capua, she recorded this revelation from her conversation with Christ, in which he said: \"Do you know what you are to Me, and what I am to you, my daughter? I am He who is, you are she who is not\". This mystical concept of God as the wellspring of being is seen in the works and ideas of Aquinas and can be seen as a simplistic rendering of apotheosis and a more rudimentary form of the doctrine of divine simplicity. She describes God in her work, \"The Dialogue\" (which she referred to simply as \"her book\"), as a \"sea, in which we are the fish\", the point being that the relationship between God and man should not be seen as man contending against the Divine and vice versa, but as God being the endless being that supports all things.\nAccording to the writings attributed to Catherine, in 1377 she had a vision in which the Virgin confirmed to her a thesis supported by the Dominican Order, to which Catherine belonged: the Virgin said that she had been conceived the original sin. The Virgin thus contradicted the future dogma of the Immaculate Conception. Cardinal Lambertini (later Pope Benedict XIV) in his treatise , 1734\u20131738, cites theologians who believed that Catherine's directors or editors had falsified her words; he also cites Father Lancicius, who believed that Catherine had made a mistake as a result of preconceived ideas.\nVeneration.\nCatherine was initially buried in the (Roman) cemetery of Santa Maria sopra Minerva which lies near the Pantheon. After miracles were reported to take place at her grave, Raymond moved her inside Santa Maria sopra Minerva, where she lies to this day.\nHer head, however, was parted from her body and inserted in a gilt bust of bronze. This bust was later taken to Siena, and carried through that city in a procession to the Dominican church. Behind the bust walked Lapa, Catherine's mother, who lived until she was 89 years old. By then she had seen the end of the wealth and the happiness of her family, and followed most of her children and several of her grandchildren to the grave. She helped Raymond of Capua write his biography of her daughter, and said, \"I think God has laid my soul athwart in my body, so that it can't get out.\" The incorrupt head and thumb were entombed in the Basilica of San Domenico at Siena, where they remain.\nPope Pius II himself canonized Catherine on 29 April 1461.\nOn 4 October 1970, Pope Paul VI named Catherine a Doctor of the Church; this title was almost simultaneously given to Teresa of \u00c1vila (27 September 1970), making them the first women to receive this honour.\nHowever, Catherine's feast day was not initially included in the General Roman Calendar. When it was added in 1597, it was put on the day of her death, 29 April; however, because this conflicted with the feast of Saint Peter of Verona, which also fell on 29 April, Catherine's feast day was moved in 1628 to the new date of 30 April. In the 1969 revision of the calendar, it was decided to leave the celebration of the feast of St Peter of Verona to local calendars, because he was not as well known worldwide, and Catherine's feast was restored to 29 April.\nCatherine is remembered in the Church of England and in the Episcopal Church on 29 April. The Evangelical Lutheran Church in America (ELCA) also commemorates Catherine of Siena on 29 April.\nLegacy.\nCatherine ranks high among the mystics and spiritual writers of the Catholic Church. She remains a greatly respected figure for her spiritual writings, and political boldness to \"speak truth to power\", with it being out of the ordinary for a woman in her time period to have had such influence in politics and on world history.\nPatronage.\nIn his decree of 13 April 1866, Pope Pius IX declared Catherine of Siena to be a co-patroness of Rome. On 18 June 1939 Pope Pius XII named her a joint patron saint of Italy along with Francis of Assisi.\nOn 1 October 1999, Pope John Paul II made her one of Europe's patron saints, along with Teresa Benedicta of the Cross and Bridget of Sweden. She is also the patroness of the historically Catholic American woman's fraternity, Theta Phi Alpha.\nSevered head.\nThe people of Siena wished to have Catherine's body. A story is told of a miracle whereby they were partially successful: knowing that they could not smuggle her whole body out of Rome, they decided to take only her head which they placed in a bag. When stopped by the Roman guards, they prayed to Catherine to help them, confident that she would rather have her body (or at least part thereof) in Siena. When they opened the bag to show the guards, it appeared no longer to hold her head but to be full of rose petals.\nSanter\u00eda.\nIn some traditions of Santer\u00eda, Saint Catherine of Siena has been syncretized with the orisha (deity) \u1eccba and is venerated.\nBiographical sources.\nThere is some internal evidence of Catherine's personality, teaching and work in her nearly four hundred letters, her \"Dialogue\", and her prayers.\nDetails about her life have also been drawn from the various sources written shortly after her death to promote her cult and canonization. Though much of the material is heavily hagiographic, written to promote her sanctity, it is an important early source for historians seeking to reconstruct Catherine's life. Various sources are particularly important, especially the works of Raymond of Capua, who was Catherine's spiritual director and close friend from 1374 to her death and himself became Master General of the Order in 1380. Raymond wrote what is known as the , his \"Life\" of Catherine which was completed in 1395, fifteen years after Catherine's death. It was soon translated into other European languages, including German and English.\nAnother important work written after Catherine's death was (\"Little Supplement Book\"), written between 1412 and 1418 by Tommaso d'Antonio Nacci da Siena (commonly called Thomas of Siena, or Tommaso Caffarini); the work is an expansion of Raymond's making heavy use of the notes of Catherine's first confessor, Tommaso della Fonte, that do not survive anywhere else. Caffarini later published a more compact account of Catherine's life, the .\nFrom 1411 onward, Caffarini also coordinated the compiling of the of Venice, the set of documents submitted as part of the process of canonisation of Catherine, which provides testimony from nearly all of Catherine's disciples. There is also an anonymous piece, (\"Miracle of Blessed Catherine\"), written by an anonymous Florentine. A few other relevant pieces survive.\nMain sanctuaries.\nThe main churches in honor of Catherine of Siena are:\nBibliography.\nModern editions and English translations.\nEnglish translations of The \"Dialogue\" include:\nThe Letters are translated into English as:\nThe Prayers are translated into English as:\nRaymond of Capua's \"Life\" was translated into English in 1493 and 1609, and in Modern English is translated as:\nLetter Excerpts translated into English:"}
{"id": "7472", "revid": "7578598", "url": "https://en.wikipedia.org/wiki?curid=7472", "title": "Charles Lyell", "text": "Sir Charles Lyell, 1st Baronet, (14 November 1797\u00a0\u2013 22 February 1875) was a Scottish geologist who demonstrated the power of known natural causes in explaining the earth's history. He is best known today for his association with Charles Darwin and as the author of \"Principles of Geology\" (1830\u201333), which presented to a wide public audience the idea that the earth was shaped by the same natural processes still in operation today, operating at similar intensities. The philosopher William Whewell dubbed this gradualistic view \"uniformitarianism\" and contrasted it with catastrophism, which had been championed by Georges Cuvier and was better accepted in Europe. The combination of evidence and eloquence in \"Principles\" convinced a wide range of readers of the significance of \"deep time\" for understanding the earth and environment.\nLyell's scientific contributions included a pioneering explanation of climate change, in which shifting boundaries between oceans and continents could be used to explain long-term variations in temperature and rainfall. Lyell also gave influential explanations of earthquakes and developed the theory of gradual \"backed up-building\" of volcanoes. In stratigraphy his division of the Tertiary period into the Pliocene, Miocene, and Eocene was highly influential. He incorrectly conjectured that icebergs were the impetus behind the transport of glacial erratics, and that silty loess deposits might have settled out of flood waters. His creation of a separate period for human history, entitled the 'Recent', is widely cited as providing the foundations for the modern discussion of the Anthropocene.\nBuilding on the innovative work of James Hutton and his follower John Playfair, Lyell favoured an indefinitely long age for the earth, despite evidence suggesting an old but finite age. He was a close friend of Charles Darwin, and contributed significantly to Darwin's thinking on the processes involved in evolution. As Darwin wrote in \"On the Origin of Species\", \"He who can read Sir Charles Lyell's grand work on the Principles of Geology, which the future historian will recognise as having produced a revolution in natural science, yet does not admit how incomprehensibly vast have been the past periods of time, may at once close this volume.\" Lyell helped to arrange the simultaneous publication in 1858 of papers by Darwin and Alfred Russel Wallace on natural selection, despite his personal religious qualms about the theory. He later published evidence from geology of the time man had existed on the earth.\nBiography.\nLyell was born into a wealthy family, on 14 November 1797, at the family's estate house, Kinnordy House, near Kirriemuir in Forfarshire. He was the eldest of ten children. Lyell's father, also named Charles Lyell, was noted as a translator and scholar of Dante. An accomplished botanist, it was he who first exposed his son to the study of nature. Lyell's grandfather, also Charles Lyell, had made the family fortune supplying the Royal Navy at Montrose, enabling him to buy Kinnordy House.\nThe family seat is located in Strathmore, near the Highland Boundary Fault. Round the house, in the strath, is good farmland, but within a short distance to the north-west, on the other side of the fault, are the Grampian Mountains in the Highlands. His family's second country home was in a completely different geological and ecological area: he spent much of his childhood at Bartley Lodge in the New Forest, in Hampshire in southern England.\nLyell entered Exeter College, Oxford, in 1816, and attended William Buckland's geological lectures. He graduated with a BA Hons. second class degree in classics, in December 1819, and gained his M.A. 1821. After graduation he took up law as a profession, entering Lincoln's Inn in 1820. He completed a circuit through rural England, where he could observe geological phenomena. In 1821 he attended Robert Jameson's lectures in Edinburgh, and visited Gideon Mantell at Lewes, in Sussex. In 1823 he was elected joint secretary of the Geological Society. As his eyesight began to deteriorate, he turned to geology as a full-time profession. His first paper, \"On a recent formation of freshwater limestone in Forfarshire\", was presented in 1826. By 1827, he had abandoned law and embarked on a geological career that would result in fame and the general acceptance of uniformitarianism, a working out of the ideas proposed by James Hutton a few decades earlier.\nIn 1832, Lyell married Mary Horner in Bonn, daughter of Leonard Horner (1785\u20131864), also associated with the Geological Society of London. The new couple spent their honeymoon in Switzerland and Italy on a geological tour of the area.\nDuring the 1840s, Lyell travelled to the United States and Canada, and wrote two popular travel-and-geology books: \"Travels in North America\" (1845) and \"A Second Visit to the United States\" (1849). In 1866, he was elected a foreign member of the Royal Swedish Academy of Sciences. After the Great Chicago Fire in 1871, Lyell was one of the first to donate books to help found the Chicago Public Library.\nIn 1841, Lyell was elected as a member to the American Philosophical Society.\nLyell's wife died in 1873, and two years later (in 1875) Lyell himself died as he was revising the twelfth edition of \"Principles\". He is buried in Westminster Abbey where there is a bust to him by William Theed in the north aisle.\nLyell was knighted (Kt) in 1848, and later, in 1864, made a baronet (Bt), which is an hereditary honour. He was awarded the Copley Medal of the Royal Society in 1858 and the Wollaston Medal of the Geological Society in 1866. Mount Lyell, the highest peak in Yosemite National Park, is named after him; the crater Lyell on the Moon and a crater on Mars were named in his honour; Mount Lyell in western Tasmania, Australia, located in a profitable mining area, bears Lyell's name; and the Lyell Range in north-west Western Australia is named after him as well. In Southwest Nelson in the South Island of New Zealand, the Lyell Range, Lyell River and the gold mining town of Lyell (now only a camping site) were all named after Lyell. Lyall Bay in Wellington, New Zealand was possibly named after Lyell. The jawless fish \"Cephalaspis lyelli\", from the Old Red Sandstone of southern Scotland, was named by Louis Agassiz in honour of Lyell.\nSir Charles Lyell was buried at Westminster Abbey on 27 February 1875. The pallbearers included T. H. Huxley, the Rev. W. S. Symonds and Mr John Carrick Moore.\nCareer and major writings.\nLyell had private means, and earned further income as an author. He came from a prosperous family, worked briefly as a lawyer in the 1820s, and held the post of Professor of Geology at King's College London in the 1830s. From 1830 onward his books provided both income and fame. Each of his three major books was a work continually in progress. All three went through multiple editions during his lifetime, although many of his friends (such as Darwin) thought the first edition of the \"Principles\" was the best written. Lyell used each edition to incorporate additional material, rearrange existing material, and revisit old conclusions in light of new evidence.\nThroughout his life, Lyell kept a remarkable series of nearly three hundred manuscript notebooks and diaries. These span Lyell's long scientific career (1825\u20131874), and offer an unrivalled insight into personal influences, field observations, thoughts and relationships. They were acquired in 2019 by the University of Edinburgh's Heritage Collections, thanks to a fundraising campaign, with many generous individual and institutional donors from the UK and overseas. Highlights include his travels throughout Europe and the United States of America, the drafts of his correspondence with the likes of Charles Darwin, his geological and landscape sketches and his constant gathering of evidence and refinement of his theories. Lyell's collection held at the University of Edinburgh, including digital images of his five series of notebooks, and with links to other Lyell material held elsewhere, is now available on a dedicated website.\n\"Principles of Geology\", Lyell's first book, was also his most famous, most influential, and most important. First published in three volumes in 1830\u201333, it established Lyell's credentials as an important geological theorist and propounded the doctrine of uniformitarianism. It was a work of synthesis, backed by his own personal observations on his travels.\nThe central argument in \"Principles\" was that \"the present is the key to the past\"\u00a0\u2013 a concept of the Scottish Enlightenment which David Hume had stated as \"all inferences from experience suppose\u00a0... that the future will resemble the past\", and James Hutton had described when he wrote in 1788 that \"from what has actually been, we have data for concluding with regard to that which is to happen thereafter.\" Geological remains from the distant past can, and should, be explained by reference to geological processes now in operation and thus directly observable. Lyell's interpretation of geological change as the steady accumulation of minute changes over enormously long spans of time was a powerful influence on the young Charles Darwin. Lyell asked Robert FitzRoy, captain of HMS \"Beagle\", to search for erratic boulders on the survey voyage of the \"Beagle\", and just before it set out FitzRoy gave Darwin Volume 1 of the first edition of Lyell's \"Principles\". When the \"Beagle\" made its first stop ashore at St Jago in the Cape Verde islands, Darwin found rock formations which seen \"through Lyell's eyes\" gave him a revolutionary insight into the geological history of the island, an insight he applied throughout his travels.\nWhile in South America Darwin received Volume 2 which considered the ideas of Jean-Baptiste Lamarck in some detail. Lyell rejected Lamarck's idea of organic evolution, proposing instead \"Centres of Creation\" to explain diversity and territory of species. However, as discussed below, many of his letters show he was fairly open to the idea of evolution. In geology Darwin was very much Lyell's disciple, and brought back observations and his own original theorising, including ideas about the formation of atolls, which supported Lyell's uniformitarianism. On the return of the \"Beagle\" (October 1836) Lyell invited Darwin to dinner and from then on they were close friends.\nAlthough Darwin discussed evolutionary ideas with him from 1842, Lyell continued to reject evolution in each of the first nine editions of the \"Principles\". He encouraged Darwin to publish, and following the 1859 publication of \"On the Origin of Species\", Lyell finally offered a tepid endorsement of evolution in the tenth edition of \"Principles\".\n\"Elements of Geology\" began as the fourth volume of the third edition of \"Principles\": Lyell intended the book to act as a suitable field guide for students of geology. The systematic, factual description of geological formations of different ages contained in \"Principles\" grew so unwieldy, however, that Lyell split it off as the \"Elements\" in 1838. The book went through six editions, eventually growing to two volumes and ceasing to be the inexpensive, portable handbook that Lyell had originally envisioned. Late in his career, therefore, Lyell produced a condensed version titled \"Student's Elements of Geology\" that fulfilled the original purpose.\n\"Geological Evidences of the Antiquity of Man\" brought together Lyell's views on three key themes from the geology of the Quaternary Period of earth history: glaciers, evolution, and the age of the human race. First published in 1863, it went through three editions that year, with a fourth and final edition appearing in 1873. The book was widely regarded as a disappointment because of Lyell's equivocal treatment of evolution. Lyell, a highly religious man with a strong belief in the special status of human reason, had great difficulty reconciling his beliefs with natural selection.\nScientific contributions.\nLyell's geological interests ranged from volcanoes and geological dynamics through stratigraphy, palaeontology, and glaciology to topics that would now be classified as prehistoric archaeology and paleoanthropology. He is best known, however, for his role in elaborating the doctrine of uniformitarianism. He played a critical role in advancing the study of loess.\nUniformitarianism.\nFrom 1830 to 1833 his multi-volume \"Principles of Geology\" was published. The work's subtitle was \"An attempt to explain the former changes of the earth's surface by reference to causes now in operation\", and this explains Lyell's impact on science. He drew his explanations from field studies conducted directly before he went to work on the founding geology text. He was, along with the earlier John Playfair, the major advocate of James Hutton's idea of uniformitarianism, that the earth was shaped entirely by slow-moving forces still in operation today, acting over a very long time. This was in contrast to catastrophism, an idea of abrupt geological changes, which had been adapted in England to explain landscape features\u2014such as rivers much smaller than their associated valleys\u2014that seemed impossible to explain other than through violent action. Criticizing the reliance of his contemporaries on what he argued were \"ad hoc\" explanations, Lyell wrote,\nNever was there a doctrine more calculated to foster indolence, and to blunt the keen edge of curiosity, than this assumption of the discordance between the former and the existing causes of change... The student was taught to despond from the first. Geology, it was affirmed, could never arise to the rank of an exact science... [With catastrophism] we see the ancient spirit of speculation revived, and a desire manifestly shown to cut, rather than patiently untie, the Gordian Knot.\nLyell saw himself as \"the spiritual saviour of geology, freeing the science from the old dispensation of Moses.\" The two terms, \"uniformitarianism\" and \"catastrophism\", were both coined by William Whewell; in 1866 R. Grove suggested the simpler term \"continuity\" for Lyell's view, but the old terms persisted. In various revised editions (12 in all, through 1872), \"Principles of Geology\" was the most influential geological work in the middle of the 19th century and did much to put geology on a modern footing.\nGeological surveys.\nLyell noted the \"economic advantages\" geological surveys could provide, citing their felicity in mineral-rich countries and provinces. Modern surveys, like the British Geological Survey (founded in 1835), and the US Geological Survey (founded in 1879), map and exhibit the natural resources within their countries. Over time, these surveys have been used extensively by modern extractive industries, such as nuclear, coal, and oil.\nVolcanoes and geological dynamics.\nBefore Lyell's work, phenomena's such as earthquakes were understood by the destruction that they brought. One of the contributions that Lyell made in \"Principles\" was to explain the cause of earthquakes. Lyell, in contrast, focused on more recent earthquakes (150 yrs), evidenced by surface irregularities such as faults, fissures, stratigraphic displacements and depressions.\nLyell's work on volcanoes focused largely on Vesuvius and Etna, both of which he had earlier studied. His conclusions supported gradual building of volcanoes, so-called \"backed up-building\", as opposed to the upheaval argument supported by other geologists.\nStratigraphy and human history.\nLyell was a key figure in establishing the classification of more recent geological deposits, long known as the Tertiary period. From May 1828, until February 1829, he travelled with Roderick Impey Murchison (1792\u20131871) to the south of France (Auvergne volcanic district) and to Italy. In these areas he concluded that the recent strata (rock layers) could be categorised according to the number and proportion of marine shells encased within. Based on this the third volume of his \"Principles of Geology\", published in 1833, proposed dividing the Tertiary period into four parts, which he named the Eocene, Miocene, Pliocene, and Recent. In 1839, Lyell termed the Pleistocene epoch, distinguishing a more recent fossil layer from the Pliocene. The Recent epoch renamed the Holocene by French paleontologist Paul Gervais in 1867 included all deposits from the era subject to human observation. In recent years Lyell's subdivisions have been widely discussed with debates about the Anthropocene.\nGlaciers.\nIn \"Principles of Geology\" (first edition, vol. 3, ch. 2, 1833) Lyell proposed that icebergs could be the means of transport for erratics. During periods of global warming, ice breaks off the poles and floats across submerged continents, carrying debris with it, he conjectured. When the iceberg melts, it rains down sediments upon the land. Because this theory could account for the presence of diluvium, the word \"drift\" became the preferred term for the loose, unsorted material, today called \"till\". Furthermore, Lyell believed that the accumulation of fine angular particles covering much of the world (today called loess) was a deposit settled from mountain flood water. Today some of Lyell's mechanisms for geological processes have been disproven, though many have stood the test of time. His observational methods and general analytical framework remain in use today as foundational principles in geology.\nEvolution.\nLyell initially accepted the conventional view of other men of science, that the fossil record indicated a directional geohistory in which species went extinct. Around 1826, when he was on circuit, he read Lamarck's \"Zoological Philosophy\" and on 2 March 1827 wrote to Mantell, expressing admiration, but cautioning that he read it \"rather as I hear an advocate on the wrong side, to know what can be made of the case in good hands\".:\nHe struggled with the implications for human dignity, and later in 1827 wrote private notes on Lamarck's ideas. Lyell reconciled transmutation of species with natural theology by suggesting that it would be as much a \"remarkable manifestation of creative Power\" as creating each species separately. He countered Lamarck's views by rejecting continued cooling of the earth in favour of \"a fluctuating cycle\", a long-term steady-state geohistory as proposed by James Hutton. The fragmentary fossil record already showed \"a high class of fishes, close to reptiles\" in the Carboniferous period which he called \"the first Zoological era\", and quadrupeds could also have existed then. In November 1827, after William Broderip found a Middle Jurassic fossil of the early mammal \"Didelphis\", Lyell told his father that \"There was everything but man even as far back as the Oolite.\" Lyell inaccurately portrayed Lamarckism as a response to the fossil record, and said it was falsified by a lack of progress. He said in the second volume of \"Principles\" that the occurrence of this one fossil of the higher mammalia \"in these ancient strata, is as fatal to the theory of successive development, as if several hundreds had been discovered.\"\nIn the first edition of \"Principles\", the first volume briefly set out Lyell's concept of a steady state with no real progression of fossils. The sole exception was the advent of humanity, with no great physical distinction from animals, but with absolutely unique intellectual and moral qualities. The second volume dismissed Lamarck's claims of animal forms arising from habits, continuous spontaneous generation of new life, and man having evolved from lower forms. Lyell explicitly rejected Lamarck's concept of transmutation of species, drawing on Cuvier's arguments, and concluded that species had been created with stable attributes. He discussed the geographical distribution of plants and animals, and proposed that every species of plant or animal was descended from a pair or individual, originated in response to differing external conditions. Species would regularly go extinct, in a \"struggle for existence\" between hybrids, or a \"war one with another\" due to population pressure. He was vague about how replacement species formed, portraying this as an infrequent occurrence which could rarely be observed.\nThe leading man of science Sir John Herschel wrote from Cape Town on 20 February 1836, thanking Lyell for sending a copy of \"Principles\" and praising the book as opening a way for bold speculation on \"that mystery of mysteries, the replacement of extinct species by others\" \u2013 by analogy with other intermediate causes, \"the origination of fresh species, could it ever come under our cognizance, would be found to be a natural in contradistinction to a miraculous process\". Lyell replied: \"In regard to the origination of new species, I am very glad to find that you think it probable that it may be carried on through the intervention of intermediate causes. I left this rather to be inferred, not thinking it worth while to offend a certain class of persons by embodying in words what would only be a speculation.\" \nWhewell subsequently questioned this topic, and in March 1837 Lyell told him:\nAs a result of his letters and, no doubt, personal conversations, Huxley and Ernst Haeckel were convinced that, at the time he wrote \"Principles\", he believed new species had arisen by natural methods. Adam Sedgwick wrote worried letters to him about this.\nBy the time Darwin returned from the \"Beagle\" survey expedition in 1836, he had begun to doubt Lyell's ideas about the permanence of species. He continued to be a close personal friend, and Lyell was one of the first scientists to support \"On the Origin of Species\", though he did not subscribe to all its contents. Lyell was also a friend of Darwin's closest colleagues, Joseph Dalton Hooker and Huxley, but unlike them he struggled to square his religious beliefs with evolution. This inner struggle has been much commented on. He had particular difficulty in believing in natural selection as the main motive force in evolution.\nLyell and Hooker were instrumental in arranging the peaceful co-publication of the theory of natural selection by Darwin and Alfred Russel Wallace in 1858: each had arrived at the theory independently. Lyell's views on gradual change and the power of a long time scale were important because Darwin thought that populations of an organism changed very slowly.\nAlthough Lyell rejected evolution at the time of writing the \"Principles\", after the Darwin\u2013Wallace papers and the \"Origin\" Lyell wrote in one of his notebooks on 3 May 1860:\nLyell's acceptance of natural selection, Darwin's proposed mechanism for evolution, was equivocal, and came in the tenth edition of \"Principles\". \"The Antiquity of Man\" (published in early February 1863, just before Huxley's \"Man's place in nature\") drew these comments from Darwin to Huxley: \"I am fearfully disappointed at Lyell's excessive caution\" and \"The book is a mere 'digest'\".Quite strong remarks: no doubt Darwin resented Lyell's repeated suggestion that he owed a lot to Lamarck, whom he (Darwin) had always specifically rejected. Darwin's daughter Henrietta (Etty) wrote to her father: \"Is it fair that Lyell always calls your theory a modification of Lamarck's?\"\nIn other respects \"Antiquity\" was a success. It sold well, and it \"shattered the tacit agreement that mankind should be the sole preserve of theologians and historians\". But when Lyell wrote that it remained a profound mystery how the huge gulf between man and beast could be bridged, Darwin wrote \"Oh!\" in the margin of his copy.\nLegacy.\nPlaces named after Lyell:"}
{"id": "7473", "revid": "47187980", "url": "https://en.wikipedia.org/wiki?curid=7473", "title": "Chelsea F.C.", "text": "Chelsea Football Club is a professional football club based in Fulham, West London, England. Named after neighbouring area Chelsea, they compete in the Premier League, the top tier of English football. Founded in 1905, the team play their home games at Stamford Bridge. The club won their first major honour, the League championship, in 1955. They won the FA Cup for the first time in 1970, won their first European honour, the Cup Winners' Cup, in 1971, and became the third English club to win the Club World Cup in 2022.\nChelsea is one of five clubs and the first English club to have won all three pre-1999 main European club competitions, the \"European Treble\" of the European Cup/UEFA Champions League, European/UEFA Cup Winners' Cup, and UEFA Cup/UEFA Europa League. They are the only club to have won all three major European competitions twice. They are the only London club to have won the Champions League and the Club World Cup. Domestically, the club has won six league titles, eight FA Cups, five League Cups, and four FA Community Shields. Internationally, they have won the UEFA Champions League, the UEFA Europa League, the UEFA Cup Winners' Cup and the UEFA Super Cup twice each, and the FIFA Club World Cup once. In terms of overall trophies won, Chelsea is the fifth-most successful club in English football.\nThe club has rivalries fellow London teams Arsenal and Tottenham Hotspur, and a historic rivalry with Leeds United. In terms of club value, Chelsea is the ninth-most-valuable football club in the world (), worth $3.13\u00a0billion, and is the ninth-highest-earning football club in the world.\nHistory.\nFounding and early years (1905\u20131952).\nIn 1904, Gus Mears acquired the Stamford Bridge athletics stadium in Fulham with the aim of turning it into a football ground. An offer to lease it to nearby Fulham F.C. was turned down, so Mears opted to found his own club to use the stadium. As there was already a team named Fulham in the borough, the name of the adjacent borough of Chelsea was chosen for the new club; names like \"Kensington FC\", \"Stamford Bridge FC\" and \"London FC\" were considered. Chelsea F.C. was founded on 10 March 1905 at The Rising Sun pub (now The Butcher's Hook), opposite the present-day main entrance to the ground on Fulham Road, and were elected to the Football League shortly afterwards.\nChelsea won promotion to the First Division in their second season, and yo-yoed between the First and Second Divisions in its early years. The team reached the 1915 FA Cup final, where they lost to Sheffield United at Old Trafford, and finished third in the First Division in 1920, the club's best league campaign to that point. Chelsea had a reputation for signing star players and attracted large crowds. The club had the highest average attendance in English football in ten separate seasons including 1907\u201308, 1909\u201310, 1911\u201312, 1912\u201313, 1913\u201314 and 1919\u201320. They were FA Cup semi-finalists in 1920 and 1932 and remained in the First Division throughout the 1930s, but success eluded the club in the inter-war years.\nModernisation and the first league championship (1952\u20131983).\nFormer Arsenal and England centre-forward Ted Drake was appointed manager in 1952 and proceeded to modernise the club. He removed the club's Chelsea pensioner crest, improved the youth set-up and training regime, rebuilt the side with shrewd signings from the lower divisions and amateur leagues, and led Chelsea to their first major trophy success \u2013 the League championship \u2013 in 1954\u201355. The following season saw UEFA create the European Champions' Cup, but after objections from The Football League, Chelsea were persuaded to withdraw from the competition before it started. Chelsea failed to build on this success, and spent the remainder of the 1950s in mid-table. Drake was dismissed in 1961 and replaced by player-coach Tommy Docherty.\nDocherty built a new team around the group of talented young players emerging from the club's youth set-up, and Chelsea challenged for honours throughout the 1960s, enduring several near-misses. They were on course for a treble of League, FA Cup and League Cup going into the final stages of the 1964\u201365 season, winning the League Cup but faltering late on in the other two. In three seasons the side were beaten in three major semi-finals and were FA Cup runners-up. Under Docherty's successor, Dave Sexton, Chelsea won the FA Cup in 1970, beating Leeds United 2\u20131 in a final replay. The following year, Chelsea took their first European honour, a UEFA Cup Winners' Cup triumph, with another replayed win, this time over Real Madrid in Athens.\nRedevelopment and financial crisis (1983\u20132003).\nThe late 1970s through to the '80s was a turbulent period for Chelsea. An ambitious redevelopment of Stamford Bridge threatened the financial stability of the club, star players were sold and the team were relegated. Further problems were caused by a notorious hooligan element among the support, which was to plague the club throughout the decade. In 1982, at the nadir of their fortunes, Chelsea were acquired by Ken Bates from Mears' great-nephew Brian Mears, for the nominal sum of \u00a31. Bates bought a controlling stake in the club and floated Chelsea on the AIM stock exchange in March 1996 although by now the Stamford Bridge freehold had been sold to property developers, meaning the club faced losing their home. On the pitch, the team had fared little better, coming close to relegation to the Third Division for the first time, but in 1983 manager John Neal put together an impressive new team for minimal outlay. Chelsea won the Second Division title in 1983\u201384 and established themselves in the top division with two top-six finishes, before being relegated again in 1988. The club bounced back immediately by winning the Second Division championship in 1988\u201389.\nAfter a long-running legal battle, Bates reunited the stadium freehold with the club in 1992 by doing a deal with the banks of the property developers, who had been bankrupted by a market crash. In the mid-1990s Chelsea fan and businessman Matthew Harding became a director and loaned the club \u00a326\u00a0million to build the new North Stand and invest in new players. Chelsea's form in the new Premier League was unconvincing, although they did reach the 1994 FA Cup final. The appointment of Ruud Gullit as player-manager in 1996 began an upturn in the team's fortunes. He added several top international players to the side and led the club to their first major honour since 1971, the FA Cup. Gullit was replaced by Gianluca Vialli, whose reign saw Chelsea win the League Cup, the UEFA Cup Winners' Cup and the UEFA Super Cup in 1998, and the FA Cup in 2000. They mounted a strong title challenge in 1998\u201399, finishing four points behind champions Manchester United, and made their first appearance in the UEFA Champions League. Vialli was sacked in favour of Claudio Ranieri, who guided Chelsea to the 2002 FA Cup final and Champions League qualification in 2002\u201303.\nAbramovich ownership (2003\u20132022).\nWith the club facing an apparent financial crisis, Bates unexpectedly sold Chelsea F.C. in June 2003 for \u00a360\u00a0million. In so doing, he reportedly recognised a personal profit of \u00a317\u00a0million on the club he had bought for \u00a31 in 1982 (his stake had been diluted to just below 30% over the years). The club's new owner was Russian oligarch and billionaire Roman Abramovich, who took on responsibility for the club's \u00a380\u00a0million of debt, quickly paying some of it. Sergei Pugachev alleged Chelsea was bought on Putin's orders, an allegation Abramovich has denied. Bates mentioned that Abramovich was in talks to buy Manchester United and Tottenham Hotspur before he bought Chelsea in a deal sealed in a day.\nOver \u00a3100\u00a0million was spent on new players, but Ranieri was unable to deliver any trophies, and was replaced by Jos\u00e9 Mourinho. Under Mourinho, Chelsea became the fifth English team to win back-to-back league championships since the Second World War (2004\u201305 and 2005\u201306), in addition to winning an FA Cup (2007) and two League Cups (2005 and 2007). After a poor start to the 2007\u201308 season, Mourinho was replaced by Avram Grant, who led the club to their first UEFA Champions League final, which they lost on penalties to Manchester United. The club did not turn a profit in the first nine years of Abramovich's ownership, and made record losses of \u00a3140m in June 2005.\nIn 2009, under caretaker manager Guus Hiddink, Chelsea won another FA Cup. In 2009\u201310, his successor Carlo Ancelotti led them to their first Premier League and FA Cup Double, becoming the first English top-flight club to score 100 league goals in a season since 1963. In 2012, Roberto Di Matteo led Chelsea to their seventh FA Cup, and their first UEFA Champions League title, beating Bayern Munich 4\u20133 on penalties, the first London club to win the trophy. The following year the club won the UEFA Europa League, making them the first club to hold two major European titles simultaneously and one of five clubs to have won the three main UEFA trophies. Mourinho returned as manager in 2013 and led Chelsea to League Cup success in March 2015, and the Premier League title two months later. Mourinho was sacked after four months of the following season after a poor start.\nIn November 2012, Chelsea announced a profit of \u00a31.4\u00a0million for the year ending 30 June 2012, the first time the club had made a profit under Abramovich's ownership. This was followed by a loss in 2013 and then their highest ever profit of \u00a318.4\u00a0million for the year to June 2014. In 2018 Chelsea announced a record after-tax profit of \u00a362\u00a0million.\nIn 2017, under new coach Antonio Conte, Chelsea won their sixth English title and the following season won their eighth FA Cup. In 2018 Conte was sacked after a fifth-place finish and replaced with Maurizio Sarri, under whom Chelsea reached the League Cup final, which they lost on penalties to Manchester City and won the Europa League for a second time, beating Arsenal 4\u20131 in the final. Sarri then left the club to become manager of Juventus and was replaced by former Chelsea player Frank Lampard.\nIn Lampard's first season, he guided Chelsea to fourth place in the Premier League and reached the FA Cup final, losing 2\u20131 to Arsenal. Lampard was dismissed in January 2021 and replaced with Thomas Tuchel. \nUnder Tuchel, Chelsea reached the FA Cup final, losing 1\u20130 to Leicester City, and won their second UEFA Champions League title with a 1\u20130 win over Manchester City in Porto. The club subsequently won the 2021 UEFA Super Cup for the second time by defeating Villarreal 6\u20135 in a penalty shootout, after it had ended 1\u20131 in Belfast after extra time, and the 2021 FIFA Club World Cup (the first for the club) in Abu Dhabi after beating Brazilian Palmeiras 2\u20131.\nOn 18 April 2021, Chelsea announced it would be joining a new European Super League, a league competition comprising the biggest European clubs. After a backlash from supporters, the club announced their withdrawal days later. The club opted against furloughing their non-matchday staff during the COVID-19 pandemic, with the decision reportedly coming from Abramovich himself. Chelsea, one of the first clubs to help the National Health Service, lent the club-owned Millennium Hotel for the NHS staff.\nAmidst financial sanctions leveled at Russian oligarchs by Western governments in response to the 2022 Russian invasion of Ukraine, Abramovich stated on 26 February that he would hand over the stewardship of Chelsea to the trustees of the Chelsea Foundation. The trustees did not immediately agree, due to legal concerns regarding the rules of the Charity Commission for England and Wales. A week later, Abramovich wrote-off the \u00a31.5 billion the club owed him, and put the club up for sale, pledging to donate net proceeds from it to the victims of the war in Ukraine.\nOn 10 March 2022, the British government announced sanctions on Abramovich with Chelsea allowed to operate under a special license until 31 May. In the following weeks, reports emerged of Abramovich's involvement in brokering a peace deal between Ukraine and Russia and securing safe evacuation corridors in besieged Ukrainian cities. An American government official revealed that the Ukrainian president, Volodymyr Zelenskyy had requested that the US government not levy sanctions against Abramovich given his importance to war relief efforts.\nBlueCo ownership (2022\u2013present).\nOn 7 May 2022, Chelsea confirmed that terms have been agreed for a new ownership group, led by Todd Boehly, Clearlake Capital, Mark Walter and Hansj\u00f6rg Wyss, to acquire the club. The group was later known as BlueCo. The UK government approved the \u00a34.25bn takeover, ending Abramovich's 19-year ownership of the club. Bruce Buck, who served as chairman since 2003, was replaced by Boehly, while long-serving club director and \"de facto\" sporting director Marina Granovskaia left, as did Petr \u010cech from the role of technical and performance advisor.\nThe club brought in Graham Potter from Brighton &amp; Hove Albion to replace Tuchel on 8 September 2022. Chelsea won six of the first 11 games of the 2022\u201323 season, but only five of the remaining 27. Potter would be sacked on 2 April 2023 and eventually be replaced by Frank Lampard as caretaker manager. Under Lampard the club would only win one of their last 11 matches resulting in a 9% win percentage. Lampard's win percentage was the worst for any Chelsea manager who managed three games or more. Chelsea scored a record-low 38 goals across the entire season and finished in the bottom half of the table for the first time since 1995\u201396.\nMauricio Pochettino was announced as Lampard's replacement on 29 May 2023 and would take over managerial duties starting on 1 July 2023 on a two-year contract. He led Chelsea to a 6th-place finish after winning their final five games of the 2023\u201324 season, which earned the club a Conference League play-off round qualification. After clashing with the sporting directors Laurence Stewart and Paul Winstanley over strategy and management of the young squad, Pochettino agreed to leave the club at the end of the season.\nOn 3 June 2024, Enzo Maresca was announced as Pochettino's replacement, with the Italian beginning his term as manager on 1 July 2024.\nStadium.\nChelsea have only had one home ground, Stamford Bridge, where they have played since the team's foundation. The stadium was officially opened on 28 April 1877 and for the next 28 years it was used by the London Athletic Club as an arena for athletics meetings. In 1904, the ground was acquired by businessman Gus Mears and his brother Joseph, who had purchased nearby land (formerly a large market garden) with the aim of staging football matches on the now 12.5\u00a0acre (51,000\u00a0m2) site. Stamford Bridge was designed for the Mears family by the noted football architect Archibald Leitch, who had designed Ibrox, Craven Cottage and Hampden Park. Most football clubs were founded first, and then sought grounds in which to play, but Chelsea were founded for Stamford Bridge.\nStarting with an open bowl-like design and one grandstand with seating, Stamford Bridge had an original capacity of around 100,000, making it the second biggest stadium in England after Crystal Palace. The early 1930s saw the construction of a terrace on the southern part of the ground with a roof that covered around 20% of the stand. As the roof resembled that of a corrugated iron shed, the stand eventually became known as the \"Shed End\", although it is unknown who first coined this name. From the 1960s, it became known as the home of Chelsea's most loyal and vocal supporters. In 1939, another small seated stand was added, the North Stand, which remained until its demolition in 1975.\nIn the early 1970s, the club's owners announced a modernisation of Stamford Bridge with plans for a state-of-the-art 50,000 all-seater stadium. Work began in 1972 but the project was beset with problems and ultimately only the East Stand was completed; the cost brought the club close to bankruptcy. The freehold was sold to property developers and the club were under threat of eviction from the stadium. Following a long legal battle, it was not until the mid-1990s that Chelsea's future at Stamford Bridge was secured and renovation work resumed. The north, west and southern parts of the ground were converted into all-seater stands and moved closer to the pitch, a process completed by 2001. The East Stand was retained from the 1970s development. In 1996, the north stand was renamed the Matthew Harding stand, after the club director and benefactor who was killed in a helicopter crash earlier that year.\nWhen Stamford Bridge was redeveloped in the Bates era many additional features were added to the complex including two Millennium &amp; Copthorne hotels, apartments, bars, restaurants, the Chelsea Megastore, and an interactive visitor attraction called Chelsea World of Sport. The intention was that these facilities would provide extra revenue to support the football side of the business, but they were less successful than hoped and before the Abramovich takeover in 2003 the debt taken on to finance them was a major burden on the club. Soon after the takeover a decision was taken to drop the \"Chelsea Village\" brand and refocus on Chelsea as a football club. However, the stadium is sometimes still referred to as part of \"Chelsea Village\" or \"The Village\".\nThe Stamford Bridge freehold, the pitch, the turnstiles and Chelsea's naming rights are now owned by Chelsea Pitch Owners, a non-profit organisation in which fans are the shareholders. The CPO was created to ensure the stadium could never again be sold to developers. As a condition for using the Chelsea FC name, the club has to play its first team matches at Stamford Bridge, which means that if the club moves to a new stadium, they may have to change their name.\nChelsea's training ground is located in Cobham, Surrey. Chelsea moved to Cobham in 2004. Their previous training ground in Harlington was taken over by QPR in 2005. The new training facilities in Cobham were completed in 2007.\nStamford Bridge hosted the FA Cup final from 1920 to 1922, has held 10 FA Cup Semi-finals (most recently in 1978), ten FA Charity Shield matches (the last in 1970), and three England international matches, the last in 1932; it was the venue for an unofficial \"Victory International\" in 1946. The 2013 UEFA Women's Champions League final was played at Stamford Bridge as well. \nThe stadium has been used for a variety of other sports. In October 1905 it hosted a rugby union match between the All Blacks and Middlesex, and in 1914 hosted a baseball match between the touring New York Giants and the Chicago White Sox. It was the venue for a boxing match between world flyweight champion Jimmy Wilde and Joe Conn in 1918. The running track was used for dirt track racing between 1928 and 1932, greyhound racing from 1933 to 1968, and Midget car racing in 1948. In 1980, Stamford Bridge hosted the first international floodlit cricket match in the UK, between Essex and the West Indies. It was the home stadium of the London Monarchs American Football team for the 1997 season.\nThe previous owner Abramovich and the club's then executive board determined that a larger stadium is necessary in order for Chelsea to stay competitive with rival clubs who have significantly larger stadia, such as Arsenal and Manchester United. Owing to its location next to a main road and two railway lines, fans can only enter Stamford Bridge via the Fulham Road, which places constraints on expansion due to health and safety regulations. The club have consistently affirmed their desire to keep Chelsea at their current home, but have nonetheless been linked with a move to various nearby sites, including the Earls Court Exhibition Centre, Battersea Power Station and the Chelsea Barracks. In October 2011, a proposal from the club to buy back the freehold to the land on which Stamford Bridge sits was voted down by Chelsea Pitch Owners shareholders. In May 2012, the club made a formal bid to purchase Battersea Power Station, with a view to developing the site into a new stadium, but lost out to a Malaysian consortium. The club subsequently announced plans to redevelop Stamford Bridge into a 60,000-seater stadium,\nand in January 2017 these plans were approved by Hammersmith and Fulham council. However, on 31 May 2018, the club released a statement saying that the new stadium project had been put on hold indefinitely, citing \"the current unfavourable investment climate\".\nIn July 2022, it was reported that the club's new owner Todd Boehly had appointed American architect Janet Marie Smith to oversee the renovation of the stadium.\nIdentity.\nCrest.\nChelsea has had four main crests, which all underwent minor variations. The first, adopted when the club was founded, was the image of a Chelsea Pensioner, the army veterans who reside at the nearby Royal Hospital Chelsea. This contributed to the club's original \"pensioner\" nickname, and remained for the next half-century, though it never appeared on the shirts. When Ted Drake became Chelsea manager in 1952, he began to modernise the club. Believing the Chelsea pensioner crest to be old-fashioned, he insisted that it be replaced. A stop-gap badge which comprised the initials C.F.C. was adopted for a year. In 1953, the club crest was changed to an upright blue lion looking backwards and holding a staff. It was based on elements in the coat of arms of the Metropolitan Borough of Chelsea with the \"lion rampant regardant\" taken from the arms of then club president Viscount Chelsea and the staff from the Abbots of Westminster, former Lords of the Manor of Chelsea. It featured three red roses, to represent England, and two footballs. This was the first Chelsea crest to appear on the shirts, in the early 1960s. In 1975, a heraldic badge was granted by the College of Arms to the English Football League for use by Chelsea. The badge took the form of the familiar lion and staff encircled by a blue ring but without lettering and without the red roses and red footballs (blazoned as \"A lion rampant reguardant azure supporting with the forepaws a crozier or all within an annulet azure\"). In 1986, with Ken Bates owner of the club, Chelsea's crest was changed again as part of another attempt to modernise and because the old rampant lion badge could not be trademarked. The new badge featured a more naturalistic non-heraldic lion, in white and not blue, standing over the C.F.C. initials. This lasted for the next 19 years, with some modifications such as the use of different colours, including red from 1987 to 1995, and yellow from 1995 until 1999, before the white returned. With the new ownership of Roman Abramovich, and the club's centenary approaching, combined with demands from fans for the popular 1950s badge to be restored, it was decided that the crest should be changed again in 2005. The new crest was officially adopted for the start of the 2005\u201306 season and marked a return to the older design, used from 1953 to 1986, featuring a blue heraldic lion holding a staff. For the centenary season this was accompanied by the words '100 Years' and 'Centenary 2005\u20132006' on the top and bottom of the crest respectively.\nColours.\nChelsea have always worn blue shirts, although they originally used the paler eton blue, which was taken from the racing colours of then club president, Earl Cadogan, and was worn with white shorts and dark blue or black socks. The light blue shirts were replaced by a royal blue version in around 1912. In the 1960s Chelsea manager Tommy Docherty changed the kit again, switching to blue shorts (which have remained ever since) and white socks, believing it made the club's colours more modern and distinctive, since no other major side used that combination; this kit was first worn during the 1964\u201365 season. Since then Chelsea have always worn white socks with their home kit apart from a short spell from 1985 to 1992, when blue socks were reintroduced.\nChelsea's away colours are usually all yellow or all white with blue trim. More recently, the club have had a number of black or dark blue away kits which alternate every year. As with most teams, they have had some more unusual ones. At Docherty's behest, in the 1966 FA Cup semi-final they wore blue and black stripes, based on Inter Milan's kit. In the mid-1970s, the away strip was a red, white and green kit inspired by the Hungarian national side of the 1950s. Other away kits include an all jade strip worn from 1986 to 1989, red and white diamonds from 1990 to 1992, graphite and tangerine from 1994 to 1996, and luminous yellow from 2007 to 2008. The graphite and tangerine strip has appeared in lists of the worst football kits ever.\nSongs and fan chants.\nThe song \"Blue is the Colour\" was released as a single in the build-up to the 1972 League Cup final, with all members of Chelsea's first team squad singing; it reached number five in the UK Singles Chart. The song has since been adopted by a number of other sports teams around the world, including the Vancouver Whitecaps (as \"White is the Colour\") and the Saskatchewan Roughriders (as \"Green is the Colour\").\nChelsea released the song \"No One Can Stop Us Now\" in 1994 for reaching the 1994 FA Cup final. It reached number 23 in the UK Singles Chart. In the build-up to the 1997 FA Cup final, the song \"Blue Day\", performed by Suggs and members of the Chelsea squad, reached number 22 in the UK chart. In 2000, Chelsea released the song \"Blue Tomorrow\". It reached number 22 in the UK Singles Chart.\nAt matches, Chelsea fans sing chants such as \"Carefree\" (to the tune of \"Lord of the Dance\", whose lyrics were probably written by supporter Mick Greenaway), \"Ten Men Went to Mow\", \"We All Follow the Chelsea\" (to the tune of \"Land of Hope and Glory\"), \"Zigga Zagga\", and the celebratory \"Celery\". The latter is often accompanied by fans throwing celery at each other, although the vegetable was banned inside Stamford Bridge after an incident involving midfielder Cesc F\u00e0bregas at the 2007 League Cup final. Popular fan chants include, \"Super Chelsea\", \"Super Frank\" (dedicated to all-time leading goal scorer Frank Lampard), \"We love you Chelsea\" and \"Come on Chelsea\". There are situation-specific or team-specific chants meant to rile up opposition teams, managers or players.\nSupport.\nChelsea is among the most widely supported football clubs in the world. It has the sixth-highest average attendance in the history of English football, and regularly attract over 40,000 fans to Stamford Bridge; they were the ninth best-supported Premier League team in the 2023\u201324 season, with an average gate of 39,700. Chelsea's traditional fanbase comes from all over the Greater London area including working-class parts such as Hammersmith and Battersea, wealthier areas like Chelsea and Kensington, and from the home counties. There are numerous official supporters clubs in the United Kingdom and all over the world. Between 2007 and 2012, Chelsea were ranked fourth worldwide in annual replica kit sales, with an average of 910,000. As of 2023, Chelsea has 118.9\u00a0million followers on social media, the fourth highest among football clubs.\nDuring the 1970s and 1980s in particular, Chelsea supporters were associated with football hooliganism. The club's \"football firm\", originally known as the Chelsea Shed Boys, and subsequently as the Chelsea Headhunters, were nationally notorious for football violence, alongside hooligan firms from other clubs such as West Ham United's Inter City Firm and Millwall's Bushwackers, before, during and after matches. The increase of hooligan incidents in the 1980s led chairman Ken Bates to propose erecting an electric fence to deter them from invading the pitch, a proposal that the Greater London Council rejected.\nSince the 1990s, there has been a marked decline in crowd trouble at matches, as a result of stricter policing, CCTV in grounds and the advent of all-seater stadia. In 2007, the club launched the Back to the Shed campaign to improve the atmosphere at home matches, with notable success. According to Home Office statistics, 126 Chelsea fans were arrested for football-related offences during the 2009\u201310 season, the third highest in the division, and 27 banning orders were issued, the fifth-highest in the division.\nRivalries.\nChelsea have long-standing rivalries with North London clubs Arsenal and Tottenham Hotspur. A strong rivalry with Leeds United dates back to several heated and controversial matches in the 1960s and 1970s, particularly the 1970 FA Cup final. More recently a rivalry with Liverpool has grown following repeated clashes in cup competitions. Fellow West London clubs Brentford, Fulham and Queens Park Rangers are considered rivals, but less so in recent times as matches have only taken place intermittently due to the teams often being in separate divisions.\nA 2004 survey by Planetfootball.com found that Chelsea fans consider their main rivalries to be with (in descending order): Arsenal, Tottenham Hotspur and Manchester United. In the same survey, fans of Arsenal, Fulham, Leeds United, QPR, Tottenham, and West Ham United named Chelsea as one of their three main rivals. A 2012 survey, conducted among 1,200 supporters of the top four league divisions across the country, found that many clubs' main rivals had changed since 2003 and reported that Chelsea fans consider Tottenham to be their main rivals, above Arsenal and Manchester United. Additionally, fans of Arsenal, Brentford, Fulham, Liverpool, Manchester United, QPR, Tottenham and West Ham identified Chelsea as one of their top three rivals.\nRecords and statistics.\nChelsea's highest appearance-maker is ex-captain Ron Harris, who played in 795 competitive games for the club between 1961 and 1980. Five other players made more than 500 appearances for the club: Peter Bonetti (729; 1959\u201379), John Terry (717; 1998\u20132017), Frank Lampard (648; 2001\u20132014), John Hollins (592; 1963\u20131975 and 1983\u20131984), and C\u00e9sar Azpilicueta (508; 2012\u20132023). With 103 caps (101 while at the club) for England, Lampard is Chelsea's most capped international player. Every starting player in Chelsea's 57 games of the 2013\u201314 season was a full international \u2013 a new club record.\nLampard is Chelsea's all-time top goalscorer, having scored 211 goals in 648 games (2001\u20132014); he passed Bobby Tambling's longstanding record of 202 in May 2013. Eight other players have scored over 100 goals for Chelsea: George Hilsdon (1906\u20131912), George Mills (1929\u20131939), Roy Bentley (1948\u20131956), Jimmy Greaves (1957\u20131961), Peter Osgood (1964\u20131974 and 1978\u20131979), Kerry Dixon (1983\u20131992), Didier Drogba (2004\u20132012 and 2014\u20132015), and Eden Hazard (2012\u20132019). Greaves holds the club record for the most goals scored in one season (43 in 1960\u201361). While a Chelsea player, Greaves became the youngest ever player to score 100 goals in the English top-flight, at 20 years and 290 days.\nChelsea's biggest winning scoreline in a competitive match is 13\u20130, achieved against Jeunesse Hautcharage in the Cup Winners' Cup in 1971. The club's biggest top-flight win was an 8\u20130 victory against Wigan Athletic in 2010, which was matched in 2012 against Aston Villa. Chelsea's biggest loss was an 8\u20131 reverse against Wolverhampton Wanderers in 1953. The club's 21\u20130 aggregate victory over Jeunesse Hautcharage in the UEFA Cup Winners' Cup in 1971 is a record in European competition. Officially, Chelsea's highest home attendance is 82,905 for a First Division match against Arsenal on 12 October 1935. However, an estimated crowd of over 100,000 attended a friendly match against Soviet team Dynamo Moscow on 13 November 1945.\nFrom 20 March 2004 to 26 October 2008, Chelsea went a record 86 consecutive league matches at home without defeat, beating the previous record of 63 matches unbeaten set by Liverpool between 1978 and 1980. Chelsea hold the English record for the fewest goals conceded during a league season (15), the highest number of clean sheets overall in a Premier League season (25) (both set during the 2004\u201305 season), and the most consecutive clean sheets from the start of a league season (6, set during the 2005\u201306 season). Chelsea is the only Premier League side to have won its opening nine league games of the season, doing so in 2005\u201306. From 2009 to 2013, Chelsea were unbeaten in a record 29 consecutive FA Cup matches (excluding penalty shoot-outs).\nOn 25 August 1928, Chelsea, along with Arsenal, became the first club to play with shirt numbers, in their match against Swansea Town. They were the first English side to travel by aeroplane to a domestic away match, when they visited Newcastle United on 19 April 1957, and the first First Division side to play a match on a Sunday, when they faced Stoke City on 27 January 1974. On 26 December 1999, Chelsea became the first British side to field an entirely foreign starting line-up (no British or Irish players) in a Premier League match against Southampton. In May 2007, Chelsea were the first team to win the FA Cup at the new Wembley Stadium, having been the last to win it at the old Wembley. They were the first English club to be ranked No. 1 under UEFA's five-year coefficient system in the 21st century. They were the first Premier League team, and the first team in the English top flight since 1962\u201363, to score at least 100 goals in a single season, reaching the milestone during the 2009\u201310 season. Chelsea is the only London club to have won the UEFA Champions League. Upon winning the 2012\u201313 UEFA Europa League, Chelsea became the first English club to win all four UEFA club trophies and the only club to hold the Champions League and the Europa League at the same time.\nChelsea have broken the record for the highest transfer fee paid by a British club three times. Their \u00a330.8\u00a0million purchase of Andriy Shevchenko from A.C. Milan in June 2006 was a British record until surpassed by the \u00a332.5\u00a0million paid by Manchester City for Robinho in September 2008. The club's \u00a350\u00a0million purchase of Fernando Torres from Liverpool in January 2011 held the record until \u00c1ngel Di Mar\u00eda signed for Manchester United in August 2014 for \u00a359.7\u00a0million. The club's \u00a371\u00a0million purchase of Kepa Arrizabalaga in August 2018 remains a world record fee paid for a goalkeeper.\nOn 12 February 2022, Chelsea became the first London club to win the FIFA Club World Cup against Palmeiras with Kai Havertz scoring a late penalty. Chelsea broke the spending record in the winter transfer window with a \u00a3289 million spending spree on eight new signings, with the \u00a3107 million signing of Enzo Fernandez breaking the British transfer record.\nOwnership and finances.\nChelsea Football Club was founded by Gus Mears in 1905. After his death in 1912, his descendants continued to own the club until 1982, when Ken Bates bought the club from Mears' great-nephew Brian Mears for \u00a31. Bates bought a controlling stake in the club and floated Chelsea on the AIM stock exchange in March 1996. In the mid-1990s Chelsea fan and businessman Matthew Harding became a director, and loaned the club \u00a326\u00a0million to build the new North Stand and invest in new players.\nIn July 2003, Roman Abramovich purchased just over 50% of Chelsea Village plc's share capital, including Bates' 29.5% stake, for \u00a330\u00a0million and over the following weeks bought out most of the remaining 12,000 shareholders at 35 pence per share, completing a \u00a3140\u00a0million takeover. Other shareholders at the time of the takeover included the Matthew Harding estate (21%), BSkyB (9.9%) and various anonymous offshore trusts.\nAt the time of the Abramovich takeover, the club had debts of around \u00a3100\u00a0million, which included a 10-year \u00a375\u00a0million Eurobond taken out in 1997 by the Bates regime to buy the freehold of Stamford Bridge and finance the redevelopment of the stadium. The 9% interest on the loan cost the club around \u00a37\u00a0million a year and according to Bruce Buck, Chelsea were struggling to pay an instalment due in July 2003. Abramovich paid off some of that debt immediately, but the outstanding \u00a336\u00a0million on the Eurobond was not fully repaid until 2008. Since then, the club had no external debt.\nAbramovich changed the ownership name to Chelsea FC plc, whose ultimate parent company was Fordstam Limited, which was controlled by him. Chelsea were additionally funded by Abramovich via interest free soft loans channelled through his holding company Fordstam Limited. The loans stood at \u00a3709\u00a0million in December 2009, when they were all converted to equity by Abramovich, leaving the club themselves debt free, although the debt remained with Fordstam.\nChelsea did not turn a profit in the first nine years of Abramovich's ownership, and made record losses of \u00a3140m in June 2005. In November 2012, Chelsea announced a profit of \u00a31.4\u00a0million for the year ending 30 June 2012, the first time the club had made a profit under Abramovich's ownership. This was followed by a loss in 2013 and then their highest ever profit of \u00a318.4\u00a0million for the year to June 2014. In 2018 Chelsea announced a record after-tax profit of \u00a362\u00a0million.\nChelsea has been described as a global brand; a 2012 report by Brand Finance ranked Chelsea fifth among football brands and valued the club's brand value at US$398\u00a0million \u2013 an increase of 27% from the previous year, valuing it at US$10\u00a0million more than the sixth best brand, London rivals Arsenal \u2013 and gave the brand a strength rating of AA (very strong). In 2016, \"Forbes\" magazine ranked Chelsea the seventh most valuable football club in the world, at \u00a31.15\u00a0billion ($1.66\u00a0billion). , Chelsea was ranked eighth in the Deloitte Football Money League with an annual commercial revenue of \u00a3322.59\u00a0million.\nAs of May 2022, Chelsea was ranked the eighth-most valuable club in the world according to \"Forbes\", and eighth according to Deloitte, with an annual commercial revenue of \u20ac493.1 million.\nThe club's recent accounting records highlight \u00a326.6m they lost in compensation to former head coach Antonio Conte for sacking and to pay off his backroom staff and the legal costs that followed.\nOn 26 February 2022, during the Russo-Ukrainian War, Abramovich handed over \"stewardship and care\" of Chelsea FC to the Chelsea Charitable Foundation. Abramovich released an official statement on 2 March 2022 confirming that he was selling the club due to the ongoing situation in Ukraine. Although the UK government froze Abramovich's assets in United Kingdom on 10 March due to his \"close ties with Kremlin\", it was made clear that the Chelsea club will be allowed to operate in terms of activities which are football related. On 12 March, the Premier League disqualified Abramovich as a director of Chelsea Football Club.\nOn 19 March 2022, there were five confirmed bids to acquire Chelsea FC: submitted to Raine Capital which was handling the sale of the club. Some of these were a consortium led by ex-Liverpool chairman Sir Martin Broughton, a group of investors led by the Ricketts family (among them Joe and Pete Ricketts), Swiss and American businessmen Hansj\u00f6rg Wyss and Todd Boehly, Aethel Partners headed by Portuguese Ricardo Santos Silva and British businessman Nick Candy, supported by former Chelsea striker Gianluca Vialli.\nOn 7 May, the club finally confirmed that \"terms have been agreed\" for a new ownership group led by Todd Boehly and Clearlake Capital. On 30 May, it was confirmed that the Boehly consortium had completed the purchase of the club. The consortium includes Wyss and Mark Walter. Walter and Boehly are also owners of the Los Angeles Dodgers, the Los Angeles Lakers, and the Los Angeles Sparks. The consortium was later known as BlueCo. The transaction had received all necessary approvals from the governments of the United Kingdom and, the Premier League, and other authorities.\nSponsorship.\nChelsea's kit has been manufactured by Nike since July 2017. Previously, the kit was manufactured by Adidas, which was originally contracted to supply the club's kit from 2006 to 2018. The partnership was extended in October 2010 in a deal worth \u00a3160\u00a0million over eight years. This deal was again extended in June 2013 in a deal worth \u00a3300\u00a0million over another 10 years. In May 2016, Adidas announced that by mutual agreement, the kit sponsorship would end six years early on 30 June 2017. Chelsea had to pay \u00a340m in compensation to Adidas. In October 2016, Nike was announced as the new kit sponsor, in a deal worth \u00a3900m over 15 years, until 2032. Previously, the kit was manufactured by Umbro (1975\u201381), Le Coq Sportif (1981\u201386), The Chelsea Collection (1986\u201387), Umbro (1987\u20132006), and Adidas (2006\u20132017).\nChelsea's first shirt sponsor was Gulf Air, agreed during the 1983\u201384 season. The club was then sponsored by Grange Farms, Bai Lin Tea and Simod before a long-term deal was signed with Commodore International in 1989; Amiga, an offshoot of Commodore, appeared on the shirts. Chelsea was subsequently sponsored by Coors beer (1994\u201397), Autoglass (1997\u20132001), Emirates (2001\u201305), Samsung Mobile (2005\u201308), Samsung (2008\u201315) and Yokohama Tyres (2015\u201320). From July 2020, Chelsea's sponsor was Three; however, it temporarily suspended its sponsorship in March 2022 in response to sanctions leveled by the UK government against Abramovich. It restored its sponsorship after the change of ownership of the club.\nFollowing the introduction of sleeve sponsors in the Premier League, Chelsea had Alliance Tyres as its first sleeve sponsor in the 2017\u201318 season, followed by Hyundai Motor Company in 2018\u201319 season. In 2022\u201323 season, Amber Group became the new sleeve sponsor, with the flagship digital asset platform WhaleFin appearing on the sleeves of both men's and women's teams.\nThe club has a variety of other sponsors and official partners, which include Cadbury, EA Sports, FICO, Hilton Worldwide, 3 (company), Levy Restaurants, MSC Cruises, Oman Air, Parimatch, Rexona, Singha, The St. James, Trivago and BingX.\nPopular culture.\nIn 1930, Chelsea featured in one of the earliest football films, \"The Great Game\". One-time Chelsea centre forward, Jack Cock, who by then was playing for Millwall, was the star of the film and several scenes were shot at Stamford Bridge, including on the pitch, the boardroom, and the dressing rooms. It included guest appearances by then-Chelsea players Andrew Wilson, George Mills, and Sam Millington. Owing to the notoriety of the Chelsea Headhunters, a football firm associated with the club, Chelsea have featured in films about football hooliganism, including 2004's \"The Football Factory\". Chelsea appeared in the Hindi film \"Jhoom Barabar Jhoom\". In April 2011, Montenegrin comedy series \"Nijesmo mi od ju\u010de\" made an episode in which Chelsea played against FK Sutjeska Nik\u0161i\u0107 for qualification of the UEFA Champions League.\nUp until the 1950s, the club had a long-running association with the music halls; their underachievement often provided material for comedians such as George Robey. It culminated in comedian Norman Long's release of a comic song in 1933, ironically titled \"On the Day That Chelsea Went and Won the Cup\", the lyrics of which describe a series of bizarre and improbable occurrences on the hypothetical day when Chelsea finally won a trophy. In Alfred Hitchcock's 1935 film \"The 39 Steps\", Mr Memory claims that Chelsea last won the Cup in 63 BC, \"in the presence of the Emperor Nero.\" Scenes in a 1980 episode of \"Minder\" were filmed during a real match at Stamford Bridge between Chelsea and Preston North End with Terry McCann (Dennis Waterman) standing on the terraces.\nChelsea Women.\nChelsea operate a women's football team, Chelsea Football Club Women, formerly known as Chelsea Ladies. They have been affiliated to the men's team since 2004 and are part of the club's Community Development programme. They play their home games at Kingsmeadow, formerly the home ground of the EFL League Two club AFC Wimbledon. The club were promoted to the Premier Division for the first time in 2005 as Southern Division champions and won the Surrey County Cup nine times between 2003 and 2013. In 2010, Chelsea Ladies were one of the eight founder members of the FA Women's Super League. In 2015, Chelsea Ladies won the FA Women's Cup for the first time, beating Notts County Ladies at Wembley Stadium, and a month later clinched their first FA WSL title to complete a league and cup double. In 2018, they won a second league and FA Cup double. Two years later, in 2020, they repeated their double success by winning the third league title and the FA Women's League Cup for the first time. In the 2020\u201321 season, Chelsea won a domestic treble by winning the league, FA Cup and League Cup. They reached the final of the UEFA Women's Champions League for the first time, losing to Barcelona 4\u20130.\nJohn Terry, former captain of the Chelsea men's team, is the president of Chelsea Women."}
{"id": "7475", "revid": "39086769", "url": "https://en.wikipedia.org/wiki?curid=7475", "title": "CANDU reactor", "text": "The CANDU (CANada Deuterium Uranium) is a Canadian pressurized heavy-water reactor design used to generate electric power. The acronym refers to its deuterium oxide (heavy water) moderator and its use of (originally, natural) uranium fuel. CANDU reactors were first developed in the late 1950s and 1960s by a partnership between Atomic Energy of Canada Limited (AECL), the Hydro-Electric Power Commission of Ontario, Canadian General Electric, and other companies.\nThere have been two major types of CANDU reactors, the original design of around 500\u00a0MWe that was intended to be used in multi-reactor installations in large plants, and the optimized CANDU 6 in the 600\u00a0MWe class that is designed to be used in single stand-alone units or in small multi-unit plants. CANDU 6 units were built in Quebec and New Brunswick, as well as Pakistan, Argentina, South Korea, Romania, and China. A single example of a non-CANDU 6 design was sold to India. The multi-unit design was used only in Ontario, Canada, and grew in size and power as more units were installed in the province, reaching ~880\u00a0MWe in the units installed at the Darlington Nuclear Generating Station. An effort to optimize the larger units in a fashion similar to CANDU 6 led to the CANDU 9.\nBy the early 2000s, sales prospects for the original CANDU designs were dwindling due to the introduction of newer designs from other companies. AECL responded by cancelling CANDU 9 development and moving to the Advanced CANDU reactor (ACR) design. ACR failed to find any buyers; its last potential sale was for an expansion at Darlington, but this was cancelled in 2009. In October 2011, the Canadian Federal Government licensed the CANDU design to Candu Energy (a wholly owned subsidiary of SNC-Lavalin, now the AtkinsR\u00e9alis Group Inc.), which also acquired the former reactor development and marketing division of AECL at that time. Candu Energy offers support services for existing sites and is completing formerly stalled installations in Romania and Argentina through a partnership with China National Nuclear Corporation. SNC Lavalin, the successor to AECL, is pursuing new CANDU 6 reactor sales in Argentina (Atucha 3), as well as China and Britain. Sales effort for the ACR reactor has ended.\nIn 2017, a consultation with industry led Natural Resources Canada to establish a \"SMR Roadmap\" targeting the development of small modular reactors (SMRs). In response, SNC-Lavalin developed a 300\u00a0MWe SMR version of the CANDU, the CANDU SMR, which it began to highlight on its website. In 2020, the CANDU SMR was not selected for further design work for a Canadian demonstration project. SNC-Lavalin is still looking at marketing a 300 MW SMR in part due to projected demand due to climate change mitigation.\nDesign and operation.\nThe basic operation of the CANDU design is similar to other nuclear reactors. Fission reactions in the reactor core heat pressurized water in a \"primary cooling loop\". A heat exchanger, also known as a steam generator, transfers the heat to a secondary cooling loop, which powers a steam turbine with an electric generator attached to it (for a typical Rankine thermodynamic cycle). The exhaust steam from the turbines is then cooled, condensed and returned as feedwater to the steam generator. The final cooling often uses cooling water from a nearby source, such as a lake, river, or ocean. Newer CANDU plants, such as the Darlington Nuclear Generating Station near Toronto, Ontario, use a diffuser to spread the warm outlet water over a larger volume and limit the effects on the environment. Although all CANDU plants to date have used open-cycle cooling, modern CANDU designs can use cooling towers instead.\nWhere the CANDU design differs from most other designs is in the details of the fissile core and the primary cooling loop. Natural uranium consists of a mix of mostly uranium-238 with small amounts of uranium-235 and trace amounts of other isotopes. Fission in these elements releases high-energy neutrons, which can cause other 235U atoms in the fuel to undergo fission as well. This process is more effective when the neutron energies are lower than what the reactions release naturally. Most reactors use some form of neutron moderator to lower the energy of the neutrons, or \"thermalize\" them, which makes the reaction more efficient. The energy lost by the neutrons during this moderation process heats the moderator, and this heat is extracted for power.\nMost commercial reactor designs use normal water as the moderator. Water absorbs some of the neutrons, enough that it is not possible to keep the reaction going in natural uranium. CANDU replaces this \"light\" water with heavy water.\nHeavy water's extra neutron decreases its ability to absorb excess neutrons, resulting in a better neutron economy. This allows CANDU to run on unenriched natural uranium, or uranium mixed with a wide variety of other materials such as plutonium and thorium. This was a major goal of the CANDU design; by operating on natural uranium the cost of enrichment is removed. This also presents an advantage in nuclear proliferation terms, as there is no need for enrichment facilities, which might also be used for weapons.\nCalandria and fuel design.\nIn conventional light-water reactor (LWR) designs, the entire fissile core is placed in a large pressure vessel. The amount of heat that can be removed by a unit of a coolant is a function of the temperature; by pressurizing the core, the water can be heated to much greater temperatures before boiling, thereby removing more heat and allowing the core to be smaller and more efficient.\nBuilding a pressure vessel of the required size is a significant challenge, and at the time of the CANDU's design, Canada's heavy industry lacked the requisite experience and capability to cast and machine reactor pressure vessels of the required size. This problem is amplified by natural uranium fuel's lower fissile density, which requires a larger reactor core. This issue was so major that even the relatively small pressure vessel originally intended for use in the NPD prior to its mid-construction redesign could not be fabricated domestically and had to be manufactured in Scotland instead. Domestic development of the technology required to produce pressure vessels of the size required for commercial-scale heavy water moderated power reactors was thought to be very unlikely.\nIn CANDU the fuel bundles of about 10\u00a0cm diameter are composed of many smaller metal tubes. The bundles are contained in pressure tubes within a larger vessel containing additional heavy water acting as a moderator. This larger vessel, known as a calandria, is not pressurized and remains at lower temperatures, making it easier to fabricate. In order to prevent the heat from the pressure tubes from leaking into the surrounding moderator, each pressure tube is enclosed in a calandria tube. Carbon dioxide gas in the gap between the two tubes acts as an insulator. The moderator tank also acts as a large heat sink that provides an additional safety feature.\nIn a conventional pressurized water reactor, refuelling the system requires to shut down the core and to open the pressure vessel. In CANDU reactors, the tube being refuelled remains pressurized. This allows the CANDU system to be continually refuelled without shutting down, another major design goal. In modern systems, two robotic machines attach to the reactor faces and open the end caps of a pressure tube. One machine pushes in the new fuel, whereby the depleted fuel is pushed out and collected at the other end. A significant operational advantage of online refuelling is that a failed or leaking fuel bundle can be removed from the core once it has been located, thus reducing the radiation levels in the primary cooling loop.\nEach fuel bundle is a cylinder assembled from thin tubes filled with ceramic pellets of uranium oxide fuel (fuel elements). In older designs, the bundle had 28 or 37 half-meter-long fuel elements with 12\u201313 such assemblies lying end-to-end in a pressure tube. The newer CANFLEX bundle has 43 fuel elements, with two element sizes (so the power rating can be increased without melting the hottest fuel elements). It is about in diameter, long, weighs about , and is intended to eventually replace the 37-element bundle. To allow the neutrons to flow freely between the bundles, the tubes and bundles are made of neutron-transparent zircaloy (zirconium + 2.5% wt niobium).\nPurpose of using heavy water.\nNatural uranium is a mix of isotopes: approximately 99.28% uranium-238 and 0.72% uranium-235 by atom fraction. Nuclear power reactors are usually operated at constant power for long periods of time, which requires a constant rate of fission over time. In order to keep the fission rate constant, the neutrons released by fission must produce an equal number of fissions in other fuel atoms. This balance is referred to as \"criticality.\" Neutrons released by nuclear fission are fairly energetic and are not readily absorbed (or \"captured\") by the surrounding fissile material. In order to improve the capture rate, the neutron energy must be reduced, or \"moderated\", to be as low as possible. In practice, the lower energy limit is the energy where the neutrons are in thermal equilibrium with the moderator. When neutrons approach this lower energy limit, they are referred to as \"thermal neutrons.\"\nDuring moderation it helps to separate the neutrons and uranium, since 238U has a large affinity for intermediate-energy neutrons (\"resonance\" absorption), but is only easily fissioned by the few energetic neutrons above \u22481.5\u20132\u00a0MeV. Since most of the fuel material is usually 238U, most reactor designs are based on thin fuel rods separated by moderator, allowing the neutrons to travel in the moderator before entering the fuel again. More neutrons are released than the minimum needed to maintain the chain reaction; when uranium-238 absorbs neutrons, plutonium is created, which helps to make up for the depletion of uranium-235. Eventually the build-up of fission products that are more neutron-absorbing than 238U slows the reaction and calls for refuelling.\nLight water makes an excellent moderator: the light hydrogen atoms are very close in mass to a neutron and can absorb a lot of energy in a single collision (like a collision of two billiard balls). However, light hydrogen can absorb neutrons, reducing the number available to react with the small amount of 235U in natural uranium, preventing criticality. In order to allow criticality, the fuel must be enriched, increasing the amount of 235U to a usable level. In light-water reactors, the fuel is typically enriched to between 2% and 5% 235U (the leftover fraction with less 235U is called depleted uranium). Enrichment facilities are expensive to build and operate. They may also pose a proliferation concern, as they can be used to enrich the 235U much further, up to weapons-grade material (90% or more 235U). This can be remedied if the fuel is supplied and reprocessed by an internationally approved supplier.\nThe main advantage of heavy water moderator over light water is the reduced absorption of the neutrons that sustain the chain reaction, allowing a lower concentration of fissile atoms (to the point of using unenriched natural uranium fuel). Deuterium (\"heavy hydrogen\") already has the extra neutron that light hydrogen would absorb, reducing the tendency to capture neutrons. Deuterium has twice the mass of a single neutron (vs light hydrogen, which has about the same mass); the mismatch means that more collisions are needed to moderate the neutrons, requiring a larger thickness of moderator between the fuel rods. This increases the size of the reactor core and the leakage of neutrons. It is also the practical reason for the calandria design, otherwise, a very large pressure vessel would be needed. The low 235U density in natural uranium also implies that less of the fuel will be consumed before the fission rate drops too low to sustain criticality, because the ratio of 235U to fission products + 238U is lower. In CANDU most of the moderator is at lower temperatures than in other designs, reducing the spread of speeds and the overall speed of the moderator particles. This means that most of the neutrons will end up at a lower energy and be more likely to cause fission, so CANDU not only \"burns\" natural uranium, but it does so more effectively as well. Overall, CANDU reactors use 30\u201340% less mined uranium than light-water reactors per unit of electricity produced. This is a major advantage of the heavy-water design; it not only requires less fuel, but as the fuel does not have to be enriched, it is much less expensive as well.\nA further unique feature of heavy-water moderation is the greater stability of the chain reaction. This is due to the relatively low binding energy of the deuterium nucleus (2.2\u00a0MeV), leading to some energetic neutrons and especially gamma rays breaking the deuterium nuclei apart to produce extra neutrons. Both gammas produced directly by fission and by the decay of fission fragments have enough energy, and the half-lives of the fission fragments range from seconds to hours or even years. The slow response of these gamma-generated neutrons delays the response of the reactor and gives the operators extra time in case of an emergency. Since gamma rays travel for meters through water, an increased rate of chain reaction in one part of the reactor will produce a response from the rest of the reactor, allowing various negative feedbacks to stabilize the reaction.\nOn the other hand, the fission neutrons are thoroughly slowed down before they reach another fuel rod, meaning that it takes neutrons a longer time to get from one part of the reactor to the other. Thus if the chain reaction accelerates in one section of the reactor, the change will propagate itself only slowly to the rest of the core, giving time to respond in an emergency. The independence of the neutrons' energies from the nuclear fuel used is what allows such fuel flexibility in a CANDU reactor, since every fuel bundle will experience the same environment and affect its neighbors in the same way, whether the fissile material is uranium-235, uranium-233 or plutonium.\nCanada developed the heavy-water-moderated design in the post\u2013World War II era to explore nuclear energy while lacking access to enrichment facilities. War-era enrichment systems were extremely expensive to build and operate, whereas the heavy water solution allowed the use of natural uranium in the experimental ZEEP reactor. A much less expensive enrichment system was developed, but the United States classified work on the cheaper gas centrifuge process. The CANDU was therefore designed to use natural uranium.\nSafety features.\nThe CANDU includes several active and passive safety features in its design. Some of these are a side effect of the physical layout of the system.\nCANDU designs have a positive void coefficient, as well as a small power coefficient, normally considered bad in reactor design. This implies that steam generated in the coolant will increase the reaction rate, which in turn would generate more steam. This is one of the many reasons for the cooler mass of moderator in the calandria, as even a serious steam incident in the core would not have a major impact on the overall moderation cycle. Only if the moderator itself starts to boil would there be any significant effect, and the large thermal mass ensures that this will occur slowly. The deliberately \"sluggish\" response of the fission process in CANDU allows controllers more time to diagnose and deal with problems.\nThe fuel channels can only maintain criticality if they are mechanically sound. If the temperature of the fuel bundles increases to the point where they are mechanically unstable, their horizontal layout means that they will bend under gravity, shifting the layout of the bundles and reducing the efficiency of the reactions. Because the original fuel arrangement is optimal for a chain reaction, and the natural uranium fuel has little excess reactivity, any significant deformation will stop the inter-fuel pellet fission reaction. This will not stop heat production from fission product decay, which would continue to supply a considerable heat output. If this process further weakens the fuel bundles, the pressure tube they are in will eventually bend far enough to touch the calandria tube, allowing heat to be transferred into the moderator tank. The moderator vessel has a considerable thermal capability on its own and is normally kept relatively cool.\nHeat generated by fission products would initially be at about 7% of full reactor power, which requires significant cooling. The CANDU designs have several emergency cooling systems, as well as having limited self-pumping capability through thermal means (the steam generator is well above the reactor). Even in the event of a catastrophic accident and core meltdown, the fuel is not critical in light water. This means that cooling the core with water from nearby sources will not add to the reactivity of the fuel mass.\nNormally the rate of fission is controlled by light-water compartments called liquid zone controllers, which absorb excess neutrons, and by adjuster rods, which can be raised or lowered in the core to control the neutron flux. These are used for normal operation, allowing the controllers to adjust reactivity across the fuel mass, as different portions would normally burn at different rates depending on their position. The adjuster rods can also be used to slow or stop criticality. Because these rods are inserted into the low-pressure calandria, not the high-pressure fuel tubes, they would not be \"ejected\" by steam, a design issue for many pressurized-water reactors.\nThere are two independent, fast-acting safety shutdown systems as well. Shutoff rods are held above the reactor by electromagnets and drop under gravity into the core to quickly end criticality. This system works even in the event of a complete power failure, as the electromagnets only hold the rods out of the reactor when power is available. A secondary system injects a high-pressure gadolinium nitrate neutron absorber solution into the calandria.\nFuel cycle.\nA heavy-water design can sustain a chain reaction with a lower concentration of fissile atoms than light-water reactors, allowing it to use some alternative fuels; for example, \"recovered uranium\" (RU) from used LWR fuel. CANDU was designed for natural uranium with only 0.7%\u00a0235U, so reprocessed uranium with 0.9%\u00a0235U is a comparatively rich fuel. This extracts a further 30\u201340% energy from the uranium. The Qinshan CANDU reactor in China has used recovered uranium. The DUPIC (\"Direct Use of spent PWR fuel in CANDU\") process under development can recycle it even without reprocessing. The fuel is sintered in air (oxidized), then in hydrogen (reduced) to break it into a powder, which is then formed into CANDU fuel pellets.\nCANDU reactors can also breed fuel from the more abundant thorium. This is being investigated by India to take advantage of its natural thorium reserves.\nEven better than LWRs, CANDU can utilize a mix of uranium and plutonium oxides (MOX fuel), the plutonium either from dismantled nuclear weapons or reprocessed reactor fuel. The mix of isotopes in reprocessed plutonium is not attractive for weapons, but can be used as fuel (instead of being simply nuclear waste), while consuming weapons-grade plutonium eliminates a proliferation hazard. If the aim is explicitly to utilize plutonium or other actinides from spent fuel, then special inert-matrix fuels are proposed to do this more efficiently than MOX. Since they contain no uranium, these fuels do not breed any extra plutonium.\nEconomics.\nThe neutron economy of heavy-water moderation and precise control of on-line refueling allow CANDU to use a wide range of fuels other than enriched uranium, e.g., natural uranium, reprocessed uranium, thorium, plutonium, and used LWR fuel. Given the expense of enrichment, this can make fuel much cheaper. There is an initial investment into the tonnes of 99.75% pure heavy water to fill the core and heat-transfer system. In the case of the Darlington plant, costs released as part of a freedom of information act request put the overnight cost of the plant (four reactors totalling 3,512\u00a0MWe net capacity) at $5.117 billion CAD (about US$4.2 billion at early-1990s exchange rates). Total capital costs including interest were $14.319 billion CAD (about US$11.9 billion) with the heavy water accounting for $1.528 billion, or 11%, of this.\nSince heavy water is less efficient than light water at slowing neutrons, CANDU needs a larger moderator-to-fuel ratio and a larger core for the same power output. Although a calandria-based core is cheaper to build, its size increases the cost for standard features like the containment building. Generally nuclear plant construction and operations are \u224865% of overall lifetime cost; for CANDU, costs are dominated by construction even more. Fueling CANDU is cheaper than other reactors, costing only \u224810% of the total, so the overall price per kWh electricity is comparable. The next-generation Advanced CANDU reactor (ACR) mitigates these disadvantages by having light-water coolant and using a more compact core with less moderator.\nWhen first introduced, CANDUs offered much better capacity factor (ratio of power generated to what would be generated by running at full power, 100% of the time) than LWRs of a similar generation. The light-water designs spent, on average, about half the time being refueled or maintained. Since the 1980s, dramatic improvements in LWR outage management have narrowed the gap, with several units achieving capacity factors ~90% and higher, with an overall US fleet performance of 92% in 2010. The latest-generation CANDU 6 reactors have an 88\u201390% CF, but overall performance is dominated by the older Canadian units with CFs on the order of 80%. \nRefurbished units had historically demonstrated poor performance, on the order of 65%. \nThis has since improved with the return of Bruce units A1 and A2 to operation, which have post-refurbishment (2013+) capacity factors of 90.78% and 90.38%, respectively.\nSome CANDU plants suffered from cost overruns during construction, often from external factors such as government action. For instance, imposed construction delays led to roughly a doubling of the cost of the Darlington Nuclear Generating Station near Toronto, Ontario. Technical problems and redesigns added about another billion to the resulting $14.4 billion price. In 2002 two CANDU 6 reactors at Qinshan in China were completed on-schedule and on-budget, an achievement attributed to tight control over scope and schedule.\nNuclear nonproliferation.\nIn terms of safeguards against nuclear weapons proliferation, CANDUs meet a similar level of international certification as other reactors. The plutonium for India's first nuclear detonation, Operation Smiling Buddha in 1974, was produced in a CIRUS reactor supplied by Canada and partially paid for by the Canadian government using heavy water supplied by the United States. In addition to its two PHWR reactors, India has some safeguarded pressurised heavy-water reactors (PHWRs) based on the CANDU design, and two safeguarded light-water reactors supplied by the US. Plutonium has been extracted from the spent fuel from all of these reactors; India mainly relies on an Indian designed and built military reactor called Dhruva. The design is believed to be derived from the CIRUS reactor, with the Dhruva being scaled-up for more efficient plutonium production. It is this reactor which is thought to have produced the plutonium for India's more recent (1998) Operation Shakti nuclear tests.\nAlthough heavy water is relatively immune to neutron capture, a small amount of the deuterium turns into tritium in this way. This tritium is extracted from some CANDU plants in Canada, mainly to improve safety in case of heavy-water leakage. The gas is stockpiled and used in a variety of commercial products, notably \"powerless\" lighting systems and medical devices. In 1985 what was then Ontario Hydro sparked controversy in Ontario due to its plans to sell tritium to the United States. The plan, by law, involved sales to non-military applications only, but some speculated that the exports could have freed American tritium for the United States nuclear weapons program. Future demands appear to outstrip production, in particular the demands of future generations of experimental fusion reactors like ITER, with up to 10kg of tritium being required in order to start up a fusion reactor and so dozens of kilograms being required for a fleet. Between of tritium were recovered annually at the Darlington separation facility by 2003, of which a minor fraction was sold. Consequently, the Canadian Nuclear Laboratories in 2024 announced a decades-long program to refurbish existing CANDU plants and equip them with tritium breeding facilities.\nThe 1998 Operation Shakti test series in India included one bomb of about yield that India has publicly claimed was a hydrogen bomb. An offhand comment in the BARC publication \"Heavy Water\u00a0\u2013 Properties, Production and Analysis\" appears to suggest that the tritium was extracted from the heavy water in the CANDU and PHWR reactors in commercial operation. \"Janes Intelligence Review\" quotes the Chairman of the Indian Atomic Energy Commission as admitting to the tritium extraction plant, but refusing to comment on its use. India is also capable of creating tritium more efficiently by irradiation of lithium-6 in reactors.\nTritium production.\nTritium, 3H, is a radioactive isotope of hydrogen, with a half-life of 12.3 years. \nIt is produced in small amounts in nature (about 4\u00a0kg per year globally) by cosmic ray interactions in the upper atmosphere. Tritium is considered a weak radionuclide because of its low-energy radioactive emissions (beta particle energy up to 18.6\u00a0keV). The beta particles travel 6\u00a0mm in air and only penetrate skin up to 6 micrometers. The biological half-life of inhaled, ingested, or absorbed tritium is 10\u201312 days.\nTritium is generated in the fuel of all reactors; CANDU reactors generate tritium also in their coolant and moderator, due to neutron capture in heavy hydrogen. \nSome of this tritium escapes into containment and is generally recovered; a small percentage (about 1%) escapes containment and is considered a routine radioactive emission (also higher than from an LWR of comparable size). Responsible operation of a CANDU plant therefore includes monitoring tritium in the surrounding environment (and publishing the results).\nIn some CANDU reactors the tritium is periodically extracted. Typical emissions from CANDU plants in Canada are less than 1% of the national regulatory limit, which is based on International Commission on Radiological Protection (ICRP) guidelines (for example, the maximal permitted drinking-water concentration for tritium in Canada, 7,000\u00a0Bq/L, corresponds to 1/10 of the ICRP's dose limit for members of the public). Tritium emissions from other CANDU plants are similarly low.\nIn general, there is significant public controversy about radioactive emissions from nuclear power plants, and for CANDU plants one of the main concerns is tritium. In 2007 Greenpeace published a critique of tritium emissions from Canadian nuclear power plants by Ian Fairlie. This report was criticized by Richard Osborne.\nHistory.\nThe CANDU development effort has gone through four major stages over time. The first systems were experimental and prototype machines of limited power. These were replaced by a second generation of machines of 500 to 600\u00a0MWe (the CANDU\u00a06), a series of larger machines of 900\u00a0MWe, and finally developing into the CANDU\u00a09 and ACR-1000 effort.\nEarly efforts.\nThe first heavy-water-moderated design in Canada was the ZEEP, which started operation just after the end of World War II. ZEEP was joined by several other experimental machines, including the NRX in 1947 and NRU in 1957. These efforts led to the first CANDU-type reactor, the Nuclear Power Demonstration (NPD), in Rolphton, Ontario. It was intended as a proof-of-concept and rated for only 22\u00a0MWe, a very low power for a commercial power reactor. NPD produced the first nuclear-generated electricity in Canada and ran successfully from 1962 to 1987.\nThe second CANDU was the Douglas Point reactor, a more powerful version rated at roughly 200\u00a0MWe and located near Kincardine, Ontario. It went into service in 1968 and ran until 1984. Uniquely among CANDU stations, Douglas Point had an oil-filled window with a view of the east reactor face, even when the reactor was operating. Douglas Point was originally planned to be a two-unit station, but the second unit was cancelled because of the success of the larger 515\u00a0MWe units at Pickering.\nGentilly-1, in B\u00e9cancour, Quebec, near Trois-Rivi\u00e8res, Quebec, was also an experimental version of CANDU, using a boiling light-water coolant and vertical pressure tubes, but was not considered successful and closed after seven years of fitful operation. Gentilly-2, a CANDU-6 reactor, began operating in 1983. Following statements from the in-coming Parti Qu\u00e9b\u00e9cois government in September 2012 that Gentilly would close, the operator, Hydro-Qu\u00e9bec, decided to cancel a previously announced refurbishment of the plant and announced its shutdown at the end of 2012, citing economic reasons for the decision. The company has started a 50-year decommissioning process estimated to cost $1.8 billion.\nIn parallel with the classic CANDU design, experimental variants were being developed. WR-1, located at the AECL's Whiteshell Laboratories in Pinawa, Manitoba, used vertical pressure tubes and organic oil as the primary coolant. The oil used has a higher boiling point than water, allowing the reactor to operate at higher temperatures and lower pressures than a conventional reactor. WR-1's outlet temperature was about 490\u00a0\u00b0C compared to the CANDU\u00a06's nominal 310\u00a0\u00b0C; the higher temperature and thus thermodynamic efficiency offsets to some degree the fact that oils have about half the heat capacity of water. The higher temperatures also result in more efficient conversion to steam, and ultimately, electricity. WR-1 operated successfully for many years and promised a significantly higher efficiency than water-cooled versions.\n600 MWe designs.\nThe successes at NPD and Douglas Point led to the decision to construct the first multi-unit station in Pickering, Ontario. Pickering A, consisting of Units 1 to 4, went into service in 1971. Pickering B with units 5 to 8 came online in 1983, giving a full-station capacity of 4,120\u00a0MWe. The station is very close to the city of Toronto, in order to reduce transmission costs.\nA series of improvements to the basic Pickering design led to the CANDU\u00a06 design, which first went into operation in the early 1980s. CANDU\u00a06 was essentially a version of the Pickering power plant that was redesigned to be able to be built in single-reactor units. CANDU\u00a06 was used in several installations outside Ontario, including the Gentilly-2 in Quebec, and Point Lepreau Nuclear Generating Station in New Brunswick. CANDU\u00a06 forms the majority of foreign CANDU systems, including the designs exported to Argentina, Romania, China and South Korea. Only India operates a CANDU system that is not based on the CANDU\u00a06 design.\n900 MWe designs.\nThe economics of nuclear power plants generally scale well with size. This improvement at larger sizes is offset by the sudden appearance of large quantities of power on the grid, which leads to a lowering of electricity prices through supply and demand effects. Predictions in the late 1960s suggested that growth in electricity demand would overwhelm these downward pricing pressures, leading most designers to introduce plants in the 1000\u00a0MWe range.\nPickering\u00a0A was quickly followed by such an upscaling effort for the Bruce Nuclear Generating Station, constructed in stages between 1970 and 1987. It is the largest nuclear facility in North America and second largest in the world (after Kashiwazaki-Kariwa in Japan), with eight reactors at around 800\u00a0MWe each, in total 6,232\u00a0MW (net) and 7,276\u00a0MW (gross). Another, smaller, upscaling led to the Darlington Nuclear Generating Station design, similar to the Bruce plant, but delivering about 880\u00a0MWe per reactor in a four-reactor station.\nAs was the case for the development of the Pickering design into the CANDU\u00a06, the Bruce design was also developed into the similar CANDU\u00a09. Like the CANDU\u00a06, the CANDU\u00a09 is essentially a repackaging of the Bruce design, so that it can be built as a single-reactor unit. No CANDU\u00a09 reactors have been built.\nGeneration III+ designs.\nThrough the 1980s and 1990s the nuclear power market suffered a major crash, with few new plants being constructed in North America or Europe. Design work continued throughout, and new design concepts were introduced that dramatically improved safety, capital costs, economics and overall performance. These generation III+ and generation IV machines became a topic of considerable interest in the early 2000s, as it appeared that a nuclear renaissance was underway and large numbers of new reactors would be built over the next decade.\nAECL had been working on a design known as the ACR-700, using elements of the latest versions of the CANDU\u00a06 and CANDU\u00a09, with a design power of 700\u00a0MWe. During the nuclear renaissance, the upscaling seen in the earlier years re-expressed itself, and the ACR-700 was developed into the 1200\u00a0MWe ACR-1000. ACR-1000 is the next-generation (officially, \"generation III+\") CANDU technology, which makes some significant modifications to the existing CANDU design.\nThe main change, and the most radical among the CANDU generations, is the use of pressurized light water as the coolant. This significantly reduces the cost of implementing the primary cooling loop, which no longer has to be filled with expensive heavy water. The ACR-1000 uses about 1/3rd the heavy water needed in earlier-generation designs. It also eliminates tritium production in the coolant loop, the major source of tritium leaks in operational CANDU designs. The redesign also allows a slightly negative void reactivity, a major design goal of all Gen III+ machines.\nThe design also requires the use of slightly enriched uranium, enriched by about 1 or 2%. The main reason for this is to increase the burn-up ratio, allowing bundles to remain in the reactor longer, so that only a third as much spent fuel is produced. This also has effects on operational costs and timetables, as the refuelling frequency is reduced. As is the case with earlier CANDU designs, the ACR-1000 also offers online refuelling.\nOutside of the reactor, the ACR-1000 has a number of design changes that are expected to dramatically lower capital and operational costs. Primary among these changes is the design lifetime of 60 years, which dramatically lowers the price of the electricity generated over the lifetime of the plant. The design also has an expected capacity factor of 90%. Higher-pressure steam generators and turbines improve efficiency downstream of the reactor.\nMany of the operational design changes were also applied to the existing CANDU\u00a06 to produce the Enhanced CANDU\u00a06. Also known as CANDU\u00a06e or EC\u00a06, this was an evolutionary upgrade of the CANDU\u00a06 design with a gross output of 740\u00a0MWe per unit. The reactors are designed with a lifetime of over 50 years, with a mid-life program to replace some of the key components e.g. the fuel channels. The projected average annual capacity factor is more than 90%. Improvements to construction techniques (including modular, open-top assembly) decrease construction costs. The CANDU\u00a06e is designed to operate at power settings as low as 50%, allowing them to adjust to load demand much better than the previous designs.\nSales efforts in Canada.\nBy most measures, the CANDU is \"the Ontario reactor\". The system was developed almost entirely in Ontario, and only two experimental designs were built in other provinces. Of the 29 commercial CANDU reactors built, 22 are in Ontario. Of these 22, a number of reactors have been removed from service. Two new CANDU reactors have been proposed for Darlington with Canadian government help with financing, but these plans ended in 2009 due to high costs.\nAECL has heavily marketed CANDU within Canada, but has found a limited reception. To date, only two non-experimental reactors have been built in other provinces, one each in Quebec and New Brunswick, other provinces have concentrated on hydro and coal-fired plants. Several Canadian provinces have developed large amounts of hydro power. Alberta and Saskatchewan do not have extensive hydro resources, and use mainly fossil fuels to generate electric power.\nInterest has been expressed in Western Canada, where CANDU reactors are being considered as heat and electricity sources for the energy-intensive oil sands extraction process, which currently uses natural gas. Energy Alberta Corporation announced 27 August 2007 that they had applied for a licence to build a new nuclear plant at Lac Cardinal (30\u00a0km west of the town of Peace River, Alberta), with two ACR-1000 reactors going online in 2017 producing 2.2 gigawatts (electric). A 2007 parliamentary review suggested placing the development efforts on hold. The company was later purchased by Bruce Power, who proposed expanding the plant to four units of a total 4.4 gigawatts. These plans were upset and Bruce later withdrew its application for the Lac Cardinal, proposing instead a new site about 60\u00a0km away. The plans are currently moribund after a wide consultation with the public demonstrated that while about of the population were open to reactors, were opposed.\nForeign sales.\nDuring the 1970s, the international nuclear sales market was extremely competitive, with many national nuclear companies being supported by their governments' foreign embassies. In addition, the pace of construction in the United States had meant that cost overruns and delayed completion was generally over, and subsequent reactors would be cheaper. Canada, a relatively new player on the international market, had numerous disadvantages in these efforts. The CANDU was deliberately designed to reduce the need for very large machined parts, making it suitable for construction by countries without a major industrial base. Sales efforts have had their most success in countries that could not locally build designs from other firms.\nIn the late 1970s, AECL noted that each reactor sale would employ 3,600 Canadians and result in $300 million in balance-of-payments income. These sales efforts were aimed primarily at countries being run by dictatorships or similar, a fact that led to serious concerns in parliament. These efforts also led to a scandal when it was discovered millions of dollars had been given to foreign sales agents, with little or no record of who they were, or what they did to earn the money. This led to a Royal Canadian Mounted Police investigation after questions were raised about sales efforts in Argentina, and new regulations on full disclosure of fees for future sales.\nCANDU's first success was the sale of early CANDU designs to India. In 1963, an agreement was signed for export of a 200 MWe power reactor based on the Douglas Point reactor. The success of the deal led to the 1966 sale of a second reactor of the same design. The first reactor, then known as RAPP-1 for \"Rajasthan Atomic Power Project\", began operation in 1972. A serious problem with cracking of the reactor's end shield led to the reactor being shut down for long periods, and the reactor was finally downrated to 100\u00a0MW. Construction of the RAPP-2 reactor was still underway when India detonated its first atomic bomb in 1974, leading to Canada ending nuclear dealings with the country. Part of the sales agreement was a technology transfer process. When Canada withdrew from development, India continued construction of CANDU-like plants across the country. By 2010, CANDU-based reactors were operational at the following sites: Kaiga (3), Kakrapar (2), Madras (2), Narora (2), Rajasthan (6), and Tarapur (2).\nIn Pakistan, the Karachi Nuclear Power Plant with a gross capacity of 137\u00a0MWe was built between 1966 and 1971.\nIn 1972, AECL submitted a design based on the Pickering plant to Argentina's Comision Nacional de Energia Atomica process, in partnership with the Italian company Italimpianti. High inflation during construction led to massive losses, and efforts to re-negotiate the deal were interrupted by the March 1976 coup led by General Videla. The Embalse Nuclear Power Station began commercial operation in January 1984. There have been ongoing negotiations to open more CANDU\u00a06 reactors in the country, including a 2007 deal between Canada, China and Argentina, but to date no firm plans have been announced.\nA licensing agreement with Romania was signed in 1977, selling the CANDU\u00a06 design for $5 million per reactor for the first four reactors, and then $2 million each for the next twelve. In addition, Canadian companies would supply a varying amount of equipment for the reactors, about $100 million of the first reactor's $800 million price tag, and then falling over time. In 1980, Nicolae Ceau\u0219escu asked for a modification to provide goods instead of cash, in exchange the amount of Canadian content was increased and a second reactor would be built with Canadian help. Economic troubles in the country worsened throughout the construction phase. The first reactor of the Cernavod\u0103 Nuclear Power Plant only came online in April 1996, a decade after its December 1985 predicted startup. Further loans were arranged for completion of the second reactor, which went online in November 2007.\nIn January 1975, a deal was announced for a single CANDU\u00a06 reactor to be built in South Korea, now known as the Wolsong-1 Power Reactor. Construction started in 1977 and commercial operation began in April 1983. In December 1990 a further deal was announced for three additional units at the same site, which began operation in the period 1997\u20131999. South Korea also negotiated development and technology transfer deals with Westinghouse for their advanced System-80 reactor design, and all future development is based on locally built versions of this reactor.\nIn June 1998, construction started on a CANDU\u00a06 reactor in Qinshan China Qinshan Nuclear Power Plant, as Phase III (units 4 and 5) of the planned 11 unit facility. Commercial operation began in December 2002 and July 2003, respectively. These are the first heavy water reactors in China. Qinshan is the first CANDU-6 project to use open-top reactor building construction, and the first project where commercial operation began earlier than the projected date.\nCANDU Energy is continuing marketing efforts in China. In addition, China and Argentina have agreed a contract to build a 700 MWe CANDU-6 derived reactor. Construction is planned to start in 2018 at Atucha.\nEconomic performance.\nThe cost of electricity from any power plant can be calculated by roughly the same selection of factors: capital costs for construction or the payments on loans made to secure that capital, the cost of fuel on a per-watt-hour basis, and fixed and variable maintenance fees. In the case of nuclear power, one normally includes two additional costs, the cost of permanent waste disposal, and the cost of decommissioning the plant when its useful lifetime is over. Generally, the capital costs dominate the price of nuclear power, as the amount of power produced is so large that it overwhelms the cost of fuel and maintenance. The World Nuclear Association calculates that the cost of fuel, including all processing, accounts for less than one cent (US$0.01) per kWh.\nInformation on economic performance on CANDU is somewhat lopsided; the majority of reactors are in Ontario, which is also the \"most public\" among the major CANDU operators. Several anti-nuclear organizations like the Ontario Clean Air Alliance (OCAA) and Pembina have claimed that every CANDU design in Ontario went over budget by at least 25%, and average over 150% higher than estimated. However, this is predicated on using \"dollar of the day\" figures that are not adjusted for inflation. With inflation accounted for, all plants were on or under budget with the exception of Darlington. Even accounting for inflation, Darlington went far over budget, at almost double the original estimate, but this project was stopped in-progress thereby incurring additional interest charges during a period of high interest rates, which is a special situation that was not expected to repeat itself.\nIn the 1980s, the pressure tubes in the Pickering\u00a0A reactors were replaced ahead of design life due to unexpected deterioration caused by hydrogen embrittlement. Extensive inspection and maintenance has avoided this problem in later reactors.\nAll the Pickering\u00a0A and Bruce\u00a0A reactors were shut down in 1999 in order to focus on restoring operational performance in the later generations at Pickering, Bruce, and Darlington. Before restarting the Pickering\u00a0A reactors, OPG undertook a limited refurbishment program. The original cost and time estimates based on inadequate project scope development were greatly below the actual time and cost and it was determined that Pickering units 2 and 3 would not be restarted for commercial reasons.\nThese overruns were repeated at Bruce, with Units 3 and 4 running 90% over budget. Similar overruns were experienced at Point Lepreau, and Gentilly-2 plant was shut down on 28 December 2012.\nBased on the projected capital costs, and the low cost of fuel and in-service maintenance, in 1994 power from CANDU was predicted to be well under 5\u00a0cents/kWh.\nIn 1999, Ontario Hydro was broken up and its generation facilities re-formed into Ontario Power Generation (OPG). In order to make the successor companies more attractive for private investors, $19.4\u00a0billion in \"stranded debt\" was placed in the control of the Ontario Electricity Financial Corporation. This debt is slowly paid down through a variety of sources, including a 0.7-cent/kWh tariff on all power, all income taxes paid by all operating companies, and all dividends paid by the OPG and Hydro One.\nAs of October 2022, Darlington is into the final half of the 10-year major refurbishment project of all four units, having reached their design mid-life. The budget is set at $12.5 billion, and planned to produce power at 6 to 8 cents/kWh. The project is currently on-time and on-budget.\nDarlington Units 1, 3 and 4 have operated with an average lifetime annual capacity factor of 85% and Unit 2 with a capacity factor of 78%, As of 2010, refurbished units at Pickering and Bruce had lifetime capacity factors between 59 and 69%. This includes periods of several years while the units were shut down for the retubing and refurbishing. Post-refurbishment capacity factors are much higher with Bruce A1 at 90.78%, Bruce A2 at 90.38% (2013+), Pickering A1 at 71.18% and Pickering A4 at 70.38%. In 2009, Bruce\u00a0A units 3 and 4 had capacity factors of 80.5% and 76.7% respectively, in a year when they had a major Vacuum Building outage.\nActive CANDU reactors.\nToday there are 31 CANDU reactors in use around the world, and 18 \"CANDU-derivatives\" in India, developed from the CANDU design. After India detonated a nuclear bomb in 1974, Canada stopped nuclear dealings with India. The breakdown is:"}
{"id": "7476", "revid": "4899266", "url": "https://en.wikipedia.org/wiki?curid=7476", "title": "Czar Nicholas II", "text": ""}
{"id": "7477", "revid": "40857617", "url": "https://en.wikipedia.org/wiki?curid=7477", "title": "Cuitl\u00e1huac", "text": "Cuitl\u00e1huac (, ) (c. 1476 \u2013 1520) or Cuitl\u00e1huac (in Spanish orthography; , , honorific form: Cuitlahuatzin) was the 10th \"Huey Tlatoani\" (emperor) of the Aztec city of Tenochtitlan for 80 days during the year Two Flint (1520). He is credited with leading the resistance to the Spanish and Tlaxcalteca conquest of the Mexica Empire, following the death of his kinsman Moctezuma II.\nBiography.\nCuitl\u00e1huac was the eleventh son of the ruler Axayacatl and a younger brother of Moctezuma II, the late Emperor of Tenochtitlan, who died during the Spanish occupation of the city. His mother's father, also called Cuitlahuac, had been ruler of Iztapalapa, and the younger Cuitl\u00e1huac also ruled there initially. Cuitl\u00e1huac was an experienced warrior and an adviser to Moctezuma, warning him not to allow the Spaniards to enter Tenochtitlan. Hern\u00e1n Cort\u00e9s imprisoned both Moctezuma and Cuitl\u00e1huac. Cortes had to leave the city in order to meet a Spanish force sent by Diego Velasquez, Spanish governor of Cuba. Following the massacre of Aztec elites when Cort\u00e9s was away from Tenochtitlan, the Mexica besieged the Spanish and their indigenous allies. Cuitl\u00e1huac was released on the pretense to reopen the market to get food to the invaders. Moctezuma was stoned to death after trying to tell his people to withdraw from the battle between the Aztecs and the Spanish, and Cuitl\u00e1huac was elected \"tlatoani\" following the flight of the Spaniards and their allies from Tenochtitlan on June 30, 1520. Some sources claim he was serving in that role even before Moctezuma's death. \nCuitl\u00e1huac was ritually married to Moctezuma's eldest daughter, a ten- or eleven-year-old girl, who later was called Isabel Moctezuma.\nCuitl\u00e1huac ruled just 80 days, perhaps dying from smallpox that had been introduced to the New World by an African suffering from the disease who was part of P\u00e1nfilo de Narv\u00e1ez's expedition to capture Cort\u00e9s. However, he played a really important role in the Aztec empire, and was best known for leading the Aztec resistance against the Spanish invaders. The early sources do not explicitly say from what he succumbed. Immediately after Cuitl\u00e1huac's death, Cuauht\u00e9moc was made the next \"tlatoani\".\nLegacy.\nThe modern Mexican municipality of Cuitl\u00e1huac, Veracruz and the Mexico City Metro station Metro Cuitl\u00e1huac are named in honor of Cuitl\u00e1huac. The asteroid 2275 Cuitl\u00e1huac is also named after this ruler.\nThere is an Avenue in Mexico City Called Cuitl\u00e1huac (Eje 3 Norte) that runs from Avenue Insurgentes to Avenue Mexico-Tacuba and that is part of an inner ring; also many streets in other towns and villages in Mexico are so called.\nExternal links.\n \n "}
{"id": "7478", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=7478", "title": "Cuauht\u00e9moc", "text": "Cuauht\u00e9moc (, ), also known as Cuauhtemotz\u00edn, Guatimoz\u00edn, or Guat\u00e9moc, was the Aztec ruler (\"tlatoani\") of Tenochtitlan from 1520 to 1521, and the last Aztec Emperor. The name Cuauhtem\u014dc means \"one who has descended like an eagle\", and is commonly rendered in English as \"Descending Eagle\", as in the moment when an eagle folds its wings and plummets down to strike its prey. This is a name that implies aggressiveness and determination.\nCuauht\u00e9moc took power in 1520 as successor of Cuitl\u00e1huac and was a cousin of the late emperor Moctezuma II. His young wife, who was later known as Isabel Moctezuma, was one of Moctezuma's daughters. He ascended to the throne when he was around 25 years old, while Tenochtitlan was being besieged by the Spanish and devastated by an epidemic of smallpox brought to the Americas by Spanish conquerors. After the killings in the Great Temple, there were probably few Aztec captains available to take the position.\nEarly life.\nCuauhtemoc's date of birth is unknown, as he does not enter the historical record until he became emperor. He was the eldest legitimate son of Emperor Ahuitzotl and may well have attended the last New Fire ceremony, marking the beginning of a new 52-year cycle in the Aztec calendar. According to several sources his mother, Tiyacapantzin, was a Tlatelolcan princess. Like the rest of Cuauhtemoc's early biography, that is inferred from knowledge of his age, and the likely events and life path of someone of his rank. Following education in the calmecac, the school for elite boys, and then his military service, he was named ruler of Tlatelolco, with the title \"cuauhtlatoani\" (\"eagle ruler\") in 1515. To have reached this position of rulership, Cuauhtemoc had to be a male of high birth and a warrior who had captured enemies for sacrifice. Cuauhtemoc married the Aztec princess who later became known as Isabel Moctezuma.\nRule.\nWhen Cuauhtemoc was elected tlatoani in 1520, Tenochtitlan had already been rocked by the invasion of the Spanish and their indigenous allies, the death of Moctezuma II, and the death of Moctezuma's brother Cuitlahuac, who succeeded him as ruler, but died of smallpox shortly afterwards. In keeping with traditional practice, the most able candidate among the high noblemen was chosen by vote of the highest noblemen, and Cuauhtemoc assumed the rulership. Although under Cuitlahuac Tenochtitlan began mounting a defense against the invaders, it was increasingly isolated militarily and largely faced the crisis alone, as the numbers of Spanish allies increased with the desertion of many polities previously under its control.\nCuauht\u00e9moc called for reinforcements from the countryside to aid the defense of Tenochtitl\u00e1n, after eighty days of warfare against the Spanish. Of all the Nahuas, only Tlatelolcas remained loyal, and the surviving Tenochcas looked for refuge in Tlatelolco, where even women took part in the battle. Cuauht\u00e9moc was captured on August 13, 1521, while fleeing Tenochtitl\u00e1n by crossing Lake Texcoco with his wife, family, and friends.\nHe surrendered to Hern\u00e1n Cort\u00e9s along with the surviving \"pipiltin\" (nobles) and, according to Spanish sources, he asked Cort\u00e9s to take his knife and \"strike me dead immediately\". According to the same Spanish accounts, Cort\u00e9s refused the offer and treated his foe magnanimously. \"You have defended your capital like a brave warrior,\" he declared. \"A Spaniard knows how to respect valor, even in an enemy.\"\nAt Cuauht\u00e9moc's request, Cort\u00e9s also allowed the defeated Mexica to depart the city unmolested. Subsequently, however, when the booty found did not measure up to the Spaniards' expectations, Cuauht\u00e9moc was subjected to \"torture by fire\", whereby the soles of his bare feet were slowly broiled over red-hot coals, in an unsuccessful attempt to discover its whereabouts. On the statue to Cuauhtemoc, on the Paseo de la Reforma in Mexico City, there is a bas relief showing the Spaniards' torture of the emperor. Eventually, some gold was recovered but far less than Cort\u00e9s and his men expected.\nCuauht\u00e9moc, now baptized as Fernando Cuauht\u00e9motz\u00edn, continued to hold his position under the Spanish, keeping the title of tlatoani, but he was no longer the sovereign ruler. From his surrender until his death, Cuauht\u00e9moc was mostly kept in guarded custody by the Spaniards.\nExecution.\nIn 1525, Cort\u00e9s took Cuauht\u00e9moc and several other indigenous nobles on his expedition to Honduras, as he feared that Cuauht\u00e9moc could have led an insurrection in his absence. While the expedition was stopped in the Chontal Maya capital of Itzamkanac, known as Acalan in Nahuatl, Cort\u00e9s had Cuauht\u00e9moc executed for allegedly conspiring to kill him and the other Spaniards.\nThere are a number of discrepancies in the various accounts of the event. According to Cort\u00e9s himself, on 27 February 1525, he learned from a citizen of Tenochtitlan, Mexicalcingo, that Cuauht\u00e9moc, Coanacoch (the ruler of Texcoco), and Tetlepanquetzal, the ruler of Tlacopan, were plotting his death. Cort\u00e9s interrogated them until each confessed and then had Cuauht\u00e9moc, Tetlepanquetzal, and another lord, Tlacatlec, hanged. Cort\u00e9s wrote that the other lords would be too frightened to plot against him again, as they believed he had uncovered the plan through magic powers. Cort\u00e9s's account was accepted by contemporary historian Francisco L\u00f3pez de G\u00f3mara.\nAccording to Bernal D\u00edaz del Castillo, a conquistador serving under Cort\u00e9s who recorded his experiences in his book \"The True History of the Conquest of New Spain\", the supposed plot was revealed by two men, named Tapia and Juan Vel\u00e1squez. D\u00edaz portrays the executions as unjust and based on no evidence, and he admits to having liked Cuauht\u00e9moc personally. He also records Cuauht\u00e9moc giving the following speech to Cort\u00e9s through his interpreter Malinche:\nD\u00edaz wrote that afterwards, Cort\u00e9s suffered from insomnia because of guilt and badly injured himself while he was wandering at night.\nFernando de Alva Cort\u00e9s Ixtlilx\u00f3chitl, a castizo historian and descendant of Coanacoch, wrote an account of the executions in the 17th century partly based on Texcocan oral tradition. According to Ixtlilx\u00f3chitl, the three lords were joking cheerfully with one another because of a rumor that Cort\u00e9s had decided to return the expedition to Mexico, when Cort\u00e9s asked a spy to tell him what they were talking about. The spy reported honestly, but Cort\u00e9s invented the plot himself. Cuauht\u00e9moc, Coanacoch, and Tetlepanquetzal were hanged as well as eight others. However, Cort\u00e9s cut down Coanacoch, the last to be hanged, after his brother began rallying his warriors. Coanacoch did not have long to enjoy his reprieve, as Ixtlilx\u00f3chitl wrote that he died a few days later.\nTlacotzin, Cuauht\u00e9moc's \"cihuacoatl\", was appointed his successor as \"tlatoani\". He died the next year before he could return to Tenochtitlan.\nBones.\nThe modern-day town of Ixcateopan in the state of Guerrero is home to an ossuary purportedly containing Cuauht\u00e9moc's remains. Archeologist Eulalia Guzm\u00e1n, a \"passionate indigenista\", excavated the bones in 1949, which were discovered shortly after bones of Cort\u00e9s, found in Mexico City, had been authenticated by the Instituto Nacional de Antropolog\u00eda e Historia (INAH). Initially, Mexican scholars congratulated Guzm\u00e1n, but after a similar examination by scholars at INAH, their authenticity as Cuauhtemoc's was rejected, as the bones in the ossuary belonged to several different persons, several of them seemingly women. The finding caused a public uproar. A panel assembled by Guzm\u00e1n gave support to the initial contention. The Secretariat of Public Education (SEP) had another panel examine the bones, which gave support to INAH's original finding, but did not report on the finding publicly. A scholarly study of the controversy was published in 2011 and argued that the available data suggests that the grave is an elaborate hoax prepared by a local of Ichcateopan as a way of generating publicity, and that subsequently supported by Mexican nationalists such as Guzman who wished to use the find for political purposes.\nLegacy.\nCuauhtemoc is the embodiment of indigenist nationalism in Mexico, being the only Aztec emperor who survived the conquest by the Spanish Empire (and their native allies). He is honored by a monument on the Paseo de la Reforma, his face has appeared on Mexican coins, banknotes, and he is celebrated in paintings, music, and popular culture.\nMany places in Mexico are named in honour of Cuauht\u00e9moc. These include Ciudad Cuauht\u00e9moc in Chihuahua and the Cuauht\u00e9moc borough of Mexico City. Smaller towns include Ciudad Cuauht\u00e9moc, Veracruz and Ciudad Cuauht\u00e9moc, Chiapas.\nThe \"Cuauht\u00e9moc\" is a vessel of the Mexican Navy that serves as a cultural ambassador with frequent visits to world ports. There is a Cuauht\u00e9moc station on Line 1 of the Mexico City metro as well as one for Moctezuma. There is also a metro station in Monterrey named after him.\nCuauht\u00e9moc is also one of the few non-Spanish given names for Mexican boys that is perennially popular. Individuals with this name include the politician\nCuauht\u00e9moc C\u00e1rdenas and footballer Cuauht\u00e9moc Blanco.\nIn the Aztec campaign of the PC game ', the player plays as Cuauht\u00e9moc, despite the name \"Montezuma\" for the campaign itself, and Cuauht\u00e9moc narrates the openings and closings to each scenario. In the next installment to the series, ', Cuauht\u00e9moc is the leader of Aztecs.\nIn the 1996 Rage Against the Machine single \"People of the Sun\", lyricist Zack De La Rocha rhymes \"When the fifth sun sets get back reclaimed, The spirit of Cuauht\u00e9moc alive and untamed\".\nCuauht\u00e9moc, in the name Guatemoc, is portrayed sympathetically in the adventure novel \"Montezuma's Daughter\", by H. Rider Haggard. First appearing in Chapter XIV, he becomes friends with the protagonist after they save each other's lives. His coronation, torture, and death are described in the novel.\nExternal links.\n "}
{"id": "7480", "revid": "47988270", "url": "https://en.wikipedia.org/wiki?curid=7480", "title": "Cross section (physics)", "text": "In physics, the cross section is a measure of the probability that a specific process will take place in a collision of two particles. For example, the Rutherford cross-section is a measure of probability that an alpha particle will be deflected by a given angle during an interaction with an atomic nucleus. Cross section is typically denoted (sigma) and is expressed in units of area, more specifically in barns. In a way, it can be thought of as the size of the object that the excitation must hit in order for the process to occur, but more exactly, it is a parameter of a stochastic process.\nWhen two discrete particles interact in classical physics, their mutual cross section is the area transverse to their relative motion within which they must meet in order to scatter from each other. If the particles are hard inelastic spheres that interact only upon contact, their scattering cross section is related to their geometric size. If the particles interact through some action-at-a-distance force, such as electromagnetism or gravity, their scattering cross section is generally larger than their geometric size.\nWhen a cross section is specified as the differential limit of a function of some final-state variable, such as particle angle or energy, it is called a differential cross section (see detailed discussion below). When a cross section is integrated over all scattering angles (and possibly other variables), it is called a total cross section or integrated total cross section. For example, in Rayleigh scattering, the intensity scattered at the forward and backward angles is greater than the intensity scattered sideways, so the forward differential scattering cross section is greater than the perpendicular differential cross section, and by adding all of the infinitesimal cross sections over the whole range of angles with integral calculus, we can find the total cross section.\nScattering cross sections may be defined in nuclear, atomic, and particle physics for collisions of accelerated beams of one type of particle with targets (either stationary or moving) of a second type of particle. The probability for any given reaction to occur is in proportion to its cross section. Thus, specifying the cross section for a given reaction is a proxy for stating the probability that a given scattering process will occur.\nThe measured reaction rate of a given process depends strongly on experimental variables such as the density of the target material, the intensity of the beam, the detection efficiency of the apparatus, or the angle setting of the detection apparatus. However, these quantities can be factored away, allowing measurement of the underlying two-particle collisional cross section.\nDifferential and total scattering cross sections are among the most important measurable quantities in nuclear, atomic, and particle physics.\nWith light scattering off of a particle, the cross section specifies the amount of optical power scattered from light of a given irradiance (power per area). Although the cross section has the same units as area, the cross section may not necessarily correspond to the actual physical size of the target given by other forms of measurement. It is not uncommon for the actual cross-sectional area of a scattering object to be much larger or smaller than the cross section relative to some physical process. For example, plasmonic nanoparticles can have light scattering cross sections for particular frequencies that are much larger than their actual cross-sectional areas.\nCollision among gas particles.\nIn a gas of finite-sized particles there are collisions among particles that depend on their cross-sectional size. The average distance that a particle travels between collisions depends on the density of gas particles. These quantities are related by\nwhere\nIf the particles in the gas can be treated as hard spheres of radius that interact by direct contact, as illustrated in Figure 1, then the effective cross section for the collision of a pair is\nIf the particles in the gas interact by a force with a larger range than their physical size, then the cross section is a larger effective area that may depend on a variety of variables such as the energy of the particles.\nCross sections can be computed for atomic collisions but also are used in the subatomic realm. For example, in nuclear physics a \"gas\" of low-energy neutrons collides with nuclei in a reactor or other nuclear device, with a cross section that is energy-dependent and hence also with well-defined mean free path between collisions.\nAttenuation of a beam of particles.\nIf a beam of particles enters a thin layer of material of thickness , the flux of the beam will decrease by according to\nwhere is the total cross section of \"all\" events, including scattering, absorption, or transformation to another species. The volumetric number density of scattering centers is designated by . Solving this equation exhibits the exponential attenuation of the beam intensity:\nwhere is the initial flux, and is the total thickness of the material. For light, this is called the Beer\u2013Lambert law.\nDifferential cross section.\nConsider a classical measurement where a single particle is scattered off a single stationary target particle. Conventionally, a spherical coordinate system is used, with the target placed at the origin and the axis of this coordinate system aligned with the incident beam. The angle is the scattering angle, measured between the incident beam and the scattered beam, and the is the azimuthal angle.\nThe impact parameter is the perpendicular offset of the trajectory of the incoming particle, and the outgoing particle emerges at an angle . For a given interaction (coulombic, magnetic, gravitational, contact, etc.), the impact parameter and the scattering angle have a definite one-to-one functional dependence on each other. Generally the impact parameter can neither be controlled nor measured from event to event and is assumed to take all possible values when averaging over many scattering events. The differential size of the cross section is the area element in the plane of the impact parameter, i.e. . The differential angular range of the scattered particle at angle is the solid angle element . The differential cross section is the quotient of these quantities, .\nIt is a function of the scattering angle (and therefore also the impact parameter), plus other observables such as the momentum of the incoming particle. The differential cross section is always taken to be positive, even though larger impact parameters generally produce less deflection. In cylindrically symmetric situations (about the beam axis), the azimuthal angle is not changed by the scattering process, and the differential cross section can be written as\nIn situations where the scattering process is not azimuthally symmetric, such as when the beam or target particles possess magnetic moments oriented perpendicular to the beam axis, the differential cross section must also be expressed as a function of the azimuthal angle.\nFor scattering of particles of incident flux off a stationary target consisting of many particles, the differential cross section at an angle is related to the flux of scattered particle detection in particles per unit time by\nHere is the finite angular size of the detector (SI unit: sr), is the number density of the target particles (SI unit: m\u22123), and is the thickness of the stationary target (SI unit: m). This formula assumes that the target is thin enough that each beam particle will interact with at most one target particle.\nThe total cross section may be recovered by integrating the differential cross section over the full solid angle ( steradians):\nIt is common to omit the \"differential\" qualifier when the type of cross section can be inferred from context. In this case, may be referred to as the \"integral cross section\" or \"total cross section\". The latter term may be confusing in contexts where multiple events are involved, since \"total\" can also refer to the sum of cross sections over all events.\nThe differential cross section is extremely useful quantity in many fields of physics, as measuring it can reveal a great amount of information about the internal structure of the target particles. For example, the differential cross section of Rutherford scattering provided strong evidence for the existence of the atomic nucleus.\nInstead of the solid angle, the momentum transfer may be used as the independent variable of differential cross sections.\nDifferential cross sections in inelastic scattering contain resonance peaks that indicate the creation of metastable states and contain information about their energy and lifetime.\nQuantum scattering.\nIn the time-independent formalism of quantum scattering, the initial wave function (before scattering) is taken to be a plane wave with definite momentum :\nwhere and are the \"relative\" coordinates between the projectile and the target. The arrow indicates that this only describes the \"asymptotic behavior\" of the wave function when the projectile and target are too far apart for the interaction to have any effect.\nAfter scattering takes place it is expected that the wave function takes on the following asymptotic form:\nwhere is some function of the angular coordinates known as the scattering amplitude. This general form is valid for any short-ranged, energy-conserving interaction. It is not true for long-ranged interactions, so there are additional complications when dealing with electromagnetic interactions.\nThe full wave function of the system behaves asymptotically as the sum\nThe differential cross section is related to the scattering amplitude:\nThis has the simple interpretation as the probability density for finding the scattered projectile at a given angle.\nA cross section is therefore a measure of the effective surface area seen by the impinging particles, and as such is expressed in units of area. The cross section of two particles (i.e. observed when the two particles are colliding with each other) is a measure of the interaction event between the two particles. The cross section is proportional to the probability that an interaction will occur; for example in a simple scattering experiment the number of particles scattered per unit of time (current of scattered particles ) depends only on the number of incident particles per unit of time (current of incident particles ), the characteristics of target (for example the number of particles per unit of surface ), and the type of interaction. For we have\nRelation to the S-matrix.\nIf the reduced masses and momenta of the colliding system are , and , before and after the collision respectively, the differential cross section is given by\nwhere the on-shell matrix is defined by\nin terms of the S-matrix. Here is the Dirac delta function. The computation of the S-matrix is the main goal of the scattering theory.\nUnits.\nAlthough the SI unit of total cross sections is m2, a smaller unit is usually used in practice.\nIn nuclear and particle physics, the conventional unit is the barn b, where 1\u00a0b = 10\u221228\u00a0m2 = 100\u00a0fm2. Smaller prefixed units such as mb and \u03bcb are also widely used. Correspondingly, the differential cross section can be measured in units such as mb/sr.\nWhen the scattered radiation is visible light, it is conventional to measure the path length in centimetres. To avoid the need for conversion factors, the scattering cross section is expressed in cm2, and the number concentration in cm\u22123. The measurement of the scattering of visible light is known as nephelometry, and is effective for particles of 2\u201350\u00a0\u03bcm in diameter: as such, it is widely used in meteorology and in the measurement of atmospheric pollution.\nThe scattering of X-rays can also be described in terms of scattering cross sections, in which case the square \u00e5ngstr\u00f6m is a convenient unit: 1\u00a0\u00c52 = 10\u221220\u00a0m2 = = 108\u00a0b. The sum of the scattering, photoelectric, and pair-production cross-sections (in barns) is charted as the \"atomic attenuation coefficient\" (narrow-beam), in barns.\nScattering of light.\nFor light, as in other settings, the scattering cross section for particles is generally different from the geometrical cross section of the particle, and it depends upon the wavelength of light and the permittivity, shape, and size of the particle. The total amount of scattering in a sparse medium is proportional to the product of the scattering cross section and the number of particles present.\nIn the interaction of light with particles, many processes occur, each with their own cross sections, including absorption, scattering, and photoluminescence. The sum of the absorption and scattering cross sections is sometimes referred to as the attenuation or extinction cross section.\nThe total extinction cross section is related to the attenuation of the light intensity through the Beer\u2013Lambert law, which says that attenuation is proportional to particle concentration:\nwhere is the attenuation at a given wavelength , is the particle concentration as a number density, and is the path length. The absorbance of the radiation is the logarithm (decadic or, more usually, natural) of the reciprocal of the transmittance :\nCombining the scattering and absorption cross sections in this manner is often necessitated by the inability to distinguish them experimentally, and much research effort has been put into developing models that allow them to be distinguished, the Kubelka-Munk theory being one of the most important in this area.\nCross section and Mie theory.\nCross sections commonly calculated using Mie theory include efficiency coefficients for extinction formula_18, scattering formula_19, and Absorption formula_20 cross sections. These are normalized by the geometrical cross sections of the particle formula_21 as formula_22\nThe cross section is defined by \nwhere formula_24 is the energy flow through the surrounding surface, and formula_25 is the intensity of the incident wave. For a plane wave the intensity is going to be formula_26, where formula_27 is the impedance of the host medium.\nThe main approach is based on the following. Firstly, we construct an imaginary sphere of radius formula_28 (surface formula_29) around the particle (the scatterer). The net rate of electromagnetic energy crosses the surface formula_29 is\nwhere formula_32 is the time averaged Poynting vector. If formula_33 energy is absorbed within the sphere, otherwise energy is being created within the sphere. We will not consider this case here. If the host medium is non-absorbing, the energy must be absorbed by the particle. We decompose the total field into incident and scattered parts formula_34, and the same for the magnetic field formula_35. Thus, we can decompose formula_36 into the three terms formula_37, where\nwhere formula_39, formula_40, and formula_41. \nAll the field can be decomposed into the series of vector spherical harmonics (VSH). After that, all the integrals can be taken.\nIn the case of a uniform sphere of radius formula_42, permittivity formula_43, and permeability formula_44, the problem has a precise solution. The scattering and extinction coefficients are formula_45 formula_46 Where formula_47. These are connected as formula_48\nDipole approximation for the scattering cross section.\nLet us assume that a particle supports only electric and magnetic dipole modes with polarizabilities formula_49 and formula_50 (here we use the notation of magnetic polarizability in the manner of Bekshaev et al. rather than the notation of Nieto-Vesperinas et al.) expressed through the Mie coefficients as \nformula_51 \nThen the cross sections are given by formula_52 formula_53 and, finally, the electric and magnetic absorption cross sections formula_54 are formula_55 and formula_56\nFor the case of a no-inside-gain particle, i.e. no energy is emitted by the particle internally (formula_57), we have a particular case of the Optical theorem formula_58 Equality occurs for non-absorbing particles, i.e. for formula_59.\nScattering of light on extended bodies.\nIn the context of scattering light on extended bodies, the scattering cross section, , describes the likelihood of light being scattered by a macroscopic particle. In general, the scattering cross section is different from the geometrical cross section of a particle, as it depends upon the wavelength of light and the permittivity in addition to the shape and size of the particle. The total amount of scattering in a sparse medium is determined by the product of the scattering cross section and the number of particles present. In terms of area, the \"total cross section\" () is the sum of the cross sections due to absorption, scattering, and luminescence:\nThe total cross section is related to the absorbance of the light intensity through the Beer\u2013Lambert law, which says that absorbance is proportional to concentration: , where is the absorbance at a given wavelength , is the concentration as a number density, and is the path length. The extinction or absorbance of the radiation is the logarithm (decadic or, more usually, natural) of the reciprocal of the transmittance :\nRelation to physical size.\nThere is no simple relationship between the scattering cross section and the physical size of the particles, as the scattering cross section depends on the wavelength of radiation used. This can be seen when looking at a halo surrounding the Moon on a decently foggy evening: Red light photons experience a larger cross sectional area of water droplets than photons of higher energy. The halo around the Moon thus has a perimeter of red light due to lower energy photons being scattering further from the center of the Moon. Photons from the rest of the visible spectrum are left within the center of the halo and perceived as white light.\nMeteorological range.\nThe scattering cross section is related to the meteorological range :\nThe quantity is sometimes denoted , the scattering coefficient per unit length.\nExamples.\nElastic collision of two hard spheres.\nThe following equations apply to two hard spheres that undergo a perfectly elastic collision. Let and denote the radii of the scattering center and scattered sphere, respectively. The differential cross section is\nand the total cross section is\nIn other words, the total scattering cross section is equal to the area of the circle (with radius ) within which the center of mass of the incoming sphere has to arrive for it to be deflected.\nRutherford scattering.\nIn Rutherford scattering, an incident particle with charge and energy scatters off a fixed particle with charge . The differential cross section is\nwhere formula_66 is the vacuum permittivity. The total cross section is infinite unless a cutoff for small scattering angles formula_67 is applied. This is due to the long range of the formula_68 Coulomb potential.\nScattering from a 2D circular mirror.\nThe following example deals with a beam of light scattering off a circle with radius and a perfectly reflecting boundary. The beam consists of a uniform density of parallel rays, and the beam-circle interaction is modeled within the framework of geometric optics. Because the problem is genuinely two-dimensional, the cross section has unit of length (e.g., metre). Let be the angle between the light ray and the radius joining the reflection point of the ray with the center point of the mirror. Then the increase of the length element perpendicular to the beam is\nThe reflection angle of this ray with respect to the incoming ray is , and the scattering angle is\nThe differential relationship between incident and reflected intensity is\nThe differential cross section is therefore ()\nIts maximum at corresponds to backward scattering, and its minimum at corresponds to scattering from the edge of the circle directly forward. This expression confirms the intuitive expectations that the mirror circle acts like a diverging lens. The total cross section is equal to the diameter of the circle:\nScattering from a 3D spherical mirror.\nThe result from the previous example can be used to solve the analogous problem in three dimensions, i.e., scattering from a perfectly reflecting sphere of radius . \nThe plane perpendicular to the incoming light beam can be parameterized by cylindrical coordinates and . In any plane of the incoming and the reflected ray we can write (from the previous example):\nwhile the impact area element is\nIn spherical coordinates,\nTogether with the trigonometric identity\nwe obtain\nThe total cross section is"}
{"id": "7482", "revid": "152145", "url": "https://en.wikipedia.org/wiki?curid=7482", "title": "Christian mythology", "text": "Christian mythology is the body of myths associated with Christianity. The term encompasses a broad variety of legends and narratives, especially those considered sacred narratives. Mythological themes and elements occur throughout Christian literature, including recurring myths such as ascending a mountain, the \"axis mundi\", myths of combat, descent into the Underworld, accounts of a dying-and-rising god, a flood myth, stories about the founding of a tribe or city, and myths about great heroes (or saints) of the past, paradises, and self-sacrifice.\nVarious authors have also used it to refer to other mythological and allegorical elements found in the Bible, such as the story of the Leviathan. The term has been applied to myths and legends from the Middle Ages, such as the story of Saint George and the Dragon, the stories of King Arthur and his Knights of the Round Table, and the legends of the \"Parsival\". Multiple commentators have classified John Milton's epic poem \"Paradise Lost\" as a work of Christian mythology. The term has also been applied to modern stories revolving around Christian themes and motifs, such as the writings of C. S. Lewis, J. R. R. Tolkien, Madeleine L'Engle, and George MacDonald.\nOver the centuries, Christianity has divided into many denominations. Not all of these denominations hold the same set of sacred traditional narratives. For example, the books of the Bible accepted by the Roman Catholic Church and the Eastern Orthodox churches include a number of texts and stories (such as those narrated in the Book of Judith and Book of Tobit) that many Protestant denominations do not accept as canonical.\nAttitudes.\nChristian theologian and professor of New Testament, Rudolf Bultmann wrote that:\nThe cosmology of the New Testament is essentially mythical in character. The world is viewed as a three storied structure, with the earth in the center, the heaven above, and the underworld beneath. Heaven is the abode of God and of celestial beings \u2013 the angels. The underworld is hell, the place of torment. Even the earth is more than the scene of natural, everyday events, of the trivial round and common task. It is the scene of the supernatural activity of God and his angels on the one hand, and of Satan and his demons on the other. These supernatural forces intervene in the course of nature and in all that men think and will and do. Miracles are by no means rare. Man is not in control of his own life. Evil spirits may take possession of him. Satan may inspire him with evil thoughts. Alternatively, God may inspire his thought and guide his purposes. He may grant him heavenly visions. He may allow him to hear his word of succor or demand. He may give him the supernatural power of his Spirit. History does not follow a smooth unbroken course; it is set in motion and controlled by these supernatural powers. This \u00e6on is held in bondage by Satan, sin, and death (for \"powers\" is precisely what they are), and hastens towards its end. That end will come very soon, and will take the form of a cosmic catastrophe. It will be inaugurated by the \"woes\" of the last time. Then the Judge will come from heaven, the dead will rise, the last judgment will take place, and men will enter into eternal salvation or damnation.\nMyths as traditional or sacred stories.\nIn its broadest academic sense, the word \"myth\" simply means a traditional story. However, many scholars restrict the term \"myth\" to sacred stories. Folklorists often go further, defining myths as \"tales believed as true, usually sacred, set in the distant past or other worlds or parts of the world, and with extra-human, inhuman, or heroic characters\".\nIn classical Greek, \"muthos\", from which the English word \"myth\" derives, meant \"story, narrative.\" By the time of Christ, \"muthos\" had started to take on the connotations of \"fable, fiction,\" and early Christian writers often avoided calling a story from canonical scripture a \"myth\". Paul warned Timothy to have nothing to do with \"godless and silly myths\" (\"beb\u0113thous kai gra\u014ddeis muthous)\". This negative meaning of \"myth\" passed into popular usage. Some modern Christian scholars and writers have attempted to rehabilitate the term \"myth\" outside academia, describing stories in canonical scripture (especially the Christ story) as \"true myth\"; examples include C. S. Lewis and Andrew Greeley. Several modern Christian writers, such as C. S. Lewis, have described elements of Christianity, particularly the story of Christ, as \"myth\" which is also \"true\" (\"true myth\"). Others object to associating Christianity with \"myth\" for a variety of reasons: the association of the term \"myth\" with polytheism, the use of the term \"myth\" to indicate falsehood or non-historicity, and the lack of an agreed-upon definition of \"myth\". As examples of Biblical myths, Every cites the creation account in Genesis 1 and 2 and the story of Eve's temptation.\nChristian tradition contains many stories that do not come from canonical Christian texts yet still illustrate Christian themes. These non-canonical Christian myths include legends, folktales, and elaborations on canonical Christian mythology. Christian tradition has produced a rich body of legends that were never incorporated into the official scriptures. Legends were a staple of medieval literature. Examples include hagiographies such as the stories of Saint George or Saint Valentine. A case in point is the historical and canonized Brendan of Clonfort, a 6th-century Irish churchman and founder of abbeys. Round his authentic figure was woven a tissue that is arguably legendary rather than historical: the \"Navigatio\" or \"Journey of Brendan\". The legend discusses mythic events in the sense of supernatural encounters. In this narrative, Brendan and his shipmates encounter sea monsters, a paradisal island and a floating ice island and a rock island inhabited by a holy hermit: literal-minded devot\u00e9s still seek to identify \"Brendan's islands\" in actual geography. This voyage was recreated by Tim Severin, suggesting that whales, icebergs and Rockall were encountered.\nFolktales form a major part of non-canonical Christian tradition. Folklorists define folktales (in contrast to \"true\" myths) as stories that are considered purely fictitious by their tellers and that often lack a specific setting in space or time. Christian-themed folktales have circulated widely among peasant populations. One widespread folktale genre is that of the Penitent Sinner (classified as Type 756A, B, C, in the Aarne-Thompson index of tale types); another popular group of folktales describe a clever mortal who outwits the Devil. Not all scholars accept the folkloristic convention of applying the terms \"myth\" and \"folktale\" to different categories of traditional narrative.\nChristian tradition produced many popular stories elaborating on canonical scripture. According to an English folk belief, certain herbs gained their current healing power from having been used to heal Christ's wounds on Mount Calvary. In this case, a non-canonical story has a connection to a non-narrative form of folklore \u2014 namely, folk medicine. Arthurian legend contains many elaborations upon canonical mythology. For example, Sir Balin discovers the Lance of Longinus, which had pierced the side of Christ. According to a tradition widely attested in early Christian writings, Adam's skull lay buried at Calvary; when Christ was crucified, his blood fell over Adam's skull, symbolizing humanity's redemption from Adam's sin.\nOther examples.\nExamples of (1) Christian myths not mentioned in canon and (2) literary and traditional elaborations on canonical Christian mythology:\nConnections to other belief systems.\nZoroastrianism.\nSome scholars believe that many elements of Christian mythology, particularly its linear portrayal of time, originated with the Persian religion of Zoroastrianism. Mary Boyce, an authority on Zoroastrianism, writes:\nMircea Eliade believes the Hebrews had a sense of linear time before Zoroastrianism influenced them. However, he argues,\n\"a number of other [Jewish] religious ideas were discovered, revalorized, of systematized in Iran\". These ideas include a dualism between good and evil, belief in a future savior and resurrection, and \"an optimistic eschatology, proclaiming the final triumph of Good\".\nThe Zoroastrian concepts of Ahriman, Amesha Spentas, Yazatas, and Daevas probably gave rise to the Christian understanding of Satan, archangels, angels, and demons.\nOther connections.\nIn Buddhist mythology, the demon Mara tries to distract the historical Buddha, Siddhartha Gautama, before he can reach enlightenment. Huston Smith, a professor of philosophy and a writer on comparative religion, notes the similarity between Mara's temptation of the Buddha before his ministry and Satan's temptation of Christ before his ministry.\nIn the Book of Revelation, the author sees a vision of a pregnant woman in the sky being pursued by a huge red dragon. The dragon tries to devour her child when she gives birth, but the child is \"caught up to God and his throne\". This appears to be an allegory for the triumph of Christianity: the child presumably represents Christ; the woman may represent God's people of the Old and New Testaments (who produced Christ); and the Dragon symbolizes Satan, who opposes Christ. According to Catholic scholars, the images used in this allegory may have been inspired by pagan mythology:\nMythical themes and types.\nAcademic studies of mythology often define mythology as deeply valued stories that explain a society's existence and world order: those narratives of a society's creation, the society's origins and foundations, their god(s), their original heroes, mankind's connection to the \"divine\", and their narratives of eschatology (what happens in the \"after-life\"). This is a very general outline of some of the basic sacred stories with those themes.\nCosmogonic myths.\nThe Christian texts use the same creation myth as Jewish mythology as written in the Old Testament. According to the Book of Genesis, the world was created out of a darkness and water in seven days. (Unlike a Jew, a Christian might include the miracle of Jesus' birth as a sort of second cosmogonic event) Canonical Christian scripture incorporates the two Hebrew cosmogonic myths found in Genesis 1\u20132:2 and Genesis 2:\nGenesis 1\u20132:3.\nIn the first text on the creation (Genesis 1\u20132:3), the Creator is called \"Elohim\" (translated \"God\"). He creates the universe over a six-day period, creating a new feature each day: first he creates day and night; then he creates the firmament to separate the \"waters above\" from the \"waters below\"; then he separates the dry land from the water; then he creates plants on the land; then he places the Sun, Moon, and stars in the sky; then he creates swimming and flying animals; then he creates land animals; and finally he creates man and woman together, \"in his own image\". On the seventh day, God rests, providing the rationale for the custom of resting on Sabbath.\nGenesis 2:4\u20133:24.\nThe second creation myth in Genesis differs from the first in a number of important elements. Here the Creator is called \"Yahweh elohim\" (commonly translated \"Lord God\", although Yahweh is in fact the personal name of the God of Israel and does not mean Lord).\nThis myth begins with the words, \"When the L God made the earth and the heavens, and no shrub of the field was yet in the earth, and no plant of the field had yet sprouted, for the LORD God had not sent rain upon the earth ...\" (Genesis 2:4\u20135 NASB). It then proceeds to describe Yahweh creating a man called Adam out of dust. Yahweh creates the Garden of Eden as a home for Adam, and tells Adam not to eat the fruit of the Tree of Knowledge of Good and Evil in the center of the Garden (next to the Tree of Life).\nYahweh also creates animals, and shows them to man, who names them. Yahweh sees that there is no suitable companion for the man among the beasts, and he subsequently puts Adam to sleep and takes out one of Adam's ribs, creating from it a woman whom Adam names Eve.\nA serpent tempts Eve to eat from the Tree of Knowledge of Good and Evil, and she succumbs, offering the fruit to Adam as well. As a punishment, Yahweh banishes the couple from the Garden and \"placed on the east side of the Garden of Eden the cherubim with a fiery revolving sword to guard the way to the Tree of Life\". The Lord says he must banish humans from the Garden because they have become like him, knowing good and evil (because of eating the forbidden fruit), and now only immortality (which they could get by eating from the Tree of Life) stands between them and godhood:\n\"The man has now become like one of us, knowing good and evil. He must not be allowed to reach out his hand and take also from the tree of life and eat, and live forever\" (Genesis 3:22).\nAlthough the text of Genesis does not identify the tempting serpent with Satan, Christian tradition equates the two. This tradition has made its way into non-canonical Christian \"myths\" such as John Milton's \"Paradise Lost\".\nAscending the mountain.\nAccording to Lorena Laura Stookey, many myths feature sacred mountains as \"the sites of revelations\": \"In myth, the ascent of the holy mountain is a spiritual journey, promising purification, insight, wisdom, or knowledge of the sacred\". As examples of this theme, Stookey includes the revelation of the Ten Commandments on Mount Sinai, Christ's ascent of a mountain to deliver his Sermon on the Mount, and Christ's ascension into Heaven from the Mount of Olives.\nAxis mundi.\nMany mythologies involve a \"world center\", which is often the sacred place of creation; this center often takes the form of a tree, mountain, or other upright object, which serves as an \"axis mundi\" or axle of the world. A number of scholars have connected the Christian story of the crucifixion at Golgotha with this theme of a cosmic center. In his \"Creation Myths of the World\", David Leeming argues that, in the Christian story of the crucifixion, the cross serves as \"the \"axis mundi\", the center of a new creation\".\nAccording to a tradition preserved in Eastern Christian folklore, Golgotha was the summit of the cosmic mountain at the center of the world and the location where Adam had been both created and buried. According to this tradition, when Christ is crucified, his blood falls on Adam's skull, buried at the foot of the cross, and redeems him. George Every discusses the connection between the cosmic center and Golgotha in his book \"Christian Mythology\", noting that the image of Adam's skull beneath the cross appears in many medieval representations of the crucifixion.\nIn \"Creation Myths of the World\", Leeming suggests that the Garden of Eden may also be considered a world center.\nCombat myth.\nMany Near Eastern religions include a story about a battle between a divine being and a dragon or other monster representing chaos\u2014a theme found, for example, in the \"Enuma Elish\". A number of scholars call this story the \"combat myth\". A number of scholars have argued that the ancient Israelites incorporated the combat myth into their religious imagery, such as the figures of Leviathan and Rahab, the Song of the Sea, Isaiah 51:9\u201310's description of God's deliverance of his people from Babylon, and the portrayals of enemies such as Pharaoh and Nebuchadnezzar. The idea of Satan as God's opponent may have developed under the influence of the combat myth. Scholars have also suggested that the Book of Revelation uses combat myth imagery in its descriptions of cosmic conflict.\nDescent to the underworld.\nAccording to David Leeming, writing in \"The Oxford Companion to World Mythology\", the harrowing of hell is an example of the motif of the hero's descent to the underworld, which is common in many mythologies. According to Christian tradition, Christ descended to hell after his death in order to free the souls there; this event is known as the Harrowing of Hell. This story is narrated in the Gospel of Nicodemus and may be the meaning behind 1 Peter 3:18\u201322.\nDying God.\nMany myths, particularly from the Near East, feature a God who dies and is resurrected; this figure is sometimes called the \"dying god\". An important study of this figure is James George Frazer's \"The Golden Bough\", which traces the dying God theme through a large number of myths. The dying God is often associated with fertility. A number of scholars, including Frazer, have suggested that the Christ story is an example of the \"dying God\" theme. In the article \"Dying God\" in \"The Oxford Companion to World Mythology\", David Leeming notes that Christ can be seen as bringing fertility, though of a spiritual as opposed to physical kind.\nIn his 2006 homily for Corpus Christi, Pope Benedict XVI noted the similarity between the Christian story of the resurrection and pagan myths of dead and resurrected gods: \"In these myths, the soul of the human person, in a certain way, reached out toward that God made man, who, humiliated unto death on a cross, in this way opened the door of life to all of us.\"\nFlood myths.\nMany cultures have myths about a flood that cleanses the world in preparation for rebirth. Such stories appear on every inhabited continent on earth. An example is the biblical story of Noah. In \"The Oxford Companion to World Mythology\", David Leeming notes that, in the Bible story, as in other flood myths, the flood marks a new beginning and a second chance for creation and humanity.\nFounding myths.\nAccording to Sandra Frankiel, the records of \"Jesus' life and death, his acts and words\" provide the \"founding myths\" of Christianity. Frankiel claims that these founding myths are \"structurally equivalent\" to the creation myths in other religions, because they are \"the pivot around which the religion turns to and which it returns\", establishing the \"meaning\" of the religion and the \"essential Christian practices and attitudes\". Tom Cain uses the expression \"founding myths\" more broadly, to encompass such stories as those of the War in Heaven and the fall of man; according to Cain, \"the disastrous consequences of disobedience\" is a pervasive theme in Christian founding myths.\nChristian mythology of their society's founding would start with Jesus and his many teachings, and include the stories of Christian disciples starting the Christian Church and congregations in the 1st century. This might be considered the stories in the four canonical gospels and the Acts of the Apostles. The heroes of the first Christian society would start with Jesus and those chosen by Jesus, the twelve apostles including Peter, John, James, as well as Paul and Mary (mother of Jesus).\nHero myths.\nIn his influential 1909 work \"The Myth of the Birth of the Hero\", Otto Rank argued that the births of many mythical heroes follow a common pattern. Rank includes the story of Christ's birth as a representative example of this pattern.\nAccording to Mircea Eliade, one pervasive mythical theme associates heroes with the slaying of dragons, a theme which Eliade traces back to \"the very ancient cosmogonico-heroic myth\" of a battle between a divine hero and a dragon. He cites the Christian legend of Saint George as an example of this theme. An example from the Late Middle Ages comes from Dieudonn\u00e9 de Gozon, third Grand Master of the Knights of Rhodes, famous for slaying the dragon of Malpasso. Eliade writes:\n\"Legend, as was natural, bestowed upon him the attributes of St. George, famed for his victorious fight with the monster. [...] In other words, by the simple fact that he was regarded as a hero, de Gozon was identified with a category, an archetype, which [...] equipped him with a mythical biography from which it was \"impossible\" to omit combat with a reptilian monster.\"\nIn the \"Oxford Companion to World Mythology\", David Leeming lists Moses, Jesus, and King Arthur as examples of the heroic monomyth, calling the Christ story \"a particularly complete example of the heroic monomyth\". Leeming regards resurrection as a common part of the heroic monomyth, in which the resurrected heroes often become sources of \"material or spiritual food for their people\"; in this connection, Leeming notes that Christians regard Jesus as the \"bread of life\".\nIn terms of values, Leeming contrasts \"the myth of Jesus\" with the myths of other \"Christian heroes such as St. George, Roland, el Cid, and even King Arthur\"; the later hero myths, Leeming argues, reflect the survival of pre-Christian heroic values\u2014\"values of military dominance and cultural differentiation and hegemony\"\u2014more than the values expressed in the Christ story.\nParadise.\nMany religious and mythological systems contain myths about a paradise. Many of these myths involve the loss of a paradise that existed at the beginning of the world. Some scholars have seen in the story of the Garden of Eden an instance of this general motif.\nSacrifice.\nSacrifice is an element in many religious traditions and often represented in myths. In \"The Oxford Companion to World Mythology\", David Leeming lists the story of Abraham and Isaac and the story of Christ's death as examples of this theme. Wendy Doniger describes the gospel accounts as a \"meta-myth\" in which Jesus realizes that he is part of a \"new myth [...] of a man who is sacrificed in hate\" but \"sees the inner myth, the old myth of origins and acceptance, the myth of a god who sacrifices himself in love\".\nEucharist.\nRelated to the doctrine of transsubstantiation, the Christian practice of eating the flesh and blood of Jesus Christ during the Eucharist is an instance of theophagy.\nTransference of evil.\nThe theological concept of Jesus being born to atone for original sin is central to the Christian narrative. According to Christian theology, by Adam disobeying God in the Garden of Eden, humanity acquired an ingrained flaw that keeps humans in a state of moral imperfection, generally called \"original sin\". According to Paul the Apostle, Adam's sin brought sin and death to all humanity: \"Through one man, sin entered the world, and through sin, death\" (Romans 5:12).\nAccording to the orthodox Christian view, Jesus saved humanity from final death and damnation by dying for them. Most Christians believe that Christ's sacrifice supernaturally reversed death's power over humanity, proved when he was resurrected, and abolished the power of sin on humanity. According to Paul, \"if the many died by the trespass of the one man, how much more did God's grace and the gift that came by the grace of the one man, Jesus Christ, overflow to the many\" (Romans 5:15). For many Christians, atonement doctrine leads naturally into the eschatological narratives of Christian people rising from the dead and living again, or immediately entering heaven to join Jesus.\nAtonement in canonical scripture.\nPaul's theological writings lay out the basic framework of the atonement doctrine in the New Testament. However, Paul's letters contain relatively little mythology (narrative). The majority of narratives in the New Testament are in the Gospels and the Book of Revelation.\nAlthough the Gospel stories do not lay out the atonement doctrine as fully as does Paul, they do have the story of the Last Supper, crucifixion, death and resurrection. Atonement is also suggested in the parables of Jesus in his final days. According to Matthew's gospel, at the Last Supper, Jesus calls his blood \"the blood of the new covenant, which will be poured out for the forgiveness of many\" (Matthew 26:28). John's gospel is especially rich in atonement parables and promises: Jesus speaks of himself as \"the living bread that came down from heaven\"; \"and the bread that I shall give is My flesh, which I shall give for the life of the world\" (John 6:51); \"Truly, truly, I say to you, unless a grain of wheat falls to the ground and dies, it remains alone; but if it dies, it bears much fruit\" (John 12:24).\nAtonement in non-canonical literature.\nThe sacrifice and atonement narrative appears explicitly in many non-canonical writings as well. For instance, in Book 3 of Milton's \"Paradise Lost\", the Son of God offers to become a man and die, thereby paying mankind's debt to God the Father.\nThe Harrowing of Hell is a non-canonical myth extrapolated from the atonement doctrine. According to this story, Christ descended into the land of the dead after his crucifixion, rescuing the righteous souls that had been cut off from heaven due to the taint of original sin. The story of the harrowing was popular during the Middle Ages. An Old English poem called \"The Harrowing of Hell\" describes Christ breaking into Hell and rescuing the Old Testament patriarchs. (The Harrowing is not the only explanation that Christians have put forth for the fate of the righteous who died before Christ accomplished the atonement)\nIn modern literature, atonement continues to be theme. In the first of C. S. Lewis's \"Narnia\" novels, \"The Lion, the Witch and the Wardrobe\", a boy named Edmund is condemned to death by a White Witch, and the magical lion-king Aslan offers to die in Edmund's place, thereby saving him. Aslan's life is sacrificed on an altar, but returns to life again. Aslan's self-sacrifice for Edmund is often interpreted as an allegory for the story of Christ's sacrifice for humanity; although Lewis denied that the novel is a mere allegory.\nEschatological myths.\nChristian eschatological myths include stories of the afterlife: the narratives of Jesus Christ rising from the dead and now acting as a saviour of all generations of Christians, and stories of heaven and hell. Eschatological myths would also include the prophesies of end of the world and a new millennium in the Book of Revelation, and the story that Jesus will return to earth some day.\nThe major features of Christian eschatological mythology include afterlife beliefs, the Second Coming, the resurrection of the dead, and the final judgment.\nImmediate afterlife (heaven and hell).\nMost Christian denominations hold some belief in an immediate afterlife when people die. Christian scripture gives a few descriptions of an immediate afterlife and a heaven and hell; however, for the most part, both New and Old Testaments focus much more on the myth of a final bodily resurrection than any beliefs about a purely spiritual afterlife away from the body.\nMuch of the Old Testament does not express a belief in a personal afterlife of reward or punishment:\"All the dead go down to Sheol, and there they lie in sleep together\u2013whether good or evil, rich or poor, slave or free (Job 3:11\u201319). It is described as a region \"dark and deep,\" \"the Pit,\" and \"the land of forgetfulness,\" cut off from both God and human life above (Pss. 6:5; 88:3\u201312). Though in some texts Yahweh's power can reach down to Sheol (Ps. 139:8), the dominant idea is that the dead are abandoned forever. This idea of Sheol is negative in contrast to the world of life and light above, but there is no idea of judgment or of reward and punishment.\"\nLater Old Testament writings, particularly the works of the Hebrew prophets, describe a final resurrection of the dead, often accompanied by spiritual rewards and punishments:\"Many who sleep in the dust of the earth shall awake. Some shall live forever; others shall be in everlasting contempt. But the wise shall shine brightly like the splendor of the firmament, and those who lead the many to justice shall be like the stars forever\" (Daniel 12:2).\nHowever, even here, the emphasis is not on an immediate afterlife in heaven or hell, but rather on a future bodily resurrection.\nThe New Testament also devotes little attention to an immediate afterlife. Its primary focus is the resurrection of the dead. Some New Testament passages seem to mention the (non-resurrected) dead experiencing some sort of afterlife (for example, the parable of rich man and Lazarus); yet the New Testament includes only a few myths about heaven and hell. Specifically, heaven is a place of peaceful residence, where Jesus goes to \"prepare a home\" or room for his disciples (John 14:2). Drawing on scriptural imagery (John 10:7, John 10:11\u201314), many Christian narratives of heaven include a nice green pasture land and a meeting with a benevolent God. Some of the earliest Christian art depicts heaven as a green pasture where people are sheep led by Jesus as \"the good shepherd\" as in interpretation of heaven.\nAs the doctrines of heaven and hell and (Catholic) purgatory developed, non-canonical Christian literature began to develop an elaborate mythology about these locations. Dante's three-part \"Divine Comedy\" is a prime example of such afterlife mythology, describing Hell (in \"Inferno\"), Purgatory (in \"Purgatorio\"), and Heaven (in \"Paradiso\"). Myths of hell differ quite widely according to the denomination.\nSecond Coming.\nThe Second Coming of Christ holds a central place in Christian mythology. The Second Coming is the return of Christ to Earth during the period of transformation preceding the end of this world and the establishment of the Kingdom of Heaven on Earth. According to Matthew's gospel, when Jesus is on trial before the Roman and Jewish authorities, he claims, \"In the future you will see the Son of Man sitting at the right hand of the Mighty One and coming on the clouds of heaven.\"\nThe legend of the Wandering Jew concerns a Jew who taunted Jesus on the way to the Crucifixion and was then cursed to walk the earth until the Second Coming.\nResurrection and final judgment.\nChristian mythology incorporates the Old Testament's prophecies of a future resurrection of the dead. Like the Hebrew prophet Daniel (e.g., Daniel 12:2), the Christian Book of Revelation (among other New Testament scriptures) describes the resurrection: \"The sea gave up the dead that were in it, and death and Hades gave up the dead that were in them; and they were judged, every one of them according to their deeds.\" The righteous and/or faithful enjoy bliss in the earthly Kingdom of Heaven, but the evil and/or non-Christian are \"cast into the lake of fire\".\nThe Kingdom of Heaven on Earth.\nChristian eschatological myths feature a total world renovation after the final judgment. According to the Book of Revelation, God \"will wipe every tear from their eyes, and there will be no more death or mourning, wailing or pain, for the old order has passed away\". According to Old and New Testament passages, a time of perfect peace and happiness is coming: \"They will beat their swords into plowshares and their spears into pruning hooks. One nation will not raise the sword against another; nor will they train for war again.\" Certain scriptural passages even suggest that God will abolish the current natural laws in favor of immortality and total peace:\nMillennialism and amillennialism.\nWhen Christianity was a new and persecuted religion, many Christians believed the end times were imminent. Scholars debate whether Jesus was an apocalyptic preacher; however, his early followers, \"the group of Jews who accepted him as messiah in the years immediately after his death, understood him in primarily apocalyptic terms\". Prevalent in the early church and especially during periods of persecution, this Christian belief in an imminent end is called \"millennialism\". (It takes its name from the thousand-year (\"millennial\") reign of Christ that, according to the Book of Revelation, will precede the final world renovation; similar beliefs in a coming paradise are found in other religions, and these phenomena are often also called \"millennialism\")\nMillennialism comforted Christians during times of persecution, for it predicted an imminent deliverance from suffering. From the perspective of millennialism, human action has little significance: millennialism is comforting precisely because it predicts that happiness is coming no matter what humans do: \"The seeming triumph of Evil made up the apocalyptic syndrome which was to precede Christ's return and the millennium.\"\nHowever, as time went on, millennialism lost its appeal. Christ had not returned immediately, as earlier Christians had predicted. Moreover, many Christians no longer needed the comfort that millennialism provided, for they were no longer persecuted: \"With the triumph of the Church, the Kingdom of Heaven was already present on earth, and in a certain sense the old world had already been destroyed.\" (Millennialism has revived during periods of historical stress, and is currently popular among Evangelical Christians)\nIn the Roman Church's condemnation of millennialism, Eliade sees \"the first manifestation of the doctrine of [human] progress\" in Christianity. According to the amillennial view, Christ will indeed come again, ushering in a perfect Kingdom of Heaven on earth, but \"the Kingdom of God is [already] present in the world today through the presence of the heavenly reign of Christ, the Bible, the Holy Spirit and Christianity\". Amillennialists do not feel \"the eschatological tension\" that persecution inspires; therefore, they interpret their eschatological myths either figuratively or as descriptions of far-off events rather than imminent ones. Thus, after taking the amillennial position, the Church not only waited for God to renovate the world (as millennialists had) but also believed itself to be improving the world through human action.\nWitches.\nIn the early modern period, distinguished Christian theologians developed elaborated witch mythologies which contributed to the intensification of witch hunts. Major works in Christian demonology, such as Malleus Maleficarum, were dedicated to the implementation of Exodus 22:18 of the Old Testament: \"You shall not permit a sorceress to live.\" The concept of witches' sabbath was well articulated by the 17th century. Theologian Martin Delrio was one of the first to provide a vivid description in his influential \"Disquisitiones magicae\":\nThere, on most occasions, once a foul, disgusting fire has been lit, an evil spirit sits on a throne as president of the assembly. His appearance is terrifying, almost always that of a male goat or a dog. The witches come forward to worship him in different ways. Sometimes they supplicate him on bended knee; sometimes they stand with their back turned to him. They offer candles made of pitch or a child's umbilical cord, and kiss him on the anal orifice as a sign of homage. Sometimes they imitate the sacrifice of the Mass (the greatest of all their crimes), as well as purifying with water and similar Catholic ceremonies. After the feast, each evil spirit takes by the hand the disciple of whom he has charge, and so that they may do everything with the most absurd kind of ritual, each person bends over backwards, joins hands in a circle, and tosses his head as frenzied fanatics do. Then they begin to dance. They sing very obscene songs in his [Satan's] honour. They behave ridiculously in every way, and in every way contrary to accepted custom. Then their demon-lovers copulate with them in the most repulsive fashion.\nLegend and folklore.\nLegendary creatures.\nNumerous legendary creatures are attested in Christian mythology. These include the Behemoth, Leviathan, Angels, Demons, Nephilim, Re'em, Ziz and dragons.\nAttitudes toward time.\nAccording to Mircea Eliade, many traditional societies have a cyclic sense of time, periodically reenacting mythical events. Through this reenactment, these societies achieve an \"eternal return\" to the mythical age. According to Eliade, Christianity retains a sense of cyclical time, through the ritual commemoration of Christ's life and the imitation of Christ's actions; Eliade calls this sense of cyclical time a \"mythical aspect\" of Christianity.\nHowever, Judeo-Christian thought also makes an \"innovation of the first importance\", Eliade says, because it embraces the notion of linear, historical time; in Christianity, \"time is no longer [only] the circular Time of the Eternal Return; it has become linear and irreversible Time\". Summarizing Eliade's statements on this subject, Eric Rust writes, \"A new religious structure became available. In the Judaeo-Christian religions\u2014Judaism, Christianity, Islam\u2014history is taken seriously, and linear time is accepted. [...] The Christian myth gives such time a beginning in creation, a center in the Christ-event, and an end in the final consummation.\"\nIn contrast, the myths of many traditional cultures present a cyclic or static view of time. In these cultures, all the \"[important] history is limited to a few events that took place in the mythical times\". In other words, these cultures place events into two categories, the mythical age and the present, between which there is no continuity. Everything in the present is seen as a direct result of the mythical age:\n\"Just as modern man considers himself to be constituted by [all of] History, the man of the archaic societies declares that he is the result of [only] a certain number of mythical events.\"\nBecause of this view, Eliade argues, members of many traditional societies see their lives as a constant repetition of mythical events, an \"eternal return\" to the mythical age: \"In \"imitating\" the exemplary acts of a god or of a mythical hero, or simply by recounting their adventures, the man of an archaic society detaches himself from profane time and magically re-enters the Great Time, the sacred time.\"\nAccording to Eliade, Christianity shares in this cyclic sense of time to an extent. \"By the very fact that it is a religion\", he argues, Christianity retains at least one \"mythical aspect\" \u2014 the repetition of mythical events through ritual. Eliade gives a typical church service as an example:\"Just as a church constitutes a break in plane in the profane space of a modern city, [so] the service celebrated inside [the church] marks a break in profane temporal duration. It is no longer today's historical time that is present\u2014the time that is experienced, for example, in the adjacent streets\u2014but the time in which the historical existence of Jesus Christ occurred, the time sanctified by his preaching, by his passion, death, and resurrection.\"\nHeinrich Zimmer also notes Christianity's emphasis on linear time; he attributes this emphasis specifically to the influence of Augustine of Hippo's theory of history. Zimmer does not explicitly describe the cyclical conception of time as itself \"mythical\" per se, although he notes that this conception \"underl[ies] Hindu mythology\".\nNeil Forsyth writes that \"what distinguishes both Jewish and Christian religious systems [...] is that they elevate to the sacred status of myth narratives that are situated in historical time\".\nLegacy.\nConcepts of progress.\nAccording to Carl Mitcham, \"the Christian mythology of progress toward transcendent salvation\" created the conditions for modern ideas of scientific and technological progress. Hayden White describes \"the myth of Progress\" as the \"secular, Enlightenment counterpart\" of \"Christian myth\". Reinhold Niebuhr described the modern idea of ethical and scientific progress as \"really a rationalized version of the Christian myth of salvation\".\nAccording to Irwin, from the perspective of the Hebrew Bible (Old Testament), \"history is a tale of progress\". Christianity inherited the Hebrew sense of history through the Old Testament. Thus, although most Christians believe that human nature is inherently \"fallen\" (see original sin) and cannot become perfected without divine grace, they do believe that the world can and will change for the better, either through human and divine action or through divine action alone.\nPolitical and philosophical ideas.\nAccording to Mircea Eliade, the medieval \"Gioacchinian myth [...] of universal renovation in a more or less imminent future\" has influenced a number of modern theories of history, such as those of Lessing (who explicitly compares his views to those of medieval \"enthusiasts\"), Fichte, Hegel, and Schelling; and has also influenced a number of Russian writers.\nCalling Marxism \"a truly messianic Judaeo-Christian ideology\", Eliade writes that Marxism \"takes up and carries on one of the great eschatological myths of the Middle Eastern and Mediterranean world, namely: the redemptive part to be played by the Just (the 'elect', the 'anointed', the 'innocent', the 'missioners', in our own days the proletariat), whose sufferings are invoked to change the ontological status of the world\".\nIn his article \"The Christian Mythology of Socialism\", Will Herberg argues that socialism inherits the structure of its ideology from the influence of Christian mythology upon western thought.\nIn \"The Oxford Companion to World Mythology\", David Leeming claims that Judeo-Christian messianic ideas have influenced 20th-century totalitarian systems, citing the state ideology of the Soviet Union as an example.\nAccording to Hugh S. Pyper, the biblical \"founding myths of the Exodus and the exile, read as stories in which a nation is forged by maintaining its ideological and racial purity in the face of an oppressive great power\", entered \"the rhetoric of nationalism throughout European history\", especially in Protestant countries and smaller nations.\nChristmas stories in popular culture.\nChristmas stories have become prevalent in Western literature and culture.\nThe Bible.\nOld Testament.\nMythic patterns such as the primordial struggle between good and evil appear in passages throughout the Hebrew Bible, including passages that describe historical events. A distinctive characteristic of the Hebrew Bible is the reinterpretation of myth on the basis of history, as in the Book of Daniel, a record of the experience of the Jews of the Second Temple period under foreign rule, presented as a prophecy of future events and expressed in terms of \"mythic structures\" with \"the Hellenistic kingdom figured as a terrifying monster that cannot but recall [the Near Eastern pagan myth of] the dragon of chaos\".\nMircea Eliade argues that the imagery used in some parts of the Hebrew Bible reflects a \"transfiguration of history into myth\". For example, Eliade says, the portrayal of Nebuchadnezzar as a dragon in Jeremiah 51:34 is a case in which the Hebrews \"interpreted contemporary events by means of the very ancient cosmogonico-heroic myth\" of a battle between a hero and a dragon.\nAccording to scholars including Neil Forsyth and John L. McKenzie, the Old Testament incorporates stories, or fragments of stories, from extra-biblical mythology. According to the New American Bible, a Catholic Bible translation produced by the Confraternity of Christian Doctrine, the story of the Nephilim in Genesis 6:1\u20134 \"is apparently a fragment of an old legend that had borrowed much from ancient mythology\", and the \"sons of God\" mentioned in that passage are \"celestial beings of mythology\". The New American Bible also says that Psalm 93 alludes to \"an ancient myth\" in which God battles a personified Sea. Some scholars have identified the biblical creature Leviathan as a monster from Canaanite mythology. According to Howard Schwartz, \"the myth of the fall of Lucifer\" existed in fragmentary form in Isaiah 14:12 and other ancient Jewish literature; Schwartz claims that the myth originated from \"the ancient Canaanite myth of Athtar, who attempted to rule the throne of Ba'al, but was forced to descend and rule the underworld instead\".\nSome scholars have argued that the calm, orderly, monotheistic creation story in Genesis 1 can be interpreted as a reaction against the creation myths of other Near Eastern cultures. In connection with this interpretation, David and Margaret Leeming describe Genesis 1 as a \"demythologized myth\", and John L. McKenzie asserts that the writer of Genesis 1 has \"excised the mythical elements\" from his creation story.\nPerhaps the most famous topic in the Bible that could possibly be connected with mythical origins is the topic of Heaven (or the sky) as the place where God (or angels, or the saints) resides, with stories such as the ascension of Elijah (who disappeared in the sky), war of man with an angel, flying angels. Even in the New Testament Paul the Apostle is said to \"have visited the third heaven\", and Jesus was portrayed in several books as going to return from Heaven on a cloud, in the same way he ascended thereto. The official text repeated by the attendees during Roman Catholic mass (the Apostles' Creed) contains the words \"He ascended into Heaven, and is Seated at the Right Hand of God, The Father. From thence He will come again to judge the living and the dead\".\nNew Testament and early Christianity.\nAccording to a number of scholars, the Christ story contains mythical themes such as descent to the underworld, the heroic monomyth, and the \"dying god\" (see section above on \"mythical themes and types\").\nSome scholars have argued that the Book of Revelation incorporates imagery from ancient mythology. According to the New American Bible, the image in Revelation 12:1\u20136 of a pregnant woman in the sky, threatened by a dragon, \"corresponds to a widespread myth throughout the ancient world that a goddess pregnant with a savior was pursued by a horrible monster; by miraculous intervention, she bore a son who then killed the monster\". Bernard McGinn suggests that the image of the two Beasts in Revelation stems from a \"mythological background\" involving the figures of Leviathan and Behemoth.\nThe Pastoral Epistles contain denunciations of \"myths\" (\"muthoi\"). This may indicate that Rabbinic or Gnostic mythology was popular among the early Christians to whom the epistles were written and that the epistles' author was attempting to resist that mythology.\nThe Sibylline oracles contain predictions that the dead Roman Emperor Nero, infamous for his persecutions, would return one day as an Antichrist-like figure. According to Bernard McGinn, these parts of the oracles were probably written by a Christian and incorporated \"mythological language\" in describing Nero's return.\nHistorical development.\nFrom Roman Empire to Europe.\nAfter Christian theology was accepted by the Roman Empire, promoted by St. Augustine in the 5th century, Christian mythology began to predominate the Roman Empire. Later the theology was carried north by Charlemagne and the Frankish people, and Christian themes began to weave into the framework of European mythologies. The pre-Christian Germanic and Celtic mythology that were native to the tribes of Northern Europe were denounced and submerged, while saint myths, Mary stories, Crusade myths, and other Christian myths took their place. However, pre-Christian myths never went entirely away, they mingled with the (Roman Catholic) Christian framework to form new stories, like myths of the mythological kings and saints and miracles, for example (Eliade 1963:162\u2013181). Stories such as that of Beowulf and Icelandic, Norse, and Germanic sagas were reinterpreted somewhat, and given Christian meanings. The legend of King Arthur and the quest for the Holy Grail is a striking example. The thrust of incorporation took on one of two directions. When Christianity was on the advance, pagan myths were Christianized; when it was in retreat, Bible stories and Christian saints lost their mythological importance to the culture.\nMiddle Ages.\nAccording to Mircea Eliade, the Middle Ages witnessed \"an upwelling of mythical thought\" in which each social group had its own \"mythological traditions\". Often a profession had its own \"origin myth\" which established models for members of the profession to imitate; for example, the knights tried to imitate Lancelot or Parsifal. The medieval trouveres developed a \"mythology of woman and Love\" which incorporated Christian elements but, in some cases, ran contrary to official church teaching.\nGeorge Every includes a discussion of medieval legends in his book \"Christian Mythology\". Some medieval legends elaborated upon the lives of Christian figures such as Christ, the Virgin Mary, and the saints. For example, a number of legends describe miraculous events surrounding Mary's birth and her marriage to Joseph.\nIn many cases, medieval mythology appears to have inherited elements from myths of pagan gods and heroes. According to Every, one example may be \"the myth of St. George\" and other stories about saints battling dragons, which were \"modelled no doubt in many cases on older representations of the creator and preserver of the world in combat with chaos\". Eliade notes that some \"mythological traditions\" of medieval knights, namely the Arthurian cycle and the Grail theme, combine a veneer of Christianity with traditions regarding the Celtic Otherworld. According to Lorena Laura Stookey, \"many scholars\" see a link between stories in \"Irish-Celtic mythology\" about journeys to the Otherworld in search of a cauldron of rejuvenation and medieval accounts of the quest for the Holy Grail.\nAccording to Eliade, \"eschatological myths\" became prominent during the Middle Ages during \"certain historical movements\". These eschatological myths appeared \"in the Crusades, in the movements of a Tanchelm and an Eudes de l'Etoile, in the elevation of Fredrick II to the rank of Messiah, and in many other collective messianic, utopian, and prerevolutionary phenomena\". One significant eschatological myth, introduced by Gioacchino da Fiore's theology of history, was the \"myth of an imminent third age that will renew and complete history\" in a \"reign of the Holy Spirit\"; this \"Gioacchinian myth\" influenced a number of messianic movements that arose in the late Middle Ages.\nRenaissance and Reformation.\nDuring the Renaissance, there arose a critical attitude that sharply distinguished between apostolic tradition and what George Every calls \"subsidiary mythology\"\u2014popular legends surrounding saints, relics, the cross, etc.\u2014suppressing the latter.\nThe works of Renaissance writers often included and expanded upon Christian and non-Christian stories such as those of creation and the Fall. Rita Oleyar describes these writers as \"on the whole, reverent and faithful to the primal myths, but filled with their own insights into the nature of God, man, and the universe\". An example is John Milton's \"Paradise Lost\", an \"epic elaboration of the Judeo-Christian mythology\" and also a \"veritable encyclopedia of myths from the Greek and Roman tradition\".\nAccording to Cynthia Stewart, during the Reformation, the Protestant reformers used \"the founding myths of Christianity\" to critique the church of their time.\nEvery argues that \"the disparagement of myth in our own civilization\" stems partly from objections to perceived idolatry, objections which intensified in the Reformation, both among Protestants and among Catholics reacting against the classical mythology revived during the Renaissance.\nEnlightenment.\nThe philosophes of the Enlightenment used criticism of myth as a vehicle for veiled criticisms of the Bible and the church. According to Bruce Lincoln, the philosophes \"made irrationality the hallmark of myth and constituted philosophy\u2014rather than the Christian \"kerygma\"\u2014as the antidote for mythic discourse. By implication, Christianity could appear as a more recent, powerful, and dangerous instance of irrational myth\".\nSince the end of the 18th century, the biblical stories have lost some of their mythological basis to western society, owing to the scepticism of the Enlightenment, 19th-century freethinking, and 20th century modernism. Most westerners no longer found Christianity to be their primary imaginative and mythological framework by which they understand the world. However other scholars believe mythology is in our psyche, and that mythical influences of Christianity are in many of our ideals, for example the Judeo-Christian idea of an after-life and heaven. The book \"\" by Tom Beaudoin explores the premise that Christian mythology is present in the mythologies of pop-culture, such as Madonna's \"Like a Prayer\" or Soundgarden's \"Black Hole Sun.\" Modern myths are strong in comic book stories (as stories of culture heroes) and detective novels as myths of good versus evil.\nModern period.\nSome commentators have categorized a number of modern fantasy works as \"Christian myth\" or \"Christian mythopoeia\". Examples include the fiction of C. S. Lewis, Madeleine L'Engle, J.R.R. Tolkien, and George MacDonald.\nIn \"The Eternal Adam and the New World Garden\", written in 1968, David W. Noble argued that the Adam figure had been \"the central myth in the American novel since 1830\". As examples, he cites the works of Cooper, Hawthorne, Melville, Twain, Hemingway, and Faulkner."}
{"id": "7484", "revid": "9768072", "url": "https://en.wikipedia.org/wiki?curid=7484", "title": "Company (disambiguation)", "text": "A company is a legal entity representing an association of people.\nCompany may also refer to:"}
{"id": "7485", "revid": "1272843604", "url": "https://en.wikipedia.org/wiki?curid=7485", "title": "Corporation", "text": "A corporation or body corporate is an individual or a group of people, such as an association or company, that has been authorized by the state to act as a single entity (a legal entity recognized by private and public law as \"born out of statute\"; a legal person in a legal context) and recognized as such in law for certain purposes. Early incorporated entities were established by charter (i.e., by an \"ad hoc\" act granted by a monarch or passed by a parliament or legislature). Most jurisdictions now allow the creation of new corporations through registration. Corporations come in many different types but are usually divided by the law of the jurisdiction where they are chartered based on two aspects: whether they can issue stock, or whether they are formed to make a profit. Depending on the number of owners, a corporation can be classified as \"aggregate\" (the subject of this article) or \"sole\" (a legal entity consisting of a single incorporated office occupied by a single natural person).\nRegistered corporations have legal personality recognized by local authorities and their shares are owned by shareholders whose liability is generally limited to their investment. One of the attractive early advantages business corporations offered to their investors, compared to earlier business entities like sole proprietorships and joint partnerships, was limited liability. Limited liability separates control of a company from ownership and means that a passive shareholder in a corporation will not be personally liable either for contractually agreed obligations of the corporation, or for torts (involuntary harms) committed by the corporation against a third party (acts done by the controllers of the corporation).\nWhere local law distinguishes corporations by their ability to issue stock, corporations allowed to do so are referred to as \"stock corporations\"; one type of investment in the corporation is through stock, and owners of stock are referred to as \"stockholders\" or \"shareholders\". Corporations not allowed to issue stock are referred to as \"non-stock corporations\"; i.e. those who are considered the owners of a non-stock corporation are persons (or other entities) who have obtained membership in the corporation and are referred to as a \"member\" of the corporation. Corporations chartered in regions where they are distinguished by whether they are allowed to be for-profit are referred to as \"for-profit\" and \"not-for-profit\" corporations, respectively.\nShareholders do not typically actively manage a corporation; shareholders instead elect or appoint a board of directors to control the corporation in a fiduciary capacity. In most circumstances, a shareholder may also serve as a director or officer of a corporation. Countries with co-determination employ the practice of workers of an enterprise having the right to vote for representatives on the board of directors in a company.\nHistory.\nThe word \"corporation\" derives from \"corpus\", the Latin word for body, or a \"body of people\". By the time of Justinian (reigned 527\u2013565), Roman law recognized a range of corporate entities under the names \"Universitas\", \"corpus\" or \"collegium\". Following the passage of the \"Lex Julia\" during the reign of Julius Caesar as Consul and Dictator of the Roman Republic (49\u201344 BC), and their reaffirmation during the reign of Caesar Augustus as \"Princeps senatus\" and Imperator of the Roman Army (27 BC\u201314 AD), \"collegia\" required the approval of the Roman Senate or the Emperor in order to be authorized as legal bodies. These included the state itself (the \"Populus Romanus\"), municipalities, and such private associations as sponsors of a religious cult, burial clubs, political groups, and guilds of craftsmen or traders. Such bodies commonly had the right to own property and make contracts, to receive gifts and legacies, to sue and be sued, and, in general, to perform legal acts through representatives. Private associations were granted designated privileges and liberties by the emperor.\nThe concept of the corporation was revived in the Middle Ages with the recovery and annotation of Justinian's by the glossators and their successors the commentators in the 11th\u201314th centuries. Particularly important in this respect were the Italian jurists Bartolus de Saxoferrato and Baldus de Ubaldis, the latter of whom connected the corporation to the metaphor of the body politic to describe the state.\nEarly entities which carried on business and were the subjects of legal rights included the collegium of ancient Rome and the \"sreni\" of the Maurya Empire in ancient India. In medieval Europe, churches became incorporated, as did local governments, such as the City of London Corporation. The point was that the incorporation would survive longer than the lives of any particular member, existing in perpetuity. The alleged oldest commercial corporation in the world, the Stora Kopparberg mining community in Falun, Sweden, obtained a charter from King Magnus Eriksson in 1347.\nIn medieval times, traders would do business through common law constructs, such as partnerships. Whenever people acted together with a view to profit, the law deemed that a partnership arose. Early guilds and livery companies were also often involved in the regulation of competition between traders.\nMercantilism.\nDutch and English chartered companies, such as the Dutch East India Company (also known by its Dutch initials: VOC) and the Hudson's Bay Company, were created to lead the colonial ventures of European nations in the 17th century. Acting under a charter sanctioned by the Dutch government, the Dutch East India Company defeated Portuguese forces and established itself in the Moluccan Islands in order to profit from the European demand for spices. Investors in the VOC were issued paper certificates as proof of share ownership, and were able to trade their shares on the original Amsterdam Stock Exchange. Shareholders were also explicitly granted limited liability in the company's royal charter.\nIn England, the government created corporations under a royal charter or an Act of Parliament with the grant of a monopoly over a specified territory. The best-known example, established in 1600, was the East India Company of London. Queen Elizabeth I granted it the exclusive right to trade with all countries to the east of the Cape of Good Hope. Some corporations at this time would act on the government's behalf, bringing in revenue from its exploits abroad. Subsequently, the company became increasingly integrated with English and later British military and colonial policy, just as most corporations were essentially dependent on the Royal Navy's ability to control trade routes.\nLabeled by both contemporaries and historians as \"the grandest society of merchants in the universe\", the English East India Company would come to symbolize the dazzlingly rich potential of the corporation, as well as new methods of business that could be both brutal and exploitative. On 31 December 1600, Queen Elizabeth I granted the company a 15-year monopoly on trade to and from the East Indies and Africa. By 1711, shareholders in the East India Company were earning a return on their investment of almost 150 per cent. Subsequent stock offerings demonstrated just how lucrative the company had become. Its first stock offering in 1713\u20131716 raised \u00a3418,000, its second in 1717\u20131722 raised \u00a31.6\u00a0million.\nA similar chartered company, the South Sea Company, was established in 1711 to trade in the Spanish South American colonies, but met with less success. The South Sea Company's monopoly rights were supposedly backed by the Treaty of Utrecht, signed in 1713 as a settlement following the War of the Spanish Succession, which gave Great Britain an \"asiento\" to trade in the region for thirty years. In fact, the Spanish remained hostile and let only one ship a year enter. Unaware of the problems, investors in Britain, enticed by extravagant promises of profit from company promoters bought thousands of shares. By 1717, the South Sea Company was so wealthy (still having done no real business) that it assumed the public debt of the British government. This accelerated the inflation of the share price further, as did the Bubble Act 1720, which (possibly with the motive of protecting the South Sea Company from competition) prohibited the establishment of any companies without a royal charter. The share price rose so rapidly that people began buying shares merely in order to sell them at a higher price, which in turn led to higher share prices. This was the first speculative bubble the country had seen, but by the end of 1720, the bubble had \"burst\", and the share price sank from \u00a31,000 to under \u00a3100. As bankruptcies and recriminations ricocheted through government and high society, the mood against corporations and errant directors was bitter.\nIn the late 18th century, Stewart Kyd, the author of the first treatise on corporate law in English, defined a corporation as:\nDevelopment of modern company law.\nDue to the late 18th century abandonment of mercantilist economic theory and the rise of classical liberalism and laissez-faire economic theory due to a revolution in economics led by Adam Smith and other economists, corporations transitioned from being government or guild affiliated entities to being public and private economic entities free of governmental directions. Smith wrote in his 1776 work \"The Wealth of Nations\" that mass corporate activity could not match private entrepreneurship, because people in charge of others' money would not exercise as much care as they would with their own.\nDeregulation.\nThe British Bubble Act 1720's prohibition on establishing companies remained in force until its repeal in 1825. By this point, the Industrial Revolution had gathered pace, pressing for legal change to facilitate business activity. The repeal was the beginning of a gradual lifting on restrictions, though business ventures (such as those chronicled by Charles Dickens in \"Martin Chuzzlewit\") under primitive companies legislation were often scams. Without cohesive regulation, proverbial operations like the \"Anglo-Bengalee Disinterested Loan and Life Assurance Company\" were undercapitalized ventures promising no hope of success except for richly paid promoters.\nThe process of incorporation was possible only through a royal charter or a private act and was limited, owing to Parliament's jealous protection of the privileges and advantages thereby granted. As a result, many businesses came to be operated as unincorporated associations with possibly thousands of members. Any consequent litigation had to be carried out in the joint names of all the members and was almost impossibly cumbersome. Though Parliament would sometimes grant a private act to allow an individual to represent the whole in legal proceedings, this was a narrow and necessarily costly expedient, allowed only to established companies.\nThen, in 1843, William Gladstone became the chairman of a Parliamentary Committee on Joint Stock Companies, which led to the Joint Stock Companies Act 1844, regarded as the first modern piece of company law. The Act created the Registrar of Joint Stock Companies, empowered to register companies by a two-stage process. The first, provisional, stage cost \u00a35 and did not confer corporate status, which arose after completing the second stage for another \u00a35. For the first time in history, it was possible for ordinary people through a simple registration procedure to incorporate. The advantage of establishing a company as a separate legal person was mainly administrative, as a unified entity under which the rights and duties of all investors and managers could be channeled.\nLimited liability.\nHowever, there was still no limited liability and company members could still be held responsible for unlimited losses by the company. The next, crucial development, then, was the Limited Liability Act 1855, passed at the behest of the then Vice President of the Board of Trade, Robert Lowe. This allowed investors to limit their liability in the event of business failure to the amount they invested in the company \u2013 shareholders were still liable directly to creditors, but just for the unpaid portion of their shares. (The principle that shareholders are liable to the corporation had been introduced in the Joint Stock Companies Act 1844).\nThe 1855 Act allowed limited liability to companies of more than 25 members (shareholders). Insurance companies were excluded from the act, though it was standard practice for insurance contracts to exclude action against individual members. Limited liability for insurance companies was allowed by the Companies Act 1862.\nThis prompted the English periodical \"The Economist\" to write in 1855 that \"never, perhaps, was a change so vehemently and generally demanded, of which the importance was so much overrated.\" The major error of this judgment was recognised by the same magazine more than 70 years later, when it claimed that, \"[t]he economic historian of the future... may be inclined to assign to the nameless inventor of the principle of limited liability, as applied to trade corporations, a place of honour with Watt and Stephenson, and other pioneers of the Industrial Revolution. \"\nThese two features \u2013 a simple registration procedure and limited liability \u2013 were subsequently codified into the landmark 1856 Joint Stock Companies Act. This was subsequently consolidated with a number of other statutes in the Companies Act 1862, which remained in force for the rest of the century, up to and including the time of the decision in \"Salomon v A Salomon &amp; Co Ltd\".\nThe legislation quickly led to a railway boom, resulting in a surge in the formation of companies. However, in the later nineteenth century, a period of depression set in, causing many of these companies to collapse and become insolvent. Strong academic, legislative, and judicial opinions emerged, opposing the notion that businessmen could escape accountability for their role in the failing businesses.\nFurther developments.\nIn 1892, Germany introduced the with a separate legal personality and limited liability even if all the shares of the company were held by only one person. This inspired other countries to introduce corporations of this kind.\nThe last significant development in the history of companies was the 1897 decision of the House of Lords in \"Salomon v. Salomon &amp; Co.,\" where the House of Lords confirmed the separate legal personality of the company, and that the liabilities of the company were separate and distinct from those of its owners.\nIn the United States, forming a corporation usually required an act of legislation until the late 19th century. Many private firms, such as Carnegie's steel company and Rockefeller's Standard Oil, avoided the corporate model for this reason (as a trust). State governments began to adopt more permissive corporate laws from the early 19th century, although these were all restrictive in design, often with the intention of preventing corporations from gaining too much wealth and power.\nNew Jersey was the first state to adopt an \"enabling\" corporate law, with the goal of attracting more business to the state, in 1896. In 1899, Delaware followed New Jersey's lead by enacting an enabling corporate statute. However, Delaware only emerged as the leading corporate state after the enabling provisions of the 1896 New Jersey corporate law were repealed in 1913.\nThe end of the 19th century saw the emergence of holding companies and corporate mergers creating larger corporations with dispersed shareholders. Countries began enacting antitrust laws to prevent anti-competitive practices and corporations were granted more legal rights and protections. The 20th century witnessed a proliferation of laws allowing for the creation of corporations through registration worldwide. These laws played a significant role in driving economic booms in many countries both before and after World War I. Another major post World War I shift was toward the development of conglomerates, in which large corporations purchased smaller corporations to expand their industrial base.\nStarting in the 1980s, many countries with large state-owned corporations began moving toward privatization, which involved selling publicly owned (or 'nationalized') services and enterprises to corporations. Deregulation aimed at reducing the regulation of corporate activity, often accompanied privatization as part of a laissez-faire policy.\nOwnership and control.\nA corporation is, at least in theory, owned and controlled by its members. In a joint-stock company, the members are known as shareholders, and each of their shares in the ownership, control, and profits of the corporation is determined by the portion of shares in the company that they own. Thus, a person who owns a quarter of the shares of a joint-stock company owns a quarter of the company, is entitled to a quarter of the profit (or at least a quarter of the profit given to shareholders as dividends) and has a quarter of the votes capable of being cast at general meetings.\nIn another kind of corporation, the legal document which established the corporation or which contains its current rules will determine the requirements for membership in the corporation. What these requirements are depends on the kind of corporation involved. In a worker cooperative, the members are people who work for the cooperative. In a credit union, the members are people who have accounts with the credit union.\nThe day-to-day activities of a corporation are typically controlled by individuals appointed by the members. In some cases, this will be a single individual but more commonly corporations are controlled by a committee or by committees. Broadly speaking, there are two kinds of committee structure.\nIn countries with co-determination (such as in Germany), workers elect a fixed fraction of the corporation's board.\nFormation.\nHistorically, corporations were created by a charter granted by the government. As explained above, such charters were often enacted as private bills. \nToday, a corporation is formed, or incorporated, by registering with the state, province, or national government and regulated by the laws enacted by that government. Registration is the main prerequisite to the corporation's assumption of limited liability. The law sometimes requires the corporation to designate its principal address, as well as a registered agent (a person or company designated to receive legal service of process). It may also be required to designate an agent or other legal representatives of the corporation.\nGenerally, a corporation files articles of incorporation with the government, laying out the general nature of the corporation, the amount of stock it is authorized to issue, and the names and addresses of directors. Once the articles are approved, the corporation's directors meet to create bylaws that govern the internal functions of the corporation, such as meeting procedures and officer positions.\nIn theory, a corporation cannot own its own stock. An exception is treasury stock, where the company essentially buys back stock from its shareholders, which reduces its outstanding shares. This essentially becomes the equivalent of unissued capital, where it is not classified as an asset on the balance sheet (passive capital).\nUnder the internal affairs doctrine, the law of the jurisdiction in which a corporation is incorporated will govern its internal activities\u2014that is, conflicts between shareholders and managers such as the board of directors and corporate officers. If a corporation operates outside its home state, it is usually required to register with other governments as a foreign corporation and must formally appoint a registered agent to accept service of process within such other jurisdictions. A foreign corporation is almost always subject to the laws of its host state pertaining to external affairs such as employment, crimes, contracts, civil actions, and the like.\nNaming.\nCorporations generally have a distinct name. Historically, some corporations were named after the members of their boards of directors: for example, the \"President and Fellows of Harvard College\" is the name of one of the two governing boards of Harvard University, but it is also the exact name under which Harvard was legally incorporated. Nowadays, corporations in most jurisdictions have a distinct name that does not need to make reference to the members of their boards. In Canada, this possibility is taken to its logical extreme: many smaller Canadian corporations have no names at all, merely numbers based on a registration number (for example, \"12345678 Ontario Limited\"), which is assigned by the provincial or territorial government where the corporation incorporates.\nIn most countries, corporate names include a term or an abbreviation that denotes the corporate status of the entity (for example, \"Incorporated\" or \"Inc.\" in the United States) or the limited liability of its members (for example, \"Limited\", \"Ltd.\", or \"LLC\"). These terms vary by jurisdiction and language. In some jurisdictions, they are mandatory, and in others, such as California, they are not. Their use puts everybody on constructive notice that they are dealing with an entity whose liability is limited: one can only collect from whatever assets the entity still controls when one obtains a judgment against it.\nCorporate names are supposed to be unique to the jurisdiction in which the corporation is registered. Governments will not allow another corporation or any other kind of legal entity to register a name that is too similar to the name of an existing corporation. However, since \"different states may register entities with the same names, a corporate name is a unique identifier only when combined with the name of the state of incorporation\". This explains why lawyers in legal papers often expressly refer to a corporation's state of incorporation after the first mention of its name. \nSome jurisdictions do not allow the use of the word \"company\" alone to denote corporate status, since the word \"company\" may refer to a partnership or some other form of collective ownership (in the United States it can be used by a sole proprietorship but this is not generally the case elsewhere).\nPersonhood.\nDespite not being human beings, corporations have been ruled legal persons in a few countries, and have many of the same rights as natural persons do. For example, a corporation can own property, and can sue or be sued for as long as it exists. Corporations can exercise human rights against real individuals and the state, and they can themselves be responsible for human rights violations. Corporations can be \"dissolved\" either by statutory operation, the order of the court, or voluntary action on the part of shareholders. Insolvency may result in a form of corporate failure, when creditors force the liquidation and dissolution of the corporation under court order, but it most often results in a restructuring of corporate holdings. Corporations can even be convicted of special criminal offenses in the UK, such as fraud and corporate manslaughter. However, corporations are not considered living entities in the way that humans are.\nLegal scholars and others, such as Joel Bakan, have observed that a business corporation created as a \"legal person\" has a psychopathic personality because it is required to elevate its own interests above those of others even when this inflicts major risks and grave harms on the public or on other third-parties. Such critics note that the legal mandate of the corporation to focus exclusively on corporate profits and self-interest often victimizes employees, customers, the public at large, and/or the natural resources. The political theorist David Runciman notes that corporate personhood forms a fundamental part of the modern history of the idea of the state, and believes the idea of the corporation as legal persons can help to clarify the role of citizens as political stakeholders, and to break down the sharp conceptual dichotomy between the state and the people or the individual, a distinction that, on his account, is \"increasingly unable to meet the demands placed on the state in the modern world\"."}
{"id": "7487", "revid": "31196195", "url": "https://en.wikipedia.org/wiki?curid=7487", "title": "Fairchild Channel F", "text": "The Fairchild Channel F, short for \"Channel Fun\", is a home video game console, the first to be based on a microprocessor and to use ROM cartridges (branded 'Videocarts') instead of having games built-in. It was released by Fairchild Camera and Instrument in November 1976 across North America at a retail price of . It was launched as the \"Video Entertainment System\", but Fairchild rebranded their console as \"Channel F\" the next year while keeping the Video Entertainment System descriptor.\nThe Fairchild Channel F sold only about 350,000 units before Fairchild sold the technology to Zircon International in 1979, trailing well behind the Atari VCS. The system was discontinued in 1983.\nHistory.\nIn 1974, Alpex Computer Corporation employees Wallace Kirschner and Lawrence Haskel developed a home video game prototype consisting of a base unit centered on an Intel 8080 microprocessor and interchangeable circuit boards containing ROM chips that could be plugged into the base unit. The duo attempted to interest several television manufacturers in the system, but were unsuccessful. Next, they contacted a buyer at Fairchild, which sent engineer Jerry Lawson to evaluate the system. Lawson was impressed by the system and suggested Fairchild license the technology, which the company did in January 1976.\nLawson worked with industrial designer Nick Talesfore and mechanical engineer Ronald A. Smith to turn the prototype into a viable project. Jerry Lawson replaced the 8080 with Fairchild's own F8 CPU; while Nick Talesfore and Ron Smith were responsible for adapting the prototype's complex keyboard controls into a single control stick, and encasing the ROM circuit boards into plastic cartridges reminiscent of 8-track tapes. Talesfore and Smith collaborated on the styling and function of the 8 degrees of freedom hand controller. They were responsible for the design of the hand controllers, console, and video game cartridges. Talesfore also worked with graphic designer Tom Kamafugi, who did the original graphic design for the early video cartridges cartons.\nJohn Donatoni, the marketing director of Fairchild's video games division, stated that the console followed the razor and blades model where they would sell the \"hardware, and then we're going to make the profit on the cartridge sales\". Their marketing campaign was conducted by Ogilvy.\nFairchild announced the console at the Consumer Electronics Show on June 14, 1976, and the Federal Communications Commission approved it for sale on October 20. It was released as the Video Entertainment System (VES) at the price of $169.95, but renamed to the Channel F the next year. Channel F was unable to compete against Atari's Video Computer System (VCS) as the console only had 22 games compared to Atari's 187. Marketing for the console included an event featuring Ken Uston playing Video Blackjack and commercials starring Milton Berle.\nThe console was licensed in Europe to television manufacturers and led to the clone consoles of Ingelen Telematch Processor in Austria, Barco Challenger in Belgium, ITT Telematch-Processor and Nordmende Color Teleplay \u03bcP in Germany, Dumont Videoplay System and Emerson Videoplay System in Italy, Luxor TV-Datorspel and Luxor Video Entertainment Computer in Sweden, and Grandstand Video Entertainment Computer in the United Kingdom. Both models of the Saba Videoplay were sold in Germany and Italy.\nChannel F System II.\nLawson moved on to form his own company, Video Soft in 1980. Talesfore continued working on the system at Fairchild, and eventually a number of these improvements resulted in the improved System II. The major changes were that the controllers were now removable, using the Atari joystick port connector (not Atari compatible), and their storage was moved to the back of the machine. The sound was now mixed into the RF modulator so you could adjust it on your TV set instead of a fixed volume internal speaker. The internal electronics were also simplified, with two custom logic chips replacing the standard TTL logic chips. This resulted in a much smaller motherboard which allowed for a smaller, simpler and more modern-looking case design.\nFairchild left the video game market in April 1979. Zircon International acquired the rights to the system and related assets in 1979. The company redesigned the console into the Channel F System II. This featured removable controllers and audio coming from the TV rather than a speaker within the console. It was sold at the price point of $99.95 or $69.95 if the previous console was traded in. Zircon released an additional four games for a final library of 26 games on the console.\nDesign.\nThe Channel F is based on the Fairchild F8 microprocessor, which was innovative compared to other contemporary processors and integrated circuits. Because chip packaging was not initially available with enough pins, a few pins were used to communicate with other chips in the system. At least two chips were necessary to set up an F8 processor system to be able run any code. The savings from using standard pin layout enabled the inclusion of 64 bytes of internal scratchpad RAM in the CPU.\nThe VES/Channel F, as well as the System II, had one CPU and two storage chips (PSU:s). \n(A single-chip variant of the F8 was used by the VideoBrain computer system).\nThe Channel F is able to use one plane of graphics and one of four background colors per line, with three plot colors to choose from (red, green, and blue) that turns white if the background is set to black, at a resolution of 128\u00a0\u00d7\u00a064, with approximately 104 \u00d7 60 pixels visible on the TV screen. This VRAM or framebuffer was \"write only\" and not usable for anything else. 64 bytes of scratchpad RAM are available for general use - half the amount of the later Atari 2600. The Maze game (Videocart-10) and Hangman game (Videocart-18) used 1024 bits of on-cartridge static RAM connected directly to one PSU port - adding to the cost of manufacturing it. The Chess game contained considerably more on-cartridge RAM than that, 2048 Bytes accomplished by using an F8 memory interface circuit to be able to use industry standard ROM and RAM. \nThe F8 processor at the heart of the console is able to provide AI to allow for player versus computer matches, a first in console history. All previous machines required a human opponent. \"Tic-Tac-Toe\" on Videocart-1 had this feature, it was only for one player against the machine. The same is true for the chess game, which could have very long turn times for the computer as the game progressed, depending on the set difficulty.\nThe Channel F is also the first video game console to feature a pause function; There is a 'Hold' button on the main unit of the console which allows players to freeze inside the two built-in games and change several game settings in the meantime. Button is controlled through code so it was used for other things in other games.\nControllers.\nThe controllers for the system were conceived by Lawson and built by Nicholas Talesfore.\nUnlike the Atari 2600 joystick, Channel F controllers lack a base. Instead, the main body is a large handgrip with a triangular \"cap\" on top, which can move in eight directions. It could be used as both a joystick and paddle (twist), and not only could it be pushed down to operate as a fire button, it could be pulled up as well. The model 1 unit contained a small compartment for storing the controllers when moving it or when not in use. The System II featured detachable controllers with two holders at the back to wind the cable around and to store the controller in. Zircon later offered a special controller that featured an action button on the front of the joystick. It was marketed by Zircon as \"Channel F Jet-Stick\" in a letter sent out to registered owners before Christmas 1982.\nOne feature, unique to the console, is the 'hold' button, which allows the player to freeze the game, change the time or speed of the game. The hold function is however not universal (like the hardwired reset) as the four buttons are set up in code. The programmer can choose their function/purpose. The text labels explains the button functions in the built-in games (and some of the Videocarts).\nDespite the failure of the Channel F, the joystick's design was so popular\u2014\"Creative Computing\" called it \"outstanding\"\u2014 that Zircon also released an Atari joystick port-compatible version, the Video Command Joystick, first released without the extra fire button. Before that, only the downwards plunge motion was connected and acted as the fire button; the pull-up and twist actions were not connected to anything.\nGames.\nTwenty-seven cartridges, termed \"Videocarts\", were officially released to consumers in the United States during the ownership of Fairchild and Zircon, the first twenty-one of which were released by Fairchild. Several of these cartridges were capable of playing more than one game and were typically priced at . The Videocarts were yellow and approximately the size and overall texture of an 8 track cartridge. They usually featured colorful label artwork. The earlier artwork was created by nationally known artist Tom Kamifuji and art directed by Nick Talesfore. The console contained two built-in games, Tennis and Hockey, which were both advanced \"Pong\" clones. In Hockey, the reflecting bar could be changed to different diagonals by twisting the controller knob and could move all over the playing field. Tennis was much like the original Pong.\nA sales brochure from 1978 listed \"Keyboard Videocarts\" for sale. The three shown were \"K-1 Casino Poker\", \"K-2 Space Odyssey\", and \"K-3 Pro-Football\". These were intended to use the Keyboard accessory, which is displayed on the Channel F II box. All further brochures, released after Zircon took over from Fairchild, never listed this accessory nor anything called a Keyboard Videocart.\nThere was one cartridge released outside the numbered series, listed as Videocart-51 and simply titled \"Demo 1\". This Videocart was shown in a single sales brochure released shortly after Zircon acquired the company. It has not been seen listed for sale after this single brochure which was sent out in the winter of 1979.\nUnreleased carts:\nGerman electronics manufacturer SABA also released a few compatible carts different from the original carts: translation in Videocart-1 \"Tic-Tac-Toe\" to German words, Videocart-3 released with different abbreviations (German), and Videocart-18 changed graphics and has a German word list.\nIn 2021, a number of new 'Homebrew' games were released on itch.io by retro developer Arlasoft. These included ports of mobile puzzle games Tents &amp; Trees, 2048 and Threes, as well as a port of the classic arcade shooter \"Centipede\". Through a secret button combination a hidden game could also be started, the box and instruction booklet has multiple hints about the needed code. &lt;br&gt; \nThese were released on cartridge as Videocart-29.\nReception.\nThe Channel F had beaten the Atari VCS to the market, but once the VCS was released, sales of the Channel F fell, attributed to the types of games that were offered. Most of the Channel F titles were slow-paced educational and intellectual games, compared to the action-driven games that launched with the VCS. Even with the redesigned Channel F II in 1978, Fairchild was unable to meet the sales that the VCS and its games were generating. By the time Fairchild sold the technology to Zircon in 1979, around 350,000 total units had been sold.\nKen Uston reviewed 32 games in his book \"Ken Uston's Guide to Buying and Beating the Home Video Games\" in 1982, and rated some of the Channel F's titles highly; of these, \"Alien Invasion\" and \"Video Whizball\" were considered by Uston to be \"the finest adult cartridges currently available for the Fairchild Channel F System\". The games on a whole, however, rated last on his survey of over 200 games for the Atari, Intellivision, Astrocade and Odyssey consoles, and contemporary games were rated \"Average\" with future Channel F games rated \"below average\". Uston rated almost one-half of the Channel F games as \"high in interest\" and called that \"an impressive proportion\" and further noted that \"Some of the Channel F cartridges are timeless; no matter what technological developments occur, they will continue to be of interest.\" His overall conclusion was that the games \"serve a limited, but useful, purpose\" and that the \"strength of the Channel F offering is in its excellent educational line for children\".\nIn 1983, after Zircon announced its discontinuation of the Channel F, \"Video Games\" reviewed the console. Calling it \"the system nobody knows\", the magazine described its graphics and sounds as \"somewhat primitive by today's standards\". It described \"Space War\" as \"may be the most antiquated game of its type still on the market\", and rated the 25 games for the console with an average \"interest grade\" of three (\"not too good\") on a scale from one to ten and \"skill rating\" at an average 4,5 of 10. The magazine stated, however, that Fairchild \"managed to create some fascinating games, even by today's standards\", calling the poker game \"Casino Royale\" (actually Videocart-25, \"Casino Poker\") \"the best card game, from blackjack to bridge, made for \"any\" TV-game system\". It also favorably reviewed \"Dodge-It\" (\"simple but great\"), \"Robot War\" (\"Berzerk without guns\"), and \"Whizball\" (\"thoroughly original ... hockey \"with\" guns\"), but concluded that only those interested in nostalgia, video game collecting, or card games would purchase the Channel F in 1983."}
{"id": "7489", "revid": "18578145", "url": "https://en.wikipedia.org/wiki?curid=7489", "title": "Collation", "text": "Collation is the assembly of written information into a standard order. Many systems of collation are based on numerical order or alphabetical order, or extensions and combinations thereof. Collation is a fundamental element of most office filing systems, library catalogs, and reference books.\nCollation differs from \"classification\" in that the classes themselves are not necessarily ordered. However, even if the order of the classes is irrelevant, the identifiers of the classes may be members of an ordered set, allowing a sorting algorithm to arrange the items by class.\nFormally speaking, a collation method typically defines a total order on a set of possible identifiers, called sort keys, which consequently produces a total preorder on the set of items of information (items with the same identifier are not placed in any defined order).\nA collation algorithm such as the Unicode collation algorithm defines an order through the process of comparing two given character strings and deciding which should come before the other. When an order has been defined in this way, a sorting algorithm can be used to put a list of any number of items into that order.\nThe main advantage of collation is that it makes it fast and easy for a user to find an element in the list, or to confirm that it is absent from the list. In automatic systems this can be done using a binary search algorithm or interpolation search; manual searching may be performed using a roughly similar procedure, though this will often be done unconsciously. Other advantages are that one can easily find the first or last elements on the list (most likely to be useful in the case of numerically sorted data), or elements in a given range (useful again in the case of numerical data, and also with alphabetically ordered data when one may be sure of only the first few letters of the sought item or items).\nOrdering.\nNumerical and chronological.\nStrings representing numbers may be sorted based on the values of the numbers that they represent. For example, \"\u22124\", \"2.5\", \"10\", \"89\", \"30,000\". Pure application of this method may provide only a partial ordering on the strings, since different strings can represent the same number (as with \"2\" and \"2.0\" or, when scientific notation is used, \"2e3\" and \"2000\").\nA similar approach may be taken with strings representing dates or other items that can be ordered chronologically or in some other natural fashion.\nAlphabetical.\nAlphabetical order is the basis for many systems of collation where items of information are identified by strings consisting principally of letters from an alphabet. The ordering of the strings relies on the existence of a standard ordering for the letters of the alphabet in question. (The system is not limited to alphabets in the strict technical sense; languages that use a syllabary or abugida, for example Cherokee, can use the same ordering principle provided there is a set ordering for the symbols used.)\nTo decide which of two strings comes first in alphabetical order, initially their first letters are compared. The string whose first letter appears earlier in the alphabet comes first in alphabetical order. If the first letters are the same, then the second letters are compared, and so on, until the order is decided. (If one string runs out of letters to compare, then it is deemed to come first; for example, \"cart\" comes before \"carthorse\".) The result of arranging a set of strings in alphabetical order is that words with the same first letter are grouped together, and within such a group words with the same first two letters are grouped together, and so on.\nCapital letters are typically treated as equivalent to their corresponding lowercase letters. (For alternative treatments in computerized systems, see Automated collation, below.)\nCertain limitations, complications, and special conventions may apply when alphabetical order is used:\nIn several languages the rules have changed over time, and so older dictionaries may use a different order than modern ones. Furthermore, collation may depend on use. For example, German dictionaries and telephone directories use different approaches.\nRoot sorting.\nSome Arabic dictionaries, such as Hans Wehr's bilingual \"A Dictionary of Modern Written Arabic\", group and sort Arabic words by semitic root. For example, the words \"kit\u0101ba\" ( 'writing'), \"kit\u0101b\" ( 'book'), \"k\u0101tib\" ( 'writer'), \"maktaba\" ( 'library'), \"maktab\" ( 'office'), \"makt\u016bb\" ( 'fate,' or 'written'), are agglomerated under the triliteral root k-t-b (), which denotes 'writing'.\nRadical-and-stroke sorting.\nAnother form of collation is radical-and-stroke sorting, used for non-alphabetic writing systems such as the hanzi of Chinese and the kanji of Japanese, whose thousands of symbols defy ordering by convention. In this system, common components of characters are identified; these are called radicals in Chinese and logographic systems derived from Chinese. Characters are then grouped by their primary radical, then ordered by number of pen strokes within radicals. When there is no obvious radical or more than one radical, convention governs which is used for collation. For example, the Chinese character \u5988 (meaning \"mother\") is sorted as a six-stroke character under the three-stroke primary radical \u5973.\nThe radical-and-stroke system is cumbersome compared to an alphabetical system in which there are a few characters, all unambiguous. The choice of which components of a logograph comprise separate radicals and which radical is primary is not clear-cut. As a result, logographic languages often supplement radical-and-stroke ordering with alphabetic sorting of a phonetic conversion of the logographs. For example, the kanji word \"T\u014dky\u014d\" (\u6771\u4eac) can be sorted as if it were spelled out in the Japanese characters of the hiragana syllabary as \"to-u-ki-yo-u\" (\u3068\u3046\u304d\u3087\u3046), using the conventional sorting order for these characters.\nIn addition, Chinese characters can also be sorted by stroke-based sorting. In Greater China, surname stroke ordering is a convention in some official documents where people's names are listed without hierarchy.\nAutomation.\nWhen information is stored in digital systems, collation may become an automated process. It is then necessary to implement an appropriate collation algorithm that allows the information to be sorted in a satisfactory manner for the application in question. Often the aim will be to achieve an alphabetical or numerical ordering that follows the standard criteria as described in the preceding sections. However, not all of these criteria are easy to automate.\nThe simplest kind of automated collation is based on the numerical codes of the symbols in a character set, such as ASCII coding (or any of its supersets such as Unicode), with the symbols being ordered in increasing numerical order of their codes, and this ordering being extended to strings in accordance with the basic principles of alphabetical ordering (mathematically speaking, lexicographical ordering). So a computer program might treat the characters \"a\", \"b\", \"C\", \"d\", and \"$\" as being ordered \"$\", \"C\", \"a\", \"b\", \"d\" (the corresponding ASCII codes are \"$\" = 36, \"a\" = 97, \"b\" = 98, \"C\" = 67, and \"d\" = 100). Therefore, strings beginning with \"C\", \"M\", or \"Z\" would be sorted before strings with lower-case \"a\", \"b\", etc. This is sometimes called \"ASCIIbetical order\". This deviates from the standard alphabetical order, particularly due to the ordering of capital letters before all lower-case ones (and possibly the treatment of spaces and other non-letter characters). It is therefore often applied with certain alterations, the most obvious being case conversion (often to uppercase, for historical reasons) before comparison of ASCII values.\nIn many collation algorithms, the comparison is based not on the numerical codes of the characters, but with reference to the collating sequence \u2013 a sequence in which the characters are assumed to come for the purpose of collation \u2013 as well as other ordering rules appropriate to the given application. This can serve to apply the correct conventions used for alphabetical ordering in the language in question, dealing properly with differently cased letters, modified letters, digraphs, particular abbreviations, and so on, as mentioned above under Alphabetical order, and in detail in the Alphabetical order article. Such algorithms are potentially quite complex, possibly requiring several passes through the text.\nProblems are nonetheless still common when the algorithm has to encompass more than one language. For example, in German dictionaries the word \"\u00f6konomisch\" comes between \"offenbar\" and \"olfaktorisch\", while Turkish dictionaries treat \"o\" and \"\u00f6\" as different letters, placing \"oyun\" before \"\u00f6b\u00fcr\".\nA standard algorithm for collating any collection of strings composed of any standard Unicode symbols is the Unicode Collation Algorithm. This can be adapted to use the appropriate collation sequence for a given language by tailoring its default collation table. Several such tailorings are collected in Common Locale Data Repository.\nSort keys.\nIn some applications, the strings by which items are collated may differ from the identifiers that are displayed. For example, \"The Shining\" might be sorted as \"Shining, The\" (see Alphabetical order above), but it may still be desired to display it as \"The Shining\". In this case two sets of strings can be stored, one for display purposes, and another for collation purposes. Strings used for collation in this way are called \"sort keys\".\nIssues with numbers.\nSometimes, it is desired to order text with embedded numbers using proper numerical order. For example, \"Figure 7b\" goes before \"Figure 11a\", even though '7' comes after '1' in Unicode. This can be extended to Roman numerals. This behavior is not particularly difficult to produce as long as only integers are to be sorted, although it can slow down sorting significantly. For example, Microsoft Windows does this when sorting file names.\nSorting decimals properly is a bit more difficult, because different locales use different symbols for a decimal point, and sometimes the same character used as a decimal point is also used as a separator, for example \"Section 3.2.5\". There is no universal answer for how to sort such strings; any rules are application dependent.\nLabeling of ordered items.\nIn some contexts, numbers and letters are used not so much as a basis for establishing an ordering, but as a means of labeling items that are already ordered. For example, pages, sections, chapters, and the like, as well as the items of lists, are frequently \"numbered\" in this way. Labeling series that may be used include ordinary Arabic numerals (1, 2, 3, ...), Roman numerals (I, II, III, ... or i, ii, iii, ...), or letters (A, B, C, ... or a, b, c, ...). (An alternative method for indicating list items, without numbering them, is to use a bulleted list.)\nWhen letters of an alphabet are used for this purpose of enumeration, there are certain language-specific conventions as to which letters are used. For example, the Russian letters \u042a and \u042c (which in writing are only used for modifying the preceding consonant), and usually also \u042b, \u0419, and \u0401, are omitted. Also in many languages that use extended Latin script, the modified letters are often not used in enumeration."}
{"id": "7490", "revid": "16162765", "url": "https://en.wikipedia.org/wiki?curid=7490", "title": "Civil Rights Act", "text": "Civil Rights Act may refer to several civil right acts in the United States. These acts of the United States Congress are meant to protect rights to ensure individuals' freedom from infringement by governments, social organizations, and private individuals.\nThe first wave of civil rights acts were passed during the Reconstruction era after the American Civil War. The Civil Rights Act of 1866 extends the rights of emancipated slaves by stating that any person born in the United States regardless of race is an American citizen. The Enforcement Acts of 1870-1871 allows the President to protect Black American men\u2019s right to vote, to hold office, to serve on juries, and for Black men and women to receive equal protection of laws, including protection from racist violence. The Civil Rights Act of 1875 prohibited discrimination in \"public accommodations\" until it was found unconstitutional in 1883 by the Supreme Court of the United States. The Jim Crow Laws were established during the 19th century and served to block African American votes, ban integration in public facilities such as schools, and forbid interracial marriage in the South. The enactment of these laws was able to vastly undermine the progress toward equality which was made during the Reconstruction era.\nCivil Rights Acts would not be passed for 82 more years until the success of the Civil rights movement which aimed to abolish legalized racial segregation, discrimination, and disenfranchisement in the country, which was most commonly employed against African Americans. The Civil Rights Act of 1957 established the Civil Rights Commission and the Civil Rights Act of 1960 established federal inspection of local voter registration polls. The landmark Civil Rights Act of 1964 prohibits discrimination based on race, color, religion, sex, and national origin by federal and state governments as well as public places. The Civil Rights Act of 1968 prohibits discrimination in sale, rental, and financing of housing based on race, creed, and national origin. The Civil Rights Restoration Act of 1987 specifies that recipients of federal funds must comply with civil rights laws in all areas, not just in the particular program or activity that received federal funding. The Civil Rights Act of 1990 was a bill that would have made it easier for plaintiffs to win civil rights cases which was vetoed by President George H. W. Bush. The Americans with Disabilities Act of 1990 prohibits discrimination based on disability. The Civil Rights Act of 1991 provides the right to trial by jury on discrimination claims and introducing the possibility of emotional distress damages, while limiting the amount that a jury could award.\nBackground.\nThe first shift towards equality for African Americans occurred when President Abraham Lincoln passed the Emancipation Proclamation in 1863, which declared that \"all persons held as slaves... shall be then, thenceforward, and forever free...\". As initially ratified, the United States Constitution granted each state complete discretion to determine voter qualifications for its residents.\nIn American history, the Reconstruction era was the period from 1865-1877 following the end of the American Civil War. This period was marked by various attempts made to redress the inequities imposed on African Americans through slavery. Three Reconstruction Amendments were ratified and limited this discretion. The Thirteenth Amendment (1865) prohibits slavery \"except as a punishment for crime\"; the Fourteenth Amendment (1868) grants citizenship to anyone \"born or naturalized in the United States\" and guarantees every person due process and equal protection rights; and the Fifteenth Amendment (1870) provides that \"[t]he right of citizens of the United States to vote shall not be denied or abridged by the United States or by any State on account of race, color, or previous condition of servitude.\"\nThese amendments were established to provide African Americans the same civil rights as white Americans, and also empower Congress to enforce their provisions through \"appropriate legislation\". This time period marked the beginnings of the Civil Rights Movement.\nTo enforce the Reconstruction Amendments, Congress passed the Enforcement Acts in the 1870s. The acts criminalized the obstruction of a citizen's voting rights and provided for federal supervision of the electoral process, including voter registration. By 1873, Supreme Court decisions began to limit the scope of Reconstruction legislation, and many whites resorted to intimidation and violence to undermine African Americans' voting rights. In 1875 the Supreme Court struck down parts of the legislation as unconstitutional in \"United States v. Cruikshank\" and \"United States v. Reese\".\nThe Compromise of 1877, an informal agreement to resolve a political dispute, marked the end of the Reconstruction era. After the Reconstruction Era ended in 1877, enforcement of these civil rights laws ceased, and in 1894, Congress repealed most of their provisions. Southern Democrats largely stopped adhering to the provisions of Reconstruction legislation, ceasing to intervene in Southern voting practices, which prompted widespread disenfranchisement of African American voters during and after Reconstruction. From 1868 to 1888, electoral fraud and violence throughout the South suppressed the African-American vote. From 1888 to 1908, Southern states legalized disenfranchisement by enacting Jim Crow laws; they amended their constitutions and passed legislation to impose various voting restrictions, including literacy tests, poll taxes, property-ownership requirements, moral character tests, requirements that voter registration applicants interpret particular documents, and grandfather clauses that allowed otherwise-ineligible persons to vote if their grandfathers voted (which excluded many African Americans whose grandfathers had been slaves or otherwise ineligible). During this period, the Supreme Court generally upheld efforts to discriminate against racial minorities. In \"Giles v. Harris\" (1903), the court held that regardless of the Fifteenth Amendment, the judiciary did not have the remedial power to force states to register racial minorities to vote.\nThe Civil Rights Act of 1866.\nThe Civil Rights Act of 1866 (, enacted April 9, 1866, reenacted 1870) was the first United States federal law to define citizenship and affirm that all citizens are equally protected by the law. It was mainly intended, in the wake of the American Civil War, to protect the civil rights of persons of African descent born in or brought to the United States.\nThe Act was passed by Congress in 1866 and vetoed by U.S. President Andrew Johnson. In April 1866, Congress again passed the bill to support the Thirteenth Amendment, and Johnson again vetoed it, but a two-thirds majority in each chamber overrode the veto to allow it to become law without presidential signature.\nJohn Bingham and other congressmen argued that Congress did not yet have sufficient constitutional power to enact this law. Following passage of the Fourteenth Amendment in 1868, Congress ratified the 1866 Act in 1870.\nThe act had three primary objectives for the integration of African Americans into the American society following the Civil War: 1.) a definition of American citizenship 2.) the rights which come with this citizenship and 3.) the unlawfulness to deprive any person of citizenship rights \"on the basis of race, color, or prior condition of slavery or involuntary servitude.\" The act accomplished these three primary objectives.\nThe author of the Civil Rights Act of 1866 was United States Senator Lyman Trumbull. Congressman James F. Wilson summarized what he considered to be the purpose of the act as follows, when he introduced the legislation in the House of Representatives:\nDuring the subsequent legislative process, the following key provision was deleted: \"there shall be no discrimination in civil rights or immunities among the inhabitants of any State or Territory of the United States on account of race, color, or previous condition of servitude.\" John Bingham was an influential supporter of this deletion, on the ground that courts might construe the term \"civil rights\" more broadly than people like Wilson intended. Weeks later, Senator Trumbull described the bill's intended scope:\nOn April 5, 1866, the Senate overrode President Andrew Johnson's veto. This marked the first time that the U.S. Congress ever overrode a presidential veto for a major piece of legislation.\nContent.\nWith an incipit of \"An Act to protect all Persons in the United States in their Civil Rights, and furnish the Means of their vindication\", the act declared that all people born in the United States who are not subject to any foreign power are entitled to be citizens, without regard to race, color, or previous condition of slavery or involuntary servitude. A similar provision (called the Citizenship Clause) was written a few months later into the proposed Fourteenth Amendment to the United States Constitution.\nThe Civil Rights Act of 1866 also said that any citizen has the same right that a white citizen has to make and enforce contracts, sue and be sued, give evidence in court, and inherit, purchase, lease, sell, hold, and convey real and personal property. Additionally, the act guaranteed to all citizens the \"full and equal benefit of all laws and proceedings for the security of person and property, as is enjoyed by white citizens, and ... like punishment, pains, and penalties...\" Persons who denied these rights on account of race or previous enslavement were guilty of a misdemeanor and upon conviction faced a fine not exceeding $1,000, or imprisonment not exceeding one year, or both.\nThe act used language very similar to that of the Equal Protection Clause in the newly proposed Fourteenth Amendment. In particular, the act discussed the need to provide \"reasonable protection to all persons in their constitutional rights of equality before the law, without distinction of race or color, or previous condition of slavery or involuntary servitude, except as a punishment for crime, whereof the party shall have been duly convicted. ...\"\nThis statute was a major part of general federal policy during Reconstruction, and was closely related to the Second Freedmen's Bureau Act of 1866. According to Congressman John Bingham, \"the seventh and eighth sections of the Freedmen's Bureau bill enumerate the same rights and all the rights and privileges that are enumerated in the first section of this [the Civil Rights] bill.\"\nParts of the Civil Rights Act of 1866 are enforceable into the 21st century, according to the United States Code:\nOne section of the United States Code (42 U.S.C. \u00a71981), is \u00a71 of the Civil Rights Act of 1866 as revised and amended by subsequent Acts of Congress. The Civil Rights Act of 1866 was reenacted by the Enforcement Act of 1870, ch. 114, \u00a7 18, 16 Stat. 144, codified as sections 1977 and 1978 of the Revised Statutes of 1874, and appears now as 42 U.S.C. \u00a7\u00a7 1981\u201382 (1970). Section 2 of the Civil Rights Act of 1866, as subsequently revised and amended, appears in the US Code at 18 U.S.C. \u00a7242. After the fourteenth amendment became effective, the 1866 Act was reenacted as an addendum to the Enforcement Act of 1870 in order to dispel any possible doubt as to its constitutionality. Act of May 31, 1870, ch. 114, \u00a7 18, 16 Stat. 144.\nEnactment, constitutionalization, and reenactment.\nSenator Lyman Trumbull was the Senate sponsor of the Civil Rights Act of 1866, and he argued that Congress had power to enact it in order to eliminate a discriminatory \"badge of servitude\" prohibited by the Thirteenth Amendment. Congressman John Bingham, principal author of the first section of the Fourteenth Amendment, was one of several Republicans who believed (prior to that Amendment) that Congress lacked power to pass the 1866 Act. In the 20th century, the U.S. Supreme Court ultimately adopted Trumbull's Thirteenth Amendment rationale for congressional power to ban racial discrimination by states and by private parties, as the Thirteenth Amendment does not require a state actor.\nTo the extent that the Civil Rights Act of 1866 may have been intended to go beyond preventing discrimination, by conferring particular rights on all citizens, the constitutional power of Congress to do that was more questionable. For example, Representative William Lawrence argued that Congress had power to enact the statute because of the Privileges and Immunities Clause in Article IV of the original unamended Constitution, even though courts had suggested otherwise.\nIn any event, there is currently no consensus that the language of the Civil Rights Act of 1866 actually purports to confer any legal benefits upon white citizens. Representative Samuel Shellabarger said that it did not.\nAfter enactment of the Civil Rights Act of 1866 by overriding a presidential veto, some members of Congress supported the Fourteenth Amendment in order to eliminate doubts about the constitutionality of the Civil Rights Act of 1866, or to ensure that no subsequent Congress could later repeal or alter the main provisions of that Act. Thus, the Citizenship Clause in the Fourteenth Amendment parallels citizenship language in the Civil Rights Act of 1866, and likewise the Equal Protection Clause parallels nondiscrimination language in the 1866 Act; the extent to which other clauses in the Fourteenth Amendment may have incorporated elements of the Civil Rights Act of 1866 is a matter of continuing debate.\nRatification of the Fourteenth Amendment was completed in 1868, 2 years after, the 1866 Act was reenacted, as Section 18 of the Enforcement Act of 1870.\nAfter Johnson's veto was overridden, the measure became law. Despite this victory, even some Republicans who had supported the goals of the Civil Rights Act began to doubt that Congress possessed the constitutional power to turn those goals into laws. The experience encouraged both radical and moderate Republicans to seek Constitutional guarantees for black rights, rather than relying on temporary political majorities.\nThe activities of groups such as the Ku Klux Klan (KKK) undermined the act, meaning that it failed to immediately secure the civil rights of African Americans.\nWhile it has been \"de jure\" illegal in the U.S. to discriminate in employment and housing on the basis of race since 1866, federal penalties were not provided for until the second half of the 20th century (with the passage of related civil rights legislation), which meant remedies were left to the individuals involved: because those being discriminated against had limited or no access to legal assistance, this often left many victims of discrimination without recourse.\nThere have been an increasing number of remedies provided under this act since the second half of the 20th century, including the landmark \"Jones v. Mayer\" and \"Sullivan v. Little Hunting Park, Inc.\" decisions in 1968.\nEnforcement Acts of 1870-1871.\nThe Enforcement Acts were three bills that were passed by the United States Congress between 1870 and 1871. They were criminal codes that protected African Americans\u2019 right to vote, to hold office, to serve on juries, and receive equal protection of laws. Passed under the presidency of Ulysses S. Grant, the laws also allowed the federal government to intervene when states did not act to protect these rights. The acts passed following the ratification of the Fourteenth Amendment to the US Constitution, which gave full citizenship to anyone born in the United States or freed slaves, and the Fifteenth Amendment, which banned racial discrimination in voting.\nAt the time, the lives of all newly freed slaves, as well as their political and economic rights, were being threatened. This threat led to the creation of the Enforcement Acts. The main goal in creating these acts was to improve conditions for black people and freed slaves. The main target was the Ku Klux Klan, a white supremacy organization, which was targeting black people, and, later, other groups. Although this act was meant to fight the KKK and help black people and freedmen, many states were reluctant to take such relatively extreme actions, for several reasons. Some politicians at the state and federal levels were either members of the Klan, or did not have enough strength to fight the Klan. Another goal of these acts was to achieve national unity, by creating a country where all races were considered equal under the law.\nThe Enforcement Acts did many things to help freedmen. The main purpose under the act was the prohibited use of violence or any form of intimidation to prevent the freedmen from voting and denying them that right. There were many provisions placed under the act, many with serious consequences. The Enforcement Acts were created as part of the Reconstruction era following the American Civil War. To allow full national unity, all citizens must be accepted and viewed equally, with violence prohibited.\nEnforcement Act of 1870.\nThe Enforcement Act of 1870 prohibited discrimination by state officials in voter registration on the basis of race, color, or previous condition of servitude. It established penalties for interfering with a person's right to vote and gave federal courts the power to enforce the act.\nThe act also authorized the President to employ the use of the army to uphold the act and the use of federal marshals to bring charges against offenders for election fraud, the bribery or intimidation of voters, and conspiracies to prevent citizens from exercising their constitutional rights.\nThe act banned the use of terror, force or bribery to prevent people from voting because of their race. Other laws banned the KKK entirely. Hundreds of KKK members were arrested and tried as common criminals and terrorists. The first Klan was all but eradicated within a year of federal prosecution.\nEnforcement Act of 1871.\nThe Second Enforcement Act of 1871 (formally, \"an Act to enforce the rights of citizens of the United States to vote in the several states of this union\"), permitted federal oversight of local and state elections if any two citizens in a town with more than twenty-thousand inhabitants desired it.\nThe Enforcement Act of 1871 (second act) and the Civil Rights Act of 1875 are very similar to the original act as they all have the same goal, but revised the first act with the intention of being more effective. The Act of 1871 has more severe punishments with larger fines for disregarding the regulations, and the prison sentences vary in length. The final act, and the most effective, was also a revision. Although the fines lowered again, and the prison sentences remained approximately the same, this act was the best enforced by the government.\nKu Klux Klan Act.\nThe Enforcement Act of 1871, the third Enforcement Act passed by Congress and also known as the Ku Klux Klan Act (formally, \"An Act to enforce the Provisions of the Fourteenth Amendment to the Constitution of the United States, and for other Purposes\"), made state officials liable in federal court for depriving anyone of their civil rights or the equal protection of the laws. It further made a number of the KKK's intimidation tactics into federal offenses, authorized the president to call out the militia to suppress conspiracies against the operation of the federal government, and prohibited those suspected of complicity in such conspiracies to serve on juries related to the Klan's activities. The Act also authorized the president to suspend the writ of \"habeas corpus\" if violence rendered efforts to suppress the Klan ineffective. It was passed at the request of Ulysses S. Grant.\nAftermath.\nAs a response to the act, Klansmen in South Carolina were put on trial in front of juries made up of mainly African Americans. Amos T. Akerman was largely involved with the prosecutions of the Klansmen. He worked to make America aware of Klan violence and how much of a problem it was becoming. His work led to trials and to jail sentences of a few hundred Klan members. Many others who were put on trial either fled or were only given a warning. By 1872, the Klan as an organization had been officially broken.\nThe Enforcement Acts were a series of acts, but it was not until the Ku Klux Klan Act of 1871, the third Enforcement Act, that their regulations to protect black Americans, and to enforce the Fourteenth and Fifteenth Amendment to the United States Constitution were really enforced and followed. It was only after the creation of the third Enforcement Act that trials were conducted, and perpetrators were convicted for any crimes they had committed in violation of the Enforcement Acts.\nJudicial interpretations.\nAfter the Colfax massacre in Louisiana, the federal government brought a civil rights case against nine men (out of 97 indicted) who were accused of paramilitary activity intended to stop black people from voting. In \"United States v. Cruikshank\" (1876), the Court ruled that the federal government did not have the authority to prosecute the men because the Fourteenth and Fifteenth Amendments provide only for redress against state actors. However, in \"Ex Parte Yarbrough\" (1884) the Court allowed individuals who were not state actors to be prosecuted because Article I Section 4 of the Constitution gives Congress the power to regulate federal elections.\nIn \"Hodges v. United States\" (1906) the Court addressed a possible Thirteenth Amendment rationale for the Enforcement Acts, and found that the federal government did not have the authority to punish a group of men for interfering with black workers through whitecapping. \"Hodges v. United States\" would be overruled in \"Jones v. Alfred H. Mayer Co.\" some 50 years later, stating for the first time since Reconstruction that the federal government could criminalize racist acts by private actors.\nCivil Rights Act of 1875.\nThe Civil Rights Act of 1875, sometimes called the Enforcement Act or the Force Act, was a United States federal law enacted during the Reconstruction era in response to civil rights violations against African Americans. The bill was passed by the 43rd United States Congress and signed into law by President Ulysses S. Grant on March 1, 1875. The act was designed to \"protect all citizens in their civil and legal rights\", providing for equal treatment in public accommodations and public transportation and prohibiting exclusion from jury service. It was originally drafted by Senator Charles Sumner in 1870, but was not passed until shortly after Sumner's death in 1875. The law was not effectively enforced, partly because President Grant had favored different measures to help him suppress election-related violence against blacks and Republicans in the Southern United States.\nThe Reconstruction era ended with the resolution of the 1876 presidential election, and the Civil Rights Act of 1875 was the last federal civil rights law enacted until the passage of the Civil Rights Act of 1957. In 1883, the Supreme Court ruled in the \"Civil Rights Cases\" that the public accommodation sections of the act were unconstitutional, saying Congress was not afforded control over private persons or corporations under the Equal Protection Clause. Parts of the Civil Rights Act of 1875 were later re-adopted in the Civil Rights Act of 1964 and the Civil Rights Act of 1968, both of which cited the Commerce Clause as the source of Congress's power to regulate private actors.\nLegislative history.\nThe drafting of the bill was performed early in 1870 by United States Senator Charles Sumner, a dominant Radical Republican in the Senate, with the assistance of John Mercer Langston, a prominent African American who established the law department at Howard University. The bill was proposed by Senator Sumner and co-sponsored by Representative Benjamin F. Butler, both Republicans from Massachusetts, in the 41st Congress of the United States in 1870. Congress removed the coverage of public schools that Sumner had included. The act was passed by the 43rd Congress in February 1875 as a memorial to honor Sumner, who had just died. It was signed into law by United States President Ulysses S. Grant on March 1, 1875.\nEnforcement.\nPresident Grant had wanted an entirely different law to help him suppress election-related violence against blacks and Republicans in the South. Congress did not give him that, but instead wrote a law for equal rights to public accommodations that was passed as a memorial to Grant's bitterest enemy, the late Senator Charles Sumner. Grant never commented on the 1875 law, and did nothing to enforce it, says historian John Hope Franklin. Grant's Justice Department ignored it and did not send copies to US attorneys, says Franklin, while many federal judges called it unconstitutional before the Supreme Court shut it down. Franklin concludes regarding Grant and Hayes administrations, \"The Civil Rights Act was never effectively enforced.\" Public opinion was opposed, with the black community in support. Historian Rayford Logan looking at newspaper editorials finds the press was overwhelmingly opposed.\nCase law.\nThe Supreme Court, in an 8\u20131 decision, declared sections of the act unconstitutional in the \"Civil Rights Cases\" on October 15, 1883, thus stripping the Civil Rights Act of 1875 of much of its ability to protect civil rights. Justice John Marshall Harlan provided the lone dissent. The Court held the Equal Protection Clause within the Fourteenth Amendment prohibits discrimination by the state and local government, but it does not give the federal government the power to prohibit discrimination by private individuals and organizations. The Court also held that the Thirteenth Amendment was meant to eliminate \"the badge of slavery,\" but not to prohibit racial discrimination in public accommodations.\nThe Civil Rights Act of 1875 was the last federal civil rights bill signed into law until the Civil Rights Act of 1957, enacted during the Civil Rights Movement. In the late 19th and early 20th century, the legal justification for voiding the Civil Rights Act of 1875 was part of a larger trend by the United States Supreme Court majorities to invalidate most government regulations of the private sector, except when dealing with laws designed to protect traditional public morality. The Civil Rights Act of 1875 is notable as the last major piece of legislation related to Reconstruction that was passed by Congress during the Reconstruction era. These include the Civil Rights Act of 1866, the four Reconstruction Acts of 1867 and 1868, the three Enforcement Acts of 1870 and 1871, and the three Constitutional Amendments adopted between 1865 and 1870.\nProvisions contained in the Civil Rights Act of 1875 were later readopted by Congress during the Civil Rights Movement as part of the Civil Rights Act of 1964 and the Civil Rights Act of 1968. The 1964 and 1968 acts relied upon the Commerce Clause contained in of the Constitution of the United States rather than the Equal Protection Clause within the Fourteenth Amendment.\nCivil Rights Act of 1957.\nThe Civil Rights Act of 1957, signed by President Dwight D. Eisenhower on September 9, 1957, was the first federal civil rights legislation since the Civil Rights Act of 1875 to become law. After the Supreme Court ruled school segregation unconstitutional in 1954 in \"Brown v. Board of Education\", Southern Democrats began a campaign of \"massive resistance\" against desegregation, and even the few moderate white leaders shifted to openly racist positions. Partly in an effort to defuse calls for more far-reaching reforms, Eisenhower proposed a civil rights bill that would increase the protection of African American voting rights.\nThe Supreme Court's 1954 ruling in the case of \"Brown v. Board of Education\" brought the issue of school desegregation to the fore of public attention, as Southern Democratic leaders began a campaign of \"massive resistance\" against desegregation. In the midst of this campaign, President Eisenhower proposed a civil rights bill designed to provide federal protection for African American voting rights; most African Americans in the Southern United States had been disenfranchised by state and local laws. Though the civil rights bill passed Congress, opponents of the act were able to remove or weaken several provisions via the Anderson\u2013Aiken amendment and the O'Mahoney jury trial amendment, significantly watering down its immediate impact. During the debate over the law, Senator Strom Thurmond conducted the longest one-person filibuster in Senate history. Under the direction of Senate Majority Leader Lyndon B. Johnson of Texas, the Senate passed a watered-down, yet also passable, version of the House bill which removed stringent voting protection clauses.\nDespite having a limited impact on African-American voter participation, at a time when black voter registration from 0% (in 11 counties) to less than 5% (in 97 counties) despite being majority-Black counties, the Civil Rights Act of 1957 did establish the United States Commission on Civil Rights and the United States Department of Justice Civil Rights Division. By 1960, black voting had increased by only 3%, and Congress passed the Civil Rights Act of 1960, which eliminated certain loopholes left by the 1957 Act. Congress would later pass far more effective civil rights laws in the form of the Civil Rights Act of 1964, the Voting Rights Act of 1965, and the Civil Rights Act of 1968.\nBackground.\nFollowing the Supreme Court ruling in \"Brown\", which eventually led to the integration of public schools, Southern whites began a campaign of \"Massive Resistance\". Violence against black people rose; in Little Rock, Arkansas where President Dwight D. Eisenhower ordered U.S. paratroopers of the 101st Airborne Division to protect nine black teenagers integrating into a public school, the first time federal troops were deployed in the South to settle civil rights issues since the Reconstruction Era. There had been continued physical assaults against suspected activists and bombings of schools and churches in the South. Partly in an effort to defuse calls for more far-reaching reforms, President Eisenhower proposed a civil rights bill that would increase the protection of African American voting rights.\nBy 1957, only about 20% of black people were registered to vote. Despite being the majority in numerous counties and congressional districts in the South, most black people had been effectively disfranchised by discriminatory voter registration rules and laws in those states since the late 19th and early 20th centuries that were heavily instituted and propagated by Southern Democrats. Civil rights organizations had collected evidence of discriminatory practices, such as the administration of literacy and comprehension tests and poll taxes. While the states had the right to establish rules for voter registration and elections, the federal government found an oversight role in ensuring that citizens could exercise the constitutional right to vote for federal officers: electors for president and vice president and members of the US Congress.\nLegislative history.\nThe Democratic Senate majority leader, Lyndon B. Johnson of Texas, who would play a vital role in the bill's passage in the Senate, realized that the bill and its journey through Congress could tear apart his party, as southern Democrats vehemently opposed civil rights, and its northern members were strongly in favor of them. Southern Democratic senators occupied chairs of numerous important committees because of their long seniority. As, in the near-century between the end of Reconstruction and the 1960s, white Southerners voted solidly as a bloc for the Democrats, Southern Democrats in Congress rarely lost their seats in elections, ensuring that they had more seniority than Democratic members of Congress from other parts of the country. Johnson sent the bill to the Senate Judiciary Committee, led by Democratic Senator James Eastland of Mississippi, who drastically altered the bill. Democratic Senator Richard Russell Jr., of Georgia had denounced the bill as an example of the federal government seeking to impose its laws on states. Johnson sought recognition from civil rights advocates for passing the bill as well as recognition from the anti-civil rights Democrats for weakening the bill so much as to make it toothless.\nAs well as a general if vague support for civil rights as the party of Lincoln, Republicans saw that this could be an effective way to increase the number of Black Republican voters as the blocking of the Bill by the Democrats in the Southern Caucus would become obvious. They, like Johnson, also saw the potential for dividing the Democratic party's Northern and Southern wings. This meant that the (on this issue) liberal but hardball Republican operators like the Vice President, Richard Nixon, who had a constitutional right to chair the Senate took a great interest in the Bill. Conservative Republican Senators who were sympathetic to Southern arguments on States rights were more likely to vote on a party basis. On the other hand, the Republicans were willing to quietly allow Democratic Southern obstruction if this meant that African-American and liberal voters would be more likely to see the culprits as Democrats.\nAnderson\u2013Aiken amendment.\nA bipartisan group of Senators realized that Southerners would not allow passage of the act with Title III, which authorized the US Attorney General to seek preventive relief in civil rights cases. Majority Leader Johnson convinced Senator Clinton Anderson (D-NM) to introduce an amendment to strip out the enforcement provisions of Title III. Anderson's initial hesitancy to be associated with the anti-civil rights bloc was met with Johnson's urging to introduce the amendment along with a Republican colleague. Anderson approached George Aiken (R-VT), who agreed to co-sponsor the amendment.\nA crucial cause of the weakening of support for Title III was a speech given by the unofficial leader of the Southern Caucus the Georgian Democrat, Richard Russell, who pointed out that Title III was not a new law but an amendment of Section 1985 of Title 42 of the United States Code. It seems that this had not been understood previously by either the opponents or the supporters of the Civil Rights Act, including Douglas or Brownell. In his speech Russell drew out the implications of this, including the invocation of Section 1993 of Title 42 of the United States Code, a Reconstruction era law which wasn't mentioned in the bill and which authorized the President to enforce judicial decisions - which would include \"Brown v Board\". This specter of military involvement in domestic politics became a worry not just for moderate previous supporters of the bill such as Bourke Hickenlooper (R-IA) - who after Russell's speech referred to Title III as a \"violation of the civil rights of the white race.\" - but also strong supporters such as Douglas. Later President Eisenhower in answer to a direct question on Russell's charges distanced himself from the \"exact language\" of Title III.\nPresident Eisenhower did not express enthusiasm for the provisions in Title III. In a press conference, he referred to it as going \"too far too fast in laws\", and instead placed an emphasis on the voting rights provisions in Title IV. This diminished the already-waning support for the title among Republicans, many of whom opposed its expansion of federal power on conservative grounds in spite of their sympathy towards civil rights causes.\nThe Anderson\u2013Aiken amendment passed by a 52\u201338 vote. The vote on the amendment did not split purely along partisan or ideological lines; it was opposed by conservative William Knowland (R-CA) and supported by liberal Frank Church (D-ID).\nJury trial amendment.\nMajority Leader Johnson, who was intent on passing a fully weakened act in contrast to overseeing a legislative graveyard at the hands of a Southern filibuster, moved to effectively weaken the voting rights-related provisions in Title IV. Alleged violators of civil rights injunctions are normally entitled to jury trials, with the exception of civil contempt actions. A jury trial amendment that included the guarantee of jury trials in civil contempt actions would, in the South, result in perpetrators of voter suppression being acquitted by an all-white jury, thus ensuring no resulted accomplishment to enfranchise blacks.\nThe jury trial amendment was not introduced by a Southern Democrat, instead being spearheaded by Wyoming senator Joseph C. O'Mahoney. The motivation for Western liberal Democrats to spearhead the cause of weakening the Civil Rights Act of 1957 was attributed to their traditional populist disdain for the perceived disproportionate power wielded by judges to quell labor causes in the Western United States, thus contributing to a resonance with the expansion of jury trial rights, although Lyndon Johnson's biographer Robert Caro also claims that Johnson had facilitated a bargain that Western liberal Democrats would vote with the South in important votes on Civil Rights in return for Southern support for public involvement in the building of the Hells Canyon Dam.\nThere was also support from some unions, particularly the Railroad brotherhoods and the United Mine Workers of America who agreed that this would also stop injunctions in union cases. Their support was seen as a major reason why Senators in mining states such as West Virginia and mid western Republican senators where the railroads were strong became less hostile to the amendment.\nOn August 2, 1957, the Senate passed the jury trial amendment with majority support from Democratic members, both Northern and Southern. Following the vote, many Republicans were visible in their bitterness, having failed in an opportunity to spearhead the cause of civil rights against a deceitful, partisan Democratic effort. According to Johnson biographer Robert A. Caro:\nSeveral conservative Republican senators who voted for the Anderson\u2013Aiken amendment on small-government grounds opposed the jury trial amendment for its intent of weakening civil rights efforts. Idaho senator Henry Dworshak decried that it \"practically scuttled any hope of getting an effective civil rights bill.\"\nFilibuster.\nThen-Democratic Senator Strom Thurmond of South Carolina, an ardent segregationist, sustained the longest one-person filibuster in history in an attempt to keep the bill from becoming law. His one-man filibuster lasted 24 hours and 18 minutes; he began with readings of every US state's election laws in alphabetical order. He later read from the Declaration of Independence, the Bill of Rights, and George Washington's Farewell Address.\nTo prevent a quorum call that could have relieved the filibuster by allowing the Senate to adjourn, cots were brought in from a nearby hotel for the legislators to sleep on while Thurmond discussed increasingly irrelevant and obscure topics. Other members of the Southern caucus, who had agreed as part of a compromise not to filibuster this bill, were upset with Thurmond. They believed his defiance made them look incompetent to their constituents. Other constituents were upset with their senators because they were seen as not helping Thurmond.\nThurmond pointed out that there was already a federal statute that prosecuted citizens who denied or intimidated voters at voting booths under a fine and/or imprisonment but that the bill then under consideration could legally deny trial by jury to those that continued to do so.\nDemocratic Representative Charles A. Boyle of Illinois, a\nmember of the powerful Appropriations Subcommittee of Defense, pushed the bill through the House of Representatives.\nFinal passage.\nThe bill passed 285\u2013126 in the House of Representatives with a majority of both parties' support (Republicans 167\u201319, Democrats 118\u2013107). It then passed 72\u201318 in the Senate, again with a majority of both parties (Republicans 43\u20130, Democrats 29\u201318). Despite large opposition from Southern Democrats, the Democratic U.S. Senators from Tennessee and Texas would support the law. President Eisenhower signed the bill on September 9, 1957.\nThe act established both the Commission on Civil Rights and the office of Assistant Attorney General for Civil Rights. Subsequently, on December 9, 1957, the Civil Rights Division was established within the Justice Department by order of US Attorney General William P. Rogers, giving the Assistant Attorney General for Civil Rights a distinct division to command. Previously, civil rights lawyers had enforced Reconstruction-era civil rights laws from within the Department's Criminal Division.\nCivil Rights Act of 1960.\nThe Civil Rights Act of 1960 () is a United States federal law that established federal inspection of local voter registration polls and introduced penalties for anyone who obstructed someone's attempt to register to vote. It dealt primarily with discriminatory laws and practices in the segregated South, by which African-Americans and Tejanos had been effectively disenfranchised since the late 19th and start of the 20th century. This was the fifth Civil Rights Act to be enacted in United States history. Over an 85-year period, it was preceded only by the Civil Rights Act of 1957, whose shortcomings largely influenced its creation. This law served to more effectively enforce what was set forth in the 1957 act through eliminating certain loopholes in it, and to establish additional provisions. Aside from addressing voting rights, the Civil Rights Act of 1960 also imposed criminal penalties for obstruction of court orders to limit resistance to the Supreme Court's school desegregation decisions, arranged for free education for military members' children, and banned the act of fleeing to avoid prosecution for property damage. The Civil Rights Act of 1960 was signed into law by President Dwight D. Eisenhower.\nCivil Rights Act of 1964.\nThe Civil Rights Act of 1964 () is a landmark civil rights and labor law in the United States that outlaws discrimination based on race, color, religion, sex, and national origin. It prohibits unequal application of voter registration requirements, racial segregation in schools and public accommodations, and employment discrimination. The act \"remains one of the most significant legislative achievements in American history\".\nInitially, powers given to enforce the act were weak, but these were supplemented during later years. Congress asserted its authority to legislate under several different parts of the United States Constitution, principally its enumerated power to regulate interstate commerce under the Commerce Clause of , its duty to guarantee all citizens equal protection of the laws under the 14th Amendment, and its duty to protect voting rights under the 15th Amendment.\nThe legislation was proposed by President John F. Kennedy in June 1963, but it was opposed by filibuster in the Senate. After Kennedy was assassinated on November 22, 1963, President Lyndon B. Johnson pushed the bill forward. The United States House of Representatives passed the bill on February 10, 1964, and after a 72-day filibuster, it passed the United States Senate on June 19, 1964. The final vote was 290\u2013130 in the House of Representatives and 73\u201327 in the Senate. After the House agreed to a subsequent Senate amendment, the Civil Rights Act of 1964 was signed into law by President Johnson at the White House on July 2, 1964.\nLegislative history.\nOn June 11, 1963, President Kennedy met with Republican leaders to discuss the legislation before his television address to the nation that evening. Two days later, Senate Minority Leader Everett Dirksen and Senate Majority Leader Mike Mansfield both voiced support for the president's bill, except for provisions guaranteeing equal access to places of public accommodations. This led to several Republican Representatives drafting a compromise bill to be considered. On June 19, the president sent his bill to Congress as it was originally written, saying legislative action was \"imperative\". The president's bill went first to the House of Representatives, where it was referred to the Judiciary Committee, chaired by New York Democrat Emanuel Celler. After a series of hearings on the bill, Celler's committee strengthened the act, adding provisions to ban racial discrimination in employment, providing greater protection to black voters, eliminating segregation in all publicly owned facilities (not just schools), and strengthening the anti-segregation clauses regarding public facilities such as lunch counters. They also added authorization for the Attorney General to file lawsuits to protect individuals against the deprivation of any rights secured by the Constitution or U.S. law. In essence, this was the controversial \"Title III\" that had been removed from the 1957 Act and 1960 Act. Civil rights organizations pressed hard for this provision because it could be used to protect peaceful protesters and black voters from police brutality and suppression of free speech rights.\nLobbying support for the Civil Rights Act was coordinated by the Leadership Conference on Civil Rights, a coalition of 70 liberal and labor organizations. The principal lobbyists for the Leadership Conference were civil rights lawyer Joseph L. Rauh Jr. and Clarence Mitchell Jr. of the NAACP.\nAfter the March on Washington for Jobs and Freedom, on August 28, 1963, the organizers visited Kennedy to discuss the civil rights bill. Roy Wilkins, A. Philip Randolph, and Walter Reuther attempted to persuade him to support a provision establishing a Fair Employment Practices Commission that would ban discriminatory practices by all federal agencies, unions, and private companies.\nKennedy called the congressional leaders to the White House in late October 1963 to line up the necessary votes in the House for passage. The bill was reported out of the Judiciary Committee in November 1963 and referred to the Rules Committee, whose chairman, Howard W. Smith, a Democrat and staunch segregationist from Virginia, indicated his intention to keep the bill bottled up indefinitely.\nThe assassination of United States President John F. Kennedy on November 22, 1963, changed the political situation. Kennedy's successor as president, Lyndon B. Johnson, made use of his experience in legislative politics, along with the bully pulpit he wielded as president, in support of the bill. In his first address to a joint session of Congress on November 27, 1963, Johnson told the legislators, \"No memorial oration or eulogy could more eloquently honor President Kennedy's memory than the earliest possible passage of the civil rights bill for which he fought so long.\"\nJudiciary Committee chairman Celler filed a petition to discharge the bill from the Rules Committee which required the support of a majority of House members to move the bill to the floor. Initially, Celler had a difficult time acquiring the signatures necessary, with many Representatives who supported the civil rights bill itself remaining cautious about violating normal House procedure with the rare use of a discharge petition. By the time of the 1963 winter recess, 50 signatures were still needed.\nAfter the return of Congress from its winter recess, however, it was apparent that public opinion in the North favored the bill and that the petition would acquire the necessary signatures. To avert the humiliation of a successful discharge petition, Chairman Smith relented and allowed the bill to pass through the Rules Committee.\nJohnson, who wanted the bill passed as soon as possible, ensured that it would be quickly considered by the Senate.\nNormally, the bill would have been referred to the Senate Judiciary Committee, which was chaired by James O. Eastland, a Democrat from Mississippi, whose firm opposition made it seem impossible that the bill would reach the Senate floor. Senate Majority Leader Mike Mansfield took a novel approach to prevent the Judiciary Committee from keeping the bill in limbo: initially waiving a second reading immediately after the first reading, which would have sent it to the Judiciary Committee, he took the unprecedented step of giving the bill a second reading on February 26, 1964, thereby bypassing the Judiciary Committee, and sending it to the Senate floor for immediate debate.\nWhen the bill came before the full Senate for debate on March 30, 1964, the \"Southern Bloc\" of 18 southern Democratic Senators and lone Republican John Tower of Texas, led by Richard Russell (D-GA), launched a filibuster to prevent its passage. Russell proclaimed, \"We will resist to the bitter end any measure or any movement which would tend to bring about social equality and intermingling and amalgamation of the races in our [Southern] states.\"\nStrong opposition to the bill also came from Senator Strom Thurmond, who was still a Democrat at the time: \"This so-called Civil Rights Proposals [\"sic\"], which the President has sent to Capitol Hill for enactment into law, are unconstitutional, unnecessary, unwise and extend beyond the realm of reason. This is the worst civil-rights package ever presented to the Congress and is reminiscent of the Reconstruction proposals and actions of the radical Republican Congress.\"\nAfter the filibuster had gone on for 54 days, Senators Mansfield, Hubert Humphrey, Everett Dirksen, and Thomas Kuchel introduced a substitute bill that they hoped would overcome it by combining a sufficient number of Republicans as well as core liberal Democrats. The compromise bill was weaker than the House version as to the government's power in regulating the conduct of private business, but not weak enough to make the House reconsider it.\nSenator Robert Byrd ended his filibuster in opposition to the bill on the morning of June 10, 1964, after 14 hours and 13 minutes. Up to then, the measure had occupied the Senate for 60 working days, including six Saturdays. The day before, Humphrey, the bill's manager, concluded that he had the 67 votes required at that time to end the debate and the filibuster. With six wavering senators providing a four-vote victory margin, the final tally stood at 71 to 29. Never before in its entire history had the Senate been able to muster enough votes to defeat a filibuster on a civil rights bill, and only once in the 37 years since 1927 had it agreed to cloture for any measure.\nThe most dramatic moment during the cloture vote came when Senator Clair Engle (D-CA) was wheeled into the chamber. Suffering from terminal brain cancer, unable to speak, he pointed to his left eye, signifying his affirmative \"Aye\" vote when his name was called. He died seven weeks later.\nOn June 19, the compromise bill passed the Senate by a vote of 73\u201327, quickly passed through the conference committee, which adopted the Senate version of the bill, then was passed by both houses of Congress and signed into law by Johnson on July 2, 1964.\nAspects.\nWomen's rights.\nOne year earlier, the same Congress had passed the Equal Pay Act of 1963, which prohibited wage differentials based on sex. The prohibition on sex discrimination was added to the Civil Rights Act by Howard W. Smith, a powerful Virginia Democrat who chaired the House Rules Committee and strongly opposed the legislation. Smith's amendment was passed by a teller vote of 168 to 133. Historians debate whether Smith cynically attempted to defeat the bill because he opposed civil rights for Black people and women or attempted to support their rights by broadening the bill to include women. Smith expected that Republicans, who had included equal rights for women in their party's platform since 1944, would probably vote for the amendment. Historians speculate that Smith was trying to embarrass northern Democrats who opposed civil rights for women because labor unions opposed the clause. Representative Carl Elliott of Alabama later said, \"Smith didn't give a damn about women's rights\", as \"he was trying to knock off votes either then or down the line because there was always a hard core of men who didn't favor women's rights\", and according to the \"Congressional Record\", laughter greeted Smith when he introduced the amendment.\nSmith asserted that he was not joking and sincerely supported the amendment. Along with Representative Martha Griffiths, he was the amendment's chief spokesperson. For 20 years, Smith had sponsored the Equal Rights Amendment (with no linkage to racial issues) in the House because he believed in it. For decades he had been close to the National Woman's Party and its leader Alice Paul, who had been a leading figure in winning the right to vote for women in 1920, co-authored the first Equal Rights Amendment, and had been a chief supporter of equal rights proposals since then. She and other feminists had worked with Smith since 1945 to find a way to include sex as a protected civil rights category, and felt now was the moment. Griffiths argued that the new law would protect black women but not white women, and that that was unfair to white women. Black feminist lawyer Pauli Murray wrote a supportive memorandum at the behest of the National Federation of Business and Professional Women. Griffiths also argued that the laws \"protecting\" women from unpleasant jobs were actually designed to enable men to monopolize those jobs, and that that was unfair to women who were not allowed to try out for those jobs. The amendment passed with the votes of Republicans and Southern Democrats. The final law passed with the votes of Republicans and Northern Democrats. Thus, as Justice William Rehnquist wrote in \"Meritor Savings Bank v. Vinson\", \"The prohibition against discrimination based on sex was added to Title VII at the last minute on the floor of the House of Representatives [...] the bill quickly passed as amended, and we are left with little legislative history to guide us in interpreting the Act's prohibition against discrimination based on 'sex.\nDesegregation.\nOne of the bill's opponents' most damaging arguments was that once passed, the bill would require forced busing to achieve certain racial quotas in schools. The bill's proponents, such as Emanuel Celler and Jacob Javits, said it would not authorize such measures. Leading sponsor Hubert Humphrey wrote two amendments specifically designed to outlaw busing. Humphrey said, \"if the bill were to compel it, it would be a violation [of the Constitution], because it would be handling the matter on the basis of race and we would be transporting children because of race.\" Javits said any government official who sought to use the bill for busing purposes \"would be making a fool of himself,\" but two years later the Department of Health, Education and Welfare said that Southern school districts would be required to meet mathematical ratios of students by busing.\nAftermath.\nThe bill divided both major American political parties and engendered a long-term change in the demographics of the support for each. President Kennedy realized that supporting this bill would risk losing the South's overwhelming support of the Democratic Party. Both Attorney General Robert F. Kennedy and Vice President Johnson had pushed for the introduction of the civil rights legislation. Johnson told Kennedy aide Ted Sorensen that \"I know the risks are great and we might lose the South, but those sorts of states may be lost anyway.\" Senator Richard Russell, Jr. later warned President Johnson that his strong support for the civil rights bill \"will not only cost you the South, it will cost you the election\". Johnson, however, went on to win the 1964 election by one of the biggest landslides in American history. The South, which had five states swing Republican in 1964, became a stronghold of the Republican Party by the 1990s.\nAlthough majorities in both parties voted for the bill, there were notable exceptions. Though he opposed forced segregation, Republican 1964 presidential candidate, Senator Barry Goldwater of Arizona, voted against the bill, remarking, \"You can't legislate morality.\" Goldwater had supported previous attempts to pass civil rights legislation in 1957 and 1960 as well as the 24th Amendment outlawing the poll tax. He stated that the reason for his opposition to the 1964 bill was Title II, which in his opinion violated individual liberty and states' rights. Democrats and Republicans from the Southern states opposed the bill and led an unsuccessful 60 working day filibuster, including Senators Albert Gore, Sr. (D-TN) and J. William Fulbright (D-AR), as well as Senator Robert Byrd (D-WV), who personally filibustered for 14 hours straight.\nThere were white business owners who claimed that Congress did not have the constitutional authority to ban segregation in public accommodations. For example, Moreton Rolleston, the owner of a motel in Atlanta, Georgia, said he should not be forced to serve black travelers, saying, \"the fundamental question [...] is whether or not Congress has the power to take away the liberty of an individual to run his business as he sees fit in the selection and choice of his customers\". Rolleston claimed that the Civil Rights Act of 1964 was a breach of the Fourteenth Amendment and also violated the Fifth and Thirteenth Amendments by depriving him of \"liberty and property without due process\". In \"Heart of Atlanta Motel v. United States\" (1964), the Supreme Court held that Congress drew its authority from the Constitution's Commerce Clause, rejecting Rolleston's claims.\nResistance to the public accommodation clause continued for years on the ground, especially in the South. When local college students in Orangeburg, South Carolina, attempted to desegregate a bowling alley in 1968, they were violently attacked, leading to rioting and what became known as the \"Orangeburg massacre.\" Resistance by school boards continued into the next decade, with the most significant declines in black-white school segregation only occurring at the end of the 1960s and the start of the 1970s in the aftermath of the \"Green v. County School Board of New Kent County\" (1968) court decision.\nIn June 2020, the U.S. Supreme Court ruled in three cases (\"Bostock v. Clayton County\", \"Altitude Express, Inc. v. Zarda\", and \"R.G. &amp; G.R. Harris Funeral Homes Inc. v. Equal Employment Opportunity Commission\") that Title VII of the Civil Rights Act, which barred employers from discriminating on the basis of sex, precluded employers from discriminating on the basis of sexual orientation or gender identity. Afterward, \"USA Today\" stated that in addition to LGBTQ employment discrimination, \"[t]he court's ruling is likely to have a sweeping impact on federal civil rights laws barring sex discrimination in education, health care, housing and financial credit.\"\nVoting Rights Act of 1965.\nThe Voting Rights Act of 1965 is a landmark piece of federal legislation in the United States that prohibits racial discrimination in voting. It was signed into law by President Lyndon B. Johnson during the height of the civil rights movement on August 6, 1965, and Congress later amended the Act five times to expand its protections. Designed to enforce the voting rights protected by the Fourteenth and Fifteenth Amendments to the United States Constitution, the Act sought to secure the right to vote for racial minorities throughout the country, especially in the South. According to the U.S. Department of Justice, the Act is considered to be the most effective piece of federal civil rights legislation ever enacted in the country. The National Archives and Records Administration stated: \"The Voting Rights Act of 1965 was the most significant statutory change in the relationship between the federal and state governments in the area of voting since the Reconstruction period following the Civil War\".\nThe act contains numerous provisions that regulate elections. The act's \"general provisions\" provide nationwide protections for voting rights. Section 2 is a general provision that prohibits state and local government from imposing any voting rule that \"results in the denial or abridgement of the right of any citizen to vote on account of race or color\" or membership in a language minority group. Other general provisions specifically outlaw literacy tests and similar devices that were historically used to disenfranchise racial minorities. The act also contains \"special provisions\" that apply to only certain jurisdictions. A core special provision is the Section 5 preclearance requirement, which prohibited certain jurisdictions from implementing any change affecting voting without first receiving confirmation from the U.S. attorney general or the U.S. District Court for D.C. that the change does not discriminate against protected minorities. Another special provision requires jurisdictions containing significant language minority populations to provide bilingual ballots and other election materials.\nSection 5 and most other special provisions applied to jurisdictions encompassed by the \"coverage formula\" prescribed in Section 4(b). The coverage formula was originally designed to encompass jurisdictions that engaged in egregious voting discrimination in 1965, and Congress updated the formula in 1970 and 1975. In \"Shelby County v. Holder\" (2013), the U.S. Supreme Court struck down the coverage formula as unconstitutional, reasoning that it was obsolete. The court did not strike down Section 5, but without a coverage formula, Section 5 is unenforceable. The jurisdictions which had previously been covered by the coverage formula massively increased the rate of voter registration purges after the \"Shelby\" decision.\nIn 2021, the \"Brnovich v. Democratic National Committee\" Supreme Court ruling reinterpreted Section 2 of the Voting Rights Act of 1965, substantially weakening it. The ruling interpreted the \"totality of circumstances\" language of Section 2 to mean that it does not generally prohibit voting rules that have disparate impact on the groups that it sought to protect, including a rule blocked under Section 5 before the Court inactivated that section in \"Shelby County v. Holder\". In particular, the ruling held that fears of election fraud could justify such rules without evidence that any such fraud had occurred in the past or that the new rule would make elections safer.\nResearch shows that the Act had successfully and massively increased voter turnout and voter registrations, in particular among black people. The Act has also been linked to concrete outcomes, such as greater public goods provision (such as public education) for areas with higher black population shares, more members of Congress who vote for civil rights-related legislation, and greater Black representation in local offices.\nBackground.\nPrior to the enactment of the Voting Rights Act of 1965 there were several efforts to stop the disenfranchisement of black voters by Southern states. Besides the above-mentioned literacy tests and poll taxes other bureaucratic restrictions were used to deny them the right to vote. African Americans also \"risked harassment, intimidation, economic reprisals, and physical violence when they tried to register or vote. As a result, very few African Americans were registered voters, and they had very little, if any, political power, either locally or nationally.\" In the 1950s the Civil Rights Movement increased pressure on the federal government to protect the voting rights of racial minorities. In 1957, Congress passed the first civil rights legislation since Reconstruction: the Civil Rights Act of 1957. This legislation authorized the attorney general to sue for injunctive relief on behalf of persons whose Fifteenth Amendment rights were denied, created the Civil Rights Division within the Department of Justice to enforce civil rights through litigation, and created the Commission on Civil Rights to investigate voting rights deprivations. Further protections were enacted in the Civil Rights Act of 1960, which allowed federal courts to appoint referees to conduct voter registration in jurisdictions that engaged in voting discrimination against racial minorities.\nAlthough these acts helped empower courts to remedy violations of federal voting rights, strict legal standards made it difficult for the Department of Justice to successfully pursue litigation. For example, to win a discrimination lawsuit against a state that maintained a literacy test, the department needed to prove that the rejected voter-registration applications of racial minorities were comparable to the accepted applications of whites. This involved comparing thousands of applications in each of the state's counties in a process that could last months. The department's efforts were further hampered by resistance from local election officials, who would claim to have misplaced the voter registration records of racial minorities, remove registered racial minorities from the electoral rolls, and resign so that voter registration ceased. Moreover, the department often needed to appeal lawsuits several times before the judiciary provided relief because many federal district court judges opposed racial minority suffrage. Thus, between 1957 and 1964, the African-American voter registration rate in the South increased only marginally even though the department litigated 71 voting rights lawsuits. Efforts to stop the disfranchisement by the Southern states had achieved only modest success overall and in some areas had proved almost entirely ineffectual, because the \"Department of Justice's efforts to eliminate discriminatory election practices by litigation on a case-by-case basis had been unsuccessful in opening up the registration process; as soon as one discriminatory practice or procedure was proven to be unconstitutional and enjoined, a new one would be substituted in its place and litigation would have to commence anew.\"\nCongress responded to rampant discrimination against racial minorities in public accommodations and government services by passing the Civil Rights Act of 1964. The act included some voting rights protections; it required registrars to equally administer literacy tests in writing to each voter and to accept applications that contained minor errors, and it created a rebuttable presumption that persons with a sixth-grade education were sufficiently literate to vote. However, despite lobbying from civil rights leaders, the Act did not prohibit most forms of voting discrimination. President Lyndon B. Johnson recognized this, and shortly after the 1964 elections in which Democrats gained overwhelming majorities in both chambers of Congress, he privately instructed Attorney General Nicholas Katzenbach to draft \"the goddamndest, toughest voting rights act that you can\". However, Johnson did not publicly push for the legislation at the time; his advisers warned him of political costs for vigorously pursuing a voting rights bill so soon after Congress had passed the Civil Rights Act of 1964, and Johnson was concerned that championing voting rights would endanger his Great Society reforms by angering Southern Democrats in Congress.\nFollowing the 1964 elections, civil rights organizations such as the Southern Christian Leadership Conference (SCLC) and the Student Nonviolent Coordinating Committee (SNCC) pushed for federal action to protect the voting rights of racial minorities. Their efforts culminated in protests in Alabama, particularly in the city of Selma, where County Sheriff Jim Clark's police force violently resisted African-American voter registration efforts. Speaking about the voting rights push in Selma, James Forman of SNCC said: \"Our strategy, as usual, was to force the U.S. government to intervene in case there were arrests\u2014and if they did not intervene, that inaction would once again prove the government was not on our side and thus intensify the development of a mass consciousness among blacks. Our slogan for this drive was 'One Man, One Vote.\nIn January 1965, Martin Luther King Jr., James Bevel, and other civil rights leaders organized several peaceful demonstrations in Selma, which were violently attacked by police and white counter-protesters. Throughout January and February, these protests received national media coverage and drew attention to the issue of voting rights. King and other demonstrators were arrested during a march on February 1 for violating an anti-parade ordinance; this inspired similar marches in the following days, causing hundreds more to be arrested. On February 4, civil rights leader Malcolm X gave a militant speech in Selma in which he said that many African Americans did not support King's nonviolent approach; he later privately said that he wanted to frighten whites into supporting King. The next day, King was released and a letter he wrote addressing voting rights, \"Letter From A Selma Jail\", appeared in \"The New York Times\".\nWith increasing national attention focused on Selma and voting rights, President Johnson reversed his decision to delay voting rights legislation. On February 6, he announced he would send a proposal to Congress. Johnson did not reveal the proposal's content or disclose when it would come before Congress.\nOn February 18 in Marion, Alabama, state troopers violently broke up a nighttime voting-rights march during which officer James Bonard Fowler shot and killed young African-American protester Jimmie Lee Jackson, who was unarmed and protecting his mother. Spurred by this event, and at the initiation of Bevel, on March 7 SCLC and SNCC began the first of the Selma to Montgomery marches, in which Selma residents intended to march to Alabama's capital, Montgomery, to highlight voting rights issues and present Governor George Wallace with their grievances. On the first march, demonstrators were stopped by state and county police on horseback at the Edmund Pettus Bridge near Selma. The police shot tear gas into the crowd and trampled protesters. Televised footage of the scene, which became known as \"Bloody Sunday\", generated outrage across the country. A second march was held on March 9, which became known as . That evening, three white Unitarian ministers who participated in the march were attacked on the street and beaten with clubs by four Ku Klux Klan members. The worst injured was Reverend James Reeb from Boston, who died on Thursday, March 11.\nIn the wake of the events in Selma, President Johnson, addressing a televised joint session of Congress on March 15, called on legislators to enact expansive voting rights legislation. In his speech, he used the words \"we shall overcome\", adopting the rallying cry of the civil rights movement. The Voting Rights Act of 1965 was introduced in Congress two days later while civil rights leaders, now under the protection of federal troops, led a march of 25,000 people from Selma to Montgomery.\nLegislative history.\nEfforts to eliminate discriminatory election practices by litigation on a case-by-case basis by the United States Department of Justice had been unsuccessful and existing federal anti-discrimination laws were not sufficient to overcome the resistance by state officials to enforcement of the 15th Amendment. Against this backdrop Congress came to the conclusion that a new comprehensive federal bill was necessary to break the grip of state disfranchisement. The United States Supreme Court explained this in \"South Carolina v. Katzenbach\" (1966) with the following words:\nIn \"South Carolina v. Katzenbach\" (1966) the Supreme Court also held that Congress had the power to pass the Voting Rights Act of 1965 under its Enforcement Powers stemming from the Fifteenth Amendment:\nOriginal bill.\nSenate.\nThe Voting Rights Act of 1965 was introduced in Congress on March 17, 1965, as S. 1564, and it was jointly sponsored by Senate majority leader Mike Mansfield (D-MT) and Senate minority leader Everett Dirksen (R-IL), both of whom had worked with Attorney General Katzenbach to draft the bill's language. Although Democrats held two-thirds of the seats in both chambers of Congress after the 1964 Senate elections, Johnson worried that Southern Democrats would filibuster the legislation because they had opposed other civil rights efforts. He enlisted Dirksen to help gain Republican support. Dirksen did not originally intend to support voting rights legislation so soon after supporting the Civil Rights Act of 1964, but he expressed willingness to accept \"revolutionary\" legislation after learning about the police violence against marchers in Selma on Bloody Sunday. Given Dirksen's key role in helping Katzenbach draft the legislation, it became known informally as the \"Dirksenbach\" bill. After Mansfield and Dirksen introduced the bill, 64 additional senators agreed to cosponsor it, with a total 46 Democratic and 20 Republican cosponsors.\nThe bill contained several special provisions that targeted certain state and local governments: a \"coverage formula\" that determined which jurisdictions were subject to the Act's other special provisions (\"covered jurisdictions\"); a \"preclearance\" requirement that prohibited covered jurisdictions from implementing changes to their voting procedures without first receiving approval from the U.S. attorney general or the U.S. District Court for D.C. that the changes were not discriminatory; and the suspension of \"tests or devices\", such as literacy tests, in covered jurisdictions. The bill also authorized the assignment of federal examiners to register voters, and of federal observers to monitor elections, to covered jurisdictions that were found to have engaged in egregious discrimination. The bill set these special provisions to expire after five years.\nThe scope of the coverage formula was a matter of contentious congressional debate. The coverage formula reached a jurisdiction if (1) the jurisdiction maintained a \"test or device\" on November 1, 1964, and (2) less than 50 percent of the jurisdiction's voting-age residents either were registered to vote on November 1, 1964, or cast a ballot in the November 1964 presidential election. This formula reached few jurisdictions outside the Deep South. To appease legislators who felt that the bill unfairly targeted Southern jurisdictions, the bill included a general prohibition on racial discrimination in voting that applied nationwide. The bill also included provisions allowing a covered jurisdiction to \"bail out\" of coverage by proving in federal court that it had not used a \"test or device\" for a discriminatory purpose or with a discriminatory effect during the 5 years preceding its bailout request. Additionally, the bill included a \"bail in\" provision under which federal courts could subject discriminatory non-covered jurisdictions to remedies contained in the special provisions.\nThe bill was first considered by the Senate Judiciary Committee, whose chair, Senator James Eastland (D-MS), opposed the legislation with several other Southern senators on the committee. To prevent the bill from dying in committee, Mansfield proposed a motion to require the Judiciary Committee to report the bill out of committee by April 9, which the Senate overwhelmingly passed by a vote of 67 to 13. During the committee's consideration of the bill, Senator Ted Kennedy (D-MA) led an effort to amend the bill to prohibit poll taxes. Although the Twenty-fourth Amendment\u2014which banned the use of poll taxes in federal elections\u2014 was ratified a year earlier, Johnson's administration and the bill's sponsors did not include a provision in the voting rights bill banning poll taxes in \"state\" elections because they feared courts would strike down the legislation as unconstitutional. Additionally, by excluding poll taxes from the definition of \"tests or devices\", the coverage formula did not reach Texas or Arkansas, mitigating opposition from those two states' influential congressional delegations. Nonetheless, with the support of liberal committee members, Kennedy's amendment to prohibit poll taxes passed by a 9\u20134 vote. In response, Dirksen offered an amendment that exempted from the coverage formula any state that had at least 60 percent of its eligible residents registered to vote or that had a voter turnout that surpassed the national average in the preceding presidential election. This amendment, which effectively exempted all states from coverage except Mississippi, passed during a committee meeting in which three liberal members were absent. Dirksen offered to drop the amendment if the poll tax ban were removed. Ultimately, the bill was reported out of committee on April 9 by a 12\u20134 vote without a recommendation.\nOn April 22, the full Senate started debating the bill. Dirksen spoke first on the bill's behalf, saying that \"legislation is needed if the unequivocal mandate of the Fifteenth Amendment\u00a0... is to be enforced and made effective, and if the Declaration of Independence is to be made truly meaningful.\" Senator Strom Thurmond (D-SC) retorted that the bill would lead to \"despotism and tyranny\", and Senator Sam Ervin (D-NC) argued that the bill was unconstitutional because it deprived states of their right under to establish voter qualifications and because the bill's special provisions targeted only certain jurisdictions. On May 6, Ervin offered an amendment to abolish the coverage formula's automatic trigger and instead allow federal judges to appoint federal examiners to administer voter registration. This amendment overwhelmingly failed, with 42 Democrats and 22 Republicans voting against it. After lengthy debate, Ted Kennedy's amendment to prohibit poll taxes also failed 49\u201345 on May 11. However, the Senate agreed to include a provision authorizing the attorney general to sue any jurisdiction, covered or non-covered, to challenge its use of poll taxes. An amendment offered by Senator Robert F. Kennedy (D-NY) to enfranchise English-illiterate citizens who had attained at least a sixth-grade education in a non-English-speaking school also passed by 48\u201319. Southern legislators offered a series of amendments to weaken the bill, all of which failed.\nOn May 25, the Senate voted for cloture by a 70\u201330 vote, thus overcoming the threat of filibuster and limiting further debate on the bill. On May 26, the Senate passed the bill by a 77\u201319 vote (Democrats 47\u201316, Republicans 30\u20132); only senators representing Southern states voted against it.\nHouse of Representatives.\nEmanuel Celler (D-NY), Chair of the House Judiciary Committee, introduced the Voting Rights Act in the House of Representatives on March 19, 1965, as H.R. 6400. The House Judiciary Committee was the first committee to consider the bill. The committee's ranking Republican, William McCulloch (R-OH), generally supported expanding voting rights, but he opposed both the poll tax ban and the coverage formula, and he led opposition to the bill in committee. The committee eventually approved the bill on May 12, but it did not file its committee report until June 1. The bill included two amendments from subcommittee: a penalty for private persons who interfered with the right to vote and a prohibition of all poll taxes. The poll tax prohibition gained Speaker of the House John McCormack's support. The bill was next considered by the Rules Committee, whose chair, Howard W. Smith (D-VA), opposed the bill and delayed its consideration until June 24, when Celler initiated proceedings to have the bill discharged from committee. Under pressure from the bill's proponents, Smith allowed the bill to be released a week later, and the full House started debating the bill on July 6.\nTo defeat the Voting Rights Act, McCulloch introduced an alternative bill, H.R. 7896. It would have allowed the attorney general to appoint federal registrars after receiving 25 serious complaints of discrimination against a jurisdiction, and it would have imposed a nationwide ban on literacy tests for persons who could prove they attained a sixth-grade education. McCulloch's bill was co-sponsored by House minority leader Gerald Ford (R-MI) and supported by Southern Democrats as an alternative to the Voting Rights Act. The Johnson administration viewed H.R. 7896 as a serious threat to passing the Voting Rights Act. However, support for H.R. 7896 dissipated after William M. Tuck (D-VA) publicly said he preferred H.R. 7896 because the Voting Rights Act would legitimately ensure that African Americans could vote. His statement alienated most supporters of H.R. 7896, and the bill failed on the House floor by a 171\u2013248 vote on July 9. Later that night, the House passed the Voting Rights Act by a 333\u201385 vote (Democrats 221\u201361, Republicans 112\u201324).\nConference committee.\nThe chambers appointed a conference committee to resolve differences between the House and Senate versions of the bill. A major contention concerned the poll tax provisions; the Senate version allowed the attorney general to sue states that used poll taxes to discriminate, while the House version outright banned all poll taxes. Initially, the committee members were stalemated. To help broker a compromise, Attorney General Katzenbach drafted legislative language explicitly asserting that poll taxes were unconstitutional and instructed the Department of Justice to sue the states that maintained poll taxes. To assuage concerns of liberal committee members that this provision was not strong enough, Katzenbach enlisted the help of Martin Luther King Jr., who gave his support to the compromise. King's endorsement ended the stalemate, and on July 29, the conference committee reported its version out of committee. The House approved this conference report version of the bill on August 3 by a 328\u201374 vote (Democrats 217\u201354, Republicans 111\u201320), and the Senate passed it on August 4 by a 79\u201318 vote (Democrats 49\u201317, Republicans 30\u20131). On August 6, President Johnson signed the Act into law with King, Rosa Parks, John Lewis, and other civil rights leaders in attendance at the signing ceremony.\nAmendments.\nCongress enacted major amendments to the Act in 1970, 1975, 1982, 1992, and 2006. Each amendment coincided with an impending expiration of some or all of the Act's special provisions. Originally set to expire by 1970, Congress repeatedly reauthorized the special provisions in recognition of continuing voting discrimination. Congress extended the coverage formula and special provisions tied to it, such as the Section 5 preclearance requirement, for five years in 1970, seven years in 1975, and 25 years in both 1982 and 2006. In 1970 and 1975, Congress also expanded the reach of the coverage formula by supplementing it with new 1968 and 1972 trigger dates. Coverage was further enlarged in 1975 when Congress expanded the meaning of \"tests or devices\" to encompass any jurisdiction that provided English-only election information, such as ballots, if the jurisdiction had a single language minority group that constituted more than five percent of the jurisdiction's voting-age citizens. These expansions brought numerous jurisdictions into coverage, including many outside of the South. To ease the burdens of the reauthorized special provisions, Congress liberalized the bailout procedure in 1982 by allowing jurisdictions to escape coverage by complying with the Act and affirmatively acting to expand minority political participation.\nIn addition to reauthorizing the original special provisions and expanding coverage, Congress amended and added several other provisions to the Act. For instance, Congress expanded the original ban on \"tests or devices\" to apply nationwide in 1970, and in 1975, Congress made the ban permanent. Separately, in 1975 Congress expanded the Act's scope to protect language minorities from voting discrimination. Congress defined \"language minority\" to mean \"persons who are American Indian, Asian American, Alaskan Natives or of Spanish heritage.\" Congress amended various provisions, such as the preclearance requirement and Section 2's general prohibition of discriminatory voting laws, to prohibit discrimination against language minorities. Congress also enacted a bilingual election requirement in Section 203, which requires election officials in certain jurisdictions with large numbers of English-illiterate language minorities to provide ballots and voting information in the language of the language minority group. Originally set to expire after 10 years, Congress reauthorized Section 203 in 1982 for seven years, expanded and reauthorized it in 1992 for 15 years, and reauthorized it in 2006 for 25 years. The bilingual election requirements have remained controversial, with proponents arguing that bilingual assistance is necessary to enable recently naturalized citizens to vote and opponents arguing that the bilingual election requirements constitute costly unfunded mandates.\nSeveral of the amendments responded to judicial rulings with which Congress disagreed. In 1982, Congress amended the Act to overturn the Supreme Court case \"Mobile v. Bolden\" (1980), which held that the general prohibition of voting discrimination prescribed in Section 2 prohibited only \"purposeful\" discrimination. Congress responded by expanding Section 2 to explicitly ban any voting practice that had a discriminatory \"effect\", regardless of whether the practice was enacted or operated for a discriminatory purpose. The creation of this \"results test\" shifted the majority of vote dilution litigation brought under the Act from preclearance lawsuits to Section 2 lawsuits. In 2006, Congress amended the Act to overturn two Supreme Court cases: \"Reno v. Bossier Parish School Board\" (2000), which interpreted the Section 5 preclearance requirement to prohibit only voting changes that were enacted or maintained for a \"retrogressive\" discriminatory purpose instead of any discriminatory purpose, and \"Georgia v. Ashcroft\" (2003), which established a broader test for determining whether a redistricting plan had an impermissible effect under Section 5 than assessing only whether a minority group could elect its preferred candidates. Since the Supreme Court struck down the coverage formula as unconstitutional in \"Shelby County v. Holder\" (2013), several bills have been introduced in Congress to create a new coverage formula and amend various other provisions; none of these bills have passed.\nProvisions.\nThe act contains two types of provisions: \"general provisions\", which apply nationwide, and \"special provisions\", which apply to only certain states and local governments. \"The Voting Rights Act was aimed at the subtle, as well as the obvious, state regulations which have the effect of denying citizens their right to vote because of their race. Moreover, compatible with the decisions of this Court, the Act gives a broad interpretation to the right to vote, recognizing that voting includes \"all action necessary to make a vote effective.\" 79 Stat. 445, 42 U.S.C. \u00a7 19731(c)(1) (1969 ed., Supp. I). See \"Reynolds v. Sims\", 377 U. S. 533, 377 U. S. 555 (1964).\" Most provisions are designed to protect the voting rights of racial and language minorities. The term \"language minority\" means \"persons who are American Indian, Asian American, Alaskan Natives or of Spanish heritage.\" The act's provisions have been colored by numerous judicial interpretations and congressional amendments.\nSection 2 prohibits any jurisdiction from implementing a \"voting qualification or prerequisite to voting, or standard, practice, or procedure\u00a0... in a manner which results in a denial or abridgement of the right\u00a0... to vote on account of race,\" color, or language minority status. Section 2 of the law contains two separate protections against voter discrimination for laws which, in contrast to Section 5 of the law, are already implemented. The first protection is a prohibition of intentional discrimination based on race or color in voting. The second protection is a prohibition of election practices that result in the denial or abridgment of the right to vote based on race or color. If the violation of the second protection is intentional, then this violation is also a violation of the Fifteenth Amendment. The Supreme Court has allowed private plaintiffs to sue to enforce these prohibitions. In \"Mobile v. Bolden\" (1980), the Supreme Court held that as originally enacted in 1965, Section 2 simply restated the Fifteenth Amendment and thus prohibited only those voting laws that were \"intentionally\" enacted or maintained for a discriminatory purpose. In 1982, Congress amended Section 2 to create a \"results\" test, which prohibits any voting law that has a discriminatory effect irrespective of whether the law was intentionally enacted or maintained for a discriminatory purpose. The 1982 amendments stipulated that the results test does not guarantee protected minorities a right to proportional representation. In \"Thornburg v. Gingles\" (1986) the United States Supreme Court explained with respect to the 1982 amendment for section 2 that the \"essence of a Section 2 claim is that a certain electoral law, practice, or structure interacts with social and historical conditions to cause an inequality in the opportunities enjoyed by black and white voters to elect their preferred representatives.\" The United States Department of Justice declared that section 2 is not only a permanent and nationwide-applying prohibition against discrimination in voting to any voting standard, practice, or procedure that results in the denial or abridgement of the right of any citizen to vote on account of race, color, or membership in a language minority group, but also a prohibition for state and local officials to adopt or maintain voting laws or procedures that purposefully discriminate on the basis of race, color, or membership in a language minority group.\nThe United States Supreme Court expressed its views regarding Section 2 and its amendment from 1982 in \"Chisom v. Roemer\" (1991). Under the amended statute, proof of intent is no longer required to prove a \u00a7 2 violation. Now plaintiffs can prevail under \u00a7 2 by demonstrating that a challenged election practice has resulted in the denial or abridgement of the right to vote based on color or race. Congress not only incorporated the results test in the paragraph that formerly constituted the entire \u00a7 2, but also designated that paragraph as subsection (a) and added a new subsection (b) to make clear that an application of the results test requires an inquiry into \"the totality of the circumstances.\" Section 2(a) adopts a results test, thus providing that proof of discriminatory intent is no longer necessary to establish any violation of the section. Section 2(b) provides guidance about how the results test is to be applied. There is a statutory framework to determine whether a jurisdiction's election law violates the general prohibition from Section 2 in its amended form:\nSection 2 prohibits voting practices that \"result[] in a denial or abridgment of the right * * * to vote on account of race or color [or language-minority status],\" and it states that such a result \"is established\" if a jurisdiction\u2019s \"political processes * * * are not equally open\" to members of such a group \"in that [they] have less opportunity * * * to participate in the political process and to elect representatives of their choice.\" 52 U.S.C. 10301. [...] Subsection (b) states in relevant part:\nA violation of subsection (a) is established if, based on the totality of circumstances, it is shown that the political processes leading to nomination or election in the State or political subdivision are not equally open to participation by members of a class of citizens protected by subsection (a) in that its members have less opportunity than other members of the electorate to participate in the political process and to elect representatives of their choice.\nThe Office of the Arizona Attorney General stated with respect to the framework to determine whether a jurisdiction's election law violates the general prohibition from Section 2 in its amended form and the reason for the adoption of Section 2 in its amended form:\nTo establish a violation of amended Section 2, the plaintiff must prove,\"based on the totality of circumstances,\" that the State\u2019s \"political processes\" are \"not equally open to participation by members\" of a protected class, \"in that its members have less opportunity than other members of the electorate to participate in the political process and to elect representatives of their choice.\" \u00a7 10301(b). That is the \"result\" that amended Section 2 prohibits: \"less \"opportunity\" than other members of the electorate,\" viewing the State\u2019s \"political processes\" as a whole. The new language was crafted as a compromise designed to eliminate the need for direct evidence of discriminatory intent, which is often difficult to obtain, but without embracing an unqualified \"disparate impact\" test that would invalidate many legitimate voting procedures. S. REP. NO. 97\u2013417, at 28\u201329, 31\u201332, 99 (1982)\nIn \"Brnovich v. Democratic National Committee\" (2021) the United States Supreme Court introduced the means to review Section 2 challenges. The slip opinion stated in its Syllabus section in this regard that \"The Court declines in these cases to announce a test to govern all VRA [Section 2] challenges to rules that specify the time, place, or manner for casting ballots. It is sufficient for present purposes to identify certain guideposts that lead to the Court's decision in these cases.\" The Court laid out these guideposts used to evaluate the state regulations in context of Section 2, which included: the size of the burden created by the rule, the degree which the rule deviates from past practices, the size of the racial imbalance, and the overall level of opportunity afforded voters in considering all election rules.\nWhen determining whether a jurisdiction's election law violates the general prohibition from Section 2 of the VRA, courts have relied on factors enumerated in the Senate Judiciary Committee report associated with the 1982 amendments (\"Senate Factors\"), including:\nThe report indicates not all or a majority of these factors need to exist for an electoral device to result in discrimination, and it also indicates that this list is not exhaustive, allowing courts to consider additional evidence at their discretion.\nSection 2 prohibits two types of discrimination: \"vote denial\", in which a person is denied the opportunity to cast a ballot or to have their vote properly counted, and \"vote dilution\", in which the strength or effectiveness of a person's vote is diminished. Most Section 2 litigation has concerned vote dilution, especially claims that a jurisdiction's redistricting plan or use of at-large/multimember elections prevents minority voters from casting sufficient votes to elect their preferred candidates. An at-large election can dilute the votes cast by minority voters by allowing a cohesive majority group to win every legislative seat in the jurisdiction. Redistricting plans can be gerrymandered to dilute votes cast by minorities by \"packing\" high numbers of minority voters into a small number of districts or \"cracking\" minority groups by placing small numbers of minority voters into a large number of districts.\nIn \"Thornburg v. Gingles\" (1986), the Supreme Court used the term \"vote dilution through submergence\" to describe claims that a jurisdiction's use of an at-large/multimember election system or gerrymandered redistricting plan diluted minority votes, and it established a legal framework for assessing such claims under Section 2. Under the \"Gingles\" test, plaintiffs must show the existence of three preconditions:\nThe first precondition is known as the \"compactness\" requirement and concerns whether a majority-minority district can be created. The second and third preconditions are collectively known as the \"racially polarized voting\" or \"racial bloc voting\" requirement, and they concern whether the voting patterns of the different racial groups are different from each other. If a plaintiff proves these preconditions exist, then the plaintiff must additionally show, using the remaining Senate Factors and other evidence, that under the \"totality of the circumstances\", the jurisdiction's redistricting plan or use of at-large or multimember elections diminishes the ability of the minority group to elect candidates of its choice.\nSubsequent litigation further defined the contours of these \"vote dilution through submergence\" claims. In \"Bartlett v. Strickland\" (2009), the Supreme Court held that the first \"Gingles\" precondition can be satisfied \"only\" if a district can be drawn in which the minority group comprises a majority of voting-age citizens. This means that plaintiffs cannot succeed on a submergence claim in jurisdictions where the size of the minority group, despite not being large enough to comprise a majority in a district, is large enough for its members to elect their preferred candidates with the help of \"crossover\" votes from some members of the majority group. In contrast, the Supreme Court has not addressed whether different protected minority groups can be aggregated to satisfy the \"Gingles\" preconditions as a coalition, and lower courts have split on the issue.\nThe Supreme Court provided additional guidance on the \"totality of the circumstances\" test in \"Johnson v. De Grandy\" (1994). The court emphasized that the existence of the three \"Gingles\" preconditions may be insufficient to prove liability for vote dilution through submergence if other factors weigh against such a determination, especially in lawsuits challenging redistricting plans. In particular, the court held that even where the three \"Gingles\" preconditions are satisfied, a jurisdiction is unlikely to be liable for vote dilution if its redistricting plan contains a number of majority-minority districts that is proportional to the minority group's population size. The decision thus clarified that Section 2 does not require jurisdictions to maximize the number of majority-minority districts. The opinion also distinguished the proportionality of majority-minority districts, which allows minorities to have a proportional \"opportunity\" to elect their candidates of choice, from the proportionality of election \"results\", which Section 2 explicitly does not guarantee to minorities.\nAn issue regarding the third \"Gingles\" precondition remains unresolved. In \"Gingles\", the Supreme Court split as to whether plaintiffs must prove that the majority racial group votes as a bloc specifically because its members are motivated to vote based on racial considerations and not other considerations that may overlap with race, such as party affiliation. A plurality of justices said that requiring such proof would violate Congress's intent to make Section 2 a \"results\" test, but Justice White maintained that the proof was necessary to show that an electoral scheme results in \"racial\" discrimination. Since \"Gingles\", lower courts have split on the issue.\nAlthough most Section 2 litigation has involved claims of vote dilution through submergence, courts also have addressed other types of vote dilution under this provision. In \"Holder v. Hall\" (1994), the Supreme Court held that claims that minority votes are diluted by the small size of a governing body, such as a one-person county commission, may not be brought under Section 2. A plurality of the court reasoned that no uniform, non-dilutive \"benchmark\" size for a governing body exists, making relief under Section 2 impossible. Another type of vote dilution may result from a jurisdiction's requirement that a candidate be elected by a majority vote. A majority-vote requirement may cause a minority group's candidate of choice, who would have won the election with a simple plurality of votes, to lose after a majority of voters unite behind another candidate in a runoff election. The Supreme Court has not addressed whether such claims may be brought under Section 2, and lower courts have reached different conclusions on the issue.\nIn addition to claims of vote dilution, courts have considered vote denial claims brought under Section 2. The Supreme Court, in \"Richardson v. Ramirez\" (1974), held that felony disenfranchisement laws cannot violate Section 2 because, among other reasons, Section 2 of the Fourteenth Amendment permits such laws. A federal district court in Mississippi held that a \"dual registration\" system that requires a person to register to vote separately for state elections and local elections may violate Section 2 if the system has a racially disparate impact in light of the Senate Factors. Starting in 2013, lower federal courts began to consider various challenges to voter ID laws brought under Section 2.\nSpecific prohibitions.\nThe act contains several specific prohibitions on conduct that may interfere with a person's ability to cast an effective vote. One of these prohibitions is prescribed in Section 201, which prohibits any jurisdiction from requiring a person to comply with any \"test or device\" to register to vote or cast a ballot. The term \"test or device\" is defined as literacy tests, educational or knowledge requirements, proof of good moral character, and requirements that a person be vouched for when voting. Before the Act's enactment, these devices were the primary tools used by jurisdictions to prevent racial minorities from voting. Originally, the Act suspended tests or devices temporarily in jurisdictions covered by the Section 4(b) coverage formula, but Congress subsequently expanded the prohibition to the entire country and made it permanent. Relatedly, Section 202 prohibits jurisdictions from imposing any \"durational residency requirement\" that requires persons to have lived in the jurisdiction for more than 30 days before being eligible to vote in a presidential election.\nSeveral further protections for voters are contained in Section 11. Section 11(a) prohibits any person acting under color of law from refusing or failing to allow a qualified person to vote or to count a qualified voter's ballot. Similarly, Section 11(b) prohibits any person from intimidating, harassing, or coercing another person for voting or attempting to vote. Two provisions in Section 11 address voter fraud: Section 11(c) prohibits people from knowingly submitting a false voter registration application to vote in a federal election, and Section 11(e) prohibits voting twice in a federal election.\nFinally, under Section 208, a jurisdiction may not prevent anyone who is English-illiterate or has a disability from being accompanied into the ballot box by an assistant of the person's choice. The only exceptions are that the assistant may not be an agent of the person's employer or union.\nBail-in.\nSection 3(c) contains a \"bail-in\" or \"pocket trigger\" process by which jurisdictions that fall outside the coverage formula of Section 4(b) may become subject to preclearance. Under this provision, if a jurisdiction has racially discriminated against voters in violation of the Fourteenth or Fifteenth Amendments, a court may order the jurisdiction to have future changes to its election laws preapproved by the federal government. Because courts have interpreted the Fourteenth and Fifteenth Amendments to prohibit only intentional discrimination, a court may bail in a jurisdiction only if the plaintiff proves that the jurisdiction enacted or operated a voting practice to purposely discriminate.\nSection 3(c) contains its own preclearance language and differs from Section 5 preclearance in several ways. Unlike Section 5 preclearance, which applies to a covered jurisdiction until such time as the jurisdiction may bail out of coverage under Section 4(a), bailed-in jurisdictions remain subject to preclearance for as long as the court orders. Moreover, the court may require the jurisdiction to preclear only particular types of voting changes. For example, the bail-in of New Mexico in 1984 applied for 10 years and required preclearance of only redistricting plans. This differs from Section 5 preclearance, which requires a covered jurisdiction to preclear all of its voting changes.\nDuring the Act's early history, Section 3(c) was little used; no jurisdictions were bailed in until 1975. Between 1975 and 2013, 18 jurisdictions were bailed in, including 16 local governments and the states of Arkansas and New Mexico. Although the Supreme Court held the Section 4(b) coverage formula unconstitutional in \"Shelby County v. Holder\" (2013), it did not hold Section 3(c) unconstitutional. Therefore, jurisdictions may continue to be bailed-in and subjected to Section 3(c) preclearance. In the months following \"Shelby County\", courts began to consider requests by the attorney general and other plaintiffs to bail in the states of Texas and North Carolina, and in January 2014 a federal court bailed in Evergreen, Alabama.\nA more narrow bail-in process pertaining to federal observer certification is prescribed in Section 3(a). Under this provision, a federal court may certify a non-covered jurisdiction to receive federal observers if the court determines that the jurisdiction violated the voting rights guaranteed by the Fourteenth or Fifteenth Amendments. Jurisdictions certified to receive federal observers under Section 3(a) are not subject to preclearance.\nSpecial provisions.\nCoverage formula.\nSection 4(b) contains a \"coverage formula\" that determines which states and local governments may be subjected to the Act's other special provisions (except for the Section 203(c) bilingual election requirements, which fall under a different formula). Congress intended for the coverage formula to encompass the most pervasively discriminatory jurisdictions. A jurisdiction is covered by the formula if:\nAs originally enacted, the coverage formula contained only November 1964 triggering dates; subsequent revisions to the law supplemented it with the additional triggering dates of November 1968 and November 1972, which brought more jurisdictions into coverage. For purposes of the coverage formula, the term \"test or device\" includes the same four devices prohibited nationally by Section 201\u2014literacy tests, educational or knowledge requirements, proof of good moral character, and requirements that a person be vouched for when voting\u2014and one further device defined in Section 4(f)(3): in jurisdictions where more than five percent of the citizen voting age population are members of a single language minority group, any practice or requirement by which registration or election materials are provided only in English. The types of jurisdictions that the coverage formula applies to include states and \"political subdivisions\" of states. Section 14(c)(2) defines \"political subdivision\" to mean any county, parish, or \"other subdivision of a State which conducts registration for voting.\"\nAs Congress added new triggering dates to the coverage formula, new jurisdictions were brought into coverage. The 1965 coverage formula included the whole of Alabama, Alaska, Georgia, Louisiana, Mississippi, South Carolina, and Virginia; and some subdivisions (mostly counties) in Arizona, Hawaii, Idaho, and North Carolina. The 1968 coverage resulted in the partial coverage of Alaska, Arizona, California, Connecticut, Idaho, Maine, Massachusetts, New Hampshire, New York, and Wyoming. Connecticut, Idaho, Maine, Massachusetts, and Wyoming filed successful \"bailout\" lawsuits, as also provided by section 4. The 1972 coverage covered the whole of Alaska, Arizona, and Texas, and parts of California, Florida, Michigan, New York, North Carolina, and South Dakota.\nThe special provisions of the Act were initially due to expire in 1970, and Congress renewed them for another five years. In 1975, the Act's special provisions were extended for another seven years. In 1982, the coverage formula was extended again, this time for 25 years, but no changes were made to the coverage formula, and in 2006, the coverage formula was again extended for 25 years.\nThroughout its history, the coverage formula remained controversial because it singled out certain jurisdictions for scrutiny, most of which were in the Deep South. In \"Shelby County v. Holder\" (2013), the Supreme Court declared the coverage formula unconstitutional because the criteria used were outdated and thus violated principles of equal state sovereignty and federalism. The other special provisions that are dependent on the coverage formula, such as the Section 5 preclearance requirement, remain valid law. However, without a valid coverage formula, these provisions are unenforceable.\nPreclearance requirement.\nSection 5 requires that covered jurisdictions receive federal approval, known as \"preclearance\", before implementing changes to their election laws. A covered jurisdiction has the burden of proving that the change does not have the purpose or effect of discriminating on the basis of race or language minority status; if the jurisdiction fails to meet this burden, the federal government will deny preclearance and the jurisdiction's change will not go into effect. The Supreme Court broadly interpreted Section 5's scope in \"Allen v. State Board of Election\" (1969), holding that any change in a jurisdiction's voting practices, even if minor, must be submitted for preclearance. The court also held that if a jurisdiction fails to have its voting change precleared, private plaintiffs may sue the jurisdiction in the plaintiff's local district court before a three-judge panel. In these Section 5 \"enforcement actions\", a court considers whether the jurisdiction made a covered voting change, and if so, whether the change had been precleared. If the jurisdiction improperly failed to obtain preclearance, the court will order the jurisdiction to obtain preclearance before implementing the change. However, the court may not consider the merits of whether the change should be approved.\nJurisdictions may seek preclearance through either an \"administrative preclearance\" process or a \"judicial preclearance\" process. If a jurisdiction seeks administrative preclearance, the attorney general will consider whether the proposed change has a discriminatory purpose or effect. After the jurisdiction submits the proposed change, the attorney general has 60 days to interpose an objection to it. The 60-day period may be extended an additional 60 days if the jurisdiction later submits additional information. If the attorney general interposes an objection, then the change is not precleared and may not be implemented. The attorney general's decision is not subject to judicial review, but if the attorney general interposes an objection, the jurisdiction may independently seek judicial preclearance, and the court may disregard the attorney general's objection at its discretion. If a jurisdiction seeks judicial preclearance, it must file a declaratory judgment action against the attorney general in the U.S. District Court for D.C. A three-judge panel will consider whether the voting change has a discriminatory purpose or effect, and the losing party may appeal directly to the Supreme Court. Private parties may intervene in judicial preclearance lawsuits.\nIn several cases, the Supreme Court has addressed the meaning of \"discriminatory effect\" and \"discriminatory purpose\" for Section 5 purposes. In \"Beer v. United States\" (1976), the court held that for a voting change to have a prohibited discriminatory effect, it must result in \"retrogression\" (backsliding). Under this standard, a voting change that causes discrimination, but does not result in \"more\" discrimination than before the change was made, cannot be denied preclearance for having a discriminatory effect. For example, replacing a poll tax with an equally expensive voter registration fee is not a \"retrogressive\" change because it causes equal discrimination, not more. Relying on the Senate report for the Act, the court reasoned that the retrogression standard was the correct interpretation of the term \"discriminatory effect\" because Section 5's purpose is \" 'to insure that [the gains thus far achieved in minority political participation] shall not be destroyed through new [discriminatory] procedures' \". The retrogression standard applies irrespective of whether the voting change allegedly causes vote denial or vote dilution.\nIn 2003, the Supreme Court held in \"Georgia v. Ashcroft\" that courts should not determine that a new redistricting plan has a retrogressive effect solely because the plan decreases the number of minority-majority districts. The court emphasized that judges should analyze various other factors under the \"totality of the circumstances\", such as whether the redistricting plan increases the number of \"influence districts\" in which a minority group is large enough to influence (but not decide) election outcomes. In 2006, Congress overturned this decision by amending Section 5 to explicitly state that \"diminishing the ability [of a protected minority] to elect their preferred candidates of choice denies or abridges the right to vote within the meaning of\" Section 5. Uncertainty remains as to what this language precisely means and how courts may interpret it.\nBefore 2000, the \"discriminatory purpose\" prong of Section 5 was understood to mean \"any\" discriminatory purpose, which is the same standard used to determine whether discrimination is unconstitutional. In \"Reno v. Bossier Parish\" (\"Bossier Parish II\") (2000), the Supreme Court extended the retrogression standard, holding that for a voting change to have a \"discriminatory purpose\" under Section 5, the change must have been implemented for a \"retrogressive\" purpose. Therefore, a voting change intended to discriminate against a protected minority was permissible under Section 5 so long as the change was not intended to increase existing discrimination. This change significantly reduced the number of instances in which preclearance was denied based on discriminatory purpose. In 2006, Congress overturned \"Bossier Parish II\" by amending Section 5 to explicitly define \"purpose\" to mean \"any discriminatory purpose.\"\nFederal examiners and observers.\nUntil the 2006 amendments to the Act, Section 6 allowed the appointment of \"federal examiners\" to oversee certain jurisdictions' voter registration functions. Federal examiners could be assigned to a covered jurisdiction if the attorney general certified that\nFederal examiners had the authority to register voters, examine voter registration applications, and maintain voter rolls. The goal of the federal examiner provision was to prevent jurisdictions from denying protected minorities the right to vote by engaging in discriminatory behavior in the voter registration process, such as refusing to register qualified applicants, purging qualified voters from the voter rolls, and limiting the hours during which persons could register. Federal examiners were used extensively in the years following the Act's enactment, but their importance waned over time; 1983 was the last year that a federal examiner registered a person to vote. In 2006, Congress repealed the provision.\nUnder the Act's original framework, in any jurisdiction certified for federal examiners, the attorney general could additionally require the appointment of \"federal observers\". By 2006, the federal examiner provision was used solely as a means to appoint federal observers. When Congress repealed the federal examiner provision in 2006, Congress amended Section 8 to allow for the assignment of federal observers to jurisdictions that satisfied the same certification criteria that had been used to appoint federal examiners.\nFederal observers are tasked with observing poll worker and voter conduct at polling places during an election and observing election officials tabulate the ballots. The goal of the federal observer provision is to facilitate minority voter participation by deterring and documenting instances of discriminatory conduct in the election process, such as election officials denying qualified minority persons the right to cast a ballot, intimidation or harassment of voters on election day, or improper vote counting. Discriminatory conduct that federal observers document may also serve as evidence in subsequent enforcement lawsuits. Between 1965 and the Supreme Court's 2013 decision in \"Shelby County v. Holder\" to strike down the coverage formula, the attorney general certified 153 local governments across 11 states. Because of time and resource constraints, federal observers are not assigned to every certified jurisdiction for every election. Separate provisions allow for a certified jurisdiction to \"bail out\" of its certification.\nBailout.\nUnder Section 4(a), a covered jurisdiction may seek exemption from coverage through a process called \"bailout.\" To achieve an exemption, a covered jurisdiction must obtain a declaratory judgment from a three-judge panel of the District Court for D.C. that the jurisdiction is eligible to bail out. As originally enacted, a covered jurisdiction was eligible to bail out if it had not used a test or device with a discriminatory purpose or effect during the 5 years preceding its bailout request. Therefore, a jurisdiction that requested to bail out in 1967 would have needed to prove that it had not misused a test or device since at least 1962. Until 1970, this effectively required a covered jurisdiction to prove that it had not misused a test or device since before the Act was enacted five years earlier in 1965, making it impossible for many covered jurisdictions to bail out. However, Section 4(a) also prohibited covered jurisdictions from using tests or devices in any manner, discriminatory or otherwise; hence, under the original act, a covered jurisdiction would become eligible for bailout in 1970 by simply complying with this requirement. But in the course of amending the Act in 1970 and 1975 to extend the special provisions, Congress also extended the period of time that a covered jurisdiction must not have misused a test or device to 10 years and then to 17 years, respectively. These extensions continued the effect of requiring jurisdictions to prove that they had not misused a test or device since before the Act's enactment in 1965.\nIn 1982, Congress amended Section 4(a) to make bailout easier to achieve in two ways. First, Congress provided that if a state is covered, local governments in that state may bail out even if the state is ineligible to bail out. Second, Congress liberalized the eligibility criteria by replacing the 17-year requirement with a new standard, allowing a covered jurisdiction to bail out by proving that in the 10 years preceding its bailout request:\nAdditionally, Congress required jurisdictions seeking bailout to produce evidence of minority registration and voting rates, including how these rates have changed over time and in comparison to the registration and voting rates of the majority. If the court determines that the covered jurisdiction is eligible for bailout, it will enter a declaratory judgment in the jurisdiction's favor. The court will retain jurisdiction for the following 10 years and may order the jurisdiction back into coverage if the jurisdiction subsequently engages in voting discrimination.\nThe 1982 amendment to the bailout eligibility standard went into effect on August 5, 1984. Between that date and 2013, 196 jurisdictions bailed out of coverage through 38 bailout actions; in each instance, the attorney general consented to the bailout request. Between that date and 2009, all jurisdictions that bailed out were located in Virginia. In 2009, a municipal utility jurisdiction in Texas bailed out after the Supreme Court's opinion in \"Northwest Austin Municipal Utility District No. 1 v. Holder\" (2009), which held that local governments that do not register voters have the ability to bail out. After this ruling, jurisdictions succeeded in at least 20 bailout actions before the Supreme Court held in \"Shelby County v. Holder\" (2013) that the coverage formula was unconstitutional.\nSeparate provisions allow a covered jurisdiction that has been certified to receive federal observers to bail out of its certification alone. Under Section 13, the attorney general may terminate the certification of a jurisdiction if 1) more than 50 percent of the jurisdiction's minority voting age population is registered to vote, and 2) there is no longer reasonable cause to believe that residents may experience voting discrimination. Alternatively, the District Court for D.C. may order the certification terminated.\nBilingual election requirements.\nTwo provisions require certain jurisdictions to provide election materials to voters in multiple languages: Section 4(f)(4) and Section 203(c). A jurisdiction covered by either provision must provide all materials related to an election\u2014such as voter registration materials, ballots, notices, and instructions\u2014in the language of any applicable language minority group residing in the jurisdiction. Language minority groups protected by these provisions include Asian Americans, Hispanics, Native Americans, and Native Alaskans. Congress enacted the provisions to break down language barriers and combat pervasive language discrimination against the protected groups.\nSection 4(f)(4) applies to any jurisdiction encompassed by the Section 4(b) coverage formula where more than five percent of the citizen voting age population are members of a single language minority group. Section 203(c) contains a formula that is separate from the Section 4(b) coverage formula, and therefore jurisdictions covered solely by 203(c) are not subject to the Act's other special provisions, such as preclearance. The Section 203(c) formula encompasses jurisdictions where the following conditions exist:\nSection 203(b) defines \"limited-English proficient\" as being \"unable to speak or understand English adequately enough to participate in the electoral process\". Determinations as to which jurisdictions satisfy the Section 203(c) criteria occur once a decade following completion of the decennial census; at these times, new jurisdictions may come into coverage while others may have their coverage terminated. Additionally, under Section 203(d), a jurisdiction may \"bail out\" of Section 203(c) coverage by proving in federal court that no language minority group within the jurisdiction has an English illiteracy rate that is higher than the national illiteracy rate. After the 2010 census, 150 jurisdictions across 25 states were covered under Section 203(c), including statewide coverage of California, Texas, and Florida.\nImpact.\n\"The Voting Rights Act had an immediate impact. By the end of 1965, a quarter of a million new Black voters had been registered, one-third by federal examiners. By the end of 1966, only four out of 13 southern states had fewer than 50 percent of African Americans registered to vote.\" After its enactment in 1965, the law immediately decreased racial discrimination in voting. The suspension of literacy tests and the assignments of federal examiners and observers allowed for high numbers of racial minorities to register to vote. Nearly 250,000 African Americans registered in 1965, one-third of whom were registered by federal examiners. In covered jurisdictions, less than one-third (29.3 percent) of the African American population was registered in 1965; by 1967, this number increased to more than half (52.1 percent), and a majority of African American residents became registered to vote in 9 of the 13 Southern states. Similar increases were seen in the number of African Americans elected to office: between 1965 and 1985, African Americans elected as state legislators in the 11 former Confederate states increased from 3 to 176. Nationwide, the number of African American elected officials increased from 1,469 in 1970 to 4,912 in 1980. By 2011, the number was approximately 10,500. Similarly, registration rates for language minority groups increased after Congress enacted the bilingual election requirements in 1975 and amended them in 1992. In 1973, the percent of Hispanics registered to vote was 34.9 percent; by 2006, that amount nearly doubled. The number of Asian Americans registered to vote in 1996 increased 58 percent by 2006.\nAfter the Act's initial success in combating tactics designed to deny minorities access to the polls, the Act became predominately used as a tool to challenge racial vote dilution. Starting in the 1970s, the attorney general commonly raised Section 5 objections to voting changes that decreased the effectiveness of racial minorities' votes, including discriminatory annexations, redistricting plans, and election methods such as at-large election systems, runoff election requirements, and prohibitions on bullet voting. In total, 81 percent (2,541) of preclearance objections made between 1965 and 2006 were based on vote dilution. Claims brought under Section 2 have also predominately concerned vote dilution. Between the 1982 creation of the Section 2 results test and 2006, at least 331 Section 2 lawsuits resulted in published judicial opinions. In the 1980s, 60 percent of Section 2 lawsuits challenged at-large election systems; in the 1990s, 37.2 percent challenged at-large election systems and 38.5 percent challenged redistricting plans. Overall, plaintiffs succeeded in 37.2 percent of the 331 lawsuits, and they were more likely to succeed in lawsuits brought against covered jurisdictions.\nBy enfranchising racial minorities, the Act facilitated a political realignment of the Democratic and Republican parties. Between 1890 and 1965, Black disenfranchisement enabled the Democratic Party to dominate Southern politics. After Johnson signed the Act into law, newly enfranchised Black voters began to push the Democratic Party to the left throughout the South; this in turn pushed Southern white conservatives to switch their support from the Democratic to Republican party. This trend caused the two parties to ideologically polarize, with the Democratic Party becoming more Liberal and the Republican Party becoming more Conservative. The trends also created competition between the two parties, which Republicans capitalized on by implementing the Southern strategy. Over the subsequent decades, the creation of majority-minority districts to remedy racial vote dilution claims also contributed to these developments. By packing liberal-leaning racial minorities into small numbers of majority-minority districts, large numbers of surrounding districts became more solidly white, conservative, and Republican. While this increased the elected representation of racial minorities as intended, it also decreased white Democratic representation and increased the representation of Republicans overall. By the mid-1990s, these trends culminated in a political realignment: the Democratic Party and the Republican Party became more ideologically polarized and defined as liberal and conservative parties, respectively; and both parties came to compete for electoral success in the South, with the Republican Party controlling most of Southern politics.\nResearch shows that the Act successfully and massively increased voter turnout and voter registration, in particular among African Americans. The act has also been linked to concrete outcomes, such as greater public goods provision (such as public education) for areas with higher black population shares and more members of Congress who vote for civil rights-related legislation. A 2016 study in the \"American Journal of Political Science\" found \"that members of Congress who represented jurisdictions subject to the preclearance requirement were substantially more supportive of civil rights-related legislation than legislators who did not represent covered jurisdictions.\" A 2013 \"Quarterly Journal of Economics\" study found that the Act boosted voter turnout and increases in public goods transfers from state governments to localities with higher black population. A 2018 study in \"The Journal of Politics\" found that Section 5 of the 1965 Voting Rights Act \"increased black voter registration by 14\u201319 percentage points, white registration by 10\u201313 percentage points, and overall voter turnout by 10\u201319 percentage points. Additional results for Democratic vote share suggest that some of this overall increase in turnout may have come from reactionary whites.\" A 2019 study in the \"American Economic Journal\" found that preclearance substantially increased turnout among minorities, even as far as to 2012 (the year prior to the Supreme Court ruling ending preclearance). The study estimates that preclearance led to an increase in minority turnout of 17 percentage points. A 2020 study found that the jurisdictions which had previously been covered by preclearance massively increased the rate of voter registration purges after the 2013 United States Supreme Court \"Shelby County v. Holder\" decision in which the \"coverage formula\" in Section 4(b) of the VRA that determined which jurisdictions had to presubmit changes in their election policies for federal approval was struck down. Another 2020 study found that VRA coverage halved the incidence and the onset of political violence.\nIn a 5\u20134 decision in \"Shelby County v. Holder\" (2013), the Supreme Court struck down Section 4(b) as unconstitutional. The court reasoned that the coverage formula violates the constitutional principles of \"equal sovereignty of the states\" and federalism because its disparate treatment of the states is \"based on 40 year-old facts having no logical relationship to the present day\", rendering the formula outdated. The court did not strike down Section 5, but without Section 4(b), no jurisdiction may be subject to Section 5 preclearance unless Congress enacts a new coverage formula. After the decision, several states that were fully or partially covered\u2014including Texas, Mississippi, North Carolina, and South Carolina\u2014implemented laws that were previously denied preclearance. This prompted new legal challenges to these laws under other provisions unaffected by the court's decision, such as Section 2. Research has shown that the coverage formula and the requirement of preclearance substantially increased turnout among racial minorities, even as far as the year before \"Shelby County\". Some jurisdictions that had previously been covered by the coverage formula increased the rate of voter registration purges after \"Shelby County\". On July 1, 2021, the Act's preclearance requirements were further weakened at the state and local level following the \" Brnovich v. Democratic National Committee\" in a 6-3 Supreme Court ruling which held that Section 2 preclearance provisions could not apply to out-of-precinct voting or ballot collecting.\nCivil Rights Act of 1968.\nThe Civil Rights Act of 1968 () is a landmark law in the United States signed into law by United States President Lyndon B. Johnson during the King assassination riots.\nTitles II through VII comprise the Indian Civil Rights Act, which applies to the Native American tribes of the United States and makes many but not all of the guarantees of the U.S. Bill of Rights applicable within the tribes. (That Act appears today in Title 25, sections 1301 to 1303 of the United States Code).\nTitles VIII and IX are commonly known as the Fair Housing Act, which was meant as a follow-up to the Civil Rights Act of 1964. (This is different legislation than the Housing and Urban Development Act of 1968, which expanded housing funding programs.) While the Civil Rights Act of 1866 prohibited discrimination in housing, there were no federal enforcement provisions. The 1968 act expanded on previous acts and prohibited discrimination concerning the sale, rental, and financing of housing based on race, religion, national origin, and since 1974, sex. Since 1988, the act protects people with disabilities and families with children. Pregnant women are also protected from illegal discrimination because they have been given familial status with their unborn child being the other family member. Victims of discrimination may use both the 1968 act and the 1866 act's section 1983 to seek redress. The 1968 act provides for federal solutions while the 1866 act provides for private solutions (i.e.,\u00a0civil suits). The act also made it a federal crime to \"by force or by threat of force, injure, intimidate, or interfere with anyone... by reason of their race, color, religion, or national origin, handicap or familial status.\"\nTitle X, commonly known as the Anti-Riot Act, makes it a felony to \"travel in interstate commerce...with the intent to incite, promote, encourage, participate in and carry on a riot.\" That provision has been criticized for \"equating organized political protest with organized violence.\"\nLegislative history and components.\nIn 1966, President Johnson proposed a new civil rights bill, but it was not passed through by the Senate. On February 17, 1967, the bill was introduced in the House by Rep. Manny Celler and in the Senate by Senator Philip A. Hart.\nThe House Judiciary Committee cleared HR 2516 (civil rights bill) and HR 10805 (extended life of Civil Rights Commission for another five years). House Judiciary Subcommittee No. 5 June 22 approved a package combining HR 2516 and HR 421 (Administration bill) in order to strengthen protections for civil rights workers.\nThe initial vote in the House of Representatives was 327\u201392 (161\u201325 in the House Republican Conference and 166\u201367 in the House Democratic Caucus) with 12 members voting present or abstaining, while in the Senate the final vote with amendments was 71\u201320 (29\u20133 in the Senate Republican Conference and 42\u201317 in the Senate Democratic Caucus) with 5 members voting present or abstaining. The House agreed to the Senate amendments by a vote of 250\u2013172 (100\u201384 in the House Republican Conference and 150\u201388 in the House Democratic Caucus) with 10 members voting present or abstaining.\nBill H.R. 2516 was passed by the 90th United States Congress and signed by the 36th President of the United States, Lyndon B. Johnson on April 11, 1968.\nTitle I: Hate crimes.\nThe Civil Rights Act of 1968 also enacted (b)(2), which permits federal prosecution of anyone who \"willingly injures, intimidates or interferes with another person, or attempts to do so, by force because of the other person's race, color, religion or national origin\" because of the victim's attempt to engage in one of six types of federally protected activities, such as attending school, patronizing a public place/facility, applying for employment, acting as a juror in a state court or voting.\nPersons violating this law face a fine or imprisonment of up to one year or both. If bodily injury results or if such acts of intimidation involve the use of firearms, explosives or fire, individuals can receive prison terms of up to 10 years, while crimes involving kidnapping, sexual assault, or murder can be punishable by life in prison or the death penalty.\nThough sexual orientation and gender identity were also excluded from this law, they are included in a more recent Federal hate-crime law, the Matthew Shepard and James Byrd, Jr. Hate Crimes Prevention Act.\nTitle II\u2013VII: Indian Civil Rights Act.\nThe Indian Civil Rights Act of 1968 granted Native Americans full access to the United States Bill of Rights. The first minor section focuses on re-establishing amendments now granted to Native Americans. The main portion of the section focuses on Native Americans in the United States legal system. The last section of this act points out other materials related to more constitutional rights of Native Americans, such as the \"Indian Affairs, Laws and Treaties\" doctrine.\nTitle VIII\u2013IX: Fair Housing Act.\nHousing discrimination.\nTitle VIII of the Civil Rights Act of 1968 is commonly referred to as the Fair Housing Act of 1968. Since 1968 its protections have been expanded significantly by amendment. The Office of Fair Housing and Equal Opportunity within the U.S. Department of Housing and Urban Development is charged with administering and enforcing this law.\nTypes of banned discrimination.\nThe Civil Rights Act of 1968 prohibited the following forms of housing discrimination:\nTypes of allowed discrimination.\nOnly certain kinds of discrimination are covered by fair housing laws. Landlords are not required by law to rent to any tenant who applies for a property. Landlords can select tenants based on objective business criteria, such as the applicant's ability to pay the rent and take care of the property. Landlords can lawfully discriminate against tenants with bad credit histories or low incomes, and (except in some areas) do not have to rent to tenants who will be receiving Section 8 vouchers. Landlords must be consistent in the screening, treat tenants who are inside and outside the protected classes in the same manner, and should document any legitimate business reason for not renting to a prospective tenant.\nThe United States Department of Housing and Urban Development has stated that buyers and renters may discriminate and may request real estate agents representing them to limit home searches to parameters that are discriminatory. The primary purpose of the Fair Housing Act is to protect the buyer's (and renter's) right to seek a dwelling anywhere they choose. It protects the buyer's right to discriminate by prohibiting certain discriminatory acts by sellers, landlords, and real estate agents.\nPeople with disabilities.\nThe Fair Housing Act defines a person with a disability in the same manner as the Americans with Disabilities Act \u2013 \"a person with a physical or mental impairment which substantially limits one or more major life activities; a record of such an impairment; or being regarded as having such an impairment.\" \nThe Fair Housing Act provides several specific protections for buyers and tenants with disabilities. Landlords and sellers cannot make a dwelling unit unavailable or deny a dwelling to a buyer or renter because of their disability or the disability of any person who intends to reside in the dwelling or because of the disability of anyone with whom they are associated. Landlords cannot deny a person with a disability all of the privileges provided in connection with the dwelling, because of the person's disability.\nThe Fair Housing Act (FHA) provides some specific protections for people with disabilities that facilitate independence and community living. First, the FHA allows tenants to make reasonable modifications to the existing premises. It makes it illegal for landlords to not allow people with disabilities to make reasonable modifications to the premises, at their own expense, if they need the modification to have full enjoyment of the premises. For example, an individual with a disability may require grab bars installed in order to have access to take a shower. The landlord must allow the tenant to install the grab bars to allow access to take a shower. However, technically, the landlord may require the tenant remove the grab bars at the end of the tenancy, at the tenant's own expense. However, the regulations specify that in rental housing, a landlord may not condition widening a bathroom doorway to provide wheelchair access, to its return to its former narrow state upon the end of the tenancy, since it will not interfere with the next tenants use and enjoyment of the premises.\nThe second protection offered by the FHA includes the requirement that no one can refuse to make reasonable accommodations to \"rules, policies, practices, or services, when the accommodation is necessary to afford\" a person with a disability \"equal opportunity to use and enjoy a dwelling unit,\" including the amenities of the dwelling, which may involve common areas. For example, a building with a \"No Pets\" policy would violate the FHA if it did not allow a blind person to have their seeing eye dog live with them as a reasonable accommodation to the policy. Similarly, a wheelchair user could request an assigned, accessible parking space as a reasonable accommodation in a \"first come first serve\" parking lot attached to an apartment complex.\nTitle X: Anti-Riot Act.\nThe Act included the \"Anti-Riot Act,\" enacted at (with its key terms, \"riot\" and \"incite a riot,\" defined in ), which makes it a federal crime to use interstate or foreign commerce routes or facilities (such as by crossing state lines or through mail, use of the Internet, or phone calls) to incite a riot, organize, promote or participate in a riot or to extend activities of a riot, or to aid and abet any person performing such activities. The provision has been informally referred to as the \"H. Rap Brown Law\" since the arrest and trial of H. Rap Brown in 1967 for carrying a gun across state lines. Rulings by the 4th Circuit in 2020 and 9th Circuit in 2021 struck down in those circuits the portions of the law which prohibit \"urging\" a riot on the grounds of freedom of speech, leaving in place bans on inciting and participation in riots.\nCivil Rights Restoration Act of 1987.\nThe Civil Rights Restoration Act of 1987, or'Grove City Bill, is a United States legislative act that specifies that entities receiving federal funds must comply with civil rights legislation in all of their operations, not just in the program or activity that received the funding. The Act overturned the precedent set by the Supreme Court decision in \"Grove City College v. Bell\", 465 U.S. 555 (1984), which held that only the particular program in an educational institution receiving federal financial assistance was required to comply with the anti-discrimination provisions of Title IX of the Education Amendments of 1972, not the institution as a whole.\nThe Act was proposed as a response to the \"Grove City College v. Bell\" Supreme Court decision in 1984. The decision held that only the particular program in an educational institution receiving federal financial assistance was required to comply with anti-discrimination provisions of Title IX. This decision created loopholes for educational institutions to continue discriminatory practices in other areas, which had a significant impact on minority communities, women, and people with disabilities.\nLegislative history.\nThe Act was first passed by the House in June 1984 (375\u201332) but stalled for several years after divisions over its potential effects on Title IX regulations prohibiting discrimination relating to abortion impeded the effectiveness of a civil rights coalition. In January 1988, the Senate accepted an amendment by Senator John Danforth (R-MO). He is described as \"abortion neutral\" and clarified that the Act does not impose a requirement for entities receiving federal funding to pay or provide for abortions and that it prohibits discrimination against women who use or seek abortion services. The amendment was opposed by the National Organization for Women and other pro-choice groups but ultimately resulted in passage of the bill in both the House and the Senate.\nThe final vote in the Senate, on January 28, 1988, was 75\u201314 (48\u20130 in the Senate Democratic Caucus and 27\u201314 in the Senate Republican Conference), with 11 members voting present or abstaining. The final vote in the House of Representatives on March 2, 1988, was 315\u201398 (242\u20134 in the House Democratic Caucus and 73\u201394 in the House Republican Conference) with 20 members voting present or abstaining.\nOn March 16, 1988, President Ronald Reagan vetoed the bill by arguing that the Act represented an overexpansion of governmental power over private organizational decision-making and \"would diminish substantially the freedom and independence of religious institutions in our society.\" On March 22, 1988, the Senate overrode Reagan's veto by a vote of 73\u201324 (52\u20130 in the Senate Democratic Caucus and 21\u201324 in the Senate Republican Conference) with 3 members voting present or abstaining. On the same day, the House voted in favor of the bill with a vote of 292\u2013133 (240\u201310 in the House Democratic Caucus and 52\u2013123 in the House Republican Conference), with 7 members voting present or abstaining. Reagan's veto was the first veto of a civil rights act since Andrew Johnson vetoed the Civil Rights Act of 1866.\nProvisions.\nIn addition to Title IX of the Education Amendments of 1972 (which prohibits sex discrimination in educational institutions), the Act applies to the Rehabilitation Act of 1973 (which prohibits discrimination on the basis of disability), Title VI of the Civil Rights Act of 1964 (which prohibits racial discrimination), and the Age Discrimination in Employment Act of 1967 (which prohibits age discrimination in employment).\nWith the passage of the act, educational institutions receiving any federal funding were required to comply with all federal civil rights laws, including those relating to gender, race, and disability, throughout the institution (not only in the parts of the institution receiving the funding). The act also extended protection against discrimination in educational institutions to a wider range of individuals, including students, faculty, and staff.\nCivil Rights Act of 1990.\nThe Civil Rights Act of 1990' was a bill that, had it been signed into law, would have made it easier for litigants in race or sex discrimination cases to win. It was introduced into the 101st United States Congress on February 7, 1990, by Senator Edward Kennedy (D-MA) in the United States Senate, and by Augustus Hawkins (D-CA) in the House of Representatives. While making its way through Congress, the bill was considered to be civil rights groups' number one legislative priority. Soon before the bill made it to the desk of then-President of the United States George H. W. Bush, it was criticized by the Harvard Law School professor Charles Fried. In a \"New York Times\" op-ed, Fried (a ranking member of the Federalist Society who served as Solicitor General in the Reagan Administration from 1985-1989), wrote that descriptions of the bill as the most important civil rights legislation in a quarter-century were \"a public relations flimflam perpetrated by a cabal of overzealous civil rights plaintiffs' lawyers.\" He concluded by saying that Bush should \"veto this bill in its present form.\"\nOn October 22, 1990, President Bush vetoed the bill, claiming that it \"employs a maze of highly legalistic language to introduce the destructive force of quotas into our national employment system.\" The Bush administration argued that the bill's provisions were strict enough that they would give employers \"powerful incentives\" to adopt quotas. Supporters of the bill argued that, contrary to Bush's claims, the bill would not have led employers to adopt quotas. For example, Benjamin Hooks, the then-executive director of the NAACP, said he was \"at a loss\" as to why Bush described the legislation as a quota bill. Congress attempted to override his veto on October 24, but their attempt failed in the Senate by one vote to achieve the two-thirds majority required.\nThe Civil Rights Act of 1991 is a United States labor law, passed in response to United States Supreme Court decisions that limited the rights of employees who had sued their employers for discrimination. The Act represented the first effort since the passage of the Civil Rights Act of 1964 to modify some of the basic procedural and substantive rights provided by federal law in employment discrimination cases. It provided the right to trial by jury on discrimination claims and introduced the possibility of emotional distress damages and limited the amount that a jury could award. It added provisions to Title VII of the Civil Rights Act of 1964 protections expanding the rights of women to sue and collect compensatory and punitive damages for sexual discrimination or harassment. U.S. President George H. W. Bush had used his veto against the more comprehensive Civil Rights Act of 1990. He feared racial quotas would be imposed but later approved the 1991 version of the bill.\nThe 1991 Act was intended to strengthen the protections afforded by 2 different civil rights acts: the Civil Rights Act of 1866, better known by the number assigned to it in the codification of federal laws as Section 1981, and the employment-related provisions of the Civil Rights Act of 1964, generally referred to as Title VII. The two statutes, passed nearly a century apart, approached the issue of employment discrimination very differently: Section 1981 prohibited only discrimination based on race or color, but Title VII also prohibited discrimination on the basis of sex, religion, and national origin. Section 1981, which had lain dormant and unenforced for a century after its passage, allowed plaintiffs to seek compensatory damages and trial by jury. Title VII, passed in the 1960s when it was assumed that Southern juries could not render a fair verdict, allowed only trial by the court and provided for only traditional equitable remedies: back pay, reinstatement, and injunctions against future acts of discrimination. By the time the 1991 Act was passed, both allowed for an award of attorneys' fees. The 1991 Act expanded the remedies available to victims of discrimination by amending Title VII of the 1964 Act.\nBackground.\nCongress had amended Title VII once before, in 1972, when it broadened the coverage of the Act. It was moved to overhaul Title VII in 1991 and to harmonize it with Section 1981 jurisprudence, as a result of a series of controversial Supreme Court decisions:\nChanges.\n\"Patterson\" had attracted much criticism since it appeared to leave employees victimized by racial harassment on the job with no effective remedies, as they could not prove a violation of Section 1981 and could rarely show any wage losses that they could recover under Title VII. In addition, the Court's narrow reading of the phrase \"make or enforce contracts\" eliminated any liability under Section 1981 for lost promotions and most other personnel decisions that did not constitute a refusal to hire on the basis of race or color.\nCongress addressed the issue by redefining the phrase \"make and enforce contracts\" to include \"the making, performance, modification, and termination of contracts, and the enjoyment of all benefits, privileges, terms, and conditions of the contractual relationship.\" Congress also clarified that Section 1981 applied to both governmental and private discrimination, the issue that the Supreme Court originally announced it would decide in \"Patterson\".\nCongress also believed that the \"Wards Cove\" case made it too difficult to prove disparate impact claims under Title VII. While the amended Act still generally requires that a plaintiff identify particular employment practice(s) allegedly causing a disparate impact, Congress added that an employer's decisionmaking process may be analyzed as a whole if the plaintiff can show that \"the elements of [an employer's] decisionmaking process are not capable of separation for analysis.\" Congress also established that the employer has the burden of proof on the business necessity defense and restored the meaning of \"business necessity\" to how it was interpreted before \"Wards Cove\". Congress did not, however, alter the portion of \"Wards Cove\" describing the plaintiff's burden with respect to statistical proof, in which the court had held: \"The mere existence of a statistical imbalance in an employer's workforce on account of race, color, religion, sex, or national origin is not alone sufficient to establish a prima facie case of disparate impact violation.\"\nWhile the majority in Congress supported the burden-shifting rule in \"Price Waterhouse\", it was uncomfortable with how that case gave the employer the ability to prove that it would have made the same decision in any event, as a complete defense in a case in which it had been shown that race or gender or another unlawful factor played a significant role in its decision. Congress amended the Act to provide that the employer's proof that it would have made the same decision in any case was a defense to back pay, reinstatement and other remedies but not to liability \"per se\". The practical effect of this change was to allow a party that proved that the employer discriminated but could not show that it made any practical difference to the outcome could still recover attorney's fees after showing that the employer discriminated, even if no other remedy was awarded.\nFinally, Congress limited the rights of non-parties to attack consent decrees by barring any challenges by parties who knew or should have known of the decree or who were adequately represented by the original parties. The Act also authorized jury trials on Title VII claims and allowed Title VII plaintiffs to recover emotional distress and punitive damages, while imposing caps on such relief. The 1991 Act also made technical changes affecting the length of time allowed to challenge unlawful seniority provisions, to sue the federal government for discrimination, and to bring age discrimination claims, but it allowed successful plaintiffs to recover expert witness fees as part of an award of attorney's fees and to collect interest on any judgment against the federal government."}
{"id": "7491", "revid": "1272861700", "url": "https://en.wikipedia.org/wiki?curid=7491", "title": "Cola", "text": "Cola is a carbonated soft drink flavored with vanilla, cinnamon, citrus oils, and other flavorings. Cola became popular worldwide after the American pharmacist John Stith Pemberton invented Coca-Cola, a trademarked brand, in 1886, which was imitated by other manufacturers. Most colas originally contained caffeine from the kola nut (\"Cola acuminata\"), leading to the drink's name, though other sources of caffeine are generally used in modern formulations. The Pemberton cola drink also contained a coca plant extract. His non-alcoholic recipe was inspired by the coca wine of pharmacist Angelo Mariani, created in 1863.\nMost modern colas have a dark caramel color and are sweetened with sugar, high-fructose corn syrup or artificial sweeteners. They come in numerous different brands, with Coca-Cola and Pepsi being among the most popular. These two companies have been competing since the 1890s, a rivalry that has intensified since the 1980s.\nFlavorings.\nThe primary modern flavorings in a cola drink are citrus oils (from orange, lime, and lemon peels), cinnamon, vanilla, and an acidic flavoring. Manufacturers of cola drinks add trace flavorings to create distinctive tastes for each brand. Trace flavorings may include a wide variety of ingredients, such as spices like nutmeg or coriander. Acidity is often provided by phosphoric acid, sometimes accompanied by citric or other isolated acids. Coca-Cola's recipe is maintained as a corporate trade secret.\nA variety of different sweeteners may be used in cola, often influenced by local agricultural policy. High-fructose corn syrup (HFCS) is predominantly used in the United States due to the lower cost of government-subsidized corn. In Europe, however, HFCS is subject to production quotas designed to encourage the production of sugar; sugar is thus preferentially used to sweeten sodas. In addition, stevia or an artificial sweetener may be used; \"sugar-free\" or \"diet\" colas typically contain artificial sweeteners only.\nIn Japan, there is a burgeoning craft cola industry, with small-scale local production methods and highly unique cola recipes using locally sourced fruits, herbs, and spices.\nClear cola.\nIn the 1940s, Coca-Cola produced White Coke at the request of Marshal of the Soviet Union Georgy Zhukov.\nClear colas were again produced during the clear craze of the early 1990s. Brands included Crystal Pepsi, Tab Clear, and 7 Up Ice Cola. Crystal Pepsi was repeatedly reintroduced in the 2010s.\nIn Denmark, a popular clear cola was made by the Cooperative FDB in 1976. It was especially known for being the \"Hippie Cola\" because of the focus on the harmful effects the color additive could have on children and the boycott of multinational brands. It was inspired by a campaign on harmful additives in Denmark by the Environmental-Organization NOAH, an independent Danish division of Friends of the Earth. This was followed up with a variety of sodas without artificial coloring. Today many organic colas are available in Denmark, but, for nostalgic reasons, clear cola has still maintained its popularity to a certain degree.\nIn June 2018, Coca-Cola introduced Coca-Cola Clear in Japan.\nHealth effects.\nA 2007 study claimed that consumption of colas, both those with natural sweetening and those with artificial sweetening, was associated with an increased risk of chronic kidney disease. The phosphoric acid used in colas was thought to be a possible cause. A link has been shown between long-term regular cola intake and osteoporosis in older women (but not men). This was thought to be due to the presence of phosphoric acid, though the risk for women was found to be greater for sugared and caffeinated colas than diet and decaffeinated variants, with a higher intake of cola correlating with lower bone density.\nOne 2005 study indicated that soda and sweetened drinks are the main source of calories in the American diet and that of those who drink more sweetened drinks, obesity rates were higher. Most nutritionists advise that Coca-Cola and other soft drinks can be harmful if consumed excessively, particularly to young children whose soft drink consumption competes with, rather than complements, a balanced diet. Studies have shown that regular soft drink users have a lower intake of calcium, magnesium, vitamin C, riboflavin, and vitamin A.\nThe drink has also aroused criticism for its use of caffeine, which can cause physical dependence (caffeine dependence), and can reduce sleep quality.\nMany soft drinks in North America are sweetened mostly or entirely with high-fructose corn syrup (HFCS), rather than white sugar. Some nutritionists caution against the consumption of corn syrup because it may aggravate obesity and type-2 diabetes more than cane sugar. , there is no high-quality evidence that replacing cane sugar (sucrose) with HFCS causes any difference in health effects."}
{"id": "7492", "revid": "42195518", "url": "https://en.wikipedia.org/wiki?curid=7492", "title": "Capability Maturity Model", "text": "The Capability Maturity Model (CMM) is a development model created in 1986 after a study of data collected from organizations that contracted with the U.S. Department of Defense, who funded the research. The term \"maturity\" relates to the degree of formality and optimization of processes, from \"ad hoc\" practices, to formally defined steps, to managed result metrics, to active optimization of the processes.\nThe model's aim is to improve existing software development processes, but it can also be applied to other processes.\nIn 2006, the Software Engineering Institute at Carnegie Mellon University developed the Capability Maturity Model Integration, which has largely superseded the CMM and addresses some of its drawbacks.\nOverview.\nThe Capability Maturity Model was originally developed as a tool for objectively assessing the ability of government contractors' \"processes\" to implement a contracted software project. The model is based on the process maturity framework first described in \"IEEE Software\" and, later, in the 1989 book \"Managing the Software Process\" by Watts Humphrey. It was later published as an article in 1993\nand as a book by the same authors in 1994.\nThough the model comes from the field of software development, it is also used as a model to aid in business processes generally, and has also been used extensively worldwide in government offices, commerce, and industry.\nHistory.\nPrior need for software processes.\nIn the 1980s, the use of computers grew more widespread, more flexible and less costly. Organizations began to adopt computerized information systems, and the demand for software development grew significantly. Many processes for software development were in their infancy, with few standard or \"best practice\" approaches defined.\nAs a result, the growth was accompanied by growing pains: project failure was common, the field of computer science was still in its early years, and the ambitions for project scale and complexity exceeded the market capability to deliver adequate products within a planned budget. Individuals such as Edward Yourdon, Larry Constantine, Gerald Weinberg, Tom DeMarco, and David Parnas began to publish articles and books with research results in an attempt to professionalize the software-development processes.\nIn the 1980s, several US military projects involving software subcontractors ran over-budget and were completed far later than planned, if at all. In an effort to determine why this was occurring, the United States Air Force funded a study at the Software Engineering Institute (SEI).\nPrecursor.\nThe first application of a staged maturity model to IT was not by CMU/SEI, but rather by Richard L. Nolan, who, in 1973 published the stages of growth model for IT organizations.\nWatts Humphrey began developing his process maturity concepts during the later stages of his 27-year career at IBM.\nDevelopment at Software Engineering Institute.\nActive development of the model by the US Department of Defense Software Engineering Institute (SEI) began in 1986 when Humphrey joined the Software Engineering Institute located at Carnegie Mellon University in Pittsburgh, Pennsylvania after retiring from IBM. At the request of the U.S. Air Force he began formalizing his Process Maturity Framework to aid the U.S. Department of Defense in evaluating the capability of software contractors as part of awarding contracts.\nThe result of the Air Force study was a model for the military to use as an objective evaluation of software subcontractors' process capability maturity. Humphrey based this framework on the earlier Quality Management Maturity Grid developed by Philip B. Crosby in his book \"Quality is Free\". Humphrey's approach differed because of his unique insight that organizations mature their processes in stages based on solving process problems in a specific order. Humphrey based his approach on the staged evolution of a system of software development practices within an organization, rather than measuring the maturity of each separate development process independently. The CMMI has thus been used by different organizations as a general and powerful tool for understanding and then improving general business process performance.\nWatts Humphrey's Capability Maturity Model (CMM) was published in 1988 and as a book in 1989, in \"Managing the Software Process\".\nOrganizations were originally assessed using a process maturity questionnaire and a Software Capability Evaluation method devised by Humphrey and his colleagues at the Software Engineering Institute.\nThe full representation of the Capability Maturity Model as a set of defined process areas and practices at each of the five maturity levels was initiated in 1991, with Version 1.1 being published in July 1993.\nThe CMM was published as a book in 1994 by the same authors Mark C. Paulk, Charles V. Weber, Bill Curtis, and Mary Beth Chrissis.\nCapability Maturity Model Integration.\nThe CMMI model's application in software development has sometimes been problematic. Applying multiple models that are not integrated within and across an organization could be costly in training, appraisals, and improvement activities. The Capability Maturity Model Integration (CMMI) project was formed to sort out the problem of using multiple models for software development processes, thus the CMMI model has superseded the CMM model, though the CMM model continues to be a general theoretical process capability model used in the public domain.\nIn 2016, the responsibility for CMMI was transferred to the Information Systems Audit and Control Association (ISACA). ISACA subsequently released CMMI v2.0 in 2021. It was upgraded again to CMMI v3.0 in 2023. CMMI now places a greater emphasis on the process architecture which is typically realized as a process diagram. Copies of CMMI are available now only by subscription.\nAdapted to other processes.\nThe CMMI was originally intended as a tool to evaluate the ability of government contractors to perform a contracted software project. Though it comes from the area of software development, it can be, has been, and continues to be widely applied as a general model of the maturity of \"process\" (e.g., IT service management processes) in IS/IT (and other) organizations.\nModel topics.\nMaturity models.\nA maturity model can be viewed as a set of structured levels that describe how well the behaviors, practices and processes of an organization can reliably and sustainably produce required outcomes.\nA maturity model can be used as a benchmark for comparison and as an aid to understanding - for example, for comparative assessment of different organizations where there is something in common that can be used as a basis for comparison. In the case of the CMM, for example, the basis for comparison would be the organizations' software development processes.\nStructure.\nThe model involves five aspects:\nLevels.\nThere are five levels defined along the continuum of the model and, according to the SEI: \"Predictability, effectiveness, and control of an organization's software processes are believed to improve as the organization moves up these five levels. While not rigorous, the empirical evidence to date supports this belief\".\nWithin each of these maturity levels are Key Process Areas which characterise that level, and for each such area there are five factors: goals, commitment, ability, measurement, and verification. These are not necessarily unique to CMMI, representing \u2014 as they do \u2014 the stages that organizations must go through on the way to becoming mature.\nThe model provides a theoretical continuum along which process maturity can be developed incrementally from one level to the next. Skipping levels is not allowed/feasible.\nBetween 2008 and 2019, about 12% of appraisals given were at maturity levels 4 and 5.\nCritique.\nThe model was originally intended to evaluate the ability of government contractors to perform a software project. It has been used for and may be suited to that purpose, but critics pointed out that process maturity according to the CMM was not necessarily mandatory for successful software development.\nSoftware process framework.\nThe software process framework documented is intended to guide those wishing to assess an organization's or project's consistency with the Key Process Areas. For each maturity level there are five checklist types:"}
{"id": "7498", "revid": "1259674588", "url": "https://en.wikipedia.org/wiki?curid=7498", "title": "Centillion", "text": ""}
{"id": "7499", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=7499", "title": "RDX", "text": "RDX (abbreviation of \"Research Department eXplosive\" or Royal Demolition eXplosive) or hexogen, among other names, is an organic compound with the formula (CH2N2O2)3. It is white, odorless, and tasteless, widely used as an explosive. Chemically, it is classified as a nitroamine alongside HMX, which is a more energetic explosive than TNT. It was used widely in World War II and remains common in military applications.\nRDX is often used in mixtures with other explosives and plasticizers or phlegmatizers (desensitizers); it is the explosive agent in C-4 plastic explosive and a key ingredient in Semtex. It is stable in storage and is considered one of the most energetic and brisant of the military high explosives, with a relative effectiveness factor of 1.60.\nName.\nRDX is also less commonly known as cyclonite, hexogen (particularly in Russian, French and German-influenced languages), T4, and, chemically, as cyclotrimethylene trinitramine. In the 1930s, the Royal Arsenal, Woolwich, started investigating cyclonite to use against German U-boats that were being built with thicker hulls. The goal was to develop an explosive more energetic than TNT. For security reasons, Britain termed cyclonite \"Research Department Explosive\" (R.D.X.). The term \"RDX\" appeared in the United States in 1946. The first public reference in the United Kingdom to the name \"RDX\", or \"R.D.X.\", to use the official title, appeared in 1948; its authors were the managing chemist, ROF Bridgwater, the chemical research and development department, Woolwich, and the director of Royal Ordnance Factories, Explosives.\nUsage.\nRDX was widely used during World War II, often in explosive mixtures with TNT such as Torpex, Composition B, Cyclotols, and H6. RDX was used in one of the first plastic explosives. The bouncing bomb depth charges used in the \"Dambusters Raid\" each contained of Torpex; The Tallboy and Grand Slam bombs designed by Barnes Wallis also used Torpex.\nRDX is believed to have been used in many bomb plots, including terrorist plots.\nRDX is the base for a number of common military explosives:\nOutside military applications, RDX is also used in controlled demolition to raze structures. The demolition of the Jamestown Bridge in the U.S. state of Rhode Island was one instance where RDX shaped charges were used to remove the span.\nSynthesis.\nRDX is classified by chemists as a hexahydro-1,3,5-triazine derivative. In laboratory settings (industrial routes are described below separately) it is obtained by treating hexamine with white fuming nitric acid.\nThis nitrolysis reaction also produces methylene dinitrate, ammonium nitrate, and water as by-products. The overall reaction is:\nThe conventional cheap nitration agent, called \"mixed acid\", cannot be used for RDX synthesis because concentrated sulfuric acid conventionally used to stimulate the nitronium ion formation decomposes hexamine into formaldehyde and ammonia.\nModern syntheses employ hexahydro triacyl triazine as it avoids formation of HMX.\nHistory.\nRDX was used by both sides in World War II. The US produced about per month during WWII and Germany about per month. RDX had the major advantages of possessing greater explosive force than TNT and required no additional raw materials for its manufacture. Thus, it was also extensively used in World War I\nGermany.\nRDX was reported in 1898 by Georg Friedrich Henning (1863-1945), who obtained a German patent for its manufacture by nitrolysis of hexamine (hexamethylenetetramine) with concentrated nitric acid. In this patent, only the medical properties of RDX were mentioned.\nDuring WWI, Heinrich Brunswig (1865-1946) at the private military-industrial laboratory (Center for Scientific-Technical Research) in Neubabelsberg studied the compound more closely and in June 1916 filed two patent applications, one for its use in smokeless propellants and another for its use as an explosive, noting its excellent characteristics. The German military hadn't considered its adoption during the war due to the expense of production but started investigating its use in 1920, referring to it as hexogen.\nResearch and development findings were not published further until Edmund von Herz, described as an Austrian and later a German citizen, rediscovered the explosive properties of RDX and applied for an Austrian patent in 1919, obtaining a British one in 1921 and an American one in 1922. All patents described the synthesis of the compound by nitrating hexamethylenetetramine. The British patent claims included the manufacture of RDX by nitration, its use with or without other explosives, its use as a bursting charge and as an initiator. The US patent claim was for the use of a hollow explosive device containing RDX and a detonator cap containing it. Herz was also the first to identify the cyclic nature of the molecule.\nIn the 1930s, Germany developed improved production methods.\nDuring World War II, Germany used the code names W Salt, SH Salt, K-method, the E-method, and the KA-method. These names represented the identities of the developers of the various chemical routes to RDX. The W-method was developed by Wolfram in 1934 and gave RDX the code name \"W-Salz\". It used sulfamic acid, formaldehyde, and nitric acid. SH-Salz (SH salt) was from Schnurr, who developed a batch-process in 1937\u201338 based on nitrolysis of hexamine. The K-method, from Kn\u00f6ffler, involved addition of ammonium nitrate to the hexamine/nitric acid process. The E-method, developed by Ebele, proved to be identical to the Ross and Schiessler process described below. The KA-method, also developed by Kn\u00f6ffler, turned out to be identical to the Bachmann process described below.\nThe explosive shells fired by the MK 108 cannon and the warhead of the R4M rocket, both used in Luftwaffe fighter aircraft as offensive armament, both used hexogen as their explosive base.\nUK.\nIn the United Kingdom (UK), RDX was manufactured from 1933 by the research department in a pilot plant at the Royal Arsenal in Woolwich, London, a larger pilot plant being built at the RGPF Waltham Abbey just outside London in 1939. In 1939 a twin-unit industrial-scale plant was designed to be installed at a new site, ROF Bridgwater, away from London and production of RDX started at Bridgwater on one unit in August 1941. The ROF Bridgwater plant brought in ammonia and methanol as raw materials: the methanol was converted to formaldehyde and some of the ammonia converted to nitric acid, which was concentrated for RDX production. The rest of the ammonia was reacted with formaldehyde to produce hexamine. The hexamine plant was supplied by Imperial Chemical Industries. It incorporated some features based on data obtained from the United States (US). RDX was produced by continually adding hexamine and concentrated nitric acid to a cooled mixture of hexamine and nitric acid in the nitrator. The RDX was purified and processed for its intended use; recovery and reuse of some methanol and nitric acid also was carried out. The hexamine-nitration and RDX purification plants were duplicated (i.e. twin-unit) to provide some insurance against loss of production due to fire, explosion, or air attack.\nThe United Kingdom and British Empire were fighting without allies against Nazi Germany until the middle of 1941 and had to be self-sufficient. At that time (1941), the UK had the capacity to produce (160,000\u00a0lb) of RDX per week; both Canada, an allied country and self-governing dominion within the British Empire, and the US were looked upon to supply ammunition and explosives, including RDX. By 1942 the Royal Air Force's annual requirement was forecast to be of RDX, much of which came from North America (Canada and the US).\nCanada.\nA different method of production to the Woolwich process was found and used in Canada, possibly at the McGill University department of chemistry. This was based on reacting paraformaldehyde and ammonium nitrate in acetic anhydride. A UK patent application was made by Robert Walter Schiessler (Pennsylvania State University) and James Hamilton Ross (McGill, Canada) in May 1942; the UK patent was issued in December 1947. Gilman states that the same method of production had been independently discovered by Ebele in Germany prior to Schiessler and Ross, but that this was not known by the Allies. Urba\u0144ski provides details of five methods of production, and he refers to this method as the (German) E-method.\nUK, US, and Canadian production and development.\nAt the beginning of the 1940s, the major US explosive manufacturers, E. I. du Pont de Nemours &amp; Company and Hercules, had several decades of experience of manufacturing trinitrotoluene (TNT) and had no wish to experiment with new explosives. US Army Ordnance held the same viewpoint and wanted to continue using TNT. RDX had been tested by Picatinny Arsenal in 1929, and it was regarded as too expensive and too sensitive. The Navy proposed to continue using ammonium picrate. In contrast, the National Defense Research Committee (NDRC), who had visited The Royal Arsenal, Woolwich, thought new explosives were necessary. James B. Conant, chairman of Division B, wished to involve academic research into this area. Conant therefore set up an experimental explosives research laboratory at the Bureau of Mines, Bruceton, Pennsylvania, using Office of Scientific Research and Development (OSRD) funding.\nWoolwich method.\nIn 1941, the UK's Tizard Mission visited the US Army and Navy departments and part of the information handed over included details of the \"Woolwich\" method of manufacture of RDX and its stabilisation by mixing it with beeswax. The UK was asking that the US and Canada, combined, supply (440,000\u00a0lb) of RDX per day. A decision was taken by William H. P. Blandy, chief of the Bureau of Ordnance, to adopt RDX for use in mines and torpedoes. Given the immediate need for RDX, the US Army Ordnance, at Blandy's request, built a plant that copied the equipment and process used at Woolwich. The result was the Wabash River Ordnance Works run by E. I. du Pont de Nemours &amp; Company. At that time, this works had the largest nitric acid plant in the world. The Woolwich process was expensive: it needed of strong nitric acid for every pound of RDX.\nBy early 1941, the NDRC was researching new processes. The Woolwich or direct nitration process has at least two serious disadvantages: (1) it used large amounts of nitric acid and (2) at least one-half of the formaldehyde is lost. One mole of hexamethylenetetramine could produce at most one mole of RDX. At least three laboratories with no previous explosive experience were instructed to develop better production methods for RDX; they were based at Cornell, Michigan, and Pennsylvania State universities. Werner Emmanuel Bachmann, from Michigan, successfully developed the \"combination process\" by combining the Ross and Schiessler process used in Canada (aka the German E-method) with direct nitration. The combination process required large quantities of acetic anhydride instead of nitric acid in the old British \"Woolwich process\". Ideally, the combination process could produce two moles of RDX from each mole of hexamethylenetetramine.\nThe expanded production of RDX could not continue to rely on the use of natural beeswax to desensitize the explosive as in the original British composition (RDX/BWK-91/9). A substitute stabilizer based on petroleum was developed at the Bruceton Explosives Research Laboratory in Pennsylvania, with the resulting explosive designated Composition A-3.\nBachmann process.\nThe National Defence Research Committee (NDRC) instructed three companies to develop pilot plants. They were the Western Cartridge Company, E. I. du Pont de Nemours &amp; Company, and Tennessee Eastman Company, part of Eastman Kodak. At the Eastman Chemical Company (TEC), a leading manufacturer of acetic anhydride, Werner Emmanuel Bachmann developed a continuous-flow process for RDX utilizing an ammonium nitrate/nitric acid mixture as a nitrating agent in a medium of acetic acid and acetic anhydride. RDX was crucial to the war effort and the current batch-production process was too slow. In February 1942, TEC began producing small amounts of RDX at its Wexler Bend pilot plant, which led to the US government authorizing TEC to design and build Holston Ordnance Works (H.O.W.) in June 1942. By April 1943, RDX was being manufactured there. At the end of 1944, the Holston plant and the Wabash River Ordnance Works, which used the Woolwich process, were producing (50 million pounds) of Composition B per month.\nThe Bachmann process yields both RDX and HMX, with the major product determined by the specific reaction conditions.\nMilitary compositions.\nThe United Kingdom's intention in World War II was to use \"desensitised\" RDX. In the original Woolwich process, RDX was phlegmatized with beeswax, but later paraffin wax was used, based on the work carried out at Bruceton. In the event the UK was unable to obtain sufficient RDX to meet its needs, some of the shortfall was met by substituting amatol, a mixture of ammonium nitrate and TNT.\nKarl D\u00f6nitz was reputed to have claimed that \"an aircraft can no more kill a U-boat than a crow can kill a mole\". Nonetheless, by May 1942 Wellington bombers began to deploy depth charges containing Torpex, a mixture of RDX, TNT, and aluminium, which had up to 50 percent more destructive power than TNT-filled depth charges. Considerable quantities of the RDX\u2013TNT mixture were produced at the Holston Ordnance Works, with Tennessee Eastman developing an automated mixing and cooling process based around the use of stainless steel conveyor belts.\nTerrorism.\nA Semtex bomb was used in the Pan Am Flight 103 (known also as the Lockerbie) bombing in 1988. A belt laden with of RDX explosives tucked under the dress of the assassin was used in the assassination of former Indian prime minister Rajiv Gandhi in 1991. The 1993 Bombay bombings used RDX placed into several vehicles as bombs. RDX was the main component used for the 2006 Mumbai train bombings and the Jaipur bombings in 2008. It also is believed to be the explosive used in the 2010 Moscow Metro bombings.\nTraces of RDX were found on pieces of wreckage from 1999 Russian apartment bombings and 2004 Russian aircraft bombings. FSB reports on the bombs used in the 1999 apartment bombings indicated that while RDX was not a part of the main charge, each bomb contained plastic explosive used as a booster charge.\nAhmed Ressam, the al-Qaeda Millennium Bomber, used a small quantity of RDX as one of the components in the bomb that he prepared to detonate in Los Angeles International Airport on New Year's Eve 1999\u20132000; the bomb could have produced a blast forty times greater than that of a devastating car bomb.\nIn July 2012, the Kenyan government arrested two Iranian nationals and charged them with illegal possession of of RDX. According to the Kenyan Police, the Iranians planned to use the RDX for \"attacks on Israeli, US, UK and Saudi Arabian targets\".\nRDX was used in the assassination of Lebanese Prime Minister Rafic Hariri on February 14, 2005.\nIn the 2019 Pulwama attack in India, 250\u00a0kg of high-grade RDX was used by Jaish-e-Mohammed. The attack resulted in the deaths of 44 Central Reserve Police Force (CRPF) personnel as well as the attacker.\nTwo letter bombs sent to journalists in Ecuador were disguised as USB flash drives which contained RDX that would detonate when plugged in.\nStability.\nRDX has a high nitrogen content and a high oxygen to carbon ratio, (O:C ratio), both of which indicate its explosive potential for formation of N2 and CO2.\nRDX undergoes a deflagration to detonation transition (DDT) in confinement and certain circumstances.\nThe velocity of detonation of RDX at a density of 1.80 g/cm3 is 8750\u00a0m/s.\nIt starts to decompose at approximately 170\u00a0\u00b0C and melts at 204\u00a0\u00b0C. At room temperature, it is very stable. It burns rather than explodes. It detonates only with a detonator, being unaffected even by small arms fire. This property makes it a useful military explosive. It is less sensitive than pentaerythritol tetranitrate (PETN). Under normal conditions, RDX has a Figure of Insensitivity of exactly 80 (RDX defines the reference point).\nRDX sublimes in vacuum, which restricts or prevents its use in some applications.\nRDX, when exploded in air, has about 1.5 times the explosive energy of TNT per unit weight and about 2.0 times per unit volume.\nRDX is insoluble in water, with solubility 0.05975 g/L at temperature of 25\u00a0\u00b0C.\nToxicity.\nThe substance's toxicity has been studied for many years. RDX has caused convulsions (seizures) in military field personnel ingesting it, and in munition workers inhaling its dust during manufacture. At least one fatality was attributed to RDX toxicity in a European munitions manufacturing plant.\nDuring the Vietnam War, at least 40 American soldiers were hospitalized with composition C-4 (which is 91% RDX) intoxication from December 1968 to December 1969. C-4 was frequently used by soldiers as a fuel to heat food, and the food was generally mixed by the same knife that was used to cut C-4 into small pieces prior to burning. Soldiers were exposed to C-4 either due to inhaling the fumes, or due to ingestion, made possible by many small particles adhering to the knife having been deposited into the cooked food. The symptom complex involved nausea, vomiting, generalized seizures, and prolonged postictal confusion and amnesia; which indicated toxic encephalopathy.\nOral toxicity of RDX depends on its physical form; in rats, the LD50 was found to be 100\u00a0mg/kg for finely powdered RDX, and 300\u00a0mg/kg for coarse, granular RDX. A case has been reported of a human child hospitalized in status epilepticus following the ingestion of 84.82\u00a0mg/kg dose of RDX (or 1.23 g for the patient's body weight of 14.5\u00a0kg) in the \"plastic explosive\" form.\nThe substance has low to moderate toxicity with a possible human carcinogen classification. Further research is ongoing, however, and this classification may be revised by the United States Environmental Protection Agency (EPA). Remediating RDX-contaminated water supplies has proven to be successful. It is known to be a kidney toxin in humans and highly toxic to earthworms and plants, thus army testing ranges where RDX was used heavily may need to undergo environmental remediation. Concerns have been raised by research published in late 2017 indicating that the issue has not been addressed correctly by U.S. officials.\nCivilian use.\nRDX has been used as a rodenticide because of its toxicity.\nBiodegradation.\nRDX is degraded by the organisms in sewage sludge as well as the fungus \"Phanaerocheate chrysosporium\". Both wild and transgenic plants can phytoremediate explosives from soil and water. One by-product of the environmental decomposition is R-salt.\nAlternatives.\nFOX-7 is considered to be approximately a 1-to-1 replacement for RDX in almost all applications."}
{"id": "7500", "revid": "35420050", "url": "https://en.wikipedia.org/wiki?curid=7500", "title": "Celebes (disambiguation)", "text": "Celebes is the western name of Sulawesi, an island in Indonesia.\nCelebes may also refer to:"}
{"id": "7501", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7501", "title": "Chairman of the board (disambiguation)", "text": ""}
