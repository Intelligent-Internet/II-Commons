{"id": "854", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=854", "title": "Anatolia", "text": "Anatolia (), also known as Asia Minor, is a peninsula in West Asia that makes up the majority of the land area of Turkey. It is the westernmost protrusion of Asia and is geographically bounded by the Mediterranean Sea to the south, the Aegean Sea to the west, the Turkish Straits to the northwest, and the Black Sea to the north. The eastern and southeastern limits have been expanded either to the entirety of Asiatic Turkey or to an imprecise line from the Black Sea to the Gulf of Alexandretta. Topographically, the Sea of Marmara connects the Black Sea with the Aegean Sea through the Bosporus and the Dardanelles, and separates Anatolia from Thrace in Southeast Europe.\nDuring the Neolithic, Anatolia was an early centre for the development of farming after it originated in the adjacent Fertile Crescent. Beginning around 9,000 years ago, there was a major migration of Anatolian Neolithic Farmers into Europe, with their descendants coming to dominate the continent as far west as the Iberian Peninsula and the British Isles.\nThe earliest recorded inhabitants of Anatolia, who were neither Indo-European nor Semitic, were gradually absorbed by the incoming Indo-European Anatolian peoples, who spoke the now-extinct Anatolian languages. The major Anatolian languages included Hittite, Luwian, and Lydian; other local languages, albeit poorly attested, included Phrygian and Mysian. The Hurro-Urartian languages were spoken throughout Mitanni in the southeast, while Galatian, a Celtic language, was spoken throughout Galatia in the central peninsula. Among the other peoples who established a significant presence in ancient Anatolia were the Galatians, the Hurrians, the Assyrians, the Armenians, the Hattians, and the Cimmerians, as well as some of the ancient Greek tribes, including the Ionians, the Dorians, and the Aeolians. In the era of classical antiquity (see Classical Anatolia), the Anatolian languages were largely replaced by the Greek language, which came to further dominate the region during the Hellenistic period and the Roman period. \nThe Byzantine period saw the decline of Greek influence throughout the peninsula as the Byzantine\u2013Seljuk wars enabled the incoming Seljuk Turks to establish a foothold in the region. Thus, the process of Anatolia's Turkification began under the Seljuk Empire in the late 11th century and continued under the Ottoman Empire until the early 20th century, when the Ottoman dynasty collapsed in the aftermath of World War I. Between 1894 and 1924, millions of non-Turkic peoples and Christians were suppressed and removed by the Ottoman Turkish authorities from the bulk of the area of modern-day Turkey. Nonetheless, a variety of non-Turkic languages continue to be spoken by ethnic minorities in Anatolia today, including Arabic, Kurdish, Neo-Aramaic, Armenian, the North Caucasian languages, Laz, Georgian, and Greek.\nGeography.\nTraditionally, Anatolia is considered to extend in the east to an indefinite line running from the Gulf of Alexandretta to the Black Sea, coterminous with the Anatolian Plateau. This traditional geographical definition is used, for example, in the latest edition of \"Merriam-Webster's Geographical Dictionary\". Under this definition, Anatolia is bounded to the east by the Armenian Highlands, and the Euphrates before that river bends to the southeast to enter Mesopotamia. To the southeast, it is bounded by the ranges that separate it from the Orontes valley in Syria and the Mesopotamian plain.\nFollowing the Armenian genocide, Western Armenia was renamed the Eastern Anatolia Region by the newly established Turkish government. In 1941, with the First Geography Congress which divided Turkey into seven geographical regions based on differences in climate and landscape, the eastern provinces of Turkey were placed into the Eastern Anatolia Region, which largely corresponds to the historical region of Western Armenia. Vazken Davidian terms the expanded use of \"Anatolia\" to apply to territory in eastern Turkey that was formerly referred to as \"Armenia\" (which had a sizeable Armenian population before the Armenian genocide) an \"ahistorical imposition\" and notes that a growing body of literature is uncomfortable with referring to the Ottoman East as \"Eastern Anatolia\".\nThe highest mountain in the Eastern Anatolia Region (also the highest peak in the Armenian Highlands) is Mount Ararat (5123\u00a0m). The Euphrates, Aras, Karasu and Murat rivers connect the Armenian Highlands to the South Caucasus and the Upper Euphrates Valley. Along with the \u00c7oruh, these rivers are the longest in the Eastern Anatolia Region.\nEtymology.\nThe English-language name \"Anatolia\" derives from the Greek () meaning \"the East\" and designating (from a Greek point of view) eastern regions in general. The Greek word refers to the direction where the sun rises, coming from \"anatello\" '(\u0399) rise up', comparable to terms in other languages such as \"levant\" from Latin 'to rise', \"orient\" from Latin 'to arise, to originate', Hebrew \"mizra\u1e25\" 'east' from \"zara\u1e25\" 'to rise, to shine', Aramaic \"midna\u1e25\" from \"dena\u1e25\" 'to rise, to shine'.\nThe use of Anatolian designations has varied over time, perhaps originally referring to the Aeolian, Ionian and Dorian colonies situated along the eastern coasts of the Aegean Sea, but also encompassing eastern regions in general. Such use of Anatolian designations was employed during the reign of Roman Emperor Diocletian (), who created the Diocese of the East, known in Greek as the Eastern Diocese, but completely unrelated to the regions of Asia Minor. In their widest territorial scope, Anatolian designations were employed during the reign of Roman Emperor Constantine\u00a0I (306\u2013337), who created the Praetorian prefecture of the East, known in Greek as the Eastern Prefecture, encompassing all eastern regions of the Late Roman Empire and spanning from Thrace to Egypt.\nOnly after the loss of other eastern regions during the 7th century and the reduction of Byzantine eastern domains to Asia Minor, that region became the only remaining part of the \"Byzantine East\", and thus commonly referred to (in Greek) as the Eastern part of the Empire. At the same time, the Anatolic Theme ( / \"the Eastern theme\") was created, as a province (\"theme\") covering the western and central parts of Turkey's present-day Central Anatolia Region, centered around Iconium, but ruled from the city of Amorium.\nThe Latinized form \"\", with its \"-ia\" ending, is probably a Medieval Latin innovation. The modern Turkish form derives directly from the Greek name (\"Anatol\u1e17\"). The Russian male name Anatoly, the French Anatole and plain Anatol, all stemming from saints Anatolius of Laodicea (d.\u00a0283) and Anatolius of Constantinople (d.\u00a0458; the first Patriarch of Constantinople), share the same linguistic origin.\nNames.\nThe oldest known name for any region within Anatolia is related to its central area, known as the \"Land of Hatti\" \u2013 a designation that was initially used for the land of ancient Hattians, but later became the most common name for the entire territory under the rule of ancient Hittites.\nThe first recorded name the Greeks used for the Anatolian peninsula, though not particularly popular at the time, was \u1f08\u03c3\u03af\u03b1 (\"As\u00eda\"), perhaps from an Akkadian expression for the \"sunrise\" or possibly echoing the name of the Assuwa league in western Anatolia. The Romans used it as the name of their province, comprising the west of the peninsula plus the nearby Aegean Islands. As the name \"Asia\" broadened its scope to apply to the vaster region east of the Mediterranean, some Greeks in Late Antiquity came to use the name Asia Minor (\u039c\u03b9\u03ba\u03c1\u1f70 \u1f08\u03c3\u03af\u03b1, \"Mikr\u00e0 As\u00eda\"), meaning \"Lesser Asia\" to refer to present-day Anatolia, whereas the administration of the Empire preferred the description \u1f08\u03bd\u03b1\u03c4\u03bf\u03bb\u03ae (\"Anatol\u1e17\"; ).\nThe endonym \u1fec\u03c9\u03bc\u03b1\u03bd\u03af\u03b1 (\"R\u014dman\u00eda\" \"the land of the Romans, i.e. the Eastern Roman Empire\") was understood as another name for the province by the invading Seljuq Turks, who founded a Sultanate of R\u00fbm in 1077. Thus (land of the) R\u00fbm became another name for Anatolia. By the 12th century Europeans had started referring to Anatolia as \"Turchia\".\nDuring the era of the Ottoman Empire, many mapmakers referred to the mountainous plateau in eastern Anatolia as Armenia. Other contemporary sources called the same area Kurdistan. Geographers have used \"East Anatolian plateau\", \"Armenian plateau\" and the \"Iranian plateau\" to refer to the region; the former two largely overlap. While a standard definition of Anatolia refers to the entire Asian side of Turkey, according to archaeologist Lori Khatchadourian, this difference in terminology \"primarily result[s] from the shifting political fortunes and cultural trajectories of the region since the nineteenth century\".\nTurkey's First Geography Congress in 1941 created two geographical regions of Turkey to the east of the Gulf of Iskenderun-Black Sea line, the Eastern Anatolia Region and the Southeastern Anatolia Region, the former largely corresponding to the western part of the Armenian Highlands, the latter to the northern part of the Mesopotamian plain. According to Richard Hovannisian, this changing of toponyms was \"necessary to obscure all evidence\" of the Armenian presence as part of the policy of Armenian genocide denial embarked upon by the newly established Turkish government and what Hovannisian calls its \"foreign collaborators\".\nHistory.\nPrehistoric Anatolia.\nHuman habitation in Anatolia dates back to the Paleolithic. Neolithic settlements include \u00c7atalh\u00f6y\u00fck, \u00c7ay\u00f6n\u00fc, Nevali Cori, A\u015f\u0131kl\u0131 H\u00f6y\u00fck, Boncuklu H\u00f6y\u00fck, Hacilar, G\u00f6bekli Tepe, Nor\u015funtepe, K\u00f6\u015fk H\u00f6y\u00fck, and Yumuktepe. \u00c7atalh\u00f6y\u00fck (7.000 BCE) is considered the most advanced of these. Recent advances in archaeogenetics have confirmed that the spread of agriculture from the Middle East to Europe was strongly correlated with the migration of early farmers from Anatolia about 9,000 years ago, and was not just a cultural exchange. Anatolian Neolithic farmers derived most of their ancestry from local Anatolian hunter-gatherers, suggesting that agriculture was adopted in site by these hunter-gatherers and not spread by demic diffusion into the region. Anatolian derived Neolithic Farmers would subsequently spread across Europe, as far west as the Iberian Peninsula and the British Isles, as well as to the Maghreb. Most modern Europeans derive a significant part of their ancestry from these Neolithic Anatolian farmers.\nNeolithic Anatolia has been proposed as the homeland of the Indo-European language family, although linguists tend to favour a later origin in the steppes north of the Black Sea. However, it is clear that the Anatolian languages, the earliest attested branch of Indo-European, have been spoken in Anatolia since at least the 19th century BCE.\nAncient Anatolia.\nThe earliest historical data related to Anatolia appear during the Bronze Age and continue throughout the Iron Age. The most ancient period in the history of Anatolia spans from the emergence of ancient Hattians, up to the conquest of Anatolia by the Achaemenid Empire in the 6th century BCE.\nHattians and Hurrians.\nThe earliest historically attested populations of Anatolia were the Hattians in central Anatolia, and Hurrians further to the east. The Hattians were an indigenous people, whose main center was the city of Hattush. Affiliation of Hattian language remains unclear, while Hurrian language belongs to a distinctive family of Hurro-Urartian languages. All of those languages are extinct; relationships with indigenous languages of the Caucasus have been proposed, but are not generally accepted. The region became famous for exporting raw materials. Organized trade between Anatolia and Mesopotamia started to emerge during the period of the Akkadian Empire, and was continued and intensified during the period of the Old Assyrian Empire, between the 21st and the 18th centuries BCE. Assyrian traders were bringing tin and textiles in exchange for copper, silver or gold. Cuneiform records, dated , found in Anatolia at the Assyrian colony of Kanesh, use an advanced system of trading computations and credit lines.\nHittite Anatolia (18th\u201312th century BCE).\nUnlike the Akkadians and Assyrians, whose Anatolian trading posts were peripheral to their core lands in Mesopotamia, the Hittites were centered at Hattusa (modern Bo\u011fazkale) in north-central Anatolia by the 17th century BCE. They were speakers of an Indo-European language, the Hittite language, or \"nesili\" (the language of Nesa) in Hittite. The Hittites originated from local ancient cultures that grew in Anatolia, in addition to the arrival of Indo-European languages. Attested for the first time in the Assyrian tablets of Nesa around 2000 BCE, they conquered Hattusa in the 18th century BCE, imposing themselves over Hattian- and Hurrian-speaking populations. According to the widely accepted Kurgan theory on the Proto-Indo-European homeland, however, the Hittites (along with the other Indo-European ancient Anatolians) were themselves relatively recent immigrants to Anatolia from the north. However, they did not necessarily displace the population genetically; they assimilated into the former peoples' culture, preserving the Hittite language.\nThe Hittites adopted the Mesopotamian cuneiform script. In the Late Bronze Age, Hittite New Kingdom () was founded, becoming an empire in the 14th century BCE after the conquest of Kizzuwatna in the south-east and the defeat of the Assuwa league in western Anatolia. The empire reached its height in the 13th century BCE, controlling much of Asia Minor, northwestern Syria, and northwest upper Mesopotamia. However, the Hittite advance toward the Black Sea coast was halted by the semi-nomadic pastoralist and tribal Kaskians, a non-Indo-European people who had earlier displaced the Palaic-speaking Indo-Europeans. Much of the history of the Hittite Empire concerned war with the rival empires of Egypt, Assyria and the Mitanni.\nThe Ancient Egyptians eventually withdrew from the region after failing to gain the upper hand over the Hittites and becoming wary of the power of Assyria, which had destroyed the Mitanni Empire. The Assyrians and Hittites were then left to battle over control of eastern and southern Anatolia and colonial territories in Syria. The Assyrians had better success than the Egyptians, annexing much Hittite (and Hurrian) territory in these regions.\nPost-Hittite Anatolia (12th\u20136th century BCE).\nAfter 1180 BCE, during the Late Bronze Age collapse, the Hittite Empire disintegrated into several independent Syro-Hittite states, subsequent to losing much territory to the Middle Assyrian Empire and being finally overrun by the Phrygians, another Indo-European people who are believed to have migrated from the Balkans. The Phrygian expansion into southeast Anatolia was eventually halted by the Assyrians, who controlled that region.\nAnother Indo-European people, the Luwians, rose to prominence in central and western Anatolia BCE. Their language belonged to the same linguistic branch as Hittite. The general consensus amongst scholars is that Luwian was spoken across a large area of western Anatolia, including (possibly) Wilusa (Troy), the Seha River Land (to be identified with the Hermos and/or Kaikos valley), and the kingdom of Mira-Kuwaliya with its core territory of the Maeander valley. From the 9th century BCE, Luwian regions coalesced into a number of states such as Lydia, Caria, and Lycia, all of which had Hellenic influence.\nArameans encroached over the borders of south-central Anatolia in the century or so after the fall of the Hittite empire, and some of the Syro-Hittite states in this region became an amalgam of Hittites and Arameans. These became known as Syro-Hittite states.\nFrom the 10th to late 7th centuries BCE, much of Anatolia (particularly the southeastern regions) fell to the Neo-Assyrian Empire, including all of the Syro-Hittite states, Tabal, Commagene, the Cimmerians and Scythians, and swathes of Cappadocia.\nThe Neo-Assyrian empire collapsed due to a bitter series of civil wars followed by a combined attack by Medes, Persians, Scythians and their own Babylonian relations. The last Assyrian city to fall was Harran in southeast Anatolia. This city was the birthplace of the last king of Babylon, the Assyrian Nabonidus and his son and regent Belshazzar. Much of the region then fell to the short-lived Iran-based Median Empire, with the Babylonians and Scythians briefly appropriating some territory.\nFrom the late 8th century BCE, a new wave of Indo-European-speaking raiders entered northern and northeast Anatolia: the Cimmerians and Scythians. The Cimmerians overran Phrygia and the Scythians threatened to do the same to Urartu and Lydia, before both were finally checked by the Assyrians.\nThe north-western coast of Anatolia was inhabited by Greeks of the Achaean/Mycenaean culture from the 20th century BCE, related to the Greeks of southeastern Europe and the Aegean. Beginning with the Bronze Age collapse at the end of the 2nd millennium BCE, the west coast of Anatolia was settled by Ionian Greeks, usurping the area of the related but earlier Mycenaean Greeks. Over several centuries, numerous Ancient Greek city-states were established on the coasts of Anatolia. Greeks started Western philosophy on the western coast of Anatolia (Pre-Socratic philosophy).\nClassical Anatolia.\nIn Classical antiquity, Anatolia was described by the Ancient Greek historian Herodotus and later historians as divided into regions that were diverse in culture, language, and religious practices. The northern regions included Bithynia, Paphlagonia, and Pontus; to the west were Mysia, Lydia, and Caria; and Lycia, Pamphylia, and Cilicia belonged to the southern shore. There were also several inland regions: Phrygia, Cappadocia, Pisidia, and Galatia. Languages spoken included the late surviving Anatolic languages, Isaurian, and Pisidian, Greek in western and coastal regions, Phrygian spoken until the 7th century CE, local variants of Thracian in the northwest, the Galatian variant of Gaulish in Galatia until the 6th century CE, Cappadocian in the homonymous region, Armenian in the east, and Kartvelian languages in the northeast.\nAnatolia is known as the birthplace of minted coinage (as opposed to unminted coinage, which first appears in Mesopotamia at a much earlier date) as a medium of exchange, some time in the 7th century BCE in Lydia. The use of minted coins continued to flourish during the Greek and Roman eras.\nDuring the 6th century BCE, all of Anatolia was conquered by the Persian Achaemenid Empire, the Persians having usurped the Medes as the dominant dynasty of Persia. In 499 BCE, the Ionian city-states on the west coast of Anatolia rebelled against Persian rule. The Ionian Revolt, as it became known, though quelled, initiated the Greco-Persian Wars, which ended in a Greek victory in 449 BCE, and the Ionian cities regained their independence. By the Peace of Antalcidas (387 BCE), which ended the Corinthian War, Persia regained control over Ionia.\nIn 334 BCE, the Macedonian Greek king Alexander the Great conquered the Anatolian peninsula from the Achaemenid Persian Empire. Alexander's conquest opened up the interior of Asia Minor to Greek settlement and influence.\n Following the death of Alexander the Great and the subsequent breakup of the Macedonian Empire, Anatolia was ruled by a series of Hellenistic kingdoms, such as the Attalids of Pergamum and the Seleucids, the latter controlling most of Anatolia. A period of peaceful Hellenization followed, such that the local Anatolian languages had been supplanted by Greek by the 1st century BCE. In 133 BCE the last Attalid king bequeathed his kingdom to the Roman Republic; western and central Anatolia came under Roman control, but Hellenistic culture remained predominant.\nMithridates VI Eupator, ruler of the Kingdom of Pontus in northern Anatolia, waged war against the Roman Republic in the year 88 BCE in order to halt the advance of Roman hegemony in the Aegean Sea region. Mithridates VI sought to dominate Asia Minor and the Black Sea region, waging several hard-fought but ultimately unsuccessful wars (the Mithridatic Wars) to break Roman dominion over Asia and the Hellenic world. He has been called the greatest ruler of the Kingdom of Pontus. Further annexations by Rome, in particular of the Kingdom of Pontus by Pompey, brought all of Anatolia under Roman control, except for the southeastern frontier with the Parthian Empire, which remained unstable for centuries, causing a series of military conflicts that culminated in the Roman\u2013Parthian Wars (54 BCE \u2013 217 CE).\nEarly Christian period.\nAfter the first division of the Roman Empire, Anatolia became part of the Eastern Roman Empire, otherwise known as the Byzantine Empire or Byzantium. In the 1st century CE, Anatolia became one of the first places where Christianity spread, so that by the 4th century CE, western and central Anatolia were overwhelmingly Christian and Greek-speaking.\nByzantine Anatolia was one of the wealthiest and most densely populated places in the Later Roman Empire. Anatolia's wealth grew during the 4th and 5th centuries thanks, in part, to the Pilgrim's Road that ran through the peninsula. Literary evidence about the rural landscape stems from the Christian hagiographies of the 6th-century Nicholas of Sion and 7th-century Theodore of Sykeon. Large and prosperous urban centers of Byzantine Anatolia included Assos, Ephesus, Miletus, Nicaea, Pergamum, Priene, Sardis, and Aphrodisias.\nFrom the mid-5th century onwards, urbanism was affected negatively and began to decline, while the rural areas reached unprecedented levels of prosperity in the region. Historians and scholars continue to debate the cause of the urban decline in Byzantine Anatolia between the 6th and 7th centuries, variously attributing it to the Plague of Justinian (541), the Byzantine\u2013Sasanian War (602\u2013628), and the Arab invasion of the Levant (634\u2013638).\nMedieval period.\nIn the 10 years following the Battle of Manzikert in 1071, the Seljuk Turks from Central Asia migrated over large areas of Anatolia, with particular concentrations around the northwestern rim. The Turkish language and the Islamic religion were gradually introduced as a result of the Seljuk conquest, and this period marks the start of Anatolia's slow transition from predominantly Christian and Greek-speaking, to predominantly Muslim and Turkish-speaking (although ethnic groups such as Armenians, Greeks, and Assyrians remained numerous and retained Christianity and their native languages). In the following century, the Byzantines managed to reassert their control in western and northern Anatolia. Control of Anatolia was then split between the Byzantine Empire and the Seljuk Sultanate of R\u00fbm, with the Byzantine holdings gradually being reduced.\nIn 1255, the Mongols swept through eastern and central Anatolia, and would remain until 1335. The Ilkhanate garrison was stationed near Ankara. After the decline of the Ilkhanate from 1335 to 1353, the Mongol Empire's legacy in the region was the Uyghur Eretna Dynasty that was overthrown by Kadi Burhan al-Din in 1381.\nBy the end of the 14th century, most of Anatolia was controlled by various Anatolian beyliks. Smyrna fell in 1330, and the last Byzantine stronghold in Anatolia, Philadelphia, fell in 1390. The Turkmen Beyliks were under the control of the Mongols, at least nominally, through declining Seljuk sultans. The Beyliks did not mint coins in the names of their own leaders while they remained under the suzerainty of the Mongol Ilkhanids. The Osmanli ruler Osman I was the first Turkish ruler who minted coins in his own name in 1320s; they bear the legend \"Minted by Osman son of Ertugrul\". Since the minting of coins was a prerogative accorded in Islamic practice only to a sovereign, it can be considered that the Osmanli, or Ottoman Turks, had become formally independent from the Mongol Khans.\nOttoman Empire.\nAmong the Turkish leaders, the Ottomans emerged as great power under Osman I and his son Orhan. The Anatolian beyliks were successively absorbed into the rising Ottoman Empire during the 15th century. It is not well understood how the Osmanl\u0131, or Ottoman Turks, came to dominate their neighbours, as the history of medieval Anatolia is still little known. The Ottomans completed the conquest of the peninsula in 1517 with the taking of Halicarnassus (modern Bodrum) from the Knights of Saint John.\nModern times.\nWith the acceleration of the decline of the Ottoman Empire in the early 19th century, and as a result of the expansionist policies of the Russian Empire in the Caucasus, many Muslim nations and groups in that region, mainly Circassians, Tatars, Azeris, Lezgis, Chechens and several Turkic groups left their homelands and settled in Anatolia. As the Ottoman Empire further shrank in the Balkan regions and then fragmented during the Balkan Wars, much of the non-Christian populations of its former possessions, mainly Balkan Muslims (Bosniaks, Albanians, Turks, Muslim Bulgarians and Greek Muslims such as the Vallahades from Greek Macedonia), were resettled in various parts of Anatolia, mostly in formerly Christian villages throughout Anatolia.\nA continuous reverse migration occurred since the early 19th century, when Greeks from Anatolia, Constantinople and Pontus area migrated toward the newly independent Kingdom of Greece, and also towards the United States, the southern part of the Russian Empire, Latin America, and the rest of Europe.\nFollowing the Russo-Persian Treaty of Turkmenchay (1828) and the incorporation of Eastern Armenia into the Russian Empire, another migration involved the large Armenian population of Anatolia, which recorded significant migration rates from Western Armenia (Eastern Anatolia) toward the Russian Empire, especially toward its newly established Armenian provinces.\nAnatolia remained multi-ethnic until the early 20th century (see the rise of nationalism under the Ottoman Empire). During World War I, the Armenian genocide, the Greek genocide (especially in Pontus), and the Assyrian genocide almost entirely removed the ancient indigenous communities of Armenian, Greek, and Assyrian populations in Anatolia and surrounding regions. Following the Greco-Turkish War of 1919\u20131922, most remaining ethnic Anatolian Greeks were forced out during the 1923 population exchange between Greece and Turkey. Of the remainder, most have left Turkey since then, leaving fewer than 5,000 Greeks in Anatolia today. According to Morris and Ze'evi, 4 million christians were ethnically cleansed from Asia minor by the Turks from 1894 to 1924.\nGeology.\nAnatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Aegean, Mediterranean, and the Black Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the K\u0131z\u0131l River, the coastal plains of \u00c7ukurova and the valley floors of the Gediz River and the B\u00fcy\u00fck Menderes River as well as some interior high plains in Anatolia, mainly around Lake Tuz (Salt Lake) and the Konya Basin (\"Konya Ovasi\").\nThere are two mountain ranges in southern Anatolia: the Taurus and the Zagros mountains.\nClimate.\nAnatolia has a varied range of climates. The central plateau is characterized by a continental climate, with hot summers and cold snowy winters. The south and west coasts enjoy a typical Mediterranean climate, with mild rainy winters, and warm dry summers. The Black Sea and Marmara coasts have a temperate oceanic climate, with warm, foggy summers and much rainfall throughout the year.\nEcoregions.\nThere is a diverse number of plant and animal communities.\nThe mountains and coastal plain of northern Anatolia experience a humid and mild climate. There are temperate broadleaf, mixed and coniferous forests. The central and eastern plateau, with its drier continental climate, has deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, contain Mediterranean forests, woodlands, and scrub ecoregions.\nDemographics.\nThe largest cities in Anatolia (aside from the Asian side of Istanbul) are Ankara, \u0130zmir, Bursa, Antalya, Konya, Adana, \u0130zmit, Mersin, Manisa, Kayseri, Samsun, Bal\u0131kesir, Kahramanmara\u015f, Ayd\u0131n, Adapazar\u0131, Denizli, Mu\u011fla, Eski\u015fehir, Trabzon, Ordu, Afyonkarahisar, Sivas, Tokat, Zonguldak, K\u00fctahya, \u00c7anakkale, Osmaniye and \u00c7orum. All have populations of more than 500,000."}
{"id": "855", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=855", "title": "Abiotic factors", "text": ""}
{"id": "856", "revid": "48588006", "url": "https://en.wikipedia.org/wiki?curid=856", "title": "Apple Inc.", "text": "Apple Inc. is an American multinational corporation and technology company headquartered in Cupertino, California, in Silicon Valley. It is best known for its consumer electronics, software, and services. Founded in 1976 as Apple Computer Company by Steve Jobs, Steve Wozniak and Ronald Wayne, the company was incorporated by Jobs and Wozniak as Apple Computer, Inc. the following year. It was renamed Apple Inc. in 2007 as the company had expanded its focus from computers to consumer electronics. Apple is the largest technology company by revenue, with billion in the 2024 fiscal year.\nThe company was founded to produce and market Wozniak's Apple I personal computer. Its second computer, the Apple II, became a best seller as one of the first mass-produced microcomputers. Apple introduced the Lisa in 1983 and the Macintosh in 1984, as some of the first computers to use a graphical user interface and a mouse. By 1985, internal company problems led to Jobs leaving to form NeXT, Inc., and Wozniak withdrawing to other ventures; John Sculley served as long-time CEO for over a decade. In the 1990s, Apple lost considerable market share in the personal computer industry to the lower-priced Wintel duopoly of the Microsoft Windows operating system on Intel-powered PC clones. In 1997, Apple was weeks away from bankruptcy. To resolve its failed operating system strategy, it bought NeXT, effectively bringing Jobs back to the company, who guided Apple back to profitability over the next decade with the introductions of the iMac, iPod, iPhone, and iPad devices to critical acclaim as well as the iTunes Store, launching the \"Think different\" advertising campaign, and opening the Apple Store retail chain. These moves elevated Apple to consistently be one of the world's most valuable brands since about 2010. Jobs resigned in 2011 for health reasons, and died two months later; he was succeeded as CEO by Tim Cook.\nApple's current product lineup includes portable and home hardware such as the iPhone, iPad, Apple Watch, Mac, and Apple TV; operating systems such as iOS, iPadOS, and macOS; and various software and services including Apple Pay, iCloud, and multimedia streaming services like Apple Music and Apple TV+. Apple is one of the Big Five American information technology companies; for the most part since 2011, Apple has been the world's largest company by market capitalization, and, , is the largest manufacturing company by revenue, the fourth-largest personal computer vendor by unit sales, the largest vendor of tablet computers, and the largest vendor of mobile phones in the world. Apple became the first publicly traded U.S. company to be valued at over $1\u00a0trillion in 2018, and, , is valued at just over $3.74\u00a0trillion.\nApple has received criticism regarding its contractors' labor practices, its relationship with trade unions, its environmental practices, and its business ethics, including anti-competitive practices and materials sourcing. Nevertheless, the company has a large following and enjoys a high level of brand loyalty.\nHistory.\n1976\u20131980: Founding and incorporation.\nApple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership. The company's first product is the Apple I, a computer designed and hand-built entirely by Wozniak. To finance its creation, Jobs sold his Volkswagen Bus, and Wozniak sold his HP-65 calculator. Neither received the full selling price but in total earned . Wozniak debuted the first prototype at the Homebrew Computer Club in July 1976. The Apple I was sold as a motherboard with CPU, RAM, and basic textual-video chips\u2014a base kit concept which was not yet marketed as a complete personal computer. It was priced soon after debut for . Wozniak later said he was unaware of the coincidental mark of the beast in the number 666, and that he came up with the price because he liked \"repeating digits\".\nApple Computer, Inc. was incorporated in Cupertino, California, on January 3, 1977, without Wayne, who had left and sold his share of the company back to Jobs and Wozniak for $800 only twelve days after having co-founded it. Multimillionaire Mike Markkula provided essential business expertise and funding of to Jobs and Wozniak during the incorporation of Apple. During the first five years of operations, revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to million, an average annual growth rate of 533%.\nThe Apple II, also designed by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differs from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. The Apple I and early Apple II models use ordinary audio cassette tapes as storage devices, which were superseded by the -inch floppy disk drive and interface called the Disk II in 1978.\nThe Apple II was chosen to be the desktop platform for the first killer application of the business world: VisiCalc, a spreadsheet program released in 1979. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office, but Apple II market share remained behind home computers made by competitors such as Atari, Commodore, and Tandy.\nOn December 12, 1980, Apple (ticker symbol \"AAPL\") went public selling 4.6 million shares at $22 per share ($.10 per share when adjusting for stock splits ), generating over $100\u00a0million, which was more capital than any IPO since Ford Motor Company in 1956. By the end of the day, around 300\u00a0millionaires were created, including Jobs and Wozniak, from a stock price of $29 per share and a market cap of $1.778\u00a0billion.\n1980\u20131990: Success with Macintosh.\nIn December 1979, Steve Jobs and Apple employees, including Jef Raskin, visited Xerox PARC, where they observed the Xerox Alto, featuring a graphical user interface (GUI). Apple subsequently negotiated access to PARC's technology, leading to Apple's option to buy shares at a preferential rate. This visit influenced Jobs to implement a GUI in Apple's products, starting with the Apple Lisa. Despite being pioneering as a mass-marketed GUI computer, the Lisa suffered from high costs and limited software options, leading to commercial failure.\nJobs, angered by being pushed off the Lisa team, took over the company's Macintosh division. Wozniak and Raskin had envisioned the Macintosh as a low-cost computer with a text-based interface like the Apple II, but a plane crash in 1981 forced Wozniak to step back from the project. Jobs quickly redefined the Macintosh as a graphical system that would be cheaper than the Lisa, undercutting his former division. Jobs was also hostile to the Apple II division, which at the time, generated most of the company's revenue.\nIn 1984, Apple launched the Macintosh, the first personal computer without a bundled programming language. Its debut was signified by \"1984\", a million television advertisement directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. This was hailed as a watershed event for Apple's success and was called a \"masterpiece\" by CNN and one of the greatest TV advertisements of all time by \"TV Guide\".\nThe advertisement created great interest in Macintosh, and sales were initially good, but began to taper off dramatically after the first three months as reviews started to come in. Jobs had required of RAM, which limited its speed and software in favor of aspiring for a projected price point of . The Macintosh shipped for , a price panned by critics due to its slow performance. In early 1985, this sales slump triggered a power struggle between Steve Jobs and CEO John Sculley, who had been hired away from Pepsi two years earlier by Jobs saying, \"Do you want to sell sugar water for the rest of your life or come with me and change the world?\" Sculley removed Jobs as the head of the Macintosh division, with unanimous support from the Apple board of directors.\nThe board of directors instructed Sculley to contain Jobs and his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from leadership. Jean-Louis Gass\u00e9e informed Sculley that Jobs had been attempting to organize a boardroom coup and called an emergency meeting at which Apple's executive staff sided with Sculley and stripped Jobs of all operational duties. Jobs resigned from Apple in September 1985 and took several Apple employees with him to found NeXT. Wozniak had also quit his active employment at Apple earlier in 1985 to pursue other ventures, expressing his frustration with Apple's treatment of the Apple II division and stating that the company had \"been going in the wrong direction for the last five years\". Wozniak remained employed by Apple as a representative, receiving a stipend estimated to be $120,000 per year. Jobs and Wozniak remained Apple shareholders following their departures.\nAfter the departures of Jobs and Wozniak in 1985, Sculley launched the Macintosh 512K that year with quadruple the RAM, and introduced the LaserWriter, the first reasonably priced PostScript laser printer. PageMaker, an early desktop publishing application taking advantage of the PostScript language, was also released by Aldus Corporation in July 1985. It has been suggested that the combination of Macintosh, LaserWriter, and PageMaker was responsible for the creation of the desktop publishing market.\nThis dominant position in the desktop publishing market allowed the company to focus on higher price points, the so-called \"high-right policy\" named for the position on a chart of price vs. profits. Newer models selling at higher price points offered higher profit margin, and appeared to have no effect on total sales as power users snapped up every increase in speed. Although some worried about pricing themselves out of the market, the high-right policy was in full force by the mid-1980s, due to Jean-Louis Gass\u00e9e's slogan of \"fifty-five or die\", referring to the 55% profit margins of the Macintosh II.\nThis policy began to backfire late in the decade as desktop publishing programs appeared on IBM PC compatibles with some of the same functionality of the Macintosh at far lower price points. The company lost its dominant position in the desktop publishing market and estranged many of its original consumer customer base who could no longer afford Apple products. The Christmas season of 1989 was the first in the company's history to have declining sales, which led to a 20% drop in Apple's stock price. During this period, the relationship between Sculley and Gass\u00e9e deteriorated, leading Sculley to effectively demote Gass\u00e9e in January 1990 by appointing Michael Spindler as the chief operating officer. Gass\u00e9e left the company later that year to set up a rival, Be Inc.\n1990\u20131997: Decline and restructuring.\nThe company pivoted strategy and, in October 1990, introduced three lower-cost models: the Macintosh Classic, the Macintosh LC, and the Macintosh IIsi, all of which generated significant sales due to pent-up demand. In 1991, Apple introduced the hugely successful PowerBook with a design that set the current shape for almost all modern laptops. The same year, Apple introduced System 7, a major upgrade to the Macintosh operating system, adding color to the interface and introducing new networking capabilities.\nThe success of the lower-cost Macs and PowerBook brought increasing revenue. For some time, Apple was doing very well, introducing fresh new products at increasing profits. The magazine \"MacAddict\" named the period between 1989 and 1991 as the \"first golden age\" of the Macintosh.\nThe success of lower-cost consumer Macs, especially the LC, cannibalized higher-priced machines. To address this, management introduced several new brands, selling largely identical machines at different price points, for different markets: the high-end Quadra series, the mid-range Centris series, and the consumer-marketed Performa series. This led to significant consumer confusion between so many models.\nIn 1993, the Apple II series was discontinued. It was expensive to produce, and the company decided it was still absorbing sales from lower-cost Macintosh models. After the launch of the LC, Apple encouraged developers to create applications for Macintosh rather than Apple II, and authorized salespersons to redirect consumers from Apple II and toward Macintosh. The Apple IIe was discontinued in 1993.\nApple experimented with several other unsuccessful consumer targeted products during the 1990s, including QuickTake digital cameras, PowerCD portable CD audio players, speakers, the Pippin video game console, the eWorld online service, and Apple Interactive Television Box. Enormous resources were invested in the problematic Newton tablet division, based on John Sculley's unrealistic market forecasts.\nThroughout this period, Microsoft continued to gain market share with Windows by focusing on delivering software to inexpensive personal computers, while Apple was delivering a richly engineered but expensive experience. Apple relied on high profit margins and never developed a clear response; it sued Microsoft for making a GUI similar to the Lisa in \"Apple Computer, Inc. v. Microsoft Corp.\" The lawsuit dragged on for years and was finally dismissed. The major product flops and the rapid loss of market share to Windows sullied Apple's reputation, and in 1993 Sculley was replaced as CEO by Michael Spindler.\nUnder Spindler, Apple, IBM, and Motorola formed the AIM alliance in 1994 to create a new computing platform (the PowerPC Reference Platform or PReP), with IBM and Motorola hardware coupled with Apple software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind and thus counter the dominance of Windows. That year, Apple introduced the Power Macintosh, the first of many computers with Motorola's PowerPC processor.\nIn the wake of the alliance, Apple opened up to the idea of allowing Motorola and other companies to build Macintosh clones. Over the next two years, 75 distinct Macintosh clone models were introduced. However, by 1996, Apple executives were worried that the clones were cannibalizing sales of its own high-end computers, where profit margins were highest.\nIn 1996, Spindler was replaced as CEO by Gil Amelio, who was hired for his reputation as a corporate rehabilitator. Amelio made deep changes, including extensive layoffs and cost-cutting.\nThis period was also marked by numerous failed attempts to modernize the Macintosh operating system (MacOS). The original Macintosh operating system (System 1) was not built for multitasking (running several applications at once). The company attempted to correct this by introducing cooperative multitasking in System 5, but still decided it needed a more modern approach. This led to the Pink project in 1988, A/UX that same year, Copland in 1994, and evaluated the purchase of BeOS in 1996. Talks with Be stalled when the CEO, former Apple executive Jean-Louis Gass\u00e9e, demanded $300\u00a0million in contrast to Apple's $125\u00a0million offer. Only weeks away from bankruptcy, Apple's board preferred NeXTSTEP and purchased NeXT in late 1996 for $400\u00a0million, retaining Steve Jobs.\n1997\u20132007: Return to profitability.\nThe NeXT acquisition was finalized on February 9, 1997, and the board brought Jobs back to Apple as an advisor. On July 9, 1997, Jobs staged a boardroom coup that resulted in Amelio's resignation after overseeing a three-year record-low stock price and crippling financial losses. The board named Jobs as interim CEO and he immediately reviewed the product lineup. Jobs canceled 70% of models, ending 3,000 jobs and paring to the core of its computer offerings.\nThe next month, in August 1997, Steve Jobs convinced Microsoft to make a $150\u00a0million investment in Apple and a commitment to continue developing Mac software. This was seen as an \"antitrust insurance policy\" for Microsoft which had recently settled with the Department of Justice over anti-competitive practices in the \"United States v. Microsoft Corp.\" case. Around then, Jobs donated Apple's internal library and archives to Stanford University, to focus more on the present and the future rather than the past. He ended the Mac clone deals and in September 1997, purchased the largest clone maker, Power Computing. On November 10, 1997, the Apple Store website launched, which was tied to a new build-to-order manufacturing model similar to PC manufacturer Dell's success. The moves paid off for Jobs; at the end of his first year as CEO, the company had a $309\u00a0million profit.\nOn May 6, 1998, Apple introduced a new all-in-one computer reminiscent of the original Macintosh: the iMac. The iMac was a huge success, with 800,000 units sold in its first five months, and ushered in major shifts in the industry by abandoning legacy technologies like the -inch diskette, being an early adopter of the USB connector, and coming pre-installed with Internet connectivity (the \"i\" in iMac) via Ethernet and a dial-up modem. Its striking teardrop shape and translucent materials were designed by Jonathan Ive, who had been hired by Amelio, and who collaborated with Jobs for more than a decade to reshape Apple's product design.\nA little more than a year later on July 21, 1999, Apple introduced the iBook consumer laptop. It culminated Jobs's strategy to produce only four products: refined versions of the Power Macintosh G3 desktop and PowerBook G3 laptop for professionals, and the iMac desktop and iBook laptop for consumers. Jobs said the small product line allowed for a greater focus on quality and innovation.\nAround then, Apple also completed numerous acquisitions to create a portfolio of digital media production software for both professionals and consumers. Apple acquired Macromedia's Key Grip digital video editing software project which was launched as Final Cut Pro in April 1999. Key Grip's development also led to Apple's release of the consumer video-editing product iMovie in October 1999. Apple acquired the German company Astarte in April 2000, which had developed the DVD authoring software DVDirector, which Apple repackaged as the professional-oriented DVD Studio Pro, and reused its technology to create iDVD for the consumer market. In 2000, Apple purchased the SoundJam MP audio player software from Casady &amp; Greene. Apple renamed the program iTunes, and simplified the user interface and added CD burning.\nIn 2001, Apple changed course with three announcements. First, on March 24, 2001, Apple announced the release of a new modern operating system, Mac OS X. This was after numerous failed attempts in the early 1990s, and several years of development. Mac OS X is based on NeXTSTEP, OpenStep, and BSD Unix, to combine the stability, reliability, and security of Unix with the ease of use of an overhauled user interface. Second, in May 2001, the first two Apple Store retail locations opened in Virginia and California, offering an improved presentation of the company's products. At the time, many speculated that the stores would fail, but they became highly successful, and the first of more than 500 stores around the world. Third, on October 23, 2001, the iPod portable digital audio player debuted. The product was first sold on November 10, 2001, and was extremely successful, with over 100\u00a0million units sold within six years.\nIn 2003, the iTunes Store was introduced with music downloads for 99\u00a2 a song and iPod integration. It quickly became the market leader in online music services, with over 5\u00a0billion downloads by June 19, 2008. Two years later, the iTunes Store was the world's largest music retailer.\nIn 2002, Apple purchased Nothing Real for its advanced digital compositing application Shake, and Emagic for the music productivity application Logic. The purchase of Emagic made Apple the first computer manufacturer to own a music software company. The acquisition was followed by the development of Apple's consumer-level GarageBand application. The release of iPhoto that year completed the iLife suite.\nAt the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would move away from PowerPC processors, and the Mac would transition to Intel processors in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line\u2014over one year sooner than announced. The Power Mac, iBook, and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.\nApple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. When Apple surpassed Dell's market cap in January 2006, Jobs sent an email to Apple employees saying Dell's CEO Michael Dell should eat his words. Nine years prior, Dell had said that if he ran Apple he would \"shut it down and give the money back to the shareholders\".\n2007\u20132011: Success with mobile devices.\nDuring his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced the renaming of Apple Computer, Inc. to Apple Inc., because the company had broadened its focus from computers to consumer electronics. This event also saw the announcement of the iPhone and the Apple TV. The company sold 270,000 first-generation iPhones during the first 30 hours of sales, and the device was called \"a game changer for the industry\".\nIn an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management, thereby allowing tracks to be played on third-party players if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce that all songs on the iTunes Store are available without their FairPlay DRM.\nIn July 2008, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60\u00a0million applications and registered an average daily revenue of $1\u00a0million, with Jobs speculating in August 2008 that the App Store could become a billion-dollar business for Apple. By October 2008, Apple was the third-largest mobile handset supplier in the world due to the popularity of the iPhone.\nOn January 14, 2009, Jobs announced in an internal memo that he would be taking a six-month medical leave of absence from Apple until the end of June 2009 and would spend the time focusing on his health. In the email, Jobs stated that \"the curiosity over my personal health continues to be a distraction not only for me and my family, but everyone else at Apple as well\", and explained that the break would allow the company \"to focus on delivering extraordinary products\". Though Jobs was absent, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession, with revenue of $8.16\u00a0billion and profit of $1.21\u00a0billion.\nAfter years of speculation and multiple rumored \"leaks\", Apple unveiled a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad ran the same touch-based operating system as the iPhone, and all iPhone apps were compatible with the iPad. This gave the iPad a large app catalog on launch, though having very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the U.S. It sold more than 300,000 units on its first day, and 500,000 by the end of the first week. In May 2010, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.\nIn June 2010, Apple released the iPhone 4, which introduced video calling using FaceTime, multitasking, and a new design with an exposed stainless steel frame as the phone's antenna system. Later that year, Apple again refreshed the iPod line by introducing a multi-touch iPod Nano, an iPod Touch with FaceTime, and an iPod Shuffle that brought back the clickwheel buttons of earlier generations. It also introduced the smaller, cheaper second-generation Apple TV which allowed the rental of movies and shows.\nOn January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence for an indefinite period to allow him to focus on his health. Chief operating officer Tim Cook assumed Jobs's day-to-day operations at Apple, although Jobs would still remain \"involved in major strategic decisions\". Apple became the most valuable consumer-facing brand in the world. In June 2011, Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files, and software which replaced MobileMe, Apple's previous attempt at content syncing. This would be the last product launch Jobs would attend before his death.\nOn August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Cook and Jobs became Apple's chairman. Apple did not have a chairman at the time and instead had two co-lead directors\u2014Andrea Jung and Arthur D. Levinson\u2014who continued with those titles until Levinson replaced Jobs as chairman of the board in November after Jobs's death.\n2011\u2013present: Post-Jobs era, Tim Cook.\nOn October 5, 2011, Steve Jobs died, marking the end of an era for Apple. The next major product announcement by Apple was on January 19, 2012, when Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. Jobs stated in the biography \"Steve Jobs\" that he wanted to reinvent the textbook industry and education.\nFrom 2011 to 2012, Apple released the iPhone 4s and iPhone 5, which featured improved cameras, an intelligent software assistant named Siri, and cloud-synced data with iCloud; the third- and fourth-generation iPads, which featured Retina displays; and the iPad Mini, which featured a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. These launches were successful, with the iPhone 5 (released September 21, 2012) becoming Apple's biggest iPhone launch with over two million pre-orders and sales of three million iPads in three days following the launch of the iPad Mini and fourth-generation iPad (released November 3, 2012). Apple also released a third-generation 13-inch MacBook Pro with a Retina display and new iMac and Mac Mini computers.\nOn August 20, 2012, Apple's rising stock price increased the company's market capitalization to a then-record $624\u00a0billion. This beat the non-inflation-adjusted record for market capitalization previously set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05\u00a0billion (\u00a3665m) in damages in an intellectual property lawsuit. Samsung appealed the damages award, which was reduced by $450\u00a0million and further granted Samsung's request for a new trial. On November 10, 2012, Apple confirmed a global settlement that dismissed all existing lawsuits between Apple and HTC up to that date, in favor of a ten-year license agreement for current and future patents between the two companies. It is predicted that Apple will make million per year from this deal with HTC.\nIn May 2014, Apple confirmed its intent to acquire Dr. Dre and Jimmy Iovine's audio company Beats Electronics\u2014producer of the \"Beats by Dr. Dre\" line of headphones and speaker products, and operator of the music streaming service Beats Music\u2014for billion, and to sell their products through Apple's retail outlets and resellers. Iovine believed that Beats had always \"belonged\" with Apple, as the company modeled itself after Apple's \"unmatched ability to marry culture and technology\". The acquisition was the largest purchase in Apple's history.\nDuring a press event on September 9, 2014, Apple introduced a smartwatch called the Apple Watch. Initially, Apple marketed the device as a fashion accessory and a complement to the iPhone, that would allow people to look at their smartphones less. Over time, the company has focused on developing health and fitness-oriented features on the watch, in an effort to compete with dedicated activity trackers. In January 2016, Apple announced that over one billion Apple devices were in active use worldwide.\nOn June 6, 2016, \"Fortune\" released Fortune 500, its list of companies ranked on revenue generation. In the trailing fiscal year of 2015, Apple was listed as the top tech company. It ranked third, overall, with billion in revenue. This represents a movement upward of two spots from the previous year's list.\nIn June 2017, Apple announced the HomePod, its smart speaker aimed to compete against Sonos, Google Home, and Amazon Echo. Toward the end of the year, \"TechCrunch\" reported that Apple was acquiring Shazam, a company that introduced its products at WWDC and specializing in music, TV, film and advertising recognition. The acquisition was confirmed a few days later, reportedly costing Apple million, with media reports that the purchase looked like a move to acquire data and tools bolstering the Apple Music streaming service. The purchase was approved by the European Union in September 2018.\nAlso in June 2017, Apple appointed Jamie Erlicht and Zack Van Amburg to head the newly formed worldwide video unit. In November 2017, Apple announced it was branching out into original scripted programming: a drama series starring Jennifer Aniston and Reese Witherspoon, and a reboot of the anthology series Amazing Stories with Steven Spielberg. In June 2018, Apple signed the Writers Guild of America's minimum basic agreement and Oprah Winfrey to a multi-year content partnership. Additional partnerships for original series include Sesame Workshop and DHX Media and its subsidiary Peanuts Worldwide, and a partnership with A24 to create original films.\nDuring the Apple Special Event in September 2017, the AirPower wireless charger was announced alongside the iPhone X, iPhone 8, and Watch Series 3. The AirPower was intended to wirelessly charge multiple devices, simultaneously. Though initially set to release in early 2018, the AirPower would be canceled in March 2019, marking the first cancellation of a device under Cook's leadership. On August 19, 2020, Apple's share price briefly topped $467.77, making it the first US company with a market capitalization of trillion.\nDuring its annual WWDC keynote speech on June 22, 2020, Apple announced it would move away from Intel processors, and the Mac would transition to processors developed in-house. The announcement was expected by industry analysts, and it has been noted that Macs featuring Apple's processors would allow for big increases in performance over current Intel-based models. On November 10, 2020, the MacBook Air, MacBook Pro, and the Mac Mini became the first Macs powered by an Apple-designed processor, the Apple M1.\nIn April 2022, it was reported that Samsung Electro-Mechanics would be collaborating with Apple on its M2 chip instead of LG Innotek. Developer logs showed that at least nine Mac models with four different M2 chips were being tested.\n\"The Wall Street Journal\" reported that Apple's effort to develop its own chips left it better prepared to deal with the semiconductor shortage that emerged during the COVID-19 pandemic, which led to increased profitability, with sales of M1-based Mac computers rising sharply in 2020 and 2021. It also inspired other companies like Tesla, Amazon, and Meta Platforms to pursue a similar path.\nIn April 2022, Apple opened an online store that allowed anyone in the U.S. to view repair manuals and order replacement parts for specific recent iPhones, although the difference in cost between this method and official repair is anticipated to be minimal.\nIn May 2022, a trademark was filed for RealityOS, an operating system reportedly intended for virtual and augmented reality headsets, first mentioned in 2017. According to Bloomberg, the headset may come out in 2023. Further insider reports state that the device uses iris scanning for payment confirmation and signing into accounts.\nOn June 18, 2022, the Apple Store in Towson, Maryland, became the first to unionize in the U.S., with the employees voting to join the International Association of Machinists and Aerospace Workers.\nOn July 7, 2022, Apple added Lockdown Mode to macOS 13 and iOS 16, as a response to the earlier Pegasus revelations; the mode increases security protections for high-risk users against targeted zero-day malware.\nApple launched a buy now, pay later service called 'Apple Pay Later' for its Apple Wallet users in March 2023. The program allows its users to apply for loans between $50 and $1,000 to make online or in-app purchases and then repaying them through four installments spread over six weeks without any interest or fees.\nIn November 2023, Apple agreed to a $25 million settlement in a U.S. Department of Justice case that alleged Apple was discriminating against U.S. citizens in hiring. Apple created jobs that were not listed online and required paper submission to apply for, while advertising these jobs to foreign workers as part of recruitment for PERM.\nIn January 2024, Apple announced compliance with the European Union's competition law, with major changes to the App Store and other services, effective on March 7. This enables iOS users in the 27-nation bloc to use alternative app stores, and alternative payment methods within apps. This adds a menu in Safari for downloading alternative browsers, such as Chrome or Firefox.\nIn June 2024, Apple introduced Apple Intelligence to incorporate on-device artificial intelligence capabilities.\nOn November 1, 2024, Apple announced its acquisition of Pixelmator, a company known for its image editing applications for iPhone and Mac. Apple had previously showcased Pixelmator's apps during its product launches, including naming Pixelmator Pro its Mac App of the Year in 2018 for its innovative use of machine learning and AI. In the announcement, Pixelmator stated that there would be no significant changes to its existing apps following the acquisition.\nOn December 31, 2024, a preliminary settlement was filed in the Oakland, California federal court that accused Apple of unlawfully recording private conversations through unintentional Siri activations and shared them with third parties, including advertisers. Apple agreed to a $95 million cash settlement to resolve this lawsuit in which its Siri assistant violated user privacy. While denying any wrongdoing, Apple settled the case, allowing affected users to potentially claim up to $20 per device. Attorneys sought $28.5 million in fees from the settlement fund.\nProducts.\nSince the company's founding and into the early 2000s, Apple primarily sold computers, which are marketed as Macintosh since the mid-1980s. Since then, the company has expanded its product categories to include various portable devices, starting with the now discontinued iPod (2001), and later with the iPhone (2007) and iPad (2010). Apple also sells several other products that it categorizes as \"Wearables, Home and Accessories\", such as the Apple Watch, Apple TV, AirPods, HomePod, and Apple Vision Pro.\nApple devices have been praised for creating a cohesive ecosystem when used in conjunction with other Apple products, though have received criticism for not functioning as well or with as many features when used with competitive devices and instead often relying on Apple's proprietary features, software, and services to work as intended by Apple, an approach often described as \"walled garden\". As of 2023, there are over 2 billion Apple devices in active use worldwide.\nMac.\nMac, which is short for Macintosh\u2014its official name until 1999\u2014is Apple's line of personal computers that use the company's proprietary macOS operating system. Personal computers were Apple's original business line, but they account for only about eight percent of the company's revenue.\nThere are six Mac computer families in production:\nOften described as a walled garden, Macs use Apple silicon chips, run the macOS operating system, and include Apple software like the Safari web browser, iMovie for home movie editing, GarageBand for music creation, and the iWork productivity suite. Apple also sells pro apps: Final Cut Pro for video production, Logic Pro for musicians and producers, and Xcode for software developers. Apple also sells a variety of accessories for Macs, including the Pro Display XDR, Apple Studio Display, Magic Mouse, Magic Trackpad, and Magic Keyboard.\niPhone.\nThe iPhone is Apple's line of smartphones, which run the iOS operating system. The first iPhone was unveiled by Steve Jobs on January 9, 2007. Since then, new iPhone models have been released every year. When it was introduced, its multi-touch screen was described as \"revolutionary\" and a \"game-changer\" for the mobile phone industry. The device has been credited with creating the app economy.\niOS is one of the two major smartphone platforms in the world, alongside Android. The iPhone has generated large profits for the company, and is credited with helping to make Apple one of the world's most valuable publicly traded companies. , the iPhone accounts for nearly half of the company's revenue.\niPad.\nThe iPad is Apple's line of tablets which run iPadOS. The first-generation iPad was announced on January 27, 2010. The iPad is mainly marketed for consuming multimedia, creating art, working on documents, videoconferencing, and playing games. The iPad lineup consists of several base iPad models, and the smaller iPad Mini, upgraded iPad Air, and high-end iPad Pro. Apple has consistently improved the iPad's performance, with the iPad Pro adopting the same M1 and M2 chips as the Mac; but the iPad still receives criticism for its limited OS.\n Apple has sold more than 500\u00a0million iPads, though sales peaked in 2013. The iPad still remains the most popular tablet computer by sales , and accounted for seven percent of the company's revenue . Apple sells several iPad accessories, including the Apple Pencil, Smart Keyboard, Smart Keyboard Folio, Magic Keyboard, and several adapters.\nOther products.\nApple makes several other products that it categorizes as \"Wearables, Home and Accessories\". These products include the AirPods line of wireless headphones, Apple TV digital media players, Apple Watch smartwatches, Beats headphones, HomePod smart speakers, and the Vision Pro mixed reality headset. , this broad line of products comprises about ten percent of the company's revenues.\nServices.\nApple offers a broad line of services, including advertising in the App Store and Apple News app, the AppleCare+ extended warranty plan, the iCloud+ cloud-based data storage service, payment services through the Apple Card credit card and the Apple Pay processing platform, digital content services including Apple Books, Apple Fitness+, Apple Music, Apple News+, Apple TV+, and the iTunes Store. , services comprise about 26% of the company's revenue. In 2019, Apple announced it would be making a concerted effort to expand its service revenues.\nMarketing.\nBranding.\nAccording to Steve Jobs, the company's name was inspired by his visit to an apple farm while on a fruitarian diet. Apple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's \"rainbow Apple\", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. This logo has been erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his method of suicide.\nOn August 27, 1999, Apple officially dropped the rainbow scheme and began to use monochromatic logos nearly identical in shape to the previous rainbow incarnation. An Aqua-themed version of the monochrome logo was used from 1998 until 2003, and a glass-themed version was used from 2007 until 2013.\nApple evangelists were actively engaged by the company at one time, but this was after the phenomenon had already been firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism \"something that was stumbled upon\", while Ive claimed in 2014 that \"people have an incredibly personal relationship\" with Apple's products.\n\"Fortune\" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. On September 30, 2013, Apple surpassed Coca-Cola to become the world's most valuable brand in the Omnicom Group's \"Best Global Brands\" report. Boston Consulting Group has ranked Apple as the world's most innovative brand every year . 1.65 billion Apple products were in active use. In February 2023, that number exceeded 2 billion devices. In 2023, the World Intellectual Property Organization (WIPO)'s Madrid Yearly Review ranked Apple Inc.'s number of marks applications filled under the Madrid System as 10th in the world, with 74 trademarks applications submitted during 2023.\nApple was ranked the No. 3 company in the world in the 2024 \"Fortune 500\" list.\nAdvertising.\nApple's first slogan, \"Byte into an Apple\", was coined in the late 1970s. From 1997 to 2002, the slogan \"Think different\" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines\u2014for example, \"iThink, therefore iMac\" was used in 1998 to promote the iMac, and \"Say hello to iPhone\" has been used in iPhone advertisements. \"Hello\" was also used to introduce the original Macintosh, Newton, iMac (\"hello (again)\"), and iPod.\nFrom the introduction of the Macintosh in 1984, with the 1984 Super Bowl advertisement to the more modern Get a Mac adverts, Apple has been recognized for its efforts toward effective advertising and marketing for its products. However, claims made by later campaigns were criticized, particularly the 2005 Power Mac ads. Apple's product advertisements gained significant attention as a result of their eye-popping graphics and catchy tunes. Musicians who benefited from an improved profile as a result of their songs being included on Apple advertisements include Canadian singer Feist with the song \"1234\" and Yael Na\u00efm with the song \"New Soul\".\nStores.\nThe first Apple Stores were originally opened as two locations in May 2001 by then-CEO Steve Jobs, after years of attempting but failing store-within-a-store concepts. Seeing a need for improved retail presentation of the company's products, he began an effort in 1997 to revamp the retail program to get an improved relationship to consumers, and hired Ron Johnson in 2000. Jobs relaunched Apple's online store in 1997, and opened the first two physical stores in 2001. The media initially speculated that Apple would fail, but its stores were highly successful, bypassing the sales numbers of competing nearby stores, and within three years reached US$1 billion in annual sales, becoming the fastest retailer in history to do so.\nOver the years, Apple has expanded the number of retail locations and its geographical coverage, with 499 stores across 22 countries worldwide . Strong product sales have placed Apple among the top-tier retail stores, with sales over $16 billion globally in 2011. Apple Stores underwent a period of significant redesign, beginning in May 2016. This redesign included physical changes to the Apple Stores, such as open spaces and re-branded rooms, and changes in function to facilitate interaction between consumers and professionals.\nMany Apple Stores are located inside shopping malls, but Apple has built several stand-alone \"flagship\" stores in high-profile locations. It has been granted design patents and received architectural awards for its stores' designs and construction, specifically for its use of glass staircases and cubes. The success of Apple Stores have had significant influence over other consumer electronics retailers, who have lost traffic, control and profits due to a perceived higher quality of service and products at Apple Stores. Due to the popularity of the brand, Apple receives a large number of job applications, many of which come from young workers. Although Apple Store employees receive above-average pay, are offered money toward education and health care, and receive product discounts, there are limited or no paths of career advancement.\nMarket power.\nOn March 16, 2020, France fined Apple \u20ac1.1 billion for colluding with two wholesalers to stifle competition and keep prices high by handicapping independent resellers. The arrangement created aligned prices for Apple products such as iPads and personal computers for about half the French retail market. According to the French regulators, the abuses occurred between 2005 and 2017 but were first discovered after a complaint by an independent reseller, eBizcuss, in 2012.\nOn August 13, 2020, Epic Games, the maker of the popular game \"Fortnite\", sued both Apple and Google after \"Fortnite\" was removed from Apple's and Google's app stores. The lawsuits came after Apple and Google blocked the game after it introduced a direct payment system that bypassed the fees that Apple and Google had imposed. In September 2020, Epic Games founded the Coalition for App Fairness together with thirteen other companies, which aims for better conditions for the inclusion of apps in the app stores. Later, in December 2020, Facebook agreed to assist Epic in their legal game against Apple, planning to support the company by providing materials and documents to Epic. Facebook had, however, stated that the company would not participate directly with the lawsuit, although did commit to helping with the discovery of evidence relating to the trial of 2021. In the months prior to their agreement, Facebook had been dealing with feuds against Apple relating to the prices of paid apps and privacy rule changes. Head of ad products for Facebook Dan Levy commented, saying that \"this is not really about privacy for them, this is about an attack on personalized ads and the consequences it's going to have on small-business owners,\" commenting on the full-page ads placed by Facebook in various newspapers in December 2020.\nPrivacy.\nApple has publicly taken a pro-privacy stance, actively making privacy-conscious features and settings part of its conferences, promotional campaigns, and public image. With its iOS 8 mobile operating system in 2014, the company started encrypting all contents of iOS devices through users' passcodes, making it impossible at the time for the company to provide customer data to law enforcement requests seeking such information. With the popularity rise of cloud storage solutions, Apple began a technique in 2016 to do deep learning scans for facial data in photos on the user's local device and encrypting the content before uploading it to Apple's iCloud storage system. It also introduced \"differential privacy\", a way to collect crowdsourced data from many users, while keeping individual users anonymous, in a system that \"Wired\" described as \"trying to learn as much as possible about a group while learning as little as possible about any individual in it\". Users are explicitly asked if they want to participate, and can actively opt-in or opt-out.\nHowever, Apple has aided law enforcement in criminal investigations by providing iCloud backups of users' devices, and the company's commitment to privacy has been questioned by its efforts to promote biometric authentication technology in its newer iPhone models, which do not have the same level of constitutional privacy as a passcode in the United States.\nWith Apple's release of an update to iOS 14, Apple required all developers of iPhone, iPad, and iPod Touch applications to directly ask iPhone users permission to track them. The feature, called \"App Tracking Transparency\", received heavy criticism from Facebook, whose primary business model revolves around the tracking of users' data and sharing such data with advertisers so users can see more relevant ads, a technique commonly known as targeted advertising. After Facebook's measures, including purchasing full-page newspaper advertisements protesting App Tracking Transparency, Apple released the update in early 2021. A study by Verizon subsidiary Flurry Analytics reported only 4% of iOS users in the United States and 12% worldwide have opted into tracking.\nPrior to the release of iOS 15, Apple announced new efforts at combating child sexual abuse material on iOS and Mac platforms. Parents of minor iMessage users can now be alerted if their child sends or receives nude photographs. Additionally, on-device hashing would take place on media destined for upload to iCloud, and hashes would be compared to a list of known abusive images provided by law enforcement; if enough matches were found, Apple would be alerted and authorities informed. The new features received praise from law enforcement and victims rights advocates. However, privacy advocates, including the Electronic Frontier Foundation, condemned the new features as invasive and highly prone to abuse by authoritarian governments.\nIreland's Data Protection Commission launched a privacy investigation to examine whether Apple complied with the EU's GDPR law following an investigation into how the company processes personal data with targeted ads on its platform.\nIn December 2019, security researcher Brian Krebs discovered that the iPhone 11 Pro would still show the arrow indicator \u2013signifying location services are being used\u2013 at the top of the screen while the main location services toggle is enabled, despite all individual location services being disabled. Krebs was unable to replicate this behavior on older models and when asking Apple for comment, he was told by Apple that \"It is expected behavior that the Location Services icon appears in the status bar when Location Services is enabled. The icon appears for system services that do not have a switch in Settings.\"\nApple later further clarified that this behavior was to ensure compliance with ultra-wideband regulations in specific countries, a technology Apple started implementing in iPhones starting with iPhone 11 Pro, and emphasized that \"the management of ultra wideband compliance and its use of location data is done entirely on the device and Apple is not collecting user location data.\" Will Strafach, an executive at security firm Guardian Firewall, confirmed the lack of evidence that location data was sent off to a remote server. Apple promised to add a new toggle for this feature and in later iOS revisions Apple provided users with the option to tap on the location services indicator in Control Center to see which specific service is using the device's location.\nAccording to published reports by Bloomberg News on March 30, 2022, Apple turned over data such as phone numbers, physical addresses, and IP addresses to hackers posing as law enforcement officials using forged documents. The law enforcement requests sometimes included forged signatures of real or fictional officials. When asked about the allegations, an Apple representative referred the reporter to a section of the company policy for law enforcement guidelines, which stated, \"We review every data request for legal sufficiency and use advanced systems and processes to validate law enforcement requests and detect abuse.\"\nCorporate affairs.\nBusiness trends.\nThe key trends for Apple are, as of each financial year ending September 24:\nLeadership.\nSenior management.\n, the management of Apple Inc. includes:\nBoard of directors.\n, the board of directors of Apple Inc. includes:\nOwnership.\n, the largest shareholders of Apple were:\nCorporate culture.\nApple is one of several highly successful companies founded in the 1970s that bucked the traditional notions of corporate culture. Jobs often walked around the office barefoot even after Apple became a Fortune 500 company. By the time of the \"1984\" television advertisement, Apple's informal culture had become a key trait that differentiated it from its competitors. According to a 2011 report in \"Fortune\", this has resulted in a corporate culture more akin to a startup rather than a multinational corporation. In a 2017 interview, Wozniak credited watching \"Star Trek\" and attending \"Star Trek\" conventions in his youth as inspiration for co-founding Apple.\nAs the company has grown and been led by a series of differently opinionated chief executives, some media have suggested that it has lost some of its original character. Nonetheless, it has maintained a reputation for fostering individuality and excellence that reliably attracts talented workers, particularly after Jobs returned. Numerous Apple employees have stated that projects without Jobs's involvement often took longer than others.\nThe Apple Fellows program awards employees for extraordinary technical or leadership contributions to personal computing. Recipients include Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Al Alcorn, Don Norman, Rich Page, Steve Wozniak, and Phil Schiller.\nJobs intended that employees were to be specialists who are not exposed to functions outside their area of expertise. For instance, Ron Johnson\u2014Senior Vice President of Retail Operations until November 1, 2011\u2014was responsible for site selection, in-store service, and store layout, yet had no control of the inventory in his stores. This was done by Tim Cook, who had a background in supply-chain management. Apple is known for strictly enforcing accountability. Each project has a \"directly responsible individual\" or \"DRI\" in Apple jargon. Unlike other major U.S. companies, Apple provides a relatively simple compensation policy for executives that does not include perks enjoyed by other CEOs like country club fees or private use of company aircraft. The company typically grants stock options to executives every other year.\nIn 2015, Apple had 110,000\u00a0full-time employees. This increased to 116,000\u00a0full-time employees the next year, a notable hiring decrease, largely due to its first revenue decline. Apple does not specify how many of its employees work in retail, though its 2014 SEC filing put the number at approximately half of its employee base. In September 2017, Apple announced that it had over 123,000 full-time employees.\nApple has a strong culture of corporate secrecy, and has an anti-leak Global Security team that recruits from the National Security Agency, the Federal Bureau of Investigation, and the United States Secret Service. In December 2017, Glassdoor said Apple was the 48th best place to work, having originally entered at rank 19 in 2009, peaking at rank 10 in 2012, and falling down the ranks in subsequent years. In 2023, \"Bloomberg\" Mark Gurman revealed the existence of Apple's Exploratory Design Group (XDG), which was working to add glucose monitoring to the Apple Watch. Gurman compared XDG to Alphabet's X \"moonshot factory\".\nOffices.\nApple Inc.'s world corporate headquarters are located in Cupertino, in the middle of California's Silicon Valley, at Apple Park, a massive circular groundscraper building with a circumference of . The building opened in April 2017 and houses more than 12,000 employees. Apple co-founder Steve Jobs wanted Apple Park to look less like a business park and more like a nature refuge, and personally appeared before the Cupertino City Council in June 2011 to make the proposal, in his final public appearance before his death.\nApple also operates from the Apple Campus (also known by its address, 1 Infinite Loop), a grouping of six buildings in Cupertino that total located about to the west of Apple Park. The Apple Campus was the company's headquarters from its opening in 1993, until the opening of Apple Park in 2017. The buildings, located at 1\u20136 Infinite Loop, are arranged in a circular pattern around a central green space, in a design that has been compared to that of a university.\nIn addition to Apple Park and the Apple Campus, Apple occupies an additional thirty office buildings scattered throughout the city of Cupertino, including three buildings as prior headquarters: Stephens Creek Three from 1977 to 1978, Bandley One from 1978 to 1982, and Mariani One from 1982 to 1993. In total, Apple occupies almost 40% of the available office space in the city.\nApple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland, called the Hollyhill campus. The facility, which opened in 1980, houses 5,500 people and was Apple's first location outside of the United States. Apple's international sales and distribution arms operate out of the campus in Cork.\nApple has two campuses near Austin, Texas: a campus opened in 2014 houses 500 engineers who work on Apple silicon and a campus opened in 2021 where 6,000 people work in technical support, supply chain management, online store curation, and Apple Maps data management. The company also has several other locations in Boulder, Colorado; Culver City, California; Herzliya (Israel), London, New York, Pittsburgh, San Diego, and Seattle that each employ hundreds of people.\nLitigation.\nApple has been a participant in various legal proceedings and claims since it began operation. In particular, Apple is known for and promotes itself as actively and aggressively enforcing its intellectual property interests. Some litigation examples include \"Apple v. Samsung\", \"Apple v. Microsoft\", \"Motorola Mobility v. Apple Inc.\", and \"Apple Corps v. Apple Computer\". Apple has also had to defend itself against charges on numerous occasions of violating intellectual property rights. Most have been dismissed in the courts as shell companies known as patent trolls, with no evidence of actual use of patents in question. On December 21, 2016, Nokia announced that in the U.S. and Germany, it has filed a suit against Apple, claiming that the latter's products infringe on Nokia's patents.\nMost recently, in November 2017, the United States International Trade Commission announced an investigation into allegations of patent infringement in regards to Apple's remote desktop technology; Aqua Connect, a company that builds remote desktop software, has claimed that Apple infringed on two of its patents. In January 2022, Ericsson sued Apple over payment of royalty of 5G technology. On June 24, 2024, the European Commission accused Apple of violating the Digital Markets Act by preventing \"app developers from freely steering consumers to alternative channels for offers and content\".\nFinances.\n, Apple is the world's largest technology company by revenue, with US$383.28 billion; the world's largest technology company by total assets; the fourth-largest personal computer vendor by unit sales; and the world's largest mobile phone manufacturer.\nIn its fiscal year ending in September 2011, Apple Inc. reported a total of $108\u00a0billion in annual revenues\u2014a significant increase from its 2010 revenues of $65\u00a0billion\u2014and nearly $82\u00a0billion in cash reserves. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.\nThe company's worldwide annual revenue in 2013 totaled $170\u00a0billion. In May 2013, Apple entered the top ten of the \"Fortune\" 500 list of companies for the first time, rising 11 places above its 2012 ranking to take the sixth position. , Apple has around US$234\u00a0billion of cash and marketable securities, of which 90% is located outside the United States for tax purposes.\nApple amassed 65% of all profits made by the eight largest worldwide smartphone manufacturers in quarter one of 2014, according to a report by Canaccord Genuity. In the first quarter of 2015, the company garnered 92% of all earnings.\nOn April 30, 2017, \"The Wall Street Journal\" reported that Apple had cash reserves of $250\u00a0billion, officially confirmed by Apple as specifically $256.8\u00a0billion a few days later.\n, Apple was the largest publicly traded corporation in the world by market capitalization. On August 2, 2018, Apple became the first publicly traded U.S. company to reach a $1\u00a0trillion market value, and , is valued at just over $3.2 trillion. Apple was ranked No. 4 on the 2018 \"Fortune\" 500 rankings of the largest United States corporations by revenue.\nIn July 2022, Apple reported an 11% decline in Q3 profits compared to 2021. Its revenue in the same period rose 2% year-on-year to $83 billion, though this figure was also lower than in 2021, where the increase was at 36%. The general downturn is reportedly caused by the slowing global economy and supply chain disruptions in China. That year, Apple was one of the largest corporate spenders on research and development worldwide, with R&amp;D expenditure amounting to over $27 billion.\nIn May 2023, Apple reported a decline in its sales for the first quarter of 2023. Compared to that of 2022, revenue for 2023 fell by 3%. This is Apple's second consecutive quarter of sales decline. This fall is attributed to the slowing economy and consumers putting off purchases of iPads and computers due to increased pricing. However, iPhone sales held up with a year-on-year increase of 1.5%. According to Apple, demands for such devices were strong, particularly in Latin America and South Asia.\nTaxes.\nApple has created subsidiaries in low-tax places such as Ireland, the Netherlands, Luxembourg, and the British Virgin Islands to cut the taxes it pays around the world. According to \"The New York Times\", in the 1980s Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. In the late 1980s, Apple was a pioneer of an accounting technique known as the \"Double Irish with a Dutch sandwich\", which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean.\nBritish Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple Inc., were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporate tax rates. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and The Coca-Cola Company, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.\nAccording to a US Senate report on the company's offshore tax structure concluded in May 2013, Apple has held billions of dollars in profits in Irish subsidiaries to pay little or no taxes to any government by using an unusual global tax structure. The main subsidiary, a holding company that includes Apple's retail stores throughout Europe, has not paid any corporate income tax in the last five years. \"Apple has exploited a difference between Irish and U.S. tax residency rules\", the report said. On May 21, 2013, Apple CEO Tim Cook defended his company's tax tactics at a Senate hearing.\nApple says that it is the single largest taxpayer in the U.S., with an effective tax rate of approximately of 26% as of Q2 FY2016. In an interview with the German newspaper \"FAZ\" in October 2017, Tim Cook stated that Apple was the biggest taxpayer worldwide.\nIn 2016, after a two-year investigation, the European Commission claimed that Apple's use of a hybrid Double Irish tax arrangement constituted \"illegal state aid\" from Ireland, and ordered Apple to pay 13 billion euros ($14.5 billion) in unpaid taxes, the largest corporate tax fine in history. This was later annulled, after the European General Court ruled that the commission had provided insufficient evidence. In 2018, Apple repatriated $285 billion to the United States, resulting in a $38 billion tax payment spread over the following eight years.\nCharity.\nApple is a partner of Product Red, a fundraising campaign for AIDS charity. In November 2014, Apple arranged for all App Store revenue in a two-week period to go to the fundraiser, generating more than US$20\u00a0million, and in March 2017, it released an iPhone 7 with a red color finish.\nApple contributes financially to fundraisers in times of natural disasters. In November 2012, it donated $2.5\u00a0million to the American Red Cross to aid relief efforts after Hurricane Sandy, and in 2017 it donated $5\u00a0million to relief efforts for both Hurricane Irma and Hurricane Harvey, and for the 2017 Central Mexico earthquake. The company has used its iTunes platform to encourage donations in the wake of environmental disasters and humanitarian crises, such as the 2010 Haiti earthquake, the 2011 Japan earthquake, Typhoon Haiyan in the Philippines in November 2013, and the 2015 European migrant crisis. Apple emphasizes that it does not incur any processing or other fees for iTunes donations, sending 100% of the payments directly to relief efforts, though it also acknowledges that the Red Cross does not receive any personal information on the users donating and that the payments may not be tax deductible.\nOn April 14, 2016, Apple and the World Wide Fund for Nature (WWF) announced that they have engaged in a partnership to, \"help protect life on our planet\". Apple released a special page in the iTunes App Store, Apps for Earth. In the arrangement, Apple has committed that through April 24, WWF will receive 100% of the proceeds from the applications participating in the App Store via both the purchases of any paid apps and the In-App Purchases. Apple and WWF's Apps for Earth campaign raised more than $8\u00a0million in total proceeds to support WWF's conservation work. WWF announced the results at WWDC 2016 in San Francisco.\nDuring the COVID-19 pandemic, Apple's CEO Cook announced that the company will be donating \"millions\" of masks to health workers in the United States and Europe. On January 13, 2021, Apple announced a $100 million Racial Equity and Justice Initiative to help combat institutional racism worldwide after the 2020 murder of George Floyd. In June 2023, Apple announced doubling this and then distributed more than $200 million to support organizations focused on education, economic growth, and criminal justice. Half is philanthropic grants and half is centered on equity.\nEnvironment.\nApple Energy.\nApple Energy, LLC is a wholly-owned subsidiary of Apple Inc. that sells solar energy. , Apple's solar farms in California and Nevada have been declared to provide 217.9 megawatts of solar generation capacity. Apple has received regulatory approval to construct a landfill gas energy plant in North Carolina to use the methane emissions to generate electricity. Apple's North Carolina data center is already powered entirely by renewable sources.\nEnergy and resources.\nIn 2010, Climate Counts, a nonprofit organization dedicated to directing consumers toward the greenest companies, gave Apple a score of 52 points out of a possible 100, which puts Apple in their top category \"Striding\". This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a \"stuck icon\", adding that Apple at the time was \"a choice to avoid for the climate-conscious consumer\".\nFollowing a Greenpeace protest, Apple released a statement on April 17, 2012, committing to ending its use of coal and shifting to 100% renewable clean energy. By 2013, Apple was using 100% renewable energy to power their data centers. Overall, 75% of the company's power came from clean renewable sources.\nIn May 2015, Greenpeace evaluated the state of the Green Internet and commended Apple on their environmental practices saying, \"Apple's commitment to renewable energy has helped set a new bar for the industry, illustrating in very concrete terms that a 100% renewable Internet is within its reach, and providing several models of intervention for other companies that want to build a sustainable Internet.\"\n, Apple states that 100% of its U.S. operations run on renewable energy, 100% of Apple's data centers run on renewable energy and 93% of Apple's global operations run on renewable energy. However, the facilities are connected to the local grid which usually contains a mix of fossil and renewable sources, so Apple carbon offsets its electricity use. The Electronic Product Environmental Assessment Tool (EPEAT) allows consumers to see the effect a product has on the environment. Each product receives a Gold, Silver, or Bronze rank depending on its efficiency and sustainability. Every Apple tablet, notebook, desktop computer, and display that EPEAT ranks achieves a Gold rating, the highest possible. Although Apple's data centers recycle water 35 times, the increased activity in retail, corporate and data centers also increase the amount of water use to in 2015.\nDuring an event on March 21, 2016, Apple provided a status update on its environmental initiative to be 100% renewable in all of its worldwide operations. Lisa P. Jackson, Apple's vice president of Environment, Policy and Social Initiatives who reports directly to CEO, Tim Cook, announced that , 93% of Apple's worldwide operations are powered with renewable energy. Also featured was the company's efforts to use sustainable paper in their product packaging; 99% of all paper used by Apple in the product packaging comes from post-consumer recycled paper or sustainably managed forests, as the company continues its move to all paper packaging for all of its products.\nApple announced on August 16, 2016, that Lens Technology, one of its major suppliers in China, has committed to power all its glass production for Apple with 100 percent renewable energy by 2018. The commitment is a large step in Apple's efforts to help manufacturers lower their carbon footprint in China. Apple also announced that all 14 of its final assembly sites in China are now compliant with UL's Zero Waste to Landfill validation. The standard, which started in January 2015, certifies that all manufacturing waste is reused, recycled, composted, or converted into energy (when necessary). Since the program began, nearly 140,000 metric tons of waste have been diverted from landfills.\nOn July 21, 2020, Apple announced its plan to become carbon neutral across its entire business, manufacturing supply chain, and product life cycle by 2030. In the next 10 years, Apple will try to lower emissions with a series of innovative actions, including: low carbon product design, expanding energy efficiency, renewable energy, process and material innovations, and carbon removal.\nIn June 2024, the United States Environmental Protection Agency (EPA) published a report about an electronic computer manufacturing facility leased by Apple in 2015 in Santa Clara, California, code named Aria. The EPA report stated that Apple was potentially in violation of federal regulations under the Resource Conservation and Recovery Act (RCRA). According to a report from \"Bloomberg\" in 2018, the facility is used to develop microLED screens under the code name T159. The inspection found that Apple was potentially mistreating waste as only subject to California regulations and that they had potentially miscalculated the effectiveness of Apple's activated carbon filters, which filter volatile organic compounds (VOCs) from the air. The EPA inspected the facility in August 2023 due to a tip from a former Apple employee who posted the report on X.\nToxins.\nFollowing further campaigns by Greenpeace, in 2008, Apple became the first electronics manufacturer to eliminate all polyvinyl chloride (PVC) and brominated flame retardants (BFRs) in its complete product line. In June 2007, Apple began replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays in its computers with mercury-free LED-backlit LCD displays and arsenic-free glass, starting with the upgraded MacBook Pro. Apple offers comprehensive and transparent information about the CO2e, emissions, materials, and electrical usage concerning every product they currently produce or have sold in the past (and which they have enough data needed to produce the report), in their portfolio on their homepage. Allowing consumers to make informed purchasing decisions on the products they offer for sale. In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, and BFRs. Since 2009, all Apple products have mercury-free LED-backlit LCD displays, arsenic-free glass, and non-PVC cables. All Apple products have EPEAT Gold status and beat the latest Energy Star guidelines in each product's respective regulatory category.\nIn November 2011, Apple was featured in Greenpeace's Guide to Greener Electronics, which ranks electronics manufacturers on sustainability, climate and energy policy, and how \"green\" their products are. The company ranked fourth of fifteen electronics companies (moving up five places from the previous year) with a score of 4.6/10. Greenpeace praised Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. Apple continues to score well on product ratings, with all of their products now being free of PVC plastic and BFRs. However, the guide criticized Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data, and for not setting any targets to reduce emissions. In January 2012, Apple requested that its cable maker, Volex, begin producing halogen-free USB and power cables.\nGreen bonds.\nIn February 2016, Apple issued a billion green bond (climate bond), the first ever of its kind by a U.S. tech company. The green bond proceeds are dedicated to the financing of environmental projects.\nSupply chain.\nApple products were made in the United States in Apple-owned factories until the late 1990s; however, as a result of outsourcing initiatives in the 2000s, almost all of its manufacturing is now handled abroad. According to a report by \"The New York Times\", Apple insiders \"believe the vast scale of overseas factories, as well as the flexibility, diligence and industrial skills of foreign workers, have so outpaced their American counterparts that 'Made in the U.S.A.' is no longer a viable option for most Apple products\".\nThe company's manufacturing, procurement, and logistics enable it to execute massive product launches without having to maintain large, profit-sapping inventories. In 2011, Apple's profit margins were 40 percent, compared with between 10 and 20 percent for most other hardware companies. Cook's catchphrase to describe his focus on the company's operational arm is: \"Nobody wants to buy sour milk.\"\nIn May 2017, the company announced a $1 billion funding project for \"advanced manufacturing\" in the United States, and subsequently invested $200\u00a0million in Corning Inc., a manufacturer of toughened Gorilla Glass technology used in Apple's iPhones. The following December, Apple's chief operating officer, Jeff Williams, told \"CNBC\" that the \"$1 billion\" amount was \"absolutely not\" the final limit on its spending, elaborating that \"We're not thinking in terms of a fund limit... We're thinking about, where are the opportunities across the U.S. to help nurture companies that are making the advanced technology \u2014 and the advanced manufacturing that goes with that \u2014 that quite frankly is essential to our innovation.\"\nDuring the Mac's early history, Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s, beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since joined the industry standards groups to influence the future direction of technology standards such as USB, AGP, HyperTransport, Wi-Fi, NVMe, PCIe and others in its products. FireWire is an Apple-originated standard that was widely adopted across the industry after it was standardized as IEEE 1394 and is a legally mandated port in all cable TV boxes in the United States.\nApple has gradually expanded its efforts in getting its products into the Indian market. In July 2012, during a conference call with investors, CEO Tim Cook said that he \"[loves] India\", but that Apple saw larger opportunities outside the region. India's requirement that 30% of products sold be manufactured in the country was described as \"really adds cost to getting product to market\". In May 2016, Apple opened an iOS app development center in Bangalore and a maps development office for 4,000 staff in Hyderabad. In March, \"The Wall Street Journal\" reported that Apple would begin manufacturing iPhone models in India \"over the next two months\", and in May, the \"Journal\" wrote that an Apple manufacturer had begun production of the iPhone SE in the country, while Apple told \"CNBC\" that the manufacturing was for a \"small number\" of units. In April 2019, Apple initiated manufacturing of the iPhone 7 at its Bengaluru facility, keeping in mind demand from local customers even as they seek more incentives from the government of India. At the beginning of 2020, Tim Cook announced that Apple schedules the opening of its first physical outlet in India for 2021, while an online store is to be launched by the end of the year. The opening of the Apple Store was postponed, and finally took place in April 2023, while the online store was launched in September 2020.\nWorker organizations.\nApple directly employs 147,000 workers including 25,000 corporate employees in Apple Park and across Silicon Valley. The vast majority of its employees work at the over 500 retail Apple Stores globally. Apple relies on a larger, outsourced workforce for manufacturing, particularly in China where Apple directly employs 10,000 workers across its retail and corporate divisions. In addition, one further million workers are contracted by Apple's suppliers to assemble Apple products, including Foxconn and Pegatron. Zhengzhou Technology Park alone employs 350,000 Chinese workers in Zhengzhou to exclusively work on the iPhone. , Apple uses hardware components from 43 different countries. The majority of assembling is done by Taiwanese original design manufacturer firms Foxconn, Pegatron, Wistron and Compal Electronics in factories primarily located inside China, and, to a lesser extent, Foxconn plants in Brazil, and India.\nApple workers around the globe have been involved in organizing since the 1990s. Apple unions are made up of retail, corporate, and outsourced workers. Apple employees have joined trade unions or formed works councils in Australia, France, Germany, Italy, Japan, the United Kingdom and the United States. In 2021, Apple Together, a solidarity union, sought to bring together the company's global worker organizations. The majority of industrial labor disputes (including union recognition) involving Apple occur indirectly through its suppliers and contractors, notably Foxconn plants in China and, to a lesser extent, in Brazil and India.\nDemocratic Republic of the Congo.\nIn 2019, Apple was named as a defendant in a forced labour and child slavery lawsuit by Congolese families of children injured and killed in cobalt mines owned by Glencore and Zhejiang Huayou Cobalt, which supply battery materials to Apple and other companies.\nIn April 2024, lawyers representing the Democratic Republic of the Congo notified Apple of evidence that Apple may be sourcing minerals from conflict areas of eastern Congo. Apple policies and documentation describe mitigation efforts against conflict minerals, however the lawyers identify discrepancies in supplier reporting as well as a Global Witness report describing a lack of \"meaningful mitigation\" on Apple's part. In December 2024, DRC filed a lawsuit against Apple's European subsidiaries."}
{"id": "857", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=857", "title": "Aberdeenshire", "text": "Aberdeenshire (; ) is one of the 32 council areas of Scotland.\nIt takes its name from the historic county of Aberdeenshire, which had substantially different boundaries. The Aberdeenshire Council area includes all of the areas of the historic counties of Aberdeenshire and Kincardineshire except the area making up Aberdeen City Council area, as well as part of Banffshire. The historic county boundaries are still officially used for a few purposes, namely land registration and lieutenancy.\nAberdeenshire Council is headquartered at Woodhill House in Aberdeen, making it the only Scottish council whose headquarters are located outside its jurisdiction. Aberdeen itself forms a different council area (Aberdeen City). Aberdeenshire borders onto Angus and Perth and Kinross to the south, Highland and Moray to the west and Aberdeen City to the east.\nTraditionally, it has depended economically on the primary sector (agriculture, fishing, and forestry) and related processing industries. Over the last 40 years, the development of the oil and gas industry and associated service sector has broadened Aberdeenshire's economic base, and contributed to a rapid population growth of some 50% since 1975. Its land represents 8% of Scotland's overall territory. It covers an area of .\nHistory.\nAberdeenshire has a rich prehistoric and historical heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites, including Longman Hill, Kempstone Hill, Catto Long Barrow and Cairn Lee. The area was settled in the Bronze Age by the Beaker culture, who arrived from the south around 2000\u20131800 BC. Stone circles and cairns were constructed predominantly in this era. In the Iron Age, hill forts were built. Around the 1st century AD, the Taexali people, who left little history, were believed to have resided along the coast. The Picts were the next documented inhabitants of the area and were no later than 800\u2013900 AD. The Romans also were in the area during this period, as they left signs at Kintore. Christianity influenced the inhabitants early on, and there were Celtic monasteries at Old Deer and Monymusk.\nSince medieval times, there have been many traditional paths that crossed the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present-day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.\nAberdeenshire played an important role in the fighting between the Scottish dynasties. Macbeth fell at Lumphanan in 1057. During the Anglo-Norman penetration, other families arrive, such as House of Balliol, Clan Bruce, and Clan Cumming (Comyn). During the Scottish Wars of Independence, the King of England Edward I travelled across the area twice with his invading army, in 1296 and 1303. In 1307, Robert the Bruce was victorious near Inverurie.\nThese new families set the stage for the upcoming rivalries during the 14th and 15th centuries. This rivalry grew worse during and after the Protestant Reformation when religion was another reason for conflict between the clans. The Gordon family adhered to Catholicism and the Forbeses to Protestantism. Aberdeenshire was the historic seat of the clan Dempster. Three universities were founded in the area prior to the 17th century, King's College in Old Aberdeen (1494), Marischal College in Aberdeen (1593), and the University of Fraserburgh (1592).\nDuring the 17th century, Aberdeenshire was the location of more fighting, centred on the Marquess of Montrose and the Wars of the Three Kingdoms. This period also saw increased wealth due to the increase in trade with Germany, Poland, and the Low Countries.\nAfter the end of the Revolution of 1688, an extended peaceful period was interrupted only by fleeting events such as the Rising of 1715 and the Rising of 1745. The latter resulted in the end of the ascendancy of Episcopalianism and the feudal power of landowners. An era began of increased agricultural and industrial progress.\nThe present council area is named after the historic county of Aberdeenshire, which has different boundaries and ceased to be used for local government purposes in 1975 under the Local Government (Scotland) Act 1973. The pre-1975 territory of Aberdeenshire was then split between four of the five new districts in the Grampian region: Banff and Buchan (which also included eastern parts of Banffshire, including its county town of Banff), Gordon, Kincardine and Deeside (which also included most of Kincardineshire), and Aberdeen City. Local government functions were shared between the two levels.\nThe modern council area was created in 1996 under the Local Government etc. (Scotland) Act 1994. It covers the combined area of the Banff and Buchan, Gordon, and Kincardine and Deeside districts that had been created in 1975. The present Aberdeenshire Council area therefore consists of all of the historic counties of Aberdeenshire and Kincardineshire (except the area of those two counties making up Aberdeen City), as well as the north-east portions of Banffshire.\nDemographics.\nThe population of the council area has risen over 50% since 1971 to approximately in , representing 4.7% of Scotland's total. Aberdeenshire's population has increased by 9.1% since 2001, while Scotland's total population grew by 3.8%.\nThe census lists a relatively high proportion of under 16s and slightly fewer working-age people compared with the Scottish average.\nAberdeenshire is one of the most homogeneous/indigenous regions of the UK. In 2011, 82.2% of residents identified as 'White Scottish', followed by 12.3% who are 'White British', whilst ethnic minorities constitute only 0.9% of the population. The largest ethnic minority group is Asian Scottish/British at 0.8%. In addition to the English language, 48.8% of residents reported being able to speak and understand the Scots language.\nSettlements.\nThe largest settlements in Aberdeenshire are:\nEconomy.\nAberdeenshire's Gross Domestic Product (GDP) is estimated at \u00a33,496M (2011), representing 5.2% of the Scottish total. Aberdeenshire's economy is closely linked to Aberdeen City's (GDP \u00a37,906M), and in 2011, the region as a whole was calculated to contribute 16.8% of Scotland's GDP. Between 2012 and 2014, the combined Aberdeenshire and Aberdeen City economic forecast GDP growth rate is 8.6%, the highest growth rate of any local council area in the UK and above the Scottish rate of 4.8%.\nA significant proportion of Aberdeenshire's working residents commute to Aberdeen City for work, varying from 11.5% from Fraserburgh to 65% from Westhill.\nAverage Gross Weekly Earnings (for full-time employees employed in workplaces in Aberdeenshire in 2011) are \u00a3572.60. This is lower than the Scottish average by \u00a32.10 and a fall of 2.6% on the 2010 figure. The average gross weekly pay of people resident in Aberdeenshire is much higher, at \u00a3741.90, as many people commute out\nof Aberdeenshire, principally into Aberdeen City.\nTotal employment (excluding farm data) in Aberdeenshire is estimated at 93,700 employees (Business Register and\nEmployment Survey 2009). The majority of employees work within the service sector, predominantly in public administration, education and health. Almost 19% of employment is within the public sector. Aberdeenshire's economy remains closely linked to Aberdeen City's and the North Sea oil industry, with many employees in oil-related jobs.\nThe average monthly unemployment (claimant count) rate for Aberdeenshire in 2011 was 1.5%. This is lower than the average rate of Aberdeen City (2.3%), Scotland (4.2%) and the UK (3.8%).\nNotable features.\nThe following significant structures or places are within Aberdeenshire:\nHydrology and climate.\nThere are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ury, River Ythan, Water of Feugh, Burn of Myrehouse, Laeca Burn and Luther Water. Numerous bays and estuaries are found along the seacoast of Aberdeenshire, including Banff Bay, Ythan Estuary, Stonehaven Bay and Thornyhive Bay. Aberdeenshire has a marine west coast climate on the K\u00f6ppen climate classification. Aberdeenshire is in the rain shadow of the Grampians, therefore it has a generally dry climate for a maritime region, with portions of the coast receiving of moisture annually. Summers are mild, and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in the winter than inland locations. Coastal areas are also subject to haar, or coastal fog."}
{"id": "858", "revid": "13916673", "url": "https://en.wikipedia.org/wiki?curid=858", "title": "AU", "text": ""}
{"id": "859", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=859", "title": "Aztlan Underground", "text": "Aztlan Underground is a band from Los Angeles, California that combines Hip-Hop, Punk Rock, Jazz, and electronic music with Chicano and Native American themes, and indigenous instrumentation. They are often cited as progenitors of Chicano rap.\nBackground.\nThe band traces its roots to the late-1980s hardcore scene in the Eastside of Los Angeles. They have played rapcore, with elements of punk, hip hop, rock, funk, jazz, indigenous music, and spoken word. Indigenous drums, flutes, and rattles are also commonly used in their music. Their lyrics often address the family and economic issues faced by the Chicano community, and they have been noted as activists for that community.\nAs an example of the politically active and culturally important artists in Los Angeles in the 1990s, Aztlan Underground appeared on \"Culture Clash\" on Fox in 1993; and was part of \"Breaking Out\", a concert on pay per view in 1998, The band was featured in the independent films \"Algun Dia\" and \"Frontierland\" in the 1990s, and on the upcoming \"Studio 49\". The band has been mentioned or featured in various newspapers and magazines: \"the Vancouver Sun\", \"New Times\", \"BLU Magazine\" (an underground hip hop magazine), \"BAM Magazine\", \"La Banda Elastica Magazine\", and the \"Los Angeles Times\" calendar section. The band is also the subject of a chapter in the book \"It's Not About a Salary\", by Brian Cross.\nAztlan Underground remains active in the community, lending their voice to annual events such as The Farce of July, and the recent movement to recognize Indigenous People's Day in Los Angeles and beyond.\nIn addition to forming their own label, Xicano Records and Film, Aztlan Underground were signed to the Basque record label Esan Ozenki in 1999 which enabled them to tour Spain extensively and perform in France and Portugal. Aztlan Underground have also performed in Canada, Australia, and Venezuela. The band has been recognized for their music with nominations in the \"New Times\" 1998 \"Best Latin Influenced\" category, the \"BAM Magazine\" 1999 \"Best Rock en Espa\u00f1ol\" category, and the \"LA Weekly\" 1999 \"Best Hip Hop\" category. The release of their eponymous third album on August 29, 2009, was met with positive reviews and earned the band four Native American Music Award (NAMMY) nominations in 2010.\nDiscography.\n\"Decolonize\".\nYear:1995\n\"Sub-Verses\".\nYear:1998\n\"Aztlan Underground\".\nYear: 2009"}
{"id": "860", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=860", "title": "Aland", "text": ""}
{"id": "863", "revid": "47187980", "url": "https://en.wikipedia.org/wiki?curid=863", "title": "American Civil War", "text": "The American Civil War (April 12, 1861May 26, 1865; also known by other names) was a civil war in the United States between the Union (\"the North\") and the Confederacy (\"the South\"), which was formed in 1861 by states that had seceded from the Union. The central conflict leading to war was a dispute over whether slavery should be permitted to expand into the western territories, leading to more slave states, or be prohibited from doing so, which many believed would place slavery on a course of ultimate extinction.\nDecades of controversy over slavery came to a head when Abraham Lincoln, who opposed slavery's expansion, won the 1860 presidential election. Seven Southern slave states responded to Lincoln's victory by seceding from the United States and forming the Confederacy. The Confederacy seized U.S. forts and other federal assets within their borders. The war began on April 12, 1861, when the Confederacy bombarded Fort Sumter in South Carolina. A wave of enthusiasm for war swept over the North and South, as military recruitment soared. Four more Southern states seceded after the war began and, led by its president, Jefferson Davis, the Confederacy asserted control over a third of the U.S. population in eleven states. Four years of intense combat, mostly in the South, ensued.\nDuring 1861\u20131862 in the Western theater, the Union made permanent gains\u2014though in the Eastern theater the conflict was inconclusive. The abolition of slavery became a Union war goal on January 1, 1863, when Lincoln issued the Emancipation Proclamation, which declared all slaves in rebel states to be free, applying to more than 3.5 million of the 4 million enslaved people in the country. To the west, the Union first destroyed the Confederacy's river navy by the summer of 1862, then much of its western armies, and seized New Orleans. The successful 1863 Union siege of Vicksburg split the Confederacy in two at the Mississippi River, while Confederate general Robert E. Lee's incursion north failed at the Battle of Gettysburg. Western successes led to General Ulysses S. Grant's command of all Union armies in 1864. Inflicting an ever-tightening naval blockade of Confederate ports, the Union marshaled resources and manpower to attack the Confederacy from all directions. This led to the fall of Atlanta in 1864 to Union general William Tecumseh Sherman, followed by his March to the Sea. The last significant battles raged around the ten-month Siege of Petersburg, gateway to the Confederate capital of Richmond. The Confederates abandoned Richmond, and on April 9, 1865, Lee surrendered to Grant following the Battle of Appomattox Court House, setting in motion the end of the war. Lincoln lived to see this victory but was shot by an assassin on April 14, dying the next day.\nBy the end of the war, much of the South's infrastructure was destroyed. The Confederacy collapsed, slavery was abolished, and four million enslaved black people were freed. The war-torn nation then entered the Reconstruction era in an attempt to rebuild the country, bring the former Confederate states back into the United States, and grant civil rights to freed slaves. The war is one of the most extensively studied and written about episodes in the history of the United States. It remains the subject of cultural and historiographical debate. Of continuing interest is the myth of the Lost Cause of the Confederacy. The war was among the first to use industrial warfare. Railroads, the electrical telegraph, steamships, the ironclad warship, and mass-produced weapons were widely used. The war left an estimated 698,000 soldiers dead, along with an undetermined number of civilian casualties, making the Civil War the deadliest military conflict in American history. The technology and brutality of the Civil War foreshadowed the coming world wars.\nOrigins.\nThe origins of the war were rooted in the desire of the Southern states to preserve the institution of slavery. Historians in the 21st century overwhelmingly agree on the centrality of slavery in the conflict\u2014at least for the Southern states. They disagree on which aspects (ideological, economic, political, or social) were most important, and on the North's reasons for refusing to allow the Southern states to secede. The pseudo-historical Lost Cause ideology denies that slavery was the principal cause of the secession, a view disproven by historical evidence, notably some of the seceding states' own secession documents. After leaving the Union, Mississippi issued a declaration stating, \"Our position is thoroughly identified with the institution of slavery\u2014the greatest material interest of the world.\"\nThe principal political battle leading to Southern secession was over whether slavery would expand into the Western territories destined to become states. Initially Congress had admitted new states into the Union in pairs, one slave and one free. This had kept a sectional balance in the Senate but not in the House of Representatives, as free states outstripped slave states in numbers of eligible voters. Thus, at mid-19th century, the free-versus-slave status of the new territories was a critical issue, both for the North, where anti-slavery sentiment had grown, and for the South, where the fear of slavery's abolition had grown. Another factor leading to secession and the formation of the Confederacy was the development of white Southern nationalism in the preceding decades. The primary reason for the North to reject secession was to preserve the Union, a cause based on American nationalism.\nBackground factors in the run up to the Civil War were partisan politics, abolitionism, nullification versus secession, Southern and Northern nationalism, expansionism, economics, and modernization in the antebellum period. As a panel of historians emphasized in 2011, \"while slavery and its various and multifaceted discontents were the primary cause of disunion, it was disunion itself that sparked the war.\"\nLincoln's election.\nAbraham Lincoln won the 1860 presidential election. Southern leaders feared Lincoln would stop slavery's expansion and put it on a course toward extinction. His victory triggered declarations of secession by seven slave states of the Deep South, all of whose riverfront or coastal economies were based on cotton that was cultivated by slave labor. Lincoln was not inaugurated until March 4, 1861, giving the South time to prepare for war during the winter of 1860\u20131861. Nationalists in the North and \"Unionists\" in the South refused to accept the declarations of secession. No foreign government ever recognized the Confederacy. The U.S. government, under President James Buchanan, refused to relinquish its forts that were in territory claimed by the Confederacy. According to Lincoln, the American people had shown they had been successful in \"establishing\" and \"administering\" a republic, but a third challenge faced the nation: \"maintaining\" a republic based on the people's vote, in the face of an attempt to destroy it.\nOutbreak of the war.\nSecession crisis.\nLincoln's election provoked South Carolina's legislature to call a state convention to consider secession. South Carolina had done more than any other state to advance the notion that a state had the right to nullify federal laws and even secede. On December 20, 1860, the convention unanimously voted to secede and adopted a secession declaration. It argued for states' rights for slave owners but complained about states' rights in the North in the form of resistance to the federal Fugitive Slave Act, claiming that Northern states were not fulfilling their obligations to assist in the return of fugitive slaves. The \"cotton states\" of Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas followed suit, seceding in January and February 1861.\nAmong the ordinances of secession, those of Texas, Alabama, and Virginia mentioned the plight of the \"slaveholding states\" at the hands of Northern abolitionists. The rest made no mention of slavery but were brief announcements by the legislatures of the dissolution of ties to the Union. However, at least four\u2014South Carolina, Mississippi, Georgia, and Texas\u2014provided detailed reasons for their secession, all blaming the movement to abolish slavery and its influence over the North. Southern states believed that the Fugitive Slave Clause made slaveholding a constitutional right. These states agreed to form a new federal government, the Confederate States of America, on February 4, 1861. They took control of federal forts and other properties within their boundaries, with little resistance from outgoing President James Buchanan, whose term ended on March 4. Buchanan said the Dred Scott decision was proof the Southern states had no reason to secede and that the Union \"was intended to be perpetual\". He added, however, that \"The power by force of arms to compel a State to remain in the Union\" was not among the \"enumerated powers granted to Congress\". A quarter of the US army\u2014the Texas garrison\u2014was surrendered in February to state forces by its general, David E. Twiggs, who joined the Confederacy.\nAs Southerners resigned their Senate and House seats, Republicans could pass projects that had been blocked. These included the Morrill Tariff, land grant colleges, a Homestead Act, a transcontinental railroad, the National Bank Act, authorization of United States Notes by the Legal Tender Act of 1862, and the end of slavery in the District of Columbia. The Revenue Act of 1861 introduced income tax to help finance the war.\nIn December 1860, the Crittenden Compromise was proposed to re-establish the Missouri Compromise line, by constitutionally banning slavery in territories to the north of it, while permitting it to the south. The Compromise would likely have prevented secession, but Lincoln and the Republicans rejected it. Lincoln stated that any compromise that would extend slavery would bring down the Union. A February peace conference met in Washington, proposing a solution similar the Compromise; it was rejected by Congress. The Republicans proposed the Corwin Amendment, an alternative, not to interfere with slavery where it existed, but the South regarded it as insufficient. The remaining eight slave states rejected pleas to join the Confederacy, following a no-vote in Virginia's First Secessionist Convention on April 4.\nOn March 4, Lincoln was sworn in as president. In his inaugural address, he argued that the Constitution was a \"more perfect union\" than the earlier Articles of Confederation and Perpetual Union, was a binding contract, and called secession \"legally void\". He did not intend to invade Southern states, nor to end slavery where it existed, but he said he would use force to maintain possession of federal property, including forts, arsenals, mints, and customhouses that had been seized. The government would not try to recover post offices, and if resisted, mail delivery would end at state lines. Where conditions did not allow peaceful enforcement of federal law, US marshals and judges would be withdrawn. No mention was made of bullion lost from mints. He stated that it would be US policy \"to collect the duties and imposts\"; \"there will be no invasion, no using of force against or among the people anywhere\" that would justify an armed revolution. His speech closed with a plea for restoration of the bonds of union, famously calling on \"the mystic chords of memory\" binding the two regions.\nThe Davis government of the new Confederacy sent delegates to Washington to negotiate a peace treaty. Lincoln rejected negotiations, because he claimed that the Confederacy was not a legitimate government and to make a treaty with it would recognize it as such. Lincoln instead attempted to negotiate directly with the governors of seceded states, whose administrations he continued to recognize.\nComplicating Lincoln's attempts to defuse the crisis was Secretary of State William H. Seward, who had been Lincoln's rival for the Republican nomination. Embittered by his defeat, Seward agreed to support Lincoln's candidacy only after he was guaranteed the executive office then considered the second most powerful. In the early stages of Lincoln's presidency Seward held little regard for him, due to his perceived inexperience. Seward viewed himself as the de facto head of government, the \"prime minister\" behind the throne. Seward attempted to engage in unauthorized and indirect negotiations that failed. Lincoln was determined to hold all remaining Union-occupied forts in the Confederacy: Fort Monroe in Virginia, Fort Pickens, Fort Jefferson, and Fort Taylor in Florida, and Fort Sumter in South Carolina.\nBattle of Fort Sumter.\nThe American Civil War began on April 12, 1861, when Confederate forces opened fire on the Union-held Fort Sumter. Fort Sumter is located in the harbor of Charleston, South Carolina. Its status had been contentious for months. Outgoing President Buchanan had dithered in reinforcing its garrison, commanded by Major Robert Anderson. Anderson took matters into his own hands and on December 26, 1860, under the cover of darkness, sailed the garrison from the poorly placed Fort Moultrie to the stalwart island Fort Sumter. Anderson's actions catapulted him to hero status in the North. An attempt to resupply the fort on January 9, 1861, failed and nearly started the war then, but an informal truce held. On March 5, Lincoln was informed the fort was low on supplies.\nFort Sumter proved a key challenge to Lincoln's administration. Back-channel dealing by Seward with the Confederates undermined Lincoln's decision-making; Seward wanted to pull out. But a firm hand by Lincoln tamed Seward, who was a staunch Lincoln ally. Lincoln decided holding the fort, which would require reinforcing it, was the only workable option. On April 6, Lincoln informed the Governor of South Carolina that a ship with food but no ammunition would attempt to supply the fort. Historian McPherson describes this win-win approach as \"the first sign of the mastery that would mark Lincoln's presidency\"; the Union would win if it could resupply and hold the fort, and the South would be the aggressor if it opened fire on an unarmed ship supplying starving men. An April 9 Confederate cabinet meeting resulted in Davis ordering General P. G. T. Beauregard to take the fort before supplies reached it.\nAt 4:30 am on April 12, Confederate forces fired the first of 4,000 shells at the fort; it fell the next day. The loss of Fort Sumter lit a patriotic fire under the North. On April 15, Lincoln called on the states to field 75,000 volunteer troops for 90\u00a0days; impassioned Union states met the quotas quickly. On May 3, 1861, Lincoln called for an additional 42,000 volunteers for three years. Shortly after this, Virginia, Tennessee, Arkansas, and North Carolina seceded and joined the Confederacy. To reward Virginia, the Confederate capital was moved to Richmond.\nAttitude of the border states.\nMaryland, Delaware, Missouri, West Virginia and Kentucky were slave states whose people had divided loyalties to Northern and Southern businesses and family members. Some men enlisted in the Union Army and others in the Confederate Army. West Virginia separated from Virginia and was admitted to the Union on June 20, 1863, though half its counties were secessionist.\nMaryland's territory surrounded Washington, D.C., and could cut it off from the North. It had anti-Lincoln officials who tolerated anti-army rioting in Baltimore and the burning of bridges, both aimed at hindering the passage of troops to the South. Maryland's legislature voted overwhelmingly to stay in the Union, but rejected hostilities with its southern neighbors, voting to close Maryland's rail lines to prevent their use for war. Lincoln responded by establishing martial law and unilaterally suspending habeas corpus in Maryland, along with sending in militia units. Lincoln took control of Maryland and the District of Columbia by seizing prominent figures, including arresting one-third of the members of the Maryland General Assembly on the day it reconvened. All were held without trial, with Lincoln ignoring a ruling on June 1, 1861, by Supreme Court Chief Justice Roger Taney, not speaking for the Court, that only Congress could suspend habeas corpus (\"Ex parte Merryman\"). Federal troops imprisoned a Baltimore newspaper editor, Frank Key Howard, after he criticized Lincoln in an editorial for ignoring Taney's ruling.\nIn Missouri, an elected convention on secession voted to remain in the Union. When pro-Confederate Governor Claiborne Fox Jackson called out the state militia, it was attacked by federal forces under General Nathaniel Lyon, who chased the governor and rest of the State Guard to the southwestern corner of Missouri (see Missouri secession). Early in the war the Confederacy controlled southern Missouri through the Confederate government of Missouri but was driven out after 1862. In the resulting vacuum, the convention on secession reconvened and took power as the Unionist provisional government of Missouri.\nKentucky did not secede, it declared itself neutral. When Confederate forces entered in September 1861, neutrality ended and the state reaffirmed its Union status while maintaining slavery. During an invasion by Confederate forces in 1861, Confederate sympathizers and delegates from 68 Kentucky counties organized the secession Russellville Convention, formed the shadow Confederate Government of Kentucky, inaugurated a governor, and Kentucky was admitted into the Confederacy on December 10, 1861. Its jurisdiction extended only as far as Confederate battle lines in the Commonwealth, which at its greatest extent was over half the state, and it went into exile after October 1862.\nAfter Virginia's secession, a Unionist government in Wheeling asked 48 counties to vote on an ordinance to create a new state in October 1861. A voter turnout of 34% approved the statehood bill (96% approving). Twenty-four secessionist counties were included in the new state, and the ensuing guerrilla war engaged about 40,000 federal troops for much of the war. Congress admitted West Virginia to the Union on June 20, 1863. West Virginians provided about 20,000 soldiers to each side in the war. A Unionist secession attempt occurred in East Tennessee, but was suppressed by the Confederacy, which arrested over 3,000 men suspected of loyalty to the Union; they were held without trial.\nWar.\nThe Civil War was marked by intense and frequent battles. Over four years, 237 named battles were fought, along with many smaller actions, often characterized by their bitter intensity and high casualties. Historian John Keegan described it as \"one of the most ferocious wars ever fought,\" where, in many cases, the only target was the enemy's soldiers.\nMobilization.\nAs the Confederate states organized, the U.S. Army numbered 16,000, while Northern governors began mobilizing their militias. The Confederate Congress authorized up to 100,000 troops in February. By May, Jefferson Davis was pushing for another 100,000 soldiers for one year or the duration, and the U.S. Congress responded in kind.\nIn the first year of the war, both sides had more volunteers than they could effectively train and equip. After the initial enthusiasm faded, relying on young men who came of age each year was not enough. Both sides enacted draft laws (conscription) to encourage or force volunteering, though relatively few were drafted. The Confederacy passed a draft law in April 1862 for men aged 18\u201335, with exemptions for overseers, government officials, and clergymen. The U.S. Congress followed in July, authorizing a militia draft within states that could not meet their quota with volunteers. European immigrants joined the Union Army in large numbers, including 177,000 born in Germany and 144,000 in Ireland. About 50,000 Canadians served, around 2,500 of whom were black.\nWhen the Emancipation Proclamation went into effect in January 1863, ex-slaves were energetically recruited to meet state quotas. States and local communities offered higher cash bonuses for white volunteers. Congress tightened the draft law in March 1863. Men selected in the draft could provide substitutes or, until mid-1864, pay commutation money. Many eligibles pooled their money to cover the cost of anyone drafted. Families used the substitute provision to select which man should go into the army and which should stay home. There was much evasion and resistance to the draft, especially in Catholic areas. The New York City draft riots in July 1863 involved Irish immigrants who had been signed up as citizens to swell the vote of the city's Democratic political machine, not realizing it made them liable for the draft. Of the 168,649 men procured for the Union through the draft, 117,986 were substitutes, leaving only 50,663 who were conscripted.\nIn the North and South, draft laws were highly unpopular. In the North, some 120,000 men evaded conscription, many fleeing to Canada, and another 280,000 soldiers deserted during the war. At least 100,000 Southerners deserted, about 10 percent of the total. Southern desertion was high because many soldiers were more concerned about the fate of their local area than the Southern cause. In the North, \"bounty jumpers\" enlisted to collect the generous bonus, deserted, then re-enlisted under a different name for a second bonus; 141 were caught and executed.\nFrom a tiny frontier force in 1860, the Union and Confederate armies grew into the \"largest and most efficient armies in the world\" within a few years. Some European observers at the time dismissed them as amateur and unprofessional, but historian John Keegan concluded that each outmatched the French, Prussian, and Russian armies, and without the Atlantic, could have threatened any of them with defeat.\nSouthern Unionists.\nUnionism was strong in certain areas within the Confederacy. As many as 100,000 men living in states under Confederate control served in the Union Army or pro-Union guerrilla groups. Although they came from all classes, most Southern Unionists differed socially, culturally, and economically from their region's dominant prewar, slave-owning planter class.\nPrisoners.\nAt the war's start, a parole system operated, under which captives agreed not to fight until exchanged. They were held in camps run by their army, paid, but not allowed to perform any military duties. The system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. After that, about 56,000 of the 409,000 POWs died in prisons, accounting for 10 percent of the conflict's fatalities.\nWomen.\nHistorian Elizabeth D. Leonard writes that between 500 and 1,000 women enlisted as soldiers on both sides, disguised as men. Women also served as spies, resistance activists, nurses, and hospital personnel. Women served on the Union hospital ship \"Red Rover\" and nursed Union and Confederate troops at field hospitals. Mary Edwards Walker, the only woman ever to receive the Medal of Honor, served in the Union Army and was given the medal for treating the wounded during the war. One woman, Jennie Hodgers, fought for the Union under the name Albert D. J. Cashier. After she returned to civilian life, she continued to live as a man until she died in 1915 at the age of 71.\nNaval tactics.\nThe small U.S. Navy of 1861 rapidly expanded to 6,000 officers and 45,000 sailors by 1865, with 671 vessels totaling 510,396 tons. Its mission was to blockade Confederate ports, control the river system, defend against Confederate raiders on the high seas, and be ready for a possible war with the British Royal Navy. The main riverine war was fought in the West, where major rivers gave access to the Confederate heartland. The U.S. Navy eventually controlled the Red, Tennessee, Cumberland, Mississippi, and Ohio rivers. In the East, the Navy shelled Confederate forts and supported coastal army operations.\nThe Civil War occurred during the early stages of the industrial revolution, leading to naval innovations, notably the ironclad warship. The Confederacy, recognizing the need to counter the Union's naval superiority, built or converted over 130 vessels, including 26 ironclads. Despite these efforts, Confederate ships were largely unsuccessful against Union ironclads. The Union Navy used timberclads, tinclads, and armored gunboats. Shipyards in Cairo, Illinois, and St. Louis built or modified steamboats.\nThe Confederacy experimented with the submarine , which was not successful, and with the ironclad , rebuilt from the sunken Union ship . On March 8, 1862, \"Virginia\" inflicted significant damage on the Union's wooden fleet, but the next day, the first Union ironclad, , arrived to challenge it in the Chesapeake Bay. The resulting three-hour Battle of Hampton Roads was a draw, proving ironclads were effective warships. The Confederacy scuttled the \"Virginia\" to prevent its capture, while the Union built many copies of the \"Monitor\". The Confederacy's efforts to obtain warships from Great Britain failed, as Britain had no interest in selling warships to a nation at war with a stronger enemy and feared souring relations with the U.S.\nUnion blockade.\nBy early 1861, General Winfield Scott had devised the Anaconda Plan to win the war with minimal bloodshed, calling for a blockade of the Confederacy to suffocate the South into surrender. Lincoln adopted parts of the plan but opted for a more active war strategy. In April 1861, Lincoln announced a blockade of all Southern ports; commercial ships could not get insurance, ending regular traffic. The South blundered by embargoing cotton exports before the blockade was fully effective; by the time they reversed this decision, it was too late. \"King Cotton\" was dead, as the South could export less than 10% of its cotton. The blockade shut down the ten Confederate seaports with railheads that moved almost all the cotton. By June 1861, warships were stationed off the principal Southern ports, and a year later nearly 300 ships were in service.\nBlockade runners.\nThe Confederates began the war short on military supplies, which the agrarian South could not produce. Northern arms manufacturers were restricted by an embargo, ending existing and future contracts with the South. The Confederacy turned to foreign sources, connecting with financiers and companies like S. Isaac, Campbell &amp; Company and the London Armoury Company in Britain, becoming the Confederacy's main source of arms.\nTo transport arms safely to the Confederacy, British investors built small, fast, steam-driven blockade runners that traded arms and supplies from Britain, through Bermuda, Cuba, and the Bahamas in exchange for high-priced cotton. Many were lightweight and designed for speed, only carrying small amounts of cotton back to England. When the Union Navy seized a blockade runner, the ship and cargo were condemned as a prize of war and sold, with proceeds given to the Navy sailors; the captured crewmen, mostly British, were released.\nEconomic impact.\nThe Southern economy nearly collapsed during the war due to multiple factors, the most notable being severe food shortages, failing railroads, loss of control over key rivers, foraging by Northern armies, and the seizure of animals and crops by Confederate forces. Historians agree the blockade was a major factor in ruining the Confederate economy; however, Wise argues blockade runners provided enough of a lifeline to allow Lee to continue fighting for additional months, thanks to supplies like 400,000 rifles, lead, blankets, and boots that the homefront economy could no longer supply.\nSurdam contends that the blockade was a powerful weapon that eventually ruined the Southern economy, costing few lives in combat. The Confederate cotton crop became nearly useless, cutting off the Confederacy's primary income source. Critical imports were scarce, and coastal trade largely ended as well. The blockade's success was not measured by the few ships that slipped through but by the thousands that never tried. European merchant ships could not get insurance and were too slow to evade the blockade, so they stopped calling at Confederate ports.\nTo fight an offensive war, the Confederacy purchased arms in Britain and converted British-built ships into commerce raiders. The smuggling of 600,000 arms enabled the Confederacy to fight on for two more years, and the commerce raiders targeted U.S. Merchant Marine ships in the Atlantic and Pacific oceans. Insurance rates soared, and the American flag virtually disappeared from international waters, though reflagging ships with European flags allowed them to continue operating unmolested. After the war, the U.S. government demanded Britain compensate it for the damage caused by blockade runners and raiders outfitted in British ports. Britain paid the U.S. $15\u00a0million in 1871, but only for commerce raiding.\nDin\u00e7aslan argues that another outcome of the blockade was the rise of oil as a prominent commodity. The declining whale oil industry took a blow as many old whaling ships were used in blockade efforts, such as the Stone Fleet, and Confederate raiders harassed Union whalers. Oil products, especially kerosene, began replacing whale oil in lamps, increasing oil's importance long before it became fuel for combustion engines.\nDiplomacy.\nAlthough the Confederacy hoped Britain and France would join them against the Union, this was never likely, so they sought to bring them in as mediators. The Union worked to block this and threatened war if any country recognized the Confederacy. In 1861, Southerners voluntarily embargoed cotton shipments, hoping to start an economic depression in Europe that would force Britain to enter the war, but this failed. Worse, Europe turned to Egypt and India for cotton, which they found superior, hindering the South's post-war recovery.\nCotton diplomacy proved a failure as Europe had a surplus of cotton, while the 1860\u201362 crop failures in Europe made the North's grain exports critically important. It also helped turn European opinion against the Confederacy. It was said that \"King Corn was more powerful than King Cotton,\" as U.S. grain went from a quarter to almost half of British imports. Meanwhile, the war created jobs for arms makers, ironworkers, and ships to transport weapons.\nLincoln's administration initially struggled to appeal to European public opinion. At first, diplomats explained that the U.S. was not committed to ending slavery and emphasized legal arguments about the unconstitutionality of secession. Confederate representatives, however, focused on their struggle for liberty, commitment to free trade, and the essential role of cotton in the European economy. The European aristocracy was \"absolutely gleeful in pronouncing the American debacle as proof that the entire experiment in popular government had failed. European government leaders welcomed the fragmentation of the ascendant American Republic.\" However, a European public with liberal sensibilities remained, which the U.S. sought to appeal to by building connections with the international press. By 1861, Union diplomats like Carl Schurz realized emphasizing the war against slavery was the Union's most effective moral asset in swaying European public opinion. Seward was concerned an overly radical case for reunification would distress European merchants with cotton interests; even so, he supported a widespread campaign of public diplomacy.\nU.S. minister to Britain Charles Francis Adams proved adept and convinced Britain not to challenge the Union blockade. The Confederacy purchased warships from commercial shipbuilders in Britain, with the most famous being the , which caused considerable damage and led to serious postwar disputes. However, public opinion against slavery in Britain created a political liability for politicians, where the anti-slavery movement was powerful.\nWar loomed in late 1861 between the U.S. and Britain over the \"Trent\" affair, which began when U.S. Navy personnel boarded the British ship and seized two Confederate diplomats. However, London and Washington smoothed this over after Lincoln released the two men. Prince Albert left his deathbed to issue diplomatic instructions to Lord Lyons during the \"Trent\" affair. His request was honored, and, as a result, the British response to the U.S. was toned down, helping avert war. In 1862, the British government considered mediating between the Union and Confederacy, though such an offer would have risked war with the U.S. British Prime Minister Lord Palmerston reportedly read \"Uncle Tom's Cabin\" three times when deciding what his decision would be.\nThe Union victory at the Battle of Antietam caused the British to delay this decision. The Emancipation Proclamation increased the political liability of supporting the Confederacy. Realizing that Washington could not intervene in Mexico as long as the Confederacy controlled Texas, France invaded Mexico in 1861 and installed the Habsburg Austrian archduke Maximilian I as emperor. Washington repeatedly protested France's violation of the Monroe Doctrine. Despite sympathy for the Confederacy, France's seizure of Mexico ultimately deterred it from war with the Union. Confederate offers late in the war to end slavery in return for diplomatic recognition were not seriously considered by London or Paris. After 1863, the Polish revolt against Russia further distracted the European powers and ensured they remained neutral.\nRussia supported the Union, largely because it believed the U.S. served as a counterbalance to its geopolitical rival, the U.K. In 1863, the Imperial Russian Navy's Baltic and Pacific fleets wintered in the American ports of New York and San Francisco, respectively.\nEastern theater.\nThe Eastern theater refers to the military operations east of the Appalachian Mountains, including Virginia, West Virginia, Maryland, and Pennsylvania, the District of Columbia, and the coastal fortifications and seaports of North Carolina.\nBackground.\nArmy of the Potomac.\nMaj. Gen. George B. McClellan took command of the Union Army of the Potomac on July 26, 1861, and the war began in earnest in 1862. The 1862 Union strategy called for simultaneous advances along four axes:\nArmy of Northern Virginia.\nThe primary Confederate force in the Eastern theater was the Army of Northern Virginia. The Army originated as the (Confederate) Army of the Potomac, which was organized on June 20, 1861, from all operational forces in Northern Virginia. On July 20 and 21, the Army of the Shenandoah and forces from the District of Harpers Ferry were added. Units from the Army of the Northwest were merged into the Army of the Potomac between March 14 and May 17, 1862. The Army of the Potomac was renamed \"Army of Northern Virginia\" on March 14. The Army of the Peninsula was merged into it on April 12, 1862.\nWhen Virginia declared its secession in April 1861, Robert E. Lee chose to follow his home state, despite his desire for the country to remain intact and an offer of a senior Union command. Lee's biographer, Douglas S. Freeman, asserts that the army received its final name from Lee when he issued orders assuming command on June 1, 1862. However, Freeman does admit that Lee corresponded with Brigadier General Joseph E. Johnston, his predecessor in army command, before that date and referred to Johnston's command as the Army of Northern Virginia. Part of the confusion results from the fact Johnston commanded the Department of Northern Virginia (as of October 22, 1861) and the name Army of Northern Virginia can be seen as an informal consequence of its parent department's name. Jefferson Davis and Johnston did not adopt the name, but it is clear the organization of units as of March 14 was the same organization that Lee received on June 1, and thus it is generally referred to today as the Army of Northern Virginia, even if that is correct only in retrospect.\nOn July 4 at Harper's Ferry, Colonel Thomas J. Jackson assigned Jeb Stuart to command all the cavalry companies of the Army of the Shenandoah. He eventually commanded the Army of Northern Virginia's cavalry.\nBattles.\nIn July 1861, in of the first highly visible battles, Union troops under the command of Maj. Gen. Irvin McDowell attacking Confederate forces led by Beauregard near Washington were repulsed at the First Battle of Bull Run.\nThe Union had the upper hand at first, nearly pushing Confederate forces holding a defensive position into a rout, but Confederate reinforcements under Joseph E. Johnston arrived from the Shenandoah Valley by railroad, and the course of the battle quickly changed. A brigade of Virginians under the relatively unknown brigadier general from the Virginia Military Institute, Thomas J. Jackson, stood its ground, which resulted in Jackson's receiving his famous nickname, \"Stonewall\".\nUpon the urging of Lincoln to begin offensive operations, McClellan attacked Virginia in the spring of 1862 by way of the peninsula between the York River and James River, southeast of Richmond. McClellan's army reached the gates of Richmond in the Peninsula campaign.\nAlso in the spring of 1862, in the Shenandoah Valley, Stonewall Jackson led his Valley Campaign. Audaciously employing rapid, unpredictable movements on interior lines, Jackson's 17,000 troops marched 646 miles (1,040\u00a0km) in 48 days and won minor battles as they successfully engaged three Union armies (52,000 men), including those of Nathaniel P. Banks and John C. Fremont, preventing them from reinforcing the Union offensive against Richmond. The swiftness of Jackson's men earned them the nickname of \"foot cavalry\".\nJohnston halted McClellan's advance at the Battle of Seven Pines, but he was wounded in the battle, and Robert E. Lee assumed his position of command. Lee and top subordinates James Longstreet and Stonewall Jackson defeated McClellan in the Seven Days Battles and forced his retreat.\nThe Northern Virginia Campaign, which included the Second Battle of Bull Run, ended in yet another victory for the South. McClellan resisted General-in-Chief Halleck's orders to send reinforcements to John Pope's Union Army of Virginia, which made it easier for Lee's Confederates to defeat twice the number of combined enemy troops.\nEmboldened by Second Bull Run, the Confederacy made its first invasion of the North with the Maryland Campaign. Lee led 45,000 troops of the Army of Northern Virginia across the Potomac River into Maryland on September 5. Lincoln then restored Pope's troops to McClellan. McClellan and Lee fought at the Battle of Antietam near Sharpsburg, Maryland, on September 17, 1862, the bloodiest single day in US military history. Lee's army, checked at last, returned to Virginia before McClellan could destroy it. Antietam is considered a Union victory because it halted Lee's invasion of the North and provided an opportunity for Lincoln to announce his Emancipation Proclamation.\nWhen the cautious McClellan failed to follow up on Antietam, he was replaced by Maj. Gen. Ambrose Burnside. Burnside was defeated at the Battle of Fredericksburg on December 13, 1862, when more than 12,000 Union soldiers were killed or wounded during futile frontal assaults against Marye's Heights. After the battle, Burnside was replaced by Maj. Gen. Joseph Hooker.\nHooker, too, proved unable to defeat Lee's army; despite outnumbering the Confederates by more than two to one, his Chancellorsville Campaign proved ineffective, and he was humiliated in the Battle of Chancellorsville in May 1863. Chancellorsville is known as Lee's \"perfect battle\" because his risky decision to divide his army in the presence of a much larger enemy force resulted in a significant Confederate victory. Stonewall Jackson was shot in the left arm and right hand by friendly fire during the battle. The arm was amputated, but he died of pneumonia. Lee famously said: \"He has lost his left arm, but I have lost my right arm.\"\nThe fiercest fighting of the battle\u2014and the second bloodiest day of the Civil War\u2014occurred on May 3 as Lee launched multiple attacks against the Union position at Chancellorsville. That same day, John Sedgwick advanced across the Rappahannock River, defeated the small Confederate force at Marye's Heights in the Second Battle of Fredericksburg, and then moved to the west. The Confederates fought a successful delaying action at the Battle of Salem Church.\nGen. Hooker was replaced by Maj. Gen. George Meade during Lee's second invasion of the North, in June. Meade defeated Lee at the Battle of Gettysburg (July 1863). This was the bloodiest battle and has been called the war's turning point. Pickett's Charge on July 3 is considered the high-water mark of the Confederacy because it signaled the collapse of serious Confederate threats of victory. Lee's army suffered 28,000 casualties, versus Meade's 23,000.\nWestern theater.\nThe Western theater refers to military operations between the Appalachian Mountains and the Mississippi River, including Alabama, Georgia, Florida, Mississippi, North Carolina, Kentucky, South Carolina, Tennessee, and parts of Louisiana.\nBackground.\nArmy of the Tennessee and Army of the Cumberland.\nThe primary Union forces in this theater were the Army of the Tennessee and Army of the Cumberland, named for the two rivers, Tennessee River and Cumberland River. After Meade's inconclusive fall campaign, Lincoln turned to the Western theater for new leadership. At the same time, the Confederate stronghold of Vicksburg surrendered, giving the Union control of the Mississippi River, permanently isolating the western Confederacy, and producing the new leader Lincoln needed, Ulysses S. Grant.\nArmy of Tennessee.\nThe primary Confederate force in the Western theater was the Army of Tennessee. The army was formed on November 20, 1862, when General Braxton Bragg renamed the former Army of Mississippi. While the Confederate forces had successes in the Eastern theater, they were defeated many times in the West.\nBattles.\nThe Union's key strategist and tactician in the West was Ulysses S. Grant, who won victories at Forts Henry (February 6, 1862) and Donelson (February 11 to 16, 1862), earning him the nickname of \"Unconditional Surrender\" Grant. With these victories the Union gained control of the Tennessee and Cumberland Rivers. Nathan Bedford Forrest rallied nearly 4,000 Confederate troops and led them to escape across the Cumberland. Nashville and central Tennessee thus fell to the Union, leading to attrition of local food supplies and livestock and a breakdown in social organization.\nConfederate general Leonidas Polk's invasion of Columbus ended Kentucky's policy of neutrality and turned it against the Confederacy. Grant used river transport and Andrew Hull Foote's gunboats of the Western Flotilla, to threaten the Confederacy's \"Gibraltar of the West\" at Columbus, Kentucky. Although rebuffed at Belmont, Grant cut off Columbus. The Confederates, lacking their gunboats, were forced to retreat and the Union took control of west Kentucky and opened Tennessee in March 1862.\nAt the Battle of Shiloh, in Shiloh, Tennessee in April 1862, the Confederates made a surprise attack that pushed Union forces against the river as night fell. Overnight, the Navy landed reinforcements, and Grant counterattacked. Grant and the Union won a decisive victory\u2014the first battle with the high casualty rates that would occur repeatedly. The Confederates lost Albert Sidney Johnston, considered their finest general before the emergence of Lee.\nOne of the early Union objectives was to capture the Mississippi River to cut the Confederacy in half. The Mississippi was opened to Union traffic to the southern border of Tennessee with the taking of Island No. 10 and New Madrid, Missouri, and then Memphis, Tennessee.\nIn April 1862, the Union Navy captured New Orleans. \"The key to the river was New Orleans, the South's largest port [and] greatest industrial center.\" U.S. Naval forces under Farragut ran past Confederate defenses south of New Orleans. Confederate forces abandoned the city, giving the Union a critical anchor in the deep South, which allowed Union forces to move up the Mississippi. Memphis fell to Union forces on June 6, 1862, and became a key base for further advances south along the Mississippi. Only the fortress city of Vicksburg, Mississippi, prevented Union control of the entire river.\nBragg's second invasion of Kentucky in the Confederate Heartland Offensive included initial successes such as Kirby Smith's triumph at the Battle of Richmond and the capture of the Kentucky capital of Frankfort on September 3, 1862. However, the campaign ended with a meaningless victory over Maj. Gen. Don Carlos Buell at the Battle of Perryville. Bragg was forced to end his attempt at invading Kentucky and retreat, due to lack of logistical support and infantry recruits. Bragg was narrowly defeated by Maj. Gen. William Rosecrans at the Battle of Stones River in Tennessee, the culmination of the Stones River Campaign.\nNaval forces assisted Grant in the long, complex Vicksburg Campaign that resulted in the Confederates surrendering at the Battle of Vicksburg in July 1863, which cemented Union control of the Mississippi and is one of the turning points of the war.\nThe one clear Confederate victory in the West was the Battle of Chickamauga. After Rosecrans' successful Tullahoma Campaign, Bragg, reinforced by Lt. Gen. James Longstreet's corps, defeated Rosecrans, despite the defensive stand of Maj. Gen. George Henry Thomas.\nRosecrans retreated to Chattanooga, which Bragg then besieged in the Chattanooga Campaign. Grant marched to the relief of Rosecrans and defeated Bragg at the Third Battle of Chattanooga, eventually causing Longstreet to abandon his Knoxville Campaign and driving Confederate forces out of Tennessee and opening a route to Atlanta and the heart of the Confederacy.\nTrans-Mississippi theater.\nBackground.\nThe Trans-Mississippi theater refers to military operations west of the Mississippi, encompassing most of Missouri, Arkansas, most of Louisiana, and the Indian Territory in present-day Oklahoma. The Trans-Mississippi District was formed by the Confederate States Army to better coordinate Ben McCulloch's command of troops in Arkansas and Louisiana, Sterling Price's Missouri State Guard, as well as the portion of Earl Van Dorn's command that included the Indian Territory and excluded the Army of the West. The Union's command was the Trans-Mississippi Division, or the Military Division of West Mississippi.\nBattles.\nThe first battle of the Trans-Mississippi theater was the Battle of Wilson's Creek (August 1861). The Confederates were driven from Missouri early in the war as a result of the Battle of Pea Ridge.\nExtensive guerrilla warfare characterized the trans-Mississippi region, as the Confederacy lacked the troops and logistics to support regular armies that could challenge Union control. Roving Confederate bands such as Quantrill's Raiders terrorized the countryside, striking military installations and civilian settlements. The \"Sons of Liberty\" and \"Order of the American Knights\" attacked pro-Union people, elected officeholders, and unarmed uniformed soldiers. These partisans could not be driven out of Missouri, until an entire regular Union infantry division was engaged. By 1864, these violent activities harmed the nationwide antiwar movement organizing against the re-election of Lincoln. Missouri not only stayed in the Union, but Lincoln took 70 percent of the vote to win re-election.\nSmall-scale military actions south and west of Missouri sought to control Indian Territory and New Mexico Territory for the Union. The Battle of Glorieta Pass was the decisive battle of the New Mexico Campaign. The Union repulsed Confederate incursions into New Mexico in 1862, and the exiled Arizona government withdrew into Texas. In the Indian Territory, civil war broke out within tribes. About 12,000 Indian warriors fought for the Confederacy but fewer for the Union. The most prominent Cherokee was Brigadier General Stand Watie, the last Confederate general to surrender.\nAfter the fall of Vicksburg in July 1863, Jefferson Davis informed General Kirby Smith in Texas that he could expect no further help from east of the Mississippi. Although he lacked resources to beat Union armies, he built up a formidable arsenal at Tyler, along with his own Kirby Smithdom economy, a virtual \"independent fiefdom\" in Texas, including railroad construction and international smuggling. The Union, in turn, did not directly engage him. Its 1864 Red River Campaign to take Shreveport, Louisiana, failed and Texas remained in Confederate hands throughout the war.\nLower seaboard theater.\nBackground.\nThe lower seaboard theater refers to military and naval operations that occurred near the coastal areas of the Southeast as well as the southern part of the Mississippi. Union naval activities were dictated by the Anaconda Plan.\nBattles.\nOne of the earliest battles was fought at Port Royal Sound (November 1861), south of Charleston. Much of the war along the South Carolina coast concentrated on capturing Charleston. In attempting to capture Charleston, the Union military tried two approaches: by land over James or Morris Islands or through the harbor. However, the Confederates were able to drive back each attack. A famous land attack was the Second Battle of Fort Wagner, in which the 54th Massachusetts Infantry took part. The Union suffered a serious defeat, losing 1,515 soldiers while the Confederates lost only 174. However, the 54th was hailed for its valor, which encouraged the general acceptance of the recruitment of African American soldiers into the Union Army, which reinforced the Union's numerical advantage.\nFort Pulaski on the Georgia coast was an early target for the Union navy. Following the capture of Port Royal, an expedition was organized with engineer troops under the command of Captain Quincy Adams Gillmore, forcing a Confederate surrender. The Union army occupied the fort for the rest of the war after repairing it.\nIn April 1862, a Union naval task force commanded by Commander David Dixon Porter attacked Forts Jackson and St. Philip, which guarded the river approach to New Orleans from the south. While part of the fleet bombarded the forts, other vessels forced a break in the obstructions in the river and enabled the rest of the fleet to steam upriver to the city. A Union army force commanded by Major General Benjamin Butler landed near the forts and forced their surrender. Butler's controversial command of New Orleans earned him the nickname \"Beast\".\nThe following year, the Union Army of the Gulf commanded by Major General Nathaniel P. Banks laid siege to Port Hudson for nearly eight weeks, the longest siege in US military history. The Confederates attempted to defend with the Bayou Teche Campaign but surrendered after Vicksburg. These surrenders gave the Union control over the Mississippi.\nSeveral small skirmishes but no major battles were fought in Florida. The biggest was the Battle of Olustee in early 1864.\nPacific coast theater.\nThe Pacific coast theater refers to military operations on the Pacific Ocean and in the states and Territories west of the Continental Divide.\nConquest of Virginia.\nAt the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac and put Maj. Gen. William Tecumseh Sherman in command of most of the western armies. Grant understood the concept of total war and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would end the war. This was total war not in killing civilians, but in taking provisions and forage and destroying homes, farms, and railroads, that Grant said \"would otherwise have gone to the support of secession and rebellion. This policy I believe exercised a material influence in hastening the end.\"\nGrant devised a coordinated strategy that would strike at the entire Confederacy from multiple directions. Generals Meade and Benjamin Butler were ordered to move against Lee near Richmond, General Franz Sigel was to attack the Shenandoah Valley, General Sherman was to capture Atlanta and march to the Atlantic Ocean, Generals George Crook and William W. Averell were to operate against railroad supply lines in West Virginia, and Maj. Gen. Nathaniel P. Banks was to capture Mobile, Alabama.\nGrant's Overland Campaign.\nGrant's army set out on the Overland Campaign intending to draw Lee into a defense of Richmond, where they would attempt to pin down and destroy the Confederate army. The Union army first attempted to maneuver past Lee and fought several battles, notably at the Wilderness, Spotsylvania, and Cold Harbor. These resulted in heavy losses on both sides and forced Lee's Confederates to fall back repeatedly. At the Battle of Yellow Tavern, the Confederates lost Jeb Stuart.\nAn attempt to outflank Lee from the south failed under Butler, who was trapped inside the Bermuda Hundred river bend. Each battle resulted in setbacks for the Union that mirrored those they had suffered under prior generals, though unlike them, Grant chose to fight on rather than retreat. Grant was tenacious and kept pressing Lee's Army of Northern Virginia back to Richmond. While Lee was preparing for an attack on Richmond, Grant unexpectedly turned south to cross the James River and began the protracted Siege of Petersburg, where the two armies engaged in trench warfare for over nine months.\nSheridan's Valley Campaign.\nTo deny the Confederacy continued use of the Shenandoah Valley as a base from which to launch invasions of Maryland and the Washington area, and to threaten Lee's supply lines for his forces, Grant launched the Valley campaigns in the spring of 1864. Initial efforts led by Gen. Sigel were repelled at the Battle of New Market by Confederate Gen. John C. Breckinridge. The Battle of New Market was the Confederacy's last major victory, and included a charge by teenage VMI cadets. After relieving Sigel, and following mixed performances by his successor, Grant finally found a commander, General Philip Sheridan, aggressive enough to prevail against the army of Maj. Gen. Jubal A. Early. After a cautious start, Sheridan defeated Early in a series of battles in September and October 1864, including a decisive defeat at the Battle of Cedar Creek. Sheridan then proceeded through that winter to destroy the agricultural base of the Shenandoah Valley, a strategy similar to the tactics Sherman later employed in Georgia.\nSherman's March to the Sea.\nMeanwhile, Sherman maneuvered from Chattanooga to Atlanta, defeating Confederate Generals Joseph E. Johnston and John Bell Hood. The fall of Atlanta on September 2, 1864, guaranteed the reelection of Lincoln. Hood left the Atlanta area to swing around and menace Sherman's supply lines and invade Tennessee in the Franklin\u2013Nashville Campaign. Union Maj. Gen. John Schofield defeated Hood at the Battle of Franklin, and George H. Thomas dealt Hood a massive defeat at the Battle of Nashville, effectively destroying Hood's army.\nLeaving Atlanta, and his base of supplies, Sherman's army marched, with no destination set, laying waste to about 20% of the farms in Georgia in his \"March to the Sea\". He reached the Atlantic at Savannah, Georgia, in December 1864. Sherman's army was followed by thousands of freed slaves; there were no major battles along the march. Sherman turned north through South Carolina and North Carolina, to approach the Confederate Virginia lines from the south, increasing the pressure on Lee's army.\nThe Waterloo of the Confederacy.\nLee's army, thinned by desertion and casualties, was now much smaller than Grant's. One last Confederate attempt to break the Union hold on Petersburg failed at the decisive Battle of Five Forks on April 1. The Union now controlled the entire perimeter surrounding Richmond\u2013Petersburg, completely cutting it off from the Confederacy. Realizing the capital was now lost, Lee's army and the Confederate government were forced to evacuate. The Confederate capital fell on April 2\u20133, to the Union XXV Corps, composed of black troops. The remaining Confederate units fled west after a defeat at Sayler's Creek on April 6.\nEnd of the war.\nLee did not intend to surrender, but planned to regroup at Appomattox Station, where supplies were to be waiting, and then continue the war. Grant chased Lee and got in front of him, so that when Lee's army reached the village of Appomattox Court House, they were surrounded. After an initial battle, Lee decided the fight was hopeless, and surrendered his Army of Northern Virginia to Grant on April 9, 1865, during a conference at the McLean House. In an untraditional gesture and as a sign of Grant's respect and anticipation of peacefully restoring Confederate states to the Union, Lee was permitted to keep his sword and horse, Traveller. His men were paroled, and a chain of Confederate surrenders began.\nOn April 14, 1865, Lincoln was shot by John Wilkes Booth, a Confederate sympathizer. Lincoln died early the next morning. Lincoln's vice president, Andrew Johnson, was unharmed, because his would-be assassin, George Atzerodt, lost his nerve, so Johnson was immediately sworn in as president.\nMeanwhile, Confederate forces across the South surrendered, as news of Lee's surrender reached them. On April 26, the same day Sergeant Boston Corbett killed Booth at a tobacco barn, Johnston surrendered nearly 90,000 troops of the Army of Tennessee to Sherman at Bennett Place, near present-day Durham, North Carolina. It proved to be the largest surrender of Confederate forces. On May 4, all remaining Confederate forces in Alabama, Mississippi, and Louisiana east of the Mississippi, under the command of Lt. General Richard Taylor, surrendered. Confederate president Davis was captured in retreat at Irwinville, Georgia on May 10.\nThe final land battle was fought on May 13, 1865, at the Battle of Palmito Ranch in Texas. On May 26, 1865, Confederate Lt. Gen. Simon B. Buckner, acting for Edmund Smith, signed a military convention surrendering Confederate forces in the Trans-Mississippi Department. This date is often cited by contemporaries and historians as the effective end date of the war. On June 2, with most of his troops having already gone home, a reluctant Kirby Smith had little choice but to sign the official surrender document. On June 23, Cherokee leader and Brig. General Stand Watie became the last Confederate general to surrender his forces.\nOn June 19, 1865, Union Maj. Gen. Gordon Granger announced General Order No. 3, bringing the Emancipation Proclamation into effect in Texas and freeing the last slaves of the Confederacy. The anniversary of this date is now celebrated as Juneteenth.\nThe naval part of the war ended more slowly. It had begun on April 11, two days after Lee's surrender, when Lincoln proclaimed that foreign nations had no further \"claim or pretense\" to deny equality of maritime rights and hospitalities to U.S. warships and, in effect, that rights extended to Confederate ships to use neutral ports as safe havens from U.S. warships should end. Having no response to Lincoln's proclamation, President Johnson issued a similar proclamation dated May 10, more directly stating that the war was almost at an end and insurgent cruisers still at sea, and prepared to attack U.S. ships, should not have rights to do so through use of safe foreign ports or waters. Britain finally responded on June 6, by transmitting a letter from Foreign Secretary John Russell, 1st Earl Russell, to the Lords of the Admiralty withdrawing rights to Confederate warships to enter British ports and waters. U.S. Secretary of State Seward welcomed the withdrawal of concessions to the Confederates. Finally, on October 18, Russell advised the Admiralty that the time specified in his June message had elapsed and \"all measures of a restrictive nature on vessels of war of the United States in British ports, harbors, and waters, are now to be considered as at an end\". Nonetheless, the final Confederate surrender was in Liverpool, England where James Iredell Waddell, the captain of CSS \"Shenandoah\", surrendered the cruiser to British authorities on November 6.\nLegally, the war did not end until August 20, 1866, when President Johnson issued a proclamation that declared \"that the said insurrection is at an end and that peace, order, tranquillity, and civil authority now exist in and throughout the whole of the United States of America\".\nUnion victory.\nThe causes of the war, reasons for its outcome, and even its name are subjects of lingering contention. The North and West grew wealthy while the once-rich South became poor for a century. The national political power of the slaveowners and rich Southerners ended. Historians are less sure about the results of postwar Reconstruction, especially regarding the second-class citizenship of the freedmen and their poverty.\nHistorians have debated whether the Confederacy could have won the war. Most scholars, including James M. McPherson, argue Confederate victory was possible. McPherson argues that the North's advantage in population and resources made Northern victory likely, but not guaranteed. He argues that if the Confederacy had fought using unconventional tactics, it would have more easily been able to hold out long enough to exhaust the Union. Confederates did not need to invade and hold enemy territory to win, but only to fight a defensive war to convince the North the cost of winning was too high. The North needed to conquer and hold vast stretches of enemy territory and defeat Confederate armies to win. Lincoln was not a military dictator and could fight only as long as the American public supported the war. The Confederacy sought to win independence by outlasting Lincoln; however, after Atlanta fell and Lincoln defeated McClellan in the election of 1864, hope for a political victory for the South ended. Lincoln had secured the support of the Republicans, War Democrats, border states, emancipated slaves, and the neutrality of Britain and France. By defeating the Democrats and McClellan, he defeated the Copperheads, who had wanted a negotiated peace with the Confederacy.\nSome scholars argue the Union held an insurmountable long-term advantage over the Confederacy in industrial strength and population. Confederate actions, they argue, only delayed defeat. Historian Shelby Foote expressed this view succinctly: \nA minority view among historians is that the Confederacy lost because, as E. Merton Coulter put it, \"people did not will hard enough and long enough to win.\" However, most historians reject the argument. McPherson, after reading thousands of letters written by Confederate soldiers, found strong patriotism that continued to the end; they truly believed they were fighting for freedom and liberty. Even as the Confederacy was visibly collapsing in 1864\u201365, most Confederate soldiers were fighting hard. Historian Gary Gallagher cites General Sherman, who in early 1864 commented, \"The devils seem to have a determination that cannot but be admired.\" Despite their loss of slaves and wealth, with starvation looming, Sherman continued, \"yet I see no sign of let-up\u2014some few deserters\u2014plenty tired of war, but the masses determined to fight it out.\"\nAlso important were Lincoln's eloquence in articulating the national purpose and his skill in keeping the border states committed to the Union cause. The Emancipation Proclamation was an effective use of the President's war powers. The Confederate government failed to get Europe involved militarily. Southern leaders needed to get European powers to help break the blockade the Union had created around Southern ports. Lincoln's naval blockade was 95 percent effective at stopping trade goods; as a result, imports and exports to the South declined significantly. The abundance of European cotton and Britain's hostility to slavery, along with Lincoln's naval blockades, severely decreased any chance that Britain or France would enter the war.\nHistorian Don H. Doyle has argued that the Union victory had a major impact on world history. The Union victory energized popular democratic forces. A Confederate victory, on the other hand, would have meant a new birth of slavery, not freedom. Historian Fergus Bordewich, following Doyle, argues that:\n Scholars have debated what the effects of the war were on political and economic power in the South. The prevailing view is that the southern planter elite retained its powerful position in the South. However, a 2017 study challenges this, noting that while some Southern elites retained their economic status, the turmoil of the 1860s created greater opportunities for economic mobility in the South, than in the North.\nCasualties.\nExact casualty figures were collected for the Union, but Confederate records were poorly kept, or lost in the chaos of defeat. Thus, the casualty figures are imprecise and based on statistical extrapolation. Neither side kept a tally of civilian deaths due to the war. In the 19th century, the death toll had been estimated at a lower 620,000. In 2011, the death toll was recalculated based on a 1% sample of census data, yielding approximately 750,000 soldier deaths, 20 percent higher than traditionally estimated, and possibly as high as 850,000. The figure was recalculated to 698,000 soldier deaths in 2024 after examining newly available full census records. Mortality rates among men were as high as 19 percent in Louisiana, and 16.6\u201316.7 percent in Georgia and South Carolina respectively.\nThe war resulted in at least 1,030,000 casualties (3 percent of the population), including an estimated 698,000 soldier deaths\u2014two-thirds by disease. Based on 1860 census figures, 8 percent of all white men aged 13\u201343 died in the war, including 6 percent in the North and 18 percent in the South. About 56,000 soldiers died in prison camps during the War. An estimated 60,000 soldiers lost limbs. As McPherson notes, the war's \"cost in American lives was as great as in all of the nation's other wars combined through Vietnam\". \nOf the 359,528 Union Army dead, amounting to 15 percent of the over two million who served:\nIn addition, there were 4,523 deaths in the Navy (2,112 in battle) and 460 in the Marines (148 in battle).\nAfter the Emancipation Proclamation authorized freed slaves to \"be received into the armed service of the United States\", former slaves who escaped from plantations or were liberated by the Union Army were recruited into the United States Colored Troops regiments of the Union Army, as were black men who had not been slaves. The US Colored Troops made up 10 percent of the Union death toll\u201415 percent of Union deaths from disease and less than 3 percent of those killed in battle. Losses among African Americans were high. In the last year and a half and from all reported casualties, approximately 20 percent of all African Americans enrolled in the military died during the war. Their mortality rate was significantly higher than white soldiers. While 15 percent of US Volunteers and just 9 percent of white Regular Army troops died, 21 percent of US Colored Troops died.\nWhile the figures of 360,000 army deaths for the Union and 260,000 for the Confederacy remained commonly cited, they are incomplete. In addition to many Confederate records being missing, partly as a result of Confederate widows not reporting deaths due to being ineligible for benefits, both armies only counted troops who died during their service and not the tens of thousands who died of wounds or diseases after being discharged. This often happened only days or weeks later. Francis Amasa Walker, superintendent of the 1870 census, used census and surgeon general data to estimate a minimum of 500,000 Union military deaths and 350,000 Confederate military deaths, a total of 850,000 soldiers. While Walker's estimates were originally dismissed because of the 1870 census's undercounting, it was later found that the census was only off by 6.5 percent and that the data Walker used would be roughly accurate.\nLosses were far higher than during the war with Mexico, which saw roughly 13,000 American deaths, including fewer than two thousand killed in battle, between 1846 and 1848. One reason for the high number of battle deaths in the civil war was the continued use of tactics similar to those of the Napoleonic Wars, such as charging. With the advent of more accurate rifled barrels, Mini\u00e9 balls, and (near the end of the war for the Union) repeating firearms such as the Spencer repeating rifle and the Henry repeating rifle, soldiers were mowed down when standing in lines in the open. This led to the adoption of trench warfare, a style of fighting that defined much of World War I.\nDeaths among former slaves has proven hard to estimate, due to the lack of reliable census data, though they were known to be considerable, as former slaves were set free or escaped in massive numbers in areas where the Union army did not have sufficient shelter, doctors, or food for them. Professor Jim Downs states that tens of thousands to hundreds of thousands of slaves died during the war from disease, starvation, or exposure, and that if these deaths are counted in the war's total, the death toll would exceed 1\u00a0million.\nIt is estimated that during the war, of the equines killed, including horses, mules, donkeys and even confiscated children's ponies, over 32,600 of them belonged to the Union and 45,800 the Confederacy. However, other estimates place the total at 1,000,000.\nIt is estimated that 544 Confederate flags were captured during the war by the Union. The flags were sent to the War Department in Washington. The Union flags captured by the Confederates were sent to Richmond.\nEmancipation.\nAbolishing slavery was not a Union war goal from the outset, but quickly became one. Lincoln's initial claims were that preserving the Union was the central goal. In contrast, the South fought to preserve slavery. While not all Southerners saw themselves as fighting for slavery, most officers and over a third of the rank and file in Lee's army had close family ties to slavery. To Northerners, the motivation was primarily to preserve the Union, not to abolish slavery. However, as the war dragged on, and it became clear slavery was central to the conflict, and that emancipation was (to quote the Emancipation Proclamation) \"a fit and necessary war measure for suppressing [the] rebellion,\" Lincoln and his cabinet made ending slavery a war goal, culminating in the Emancipation Proclamation. Lincoln's decision to issue the Proclamation angered Peace Democrats (\"Copperheads\") and War Democrats, but energized most Republicans. By warning that free blacks would flood the North, Democrats made gains in the 1862 elections, but they did not gain control of Congress. The Republicans' counterargument that slavery was the mainstay of the enemy steadily gained support, with the Democrats losing decisively in the 1863 elections in the Northern state of Ohio, when they tried to resurrect anti-black sentiment.\nEmancipation Proclamation.\nThe Emancipation Proclamation legally freed the slaves in states \"in rebellion,\" but, as a practical matter, slavery for the 3.5\u00a0million black people in the South effectively ended in each area when Union armies arrived. The last Confederate slaves were freed on June 19, 1865, celebrated as the modern holiday of Juneteenth. Slaves in the border states and those in some former Confederate territory occupied before the Emancipation Proclamation were freed by state action or (on December 6, 1865) by the Thirteenth Amendment. The Emancipation Proclamation enabled African Americans, both free blacks and escaped slaves, to join the Union Army. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of undermining the legitimacy of slavery.\nDuring the war, sentiment concerning slaves, enslavement, and emancipation in the United States was divided. Lincoln's fears of making slavery a war issue were based on a harsh reality: abolition did not enjoy wide support in the west, the territories, and the border states. In 1861, Lincoln worried that premature attempts at emancipation would mean the loss of the border states, and that \"to lose Kentucky is nearly the same as to lose the whole game.\" Copperheads and some War Democrats opposed emancipation, although the latter eventually accepted it as part of the total war needed to save the Union.\nAt first, Lincoln reversed attempts at emancipation by Secretary of War Simon Cameron and Generals John C. Fr\u00e9mont and David Hunter, to keep the loyalty of the border states and the War Democrats. Lincoln warned the border states that a more radical type of emancipation would happen if his plan of gradual compensated emancipation and voluntary colonization was rejected. But compensated emancipation occurred only in the District of Columbia, where Congress had the power to enact it. When Lincoln told his cabinet about his proposed emancipation proclamation, which would apply to the states still in rebellion on January 1, 1863, Seward advised Lincoln to wait for a Union military victory before issuing it, as to do otherwise would seem like \"our last shriek on the retreat\". Walter Stahr, however, writes, \"There are contemporary sources, however, that suggest others were involved in the decision to delay\", and Stahr quotes them.\nLincoln laid the groundwork for public support in an open letter published in response to Horace Greeley's \"The Prayer of Twenty Millions\"; the letter stated that Lincoln's goal was to save the Union, and that, if he freed the slaves, it would be as a means to that end. He also had a meeting at the White House with five African American representatives on August 14, 1862. Arranging for a reporter to be present, he urged his visitors to agree to the voluntary colonization of black people. Lincoln's motive for both his letter to Greeley and his statement to the black visitors was apparently to make his forthcoming Emancipation Proclamation more palatable to racist white people. A Union victory in the Battle of Antietam on September 17, 1862, provided Lincoln with an opportunity to issue the preliminary Emancipation Proclamation, and the War Governors' Conference added support for the proclamation.\nLincoln issued his preliminary Emancipation Proclamation on September 22, 1862. It stated that slaves in all states in rebellion on January 1, 1863, would be free. He issued his final Emancipation Proclamation on January 1, 1863, keeping his promise. In his letter to Albert G. Hodges, Lincoln explained his belief that \"If slavery is not wrong, nothing is wrong\u00a0... And yet I have never understood that the Presidency conferred upon me an unrestricted right to act officially upon this judgment and feeling\u00a0... I claim not to have controlled events, but confess plainly that events have controlled me.\"\nLincoln's moderate approach succeeded in inducing the border states to remain in the Union and War Democrats to support the Union. The border states, which included Kentucky, Missouri, Maryland, Delaware, and Union-controlled regions around New Orleans, Norfolk, Virginia, and elsewhere, were not covered by the Emancipation Proclamation. Nor was Tennessee, which had come under Union control. Missouri and Maryland abolished slavery on their own; Kentucky and Delaware did not. Still, the proclamation did not enjoy universal support. It caused much unrest in what were then considered western states, where racist sentiments led to a great fear of abolition. There was some concern that the proclamation would lead to the secession of western states, and its issuance prompted the stationing of Union troops in Illinois in case of rebellion.\nSince the Emancipation Proclamation was based on the President's war powers, it applied only in territory held by Confederates at the time it was issued. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. The Emancipation Proclamation greatly reduced the Confederacy's hope of being recognized or otherwise aided by Britain or France. By late 1864, Lincoln was playing a leading role in getting the House of Representatives to vote for the Thirteenth Amendment, which mandated the ending of chattel slavery.\nReconstruction.\nThe war devastated the South and posed serious questions of how it would be reintegrated into the Union. The war destroyed much of the South's wealth, in part because wealth held in enslaved people (at least $1,000 each for a healthy adult prior to the war) was wiped off the books. All accumulated investment in Confederate bonds was forfeited; most banks and railroads were bankrupt. The income per person dropped to less than 40 percent of that of the North, and that lasted into the 20th century. Southern influence in the federal government, previously considerable, was greatly diminished until the second half of the 20th century. Reconstruction began during the war, with the Emancipation Proclamation of January 1863, and it continued until 1877. It comprised multiple complex methods to resolve the outstanding issues of the aftermath, the most important of which were the three \"Reconstruction Amendments\" to the Constitution: the 13th outlawing slavery (1865), the 14th guaranteeing citizenship to former slaves (1868), and the 15th prohibiting the denial of voting rights \"on account of race, color, or previous condition of servitude\" (1870). From the Union perspective, the goals of Reconstruction were to consolidate victory by reuniting the Union, to guarantee a \"republican form of government\" for the ex-Confederate states, and to permanently end slavery\u2014and prevent semi-slavery status.\nPresident Johnson, who took office in April 1865, took a lenient approach and saw the achievement of the main war goals as realized in 1865, when each ex-rebel state repudiated secession and ratified the Thirteenth Amendment. Radical Republicans demanded proof that Confederate nationalism was dead and that the slaves were truly free. They overrode Johnson's vetoes of civil rights legislation, and the House impeached him, although the Senate did not convict him. In 1868 and 1872, the Republican candidate Grant won the presidency. In 1872, the \"Liberal Republicans\" argued that the war goals had been achieved and Reconstruction should end. They chose Horace Greeley to head a presidential ticket in 1872 but were decisively defeated. In 1874, Democrats, primarily Southern, took control of Congress and opposed further reconstruction. The Compromise of 1877 closed with a national consensus, except on the part of former slaves, that the war had finally ended. With the withdrawal of federal troops, however, whites retook control of every Southern legislature, and the Jim Crow era of disenfranchisement and legal segregation was ushered in.\nThe war had a demonstrable impact on American politics. Many veterans on both sides were elected to political office, including five U.S. Presidents: Ulysses Grant, Rutherford B. Hayes, James A. Garfield, Benjamin Harrison, and William McKinley.\nMemory and historiography.\nThe war is a central event in American collective memory. There are innumerable statues, commemorations, books, and archival collections. The memory includes the home front, military affairs, the treatment of soldiers, both living and dead, in the war's aftermath, depictions of the war in literature and art, evaluations of heroes and villains, and considerations of the moral and political lessons of the war. The last theme includes moral evaluations of racism and slavery, heroism in combat and behind the lines, and issues of democracy and minority rights, as well as the notion of an \"Empire of Liberty\" influencing the world.\nHistorians have paid more attention to the causes of the war than to the war itself. Military history has largely developed outside academia, leading to a proliferation of studies by non-scholars who nevertheless are familiar with the primary sources and pay close attention to battles and campaigns and who write for the general public. Practically every major figure in the war, both North and South, has had a serious biographical study.\nEven the name used for the conflict has been controversial, with many names used for it. During and immediately after the war, Northern historians often used a term like \"War of the Rebellion\". Writers in rebel states often referred to the \"War for Southern Independence\". Some Southerners have described it as the \"War of Northern Aggression\".\nLost Cause.\nThe memory of the war in the white South crystallized in the myth of the \"Lost Cause\": that the Confederate cause was just and heroic. The myth shaped regional identity and race relations for generations. Alan T. Nolan notes that the Lost Cause was expressly a rationalization, a cover-up to vindicate the name and fame of those in rebellion. Some claims revolve around the insignificance of slavery as a cause; some appeals highlight cultural differences between North and South; the military conflict by Confederate actors is idealized; in any case, secession was said to be lawful. Nolan argues that the adoption of the Lost Cause perspective facilitated the reunification of the North and the South while excusing the \"virulent racism\" of the 19th century, sacrificing black American progress to white man's reunification. He also deems the Lost Cause \"a caricature of the truth. This caricature wholly misrepresents and distorts the facts of the matter\" in every instance. The Lost Cause myth was formalized by Charles A. Beard and Mary R. Beard, whose \"The Rise of American Civilization\" (1927) spawned \"Beardian historiography\". The Beards downplayed slavery, abolitionism, and issues of morality. Though this interpretation was abandoned by the Beards in the 1940s, and by historians generally by the 1950s, Beardian themes still echo among Lost Cause writers.\nThe United Daughters of the Confederacy\nThe United Daughters of the Confederacy (UDC) is a Southern heritage organization founded in 1894 in Nashville, Tennessee, by a group of women whose stated mission was to honor Confederate veterans and preserve their memory. The organization quickly grew in influence during the late 19th and early 20th centuries and ended up playing a pivotal role in shaping the collective memory of the American Civil War.\nThe UDC focused on erecting Confederate monuments, funding the education of Confederate descendants, and promoting Confederate history through textbooks and public ceremonies. The group emphasized the valor of Confederate soldiers and the righteousness of the Southern cause, often omitting or downplaying the central role of slavery in the conflict.\nThe UDC became a major proponent of the Lost Cause ideology, a narrative that romanticized the Confederacy as a noble, states'-rights-driven effort rather than a rebellion to preserve slavery. Through speeches, publications, and curriculum influence, the UDC worked to recast the Confederacy in a sympathetic light, framing the Civil War as a struggle against Northern aggression.\nThis effort contributed to the widespread proliferation of Confederate symbols and a sanitized portrayal of Southern history in public spaces and schools. Critics argue that the UDC's activities perpetuated racist ideologies by fostering nostalgia for the antebellum South and minimizing the horrors of slavery.\nIn recent years, the role of the UDC and the Lost Cause myth has come under scrutiny amid debates over Confederate monuments and systemic racism in the United States. Many of the monuments and historical markers the UDC sponsored have been reevaluated and removed, sparking ongoing discussions about memory, heritage, and justice.\nBattlefield preservation.\nThe first efforts at Civil War battlefield preservation and memorialization came during the war, with the establishment of National Cemeteries at Gettysburg, Mill Springs and Chattanooga. Soldiers began erecting markers on battlefields beginning with the First Battle of Bull Run in 1861. The oldest surviving monument is the Hazen Brigade Monument near Murfreesboro in Central Tennessee, built in the summer of 1863 by soldiers in Union Col. William B. Hazen's brigade to mark the spot where they buried their dead, following the Battle of Stones River.\nIn the 1890s, the government established five Civil War battlefield parks under the jurisdiction of the War Department, beginning with the creation of the Chickamauga and Chattanooga National Military Park at Fort Oglethorpe, Georgia, and the Antietam National Battlefield in Sharpsburg, Maryland, in 1890. The Shiloh National Military Park was established in 1894 in Shiloh, Tennessee, followed by the Gettysburg National Military Park in 1895, and Vicksburg National Military Park in 1899. In 1933, these five parks and other national monuments were transferred to the National Park Service. Chief among modern efforts to preserve Civil War sites has been the American Battlefield Trust, with more than 130 battlefields in 24 states. The five major battlefield parks operated by the National Park Service had a combined 3\u00a0million visitors in 2018, down 70% from 10\u00a0million in 1970.\nCommemoration.\nThe Civil War has been commemorated in many capacities, ranging from the reenactment of battles to statues and memorial halls erected, films, stamps and coins with Civil War themes being issued, all of which helped to shape public memory. These commemorations occurred in greater numbers on the 100th and 150th anniversaries of the war.\nHollywood's take on the war has been especially influential in shaping public memory, as in such film classics as \"The Birth of a Nation\" (1915), \"Gone with the Wind\" (1939), and \"Lincoln\" (2012). Ken Burns's PBS television series \"The Civil War\" (1990) is well-remembered, though criticized for its historical inaccuracy.\nTechnological significance.\nTechnological innovations during the war had a great impact on 19th-century science. The war was an early example of an \"industrial war\", in which technological might is used to achieve military supremacy. New inventions, such as the train and telegraph, delivered soldiers, supplies and messages at a time when horses had been the fastest way to travel. It was also in this war that aerial warfare, in the form of reconnaissance balloons, was first used. It saw the first action involving steam-powered ironclad warships in naval warfare history. Repeating firearms such as the Henry rifle, Spencer rifle, Colt revolving rifle, Triplett &amp; Scott carbine and others, first appeared during the Civil War; they were a revolutionary invention that would soon replace muzzle-loading and single-shot firearms. The war saw the first appearances of rapid-firing weapons and machine guns such as the Agar gun and Gatling gun.\nIn works of culture and art.\nThe Civil War is one of the most studied events in American history, and the collection of cultural works around it is enormous. This section gives an abbreviated overview of the most notable works."}
{"id": "864", "revid": "24473539", "url": "https://en.wikipedia.org/wiki?curid=864", "title": "Andy Warhol", "text": "Andy Warhol (; born Andrew Warhola Jr.; August 6, 1928 \u2013 February 22, 1987) was an American visual artist, film director and producer. A leading figure in the pop art movement, Warhol is considered one the most important artists of the second half of the 20th century. His works explore the relationship between artistic expression, advertising, and celebrity culture that flourished by the 1960s, and span a variety of media, including painting, sculpture, photography, and filmmaking. Some of his best-known works include the silkscreen paintings \"Campbell's Soup Cans\" (1962) and \"Marilyn Diptych\" (1962), the experimental film \"Chelsea Girls\" (1966), the multimedia events known as the \"Exploding Plastic Inevitable\" (1966\u201367), and the erotic film \"Blue Movie\" (1969) that started the \"Golden Age of Porn\".\nBorn and raised in Pittsburgh in a family of Eastern European immigrants, Warhol initially pursued a successful career as a commercial illustrator in the 1950s. After exhibiting his work in art galleries, he began to receive recognition as an influential and controversial artist in the 1960s. His New York studio, The Factory, became a well-known gathering place that brought together distinguished intellectuals, drag queens, playwrights, bohemian street people, Hollywood celebrities and wealthy patrons. He directed and produced several underground films starring a collection of personalities known as Warhol superstars, and is credited with inspiring the widely used expression \"15 minutes of fame.\" Warhol managed and produced the experimental rock band the Velvet Underground. Warhol expressed his queer identity through many of his works at a time when homosexuality was actively suppressed in the United States.\nAfter surviving an assassination attempt by radical feminist Valerie Solanas in June 1968, Warhol focused on transforming The Factory into a business enterprise. He founded \"Interview\" magazine and authored numerous books, including \"The Philosophy of Andy Warhol\" (1975) and \"\" (1980). He also hosted the television series \"Fashion\" (1979\u201380), \"Andy Warhol's TV\" (1980\u201383), and \"Andy Warhol's Fifteen Minutes\" (1985\u201387). Warhol died of cardiac arrhythmia, aged 58, after gallbladder surgery in February 1987.\nWarhol has been described as the \"bellwether of the art market\", with several of his works ranking among the most expensive paintings ever sold. In 2013, \"Silver Car Crash (Double Disaster)\" (1963) sold for $105 million, setting a record for the artist. In 2022, \"Shot Sage Blue Marilyn\" (1964) sold for $195 million, which is the highest price paid at auction for a work by an American artist. Warhol has been the subject of numerous retrospective exhibitions, books, and documentary films. The Andy Warhol Museum in his native city of Pittsburgh, which holds an extensive permanent collection of art and archives, is the largest museum in the United States dedicated to a single artist.\nEarly life and education.\nWarhol was born on August 6, 1928, in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Warhola (Americanized as Andrew Warhola Sr.; 1889\u20131942) and Julia Warhola (\"n\u00e9e\" Zavack\u00e1, 1891\u20131972). His parents were working-class Rusyn emigrants from Mik\u00f3, Austria-Hungary (now called Mikov\u00e1, located in today's northeastern Slovakia).\nWarhol's father emigrated to the United States in 1912 and worked in a coal mine. His wife joined him in Pittsburgh in 1921. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. They were Ruthenian Catholic and attended St. John Chrysostom Byzantine Catholic Church. Warhol had two elder brothers\u2014Paul (1922\u20132014) and John (1925\u20132010). Paul's son, James Warhola, became a successful children's book illustrator. Warhol had an older sister, Maria, who died in infancy in Austria-Hungary.\nIn third grade, Warhol had Sydenham's chorea (also known as St. Vitus' Dance), the nervous system disease that causes involuntary movements of the extremities, which is believed to be a complication of scarlet fever which causes skin pigmentation blotchiness. At times when he was confined to bed, he drew, listened to the radio and collected pictures of movie stars around his bed. Warhol later described this period as very important in the development of his personality, skill-set and preferences. When Warhol was 13, his father died in an accident.\nAs a teenager, Warhol graduated from Schenley High School in 1945, and also won a Scholastic Art and Writing Award. After graduating from high school, he enrolled at the Carnegie Institute of Technology in Pittsburgh, where he studied commercial art. During his time there, Warhol joined the campus Modern Dance Club and Beaux Arts Society. He also served as art director of the student art magazine, \"Cano\", illustrating a cover in 1948 and a full-page interior illustration in 1949. These are believed to be his first two published artworks. Warhol earned a Bachelor of Fine Arts in pictorial design in 1949. Later that year, he moved to New York City and began a career in magazine illustration and advertising.\nCareer.\n1950s.\nWarhol's early career was dedicated to commercial and advertising art, where his first commission had been to draw shoes for \"Glamour\" magazine in 1949. \nIn 1952, Alexander Iolas is credited as discovering Andy Warhol, and he organized first solo show at the Hugo Gallery in New York. \nIn 1955, Warhol began designing advertisements for shoe manufacturer Israel Miller. He developed his \"blotted line\" technique, applying ink to paper and then blotting the ink while still wet, which was akin to a printmaking process on the most rudimentary scale. His use of tracing paper and ink allowed him to repeat the basic image and also to create endless variations on the theme. American photographer John Coplans recalled that \"nobody drew shoes the way Andy did. He somehow gave each shoe a temperament of its own, a sort of sly, Toulouse-Lautrec kind of sophistication, but the shape and the style came through accurately and the buckle was always in the right place. The kids in the apartment [which Andy shared in New York \u2013 note by Coplans] noticed that the vamps on Andy's shoe drawings kept getting longer and longer but [Israel] Miller didn't mind. Miller loved them.\"\nIn 1956, Warhol was included in his first group exhibition at the Museum of Modern Art, New York. That year, he traveled around the world with his friend, production designer Charles Lisanby, studying art and culture in several countries. \nIn 1956, Warhol began to sketch ornate footwear as a hobby. He designed whimsical shoes that were embellished with gold leaf, and each represented a famous figure such as Truman Capote, Kate Smith, James Dean, Julie Andrews, Elvis Presley, and Zsa Zsa Gabor. They sold for $50 to $225 apiece when they were exhibited at the Bodley Gallery in New York in 1957.\nWarhol habitually used the expedient of tracing photographs projected with an epidiascope. Using prints by Edward Wallowitch, his \"first boyfriend\", the photographs would undergo a subtle transformation during Warhol's often cursory tracing of contours and hatching of shadows. Warhol used Wallowitch's photograph \"Young Man Smoking a Cigarette\" () for a 1958 design for a book cover he submitted to Simon and Schuster for the Walter Ross pulp novel \"The Immortal\", and later used others for his series of paintings.\nWith the rapid expansion of the record industry, RCA Records hired Warhol, along with another freelance artist, Sid Maurer, to design album covers and promotional materials.\n1960s.\nAs a commercial artist, Warhol worked with high-end advertising clients such as Tiffany &amp; Co.\nIn 1961 Warhol purchased a townhouse at 1342 Lexington Avenue in Carnegie Hill, which he also used as his art studio. In 1962, Warhol was taught silkscreen printmaking techniques by Max Arthur Cohn at his graphic arts business in Manhattan. In his book \"\", Warhol writes: \"When you do something exactly wrong, you always turn up something\".\nIn May 1962, Warhol was featured in an article in \"Time\" with his painting \"Big Campbell's Soup Can with Can Opener (Vegetable)\" (1962), which initiated his most sustained motif, the Campbell's soup can. That painting became Warhol's first to be shown in a museum when it was exhibited at the Wadsworth Atheneum in Hartford in July 1962. On July 9, 1962, Warhol's exhibition opened at the Ferus Gallery in Los Angeles with \"Campbell's Soup Cans\", marking his West Coast debut of pop art.\nIn November 1962, Warhol had an exhibition at Eleanor Ward's Stable Gallery in New York. The exhibit included the works \"Gold Marilyn\", eight of the classic \"Marilyn\" series also named \"Flavor Marilyns\", \"Marilyn Diptych\", \"100 Soup Cans\", \"100 Coke Bottles\", and \"100 Dollar Bills\". \"Gold Marilyn\" was bought by the architect Philip Johnson and donated to the Museum of Modern Art.\nIn December 1962, New York City's Museum of Modern Art hosted a symposium on pop art, during which artists such as Warhol were attacked for \"capitulating\" to consumerism. Critics were appalled by Warhol's open acceptance of market culture, which set the tone for his reception.\nIn 1963, Warhol formed The Druds, a short-lived avant-garde noise band that included notable figures from the New York minimal art and proto-conceptual art scenes, including Larry Poons, La Monte Young, Walter De Maria, Jasper Johns, Claes Oldenberg, and Lucas Samaras.\nIn January 1963, Warhol rented his first studio\u2014an old firehouse at 159 East 87th Street\u2014where he created his \"Elvis\" series, which included \"Eight Elvises\" (1963) and \"Triple Elvis\" (1963). These portraits, along with a series of Elizabeth Taylor portraits, were shown at his second exhibition at the Ferus Gallery in Los Angeles. Later that year, Warhol relocated his studio to East 47th Street, which would turn into The Factory. The Factory became a popular gathering spot for a wide range of artists, writers, musicians and underground celebrities.\nWarhol had his second exhibition at the Stable Gallery in the spring of 1964, which featured sculptures of commercial boxes stacked and scattered throughout the space to resemble a warehouse. For the exhibition, Warhol custom ordered wooden boxes and silkscreened graphics onto them. The sculptures\u2014\"Brillo Box\", \"Del Monte Peach Box\", \"Heinz Tomato Ketchup Box\", \"Kellogg's Cornflakes Box\", \"Campbell's Tomato Juice Box\" and \"Mott's Apple Juice Box\"\u2014sold for $200 to $400 depending on the size of the box.\nA pivotal event was \"The American Supermarket\" exhibition at Paul Bianchini's Upper East Side gallery in late 1964. The show was presented as a typical small supermarket environment, except that everything in it\u2014from the produce, canned goods, meat, posters on the wall, etc.\u2014was created by prominent pop artists of the time, among them sculptor Claes Oldenburg, Mary Inman and Bob Watts. Warhol designed a $12 paper shopping bag\u2014plain white with a red Campbell's soup can. His painting of a can of a Campbell's soup cost $1,500 while each autographed can sold for three for $18, $6.50 each. The exhibit was one of the first mass events that directly confronted the general public with both pop art and the perennial question of what art is.\nWarhol used assistants to increase his productivity and these collaborations would remain a defining and controversial aspect of his working methods throughout his career. One of Warhol's most important collaborators during this period was Gerard Malanga who assisted him with the production of silkscreens and films at The Factory, Warhol's studio that was covered in aluminum foil and painted silver by Billy Name. \nIn November 1964, Warhol's first \"Flowers\" series exhibited at the Leo Castelli Gallery in New York. In May 1965, his second \"Flowers\" series, which had more sizes and color variation that the previous, was shown at Galerie Ileana Sonnabend in Paris. During this trip Warhol announced that he was retiring from painting to focus on film.\nFrom the mid-1960s to the early 1970s, Warhol also groomed a retinue of bohemian and counterculture eccentrics upon whom he bestowed the designation \"superstars\", including Baby Jane Holzer, Brigid Berlin, Ondine, Edie Sedgwick, Ingrid Superstar, Nico, International Velvet, Mary Woronov, Viva, Ultra Violet, Joe Dallesandro, Candy Darling, Holly Woodlawn, Jackie Curtis and Jane Forth. These people participated in the Factory films, and some\u2014like Berlin\u2014remained friends with Warhol until his death. Important figures in the New York underground art/cinema world, such as writer John Giorno and filmmaker Jack Smith, also appear in Warhol films of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this time. Less well known was his support and collaboration with several teenagers during this era, who would achieve prominence later in life, including writer David Dalton, photographer Stephen Shore and artist Bibbe Hansen (mother of pop musician Beck).\nThe experimental rock group The Velvet Underground was taken on by Warhol around the end of 1965. In his capacity as their manager, he included them as a key component of his \"Exploding Plastic Inevitable\" multimedia performances in 1966 and 1967, and he funded their debut album, \"The Velvet Underground &amp; Nico\" (1967).\nWarhol made a conscious decision to oppose conventional painting, stating that he no longer believed in painting. In response to art dealer Ivan Karp's suggestion to paint cows, Warhol produced \"Cow Wallpaper,\" which covered the walls of the Leo Castelli Gallery during his April 1966 exhibition.\nIn 1967, Warhol established Factory Additions for his printmaking and publishing enterprise. In order to duplicate prints for a wide audience, Factory Additions published multiple portfolios of ten images each in editions of 250. These were then printed using professional screen printers.\nWarhol intended to present the film \"Chelsea Girls\" (1966) at the 1967 Cannes Film Festival, but it wasn't shown because \"the festival authorities explained that the film was too long, there were technical problems.\"\nIn February 1968, Warhol's first solo museum exhibition was mounted at the Moderna Museet in Stockholm.\n1968 assassination attempt\nOn June 3, 1968, radical feminist writer Valerie Solanas shot Warhol and Mario Amaya, art critic and curator, at The Factory. Solanas had been a marginal figure in the Factory scene before the shooting. She authored the \"SCUM Manifesto\", a separatist feminist tract that advocated the elimination of men; and appeared in the Warhol film \"I, a Man\" (1967). Amaya received only minor injuries and was released from the hospital later the same day. Warhol was seriously wounded by the attack and barely survived and remained in the hospital for nearly two months. Solanas turned herself in to the police a few hours after the attack and said that Warhol \"had too much control over my life.\" She was subsequently diagnosed with paranoid schizophrenia and eventually sentenced to three years in prison.\nOne of the Factory's assistants, Jed Johnson, had witnessed the shooting. Johnson visited Warhol regularly during his hospitalization, and the two developed an intimate relationship. Johnson moved in with Warhol shortly after he was discharged from the hospital to assist him in recuperating and taking care of his mother, Julia Warhola.\nThe assassination attempt had a profound effect on Warhol's life and art. He had physical effects for the rest of his life, including being required to wear a surgical corset. The Factory became more regulated and Warhol focused on making it a business enterprise. He credited his collaborator Paul Morrissey with transforming the Factory into a \"regular office.\"\nIn August 1968, Warhol made an appearance in court after Phillip \"Fufu\" Van Scoy Smith, an investor in a canceled film adaptation of the Charlotte Bront\u00eb novel \"Jane Eyre\", sued him for $80,000. A legal battle ensued for 2 years, ending after the backer failed to show up in court.\nIn September 1968, Warhol and Ultra Violet attended a party to celebrate the completion of the film \"Midnight Cowboy\". In the film, there is a party scene featuring members of the Factory that was filmed during Warhol's hospitalization.\nWarhol hosted a party at the Factory for Nico's album \"The Marble Index\" in September 1968. Warhol, Viva and Ultra Violet appeared on the cover of the November 10, 1968, issue of \"The New York Times Magazine\".\nIn 1969, Warhol and his entourage traveled to Los Angeles to discuss a prospective movie deal with Columbia Pictures. Warhol, who has always had an interest in photography, used a Polaroid camera to document his recuperation after the shooting. In 1969, some of his photographs were published in \"Esquire\" magazine. He would become well known for always carrying his Polaroid camera to chronicle his encounters. Eventually, he used instant photography as the basis for his silkscreen portraits when he resumed painting in the 1970s.\nIn late 1969, Warhol and British journalist John Wilcock founded \"Interview\" magazine. The magazine was initially published as \"inter/VIEW: A Monthly Film Journal\". It was revamped a few years later and came to represent Warhol's social life and fascination with celebrity.\n1970s.\nCompared to the success and scandal of Warhol's work in the 1960s, the early 1970s were much quieter years, as he became more entrepreneurial. He was generally regarded as quiet, shy and a meticulous observer. Art critic Robert Hughes called him \"the white mole of Union Square\". His fashion evolved from what Warhol called his \"leather look\" to his \"Brook Brothers look,\" which included a Brooks Brothers shirt and tie, DeNoyer blazer, and Levi jeans.\nAs Warhol continued to forge into filmmaking, he had established himself as \"one of the most celebrated and well-known pop art figures to emerge from the sixties.\" The Pasadena Art Museum in Pasadena organized a major retrospective of his work in 1970, which traveled in the United States and abroad. In 1971, the exhibition was mounted at the Tate Gallery in London and the Whitney Museum of American Art in New York. The Whitney show distinctly featured Warhol's \"Cow Wallpaper\" (1966) as the backdrop for his paintings.\nIn May 1971, Warhol's first and only theater production, \"Andy Warhol's Pork\", opened at the La MaMa Experimental Theatre in New York. In August 1971, it was brought to the Roundhouse in London.\nIn late 1971, Warhol and his business partner Paul Morrissey purchased Eothen, an oceanfront estate in Montauk, New York on Long Island. They began renting the main house on the property in 1972. Lee Radziwill, Jackie Kennedy, The Rolling Stones, Elizabeth Taylor, Truman Capote, and Halston were among the estate's notable guests.\nWarhol is credited with both the cover concept and photography for The Rolling Stones' albums \"Sticky Fingers\" (1971). He received a Grammy nomination for Best Album Cover at the 14th Annual Grammy Awards in 1972.\nAlthough Warhol was considered to be apolitical, he participated in an exhibition with the poster \"Vote McGovern\" (1972) in effort to raise funds for George McGovern's 1972 presidential campaign.\nIn October 1972, Warhol's work was included in the inaugural show at the Art Museum of South Texas in Corpus Christi, Texas. \nAfter years of deteriorating health, Warhol's mother, Julia Warhola, died in Pittsburgh in November 1972. Although he covered the cost of her funeral, he chose not to attend or inform his friends of her death.\nWarhol and his longtime partner Jed Johnson got a dachshund, Archie Warhol, in November 1972. Warhol doted on Archie and took him everywhere: to the studio, parties, restaurants, and on trips to Europe. He created portraits of Johnson, Archie, and Amos\u2014a second dachshund they got a few years later.\nBetween 1972 and 1973, Warhol created a series of portraits of Chinese Communist leader Mao Zedong with funding from two New York galleries, Knoedler &amp; Co. and the Leo Castelli Gallery, as well as art collector Peter Brant. In February 1974, some of the Mao portraits were installed at the Mus\u00e9e Galliera in Paris.\nIn the early 1970s, Warhol began traveling to Europe more frequently and developed a fondness for Paris. By 1973, Warhol had an apartment that he shared with his business manager Fred Hughes on the Left Bank of Paris on Rue du Cherche-Midi. In 1974, Warhol and Johnson moved from his home on Lexington Avenue to a townhouse at 57 East 66th Street in Manhattan's Lenox Hill neighborhood.\nBy the mid-1970s, Warhol's public presence had increased significantly due to his attendance at parties. In 1974, he said, \"I try to go around so often so much and try to go to every party so that they'll be bored with me and stop writing about me.\"\nIn May 1975, Warhol attended President Gerald Ford's state dinner in honor of the Shah of Iran, Mohammad Reza Pahlavi, at the White House.\nIn 1975, Warhol published \"The Philosophy of Andy Warhol (From A to B &amp; Back Again).\" In September 1975, he went on an eight-city U.S. book tour, followed by stops in Italy, France, and England.\nIn 1976, Warhol and painter Jamie Wyeth were commissioned to paint each other's portraits by the Coe Kerr Gallery in Manhattan. In January 1977, Warhol traveled to Kuwait for the opening of his exhibition at the Dhaiat Abdulla Al Salem Gallery. In June 1977, Warhol was invited to a special reception honoring the \"Inaugural Artists\" who had contributed prints to the Jimmy Carter presidential campaign. In 1977, Warhol was commissioned by art collector Richard Weisman to create \"Athletes\", ten portraits consisting of the leading athletes of the day.\nThe opening of Studio 54 in 1977 ushered in a new era in New York City nightlife. Warhol would often socialize at Studio 54 and take note of the drug-fueled activities that his friends engaged in at parties. In 1977, Warhol began taking nude photographs of men in various poses and performing sexual acts\u2014referred to as \"landscapes\"\u2014for what became known as the \"Torsos\" and \"Sex Parts\" series. Most of the men were street hustlers and male prostitutes brought to the Factory by Halston's lover Victor Hugo. This caused tension in Warhol's relationship with Johnson who did not approve of his friendship with Hugo. \"When Studio 54 opened things changed with Andy. That was New York when it was at the height of its most decadent period, and I didn't take part. I never liked that scene, I was never comfortable. ... Andy was just wasting his time, and it was really upsetting. ... He just spent his time with the most ridiculous people,\" said Johnson.\nIn 1979, Warhol formed a publishing company, Andy Warhol Books, and released the book \"Exposures\", which contained his photographs of famous friends and acquaintances. In November 1979, he embarked on a three-week book tour in the US.\nAccording to former \"Interview\" editor Bob Colacello, Warhol devoted much of his time to rounding up new, rich patrons for portrait commissions\u2014including Shah of Iran Mohammad Reza Pahlavi, his wife Empress Farah Pahlavi, his sister Princess Ashraf Pahlavi, Mick Jagger, Liza Minnelli, John Lennon, Diana Ross and Brigitte Bardot. In November 1979, the Whitney Museum of American Art mounted the exhibition \"Andy Warhol: Portraits of the '70s\" to celebrate the \"very commercial celebrity of the '70s, the decade of \"People\" magazine and designer jeans.\" Some critics disliked his exhibits of portraits of personalities and celebrities, calling them superficial, facile and commercial, with no depth or indication of the significance of the subjects.\n1980s.\nWarhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the \"bull market\" of 1980s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and other so-called Neo-Expressionists, as well as members of the Transavantgarde movement in Europe, including Francesco Clemente and Enzo Cucchi. Warhol also earned street credibility and graffiti artist Fab Five Freddy paid homage to him by painting an entire train with Campbell soup cans.His 1980 exhibition \"Ten Portraits of Jews of the Twentieth Century\" at the Jewish Museum in Manhattan was panned by critics. Warhol\u2014who was uninterested in Judaism and Jews\u2014had described in his diary as \"They're going to sell.\"\nThe New York Academy of Art was founded in part by Warhol. First established in 1980, the institute's mission was to \"revive traditional methods of training artists.\" According to Stuart Pivar, a fellow co-founder and art collector, \"What happened was that Modernism got boring [for Warhol] ... But his overall game plan, what he really believed, was that the modern age was going away and that we were entering a neoclassical period.\"\nIn 1981, Warhol worked on a project with Peter Sellars and Lewis Allen that would create a traveling stage show called, \"A No Man Show\", with a life-sized animatronic robot in the exact image of Warhol. The \"Andy Warhol Robot\" would then be able to read Warhol's diaries as a theatrical production. Warhol was quoted as saying, \"I'd like to be a machine, wouldn't you?\"\nWarhol also had an appreciation for intense Hollywood glamour. He once said: \"I love Los Angeles. I love Hollywood. They're so beautiful. Everything's plastic, but I love plastic. I want to be plastic.\" Warhol occasionally walked the fashion runways and did product endorsements, represented by Zoli Agency and later Ford Models.\nIn 1983, Warhol created a series of endangered species silkscreen prints for his exhibition \"Warhol's Animals: Species at Risk\" at the American Museum of Natural History in New York. He donated 10 of the 150 sets he made to wildlife organizations \"so they could sell them to raise money.\"\nBefore the 1984 Sarajevo Winter Olympics, he teamed with 15 other artists, including David Hockney and Cy Twombly, and contributed a Speed Skater print to the Art and Sport collection. The Speed Skater was used for the official Sarajevo Winter Olympics poster.\nIn 1984, \"Vanity Fair\" commissioned Warhol to produce a portrait of Prince, to accompany an article that celebrated the success of \"Purple Rain\" and its accompanying movie. Referencing the many celebrity portraits produced by Warhol across his career, \"Orange Prince (1984)\" was created using a similar composition to the Marilyn \"Flavors\" series from 1962, among some of Warhol's first celebrity portraits. Prince is depicted in a pop color palette commonly used by Warhol, in bright orange with highlights of bright green and blue. The facial features and hair are screen-printed in black over the orange background.\nIn September 1985, Warhol's joint exhibition with Basquiat, \"Paintings\", opened to negative reviews at the Tony Shafrazi Gallery. That month, despite apprehension from Warhol, his silkscreen series \"Reigning Queens\" was shown at the Leo Castelli Gallery. In the \"Andy Warhol Diaries\", Warhol noted: \"They were supposed to be only for Europe\u2014nobody here cares about royalty and it'll be another bad review.\"\nIn January 1987, Warhol traveled to Milan for the opening of his last exhibition, \"Last Supper\", at the Palazzo delle Stelline. The next month, Warhol modeled with jazz musician Miles Davis for Koshin Satoh's fashion show at the Tunnel in New York City on February 17, 1987.\nDeath.\nWarhol died at age 58 following gallbladder surgery at New York Hospital in Manhattan on February 22, 1987. Reportedly, he had been making a good recovery from the surgery before dying in his sleep at 6:32\u00a0a.m. from a sudden post-operative irregular heartbeat. Prior to his diagnosis and operation, Warhol delayed having his recurring gallbladder problems checked, as he was afraid to enter hospitals and see doctors.\nWarhol's brothers took his body back to Pittsburgh, where an open-casket wake was held at the Thomas P. Kunsak Funeral Home. The solid bronze casket had gold-plated rails and white upholstery. Warhol was dressed in a black cashmere suit, a paisley tie, a platinum wig, and sunglasses. He was laid out holding a small prayer book and a red rose. The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side on February 27, 1987. The eulogy was given by Monsignor Peter Tay. Yoko Ono and John Richardson were speakers. The casket was covered with white roses and asparagus ferns.\nAfter the liturgy, the casket was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh, where Warhol was buried near his parents. The priest said a brief prayer at the graveside and sprinkled holy water on the casket. Before the casket was lowered, Warhol's close friend and associate publisher of \"Interview\", Paige Powell, dropped a copy of the magazine and a bottle of Beautiful Eau de Parfum by Est\u00e9e Lauder into the grave. \nA memorial service was held in Manhattan for Warhol at St. Patrick's Cathedral in New York on April 1, 1987. It was attended by over 2,000 people, including numerous celebrities and Warhol collaborators such as Raquel Welch, Debbie Harry, Liza Minnelli, Yoko Ono, Claus von B\u00fclow, and Calvin Klein, among others.\nWrongful death lawsuit.\nIn December 1991, Warhol's family sued the hospital in the New York Supreme Court for inadequate care, before judge Ira Gammerman, saying that the arrhythmia was caused by improper care and water intoxication. The malpractice case was quickly settled out of court; Warhol's family received an undisclosed sum of money.\nPrior to his surgery, doctors expected Warhol to survive, though a re-evaluation of the case about thirty years after his death showed many indications that Warhol's surgery was in fact riskier than originally thought. It was widely reported at the time that Warhol had died of a \"routine\" surgery, though when considering factors such as his age, a family history of gallbladder problems, his previous gunshot wound, and his medical state in the weeks leading up to the procedure, the potential risk of death following the surgery appeared to have been significant.\nArt works.\nPaintings.\nBy the beginning of the 1960s, pop art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the \"Pope of Pop\", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Those drips emulated the style of successful abstract expressionists such as Willem de Kooning.\nFrom these beginnings, he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the handmade from the artistic process. Warhol was an early adopter of the silkscreen printmaking process as a technique for making paintings. His later drawings were traced from slide projections. Warhol had several assistants through the years, including Gerard Malanga, Ronnie Cutrone, and George Condo, who produced his silkscreen multiples, following his directions to make different versions and variations.\nWarhol's first pop art paintings were displayed in April 1961, serving as the backdrop for New York Department Store Bonwit Teller's window display. This was the same stage his Pop Art contemporaries Jasper Johns, James Rosenquist and Robert Rauschenberg had also once graced. It was the gallerist Muriel Latow who came up with the ideas for both the soup cans and Warhol's dollar paintings. On November 23, 1961, Warhol wrote Latow a check for $50 which, according to the 2009 Warhol biography, \"Pop, The Genius of Warhol\", was payment for coming up with the idea of the soup cans as subject matter. For his first major exhibition, Warhol painted his famous cans of Campbell's soup, which he claimed to have had for lunch for most of his life.\nIt was during the 1960s that Warhol began to make paintings of iconic American objects such as dollar bills, mushroom clouds, electric chairs, Campbell's soup cans, Coca-Cola bottles, celebrities such as Marilyn Monroe, Elvis Presley and Elizabeth Taylor, as well as newspaper headlines or photographs of police dogs attacking African-American protesters during the Birmingham campaign in the civil rights movement. His work became popular and controversial. Warhol had this to say about Coca-Cola: In 1962, Warhol created his famous \"Marilyn\" series. The Flavor Marilyns were selected from a group of fourteen canvases in the sub-series, each measuring 20\" x 16\". Some of the canvases were named after various candy Life Savers flavors, including \"Cherry Marilyn\", \"Lemon Marilyn\" and \"Licorice Marilyn\". The others are identified by their background colors.\nWarhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques\u2014silkscreens, reproduced serially, and often painted with bright colors\u2014whether he painted celebrities, everyday objects, or images of suicide, car crashes and disasters, as in the 1962\u201363 \"Death and Disaster\" series.\nIn the 1970s, Warhol evolved into a commercial artist, painting mostly commissioned portraits of celebrities. In 1979, Warhol was commissioned to paint a BMW M1 Group 4 racing version for the fourth installment of the BMW Art Car project. He was initially asked to paint a BMW 320i in 1978, but the car model was changed and it didn't qualify for the race that year. Warhol was the first artist to paint directly onto the automobile himself instead of letting technicians transfer a scale-model design to the car. Reportedly, it took him only 23 minutes to paint the entire car. Racecar drivers Herv\u00e9 Poulain, Manfred Winkelhock and Marcel Mignot drove the car at the 1979 24 Hours of Le Mans.\nSome of Warhol's work, as well as his own personality, has been described as being Keatonesque. Warhol has been described as playing dumb to the media. He sometimes refused to explain his work. He has suggested that all one needs to know about his work is \"already there 'on the surface.\nHis Rorschach inkblots are intended as pop comments on art and what art could be. His cow wallpaper (literally, wallpaper with a cow motif) and his oxidation paintings (canvases prepared with copper paint that was then oxidized with urine) are also noteworthy in this context. Equally noteworthy is the way these works\u2014and their means of production\u2014mirrored the atmosphere at Andy's New York \"Factory\". Former \"Interview\" editor Bob Colacello provides some details on Andy's \"piss paintings\":\nWarhol's 1982 portrait of Basquiat, \"Jean-Michel Basquiat\", is a silkscreen over an oxidized copper \"piss painting\". After many years of silkscreen, oxidation, photography, etc., Warhol returned to painting with a brush in hand. In 1983, Warhol began collaborating with Basquiat and Clemente. Warhol and Basquiat created a series of more than 50 large collaborative works between 1984 and 1985. Despite criticism when these were first shown, Warhol called some of them \"masterpieces\", and they were influential for his later work.\nIn 1984, Warhol was commissioned by collector and gallerist Alexander Iolas to produce work based on Leonardo da Vinci's \"The Last Supper\" for an exhibition at the old refectory of the Palazzo delle Stelline in Milan, opposite from the Santa Maria delle Grazie where Leonardo da Vinci's mural can be seen. Warhol exceeded the demands of the commission and produced nearly 100 variations on the theme, mostly silkscreens and paintings, and among them a collaborative sculpture with Basquiat, the \"Ten Punching Bags (Last Supper)\". The Milan exhibition that opened in January 1987 with a set of 22 silk-screens, was the last exhibition for both the artist and the gallerist. The series of \"The Last Supper\" was seen by some as \"arguably his greatest\", but by others as \"wishy-washy, religiose\" and \"spiritless\". It is the largest series of religious-themed works by any American artist.\nArtist Maurizio Cattelan describes that it is difficult to separate daily encounters from the art of Andy Warhol: \"That's probably the greatest thing about Warhol: the way he penetrated and summarized our world, to the point that distinguishing between him and our everyday life is basically impossible, and in any case useless.\" Warhol was an inspiration towards Cattelan's magazine and photography compilations, such as \"Permanent Food, Charley\", and \"Toilet Paper\".\nIn the period just before his death, Warhol was working on \"Cars\", a series of paintings for Mercedes-Benz.\nDrawings.\nAccording to a 2023 \"Artnet\" article\",\" \"Though he is often associated with printmaking\u2014specifically silkscreen\u2014Warhol was also an incredibly talented illustrator and draughtsman, and drawing was an integral part of his practice throughout his career. His early drawings on paper bare a resemblance to both continuous line and blind contour drawing techniques, giving his work a sense of ease and immediacy. While working primarily within commercial advertisement, he pioneered the blotted line technique, which synthesized graphite drawing on paper with elements of printmaking. Warhol continued his practice of drawing through the last years of his life and career, and the work from this later period exemplifies a long and storied career's worth of honed skill and technique.\"\nArt market.\nIn 1970, screens and film matrixes that had been used to produce original Warhol works in the 1960s were taken to Europe for the production of Warhol screenprints under the name \"Sunday B Morning\". Warhol signed and numbered one edition of 250 before subsequent unauthorized unsigned versions were produced. The unauthorized works were the result of a falling out between Warhol and some of his New York City studio employees who went to Brussels where they produced work stamped with \"Sunday B Morning\" and \"Add Your Own Signature Here\". Since the works began as a collaboration, Warhol facilitated exact duplication by providing the photo negatives and precise color codes. Some of the unauthorized productions bore the markings \"This is not by me, Andy Warhol\". The most famous unauthorized reproductions are 1967 Marilyn Monroe portfolio screenprints. These \"Sunday B Morning\" Marilyn Monroe prints were among those still under production as of 2013. Art galleries and dealers also market Sunday B Morning reprint versions of several other screenprint works including \"Flowers\", \"Campbell's Soup I\", \"Campbell's Soup Cans II\",\"Gold Marilyn Monroe\" Mao and Dollare bill prints. Although the original Sunday B Morning versions had black stamps on the back, by the 1980s, they switched to blue.\nIn 1970, Warhol's painting \"Campbell's Soup Can With Peeling Label\" (1962) sold for $60,000 at an auction by Parke-Bernet Galleries. At the time it was the high price ever paid at a public auction for a work by a living American artist.\nIn the 1970s, the price of a commissioned portrait by Warhol was $25,000, two for $40,000. The value of Andy Warhol's work has been on an endless upward trajectory since his death in 1987. In 2014, his works accumulated $569\u00a0million at auction, which accounted for more than a sixth of the global art market. However, there have been some dips. According to art dealer Dominique L\u00e9vy: \"The Warhol trade moves something like a seesaw being pulled uphill: it rises and falls, but each new high and low is above the last one.\" She attributes this to the consistent influx of new collectors intrigued by Warhol. \"At different moments, you've had different groups of collectors entering the Warhol market, and that resulted in peaks in demand, then satisfaction and a slow down,\" before the process repeats another demographic or the next generation.\nIn 1998, \"Orange Marilyn\" (1964), a depiction of Marilyn Monroe, sold for $17.3\u00a0million, which at the time set a new record as the highest price paid for a Warhol artwork. In 2007, one of Warhol's 1963 paintings of Elizabeth Taylor, \"Liz (Colored Liz)\", which was owned by actor Hugh Grant, sold for $23.7\u00a0million at Christie's.\nIn 2007, Stefan Edlis and Gael Neeson sold Warhol's \"Turquoise Marilyn\" (1964) to financier Steven A. Cohen for $80\u00a0million. In May 2007, \"Green Car Crash\" (1963) sold for $71.1\u00a0million and \"Lemon Marilyn\" (1962) sold for $28\u00a0million at Christie's post-war and contemporary art auction. In 2007, \"Large Campbell's Soup Can\" (1964) was sold at a Sotheby's auction to a South American collector for 7.4\u00a0million. In November 2009, \"200 One Dollar Bills\" (1962) at Sotheby's for $43.8\u00a0million.\nIn 2008, \"Eight Elvises\" (1963) was sold by Annibale Berlingieri for $100\u00a0million to a private buyer. The work depicts Elvis Presley in a gunslinger pose. It was first exhibited in 1963 at the Ferus Gallery in Los Angeles. Warhol made 22 versions of the \"Elvis\" portraits, eleven of which are held in museums. In May 2012, \"Double Elvis (Ferus Type)\" sold at auction at Sotheby's for $37\u00a0million. In November 2014, \"Triple Elvis (Ferus Type)\" sold for $81.9 million at Christie's.\nIn May 2010, a purple self-portrait of Warhol from 1986 that was owned by fashion designer Tom Ford sold for $32.6\u00a0million at Sotheby's. In November 2010, \"Men in Her Life\" (1962), based on Elizabeth Taylor, sold for $63.4\u00a0million at Phillips de Pury and \"Coca-Cola (4)\" (1962) sold for $35.3\u00a0million at Sotheby's. In May 2011, Warhol's first self-portrait from 1963 to 1964 sold for $38.4\u00a0million and a red self-portrait from 1986 sold for $27.5\u00a0million at Christie's. In May 2011, \"Liz No. 5 (Early Colored Liz)\" sold for $26.9\u00a0million at Phillips.\nIn November 2013, Warhol's rarely seen 1963 diptych, \"Silver Car Crash (Double Disaster)\", sold at Sotheby's for $105.4\u00a0million, a new record for the artist. In November 2013, \"Coca-Cola (3)\" (1962) sold for $57.3\u00a0million at Christie's. In May 2014, \"White Marilyn\" (1962) sold for $41\u00a0million at Christie's. In November 2014, \"Four Marlons\" (1964), which depicts Marlon Brando, sold for $69.6\u00a0million at Christie's. In May 2015, \"Silver Liz (diptych)\", painted in 1963, sold for $28\u00a0million and \"Colored Mona Lisa\" (1963) sold for $56.2\u00a0million at Christie's. In May 2017, Warhol's 1962 painting \"Big Campbell's Soup Can With Can Opener (Vegetable)\" sold for $27.5\u00a0million at Christie's. In 2017, billionaire hedge-fund manager Ken Griffin purchased \"Orange Marilyn\" privately for around $200\u00a0million. In March 2022, \"Silver Liz (Ferus Type)\" sold for 2.3\u00a0billion yen ($18.9\u00a0million) at Shinwa Auction, which set a new record for the highest bid ever at auction in Japan. In May 2022, \"Shot Sage Blue Marilyn\" (1964) sold for $195\u00a0million at Christie's, becoming the most expensive American artwork sold at auction.\nCollectors.\nAmong Warhol's early collectors and influential supporters were Emily and Burton Tremaine. Among the over 15 artworks purchased, \"Marilyn Diptych\" (now at Tate Modern, London) and \"A boy for Meg\" (now at the National Gallery of Art in Washington, DC), were purchased directly out of Warhol's studio in 1962. One Christmas, Warhol left a small \"Head of Marilyn Monroe\" by the Tremaine's door at their New York apartment in gratitude for their support and encouragement.\nWorks.\nWarhol was a fan of \"Business Art\", as he stated in his book \"The Philosophy of Andy Warhol from A to B and Back Again\". \"I went into business art. I wanted to be an art business man or a business artist. Being good in business is the most fascinating kind of art,\" he said. His transformation into a mere business artist was a point of criticism. In hindsight, however, some critics have come to view Warhol's superficiality and commerciality as \"the most brilliant mirror of our times\", contending that \"Warhol had captured something irresistible about the zeitgeist of American culture in the 1970s.\"\nIn addition to his paintings and drawings, Warhol directed and produced films, managed the Velvet Underground, and authored numerous books, as well as producing works in such diverse media as audio, photography, sculpture, theater, fashion and performance art. His ability to blur the lines between art, commerce, and everyday life was central to his creative philosophy.\nFilmography.\nWarhol attended the 1962 premiere of the static composition by La Monte Young called \"Trio for Strings\" and subsequently created his famous series of static films. Filmmaker Jonas Mekas, who accompanied Warhol to the premiere, claims Warhol's static films were directly inspired by that performance. Between 1963 and 1968, Warhol made more than 600 underground films, including short black-and-white \"screen test\" portraits of Factory visitors. Many of his films premiered at the New Andy Warhol Garrick Theatre in Greenwich Village and 55th Street Playhouse in Midtown Manhattan.\nHis early experimental films were silent observations of very typical daily life. \"Sleep\" (1964) monitors poet John Giorno sleeping for six hours. \"Kiss\" (1964) shows couples kissing. The film \"Eat\" (1964) consists of an artist Robert Indiana eating a mushroom for 45 minutes. The 35-minute film \"Blow Job\" (1964) is one continuous shot of the face of DeVeren Bookwalter supposedly receiving oral sex from poet Willard Maas, although the camera never tilts down to see this.\nFor these efforts, Mekas presented Warhol with the Independent Film Award of 1964, \"the underground's answer to Oscar.\" \"Newsday\"'s Mike McGrady hailed Warhol as \"the Cecil B. DeMille of the Off-Hollywood movie makers.\"\n\"Batman Dracula\" is a 1964 film that was produced and directed by Warhol, without the permission of DC Comics. It was screened only at his art exhibits. A fan of the \"Batman\" series, Warhol's movie was an \"homage\" and is considered the first appearance of a blatantly campy Batman. The film was until recently thought to have been lost, until scenes from the picture were shown at some length in the 2006 documentary \"Jack Smith and the Destruction of Atlantis\".\nWarhol's 1965 film \"Empire\" is an eight-hour view of the Empire State Building, and shortly after he released \"Vinyl\" (1965), an adaptation of Anthony Burgess' popular dystopian novel \"A Clockwork Orange\". Other films record improvised encounters between Factory regulars such as Brigid Berlin, Viva, Edie Sedgwick, Candy Darling, Holly Woodlawn, Ondine, Nico and Jackie Curtis. The underground artist Jack Smith appears in the film \"Camp\".\nWarhol's most popular and critically successful film was \"Chelsea Girls\" (1966). It was the first underground film of the 1960s to reach widespread popularity and capture the attention of notable film critics. The film was highly innovative in that it consisted of two 16 mm-films being projected simultaneously, with two different stories being shown in tandem. From the projection booth, the sound would be raised for one film to elucidate that \"story\" while it was lowered for the other. The multiplication of images evoked Warhol's seminal silkscreen works of the early 1960s.\nThe 1969 film \"Blue Movie\"\u2014in which Warhol superstars Viva and Louis Waldon make love in bed\u2014was Warhol's last film as director. It is a seminal film in the Golden Age of Porn, and at the time it was controversial for its frank approach to a sexual encounter. \"Blue Movie\" was publicly screened in New York City in 2005, for the first time in more than 30 years.\nIn the wake of the 1968 shooting, Warhol's assistant director, Paul Morrissey, took over most of the film-making chores for the Factory collective, steering Warhol-branded cinema towards more mainstream, narrative-based, B-movie exploitation fare with \"Flesh\" (1968), \"Trash\" (1970) and \"Heat\" (1972). All of these films, including the later \"Andy Warhol's Dracula\" (1973) and \"Andy Warhol's Frankenstein\" (1974), were far more mainstream than anything Warhol as a director had attempted. Joe Dallesandro starred in these latter films, which are now considered cult classics. The last Warhol-produced film, \"Bad,\" starred Carroll Baker and was made without either Morrissey or Dallesandro. It was directed by Warhol's boyfriend Jed Johnson, who had assisted Morrissey on several films.\nMost of the films directed by Warhol were pulled out of circulation by Warhol and the people around him who ran his business. With assistance from Warhol in 1984, the Whitney Museum and the Museum of Modern Art began to restore his films, which are occasionally shown at museums and film festivals. In 2022, the Andy Warhol Museum announced the launch of The Warhol TV, a streaming platform that allows users to watch free museum content and to rent a selection of Warhol's films from its collection.\nMusic.\nIn 1965, Warhol adopted the band the Velvet Underground, making them a crucial element of the \"Exploding Plastic Inevitable\" multimedia performance art show. Warhol, with Paul Morrissey, acted as the band's manager, introducing them to Nico (who would perform with the band at Warhol's request). While managing The Velvet Underground, Andy would have them dressed in all black to perform in front of movies that he was also presenting. In 1966, he \"produced\" their first album \"The Velvet Underground &amp; Nico\", as well as providing its album art. His actual participation in the album's production amounted to simply paying for the studio time.\nAfter the band's first album, Warhol and band leader Lou Reed started to disagree more about the direction the band should take, and Warhol was fired in 1967. In 1989, Reed and John Cale reunited for the first time since 1972 to write, perform, record and release the concept album \"Songs for Drella\", as a tribute to Warhol. In October 2019, an audio tape of publicly unknown music by Reed, based on Warhol's 1975 book, \"The Philosophy of Andy Warhol: From A to B and Back Again\", was reported to have been discovered in an archive at the Andy Warhol Museum in Pittsburgh.\nWarhol designed many album covers for various artists beginning during his days as an illustrator in the 1950s. The album covers he designed include for \"I'm Still Swinging\" (1955) by The Joe Newman Octet, \"Blue Lights, Vols. 1 &amp; 2\" (1958) by Kenny Burrell, \"This Is John Wallowitch!!!\" (1964) by John Wallowitch, \"Sticky Fingers\" (1971) and \"Love You Live\" (1977) by The Rolling Stones, \"The Academy in Peril\" (1972) by John Cale, \"Silk Electric\" (1982) by Diana Ross, and \"Aretha\" (1986) by Aretha Franklin.\nIn 1984, Warhol co-directed the music video \"Hello Again\" by the Cars, and he appeared in the video as a bartender. In 1986, Warhol co-directed the music video \"Misfit\" by Curiosity Killed the Cat and he made a cameo in video.\nBooks and print.\nBeginning in the early 1950s, Warhol produced several unbound portfolios of his work. The first of several bound self-published books by Warhol was \"25 Cats Name Sam and One Blue Pussy\", printed in 1954 by Seymour Berlin on Arches brand watermarked paper using his blotted line technique for the lithographs. The original edition was limited to 190 numbered, hand-colored copies, using Dr. Martin's ink washes. Most of these were given by Warhol as gifts to clients and friends. Copy No. 4, inscribed \"Jerry\" on the front cover and given to Geraldine Stutz, was used for a facsimile printing in 1987, and the original was auctioned in May 2006 for US$35,000 by Doyle New York.\nOther self-published books by Warhol include:\nWarhol's book \"A La Recherche du Shoe Perdu\" (1955) marked his \"transition from commercial to gallery artist\". (The title is a play on words by Warhol on the title of French author Marcel Proust's \"\u00c0 la recherche du temps perdu\".)\nAfter gaining fame, Warhol \"wrote\" several books that were commercially published:\nWarhol created the fashion magazine \"Interview\" that is still published. The loopy title script on the cover is thought to be either his own handwriting or that of his mother, Julia Warhola, who would often do text work for his early commercial pieces.\nWarhol created covers for a number of magazines, including \"Time\" and \"Vogue\".\nOther media.\nAlthough Andy Warhol is most known for his paintings and films, he authored works in many different media.\nPersonal life.\nSexuality.\nWarhol lived as a gay man before the gay liberation movement, but he often veiled his personal life in the press. In 1980, Warhol proclaimed that he was still a virgin. Former \"Interview\" editor Bob Colacello felt it was probably true and that what little sex he had was probably \"a mixture of voyeurism and masturbation\u2014to use [Andy's] word \"abstract.\"\" However, Warhol's assertion of virginity is contradicted by his hospital treatment in 1960 for condylomata, a sexually transmitted disease. His friend Charles Lisanby, whom Warhol had unrequited romantic feelings for, said Warhol told him sex was \"messy and distasteful.\" \"He told me he'd had sex a few times, he had tried it and didn't really like it,\" said Lisanby. Furthermore, some of Warhol's friends from his early career claimed to have either witnessed Warhol having sex or heard him boasting about his sexual relations.\nDue to Warhol's own admission that he was asexual, it has been assumed that all his relationships were platonic. Warhol superstar Jay Johnson, whose twin brother was Warhol's longtime partner, stated, \"He enjoyed the idea that he was considered a voyeur and that he was considered asexual. That was his mystique.\" The Factory photographer Billy Name was briefly Warhol's lover. He said Warhol was \"the essence of sexuality. It permeated everything. Andy exuded it, along with his great artistic creativity ... It brought a joy to the whole art world in New York.\" \"But his personality was so vulnerable that it became a defense to put up the blank front,\" said Name. Warhol's other lovers included aspiring filmmaker and artist John Giorno. Paramount Pictures executive Jon Gould was one of his last companions. His longest-lasting relationship was with Jed Johnson, who nursed him back to health after he was shot, collaborated with him on films, and went on to achieve fame as an interior designer. Warhol and Johnson \"functioned as husband and husband, sharing a bed and a domestic life\" for 12 years.\nThe impact of Warhol's homosexuality on his work and connection with the art industry has been extensively studied. Throughout his career, Warhol produced erotic photography and drawings of male nudes. Many of his most famous works\u2014portraits of Liza Minnelli, Judy Garland, and Elizabeth Taylor and films such as \"Blow Job\", \"My Hustler\" and \"Lonesome Cowboys\"\u2014draw from gay underground culture or openly explore the complexity of sexuality and desire. As has been addressed by a range of scholars, many of his films premiered in gay porn theaters, including the New Andy Warhol Garrick Theatre and 55th Street Playhouse, in the 1960s.\nThe first works that Warhol submitted to a fine art gallery, homoerotic drawings of male nudes, were rejected for being too openly gay. In \"Popism\", furthermore, the artist recalls a conversation with the filmmaker Emile de Antonio about the difficulty Warhol had being accepted socially by the then-more-famous (but closeted) gay artists Jasper Johns and Robert Rauschenberg. De Antonio explained that Warhol was \"too swish and that upsets them\". In response to this, Warhol writes, \"There was nothing I could say to that. It was all too true. So I decided I just wasn't going to care, because those were all the things that I didn't want to change anyway, that I didn't think I 'should' want to change\u00a0... Other people could change their attitudes but not me\". In exploring Warhol's biography, many turn to this period\u2014the late 1950s and early 1960s\u2014as a key moment in the development of his persona.\nSome have suggested that his frequent refusal to comment on his work, to speak about himself (confining himself in interviews to responses like \"Um, no\" and \"Um, yes\", and often allowing others to speak for him)\u2014and even the evolution of his pop style\u2014can be traced to the years when Warhol was first dismissed by the inner circles of the New York art world.\nReligion.\nWarhol was a practicing Ruthenian Catholic. He regularly volunteered at homeless shelters in New York City, particularly during the busier times of the year, and described himself as a religious person. Many of Warhol's later works depicted religious subjects, including two series, \"Details of Renaissance Paintings\" (1984) and \"The Last Supper\" (1986). In addition, a body of religious-themed works was found posthumously in his estate.\nWarhol regularly attended Mass, and the priest at Warhol's church, Saint Vincent Ferrer, said that the artist went there almost daily, although he was not observed taking Communion or going to Confession and sat or knelt in the pews at the back. The priest thought he was afraid of being recognized; Warhol said he was self-conscious about being seen in a Latin Catholic church crossing himself \"in the Orthodox way\" (right to left instead of the reverse).\nWarhol's art is noticeably influenced by the Eastern Christian tradition which was so evident in his places of worship. Warhol's brother has described the artist as \"really religious, but he didn't want people to know about that because [it was] private\". Despite the private nature of his faith, in Warhol's eulogy John Richardson depicted it as devout: \"To my certain knowledge, he was responsible for at least one conversion. He took considerable pride in financing his nephew's studies for the priesthood\".\nFrom November 2021 to June 2022, the Brooklyn Museum displayed the \"Andy Warhol: Revelation\" exhibition. The exhibition delved at the artist's enduring connection to his faith, which was often reflected in his artwork.\nCollections.\nWarhol was an avid collector. His friends referred to his numerous collections, which filled not only his four-story townhouse, but also a nearby storage unit, as \"Andy's Stuff\". The true extent of his collections was not discovered until after his death, when The Andy Warhol Museum in Pittsburgh took in 641 boxes of his \"Stuff\".\nWarhol's collections included a Coca-Cola memorabilia sign, and 19th century paintings along with airplane menus, unpaid invoices, pizza dough, pornographic pulp novels, newspapers, stamps, supermarket flyers and cookie jars, among other eccentricities. It also included significant works of art, such as George Bellows's \"Miss Bentham\". One of his main collections was his wigs. Warhol owned more than 40 and felt very protective of his hairpieces, which were sewn by a New York wig-maker from hair imported from Italy. In 1985, a girl snatched Warhol's wig off his head. It was later discovered in Warhol's diary entry for that day that he wrote: \"I don't know what held me back from pushing her over the balcony.\"\nIn 1960, he had bought a drawing of a light bulb by Jasper Johns. Another item found in Warhol's boxes at the museum in Pittsburgh was a mummified human foot from Ancient Egypt. The curator of anthropology at Carnegie Museum of Natural History felt that Warhol most likely found it at a flea market.\nWarhol collected many books, with more than 1,200 titles in his collection. Of these, 139 titles have been publicly identified through a 1988 Sotheby's Auction catalog, \"The Andy Warhol Collection\" and can be viewed online. His book collection reflects his eclectic taste and interests, and includes books written by and about some of his acquaintances and friends. Some of the titles in his collection include \"The Two Mrs. Grenvilles: A Novel\" by Dominick Dunne, \"Artists in Uniform\" by Max Eastman, \"Andrews' Diseases of the Skin: Clinical Dermatology\" by George Clinton Andrews, \"D.V.\" by Diana Vreeland, \"Blood of a Poet\" by Jean Cocteau, \"Watercolours\" by Francesco Clemente, \"Little World, Hello!\" by Jimmy Savo, \"Hidden Faces\" by Salvador Dal\u00ed and \"The Dinah Shore Cookbook\".\nLegacy.\nIn 1991, the Warhol Family Museum of Modern Art was established in Medzilaborce, Slovakia by Warhol's family and the Slovak Ministry of Culture. In 1996, it was renamed the Andy Warhol Museum of Modern Art.\nIn 1992, Warhol's estate donated 15-acres of land on his former property Eothen to The Nature Conservancy. Now called The Andy Warhol Preserve, it is part of a 2,400-acre protected area in Montauk.\nIn 1994, the Andy Warhol Museum opened in Pittsburgh. It holds the largest collection of the artist's works in the world.\nIn 1998, Warhol's Upper East Side townhouse at 57 E 66th Street in Manhattan was designated a cultural landmark by the Historical Landmarks Preservation Center to commemorate the 70th anniversary of his birthday.\nIn 2002, the US Postal Service issued an 18-cent stamp commemorating Warhol. Designed by Richard Sheaff of Scottsdale, Arizona, the stamp was unveiled at a ceremony at The Andy Warhol Museum and features Warhol's painting \"Self-Portrait, 1964\". In March 2011, a chrome statue of Andy Warhol and his Polaroid camera was revealed at Union Square in New York City.\nA crater on Mercury was named after Warhol in 2012.\nIn 2013, to honor the 85th anniversary of Warhol's birthday, The Andy Warhol Museum and EarthCam launched a collaborative project titled \"Figment\", a live feed of Warhol's gravesite.\nWarhol Foundation.\nWarhol's will dictated that his entire estate\u2014with the exception of a few modest legacies to family members\u2014would go to create a foundation dedicated to the \"advancement of the visual arts\". Warhol had so many possessions that it took Sotheby's nine days to auction his estate after his death; the auction grossed more than $20\u00a0million.\nIn 1987, in accordance with Warhol's will, the Andy Warhol Foundation for the Visual Arts was formed. The foundation serves as the estate of Andy Warhol, but also has a mission \"to foster innovative artistic expression and the creative process\" and is \"focused primarily on supporting work of a challenging and often experimental nature\".\nThe Artists Rights Society is the US copyright representative for the Andy Warhol Foundation for the Visual Arts for all Warhol works with the exception of Warhol film stills. The US copyright representative for Warhol film stills is the Warhol Museum in Pittsburgh. Additionally, the Andy Warhol Foundation for the Visual Arts has agreements in place for its image archive. All digital images of Warhol are exclusively managed by Corbis, while all transparency images of Warhol are managed by Art Resource.\nThe Andy Warhol Foundation released its \"20th Anniversary Annual Report\" as a three-volume set in 2007: Vol. I, 1987\u20132007; Vol. II, Grants &amp; Exhibitions; and Vol. III, Legacy Program.\nThe Foundation is in the process of compiling its catalogue raisonn\u00e9 of paintings and sculptures in volumes covering blocks of years of the artist's career. Volumes IV and V were released in 2019. The subsequent volumes are still in the process of being compiled.\nThe Foundation remains one of the largest grant-giving organizations for the visual arts in the US.\nMany of Warhol's works and possessions are on display at the Andy Warhol Museum in Pittsburgh. The foundation donated more than 3,000 works of art to the museum.\nIn pop culture.\nWarhol founded \"Interview\", a stage for celebrities he \"endorsed\" and a business staffed by his friends. One might even say that he produced people (as in the Warholian \"Superstar\" and the Warholian portrait). Warhol endorsed products, appeared in commercials, and made frequent celebrity guest appearances on television shows and films.\nFilms.\nWarhol appeared in the films \"Dynamite Chicken\" (1971), \"The Driver's Seat\" (1974), \"Cocaine Cowboys\" (1979) and \"Tootsie\" (1982).\nAfter his death, Warhol was portrayed by Crispin Glover in Oliver Stone's film \"The Doors\" (1991), by Jared Harris in Mary Harron's film \"I Shot Andy Warhol\" (1996), and by David Bowie in Julian Schnabel's film \"Basquiat\" (1996). Bowie recalled how meeting Warhol in real life helped him in the role, and recounted his early meetings with him:\nWarhol appeared as a character in Michael Daugherty's opera \"Jackie O\" (1997). Actor Mark Bringleson makes a brief cameo as Warhol in ' (1997). Many films by avant-garde cineast Jonas Mekas have caught the moments of Warhol's life. Sean Gregory Sullivan depicted Warhol in the film \"54\" (1998). Guy Pearce portrayed Warhol in the film \"Factory Girl\" (2007) about Edie Sedgwick's life. Actor Greg Travis portrays Warhol in a brief scene from the film \"Watchmen\" (2009). Comedian Conan O'Brien portrayed Warhol in the film ' (2022).\nIn the movie \"Highway to Hell\" a group of Andy Warhols are part of the \"Good Intentions Paving Company\" where good-intentioned souls are ground into pavement. In the film \"Men in Black 3\" (2012) Andy Warhol turns out to really be undercover MIB Agent W (played by Bill Hader). Warhol is throwing a party at The Factory in 1969, where he is encountered by MIB Agents K and J.\nAndy Warhol (portrayed by Tom Meeten) is one of main characters of the 2012 British television show \"Noel Fielding's Luxury Comedy\". The character is portrayed as having robot-like mannerisms. In the 2017 feature \"The Billionaire Boys Club\", Cary Elwes portrays Warhol in a film based on the true story about Ron Levin (portrayed by Kevin Spacey) a friend of Warhol's who was murdered in 1986. In September 2016, it was announced that Jared Leto would portray the title character in \"Warhol\", an upcoming American biographical drama film produced by Michael De Luca and written by Terence Winter, based on the book \"Warhol: The Biography\" by Victor Bockris.\nTelevision.\nIn 1965, Warhol and his muse Edie Sedgwick appeared on \"The Merv Griffin Show\". Warhol doesn't say much save for bashful gestures and whispering \"yes\" or \"no,\" while Sedgwick mediates a conversation on how Pop Art is art without any sense of emotion.\nIn 1969, Warhol was commissioned by Braniff International to appear in two television commercials to promote the luxury airline's \"When You Got It \u2013 Flaunt It\" campaign. The campaign was created by the advertising agency Lois Holland Calloway, which was led by George Lois, creator of a famed series of \"Esquire\" covers. The first commercial series involved the unlikely paring of Warhol and heavyweight boxing champion Sonny Liston who shared the fact that they both flew Braniff Airways. The odd commercial worked and Warhol was featured in another commercial entering a Braniff jet and being greeted by a Braniff hostess, while espousing their like for flying Braniff. The rights to Warhol's films for Braniff and his signed contracts are owned by a private trust and are administered by Braniff Airways Foundation in Dallas, Texas.\nWarhol appeared on the BBC series Arena in a scene with writers William S. Burroughs and Victor Bockris in an episode that aired in January 1981. Warhol filmed a segment for the sketch comedy television show \"Saturday Night Live\", which aired in October 1981. In a 1981 Sony Beta Tapes advertisement, Warhol featured beside a Marilyn image to showcase the tapes' capacity to record \"brilliant color and delicate shading.\" In 1983, he appeared in a commercial for TDK Videotape.\nIn 1985, Warhol appeared in a Diet Coke commercial. He also had a guest appearance on the 200th episode of the television series \"The Love Boat\" wherein a Midwestern wife (Marion Ross) fears Andy Warhol will reveal to her husband (Tom Bosley) her secret past as a Warhol superstar named Marina del Rey.\nIn 1986, Warhol appeared in an ad for the Drexel Burnham Lambert investment group.\nWarhol appeared as a recurring character in TV series \"Vinyl\", played by John Cameron Mitchell. Warhol was portrayed by Evan Peters in the \" episode \". The episode depicts the attempted assassination of Warhol by Valerie Solanas (Lena Dunham).\nMusic.\nWarhol strongly influenced the new wave/punk rock band Devo, as well as David Bowie. Bowie recorded a song called \"Andy Warhol\" for his 1971 album \"Hunky Dory\". Lou Reed wrote the song \"Andy's Chest\" in response to the attempted assassination of Warhol. The song was originally recorded by the Velvet Underground in 1969, but it wasn't released until a version appeared on Reed's solo album \"Transformer\" in 1972. The band Triumph also wrote a song about Andy Warhol, \"Stranger In A Strange Land\" off their 1984 album \"Thunder Seven\".\nBooks.\nMany books have been written about Warhol. In 1989, the biography \"The Life and Death of Andy Warhol\" by author Victor Bockris was published. Bockris expanded the book in 2003 for the 75th anniversary of Warhol's birth and called it \"Warhol: The Biography\". Former Interview editor Bob Colacello wrote the book \"Holy Terror: Andy Warhol Close Up\", which was published in 1990. A biography written by art critic Blake Gopnik was published in 2020 under the title \"Warhol\".\nComic books.\nWarhol is featured as a character in the \"Miracleman\" series of comics. It is first mentioned that he was resurrected by the alien scientist Mors and subsequently convinces the latter to mass-produce copies of himself. Later on, 18 copies of Warhol are seen in the underworld beneath the pyramid structure Olympus, where they produce pop art relating to the new superhuman regime. One Warhol clone numbered 6 is assigned to and develop a friendship with a clone of Emil Gargunza (Miracleman's creator) before the latter's betrayal and attempted escape.\nVideo games.\nWarhol makes an appearance in the 2003 video game \"\" as the photographer in Studio Town. Warhol (played by Jeff Grace) makes a cameo appearance in the 2022 video game \"Immortality\"."}
{"id": "868", "revid": "42788136", "url": "https://en.wikipedia.org/wiki?curid=868", "title": "Alp Arslan", "text": "Alp Arslan, born Muhammad Alp Arslan bin Dawud Chaghri, was the second sultan of the Seljuk Empire and great-grandson of Seljuk, the eponymous founder of the dynasty. He greatly expanded the Seljuk territory and consolidated his power, defeating rivals to the south, east and northwest, and his victory over the Byzantines at the Battle of Manzikert, in 1071, ushered in the Turcoman settlement of Anatolia.\nEarly life.\nHistorical sources differ about his actual birth date. His birth year, which some early sources of medieval period mentioned 1032 and 1033 while later sources gave 1030. However, the most authentic considered as \"TDV Encyclopedia of Islam\" mentions, is that recorded by Ibn al-Athir, a medieval historian, as 1 Muharram 420 AH equivalent to 20 January 1029 CE. He was the son of Chaghri and nephew of Tughril, the founding sultans of the Seljuk Empire. His grandfather was Mikail, who in turn was the son of the warlord Seljuk. He was the father of numerous children, including Malik-Shah I and Tutush I. It is unclear who the mother or mothers of his children were. He was known to have been married at least twice. His wives included the widow of his uncle Tughril, a Kara-Khanid princess known as Aka or Seferiye Khatun, and the daughter or niece of Bagrat IV of Georgia (who would later marry his vizier, Nizam al-Mulk). One of Seljuk's other sons was the Turkic chieftain Arslan Isra'il, whose son, Kutalmish, contested his nephew's succession to the sultanate. Alp Arslan's younger brothers Suleiman ibn Chaghri and Qavurt were his rivals. Kilij Arslan, the son and successor of Suleiman ibn Kutalmish (Kutalmish's son, who would later become Sultan of R\u00fbm), was a major opponent of the Franks during the First Crusade and the Crusade of 1101.\nEarly career.\nAlp Arslan accompanied his uncle Tughril on campaigns in the south against the Fatimids while his father Chaghri remained in Khorasan. Upon Alp Arslan's return to Khorasan, he began his work in administration at his father's suggestion. While there, his father introduced him to Nizam al-Mulk, one of the most eminent statesmen in early Muslim history and Alp Arslan's future vizier.\nAfter the death of his father, Alp Arslan succeeded him as governor of Khorasan in 1059. His uncle Tughril died in 1063 and designated his successor as Suleiman, Arslan's infant brother. Arslan and his uncle Kutalmish both contested this succession which was resolved at the battle of Damghan in 1063. Arslan defeated Kutalmish for the throne and succeeded on 27 April 1064 as sultan of the Seljuk Empire, thus becoming the sole monarch of Persia from the river Oxus to the Tigris. In 1064 he led a campaign in Georgia during which he captured the regions between Tbilisi and the \u00c7oruh river, Akhalkalaki and Alaverdi. Bagrat IV submitted to paying jizya to the Seljuks but the Georgians broke the agreement in 1065. Alp Arslan invaded Georgia again in 1068. He captured Tbilisi after a short battle and obtained the submission of Bagrat IV; however, the Georgians freed themselves from Seljuk rule around 1073\u20131074.\nIn consolidating his empire and subduing contending factions, Arslan was ably assisted by Nizam al-Mulk, and the two are credited with helping to stabilize the empire after the death of Tughril. With peace and security established in his dominions, Arslan convoked an assembly of the states, and in 1066, he declared his son Malik Shah I his heir and successor. With the hope of capturing Caesarea Mazaca, the capital of Cappadocia, he placed himself at the head of the Turkoman cavalry, crossed the Euphrates, and entered and invaded the city. Along with Nizam al-Mulk, he then marched into Armenia and Georgia, which he conquered in 1064. After a siege of 25 days, the Seljuks captured Ani, the capital city of Armenia. An account of the sack and massacres in Ani is given by the historian Sibt ibn al-Jawzi, who quotes an eyewitness saying:\nByzantine struggle.\nEn route to fight the Fatimids in Syria in 1068, Alp Arslan invaded the Byzantine Empire. The Emperor Romanos IV Diogenes, assuming command in person, met the invaders in Cilicia. In three arduous campaigns, the Turks were defeated in detail and driven across the Euphrates in 1070. The first two campaigns were conducted by the emperor himself, while the third was directed by Manuel Komnenos, the brother of future emperor Alexios I Komnenos. During this time, Arslan gained the allegiance of Rashid al-Dawla Mahmud, the Mirdasid emir of Aleppo.\nIn 1071, Romanos again took the field and advanced into Armenia with possibly 30,000 men, including a contingent of Cuman Turks as well as contingents of Franks and Normans, under Ursel de Baieul. Alp Arslan, who had moved his troops south to fight the Fatimids, quickly reversed to meet the Byzantines. Alp Arslan handed control of his army to his eunuch slave general, Taranges, and commanded him to \"Win or be beheaded.\" Taranges prepared for the battle by setting traps and organizing ambushes. The Seljuk and Byzantine armies met on Friday, 26 August 1071 at Manzikert on the Murat River, north of Lake Van, beginning the Battle of Manzikert. The Cuman mercenaries among the Byzantine forces immediately defected to the Turkic side. Seeing this, the Western mercenaries subsequently abandoned the battlefield as well. To be exact, Romanos was betrayed by general Andronikos Doukas, son of the Caesar (Romanos's stepson), who pronounced him dead and rode off with a large part of the Byzantine forces at a critical moment. The Byzantines were wholly routed.\nEmperor Romanos himself was captured in battle and presented to Alp Arslan. It is reported that upon seeing the Roman emperor, the sultan leaped from his throne, commanded Romanos to kiss the ground, and stepped on his neck. He repeatedly berated the emperor, including for spurning his emissaries and offers of peace. Romanos remained unrepentant, asserting that he had merely done what was \"possible for a man, and which kings are bound to do, and I have fallen short in nothing. But God has fulfilled his will. And now, do what you wish and abandon recriminations.\" Purportedly declaring Romanos \"too trivial... to kill\", Arslan then led him about the camp to sell the prisoner to one of his men. The Seljuk soldiers initially refused to spend any money on buying the emperor, until one man traded a dog for him. Next, wishing to test Romanos, Alp Arslan asked Romanos what he would do if their situation were reversed and Arslan was imprisoned by the Byzantines. Romanos bluntly answered \"The worst!\" His honesty impressed Arslan, who then decided to spare Romanos's life and instead ransom him back to his homeland. After agreeing on a ransom, Alp Arslan sent Romanos to Constantinople with a Turkish escort, carrying a banner above the disgraced emperor that read: \"There is no god but Allah and Muhammad is his messenger\".\nThe reason Alp Arslan spared Romanos was likely to avoid a two-front war. The Fatimids were launching devastating raids on the Seljuk domains during this period, Arslan may have worried that executing the Roman emperor might escalate his conflict with the Byzantines. Romanos himself had told the sultan that \"killing me will not be of any use to you\".\nAfter hearing of the death of Byzantine Emperor Romanos IV Diogenes, Sultan Alp Arslan pledged: \"The Byzantine nation has no God, so this day the oath of peace and friendship taken by both the Persians and Byzantines is nullified; henceforth I shall consume with the sword all those people who venerate the cross, and all the lands of the Christians shall be enslaved.\"\nAlp Arslan and his successor Malik Shah urged Turkish tribes to invade and settle Anatolia where they would not only cease to be a problem for the Seljuk Sultanate but also extend its territory further. Alp Arslan commanded the Turks as follows:\nAlp Arslan's victories changed the balance in western Asia completely in favor of the Seljuq Turks and Sunni Muslims. While the Byzantine Empire was to continue for nearly four more centuries, the victory at Manzikert signalled the beginning of Turkic ascendancy in Anatolia. The victory at Manzikert became so popular among the Turks that later every noble family in Anatolia claimed to have had an ancestor who had fought on that day.\nState organization.\nAlp Arslan's strength lay in the military realm. Domestic affairs were handled by his able vizier, Nizam al-Mulk, the founder of the administrative organization that characterized and strengthened the sultanate during the reigns of Alp Arslan and his son, Malik Shah. Military Iqtas, governed by Seljuq princes, were established to provide support for the soldiery and to accommodate the nomadic Turks to the established Anatolian agricultural scene. This type of military fiefdom enabled the nomadic Turks to draw on the resources of the sedentary Persians, Turks, and other established cultures within the Seljuq realm, and allowed Alp Arslan to field a huge standing army without depending on tribute from conquest to pay his soldiers. He not only had enough food from his subjects to maintain his military, but the taxes collected from traders and merchants added to his coffers sufficiently to fund his continuous wars.\nSuleiman ibn Qutalmish was the son of the contender for Arslan's throne; he was appointed governor of the north-western provinces and assigned to complete the invasion of Anatolia. An explanation for this choice can only be conjectured from Ibn al-Athir's account of the battle between Alp-Arslan and Kutalmish, in which he writes that Alp-Arslan wept for the latter's death and greatly mourned the loss of his kinsman.\nPhysical appearance and personality.\nContemporary descriptions portray Alp Arslan as \"very awe-inspiring, dominating,\" a \"greatformed one, elegant of stature. He had long, thin whiskers, which he used to knot up when shooting arrows. And they say his arrow never went astray... From the top button of his hat to the end of his moustaches it was two yards\"\nMuslim sources show Alp Arslan as fanatically pious but just. Alp Arslan was so dedicated to the Hanafi madhhab that he always kept a qadi by his side, including in battles.\nHis vizier, Nizam al-Mulk, described the young sultan:\nDeath.\nAfter Manzikert, the dominion of Alp Arslan extended over much of western Asia. He soon prepared to march for the conquest of Turkestan, the original seat of his ancestors. With a powerful army, he advanced to the banks of the Oxus. Before he could pass the river safely, however, it was necessary to subdue certain fortresses, one of which was for several days vigorously defended by the rebel, Yusuf al-Kharezmi or Yusuf al-Harani. Perhaps over-eager to press on against his Qarakhanid enemy, Alp Arslan gained the governor's submission by promising the rebel 'perpetual ownership of his lands'. When he was produced a captive in the royal tent, the sultan, instead of praising his valor, severely reproached his obstinate folly: and the insolent replies of the rebel provoked a sentence, that he should be fastened to four stakes, and left to expire in that painful situation.\u00a0 At this command, the desperate Yusuf al-Kharezmi, drawing a dagger, rushed headlong towards the throne: the guards raised their battle-axes; their zeal was checked by Alp Arslan, the most skilful archer of the age: he drew his bow, but his foot slipped, the arrow glanced aside, and he received in his breast the dagger of Yusuf al-Kharezmi, who was instantly cut in pieces.\nThe wound was mortal; and the Turkish sultan bequeathed a dying admonition to the pride of kings.\u00a0 \"In my youth,\" said Alp Arslan, \"I was advised by a sage to humble before God; to distrust my own strength; and never to despise the most contemptible foe.\u00a0 I have neglected these lessons; and my neglect has been deservedly punished. Yesterday, as from an eminence I beheld the numbers, the discipline, and the spirit, of my armies, the earth seemed to tremble under my feet; and I said in my heart, Surely thou art the king of the world, the greatest and most invincible of warriors. These armies are no longer mine; and, in the confidence of my personal strength, I now fall by the hand of an assassin. Four days later on 24 November 1072, Alp Arslan died and was buried at Merv, having designated his 18-year-old son Malik Shah as his successor.\nFamily.\nOne of his wives was Safariyya Khatun. She had a daughter, Sifri Khatun, who in 1071\u201372, married Abbasid Caliph Al-Muqtadi. Safariyya died in Isfahan in 1073\u201374. Another of his wives was Akka Khatun. She had been formerly the wife of Sultan Tughril. Alp Arslan married her after Tughril's death in 1063. Another of his wives was Shah Khatun. She was the daughter of Qadir Khan Yusuf, and had been formerly married to Ghaznavid Mas'ud I. Another wife was Ummu Hifchaq also known as Ummu Qipchaq. Another of his wives was the daughter of King of Tashir Kiurike I, who was married to the sister of the Georgian king Bagrat IV. Alp Arslan divorced her, and married her to Nizam al-Mulk. His sons were Malik-Shah I, Tutush I, Arslan Shah, Tekish, Toghan-Shah, Ayaz and Buibars. One of his daughters married the son of Kurd Surkhab, son of Bard in 1068. Another daughter, Zulaikha Khatun, was married to a Muslim, son of Quraish in 1086\u201387. Another daughter, Aisha Khatun, married Shams al-Mulk Nasr, son of Ibrahim Khan Tamghach. Another daughter was married to Mas'ud III of Ghazni and was his first wife. Another daughter was Sara Khatun.\nLegacy.\nAlp Arslan's conquest of Anatolia from the Byzantines is also seen as one of the pivotal precursors to the launch of the Crusades.\nFrom 2002 to July 2008 under Turkmen calendar reform, the month of August was named after Alp Arslan.\nThe 2nd Training Motorized Rifle Division of the Turkmen Ground Forces is named in his honor."}
{"id": "869", "revid": "4441371", "url": "https://en.wikipedia.org/wiki?curid=869", "title": "American Film Institute", "text": "The American Film Institute (AFI) is an American nonprofit film organization that educates filmmakers and honors the heritage of the motion picture arts in the United States. AFI is supported by private funding and public membership fees.\nLeadership.\nThe institute is composed of leaders from the film, entertainment, business, and academic communities. The board of trustees is chaired by Kathleen Kennedy and the board of directors chaired by Robert A. Daly guide the organization, which is led by President and CEO, film historian Bob Gazzale. Prior leaders were founding director George Stevens Jr. (from the organization's inception in 1967 until 1980) and Jean Picker Firstenberg (from 1980 to 2007).\nHistory.\nThe American Film Institute was founded by a 1965 presidential mandate announced in the Rose Garden of the White House by Lyndon B. Johnson\u2014to establish a national arts organization to preserve the legacy of American film heritage, educate the next generation of filmmakers, and honor the artists and their work. Two years later, in 1967, AFI was established, supported by the National Endowment for the Arts, the Motion Picture Association of America and the Ford Foundation.\nThe original 22-member Board of Trustees included actor Gregory Peck as chairman and actor Sidney Poitier as vice-chairman, as well as director Francis Ford Coppola, film historian Arthur Schlesinger, Jr., lobbyist Jack Valenti, and other representatives from the arts and academia.\nThe institute established a training program for filmmakers known then as the Center for Advanced Film Studies. Also created in the early years were a repertory film exhibition program at the Kennedy Center for the Performing Arts and the AFI Catalog of Feature Films \u2014 a scholarly source for American film history. The institute moved to its current eight-acre Hollywood campus in 1981. The film training program grew into the AFI Conservatory, an accredited graduate school.\nAFI moved its presentation of first-run and auteur films from the Kennedy Center to the historic AFI Silver Theatre and Cultural Center, which hosts the AFI DOCS film festival, making AFI the largest nonprofit film exhibitor in the world. AFI educates audiences and recognizes artistic excellence through its awards programs and 10 Top 10 Lists.\nIn 2017, then-aspiring filmmaker Ilana Bar-Din Giannini claimed that the AFI expelled her after she accused Dezso Magyar of sexually harassing her in the early 1980s.\nList of programs in brief.\nAFI educational and cultural programs include:\nAFI Conservatory.\nIn 1969, the institute established the AFI Conservatory for Advanced Film Studies at Greystone, the Doheny Mansion in Beverly Hills, California. The first class included filmmakers Terrence Malick, Caleb Deschanel, and Paul Schrader. That program grew into the AFI Conservatory, an accredited graduate film school located in the hills above Hollywood, California, providing training in six filmmaking disciplines: cinematography, directing, editing, producing, production design, and screenwriting. Mirroring a professional production environment, Fellows collaborate to make more films than any other graduate level program. Admission to AFI Conservatory is highly selective, with a maximum of 140 graduates per year.\nIn 2013, Emmy and Oscar-winning director, producer, and screenwriter James L. Brooks (\"As Good as It Gets\", \"Broadcast News\", \"Terms of Endearment\") joined as the artistic director of the AFI Conservatory where he provides leadership for the film program. Brooks' artistic role at the AFI Conservatory has a rich legacy that includes Daniel Petrie, Jr., Robert Wise, and Frank Pierson. Award-winning director Bob Mandel served as dean of the AFI Conservatory for nine years. Jan Schuette took over as dean in 2014 and served until 2017. Film producer Richard Gladstein was dean from 2017 until 2019, when Susan Ruskin was appointed.\nNotable alumni.\nAFI Conservatory's alumni have careers in film, television and on the web. They have been recognized with all of the major industry awards\u2014Academy Award, Emmy Award, guild awards, and the Tony Award.\nAFI Film Festivals.\nAFI operates two film festivals: in Los Angeles, and AFI Docs (formally known as Silverdocs) in Silver Spring, Maryland, and Washington, D.C.\nAmerican Film Institute Festival.\nCommonly shortened to AFI Fest, it is the American Film Institute\u2019s annual celebration of artistic excellence. It is a showcase for the best festival films of the year as selected by AFI and an opportunity for master filmmakers and emerging artists to come together with audiences in New York. It is the only festival of its stature that is free to the public. The Academy of Motion Picture Arts and Sciences recognizes AFI Fest as a qualifying festival for the Short Films category for the annual Academy Awards.\nThe festival has paid tribute to numerous influential filmmakers and artists over the years, including Agn\u00e8s Varda, Pedro Almod\u00f3var and David Lynch as guest artistic directors, and has screened scores of films that have gone on to win Oscar nominations and awards.\nThe movies selected by AFI are assigned to different sections for the festival; these include Galas/Red Carpet Premieres, Special Screenings, Documentaries, Discovery, and Short Film Competition.\nRed Carpet Premieres.\nFormerly named Galas, it is AFI Fest\u2019s section for the most highly anticipated films at the festival, presenting selected feature-length movies from world-class filmmakers and artisans. Although it is a very restrictive selection, usually presenting between three and seven movies at most, many films selected by AFI for this section eventually also earn an Academy Award Best Picture nomination. Examples include Bradley Cooper's \"Maestro\" (2023), Steven Spielberg's \"The Fabelmans\" (2022), Will Smith's \"King Richard\" (2021), Jane Campion's \"The Power of the Dog\" (2021), Anthony Hopkins's \"The Father\" (2020), Noah Baumbach's \"Marriage Story\" (2019), Peter Farrelly's \"Green Book\" (2018), Luca Guadagnino's \"Call Me by Your Name\" (2017), Damien Chazelle's \"La La Land\" (2016), and Adam McKay's \"The Big Short\" (2015).\nAFI Docs.\nHeld annually in June, AFI Docs (formerly Silverdocs) is a documentary festival in Washington, D.C. The festival attracts over 27,000 documentary enthusiasts.\nAFI programs.\nAFI Catalog of Feature Films.\nThe AFI Catalog, started in 1968, is a web-based filmographic database. A research tool for film historians, the catalog consists of entries on more than 60,000 feature films and 17,000 short films produced from 1893 to 2011, as well as AFI Awards Outstanding Movies of the Year from 2000 through 2010. Early print copies of this catalog may also be found at local libraries.\nAFI Awards.\nCreated in 2000, the AFI Awards honor the ten outstanding films (\"Movies of the Year\") and ten outstanding television programs (\"TV Programs of the Year\"). The awards are a non-competitive acknowledgment of excellence.\nThe awards are announced in December, and a private luncheon for award honorees takes place the following January.\nAFI 100 Years... series.\nThe AFI 100 Years... series, which ran from 1998 to 2008 and created jury-selected lists of America's best movies in categories such as Musicals, Laughs and Thrills, prompted new generations to experience classic American films. The juries consisted of over 1,500 artists, scholars, critics, and historians. \"Citizen Kane\" was voted the greatest American film twice.\nAFI Silver Theatre and Cultural Center.\nThe AFI Silver Theatre and Cultural Center is a moving image exhibition, education and cultural center located in Silver Spring, Maryland. Anchored by the restoration of noted architect John Eberson's historic 1938 Silver Theatre, it features 32,000 square feet of new construction housing two stadium theatres, office and meeting space, and reception and exhibit areas.\nThe AFI Silver Theatre and Cultural Center presents film and video programming, augmented by filmmaker interviews, panels, discussions, and musical performances.\nThe AFI Directing Workshop for Women.\nThe Directing Workshop for Women is a training program committed to educating and mentoring participants in an effort to increase the number of women working professionally in screen directing. In this tuition-free program, each participant is required to complete a short film by the end of the year-long program.\nAlumnae of the program include Maya Angelou, Anne Bancroft, Dyan Cannon, Ellen Burstyn, Jennifer Getzinger, Lesli Linka Glatter, Lily Tomlin, Susan Oliver and Nancy Malone.\nAFI Directors Series.\nAFI released a set of hour-long programs reviewing the career of acclaimed directors. The Directors Series content was copyrighted in 1997 by Media Entertainment Inc and The American Film Institute, and the VHS and DVDs were released between 1999 and 2001 on Winstar TV and Video.\nDirectors featured included:"}
{"id": "872", "revid": "1743745", "url": "https://en.wikipedia.org/wiki?curid=872", "title": "Akira Kurosawa", "text": " was a Japanese filmmaker who created 30 films of his own as well as occasionally directing and writing for others in a career spanning seven decades. He is widely regarded as one of the greatest and most influential filmmakers in the history of cinema. Kurosawa displayed a bold, dynamic style strongly influenced by Western cinema yet distinct from it. He was involved with all aspects of film production.\nKurosawa entered the Japanese film industry in 1936, following a brief stint as a painter. After years of working on numerous films as an assistant director and scriptwriter, he made his debut as a director during World War II with the popular action film \"Sanshiro Sugata\" (1943). After the war, the critically acclaimed \"Drunken Angel\" (1948), in which Kurosawa cast the then little-known actor Toshiro Mifune in a starring role, cemented the director's reputation as one of the most important young filmmakers in Japan. The two men would go on to collaborate on another fifteen films.\n\"Rashomon\" (1950), which premiered in Tokyo, became the surprise winner of the Golden Lion at the 1951 Venice Film Festival. The commercial and critical success of that film opened up Western film markets for the first time to the products of the Japanese film industry, which in turn led to international recognition for other Japanese filmmakers. Kurosawa directed approximately one film per year throughout the 1950s and early 1960s, including a number of highly regarded (and often adapted) films, including (1952), \"Seven Samurai\" (1954), \"Throne of Blood\" (1957), \"The Hidden Fortress\" (1958), \"Yojimbo\" (1961), \"High and Low\" (1963) and \"Red Beard\" (1965). After the 1960s he became much less prolific; even so, his later work \u2013 including two of his final films, (1980) and (1985) \u2013 continued to receive great acclaim.\nIn 1990, he accepted the Academy Award for Lifetime Achievement. Posthumously, he was named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by \"AsianWeek\" magazine and CNN, cited there as being among the five people who most prominently contributed to the improvement of Asia in the 20th century. His career has been honored by many retrospectives, critical studies and biographies in both print and video, and by releases in many consumer media. Kurosawa told the critic Donald Richie: \"I suppose all of my films have a common theme. If I think about it, though, the only theme I can think of is really a question: Why can't people be happier together?\"\nBiography.\nChildhood to war years (1910\u20131945).\nChildhood and youth (1910\u20131935).\nKurosawa was born on March 23, 1910, in \u014cimachi in the \u014cmori district of Tokyo. His father Isamu (1864\u20131948), a member of a samurai family from Akita Prefecture, worked as the director of the Army's Physical Education Institute's lower secondary school, while his mother Shima (1870\u20131952) came from a merchant's family living in Osaka. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving Kurosawa to grow up with three sisters and a brother.\nIn addition to promoting physical exercise, Isamu Kurosawa was open to Western traditions and considered theatre and motion pictures to have educational merit. He encouraged his children to watch films; young Akira viewed his first movies at the age of six. An important formative influence was his elementary school teacher Mr. Tachikawa, whose progressive educational practices ignited in his young pupil first a love of drawing and then an interest in education in general. During this time, Akira also studied calligraphy and Kendo swordsmanship.\nAnother major childhood influence was Heigo Kurosawa (1906\u20131933), Akira's older brother by four years. In the aftermath of the Great Kant\u014d earthquake and the subsequent Kant\u014d Massacre of 1923, Heigo took the thirteen-year-old Akira to view the devastation. When Akira wanted to look away from the corpses of humans and animals scattered everywhere, Heigo forbade him to do so, encouraging Akira instead to face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as the director was seldom hesitant to confront unpleasant truths in his work.\nHeigo was academically gifted, but soon after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family, preferring to concentrate on his interest in foreign literature. In the late 1920s, Heigo became a benshi (silent film narrator) for Tokyo theaters showing foreign films and quickly made a name for himself. Akira, who at this point planned to become a painter, moved in with him, and the two brothers became inseparable. With Heigo's guidance, Akira devoured not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. However, he was never able to make a living with his art, and, as he began to perceive most of the proletarian movement as \"putting unfulfilled political ideals directly onto the canvas\", he lost his enthusiasm for painting.\nWith the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Akira moved back in with his parents. In July 1933, Heigo died by suicide. Kurosawa has commented on the lasting sense of loss he felt at his brother's death and the chapter of \"Something Like an Autobiography\" that describes it\u2014written nearly half a century after the event\u2014is titled, \"A Story I Don't Want to Tell\". Only four months later, Kurosawa's eldest brother also died, leaving Akira, at age 23, the only one of the Kurosawa brothers still living, together with his three surviving sisters.\nDirector in training (1935\u20131941).\nIn 1935, the new film studio Photo Chemical Laboratories, known as P.C.L. (which later became the major studio Toho), advertised for assistant directors. Although he had demonstrated no previous interest in film as a profession, Kurosawa submitted the required essay, which asked applicants to discuss the fundamental deficiencies of Japanese films and find ways to overcome them. His half-mocking view was that if the deficiencies were fundamental, there was no way to correct them. Kurosawa's essay earned him a call to take the follow-up exams, and director Kajir\u014d Yamamoto, who was among the examiners, took a liking to Kurosawa and insisted that the studio hire him. The 25-year-old Kurosawa joined P.C.L. in February 1936.\nDuring his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Ken'ichi Enomoto, known as \"Enoken\". Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing, and second-unit directing. In the last of Kurosawa's films as an assistant director for Yamamoto, \"Horse\" (1941), Kurosawa took over most of the production, as his mentor was occupied with the shooting of another film.\nYamamoto advised Kurosawa that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. He later wrote or co-wrote all his films and frequently penned screenplays for other directors such as Satsuo Yamamoto's film, \"A Triumph of Wings\" (\"Tsubasa no gaika\", 1942). This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became famous.\nWartime films and marriage (1942\u20131945).\nIn the two years following the release of \"Horse\" in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the Japanese attack on Pearl Harbor, novelist Tsuneo Tomita published his Musashi Miyamoto-inspired judo novel, \"Sanshiro Sugata\", the advertisements for which intrigued Kurosawa. He bought the book on its publication day, devoured it in one sitting, and immediately asked Toho to secure the film rights. Kurosawa's initial instinct proved correct as, within a few days, three other major Japanese studios also offered to buy the rights. Toho prevailed, and Kurosawa began pre-production on his debut work as director.\nShooting of \"Sanshiro Sugata\" began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship office considered the work to be objectionably \"British-American\" by the standards of wartime Japan, and it was only through the intervention of director Yasujir\u014d Ozu, who championed the film, that \"Sanshiro Sugata\" was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.\nHe next turned to the subject of wartime female factory workers in \"The Most Beautiful\", a propaganda film which he shot in a semi-documentary style in early 1944. To elicit realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would use similar methods with his performers throughout his career.\nDuring production, the actress playing the leader of the factory workers, Y\u014dko Yaguchi, was chosen by her colleagues to present their demands to the director. She and Kurosawa were constantly at odds, and it was through these arguments that the two paradoxically became close. They married on May 21, 1945, with Yaguchi two months pregnant (she never resumed her acting career), and the couple would remain together until her death in 1985. They had two children, both surviving Kurosawa : a son, Hisao, born December 20, 1945, who served as producer on some of his father's last projects, and Kazuko, a daughter, born April 29, 1954, who became a costume designer.\nShortly before his marriage, Kurosawa was pressured by the studio against his will to direct a sequel to his debut film. The often blatantly propagandistic \"Sanshiro Sugata Part II\", which premiered in May 1945, is generally considered one of his weakest pictures.\nKurosawa decided to write the script for a film that would be both censor-friendly and less expensive to produce. \"The Men Who Tread on the Tiger's Tail\", based on the Kabuki play \"Kanjinch\u014d\" and starring the comedian Enoken, with whom Kurosawa had often worked during his assistant director days, was completed in September 1945. By this time, Japan had surrendered and the occupation of Japan had begun. The new American censors interpreted the values allegedly promoted in the picture as overly \"feudal\" and banned the work. It was not released until 1952, the year another Kurosawa film, , was also released. Ironically, while in production, the film had already been savaged by Japanese wartime censors as too Western and \"democratic\" (they particularly disliked the comic porter played by Enoken), so the movie most probably would not have seen the light of day even if the war had continued beyond its completion.\nEarly postwar years to \"Red Beard\" (1946\u20131965).\nFirst postwar works (1946\u20131950).\nAfter the war, Kurosawa, influenced by the democratic ideals of the Occupation, sought to make films that would establish a new respect towards the individual and the self. The first such film, \"No Regrets for Our Youth\" (1946), inspired by both the 1933 Takigawa incident and the Hotsumi Ozaki wartime spy case, criticized Japan's prewar regime for its political oppression. Atypically for the director, the heroic central character is a woman, Yukie (Setsuko Hara), who, born into upper-middle-class privilege, comes to question her values in a time of political crisis. The original script had to be extensively rewritten and, because of its controversial theme and gender of its protagonist, the completed work divided critics. Nevertheless, it managed to win the approval of audiences, who turned variations on the film's title into a postwar catchphrase.\nHis next film, \"One Wonderful Sunday\", premiered in July 1947 to mixed reviews. It is a relatively uncomplicated and sentimental love story dealing with an impoverished postwar couple trying to enjoy, within the devastation of postwar Tokyo, their one weekly day off. The movie bears the influence of Frank Capra, D. W. Griffith and F. W. Murnau, each of whom was among Kurosawa's favorite directors. Another film released in 1947 with Kurosawa's involvement was the action-adventure thriller, \"Snow Trail\", directed by Senkichi Taniguchi from Kurosawa's screenplay. It marked the debut of the intense young actor Toshiro Mifune. It was Kurosawa who, with his mentor Yamamoto, had intervened to persuade Toho to sign Mifune, during an audition in which the young man greatly impressed Kurosawa, but managed to alienate most of the other judges.\n\"Drunken Angel\" is often considered the director's first major work. Although the script, like all of Kurosawa's occupation-era works, had to go through rewrites due to American censorship, Kurosawa felt that this was the first film in which he was able to express himself freely. A gritty story of a doctor who tries to save a gangster (yakuza) with tuberculosis, it was also the first time that Kurosawa directed Mifune, who went on to play major roles in all but one of the director's next 16 films (the exception being ). While Mifune was not cast as the protagonist in \"Drunken Angel\", his explosive performance as the gangster so dominates the drama that he shifted the focus from the title character, the alcoholic doctor played by Takashi Shimura, who had already appeared in several Kurosawa movies. However, Kurosawa did not want to smother the young actor's immense vitality, and Mifune's rebellious character electrified audiences in much the way that Marlon Brando's defiant stance would startle American film audiences a few years later. The film premiered in Tokyo in April 1948 to rave reviews and was chosen by the prestigious \"Kinema Junpo\" critics poll as the best film of its year, the first of three Kurosawa movies to be so honored.\nAfter the completion of \"Drunken Angel\", Toho became embroiled in a months-long labor strike, in which the Toho union occupied the grounds of the studio. When Toho management ceased paying workers' salaries, Kurosawa formed a touring acting troupe to raise funds, directing Anton Chekhov's \"The Proposal\", and an adaptation of \"Drunken Angel\" starring Mifune and Shimura. Disillusioned by the division and violence between employees at Toho, the underhanded tactics of Toho leadership, and the breaking of the occupation by police and military standoff, Kurosawa left Toho, later recalling \"I had come to understand that the studio I had thought was my home actually belonged to strangers\".\nKurosawa, with producer S\u014djir\u014d Motoki and fellow directors and friends Kajiro Yamamoto, Mikio Naruse and Senkichi Taniguchi, formed a new independent production unit called Film Art Association (Eiga Geijutsu Ky\u014dkai). For this organization's debut work, and first film for Daiei studios, Kurosawa turned to a contemporary play by Kazuo Kikuta and, together with Taniguchi, adapted it for the screen. \"The Quiet Duel\" starred Toshiro Mifune as an idealistic young doctor struggling with syphilis, a deliberate attempt by Kurosawa to break the actor away from being typecast as gangsters. Released in March 1949, it was a box office success, but is generally considered one of the director's lesser achievements.\nHis second film of 1949, also produced by Film Art Association and released by Shintoho, was \"Stray Dog\". It is a detective movie (perhaps the first important Japanese film in that genre) that explores the mood of Japan during its painful postwar recovery through the story of a young detective, played by Mifune, and his fixation on the recovery of his handgun, which was stolen by a penniless war veteran who proceeds to use it to rob and murder. Adapted from an unpublished novel by Kurosawa in the style of a favorite writer of his, Georges Simenon, it was the director's first collaboration with screenwriter Ryuzo Kikushima, who would later help to script eight other Kurosawa films. A famous, virtually wordless sequence, lasting over eight minutes, shows the detective, disguised as an impoverished veteran, wandering the streets in search of the gun thief; it employed actual documentary footage of war-ravaged Tokyo neighborhoods shot by Kurosawa's friend, Ishir\u014d Honda, the future director of \"Godzilla\". The film is considered a precursor to the contemporary police procedural and buddy cop film genres.\n\"Scandal\", released by Shochiku in April 1950, was inspired by the director's personal experiences with (and anger towards) Japanese yellow journalism. The work is an ambitious mixture of courtroom drama and social problem film about free speech and personal responsibility, but even Kurosawa regarded the finished product as dramatically unfocused and unsatisfactory, and almost all critics agree. However, it would be Kurosawa's second film of 1950 that would ultimately win him (and Japanese cinema) a whole new international audience.\nInternational recognition (1950\u20131958).\nAfter finishing \"Scandal\", Kurosawa was approached by Daiei studios to make another film for them. Kurosawa picked a script by an aspiring young screenwriter, Shinobu Hashimoto, who would eventually work on nine of his films. Their first joint effort was based on Ry\u016bnosuke Akutagawa's experimental short story \"In a Grove\", which recounts the murder of a samurai and the rape of his wife from various different and conflicting points of view. Kurosawa saw potential in the script and, with Hashimoto's help, polished and expanded it and then pitched it to Daiei, who were happy to accept the project due to its low budget.\nThe shooting of \"Rashomon\" began on July 7, 1950, and, after extensive location work in the primeval forest of Nara, wrapped on August 17. Just one week was spent in hurried post-production, hampered by a studio fire, and the finished film premiered at Tokyo's Imperial Theatre on August 25, expanding nationwide the following day. The movie was met by lukewarm reviews, with many critics puzzled by its unique theme and treatment, but it was nevertheless a moderate financial success for Daiei.\nKurosawa's next film, for Shochiku, was \"The Idiot\", an adaptation of the novel by the director's favorite writer, Fyodor Dostoevsky. The story is relocated from Russia to Hokkaido, but otherwise adheres closely to the original, a fact seen by many critics as detrimental to the work. A studio-mandated edit shortened it from Kurosawa's original cut of 265 minutes to just 166 minutes, making the resulting narrative exceedingly difficult to follow. The severely edited film version is widely considered to be one of the director's least successful works and the original full-length version no longer exists. Contemporary reviews of the much shortened edited version were very negative, but the film was a moderate success at the box office, largely because of the popularity of one of its stars, Setsuko Hara.\nMeanwhile, unbeknownst to Kurosawa, \"Rashomon\" had been entered in the Venice Film Festival, due to the efforts of Giuliana Stramigioli, a Japan-based representative of an Italian film company, who had seen and admired the movie and convinced Daiei to submit it. On September 10, 1951, \"Rashomon\" was awarded the festival's highest prize, the Golden Lion, shocking not only Daiei but the international film world, which at the time was largely unaware of Japan's decades-old cinematic tradition.\nAfter Daiei briefly exhibited a subtitled print of the film in Los Angeles, RKO purchased distribution rights to \"Rashomon\" in the United States. The company was taking a considerable gamble. It had put out only one prior subtitled film in the American market, and the only previous Japanese talkie commercially released in New York had been Mikio Naruse's comedy, \"Wife! Be Like a Rose!\", in 1937: a critical and box-office flop. However, \"Rashomon\"s commercial run, greatly helped by strong reviews from critics and even the columnist Ed Sullivan, earned $35,000 in its first three weeks at a single New York theatre, an almost unheard-of sum at the time.\nThis success in turn led to a vogue in America and the West for Japanese movies throughout the 1950s, replacing the enthusiasm for Italian neorealist cinema. By the end of 1952 \"Rashomon\" was released in Japan, the United States, and most of Europe. Among the Japanese film-makers whose work, as a result, began to win festival prizes and commercial release in the West were Kenji Mizoguchi (\"The Life of Oharu\", \"Ugetsu\", \"Sansho the Bailiff\") and, somewhat later, Yasujir\u014d Ozu (\"Tokyo Story\", \"An Autumn Afternoon\")\u2014artists highly respected in Japan but, before this period, almost totally unknown in the West. Kurosawa's growing reputation among Western audiences in the 1950s would make Western audiences more sympathetic to the reception of later generations of Japanese film-makers ranging from Kon Ichikawa, Masaki Kobayashi, Nagisa Oshima and Shohei Imamura to Juzo Itami, Takeshi Kitano and Takashi Miike.\nHis career boosted by his sudden international fame, Kurosawa, now reunited with his original film studio, Toho (which would go on to produce his next 11 films), set to work on his next project, . Based on Leo Tolstoy's \"The Death of Ivan Ilyich\", the movie stars Takashi Shimura as a cancer-ridden Tokyo bureaucrat, Watanabe, on a final quest for meaning before his death. For the screenplay, Kurosawa brought in Hashimoto as well as writer Hideo Oguni, who would go on to co-write twelve Kurosawa films. Despite the work's grim subject matter, the screenwriters took a satirical approach, which some have compared to the work of Brecht, to both the bureaucratic world of its hero and the U.S. cultural colonization of Japan. (American pop songs figure prominently in the film.) Because of this strategy, the filmmakers are usually credited with saving the picture from the kind of sentimentality common to dramas about characters with terminal illnesses. opened in October 1952 to rave reviews\u2014it won Kurosawa his second Kinema Junpo \"Best Film\" award\u2014and enormous box office success. It remains the most acclaimed of all the artist's films set in the modern era.\nIn December 1952, Kurosawa took his screenwriters, Shinobu Hashimoto and Hideo Oguni, for a forty-five-day secluded residence at an inn to create the screenplay for his next movie, \"Seven Samurai\". The ensemble work was Kurosawa's first proper samurai film, the genre for which he would become most famous. The simple story, about a poor farming village in Sengoku period Japan that hires a group of samurai to defend it against an impending attack by bandits, was given a full epic treatment, with a huge cast (largely consisting of veterans of previous Kurosawa productions) and meticulously detailed action, stretching out to almost three-and-a-half hours of screen time.\nThree months were spent in pre-production and a month in rehearsals. Shooting took up 148 days spread over almost a year, interrupted by production and financing troubles and Kurosawa's health problems. The film finally opened in April 1954, half a year behind its original release date and about three times over budget, making it at the time the most expensive Japanese film ever made. (However, by Hollywood standards, it was a quite modestly budgeted production, even for that time.) The film received positive critical reaction and became a big hit, quickly making back the money invested in it and providing the studio with a product that they could (and did) market internationally\u2014though with extensive edits. Over time\u2014and with the theatrical and home video releases of the uncut version\u2014its reputation has steadily grown. It is now regarded by some commentators as the greatest Japanese film ever made, and in 1999 a poll of Japanese film critics also voted it the best Japanese film ever made. In the most recent (2022) version of the widely respected British Film Institute (BFI) \"Sight &amp; Sound\" \"Greatest Films of All Time\" poll, \"Seven Samurai\" placed 20th among all films from all countries in the critics' and tied at 14th in the directors' polls, receiving a place in the Top Ten lists of 48 critics and 22 directors.\nIn 1954, nuclear tests in the Pacific were causing radioactive rainstorms in Japan and one particular incident in March had exposed a Japanese fishing boat to nuclear fallout, with disastrous results. It is in this anxious atmosphere that Kurosawa's next film, \"I Live in Fear\", was conceived. The story concerned an elderly factory owner (Toshiro Mifune) so terrified of the prospect of a nuclear attack that he becomes determined to move his entire extended family (both legal and extra-marital) to what he imagines is the safety of a farm in Brazil. Production went much more smoothly than the director's previous film, but a few days before shooting ended, Kurosawa's composer, collaborator, and close friend Fumio Hayasaka died (of tuberculosis) at the age of 41. The film's score was finished by Hayasaka's student, Masaru Sato, who would go on to score all of Kurosawa's next eight films. \"I Live in Fear\" opened in November 1955 to mixed reviews and muted audience reaction, becoming the first Kurosawa film to lose money during its original theatrical run. Today, it is considered by many to be among the finest films dealing with the psychological effects of the global nuclear stalemate.\nKurosawa's next project, \"Throne of Blood\", an adaptation of William Shakespeare's \"Macbeth\"\u2014set, like \"Seven Samurai\", in the Sengoku Era\u2014represented an ambitious transposition of the English work into a Japanese context. Kurosawa instructed his leading actress, Isuzu Yamada, to regard the work as if it were a cinematic version of a \"Japanese\" rather than a European literary classic. Given Kurosawa's appreciation of traditional Japanese stage acting, the acting of the players, particularly Yamada, draws heavily on the stylized techniques of the Noh theater. It was filmed in 1956 and released in January 1957 to a slightly less negative domestic response than had been the case with the director's previous film. Abroad, \"Throne of Blood\", regardless of the liberties it takes with its source material, quickly earned a place among the most celebrated Shakespeare adaptations.\nAnother adaptation of a classic European theatrical work followed almost immediately, with production of \"The Lower Depths\", based on a play by Maxim Gorky, taking place in May and June 1957. In contrast to the Shakespearean sweep of \"Throne of Blood\", \"The Lower Depths\" was shot on only two confined sets, in order to emphasize the restricted nature of the characters' lives. Though faithful to the play, this adaptation of Russian material to a completely Japanese setting\u2014in this case, the late Edo period\u2014unlike his earlier \"The Idiot\", was regarded as artistically successful. The film premiered in September 1957, receiving a mixed response similar to that of \"Throne of Blood\". However, some critics rank it among the director's most underrated works.\nKurosawa's three next movies after \"Seven Samurai\" had not managed to capture Japanese audiences in the way that that film had. The mood of the director's work had been growing increasingly pessimistic and dark even as Japan entered a boom period of high-speed growth and rising standards of living. Out of step with the prevailing mood of the era, Kurosawa's films questioned the possibility of redemption through personal responsibility, particularly in \"Throne of Blood\" and \"The Lower Depths\". He recognized this and deliberately aimed for a more light-hearted and entertaining film for his next production while switching to the new widescreen format that had been gaining popularity in Japan. The resulting film, \"The Hidden Fortress\", is an action-adventure comedy-drama about a medieval princess, her loyal general, and two peasants who all need to travel through enemy lines in order to reach their home region. Released in December 1958, \"The Hidden Fortress\" became an enormous box-office success in Japan and was warmly received by critics both in Japan and abroad. Today, the film is considered one of Kurosawa's most lightweight efforts, though it remains popular, not least because it is one of several major influences on George Lucas's 1977 space opera, \"Star Wars\".\nBirth of a company and \"Red Beard\" (1959\u20131965).\nStarting with \"Rashomon\", Kurosawa's productions had become increasingly large in scope and so had the director's budgets. Toho, concerned about this development, suggested that he might help finance his own works, therefore making the studio's potential losses smaller, while in turn allowing himself more artistic freedom as co-producer. Kurosawa agreed, and the Kurosawa Production Company was established in April 1959, with Toho as the majority shareholder.\nDespite risking his own money, Kurosawa chose a story that was more directly critical of the Japanese business and political elites than any previous work. \"The Bad Sleep Well\", based on a script by Kurosawa's nephew Mike Inoue, is a revenge drama about a young man who is able to infiltrate the hierarchy of a corrupt Japanese company with the intention of exposing the men responsible for his father's death. Its theme proved topical: while the film was in production, the massive Anpo protests were held against the new U.S.\u2013Japan Security treaty, which was seen by many Japanese, particularly the young, as threatening the country's democracy by giving too much power to corporations and politicians. The film opened in September 1960 to positive critical reaction and modest box office success. The 25-minute opening sequence depicting a corporate wedding reception is widely regarded as one of Kurosawa's most skillfully executed set pieces, but the remainder of the film is often perceived as disappointing by comparison. The movie has also been criticized for employing the conventional Kurosawan hero to combat a social evil that cannot be resolved through the actions of individuals, however courageous or cunning.\n\"Yojimbo\" (\"The Bodyguard\"), Kurosawa Production's second film, centers on a masterless samurai, Sanjuro, who strolls into a 19th-century town ruled by two opposing violent factions and provokes them into destroying each other. The director used this work to play with many genre conventions, particularly the Western, while at the same time offering an unprecedentedly (for the Japanese screen) graphic portrayal of violence. Some commentators have seen the Sanjuro character in this film as a fantasy figure who magically reverses the historical triumph of the corrupt merchant class over the samurai class. Featuring Tatsuya Nakadai in his first major role in a Kurosawa movie, and with innovative photography by Kazuo Miyagawa (who shot \"Rashomon\") and Takao Saito, the film premiered in April 1961 and was a critically and commercially successful venture, earning more than any previous Kurosawa film. The movie and its blackly comic tone were also widely imitated abroad. Sergio Leone's \"A Fistful of Dollars\" was a virtual (unauthorized) scene-by-scene remake with Toho filing a lawsuit on Kurosawa's behalf and prevailing.\nFollowing the success of \"Yojimbo\", Kurosawa found himself under pressure from Toho to create a sequel. Kurosawa turned to a script he had written before \"Yojimbo\", reworking it to include the hero of his previous film. \"Sanjuro\" was the first of three Kurosawa films to be adapted from the work of the writer Sh\u016bgor\u014d Yamamoto (the others would be \"Red Beard\" and \"Dodeskaden\"). It is lighter in tone and closer to a conventional period film than \"Yojimbo\", though its story of a power struggle within a samurai clan is portrayed with strongly comic undertones. The film opened on January 1, 1962, quickly surpassing \"Yojimbo\"s box office success and garnering positive reviews.\nKurosawa had meanwhile instructed Toho to purchase the film rights to \"King's Ransom\", a novel about a kidnapping written by American author and screenwriter Evan Hunter, under his pseudonym of Ed McBain, as one of his 87th Precinct series of crime books. The director intended to create a work condemning kidnapping, which he considered one of the very worst crimes. The suspense film, titled \"High and Low\", was shot during the latter half of 1962 and released in March 1963. It broke Kurosawa's box office record (the third film in a row to do so), became the highest grossing Japanese film of the year and won glowing reviews. However, his triumph was somewhat tarnished when, ironically, the film was blamed for a wave of kidnappings which occurred in Japan about this time (he himself received kidnapping threats directed at his young daughter, Kazuko). \"High and Low\" is considered by many commentators to be among the director's strongest works.\nKurosawa quickly moved on to his next project, \"Red Beard\". Based on a short story collection by Sh\u016bgor\u014d Yamamoto and incorporating elements from Dostoevsky's novel \"The Insulted and Injured\", it is a period film, set in a mid-nineteenth century clinic for the poor, in which Kurosawa's humanist themes receive perhaps their fullest statement. A conceited and materialistic, foreign-trained young doctor, Yasumoto, is forced to become an intern at the clinic under the stern tutelage of Doctor Niide, known as \"Akahige\" (\"Red Beard\"), played by Mifune. Although he resists Red Beard initially, Yasumoto comes to admire his wisdom and courage and to perceive the patients at the clinic, whom he at first despised, as worthy of compassion and dignity.\nY\u016bz\u014d Kayama, who plays Yasumoto, was an extremely popular film and music star at the time, particularly for his \"Young Guy\" (\"Wakadaish\u014d\") series of musical comedies, so signing him to appear in the film virtually guaranteed Kurosawa strong box-office. The shoot, the filmmaker's longest ever, lasted well over a year (after five months of pre-production) and wrapped in spring 1965, leaving the director, his crew and his actors exhausted. \"Red Beard\" premiered in April 1965, becoming the year's highest-grossing Japanese production and the third (and last) Kurosawa film to top the prestigious \"Kinema Jumpo\" yearly critics poll. It remains one of Kurosawa's best-known and most-loved works in his native country. Outside Japan, critics have been much more divided. Most commentators concede its technical merits and some praise it as among Kurosawa's best, while others insist that it lacks complexity and genuine narrative power, with still others claiming that it represents a retreat from the artist's previous commitment to social and political change.\nThe film marked something of an end of an era for its creator. The director himself recognized this at the time of its release, telling critic Donald Richie that a cycle of some kind had just come to an end and that his future films and production methods would be different. His prediction proved quite accurate. Beginning in the late 1950s, television began increasingly to dominate the leisure time of the formerly large and loyal Japanese cinema audience. And as film company revenues dropped, so did their appetite for risk\u2014particularly the risk represented by Kurosawa's costly production methods.\n\"Red Beard\" also marked the midway point, chronologically, in the artist's career. During his previous twenty-nine years in the film industry (which includes his five years as assistant director), he had directed twenty-three films, while during the remaining twenty-eight years, for many complex reasons, he would complete only seven more. Also, for reasons never adequately explained, \"Red Beard\" would be his final film starring Toshiro Mifune. Y\u016b Fujiki, an actor who worked on \"The Lower Depths\", observed, regarding the closeness of the two men on the set, \"Mr. Kurosawa's heart was in Mr. Mifune's body.\" Donald Richie has described the rapport between them as a unique \"symbiosis\".\nHollywood ambitions to last films (1966\u20131998).\nHollywood detour (1966\u20131968).\nWhen Kurosawa's exclusive contract with Toho came to an end in 1966, the 56-year-old director was seriously contemplating change. Observing the troubled state of the domestic film industry and having already received dozens of offers from abroad, the idea of working outside Japan appealed to him as never before.\nFor his first foreign project, Kurosawa chose a story based on a \"Life\" magazine article. The Embassy Pictures action thriller, to be filmed in English and called simply \"Runaway Train\", would have been his first in color. But the language barrier proved a major problem, and the English version of the screenplay was not even finished by the time filming was to begin in autumn 1966. The shoot, which required snow, was moved to autumn 1967, then canceled in 1968. Almost two decades later, another foreign director working in Hollywood, Andrei Konchalovsky, finally made \"Runaway Train\" (1985), though from a new script loosely based on Kurosawa's.\nThe director meanwhile had become involved in a much more ambitious Hollywood project. \"Tora! Tora! Tora!\", produced by 20th Century Fox and Kurosawa Production, would be a portrayal of the Japanese attack on Pearl Harbor from both the American and the Japanese points of view, with Kurosawa helming the Japanese half and an Anglophonic film-maker directing the American half. He spent several months working on the script with Ryuzo Kikushima and Hideo Oguni, but very soon the project began to unravel. The director of the American sequences turned out not to be David Lean, as originally planned, but American Richard Fleischer. The budget was also cut, and the screen time allocated for the Japanese segment would now be no longer than 90 minutes\u2014a major problem, considering that Kurosawa's script ran over four hours. After numerous revisions with the direct involvement of Darryl Zanuck, a more or less finalized cut screenplay was agreed upon in May 1968.\nShooting began in early December, but Kurosawa would last only a little over three weeks as director. He struggled to work with an unfamiliar crew and the requirements of a Hollywood production, while his working methods puzzled his American producers, who ultimately concluded that the director must be mentally ill. Kurosawa was examined at Kyoto University Hospital by a neuropsychologist, Dr. Murakami, whose diagnosis was forwarded to Darryl Zanuck and Richard Zanuck at Fox studios indicating a diagnosis of neurasthenia stating that, \"He is suffering from disturbance of sleep, agitated with feelings of anxiety and in manic excitement caused by the above mentioned illness. It is necessary for him to have rest and medical treatment for more than two months.\" On Christmas Eve 1968, the Americans announced that Kurosawa had left the production due to \"fatigue\", effectively firing him. He was ultimately replaced, for the film's Japanese sequences, with two directors, Kinji Fukasaku and Toshio Masuda.\n\"Tora! Tora! Tora!\", finally released to unenthusiastic reviews in September 1970, was, as Donald Richie put it, an \"almost unmitigated tragedy\" in Kurosawa's career. He had spent years of his life on a logistically nightmarish project to which he ultimately did not contribute a foot of film shot by himself. (He had his name removed from the credits, though the script used for the Japanese half was still his and his co-writers'.) He became estranged from his longtime collaborator, writer Ryuzo Kikushima, and never worked with him again. The project had inadvertently exposed corruption in his own production company (a situation reminiscent of his own movie, \"The Bad Sleep Well\"). His very sanity had been called into question. Worst of all, the Japanese film industry\u2014and perhaps Kurosawa himself\u2014began to suspect that he would never make another film.\nA difficult decade (1969\u20131977).\nKnowing that his reputation was at stake following the much publicised \"Tora! Tora! Tora!\" debacle, Kurosawa moved quickly to a new project to prove he was still viable. To his aid came friends and famed directors Keisuke Kinoshita, Masaki Kobayashi and Kon Ichikawa, who together with Kurosawa established in July 1969 a production company called the Club of the Four Knights (Yonki no kai). Although the plan was for the four directors to create a film each, it has been suggested that the real motivation for the other three directors was to make it easier for Kurosawa to successfully complete a film and therefore find his way back into the business.\nThe first project proposed and worked on was a period film to be called \"Dora-heita\", but when this was deemed too expensive, attention shifted to \"Dodesukaden\", an adaptation of yet another Sh\u016bgor\u014d Yamamoto work, again about the poor and destitute. The film was shot quickly (by Kurosawa's standards) in about nine weeks, with Kurosawa determined to show he was still capable of working quickly and efficiently within a limited budget. For his first work in color, the dynamic editing and complex compositions of his earlier pictures were set aside, with the artist focusing on the creation of a bold, almost surreal palette of primary colors, in order to reveal the toxic environment in which the characters live. It was released in Japan in October 1970, but though a minor critical success, it was greeted with audience indifference. The picture lost money and caused the Club of the Four Knights to dissolve. Initial reception abroad was somewhat more favorable, but \"Dodesukaden\" has since been typically considered an interesting experiment not comparable to the director's best work.\nAfter struggling through the production of \"Dodesukaden\", Kurosawa turned to television work the following year for the only time in his career with \"Song of the Horse\", a documentary about thoroughbred race horses. It featured a voice-over narrated by a fictional man and a child (voiced by the same actors as the beggar and his son in \"Dodesukaden\"). It is the only documentary in Kurosawa's filmography; the small crew included his frequent collaborator Masaru Sato, who composed the music. \"Song of the Horse\" is also unique in Kurosawa's oeuvre in that it includes an editor's credit, suggesting that it is the only Kurosawa film that he did not cut himself.\nUnable to secure funding for further work and allegedly having health problems, Kurosawa apparently reached the breaking point: on December 22, 1971, he slit his wrists and throat multiple times. The suicide attempt proved unsuccessful and the director's health recovered fairly quickly, with Kurosawa now taking refuge in domestic life, uncertain if he would ever direct another film.\nIn early 1973, the Soviet studio Mosfilm approached the film-maker to ask if he would be interested in working with them. Kurosawa proposed an adaptation of Russian explorer Vladimir Arsenyev's autobiographical work \"Dersu Uzala\". The book, about a Goldi hunter who lives in harmony with nature until destroyed by encroaching civilization, was one that he had wanted to make since the 1930s. In December 1973, the 63-year-old Kurosawa set off for the Soviet Union with four of his closest aides, beginning a year-and-a-half stay in the country. Shooting began in May 1974 in Siberia, with filming in exceedingly harsh natural conditions proving very difficult and demanding. The picture wrapped in April 1975, with a thoroughly exhausted and homesick Kurosawa returning to Japan and his family in June. \"Dersu Uzala\" had its world premiere in Japan on August 2, 1975 and did well at the box office. While critical reception in Japan was muted, the film was better reviewed abroad, winning the Golden Prize at the 9th Moscow International Film Festival, as well as an Academy Award for Best Foreign Language Film. Today, critics remain divided over the film: some see it as an example of Kurosawa's alleged artistic decline, while others count it among his finest works.\nAlthough proposals for television projects were submitted to him, he had no interest in working outside the film world. Nevertheless, the hard-drinking director did agree to appear in a series of television ads for Suntory whiskey, which aired in 1976. While fearing that he might never be able to make another film, the director nevertheless continued working on various projects, writing scripts and creating detailed illustrations, intending to leave behind a visual record of his plans in case he would never be able to film his stories.\nTwo epics (1978\u20131986).\nIn 1977, George Lucas released \"Star Wars\", a wildly successful science fiction film influenced by Kurosawa's \"The Hidden Fortress\". Lucas, like many other New Hollywood directors, revered Kurosawa and considered him a role model and was shocked to discover that the Japanese film-maker was unable to secure financing for any new work. The two met in San Francisco in July 1978 to discuss the project Kurosawa considered most financially viable: , the epic story of a thief hired as the double of a medieval Japanese lord of a great clan. Lucas, enthralled by the screenplay and Kurosawa's illustrations, leveraged his influence over 20th Century Fox to coerce the studio that had fired Kurosawa just ten years earlier to produce , then recruited fellow fan Francis Ford Coppola as co-producer.\nProduction began the following April, with Kurosawa in high spirits. Shooting lasted from June 1979 through March 1980 and was plagued with problems, not the least of which was the firing of the original lead actor, Shintaro Katsu\u2014known for portraying the popular character Zatoichi\u2014due to an incident in which the actor insisted, against the director's wishes, on videotaping his own performance. (He was replaced by Tatsuya Nakadai, in his first of two consecutive leading roles in a Kurosawa movie.) The film was completed only a few weeks behind schedule and opened in Tokyo in April 1980. It quickly became a massive hit in Japan. The film was also a critical and box office success abroad, winning the coveted at the 1980 Cannes Film Festival in May, though some critics, then and now, have faulted the film for its alleged coldness. Kurosawa spent much of the rest of the year in Europe and America promoting , collecting awards and accolades and exhibiting as art the drawings he had made to serve as storyboards for the film.\nThe international success of allowed Kurosawa to proceed with his next project, , another epic in a similar vein. The script, partly based on Shakespeare's \"King Lear\", depicted a ruthless, bloodthirsty \"daimy\u014d\" (warlord), played by Tatsuya Nakadai, who, after foolishly banishing his one loyal son, surrenders his kingdom to his other two sons, who then betray him, thus plunging the entire kingdom into war. As Japanese studios still felt wary about producing another film that would rank among the most expensive ever made in the country, international help was again needed. This time it came from French producer Serge Silberman, who had produced Luis Bu\u00f1uel's final movies. Filming did not begin until December 1983 and lasted more than a year.\nIn January 1985, production of was halted as Kurosawa's 64-year-old wife Y\u014dko fell ill. She died on February 1. Kurosawa returned to finish his film and premiered at the Tokyo Film Festival on May 31, with a wide release the next day. The film was a moderate financial success in Japan, but a larger one abroad and, as he had done with , Kurosawa embarked on a trip to Europe and America, where he attended the film's premieres in September and October.\n won several awards in Japan, but was not quite as honored there as many of the director's best films of the 1950s and 1960s had been. The film world was surprised, however, when Japan passed over the selection of in favor of another film as its official entry to compete for an Oscar nomination in the Best Foreign Film category, which was ultimately rejected for competition at the 58th Academy Awards. Both the producer and Kurosawa himself attributed the failure to even submit for competition to a misunderstanding: because of the academy's arcane rules, no one was sure whether qualified as a \"Japanese\" film, a \"French\" film (due to its financing), or both, so it was not submitted at all. In response to what at least appeared to be a blatant snub by his own countrymen, the director Sidney Lumet led a successful campaign to have Kurosawa receive an Oscar nomination for Best Director that year (Sydney Pollack ultimately won the award for directing \"Out of Africa\"). s costume designer, Emi Wada, won the movie's only Oscar.\n and , particularly the latter, are often considered to be among Kurosawa's finest works. After s release, Kurosawa would point to it as his best film, a major change of attitude for the director who, when asked which of his works was his best, had always previously answered \"my next one\".\nFinal works and last years (1987\u20131998).\nFor his next movie, Kurosawa chose a subject very different from any that he had ever filmed before. While some of his previous pictures (for example, \"Drunken Angel\" and ) had included brief dream sequences, \"Dreams\" was to be entirely based upon the director's own dreams. Significantly, for the first time in over forty years, Kurosawa, for this deeply personal project, wrote the screenplay alone. Although its estimated budget was lower than the films immediately preceding it, Japanese studios were still unwilling to back one of his productions, so Kurosawa turned to another famous American fan, Steven Spielberg, who convinced Warner Bros. to buy the international rights to the completed film. This made it easier for Kurosawa's son, Hisao, as co-producer and soon-to-be head of Kurosawa Production, to negotiate a loan in Japan that would cover the film's production costs. Shooting took more than eight months to complete, and \"Dreams\" premiered at Cannes in May 1990 to a polite but muted reception, similar to the reaction the picture would generate elsewhere in the world. In 1990, he accepted the Academy Award for Lifetime Achievement. In his acceptance speech, he famously said \"I'm a little worried because I don't feel that I understand cinema yet.\" At the time, Bob Thomas of \"The Daily Spectrum\" noted that Kurosawa was \"considered by many critics as the greatest living filmmaker.\"\nKurosawa now turned to a more conventional story with \"Rhapsody in August\"\u2014the director's first film fully produced in Japan since \"Dodeskaden\" over twenty years before\u2014which explored the scars of the nuclear bombing which destroyed Nagasaki at the very end of World War II. It was adapted from a Kiyoko Murata novel, but the film's references to the Nagasaki bombing came from the director rather than from the book. This was his only movie to include a role for an American movie star: Richard Gere, who plays a small role as the nephew of the elderly heroine. Shooting took place in early 1991, with the film opening on May 25 that year to a largely negative critical reaction, especially in the United States, where the director was accused of promulgating na\u00efvely anti-American sentiments, though Kurosawa rejected these accusations.\nKurosawa wasted no time moving onto his next project: \"Madadayo\", or \"Not Yet\". Based on autobiographical essays by Hyakken Uchida, the film follows the life of a Japanese professor of German through the Second World War and beyond. The narrative centers on yearly birthday celebrations with his former students, during which the protagonist declares his unwillingness to die just yet\u2014a theme that was becoming increasingly relevant for the film's 81-year-old creator. Filming began in February 1992 and wrapped by the end of September. Its release on April 17, 1993, was greeted by an even more disappointed reaction than had been the case with his two preceding works.\nKurosawa nevertheless continued to work. He wrote the original screenplays \"The Sea Is Watching\" in 1993 and \"After the Rain\" in 1995. While putting finishing touches on the latter work in 1995, Kurosawa slipped and broke the base of his spine. Following the accident, he would use a wheelchair for the rest of his life, putting an end to any hopes of him directing another film. His longtime wish\u2014to die on the set while shooting a movie\u2014was never to be fulfilled.\nAfter his accident, Kurosawa's health began to deteriorate. While his mind remained sharp and lively, his body was giving up, and for the last half-year of his life the director was largely confined to bed, listening to music and watching television at home. On September 6, 1998, Kurosawa died of a stroke in Setagaya, Tokyo, at the age of 88. At the time of his death, Kurosawa had two children, his son Hisao Kurosawa (who married Hiroko Hayashi) and his daughter Kazuko Kurosawa (who married Harayuki Kato), along with several grandchildren. One of Kazuko Kurosawa's children, Takayuki Kato, became a supporting actor in two films posthumously developed from screenplays written by Kurosawa, Takashi Koizumi's \"After the Rain\" (1999) and Kei Kumai's \"The Sea Is Watching\" (2002).\nFilmography.\nAlthough Kurosawa is primarily known as a filmmaker, he also worked in theater and television and wrote books. A detailed list, including his complete filmography, can be found in the list of works by Akira Kurosawa.\nStyle, themes and techniques.\nKurosawa displayed a bold, dynamic style, strongly influenced by Western cinema yet distinct from it; he was involved with all aspects of film production. He was a gifted screenwriter and worked closely with his co-writers from the film's development onward to ensure a high-quality script, which he considered the firm foundation of a good film. He frequently served as editor of his own films. His team, known as the , which included the cinematographer Asakazu Nakai, the production assistant Teruyo Nogami and the actor Takashi Shimura, was notable for its loyalty and dependability.\nKurosawa's style is marked by a number of devices and techniques. In his films of the 1940s and 1950s, he frequently employs the \"axial cut\", in which the camera moves toward or away from the subject through a series of matched jump cuts rather than tracking shots or dissolves. Another stylistic trait is \"cut on motion\", which displays the motion on the screen in two or more shots instead of one uninterrupted one. A form of cinematic punctuation strongly identified with Kurosawa is the wipe, an effect created through an optical printer: a line or bar appears to move across the screen, wiping away the end of a scene and revealing the first image of the next. As a transitional device, it is used as a substitute for the straight cut or the dissolve; in his mature work, the wipe became Kurosawa's signature.\nIn the film's soundtrack, Kurosawa favored the sound-image counterpoint, in which the music or sound effects appeared to comment ironically on the image rather than emphasizing it. Teruyo Nogami's memoir gives several such examples from \"Drunken Angel\" and \"Stray Dog\". Kurosawa was also involved with several of Japan's outstanding contemporary composers, including Fumio Hayasaka and T\u014dru Takemitsu.\nKurosawa employed a number of recurring themes in his films: the master-disciple relationship between a usually older mentor and one or more novices, which often involves spiritual as well as technical mastery and self-mastery; the heroic champion, the exceptional individual who emerges from the mass of people to produce something or right some wrong; the depiction of extremes of weather as both dramatic devices and symbols of human passion; and the recurrence of cycles of savage violence within history. According to Stephen Prince, the last theme, which he calls, \"the countertradition to the committed, heroic mode of Kurosawa's cinema,\" began with \"Throne of Blood\" (1957) and recurred in the films of the 1980s.\nLegacy and cultural impact.\nKurosawa is often cited as one of the greatest filmmakers of all time. In 1999, he was named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by \"AsianWeek\" magazine and CNN, cited as \"one of the [five] people who contributed most to the betterment of Asia in the past 100 years\". Kurosawa was ranked third in the directors' poll and fifth in the critics' poll in \"Sight &amp; Sound\"'s 2002 list of the greatest directors of all time. In commemoration of the 100th anniversary of Kurosawa's birth in 2010, a project called AK100 was launched in 2008. The AK100 Project aims to \"expose young people who are the representatives of the next generation, and all people everywhere, to the light and spirit of Akira Kurosawa and the wonderful world he created\".\nReputation among filmmakers.\nMany filmmakers have been influenced by Kurosawa's work. Ingmar Bergman called his own film \"The Virgin Spring\" a \"touristic... lousy imitation of Kurosawa\" and added, \"At that time my admiration for the Japanese cinema was at its height. I was almost a samurai myself!\" Federico Fellini considered Kurosawa to be \"the greatest living example of all that an author of the cinema should be\". Steven Spielberg cited Kurosawa's cinematic vision as shaping his own. Satyajit Ray, who was posthumously awarded the \"Akira Kurosawa Award for Lifetime Achievement in Directing\" at the San Francisco International Film Festival in 1992, had said earlier of \"Rashomon\": Ray described him as \"one of the giants of cinema.\" \nRoman Polanski considered Kurosawa to be among the three film-makers he favored most, along with Fellini and Orson Welles, and picked \"Seven Samurai\", \"Throne of Blood\" and \"The Hidden Fortress\" for praise. Bernardo Bertolucci considered Kurosawa's influence to be seminal: \"Kurosawa's movies and \"La Dolce Vita\" of Fellini are the things that pushed me, sucked me into being a film director.\" Andrei Tarkovsky cited Kurosawa as one of his favorites and named \"Seven Samurai\" as one of his ten favorite films. Sidney Lumet called Kurosawa the \"Beethoven of movie directors\". Werner Herzog reflected on film-makers with whom he feels kinship and the movies that he admires:\nAccording to an assistant, Stanley Kubrick considered Kurosawa to be \"one of the great film directors\" and spoke of him \"consistently and admiringly\", to the point that a letter from him \"meant more than any Oscar\" and caused him to agonize for months over drafting a reply. Robert Altman claimed that, upon first seeing \"Rashomon\", he was so impressed by the sequence of frames of the sun that he began to shoot the same sequences in his work the very next day. George Lucas cited \"The Hidden Fortress\" as the main inspiration for \"Star Wars\". He also cited other films of Kurosawa as his favorites including \"Seven Samurai\", \"Yojimbo\", and . He also said, \"I had never seen anything that powerful or cinematographic. The emotions were so strong that it didn't matter that I did not understand the culture or the traditions. From that moment on, Kurosawa's films have served as one of my strongest sources of creative inspiration.\" Wes Anderson's animated film \"Isle of Dogs\" is partially inspired by Kurosawa's filming techniques. At the 64th Sydney Film Festival, there was a retrospective of Akira Kurosawa where films of his were screened to remember the great legacy he has created from his work. Zack Snyder cited him as one of his influences for his Netflix film \"Rebel Moon\".\nCriticism.\nKenji Mizoguchi, the acclaimed director of \"Ugetsu\" (1953) and \"Sansho the Bailiff\" (1954), was eleven years Kurosawa's senior. After the mid-1950s, some critics of the French New Wave began to favor Mizoguchi over Kurosawa. New Wave critic and film-maker Jacques Rivette, in particular, thought Mizoguchi to be the only Japanese director whose work was at once entirely Japanese and truly universal; Kurosawa, by contrast, was thought to be more influenced by Western cinema and culture, a view that has been disputed.\nIn Japan, some critics and filmmakers considered Kurosawa to be elitist. They viewed him to center his effort and attention on exceptional or heroic characters. In her DVD commentary on \"Seven Samurai\", Joan Mellen argued that certain shots of the samurai characters Kambei and Kyuzo, which show Kurosawa to have accorded higher status or validity to them, constitutes evidence for this point of view. These Japanese critics argued that Kurosawa was not sufficiently progressive because the peasants were unable to find leaders from within their ranks. In an interview with Mellen, Kurosawa defended himself, saying, \nFrom the early 1950s, Kurosawa was also charged with catering to Western tastes due to his popularity in Europe and America. In the 1970s, the politically engaged, left-wing director Nagisa \u014cshima, who was noted for his critical reaction to Kurosawa's work, accused Kurosawa of pandering to Western beliefs and ideologies. Author Audie Block, however, assessed Kurosawa to have never played up to a non-Japanese viewing public and to have denounced those directors who did.\nPosthumous screenplays.\nFollowing Kurosawa's death, several posthumous works based on his unfilmed screenplays have been produced. \"After the Rain\", directed by Takashi Koizumi, was released in 1999, and \"The Sea Is Watching\", directed by Kei Kumai, premiered in 2002. A script created by the Yonki no Kai (\"Club of the Four Knights\") (Kurosawa, Keisuke Kinoshita, Masaki Kobayashi, and Kon Ichikawa), around the time that \"Dodeskaden\" was made, finally was filmed and released (in 2000) as \"Dora-heita\", by the only surviving founding member of the club, Kon Ichikawa. Huayi Brothers Media and CKF Pictures in China announced in 2017 plans to produce a film of Kurosawa's posthumous screenplay of \"The Masque of the Red Death\" by Edgar Allan Poe for 2020, to be entitled \"The Mask of the Black Death\". Patrick Frater writing for \"Variety\" magazine in May 2017 stated that another two unfinished films by Kurosawa were planned, with \"Silvering Spear\" to start filming in 2018.\nKurosawa Production Company.\nIn September 2011, it was reported that remake rights to most of Kurosawa's movies and unproduced screenplays were assigned by the Akira Kurosawa 100 Project to the L.A.-based company Splendent. Splendent's chief Sakiko Yamada, stated that he aimed to \"help contemporary film-makers introduce a new generation of moviegoers to these unforgettable stories\".\nKurosawa Production Co., established in 1959, continues to oversee many of the aspects of Kurosawa's legacy. The director's son, Hisao Kurosawa, is the current head of the company. Its American subsidiary, Kurosawa Enterprises, is located in Los Angeles. Rights to Kurosawa's works were then held by Kurosawa Production and the film studios under which he worked, most notably Toho. These rights were then assigned to the Akira Kurosawa 100 Project before being reassigned in 2011 to the L.A. based company Splendent. Kurosawa Production works closely with the Akira Kurosawa Foundation, established in December 2003 and also run by Hisao Kurosawa. The foundation organizes an annual short film competition and spearheads Kurosawa-related projects, including a recently shelved one to build a memorial museum for the director.\nFilm studios.\nIn 1981, the Kurosawa Film Studio was opened in Yokohama; two additional locations have since been launched in Japan. A large collection of archive material, including scanned screenplays, photos and news articles, has been made available through the Akira Kurosawa Digital Archive, a Japanese proprietary website maintained by Ryukoku University Digital Archives Research Center in collaboration with Kurosawa Production.\nAnaheim University Akira Kurosawa School of Film.\nAnaheim University in collaboration with Kurosawa Production and the Kurosawa family established the Anaheim University Akira Kurosawa School of Film in spring 2009. The Anaheim University Akira Kurosawa School of Film offers an Online Master of Fine Arts (MFA) in Digital Filmmaking supported by many of the world's greatest filmmakers.\nKurosawa Restaurant Group.\nKurosawa was known to be a connoisseur of Japanese cuisine and as such, the Kurosawa family foundation established the Kurosawa Restaurant Group after his passing in 1999, opening four restaurants in the Tokyo area bearing the family name. \"Nagatacho Kurosawa\" specializing in Shabu-shabu, \"Teppanyaki Kurosawa\" in Tsukiji specializing in Teppanyaki, \"Keyaki Kurosawa\" in Nishi-Azabu specializing in soba, and \"Udon Kurosawa\" specializing in udon in Roppongi. All four locations were designed to evoke the Meiji era machiya of Kurosawa's youth and feature memorabilia of Kurosawa's career. As of 2023, only the Tsukiji location is currently still operating. A number of entrepreneurs around the world have also opened restaurants and businesses in honor of Kurosawa without any connection to Akira or the estate.\nAwards and honours.\nTwo film awards have also been named in Kurosawa's honour. The Akira Kurosawa Award for Lifetime Achievement in Film Directing is awarded during the San Francisco International Film Festival, while the Akira Kurosawa Award is given during the Tokyo International Film Festival.\nKurosawa has also been given a number of state honours, including being named as an officer of the French L\u00e9gion d'honneur in 1984 and a Knight Grand Cross of the Order of Merit of the Italian Republic in 1986, and he was the first filmmaker to receive the Order of Culture from his native Japan in 1985. Posthumously, he was recognized with the Junior Third Court Rank, which would be the modern equivalent of a noble title under the Kazoku aristocracy.\nDocumentaries.\nA significant number of short and full-length documentaries concerning the life and work of Kurosawa were made both during his artistic heyday and after his death. \"AK\", by French video essay director Chris Marker, was filmed while Kurosawa was working on ; however, the documentary is more concerned about Kurosawa's distant yet polite personality than on the making of the film. Other documentaries concerning Kurosawa's life and works produced posthumously include:"}
{"id": "873", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=873", "title": "Ancient civilization", "text": ""}
{"id": "874", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=874", "title": "Ancient Egypt", "text": "Ancient Egypt was a civilization of ancient Northeast Africa. It was concentrated along the lower reaches of the Nile River, situated within the contemporary territory of modern-day Egypt. Ancient Egyptian civilization followed prehistoric Egypt and coalesced around 3100BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under pharaoh or king Menes (often identified with Narmer). The history of ancient Egypt unfolded as a series of stable kingdoms interspersed by periods of relative instability known as \"Intermediate Periods\". The various kingdoms fall into one of three categories: the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age, or the New Kingdom of the Late Bronze Age.\nAncient Egypt reached the pinnacle of its power during the New Kingdom, ruling much of Nubia and a sizable portion of the Levant. After this period, it entered an era of slow decline. During the course of its history, ancient Egypt was invaded or conquered by a number of foreign powers, including the Hyksos, the Nubians, the Assyrians, the Achaemenid Persians, and the Macedonians under Alexander the Great. The Greek Ptolemaic Kingdom, formed in the aftermath of Alexander's death, ruled until 30BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province. Egypt remained under Roman control until 642 AD, when it was conquered by the Rashidun Caliphate.\nThe success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River valley for agriculture. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which supported a more dense population, and social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.\nThe many achievements of the ancient Egyptians include the quarrying, surveying, and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems, and agricultural production techniques, the first known planked boats, Egyptian faience and glass technology, new forms of literature, and the earliest known peace treaty, made with the Hittites. Ancient Egypt has left a lasting legacy. Its art and architecture were widely copied, and its antiquities were carried off to be studied, admired or coveted in the far corners of the world. Its monumental ruins have inspired the imaginations of travelers and writers for millennia. A newfound respect for antiquities and excavations in the early modern period by Europeans and Egyptians has led to the scientific investigation of Egyptian civilization and a greater appreciation of its cultural legacy.\nHistory.\nThe Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization.\nPredynastic period.\nIn Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs, and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.\nBy about 5500\u00a0BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badarian culture, which probably originated in the Western Desert; it was known for its high-quality ceramics, stone tools, and its use of copper.\nThe Badari was followed by the Naqada culture: the Naqada I (Amratian), the Naqada II (Gerzeh), and Naqada III (Semainean). These brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. Mutual trade with the Levant was established during Naqada II (); this period was also the beginning of trade with Mesopotamia, which continued into the early dynastic period and beyond. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen, and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east.\nThe Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.\nEarly Dynastic Period ( BC).\nThe Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilization of Mesopotamia and of ancient Elam. The third-centuryBC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named \"Meni\" (or Menes in Greek), who was believed to have united the two kingdoms of Upper and Lower Egypt.\nThe transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial \"Narmer Palette,\" in a symbolic act of unification. In the Early Dynastic Period, which began about 3000BC, the first of the Dynastic kings solidified control over lower Egypt by establishing a capital at Memphis, from which he could control the labor force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified king after his death. The strong institution of kingship developed by the kings served to legitimize state control over the land, labor, and resources that were essential to the survival and growth of ancient Egyptian civilization.\nOld Kingdom (2686\u20132181 BC).\nMajor advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population growth, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, and drafted peasants to work on construction projects. \nWith the rising importance of central administration in Egypt, a new class of educated scribes and officials arose who were granted estates by the king in payment for their services. Kings also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.\nFirst Intermediate Period (2181\u20132055 BC).\nAfter Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. The ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer\u2014which was demonstrated by larger and better burials among all social classes.\nFree from their loyalties to the king, local rulers began competing with each other for territorial control and political power. By 2160BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands. They inaugurated a period of economic and cultural renaissance known as the Middle Kingdom.\nMiddle Kingdom (2134\u20131690 BC).\nThe kings of the Middle Kingdom restored the country's stability, which saw a resurgence of art and monumental building projects, and a new flourishing of literature. Mentuhotep II and his Eleventh Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming the kingship at the beginning of the Twelfth Dynasty around 1985BC, shifted the kingdom's capital to the city of Itjtawy, located in Faiyum. From Itjtawy, the kings of the Twelfth Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia that was rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the \"Walls of the Ruler\", to defend against foreign attack.\nWith the kings having secured the country militarily and politically and with vast agricultural and mineral wealth at their disposal, the nation's population, arts, and religion flourished. The Middle Kingdom displayed an increase in expressions of personal piety toward the gods. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style. The relief and portrait sculpture of the period captured subtle, individual details that reached new heights of technical sophistication.\nSecond Intermediate Period (1674\u20131549 BC) and the Hyksos.\nAround 1785BC, as the power of the Middle Kingdom kings weakened, a Western Asian people called the Hyksos, who had already settled in the Delta, seized control of Egypt and established their capital at Avaris, forcing the former central government to retreat to Thebes. The king was treated as a vassal and expected to pay tribute. The Hyksos ('foreign rulers') retained Egyptian models of government and identified as kings, thereby integrating Egyptian elements into their culture.\nAfter retreating south, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555BC. Ahmose I waged a series of campaigns that permanently eradicated the Hyksos' presence in Egypt. He is considered the founder of the Eighteenth Dynasty, and the military became a central priority for his successors, who sought to expand Egypt's borders and attempted to gain mastery of the Near East.\nNew Kingdom (1549\u20131069 BC).\nThe New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen.\nBetween their reigns, Hatshepsut, a queen who established herself as pharaoh, launched many building projects, including the restoration of temples damaged by the Hyksos, and sent trading expeditions to Punt and the Sinai. When Tuthmosis III died in 1425BC, Egypt had an empire extending from Niya in north west Syria to the Fourth Cataract of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood.\nThe New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The Karnak temple is the largest Egyptian temple ever built.\nAround 1350BC, the stability of the New Kingdom was threatened when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities, and moved the capital to the new city of Akhetaten (modern-day Amarna). He was devoted to his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned and the traditional religious order restored. The subsequent pharaohs, Tutankhamun, Ay, and Horemheb, worked to erase all mention of Akhenaten's heresy, now known as the Amarna Period.\nAround 1279BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258BC.\nEgypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a conjectured confederation of seafarers from the Aegean Sea. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Canaan, much of it falling to the Assyrians. The effects of external threats were exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth, and their expanded power splintered the country during the Third Intermediate Period.\nThird Intermediate Period (1069\u2013653 BC).\nFollowing the death of Ramesses XI in 1078BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Libyans had been settling in the western delta, and chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945BC, founding the so-called Libyan or Bubastite dynasty that would rule for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. Libyan control began to erode as a rival dynasty in the delta arose in Leontopolis, and Kushites threatened from the south.\nAround 727BC the Kushite king Piye invaded northward, seizing control of Thebes and eventually the Delta, which established the 25th Dynasty. During the 25th Dynasty, Pharaoh Taharqa created an empire nearly as large as the New Kingdom's. Twenty-fifth Dynasty pharaohs built, or restored, temples and monuments throughout the Nile valley, including at Memphis, Karnak, Kawa, and Jebel Barkal. During this period, the Nile valley saw the first widespread construction of pyramids (many in modern Sudan) since the Middle Kingdom.\nEgypt's far-reaching prestige declined considerably toward the end of the Third Intermediate Period. Its foreign allies had fallen into the Assyrian sphere of influence, and by 700BC war between the two states became inevitable. Between 671 and 667BC the Assyrians began the Assyrian conquest of Egypt. The reigns of both Taharqa and his successor, Tanutamun, were filled with frequent conflict with the Assyrians. Ultimately, the Assyrians pushed the Kushites back into Nubia, occupied Memphis, and sacked the temples of Thebes.\nLate Period (653\u2013332 BC).\nThe Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653BC, the Saite king Psamtik I was able to oust the Assyrians with the help of Greek mercenaries, who were recruited to form Egypt's first navy. Greek influence expanded greatly as the city-state of Naucratis became the home of Greeks in the Nile Delta. The Saite kings based in the new capital of Sais witnessed a brief but spirited resurgence in the economy and culture, but in 525BC, the Persian Empire, led by Cambyses II, began its conquest of Egypt, eventually defeating the pharaoh Psamtik III at the Battle of Pelusium. Cambyses II then assumed the formal title of pharaoh, but ruled Egypt from Iran, leaving Egypt under the control of a satrap. A few revolts against the Persians marked the 5th centuryBC, but Egypt was never able to overthrow the Persians until the end of the century.\nFollowing its annexation by Persia, Egypt was joined with Cyprus and Phoenicia in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh Dynasty, ended in 402BC, when Egypt regained independence under a series of native dynasties. The last of these dynasties, the Thirtieth, proved to be the last native royal house of ancient Egypt, ending with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343BC, but shortly after, in 332BC, the Persian ruler Mazaces handed Egypt over to Alexander the Great without a fight.\nPtolemaic period (332\u201330 BC).\nIn 332BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic Kingdom, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a centre of learning and culture that included the famous Library of Alexandria and the Mouseion. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city\u2014as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.\nHellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and frequent mob violence in Alexandria. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful opponents from the Near East made this situation unstable, leading Rome to send forces to secure the country as a province of its empire.\nRoman period (30 BC \u2013 AD 641).\nEgypt became a province of the Roman Empire in 30BC, following the defeat of Mark Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.\nAlthough the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed to native Egyptians.\nFrom the mid-first century AD, Christianity took root in Egypt and it was originally seen as another cult that could be accepted. However, it was an uncompromising religion that sought to win converts from the pagan Egyptian and Greco-Roman religions and threatened popular religious traditions. This led to the persecution of converts to Christianity, culminating in the great purges of Diocletian starting in 303, but eventually Christianity won out. In 391, the Christian emperor Theodosius introduced legislation that banned pagan rites and closed temples. Alexandria became the scene of great anti-pagan riots with public and private religious imagery destroyed. As a consequence, Egypt's native religious culture was continually in decline. While the native population continued to speak their language, the ability to read hieroglyphic writing slowly disappeared as the role of the Egyptian temple priests and priestesses diminished. The temples themselves were sometimes converted to churches or abandoned to the desert.\nGovernment and economy.\nAdministration and commerce.\nThe pharaoh was the absolute monarch of the country and, at least in theory, wielded complete control of the land and its resources. The king was the supreme military commander and head of the government, who relied on a bureaucracy of officials to manage his affairs. In charge of the administration was his second in command, the vizier, who acted as the king's representative and coordinated land surveys, the treasury, building projects, the legal system, and the archives. At a regional level, the country was divided into as many as 42 administrative regions called nomes each governed by a nomarch, who was accountable to the vizier for his jurisdiction. The temples formed the backbone of the economy. Not only were they places of worship, but were also responsible for collecting and storing the kingdom's wealth in a system of granaries and treasuries administered by overseers, who redistributed grain and goods.\nMuch of the economy was centrally organized and strictly controlled. Although the ancient Egyptians did not use coinage until the Late period, they did use a type of money-barter system, with standard sacks of grain and the \"deben\", a weight of roughly of copper or silver, forming a common denominator. Workers were paid in grain; a simple laborer might earn \u00a0sacks (200\u00a0kg or 400\u00a0lb) of grain per month, while a foreman might earn \u00a0sacks (250\u00a0kg or 550\u00a0lb). Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140deben. Grain could be traded for other goods, according to the fixed price list. During the fifth centuryBC coined money was introduced into Egypt from abroad. At first the coins were used as standardized pieces of precious metal rather than true money, but in the following centuries international traders came to rely on coinage.\nSocial status.\nEgyptian society was highly stratified, and social status was expressly displayed. Farmers made up the bulk of the population, but agricultural produce was owned directly by the state, temple, or noble family that owned the land. Farmers were also subject to a labor tax and were required to work on irrigation or construction projects in a corv\u00e9e system. Artists and craftsmen were of higher status than farmers, but they were also under state control, working in the shops attached to the temples and paid directly from the state treasury. Scribes and officials formed the upper class in ancient Egypt, known as the \"white kilt class\" in reference to the bleached linen garments that served as a mark of their rank. The upper class prominently displayed their social status in art and literature. Below the nobility were the priests, physicians, and engineers with specialized training in their field. It is unclear whether slavery as understood today existed in ancient Egypt; there is difference of opinions among authors.\nThe ancient Egyptians viewed men and women, including people from all social classes, as essentially equal under the law, and even the lowliest peasant was entitled to petition the vizier and his court for redress. Although slaves were mostly used as indentured servants, they were able to buy and sell their servitude, work their way to freedom or nobility, and were usually treated by doctors in the workplace. Both men and women had the right to own and sell property, make contracts, marry and divorce, receive inheritance, and pursue legal disputes in court. Married couples could own property jointly and protect themselves from divorce by agreeing to marriage contracts, which stipulated the financial obligations of the husband to his wife and children should the marriage end. Compared with their counterparts in ancient Greece, Rome, and even more modern places around the world, ancient Egyptian women had a greater range of personal choices, legal rights, and opportunities for achievement. Women such as Hatshepsut and Cleopatra VII even became pharaohs, while others wielded power as Divine Wives of Amun. Despite these freedoms, ancient Egyptian women did not often take part in official roles in the administration, aside from the royal high priestesses, apparently served only secondary roles in the temples (not much data for many dynasties), and were not so probably to be as educated as men.\nLegal system.\nThe head of the legal system was officially the pharaoh, who was responsible for enacting laws, delivering justice, and maintaining law and order, a concept the ancient Egyptians referred to as Ma'at. Although no legal codes from ancient Egypt survive, court documents show that Egyptian law was based on a common-sense view of right and wrong that emphasized reaching agreements and resolving conflicts rather than strictly adhering to a complicated set of statutes. Local councils of elders, known as \"Kenbet\" in the New Kingdom, were responsible for ruling in court cases involving small claims and minor disputes. More serious cases involving murder, major land transactions, and tomb robbery were referred to the \"Great Kenbet\", over which the vizier or pharaoh presided. Plaintiffs and defendants were expected to represent themselves and were required to swear an oath that they had told the truth. In some cases, the state took on both the role of prosecutor and judge, and it could torture the accused with beatings to obtain a confession and the names of any co-conspirators. Whether the charges were trivial or serious, court scribes documented the complaint, testimony, and verdict of the case for future reference.\nPunishment for minor crimes involved either imposition of fines, beatings, facial mutilation, or exile, depending on the severity of the offense. Serious crimes such as murder and tomb robbery were punished by execution, carried out by decapitation, drowning, or impaling the criminal on a stake. Punishment could also be extended to the criminal's family. Beginning in the New Kingdom, oracles played a major role in the legal system, dispensing justice in both civil and criminal cases. The procedure was to ask the god a \"yes\" or \"no\" question concerning the right or wrong of an issue. The god, carried by a number of priests, rendered judgement by choosing one or the other, moving forward or backward, or pointing to one of the answers written on a piece of papyrus or an ostracon.\nAgriculture.\nA combination of favorable geographical features contributed to the success of ancient Egyptian culture, the most important of which was the rich fertile soil resulting from annual inundations of the Nile River. The ancient Egyptians were thus able to produce an abundance of food, allowing the population to devote more time and resources to cultural, technological, and artistic pursuits. Land management was crucial in ancient Egypt because taxes were assessed based on the amount of land a person owned.\nFarming in Egypt was dependent on the cycle of the Nile River. The Egyptians recognized three seasons: \"Akhet\" (flooding), \"Peret\" (planting), and \"Shemu\" (harvesting). The flooding season lasted from June to September, depositing on the river's banks a layer of mineral-rich silt ideal for growing crops. After the floodwaters had receded, the growing season lasted from October to February. Farmers plowed and planted seeds in the fields, which were irrigated with ditches and canals. Egypt received little rainfall, so farmers relied on the Nile to water their crops. From March to May, farmers used sickles to harvest their crops, which were then threshed with a flail to separate the straw from the grain. Winnowing removed the chaff from the grain, and the grain was then ground into flour, brewed to make beer, or stored for later use.\nThe ancient Egyptians cultivated emmer and barley, and several other cereal grains, all of which were used to make the two main food staples of bread and beer. Flax plants, uprooted before they started flowering, were grown for the fibers of their stems. These fibers were split along their length and spun into thread, which was used to weave sheets of linen and to make clothing. Papyrus growing on the banks of the Nile River was used to make paper. Vegetables and fruits were grown in garden plots, close to habitations and on higher ground, and had to be watered by hand. Vegetables included leeks, garlic, melons, squashes, pulses, lettuce, and other crops, in addition to grapes that were made into wine.\nAnimals.\nThe Egyptians believed that a balanced relationship between people and animals was an essential element of the cosmic order; thus humans, animals and plants were believed to be members of a single whole. Animals, both domesticated and wild, were therefore a critical source of spirituality, companionship, and sustenance to the ancient Egyptians. Cattle were the most important livestock; the administration collected taxes on livestock in regular censuses, and the size of a herd reflected the prestige and importance of the estate or temple that owned them. In addition to cattle, the ancient Egyptians kept sheep, goats, and pigs. Poultry, such as ducks, geese, and pigeons, were captured in nets and bred on farms, where they were force-fed with dough to fatten them. The Nile provided a plentiful source of fish. Bees were also domesticated from at least the Old Kingdom, and provided both honey and wax.\nThe ancient Egyptians used donkeys and oxen as beasts of burden, and they were responsible for plowing the fields and trampling seed into the soil. The slaughter of a fattened ox was also a central part of an offering ritual. Horses were introduced by the Hyksos in the Second Intermediate Period. Camels, although known from the New Kingdom, were not used as beasts of burden until the Late Period. There is also evidence to suggest that elephants were briefly used in the Late Period but largely abandoned due to lack of grazing land. Cats, dogs, and monkeys were common family pets, while more exotic pets imported from the heart of Africa, such as Sub-Saharan African lions, were reserved for royalty. Herodotus observed that the Egyptians were the only people to keep their animals with them in their houses. During the Late Period, the worship of the gods in their animal form was extremely popular, such as the cat goddess Bastet and the ibis god Thoth, and these animals were kept in large numbers for the purpose of ritual sacrifice.\nNatural resources.\nEgypt is rich in building and decorative stone, copper and lead ores, gold, and semiprecious stones. These natural resources allowed the ancient Egyptians to build monuments, sculpt statues, make tools, and fashion jewelry. Embalmers used salts from the Wadi Natrun for mummification, which also provided the gypsum needed to make plaster. Ore-bearing rock formations were found in distant, inhospitable wadis in the Eastern Desert and the Sinai, requiring large, state-controlled expeditions to obtain natural resources found there. There were extensive gold mines in Nubia, and one of the first maps known is of a gold mine in this region. The Wadi Hammamat was a notable source of granite, greywacke, and gold. Flint was the first mineral collected and used to make tools, and flint handaxes are the earliest pieces of evidence of habitation in the Nile valley. Nodules of the mineral were carefully flaked to make blades and arrowheads of moderate hardness and durability even after copper was adopted for this purpose. Ancient Egyptians were among the first to use minerals such as sulfur as cosmetic substances.\nThe Egyptians worked deposits of the lead ore galena at Gebel Rosas to make net sinkers, plumb bobs, and small figurines. Copper was the most important metal for toolmaking in ancient Egypt and was smelted in furnaces from malachite ore mined in the Sinai. Workers collected gold by washing the nuggets out of sediment in alluvial deposits, or by the more labor-intensive process of grinding and washing gold-bearing quartzite. Iron deposits found in upper Egypt were used in the Late Period. High-quality building stones were abundant in Egypt; the ancient Egyptians quarried limestone all along the Nile valley, granite from Aswan, and basalt and sandstone from the wadis of the Eastern Desert. Deposits of decorative stones such as porphyry, greywacke, alabaster, and carnelian dotted the Eastern Desert and were collected even before the First Dynasty. In the Ptolemaic and Roman Periods, miners worked deposits of emeralds in Wadi Sikait and amethyst in Wadi el-Hudi.\nTrade.\nThe ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. An Egyptian colony stationed in southern Canaan dates to slightly before the First Dynasty. Tell es-Sakan in present-day Gaza was established as an Egyptian settlement in the late 4th millennium\u00a0BC, and is theorised to have been the main Egyptian colonial site in the region. Narmer had Egyptian pottery produced in Canaan and exported back to Egypt.\nBy the Second Dynasty at latest, ancient Egyptian trade with Byblos yielded a critical source of quality timber not found in Egypt. By the Fifth Dynasty, trade with Punt provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons. Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil.\nLanguage.\nHistorical development.\nThe Egyptian language is a northern Afro-Asiatic language closely related to the Berber and Semitic languages. It has the longest known history of any language having been written from BC to the Middle Ages and remaining as a spoken language for longer. The phases of ancient Egyptian are Old Egyptian, Middle Egyptian (Classical Egyptian), Late Egyptian, Demotic and Coptic. Egyptian writings do not show dialect differences before Coptic, but it was probably spoken in regional dialects around Memphis and later Thebes.\nAncient Egyptian was a synthetic language, but it became more analytic later on. Late Egyptian developed prefixal definite and indefinite articles, which replaced the older inflectional suffixes. There was a change from the older verb\u2013subject\u2013object word order to subject\u2013verb\u2013object. The Egyptian hieroglyphic, hieratic, and demotic scripts were eventually replaced by the more phonetic Coptic alphabet. Coptic is still used in the liturgy of the Egyptian Orthodox Church, and traces of it are found in modern Egyptian Arabic.\nSounds and grammar.\nAncient Egyptian has 25 consonants similar to those of other Afro-Asiatic languages. These include pharyngeal and emphatic consonants, voiced and voiceless stops, voiceless fricatives and voiced and voiceless affricates. It has three long and three short vowels, which expanded in Late Egyptian to about nine. The basic word in Egyptian, similar to Semitic and Berber, is a triliteral or biliteral root of consonants and semiconsonants. Suffixes are added to form words. The verb conjugation corresponds to the person. For example, the triconsonantal skeleton is the semantic core of the word 'hear'; its basic conjugation is ', 'he hears'. If the subject is a noun, suffixes are not added to the verb: ', 'the woman hears'.\nAdjectives are derived from nouns through a process that Egyptologists call \"nisbation\" because of its similarity with Arabic. The word order is in verbal and adjectival sentences, and in nominal and adverbial sentences. The subject can be moved to the beginning of sentences if it is long and is followed by a resumptive pronoun. Verbs and nouns are negated by the particle \"n\", but \"nn\" is used for adverbial and adjectival sentences. Stress falls on the ultimate or penultimate syllable, which can be open (CV) or closed (CVC).\nWriting.\nHieroglyphic writing dates from BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction (though typically written from right to left), hieratic was always written from right to left, usually in horizontal rows. A new form of writing, Demotic, became the prevalent writing style, and it is this form of writing\u2014along with formal hieroglyphs\u2014that accompany the Greek text on the Rosetta Stone.\nAround the first century AD, the Coptic alphabet started to be used alongside the Demotic script. Coptic is a modified Greek alphabet with the addition of some Demotic signs. Although formal hieroglyphs were used in a ceremonial role until the fourth century, towards the end only a small handful of priests could still read them. As the traditional religious establishments were disbanded, knowledge of hieroglyphic writing was mostly lost. Attempts to decipher them date to the Byzantine and Islamic periods in Egypt, but only in the 1820s, after the discovery of the Rosetta Stone and years of research by Thomas Young and Jean-Fran\u00e7ois Champollion, were hieroglyphs substantially deciphered.\nLiterature.\nWriting first appeared in association with kingship on labels and tags for items found in royal tombs. It was primarily an occupation of the scribes, who worked out of the \"Per Ankh\" institution or the House of Life. The latter comprised offices, libraries (called House of Books), laboratories and observatories. Some of the best-known pieces of ancient Egyptian literature, such as the Pyramid and Coffin Texts, were written in Classical Egyptian, which continued to be the language of writing until about 1300BC. Late Egyptian was spoken from the New Kingdom onward and is represented in Ramesside administrative documents, love poetry and tales, as well as in Demotic and Coptic texts. During this period, the tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as \"Sebayt\" ('instructions') was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is a famous example.\nThe \"Story of Sinuhe\", written in Middle Egyptian, might be the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. The Instruction of Amenemope is considered a masterpiece of Near Eastern literature. Towards the end of the New Kingdom, the vernacular language was more often employed to write popular pieces such as the Story of Wenamun and the Instruction of Any. The former tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt. From about 700BC, narrative stories and instructions, such as the popular Instructions of Onchsheshonqy, as well as personal and business documents were written in the demotic script and phase of Egyptian. Many stories written in demotic during the Greco-Roman period were set in previous historical eras, when Egypt was an independent nation ruled by great pharaohs such as Ramesses II.\nCulture.\nDaily life.\nMost ancient Egyptians were farmers tied to the land. Their dwellings were restricted to immediate family members, and were constructed of mudbrick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling grain and a small oven for baking the bread. Ceramics served as household wares for the storage, preparation, transport, and consumption of food, drink, and raw materials. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, while wooden stools, beds raised from the floor and individual tables comprised the furniture.\nThe ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness; perfumes and aromatic ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets that were bleached white, and both men and women of the upper classes wore wigs, jewelry, and cosmetics. Children went without clothing until maturity, at about age 12, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income.\nMusic and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, drums, and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.\nThe ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. \"Hounds and Jackals\" also known as 58 holes is another example of board games played in ancient Egypt. The first complete set of this game was discovered from a Theban tomb of the Egyptian pharaoh Amenemhat IV that dates to the 13th Dynasty. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting, fishing, and boating as well.\nThe excavation of the workers' village of Deir el-Medina has resulted in one of the most thoroughly documented accounts of community life in the ancient world, which spans almost four hundred years. There is no comparable site in which the organization, social interactions, and working and living conditions of a community have been studied in such detail.\nCuisine.\nEgyptian cuisine remained remarkably stable over time; indeed, the cuisine of modern Egypt retains some striking similarities to the cuisine of the ancients. The staple diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed by all on feast days while the upper classes indulged on a more regular basis. Fish, meat, and fowl could be salted or dried, and could be cooked in stews or roasted on a grill.\nArchitecture.\nThe architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza and the temples at Thebes. Building projects were organized and funded by the state for religious and commemorative purposes, but also to reinforce the wide-ranging power of the pharaoh. The ancient Egyptians were skilled builders; using only simple but effective tools and sighting instruments, architects could build large stone structures with great accuracy and precision that is still envied today.\nThe domestic dwellings of elite and ordinary Egyptians alike were constructed from perishable materials such as mudbricks and wood, and have not survived. Peasants lived in simple homes, while the palaces of the elite and the pharaoh were more elaborate structures. A few surviving New Kingdom palaces, such as those in Malkata and Amarna, show richly decorated walls and floors with scenes of people, birds, water pools, deities and geometric designs. Important structures such as temples and tombs that were intended to last forever were constructed of stone instead of mudbricks. The architectural elements used in the world's first large-scale stone building, Djoser's mortuary complex, include post and lintel supports in the papyrus and lotus motif.\nThe earliest preserved ancient Egyptian temples, such as those at Giza, consist of single, enclosed halls with roof slabs supported by columns. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary, a style that was standard until the Greco-Roman period. The earliest and most popular tomb architecture in the Old Kingdom was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The step pyramid of Djoser is a series of stone mastabas stacked on top of each other. Pyramids were built during the Old and Middle Kingdoms, but most later rulers abandoned them in favor of less conspicuous rock-cut tombs. The use of the pyramid form continued in private tomb chapels of the New Kingdom and in the royal pyramids of Nubia.\nArt.\nThe ancient Egyptians produced art to serve functional purposes. For over 3500 years, artists adhered to artistic forms and iconography that were developed during the Old Kingdom, following a strict set of principles that resisted foreign influence and internal change. These artistic standards\u2014simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth\u2014created a sense of order and balance within a composition. Images and text were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. The Narmer Palette, for example, displays figures that can also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.\nAncient Egyptian artisans used stone as a medium for carving statues and fine reliefs, but used wood as a cheap and easily carved substitute. Paints were obtained from minerals such as iron ores (red and yellow ochres), copper ores (blue and green), soot or charcoal (black), and limestone (white). Paints could be mixed with gum arabic as a binder and pressed into cakes, which could be moistened with water when needed.\nPharaohs used reliefs to record victories in battle, royal decrees, and religious scenes. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.\nDespite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan-style frescoes were found in Avaris. The most striking example of a politically driven change in artistic forms comes from the Amarna Period, where figures were radically altered to conform to Akhenaten's revolutionary religious ideas. This style, known as Amarna art, was quickly abandoned after Akhenaten's death and replaced by the traditional forms.\nReligious beliefs.\nBeliefs in the divine and in the afterlife were ingrained in ancient Egyptian civilization from its inception; pharaonic rule was based on the divine right of kings. The Egyptian pantheon was populated by gods who had supernatural powers and were called on for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting myths and stories into a coherent system. These various conceptions of divinity were not considered contradictory but rather layers in the multiple facets of reality.\nGods were worshiped in cult temples administered by priests acting on the king's behalf. At the center of the temple was the cult statue in a shrine. Temples were not places of public worship or congregation, and only on select feast days and celebrations was a shrine carrying the statue of the god brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials. Common citizens could worship private statues in their homes, and amulets offered protection against the forces of chaos. After the New Kingdom, the pharaoh's role as a spiritual intermediary was de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people.\nThe Egyptians believed that every human being was composed of physical and spiritual parts or \"aspects\". In addition to the body, each person had a \"\u0161wt\" (shadow), a \"ba\" (personality or soul), a \"ka\" (life-force), and a \"name\". The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his \"ka\" and \"ba\" and become one of the \"blessed dead\", living on as an \"akh\", or \"effective one\". For this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a \"feather of truth\". If deemed worthy, the deceased could continue their existence on earth in spiritual form. If they were not deemed worthy, their heart was eaten by Ammit the Devourer and they were erased from the Universe.\nBurial customs.\nThe ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring with the body goods the deceased would use in the afterlife. Before the Old Kingdom, bodies buried in desert pits were naturally preserved by desiccation. The arid, desert conditions were a boon throughout the history of ancient Egypt for burials of the poor, who could not afford the elaborate burial preparations available to the elite. Wealthier Egyptians began to bury their dead in stone tombs and use artificial mummification, which involved removing the internal organs, wrapping the body in linen, and burying it in a rectangular stone sarcophagus or wooden coffin. Beginning in the Fourth Dynasty, some parts were preserved separately in canopic jars.\nBy the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated.\nWealthy Egyptians were buried with larger quantities of luxury items, but all burials, regardless of social status, included goods for the deceased. Funerary texts were often included in the grave, and, beginning in the New Kingdom, so were shabti statues that were believed to perform manual labor for them in the afterlife. Rituals in which the deceased was magically re-animated accompanied burials. After burial, living relatives were expected to occasionally bring food to the tomb and recite prayers on behalf of the deceased.\nMilitary.\nThe ancient Egyptian military was responsible for defending Egypt against foreign invasion, and for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.\nTypical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that had earlier been introduced by the Hyksos invaders. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and the khopesh was adopted from Asiatic soldiers. The pharaoh was usually depicted in art and literature riding at the head of the army; it has been suggested that at least a few pharaohs, such as Seqenenre Tao II and his sons, did do so. However, it has also been argued that \"kings of this period did not personally act as frontline war leaders, fighting alongside their troops\". Soldiers were recruited from the general population, but during, and especially after, the New Kingdom, mercenaries from Nubia, Kush, and Libya were hired to fight for Egypt.\nTechnology, medicine and mathematics.\nTechnology.\nIn technology, medicine, and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (), is first credited to Egypt. The Egyptians created their own alphabet and decimal system.\nFaience and glass.\nEven before the Old Kingdom, the ancient Egyptians had developed a glassy material known as faience, which they treated as a type of artificial semi-precious stone. Faience is a non-clay ceramic made of silica, small amounts of lime and soda, and a colorant, typically copper. The material was used to make beads, tiles, figurines, and small wares. Several methods can be used to create faience, but typically production involved application of the powdered materials in the form of a paste over a clay core, which was then fired. By a related technique, the ancient Egyptians produced a pigment known as Egyptian blue, also called blue frit, which is produced by fusing (or sintering) silica, copper, lime, and an alkali such as natron. The product can be ground up and used as a pigment.\nThe ancient Egyptians could fabricate a wide variety of objects from glass with great skill, but it is not clear whether they developed the process independently. It is also unclear whether they made their own raw glass or merely imported pre-made ingots, which they melted and finished. However, they did have technical expertise in making objects, as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.\nMedicine.\nThe medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The lifelong labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on the body. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abscesses (though caries were rare).\nThe diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Adult life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.\nAncient Egyptian physicians were renowned in the ancient Near East for their healing skills, and some, such as Imhotep, remained famous long after their deaths. Herodotus remarked that there was a high degree of specialization among Egyptian physicians, with some treating only the head or the stomach, while others were eye-doctors and dentists. Training of physicians took place at the \"Per Ankh\" or \"House of Life\" institution, most notably those headquartered in Per-Bastet during the New Kingdom and at Abydos and Sa\u00efs in the Late period. Medical papyri show empirical knowledge of anatomy, injuries, and practical treatments.\nWounds were treated by bandaging with raw meat, white linen, sutures, nets, pads, and swabs soaked with honey to prevent infection, while opium, thyme, and belladona were used to relieve pain. The earliest records of burn treatment describe burn dressings that use the milk from mothers of male babies. Prayers were made to the goddess Isis. Moldy bread, honey, and copper salts were also used to prevent infection from dirt in burns. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until death occurred.\nMaritime technology.\nEarly Egyptians knew how to assemble planks of wood into a ship hull and had mastered advanced forms of shipbuilding as early as 3000BC. The Archaeological Institute of America reports that the oldest planked ships known are the Abydos boats. A group of 14 discovered ships in Abydos were constructed of wooden planks \"sewn\" together. Discovered by Egyptologist David O'Connor of New York University, woven straps were found to have been used to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. Because the ships are all buried together and near a mortuary belonging to Pharaoh Khasekhemwy, originally they were all thought to have belonged to him, but one of the 14 ships dates to 3000BC, and the associated pottery jars buried with the vessels also suggest earlier dating. The ship dating to 3000BC was long and is now thought to perhaps have belonged to an earlier pharaoh, perhaps one as early as Hor-Aha.\nEarly Egyptians also knew how to assemble planks of wood with treenails to fasten them together, using pitch for caulking the seams. The \"Khufu ship\", a vessel sealed into a pit in the Giza pyramid complex at the foot of the Great Pyramid of Giza in the Fourth Dynasty around 2500BC, is a full-size surviving example that may have filled the symbolic function of a solar barque. Early Egyptians also knew how to fasten the planks of this ship together with mortise and tenon joints.\nLarge seagoing ships are known to have been heavily used by the Egyptians in their trade with the city states of the eastern Mediterranean, especially Byblos (on the coast of modern-day Lebanon), and in several expeditions down the Red Sea to the Land of Punt. In fact one of the earliest Egyptian words for a seagoing ship is a \"Byblos Ship\", which originally defined a class of Egyptian seagoing ships used on the Byblos run; however, by the end of the Old Kingdom, the term had come to include large seagoing ships, whatever their destination.\nIn 1977, an ancient north\u2013south canal was discovered extending from Lake Timsah to the Ballah Lakes. It was dated to the Middle Kingdom of Egypt by extrapolating dates of ancient sites constructed along its course.\nIn 2011, archaeologists from Italy, the United States, and Egypt, excavating a dried-up lagoon known as Mersa Gawasis, unearthed traces of an ancient harbor that once launched early voyages, such as Hatshepsut's Punt, expedition onto the open ocean. Some of the site's most evocative evidence for the ancient Egyptians' seafaring prowess include large ship timbers and hundreds of feet of ropes, made from papyrus, coiled in huge bundles. In 2013, a team of Franco-Egyptian archaeologists discovered what is believed to be the world's oldest port, dating back about 4500 years, from the time of King Khufu, on the Red Sea coast, near Wadi el-Jarf (about 110 miles south of Suez).\nMathematics.\nThe earliest attested examples of mathematical calculations date to the predynastic Naqada period, and show a fully developed numeral system. The importance of mathematics to an educated Egyptian is suggested by a New Kingdom fictional letter in which the writer proposes a scholarly competition between himself and another scribe regarding everyday calculation tasks such as accounting of land, labor, and grain. Texts such as the Rhind Mathematical Papyrus and the Moscow Mathematical Papyrus show that the ancient Egyptians could perform the four basic mathematical operations\u2014addition, subtraction, multiplication, and division\u2014use fractions, calculate the areas of rectangles, triangles, and circles and compute the volumes of boxes, columns and pyramids. They understood basic concepts of algebra and geometry, and could solve systems of equations.\nMathematical notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. Each of these could be written as many times as necessary to add up to the desired number; so to write the number eighty or eight hundred, the symbol for ten or one hundred was written eight times respectively. Because their methods of calculation could not handle most fractions with a numerator greater than one, they had to write fractions as the sum of several fractions. For example, they resolved the fraction \"two-fifths\" into the sum of \"one-third\" + \"one-fifteenth\". Standard tables of values facilitated this. Some common fractions, however, were written with a special glyph\u2014the equivalent of the modern two-thirds is shown on the right.\nAncient Egyptian mathematicians knew the Pythagorean theorem as an empirical formula. They were aware, for example, that a triangle had a right angle opposite the hypotenuse when its sides were in a 3\u20134\u20135 ratio. They were able to estimate the area of a circle by subtracting one-ninth from its diameter and squaring the result:\na reasonable approximation of the formula .\nPopulation.\nEstimates of the size of the population range from 1\u20131.5 million in the 3rd millennium BC to possibly 2\u20133 million by the 1st millennium BC, before growing significantly towards the end of that millennium.\nArchaeogenetics.\nAccording to historian William Stiebling and archaeologist Susan N. Helft, conflicting DNA analysis on recent genetic samples such as the Amarna royal mummies has led to a lack of consensus on the genetic makeup of the ancient Egyptians and their geographic origins.\nThe genetic history of Ancient Egypt remains a developing field, and is relevant for the understanding of population demographic events connecting Africa and Eurasia. To date, the amount of genome-wide aDNA analyses on ancient specimens from Egypt and Sudan remain scarce, although studies on uniparental haplogroups in ancient individuals have been carried out several times, pointing broadly to affinities with other African and Eurasian groups.\nThe currently most advanced full genome analyses was made on three ancient specimens recovered from the Nile River Valley, Abusir el-Meleq, Egypt. Two of the individuals were dated to the Pre-Ptolemaic Period (New Kingdom to Late Period), and one individual to the Ptolemaic Period, spanning around 1300 years of Egyptian history. These results point to a genetic continuity of Ancient Egyptians with modern Egyptians. The results further point to a close genetic affinity between ancient Egyptians and Middle Eastern populations, especially ancient groups from the Levant.\nAncient Egyptians also displayed affinities to Nubians to the south of Egypt, in modern-day Sudan. Archaeological and historical evidence support interactions between Egyptian and Nubian populations more than 5000 years ago, with socio-political dynamics between Egyptians and Nubians ranging from peaceful coexistence to variably successful attempts of conquest. A study on sixty-six ancient Nubian individuals revealed significant contact with ancient Egyptians, characterized by the presence of % Neolithic/Bronze Age Levantine ancestry in these individuals. Such geneflow of Levantine-like ancestry corresponds with archaeological and botanic evidence, pointing to a Neolithic movement around 7,000 years ago.\nModern Egyptians, like modern Nubians, also underwent subsequent admixture events, contributing both \"Sub-Saharan\" African-like and West Asian-like ancestries, since the Roman period, with significance on the African Slave Trade and the Spread of Islam.\nSome scholars, such as Christopher Ehret, caution that a wider sampling area is needed and argue that the current data is inconclusive on the origin of ancient Egyptians. They also point out issues with the previously used methodology such as the sampling size, comparative approach and a \"biased interpretation\" of the genetic data. They argue in favor for a link between Ancient Egypt and the northern Horn of Africa. This latter view has been attributed to the corresponding archaeological, genetic, linguistic and biological anthropological sources of evidence which broadly indicate that the earliest Egyptians and Nubians were the descendants of populations in northeast Africa.\nLegacy.\nThe culture and monuments of ancient Egypt have left a lasting legacy on the world. Egyptian civilization significantly influenced the Kingdom of Kush and Mero\u00eb with both adopting Egyptian religious and architectural norms (hundreds of pyramids (6\u201330 meters high) were built in Egypt/Sudan), as well as using Egyptian writing as the basis of the Meroitic script. Meroitic is the oldest written language in Africa, other than Egyptian, and was used from the 2nd century BC until the early 5th century AD. The cult of the goddess Isis, for example, became popular in the Roman Empire, as obelisks and other relics were transported back to Rome. The Romans also imported building materials from Egypt to erect Egyptian-style structures. Early historians such as Herodotus, Strabo, and Diodorus Siculus studied and wrote about the land, which Romans came to view as a place of mystery.\nDuring the Middle Ages and the Renaissance, Egyptian pagan culture was in decline after the rise of Christianity and later Islam, but interest in Egyptian antiquity continued in the writings of medieval scholars such as Dhul-Nun al-Misri and al-Maqrizi. In the seventeenth and eighteenth centuries, European travelers and tourists brought back antiquities and wrote stories of their journeys, leading to a wave of Egyptomania across Europe, as evident in symbolism such as the Eye of Providence and the Great Seal of the United States. This renewed interest sent collectors to Egypt, who took, purchased, or were given many important antiquities. Napoleon arranged the first studies in Egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the \"Description de l'\u00c9gypte\".\nIn the 20th century, the Egyptian Government and archaeologists alike recognized the importance of cultural respect and integrity in excavations. Since the 2010s, the Ministry of Tourism and Antiquities has overseen excavations and the recovery of artifacts."}
{"id": "875", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=875", "title": "Analog Brothers", "text": "Analog Brothers were an experimental hip hop band featuring Tracy \"Ice-T\" Marrow (Ice Oscillator) on keyboards, drums and vocals, Keith \"Kool Keith\" Thornton (Keith Korg) on bass, strings and vocals, Marc Live (Marc Moog) on drums, violins and vocals, Christopher \"Black Silver\" Rodgers (Silver Synth) on synthesizer, lazar bell and vocals, and Rex Colonel \"Pimpin' Rex\" Doby Jr. (Rex Roland JX3P) on keyboards, vocals and production. \nMusic.\nThe group's only studio album \"Pimp to Eat\" featured guest appearances by various members of Rhyme Syndicate, Odd Oberheim, Jacky Jasper (who appears as Jacky Jasper on the song \"We Sleep Days\" and H-Bomb on \"War\"), D.J. Cisco from S.M., Synth-A-Size Sisters and Teflon.\nLegacy.\nWhile the group only recorded one album together as the Analog Brothers, a few bootlegs of its live concert performances, including freestyles with original lyrics, have occasionally surfaced online. After \"Pimp to Eat\", the Analog Brothers continued performing together in various line ups. Kool Keith and Marc Live joined with Jacky Jasper to release two albums as KHM. Marc Live rapped with Ice-T's group SMG. Marc also formed a group with Black Silver called Live Black, but while five of their tracks were released on a demo CD sold at concerts, Live Black's first album has yet to be released.\nIn 2008, Ice-T and Black Silver toured together as Black Ice, and released an album together called \"Urban Legends\".\nIn 2013, Black Silver and newest member to Analog Brothers, Kiew Kurzweil (Kiew Nikon of Kinetic) collaborated on the joint album called \"Slang Banging (Return to Analog)\" with production by Junkadelic Music. In addition to all this, the Analog Brothers continue to make frequent appearances on each other's solo albums."}
{"id": "876", "revid": "43154963", "url": "https://en.wikipedia.org/wiki?curid=876", "title": "Motor neuron diseases", "text": "Motor neuron diseases or motor neurone diseases (MNDs) are a group of rare neurodegenerative disorders that selectively affect motor neurons, the cells which control voluntary muscles of the body. They include amyotrophic lateral sclerosis (ALS), progressive bulbar palsy (PBP), pseudobulbar palsy, progressive muscular atrophy (PMA), primary lateral sclerosis (PLS), spinal muscular atrophy (SMA) and monomelic amyotrophy (MMA), as well as some rarer variants resembling ALS.\nMotor neuron diseases affect both children and adults. While each motor neuron disease affects patients differently, they all cause movement-related symptoms, mainly muscle weakness. Most of these diseases seem to occur randomly without known causes, but some forms are inherited. Studies into these inherited forms have led to discoveries of various genes (e.g. \"SOD1\") that are thought to be important in understanding how the disease occurs.\nSymptoms of motor neuron diseases can be first seen at birth or can come on slowly later in life. Most of these diseases worsen over time; while some, such as ALS, shorten one's life expectancy, others do not. Currently, there are no approved treatments for the majority of motor neuron disorders, and care is mostly symptomatic.\nSigns and symptoms.\nSigns and symptoms depend on the specific disease, but motor neuron diseases typically manifest as a group of movement-related symptoms. They come on slowly, and worsen over the course of more than three months. Various patterns of muscle weakness are seen, and muscle cramps and spasms may occur. One can have difficulty breathing with climbing stairs (exertion), difficulty breathing when lying down (orthopnea), or even respiratory failure if breathing muscles become involved. Bulbar symptoms, including difficulty speaking (dysarthria), difficulty swallowing (dysphagia), and excessive saliva production (sialorrhea), can also occur. Sensation, or the ability to feel, is typically not affected. Emotional disturbance (e.g. pseudobulbar affect) and cognitive and behavioural changes (e.g. problems in word fluency, decision-making, and memory) are also seen. There can be lower motor neuron findings (e.g. muscle wasting, muscle twitching), upper motor neuron findings (e.g. brisk reflexes, Babinski reflex, Hoffman's reflex, increased muscle tone), or both.\nMotor neuron diseases are seen both in children and adults. Those that affect children tend to be inherited or familial, and their symptoms are either present at birth or appear before learning to walk. Those that affect adults tend to appear after age 40. The clinical course depends on the specific disease, but most progress or worsen over the course of months. Some are fatal (e.g. ALS), while others are not (e.g. PLS).\nPatterns of weakness.\nVarious patterns of muscle weakness occur in different motor neuron diseases. Weakness can be symmetric or asymmetric, and it can occur in body parts that are distal, proximal, or both. According to Statland et al., there are three main weakness patterns that are seen in motor neuron diseases, which are:\nLower and upper motor neuron findings.\nMotor neuron diseases are on a spectrum in terms of upper and lower motor neuron involvement. Some have just lower or upper motor neuron findings, while others have a mix of both. Lower motor neuron (LMN) findings include muscle atrophy and fasciculations, and upper motor neuron (UMN) findings include hyperreflexia, spasticity, muscle spasm, and abnormal reflexes.\nPure upper motor neuron diseases, or those with just UMN findings, include PLS.\nPure lower motor neuron diseases, or those with just LMN findings, include PMA.\nMotor neuron diseases with both UMN and LMN findings include both familial and sporadic ALS.\nCauses.\nMost cases are sporadic and their causes are usually not known. It is thought that environmental, toxic, viral, or genetic factors may be involved.\nDNA damage.\nTAR DNA-binding protein 43 (TDP-43), is a critical component of the non-homologous end joining (NHEJ) enzymatic pathway that repairs DNA double-strand breaks in pluripotent stem cell-derived motor neurons. TDP-43 is rapidly recruited to double-strand breaks where it acts as a scaffold for the recruitment of the XRCC4-DNA ligase protein complex that then acts to repair double-strand breaks. About 95% of ALS patients have abnormalities in the nucleus-cytoplasmic localization in spinal motor neurons of TDP43. In TDP-43 depleted human neural stem cell-derived motor neurons, as well as in sporadic ALS patients' spinal cord specimens there is significant double-strand break accumulation and reduced levels of NHEJ.\nAssociated risk factors.\nIn adults, men are more commonly affected than women.\nDiagnosis.\nDifferential diagnosis can be challenging due to the number of overlapping symptoms, shared between several motor neuron diseases. Frequently, the diagnosis is based on clinical findings (i.e. LMN vs. UMN signs and symptoms, patterns of weakness), family history of MND, and a variation of tests, many of which are used to rule out disease mimics, which can manifest with identical symptoms.\nClassification.\nMotor neuron disease describes a collection of clinical disorders, characterized by progressive muscle weakness and the degeneration of the motor neuron on electrophysiological testing. The term \"motor neuron disease\" has varying meanings in different countries. Similarly, the literature inconsistently classifies which degenerative motor neuron disorders can be included under the umbrella term \"motor neuron disease\". The four main types of MND are marked (*) in the table below.\nAll types of MND can be differentiated by two defining characteristics:\nSporadic or acquired MNDs occur in patients with no family history of degenerative motor neuron disease. Inherited or genetic MNDs adhere to one of the following inheritance patterns: autosomal dominant, autosomal recessive, or X-linked. Some disorders, like ALS, can occur sporadically (85%) or can have a genetic cause (15%) with the same clinical symptoms and progression of disease.\nUMNs are motor neurons that project from the cortex down to the brainstem or spinal cord. LMNs originate in the anterior horns of the spinal cord and synapse on peripheral muscles. Both motor neurons are necessary for the strong contraction of a muscle, but damage to an UMN can be distinguished from damage to a LMN by physical exam.\nTreatment.\nThere are no known curative treatments for the majority of motor neuron disorders. Please refer to the articles on individual disorders for more details.\nPrognosis.\nThe table below lists life expectancy for patients who are diagnosed with MND.\nTerminology.\nIn the United States and Canada, the term \"motor neuron disease\" usually refers to the group of disorders while amyotrophic lateral sclerosis is frequently called \"Lou Gehrig's disease\". In the United Kingdom and Australia, the term \"motor neuron(e) disease\" is used for amyotrophic lateral sclerosis, although is not uncommon to refer to the entire group.\nWhile MND refers to a specific subset of similar diseases, there are numerous other diseases of motor neurons that are referred to collectively as \"motor neuron disorders\", for instance the diseases belonging to the spinal muscular atrophies group. However, they are not classified as \"motor neuron diseases\" by the 11th edition of the International Statistical Classification of Diseases and Related Health Problems (ICD-11), which is the definition followed in this article."}
{"id": "877", "revid": "2766075", "url": "https://en.wikipedia.org/wiki?curid=877", "title": "Abjad", "text": "An abjad (, , Hebrew: \u05d0\u05d1\u05d2\u05d3), also abgad, is a writing system in which only consonants are represented, leaving the vowel sounds to be inferred by the reader. This contrasts with alphabets, which provide graphemes for both consonants and vowels. The term was introduced in 1990 by Peter T. Daniels. Other terms for the same concept include partial phonemic script, segmentally linear defective phonographic script, consonantary, consonant writing, and consonantal alphabet.\nImpure abjads represent vowels with either optional diacritics, a limited number of distinct vowel glyphs, or both.\nEtymology.\nThe name \"abjad\" is based on the Arabic alphabet's first (in its original order) four corresponding to \"a\", \"b\", \"j\", and to replace the more common terms \"consonantary\" and \"consonantal alphabet\" in describing the family of scripts classified as \"West Semitic\". It is similar to other Semitic languages such as Phoenician, Hebrew and Semitic proto-alphabets: specifically, aleph, bet, gimel, dalet.\nTerminology.\nAccording to the formulations of Peter T. Daniels, abjads differ from alphabets in that only consonants, not vowels, are represented among the basic graphemes. Abjads differ from abugidas, another category defined by Daniels, in that in abjads, the vowel sound is \"implied\" by phonology, and where vowel marks exist for the system, such as nikkud for Hebrew and \u1e25arak\u0101t for Arabic, their use is optional and not the dominant (or literate) form. Abugidas mark all vowels (other than the \"inherent\" vowel) with a diacritic, a minor attachment to the letter, a standalone glyph, or (in Canadian Aboriginal syllabics) by rotation of the letter. Some abugidas use a special symbol to \"suppress\" the inherent vowel so that the consonant alone can be properly represented. In a syllabary, a grapheme denotes a complete syllable, that is, either a lone vowel sound or a combination of a vowel sound with one or more consonant sounds.\nThe contrast of abjad versus alphabet has been rejected by other scholars because \"abjad\" is also used as a term for the Arabic numeral system. Also, it may be taken as suggesting that consonantal alphabets, in contrast to e.g. the Greek alphabet, were not yet true alphabets. Florian Coulmas, a critic of Daniels and of the abjad terminology, argues that this terminology can confuse alphabets with \"transcription systems\", and that there is no reason to relegate the Hebrew, Aramaic or Phoenician alphabets to second-class status as an \"incomplete alphabet\".\nHowever, Daniels's terminology has found acceptance in the linguistic community.\nOrigins.\nThe first abjad to gain widespread usage was the Phoenician abjad. Unlike other contemporary scripts, such as cuneiform and Egyptian hieroglyphs, the Phoenician script consisted of only a few dozen symbols. This made the script easy to learn, and seafaring Phoenician merchants took the script throughout the then-known world.\nThe Phoenician abjad was a radical simplification of phonetic writing, since hieroglyphics required the writer to pick a hieroglyph starting with the same sound that the writer wanted to write in order to write phonetically, much as \"man'y\u014dgana\" (kanji used solely for phonetic use) was used to represent Japanese phonetically before the invention of kana.\nPhoenician gave rise to a number of new writing systems, including the widely used Aramaic abjad and the Greek alphabet. The Greek alphabet evolved into the modern western alphabets, such as Latin and Cyrillic, while Aramaic became the ancestor of many modern abjads and abugidas of Asia.\nImpure abjads.\nImpure abjads have characters for some vowels, optional vowel diacritics, or both. The term pure abjad refers to scripts entirely lacking in vowel indicators. However, most modern abjads, such as Arabic, Hebrew, Aramaic, and Pahlavi, are \"impure\" abjadsthat is, they also contain symbols for some of the vowel phonemes, although the said non-diacritic vowel letters are also used to write certain consonants, particularly approximants that sound similar to long vowels. A \"pure\" abjad is exemplified (perhaps) by very early forms of ancient Phoenician, though at some point (at least by the 9th century BC) it and most of the contemporary Semitic abjads had begun to overload a few of the consonant symbols with a secondary function as vowel markers, called \"matres lectionis\". This practice was at first rare and limited in scope but became increasingly common and more developed in later times.\nAddition of vowels.\nIn the 9th century BC the Greeks adapted the Phoenician script for use in their own language. The phonetic structure of the Greek language created too many ambiguities when vowels went unrepresented, so the script was modified. They did not need letters for the guttural sounds represented by \"aleph\", \"he\", \"heth\" or \"ayin\", so these symbols were assigned vocalic values. The letters \"waw\" and \"yod\" were also adapted into vowel signs; along with \"he\", these were already used as \"matres lectionis\" in Phoenician. The major innovation of Greek was to dedicate these symbols exclusively and unambiguously to vowel sounds that could be combined arbitrarily with consonants (as opposed to syllabaries such as Linear B which usually have vowel symbols but cannot combine them with consonants to form arbitrary syllables).\nAbugidas developed along a slightly different route. The basic consonantal symbol was considered to have an inherent \"a\" vowel sound. Hooks or short lines attached to various parts of the basic letter modify the vowel. In this way, the South Arabian abjad evolved into the Ge'ez abugida of Ethiopia between the 5th century BC and the 5th century AD. Similarly, the Br\u0101hm\u012b abugida of the Indian subcontinent developed around the 3rd century BC (from the Aramaic abjad, it has been hypothesized).\nAbjads and the structure of Semitic languages.\nThe abjad form of writing is well-adapted to the morphological structure of the Semitic languages it was developed to write. This is because words in Semitic languages are formed from a root consisting of (usually) three consonants, the vowels being used to indicate inflectional or derived forms. For instance, according to Classical Arabic and Modern Standard Arabic, from the Arabic root \"K-T-B\" (to write) can be derived the forms ' (he wrote), ' (you (masculine singular) wrote), ' (he writes), and ' (library). In most cases, the absence of full glyphs for vowels makes the common root clearer, allowing readers to guess the meaning of unfamiliar words from familiar roots (especially in conjunction with context clues) and improving word recognition while reading for practiced readers.\nBy contrast, the Arabic and Hebrew scripts sometimes perform the role of true alphabets rather than abjads when used to write certain Indo-European languages, including Kurdish, Bosnian, Yiddish, and some Romance languages such as Mozarabic, Aragonese, Portuguese, Spanish and Ladino."}
{"id": "878", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=878", "title": "Abugida", "text": "An abugida (; from Ge\u02bdez: , )sometimes also called alphasyllabary, neosyllabary, or pseudo-alphabetis a segmental writing system in which consonant\u2013vowel sequences are written as units; each unit is based on a consonant letter, and vowel notation is secondary, similar to a diacritical mark. This contrasts with a full alphabet, in which vowels have status equal to consonants, and with an abjad, in which vowel marking is absent, partial, or optional \u2013 in less formal contexts, all three types of the script may be termed \"alphabets\". The terms also contrast them with a syllabary, in which a single symbol denotes the combination of one consonant and one vowel.\nRelated concepts were introduced independently in 1948 by James Germain F\u00e9vrier (using the term ) and David Diringer (using the term \"semisyllabary\"), then in 1959 by Fred Householder (introducing the term \"pseudo-alphabet\"). The Ethiopic term \"abugida\" was chosen as a designation for the concept in 1990 by Peter T. Daniels. In 1992, Faber suggested \"segmentally coded syllabically linear phonographic script\", and in 1992 Bright used the term \"alphasyllabary\", and Gnanadesikan and Rimzhim, Katz, &amp; Fowler have suggested \"aksara\" or \"\u0101ksharik\".\nAbugidas include the extensive Brahmic family of scripts of Tibet, South and Southeast Asia, Semitic Ethiopic scripts, and Canadian Aboriginal syllabics. As is the case for syllabaries, the units of the writing system may consist of the representations both of syllables and of consonants. For scripts of the Brahmic family, the term \"akshara\" is used for the units.\nEtymology.\nIn several languages of Ethiopia and Eritrea, \"abugida\" traditionally meant letters of the Ethiopic or Ge\u02bdez script in which many of these languages are written. The Ge\u02bdez script is one of several segmental writing systems in the world, others include Indic/Brahmic scripts and Canadian Aboriginal Syllabics. The word abugida is derived from the four letters, \"\u00e4, bu, gi,\" and \"da\", in much the same way that \"abecedary\" is derived from Latin letters \"a be ce de\", \"abjad\" is derived from the Arabic \"a b j d\", and \"alphabet\" is derived from the names of the two first letters in the Greek alphabet, \"alpha\" and \"beta\". \"Abugida\" as a term in linguistics was proposed by Peter T. Daniels in his 1990 typology of writing systems.\nTerminology.\nAs Daniels used the word, an abugida is in contrast with a syllabary, where letters with shared consonant or vowel sounds show no particular resemblance to one another. Furthermore, an abugida is also in contrast with an alphabet proper, where independent letters are used to denote consonants and vowels. The term \"alphasyllabary\" was suggested for the Indic scripts in 1997 by William Bright, following South Asian linguistic usage, to convey the idea that, \"they share features of both alphabet and syllabary.\"\nThe formal definitions given by Daniels and Bright for abugida and alphasyllabary differ; some writing systems are abugidas but not alphasyllabaries, and some are alphasyllabaries but not abugidas. An abugida is defined as \"a type of writing system whose basic characters denote consonants followed by a particular vowel, and in which diacritics denote other vowels\". (This 'particular vowel' is referred to as the \"inherent\" or \"implicit\" vowel, as opposed to the \"explicit\" vowels marked by the 'diacritics'.)\nAn alphasyllabary is defined as \"a type of writing system in which the vowels are denoted by subsidiary symbols, not all of which occur in a linear order (with relation to the consonant symbols) that is congruent with their temporal order in speech\". Bright did not require that an alphabet explicitly represent all vowels. \u02bcPhags-pa is an example of an abugida because it has an inherent vowel, but it is not an alphasyllabary because its vowels are written in linear order. Modern Lao is an example of an alphasyllabary that is not an abugida, for there is no inherent vowel and its vowels are always written explicitly and not in accordance to their temporal order in speech, meaning that a vowel can be written before, below or above a consonant letter, while the syllable is still pronounced in the order of a consonant-vowel combination (CV).\nGeneral description.\nThe fundamental principles of an abugida apply to words made up of consonant-vowel (CV) syllables. The syllables are written as letters in a straight line, where each syllable is either a letter that represents the sound of a consonant and its inherent vowel or a letter modified to indicate the vowel. Letters can be modified either by means of diacritics or by changes in the form of the letter itself. If all modifications are by diacritics and all diacritics follow the direction of the writing of the letters, then the abugida is not an alphasyllabary. However, most languages have words that are more complicated than a sequence of CV syllables, even ignoring tone.\nThe first complication is syllables that consist of just a vowel (V). For some languages, a zero consonant letter is used as though every syllable began with a consonant. For other languages, each vowel has a separate letter that is used for each syllable consisting of just the vowel. These letters are known as \"independent vowels\", and are found in most Indic scripts. These letters may be quite different from the corresponding diacritics, which by contrast are known as \"dependent vowels\". As a result of the spread of writing systems, independent vowels may be used to represent syllables beginning with a glottal stop, even for non-initial syllables.\nThe next two complications are consonant clusters before a vowel (CCV) and syllables ending in a consonant (CVC). The simplest solution, which is not always available, is to break with the principle of writing words as a sequence of syllables and use a letter representing just a consonant (C). This final consonant may be represented with:\nIn a true abugida, the lack of distinctive vowel marking of the letter may result from the diachronic loss of the inherent vowel, e.g. by syncope and apocope in Hindi.\nWhen not separating syllables containing consonant clusters (CCV) into C + CV, these syllables are often written by combining the two consonants. In the Indic scripts, the earliest method was simply to arrange them vertically, writing the second consonant of the cluster below the first one. The two consonants may also merge as conjunct consonant letters, where two or more letters are graphically joined in a ligature, or otherwise change their shapes. Rarely, one of the consonants may be replaced by a gemination mark, e.g. the Gurmukhi \"addak\".\nWhen they are arranged vertically, as in Burmese or Khmer, they are said to be 'stacked'. Often there has been a change to writing the two consonants side by side. In the latter case, this combination may be indicated by a diacritic on one of the consonants or a change in the form of one of the consonants, e.g. the half forms of Devanagari. Generally, the reading order of stacked consonants is top to bottom, or the general reading order of the script, but sometimes the reading order can be reversed.\nThe division of a word into syllables for the purposes of writing does not always accord with the natural phonetics of the language. For example, Brahmic scripts commonly handle a phonetic sequence CVC-CV as CV-CCV or CV-C-CV. However, sometimes phonetic CVC syllables are handled as single units, and the final consonant may be represented:\nMore complicated unit structures (e.g. CC or CCVC) are handled by combining the various techniques above.\nExamples using the Devanagari script\nFamily-specific features.\nThere are three principal families of abugidas, depending on whether vowels are indicated by modifying consonants by \"diacritics, distortion,\" or \"orientation.\"\nLao and T\u0101na have dependent vowels and a zero vowel sign, but no inherent vowel.\nIndic (Brahmic).\nIndic scripts originated in India and spread to Southeast Asia, Bangladesh, Sri Lanka, Nepal, Bhutan, Tibet, Mongolia, and Russia. All surviving Indic scripts are descendants of the Brahmi alphabet. Today they are used in most languages of South Asia (although replaced by Perso-Arabic in Urdu, Kashmiri and some other languages of Pakistan and India), mainland Southeast Asia (Myanmar, Thailand, Laos, Cambodia, and Vietnam), Tibet (Tibetan), Indonesian archipelago (Javanese, Balinese, Sundanese, Batak, Lontara, Rejang, Rencong, Makasar, etc.), Philippines (Baybayin, Buhid, Hanunuo, Kulitan, and Aborlan Tagbanwa), Malaysia (Rencong).\nThe primary division is with North Indic scripts, used in Northern India, Nepal, Tibet, Bhutan, Mongolia, and Russia; and Southern Indic scripts, used in South India, Sri Lanka and Southeast Asia. South Indic letter forms are more rounded than North Indic forms, though Odia, Golmol and Litumol of Nepal script are rounded. Most North Indic scripts' full letters incorporate a horizontal line at the top, with Gujarati and Odia as exceptions; South Indic scripts do not.\nIndic scripts indicate vowels through dependent vowel signs (diacritics) around the consonants, often including a sign that explicitly indicates the lack of a vowel. If a consonant has no vowel sign, this indicates a default vowel. Vowel diacritics may appear above, below, to the left, to the right, or around the consonant.\nThe most widely used Indic script is Devanagari, shared by Hindi, Bihari, Marathi, Konkani, Nepali, and often Sanskrit. A basic letter such as \u0915 in Hindi represents a syllable with the default vowel, in this case \"ka\" (). In some languages, including Hindi, it becomes a final closing consonant at the end of a word, in this case \"k\". The inherent vowel may be changed by adding vowel mark (diacritics), producing syllables such as \u0915\u093f \"ki,\" \u0915\u0941 \"ku,\" \u0915\u0947 \"ke,\" \u0915\u094b \"ko.\"\nIn many of the Brahmic scripts, a syllable beginning with a cluster is treated as a single character for purposes of vowel marking, so a vowel marker like \u093f \"-i,\" falling before the character it modifies, may appear several positions before the place where it is pronounced. For example, the game cricket in Hindi is \u0915\u094d\u0930\u093f\u0915\u0947\u091f ; the diacritic for appears before the consonant cluster , not before the . A more unusual example is seen in the Batak alphabet: Here the syllable \"bim\" is written \"ba-ma-i-(virama)\". That is, the vowel diacritic and virama are both written after the consonants for the whole syllable.\nIn many abugidas, there is also a diacritic to suppress the inherent vowel, yielding the bare consonant. In Devanagari, \u092a\u094d is \"p,\" and \u092b\u094d is \"ph\". This is called the \"vir\u0101ma\" or \"halantam\" in Sanskrit. It may be used to form consonant clusters, or to indicate that a consonant occurs at the end of a word. Thus in Sanskrit, a default vowel consonant such as \u092b does not take on a final consonant sound. Instead, it keeps its vowel. For writing two consonants without a vowel in between, instead of using diacritics on the first consonant to remove its vowel, another popular method of special conjunct forms is used in which two or more consonant characters are merged to express a cluster, such as Devanagari, as in \u0905\u092a\u094d\u092b \"appha.\" (Some fonts display this as \u092a\u094d followed by \u092b, rather than forming a conjunct. This expedient is used by ISCII and South Asian scripts of Unicode.) Thus a closed syllable such as \"pha\u1e63\" requires two \"aksharas\" to write: \u092b\u0937\u094d \"pha\u1e63\".\nThe R\u00f3ng script used for the Lepcha language goes further than other Indic abugidas, in that a single \"akshara\" can represent a closed syllable: Not only the vowel, but any final consonant is indicated by a diacritic. For example, the syllable [sok] would be written as something like s\u0325\u033d, here with an underring representing and an overcross representing the diacritic for final . Most other Indic abugidas can only indicate a very limited set of final consonants with diacritics, such as or , if they can indicate any at all.\nEthiopic.\nIn Ge\u02bdez script, \"fidels\" (individual \"letters\" of the script) have \"diacritics\" that are fused with the consonants to the point that they must be considered modifications of the form of the letters. Children learn each modification separately, as in a syllabary; nonetheless, the graphic similarities between syllables with the same consonant are readily apparent, unlike the case in a true syllabary.\nThough now an abugida, the Ge\u02bdez script, until the advent of Christianity (\"ca.\" AD 350), had originally been what would now be termed an \"abjad\". In the Ge\u02bdez script (or \"fidel\"), the base form of the letter (also known as \"fidel\") may be altered. For example, \u1200 \"h\u00e4\" (base form), \u1201 \"hu\" (with a right-side diacritic that does not alter the letter), \u1202 \"hi\" (with a subdiacritic that compresses the consonant, so it is the same height), \u1205 \"h\u0259\" or (where the letter is modified with a kink in the left arm).\nCanadian Aboriginal syllabics.\nIn the family known as Canadian Aboriginal syllabics, which was inspired by the Devanagari script of India, vowels are indicated by changing the orientation of the syllabogram. Each vowel has a consistent orientation; for example, Inuktitut \u1431 \"pi,\" \u1433 \"pu,\" \u1438 \"pa;\" \u144e \"ti,\" \u1450 \"tu,\" \u1455 \"ta\". Although there is a vowel inherent in each, all rotations have equal status and none can be identified as basic. Bare consonants are indicated either by separate diacritics, or by superscript versions of the \"aksharas\"; there is no vowel-killer mark.\nBorderline cases.\nVowelled abjads.\nAbjads are typically written without indication of many vowels. However, in some contexts like teaching materials or scriptures, Arabic and Hebrew are written with full indication of vowels via diacritic marks (\"harakat\", \"niqqud\") making them effectively alphasyllabaries.\nThe Arabic scripts used for Kurdish in Iraq and for Uyghur in Xinjiang, China, as well as the Hebrew script of Yiddish, are fully vowelled, but because the vowels are written with full letters rather than diacritics (with the exception of distinguishing between /a/ and /o/ in the latter) and there are no inherent vowels, these are considered alphabets, not abugidas.\nThe Arabic script used for South Azerbaijani generally writes the vowel /\u00e6/ (written as \u0259 in North Azerbaijani) as a diacritic, but writes all other vowels as full letters (similarly to Kurdish and Uyghur). This means that when no vowel diacritics are present (most of the time), it technically has an inherent vowel. However, like the Phagspa and Meroitic scripts whose status as abugidas is controversial (see below), all other vowels are written in-line. Additionally, the practice of explicitly writing all-but-one vowel does not apply to loanwords from Arabic and Persian, so the script does not have an inherent vowel for Arabic and Persian words. The inconsistency of its vowel notation makes it difficult to categorize.\nPhagspa.\nThe imperial Mongol script called Phagspa was derived from the Tibetan abugida, but all vowels are written in-line rather than as diacritics. However, it retains the features of having an inherent vowel /a/ and having distinct initial vowel letters.\nPahawh.\nPahawh Hmong is a non-segmental script that indicates syllable onsets and rimes, such as consonant clusters and vowels with final consonants. Thus it is not segmental and cannot be considered an abugida. However, it superficially resembles an abugida with the roles of consonant and vowel reversed. Most syllables are written with two letters in the order rime\u2013onset (typically vowel-consonant), even though they are pronounced as onset-rime (consonant-vowel), rather like the position of the vowel in Devanagari, which is written before the consonant. Pahawh is also unusual in that, while an inherent rime (with mid tone) is unwritten, it also has an inherent onset . For the syllable , which requires one or the other of the inherent sounds to be overt, it is that is written. Thus it is the rime (vowel) that is basic to the system.\nMeroitic.\nDrawing a dividing line between abugidas and other segmental scripts can be difficult. For example, the Meroitic script of ancient Sudan did not indicate an inherent \"a\" (one symbol stood for both \"m\" and \"ma,\" for example), and is thus similar to Brahmic family of abugidas. However, the other vowels were indicated with full letters, not diacritics or modification, so the system was essentially an alphabet that did not bother to write the most common vowel.\nShorthand.\nSeveral systems of shorthand use diacritics for vowels, but they do not have an inherent vowel, and are thus more similar to Thaana and Kurdish script than to the Brahmic scripts. The Gabelsberger shorthand system and its derivatives modify the \"following\" consonant to represent vowels. The Pollard script, which was based on shorthand, also uses diacritics for vowels; the placements of the vowel relative to the consonant indicates tone. Pitman shorthand uses straight strokes and quarter-circle marks in different orientations as the principal \"alphabet\" of consonants; vowels are shown as light and heavy dots, dashes and other marks in one of 3 possible positions to indicate the various vowel-sounds. However, to increase writing speed, Pitman has rules for \"vowel indication\" using the positioning or choice of consonant signs so that writing vowel-marks can be dispensed with.\nDevelopment.\nAs the term \"alphasyllabary\" suggests, abugidas have been considered an intermediate step between alphabets and syllabaries. Historically, abugidas appear to have evolved from abjads (vowelless alphabets). They contrast with syllabaries, where there is a distinct symbol for each syllable or consonant-vowel combination, and where these have no systematic similarity to each other, and typically develop directly from logographic scripts. Compare the examples above to sets of syllables in the Japanese hiragana syllabary: \u304b \"ka\", \u304d \"ki\", \u304f \"ku\", \u3051 \"ke\", \u3053 \"ko\" have nothing in common to indicate \"k;\" while \u3089 \"ra\", \u308a \"ri\", \u308b \"ru\", \u308c \"re\", \u308d \"ro\" have neither anything in common for \"r\", nor anything to indicate that they have the same vowels as the \"k\" set.\nMost Indian and Indochinese abugidas appear to have first been developed from abjads with the Kharo\u1e63\u1e6dh\u012b and Br\u0101hm\u012b scripts; the abjad in question is usually considered to be the Aramaic one, but while the link between Aramaic and Kharosthi is more or less undisputed, this is not the case with Brahmi. The Kharosthi family does not survive today, but Brahmi's descendants include most of the modern scripts of South and Southeast Asia.\nGe\u02bdez script derived from a different abjad, the Sabean script of Yemen; the advent of vowels coincided with the introduction or adoption of Christianity about AD 350. The Ethiopic script is the elaboration of an abjad.\nThe Cree syllabary was invented with full knowledge of the Devanagari system.\nThe Meroitic script was developed from Egyptian hieroglyphs, within which various schemes of 'group writing' had been used for showing vowels."}
{"id": "880", "revid": "43373957", "url": "https://en.wikipedia.org/wiki?curid=880", "title": "ABBA", "text": "ABBA were a Swedish pop group formed in Stockholm in 1972 by Agnetha F\u00e4ltskog, Bj\u00f6rn Ulvaeus, Benny Andersson, Anni-Frid Lyngstad. They are one of the most popular and successful musical groups of all time, and are one of the best-selling music acts in the history of popular music.\nIn , ABBA became 's first winner of the Eurovision Song Contest with the song \"Waterloo\", which in 2005 was chosen as the best song in the competition's history as part of the of the contest. During the band's main active years, it consisted of two married couples: F\u00e4ltskog and Ulvaeus, and Lyngstad and Andersson. With the increase of their popularity, their personal lives suffered, which eventually resulted in the collapse of both marriages. The relationship changes were reflected in the group's music, with later songs featuring darker and more introspective lyrics. After ABBA disbanded in December 1982, Andersson and Ulvaeus continued their success writing music for multiple audiences including stage, musicals and movies, while F\u00e4ltskog and Lyngstad pursued solo careers. Ten years after the group broke up, a compilation, \"ABBA Gold\", was released, becoming a worldwide best-seller. In 1999, ABBA's music was adapted into \"Mamma Mia!\", a stage musical that toured worldwide and, as of October 2024, is still in the top-ten longest running productions on both Broadway (closed in 2015) and the West End (still running). A film of the same name, released in 2008, became the highest-grossing film in the United Kingdom that year. A sequel, \"Mamma Mia! Here We Go Again\", was released in 2018.\nABBA are among the best-selling music artists in history, with record sales estimated to be between 150 million to 385\u00a0million sold worldwide and the group were ranked 3rd best-selling singles artists in the United Kingdom with a total of 11.3\u00a0million singles sold by 3 November 2012. In May 2023, ABBA were awarded the BRIT Billion Award, which celebrates those who have surpassed the milestone of one billion UK streams in their career. ABBA were the first group from a non-English-speaking country to achieve consistent success in the charts of English-speaking countries, including the United Kingdom, Australia, United States, Republic of Ireland, Canada, New Zealand and South Africa. They are the best-selling Swedish band of all time and the best-selling band originating in continental Europe. ABBA had eight consecutive number-one albums in the UK. The group also enjoyed significant success in Latin America and recorded a collection of their hit songs in Spanish. ABBA were inducted into the Vocal Group Hall of Fame in 2002. The group were inducted into the Rock and Roll Hall of Fame in 2010, the first recording artists to receive this honour from outside an Anglophonic country. In 2015, their song \"Dancing Queen\" was inducted into the Recording Academy's Grammy Hall of Fame. In 2024, the United States Library of Congress included the album \"Arrival\" (1976) in the National Recording Registry, which recognises works \"worthy of preservation for all time based on their cultural, historical or aesthetic importance in the nation\u2019s recorded sound heritage\".\nIn 2016, the group reunited and started working on a digital avatar concert tour. Newly recorded songs were announced in 2018. \"Voyage\", their first new album in 40 years, was released on 5 November 2021 to positive critical reviews and strong sales in numerous countries. ABBA Voyage, a concert residency featuring ABBA as virtual avatars, opened in May 2022 in London.\nHistory.\n1958\u20131970: before ABBA.\nMember origins and collaboration.\nAgnetha F\u00e4ltskog (born 5 April 1950 in J\u00f6nk\u00f6ping, Sweden) sang with a local dance band (headed by Bernt Enghardt) who sent a demo recording of their music to Karl-Gerhard Lundkvist. The demo tape featured a song written and sung by Agnetha: \"Jag var s\u00e5 k\u00e4r\" (\"I Was So in Love\"). Lundkvist was so impressed with her voice that he was convinced she would be a star. After going through considerable effort to locate the singer, he arranged for Agnetha to come to Stockholm and to record two of her own songs. This led to Agnetha at the age of 18 having a number-one record in Sweden with a self-composed song, which later went on to sell over 80,000 copies. She was soon noticed by the critics and songwriters as a talented singer/songwriter of schlager style songs. F\u00e4ltskog's main inspiration in her early years was singers such as Connie Francis. Along with her own compositions, she recorded covers of foreign hits and performed them on tours in Swedish folkparks. Most of her biggest hits were self-composed, which was quite unusual for a female singer in the 1960s. Agnetha released four solo LPs between 1968 and 1971. She had many successful singles in the Swedish charts.\nBj\u00f6rn Ulvaeus (born 25 April 1945 in Gothenburg, Sweden) also began his musical career at the age of 18 (as a singer and guitarist), when he fronted the Hootenanny Singers, a popular Swedish folk\u2013skiffle group. Ulvaeus started writing English-language songs for his group and even had a brief solo career alongside. The Hootenanny Singers and the Hep Stars sometimes crossed paths while touring. In June 1966, Ulvaeus and Andersson decided to write a song together. Their first attempt was \"Isn't It Easy to Say\", a song that was later recorded by the Hep Stars. Stig Anderson was the manager of the Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration, and encouraged them to write more. The two also began playing occasionally with the other's bands on stage and on record, although it was not until 1969 that the pair wrote and produced some of their first real hits together: \"Ljuva sextital\" (\"Sweet Sixties\"), recorded by Brita Borg, and the Hep Stars' 1969 hit \"Speleman\" (\"Fiddler\").\nBenny Andersson (born 16 December 1946 in Stockholm, Sweden) became (at age 18) a member of a popular Swedish pop-rock group, the Hep Stars, that performed, among other things, covers of international hits. The Hep Stars were known as \"the Swedish Beatles\". They also set up Hep House, their equivalent of Apple Corps. Andersson played the keyboard and eventually started writing original songs for his band, many of which became major hits, including \"No Response\", which hit number three in 1965, and \"Sunny Girl\", \"Wedding\", and \"Consolation\", all of which hit number one in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he wrote his first Svensktoppen entry, \"Sagan om lilla Sofie\" (\"The tale of Little Sophie\") in 1968.\nAndersson wrote and submitted the song \"Hej, Clown\" for Melodifestivalen 1969, the national festival to select the Swedish entry to the Eurovision Song Contest. The song tied for first place, but re-voting relegated Andersson's song to second place. On that occasion Andersson briefly met his future spouse, singer Anni-Frid Lyngstad, who also participated in the contest. A month later, the two had become a couple. As their respective bands began to break up during 1969, Andersson and Ulvaeus teamed up and recorded their first album together in 1970, called \"Lycka\" (\"Happiness\"), which included original songs sung by both men. Their partners were often present in the recording studio, and sometimes added backing vocals; F\u00e4ltskog even co-wrote a song with the two. Ulvaeus still occasionally recorded and performed with the Hootenanny Singers until the middle of 1974, and Andersson took part in producing their records.\nAnni-Frid \"Frida\" Lyngstad (born 15 November 1945 in Bj\u00f8rk\u00e5sen in Ballangen Municipality, Norway) sang from the age of 13 with various dance bands, and worked mainly in a jazz-oriented cabaret style. She also formed her own band, the Anni-Frid Four. In the middle of 1967, she won a national talent competition with \"En ledig dag\" (\"A Day Off\"), a Swedish version of the bossa nova song \"A Day in Portofino\", which is included in the EMI compilation \"Frida 1967\u20131972\". The first prize was a recording contract with EMI Sweden and to perform live on the most popular TV shows in the country. This TV performance, among many others, is included in the -hour documentary \"Frida \u2013 The DVD\". Lyngstad released several schlager style singles on EMI with mixed success. When Benny Andersson started to produce her recordings in 1971, she had her first number-one single, \"Min egen stad\" (\"My Own Town\"), written by Benny and featuring all the future ABBA members on backing vocals. Lyngstad toured and performed regularly in the folkpark circuit and made appearances on radio and TV. She had a second number-one single with \"Man Vill Ju Leva Lite Dessemellan\" in late 1972. She had met Ulvaeus briefly in 1963 during a talent contest, and F\u00e4ltskog during a TV show in early 1968.\nLyngstad linked up with her future bandmates in 1969. On 1 March 1969, she participated in the Melodifestival, where she met Andersson for the first time. A few weeks later they met again during a concert tour in southern Sweden and they soon became a couple. Andersson produced her single \"Peter Pan\" in September 1969\u2014her first collaboration with Benny &amp; Bj\u00f6rn, as they had written the song. Andersson would then produce Lyngstad's debut studio album, \"Frida\", which was released in March 1971. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another successful album in 1975, \"Frida ensam\", which included the original Swedish rendition of \"Fernando\", a hit on the Swedish radio charts before the English version was released by ABBA.\nDuring filming of a Swedish TV special in May 1969, F\u00e4ltskog met Ulvaeus and they married on 6 July 1971. F\u00e4ltskog and Ulvaeus eventually were involved in each other's recording sessions, and soon even Andersson and Lyngstad added backing vocals to F\u00e4ltskog's third studio album, \"Som jag \u00e4r\" (\"As I Am\") (1970). In 1972, F\u00e4ltskog starred as Mary Magdalene in the original Swedish production of \"Jesus Christ Superstar\" and attracted favourable reviews. Between 1967 and 1975, F\u00e4ltskog released five studio albums.\nFirst live performance and the start of \"Festfolket\".\nAn attempt at combining their talents occurred in April 1970 when the two couples went on holiday together to the island of Cyprus. What started as singing for fun on the beach ended up as an improvised live performance in front of the United Nations soldiers stationed on the island. Andersson and Ulvaeus were at this time recording their first album together, \"Lycka\", which was to be released in September 1970. F\u00e4ltskog and Lyngstad added backing vocals on several tracks during June, and the idea of their working together saw them launch a stage act, \"Festfolket\" (which translates from Swedish to \"Party People\" and in pronunciation also \"engaged couples\"), on 1 November 1970 in Gothenburg.\nThe cabaret show attracted generally negative reviews, except for the performance of the Andersson and Ulvaeus hit \"Hej, gamle man\" (\"Hello, Old Man\")\u2014the first Bj\u00f6rn and Benny recording to feature all four. They also performed solo numbers from respective albums, but the lukewarm reception convinced the foursome to shelve plans for working together for the time being, and each soon concentrated on individual projects again.\nFirst record together \"Hej, gamle man\".\n\"Hej, gamle man\", a song about an old Salvation Army soldier, became the quartet's first hit. The record was credited to Bj\u00f6rn &amp; Benny and reached number five on the sales charts and number one on Svensktoppen, staying on the latter chart (which was not a chart linked to sales or airplay) for 15 weeks.\nIt was during 1971 that the four artists began working together more, adding vocals to the others' recordings. F\u00e4ltskog, Andersson and Ulvaeus toured together in May, while Lyngstad toured on her own. Frequent recording sessions brought the foursome closer together during the summer.\n1970\u20131973: forming the group.\nAfter the 1970 release of \"Lycka\", two more singles credited to \"Bj\u00f6rn &amp; Benny\" were released in Sweden, \"Det kan ingen doktor hj\u00e4lpa\" (\"No Doctor Can Help with That\") and \"T\u00e4nk om jorden vore ung\" (\"Imagine If Earth Was Young\"), with more prominent vocals by F\u00e4ltskog and Lyngstad\u2013and moderate chart success. F\u00e4ltskog and Ulvaeus, now married, started performing together with Andersson on a regular basis at the Swedish folkparks in the middle of 1971.\nStig Anderson, founder and owner of Polar Music, was determined to break into the mainstream international market with music by Andersson and Ulvaeus. \"One day the pair of you will write a song that becomes a worldwide hit,\" he predicted. Stig Anderson encouraged Ulvaeus and Andersson to write a song for Melodifestivalen, and after two rejected entries in 1971, Andersson and Ulvaeus submitted their new song \"S\u00e4g det med en s\u00e5ng\" (\"Say It with a Song\") for the 1972 contest, choosing newcomer Lena Anderson to perform. The song came in third place, encouraging Stig Anderson, and became a hit in Sweden.\nThe first signs of foreign success came as a surprise, as the Andersson and Ulvaeus single \"She's My Kind of Girl\" was released through Epic Records in Japan in March 1972, giving the duo a Top 10 hit. Two more singles were released in Japan, \"En Carousel\" (\"En Karusell\" in Scandinavia, an earlier version of \"Merry-Go-Round\") and \"Love Has Its Ways\" (a song they wrote with K\u014dichi Morita).\nFirst hit as Bj\u00f6rn, Benny, Agnetha and Anni-Frid.\nUlvaeus and Andersson persevered with their songwriting and experimented with new sounds and vocal arrangements. \"People Need Love\" was released in June 1972, featuring guest vocals by the women, who were now given much greater prominence. Stig Anderson released it as a single, credited to \"Bj\u00f6rn &amp; Benny, Agnetha &amp; Anni-Frid\". The song peaked at number 17 in the Swedish combined single and album charts, enough to convince them they were on to something.\n\"People Need Love\" also became the first record to chart for the quartet in the United States, where it peaked at number 114 on the \"Cashbox\" singles chart and number 117 on the \"Record World\" singles chart. Labelled as \"Bj\u00f6rn &amp; Benny (with Svenska Flicka)\" meaning Swedish Girl, it was released there through Playboy Records. According to Stig Anderson, \"People Need Love\" could have been a much bigger American hit, but a small label like Playboy Records did not have the distribution resources to meet the demand for the single from retailers and radio programmers.\n\"Ring Ring\".\nIn 1973, the band and their manager Stig Anderson decided to have another try at Melodifestivalen, this time with the song \"Ring Ring\". The studio sessions were handled by Michael B. Tretow, who experimented with a \"wall of sound\" production technique that became a distinctive new sound thereafter associated with ABBA. Stig Anderson arranged an English translation of the lyrics by Neil Sedaka and Phil Cody and they thought this would be a success. However, on 10 February 1973, the song came third in Melodifestivalen; thus it never reached the Eurovision Song Contest itself. Nevertheless, the group released their debut studio album, also called \"Ring Ring\". The album did well and the \"Ring Ring\" single was a hit in many parts of Europe and also in South Africa. However, Stig Anderson felt that the true breakthrough could only come with a UK or US hit.\nWhen Agnetha F\u00e4ltskog gave birth to her daughter Linda in 1973, she was replaced for a short period by Inger Brundin on a trip to West Germany.\nOfficial naming.\nIn 1973, Stig Anderson, tired of unwieldy names, started to refer to the group privately and publicly as ABBA (a palindrome). At first, this was a play on words, as Abba is also the name of a well-known fish-canning company in Sweden, and itself an abbreviation. However, since the fish-canners were unknown outside Sweden, Anderson came to believe the name would work in international markets. A competition to find a suitable name for the group was held in a Gothenburg newspaper and it was officially announced in the summer that the group were to be known as \"ABBA\". The group negotiated with the canners for the rights to the name. Fred Bronson reported for \"Billboard\" that F\u00e4ltskog told him in a 1988 interview that \"[ABBA] had to ask permission and the factory said, 'O.K., as long as you don't make us feel ashamed for what you're doing. \n\"ABBA\" is an acronym formed from the first letters of each group member's first name: Agnetha, Bj\u00f6rn, Benny, Anni-Frid, although there has never been any official confirmation of who each letter in the sequence refers to. The earliest known example of \"ABBA\" written on paper is on a recording session sheet from the Metronome Studio in Stockholm dated 16 October 1973. This was first written as \"Bj\u00f6rn, Benny, Agnetha &amp; Frida\", but was subsequently crossed out with \"ABBA\" written in large letters on top.\nOfficial logo.\nTheir official logo, with its distinctive backward \"B\", was designed by Rune S\u00f6derqvist, who designed most of ABBA's record sleeves. The ambigram first appeared on the French compilation album, \"Golden Double Album\", released in May 1976 by Disques Vogue, and would henceforth be used for all official releases.\nThe idea for the official logo was made by the German photographer on a velvet jumpsuit photo shoot for the teenage magazine \"Bravo\". In the photo, the ABBA members held giant initial letters of their names. After the pictures were made, Heilemann found out that Benny Andersson reversed his letter \"B;\" this prompted discussions about the mirrored \"B\", and the members of ABBA agreed on the mirrored letter. From 1976 onward, the first \"B\" in the logo version of the name was \"mirror-image\" reversed on the band's promotional material.\nFollowing their acquisition of the group's catalogue, PolyGram began using variations of the ABBA logo, employing a different font. In 1992, Polygram added a crown emblem to it for the first release of the \"ABBA Gold: Greatest Hits\" compilation. After Universal Music purchased PolyGram (and, thus, ABBA's label Polar Music International), control of the group's catalogue returned to Stockholm. Since then, the original logo has been reinstated on all official products.\n1973\u20131976: breakthrough.\nEurovision Song Contest 1974.\nABBA entered the Melodifestivalen with \"Ring Ring\" but did not qualify as the 1973 Swedish entry. Stig Anderson started planning for the 1974 contest. Ulvaeus, Andersson and Stig Anderson saw possibilities in using the Eurovision Song Contest to make the music business aware of them as songwriters, as well as to publicise the band. In late 1973 they were invited by Swedish television to contribute a song for the Melodifestivalen 1974, and the upbeat song \"Waterloo\" was chosen. The group were now inspired by the growing glam rock scene in England.\nWith this third attempt, ABBA were more experienced and better prepared for the Eurovision Song Contest, and they won the nation's hearts on Swedish television on 9 February 1974. Winning the 1974 Eurovision Song Contest on 6 April 1974, and singing \"Waterloo\" in English instead of their native language, gave them the chance to tour Europe and perform on major television shows, as a result of which the \"Waterloo\" single charted in many European countries. After winning the contest, ABBA spent an evening of glory partying in the appropriately named first-floor Napoleon suite of The Grand Brighton Hotel.\n\"Waterloo\" was ABBA's first major hit and their first number-one single in nine western and northern European countries, including the major markets of the UK and West Germany, and in South Africa. It made the top ten in other countries, rising to number three in Spain, number four in Australia and France, and number seven in Canada. In the United States, the song peaked at number six on the \"Billboard\" Hot 100 chart, paving the way for their first album and their first trip to the US as a group. Although only a short promotional visit, this included their first performance on American television, on \"The Mike Douglas Show\". The \"Waterloo\" album peaked at only number 145 on the \"Billboard\" 200 chart, but received unanimous praise from US critics. The \"Los Angeles Times\" said the album was a \"compelling and fascinating debut album\" that captured the spirit of mainstream pop, and described it as \"immensely enjoyable and pleasant\", while \"Creem\" said it was \"a perfect blend of exceptional, lovable compositions\".\nABBA's follow-up single, \"Honey, Honey\", peaked at number 27 on the US \"Billboard\" Hot 100, reached the top twenty in several other countries, and was a number-two hit in West Germany, although it only reached the top 30 in Australia and the US. In the UK, ABBA's British record label, Epic, decided to re-release a remixed version of \"Ring Ring\" instead of \"Honey, Honey\". A cover version of \"Honey, Honey\" by Sweet Dreams peaked at number 10, and both records debuted on the UK chart within a week of each other. \"Ring Ring\" failed to reach the Top 30 in the UK, increasing growing speculation that the group were simply a Eurovision one-hit wonder.\nPost-Eurovision.\nIn November 1974, ABBA embarked on their first European tour, playing dates in Denmark, West Germany and Austria. It was not as successful as the band had hoped, since most of the venues did not sell out. Due to a lack of demand, they were even forced to cancel a few shows, including a sole concert scheduled in Switzerland. The second leg of the tour, which took them through Scandinavia in January 1975, was very different. They played to full houses everywhere and finally got the reception they had aimed for. Live performances continued in the middle of 1975 when ABBA embarked on a fourteen open-air date tour of Sweden and Finland. Their Stockholm show at the Gr\u00f6na Lund amusement park had an estimated audience of 19,200. Bj\u00f6rn Ulvaeus later said, \"If you look at the singles we released straight after Waterloo, we were trying to be more like The Sweet, a semi-glam rock group, which was stupid because we were always a pop group.\"\nIn late 1974, \"So Long\" was released as a single in the United Kingdom but it received no airplay from Radio 1 and failed to chart in the UK; the only countries in which it was successful were Austria, Sweden and Germany, reaching the top ten in the first two and number 21 in the latter. In the middle of 1975, ABBA released \"I Do, I Do, I Do, I Do, I Do\", which again received little airplay on Radio 1, but did manage to climb to number 38 on the UK chart, while making top five in several northern and western European countries, and number one in South Africa. Later that year, the release of their self-titled third studio album \"ABBA\" and single \"SOS\" brought back their chart presence in the UK, where the single hit number six and the album peaked at number 13. \"SOS\" also became ABBA's second number-one single in Germany, their third in Australia and reached number two in several other European countries, including Italy.\nSuccess was further solidified with \"Mamma Mia\" reaching number-one in the United Kingdom, Germany and Australia and the top two in a few other western and northern European countries. In the United States, both \"I Do, I Do, I Do, I Do, I Do\" and \"SOS\" peaked at number 15 on the \"Billboard\" Hot 100 chart, with the latter picking up the BMI Award along the way as one of the most played songs on American radio in 1975. \"Mamma Mia\", however, stalled at number 32. In Canada, the three songs rose to number 12, nine and 18, respectively.\nThe success of the group in the United States had until that time been limited to single releases. By early 1976, the group already had four Top 30 singles on the US charts, but the album market proved to be tough to crack. The eponymous \"ABBA\" album generated three American hits, but it only peaked at number 165 on the \"Cashbox\" album chart and number 174 on the \"Billboard\" 200 chart. Opinions were voiced, by \"Creem\" in particular, that in the US ABBA had endured \"a very sloppy promotional campaign\". Nevertheless, the group enjoyed warm reviews from the American press. \"Cashbox\" went as far as saying that \"there is a recurrent thread of taste and artistry inherent in Abba's marketing, creativity and presentation that makes it almost embarrassing to critique their efforts\", while \"Creem\" wrote: \"SOS is surrounded on this LP by so many good tunes that the mind boggles.\"\nIn Australia, the airing of the music videos for \"I Do, I Do, I Do, I Do, I Do\" and \"Mamma Mia\" on the nationally broadcast TV pop show \"Countdown\" (which premiered in November 1974) saw the band rapidly gain enormous popularity, and \"Countdown\" become a key promoter of the group via their distinctive music videos. This started an immense interest for ABBA in Australia, resulting in \"I Do, I Do, I Do, I Do, I Do\" staying at number one for three weeks, then \"SOS\" spending a week there, followed by \"Mamma Mia\" staying there for ten weeks, and the album holding down the number one position for months. The three songs were also successful in nearby New Zealand with the first two topping that chart and the third reaching number two.\n1976\u20131981: superstardom.\n\"Greatest Hits\" and \"Arrival\".\nIn March 1976, the band released the compilation album \"Greatest Hits\". It became their first UK number-one album, and also took ABBA into the Top 50 on the US album charts for the first time, eventually selling more than a million copies there. Also included on \"Greatest Hits\" was a new single, \"Fernando\", which went to number-one in at least thirteen countries all over the world, including the UK, Germany, France, Australia, South Africa and Mexico, and the top five in most other significant markets, including, at number four, becoming their biggest hit to date in Canada; the single went on to sell over 10\u00a0million copies worldwide.\nIn Australia, \"Fernando\" occupied the top position for a then record breaking 14 weeks (and stayed in the chart for 40 weeks), and was the longest-running chart-topper there for over 40 years until it was overtaken by Ed Sheeran's \"Shape of You\" in May 2017. It still remains as one of the best-selling singles of all time in Australia. Also in 1976, the group received its first international prize, with \"Fernando\" being chosen as the \"Best Studio Recording of 1975\". In the United States, \"Fernando\" reached the Top 10 of the Cashbox Top 100 singles chart and number 13 on the \"Billboard\" Hot 100. It topped the \"Billboard\" Adult Contemporary chart, ABBA's first American number-one single on any chart. At the same time, a compilation named \"The Very Best of ABBA\" was released in Germany, becoming a number-one album there whereas the \"Greatest Hits\" compilation which followed a few months later ascended to number two in Germany, despite all similarities with \"The Very Best\" album.\nThe group's fourth studio album, \"Arrival\", a number-one best-seller in parts of Europe, the UK and Australia, and a number-three hit in Canada and Japan, represented a new level of accomplishment in both songwriting and studio work, prompting rave reviews from more rock-oriented UK music weeklies such as \"Melody Maker\" and \"New Musical Express\", and mostly appreciative notices from US critics.\nHit after hit flowed from \"Arrival\": \"Money, Money, Money\", another number-one in Germany, France, Australia and other countries of western and northern Europe, plus number three in the UK; and, \"Knowing Me, Knowing You\", ABBA's sixth consecutive German number-one, as well as another UK number-one, plus a top five hit in many other countries, although it was only a number nine hit in Australia and France. The real sensation was the first single, \"Dancing Queen\", not only topping the charts in loyal markets like the UK, Germany, Sweden, several other western and northern European countries, and Australia, but also reaching number-one in the United States, Canada, the Soviet Union and Japan, and the top ten in France, Spain and Italy. All three songs were number-one hits in Mexico. In South Africa, ABBA had astounding success with each of \"Fernando\", \"Dancing Queen\" and \"Knowing Me, Knowing You\" being among the top 20 best-selling singles for 1976\u201377. In 1977, \"Arrival\" was nominated for the inaugural BRIT Award in the category \"Best International Album of the Year\". By this time ABBA were popular in the UK, most of Europe, Australia, New Zealand and Canada. In \"Frida \u2013 The DVD\", Lyngstad explains how she and F\u00e4ltskog developed as singers, as ABBA's recordings grew more complex over the years.\nThe band's mainstream popularity in the United States would remain on a comparatively smaller scale, and \"Dancing Queen\" became the only \"Billboard\" Hot 100 number-one single for ABBA (though it immediately became, and remains to this day, a major gay anthem) with \"Knowing Me, Knowing You\" later peaking at number seven; \"Money, Money, Money\", however, had barely charted there or in Canada (where \"Knowing Me, Knowing You\" had reached number five). They did, however, get three more singles to the number-one position on other \"Billboard\" US charts, including \"Billboard\" Adult Contemporary and Hot Dance Club Play). Nevertheless, \"Arrival\" finally became a true breakthrough release for ABBA on the US album market where it peaked at number 20 on the \"Billboard\" 200 chart and was certified gold by RIAA.\nEuropean and Australian tour.\nIn January 1977, ABBA embarked on their first major tour. The group's status had changed dramatically and they were widely regarded as superstars. They opened their much anticipated tour in Oslo, Norway, on 28 January, and mounted a lavishly produced spectacle that included a few scenes from their self-written mini-operetta \"The Girl with the Golden Hair\". The concert attracted huge media attention from across Europe and Australia. They continued the tour through Western Europe, visiting Gothenburg, Copenhagen, Berlin, Cologne, Amsterdam, Antwerp, Essen, Hanover, and Hamburg and ending with shows in the United Kingdom in Manchester, Birmingham, Glasgow and two sold-out concerts at London's Royal Albert Hall. Tickets for these two shows were available only by mail application and it was later revealed that the box-office received 3.5\u00a0million requests for tickets, enough to fill the venue 580 times.\nAlong with praise (\"ABBA turn out to be amazingly successful at reproducing their records\", wrote \"Creem\"), there were complaints that \"ABBA performed slickly...but with a zero personality coming across from a total of 16 people on stage\" (\"Melody Maker\"). One of the Royal Albert Hall concerts was filmed as a reference for the filming of the Australian tour for what became \"\", though it is not exactly known how much of the concert was filmed.\nAfter the European leg of the tour, in March 1977, ABBA played 11 dates in Australia before a total of 160,000 people. The opening concert in Sydney at the Sydney Showground on 3 March to an audience of 20,000 was marred by torrential rain with Lyngstad slipping on the wet stage during the concert. However, all four members would later recall this concert as the most memorable of their career.\nUpon their arrival in Melbourne, a civic reception was held at the Melbourne Town Hall and ABBA appeared on the balcony to greet an enthusiastic crowd of 6,000. In Melbourne, the group gave three concerts at the Sidney Myer Music Bowl with 14,500 at each including the Australian Prime Minister Malcolm Fraser and his family. At the first Melbourne concert, an additional 16,000 people gathered outside the fenced-off area to listen to the concert. In Adelaide, the group performed one concert at Football Park in front of 20,000 people, with another 10,000 listening outside. During the first of five concerts in Perth, there was a bomb scare with everyone having to evacuate the Entertainment Centre. The trip was accompanied by mass hysteria and unprecedented media attention (\"Swedish ABBA stirs box-office in Down Under tour...and the media coverage of the quartet rivals that set to cover the upcoming Royal tour of Australia\", wrote \"Variety\"), and is captured on film in \"\", directed by Lasse Hallstr\u00f6m.\nThe Australian tour and its subsequent \"ABBA: The Movie\" produced some ABBA lore, as well. F\u00e4ltskog's blonde good looks had long made her the band's \"pin-up girl\", a role she disdained. During the Australian tour, she performed in a skin-tight white jumpsuit, causing one Australian newspaper to use the headline \"Agnetha's bottom tops dull show\". When asked about this at a news conference, she replied: \"Don't they have bottoms in Australia?\"\n\"ABBA: The Album\".\nIn December 1977, ABBA followed up \"Arrival\" with the more ambitious fifth album, \"\", released to coincide with the debut of \"ABBA: The Movie\". Although the album was less well received by UK reviewers, it did spawn more worldwide hits: \"The Name of the Game\" and \"Take a Chance on Me\", which both topped the UK charts and racked up impressive sales in most countries, although \"The Name of the Game\" was generally the more successful in the Nordic countries and Australia, while \"Take a Chance on Me\" was more successful in North America and the German-speaking countries.\n\"The Name of the Game\" was a number two hit in the Netherlands, Belgium and Sweden while also making the Top 5 in Finland, Norway, New Zealand and Australia, while only peaking at numbers 10, 12 and 15 in Mexico, the US and Canada. \"Take a Chance on Me\" was a number one hit in Austria, Belgium and Mexico, made the Top 3 in the US, Canada, the Netherlands, Germany and Switzerland, while only reaching numbers 12 and 14 in Australia and New Zealand, respectively. Both songs were Top 10 hits in countries as far afield as Rhodesia and South Africa, as well as in France. Although \"Take a Chance on Me\" did not top the American charts, it proved to be ABBA's biggest hit single there, selling more copies than \"Dancing Queen\". The drop in sales in Australia was felt to be inevitable by industry observers as an \"Abba-Fever\" that had existed there for almost three years could only last so long as adolescents would naturally begin to move away from a group so deified by both their parents and grandparents.\nA third single, \"Eagle\", was released in continental Europe and Australia becoming a number one hit in Belgium and a Top 10 hit in the Netherlands, Germany, Switzerland and South Africa, but barely charting in Australia. The B-side of \"Eagle\" was \"Thank You for the Music\", and it was belatedly released as an A-side single in both the United Kingdom and Ireland in 1983. \"Thank You for the Music\" has become one of the best loved and best known ABBA songs without being released as a single during the group's lifetime. \"ABBA: The Album\" topped the album charts in the UK, the Netherlands, New Zealand, Sweden, Norway, Switzerland, while ascending to the Top 5 in Australia, Germany, Austria, Finland and Rhodesia, and making the Top 10 in Canada and Japan. Sources also indicate that sales in Poland exceeded 1 million copies and that sales demand in Russia could not be met by the supply available. The album peaked at number 14 in the US.\nPolar Music Studio formation.\nBy 1978, ABBA were one of the biggest bands in the world. They converted a vacant cinema into the Polar Music Studio, a state-of-the-art studio in Stockholm. The studio was used by several other bands; notably Genesis' \"Duke\", Led Zeppelin's \"In Through the Out Door\" and Scorpions's \"Lovedrive\" were recorded there. During May 1978, the group went to the United States for a promotional campaign, performing alongside Andy Gibb on Olivia Newton-John's TV show. Recording sessions for the single \"Summer Night City\" were an uphill struggle, but upon release the song became another hit for the group. The track would set the stage for ABBA's foray into disco with their next album.\nOn 9 January 1979, the group performed \"Chiquitita\" at the Music for UNICEF Concert held at the United Nations General Assembly to celebrate UNICEF's Year of the Child. ABBA donated the copyright of this worldwide hit to the UNICEF; see Music for UNICEF Concert. The single was released the following week, and reached number-one in ten countries.\nNorth American and European tours.\nIn mid-January 1979, Ulvaeus and F\u00e4ltskog announced they were getting divorced. The news caused interest from the media and led to speculation about the band's future. ABBA assured the press and their fan base they were continuing their work as a group and that the divorce would not affect them. Nonetheless, the media continued to confront them with this in interviews. To escape the media swirl and concentrate on their writing, Andersson and Ulvaeus secretly travelled to Compass Point Studios in Nassau, Bahamas, where for two weeks they prepared their next album's songs.\nThe group's sixth studio album, \"Voulez-Vous\", was released in April 1979, with its title track recorded at the famous Criteria Studios in Miami, Florida, with the assistance of recording engineer Tom Dowd among others. The album topped the charts across Europe and in Japan and Mexico, hit the Top 10 in Canada and Australia and the Top 20 in the US. While none of the singles from the album reached number one on the UK chart, the lead single, \"Chiquitita\", and the fourth single, \"I Have a Dream\", both ascended to number two, and the other two, \"Does Your Mother Know\" and \"Angeleyes\" (with \"Voulez-Vous\", released as a double A-side) both made the top 5. All four singles reached number one in Belgium, although the last three did not chart in Sweden or Norway. \"Chiquitita\", which was featured in the \"Music for UNICEF Concert\" after which ABBA decided to donate half of the royalties from the song to UNICEF, topped the singles charts in the Netherlands, Switzerland, Finland, Spain, Mexico, South Africa, Rhodesia and New Zealand, rose to number two in Sweden, and made the Top 5 in Germany, Austria, Norway and Australia, although it only reached number 29 in the US.\n\"I Have a Dream\" was a sizeable hit reaching number one in the Netherlands, Switzerland, and Austria, number three in South Africa, and number four in Germany, although it only reached number 64 in Australia. In Canada, \"I Have a Dream\" became ABBA's second number one on the RPM Adult Contemporary chart (after \"Fernando\" hit the top previously) although it did not chart in the US. \"Does Your Mother Know\", a rare song in which Ulvaeus sings lead vocals, was a Top 5 hit in the Netherlands and Finland, and a Top 10 hit in Germany, Switzerland, Australia, although it only reached number 27 in New Zealand. It did better in North America than \"Chiquitita\", reaching number 12 in Canada and number 19 in the US, and made the Top 20 in Japan. \"Voulez-Vous\" was a Top 10 hit in the Netherlands and Switzerland, a Top 20 hit in Germany and Finland, but only peaked in the 80s in Australia, Canada and the US.\nAlso in 1979, the group released their second compilation album, \"Greatest Hits Vol. 2\", which featured a brand-new track: \"Gimme! Gimme! Gimme! (A Man After Midnight)\", which was a Top 3 hit in the UK, Belgium, the Netherlands, Germany, Austria, Switzerland, Finland and Norway, and returned ABBA to the Top 10 in Australia. \"Greatest Hits Vol. 2\" went to number one in the UK, Belgium, Canada and Japan while making the Top 5 in several other countries, but only reaching number 20 in Australia and number 46 in the US. In the Soviet Union during the late 1970s, the group were paid in oil commodities because of an embargo on the rouble.\nOn 13 September 1979, ABBA began at Northlands Coliseum in Edmonton, Canada, with a full house of 14,000. \"The voices of the band, Agnetha's high sauciness combined with round, rich lower tones of Anni-Frid, were excellent...Technically perfect, melodically correct and always in perfect pitch...The soft lower voice of Anni-Frid and the high, edgy vocals of Agnetha were stunning\", raved \"Edmonton Journal\".\nDuring the next four weeks they played a total of 17 sold-out dates, 13 in the United States and four in Canada. The last scheduled ABBA concert in the United States in Washington, D.C. was cancelled due to emotional distress F\u00e4ltskog experienced during the flight from New York to Boston. The group's private plane was subjected to extreme weather conditions and was unable to land for an extended period. They appeared at the Boston Music Hall for the performance 90 minutes late. The tour ended with a show in Toronto, Canada at Maple Leaf Gardens before a capacity crowd of 18,000. \"ABBA plays with surprising power and volume; but although they are loud, they're also clear, which does justice to the signature vocal sound... Anyone who's been waiting five years to see Abba will be well satisfied\", wrote \"Record World\". On 19 October 1979, the tour resumed in Western Europe where the band played 23 sold-out gigs, including six sold-out nights at London's Wembley Arena.\nProgression.\nIn March 1980, ABBA travelled to Japan where upon their arrival at Narita International Airport, they were besieged by thousands of fans. The group performed eleven concerts to full houses, including six shows at Tokyo's Budokan. This tour was the last \"on the road\" adventure of their career.\nIn July 1980, ABBA released the single \"The Winner Takes It All\", the group's eighth UK chart topper (and their first since 1978). The song is widely misunderstood as being written about Ulvaeus and F\u00e4ltskog's marital tribulations; Ulvaeus wrote the lyrics, but has stated they were not about his own divorce; F\u00e4ltskog has repeatedly stated she was not the loser in their divorce. In the United States, the single peaked at number-eight on the \"Billboard\" Hot 100 chart and became ABBA's second \"Billboard\" Adult Contemporary number-one. It was also re-recorded by Andersson and Ulvaeus with a slightly different backing track, by French chanteuse Mireille Mathieu at the end of 1980\u00a0\u2013 as \"Bravo tu as gagn\u00e9\", with French lyrics by Alain Boublil.\nIn November 1980, ABBA's seventh album \"Super Trouper\" was released, which reflected a certain change in ABBA's style with more prominent use of synthesizers and increasingly personal lyrics. It set a record for the most pre-orders ever received for a UK album after one million copies were ordered before release. The second single from the album, \"Super Trouper\", also hit number-one in the UK, becoming the group's ninth and final UK chart-topper. Another track from the album, \"Lay All Your Love on Me\", released in 1981 as a Twelve-inch single only in selected territories, managed to top the \"Billboard\" Hot Dance Club Play chart and peaked at number-seven on the UK singles chart becoming, at the time, the highest ever charting 12-inch release in UK chart history.\nAlso in 1980, ABBA recorded a compilation of Spanish-language versions of their hits called \"Gracias Por La M\u00fasica\". This was released in Spanish-speaking countries as well as in Japan and Australia. The album became a major success, and along with the Spanish version of \"Chiquitita\", this signalled the group's breakthrough in Latin America. \"ABBA Oro: Grandes \u00c9xitos\", the Spanish equivalent of \"ABBA Gold: Greatest Hits\", was released in 1999.\n1981\u20131982: \"The Visitors\" and later performances.\nIn January 1981, Ulvaeus married Lena K\u00e4llersj\u00f6, and manager Stig Anderson celebrated his 50th birthday with a party. For this occasion, ABBA recorded the track \"Hovas Vittne\" (a pun on the Swedish name for Jehovah's Witness and Anderson's birthplace, Hova) as a tribute to him, and released it only on 200 red vinyl copies, to be distributed to the guests attending the party. This single has become a sought-after collectable. In mid-February 1981, Andersson and Lyngstad announced they were filing for divorce. Information surfaced that their marriage had been an uphill struggle for years, and Benny had already met another woman, Mona N\u00f6rklit, whom he married in November 1981.\nAndersson and Ulvaeus had songwriting sessions in early 1981, and recording sessions began in mid-March. At the end of April, the group recorded a TV special, \"Dick Cavett Meets ABBA\" with the US talk show host Dick Cavett. \"The Visitors\", ABBA's eighth studio album, showed a songwriting maturity and depth of feeling distinctly lacking from their earlier recordings but still placing the band squarely in the pop genre, with catchy tunes and harmonies. Although not revealed at the time of its release, the album's title track, according to Ulvaeus, refers to the secret meetings held against the approval of totalitarian governments in Soviet-dominated states, while other tracks address topics like failed relationships, the threat of war, ageing, and loss of innocence. The album's only major single release, \"One of Us\", proved to be the last of ABBA's nine number-one singles in Germany, this being in December 1981; and the swansong of their sixteen Top 5 singles on the South African chart. \"One of Us\" was also ABBA's final Top 3 hit in the UK, reaching number-three on the UK Singles Chart.\nAlthough it topped the album charts across most of Europe, including Ireland, the UK and Germany, \"The Visitors\" was not as commercially successful as its predecessors, showing a commercial decline in previously loyal markets such as France, Australia and Japan. A track from the album, \"When All Is Said and Done\", was released as a single in North America, Australia and New Zealand, and fittingly became ABBA's final Top 40 hit in the US (debuting on the US charts on 31 December 1981), while also reaching the US Adult Contemporary Top 10, and number-four on the RPM Adult Contemporary chart in Canada. The song's lyrics, as with \"The Winner Takes It All\" and \"One of Us\", dealt with the painful experience of separating from a long-term partner, though it looked at the trauma more optimistically. With the now publicised story of Andersson and Lyngstad's divorce, speculation increased of tension within the band. Also released in the United States was the title track of \"The Visitors\", which hit the Top Ten on the \"Billboard\" Hot Dance Club Play chart.\nLater recording sessions.\nIn the spring of 1982, songwriting sessions had started and the group came together for more recordings. Plans were not completely clear, but a new album was discussed and the prospect of a small tour suggested. The recording sessions in May and June 1982 were a struggle, and only three songs were eventually recorded: \"You Owe Me One\", \"I Am the City\" and \"Just Like That\". Andersson and Ulvaeus were not satisfied with the outcome, so the tapes were shelved and the group took a break for the summer.\nBack in the studio again in early August, the group had changed plans for the rest of the year: they settled for a Christmas release of a double album compilation of all their past single releases to be named \"\". New songwriting and recording sessions took place, and during October and December, they released the singles \"The Day Before You Came\"/\"Cassandra\" and \"Under Attack\"/\"You Owe Me One\", the A-sides of which were included on the compilation album. Neither single made the Top 20 in the United Kingdom, though \"The Day Before You Came\" became a Top 5 hit in many European countries such as Germany, the Netherlands and Belgium. The album went to number one in the UK and Belgium, Top 5 in the Netherlands and Germany and Top 20 in many other countries. \"Under Attack\", the group's final release before disbanding, was a Top 5 hit in the Netherlands and Belgium.\n\"I Am the City\" and \"Just Like That\" were left unreleased on \"The Singles: The First Ten Years\" for possible inclusion on the next projected studio album, though this never came to fruition. \"I Am the City\" was eventually released on the compilation album \"\" in 1993, while \"Just Like That\" has been recycled in new songs with other artists produced by Andersson and Ulvaeus. A reworked version of the verses ended up in the musical \"Chess\". The chorus section of \"Just Like That\" was eventually released on a retrospective box set in 1994, as well as in the \"ABBA Undeleted\" medley featured on disc 9 of \"The Complete Studio Recordings\". Despite a number of requests from fans, Ulvaeus and Andersson are still refusing to release ABBA's version of \"Just Like That\" in its entirety, even though the complete version has surfaced on bootlegs.\nThe group travelled to London to promote \"The Singles: The First Ten Years\" in the first week of November 1982, appearing on \"Saturday Superstore\" and \"The Late, Late Breakfast Show\", and also to West Germany in the second week, to perform on Show Express. On 19 November 1982, ABBA appeared for the last time in Sweden on the TV programme N\u00f6jesmaskinen, and on 11 December 1982, they made their last performance ever, transmitted to the UK on Noel Edmonds' \"The Late, Late Breakfast Show\", through a live link from a TV studio in Stockholm.\nLater performances.\nAndersson and Ulvaeus began collaborating with Tim Rice in early 1983 on writing songs for the musical project \"Chess\", while F\u00e4ltskog and Lyngstad both concentrated on international solo careers. While Andersson and Ulvaeus were working on the musical, a further co-operation among the three of them came with the musical \"Abbacadabra\" that was produced in France for television. It was a children's musical using 14\u00a0ABBA songs. Alain and Daniel Boublil, who wrote \"Les Mis\u00e9rables\", had been in touch with Stig Anderson about the project, and the TV musical was aired over Christmas on French TV and later a Dutch version was also broadcast. Boublil previously also wrote the French lyric for Mireille Mathieu's version of \"The Winner Takes It All\".\nLyngstad, who had recently moved to Paris, participated in the French version, and recorded a single, \"Belle\", a duet with French singer Daniel Balavoine. The song was a cover of ABBA's 1976 instrumental track \"Arrival\". As the single \"Belle\" sold well in France, Cameron Mackintosh wanted to stage an English-language version of the show in London, with the French lyrics translated by David Wood and Don Black; Andersson and Ulvaeus got involved in the project, and contributed with one new song, \"I Am the Seeker\". \"Abbacadabra\" premiered on 8 December 1983 at the Lyric Hammersmith Theatre in London, to mixed reviews and full houses for eight weeks, closing on 21 January 1984. Lyngstad was also involved in this production, recording \"Belle\" in English as \"Time\", a duet with actor and singer B. A. Robertson: the single sold well and was produced and recorded by Mike Batt. In May 1984, Lyngstad performed \"I Have a Dream\" with a children's choir at the United Nations Organisation Gala, in Geneva, Switzerland.\nAll four members made their (at the time, final) public appearance as four friends more than as ABBA in January 1986, when they recorded a video of themselves performing an acoustic version of \"Tivedshambo\" (which was the first song written by their manager Stig Anderson), for a Swedish TV show honouring Anderson on his 55th birthday. The four had not seen each other for more than two years. That same year they also performed privately at another friend's 40th birthday: their old tour manager, Claes af Geijerstam. They sang a self-written song titled \"Der Kleine Franz\" that was later to resurface in \"Chess\". Also in 1986, \"ABBA Live\" was released, featuring selections of live performances from the group's 1977 and 1979 tours. The four members were guests at the 50th birthday of G\u00f6rel Hanser in 1999. Hanser was a long-time friend of all four, and also former secretary of Stig Anderson. Honouring G\u00f6rel, ABBA performed a Swedish birthday song \"Med en enkel tulipan\" a cappella.\nAndersson has on several occasions performed ABBA songs. In June 1992, he and Ulvaeus appeared with U2 at a Stockholm concert, singing the chorus of \"Dancing Queen\", and a few years later during the final performance of the B &amp; B in Concert in Stockholm, Andersson joined the cast for an encore at the piano. Andersson frequently adds an ABBA song to the playlist when he performs with his BAO band. He also played the piano during new recordings of the ABBA songs \"Like an Angel Passing Through My Room\" with opera singer Anne Sofie von Otter, and \"When All Is Said and Done\" with Swede Viktoria Tolstoy. In 2002, Andersson and Ulvaeus both performed an a cappella rendition of the first verse of \"Fernando\" as they accepted their Ivor Novello award in London. Lyngstad performed and recorded an a cappella version of \"Dancing Queen\" with the Swedish group the Real Group in 1993, and also re-recorded \"I Have a Dream\" with Swiss singer Dan Daniell in 2003.\nBreak and reunion.\nABBA never officially announced the end of the group or an indefinite break, but it was long considered dissolved after their final public performance together in 1982. Their final public performance together as ABBA before their 2016 reunion was on the British TV programme \"The Late, Late Breakfast Show\" (live from Stockholm) on 11 December 1982. While reminiscing on \"The Day Before You Came\", Ulvaeus said: \"we might have continued for a while longer if that had been a number one\".\nIn January 1983, F\u00e4ltskog started recording sessions for a solo album, as Lyngstad had successfully released her album \"Something's Going On\" some months earlier. Ulvaeus and Andersson, meanwhile, started songwriting sessions for the musical \"Chess\". In interviews at the time, Bj\u00f6rn and Benny denied the split of ABBA (\"Who are we without our ladies? Initials of Brigitte Bardot?\"), and Lyngstad and F\u00e4ltskog kept claiming in interviews that ABBA would come together for a new album repeatedly during 1983 and 1984. Internal strife between the group and their manager escalated and the band members sold their shares in Polar Music during 1983. Except for a TV appearance in 1986, the foursome did not come together publicly again until they were reunited at the Swedish premiere of the \"Mamma Mia!\" musical on 14 February 2005. The individual members' endeavours shortly before and after their final public performance coupled with the collapse of both marriages and the lack of significant activity in the following few years after that widely suggested that the group had broken up.\nIn an interview with the \"Sunday Telegraph\" following the premiere, Ulvaeus and Andersson said that there was nothing that could entice them back on stage again. Ulvaeus said: \"We will never appear on stage again. [...] There is simply no motivation to re-group. Money is not a factor and we would like people to remember us as we were. Young, exuberant, full of energy and ambition. I remember Robert Plant saying Led Zeppelin were a cover band now because they cover all their own stuff. I think that hit the nail on the head.\"\nHowever, on 3 January 2011, F\u00e4ltskog, long considered to be the most reclusive member of the group and a major obstacle to any reunion, raised the possibility of reuniting for a one-off engagement. She admitted that she has not yet brought the idea up to the other three members. In April 2013, she reiterated her hopes for reunion during an interview with \"Die Zeit\", stating: \"If they ask me, I'll say yes.\"\nIn a May 2013 interview, F\u00e4ltskog, aged 63 at the time, stated that an ABBA reunion would never occur: \"I think we have to accept that it will not happen, because we are too old and each one of us has their own life. Too many years have gone by since we stopped, and there's really no meaning in putting us together again\". F\u00e4ltskog further explained that the band members remained on amicable terms: \"It's always nice to see each other now and then and to talk a little and to be a little nostalgic.\" In an April 2014 interview, F\u00e4ltskog, when asked about whether the band might reunite for a new recording said: \"It's difficult to talk about this because then all the news stories will be: 'ABBA is going to record another song!' But as long as we can sing and play, then why not? I would love to, but it's up to Bj\u00f6rn and Benny.\"\nResurgence of public interest.\nThe same year the members of ABBA went their separate ways, the French production of a \"tribute\" show (a children's TV musical named \"Abbacadabra\" using 14 ABBA songs) spawned new interest in the group's music.\nAfter receiving little attention during the mid-to-late-1980s, ABBA's music experienced a resurgence in the early 1990s due to the UK synth-pop duo Erasure, who released \"Abba-esque\", a four track extended play release featuring cover versions of ABBA songs which topped several European charts in 1992. As U2 arrived in Stockholm for a concert in June of that year, the band paid homage to ABBA by inviting Bj\u00f6rn Ulvaeus and Benny Andersson to join them on stage for a rendition of \"Dancing Queen\", playing guitar and keyboards. September 1992 saw the release of \"\", a new compilation album. The single \"Dancing Queen\" received radio airplay in the UK in the middle of 1992 to promote the album. The song returned to the Top 20 of the UK singles chart in August that year, this time peaking at number 16. With sales of 30 million, \"Gold\" is the best-selling ABBA album, as well as one of the best-selling albums worldwide. With sales of 5.5\u00a0million copies it is the second-highest selling album of all time in the UK, after Queen's \"Greatest Hits\". \",\" a follow-up to \"Gold\", was released in 1993.\nIn 1994, two Australian cult films caught the attention of the world's media, both focusing on admiration for ABBA: \"The Adventures of Priscilla, Queen of the Desert\" and \"Muriel's Wedding\". The same year, \"Thank You for the Music\", a four-disc box set comprising all the group's hits and stand-out album tracks, was released with the involvement of all four members. \"By the end of the twentieth century,\" American critic Chuck Klosterman wrote a decade later, \"it was far more contrarian to hate ABBA than to love them.\"\nTwo different compilation albums of ABBA songs have been released. \"ABBA: A Tribute\" coincided with the 25th anniversary celebration and featured 17 songs, some of which were recorded especially for this release. Notable tracks include Go West's \"One of Us\", Army of Lovers \"Hasta Ma\u00f1ana\", Information Society's \"Lay All Your Love on Me\", Erasure's \"Take a Chance on Me\" (with MC Kinky), and Lyngstad's a cappella duet with the Real Group of \"Dancing Queen\". A second 12-track album was released in 1999, titled \"ABBAmania\", with proceeds going to the Youth Music charity in England. It featured all new cover versions: notable tracks were by Madness (\"Money, Money, Money\"), Culture Club (\"Voulez-Vous\"), the Corrs (\"The Winner Takes It All\"), Steps (\"Lay All Your Love on Me\", \"I Know Him So Well\"), and a medley titled \"Thank ABBA for the Music\" performed by several artists and as featured on the Brits Awards that same year.\nIn 1998, an ABBA tribute group was formed, the ABBA Teens, which was subsequently renamed the A-Teens to allow the group some independence. The group's first album, \"The ABBA Generation\", consisting solely of ABBA covers reimagined as 1990s pop songs, was a worldwide success and so were subsequent albums. The group disbanded in 2004 due to a gruelling schedule and intentions to go solo. In Sweden, the growing recognition of the legacy of Andersson and Ulvaeus resulted in the 1998 \"B &amp; B Concerts\", a tribute concert (with Swedish singers who had worked with the songwriters through the years) showcasing not only their ABBA years, but hits both before and after ABBA. The concert was a success and was ultimately released on CD. It later toured Scandinavia and even went to Beijing in the People's Republic of China for two concerts. In 2000 ABBA were reported to have turned down an offer of approximately one billion US dollars to do a reunion tour consisting of 100 concerts.\nFor the semi-final of the Eurovision Song Contest 2004, staged in Istanbul 30 years after ABBA had won the contest in Brighton, all four members made cameo appearances in a special comedy video made for the interval act, titled \"Our Last Video Ever\". Other well-known stars such as Rik Mayall, Cher and Iron Maiden's Eddie also made appearances in the video. It was not included in the official DVD release of the 2004 Eurovision contest, but was issued as a separate DVD release, retitled \"The Last Video\" at the request of the former ABBA members. The video was made using puppet models of the members of the band. The video has surpassed 13 million views on YouTube as of November 2020.\nIn 2005, all four members of ABBA appeared at the Stockholm premiere of the musical \"Mamma Mia!\". On 22 October 2005, at the , \"Waterloo\" was chosen as the best song in the competition's history. In the same month, American singer Madonna released the single \"Hung Up\", which contains a sample of the keyboard melody from ABBA's 1979 song \"Gimme! Gimme! Gimme! (A Man After Midnight)\"; the song was a smash hit, peaking at number one in at least 50 countries. On 4 July 2008, all four ABBA members were reunited at the Swedish premiere of the film \"Mamma Mia!\". It was only the second time all of them had appeared together in public since 1986. During the appearance, they re-emphasised that they intended never to officially reunite, citing the opinion of Robert Plant that the re-formed Led Zeppelin was more like a cover band of itself than the original band. Ulvaeus stated that he wanted the band to be remembered as they were during the peak years of their success.\n\"Gold\" returned to number-one in the UK album charts for the fifth time on 3 August 2008. On 14 August 2008, the \"Mamma Mia! The Movie\" film soundtrack went to number-one on the US \"Billboard\" charts, ABBA's first US chart-topping album. During the band's heyday, the highest album chart position they had ever achieved in America was number 14. In November 2008, all eight studio albums, together with a ninth of rare tracks, were released as \"The Albums\". It hit several charts, peaking at number-four in Sweden and reaching the Top 10 in several other European territories.\nIn 2008, Sony Computer Entertainment Europe, in collaboration with Universal Music Group Sweden AB, released \"SingStar ABBA\" on both the PlayStation 2 and PlayStation 3 games consoles, as part of the SingStar music video games. The PS2 version features 20 ABBA songs, while 25 songs feature on the PS3 version.\nOn 22 January 2009, F\u00e4ltskog and Lyngstad appeared together on stage to receive the Swedish music award \"Rockbj\u00f6rnen\" (for \"lifetime achievement\"). In an interview, the two women expressed their gratitude for the honorary award and thanked their fans. On 25 November 2009, PRS for Music announced that the British public voted ABBA as the band they would most like to see re-form. On 27 January 2010, ABBAWORLD, a 25-room touring exhibition featuring interactive and audiovisual activities, debuted at Earls Court Exhibition Centre in London. According to the exhibition's website, ABBAWORLD is \"approved and fully supported\" by the band members.\n\"Mamma Mia\" was released as one of the first few non-premium song selections for the online RPG game \"Bandmaster\". On 17 May 2011, \"Gimme! Gimme! Gimme!\" was added as a non-premium song selection for the Bandmaster Philippines server. On 15 November 2011, Ubisoft released a dancing game called \"\" for the Wii. In January 2012, Universal Music announced the re-release of ABBA's final album \"The Visitors\", featuring a previously unheard track \"From a Twinkling Star to a Passing Angel\".\nA book titled \"ABBA: The Official Photo Book\" was published in early 2014 to mark the 40th anniversary of the band's Eurovision victory. The book reveals that part of the reason for the band's outrageous costumes was that Swedish tax laws at the time allowed the cost of garish outfits that were not suitable for daily wear to be tax deductible.\n2016\u20132024: Reunion, \"Voyage\", and ABBAtars.\nOn 20 January 2016, all four members of ABBA made a public appearance at \"Mamma Mia! The Party\" in Stockholm. On 6 June 2016, the quartet appeared together at a private party at Berns Salonger in Stockholm, which was held to celebrate the 50th anniversary of Andersson and Ulvaeus's first meeting. F\u00e4ltskog and Lyngstad performed live, singing \"The Way Old Friends Do\" before they were joined on stage by Andersson and Ulvaeus.\nBritish manager Simon Fuller announced in a statement in October 2016 that the group would be reuniting to work on a new \"digital entertainment experience\". The project would feature the members in their \"life-like\" avatar form, called \"ABBAtars\", based on and would be set to launch by the spring of 2019.\nIn May 2017, a sequel to the 2008 movie \"Mamma Mia!\", titled \"Mamma Mia! Here We Go Again\", was announced; the film was released on 20 July 2018. Cher, who appeared in the movie, also released \"Dancing Queen\", an ABBA cover album, in September 2018. In June 2017, a blue plaque outside Brighton Dome was set to commemorate their 1974 Eurovision win.\nOn 27 April 2018, all four original members of ABBA made a joint announcement that they had recorded two new songs, titled \"I Still Have Faith in You\" and \"Don't Shut Me Down\", to feature in a TV special set to air later that year. In September 2018, Ulvaeus stated that the two new songs, as well as the TV special, now called \"\", would not be released until 2019. The TV special was later revealed to be scrapped by 2018, as Andersson and Ulvaeus rejected Fuller's project, and instead partnered with visual effects company Industrial Light and Magic to prepare the ABBAtars for a music video and a concert. In January 2019, it was revealed that neither song would be released before the summer. Andersson hinted at the possibility of a third song.\nIn June 2019, Ulvaeus announced that the first new song and video containing the ABBAtars would be released in November 2019. In September, he stated in an interview that there were now five new ABBA songs to be released in 2020. In early 2020, Andersson confirmed that he was aiming for the songs to be released in September 2020.\nIn April 2020, Ulvaeus gave an interview saying that in the wake of the COVID-19 pandemic, the avatar project had been delayed. Five out of the eight original songs written by Benny for the new album had been recorded by the two female members, and the release of a new \u00a315\u00a0million music video with new unseen technology was under consideration. In May 2020, it was announced that ABBA's entire studio discography would be released on coloured vinyl for the first time, in a box set titled \"ABBA: The Studio Albums.\" In July 2020, Ulvaeus revealed that the release of the new ABBA recordings had been delayed until 2021.\nOn 22 September 2020, all four ABBA members reunited at Ealing Studios in London to continue working on the avatar project and filming for the tour. Ulvaeus confirmed that the avatar tour would be scheduled for 2022. When questioned if the new recordings were definitely coming out in 2021, Bj\u00f6rn said \"There will be new music this year, that is definite, it's not a case anymore of it might happen, it will happen.\"\nOn 26 August 2021, a new website was launched, with the title \"ABBA Voyage\". On the page, visitors were prompted to subscribe \"to be the first in line to hear more about \"ABBA Voyage\"\". Simultaneously with the launch of the webpage, new \"ABBA Voyage\" social media accounts were launched, and billboards around London started to appear, all showing the date \"02.09.21\", leading to expectation of what was to be revealed on that date. On 29 August, the band officially joined TikTok with a video of Benny Andersson playing \"Dancing Queen\" on the piano, and media reported on a new album to be announced on 2 September. On that date, \"Voyage\", their first new album in 40 years, was announced to be released on 5 November 2021, along with ABBA Voyage, a concert residency in a custom-built venue at Queen Elizabeth Olympic Park in London featuring the motion capture digital avatars of the four band members alongside a 10-piece live band, starting 27 May 2022. F\u00e4ltskog stated that the \"Voyage\" album and concert residency are likely to be their last activity as a group.\nThe announcement of the new album was accompanied by the release of the singles \"I Still Have Faith in You\" and \"Don't Shut Me Down\". The music video for \"I Still Have Faith in You\", featuring footage of the band during their performing years and a first look at the ABBAtars, earned over a million views in its first three hours. \"Don't Shut Me Down\" became the first ABBA release since October 1978 to top the singles chart in Sweden. In October 2021, the third single \"Just a Notion\" was released, and it was announced that ABBA would split for good after the release of \"Voyage\". However, in an interview with BBC Radio 2 on 11 November, Lyngstad stated \"don't be too sure\" that \"Voyage\" is the final ABBA album. Also, in an interview with BBC News on 5 November, Andersson stated \"if they [the ladies] twist my arm I might change my mind.\" The fourth single from the album, \"Little Things\", was released on 3 December.\nIn May 2022, after the premiere of ABBA Voyage, Andersson stated in an interview with \"Variety\" that \"nothing is going to happen after this\", confirming the residency as ABBA's final group collaboration. In April 2023, longtime ABBA guitarist Lasse Wellander died at the age of 70; Wellander played on seven of the group's nine studio albums, including \"Voyage\".\nOn 21 March 2024, all four members of ABBA were appointed Commander, First Class, of the Royal Order of Vasa by King Carl XVI Gustaf of Sweden. This was the first time in almost 50 years that the Swedish Royal Orders of Knighthood was bestowed on Swedes, also the 50th anniversary of ABBA winning the Eurovision Song Contest. ABBA shared the honour with nine other persons. They ruled out a reunion at the Eurovision Song Contest 2024, held in their native Sweden; however, during the grand final of the contest, a clip from ABBA Voyage was shown, combined with archival footage of their 1974 performance of \"Waterloo\" at the contest and with Charlotte Perrelli, Carola and Conchita Wurst performing \"Waterloo\" on the stage as part of the interval.\nArtistry.\nRecording process.\nABBA were perfectionists in the studio, working on tracks until they got them right rather than leaving them to come back to later on. They spent the bulk of their time within the studio; in separate 2021 interviews Ulvaeus stated they may have toured for only 6 months while Andersson said they played fewer than 100 shows during the band's career. Although, counting shorter 30 to 60 minute concerts during their Folkpark tours, the group in fact played over 200 shows.\nThe band created a basic rhythm track with a drummer, guitarist and bass player, and overlaid other arrangements and instruments. Vocals were then added, and orchestra overdubs were usually left until last.\nF\u00e4ltskog and Lyngstad contributed ideas at the studio stage. Andersson and Ulvaeus played them the backing tracks and they made comments and suggestions. According to F\u00e4ltskog, she and Lyngstad had the final say in how the lyrics were shaped.\n After vocals and overdubs were done, the band took up to five days to mix a song.\nFashion, style, videos, advertising campaigns.\nABBA was widely noted for the colourful and trend-setting costumes its members wore. The reason for the wild costumes was Swedish tax law: the cost of the clothes was deductible only if they could not be worn other than for performances. In their early years, group member Anni-Frid Lyngstad designed and even hand sewed the outfits. Later, as their success grew, they used professional theatrical clothes designer Owe Sandstr\u00f6m together with tailor Lars Wigenius with Lyngstad continuing to suggest ideas while co-ordinating the outfits with concert set designs. Choreography by Graham Tainton also contributed to their performance style.\nThe videos that accompanied some of the band's biggest hits are often cited as being among the earliest examples of the genre. Most of ABBA's videos (and \"ABBA: The Movie\") were directed by Lasse Hallstr\u00f6m, who would later direct the films \"My Life as a Dog\", \"The Cider House Rules\" and \"Chocolat\".\nABBA made videos because their songs were hits in many different countries and personal appearances were not always possible. This was also done in an effort to minimise travelling, particularly to countries that would have required extremely long flights. F\u00e4ltskog and Ulvaeus had two young children and F\u00e4ltskog, who was also afraid of flying, was very reluctant to leave her children for such a long time. ABBA's manager, Stig Anderson, realised the potential of showing a simple video clip on television to publicise a single or album, thereby allowing easier and quicker exposure than a concert tour. Some of these videos have become classics because of the 1970s-era costumes and early video effects, such as the grouping of the band members in different combinations of pairs, overlapping one singer's profile with the other's full face, and the contrasting of one member against another.\nIn 1976, ABBA participated in an advertising campaign to promote the Matsushita Electric Industrial Co.'s brand, National, in Australia. The campaign was also broadcast in Japan. Five commercial spots, each of approximately one minute, were produced, each presenting the \"National Song\" performed by ABBA using the melody and instrumental arrangements of \"Fernando\" and revised lyrics.\nPolitical use of ABBA's music.\nJohn McCain used the song \"Take a Chance on Me\" for his 2008 presidential campaign. McCain publicly expressed his liking of the band.\nIn September 2010, band members Andersson and Ulvaeus criticised the right-wing Danish People's Party (DF) for using the ABBA song \"Mamma Mia\" (with modified lyrics referencing Pia Kj\u00e6rsgaard) at rallies. The band threatened to file a lawsuit against the DF, saying they never allowed their music to be used politically and that they had absolutely no interest in supporting the party. Their record label Universal Music later stated that no legal action would be taken because an agreement had been reached. \nIn August 2024 after Donald Trump played several of their songs and used footage of the group at a campaign rally, ABBA demanded he stop using their music. Their record company, Universal Music, said they had not been asked for permission to use ABBA music or videos by the Trump campaign and that footage from the event must be \"immediately taken down and removed\".\nSuccess in the United States.\nDuring their active career, from 1972 to 1982, 20 of ABBA's singles entered the \"Billboard\" Hot 100; 14 of these made the Top 40 (13 on the Cashbox Top 100), with 10 making the Top 20 on both charts. A total of four of those singles reached the Top 10, including \"Dancing Queen\", which reached number one in April 1977. While \"Fernando\" and \"SOS\" did not break the Top 10 on the \"Billboard\" Hot 100 (reaching number 13 and 15 respectively), they did reach the Top 10 on Cashbox (\"Fernando\") and Record World (\"SOS\") charts. Both \"Dancing Queen\" and \"Take a Chance on Me\" were certified gold by the Recording Industry Association of America for sales of over one million copies each.\nThe group also had 12 Top 20 singles on the \"Billboard\" Adult Contemporary chart with two of them, \"Fernando\" and \"The Winner Takes It All\", reaching number one. \"Lay All Your Love on Me\" was ABBA's fourth number-one single on a \"Billboard\" chart, topping the Hot Dance Club Play chart.\nTen ABBA albums have made their way into the top half of the \"Billboard\" 200 album chart, with eight reaching the Top 50, five reaching the Top 20 and one reaching the Top 10. In November 2021, Voyage became ABBA's highest-charting album on the Billboard 200 peaking at No. 2. Five albums received RIAA gold certification (more than 500,000 copies sold), while three acquired platinum status (selling more than one million copies).\nThe compilation album \"\" topped the \"Billboard\" Top Pop Catalog Albums chart in August 2008 (15 years after it was first released in the US in 1993), becoming the group's first number-one album ever on any of the \"Billboard\" album charts. It has sold 6 million copies there.\nOn 15 March 2010, ABBA was inducted into the Rock and Roll Hall of Fame by Bee Gees members Barry Gibb and Robin Gibb. The ceremony was held at the Waldorf Astoria Hotel in New York City. The group were represented by Anni-Frid Lyngstad and Benny Andersson.\nIn November 2021, the group received a Grammy nomination for Record of the Year. The single, \"I Still Have Faith in You\", from the album, \"Voyage\", was their first ever nomination. In November 2022, \"Don't Shut Me Down\", also from \"Voyage\", was nominated for Best Pop Duo/Group Performance.\n\"Saturday Night Live\" featured a sketch that promoted a fictional ABBA album, which took pre-existing songs and reworked their lyrics to reference common Christmas traditions in the United States. Episode host Kate McKinnon and cast member Bowen Yang were joined by Maya Rudolph and Kristin Wiig, both former cast members on the show. The episode aired on 16 December 2023.\nMembers.\nThe members of ABBA were married as follows: Agnetha F\u00e4ltskog and Bj\u00f6rn Ulvaeus from 1971 to 1979; Benny Andersson and Anni-Frid Lyngstad from 1978 to 1981. For their subsequent marriages, see their articles.\nIn addition to the four members of ABBA, other musicians regularly played on their studio recordings, live appearances and concert performances. These include:\nDiscography.\nStudio albums\nDocumentaries.\nDocumentaries often profess to show the \"real ABBA\" and may employ several methods of legitimising such claims, such as the use of archival documents, testimonies from \"music and cultural 'experts'\", and interviews with the group members and fans."}
{"id": "881", "revid": "237572", "url": "https://en.wikipedia.org/wiki?curid=881", "title": "Allegiance", "text": "An allegiance is a duty of fidelity said to be owed, or freely committed, by the people, subjects or citizens to their state or sovereign.\nEtymology.\nThe word \"allegiance\" comes from Middle English ' (see Medieval Latin ', \"a liegance\"). The \"al-\" prefix was probably added through confusion with another legal term, \"allegiance\", an \"allegation\" (the French ' comes from the English). \"Allegiance\" is formed from \"liege,\" from Old French ', \"liege, free\", of Germanic origin. The connection with Latin \"\", \"to bind,\" is erroneous.\nUsage.\nTraditionally, English legal commentators used the term \"allegiance\" in two ways. In one sense, it referred to the deference which anyone, even a foreigner, was expected to pay to the institutions of the country where one lived. In the other sense, it meant national character and the subjection due to that character.\nUnited Kingdom.\nThe English doctrine, which was at one time adopted in the United States, asserted that allegiance was indelible: \"Nemo potest exuere patriam\". As the law stood prior to 1870, every person who by birth or naturalisation satisfied the conditions set forth, even if removed in infancy to another country where their family resided, owed an allegiance to the British crown which they could never resign or lose, except by act of parliament or by the recognition of the independence or the cession of the portion of British territory in which they resided.\nThis refusal to accept any renunciation of allegiance to the Crown led to conflict with the United States over impressment, which led to further conflicts during the War of 1812, when thirteen Irish American prisoners of war were executed as traitors after the Battle of Queenston Heights; Winfield Scott urged American reprisal, but none was carried out.\nAllegiance was the tie which bound the subject to the sovereign, in return for that protection which the sovereign afforded the subject. It was the mutual bond and obligation between monarch and subjects, whereby subjects were called their liege subjects, because they are bound to obey and serve them; and the monarch was called their liege lord, because they should maintain and defend them (\"Ex parte Anderson\" (1861) 3 El &amp; El 487; 121 ER 525; \"China Navigation Co v Attorney-General\" (1932) 48 TLR 375; \"Attorney-General v Nissan\" [1969] 1 All ER 629; \"Oppenheimer v Cattermole\" [1972] 3 All ER 1106). The duty of the crown towards its subjects was to govern and protect them. The reciprocal duty of the subject towards the crown was that of allegiance.\nAt common law, allegiance was a true and faithful obedience of the subject due to their sovereign. As the subject owed to their sovereign their true and faithful allegiance and obedience, so the sovereign\nNatural allegiance and obedience is an incident inseparable to every subject, for parte Anderson (1861) 3 El &amp; El 487; 121 ER 525). Natural-born subjects owe allegiance wherever they may be. Where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country (\"R v Vermaak\" (1900) 21 NLR 204 (South Africa)).\nAllegiance is owed both to the sovereign as a natural person and to the sovereign in the political capacity (\"Re Stepney Election Petition, Isaacson v Durant\" (1886) 17 QBD 54 (per Lord Coleridge CJ)). Attachment to the person of the reigning sovereign is not sufficient. Loyalty requires affection also to the office of the sovereign, attachment to royalty, attachment to the law and to the constitution of the realm, and he who would, by force or by fraud, endeavour to prostrate that law and constitution, though he may retain his affection for its head, can boast but an imperfect and spurious species of loyalty (\"R v O'Connell\" (1844) 7 ILR 261).\nThere were four kinds of allegiances (\"Rittson v Stordy\" (1855) 3 Sm &amp; G 230; \"De Geer v Stone\" (1882) 22 Ch D 243; \"Isaacson v Durant\" (1886) 54 LT 684; \"Gibson, Gavin v Gibson\" [1913] 3 KB 379; \"Joyce v DPP\" [1946] AC 347; \"Collingwood v Pace\" (1661) O Bridg 410; \"Lane v Bennett\" (1836) 1 M &amp; W 70; \"Lyons Corp v East India Co\" (1836) 1 Moo PCC 175; \"Birtwhistle v Vardill\" (1840) 7 Cl &amp; Fin 895; \"R v Lopez, R v Sattler\" (1858) Dears &amp; B 525; Ex p Brown (1864) 5 B &amp; S 280):\nNatural allegiance was acquired by birth within the sovereign's dominions (except for the issue of diplomats or of invading forces or of an alien in an enemy occupied territory). The natural allegiance and obedience are an incident inseparable from every subject, for as soon as they are born they owe by birthright allegiance and obedience to the Sovereign (\"Ex p. Anderson\" (1861) 3 E &amp; E 487). A natural-born subject owes allegiance wherever they may be, so that where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country (\"R v Vermaak\" (1900) 21 NLR 204 (South Africa)).\nAcquired allegiance was acquired by naturalisation or denization. Denization, or \"ligeantia acquisita\", appears to be threefold (\"Thomas v Sorrel\" (1673) 3 Keb 143):\nLocal allegiance was due by an alien while in the protection of the crown. All friendly resident aliens incurred all the obligations of subjects (\"The Angelique\" (1801) 3 Ch Rob App 7). An alien, coming into a colony, also became, temporarily, a subject of the crown, and acquired rights both within and beyond the colony, and these latter rights could not be affected by the laws of that colony (\"Routledge v Low\" (1868) LR 3 HL 100; 37 LJ Ch 454; 18 LT 874; 16 WR 1081, HL; \"Reid v Maxwell\" (1886) 2 TLR 790; \"Falcon v Famous Players Film Co\" [1926] 2 KB 474).\nA resident alien owed allegiance even when the protection of the crown was withdrawn owing to the occupation of an enemy, because the absence of the crown's protection was temporary and involuntary (\"de Jager v Attorney-General of Natal\" [1907] AC 326).\nLegal allegiance was due when an alien took an oath of allegiance required for a particular office under the crown.\nBy the Naturalization Act 1870 (33 &amp; 34 Vict. c. 14), it was made possible for British subjects to renounce their nationality and allegiance, and the ways in which that nationality is lost were defined. So British subjects voluntarily naturalized in a foreign state are deemed aliens from the time of such naturalization, unless, in the case of persons naturalized before the passing of the act, they had declared their desire to remain British subjects within two years from the passing of the act. Persons who, from having been born within British territory, are British subjects, but who, at birth, came under the law of any foreign state or of subjects of such state, and, also, persons who, though born abroad, are British subjects by reason of parentage, may, by declarations of alienage, get rid of British nationality. Emigration to an uncivilized country left British nationality unaffected: indeed the right claimed by all states to follow with their authority their subjects so emigrating was one of the usual and recognized means of colonial expansion.\nUnited States.\nThe doctrine that no man can cast off his native allegiance without the consent of his sovereign was early abandoned in the United States, and Chief Justice John Rutledge also declared in Talbot v. Janson, \"a man may, at the same time, enjoy the rights of citizenship under two governments.\" On July 27, 1868, the day before the Fourteenth Amendment was adopted, U.S. Congress declared in the preamble of the Expatriation Act that \"the right of expatriation is a natural and inherent right of all people, indispensable to the enjoyment of the rights of life, liberty and the pursuit of happiness,\" and (Section I) one of \"the fundamental principles of this government\" (United States Revised Statutes, sec. 1999). Every natural-born citizen of a foreign state who is also an American citizen, and every natural-born American citizen who is also a citizen of a foreign land, owes a double allegiance, one to the United States, and one to their homeland (in the event of an immigrant becoming a citizen of the US) or to their adopted land (in the event of an emigrant natural-born citizen of the US becoming a citizen of another nation). If these allegiances come into conflict, the person may be guilty of treason against one or both. If the demands of these two sovereigns upon their duty of allegiance come into conflict, those of the United States have the paramount authority in American law; likewise, those of the foreign land have paramount authority in their legal system. In such a situation, it may be incumbent on the individual to renounce one of their citizenships, to avoid possibly being forced into situations where countervailing duties are required of them, such as might occur in the event of war.\nOath of allegiance.\nThe oath of allegiance is an oath of fidelity to the sovereign taken by all persons holding important public office and as a condition of naturalization. By ancient common law, it was required of all persons above the age of 12, and it was repeatedly used as a test for the disaffected. In England, it was first imposed by statute in the reign of Elizabeth I (1558), and its form has, more than once, been altered since. Up to the time of the revolution, the promise was \"to be true and faithful to the king and his heirs, and truth and faith to bear of life and limb and terrene honour, and not to know or hear of any ill or damage intended him without defending him therefrom.\" This was thought to favour the doctrine of absolute non-resistance, and, accordingly, the Convention Parliament enacted the form that has been in use since that time\u2014\"I do sincerely promise and swear that I will be faithful and bear true allegiance to His Majesty ...\"\nIn the United States and some other republics, the oath is known as the Pledge of Allegiance. Instead of declaring fidelity to a monarch, the pledge is made to the flag, the republic, and to the core values of the country, specifically liberty and justice. The reciting of the pledge in the United States is voluntary because of the rights guaranteed to the people under the First Amendment to the United States Constitution\u2014specifically, the guarantee of freedom of speech, which inherently includes the freedom \"not\" to speak.\nIn Islam.\nThe word used in the Arabic language for allegiance is \"bay'at\" (Arabic: \u0628\u064a\u0639\u0629), which means \"taking hand\". The practice is sanctioned in the Quran by Surah 48:10: \"Verily, those who give thee their allegiance, they give it but to Allah Himself\". The word is used for the oath of allegiance to an emir. It is also used for the initiation ceremony specific to many Sufi orders."}
{"id": "882", "revid": "43067996", "url": "https://en.wikipedia.org/wiki?curid=882", "title": "Absolute majority", "text": ""}
{"id": "885", "revid": "46949569", "url": "https://en.wikipedia.org/wiki?curid=885", "title": "Altenberg", "text": "Altenberg (German for \"old mountain\" or \"mountain of the old\") may refer to:"}
{"id": "887", "revid": "44217690", "url": "https://en.wikipedia.org/wiki?curid=887", "title": "MessagePad", "text": "The MessagePad is a series of personal digital assistant devices developed by Apple Computer for the Newton platform, first released in 1993. Some electronic engineering and the manufacture of Apple's MessagePad devices was undertaken in Japan by Sharp. The devices are based on the ARM 610 RISC processor, run Newton OS, and all feature handwriting recognition software. Alongside the MessagePad series, Apple also developed and released the eMate 300 Newton device.\nHistory.\nThe development of the Newton MessagePad first began with Apple's former senior vice president of research and development, Jean-Louis Gass\u00e9e; his team included Steve Capps, co-writer of Mac OS Finder, and an employed engineer named Steve Sakoman. The development of the Newton MessagePad operated in secret until it was eventually revealed to the Apple Board of Directors in late 1990.\nWhen Gass\u00e9e resigned from his position due to a significant disagreement with the board, seeing how his employer was treated, Sakoman also stopped developing the MessagePad on March 2, 1990.\nBill Atkinson, an Apple Executive responsible for the company's Lisa graphical interface, invited Steve Capps, John Sculley, Andy Hertzfeld, Susan Kare, and Marc Porat to a meeting on March 11, 1990. There, they brainstormed a way of saving the MessagePad. Sculley suggested adding new features, including libraries, museums, databases, or institutional archives features, allowing customers to navigate through various window tabs or opened galleries/stacks. The Board later approved his suggestion; he then gave the Newton his official and full backing.\nThe first MessagePad was unveiled by Sculley on the 29th of May 1992 at the summer Consumer Electronics Show (CES) in Chicago. Sculley caved in to pressure to unveil the product early because the Newton did not officially ship until 14 months later on the 2nd of August 1993, starting at a price of . Over 50,000 units were sold by late November 1993.\nDetails.\nScreen and input.\nWith the MessagePad 120 with Newton OS 2.0, the Newton Keyboard by Apple became available, which can also be used via the dongle on Newton devices with a Newton InterConnect port, most notably the Apple MessagePad 2000/2100 series, as well as the Apple eMate 300.\nNewton devices featuring Newton OS 2.1 or higher can be used with the screen turned horizontally (\"landscape\") as well as vertically (\"portrait\"). A change of a setting rotates the contents of the display by 90, 180 or 270 degrees. Handwriting recognition still works properly with the display rotated, although display calibration is needed when rotation in any direction is used for the first time or when the Newton device is reset.\nHandwriting recognition.\nIn initial versions (Newton OS 1.x) the handwriting recognition gave extremely mixed results for users and was sometimes inaccurate. The original handwriting recognition engine was called Calligrapher, and was licensed from a Russian company called . Calligrapher's design was quite sophisticated; it attempted to learn the user's natural handwriting, using a database of known words to make guesses as to what the user was writing, and could interpret writing anywhere on the screen, whether hand-printed, in cursive, or a mix of the two. By contrast, Palm Pilot's Graffiti had a less sophisticated design than Calligrapher, but was sometimes found to be more accurate and precise due to its reliance on a fixed, predefined stroke alphabet. The stroke alphabet used letter shapes which resembled standard handwriting, but which were modified to be both simple and very easy to differentiate. Palm Computing also released two versions of Graffiti for Newton devices. The Newton version sometimes performed better and could also show strokes as they were being written as input was done on the display itself, rather than on a silkscreen area.\nFor editing text, Newton had a very intuitive system for handwritten editing, such as scratching out words to be deleted, circling text to be selected, or using written carets to mark inserts.\nLater releases of the Newton operating system retained the original recognizer for compatibility, but added a hand-printed-text-only (not cursive) recognizer, called \"Rosetta\", which was developed by Apple, included in version 2.0 of the Newton operating system, and refined in Newton 2.1. Rosetta is generally considered a significant improvement and many reviewers, testers, and most users consider the Newton 2.1 handwriting recognition software better than any of the alternatives even 10 years after it was introduced. Recognition and computation of handwritten horizontal and vertical formulas such as \"1 + 2 =\" was also under development but never released. However, users wrote similar programs which could evaluate mathematical formulas using the Newton OS Intelligent Assistant, a unique part of every Newton device.\nThe handwriting recognition and parts of the user interface for the Newton are best understood in the context of the broad history of pen computing, which is quite extensive.\nA vital feature of the Newton handwriting recognition system is the modeless error correction. That is, correction done \"in situ\" without using a separate window or widget, using a minimum of gestures. If a word is recognized improperly, the user could double-tap the word and a list of alternatives would pop up in a menu under the stylus. Most of the time, the correct word will be in the list. If not, a button at the bottom of the list allows the user to edit individual characters in that word. Other pen gestures could do such things as transpose letters (also \"in situ\"). The correction popup also allowed the user to revert to the original, un-recognized letter shapes - this would be useful in note-taking scenarios if there was insufficient time to make corrections immediately. To conserve memory and storage space, alternative recognition hypotheses would not be saved indefinitely. If the user returned to a note a week later, for example, they would only see the best match. Error correction in many current handwriting systems provides such functionality but adds more steps to the process, greatly increasing the interruption to a user's workflow that a given correction requires.\nUser interface.\nText could also be entered by tapping with the stylus on a small on-screen pop-up QWERTY virtual keyboard, although more layouts were developed by users. Newton devices could also accept free-hand \"Sketches\", \"Shapes\", and \"Ink Text\", much like a desktop computer graphics tablet. With \"Shapes\", Newton could recognize that the user was attempting to draw a circle, a line, a polygon, etc., and it would clean them up into perfect vector representations (with modifiable control points and defined vertices) of what the user was attempting to draw. \"Shapes\" and \"Sketches\" could be scaled or deformed once drawn. \"Ink text\" captured the user's free-hand writing but allowed it to be treated somewhat like recognized text when manipulating for later editing purposes (\"ink text\" supported word wrap, could be formatted to be bold, italic, etc.). At any time a user could also direct their Newton device to recognize selected \"ink text\" and turn it into recognized text (deferred recognition). A Newton note (or the notes attached to each contact in Names and each Dates calendar or to-do event) could contain any mix of interleaved text, Ink Text, Shapes, and Sketches.\nWhile the Newton offered handwriting recognition training and would clean up sketches into vector shapes, both were unreliable and required much rewriting and redrawing. The most reliable application of the Newton was collecting and organizing address and phone numbers. While handwritten messages could be stored, they could not be easily filed, sorted or searched. While the technology was a probable cause for the failure of the device (which otherwise met or exceeded expectations), the technology has been instrumental in producing the future generation of handwriting software that realizes the potential and promise that began in the development of Newton-Apple's Ink Handwriting Recognition.\nConnectivity.\nThe MessagePad 100 series of devices used Macintosh's proprietary serial ports\u2014round Mini-DIN 8 connectors. The MessagePad 2000/2100 models (as well as the eMate 300) have a small, proprietary \"Newton InterConnect\" port. However, the development of the Newton hardware/software platform was canceled by Steve Jobs on February 27, 1998, so the InterConnect port, while itself very advanced, can only be used to connect a serial dongle. A prototype multi-purpose InterConnect device containing serial, audio in, audio out, and other ports was also discovered. In addition, all Newton devices have infrared connectivity, initially only the Sharp ASK protocol, but later also IrDA, though the Sharp ASK protocol was kept in for compatibility reasons. Unlike the Palm Pilot, all Newton devices are equipped with a standard PC Card expansion slot (two on the 2000/2100). This allows native modem and even Ethernet connectivity; Newton users have also written drivers for 802.11b wireless networking cards and ATA-type flash memory cards (including the popular CompactFlash format), as well as for Bluetooth cards. Newton can also dial a phone number through the built-in speaker of the Newton device by simply holding a telephone handset up to the speaker and transmitting the appropriate tones. Fax and printing support is also built in at the operating system level, although it requires peripherals such as parallel adapters, PCMCIA cards, or serial modems, the most notable of which is the lightweight Newton Fax Modem released by Apple in 1993. It is powered by 2 AA batteries, and can also be used with a power adapter. It provides data transfer at 2,400 bit/s, and can also send and receive fax messages at 9,600 and 4,800 bit/s respectively.\nPower options.\nThe original Apple MessagePad and MessagePad 100 used four AAA batteries. They were eventually replaced by AA batteries with the release of the Apple MessagePad 110.\nThe use of 4 AA NiCd (MessagePad 110, 120 and 130) and 4x AA NiMH cells (MP2x00 series, eMate 300) give a runtime of up to 30 hours (MP2100 with two 20\u00a0MB Linear Flash memory PC Cards, no backlight usage) and up to 24 hours with backlight on. While adding more weight to the handheld Newton devices than AAA batteries or custom battery packs, the choice of an easily replaceable/rechargeable cell format gives the user a still unsurpassed runtime and flexibility of power supply. This, together with the flash memory used as internal storage starting with the Apple MessagePad 120 (if all cells lost their power, no data was lost due to the non-volatility of this storage), gave birth to the slogan \"Newton never dies, it only gets new batteries\".\nLater efforts and improvements.\nThe Apple MessagePad 2000/2100, with a vastly improved handwriting recognition system, 162\u00a0MHz StrongARM SA-110 RISC processor, Newton OS 2.1, and a better, clearer, backlit screen, attracted critical plaudits.\neMate 300.\nThe eMate 300 was a Newton device in a laptop form factor offered to schools in 1997 as an inexpensive ($799 US, originally sold to education markets only) and durable computer for classroom use. However, in order to achieve its low price, the eMate 300 did not have all the speed and features of the contemporary MessagePad equivalent, the MessagePad 2000. The eMate was cancelled along with the rest of the Newton products in 1998. It is the only Newton device to use the ARM710 microprocessor (running at 25\u00a0MHz), have an integrated keyboard, use Newton OS 2.2 (officially numbered 2.1), and its batteries are officially irreplaceable, although several users replaced them with longer-lasting ones without any damage to the eMate hardware whatsoever.\nPrototypes.\nMany prototypes of additional Newton devices were spotted. Most notable was a Newton tablet or \"slate\", a large, flat screen that could be written on. Others included a \"Kids Newton\" with side handgrips and buttons, \"VideoPads\" which would have incorporated a video camera and screen on their flip-top covers for two-way communications, the \"Mini 2000\" which would have been very similar to a Palm Pilot, and the NewtonPhone developed by Siemens, which incorporated a handset and a keyboard.\nMarket reception.\nFourteen months after Sculley demoed it at the May 1992, Chicago CES, the MessagePad was first offered for sale on August 2, 1993, at the Boston Macworld Expo. The hottest item at the show, it cost $900. 50,000 MessagePads were sold in the device's first three months on the market.\nThe original Apple MessagePad and MessagePad 100 were limited by the very short lifetime of their inadequate AAA batteries.\nLater versions of Newton OS offered improved handwriting recognition, quite possibly a leading reason for the continued popularity of the devices among Newton users. Even given the age of the hardware and software, Newtons still demand a sale price on the used market far greater than that of comparatively aged PDAs produced by other companies. In 2006, CNET compared an Apple MessagePad 2000 to a Samsung Q1, and the Newton was declared better. In 2009, CNET compared an Apple MessagePad 2000 to an iPhone 3GS, and the Newton was declared more innovative at its time of release.\nA chain of dedicated Newton-only stores called Newton Source, independently run by Stephen Elms, existed from 1994 until 1998. Locations included New York, Los Angeles, San Francisco, Chicago and Boston. The Westwood Village, California, near UCLA featured the trademark red and yellow light bulb Newton logo in neon. The stores provided an informative educational venue to learn about the Newton platform in a hands on relaxed fashion. The stores had no traditional computer retail counters and featured oval desktops where interested users could become intimately involved with the Newton product range. The stores were a model for the later Apple Stores.\nNewton device models.\nNotes: The eMate 300 actually has ROM chips silk screened with 2.2 on them. Stephanie Mak on her website discusses this:\nIf one removes all patches to the eMate 300 (by replacing the ROM chip, and then putting in the original one again, as the eMate and the MessagePad 2000/2100 devices erase their memory completely after replacing the chip), the result will be the Newton OS saying that this is version 2.2.00. Also, the Original MessagePad and the MessagePad 100 share the same model number, as they only differ in the ROM chip version. (The OMP has OS versions 1.0 to 1.05, or 1.10 to 1.11, while the MP100 has 1.3 that can be upgraded with various patches.)\nThird party licenses.\nThe Newton OS was also licensed to a number of third-party developers including Sharp and Motorola who developed additional PDA devices based on the Newton platform. Motorola added wireless connectivity, as well as made a unique two-part design, and shipped additional software with its Newton device, called the Marco. Sharp developed a line of Newton devices called the ExpertPad PI-7000/7100; those were the same as Apple's MessagePad and MessagePad 100, the only difference is the physical design (the ExpertPads feature a screen lid, which Apple added in 1994 with the release of the MessagePad 110) and the naming.\nOther uses.\nThere were a number of projects that used the Newton as a portable information device in cultural settings such as museums. For example, Visible Interactive created a walking tour in San Francisco's Chinatown but the most significant effort took place in Malaysia at the Petronas Discovery Center, known as Petrosains.\nIn 1995, an exhibit design firm, DMCD Inc., was awarded the contract to design a new science museum in the Petronas Towers in Kuala Lumpur. A major factor in the award was the concept that visitors would use a Newton device to access additional information, find out where they were in the museum, listen to audio, see animations, control robots and other media, and to bookmark information for printout at the end of the exhibit.\nThe device became known as the ARIF, a Malay word for \"wise man\" or \"seer\" and it was also an acronym for A Resourceful Informative Friend. Some 400 ARIFS were installed and over 300 are still in use today. The development of the ARIF system was extremely complex and required a team of hardware and software engineers, designers, and writers. ARIF is an ancestor of the PDA systems used in museums today and it boasted features that have not been attempted since.\nAnyway &amp; Company firm was involved with the Petronas Discovery Center project back in 1998 and NDAs were signed which prevents getting to know more information about this project. It was confirmed that they purchased of MP2000u or MP2100's by this firm on the behalf of the project under the name of \"Petrosains Project Account\". By 1998 they had invested heavily into the R&amp;D of this project with the Newton at the center. After Apple officially cancelled the Newton in 1998 they had to acquire as many Newtons as possible for this project. It was estimated initially 1000 Newtons, but later readjusted the figure to possibly 750 Newtons. They placed an \u201cInternet Call\u201d for Newtons. They purchased them in large and small quantities.\nThe Newton was also used in healthcare applications, for example in collecting data directly from patients. Newtons were used as electronic diaries, with patients entering their symptoms and other information concerning their health status on a daily basis. The compact size of the device and its ease of use made it possible for the electronic diaries to be carried around and used in the patients' everyday life setting. This was an early example of electronic patient-reported outcomes (ePRO)."}
{"id": "888", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=888", "title": "A. E. van Vogt", "text": "Alfred Elton van Vogt ( ; April 26, 1912\u00a0\u2013 January 26, 2000) was a Canadian-born American science fiction writer. His fragmented, bizarre narrative style influenced later science fiction writers, notably Philip K. Dick. He was one of the most popular and influential practitioners of science fiction in the mid-twentieth century, the genre's so-called Golden Age, and one of the most complex. The Science Fiction Writers of America named him their 14th Grand Master in 1995 (presented 1996).\nEarly life.\nAlfred Vogt (both \"Elton\" and \"van\" were added much later) was born on April 26, 1912, on his grandparents' farm in Edenburg, Manitoba, a tiny (and now defunct) Russian Mennonite community east of Gretna, Manitoba, Canada, in the Mennonite West Reserve. He was the third of six children born to Heinrich \"Henry\" Vogt and Aganetha \"Agnes\" Vogt (n\u00e9e Buhr), both of whom were born in Manitoba and grew up in heavily immigrant communities. Until he was four, van Vogt spoke only Plautdietsch at home.\nFor the first dozen or so years of his life, van Vogt's father, Henry Vogt, a lawyer, moved his family several times within central Canada, moving to Neville, Saskatchewan; Morden, Manitoba; and finally Winnipeg, Manitoba. Alfred Vogt found these moves difficult, later remarking:\nBy the 1920s, living in Winnipeg, father Henry worked as an agent for a steamship company, but the stock market crash of 1929 proved financially disastrous, and the family could not afford to send Alfred to college. During his teen years, Alfred worked as a farmhand and a truck driver, and by the age of 19, he was working in Ottawa for the Canadian Census Bureau.\nIn \"the dark days of '31 and '32,\" van Vogt took a correspondence course in writing from the Palmer Institute of Authorship. He sold his first story in fall 1932. His early published works were stories in the true confession style of magazines such as \"True Story\". Most of these stories were published anonymously, with the first-person narratives allegedly being written by people (often women) in extraordinary, emotional, and life-changing circumstances.\nAfter a year in Ottawa, he moved back to Winnipeg, where he sold newspaper advertising space and continued to write. While continuing to pen melodramatic \"true confessions\" stories through 1937, he also began writing short radio dramas for local radio station CKY, as well as conducting interviews published in trade magazines. He added the middle name \"Elton\" at some point in the mid-1930s, and at least one confessional story (1937's \"To Be His Keeper\") was sold to the \"Toronto Star\", who misspelled his name \"Alfred Alton Bogt\" in the byline. Shortly thereafter, he added the \"van\" to his surname, and from that point forward he used the name \"A. E. van Vogt\" both personally and professionally.\nCareer.\nBy 1938, van Vogt decided to switch to writing science fiction, a genre he enjoyed reading. He was inspired by the August 1938 issue of \"Astounding Science Fiction,\" which he picked up at a newsstand. John W. Campbell's novelette \"Who Goes There?\" (later adapted into \"The Thing from Another World\" and \"The Thing\") inspired van Vogt to write \"Vault of the Beast\", which he submitted to that same magazine. Campbell, who edited \"Astounding\" (and had written the story under a pseudonym), sent van Vogt a rejection letter in which Campbell encouraged van Vogt to try again. Van Vogt sent another story, entitled \"Black Destroyer\", which was accepted. It featured a fierce, carnivorous alien stalking the crew of a spaceship, and served as the inspiration for multiple science fiction movies, including \"Alien\" (1979). A revised version of \"Vault of the Beast\" was published in 1940.\nWhile still living in Winnipeg, in 1939 van Vogt married Edna Mayne Hull, a fellow Manitoban. Hull, who had previously worked as a private secretary, went on to act as van Vogt's typist, and was credited with writing several SF stories of her own throughout the early 1940s.\nThe outbreak of World War II in September 1939 caused a change in van Vogt's circumstances. Ineligible for military service due to his poor eyesight, he accepted a clerking job with the Canadian Department of National Defence. This necessitated a move back to Ottawa, where he and his wife stayed for the next year and a half.\nMeanwhile, his writing career continued. \"Discord in Scarlet\" was van Vogt's second story to be published, also appearing as the cover story. It was accompanied by interior illustrations created by Frank Kramer and Paul Orban. (Van Vogt and Kramer thus debuted in the issue of \"Astounding\" that is sometimes identified as the start of the Golden Age of Science Fiction.) Among his most famous works of this era, \"Far Centaurus\" appeared in the January 1944 edition of \"Astounding\".\nVan Vogt's first completed novel, and one of his most famous, is \"Slan\" (Arkham House, 1946), which Campbell serialized in \"Astounding\" (September to December 1940). Using what became one of van Vogt's recurring themes, it told the story of a nine-year-old superman living in a world in which his kind are slain by \"Homo sapiens\".\nOthers saw van Vogt's talent from his first story, and in May 1941 van Vogt decided to become a full-time writer, quitting his job at the Canadian Department of National Defence. Freed from the necessity of living in Ottawa, he and his wife lived for a time in the Gatineau region of Quebec before moving to Toronto in the fall of 1941.\nProlific throughout this period, van Vogt wrote many of his more famous short stories and novels in the years from 1941 through 1944. The novels \"The Book of Ptath\" and \"The Weapon Makers\" both appeared in magazines in serial form during this period; they were later published in book form after World War II. As well, several (though not all) of the stories that were compiled to make up the novels \"The Weapon Shops of Isher\", \"The Mixed Men\" and \"The War Against the Rull\" were published during this time.\nCalifornia and post-war writing (1944\u20131950).\nIn November 1944, van Vogt and Hull moved to Hollywood; van Vogt would spend the rest of his life in California. He had been using the name \"A. E. van Vogt\" in his public life for several years, and as part of the process of obtaining American citizenship in 1945 he finally and formally changed his legal name from Alfred Vogt to Alfred Elton van Vogt. To his friends in the California science fiction community, he was known as \"Van\".\nMethod and themes.\nVan Vogt systematized his writing method, using scenes of 800 words or so where a new complication was added or something resolved. Several of his stories hinge on temporal conundra, a favorite theme. He stated that he acquired many of his writing techniques from three books: \"Narrative Technique\" by Thomas Uzzell, \"The Only Two Ways to Write a Story\" by John Gallishaw, and \"Twenty Problems of the Fiction Writer\" by Gallishaw. He also claimed many of his ideas came from dreams; throughout his writing life he arranged to be awakened every 90\u00a0minutes during his sleep period so he could write down his dreams.\nVan Vogt was also always interested in the idea of all-encompassing systems of knowledge (akin to modern meta-systems). The characters in his very first story used a system called \"Nexialism\" to analyze the alien's behavior. Around this time, he became particularly interested in the general semantics of Alfred Korzybski.\nHe subsequently wrote a novel merging these overarching themes, \"The World of \u0100\", originally serialized in \"Astounding\" in 1945. \u0100 (often rendered as \"Null-A\"), or non-Aristotelian logic, refers to the capacity for, and practice of, using intuitive, inductive reasoning (compare fuzzy logic), rather than reflexive, or conditioned, deductive reasoning. The novel recounts the adventures of an individual living in an apparent Utopia, where those with superior brainpower make up the ruling class... though all is not as it seems. A sequel, \"The Players of \u0100\" (later re-titled \"The Pawns of Null-A\") was serialized in 1948\u201349.\nAt the same time, in his fiction, van Vogt was consistently sympathetic to absolute monarchy as a form of government. This was the case, for instance, in the \"Weapon Shop\" series, the \"Mixed Men\" series, and in single stories such as \"Heir Apparent\" (1945), whose protagonist was described as a \"benevolent dictator\". These sympathies were the subject of much critical discussion during van Vogt's career, and afterwards.\nVan Vogt published \"Enchanted Village\" in the July 1950 issue of \"Other Worlds Science Stories\". It was reprinted in over 20 collections or anthologies, and appeared many times in translation.\nDianetics and fix-ups (1950\u20131961).\nIn 1950, van Vogt was briefly appointed as head of L. Ron Hubbard's Dianetics operation in California. Van Vogt had first met Hubbard in 1945, and became interested in his theories, which were published shortly thereafter. Dianetics was the secular precursor to Hubbard's Church of Scientology; van Vogt would have no association with Scientology, as he did not approve of its mysticism.\nThe California Dianetics operation went broke nine months later, but never went bankrupt, due to van Vogt's arrangements with creditors. Shortly afterward, van Vogt and his wife opened their own Dianetics center, partly financed by his writings, until he \"signed off\" around 1961. From 1951 until 1961, van Vogt's focus was on Dianetics, and no new story ideas flowed from his typewriter.\nFix-ups.\nHowever, during the 1950s, van Vogt retrospectively patched together many of his previously published stories into novels, sometimes creating new interstitial material to help bridge gaps in the narrative. Van Vogt referred to the resulting books as \"fix-ups\", a term that entered the vocabulary of science-fiction criticism. When the original stories were closely related this was often successful, although some van Vogt fix-ups featured disparate stories thrown together that bore little relation to each other, generally making for a less coherent plot. One of his best-known (and well-regarded) novels, \"The Voyage of the Space Beagle\" (1950) was a fix-up of four short stories including \"Discord in Scarlet\"; it was published in at least five European languages by 1955.\nAlthough Van Vogt averaged a new book title every ten months from 1951 to 1961, none of them were entirely new content; they were all fix-ups, collections of previously published stories, expansions of previously published short stories to novel length, or republications of previous books under new titles and all based on story material written and originally published between 1939 and 1950. Examples include \"The Weapon Shops of Isher\" (1951), \"The Mixed Men\" (1952), \"The War Against the Rull\" (1959), and the two \"Clane\" novels, \"Empire of the Atom\" (1957) and \"The Wizard of Linn\" (1962), which were inspired (like Asimov's Foundation series) by Roman imperial history; specifically, as Damon Knight wrote, the plot of \"Empire of the Atom\" was \"lifted almost bodily\" from that of Robert Graves' \"I, Claudius\". (Also, one non-fiction work, \"The Hypnotism Handbook\", appeared in 1956, though it had apparently been written much earlier.)\nAfter more than a decade of running their Dianetics center, Hull and van Vogt closed it in 1961. Nevertheless, van Vogt maintained his association with the organization and was still president of the Californian Association of Dianetic Auditors into the 1980s.\nReturn to writing and later career (1962\u20131986).\nThough the constant re-packaging of his older work meant that he had never really been away from the book publishing world, van Vogt had not published any wholly new fiction for almost 12 years when he decided to return to writing in 1962. He did not return immediately to science fiction, but instead wrote the only mainstream, non-sf novel of his career.\nVan Vogt was profoundly affected by revelations of totalitarian police states that emerged after World War II. Accordingly, he wrote a mainstream novel that he set in Communist China, \"The Violent Man\" (1962). Van Vogt explained that to research this book he had read 100 books about China. Into this book he incorporated his view of \"the violent male type\", which he described as a \"man who had to be right\", a man who \"instantly attracts women\" and who he said were the men who \"run the world\". Contemporary reviews were lukewarm at best, and van Vogt thereafter returned to science fiction.\nFrom 1963 through the mid-1980s, van Vogt once again published new material on a regular basis, though fix-ups and reworked material also appeared relatively often. His later novels included fix-ups such as \"The Beast\" (also known as \"Moonbeast\") (1963), \"Rogue Ship\" (1965), \"Quest for the Future\" (1970) and \"Supermind\" (1977). He also wrote novels by expanding previously published short stories; works of this type include \"The Darkness on Diamondia\" (1972) and \"Future Glitter\" (also known as \"Tyranopolis\"; 1973).\nNovels that were written simply as novels, and not serialized magazine pieces or fix-ups, had been very rare in van Vogt's oeuvre, but began to appear regularly beginning in the 1970s. Van Vogt's original novels included \"Children of Tomorrow\" (1970), \"The Battle of Forever\" (1971) and \"The Anarchistic Colossus\" (1977). Over the years, many sequels to his classic works were promised, but only one appeared: \"Null-A Three\" (1984; originally published in French). Several later books were initially published in Europe, and at least one novel only ever appeared in foreign language editions and was never published in its original English.\nFinal years.\nWhen the 1979 film \"Alien\" appeared, it was noted that the plot closely matched the plots of both \"Black Destroyer\" and \"Discord in Scarlet\", both published in \"Astounding magazine\" in 1939, and then later published in the 1950 book \"Voyage of the Space Beagle\". Van Vogt sued the production company for plagiarism, and eventually collected an out-of-court settlement of $50,000 from 20th Century Fox. \nIn increasingly frail health, van Vogt published his final short story in 1986.\nPersonal life.\nVan Vogt's first wife, Edna Mayne Hull, died in 1975. Van Vogt married Lydia Bereginsky in 1979; they remained together until his death.\nDeath.\nOn January 26, 2000, A. E. van Vogt died in Los Angeles from Alzheimer's disease. He was survived by his second wife.\nCritical reception.\nCritical opinion about the quality of van Vogt's work is sharply divided. An early and articulate critic was Damon Knight. In a 1945 chapter-long essay reprinted in \"In Search of Wonder,\" entitled \"Cosmic Jerrybuilder: A. E. van Vogt\", Knight described van Vogt as \"no giant; he is a pygmy who has learned to operate an overgrown typewriter\". Knight described \"The World of Null-A\" as \"one of the worst allegedly adult science fiction stories ever published\". Concerning van Vogt's writing, Knight said:\nAbout \"Empire of the Atom\" Knight wrote:\nKnight also expressed misgivings about van Vogt's politics. He noted that van Vogt's stories almost invariably present absolute monarchy in a favorable light. In 1974, Knight retracted some of his criticism after finding out about Vogt's writing down his dreams as a part of his working methods:\nKnight's criticism greatly damaged van Vogt's reputation. On the other hand, when science fiction author Philip K. Dick was asked which science fiction writers had influenced his work the most, he replied:\nDick also defended van Vogt against Damon Knight's criticisms:\nIn a review of \"Transfinite: The Essential A. E. van Vogt\", science fiction writer Paul Di Filippo said:\nIn \"The John W. Campbell Letters\", Campbell says, \"The son-of-a-gun gets hold of you in the first paragraph, ties a knot around you, and keeps it tied in every paragraph thereafter\u2014including the ultimate last one\".\nHarlan Ellison (who had begun reading van Vogt as a teenager) wrote, \"Van was the first writer to shine light on the restricted ways in which I had been taught to view the universe and the human condition\".\nWriting in 1984, David Hartwell said:\nThe literary critic Leslie A. Fiedler said something similar:\nAmerican literary critic Fredric Jameson says of van Vogt:\nVan Vogt still has his critics. For example, Darrell Schweitzer, writing to \"The New York Review of Science Fiction\" in 1999, quoted a passage from the original van Vogt novelette \"The Mixed Men\", which he was then reading, and remarked:\nRecognition.\nIn 1946, van Vogt and his first wife, Edna Mayne Hull, were Guests of Honor at the fourth World Science Fiction Convention.\nIn 1980, van Vogt received a \"Casper Award\" (precursor to the Canadian Prix Aurora Awards) for Lifetime Achievement.\nThe Science Fiction Writers of America (SFWA) named him its 14th Grand Master in 1995 (presented 1996). Great controversy within SFWA accompanied its long wait in bestowing its highest honor (limited to living writers, no more than one annually). Writing an obituary of van Vogt, Robert J. Sawyer, a fellow Canadian writer of science fiction, remarked:\nIt is generally held that a key factor in the delay was \"damnable SFWA politics\" reflecting the concerns of Damon Knight, the founder of the SFWA, who abhorred van Vogt's style and politics and thoroughly demolished his literary reputation in the 1950s.\nHarlan Ellison was more explicit in 1999 introduction to \"Futures Past: The Best Short Fiction of A. E. van Vogt\":\nIn 1996, van Vogt received a Special Award from the World Science Fiction Convention \"for six decades of golden age science fiction\". That same year, the Science Fiction and Fantasy Hall of Fame inducted him in its inaugural class of two deceased and two living persons, along with writer Jack Williamson (also living) and editors Hugo Gernsback and John W. Campbell.\nThe works of van Vogt were translated into French by the surrealist Boris Vian (\"The World of Null-A\" as \"Le Monde des \u00c5\" in 1958), and van Vogt's works were \"viewed as great literature of the surrealist school\". In addition, \"Slan\" was published in French, translated by Jean Rosenthal, under the title \"\u00c0 la poursuite des Slans\", as part of the paperback series 'Editions J'ai Lu: Romans-Texte Integral' in 1973. This edition also listing the following works by van Vogt as having been published in French as part of this series: \"Le Monde des \u00c5\", \"La faune de l'espace\", \"Les joueurs du \u00c5\", \"L'empire de l'atome\", \"Le sorcier de Linn\", \"Les armureries d'Isher\", \"Les fabricants d'armes\", and \"Le livre de Ptath\". Van Vogt's last novel, 1985's \"To Conquer Kiber\", has only been released in French (as \"\u00c0 la conqu\u00eate de Kiber\".)"}
{"id": "890", "revid": "23641757", "url": "https://en.wikipedia.org/wiki?curid=890", "title": "Anna Kournikova", "text": "Anna Sergeyevna Kournikova Iglesias (n\u00e9e Kournikova; ; born 7 June 1981) is a Russian model and television personality, and former professional tennis player. Her appearance and celebrity status made her one of the best known tennis stars worldwide. At the peak of her fame, fans looking for images of Kournikova made her name one of the most common search strings on Google Search.\nDespite never winning a singles title, she reached No.\u00a08 in the world in 2000. She achieved greater success playing doubles, where she was at times the world No.\u00a01 player. With Martina Hingis as her partner, she won Grand Slam titles in Australia in 1999 and 2002, and the WTA Championships in 1999 and 2000. They referred to themselves as the \"Spice Girls of Tennis\".\nKournikova retired from professional tennis in 2003 due to serious back and spinal problems, including a herniated disk. She lives in Miami Beach, Florida, and played in occasional exhibitions and in doubles for the St.\u00a0Louis Aces of World TeamTennis before the team folded in 2011. She was a new trainer for season 12 of the television show \"The Biggest Loser\", replacing Jillian Michaels, but did not return for season 13. In addition to her tennis and television work, Kournikova serves as a Global Ambassador for Population Services International's \"Five &amp; Alive\" program, which addresses health crises facing children under the age of five and their families.\nEarly life.\nKournikova was born in Moscow, Russia, on 7 June 1981. Her father, Sergei Kournikov (born 1961), a former Greco-Roman wrestling champion, eventually earned a PhD and was a professor at the University of Physical Culture and Sport in Moscow. As of 2001, he was still a part-time martial arts instructor there. Her mother Alla (born 1963) had been a 400-metre runner. Her younger half-brother, Allan, is a youth golf world champion who was featured in the 2013 documentary film \"The Short Game\".\nSergei Kournikov has said, \"We were young and we liked the clean, physical life, so Anna was in a good environment for sport from the beginning\".\nKournikova received her first tennis racquet as a New Year gift in 1986 at the age of five. Describing her early regimen, she said, \"I played two times a week from age six. It was a children's program. And it was just for fun; my parents didn't know I was going to play professionally, they just wanted me to do something because I had lots of energy. It was only when I started playing well at seven that I went to a professional academy. I would go to school, and then my parents would take me to the club, and I'd spend the rest of the day there just having fun with the kids.\" In 1986, Kournikova became a member of the Spartak Tennis Club, coached by Larissa Preobrazhenskaya. In 1989, at the age of eight, Kournikova began appearing in junior tournaments, and by the following year, was attracting attention from tennis scouts across the world. She signed a management deal at age ten and went to Bradenton, Florida, to train at Nick Bollettieri's celebrated tennis academy.\nTennis career.\n1989\u20131997: early years and breakthrough.\nFollowing her arrival in the United States, she became prominent on the tennis scene. At the age of 14, she won the European Championships and the Italian Open Junior tournament. In December 1995, she became the youngest player to win the 18-and-under division of the Junior Orange Bowl tennis tournament. By the end of the year, Kournikova was crowned the ITF Junior World Champion U-18 and Junior European Champion U-18.\nEarlier, in September 1995, Kournikova, still only 14 years of age, debuted in the WTA Tour, when she received a wildcard into the qualifications at the WTA tournament in Moscow, the Moscow Ladies Open, and qualified before losing in the second round of the main draw to third-seeded Sabine Appelmans. She also reached her first WTA Tour doubles final in that debut appearance \u2013 partnering with 1995 Wimbledon girls' champion in both singles and doubles Aleksandra Olsza, she lost the title match to Meredith McGrath and Larisa Savchenko-Neiland.\nIn February\u2013March 1996, Kournikova won two ITF titles, in Midland, Michigan and Rockford, Illinois. Still only 14 years of age, in April 1996 she debuted at the Fed Cup for Russia, the youngest player ever to participate and win a match.\nIn 1996, she started playing under a new coach, Ed Nagel. Her six-year association with Nagel was successful. At 15, she made her Grand Slam debut, reaching the fourth round of the 1996 US Open, losing to Steffi Graf, the eventual champion. After this tournament, Kournikova's ranking jumped from No.\u00a0144 to debut in the Top 100 at\u00a0No. 69. Kournikova was a member of the Russian delegation to the 1996 Olympic Games in Atlanta, Georgia. In 1996, she was named WTA Newcomer of the Year, and she was ranked No. 57 in the end of the season.\nKournikova entered the 1997 Australian Open as world No. 67, where she lost in the first round to world No. 12, Amanda Coetzer. At the Italian Open, Kournikova lost to Amanda Coetzer in the second round. She reached the semi-finals in the doubles partnering with Elena Likhovtseva, before losing to the sixth seeds Mary Joe Fern\u00e1ndez and Patricia Tarabini.\nAt the French Open, Kournikova made it to the third round before losing to world No. 1, Martina Hingis. She also reached the third round in doubles with Likhovtseva. At the Wimbledon Championships, Kournikova became only the second woman in the open era to reach the semi-finals in her Wimbledon debut, the first being Chris Evert in 1972. There she lost to eventual champion Martina Hingis.\nAt the US Open, she lost in the second round to the eleventh seed Irina Sp\u00eerlea. Partnering with Likhovtseva, she reached the third round of the women's doubles event. Kournikova played her last WTA Tour event of 1997 at Porsche Tennis Grand Prix in Filderstadt, losing to Amanda Coetzer in the second round of singles, and in the first round of doubles to Lindsay Davenport and Jana Novotn\u00e1 partnering with Likhovtseva. She broke into the top 50 on 19 May, and was ranked No. 32 in singles and No. 41 in doubles at the end of the season.\n1998\u20132000: success and stardom.\nIn 1998, Kournikova broke into the WTA's top 20 rankings for the first time, when she was ranked No. 16. At the Australian Open, Kournikova lost in the third round to world No. 1 player, Martina Hingis. She also partnered with Larisa Savchenko-Neiland in women's doubles, and they lost to eventual champions Hingis and Mirjana Lu\u010di\u0107 in the second round. Although she lost in the second round of the Paris Open to Anke Huber in singles, Kournikova reached her second doubles WTA Tour final, partnering with Larisa Savchenko-Neiland. They lost to Sabine Appelmans and Miriam Oremans. Kournikova and Savchenko-Neiland reached their second consecutive final at the Linz Open, losing to Alexandra Fusai and Nathalie Tauziat. At the Miami Open, Kournikova reached her first WTA Tour singles final, before losing to Venus Williams in the final.\nKournikova then reached two consecutive quarterfinals, at Amelia Island and the Italian Open, losing respectively to Lindsay Davenport and Martina Hingis. At the German Open, she reached the semi-finals in both singles and doubles, partnering with Larisa Savchenko-Neiland. At the French Open Kournikova had her best result at this tournament, making it to the fourth round before losing to Jana Novotn\u00e1. She also reached her first Grand Slam doubles semi-finals, losing with Savchenko-Neiland to Lindsay Davenport and Natasha Zvereva. During her quarterfinals match at the grass-court Eastbourne Open versus Steffi Graf, Kournikova injured her thumb, which would eventually force her to withdraw from the 1998 Wimbledon Championships. However, she won that match, but then withdrew from her semi-finals match against Arantxa S\u00e1nchez Vicario. Kournikova returned for the Du Maurier Open and made it to the third round, before losing to Conchita Mart\u00ednez. At the US Open Kournikova reached the fourth round before losing to Arantxa S\u00e1nchez Vicario. Her strong year qualified her for the year-end 1998 WTA Tour Championships, but she lost to Monica Seles in the first round. However, with Seles, she won her first WTA doubles title, in Tokyo, beating Mary Joe Fern\u00e1ndez and Arantxa S\u00e1nchez Vicario in the final. At the end of the season, she was ranked No. 10 in doubles.\nAt the start of the 1999 season, Kournikova advanced to the fourth round in singles at the Australian Open before losing to Mary Pierce. In the doubles Kournikova won her first Grand Slam title, partnering with Martina Hingis to defeat Lindsay Davenport and Natasha Zvereva in the final. At the Tier I Family Circle Cup, Kournikova reached her second WTA Tour final, but lost to Martina Hingis. She then defeated Jennifer Capriati, Lindsay Davenport and Patty Schnyder on her route to the Bausch &amp; Lomb Championships semi-finals, losing to Ruxandra Dragomir. At The French Open, Kournikova reached the fourth round before losing to eventual champion Steffi Graf. Once the grass-court season commenced in England, Kournikova lost to Nathalie Tauziat in the semi-finals in Eastbourne. At Wimbledon, Kournikova lost to Venus Williams in the fourth round. She also reached the final in mixed doubles, partnering with Jonas Bj\u00f6rkman, but they lost to Leander Paes and Lisa Raymond. Kournikova again qualified for year-end WTA Tour Championships, but lost to Mary Pierce in the first round, and ended the season as World No. 12.\nWhile Kournikova had a successful singles season, she was even more successful in doubles. After their victory at the Australian Open, she and Martina Hingis won tournaments in Indian Wells, Rome, Eastbourne and the WTA Tour Championships, and reached the final of The French Open where they lost to Serena and Venus Williams. Partnering with Elena Likhovtseva, Kournikova also reached the final in Stanford. On 22 November 1999 she reached the world No. 1 ranking in doubles, and ended the season at this ranking. Kournikova and Hingis were presented with the WTA Award for Doubles Team of the Year.\nKournikova opened her 2000 season winning the Gold Coast Open doubles tournament partnering with Julie Halard. She then reached the singles semi-finals at the Medibank International Sydney, losing to Lindsay Davenport. At the Australian Open, she reached the fourth round in singles and the semi-finals in doubles. That season, Kournikova reached eight semi-finals (Sydney, Scottsdale, Stanford, San Diego, Luxembourg, Leipzig and Tour Championships), seven quarterfinals (Gold Coast, Tokyo, Amelia Island, Hamburg, Eastbourne, Z\u00fcrich and Philadelphia) and one final. On 20 November 2000 she broke into top 10 for the first time, reaching No. 8. She was also ranked No. 4 in doubles at the end of the season. Kournikova was once again, more successful in doubles. She reached the final of the US Open in mixed doubles, partnering with Max Mirnyi, but they lost to Jared Palmer and Arantxa S\u00e1nchez Vicario. She also won six doubles titles \u2013 Gold Coast (with Julie Halard), Hamburg (with Natasha Zvereva), Filderstadt, Z\u00fcrich, Philadelphia and the Tour Championships (with Martina Hingis).\n2001\u20132003: injuries and final years.\nHer 2001 season was plagued by injuries, including a left foot stress fracture which made her withdraw from 12 tournaments, including the French Open and Wimbledon. She underwent surgery in April. She reached her second career grand slam quarterfinals, at the Australian Open. Kournikova then withdrew from several events due to continuing problems with her left foot and did not return until Leipzig. With Barbara Schett, she won the doubles title in Sydney. She then lost in the finals in Tokyo, partnering with Iroda Tulyaganova, and at San Diego, partnering with Martina Hingis. Hingis and Kournikova also won the Kremlin Cup. At the end of the 2001 season, she was ranked No. 74 in singles and No. 26 in doubles.\nKournikova regained some success in 2002. She reached the semi-finals of Auckland, Tokyo, Acapulco and San Diego, and the final of the China Open, losing to Anna Smashnova. This was Kournikova's last singles final. With Martina Hingis, she lost in the final at Sydney, but they won their second Grand Slam title together, the Australian Open. They also lost in the quarterfinals of the US Open. With Chanda Rubin, Kournikova played the semi-finals of Wimbledon, but they lost to Serena and Venus Williams. Partnering with Janet Lee, she won the Shanghai title. At the end of 2002 season, she was ranked No. 35 in singles and No. 11 in doubles.\nIn 2003, Anna Kournikova achieved her first Grand Slam match victory in two years at the Australian Open. She defeated Henrieta Nagyov\u00e1 in the first round, and then lost to Justine Henin-Hardenne in the 2nd round. She withdrew from Tokyo due to a sprained back suffered at the Australian Open and did not return to Tour until Miami. On 9 April, in what would be the final WTA match of her career, Kournikova dropped out in the first round of the Family Circle Cup in Charleston, due to a left adductor strain. Her singles world ranking was 67. She reached the semi-finals at the ITF tournament in Sea Island, before withdrawing from a match versus Maria Sharapova due to the adductor injury. She lost in the first round of the ITF tournament in Charlottesville. She did not compete for the rest of the season due to a continuing back injury. At the end of the 2003 season and her professional career, she was ranked No. 305 in singles and No. 176 in doubles.\nKournikova's two Grand Slam doubles titles came in 1999 and 2002, both at the Australian Open in the Women's Doubles event with partner Martina Hingis. Kournikova proved a successful doubles player on the professional circuit, winning 16 tournament doubles titles, including two Australian Opens and being a finalist in mixed doubles at the US Open and at Wimbledon, and reaching the No. 1 ranking in doubles in the WTA Tour rankings. Her pro career doubles record was 200\u201371. However, her singles career plateaued after 1999. For the most part, she managed to retain her ranking between 10 and 15 (her career high singles ranking was No.8), but her expected finals breakthrough failed to occur; she only reached four finals out of 130 singles tournaments, never in a Grand Slam event, and never won one.\nHer singles record is 209\u2013129. Her final playing years were marred by a string of injuries, especially back injuries, which caused her ranking to erode gradually. As a personality Kournikova was among the most common search strings for both articles and images in her prime.\n2004\u2013present: exhibitions and World Team Tennis.\nKournikova has not played on the WTA Tour since 2003, but still plays exhibition matches for charitable causes. In late 2004, she participated in three events organized by Elton John and by fellow tennis players Serena Williams and Andy Roddick. In January 2005, she played in a doubles charity event for the Indian Ocean tsunami with John McEnroe, Andy Roddick, and Chris Evert. In November 2005, she teamed up with Martina Hingis, playing against Lisa Raymond and Samantha Stosur in the WTT finals for charity. Kournikova is also a member of the St. Louis Aces in the World Team Tennis (WTT), playing doubles only.\nIn September 2008, Kournikova showed up for the 2008 Nautica Malibu Triathlon held at Zuma Beach in Malibu, California. The Race raised funds for children's Hospital Los Angeles. She won that race for women's K-Swiss team. On 27 September 2008, Kournikova played exhibition mixed doubles matches in Charlotte, North Carolina, partnering with Tim Wilkison and Karel Nov\u00e1\u010dek. Kournikova and Wilkison defeated Jimmy Arias and Chanda Rubin, and then Kournikova and Novacek defeated Rubin and Wilkison.\nOn 12 October 2008, Anna Kournikova played one exhibition match for the annual charity event, hosted by Billie Jean King and Elton John, and raised more than $400,000 for the Elton John AIDS Foundation and Atlanta AIDS Partnership Fund. She played doubles with Andy Roddick (they were coached by David Chang) versus Martina Navratilova and Jesse Levine (coached by Billie Jean King); Kournikova and Roddick won.\nKournikova was one of \"four former world No. 1 players\" who participated in \"Legendary Night\", held on 2 May 2009, at the Turning Stone Event Center in Verona, New York, the others being John McEnroe (who had been No. 1 in both singles and doubles), Tracy Austin and Jim Courier (both of whom who had been No. 1 in singles but not doubles). The exhibition included a mixed doubles match in which McEnroe and Kournikova defeated Courier and Austin.\nIn 2008, she was named a spokesperson for K-Swiss. In 2005, Kournikova stated that if she were 100% fit, she would like to come back and compete again.\nIn June 2010, Kournikova reunited with her doubles partner Martina Hingis to participate in competitive tennis for the first time in seven years in the Invitational Ladies Doubles event at Wimbledon. On 29 June 2010 they defeated the British pair Samantha Smith and Anne Hobbs.\nPlaying style.\nKournikova plays right-handed with a two-handed backhand. She is a great player at the net. She can hit forceful groundstrokes and also drop shots.\nHer playing style fits the profile for a doubles player, and is complemented by her height. She has been compared to such doubles specialists as Pam Shriver and Peter Fleming.\nPersonal life.\nKournikova was in a relationship with fellow Russian, Pavel Bure, an NHL ice hockey player. The two met in 1999, when Kournikova was still linked to Bure's former Russian teammate Sergei Fedorov. Bure and Kournikova were reported to have been engaged in 2000 after a reporter took a photo of them together in a Florida restaurant where Bure supposedly asked Kournikova to marry him. As the story made headlines in Russia, where they were both heavily followed in the media as celebrities, Bure and Kournikova both denied any engagement. Kournikova, 10 years younger than Bure, was 18 years old at the time.\nFedorov claimed that he and Kournikova were married in 2001, and divorced in 2003. Kournikova's representatives deny any marriage to Fedorov; however, Fedorov's agent Pat Brisson claims that although he does not know when they got married, he knew \"Fedorov was married\".\nKournikova started dating singer Enrique Iglesias in late 2001 after she had appeared in his music video for \"Escape\". The couple have three children together, fraternal twins, a son and daughter, born on 16 December 2017, and another daughter born on 30 January 2020.\nIt was reported in 2010 that Kournikova had become an American citizen.\nMedia publicity.\nIn 2000, Kournikova became the new face for Berlei's shock absorber sports bras, and appeared in the \"only the ball should bounce\" billboard campaign. Following that, she was cast by the Farrelly brothers for a minor role in the 2000 film \"Me, Myself &amp; Irene\" starring Jim Carrey and Ren\u00e9e Zellweger. Photographs of her have appeared on covers of various publications, including men's magazines, such as one in the much-publicized 2004 \"Sports Illustrated Swimsuit Issue\", where she posed in bikinis and swimsuits, as well as in \"FHM\" and \"Maxim\".\nKournikova was named one of \"People\"s 50 Most Beautiful People in 1998 and was voted \"hottest female athlete\" on ESPN.com. In 2002, she also placed first in \"FHM's 100 Sexiest Women in the World\" in US and UK editions. By contrast, ESPN \u2013 citing the degree of hype as compared to actual accomplishments as a singles player \u2013 ranked Kournikova 18th in its \"25 Biggest Sports Flops of the Past 25 Years\". Kournikova was also ranked No.\u00a01 in the ESPN Classic series \"Who's number 1?\" when the series featured sport's most overrated athletes.\nShe continued to be the most searched athlete on the Internet through 2008 even though she had retired from the professional tennis circuit years earlier. After slipping from first to sixth among athletes in 2009, she moved back up to third place among athletes in terms of search popularity in 2010.\nIn October 2010, Kournikova headed to NBC's \"The Biggest Loser\" where she led the contestants in a tennis-workout challenge. In May 2011, it was announced that Kournikova would join \"The Biggest Loser\" as a regular celebrity trainer in season 12. She did not return for season 13.\nExternal links.\n \n \n \n "}
{"id": "891", "revid": "1091098113", "url": "https://en.wikipedia.org/wiki?curid=891", "title": "Accountancy", "text": ""}
{"id": "892", "revid": "41588820", "url": "https://en.wikipedia.org/wiki?curid=892", "title": "Alfons Maria Jakob", "text": "Alfons Maria Jakob (2 July 1884 \u2013 17 October 1931) was a German neurologist who worked in the field of neuropathology.\nHe was born in Aschaffenburg, Bavaria and educated in medicine at the universities of Munich, Berlin, and Strasbourg, where he received his doctorate in 1908. During the following year, he began clinical work under the psychiatrist Emil Kraepelin and did laboratory work with Franz Nissl and Alois Alzheimer in Munich.\nIn 1911, by way of an invitation from Wilhelm Weygandt, he relocated to Hamburg, where he worked with Theodor Kaes and eventually became head of the laboratory of anatomical pathology at the psychiatric State Hospital Hamburg-Friedrichsberg. Following the death of Kaes in 1913, Jakob succeeded him as prosector. During World War I he served as an army physician in Belgium, and afterwards returned to Hamburg. In 1919, he obtained his habilitation for neurology and in 1924 became a professor of neurology. Under Jakob's guidance the department grew rapidly. He made significant contributions to knowledge on concussion and secondary nerve degeneration and became a doyen of neuropathology.\nJakob was the author of five monographs and nearly 80 scientific papers. His neuropathological research contributed greatly to the delineation of several diseases, including multiple sclerosis and Friedreich's ataxia. He first recognised and described Alper's disease and Creutzfeldt\u2013Jakob disease (named along with Munich neuropathologist Hans Gerhard Creutzfeldt). He gained experience in neurosyphilis, having a 200-bed ward devoted entirely to that disorder. Jakob made a lecture tour of the United States (1924) and South America (1928), of which, he wrote a paper on the neuropathology of yellow fever.\nHe suffered from chronic osteomyelitis for the last seven years of his life. This eventually caused a retroperitoneal abscess and paralytic ileus from which he died following operation."}
{"id": "894", "revid": "11804706", "url": "https://en.wikipedia.org/wiki?curid=894", "title": "Agnosticism", "text": "Agnosticism is the view or belief that the existence of God, the divine, or the supernatural is either unknowable in principle or unknown in fact. It can also mean an apathy towards such religious belief and refer to personal limitations rather than a worldview. Another definition is the view that \"human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist.\"\nThe English biologist Thomas Henry Huxley said that he originally coined the word \"agnostic\" in 1869 \"to denote people who, like [himself], confess themselves to be hopelessly ignorant concerning a variety of matters [including the matter of God's existence], about which metaphysicians and theologians, both orthodox and heterodox, dogmatise with the utmost confidence.\" Earlier thinkers had written works that promoted agnostic points of view, such as Sanjaya Belatthiputta, a 5th-century BCE Indian philosopher who expressed agnosticism about any afterlife; and Protagoras, a 5th-century BCE Greek philosopher who expressed agnosticism about the existence of \"the gods\".\nDefining agnosticism.\nBeing a scientist, above all else, Huxley presented agnosticism as a form of demarcation. A hypothesis with no supporting, objective, testable evidence is not an objective, scientific claim. As such, there would be no way to test said hypotheses, leaving the results inconclusive. His agnosticism was not compatible with forming a belief as to the truth, or falsehood, of the claim at hand. Karl Popper would also describe himself as an agnostic. According to philosopher William L. Rowe, in this strict sense, agnosticism is the view that human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist.\nGeorge H. Smith, while admitting that the narrow definition of atheist was the common usage definition of that word, and admitting that the broad definition of agnostic was the common usage definition of that word, promoted broadening the definition of atheist and narrowing the definition of agnostic. Smith rejects agnosticism as a third alternative to theism and atheism and promotes terms such as agnostic atheism (the view of those who do not hold a belief in the existence of any deity but claim that the existence of a deity is unknown or inherently unknowable) and agnostic theism (the view of those who believe in the existence of a deity(s) but claim that the existence of a deity is unknown or inherently unknowable).\nEtymology.\n\"Agnostic\" () was used by Thomas Henry Huxley in a speech at a meeting of the Metaphysical Society in 1869 to describe his philosophy, which rejects all claims of spiritual or mystical knowledge.\nEarly Christian church leaders used the Greek word \"gnosis\" (knowledge) to describe \"spiritual knowledge\". Agnosticism is not to be confused with religious views opposing the ancient religious movement of Gnosticism in particular; Huxley used the term in a broader, more abstract sense. Huxley identified agnosticism not as a creed but rather as a method of skeptical, evidence-based inquiry.\nThe term \"agnostic\" is also cognate with the Sanskrit word \"aj\u00f1asi\", which translates literally to \"not knowable\", and relates to the ancient Indian philosophical school of Aj\u00f1ana, which proposes that it is impossible to obtain knowledge of metaphysical nature or ascertain the truth value of philosophical propositions; and even if knowledge were possible, it is useless and disadvantageous for final salvation.\nIn recent years, scientific literature dealing with neuroscience and psychology has used the word to mean \"not knowable\". In technical and marketing literature, \"agnostic\" can also mean independence from some parameters\u2014for example, \"platform agnostic\" (referring to cross-platform software), or \"hardware-agnostic\".\nQualifying agnosticism.\nScottish Enlightenment philosopher David Hume contended that meaningful statements about the universe are always qualified by some degree of doubt. He asserted that the fallibility of human beings means that they cannot obtain absolute certainty except in trivial cases where a statement is true by definition (e.g. tautologies such as \"all bachelors are unmarried\" or \"all triangles have three corners\").\nTypes.\nStrong agnosticism.\nAlso called \"hard\", \"closed\", \"strict\", or \"permanent agnosticism\", strong agnosticism is the view that the question of the existence or nonexistence of a deity or deities, and the nature of ultimate reality is unknowable by reason of our natural inability to verify any subjective experience with anything but another subjective experience. A strong agnostic would say, \"I cannot know whether a deity exists or not, and neither can you.\"\nWeak agnosticism.\nAlso called \"soft\", \"open\", \"empirical\", \"hopeful\", or \"temporal agnosticism\", weak agnosticism is the view that the existence or nonexistence of any deities is currently unknown but is not necessarily unknowable; therefore, one will withhold judgement until evidence, if any, becomes available. A weak agnostic would say, \"I don't know whether any deities exist or not, but maybe one day, if there is evidence, we can find something out.\"\nApathetic agnosticism.\nThe view that no amount of debate can prove or disprove the existence of one or more deities, and if one or more deities exist, they do not appear to be concerned about the fate of humans. Therefore, their existence has little to no impact on personal human affairs and should be of little interest. An apathetic agnostic would say, \"I don't know whether any deity exists or not, and I don't care if any deity exists or not.\"\nHistory.\nHindu philosophy.\nThroughout the history of Hinduism there has been a strong tradition of philosophic speculation and skepticism.\nThe Rig Veda takes an agnostic view on the fundamental question of how the universe and the gods were created. Nasadiya Sukta (\"Creation Hymn\") in the tenth chapter of the Rig Veda says:\nHume, Kant, and Kierkegaard.\nAristotle,\nAnselm,\nAquinas,\nDescartes,\nand G\u00f6del presented arguments attempting to rationally prove the existence of God. The skeptical empiricism of David Hume, the antinomies of Immanuel Kant, and the existential philosophy of S\u00f8ren Kierkegaard convinced many later philosophers to abandon these attempts, regarding it impossible to construct any unassailable proof for the existence or non-existence of God.\nIn his 1844 book \"Philosophical Fragments\", Kierkegaard writes:\nHume was Huxley's favourite philosopher, calling him \"the Prince of Agnostics\". Diderot wrote to his mistress, telling of a visit by Hume to the Baron D'Holbach, and describing how a word for the position that Huxley would later describe as agnosticism did not seem to exist, or at least was not common knowledge, at the time.\nUnited Kingdom.\nCharles Darwin.\nRaised in a religious environment, Charles Darwin (1809\u20131882) studied to be an Anglican clergyman. While eventually doubting parts of his faith, Darwin continued to help in church affairs, even while avoiding church attendance. Darwin stated that it would be \"absurd to doubt that a man might be an ardent theist and an evolutionist\". Although reticent about his religious views, in 1879 he wrote that \"I have never been an atheist in the sense of denying the existence of a God. \u2013 I think that generally ... an agnostic would be the most correct description of my state of mind.\"\nThomas Henry Huxley.\nAgnostic views are as old as philosophical skepticism, but the terms agnostic and agnosticism were created by Huxley (1825\u20131895) to sum up his thoughts on contemporary developments of metaphysics about the \"unconditioned\" (William Hamilton) and the \"unknowable\" (Herbert Spencer). Though Huxley began to use the term \"agnostic\" in 1869, his opinions had taken shape some time before that date. In a letter of September 23, 1860, to Charles Kingsley, Huxley discussed his views extensively:\nAnd again, to the same correspondent, May 6, 1863:\nOf the origin of the name agnostic to describe this attitude, Huxley gave the following account:\nWilliam Stewart Ross.\nWilliam Stewart Ross (1844\u20131906) wrote under the name of Saladin. He was associated with Victorian Freethinkers and the organization the British Secular Union. He edited the \"Secular Review\" from 1882; it was renamed \"Agnostic Journal and Eclectic Review\" and closed in 1907. Ross championed agnosticism in opposition to the atheism of Charles Bradlaugh as an open-ended spiritual exploration.\nIn \"Why I am an Agnostic\" () he claims that agnosticism is \"the very reverse of atheism\".\nBertrand Russell.\nBertrand Russell (1872\u20131970) declared \"Why I Am Not a Christian\" in 1927, a classic statement of agnosticism.\nHe calls upon his readers to \"stand on their own two feet and look fair and square at the world with a fearless attitude and a free intelligence\".\nIn 1939, Russell gave a lecture on \"The existence and nature of God\", in which he characterized himself as an atheist. He said:\nHowever, later in the same lecture, discussing modern non-anthropomorphic concepts of God, Russell states:\nIn Russell's 1947 pamphlet, \"Am I An Atheist or an Agnostic?\" (subtitled \"A Plea For Tolerance in the Face of New Dogmas\"), he ruminates on the problem of what to call himself:\nIn his 1953 essay, \"What Is An Agnostic?\" Russell states:\nLater in the essay, Russell adds:\nLeslie Weatherhead.\nIn 1965, Christian theologian Leslie Weatherhead (1893\u20131976) published \"The Christian Agnostic\", in which he argues:\nAlthough radical and unpalatable to conventional theologians, Weatherhead's \"agnosticism\" falls far short of Huxley's, and short even of \"weak agnosticism\":\nUnited States.\nRobert G. Ingersoll.\nRobert G. Ingersoll (1833\u20131899), an Illinois lawyer and politician who evolved into a well-known and sought-after orator in 19th-century America, has been referred to as the \"Great Agnostic\".\nIn an 1896 lecture titled \"Why I Am An Agnostic\", Ingersoll stated this: \nIn the conclusion of the speech he simply sums up the agnostic position as:\nIn 1885, Ingersoll explained his comparative view of agnosticism and atheism as follows:\nBernard Iddings Bell.\nCanon Bernard Iddings Bell (1886\u20131958), a popular cultural commentator, Episcopal priest, and author, lauded the necessity of agnosticism in \"Beyond Agnosticism: A Book for Tired Mechanists\", calling it the foundation of \"all intelligent Christianity\". Agnosticism was a temporary mindset in which one rigorously questioned the truths of the age, including the way in which one believed God. His view of Robert Ingersoll and Thomas Paine was that they were not denouncing true Christianity but rather \"a gross perversion of it\". Part of the misunderstanding stemmed from ignorance of the concepts of God and religion. Historically, a god was any real, perceivable force that ruled the lives of humans and inspired admiration, love, fear, and homage; religion was the practice of it. Ancient peoples worshiped gods with real counterparts, such as Mammon (money and material things), Nabu (rationality), or Ba'al (violent weather); Bell argued that modern peoples were still paying homage\u2014with their lives and their children's lives\u2014to these old gods of wealth, physical appetites, and self-deification. Thus, if one attempted to be agnostic passively, he or she would incidentally join the worship of the world's gods.\nIn \"Unfashionable Convictions\" (1931), he criticized the Enlightenment's complete faith in human sensory perception, augmented by scientific instruments, as a means of accurately grasping Reality. Firstly, it was fairly new, an innovation of the Western World, which Aristotle invented and Thomas Aquinas revived among the scientific community. Secondly, the divorce of \"pure\" science from human experience, as manifested in American Industrialization, had completely altered the environment, often disfiguring it, so as to suggest its insufficiency to human needs. Thirdly, because scientists were constantly producing more data\u2014to the point where no single human could grasp it all at once\u2014it followed that human intelligence was incapable of attaining a complete understanding of universe; therefore, to admit the mysteries of the unobserved universe was to be \"actually\" scientific.\nBell believed that there were two other ways that humans could perceive and interact with the world. \"Artistic experience\" was how one expressed meaning through speaking, writing, painting, gesturing\u2014any sort of communication which shared insight into a human's inner reality. \"Mystical experience\" was how one could \"read\" people and harmonize with them, being what we commonly call love. In summary, man was a scientist, artist, and lover. Without exercising all three, a person became \"lopsided\".\nBell considered a humanist to be a person who cannot rightly ignore the other ways of knowing. However, humanism, like agnosticism, was also temporal, and would eventually lead to either scientific materialism or theism. He lays out the following thesis:\nDemographics.\nDemographic research services normally do not differentiate between various types of non-religious respondents, so agnostics are often classified in the same category as atheists or other non-religious people.\nA 2010 survey published in \"Encyclop\u00e6dia Britannica\" found that the non-religious people or the agnostics made up about 9.6% of the world's population.\nA November\u2013December 2006 poll published in the \"Financial Times\" gives rates for the United States and five European countries. The rates of agnosticism in the United States were at 14%, while the rates of agnosticism in the European countries surveyed were considerably higher: Italy (20%), Spain (30%), Great Britain (35%), Germany (25%), and France (32%).\nA study conducted by the Pew Research Center found that about 16% of the world's people, the third largest group after Christianity and Islam, have no religious affiliation.\nAccording to a 2012 report by the Pew Research Center, agnostics made up 3.3% of the US adult population.\nIn the \"U.S. Religious Landscape Survey\", conducted by the Pew Research Center, 55% of agnostic respondents expressed \"a belief in God or a universal spirit\",\nwhereas 41% stated that they thought that they felt a tension \"being non-religious in a society where most people are religious\".\nAccording to the 2021 Australian Bureau of Statistics, 38.9% of Australians have \"no religion\", a category that includes agnostics.\nBetween 64% and 65% of Japanese, and up to 81% of Vietnamese, are atheists, agnostics, or do not believe in a god. An official European Union survey reported that 3% of the EU population is unsure about their belief in a god or spirit.\nCriticism.\nAgnosticism is criticized from a variety of standpoints. Some atheists criticize the use of the term agnosticism as functionally indistinguishable from atheism; this results in frequent criticisms of those who adopt the term as avoiding the atheist label.\nTheistic.\nTheistic critics claim that agnosticism is impossible in practice, since a person can live only either as if God did not exist (\"etsi deus non-daretur\"), or as if God did exist (\"etsi deus daretur\").\nChristian.\nAccording to Pope Benedict XVI, strong agnosticism in particular contradicts itself in affirming the power of reason to know scientific truth. He blames the exclusion of reasoning from religion and ethics for dangerous pathologies such as crimes against humanity and ecological disasters.\n\"Agnosticism\", said Benedict, \"is always the fruit of a refusal of that knowledge which is in fact offered to man\u00a0... The knowledge of God has always existed\". He asserted that agnosticism is a choice of comfort, pride, dominion, and utility over truth, and is opposed by the following attitudes: the keenest self-criticism, humble listening to the whole of existence, the persistent patience and self-correction of the scientific method, a readiness to be purified by the truth.\nThe Catholic Church sees merit in examining what it calls \"partial agnosticism\", specifically those systems that \"do not aim at constructing a complete philosophy of the unknowable, but at excluding special kinds of truth, notably religious, from the domain of knowledge\". However, the Church is historically opposed to a full denial of the capacity of human reason to know God. The Council of the Vatican declares, \"God, the beginning and end of all, can, by the natural light of human reason, be known with certainty from the works of creation\".\nBlaise Pascal argued that even if there were truly no evidence for God, agnostics should consider what is now known as Pascal's Wager: the infinite expected value of acknowledging God is always greater than the finite expected value of not acknowledging his existence, and thus it is a safer \"bet\" to choose God.\nAtheistic.\nAccording to Richard Dawkins, a distinction between agnosticism and atheism is unwieldy and depends on how close to zero a person is willing to rate the probability of existence for any given god-like entity. About himself, Dawkins continues, \"I am agnostic only to the extent that I am agnostic about fairies at the bottom of the garden.\" Dawkins also identifies two categories of agnostics; \"Temporary Agnostics in Practice\" (TAPs), and \"Permanent Agnostics in Principle\" (PAPs). He states that \"agnosticism about the existence of God belongs firmly in the temporary or TAP category. Either he exists or he doesn't. It is a scientific question; one day we may know the answer, and meanwhile we can say something pretty strong about the probability\", and considers PAP a \"deeply inescapable kind of fence-sitting\".\nIgnosticism.\nA related concept is ignosticism, the view that a coherent definition of a deity must be put forward before the question of the existence of a deity can be meaningfully discussed. If the chosen definition is not coherent, the ignostic holds the noncognitivist view that the existence of a deity is meaningless or empirically untestable. A.\u00a0J. Ayer, Theodore Drange, and other philosophers see both atheism and agnosticism as incompatible with ignosticism on the grounds that atheism and agnosticism accept the statement \"a deity exists\" as a meaningful proposition that can be argued for or against."}
{"id": "896", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=896", "title": "Argon", "text": "Argon is a chemical element; it has symbol Ar and atomic number 18. It is in group 18 of the periodic table and is a noble gas. Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor (which averages about 4000 ppmv, but varies greatly), 23 times as abundant as carbon dioxide (400 ppmv), and more than 500 times as abundant as neon (18 ppmv). Argon is the most abundant noble gas in Earth's crust, comprising 0.00015% of the crust.\nNearly all argon in Earth's atmosphere is radiogenic argon-40, derived from the decay of potassium-40 in Earth's crust. In the universe, argon-36 is by far the most common argon isotope, as it is the most easily produced by stellar nucleosynthesis in supernovas.\nThe name \"argon\" is derived from the Greek word , neuter singular form of meaning 'lazy' or 'inactive', as a reference to the fact that the element undergoes almost no chemical reactions. The complete octet (eight electrons) in the outer atomic shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058\u00a0K is a defining fixed point in the International Temperature Scale of 1990.\nArgon is extracted industrially by the fractional distillation of liquid air. It is mostly used as an inert shielding gas in welding and other high-temperature industrial processes where ordinarily unreactive substances become reactive; for example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning. It is also used in incandescent and fluorescent lighting, and other gas-discharge tubes. It makes a distinctive blue-green gas laser. It is also used in fluorescent glow starters.\nCharacteristics.\nArgon has approximately the same solubility in water as oxygen and is 2.5 times more soluble in water than nitrogen. Argon is colorless, odorless, nonflammable and nontoxic as a solid, liquid or gas. Argon is chemically inert under most conditions and forms no confirmed stable compounds at room temperature.\nAlthough argon is a noble gas, it can form some compounds under various extreme conditions. Argon fluorohydride (HArF), a compound of argon with fluorine and hydrogen that is stable below , has been demonstrated. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of argon are trapped in a lattice of water molecules. Ions, such as , and excited-state complexes, such as ArF, have been demonstrated. Theoretical calculation predicts several more argon compounds that should be stable but have not yet been synthesized.\nHistory.\n\"Argon\" (Greek , neuter singular form of meaning \"lazy\" or \"inactive\") is named in reference to its chemical inactivity. This chemical property of this first noble gas to be discovered impressed the namers. An unreactive gas was suspected to be a component of air by Henry Cavendish in 1785.\nArgon was first isolated from air in 1894 by Lord Rayleigh and Sir William Ramsay at University College London by removing oxygen, carbon dioxide, water, and nitrogen from a sample of clean air. They first accomplished this by replicating an experiment of Henry Cavendish's. They trapped a mixture of atmospheric air with additional oxygen in a test-tube (A) upside-down over a large quantity of dilute alkali solution (B), which in Cavendish's original experiment was potassium hydroxide, and conveyed a current through wires insulated by U-shaped glass tubes (CC) which sealed around the platinum wire electrodes, leaving the ends of the wires (DD) exposed to the gas and insulated from the alkali solution. The arc was powered by a battery of five Grove cells and a Ruhmkorff coil of medium size. The alkali absorbed the oxides of nitrogen produced by the arc and also carbon dioxide. They operated the arc until no more reduction of volume of the gas could be seen for at least an hour or two and the spectral lines of nitrogen disappeared when the gas was examined. The remaining oxygen was reacted with alkaline pyrogallate to leave behind an apparently non-reactive gas which they called argon.\nBefore isolating the gas, they had determined that nitrogen produced from chemical compounds was 0.5% lighter than nitrogen from the atmosphere. The difference was slight, but it was important enough to attract their attention for many months. They concluded that there was another gas in the air mixed in with the nitrogen. Argon was also encountered in 1882 through independent research of H. F. Newall and W. N. Hartley. Each observed new lines in the emission spectrum of air that did not match known elements.\nPrior to 1957, the symbol for argon was \"A\". This was changed to Ar after the International Union of Pure and Applied Chemistry published the work \"Nomenclature of Inorganic Chemistry\" in 1957.\nOccurrence.\nArgon constitutes 0.934% by volume and 1.288% by mass of Earth's atmosphere. Air is the primary industrial source of purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon. Earth's crust and seawater contain 1.2 ppm and 0.45 ppm of argon, respectively.\nIsotopes.\nThe main isotopes of argon found on Earth are (99.6%), (0.34%), and (0.06%). Naturally occurring , with a half-life of 1.25 years, decays to stable (11.2%) by electron capture or positron emission, and also to stable (88.8%) by beta decay. These properties and ratios are used to determine the age of rocks by K\u2013Ar dating.\nIn Earth's atmosphere, is made by cosmic ray activity, primarily by neutron capture of followed by two-neutron emission. In the subsurface environment, it is also produced through neutron capture by , followed by proton emission. is created from the neutron capture by followed by an alpha particle emission as a result of subsurface nuclear explosions. It has a half-life of 35 days.\nBetween locations in the Solar System, the isotopic composition of argon varies greatly. Where the major source of argon is the decay of in rocks, will be the dominant isotope, as it is on Earth. Argon produced directly by stellar nucleosynthesis is dominated by the alpha-process nuclide . Correspondingly, solar argon contains 84.6% (according to solar wind measurements), and the ratio of the three isotopes 36Ar\u00a0:\u00a038Ar\u00a0:\u00a040Ar in the atmospheres of the outer planets is 8400\u00a0:\u00a01600\u00a0:\u00a01. This contrasts with the low abundance of primordial in Earth's atmosphere, which is only 31.5 ppmv (= 9340 ppmv \u00d7 0.337%), comparable with that of neon (18.18 ppmv) on Earth and with interplanetary gasses, measured by probes.\nThe atmospheres of Mars, Mercury and Titan (the largest moon of Saturn) contain argon, predominantly as .\nThe predominance of radiogenic is the reason the standard atomic weight of terrestrial argon is greater than that of the next element, potassium, a fact that was puzzling when argon was discovered. Mendeleev positioned the elements on his periodic table in order of atomic weight, but the inertness of argon suggested a placement \"before\" the reactive alkali metal. Henry Moseley later solved this problem by showing that the periodic table is actually arranged in order of atomic number (see History of the periodic table).\nCompounds.\nArgon's complete octet of electrons indicates full s and p subshells. This full valence shell makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. The first argon compound with tungsten pentacarbonyl, W(CO)5Ar, was isolated in 1975. However, it was not widely recognised at that time. In August 2000, another argon compound, argon fluorohydride (HArF), was formed by researchers at the University of Helsinki, by shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride with caesium iodide. This discovery caused the recognition that argon could form weakly bound compounds, even though it was not the first. It is stable up to 17\u00a0kelvins (\u2212256\u00a0\u00b0C). The metastable dication, which is valence-isoelectronic with carbonyl fluoride and phosgene, was observed in 2010. Argon-36, in the form of argon hydride (argonium) ions, has been detected in interstellar medium associated with the Crab Nebula supernova; this was the first noble-gas molecule detected in outer space.\nSolid argon hydride (Ar(H2)2) has the same crystal structure as the MgZn2 Laves phase. It forms at pressures between 4.3 and 220 GPa, though Raman measurements suggest that the H2 molecules in Ar(H2)2 dissociate above 175 GPa.\nProduction.\nArgon is extracted industrially by the fractional distillation of liquid air in a cryogenic air separation unit; a process that separates liquid nitrogen, which boils at 77.3\u00a0K, from argon, which boils at 87.3\u00a0K, and liquid oxygen, which boils at 90.2\u00a0K. About 700,000 tonnes of argon are produced worldwide every year.\nApplications.\nArgon has several desirable properties:\nOther noble gases would be equally suitable for most of these applications, but argon is by far the cheapest. It is inexpensive, since it occurs naturally in air and is readily obtained as a byproduct of cryogenic air separation in the production of liquid oxygen and liquid nitrogen: the primary constituents of air are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far. The bulk of its applications arise simply because it is inert and relatively cheap.\nIndustrial processes.\nArgon is used in some high-temperature industrial processes where ordinarily non-reactive substances become reactive. For example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning.\nFor some of these processes, the presence of nitrogen or oxygen gases might cause defects within the material. Argon is used in some types of arc welding such as gas metal arc welding and gas tungsten arc welding, as well as in the processing of titanium and other reactive elements. An argon atmosphere is also used for growing crystals of silicon and germanium.\nArgon is used in the poultry industry to asphyxiate birds, either for mass culling following disease outbreaks, or as a means of slaughter more humane than electric stunning. Argon is denser than air and displaces oxygen close to the ground during inert gas asphyxiation. Its non-reactive nature makes it suitable in a food product, and since it replaces oxygen within the dead bird, argon also enhances shelf life.\nArgon is sometimes used for extinguishing fires where valuable equipment may be damaged by water or foam.\nScientific research.\nLiquid argon is used as the target for neutrino experiments and direct dark matter searches. The interaction between the hypothetical WIMPs and an argon nucleus produces scintillation light that is detected by photomultiplier tubes. Two-phase detectors containing argon gas are used to detect the ionized electrons produced during the WIMP\u2013nucleus scattering. As with most other liquefied noble gases, argon has a high scintillation light yield (about 51 photons/keV), is transparent to its own scintillation light, and is relatively easy to purify. Compared to xenon, argon is cheaper and has a distinct scintillation time profile, which allows the separation of electronic recoils from nuclear recoils. On the other hand, its intrinsic beta-ray background is larger due to contamination, unless one uses argon from underground sources, which has much less contamination. Most of the argon in Earth's atmosphere was produced by electron capture of long-lived ( + e\u2212 \u2192 + \u03bd) present in natural potassium within Earth. The activity in the atmosphere is maintained by cosmogenic production through the knockout reaction (n,2n) and similar reactions. The half-life of is only 269\u00a0years. As a result, the underground Ar, shielded by rock and water, has much less contamination. Dark-matter detectors currently operating with liquid argon include DarkSide, WArP, ArDM, microCLEAN and DEAP. Neutrino experiments include ICARUS and MicroBooNE, both of which use high-purity liquid argon in a time projection chamber for fine grained three-dimensional imaging of neutrino interactions.\nAt Link\u00f6ping University, Sweden, the inert gas is being utilized in a vacuum chamber in which plasma is introduced to ionize metallic films. This process results in a film usable for manufacturing computer processors. The new process would eliminate the need for chemical baths and use of expensive, dangerous and rare materials.\nPreservative.\nArgon is used to displace oxygen- and moisture-containing air in packaging material to extend the shelf-lives of the contents (argon has the European food additive code E938). Aerial oxidation, hydrolysis, and other chemical reactions that degrade the products are retarded or prevented entirely. High-purity chemicals and pharmaceuticals are sometimes packed and sealed in argon.\nIn winemaking, argon is used in a variety of activities to provide a barrier against oxygen at the liquid surface, which can spoil wine by fueling both microbial metabolism (as with acetic acid bacteria) and standard redox chemistry.\nArgon is sometimes used as the propellant in aerosol cans.\nArgon is also used as a preservative for such products as varnish, polyurethane, and paint, by displacing air to prepare a container for storage.\nSince 2002, the American National Archives stores important national documents such as the Declaration of Independence and the Constitution within argon-filled cases to inhibit their degradation. Argon is preferable to the helium that had been used in the preceding five decades, because helium gas escapes through the intermolecular pores in most containers and must be regularly replaced.\nLaboratory equipment.\nArgon may be used as the inert gas within Schlenk lines and gloveboxes. Argon is preferred to less expensive nitrogen in cases where nitrogen may react with the reagents or apparatus.\nArgon may be used as the carrier gas in gas chromatography and in electrospray ionization mass spectrometry; it is the gas of choice for the plasma used in ICP spectroscopy. Argon is preferred for the sputter coating of specimens for scanning electron microscopy. Argon gas is also commonly used for sputter deposition of thin films as in microelectronics and for wafer cleaning in microfabrication.\nMedical use.\nCryosurgery procedures such as cryoablation use liquid argon to destroy tissue such as cancer cells. It is used in a procedure called \"argon-enhanced coagulation\", a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism and has resulted in the death of at least one patient.\nBlue argon lasers are used in surgery to weld arteries, destroy tumors, and correct eye defects.\nArgon has also been used experimentally to replace nitrogen in the breathing or decompression mix known as Argox, to speed the elimination of dissolved nitrogen from the blood.\nLighting.\nIncandescent lights are filled with argon, to preserve the filaments at high temperature from oxidation. It is used for the specific way it ionizes and emits light, such as in plasma globes and calorimetry in experimental particle physics. Gas-discharge lamps filled with pure argon provide lilac/violet light; with argon and some mercury, blue light. Argon is also used for blue and green argon-ion lasers.\nMiscellaneous uses.\nArgon is used for thermal insulation in energy-efficient windows. Argon is also used in technical scuba diving to inflate a dry suit because it is inert and has low thermal conductivity.\nArgon is used as a propellant in the development of the Variable Specific Impulse Magnetoplasma Rocket (VASIMR). Compressed argon gas is allowed to expand, to cool the seeker heads of some versions of the AIM-9 Sidewinder missile and other missiles that use cooled thermal seeker heads. The gas is stored at high pressure.\nArgon-39, with a half-life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. Also, potassium\u2013argon dating and related argon-argon dating are used to date sedimentary, metamorphic, and igneous rocks.\nArgon has been used by athletes as a doping agent to simulate hypoxic conditions. In 2014, the World Anti-Doping Agency (WADA) added argon and xenon to the list of prohibited substances and methods, although at this time there is no reliable test for abuse.\nSafety.\nAlthough argon is non-toxic, it is 38% more dense than air and therefore considered a dangerous asphyxiant in closed areas. It is difficult to detect because it is colorless, odorless, and tasteless. A 1994 incident, in which a man was asphyxiated after entering an argon-filled section of oil pipe under construction in Alaska, highlights the dangers of argon tank leakage in confined spaces and emphasizes the need for proper use, storage and handling."}
{"id": "897", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=897", "title": "Arsenic", "text": "Arsenic is a chemical element with the symbol As and the atomic number 33. It is a metalloid and one of the pnictogens, and therefore shares many properties with its group 15 neighbors phosphorus and antimony. Arsenic is a notoriously toxic heavy metal. It occurs naturally in many minerals, usually in combination with sulfur and metals, but also as a pure elemental crystal. It has various allotropes, but only the grey form, which has a metallic appearance, is important to industry.\nThe primary use of arsenic is in alloys of lead (for example, in car batteries and ammunition). Arsenic is also a common n-type dopant in semiconductor electronic devices, and a component of the III\u2013V compound semiconductor gallium arsenide. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining with the increasing recognition of the toxicity of arsenic and its compounds.\nArsenic has been known since ancient times to be poisonous to humans. However, a few species of bacteria are able to use arsenic compounds as respiratory metabolites. Trace quantities of arsenic have been proposed to be an essential dietary element in rats, hamsters, goats, and chickens. Research has not been conducted to determine whether small amounts of arsenic may play a role in human metabolism. However, arsenic poisoning occurs in multicellular life if quantities are larger than needed. Arsenic contamination of groundwater is a problem that affects millions of people across the world.\nThe United States' Environmental Protection Agency states that all forms of arsenic are a serious risk to human health. The United States' Agency for Toxic Substances and Disease Registry ranked arsenic number 1 in its 2001 prioritized list of hazardous substances at Superfund sites. Arsenic is classified as a Group-A carcinogen.\nCharacteristics.\nPhysical characteristics.\nThe three most common arsenic allotropes are grey, yellow, and black arsenic, with grey being the most common. Grey arsenic (\u03b1-As, space group Rm No. 166) adopts a double-layered structure consisting of many interlocked, ruffled, six-membered rings. Because of weak bonding between the layers, grey arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73\u00a0g/cm3. Grey arsenic is a semimetal, but becomes a semiconductor with a bandgap of 1.2\u20131.4\u00a0eV if amorphized. Grey arsenic is also the most stable form.\nYellow arsenic is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense, and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor, . It is rapidly transformed into grey arsenic by light. The yellow form has a density of 1.97\u00a0g/cm3. Black arsenic is similar in structure to black phosphorus.\nBlack arsenic can also be formed by cooling vapor at around 100\u2013220\u00a0\u00b0C and by crystallization of amorphous arsenic in the presence of mercury vapors. It is glassy and brittle. Black arsenic is also a poor electrical conductor.\nArsenic sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state at . The triple point is at 3.63\u00a0MPa and .\nIsotopes.\nArsenic occurs in nature as one stable isotope, 75As, and is therefore called a monoisotopic element. As of 2024, at least 32 radioisotopes have also been synthesized, ranging in atomic mass from 64 to 95. The most stable of these is 73As with a half-life of 80.30\u00a0days. All other isotopes have half-lives of under one day, with the exception of 71As (\"t\"1/2=65.30 hours), 72As (\"t\"1/2=26.0 hours), 74As (\"t\"1/2=17.77 days), 76As (\"t\"1/2=26.26 hours), and 77As (\"t\"1/2=38.83 hours). Isotopes that are lighter than the stable 75As tend to decay by \u03b2+ decay, and those that are heavier tend to decay by \u03b2\u2212 decay, with some exceptions.\nAt least 10 nuclear isomers have been described, ranging in atomic mass from 66 to 84. The most stable of arsenic's isomers is 68mAs with a half-life of 111\u00a0seconds.\nChemistry.\nArsenic has a similar electronegativity and ionization energies to its lighter pnictogen congener phosphorus and therefore readily forms covalent molecules with most of the nonmetals. Though stable in dry air, arsenic forms a golden-bronze tarnish upon exposure to humidity which eventually becomes a black surface layer. When heated in air, arsenic oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. It burns in oxygen to form arsenic trioxide and arsenic pentoxide, which have the same structure as the more well-known phosphorus compounds, and in fluorine to give arsenic pentafluoride. Arsenic makes arsenic acid with concentrated nitric acid, arsenous acid with dilute nitric acid, and arsenic trioxide with concentrated sulfuric acid; however, it does not react with water, alkalis, or non-oxidising acids. Arsenic reacts with metals to form arsenides, though these are not ionic compounds containing the As3\u2212 ion as the formation of such an anion would be highly endothermic and even the group 1 arsenides have properties of intermetallic compounds. Like germanium, selenium, and bromine, which like arsenic succeed the 3d transition series, arsenic is much less stable in the +5 oxidation state than its vertical neighbors phosphorus and antimony, and hence arsenic pentoxide and arsenic acid are potent oxidizers.\nCompounds.\nCompounds of arsenic resemble, in some respects, those of phosphorus, which occupies the same group (column) of the periodic table. The most common oxidation states for arsenic are: \u22123 in the arsenides, which are alloy-like intermetallic compounds, +3 in the arsenites, and +5 in the arsenates and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal owing to the influence of the lone pair of electrons.\nInorganic compounds.\nOne of the simplest arsenic compounds is the trihydride, the highly toxic, flammable, pyrophoric arsine (AsH3). This compound is generally regarded as stable, since at room temperature it decomposes only slowly. At temperatures of 250\u2013300\u00a0\u00b0C decomposition to arsenic and hydrogen is rapid. Several factors, such as humidity, presence of light and certain catalysts (namely aluminium) facilitate the rate of decomposition. It oxidises readily in air to form arsenic trioxide and water, and analogous reactions take place with sulfur and selenium instead of oxygen.\nArsenic forms colorless, odorless, crystalline oxides As2O3 (\"white arsenic\") and As2O5 which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid and its salts, known as arsenates, are a major source of arsenic contamination of groundwater in regions with high levels of naturally-occurring arsenic minerals. Synthetic arsenates include Scheele's Green (cupric hydrogen arsenate, acidic copper arsenate), calcium arsenate, and lead hydrogen arsenate. These three have been used as agricultural insecticides and poisons.\nThe protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorous acid, arsenous acid is genuinely tribasic, with the formula As(OH)3.\nA broad variety of sulfur compounds of arsenic are known. Orpiment (As2S3) and realgar (As4S4) are somewhat abundant and were formerly used as painting pigments. In As4S10, arsenic has a formal oxidation state of +2 in As4S4 which features As-As bonds so that the total covalency of As is still 3. Both orpiment and realgar, as well as As4S3, have selenium analogs; the analogous As2Te3 is known as the mineral kalgoorlieite, and the anion As2Te\u2212 is known as a ligand in cobalt complexes.\nAll trihalides of arsenic(III) are well known except the astatide, which is unknown. Arsenic pentafluoride (AsF5) is the only important pentahalide, reflecting the lower stability of the +5 oxidation state; even so, it is a very strong fluorinating and oxidizing agent. (The pentachloride is stable only below \u221250\u00a0\u00b0C, at which temperature it decomposes to the trichloride, releasing chlorine gas.)\nAlloys.\nArsenic is used as the group 5 element in the III-V semiconductors gallium arsenide, indium arsenide, and aluminium arsenide. The valence electron count of GaAs is the same as a pair of Si atoms, but the band structure is completely different which results in distinct bulk properties. Other arsenic alloys include the II-V semiconductor cadmium arsenide.\nOrganoarsenic compounds.\nA large variety of organoarsenic compounds are known. Several were developed as chemical warfare agents during World War I, including vesicants such as lewisite and vomiting agents such as adamsite. Cacodylic acid, which is of historic and practical interest, arises from the methylation of arsenic trioxide, a reaction that has no analogy in phosphorus chemistry. Cacodyl was the first organometallic compound known (even though arsenic is not a true metal) and was named from the Greek \"\u03ba\u03b1\u03ba\u03c9\u03b4\u03af\u03b1\" \"stink\" for its offensive, garlic-like odor; it is very toxic.\nOccurrence and production.\nArsenic is the 53rd most abundant element in the Earth's crust, comprising about 1.5\u00a0parts per million\u00a0(0.00015%). Typical background concentrations of arsenic do not exceed 3\u00a0ng/m3 in the atmosphere; 100\u00a0mg/kg in soil; 400\u00a0\u03bcg/kg in vegetation; 10\u00a0\u03bcg/L in freshwater and 1.5\u00a0\u03bcg/L in seawater. Arsenic is the 22nd most abundant element in seawater and ranks 41st in abundance in the universe.\nMinerals with the formula MAsS and MAs2 (M = Fe, Ni, Co) are the dominant commercial sources of arsenic, together with realgar (an arsenic sulfide mineral) and native (elemental) arsenic. An illustrative mineral is arsenopyrite (FeAsS), which is structurally related to iron pyrite. Many minor As-containing minerals are known. Arsenic also occurs in various organic forms in the environment.\nIn 2014, China was the top producer of white arsenic with almost 70% world share, followed by Morocco, Russia, and Belgium, according to the British Geological Survey and the United States Geological Survey. Most arsenic refinement operations in the US and Europe have closed over environmental concerns. Arsenic is found in the smelter dust from copper, gold, and lead smelters, and is recovered primarily from copper refinement dust.\nOn roasting arsenopyrite in air, arsenic sublimes as arsenic(III) oxide leaving iron oxides, while roasting without air results in the production of gray arsenic. Further purification from sulfur and other chalcogens is achieved by sublimation in vacuum, in a hydrogen atmosphere, or by distillation from molten lead-arsenic mixture.\nHistory.\nThe word \"arsenic\" has its origin in the Syriac word \"zarnika\", from Arabic al-zarn\u012b\u1e35 'the orpiment', based on Persian zar (\"gold\") from the word \"zarnikh\", meaning \"yellow\" (literally \"gold-colored\") and hence \"(yellow) orpiment\". It was adopted into Greek (using folk etymology) as \"arsenikon\" () \u2013 a neuter form of the Greek adjective \"arsenikos\" (), meaning \"male\", \"virile\".\nLatin-speakers adopted the Greek term as , which in French ultimately became , whence the English word \"arsenic\".\nArsenic sulfides (orpiment, realgar) and oxides have been known and used since ancient times. Zosimos () describes roasting \"sandarach\" (realgar) to obtain \"cloud of arsenic\" (arsenic trioxide), which he then reduces to gray arsenic. As the symptoms of arsenic poisoning are not very specific, the substance was frequently used for murder until the advent in the 1830s of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Owing to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the \"poison of kings\" and the \"king of poisons\". Arsenic became known as \"the inheritance powder\" due to its use in killing family members in the Renaissance era.\nDuring the Bronze Age, arsenic was melted with copper to make arsenical bronze.\nJabir ibn Hayyan described the isolation of arsenic before 815 AD. Albertus Magnus (Albert the Great, 1193\u20131280) later isolated the element from a compound in 1250, by heating soap together with arsenic trisulfide. In 1649, Johann Schr\u00f6der published two ways of preparing arsenic. Crystals of elemental (native) arsenic are found in nature, although rarely.\nCadet's fuming liquid (impure cacodyl), often claimed as the first synthetic organometallic compound, was synthesized in 1760 by Louis Claude Cadet de Gassicourt through the reaction of potassium acetate with arsenic trioxide.\nIn the Victorian era, women would eat \"arsenic\" (\"white arsenic\" or arsenic trioxide) mixed with vinegar and chalk to improve the complexion of their faces, making their skin paler (to show they did not work in the fields). The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in 21 deaths. From the late-18th century wallpaper production began to use dyes made from arsenic,\nwhich was thought to increase the pigment's brightness. One account of the illness and 1821 death of Napoleon I implicates arsenic poisoning involving wallpaper.\nTwo arsenic pigments have been widely used since their discovery \u2013 Paris Green in 1814 and Scheele's Green in 1775. After the toxicity of arsenic became widely known, these chemicals were used less often as pigments and more often as insecticides. In the 1860s, an arsenic byproduct of dye production, London Purple, was widely used. This was a solid mixture of arsenic trioxide, aniline, lime, and ferrous oxide, insoluble in water and very toxic by inhalation or ingestion But it was later replaced with Paris Green, another arsenic-based dye. With better understanding of the toxicology mechanism, two other compounds were used starting in the 1890s. Arsenite of lime and arsenate of lead were used widely as insecticides until the discovery of DDT in 1942.\nIn small doses, soluble arsenic compounds act as stimulants, and were once popular as medicine by people in the mid-18th to 19th centuries; this use was especially prevalent for sport animals such as race horses or work dogs and continued into the 20th century.\nA 2006 study of the remains of the Australian racehorse Phar Lap determined that its 1932 death was caused by a massive overdose of arsenic. Sydney veterinarian Percy Sykes stated, \"In those days, arsenic was quite a common tonic, usually given in the form of a solution (Fowler's Solution) ... It was so common that I'd reckon 90 per cent of the horses had arsenic in their system.\"\nApplications.\nAgricultural.\nThe toxicity of arsenic to insects, bacteria, and fungi led to its use as a wood preservative. In the 1930s, a process of treating wood with chromated copper arsenate (also known as CCA or Tanalith) was invented, and for decades, this treatment was the most extensive industrial use of arsenic. An increased appreciation of the toxicity of arsenic led to a ban of CCA in consumer products in 2004, initiated by the European Union and United States. However, CCA remains in heavy use in other countries (such as on Malaysian rubber plantations).\nArsenic was also used in various agricultural insecticides and poisons. For example, lead hydrogen arsenate was a common insecticide on fruit trees, but contact with the compound sometimes resulted in brain damage among those working the sprayers. In the second half of the 20th century, monosodium methyl arsenate (MSMA) and disodium methyl arsenate (DSMA) \u2013 less toxic organic forms of arsenic \u2013 replaced lead arsenate in agriculture. These organic arsenicals were in turn phased out in the United States by 2013 in all agricultural activities except cotton farming.\nThe biogeochemistry of arsenic is complex and includes various adsorption and desorption processes. The toxicity of arsenic is connected to its solubility and is affected by pH. Arsenite () is more soluble than arsenate () and is more toxic; however, at a lower pH, arsenate becomes more mobile and toxic. It was found that addition of sulfur, phosphorus, and iron oxides to high-arsenite soils greatly reduces arsenic phytotoxicity.\nArsenic is used as a feed additive in poultry and swine production, in particular it was used in the U.S. until 2015 to increase weight gain, improve feed efficiency, and prevent disease. An example is roxarsone, which had been used as a broiler starter by about 70% of U.S. broiler growers. In 2011, Alpharma, a subsidiary of Pfizer Inc., which produces roxarsone, voluntarily suspended sales of the drug in response to studies showing elevated levels of inorganic arsenic, a carcinogen, in treated chickens. A successor to Alpharma, Zoetis, continued to sell nitarsone until 2015, primarily for use in turkeys.\nMedical use.\nDuring the 17th, 18th, and 19th centuries, a number of arsenic compounds were used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler), for treating diseases such as cancer or psoriasis. Arsphenamine, as well as neosalvarsan, was indicated for syphilis, but has been superseded by modern antibiotics. However, arsenicals such as melarsoprol are still used for the treatment of trypanosomiasis in spite of their severe toxicity, since the disease is almost uniformly fatal if untreated. In 2000 the US Food and Drug Administration approved arsenic trioxide for the treatment of patients with acute promyelocytic leukemia that is resistant to all-trans retinoic acid.\nA 2008 paper reports success in locating tumors using arsenic-74 (a positron emitter). This isotope produces clearer PET scan images than the previous radioactive agent, iodine-124, because the body tends to transport iodine to the thyroid gland producing signal noise. Nanoparticles of arsenic have shown ability to kill cancer cells with lesser cytotoxicity than other arsenic formulations.\nAlloys.\nThe main use of arsenic is in alloying with lead. Lead components in car batteries are strengthened by the presence of a very small percentage of arsenic. Dezincification of brass (a copper-zinc alloy) is greatly reduced by the addition of arsenic. \"Phosphorus Deoxidized Arsenical Copper\" with an arsenic content of 0.3% has an increased corrosion stability in certain environments. Gallium arsenide is an important semiconductor material, used in integrated circuits. Circuits made from GaAs are much faster (but also much more expensive) than those made from silicon. Unlike silicon, GaAs has a direct bandgap, and can be used in laser diodes and LEDs to convert electrical energy directly into light.\nMilitary.\nAfter World War I, the United States built a stockpile of 20,000 tons of weaponized lewisite (ClCH=CHAsCl2), an organoarsenic vesicant (blister agent) and lung irritant. The stockpile was neutralized with bleach and dumped into the Gulf of Mexico in the 1950s. During the Vietnam War, the United States used Agent Blue, a mixture of sodium cacodylate and its acid form, as one of the rainbow herbicides to deprive North Vietnamese soldiers of foliage cover and rice.\nBiological role.\nBacteria.\nSome species of bacteria obtain their energy in the absence of oxygen by oxidizing various fuels while reducing arsenate to arsenite. Under oxidative environmental conditions some bacteria use arsenite as fuel, which they oxidize to arsenate. The enzymes involved are known as arsenate reductases (Arr).\nIn 2008, bacteria were discovered that employ a version of photosynthesis in the absence of oxygen with arsenites as electron donors, producing arsenates (just as ordinary photosynthesis uses water as electron donor, producing molecular oxygen). Researchers conjecture that, over the course of history, these photosynthesizing organisms produced the arsenates that allowed the arsenate-reducing bacteria to thrive. One strain, PHS-1, has been isolated and is related to the gammaproteobacterium \"Ectothiorhodospira shaposhnikovii\". The mechanism is unknown, but an encoded Arr enzyme may function in reverse to its known homologues.\nIn 2011, it was postulated that the \"Halomonadaceae\" strain GFAJ-1 could be grown in the absence of phosphorus if that element were substituted with arsenic, exploiting the fact that the arsenate and phosphate anions are similar structurally. The study was widely criticised and subsequently refuted by independent researcher groups.\nPotential role in higher animals.\nArsenic may be an essential trace mineral in birds, involved in the synthesis of methionine metabolites. However, the role of arsenic in bird nutrition is disputed, as other authors state that arsenic is toxic in small amounts.\nSome evidence indicates that arsenic is an essential trace mineral in mammals.\nHeredity.\nArsenic has been linked to epigenetic changes, heritable changes in gene expression that occur without changes in DNA sequence. These include DNA methylation, histone modification, and RNA interference. Toxic levels of arsenic cause significant DNA hypermethylation of tumor suppressor genes p16 and p53, thus increasing risk of carcinogenesis. These epigenetic events have been studied \"in vitro\" using human kidney cells and \"in vivo\" using rat liver cells and peripheral blood leukocytes in humans. Inductively coupled plasma mass spectrometry (ICP-MS) is used to detect precise levels of intracellular arsenic and other arsenic bases involved in epigenetic modification of DNA. Studies investigating arsenic as an epigenetic factor can be used to develop precise biomarkers of exposure and susceptibility.\nThe Chinese brake fern (\"Pteris vittata\") hyperaccumulates arsenic from the soil into its leaves and has a proposed use in phytoremediation.\nBiomethylation.\nInorganic arsenic and its compounds, upon entering the food chain, are progressively metabolized through a process of methylation. For example, the mold \"Scopulariopsis brevicaulis\" produces trimethylarsine if inorganic arsenic is present. The organic compound arsenobetaine is found in some marine foods such as fish and algae, and also in mushrooms in larger concentrations. The average person's intake is about 10\u201350\u00a0\u03bcg/day. Values about 1000\u00a0\u03bcg are not unusual following consumption of fish or mushrooms, but there is little danger in eating fish because this arsenic compound is nearly non-toxic.\nEnvironmental issues.\nExposure.\nNaturally occurring sources of human exposure include volcanic ash, weathering of minerals and ores, and mineralized groundwater. Arsenic is also found in food, water, soil, and air. Arsenic is absorbed by all plants, but is more concentrated in leafy vegetables, rice, apple and grape juice, and seafood. An additional route of exposure is inhalation of atmospheric gases and dusts.\nDuring the Victorian era, arsenic was widely used in home decor, especially wallpapers. In Europe, an analysis based on 20,000 soil samples across all 28 countries show that 98% of sampled soils have concentrations less than 20 mg kg-1. In addition, the As hotspots are related to frequent fertilization and close distance to mining activities.\nOccurrence in drinking water.\nExtensive arsenic contamination of groundwater has led to widespread arsenic poisoning in Bangladesh and neighboring countries. It is estimated that approximately 57\u00a0million people in the Bengal basin are drinking groundwater with arsenic concentrations elevated above the World Health Organization's standard of 10 parts per billion (ppb). However, a study of cancer rates in Taiwan suggested that significant increases in cancer mortality appear only at levels above 150\u00a0ppb. The arsenic in the groundwater is of natural origin, and is released from the sediment into the groundwater, caused by the anoxic conditions of the subsurface. This groundwater was used after local and western NGOs and the Bangladeshi government undertook a massive shallow tube well drinking-water program in the late twentieth century. This program was designed to prevent drinking of bacteria-contaminated surface waters, but failed to test for arsenic in the groundwater. Many other countries and districts in Southeast Asia, such as Vietnam and Cambodia, have geological environments that produce groundwater with a high arsenic content. was reported in Nakhon Si Thammarat, Thailand, in 1987, and the Chao Phraya River probably contains high levels of naturally occurring dissolved arsenic without being a public health problem because much of the public uses bottled water. In Pakistan, more than 60\u00a0million people are exposed to arsenic polluted drinking water indicated by a 2017 report in \"Science\". Podgorski's team investigated more than 1200 samples and more than 66% exceeded the WHO minimum contamination level.\nSince the 1980s, residents of the Ba Men region of Inner Mongolia, China have been chronically exposed to arsenic through drinking water from contaminated wells. A 2009 research study observed an elevated presence of skin lesions among residents with well water arsenic concentrations between 5 and 10\u00a0\u03bcg/L, suggesting that arsenic induced toxicity may occur at relatively low concentrations with chronic exposure. Overall, 20 of China's 34 provinces have high arsenic concentrations in the groundwater supply, potentially exposing 19\u00a0million people to hazardous drinking water.\nA study by IIT Kharagpur found high levels of Arsenic in groundwater of 20% of India's land, exposing more than 250\u00a0million people. States such as Punjab, Bihar, West Bengal, Assam, Haryana, Uttar Pradesh, and Gujarat have highest land area exposed to arsenic.\nIn the United States, arsenic is most commonly found in the ground waters of the southwest. Parts of New England, Michigan, Wisconsin, Minnesota and the Dakotas are also known to have significant concentrations of arsenic in ground water. Increased levels of skin cancer have been associated with arsenic exposure in Wisconsin, even at levels below the 10\u00a0ppb drinking water standard. According to a recent film funded by the US Superfund, millions of private wells have unknown arsenic levels, and in some areas of the US, more than 20% of the wells may contain levels that exceed established limits.\nLow-level exposure to arsenic at concentrations of 100\u00a0ppb (i.e., above the 10\u00a0ppb drinking water standard) compromises the initial immune response to H1N1 or swine flu infection according to NIEHS-supported scientists. The study, conducted in laboratory mice, suggests that people exposed to arsenic in their drinking water may be at increased risk for more serious illness or death from the virus.\nSome Canadians are drinking water that contains inorganic arsenic. Private-dug\u2013well waters are most at risk for containing inorganic arsenic. Preliminary well water analysis typically does not test for arsenic. Researchers at the Geological Survey of Canada have modeled relative variation in natural arsenic hazard potential for the province of New Brunswick. This study has important implications for potable water and health concerns relating to inorganic arsenic.\nEpidemiological evidence from Chile shows a dose-dependent connection between chronic arsenic exposure and various forms of cancer, in particular when other risk factors, such as cigarette smoking, are present. These effects have been demonstrated at contaminations less than 50\u00a0ppb. Arsenic is itself a constituent of tobacco smoke.\nAnalyzing multiple epidemiological studies on inorganic arsenic exposure suggests a small but measurable increase in risk for bladder cancer at 10\u00a0ppb. According to Peter Ravenscroft of the Department of Geography at the University of Cambridge, roughly 80\u00a0million people worldwide consume between 10 and 50\u00a0ppb arsenic in their drinking water. If they all consumed exactly 10\u00a0ppb arsenic in their drinking water, the previously cited multiple epidemiological study analysis would predict an additional 2,000 cases of bladder cancer alone. This represents a clear underestimate of the overall impact, since it does not include lung or skin cancer, and explicitly underestimates the exposure. Those exposed to levels of arsenic above the current WHO standard should weigh the costs and benefits of arsenic remediation.\nEarly (1973) evaluations of the processes for removing dissolved arsenic from drinking water demonstrated the efficacy of co-precipitation with either iron or aluminium oxides. In particular, iron as a coagulant was found to remove arsenic with an efficacy exceeding 90%. Several adsorptive media systems have been approved for use at point-of-service in a study funded by the United States Environmental Protection Agency (US EPA) and the National Science Foundation (NSF). A team of European and Indian scientists and engineers have set up six arsenic treatment plants in West Bengal based on in-situ remediation method (SAR Technology). This technology does not use any chemicals and arsenic is left in an insoluble form (+5 state) in the subterranean zone by recharging aerated water into the aquifer and developing an oxidation zone that supports arsenic oxidizing micro-organisms. This process does not produce any waste stream or sludge and is relatively cheap.\nAnother effective and inexpensive method to avoid arsenic contamination is to sink wells 500\u00a0feet or deeper to reach purer waters. A recent 2011 study funded by the US National Institute of Environmental Health Sciences' Superfund Research Program shows that deep sediments can remove arsenic and take it out of circulation. In this process, called \"adsorption\", arsenic sticks to the surfaces of deep sediment particles and is naturally removed from the ground water.\nMagnetic separations of arsenic at very low magnetic field gradients with high-surface-area and monodisperse magnetite (Fe3O4) nanocrystals have been demonstrated in point-of-use water purification. Using the high specific surface area of Fe3O4 nanocrystals, the mass of waste associated with arsenic removal from water has been dramatically reduced.\nEpidemiological studies have suggested a correlation between chronic consumption of drinking water contaminated with arsenic and the incidence of all leading causes of mortality. The literature indicates that arsenic exposure is causative in the pathogenesis of diabetes.\nChaff-based filters have recently been shown to reduce the arsenic content of water to 3\u00a0\u03bcg/L. This may find applications in areas where the potable water is extracted from underground aquifers.\nSan Pedro de Atacama.\nFor several centuries, the people of San Pedro de Atacama in Chile have been drinking water that is contaminated with arsenic, and some evidence suggests they have developed some immunity.\nHazard maps for contaminated groundwater.\nAround one-third of the world's population drinks water from groundwater resources. Of this, about 10 percent, approximately 300\u00a0million people, obtains water from groundwater resources that are contaminated with unhealthy levels of arsenic or fluoride. These trace elements derive mainly from minerals and ions in the ground.\nRedox transformation of arsenic in natural waters.\nArsenic is unique among the trace metalloids and oxyanion-forming trace metals (e.g. As, Se, Sb, Mo, V, Cr, U, Re). It is sensitive to mobilization at pH values typical of natural waters (pH 6.5\u20138.5) under both oxidizing and reducing conditions. Arsenic can occur in the environment in several oxidation states (\u22123, 0, +3 and +5), but in natural waters it is mostly found in inorganic forms as oxyanions of trivalent arsenite [As(III)] or pentavalent arsenate [As(V)]. Organic forms of arsenic are produced by biological activity, mostly in surface waters, but are rarely quantitatively important. Organic arsenic compounds may, however, occur where waters are significantly impacted by industrial pollution.\nArsenic may be solubilized by various processes. When pH is high, arsenic may be released from surface binding sites that lose their positive charge. When water level drops and sulfide minerals are exposed to air, arsenic trapped in sulfide minerals can be released into water. When organic carbon is present in water, bacteria are fed by directly reducing As(V) to As(III) or by reducing the element at the binding site, releasing inorganic arsenic.\nThe aquatic transformations of arsenic are affected by pH, reduction-oxidation potential, organic matter concentration and the concentrations and forms of other elements, especially iron and manganese. The main factors are pH and the redox potential. Generally, the main forms of arsenic under oxic conditions are , , , and at pH 2, 2\u20137, 7\u201311 and 11, respectively. Under reducing conditions, is predominant at pH 2\u20139.\nOxidation and reduction affects the migration of arsenic in subsurface environments. Arsenite is the most stable soluble form of arsenic in reducing environments and arsenate, which is less mobile than arsenite, is dominant in oxidizing environments at neutral pH. Therefore, arsenic may be more mobile under reducing conditions. The reducing environment is also rich in organic matter which may enhance the solubility of arsenic compounds. As a result, the adsorption of arsenic is reduced and dissolved arsenic accumulates in groundwater. That is why the arsenic content is higher in reducing environments than in oxidizing environments.\nThe presence of sulfur is another factor that affects the transformation of arsenic in natural water. Arsenic can precipitate when metal sulfides form. In this way, arsenic is removed from the water and its mobility decreases. When oxygen is present, bacteria oxidize reduced sulfur to generate energy, potentially releasing bound arsenic.\nRedox reactions involving Fe also appear to be essential factors in the fate of arsenic in aquatic systems. The reduction of iron oxyhydroxides plays a key role in the release of arsenic to water. So arsenic can be enriched in water with elevated Fe concentrations. Under oxidizing conditions, arsenic can be mobilized from pyrite or iron oxides especially at elevated pH. Under reducing conditions, arsenic can be mobilized by reductive desorption or dissolution when associated with iron oxides. The reductive desorption occurs under two circumstances. One is when arsenate is reduced to arsenite which adsorbs to iron oxides less strongly. The other results from a change in the charge on the mineral surface which leads to the desorption of bound arsenic.\nSome species of bacteria catalyze redox transformations of arsenic. Dissimilatory arsenate-respiring prokaryotes (DARP) speed up the reduction of As(V) to As(III). DARP use As(V) as the electron acceptor of anaerobic respiration and obtain energy to survive. Other organic and inorganic substances can be oxidized in this process. Chemoautotrophic arsenite oxidizers (CAO) and heterotrophic arsenite oxidizers (HAO) convert As(III) into As(V). CAO combine the oxidation of As(III) with the reduction of oxygen or nitrate. They use obtained energy to fix produce organic carbon from CO2. HAO cannot obtain energy from As(III) oxidation. This process may be an arsenic detoxification mechanism for the bacteria.\nEquilibrium thermodynamic calculations predict that As(V) concentrations should be greater than As(III) concentrations in all but strongly reducing conditions, i.e. where sulfate reduction is occurring. However, abiotic redox reactions of arsenic are slow. Oxidation of As(III) by dissolved O2 is a particularly slow reaction. For example, Johnson and Pilson (1975) gave half-lives for the oxygenation of As(III) in seawater ranging from several months to a year. In other studies, As(V)/As(III) ratios were stable over periods of days or weeks during water sampling when no particular care was taken to prevent oxidation, again suggesting relatively slow oxidation rates. Cherry found from experimental studies that the As(V)/As(III) ratios were stable in anoxic solutions for up to 3 weeks but that gradual changes occurred over longer timescales. Sterile water samples have been observed to be less susceptible to speciation changes than non-sterile samples. Oremland found that the reduction of As(V) to As(III) in Mono Lake was rapidly catalyzed by bacteria with rate constants ranging from 0.02 to 0.3-day\u22121.\nWood preservation in the US.\nAs of 2002, US-based industries consumed 19,600 metric tons of arsenic. Ninety percent of this was used for treatment of wood with chromated copper arsenate (CCA). In 2007, 50% of the 5,280 metric tons of consumption was still used for this purpose. In the United States, the voluntary phasing-out of arsenic in production of consumer products and residential and general consumer construction products began on 31 December 2003, and alternative chemicals are now used, such as Alkaline Copper Quaternary, borates, copper azole, cyproconazole, and propiconazole.\nAlthough discontinued, this application is also one of the most concerning to the general public. The vast majority of older pressure-treated wood was treated with CCA. CCA lumber is still in widespread use in many countries, and was heavily used during the latter half of the 20th century as a structural and outdoor building material. Although the use of CCA lumber was banned in many areas after studies showed that arsenic could leach out of the wood into the surrounding soil (from playground equipment, for instance), a risk is also presented by the burning of older CCA timber. The direct or indirect ingestion of wood ash from burnt CCA lumber has caused fatalities in animals and serious poisonings in humans; the lethal human dose is approximately 20\u00a0grams of ash. Scrap CCA lumber from construction and demolition sites may be inadvertently used in commercial and domestic fires. Protocols for safe disposal of CCA lumber are not consistent throughout the world. Widespread landfill disposal of such timber raises some concern, but other studies have shown no arsenic contamination in the groundwater.\nMapping of industrial releases in the US.\nOne tool that maps the location (and other information) of arsenic releases in the United States is TOXMAP. TOXMAP is a Geographic Information System (GIS) from the Division of Specialized Information Services of the United States National Library of Medicine (NLM) funded by the US Federal Government. With marked-up maps of the United States, TOXMAP enables users to visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs. TOXMAP's chemical and environmental health information is taken from NLM's Toxicology Data Network (TOXNET), PubMed, and from other authoritative sources.\nBioremediation.\nPhysical, chemical, and biological methods have been used to remediate arsenic contaminated water. Bioremediation is said to be cost-effective and environmentally friendly. Bioremediation of ground water contaminated with arsenic aims to convert arsenite, the toxic form of arsenic to humans, to arsenate. Arsenate (+5 oxidation state) is the dominant form of arsenic in surface water, while arsenite (+3 oxidation state) is the dominant form in hypoxic to anoxic environments. Arsenite is more soluble and mobile than arsenate. Many species of bacteria can transform arsenite to arsenate in anoxic conditions by using arsenite as an electron donor. This is a useful method in ground water remediation. Another bioremediation strategy is to use plants that accumulate arsenic in their tissues via phytoremediation but the disposal of contaminated plant material needs to be considered.\nBioremediation requires careful evaluation and design in accordance with existing conditions. Some sites may require the addition of an electron acceptor while others require microbe supplementation (bioaugmentation). Regardless of the method used, only constant monitoring can prevent future contamination.\nArsenic removal.\nCoagulation and flocculation are closely related processes common in arsenate removal from water. Due to the net negative charge carried by arsenate ions, they settle slowly or not at all due to charge repulsion. In coagulation, a positively charged coagulent such as iron and aluminum (commonly used salts: FeCl3, Fe2(SO4)3, Al2(SO4)3) neutralize the negatively charged arsenate, enable it to settle. Flocculation follows where a flocculant bridges smaller particles and allows the aggregate to precipitate out from water. However, such methods may not be efficient on arsenite as As(III) exists in uncharged arsenious acid, H3AsO3, at near-neutral pH.\nThe major drawbacks of coagulation and flocculation are the costly disposal of arsenate-concentrated sludge, and possible secondary contamination of environment. Moreover, coagulents such as iron may produce ion contamination that exceeds safety levels.\nToxicity and precautions.\nArsenic and many of its compounds are especially potent poisons (e.g. arsine). Small amount of arsenic can be detected by pharmacopoial methods which includes reduction of arsenic to arsenious with help of zinc and can be confirmed with mercuric chloride paper.\nClassification.\nElemental arsenic and arsenic sulfate and trioxide compounds are classified as \"toxic\" and \"dangerous for the environment\" in the European Union under directive 67/548/EEC.\nThe International Agency for Research on Cancer (IARC) recognizes arsenic and inorganic arsenic compounds as group 1 carcinogens, and the EU lists arsenic trioxide, arsenic pentoxide, and arsenate salts as category 1 carcinogens.\nArsenic is known to cause arsenicosis when present in drinking water, \"the most common species being arsenate [; As(V)] and arsenite [; As(III)]\".\nLegal limits, food, and drink.\nIn the United States since 2006, the maximum concentration in drinking water allowed by the Environmental Protection Agency (EPA) is 10\u00a0ppb and the FDA set the same standard in 2005 for bottled water. The Department of Environmental Protection for New Jersey set a drinking water limit of 5\u00a0ppb in 2006. The IDLH (immediately dangerous to life and health) value for arsenic metal and inorganic arsenic compounds is 5\u00a0mg/m3 (5\u00a0ppb). The Occupational Safety and Health Administration has set the permissible exposure limit (PEL) to a time-weighted average (TWA) of 0.01\u00a0mg/m3 (0.01\u00a0ppb), and the National Institute for Occupational Safety and Health (NIOSH) has set the recommended exposure limit (REL) to a 15-minute constant exposure of 0.002\u00a0mg/m3 (0.002\u00a0ppb). The PEL for organic arsenic compounds is a TWA of 0.5\u00a0mg/m3. (0.5\u00a0ppb).\nIn 2008, based on its ongoing testing of a wide variety of American foods for toxic chemicals, the U.S. Food and Drug Administration set the \"level of concern\" for inorganic arsenic in apple and pear juices at 23\u00a0ppb, based on non-carcinogenic effects, and began blocking importation of products in excess of this level; it also required recalls for non-conforming domestic products. In 2011, the national \"Dr. Oz\" television show broadcast a program highlighting tests performed by an independent lab hired by the producers. Though the methodology was disputed (it did not distinguish between organic and inorganic arsenic) the tests showed levels of arsenic up to 36\u00a0ppb. In response, the FDA tested the worst brand from the \"Dr.\" \"Oz\" show and found much lower levels. Ongoing testing found 95% of the apple juice samples were below the level of concern. Later testing by Consumer Reports showed inorganic arsenic at levels slightly above 10\u00a0ppb, and the organization urged parents to reduce consumption. In July 2013, on consideration of consumption by children, chronic exposure, and carcinogenic effect, the FDA established an \"action level\" of 10\u00a0ppb for apple juice, the same as the drinking water standard.\nConcern about arsenic in rice in Bangladesh was raised in 2002, but at the time only Australia had a legal limit for food (one milligram per kilogram, or 1000 ppb). Concern was raised about people who were eating U.S. rice exceeding WHO standards for personal arsenic intake in 2005. In 2011, the People's Republic of China set a food standard of 150\u00a0ppb for arsenic.\nIn the United States in 2012, testing by separate groups of researchers at the Children's Environmental Health and Disease Prevention Research Center at Dartmouth College (early in the year, focusing on urinary levels in children) and Consumer Reports (in November) found levels of arsenic in rice that resulted in calls for the FDA to set limits. The FDA released some testing results in September 2012, and as of July 2013, is still collecting data in support of a new potential regulation. It has not recommended any changes in consumer behavior.\nConsumer Reports recommended:\nA 2014 World Health Organization advisory conference was scheduled to consider limits of 200\u2013300\u00a0ppb for rice.\nReducing arsenic content in rice.\nIn 2020, scientists assessed multiple preparation procedures of rice for their capacity to reduce arsenic content and preserve nutrients, recommending a procedure involving parboiling and water-absorption.\nEcotoxicity.\nArsenic is bioaccumulative in many organisms, marine species in particular, but it does not appear to biomagnify significantly in food webs. In polluted areas, plant growth may be affected by root uptake of arsenate, which is a phosphate analog and therefore readily transported in plant tissues and cells. In polluted areas, uptake of the more toxic arsenite ion (found more particularly in reducing conditions) is likely in poorly-drained soils.\nBiological mechanism.\nArsenic's toxicity comes from the affinity of arsenic(III) oxides for thiols. Thiols, in the form of cysteine residues and cofactors such as lipoic acid and coenzyme A, are situated at the active sites of many important enzymes.\nArsenic disrupts ATP production through several mechanisms. At the level of the citric acid cycle, arsenic inhibits lipoic acid, which is a cofactor for pyruvate dehydrogenase. By competing with phosphate, arsenate uncouples oxidative phosphorylation, thus inhibiting energy-linked reduction of NAD+, mitochondrial respiration and ATP synthesis. Hydrogen peroxide production is also increased, which, it is speculated, has potential to form reactive oxygen species and oxidative stress. These metabolic interferences lead to death from multi-system organ failure. The organ failure is presumed to be from necrotic cell death, not apoptosis, since energy reserves have been too depleted for apoptosis to occur.\nExposure risks and remediation.\nOccupational exposure and arsenic poisoning may occur in persons working in industries involving the use of inorganic arsenic and its compounds, such as wood preservation, glass production, nonferrous metal alloys, and electronic semiconductor manufacturing. Inorganic arsenic is also found in coke oven emissions associated with the smelter industry.\nThe conversion between As(III) and As(V) is a large factor in arsenic environmental contamination. According to Croal, Gralnick, Malasarn and Newman, \"[the] understanding [of] what stimulates As(III) oxidation and/or limits As(V) reduction is relevant for bioremediation of contaminated sites (Croal). The study of chemolithoautotrophic As(III) oxidizers and the heterotrophic As(V) reducers can help the understanding of the oxidation and/or reduction of arsenic.\nTreatment.\nTreatment of chronic arsenic poisoning is possible. British anti-lewisite (dimercaprol) is prescribed in doses of 5\u00a0mg/kg up to 300\u00a0mg every 4\u00a0hours for the first day, then every 6\u00a0hours for the second day, and finally every 8\u00a0hours for 8 additional days. However the USA's Agency for Toxic Substances and Disease Registry (ATSDR) states that the long-term effects of arsenic exposure cannot be predicted. Blood, urine, hair, and nails may be tested for arsenic; however, these tests cannot foresee possible health outcomes from the exposure. Long-term exposure and consequent excretion through urine has been linked to bladder and kidney cancer in addition to cancer of the liver, prostate, skin, lungs, and nasal cavity."}
{"id": "898", "revid": "19531195", "url": "https://en.wikipedia.org/wiki?curid=898", "title": "Antimony", "text": "Antimony is a chemical element; it has symbol Sb () and atomic number 51. A lustrous grey metal or metalloid, it is found in nature mainly as the sulfide mineral stibnite (Sb2S3). Antimony compounds have been known since ancient times and were powdered for use as medicine and cosmetics, often known by the Arabic name kohl. The earliest known description of this metalloid in the West was written in 1540 by Vannoccio Biringuccio.\nChina is the largest producer of antimony and its compounds, with most production coming from the Xikuangshan Mine in Hunan. The industrial methods for refining antimony from stibnite are roasting followed by reduction with carbon, or direct reduction of stibnite with iron.\nThe most common applications for metallic antimony are in alloys with lead and tin, which have improved properties for solders, bullets, and plain bearings. It improves the rigidity of lead-alloy plates in lead\u2013acid batteries. Antimony trioxide is a prominent additive for halogen-containing flame retardants. Antimony is used as a dopant in semiconductor devices.\nCharacteristics.\nProperties.\nAntimony is a member of group 15 of the periodic table, one of the elements called pnictogens, and has an electronegativity of 2.05. In accordance with periodic trends, it is more electronegative than tin or bismuth, and less electronegative than tellurium or arsenic. Antimony is stable in air at room temperature but, if heated, it reacts with oxygen to produce antimony trioxide, Sb2O3.\nAntimony is a silvery, lustrous gray metalloid with a Mohs scale hardness of 3, which is too soft to mark hard objects. Coins of antimony were issued in China's Guizhou in 1931; durability was poor, and minting was soon discontinued because of its softness and toxicity. Antimony is resistant to attack by acids.\nThe only stable allotrope of antimony under standard conditions is metallic, brittle, silver-white, and shiny. It crystallises in a trigonal cell, isomorphic with bismuth and the gray allotrope of arsenic, and is formed when molten antimony is cooled slowly. Amorphous black antimony is formed upon rapid cooling of antimony vapor, and is only stable as a thin film (thickness in nanometres); thicker samples spontaneously transform into the metallic form. It oxidizes in air and may ignite spontaneously. At 100\u00a0\u00b0C, it gradually transforms into the stable form. The supposed yellow allotrope of antimony, generated only by oxidation of stibine (SbH3) at \u221290\u00a0\u00b0C, is also impure and not a true allotrope; above this temperature and in ambient light, it transforms into the more stable black allotrope. A rare explosive form of antimony can be formed from the electrolysis of antimony trichloride, but it always contains appreciable chlorine and is not really an antimony allotrope. When scratched with a sharp implement, an exothermic reaction occurs and white fumes are given off as metallic antimony forms; when rubbed with a pestle in a mortar, a strong detonation occurs.\nElemental antimony adopts a layered structure (space group Rm No. 166) whose layers consist of fused, ruffled, six-membered rings. The nearest and next-nearest neighbors form an irregular octahedral complex, with the three atoms in each double layer slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 6.697\u00a0g/cm3, but the weak bonding between the layers leads to the low hardness and brittleness of antimony.\nIsotopes.\nAntimony has two stable isotopes: 121Sb with a natural abundance of 57.36% and 123Sb with a natural abundance of 42.64%. It also has 35 radioisotopes, of which the longest-lived is 125Sb with a half-life of 2.75\u00a0years. In addition, 29 metastable states have been characterized. The most stable of these is 120m1Sb with a half-life of 5.76\u00a0days. Isotopes that are lighter than the stable 123Sb tend to decay by \u03b2+ decay, and those that are heavier tend to decay by \u03b2\u2212 decay, with some exceptions. Antimony is the lightest element to have an isotope with an alpha decay branch, excluding 8Be and other light nuclides with beta-delayed alpha emission.\nOccurrence.\nThe abundance of antimony in the Earth's crust is estimated at 0.2 parts per million, comparable to thallium at 0.5\u00a0ppm and silver at 0.07\u00a0ppm. It is the 63rd most abundant element in the crust. Even though this element is not abundant, it is found in more than 100 mineral species. Antimony is sometimes found natively (e.g. on Antimony Peak), but more frequently it is found in the sulfide stibnite (Sb2S3) which is the predominant ore mineral.\nCompounds.\nAntimony compounds are often classified according to their oxidation state: Sb(III) and Sb(V). The +5 oxidation state is more common.\nOxides and hydroxides.\nAntimony trioxide is formed when antimony is burnt in air. In the gas phase, the molecule of the compound is , but it polymerizes upon condensing. Antimony pentoxide () can be formed only by oxidation with concentrated nitric acid. Antimony also forms a mixed-valence oxide, antimony tetroxide (), which features both Sb(III) and Sb(V). Unlike oxides of phosphorus and arsenic, these oxides are amphoteric, do not form well-defined oxoacids, and react with acids to form antimony salts.\nAntimonous acid is unknown, but the conjugate base sodium antimonite () forms upon fusing sodium oxide and . Transition metal antimonites are also known. Antimonic acid exists only as the hydrate , forming salts as the antimonate anion . When a solution containing this anion is dehydrated, the precipitate contains mixed oxides.\nThe most important antimony ore is stibnite (). Other sulfide minerals include pyrargyrite (), zinkenite, jamesonite, and boulangerite. Antimony pentasulfide is non-stoichiometric, which features antimony in the +3 oxidation state and S\u2013S bonds. Several thioantimonides are known, such as and .\nHalides.\nAntimony forms two series of halides: and . The trihalides , , , and are all molecular compounds having trigonal pyramidal molecular geometry.\nThe trifluoride is prepared by the reaction of with HF:\nIt is Lewis acidic and readily accepts fluoride ions to form the complex anions and . Molten is a weak electrical conductor. The trichloride is prepared by dissolving in hydrochloric acid:\nArsenic sulfides are not readily attacked by the hydrochloric acid, so this method offers a route to As-free Sb.\nThe pentahalides and have trigonal bipyramidal molecular geometry in the gas phase, but in the liquid phase, is polymeric, whereas is monomeric. is a powerful Lewis acid used to make the superacid fluoroantimonic acid (\"H2SbF7\").\nOxyhalides are more common for antimony than for arsenic and phosphorus. Antimony trioxide dissolves in concentrated acid to form oxoantimonyl compounds such as SbOCl and .\nAntimonides, hydrides, and organoantimony compounds.\nCompounds in this class generally are described as derivatives of Sb3\u2212. Antimony forms antimonides with metals, such as indium antimonide (InSb) and silver antimonide (). The alkali metal and zinc antimonides, such as Na3Sb and Zn3Sb2, are more reactive. Treating these antimonides with acid produces the highly unstable gas stibine, :\nStibine can also be produced by treating salts with hydride reagents such as sodium borohydride. Stibine decomposes spontaneously at room temperature. Because stibine has a positive heat of formation, it is thermodynamically unstable and thus antimony does not react with hydrogen directly.\nOrganoantimony compounds are typically prepared by alkylation of antimony halides with Grignard reagents. A large variety of compounds are known with both Sb(III) and Sb(V) centers, including mixed chloro-organic derivatives, anions, and cations. Examples include triphenylstibine (Sb(C6H5)3) and pentaphenylantimony (Sb(C6H5)5). \nHistory.\nAntimony(III) sulfide, Sb2S3, was recognized in predynastic Egypt as an eye cosmetic (kohl) as early as about 3100\u00a0BC, when the cosmetic palette was invented.\nAn artifact, said to be part of a vase, made of antimony dating to about 3000\u00a0BC was found at Telloh, Chaldea (part of present-day Iraq), and a copper object plated with antimony dating between 2500\u00a0BC and 2200\u00a0BC has been found in Egypt. Austen, at a lecture by Herbert Gladstone in 1892, commented that \"we only know of antimony at the present day as a highly brittle and crystalline metal, which could hardly be fashioned into a useful vase, and therefore this remarkable 'find' (artifact mentioned above) must represent the lost art of rendering antimony malleable.\"\nThe British archaeologist Roger Moorey was unconvinced the artifact was indeed a vase, mentioning that Selimkhanov, after his analysis of the Tello object (published in 1975), \"attempted to relate the metal to Transcaucasian natural antimony\" (i.e. native metal) and that \"the antimony objects from Transcaucasia are all small personal ornaments.\" This weakens the evidence for a lost art \"of rendering antimony malleable\".\nThe Roman scholar Pliny the Elder described several ways of preparing antimony sulfide for medical purposes in his treatise \"Natural History\", around 77\u00a0AD. Pliny the Elder also made a distinction between \"male\" and \"female\" forms of antimony; the male form is probably the sulfide, while the female form, which is superior, heavier, and less friable, has been suspected to be native metallic antimony.\nThe Greek naturalist Pedanius Dioscorides mentioned that antimony sulfide could be roasted by heating by a current of air. It is thought that this produced metallic antimony.\nAntimony was frequently described in alchemical manuscripts, including the \"Summa Perfectionis\" of Pseudo-Geber, written around the 14th century. A description of a procedure for isolating antimony is later given in the 1540 book \"De la pirotechnia\" by Vannoccio Biringuccio, predating the more famous 1556 book by Agricola, \"De re metallica\". In this context Agricola has been often incorrectly credited with the discovery of metallic antimony. The book \"Currus Triumphalis Antimonii\" (The Triumphal Chariot of Antimony), describing the preparation of metallic antimony, was published in Germany in 1604. It was purported to be written by a Benedictine monk, writing under the name Basilius Valentinus in the 15th century; if it were authentic, which it is not, it would predate Biringuccio.\nThe metal antimony was known to German chemist Andreas Libavius in 1615 who obtained it by adding iron to a molten mixture of antimony sulfide, salt and potassium tartrate. This procedure produced antimony with a crystalline or starred surface.\nWith the advent of challenges to phlogiston theory, it was recognized that antimony is an element forming sulfides, oxides, and other compounds, as do other metals.\nThe first discovery of naturally occurring pure antimony in the Earth's crust was described by the Swedish scientist and local mine district engineer Anton von Swab in 1783; the type-sample was collected from the Sala Silver Mine in the Bergslagen mining district of Sala, V\u00e4stmanland, Sweden.\nEtymology.\nThe medieval Latin form, from which the modern languages and late Byzantine Greek take their names for antimony, is \"\". The origin of that is uncertain, and all suggestions have some difficulty either of form or interpretation. The popular etymology, from \u1f00\u03bd\u03c4\u03af\u03bc\u03bf\u03bd\u03b1\u03c7\u03cc\u03c2 \"anti-monachos\" or French , would mean \"monk-killer\", which is explained by the fact that many early alchemists were monks, and some antimony compounds were poisonous. \nAnother popular etymology is the hypothetical Greek word \u1f00\u03bd\u03c4\u03af\u03bc\u03cc\u03bd\u03bf\u03c2 \"antimonos\", \"against aloneness\", explained as \"not found as metal\", or \"not found unalloyed\". However, ancient Greek would more naturally express the pure negative as \"\u03b1-\" (\"not\"). Edmund Oscar von Lippmann conjectured a hypothetical Greek word \u03b1\u03bd\u03b8\u03ae\u03bc\u03cc\u03bd\u03b9\u03bf\u03bd \"anthemonion\", which would mean \"floret\", and cites several examples of related Greek words (but not that one) which describe chemical or biological efflorescence.\nThe early uses of \"antimonium\" include the translations, in 1050\u20131100, by Constantine the African of Arabic medical treatises. Several authorities believe \"antimonium\" is a scribal corruption of some Arabic form; Meyerhof derives it from \"ithmid\"; other possibilities include \"athimar\", the Arabic name of the metalloid, and a hypothetical \"as-stimmi\", derived from or parallel to the Greek.\nThe standard chemical symbol for antimony (Sb) is credited to J\u00f6ns Jakob Berzelius, who derived the abbreviation from \"stibium\".\nThe ancient words for antimony mostly have, as their chief meaning, kohl, the sulfide of antimony.\nThe Egyptians called antimony \"m\u015bdmt\" or \"stm\".\nThe Arabic word for the substance, as opposed to the cosmetic, can appear as \"ithmid, athmoud, othmod\", or \"uthmod\". Littr\u00e9 suggests the first form, which is the earliest, derives from \"stimmida\", an accusative for \"stimmi\". The Greek word \u03c3\u03c4\u03af\u03bc\u03bc\u03b9 (stimmi) is used by Attic tragic poets of the 5th century BC, and is possibly a loan word from Arabic or from Egyptian \"stm\".\nProduction.\nProcess.\nThe extraction of antimony from ores depends on the quality and composition of the ore. Most antimony is mined as the sulfide; lower-grade ores are concentrated by froth flotation, while higher-grade ores are heated to 500\u2013600\u00a0\u00b0C, the temperature at which stibnite melts and separates from the gangue minerals. Antimony can be isolated from the crude antimony sulfide by reduction with scrap iron:\nThe sulfide is converted to an oxide by roasting. The product is further purified by vaporizing the volatile antimony(III) oxide, which is recovered. This sublimate is often used directly for the main applications, impurities being arsenic and sulfide. Antimony is isolated from the oxide by a carbothermal reduction:\nThe lower-grade ores are reduced in blast furnaces while the higher-grade ores are reduced in reverberatory furnaces.\nTop producers and production volumes.\nIn 2022, according to the US Geological Survey, China accounted for 54.5% of total antimony production, followed in second place by Russia with 18.2% and Tajikistan with 15.5%.\nChinese production of antimony is expected to decline in the future as mines and smelters are closed down by the government as part of pollution control. Especially due to an environmental protection law having gone into effect in January 2015 and revised \"Emission Standards of Pollutants for Stanum, Antimony, and Mercury\" having gone into effect, hurdles for economic production are higher.\nReported production of antimony in China has fallen and is unlikely to increase in the coming years, according to the Roskill report. No significant antimony deposits in China have been developed for about ten years, and the remaining economic reserves are being rapidly depleted.\nSupply risk.\nFor antimony-importing regions, such as Europe and the U.S., antimony is considered to be a critical mineral for industrial manufacturing that is at risk of supply chain disruption. With global production coming mainly from China (74%), Tajikistan (8%), and Russia (4%), these sources are critical to supply.\nApplications.\nApproximately 48% of antimony is consumed in flame retardants, 33% in lead\u2013acid batteries, and 8% in plastics.\nFlame retardants.\nAntimony is mainly used as the trioxide for flame-proofing compounds, always in combination with halogenated flame retardants except in halogen-containing polymers. The flame retarding effect of antimony trioxide is produced by the formation of halogenated antimony compounds, which react with hydrogen atoms, and probably also with oxygen atoms and OH radicals, thus inhibiting fire. Markets for these flame-retardants include children's clothing, toys, aircraft, and automobile seat covers. They are also added to polyester resins in fiberglass composites for such items as light aircraft engine covers. The resin will burn in the presence of an externally generated flame, but will extinguish when the external flame is removed.\nAlloys.\nAntimony forms a highly useful alloy with lead, increasing its hardness and mechanical strength. When casting it increases fluidity of the melt and reduces shrinkage during cooling. For most applications involving lead, varying amounts of antimony are used as alloying metal. In lead\u2013acid batteries, this addition improves plate strength and charging characteristics. For sailboats, lead keels are used to provide righting moment, ranging from 600 lbs to over 200 tons for the largest sailing superyachts; to improve hardness and tensile strength of the lead keel, antimony is mixed with lead between 2% and 5% by volume. Antimony is used in antifriction alloys (such as Babbitt metal), in bullets and lead shot, electrical cable sheathing, type metal (for example, for linotype printing machines), solder (some \"lead-free\" solders contain 5% Sb), in pewter, and in hardening alloys with low tin content in the manufacturing of organ pipes.\nOther applications.\nThree other applications consume nearly all the rest of the world's supply. One application is as a stabilizer and catalyst for the production of polyethylene terephthalate. Another is as a fining agent to remove microscopic bubbles in glass, mostly for TV screens antimony ions interact with oxygen, suppressing the tendency of the latter to form bubbles. The third application is pigments.\nIn the 1990s antimony was increasingly being used in semiconductors as a dopant in n-type silicon wafers for diodes, infrared detectors, and Hall-effect devices. In the 1950s, the emitters and collectors of n-p-n alloy junction transistors were doped with tiny beads of a lead-antimony alloy. Indium antimonide (InSb) is used as a material for mid-infrared detectors.\nThe material Ge2Sb2Te5 is used as for phase-change memory, a type of computer memory.\nBiology and medicine have few uses for antimony. Treatments containing antimony, known as antimonials, are used as emetics. Antimony compounds are used as antiprotozoan drugs. Potassium antimonyl tartrate, or tartar emetic, was once used as an anti-schistosomal drug from 1919 on. It was subsequently replaced by praziquantel. Antimony and its compounds are used in several veterinary preparations, such as anthiomaline and lithium antimony thiomalate, as a skin conditioner in ruminants. Antimony has a nourishing or conditioning effect on keratinized tissues in animals.\nAntimony-based drugs, such as meglumine antimoniate, are also considered the drugs of choice for treatment of leishmaniasis. Early treatments used antimony(III) species (trivalent antimonials), but in 1922 Upendranath Brahmachari invented a much safer antimony(V) drug, and since then so-called pentavalent antimonials have been the standard first-line treatment. However, \"Leishmania\" strains in Bihar and neighboring regions have developed resistance to antimony. Elemental antimony as an antimony pill was once used as a medicine. It could be reused by others after ingestion and elimination.\nAntimony(III) sulfide is used in the heads of some safety matches. Antimony sulfides help to stabilize the friction coefficient in automotive brake pad materials. Antimony is used in bullets, bullet tracers, paint, glass art, and as an opacifier in enamel. Antimony-124 is used together with beryllium in neutron sources; the gamma rays emitted by antimony-124 initiate the photodisintegration of beryllium. The emitted neutrons have an average energy of 24\u00a0keV. Natural antimony is used in startup neutron sources.\nThe powder derived from crushed antimony sulfide (\"kohl\") has been used for millennia as an eye cosmetic. Historically it was applied to the eyes with a metal rod and with one's spittle, and was thought by the ancients to aid in curing eye infections. The practice is still seen in Yemen and in other Muslim countries.\nPrecautions.\nAntimony and many of its compounds are toxic, and the effects of antimony poisoning are similar to arsenic poisoning. The toxicity of antimony is far lower than that of arsenic; this might be caused by the significant differences of uptake, metabolism and excretion between arsenic and antimony. The uptake of antimony(III) or antimony(V) in the gastrointestinal tract is at most 20%. Antimony(V) is not quantitatively reduced to antimony(III) in the cell (in fact antimony(III) is oxidised to antimony(V) instead).\nSince methylation of antimony does not occur, the excretion of antimony(V) in urine is the main way of elimination. Like arsenic, the most serious effect of acute antimony poisoning is cardiotoxicity and the resulting myocarditis; however, it can also manifest as Adams\u2013Stokes syndrome, which arsenic does not. Reported cases of intoxication by antimony equivalent to 90\u00a0mg antimony potassium tartrate dissolved from enamel has been reported to show only short term effects. An intoxication with 6\u00a0g of antimony potassium tartrate was reported to result in death after three days.\nInhalation of antimony dust is harmful and in certain cases may be fatal; in small doses, antimony causes headaches, dizziness, and depression. Larger doses such as prolonged skin contact may cause dermatitis, or damage the kidneys and the liver, causing violent and frequent vomiting, leading to death in a few days.\nAntimony is incompatible with strong oxidizing agents, strong acids, halogen acids, chlorine, or fluorine. It should be kept away from heat.\nAntimony leaches from polyethylene terephthalate (PET) bottles into liquids. While levels observed for bottled water are below drinking water guidelines, fruit juice concentrates (for which no guidelines are established) produced in the UK were found to contain up to 44.7\u00a0\u03bcg/L of antimony, well above the EU limits for tap water of 5\u00a0\u03bcg/L. The guidelines are:\nThe tolerable daily intake (TDI) proposed by WHO is 6\u00a0\u03bcg antimony per kilogram of body weight. The immediately dangerous to life or health (IDLH) value for antimony is 50\u00a0mg/m3.\nToxicity.\nCertain compounds of antimony appear to be toxic, particularly antimony trioxide and antimony potassium tartrate. Effects may be similar to arsenic poisoning. Occupational exposure may cause respiratory irritation, pneumoconiosis, antimony spots on the skin, gastrointestinal symptoms, and cardiac arrhythmias. In addition, antimony trioxide is potentially carcinogenic to humans.\nAdverse health effects have been observed in humans and animals following inhalation, oral, or dermal exposure to antimony and antimony compounds. Antimony toxicity typically occurs either due to occupational exposure, during therapy or from accidental ingestion. It is unclear if antimony can enter the body through the skin. The presence of low levels of antimony in saliva may also be associated with dental decay."}
{"id": "899", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=899", "title": "Actinium", "text": "Actinium is a chemical element; it has symbol Ac and atomic number\u00a089. It was first isolated by Friedrich Oskar Giesel in 1902, who gave it the name \"emanium\"; the element got its name by being wrongly identified with a substance Andr\u00e9-Louis Debierne found in 1899 and called actinium. The actinide series, a set of 15 elements between actinium and lawrencium in the periodic table, are named for actinium. Together with polonium, radium, and radon, actinium was one of the first non-primordial radioactive elements to be isolated.\nA soft, silvery-white radioactive metal, actinium reacts rapidly with oxygen and moisture in air forming a white coating of actinium oxide that prevents further oxidation. As with most lanthanides and many actinides, actinium assumes oxidation state +3 in nearly all its chemical compounds. Actinium is found only in traces in uranium and thorium ores as the isotope 227Ac, which decays with a half-life of 21.772 years, predominantly emitting beta and sometimes alpha particles, and 228Ac, which is beta active with a half-life of 6.15 hours. One tonne of natural uranium in ore contains about 0.2 milligrams of actinium-227, and one tonne of thorium contains about 5 nanograms of actinium-228. The close similarity of physical and chemical properties of actinium and lanthanum makes separation of actinium from the ore impractical. Instead, the element is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor. Owing to its scarcity, high price and radioactivity, actinium has no significant industrial use. Its current applications include a neutron source and an agent for radiation therapy.\nHistory.\nAndr\u00e9-Louis Debierne, a French chemist, announced the discovery of a new element in 1899. He separated it from pitchblende residues left by Marie and Pierre Curie after they had extracted radium. In 1899, Debierne described the substance as similar to titanium and (in 1900) as similar to thorium. Friedrich Oskar Giesel found in 1902 a substance similar to lanthanum and called it \"emanium\" in 1904. After a comparison of the substances' half-lives determined by Debierne, Harriet Brooks in 1904, and Otto Hahn and Otto Sackur in 1905, Debierne's chosen name for the new element was retained because it had seniority, despite the contradicting chemical properties he claimed for the element at different times.\nArticles published in the 1970s and later suggest that Debierne's results published in 1904 conflict with those reported in 1899 and 1900. Furthermore, the now-known chemistry of actinium precludes its presence as anything other than a minor constituent of Debierne's 1899 and 1900 results; in fact, the chemical properties he reported make it likely that he had, instead, accidentally identified protactinium, which would not be discovered for another fourteen years, only to have it disappear due to its hydrolysis and adsorption onto his laboratory equipment. This has led some authors to advocate that Giesel alone should be credited with the discovery. A less confrontational vision of scientific discovery is proposed by Adloff. He suggests that hindsight criticism of the early publications should be mitigated by the then nascent state of radiochemistry: highlighting the prudence of Debierne's claims in the original papers, he notes that nobody can contend that Debierne's substance did not contain actinium. Debierne, who is now considered by the vast majority of historians as the discoverer, lost interest in the element and left the topic. Giesel, on the other hand, can rightfully be credited with the first preparation of radiochemically pure actinium and with the identification of its atomic number 89.\nThe name actinium originates from the Ancient Greek \"aktis, aktinos\" (\u03b1\u03ba\u03c4\u03af\u03c2, \u03b1\u03ba\u03c4\u03af\u03bd\u03bf\u03c2), meaning beam or ray. Its symbol Ac is also used in abbreviations of other compounds that have nothing to do with actinium, such as acetyl, acetate and sometimes acetaldehyde.\nProperties.\nActinium is a soft, silvery-white, radioactive, metallic element. Its estimated shear modulus is similar to that of lead. Owing to its strong radioactivity, actinium glows in the dark with a pale blue light, which originates from the surrounding air ionized by the emitted energetic particles. Actinium has similar chemical properties to lanthanum and other lanthanides, and therefore these elements are difficult to separate when extracting from uranium ores. Solvent extraction and ion chromatography are commonly used for the separation.\nThe first element of the actinides, actinium gave the set its name, much as lanthanum had done for the lanthanides. The actinides are much more diverse than the lanthanides and therefore it was not until 1945 that the most significant change to Dmitri Mendeleev's periodic table since the recognition of the lanthanides, the introduction of the actinides, was generally accepted after Glenn T. Seaborg's research on the transuranium elements (although it had been proposed as early as 1892 by British chemist Henry Bassett).\nActinium reacts rapidly with oxygen and moisture in air forming a white coating of actinium oxide that impedes further oxidation. As with most lanthanides and actinides, actinium exists in the oxidation state +3, and the Ac3+ ions are colorless in solutions. The oxidation state +3 originates from the [Rn] 6d17s2 electronic configuration of actinium, with three valence electrons that are easily donated to give the stable closed-shell structure of the noble gas radon. Although the 5f orbitals are unoccupied in an actinium atom, it can be used as a valence orbital in actinium complexes and hence it is generally considered the first 5f element by authors working on it. Ac3+ is the largest of all known tripositive ions and its first coordination sphere contains approximately 10.9 \u00b1 0.5 water molecules.\nChemical compounds.\nDue to actinium's intense radioactivity, only a limited number of actinium compounds are known. These include: AcF3, AcCl3, AcBr3, AcOF, AcOCl, AcOBr, Ac2S3, Ac2O3, AcPO4 and Ac(NO3)3. They all contain actinium in the oxidation state +3. In particular, the lattice constants of the analogous lanthanum and actinium compounds differ by only a few percent.\nHere \"a\", \"b\" and \"c\" are lattice constants, No is space group number and \"Z\" is the number of formula units per unit cell. Density was not measured directly but calculated from the lattice parameters.\nOxides.\nActinium oxide (Ac2O3) can be obtained by heating the hydroxide at or the oxalate at , in vacuum. Its crystal lattice is isotypic with the oxides of most trivalent rare-earth metals.\nHalides.\nActinium trifluoride can be produced either in solution or in solid reaction. The former reaction is carried out at room temperature, by adding hydrofluoric acid to a solution containing actinium ions. In the latter method, actinium metal is treated with hydrogen fluoride vapors at in an all-platinum setup. Treating actinium trifluoride with ammonium hydroxide at yields oxyfluoride AcOF. Whereas lanthanum oxyfluoride can be easily obtained by burning lanthanum trifluoride in air at for an hour, similar treatment of actinium trifluoride yields no AcOF and only results in melting of the initial product.\nActinium trichloride is obtained by reacting actinium hydroxide or oxalate with carbon tetrachloride vapors at temperatures above . Similarly to the oxyfluoride, actinium oxychloride can be prepared by hydrolyzing actinium trichloride with ammonium hydroxide at . However, in contrast to the oxyfluoride, the oxychloride could well be synthesized by igniting a solution of actinium trichloride in hydrochloric acid with ammonia.\nReaction of aluminium bromide and actinium oxide yields actinium tribromide:\nand treating it with ammonium hydroxide at results in the oxybromide AcOBr.\nOther compounds.\nActinium hydride was obtained by reduction of actinium trichloride with potassium at , and its structure was deduced by analogy with the corresponding LaH2 hydride. The source of hydrogen in the reaction was uncertain.\nMixing monosodium phosphate (NaH2PO4) with a solution of actinium in hydrochloric acid yields white-colored actinium phosphate hemihydrate (AcPO4\u00b70.5H2O), and heating actinium oxalate with hydrogen sulfide vapors at for a few minutes results in a black actinium sulfide Ac2S3. It may possibly be produced by acting with a mixture of hydrogen sulfide and carbon disulfide on actinium oxide at .\nIsotopes.\nNaturally occurring actinium is principally composed of two radioactive isotopes; (from the radioactive family of ) and (a granddaughter of ). decays mainly as a beta emitter with a very small energy, but in 1.38% of cases it emits an alpha particle, so it can readily be identified through alpha spectrometry. Thirty-three radioisotopes have been identified, the most stable being with a half-life of 21.772 years, with a half-life of 10.0 days and with a half-life of 29.37 hours. All remaining radioactive isotopes have half-lives that are less than 10 hours and the majority of them have half-lives shorter than one minute. The shortest-lived known isotope of actinium is (half-life of 69 nanoseconds) which decays through alpha decay. Actinium also has two known meta states. The most significant isotopes for chemistry are 225Ac, 227Ac, and 228Ac.\nPurified comes into equilibrium with its decay products after about a half of year. It decays according to its 21.772-year half-life emitting mostly beta (98.62%) and some alpha particles (1.38%); the successive decay products are part of the actinium series. Owing to the low available amounts, low energy of its beta particles (maximum 44.8\u00a0keV) and low intensity of alpha radiation, is difficult to detect directly by its emission and it is therefore traced via its decay products. The isotopes of actinium range in atomic weight from 203\u00a0u () to 236\u00a0u ().\nOccurrence and synthesis.\nActinium is found only in traces in uranium ores\u00a0\u2013 one tonne of uranium in ore contains about 0.2 milligrams of 227Ac \u2013 and in thorium ores, which contain about 5 nanograms of 228Ac per one tonne of thorium. The actinium isotope 227Ac is a transient member of the uranium-actinium series decay chain, which begins with the parent isotope 235U (or 239Pu) and ends with the stable lead isotope 207Pb. The isotope 228Ac is a transient member of the thorium series decay chain, which begins with the parent isotope 232Th and ends with the stable lead isotope 208Pb. Another actinium isotope (225Ac) is transiently present in the neptunium series decay chain, beginning with 237Np (or 233U) and ending with thallium (205Tl) and near-stable bismuth (209Bi); even though all primordial 237Np has decayed away, it is continuously produced by neutron knock-out reactions on natural 238U.\nThe low natural concentration, and the close similarity of physical and chemical properties to those of lanthanum and other lanthanides, which are always abundant in actinium-bearing ores, render separation of actinium from the ore impractical. The most concentrated actinium sample prepared from raw material consisted of 7 micrograms of 227Ac in less than 0.1 milligrams of La2O3, and complete separation was never achieved. Instead, actinium is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor.\nThe reaction yield is about 2% of the radium weight. 227Ac can further capture neutrons resulting in small amounts of 228Ac. After the synthesis, actinium is separated from radium and from the products of decay and nuclear fusion, such as thorium, polonium, lead and bismuth. The extraction can be performed with thenoyltrifluoroacetone-benzene solution from an aqueous solution of the radiation products, and the selectivity to a certain element is achieved by adjusting the pH (to about 6.0 for actinium). An alternative procedure is anion exchange with an appropriate resin in nitric acid, which can result in a separation factor of 1,000,000 for radium and actinium vs. thorium in a two-stage process. Actinium can then be separated from radium, with a ratio of about 100, using a low cross-linking cation exchange resin and nitric acid as eluant.\n225Ac was first produced artificially at the Institute for Transuranium Elements (ITU) in Germany using a cyclotron and at St George Hospital in Sydney using a linac in 2000. This rare isotope has potential applications in radiation therapy and is most efficiently produced by bombarding a radium-226 target with 20\u201330\u00a0MeV deuterium ions. This reaction also yields 226Ac which however decays with a half-life of 29 hours and thus does not contaminate 225Ac.\nActinium metal has been prepared by the reduction of actinium fluoride with lithium vapor in vacuum at a temperature between . Higher temperatures resulted in evaporation of the product and lower ones lead to an incomplete transformation. Lithium was chosen among other alkali metals because its fluoride is most volatile.\nApplications.\nOwing to its scarcity, high price and radioactivity, 227Ac currently has no significant industrial use, but 225Ac is currently being studied for use in cancer treatments such as targeted alpha therapies.\n227Ac is highly radioactive and was therefore studied for use as an active element of radioisotope thermoelectric generators, for example in spacecraft. The oxide of 227Ac pressed with beryllium is also an efficient neutron source with the activity exceeding that of the standard americium-beryllium and radium-beryllium pairs. In all those applications, 227Ac (a beta source) is merely a progenitor which generates alpha-emitting isotopes upon its decay. Beryllium captures alpha particles and emits neutrons owing to its large cross-section for the (\u03b1,n) nuclear reaction:\nThe 227AcBe neutron sources can be applied in a neutron probe\u00a0\u2013 a standard device for measuring the quantity of water present in soil, as well as moisture/density for quality control in highway construction. Such probes are also used in well logging applications, in neutron radiography, tomography and other radiochemical investigations.\n225Ac is applied in medicine to produce in a reusable generator or can be used alone as an agent for radiation therapy, in particular targeted alpha therapy (TAT). This isotope has a half-life of 10 days, making it much more suitable for radiation therapy than 213Bi (half-life 46 minutes). Additionally, 225Ac decays to nontoxic 209Bi rather than toxic lead, which is the final product in the decay chains of several other candidate isotopes, namely 227Th, 228Th, and 230U. Not only 225Ac itself, but also its daughters, emit alpha particles which kill cancer cells in the body. The major difficulty with application of 225Ac was that intravenous injection of simple actinium complexes resulted in their accumulation in the bones and liver for a period of tens of years. As a result, after the cancer cells were quickly killed by alpha particles from 225Ac, the radiation from the actinium and its daughters might induce new mutations. To solve this problem, 225Ac was bound to a chelating agent, such as citrate, ethylenediaminetetraacetic acid (EDTA) or diethylene triamine pentaacetic acid (DTPA). This reduced actinium accumulation in the bones, but the excretion from the body remained slow. Much better results were obtained with such chelating agents as HEHA () or DOTA () coupled to trastuzumab, a monoclonal antibody that interferes with the HER2/neu receptor. The latter delivery combination was tested on mice and proved to be effective against leukemia, lymphoma, breast, ovarian, neuroblastoma and prostate cancers.\nThe medium half-life of 227Ac (21.77 years) makes it a very convenient radioactive isotope in modeling the slow vertical mixing of oceanic waters. The associated processes cannot be studied with the required accuracy by direct measurements of current velocities (of the order 50 meters per year). However, evaluation of the concentration depth-profiles for different isotopes allows estimating the mixing rates. The physics behind this method is as follows: oceanic waters contain homogeneously dispersed 235U. Its decay product, 231Pa, gradually precipitates to the bottom, so that its concentration first increases with depth and then stays nearly constant. 231Pa decays to 227Ac; however, the concentration of the latter isotope does not follow the 231Pa depth profile, but instead increases toward the sea bottom. This occurs because of the mixing processes which raise some additional 227Ac from the sea bottom. Thus analysis of both 231Pa and 227Ac depth profiles allows researchers to model the mixing behavior.\nThere are theoretical predictions that AcHx hydrides (in this case with very high pressure) are a candidate for a near room-temperature superconductor as they have Tc significantly higher than H3S, possibly near 250\u00a0K.\nPrecautions.\n227Ac is highly radioactive and experiments with it are carried out in a specially designed laboratory equipped with a tight glove box. When actinium trichloride is administered intravenously to rats, about 33% of actinium is deposited into the bones and 50% into the liver. Its toxicity is comparable to, but slightly lower, than that of americium and plutonium. For trace quantities, fume hoods with good aeration suffice; for gram amounts, hot cells with shielding from the intense gamma radiation emitted by 227Ac are necessary."}
{"id": "900", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=900", "title": "Americium", "text": "Americium is a synthetic chemical element; it has symbol Am and atomic number 95. It is radioactive and a transuranic member of the actinide series in the periodic table, located under the lanthanide element europium and was thus named after the Americas by analogy.\nAmericium was first produced in 1944 by the group of Glenn T. Seaborg from Berkeley, California, at the Metallurgical Laboratory of the University of Chicago, as part of the Manhattan Project. Although it is the third element in the transuranic series, it was discovered fourth, after the heavier curium. The discovery was kept secret and only released to the public in November 1945. Most americium is produced by uranium or plutonium being bombarded with neutrons in nuclear reactors \u2013 one tonne of spent nuclear fuel contains about 100 grams of americium. It is widely used in commercial ionization chamber smoke detectors, as well as in neutron sources and industrial gauges. Several unusual applications, such as nuclear batteries or fuel for space ships with nuclear propulsion, have been proposed for the isotope 242mAm, but they are as yet hindered by the scarcity and high price of this nuclear isomer.\nAmericium is a relatively soft radioactive metal with a silvery appearance. Its most common isotopes are 241Am and 243Am. In chemical compounds, americium usually assumes the oxidation state +3, especially in solutions. Several other oxidation states are known, ranging from +2 to +7, and can be identified by their characteristic optical absorption spectra. The crystal lattices of solid americium and its compounds contain small intrinsic radiogenic defects, due to metamictization induced by self-irradiation with alpha particles, which accumulates with time; this can cause a drift of some material properties over time, more noticeable in older samples.\nHistory.\nAlthough americium was likely produced in previous nuclear experiments, it was first intentionally synthesized, isolated and identified in late autumn 1944, at the University of California, Berkeley, by Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, and Albert Ghiorso. They used a 60-inch cyclotron at the University of California, Berkeley. The element was chemically identified at the Metallurgical Laboratory (now Argonne National Laboratory) of the University of Chicago. Following the lighter neptunium, plutonium, and heavier curium, americium was the fourth transuranium element to be discovered. At the time, the periodic table had been restructured by Seaborg to its present layout, containing the actinide row below the lanthanide one. This led to americium being located right below its twin lanthanide element europium; it was thus by analogy named after the Americas: \"The name americium (after the Americas) and the symbol Am are suggested for the element on the basis of its position as the sixth member of the actinide rare-earth series, analogous to europium, Eu, of the lanthanide series.\"\nThe new element was isolated from its oxides in a complex, multi-step process. First plutonium-239 nitrate (239PuNO3) solution was coated on a platinum foil of about 0.5\u00a0cm2 area, the solution was evaporated and the residue was converted into plutonium dioxide (PuO2) by calcining. After cyclotron irradiation, the coating was dissolved with nitric acid, and then precipitated as the hydroxide using concentrated aqueous ammonia solution. The residue was dissolved in perchloric acid. Further separation was carried out by ion exchange, yielding a certain isotope of curium. The separation of curium and americium was so painstaking that those elements were initially called by the Berkeley group as \"pandemonium\" (from Greek for \"all demons\" or \"hell\") and \"delirium\" (from Latin for \"madness\").\nInitial experiments yielded four americium isotopes: 241Am, 242Am, 239Am and 238Am. Americium-241 was directly obtained from plutonium upon absorption of two neutrons. It decays by emission of a \u03b1-particle to 237Np; the half-life of this decay was first determined as years but then corrected to 432.2 years.\nThe second isotope 242Am was produced upon neutron bombardment of the already-created 241Am. Upon rapid \u03b2-decay, 242Am converts into the isotope of curium 242Cm (which had been discovered previously). The half-life of this decay was initially determined at 17 hours, which was close to the presently accepted value of 16.02 h.\nThe discovery of americium and curium in 1944 was closely related to the Manhattan Project; the results were confidential and declassified only in 1945. Seaborg leaked the synthesis of the elements 95 and 96 on the U.S. radio show for children \"Quiz Kids\" five days before the official presentation at an American Chemical Society meeting on 11 November 1945, when one of the listeners asked whether any new transuranium element besides plutonium and neptunium had been discovered during the war. After the discovery of americium isotopes 241Am and 242Am, their production and compounds were patented listing only Seaborg as the inventor. The initial americium samples weighed a few micrograms; they were barely visible and were identified by their radioactivity. The first substantial amounts of metallic americium weighing 40\u2013200 micrograms were not prepared until 1951 by reduction of americium(III) fluoride with barium metal in high vacuum at 1100\u00a0\u00b0C.\nOccurrence.\nThe longest-lived and most common isotopes of americium, 241Am and 243Am, have half-lives of 432.2 and 7,370 years, respectively. Therefore, any primordial americium (americium that was present on Earth during its formation) should have decayed by now. Trace amounts of americium probably occur naturally in uranium minerals as a result of neutron capture and beta decay (238U \u2192 239Pu \u2192 240Pu \u2192 241Am), though the quantities would be tiny and this has not been confirmed. Extraterrestrial long-lived 247Cm is probably also deposited on Earth and has 243Am as one of its intermediate decay products, but again this has not been confirmed.\nExisting americium is concentrated in the areas used for the atmospheric nuclear weapons tests conducted between 1945 and 1980, as well as at the sites of nuclear incidents, such as the Chernobyl disaster. For example, the analysis of the debris at the testing site of the first U.S. hydrogen bomb, Ivy Mike, (1 November 1952, Enewetak Atoll), revealed high concentrations of various actinides including americium; but due to military secrecy, this result was not published until later, in 1956. Trinitite, the glassy residue left on the desert floor near Alamogordo, New Mexico, after the plutonium-based Trinity nuclear bomb test on 16 July 1945, contains traces of americium-241. Elevated levels of americium were also detected at the crash site of a US Boeing B-52 bomber aircraft, which carried four hydrogen bombs, in 1968 in Greenland.\nIn other regions, the average radioactivity of surface soil due to residual americium is only about 0.01\u00a0picocuries per gram (0.37\u00a0mBq/g). Atmospheric americium compounds are poorly soluble in common solvents and mostly adhere to soil particles. Soil analysis revealed about 1,900 times higher concentration of americium inside sandy soil particles than in the water present in the soil pores; an even higher ratio was measured in loam soils.\nAmericium is produced mostly artificially in small quantities, for research purposes. A tonne of spent nuclear fuel contains about 100\u00a0grams of various americium isotopes, mostly 241Am and 243Am. Their prolonged radioactivity is undesirable for the disposal, and therefore americium, together with other long-lived actinides, must be neutralized. The associated procedure may involve several steps, where americium is first separated and then converted by neutron bombardment in special reactors to short-lived nuclides. This procedure is well known as nuclear transmutation, but it is still being developed for americium. The transuranic elements from americium to fermium occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\nAmericium is also one of the elements that have theoretically been detected in Przybylski's Star.\nSynthesis and extraction.\nIsotope nucleosynthesis.\nAmericium has been produced in small quantities in nuclear reactors for decades, and kilograms of its 241Am and 243Am isotopes have been accumulated by now. Nevertheless, since it was first offered for sale in 1962, its price, about of 241Am, remains almost unchanged owing to the very complex separation procedure. The heavier isotope 243Am is produced in much smaller amounts; it is thus more difficult to separate, resulting in a higher cost of the order .\nAmericium is not synthesized directly from uranium \u2013 the most common reactor material \u2013 but from the plutonium isotope 239Pu. The latter needs to be produced first, according to the following nuclear process:\nThe capture of two neutrons by 239Pu (a so-called (n,\u03b3) reaction), followed by a \u03b2-decay, results in 241Am:\nThe plutonium present in spent nuclear fuel contains about 12% of 241Pu. Because it beta-decays to 241Am, 241Pu can be extracted and may be used to generate further 241Am. However, this process is rather slow: half of the original amount of 241Pu decays to 241Am after about 15 years, and the 241Am amount reaches a maximum after 70 years.\nThe obtained 241Am can be used for generating heavier americium isotopes by further neutron capture inside a nuclear reactor. In a light water reactor (LWR), 79% of 241Am converts to 242Am and 10% to its nuclear isomer 242mAm:\nAmericium-242 has a half-life of only 16 hours, which makes its further conversion to 243Am extremely inefficient. The latter isotope is produced instead in a process where 239Pu captures four neutrons under high neutron flux:\nMetal generation.\nMost synthesis routines yield a mixture of different actinide isotopes in oxide forms, from which isotopes of americium can be separated. In a typical procedure, the spent reactor fuel (e.g. MOX fuel) is dissolved in nitric acid, and the bulk of uranium and plutonium is removed using a PUREX-type extraction (Plutonium\u2013URanium EXtraction) with tributyl phosphate in a hydrocarbon. The lanthanides and remaining actinides are then separated from the aqueous residue (raffinate) by a diamide-based extraction, to give, after stripping, a mixture of trivalent actinides and lanthanides. Americium compounds are then selectively extracted using multi-step chromatographic and centrifugation techniques with an appropriate reagent. A large amount of work has been done on the solvent extraction of americium. For example, a 2003 EU-funded project codenamed \"EUROPART\" studied triazines and other compounds as potential extraction agents. A \"bis\"-triazinyl bipyridine complex was proposed in 2009 as such a reagent is highly selective to americium (and curium). Separation of americium from the highly similar curium can be achieved by treating a slurry of their hydroxides in aqueous sodium bicarbonate with ozone, at elevated temperatures. Both Am and Cm are mostly present in solutions in the +3 valence state; whereas curium remains unchanged, americium oxidizes to soluble Am(IV) complexes which can be washed away.\nMetallic americium is obtained by reduction from its compounds. Americium(III) fluoride was first used for this purpose. The reaction was conducted using elemental barium as reducing agent in a water- and oxygen-free environment inside an apparatus made of tantalum and tungsten.\nAn alternative is the reduction of americium dioxide by metallic lanthanum or thorium:\nPhysical properties.\nIn the periodic table, americium is located to the right of plutonium, to the left of curium, and below the lanthanide europium, with which it shares many physical and chemical properties. Americium is a highly radioactive element. When freshly prepared, it has a silvery-white metallic lustre, but then slowly tarnishes in air. With a density of 12\u00a0g/cm3, americium is less dense than both curium (13.52\u00a0g/cm3) and plutonium (19.8\u00a0g/cm3); but has a higher density than europium (5.264\u00a0g/cm3)\u2014mostly because of its higher atomic mass. Americium is relatively soft and easily deformable and has a significantly lower bulk modulus than the actinides before it: Th, Pa, U, Np and Pu. Its melting point of 1173\u00a0\u00b0C is significantly higher than that of plutonium (639\u00a0\u00b0C) and europium (826\u00a0\u00b0C), but lower than for curium (1340\u00a0\u00b0C).\nAt ambient conditions, americium is present in its most stable \u03b1 form which has a hexagonal crystal symmetry, and a space group P63/mmc with cell parameters \"a\"\u00a0= 346.8\u00a0pm and \"c\"\u00a0= 1124\u00a0pm, and four atoms per unit cell. The crystal consists of a double-hexagonal close packing with the layer sequence ABAC and so is isotypic with \u03b1-lanthanum and several actinides such as \u03b1-curium. The crystal structure of americium changes with pressure and temperature. When compressed at room temperature to 5 GPa, \u03b1-Am transforms to the \u03b2 modification, which has a face-centered cubic (\"fcc\") symmetry, space group Fmm and lattice constant \"a\"\u00a0= 489\u00a0pm. This \"fcc\" structure is equivalent to the closest packing with the sequence ABC. Upon further compression to 23 GPa, americium transforms to an orthorhombic \u03b3-Am structure similar to that of \u03b1-uranium. There are no further transitions observed up to 52 GPa, except for an appearance of a monoclinic phase at pressures between 10 and 15 GPa. There is no consistency on the status of this phase in the literature, which also sometimes lists the \u03b1, \u03b2 and \u03b3 phases as I, II and III. The \u03b2-\u03b3 transition is accompanied by a 6% decrease in the crystal volume; although theory also predicts a significant volume change for the \u03b1-\u03b2 transition, it is not observed experimentally. The pressure of the \u03b1-\u03b2 transition decreases with increasing temperature, and when \u03b1-americium is heated at ambient pressure, at 770\u00a0\u00b0C it changes into an \"fcc\" phase which is different from \u03b2-Am, and at 1075\u00a0\u00b0C it converts to a body-centered cubic structure. The pressure-temperature phase diagram of americium is thus rather similar to those of lanthanum, praseodymium and neodymium.\nAs with many other actinides, self-damage of the crystal structure due to alpha-particle irradiation is intrinsic to americium. It is especially noticeable at low temperatures, where the mobility of the produced structure defects is relatively low, by broadening of X-ray diffraction peaks. This effect makes somewhat uncertain the temperature of americium and some of its properties, such as electrical resistivity. So for americium-241, the resistivity at 4.2 K increases with time from about 2\u00a0\u03bcOhm\u00b7cm to 10\u00a0\u03bcOhm\u00b7cm after 40 hours, and saturates at about 16\u00a0\u03bcOhm\u00b7cm after 140 hours. This effect is less pronounced at room temperature, due to annihilation of radiation defects; also heating to room temperature the sample which was kept for hours at low temperatures restores its resistivity. In fresh samples, the resistivity gradually increases with temperature from about 2 \u03bcOhm\u00b7cm at liquid helium to 69\u00a0\u03bcOhm\u00b7cm at room temperature; this behavior is similar to that of neptunium, uranium, thorium and protactinium, but is different from plutonium and curium which show a rapid rise up to 60\u00a0K followed by saturation. The room temperature value for americium is lower than that of neptunium, plutonium and curium, but higher than for uranium, thorium and protactinium.\nAmericium is paramagnetic in a wide temperature range, from that of liquid helium, to room temperature and above. This behavior is markedly different from that of its neighbor curium which exhibits antiferromagnetic transition at 52\u00a0K. The thermal expansion coefficient of americium is slightly anisotropic and amounts to along the shorter \"a\" axis and for the longer \"c\" hexagonal axis. The enthalpy of dissolution of americium metal in hydrochloric acid at standard conditions is , from which the standard enthalpy change of formation (\u0394f\"H\"\u00b0) of aqueous Am3+ ion is . The standard potential Am3+/Am0 is .\nChemical properties.\nAmericium metal readily reacts with oxygen and dissolves in aqueous acids. The most stable oxidation state for americium is +3. The chemistry of americium(III) has many similarities to the chemistry of lanthanide(III) compounds. For example, trivalent americium forms insoluble fluoride, oxalate, iodate, hydroxide, phosphate and other salts. Compounds of americium in oxidation states +2, +4, +5, +6 and +7 have also been studied. This is the widest range that has been observed with actinide elements. The color of americium compounds in aqueous solution is as follows: Am3+ (yellow-reddish), Am4+ (yellow-reddish), ; (yellow), (brown) and (dark green). The absorption spectra have sharp peaks, due to \"f\"-\"f\" transitions' in the visible and near-infrared regions. Typically, Am(III) has absorption maxima at ca. 504 and 811\u00a0nm, Am(V) at ca. 514 and 715\u00a0nm, and Am(VI) at ca. 666 and 992\u00a0nm.\nAmericium compounds with oxidation state +4 and higher are strong oxidizing agents, comparable in strength to the permanganate ion () in acidic solutions. Whereas the Am4+ ions are unstable in solutions and readily convert to Am3+, compounds such as americium dioxide (AmO2) and americium(IV) fluoride (AmF4) are stable in the solid state.\nThe pentavalent oxidation state of americium was first observed in 1951. In acidic aqueous solution the ion is unstable with respect to disproportionation. The reaction\nis typical. The chemistry of Am(V) and Am(VI) is comparable to the chemistry of uranium in those oxidation states. In particular, compounds like and are comparable to uranates and the ion is comparable to the uranyl ion, . Such compounds can be prepared by oxidation of Am(III) in dilute nitric acid with ammonium persulfate. Other oxidising agents that have been used include silver(I) oxide, ozone and sodium persulfate.\nChemical compounds.\nOxygen compounds.\nThree americium oxides are known, with the oxidation states +2 (AmO), +3 (Am2O3) and +4 (AmO2). Americium(II) oxide was prepared in minute amounts and has not been characterized in detail. Americium(III) oxide is a red-brown solid with a melting point of 2205\u00a0\u00b0C. Americium(IV) oxide is the main form of solid americium which is used in nearly all its applications. As most other actinide dioxides, it is a black solid with a cubic (fluorite) crystal structure.\nThe oxalate of americium(III), vacuum dried at room temperature, has the chemical formula Am2(C2O4)3\u00b77H2O. Upon heating in vacuum, it loses water at 240\u00a0\u00b0C and starts decomposing into AmO2 at 300\u00a0\u00b0C, the decomposition completes at about 470\u00a0\u00b0C. The initial oxalate dissolves in nitric acid with the maximum solubility of 0.25\u00a0g/L.\nHalides.\nHalides of americium are known for the oxidation states +2, +3 and +4, where the +3 is most stable, especially in solutions.\nReduction of Am(III) compounds with sodium amalgam yields Am(II) salts \u2013 the black halides AmCl2, AmBr2 and AmI2. They are very sensitive to oxygen and oxidize in water, releasing hydrogen and converting back to the Am(III) state. Specific lattice constants are:\nAmericium(III) fluoride (AmF3) is poorly soluble and precipitates upon reaction of Am3+ and fluoride ions in weak acidic solutions:\nThe tetravalent americium(IV) fluoride (AmF4) is obtained by reacting solid americium(III) fluoride with molecular fluorine:\nAnother known form of solid tetravalent americium fluoride is KAmF5. Tetravalent americium has also been observed in the aqueous phase. For this purpose, black Am(OH)4 was dissolved in 15-M NH4F with the americium concentration of 0.01 M. The resulting reddish solution had a characteristic optical absorption spectrum which is similar to that of AmF4 but differed from other oxidation states of americium. Heating the Am(IV) solution to 90\u00a0\u00b0C did not result in its disproportionation or reduction, however a slow reduction was observed to Am(III) and assigned to self-irradiation of americium by alpha particles.\nMost americium(III) halides form hexagonal crystals with slight variation of the color and exact structure between the halogens. So, chloride (AmCl3) is reddish and has a structure isotypic to uranium(III) chloride (space group P63/m) and the melting point of 715\u00a0\u00b0C. The fluoride is isotypic to LaF3 (space group P63/mmc) and the iodide to BiI3 (space group R). The bromide is an exception with the orthorhombic PuBr3-type structure and space group Cmcm. Crystals of americium(III) chloride hexahydrate (AmCl3\u00b76H2O) can be prepared by dissolving americium dioxide in hydrochloric acid and evaporating the liquid. Those crystals are hygroscopic and have yellow-reddish color and a monoclinic crystal structure.\nOxyhalides of americium in the form AmVIO2X2, AmVO2X, AmIVOX2 and AmIIIOX can be obtained by reacting the corresponding americium halide with oxygen or Sb2O3, and AmOCl can also be produced by vapor phase hydrolysis:\nChalcogenides and pnictides.\nThe known chalcogenides of americium include the sulfide AmS2, selenides AmSe2 and Am3Se4, and tellurides Am2Te3 and AmTe2. The pnictides of americium (243Am) of the AmX type are known for the elements phosphorus, arsenic, antimony and bismuth. They crystallize in the rock-salt lattice.\nSilicides and borides.\nAmericium monosilicide (AmSi) and \"disilicide\" (nominally AmSix with: 1.87 &lt; x &lt; 2.0) were obtained by reduction of americium(III) fluoride with elementary silicon in vacuum at 1050\u00a0\u00b0C (AmSi) and 1150\u22121200\u00a0\u00b0C (AmSix). AmSi is a black solid isomorphic with LaSi, it has an orthorhombic crystal symmetry. AmSix has a bright silvery lustre and a tetragonal crystal lattice (space group \"I\"41/amd), it is isomorphic with PuSi2 and ThSi2. Borides of americium include AmB4 and AmB6. The tetraboride can be obtained by heating an oxide or halide of americium with magnesium diboride in vacuum or inert atmosphere.\nOrganoamericium compounds.\nAnalogous to uranocene, americium is predicted to form the organometallic compound amerocene with two cyclooctatetraene ligands, with the chemical formula (\u03b78-C8H8)2Am. A cyclopentadienyl complex is also known that is likely to be stoichiometrically AmCp3.\nFormation of the complexes of the type Am(n-C3H7-BTP)3, where BTP stands for 2,6-di(1,2,4-triazin-3-yl)pyridine, in solutions containing n-C3H7-BTP and Am3+ ions has been confirmed by EXAFS. Some of these BTP-type complexes selectively interact with americium and therefore are useful in its selective separation from lanthanides and another actinides.\nBiological aspects.\nAmericium is an artificial element of recent origin, and thus does not have a biological requirement. It is harmful to life. It has been proposed to use bacteria for removal of americium and other heavy metals from rivers and streams. Thus, Enterobacteriaceae of the genus \"Citrobacter\" precipitate americium ions from aqueous solutions, binding them into a metal-phosphate complex at their cell walls. Several studies have been reported on the biosorption and bioaccumulation of americium by bacteria and fungi. In the laboratory, both americium and curium were found to support the growth of methylotrophs.\nFission.\nThe isotope 242mAm (half-life 141 years) has the largest cross sections for absorption of thermal neutrons (5,700 barns), that results in a small critical mass for a sustained nuclear chain reaction. The critical mass for a bare 242mAm sphere is about 9\u201314\u00a0kg (the uncertainty results from insufficient knowledge of its material properties). It can be lowered to 3\u20135\u00a0kg with a metal reflector and should become even smaller with a water reflector. Such small critical mass is favorable for portable nuclear weapons, but those based on 242mAm are not known yet, probably because of its scarcity and high price. The critical masses of the two readily available isotopes, 241Am and 243Am, are relatively high \u2013 57.6 to 75.6\u00a0kg for 241Am and 209\u00a0kg for 243Am. Scarcity and high price yet hinder application of americium as a nuclear fuel in nuclear reactors.\nThere are proposals of very compact 10-kW high-flux reactors using as little as 20\u00a0grams of 242mAm. Such low-power reactors would be relatively safe to use as neutron sources for radiation therapy in hospitals.\nIsotopes.\nAbout 18 isotopes and 11 nuclear isomers are known for americium, having mass numbers 229, 230, and 232 through 247. There are two long-lived alpha-emitters; 243Am has a half-life of 7,370\u00a0years and is the most stable isotope, and 241Am has a half-life of 432.2\u00a0years. The most stable nuclear isomer is 242m1Am; it has a long half-life of 141\u00a0years. The half-lives of other isotopes and isomers range from 0.64\u00a0microseconds for 245m1Am to 50.8\u00a0hours for 240Am. As with most other actinides, the isotopes of americium with odd number of neutrons have relatively high rate of nuclear fission and low critical mass.\nAmericium-241 decays to 237Np emitting alpha particles of 5 different energies, mostly at 5.486\u00a0MeV (85.2%) and 5.443\u00a0MeV (12.8%). Because many of the resulting states are metastable, they also emit gamma rays with the discrete energies between 26.3 and 158.5\u00a0keV.\nAmericium-242 is a short-lived isotope with a half-life of 16.02\u00a0h. It mostly (82.7%) converts by \u03b2-decay to 242Cm, but also by electron capture to 242Pu (17.3%). Both 242Cm and 242Pu transform via nearly the same decay chain through 238Pu down to 234U.\nNearly all (99.541%) of 242m1Am decays by internal conversion to 242Am and the remaining 0.459% by \u03b1-decay to 238Np. The latter subsequently decays to 238Pu and then to 234U.\nAmericium-243 transforms by \u03b1-emission into 239Np, which converts by \u03b2-decay to 239Pu, and the 239Pu changes into 235U by emitting an \u03b1-particle.\nApplications.\nIonization-type smoke detector.\nAmericium is used in the most common type of household smoke detector, which uses 241Am in the form of americium dioxide as its source of ionizing radiation. This isotope is preferred over 226Ra because it emits 5 times more alpha particles and relatively little harmful gamma radiation.\nThe amount of americium in a typical new smoke detector is 1\u00a0microcurie (37\u00a0kBq) or 0.29 microgram. This amount declines slowly as the americium decays into neptunium-237, a different transuranic element with a much longer half-life (about 2.14 million years). With its half-life of 432.2 years, the americium in a smoke detector includes about 3% neptunium after 19 years, and about 5% after 32 years. The radiation passes through an ionization chamber, an air-filled space between two electrodes, and permits a small, constant current between the electrodes. Any smoke that enters the chamber absorbs the alpha particles, which reduces the ionization and affects this current, triggering the alarm. Compared to the alternative optical smoke detector, the ionization smoke detector is cheaper and can detect particles which are too small to produce significant light scattering; however, it is more prone to false alarms.\nRadionuclide.\nAs 241Am has a roughly similar half-life to 238Pu (432.2 years vs. 87 years), it has been proposed as an active element of radioisotope thermoelectric generators, for example in spacecraft. Although americium produces less heat and electricity \u2013 the power yield is 114.7\u00a0mW/g for 241Am and 6.31\u00a0mW/g for 243Am (cf. 390\u00a0mW/g for 238Pu) \u2013 and its radiation poses more threat to humans owing to neutron emission, the European Space Agency is considering using americium for its space probes.\nAnother proposed space-related application of americium is a fuel for space ships with nuclear propulsion. It relies on the very high rate of nuclear fission of 242mAm, which can be maintained even in a micrometer-thick foil. Small thickness avoids the problem of self-absorption of emitted radiation. This problem is pertinent to uranium or plutonium rods, in which only surface layers provide alpha-particles. The fission products of 242mAm can either directly propel the spaceship or they can heat a thrusting gas. They can also transfer their energy to a fluid and generate electricity through a magnetohydrodynamic generator.\nOne more proposal which utilizes the high nuclear fission rate of 242mAm is a nuclear battery. Its design relies not on the energy of the emitted by americium alpha particles, but on their charge, that is the americium acts as the self-sustaining \"cathode\". A single 3.2\u00a0kg 242mAm charge of such battery could provide about 140\u00a0kW of power over a period of 80 days. Even with all the potential benefits, the current applications of 242mAm are as yet hindered by the scarcity and high price of this particular nuclear isomer.\nIn 2019, researchers at the UK National Nuclear Laboratory and the University of Leicester demonstrated the use of heat generated by americium to illuminate a small light bulb. This technology could lead to systems to power missions with durations up to 400 years into interstellar space, where solar panels do not function.\nNeutron source.\nThe oxide of 241Am pressed with beryllium is an efficient neutron source. Here americium acts as the alpha source, and beryllium produces neutrons owing to its large cross-section for the (\u03b1,n) nuclear reaction:\nThe most widespread use of 241AmBe neutron sources is a neutron probe \u2013 a device used to measure the quantity of water present in soil, as well as moisture/density for quality control in highway construction. 241Am neutron sources are also used in well logging applications, as well as in neutron radiography, tomography and other radiochemical investigations.\nProduction of other elements.\nAmericium is a starting material for the production of other transuranic elements and transactinides \u2013 for example, 82.7% of 242Am decays to 242Cm and 17.3% to 242Pu. In the nuclear reactor, 242Am is also up-converted by neutron capture to 243Am and 244Am, which transforms by \u03b2-decay to 244Cm:\nIrradiation of 241Am by 12C or 22Ne ions yields the isotopes 247Es (einsteinium) or 260Db (dubnium), respectively. Furthermore, the element berkelium (243Bk isotope) had been first intentionally produced and identified by bombarding 241Am with alpha particles, in 1949, by the same Berkeley group, using the same 60-inch cyclotron. Similarly, nobelium was produced at the Joint Institute for Nuclear Research, Dubna, Russia, in 1965 in several reactions, one of which included irradiation of 243Am with 15N ions. Besides, one of the synthesis reactions for lawrencium, discovered by scientists at Berkeley and Dubna, included bombardment of 243Am with 18O.\nSpectrometer.\nAmericium-241 has been used as a portable source of both gamma rays and alpha particles for a number of medical and industrial uses. The 59.5409\u00a0keV gamma ray emissions from 241Am in such sources can be used for indirect analysis of materials in radiography and X-ray fluorescence spectroscopy, as well as for quality control in fixed nuclear density gauges and nuclear densometers. For example, the element has been employed to gauge glass thickness to help create flat glass. Americium-241 is also suitable for calibration of gamma-ray spectrometers in the low-energy range, since its spectrum consists of nearly a single peak and negligible Compton continuum (at least three orders of magnitude lower intensity). Americium-241 gamma rays were also used to provide passive diagnosis of thyroid function. This medical application is however obsolete.\nHealth concerns.\nAs a highly radioactive element, americium and its compounds must be handled only in an appropriate laboratory under special arrangements. Although most americium isotopes predominantly emit alpha particles which can be blocked by thin layers of common materials, many of the daughter products emit gamma-rays and neutrons which have a long penetration depth.\nIf consumed, most of the americium is excreted within a few days, with only 0.05% absorbed in the blood, of which roughly 45% goes to the liver and 45% to the bones, and the remaining 10% is excreted. The uptake to the liver depends on the individual and increases with age. In the bones, americium is first deposited over cortical and trabecular surfaces and slowly redistributes over the bone with time. The biological half-life of 241Am is 50 years in the bones and 20 years in the liver, whereas in the gonads (testicles and ovaries) it remains permanently; in all these organs, americium promotes formation of cancer cells as a result of its radioactivity.\nAmericium often enters landfills from discarded smoke detectors. The rules associated with the disposal of smoke detectors are relaxed in most jurisdictions. In 1994, 17-year-old David Hahn extracted the americium from about 100 smoke detectors in an attempt to build a breeder nuclear reactor. There have been a few cases of exposure to americium, the worst case being that of chemical operations technician Harold McCluskey, who at the age of 64 was exposed to 500 times the occupational standard for americium-241 as a result of an explosion in his lab. McCluskey died at the age of 75 of unrelated pre-existing disease."}
{"id": "901", "revid": "37666881", "url": "https://en.wikipedia.org/wiki?curid=901", "title": "Astatine", "text": "Astatine is a chemical element; it has symbol At and atomic number 85. It is the rarest naturally occurring element in the Earth's crust, occurring only as the decay product of various heavier elements. All of astatine's isotopes are short-lived; the most stable is astatine-210, with a half-life of 8.1 hours. Consequently, a solid sample of the element has never been seen, because any macroscopic specimen would be immediately vaporized by the heat of its radioactivity.\nThe bulk properties of astatine are not known with certainty. Many of them have been estimated from its position on the periodic table as a heavier analog of fluorine, chlorine, bromine, and iodine, the four stable halogens. However, astatine also falls roughly along the dividing line between metals and nonmetals, and some metallic behavior has also been observed and predicted for it. Astatine is likely to have a dark or lustrous appearance and may be a semiconductor or possibly a metal. Chemically, several anionic species of astatine are known and most of its compounds resemble those of iodine, but it also sometimes displays metallic characteristics and shows some similarities to silver.\nThe first synthesis of astatine was in 1940 by Dale R. Corson, Kenneth Ross MacKenzie, and Emilio G. Segr\u00e8 at the University of California, Berkeley. They named it from the Ancient Greek () 'unstable'. Four isotopes of astatine were subsequently found to be naturally occurring, although much less than one gram is present at any given time in the Earth's crust. Neither the most stable isotope, astatine-210, nor the medically useful astatine-211 occur naturally; they are usually produced by bombarding bismuth-209 with alpha particles.\nCharacteristics.\nAstatine is an extremely radioactive element; all its isotopes have half-lives of 8.1 hours or less, decaying into other astatine isotopes, bismuth, polonium, or radon. Most of its isotopes are very unstable, with half-lives of seconds or less. Of the first 101 elements in the periodic table, only francium is less stable, and all the astatine isotopes more stable than the longest-lived francium isotopes (205\u2013211At) are in any case synthetic and do not occur in nature.\nThe bulk properties of astatine are not known with any certainty. Research is limited by its short half-life, which prevents the creation of weighable quantities. A visible piece of astatine would immediately vaporize itself because of the heat generated by its intense radioactivity. It remains to be seen if, with sufficient cooling, a macroscopic quantity of astatine could be deposited as a thin film. Astatine is usually classified as either a nonmetal or a metalloid; metal formation has also been predicted.\nPhysical.\nMost of the physical properties of astatine have been estimated (by interpolation or extrapolation), using theoretically or empirically derived methods. For example, halogens get darker with increasing atomic weight\u00a0\u2013 fluorine is nearly colorless, chlorine is yellow-green, bromine is red-brown, and iodine is dark gray/violet. Astatine is sometimes described as probably being a black solid (assuming it follows this trend), or as having a metallic appearance (if it is a metalloid or a metal).\nAstatine sublimes less readily than iodine, having a lower vapor pressure. Even so, half of a given quantity of astatine will vaporize in approximately an hour if put on a clean glass surface at room temperature. The absorption spectrum of astatine in the middle ultraviolet region has lines at 224.401 and 216.225\u00a0nm, suggestive of 6p to 7s transitions.\nThe structure of solid astatine is unknown. As an analog of iodine it may have an orthorhombic crystalline structure composed of diatomic astatine molecules, and be a semiconductor (with a band gap of 0.7\u00a0eV). Alternatively, if condensed astatine forms a metallic phase, as has been predicted, it may have a monatomic face-centered cubic structure; in this structure, it may well be a superconductor, like the similar high-pressure phase of iodine. Metallic astatine is expected to have a density of 8.91\u20138.95\u00a0g/cm3.\nEvidence for (or against) the existence of diatomic astatine (At2) is sparse and inconclusive. Some sources state that it does not exist, or at least has never been observed, while other sources assert or imply its existence. Despite this controversy, many properties of diatomic astatine have been predicted; for example, its bond length would be , dissociation energy &lt;, and heat of vaporization (\u2206Hvap) 54.39\u00a0kJ/mol. Many values have been predicted for the melting and boiling points of astatine, but only for At2.\nChemical.\nThe chemistry of astatine is \"clouded by the extremely low concentrations at which astatine experiments have been conducted, and the possibility of reactions with impurities, walls and filters, or radioactivity by-products, and other unwanted nano-scale interactions\". Many of its apparent chemical properties have been observed using tracer studies on extremely dilute astatine solutions, typically less than 10\u221210 mol\u00b7L\u22121. Some properties, such as anion formation, align with other halogens. Astatine has some metallic characteristics as well, such as plating onto a cathode, and coprecipitating with metal sulfides in hydrochloric acid. It forms complexes with EDTA, a metal chelating agent, and is capable of acting as a metal in antibody radiolabeling; in some respects, astatine in the +1 state is akin to silver in the same state. Most of the organic chemistry of astatine is, however, analogous to that of iodine. It has been suggested that astatine can form a stable monatomic cation in aqueous solution.\nAstatine has an electronegativity of 2.2 on the revised Pauling scale\u00a0\u2013 lower than that of iodine (2.66) and the same as hydrogen. In hydrogen astatide (HAt), the negative charge is predicted to be on the hydrogen atom, implying that this compound could be referred to as astatine hydride according to certain nomenclatures. That would be consistent with the electronegativity of astatine on the Allred\u2013Rochow scale (1.9) being less than that of hydrogen (2.2). However, official IUPAC stoichiometric nomenclature is based on an idealized convention of determining the relative electronegativities of the elements by the mere virtue of their position within the periodic table. According to this convention, astatine is handled as though it is more electronegative than hydrogen, irrespective of its true electronegativity. The electron affinity of astatine, at 233 kJ mol\u22121, is 21% less than that of iodine. In comparison, the value of Cl (349) is 6.4% higher than F (328); Br (325) is 6.9% less than Cl; and I (295) is 9.2% less than Br. The marked reduction for At was predicted as being due to spin\u2013orbit interactions. The first ionization energy of astatine is about 899\u00a0kJ mol\u22121, which continues the trend of decreasing first ionization energies down the halogen group (fluorine, 1681; chlorine, 1251; bromine, 1140; iodine, 1008).\nCompounds.\nLess reactive than iodine, astatine is the least reactive of the halogens; the chemical properties of tennessine, the next-heavier group 17 element, have not yet been investigated, however. Astatine compounds have been synthesized in nano-scale amounts and studied as intensively as possible before their radioactive disintegration. The reactions involved have been typically tested with dilute solutions of astatine mixed with larger amounts of iodine. Acting as a carrier, the iodine ensures there is sufficient material for laboratory techniques (such as filtration and precipitation) to work. Like iodine, astatine has been shown to adopt odd-numbered oxidation states ranging from \u22121 to +7.\nOnly a few compounds with metals have been reported, in the form of astatides of sodium, palladium, silver, thallium, and lead. Some characteristic properties of silver and sodium astatide, and the other hypothetical alkali and alkaline earth astatides, have been estimated by extrapolation from other metal halides.\nThe formation of an astatine compound with hydrogen\u00a0\u2013 usually referred to as hydrogen astatide\u00a0\u2013 was noted by the pioneers of astatine chemistry. As mentioned, there are grounds for instead referring to this compound as astatine hydride. It is easily oxidized; acidification by dilute nitric acid gives the At0 or At+ forms, and the subsequent addition of silver(I) may only partially, at best, precipitate astatine as silver(I) astatide (AgAt). Iodine, in contrast, is not oxidized, and precipitates readily as silver(I) iodide.\nAstatine is known to bind to boron, carbon, and nitrogen. Various boron cage compounds have been prepared with At\u2013B bonds, these being more stable than At\u2013C bonds. Astatine can replace a hydrogen atom in benzene to form astatobenzene C6H5At; this may be oxidized to C6H5AtCl2 by chlorine. By treating this compound with an alkaline solution of hypochlorite, C6H5AtO2 can be produced. The dipyridine-astatine(I) cation, [At(C5H5N)2]+, forms ionic compounds with perchlorate (a non-coordinating anion) and with nitrate, [At(C5H5N)2]NO3. This cation exists as a coordination complex in which two dative covalent bonds separately link the astatine(I) centre with each of the pyridine rings via their nitrogen atoms.\nWith oxygen, there is evidence of the species AtO\u2212 and AtO+ in aqueous solution, formed by the reaction of astatine with an oxidant such as elemental bromine or (in the last case) by sodium persulfate in a solution of perchloric acid. The species previously thought to be has since been determined to be , a hydrolysis product of AtO+ (another such hydrolysis product being AtOOH). The well characterized anion can be obtained by, for example, the oxidation of astatine with potassium hypochlorite in a solution of potassium hydroxide. Preparation of lanthanum triastatate La(AtO3)3, following the oxidation of astatine by a hot Na2S2O8 solution, has been reported. Further oxidation of , such as by xenon difluoride (in a hot alkaline solution) or periodate (in a neutral or alkaline solution), yields the perastatate ion ; this is only stable in neutral or alkaline solutions. Astatine is also thought to be capable of forming cations in salts with oxyanions such as iodate or dichromate; this is based on the observation that, in acidic solutions, monovalent or intermediate positive states of astatine coprecipitate with the insoluble salts of metal cations such as silver(I) iodate or thallium(I) dichromate.\nAstatine may form bonds to the other chalcogens; these include S7At+ and with sulfur, a coordination selenourea compound with selenium, and an astatine\u2013tellurium colloid with tellurium.\nAstatine is known to react with its lighter homologs iodine, bromine, and chlorine in the vapor state; these reactions produce diatomic interhalogen compounds with formulas AtI, AtBr, and AtCl. The first two compounds may also be produced in water\u00a0\u2013 astatine reacts with iodine/iodide solution to form AtI, whereas AtBr requires (aside from astatine) an iodine/iodine monobromide/bromide solution. The excess of iodides or bromides may lead to and ions, or in a chloride solution, they may produce species like or via equilibrium reactions with the chlorides. Oxidation of the element with dichromate (in nitric acid solution) showed that adding chloride turned the astatine into a molecule likely to be either AtCl or AtOCl. Similarly, or may be produced. The polyhalides PdAtI2, CsAtI2, TlAtI2, and PbAtI are known or presumed to have been precipitated. In a plasma ion source mass spectrometer, the ions [AtI]+, [AtBr]+, and [AtCl]+ have been formed by introducing lighter halogen vapors into a helium-filled cell containing astatine, supporting the existence of stable neutral molecules in the plasma ion state. No astatine fluorides have been discovered yet. Their absence has been speculatively attributed to the extreme reactivity of such compounds, including the reaction of an initially formed fluoride with the walls of the glass container to form a non-volatile product. Thus, although the synthesis of an astatine fluoride is thought to be possible, it may require a liquid halogen fluoride solvent, as has already been used for the characterization of radon fluoride.\nHistory.\nIn 1869, when Dmitri Mendeleev published his periodic table, the space under iodine was empty; after Niels Bohr established the physical basis of the classification of chemical elements, it was suggested that the fifth halogen belonged there. Before its officially recognized discovery, it was called \"eka-iodine\" (from Sanskrit \"eka\"\u00a0\u2013 \"one\") to imply it was one space under iodine (in the same manner as eka-silicon, eka-boron, and others). Scientists tried to find it in nature; given its extreme rarity, these attempts resulted in several false discoveries.\nThe first claimed discovery of eka-iodine was made by Fred Allison and his associates at the Alabama Polytechnic Institute (now Auburn University) in 1931. The discoverers named element 85 \"alabamine\", and assigned it the symbol Ab, designations that were used for a few years. In 1934, H. G. MacPherson of University of California, Berkeley disproved Allison's method and the validity of his discovery. There was another claim in 1937, by the chemist Rajendralal De. Working in Dacca in British India (now Dhaka in Bangladesh), he chose the name \"dakin\" for element 85, which he claimed to have isolated as the thorium series equivalent of radium F (polonium-210) in the radium series. The properties he reported for dakin do not correspond to those of astatine, and astatine's radioactivity would have prevented him from handling it in the quantities he claimed. Moreover, astatine is not found in the thorium series, and the true identity of dakin is not known.\nIn 1936, the team of Romanian physicist Horia Hulubei and French physicist Yvette Cauchois claimed to have discovered element 85 by observing its X-ray emission lines. In 1939, they published another paper which supported and extended previous data. In 1944, Hulubei published a summary of data he had obtained up to that time, claiming it was supported by the work of other researchers. He chose the name \"dor\", presumably from the Romanian for \"longing\" [for peace], as World War II had started five years earlier. As Hulubei was writing in French, a language which does not accommodate the \"ine\" suffix, dor would likely have been rendered in English as \"dorine\", had it been adopted. In 1947, Hulubei's claim was effectively rejected by the Austrian chemist Friedrich Paneth, who would later chair the IUPAC committee responsible for recognition of new elements. Even though Hulubei's samples did contain astatine-218, his means to detect it were too weak, by current standards, to enable correct identification; moreover, he could not perform chemical tests on the element. He had also been involved in an earlier false claim as to the discovery of element 87 (francium) and this is thought to have caused other researchers to downplay his work.\nIn 1940, the Swiss chemist Walter Minder announced the discovery of element 85 as the beta decay product of radium A (polonium-218), choosing the name \"helvetium\" (from , the Latin name of Switzerland). Berta Karlik and Traude Bernert were unsuccessful in reproducing his experiments, and subsequently attributed Minder's results to contamination of his radon stream (radon-222 is the parent isotope of polonium-218). In 1942, Minder, in collaboration with the English scientist Alice Leigh-Smith, announced the discovery of another isotope of element 85, presumed to be the product of thorium A (polonium-216) beta decay. They named this substance \"anglo-helvetium\", but Karlik and Bernert were again unable to reproduce these results.\nLater in 1940, Dale R. Corson, Kenneth Ross MacKenzie, and Emilio Segr\u00e8 isolated the element at the University of California, Berkeley. Instead of searching for the element in nature, the scientists created it by bombarding bismuth-209 with alpha particles in a cyclotron (particle accelerator) to produce, after emission of two neutrons, astatine-211. The discoverers, however, did not immediately suggest a name for the element. The reason for this was that at the time, an element created synthetically in \"invisible quantities\" that had not yet been discovered in nature was not seen as a completely valid one; in addition, chemists were reluctant to recognize radioactive isotopes as legitimately as stable ones. In 1943, astatine was found as a product of two naturally occurring decay chains by Berta Karlik and Traude Bernert, first in the so-called uranium series, and then in the actinium series. (Since then, astatine was also found in a third decay chain, the neptunium series.) Friedrich Paneth in 1946 called to finally recognize synthetic elements, quoting, among other reasons, recent confirmation of their natural occurrence, and proposed that the discoverers of the newly discovered unnamed elements name these elements. In early 1947, \"Nature\" published the discoverers' suggestions; a letter from Corson, MacKenzie, and Segr\u00e8 suggested the name \"astatine\" coming from the Ancient Greek () meaning , because of its propensity for radioactive decay, with the ending \"-ine\", found in the names of the four previously discovered halogens. The name was also chosen to continue the tradition of the four stable halogens, where the name referred to a property of the element.\nCorson and his colleagues classified astatine as a metal on the basis of its analytical chemistry. Subsequent investigators reported iodine-like, cationic, or amphoteric behavior. In a 2003 retrospective, Corson wrote that \"some of the properties [of astatine] are similar to iodine\u00a0... it also exhibits metallic properties, more like its metallic neighbors Po and Bi.\"\nIsotopes.\nThere are 41 known isotopes of astatine, with mass numbers of 188 and 190\u2013229. Theoretical modeling suggests that about 37 more isotopes could exist. No stable or long-lived astatine isotope has been observed, nor is one expected to exist.\nAstatine's alpha decay energies follow the same trend as for other heavy elements. Lighter astatine isotopes have quite high energies of alpha decay, which become lower as the nuclei become heavier. Astatine-211 has a significantly higher energy than the previous isotope, because it has a nucleus with 126 neutrons, and 126 is a magic number corresponding to a filled neutron shell. Despite having a similar half-life to the previous isotope (8.1\u00a0hours for astatine-210 and 7.2\u00a0hours for astatine-211), the alpha decay probability is much higher for the latter: 41.81% against only 0.18%. The two following isotopes release even more energy, with astatine-213 releasing the most energy. For this reason, it is the shortest-lived astatine isotope. Even though heavier astatine isotopes release less energy, no long-lived astatine isotope exists, because of the increasing role of beta decay (electron emission). This decay mode is especially important for astatine; as early as 1950 it was postulated that all isotopes of the element undergo beta decay, though nuclear mass measurements indicate that 215At is in fact beta-stable, as it has the lowest mass of all isobars with \"A\"\u00a0=\u00a0215. Astatine-210 and most of the lighter isotopes exhibit beta plus decay (positron emission), astatine-217 and heavier isotopes except astatine-218 exhibit beta minus decay, while astatine-211 undergoes electron capture.\nThe most stable isotope is astatine-210, which has a half-life of 8.1\u00a0hours. The primary decay mode is beta plus, to the relatively long-lived (in comparison to astatine isotopes) alpha emitter polonium-210. In total, only five isotopes have half-lives exceeding one hour (astatine-207 to -211). The least stable ground state isotope is astatine-213, with a half-life of 125 nanoseconds. It undergoes alpha decay to the extremely long-lived bismuth-209.\nAstatine has 24 known nuclear isomers, which are nuclei with one or more nucleons (protons or neutrons) in an excited state. A nuclear isomer may also be called a \"meta-state\", meaning the system has more internal energy than the \"ground state\" (the state with the lowest possible internal energy), making the former likely to decay into the latter. There may be more than one isomer for each isotope. The most stable of these nuclear isomers is astatine-202m1, which has a half-life of about 3 minutes, longer than those of all the ground states bar those of isotopes 203\u2013211 and 220. The least stable is astatine-213m1; its half-life of 110 nanoseconds is shorter than 125 nanoseconds for astatine-213, the shortest-lived ground state.\nNatural occurrence.\nAstatine is the rarest naturally occurring element. The total amount of astatine in the Earth's crust (quoted mass 2.36 \u00d7 1025 grams) is estimated by some to be less than one gram at any given time. Other sources estimate the amount of ephemeral astatine, present on earth at any given moment, to be up to one ounce (about 28 grams).\nAny astatine present at the formation of the Earth has long since disappeared; the four naturally occurring isotopes (astatine-215, -217, -218 and -219) are instead continuously produced as a result of the decay of radioactive thorium and uranium ores, and trace quantities of neptunium-237. The landmass of North and South America combined, to a depth of 16 kilometers (10 miles), contains only about one trillion astatine-215 atoms at any given time (around 3.5 \u00d7 10\u221210 grams). Astatine-217 is produced via the radioactive decay of neptunium-237. Primordial remnants of the latter isotope\u2014due to its relatively short half-life of 2.14 million years\u2014are no longer present on Earth. However, trace amounts occur naturally as a product of transmutation reactions in uranium ores. Astatine-218 was the first astatine isotope discovered in nature. Astatine-219, with a half-life of 56 seconds, is the longest lived of the naturally occurring isotopes.\nIsotopes of astatine are sometimes not listed as naturally occurring because of misconceptions that there are no such isotopes, or discrepancies in the literature. Astatine-216 has been counted as a naturally occurring isotope but reports of its observation (which were described as doubtful) have not been confirmed.\nSynthesis.\nFormation.\nAstatine was first produced by bombarding bismuth-209 with energetic alpha particles, and this is still the major route used to create the relatively long-lived isotopes astatine-209 through astatine-211. Astatine is only produced in minuscule quantities, with modern techniques allowing production runs of up to 6.6\u00a0gigabecquerels (about 86\u00a0nanograms or 2.47 atoms). Synthesis of greater quantities of astatine using this method is constrained by the limited availability of suitable cyclotrons and the prospect of melting the target. Solvent radiolysis due to the cumulative effect of astatine decay is a related problem. With cryogenic technology, microgram quantities of astatine might be able to be generated via proton irradiation of thorium or uranium to yield radon-211, in turn decaying to astatine-211. Contamination with astatine-210 is expected to be a drawback of this method.\nThe most important isotope is astatine-211, the only one in commercial use. To produce the bismuth target, the metal is sputtered onto a gold, copper, or aluminium surface at 50 to 100 milligrams per square centimeter. Bismuth oxide can be used instead; this is forcibly fused with a copper plate. The target is kept under a chemically neutral nitrogen atmosphere, and is cooled with water to prevent premature astatine vaporization. In a particle accelerator, such as a cyclotron, alpha particles are collided with the bismuth. Even though only one bismuth isotope is used (bismuth-209), the reaction may occur in three possible ways, producing astatine-209, astatine-210, or astatine-211. Although higher energies can produce more astatine-211, it will produce unwanted astatine-210 that decays to toxic polonium-210 as well. Instead, the maximum energy of the particle accelerator is set to be below or slightly above the threshold of astatine-210 production, in order to maximize the production of astatine-211 while keeping the amount of astatine-210 at an acceptable level.\nSeparation methods.\nSince astatine is the main product of the synthesis, after its formation it must only be separated from the target and any significant contaminants. Several methods are available, \"but they generally follow one of two approaches\u2014dry distillation or [wet] acid treatment of the target followed by solvent extraction.\" The methods summarized below are modern adaptations of older procedures, as reviewed by Kugler and Keller. Pre-1985 techniques more often addressed the elimination of co-produced toxic polonium; this requirement is now mitigated by capping the energy of the cyclotron irradiation beam.\nDry.\nThe astatine-containing cyclotron target is heated to a temperature of around 650\u00a0\u00b0C. The astatine volatilizes and is condensed in (typically) a cold trap. Higher temperatures of up to around 850\u00a0\u00b0C may increase the yield, at the risk of bismuth contamination from concurrent volatilization. Redistilling the condensate may be required to minimize the presence of bismuth (as bismuth can interfere with astatine labeling reactions). The astatine is recovered from the trap using one or more low concentration solvents such as sodium hydroxide, methanol or chloroform. Astatine yields of up to around 80% may be achieved. Dry separation is the method most commonly used to produce a chemically useful form of astatine.\nWet.\nThe irradiated bismuth (or sometimes bismuth trioxide) target is first dissolved in, for example, concentrated nitric or perchloric acid. Following this first step, the acid can be distilled away to leave behind a white residue that contains both bismuth and the desired astatine product. This residue is then dissolved in a concentrated acid, such as hydrochloric acid. Astatine is extracted from this acid using an organic solvent such as dibutyl ether, diisopropyl ether (DIPE), or thiosemicarbazide. Using liquid-liquid extraction, the astatine product can be repeatedly washed with an acid, such as HCl, and extracted into the organic solvent layer. A separation yield of 93% using nitric acid has been reported, falling to 72% by the time purification procedures were completed (distillation of nitric acid, purging residual nitrogen oxides, and redissolving bismuth nitrate to enable liquid\u2013liquid extraction). Wet methods involve \"multiple radioactivity handling steps\" and have not been considered well suited for isolating larger quantities of astatine. However, wet extraction methods are being examined for use in production of larger quantities of astatine-211, as it is thought that wet extraction methods can provide more consistency. They can enable the production of astatine in a specific oxidation state and may have greater applicability in experimental radiochemistry.\nUses and precautions.\nNewly formed astatine-211 is the subject of ongoing research in nuclear medicine. It must be used quickly as it decays with a half-life of 7.2\u00a0hours; this is long enough to permit multistep labeling strategies. Astatine-211 has potential for targeted alpha-particle therapy, since it decays either via emission of an alpha particle (to bismuth-207), or via electron capture (to an extremely short-lived nuclide, polonium-211, which undergoes further alpha decay), very quickly reaching its stable granddaughter lead-207. Polonium X-rays emitted as a result of the electron capture branch, in the range of 77\u201392\u00a0keV, enable the tracking of astatine in animals and patients. Although astatine-210 has a slightly longer half-life, it is wholly unsuitable because it usually undergoes beta plus decay to the extremely toxic polonium-210.\nThe principal medicinal difference between astatine-211 and iodine-131 (a radioactive iodine isotope also used in medicine) is that iodine-131 emits high-energy beta particles, and astatine does not. Beta particles have much greater penetrating power through tissues than do the much heavier alpha particles. An average alpha particle released by astatine-211 can travel up to 70\u00a0\u03bcm through surrounding tissues; an average-energy beta particle emitted by iodine-131 can travel nearly 30 times as far, to about 2\u00a0mm. The short half-life and limited penetrating power of alpha radiation through tissues offers advantages in situations where the \"tumor burden is low and/or malignant cell populations are located in close proximity to essential normal tissues.\" Significant morbidity in cell culture models of human cancers has been achieved with from one to ten astatine-211 atoms bound per cell.\nSeveral obstacles have been encountered in the development of astatine-based radiopharmaceuticals for cancer treatment. World War II delayed research for close to a decade. Results of early experiments indicated that a cancer-selective carrier would need to be developed and it was not until the 1970s that monoclonal antibodies became available for this purpose. Unlike iodine, astatine shows a tendency to dehalogenate from molecular carriers such as these, particularly at sp3 carbon sites (less so from sp2 sites). Given the toxicity of astatine accumulated and retained in the body, this emphasized the need to ensure it remained attached to its host molecule. While astatine carriers that are slowly metabolized can be assessed for their efficacy, more rapidly metabolized carriers remain a significant obstacle to the evaluation of astatine in nuclear medicine. Mitigating the effects of astatine-induced radiolysis of labeling chemistry and carrier molecules is another area requiring further development. A practical application for astatine as a cancer treatment would potentially be suitable for a \"staggering\" number of patients; production of astatine in the quantities that would be required remains an issue.\nAnimal studies show that astatine, similarly to iodine\u2014although to a lesser extent, perhaps because of its slightly more metallic nature\u2014is preferentially (and dangerously) concentrated in the thyroid gland. Unlike iodine, astatine also shows a tendency to be taken up by the lungs and spleen, possibly because of in-body oxidation of At\u2013 to At+. If administered in the form of a radiocolloid it tends to concentrate in the liver. Experiments in rats and monkeys suggest that astatine-211 causes much greater damage to the thyroid gland than does iodine-131, with repetitive injection of the nuclide resulting in necrosis and cell dysplasia within the gland. Early research suggested that injection of astatine into female rodents caused morphological changes in breast tissue; this conclusion remained controversial for many years. General agreement was later reached that this was likely caused by the effect of breast tissue irradiation combined with hormonal changes due to irradiation of the ovaries. Trace amounts of astatine can be handled safely in fume hoods if they are well-aerated; biological uptake of the element must be avoided."}
{"id": "902", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=902", "title": "Atom", "text": "Atoms are the basic particles of the chemical elements. An atom consists of a nucleus of protons and generally neutrons, surrounded by an electromagnetically bound swarm of electrons. The chemical elements are distinguished from each other by the number of protons that are in their atoms. For example, any atom that contains 11 protons is sodium, and any atom that contains 29 protons is copper. Atoms with the same number of protons but a different number of neutrons are called isotopes of the same element.\nAtoms are extremely small, typically around 100\u00a0picometers across. A human hair is about a million carbon atoms wide. Atoms are smaller than the shortest wavelength of visible light, which means humans cannot see atoms with conventional microscopes. They are so small that accurately predicting their behavior using classical physics is not possible due to quantum effects.\nMore than 99.9994% of an atom's mass is in the nucleus. Protons have a positive electric charge and neutrons have no charge, so the nucleus is positively charged. The electrons are negatively charged, and this opposing charge is what binds them to the nucleus. If the numbers of protons and electrons are equal, as they normally are, then the atom is electrically neutral as a whole. If an atom has more electrons than protons, then it has an overall negative charge and is called a negative ion (or anion). Conversely, if it has more protons than electrons, it has a positive charge and is called a positive ion (or cation).\nThe electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.\nAtoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to attach and detach from each other is responsible for most of the physical changes observed in nature. Chemistry is the science that studies these changes.\nHistory of atomic theory.\nIn philosophy.\nThe basic idea that matter is made up of tiny indivisible particles is an old idea that appeared in many ancient cultures. The word \"atom\" is derived from the ancient Greek word \"atomos\", which means \"uncuttable\". But this ancient idea was based in philosophical reasoning rather than scientific reasoning. Modern atomic theory is not based on these old concepts. In the early 19th century, the scientist John Dalton found evidence that matter really is composed of discrete units, and so applied the word \"atom\" to those units.\nDalton's law of multiple proportions.\nIn the early 1800s, John Dalton compiled experimental data gathered by him and other scientists and discovered a pattern now known as the \"law of multiple proportions\". He noticed that in any group of chemical compounds which all contain two particular chemical elements, the amount of Element A per measure of Element B will differ across these compounds by ratios of small whole numbers. This pattern suggested that each element combines with other elements in multiples of a basic unit of weight, with each element having a unit of unique weight. Dalton decided to call these units \"atoms\".\nFor example, there are two types of tin oxide: one is a grey powder that is 88.1% tin and 11.9% oxygen, and the other is a white powder that is 78.7% tin and 21.3% oxygen. Adjusting these figures, in the grey powder there is about 13.5\u00a0g of oxygen for every 100\u00a0g of tin, and in the white powder there is about 27\u00a0g of oxygen for every 100\u00a0g of tin. 13.5 and 27 form a ratio of 1:2. Dalton concluded that in the grey oxide there is one atom of oxygen for every atom of tin, and in the white oxide there are two atoms of oxygen for every atom of tin (SnO and SnO2).\nDalton also analyzed iron oxides. There is one type of iron oxide that is a black powder which is 78.1% iron and 21.9% oxygen; and there is another iron oxide that is a red powder which is 70.4% iron and 29.6% oxygen. Adjusting these figures, in the black powder there is about 28\u00a0g of oxygen for every 100\u00a0g of iron, and in the red powder there is about 42\u00a0g of oxygen for every 100\u00a0g of iron. 28 and 42 form a ratio of 2:3. Dalton concluded that in these oxides, for every two atoms of iron, there are two or three atoms of oxygen respectively (Fe2O2 and Fe2O3).\nAs a final example: nitrous oxide is 63.3% nitrogen and 36.7% oxygen, nitric oxide is 44.05% nitrogen and 55.95% oxygen, and nitrogen dioxide is 29.5% nitrogen and 70.5% oxygen. Adjusting these figures, in nitrous oxide there is 80\u00a0g of oxygen for every 140\u00a0g of nitrogen, in nitric oxide there is about 160\u00a0g of oxygen for every 140\u00a0g of nitrogen, and in nitrogen dioxide there is 320\u00a0g of oxygen for every 140\u00a0g of nitrogen. 80, 160, and 320 form a ratio of 1:2:4. The respective formulas for these oxides are N2O, NO, and NO2.\nDiscovery of the electron.\nIn 1897, J. J. Thomson discovered that cathode rays can be deflected by electric and magnetic fields, which meant that cathode rays are not a form of light but made of electrically charged particles, and their charge was negative given the direction the particles were deflected in. He measured these particles to be 1,700 times lighter than hydrogen (the lightest atom). He called these new particles \"corpuscles\" but they were later renamed \"electrons\" since these are the particles that carry electricity. Thomson also showed that electrons were identical to particles given off by photoelectric and radioactive materials. Thomson explained that an electric current is the passing of electrons from one atom to the next, and when there was no current the electrons embedded themselves in the atoms. This in turn meant that atoms were not indivisible as scientists thought. The atom was composed of electrons whose negative charge was balanced out by some source of positive charge to create an electrically neutral atom. Ions, Thomson explained, must be atoms which have an excess or shortage of electrons.\nDiscovery of the nucleus.\nThe electrons in the atom logically had to be balanced out by a commensurate amount of positive charge, but Thomson had no idea where this positive charge came from, so he tentatively proposed that it was everywhere in the atom, the atom being in the shape of a sphere. This was the mathematically simplest hypothesis to fit the available evidence, or lack thereof. Following from this, Thomson imagined that the balance of electrostatic forces would distribute the electrons throughout the sphere in a more or less even manner. Thomson's model is popularly known as the plum pudding model, though neither Thomson nor his colleagues used this analogy. Thomson's model was incomplete, it was unable to predict any other properties of the elements such as emission spectra and valencies. It was soon rendered obsolete by the discovery of the atomic nucleus.\nBetween 1908 and 1913, Ernest Rutherford and his colleagues Hans Geiger and Ernest Marsden performed a series of experiments in which they bombarded thin foils of metal with a beam of alpha particles. They did this to measure the scattering patterns of the alpha particles. They spotted a small number of alpha particles being deflected by angles greater than 90\u00b0. This shouldn't have been possible according to the Thomson model of the atom, whose charges were too diffuse to produce a sufficiently strong electric field. The deflections should have all been negligible. Rutherford proposed that the positive charge of the atom is concentrated in a tiny volume at the center of the atom and that the electrons surround this nucleus in a diffuse cloud. This nucleus carried almost all of the atom's mass, the electrons being so very light. Only such an intense concentration of charge, anchored by its high mass, could produce an electric field that could deflect the alpha particles so strongly.\nBohr model.\nA problem in classical mechanics is that an accelerating charged particle radiates electromagnetic radiation, causing the particle to lose kinetic energy. Circular motion counts as acceleration, which means that an electron orbiting a central charge should spiral down into that nucleus as it loses speed. In 1913, the physicist Niels Bohr proposed a new model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons' orbits are stable and why elements absorb and emit electromagnetic radiation in discrete spectra. Bohr's model could only predict the emission spectra of hydrogen, not atoms with more than one electron.\nDiscovery of protons and neutrons.\nBack in 1815, William Prout observed that the atomic weights of many elements were multiples of hydrogen's atomic weight, which is in fact true for all of them if one takes isotopes into account. In 1898, J. J. Thomson found that the positive charge of a hydrogen ion is equal to the negative charge of an electron, and these were then the smallest known charged particles. Thomson later found that the positive charge in an atom is a positive multiple of an electron's negative charge. In 1913, Henry Moseley discovered that the frequencies of X-ray emissions from an excited atom were a mathematical function of its atomic number and hydrogen's nuclear charge. In 1919 Rutherford bombarded nitrogen gas with alpha particles and detected hydrogen ions being emitted from the gas, and concluded that they were produced by alpha particles hitting and splitting the nuclei of the nitrogen atoms.\nThese observations led Rutherford to conclude that the hydrogen nucleus is a singular particle with a positive charge equal to the electron's negative charge. He named this particle \"proton\" in 1920. The number of protons in an atom (which Rutherford called the \"atomic number\") was found to be equal to the element's ordinal number on the periodic table and therefore provided a simple and clear-cut way of distinguishing the elements from each other. The atomic weight of each element is higher than its proton number, so Rutherford hypothesized that the surplus weight was carried by unknown particles with no electric charge and a mass equal to that of the proton.\nIn 1928, Walter Bothe observed that beryllium emitted a highly penetrating, electrically neutral radiation when bombarded with alpha particles. It was later discovered that this radiation could knock hydrogen atoms out of paraffin wax. Initially it was thought to be high-energy gamma radiation, since gamma radiation had a similar effect on electrons in metals, but James Chadwick found that the ionization effect was too strong for it to be due to electromagnetic radiation, so long as energy and momentum were conserved in the interaction. In 1932, Chadwick exposed various elements, such as hydrogen and nitrogen, to the mysterious \"beryllium radiation\", and by measuring the energies of the recoiling charged particles, he deduced that the radiation was actually composed of electrically neutral particles which could not be massless like the gamma ray, but instead were required to have a mass similar to that of a proton. Chadwick now claimed these particles as Rutherford's neutrons.\nThe current consensus model.\nIn 1925, Werner Heisenberg published the first consistent mathematical formulation of quantum mechanics (matrix mechanics). One year earlier, Louis de Broglie had proposed that all particles behave like waves to some extent, and in 1926 Erwin Schroedinger used this idea to develop the Schroedinger equation, which describes electrons as three-dimensional waveforms rather than points in space. A consequence of using waveforms to describe particles is that it is mathematically impossible to obtain precise values for both the position and momentum of a particle at a given point in time. This became known as the uncertainty principle, formulated by Werner Heisenberg in 1927. In this concept, for a given accuracy in measuring a position one could only obtain a range of probable values for momentum, and vice versa. Thus, the planetary model of the atom was discarded in favor of one that described atomic orbital zones around the nucleus where a given electron is most likely to be found. This model was able to explain observations of atomic behavior that previous models could not, such as certain structural and spectral patterns of atoms larger than hydrogen.\nStructure.\nSubatomic particles.\nThough the word \"atom\" originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom are the electron, the proton and the neutron.\nThe electron is the least massive of these particles by four orders of magnitude at , with a negative electrical charge and a size that is too small to be measured using available techniques. It was the lightest particle with a positive rest mass measured, until the discovery of neutrino mass. Under ordinary conditions, electrons are bound to the positively charged nucleus by the attraction created from opposite electric charges. If an atom has more or fewer electrons than its atomic number, then it becomes respectively negatively or positively charged as a whole; a charged atom is called an ion. Electrons have been known since the late 19th century, mostly thanks to J.J. Thomson; see history of subatomic physics for details.\nProtons have a positive charge and a mass of . The number of protons in an atom is called its atomic number. Ernest Rutherford (1919) observed that nitrogen under alpha-particle bombardment ejects what appeared to be hydrogen nuclei. By 1920 he had accepted that the hydrogen nucleus is a distinct particle within the atom and named it proton.\nNeutrons have no electrical charge and have a mass of . Neutrons are the heaviest of the three constituent particles, but their mass can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions\u2014on the order of \u2014although the 'surface' of these particles is not sharply defined. The neutron was discovered in 1932 by the English physicist James Chadwick.\nIn the Standard Model of physics, electrons are truly elementary particles with no internal structure, whereas protons and neutrons are composite particles composed of elementary particles called quarks. There are two types of quarks in atoms, each having a fractional electric charge. Protons are composed of two up quarks (each with charge +) and one down quark (with a charge of \u2212). Neutrons consist of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles.\nThe quarks are held together by the strong interaction (or strong force), which is mediated by gluons. The protons and neutrons, in turn, are held to each other in the nucleus by the nuclear force, which is a residuum of the strong force that has somewhat different range-properties (see the article on the nuclear force for more). The gluon is a member of the family of gauge bosons, which are elementary particles that mediate physical forces.\nNucleus.\nAll the bound protons and neutrons in an atom make up a tiny atomic nucleus, and are collectively called nucleons. The radius of a nucleus is approximately equal to formula_1\u00a0femtometres, where formula_2 is the total number of nucleons. This is much smaller than the radius of the atom, which is on the order of 105\u00a0fm. The nucleons are bound together by a short-ranged attractive potential called the residual strong force. At distances smaller than 2.5 fm this force is much more powerful than the electrostatic force that causes positively charged protons to repel each other.\nAtoms of the same element have the same number of protons, called the atomic number. Within a single element, the number of neutrons may vary, determining the isotope of that element. The total number of protons and neutrons determine the nuclide. The number of neutrons relative to the protons determines the stability of the nucleus, with certain isotopes undergoing radioactive decay.\nThe proton, the electron, and the neutron are classified as fermions. Fermions obey the Pauli exclusion principle which prohibits \"identical\" fermions, such as multiple protons, from occupying the same quantum state at the same time. Thus, every proton in the nucleus must occupy a quantum state different from all other protons, and the same applies to all neutrons of the nucleus and to all electrons of the electron cloud.\nA nucleus that has a different number of protons than neutrons can potentially drop to a lower energy state through a radioactive decay that causes the number of protons and neutrons to more closely match. As a result, atoms with matching numbers of protons and neutrons are more stable against decay, but with increasing atomic number, the mutual repulsion of the protons requires an increasing proportion of neutrons to maintain the stability of the nucleus.\nThe number of protons and neutrons in the atomic nucleus can be modified, although this can require very high energies because of the strong force. Nuclear fusion occurs when multiple atomic particles join to form a heavier nucleus, such as through the energetic collision of two nuclei. For example, at the core of the Sun protons require energies of 3 to 10 keV to overcome their mutual repulsion\u2014the coulomb barrier\u2014and fuse together into a single nucleus. Nuclear fission is the opposite process, causing a nucleus to split into two smaller nuclei\u2014usually through radioactive decay. The nucleus can also be modified through bombardment by high energy subatomic particles or photons. If this modifies the number of protons in a nucleus, the atom changes to a different chemical element.\nIf the mass of the nucleus following a fusion reaction is less than the sum of the masses of the separate particles, then the difference between these two values can be emitted as a type of usable energy (such as a gamma ray, or the kinetic energy of a beta particle), as described by Albert Einstein's mass\u2013energy equivalence formula, \"E=mc2\", where \"m\" is the mass loss and \"c\" is the speed of light. This deficit is part of the binding energy of the new nucleus, and it is the non-recoverable loss of the energy that causes the fused particles to remain together in a state that requires this energy to separate.\nThe fusion of two nuclei that create larger nuclei with lower atomic numbers than iron and nickel\u2014a total nucleon number of about 60\u2014is usually an exothermic process that releases more energy than is required to bring them together. It is this energy-releasing process that makes nuclear fusion in stars a self-sustaining reaction. For heavier nuclei, the binding energy per nucleon begins to decrease. That means that a fusion process producing a nucleus that has an atomic number higher than about 26, and a mass number higher than about 60, is an endothermic process. Thus, more massive nuclei cannot undergo an energy-producing fusion reaction that can sustain the hydrostatic equilibrium of a star.\nElectron cloud.\nThe electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons inside an electrostatic potential well surrounding the smaller nucleus, which means that an external source of energy is needed for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence electrons bound near the center of the potential well require more energy to escape than those at greater separations.\nElectrons, like other particles, have properties of both a particle and a wave. The electron cloud is a region inside the potential well where each electron forms a type of three-dimensional standing wave\u2014a wave form that does not move relative to the nucleus. This behavior is defined by an atomic orbital, a mathematical function that characterises the probability that an electron appears to be at a particular location when its position is measured. Only a discrete (or quantized) set of these orbitals exist around the nucleus, as other possible wave patterns rapidly decay into a more stable form. Orbitals can have one or more ring or node structures, and differ from each other in size, shape and orientation.\nEach atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing a photon with sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy as a photon. These characteristic energy values, defined by the differences in the energies of the quantum states, are responsible for atomic spectral lines.\nThe amount of energy needed to remove or add an electron\u2014the electron binding energy\u2014is far less than the binding energy of nucleons. For example, it requires only 13.6\u00a0eV to strip a ground-state electron from a hydrogen atom, compared to 2.23\u00a0\"million\" eV for splitting a deuterium nucleus. Atoms are electrically neutral if they have an equal number of protons and electrons. Atoms that have either a deficit or a surplus of electrons are called ions. Electrons that are farthest from the nucleus may be transferred to other nearby atoms or shared between atoms. By this mechanism, atoms are able to bond into molecules and other types of chemical compounds like ionic and covalent network crystals.\nProperties.\nNuclear properties.\nBy definition, any two atoms with an identical number of \"protons\" in their nuclei belong to the same chemical element. Atoms with equal numbers of protons but a different number of \"neutrons\" are different isotopes of the same element. For example, all hydrogen atoms admit exactly one proton, but isotopes exist with no neutrons (hydrogen-1, by far the most common form, also called protium), one neutron (deuterium), two neutrons (tritium) and more than two neutrons. The known elements form a set of atomic numbers, from the single-proton element hydrogen up to the 118-proton element oganesson. All known isotopes of elements with atomic numbers greater than 82 are radioactive, although the radioactivity of element 83 (bismuth) is so slight as to be practically negligible.\nAbout 339 nuclides occur naturally on Earth, of which 251 (about 74%) have not been observed to decay, and are referred to as \"stable isotopes\". Only 90 nuclides are stable theoretically, while another 161 (bringing the total to 251) have not been observed to decay, even though in theory it is energetically possible. These are also formally classified as \"stable\". An additional 35 radioactive nuclides have half-lives longer than 100 million years, and are long-lived enough to have been present since the birth of the Solar System. This collection of 286 nuclides are known as primordial nuclides. Finally, an additional 53 short-lived nuclides are known to occur naturally, as daughter products of primordial nuclide decay (such as radium from uranium), or as products of natural energetic processes on Earth, such as cosmic ray bombardment (for example, carbon-14).\nFor 80 of the chemical elements, at least one stable isotope exists. As a rule, there is only a handful of stable isotopes for each of these elements, the average being 3.1 stable isotopes per element. Twenty-six \"monoisotopic elements\" have only a single stable isotope, while the largest number of stable isotopes observed for any element is ten, for the element tin. Elements 43, 61, and all elements numbered 83 or higher have no stable isotopes.\nStability of isotopes is affected by the ratio of protons to neutrons, and also by the presence of certain \"magic numbers\" of neutrons or protons that represent closed and filled quantum shells. These quantum shells correspond to a set of energy levels within the shell model of the nucleus; filled shells, such as the filled shell of 50 protons for tin, confers unusual stability on the nuclide. Of the 251 known stable nuclides, only four have both an odd number of protons \"and\" odd number of neutrons: hydrogen-2 (deuterium), lithium-6, boron-10, and nitrogen-14. (Tantalum-180m is odd-odd and observationally stable, but is predicted to decay with a very long half-life.) Also, only four naturally occurring, radioactive odd-odd nuclides have a half-life over a billion years: potassium-40, vanadium-50, lanthanum-138, and lutetium-176. Most odd-odd nuclei are highly unstable with respect to beta decay, because the decay products are even-even, and are therefore more strongly bound, due to nuclear pairing effects.\nMass.\nThe large majority of an atom's mass comes from the protons and neutrons that make it up. The total number of these particles (called \"nucleons\") in a given atom is called the mass number. It is a positive integer and dimensionless (instead of having dimension of mass), because it expresses a count. An example of use of a mass number is \"carbon-12,\" which has 12 nucleons (six protons and six neutrons).\nThe actual mass of an atom at rest is often expressed in daltons (Da), also called the unified atomic mass unit (u). This unit is defined as a twelfth of the mass of a free neutral atom of carbon-12, which is approximately . Hydrogen-1 (the lightest isotope of hydrogen which is also the nuclide with the lowest mass) has an atomic weight of 1.007825\u00a0Da. The value of this number is called the atomic mass. A given atom has an atomic mass approximately equal (within 1%) to its mass number times the atomic mass unit (for example the mass of a nitrogen-14 is roughly 14\u00a0Da), but this number will not be exactly an integer except (by definition) in the case of carbon-12. The heaviest stable atom is lead-208, with a mass of .\nAs even the most massive atoms are far too light to work with directly, chemists instead use the unit of moles. One mole of atoms of any element always has the same number of atoms (about ). This number was chosen so that if an element has an atomic mass of 1\u00a0u, a mole of atoms of that element has a mass close to one gram. Because of the definition of the unified atomic mass unit, each carbon-12 atom has an atomic mass of exactly 12\u00a0Da, and so a mole of carbon-12 atoms weighs exactly 0.012\u00a0kg.\nShape and size.\nAtoms lack a well-defined outer boundary, so their dimensions are usually described in terms of an atomic radius. This is a measure of the distance out to which the electron cloud extends from the nucleus. This assumes the atom to exhibit a spherical shape, which is only obeyed for atoms in vacuum or free space. Atomic radii may be derived from the distances between two nuclei when the two atoms are joined in a chemical bond. The radius varies with the location of an atom on the atomic chart, the type of chemical bond, the number of neighboring atoms (coordination number) and a quantum mechanical property known as spin. On the periodic table of the elements, atom size tends to increase when moving down columns, but decrease when moving across rows (left to right). Consequently, the smallest atom is helium with a radius of 32\u00a0pm, while one of the largest is caesium at 225\u00a0pm.\nWhen subjected to external forces, like electrical fields, the shape of an atom may deviate from spherical symmetry. The deformation depends on the field magnitude and the orbital type of outer shell electrons, as shown by group-theoretical considerations. Aspherical deviations might be elicited for instance in crystals, where large crystal-electrical fields may occur at low-symmetry lattice sites. Significant ellipsoidal deformations have been shown to occur for sulfur ions and chalcogen ions in pyrite-type compounds.\nAtomic dimensions are thousands of times smaller than the wavelengths of light (400\u2013700\u00a0nm) so they cannot be viewed using an optical microscope, although individual atoms can be observed using a scanning tunneling microscope. To visualize the minuteness of the atom, consider that a typical human hair is about 1\u00a0million carbon atoms in width. A single drop of water contains about 2\u00a0sextillion () atoms of oxygen, and twice the number of hydrogen atoms. A single carat diamond with a mass of contains about 10\u00a0sextillion (1022) atoms of carbon. If an apple were magnified to the size of the Earth, then the atoms in the apple would be approximately the size of the original apple.\nRadioactive decay.\nEvery element has one or more isotopes that have unstable nuclei that are subject to radioactive decay, causing the nucleus to emit particles or electromagnetic radiation. Radioactivity can occur when the radius of a nucleus is large compared with the radius of the strong force, which only acts over distances on the order of 1\u00a0fm.\nThe most common forms of radioactive decay are:\nOther more rare types of radioactive decay include ejection of neutrons or protons or clusters of nucleons from a nucleus, or more than one beta particle. An analog of gamma emission which allows excited nuclei to lose energy in a different way, is internal conversion\u2014a process that produces high-speed electrons that are not beta rays, followed by production of high-energy photons that are not gamma rays. A few large nuclei explode into two or more charged fragments of varying masses plus several neutrons, in a decay called spontaneous nuclear fission.\nEach radioactive isotope has a characteristic decay time period\u2014the half-life\u2014that is determined by the amount of time needed for half of a sample to decay. This is an exponential decay process that steadily decreases the proportion of the remaining isotope by 50% every half-life. Hence after two half-lives have passed only 25% of the isotope is present, and so forth.\nMagnetic moment.\nElementary particles possess an intrinsic quantum mechanical property known as spin. This is analogous to the angular momentum of an object that is spinning around its center of mass, although strictly speaking these particles are believed to be point-like and cannot be said to be rotating. Spin is measured in units of the reduced Planck constant (\u0127), with electrons, protons and neutrons all having spin \u00a0\u0127, or \"spin-\". In an atom, electrons in motion around the nucleus possess orbital angular momentum in addition to their spin, while the nucleus itself possesses angular momentum due to its nuclear spin.\nThe magnetic field produced by an atom\u2014its magnetic moment\u2014is determined by these various forms of angular momentum, just as a rotating charged object classically produces a magnetic field, but the most dominant contribution comes from electron spin. Due to the nature of electrons to obey the Pauli exclusion principle, in which no two electrons may be found in the same quantum state, bound electrons pair up with each other, with one member of each pair in a spin up state and the other in the opposite, spin down state. Thus these spins cancel each other out, reducing the total magnetic dipole moment to zero in some atoms with even number of electrons.\nIn ferromagnetic elements such as iron, cobalt and nickel, an odd number of electrons leads to an unpaired electron and a net overall magnetic moment. The orbitals of neighboring atoms overlap and a lower energy state is achieved when the spins of unpaired electrons are aligned with each other, a spontaneous process known as an exchange interaction. When the magnetic moments of ferromagnetic atoms are lined up, the material can produce a measurable macroscopic field. Paramagnetic materials have atoms with magnetic moments that line up in random directions when no magnetic field is present, but the magnetic moments of the individual atoms line up in the presence of a field.\nThe nucleus of an atom will have no spin when it has even numbers of both neutrons and protons, but for other cases of odd numbers, the nucleus may have a spin. Normally nuclei with spin are aligned in random directions because of thermal equilibrium, but for certain elements (such as xenon-129) it is possible to polarize a significant proportion of the nuclear spin states so that they are aligned in the same direction\u2014a condition called hyperpolarization. This has important applications in magnetic resonance imaging.\nEnergy levels.\nThe potential energy of an electron in an atom is negative relative to when the distance from the nucleus goes to infinity; its dependence on the electron's position reaches the minimum inside the nucleus, roughly in inverse proportion to the distance. In the quantum-mechanical model, a bound electron can occupy only a set of states centered on the nucleus, and each state corresponds to a specific energy level; see time-independent Schr\u00f6dinger equation for a theoretical explanation. An energy level can be measured by the amount of energy needed to unbind the electron from the atom, and is usually given in units of electronvolts (eV). The lowest energy state of a bound electron is called the ground state, i.e. stationary state, while an electron transition to a higher level results in an excited state. The electron's energy increases along with \"n\" because the (average) distance to the nucleus increases. Dependence of the energy on is caused not by the electrostatic potential of the nucleus, but by interaction between electrons.\nFor an electron to transition between two different states, e.g. ground state to first excited state, it must absorb or emit a photon at an energy matching the difference in the potential energy of those levels, according to the Niels Bohr model, what can be precisely calculated by the Schr\u00f6dinger equation.\nElectrons jump between orbitals in a particle-like fashion. For example, if a single photon strikes the electrons, only a single electron changes states in response to the photon; see Electron properties.\nThe energy of an emitted photon is proportional to its frequency, so these specific energy levels appear as distinct bands in the electromagnetic spectrum. Each element has a characteristic spectrum that can depend on the nuclear charge, subshells filled by electrons, the electromagnetic interactions between the electrons and other factors.\nWhen a continuous spectrum of energy is passed through a gas or plasma, some of the photons are absorbed by atoms, causing electrons to change their energy level. Those excited electrons that remain bound to their atom spontaneously emit this energy as a photon, traveling in a random direction, and so drop back to lower energy levels. Thus the atoms behave like a filter that forms a series of dark absorption bands in the energy output. (An observer viewing the atoms from a view that does not include the continuous spectrum in the background, instead sees a series of emission lines from the photons emitted by the atoms.) Spectroscopic measurements of the strength and width of atomic spectral lines allow the composition and physical properties of a substance to be determined.\nClose examination of the spectral lines reveals that some display a fine structure splitting. This occurs because of spin\u2013orbit coupling, which is an interaction between the spin and motion of the outermost electron. When an atom is in an external magnetic field, spectral lines become split into three or more components; a phenomenon called the Zeeman effect. This is caused by the interaction of the magnetic field with the magnetic moment of the atom and its electrons. Some atoms can have multiple electron configurations with the same energy level, which thus appear as a single spectral line. The interaction of the magnetic field with the atom shifts these electron configurations to slightly different energy levels, resulting in multiple spectral lines. The presence of an external electric field can cause a comparable splitting and shifting of spectral lines by modifying the electron energy levels, a phenomenon called the Stark effect.\nIf a bound electron is in an excited state, an interacting photon with the proper energy can cause stimulated emission of a photon with a matching energy level. For this to occur, the electron must drop to a lower energy state that has an energy difference matching the energy of the interacting photon. The emitted photon and the interacting photon then move off in parallel and with matching phases. That is, the wave patterns of the two photons are synchronized. This physical property is used to make lasers, which can emit a coherent beam of light energy in a narrow frequency band.\nValence and bonding behavior.\nValency is the combining power of an element. It is determined by the number of bonds it can form to other atoms or groups. The outermost electron shell of an atom in its uncombined state is known as the valence shell, and the electrons in\nthat shell are called valence electrons. The number of valence electrons determines the bonding\nbehavior with other atoms. Atoms tend to chemically react with each other in a manner that fills (or empties) their outer valence shells. For example, a transfer of a single electron between atoms is a useful approximation for bonds that form between atoms with one-electron more than a filled shell, and others that are one-electron short of a full shell, such as occurs in the compound sodium chloride and other chemical ionic salts. Many elements display multiple valences, or tendencies to share differing numbers of electrons in different compounds. Thus, chemical bonding between these elements takes many forms of electron-sharing that are more than simple electron transfers. Examples include the element carbon and the organic compounds.\nThe chemical elements are often displayed in a periodic table that is laid out to display recurring chemical properties, and elements with the same number of valence electrons form a group that is aligned in the same column of the table. (The horizontal rows correspond to the filling of a quantum shell of electrons.) The elements at the far right of the table have their outer shell completely filled with electrons, which results in chemically inert elements known as the noble gases.\nStates.\nQuantities of atoms are found in different states of matter that depend on the physical conditions, such as temperature and pressure. By varying the conditions, materials can transition between solids, liquids, gases and plasmas. Within a state, a material can also exist in different allotropes. An example of this is solid carbon, which can exist as graphite or diamond. Gaseous allotropes exist as well, such as dioxygen and ozone.\nAt temperatures close to absolute zero, atoms can form a Bose\u2013Einstein condensate, at which point quantum mechanical effects, which are normally only observed at the atomic scale, become apparent on a macroscopic scale. This super-cooled collection of atoms\nthen behaves as a single super atom, which may allow fundamental checks of quantum mechanical behavior.\nIdentification.\nWhile atoms are too small to be seen, devices such as the scanning tunneling microscope (STM) enable their visualization at the surfaces of solids. The microscope uses the quantum tunneling phenomenon, which allows particles to pass through a barrier that would be insurmountable in the classical perspective. Electrons tunnel through the vacuum between two biased electrodes, providing a tunneling current that is exponentially dependent on their separation. One electrode is a sharp tip ideally ending with a single atom. At each point of the scan of the surface the tip's height is adjusted so as to keep the tunneling current at a set value. How much the tip moves to and away from the surface is interpreted as the height profile. For low bias, the microscope images the averaged electron orbitals across closely packed energy levels\u2014the local density of the electronic states near the Fermi level. Because of the distances involved, both electrodes need to be extremely stable; only then periodicities can be observed that correspond to individual atoms. The method alone is not chemically specific, and cannot identify the atomic species present at the surface.\nAtoms can be easily identified by their mass. If an atom is ionized by removing one of its electrons, its trajectory when it passes through a magnetic field will bend. The radius by which the trajectory of a moving ion is turned by the magnetic field is determined by the mass of the atom. The mass spectrometer uses this principle to measure the mass-to-charge ratio of ions. If a sample contains multiple isotopes, the mass spectrometer can determine the proportion of each isotope in the sample by measuring the intensity of the different beams of ions. Techniques to vaporize atoms include inductively coupled plasma atomic emission spectroscopy and inductively coupled plasma mass spectrometry, both of which use a plasma to vaporize samples for analysis.\nThe atom-probe tomograph has sub-nanometer resolution in 3-D and can chemically identify individual atoms using time-of-flight mass spectrometry.\nElectron emission techniques such as X-ray photoelectron spectroscopy (XPS) and Auger electron spectroscopy (AES), which measure the binding energies of the core electrons, are used to identify the atomic species present in a sample in a non-destructive way. With proper focusing both can be made area-specific. Another such method is electron energy loss spectroscopy (EELS), which measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\nSpectra of excited states can be used to analyze the atomic composition of distant stars. Specific light wavelengths contained in the observed light from stars can be separated out and related to the quantized transitions in free gas atoms. These colors can be replicated using a gas-discharge lamp containing the same element. Helium was discovered in this way in the spectrum of the Sun 23\u00a0years before it was found on Earth.\nOrigin and current state.\nBaryonic matter forms about 4% of the total energy density of the observable universe, with an average density of about 0.25\u00a0particles/m3 (mostly protons and electrons). Within a galaxy such as the Milky Way, particles have a much higher concentration, with the density of matter in the interstellar medium (ISM) ranging from 105 to 109 atoms/m3. The Sun is believed to be inside the Local Bubble, so the density in the solar neighborhood is only about 103 atoms/m3. Stars form from dense clouds in the ISM, and the evolutionary processes of stars result in the steady enrichment of the ISM with elements more massive than hydrogen and helium.\nUp to 95% of the Milky Way's baryonic matter are concentrated inside stars, where conditions are unfavorable for atomic matter. The total baryonic mass is about 10% of the mass of the galaxy; the remainder of the mass is an unknown dark matter. High temperature inside stars makes most \"atoms\" fully ionized, that is, separates \"all\" electrons from the nuclei. In stellar remnants\u2014with exception of their surface layers\u2014an immense pressure make electron shells impossible.\nFormation.\nElectrons are thought to exist in the Universe since early stages of the Big Bang. Atomic nuclei forms in nucleosynthesis reactions. In about three minutes Big Bang nucleosynthesis produced most of the helium, lithium, and deuterium in the Universe, and perhaps some of the beryllium and boron.\nUbiquitousness and stability of atoms relies on their binding energy, which means that an atom has a lower energy than an unbound system of the nucleus and electrons. Where the temperature is much higher than ionization potential, the matter exists in the form of plasma\u2014a gas of positively charged ions (possibly, bare nuclei) and electrons. When the temperature drops below the ionization potential, atoms become statistically favorable. Atoms (complete with bound electrons) became to dominate over charged particles 380,000\u00a0years after the Big Bang\u2014an epoch called recombination, when the expanding Universe cooled enough to allow electrons to become attached to nuclei.\nSince the Big Bang, which produced no carbon or heavier elements, atomic nuclei have been combined in stars through the process of nuclear fusion to produce more of the element helium, and (via the triple-alpha process) the sequence of elements from carbon up to iron; see stellar nucleosynthesis for details.\nIsotopes such as lithium-6, as well as some beryllium and boron are generated in space through cosmic ray spallation. This occurs when a high-energy proton strikes an atomic nucleus, causing large numbers of nucleons to be ejected.\nElements heavier than iron were produced in supernovae and colliding neutron stars through the r-process, and in AGB stars through the s-process, both of which involve the capture of neutrons by atomic nuclei. Elements such as lead formed largely through the radioactive decay of heavier elements.\nEarth.\nMost of the atoms that make up the Earth and its inhabitants were present in their current form in the nebula that collapsed out of a molecular cloud to form the Solar System. The rest are the result of radioactive decay, and their relative proportion can be used to determine the age of the Earth through radiometric dating. Most of the helium in the crust of the Earth (about 99% of the helium from gas wells, as shown by its lower abundance of helium-3) is a product of alpha decay.\nThere are a few trace atoms on Earth that were not present at the beginning (i.e., not \"primordial\"), nor are results of radioactive decay. Carbon-14 is continuously generated by cosmic rays in the atmosphere. Some atoms on Earth have been artificially generated either deliberately or as by-products of nuclear reactors or explosions. Of the transuranic elements\u2014those with atomic numbers greater than 92\u2014only plutonium and neptunium occur naturally on Earth. Transuranic elements have radioactive lifetimes shorter than the current age of the Earth and thus identifiable quantities of these elements have long since decayed, with the exception of traces of plutonium-244 possibly deposited by cosmic dust. Natural deposits of plutonium and neptunium are produced by neutron capture in uranium ore.\nThe Earth contains approximately atoms. Although small numbers of independent atoms of noble gases exist, such as argon, neon, and helium, 99% of the atmosphere is bound in the form of molecules, including carbon dioxide and diatomic oxygen and nitrogen. At the surface of the Earth, an overwhelming majority of atoms combine to form various compounds, including water, salt, silicates and oxides. Atoms can also combine to create materials that do not consist of discrete molecules, including crystals and liquid or solid metals. This atomic matter forms networked arrangements that lack the particular type of small-scale interrupted order associated with molecular matter.\nRare and theoretical forms.\nSuperheavy elements.\nAll nuclides with atomic numbers higher than 82 (lead) are known to be radioactive. No nuclide with an atomic number exceeding 92 (uranium) exists on Earth as a primordial nuclide, and heavier elements generally have shorter half-lives. Nevertheless, an \"island of stability\" encompassing relatively long-lived isotopes of superheavy elements with atomic numbers 110 to 114 might exist. Predictions for the half-life of the most stable nuclide on the island range from a few minutes to millions of years. In any case, superheavy elements (with \"Z\"\u00a0&gt;\u00a0104) would not exist due to increasing Coulomb repulsion (which results in spontaneous fission with increasingly short half-lives) in the absence of any stabilizing effects.\nExotic matter.\nEach particle of matter has a corresponding antimatter particle with the opposite electrical charge. Thus, the positron is a positively charged antielectron and the antiproton is a negatively charged equivalent of a proton. When a matter and corresponding antimatter particle meet, they annihilate each other. Because of this, along with an imbalance between the number of matter and antimatter particles, the latter are rare in the universe. The first causes of this imbalance are not yet fully understood, although theories of baryogenesis may offer an explanation. As a result, no antimatter atoms have been discovered in nature. In 1996, the antimatter counterpart of the hydrogen atom (antihydrogen) was synthesized at the CERN laboratory in Geneva.\nOther exotic atoms have been created by replacing one of the protons, neutrons or electrons with other particles that have the same charge. For example, an electron can be replaced by a more massive muon, forming a muonic atom. These types of atoms can be used to test fundamental predictions of physics."}
{"id": "903", "revid": "48249625", "url": "https://en.wikipedia.org/wiki?curid=903", "title": "Arable land", "text": "Arable land (from the , \"able to be ploughed\") is any land capable of being ploughed and used to grow crops. Alternatively, for the purposes of agricultural statistics, the term often has a more precise definition: \nA more concise definition appearing in the Eurostat glossary similarly refers to actual rather than potential uses: \"land worked (ploughed or tilled) regularly, generally under a system of crop rotation\". In Britain, arable land has traditionally been contrasted with pasturable land such as heaths, which could be used for sheep-rearing but not as farmland.\nArable land is vulnerable to land degradation and some types of un-arable land can be enriched to create useful land. Climate change and biodiversity loss, are driving pressure on arable land.\nBy country.\nAccording to the Food and Agriculture Organization of the United Nations, in 2013, the world's arable land amounted to 1.407\u00a0billion hectares, out of a total of 4.924\u00a0billion hectares of land used for agriculture.\nNon-arable land.\nAgricultural land that is not arable according to the FAO definition above includes:\nOther non-arable land includes land that is not suitable for any agricultural use. Land that is not arable, in the sense of lacking capability or suitability for cultivation for crop production, has one or more limitationsa lack of sufficient freshwater for irrigation, stoniness, steepness, adverse climate, excessive wetness with the impracticality of drainage, excessive salts, or a combination of these, among others. Although such limitations may preclude cultivation, and some will in some cases preclude any agricultural use, large areas unsuitable for cultivation may still be agriculturally productive. For example, United States NRCS statistics indicate that about 59 percent of US non-federal pasture and unforested rangeland is unsuitable for cultivation, yet such land has value for grazing of livestock. In British Columbia, Canada, 41 percent of the provincial Agricultural Land Reserve area is unsuitable for the production of cultivated crops, but is suitable for uncultivated production of forage usable by grazing livestock. Similar examples can be found in many rangeland areas elsewhere.\nChanges in arability.\nLand conversion.\nLand incapable of being cultivated for the production of crops can sometimes be converted to arable land. New arable land makes more food and can reduce starvation. This outcome also makes a country more self-sufficient and politically independent, because food importation is reduced. Making non-arable land arable often involves digging new irrigation canals and new wells, aqueducts, desalination plants, planting trees for shade in the desert, hydroponics, fertilizer, nitrogen fertilizer, pesticides, reverse osmosis water processors, PET film insulation or other insulation against heat and cold, digging ditches and hills for protection against the wind, and installing greenhouses with internal light and heat for protection against the cold outside and to provide light in cloudy areas. Such modifications are often prohibitively expensive. An alternative is the seawater greenhouse, which desalinates water through evaporation and condensation using solar energy as the only energy input. This technology is optimized to grow crops on desert land close to the sea.\nThe use of artifices does not make the land arable. Rock still remains rock, and shallowless than turnable soil is still not considered toilable. The use of artifice is an open-air non-recycled water hydroponics relationship. The below described circumstances are not in perspective, have limited duration, and have a tendency to accumulate trace materials in soil that either there or elsewhere cause deoxygenation. The use of vast amounts of fertilizer may have unintended consequences for the environment by devastating rivers, waterways, and river endings through the accumulation of non-degradable toxins and nitrogen-bearing molecules that remove oxygen and cause non-aerobic processes to form.\nExamples of infertile non-arable land being turned into fertile arable land include:\nLand degradation.\nExamples.\nExamples of fertile arable land being turned into infertile land include:"}
{"id": "904", "revid": "34515925", "url": "https://en.wikipedia.org/wiki?curid=904", "title": "Aluminium", "text": "Aluminium (or aluminum in North American English) is a chemical element; it has symbol\u00a0Al and atomic number\u00a013. Aluminium has a density lower than that of other common metals, about one-third that of steel. It has a great affinity towards oxygen, forming a protective layer of oxide on the surface when exposed to air. Aluminium visually resembles silver, both in its color and in its great ability to reflect light. It is soft, nonmagnetic, and ductile. It has one stable isotope, 27Al, which is highly abundant, making aluminium the twelfth-most common element in the universe. The radioactivity of 26Al leads to it being used in radiometric dating.\nChemically, aluminium is a post-transition metal in the boron group; as is common for the group, aluminium forms compounds primarily in the +3 oxidation state. The aluminium cation Al3+ is small and highly charged; as such, it has more polarizing power, and bonds formed by aluminium have a more covalent character. The strong affinity of aluminium for oxygen leads to the common occurrence of its oxides in nature. Aluminium is found on Earth primarily in rocks in the crust, where it is the third-most abundant element, after oxygen and silicon, rather than in the mantle, and virtually never as the free metal. It is obtained industrially by mining bauxite, a sedimentary rock rich in aluminium minerals.\nThe discovery of aluminium was announced in 1825 by Danish physicist Hans Christian \u00d8rsted. The first industrial production of aluminium was initiated by French chemist Henri \u00c9tienne Sainte-Claire Deville in 1856. Aluminium became much more available to the public with the Hall\u2013H\u00e9roult process developed independently by French engineer Paul H\u00e9roult and American engineer Charles Martin Hall in 1886, and the mass production of aluminium led to its extensive use in industry and everyday life. In the First and Second World Wars, aluminium was a crucial strategic resource for aviation. In 1954, aluminium became the most produced non-ferrous metal, surpassing copper. In the 21st century, most aluminium was consumed in transportation, engineering, construction, and packaging in the United States, Western Europe, and Japan.\nDespite its prevalence in the environment, no living organism is known to metabolize aluminium salts, but this aluminium is well tolerated by plants and animals. Because of the abundance of these salts, the potential for a biological role for them is of interest, and studies are ongoing.\nPhysical characteristics.\nIsotopes.\nOf aluminium isotopes, only is stable. This situation is common for elements with an odd atomic number. It is the only primordial aluminium isotope, i.e. the only one that has existed on Earth in its current form since the formation of the planet. It is therefore a mononuclidic element and its standard atomic weight is virtually the same as that of the isotope. This makes aluminium very useful in nuclear magnetic resonance (NMR), as its single stable isotope has a high NMR sensitivity. The standard atomic weight of aluminium is low in comparison with many other metals.\nAll other isotopes of aluminium are radioactive. The most stable of these is 26Al: while it was present along with stable 27Al in the interstellar medium from which the Solar System formed, having been produced by stellar nucleosynthesis as well, its half-life is only 717,000\u00a0years and therefore a detectable amount has not survived since the formation of the planet. However, minute traces of 26Al are produced from argon in the atmosphere by spallation caused by cosmic ray protons. The ratio of 26Al to 10Be has been used for radiodating of geological processes over 105 to 106\u00a0year time scales, in particular transport, deposition, sediment storage, burial times, and erosion. Most meteorite scientists believe that the energy released by the decay of 26Al was responsible for the melting and differentiation of some asteroids after their formation 4.55\u00a0billion years ago.\nThe remaining isotopes of aluminium, with mass numbers ranging from 21 to 43, all have half-lives well under an hour. Three metastable states are known, all with half-lives under a minute.\nElectron shell.\nAn aluminium atom has 13 electrons, arranged in an electron configuration of , with three electrons beyond a stable noble gas configuration. Accordingly, the combined first three ionization energies of aluminium are far lower than the fourth ionization energy alone. Such an electron configuration is shared with the other well-characterized members of its group, boron, gallium, indium, and thallium; it is also expected for nihonium. Aluminium can surrender its three outermost electrons in many chemical reactions (see below). The electronegativity of aluminium is 1.61 (Pauling scale).\nA free aluminium atom has a radius of 143\u00a0pm. With the three outermost electrons removed, the radius shrinks to 39\u00a0pm for a 4-coordinated atom or 53.5\u00a0pm for a 6-coordinated atom. At standard temperature and pressure, aluminium atoms (when not affected by atoms of other elements) form a face-centered cubic crystal system bound by metallic bonding provided by atoms' outermost electrons; hence aluminium (at these conditions) is a metal. This crystal system is shared by many other metals, such as lead and copper; the size of a unit cell of aluminium is comparable to that of those other metals. The system, however, is not shared by the other members of its group: boron has ionization energies too high to allow metallization, thallium has a hexagonal close-packed structure, and gallium and indium have unusual structures that are not close-packed like those of aluminium and thallium. The few electrons that are available for metallic bonding in aluminium are a probable cause for it being soft with a low melting point and low electrical resistivity.\nBulk.\nAluminium metal has an appearance ranging from silvery white to dull gray depending on its surface roughness. Aluminium mirrors are the most reflective of all metal mirrors for near ultraviolet and far infrared light. It is also one of the most reflective for light in the visible spectrum, nearly on par with silver in this respect, and the two therefore look similar. Aluminium is also good at reflecting solar radiation, although prolonged exposure to sunlight in air adds wear to the surface of the metal; this may be prevented if aluminium is anodized, which adds a protective layer of oxide on the surface.\nThe density of aluminium is 2.70\u00a0g/cm3, about 1/3 that of steel, much lower than other commonly encountered metals, making aluminium parts easily identifiable through their lightness. Aluminium's low density compared to most other metals arises from the fact that its nuclei are much lighter, while difference in the unit cell size does not compensate for this difference. The only lighter metals are the metals of groups 1 and 2, which apart from beryllium and magnesium are too reactive for structural use (and beryllium is very toxic). Aluminium is not as strong or stiff as steel, but the low density makes up for this in the aerospace industry and for many other applications where light weight and relatively high strength are crucial.\nPure aluminium is quite soft and lacking in strength. In most applications various aluminium alloys are used instead because of their higher strength and hardness. The yield strength of pure aluminium is 7\u201311 MPa, while aluminium alloys have yield strengths ranging from 200 MPa to 600 MPa. Aluminium is ductile, with a percent elongation of 50\u201370%, and malleable allowing it to be easily drawn and extruded. It is also easily machined and cast.\nAluminium is an excellent thermal and electrical conductor, having around 60% the conductivity of copper, both thermal and electrical, while having only 30% of copper's density. Aluminium is capable of superconductivity, with a superconducting critical temperature of 1.2 kelvin and a critical magnetic field of about 100 gauss (10 milliteslas). It is paramagnetic and thus essentially unaffected by static magnetic fields. The high electrical conductivity, however, means that it is strongly affected by alternating magnetic fields through the induction of eddy currents.\nChemistry.\nAluminium combines characteristics of pre- and post-transition metals. Since it has few available electrons for metallic bonding, like its heavier group 13 congeners, it has the characteristic physical properties of a post-transition metal, with longer-than-expected interatomic distances. Furthermore, as Al3+ is a small and highly charged cation, it is strongly polarizing and bonding in aluminium compounds tends towards covalency; this behavior is similar to that of beryllium (Be2+), and the two display an example of a diagonal relationship.\nThe underlying core under aluminium's valence shell is that of the preceding noble gas, whereas those of its heavier congeners gallium, indium, thallium, and nihonium also include a filled d-subshell and in some cases a filled f-subshell. Hence, the inner electrons of aluminium shield the valence electrons almost completely, unlike those of aluminium's heavier congeners. As such, aluminium is the most electropositive metal in its group, and its hydroxide is in fact more basic than that of gallium. Aluminium also bears minor similarities to the metalloid boron in the same group: AlX3 compounds are valence isoelectronic to BX3 compounds (they have the same valence electronic structure), and both behave as Lewis acids and readily form adducts. Additionally, one of the main motifs of boron chemistry is regular icosahedral structures, and aluminium forms an important part of many icosahedral quasicrystal alloys, including the Al\u2013Zn\u2013Mg class.\nAluminium has a high chemical affinity to oxygen, which renders it suitable for use as a reducing agent in the thermite reaction. A fine powder of aluminium reacts explosively on contact with liquid oxygen; under normal conditions, however, aluminium forms a thin oxide layer (~5\u00a0nm at room temperature) that protects the metal from further corrosion by oxygen, water, or dilute acid, a process termed passivation. Because of its general resistance to corrosion, aluminium is one of the few metals that retains silvery reflectance in finely powdered form, making it an important component of silver-colored paints. Aluminium is not attacked by oxidizing acids because of its passivation. This allows aluminium to be used to store reagents such as nitric acid, concentrated sulfuric acid, and some organic acids.\nIn hot concentrated hydrochloric acid, aluminium reacts with water with evolution of hydrogen, and in aqueous sodium hydroxide or potassium hydroxide at room temperature to form aluminates\u2014protective passivation under these conditions is negligible. Aqua regia also dissolves aluminium. Aluminium is corroded by dissolved chlorides, such as common sodium chloride, which is why household plumbing is never made from aluminium. The oxide layer on aluminium is also destroyed by contact with mercury due to amalgamation or with salts of some electropositive metals. As such, the strongest aluminium alloys are less corrosion-resistant due to galvanic reactions with alloyed copper, and aluminium's corrosion resistance is greatly reduced by aqueous salts, particularly in the presence of dissimilar metals.\nAluminium reacts with most nonmetals upon heating, forming compounds such as aluminium nitride (AlN), aluminium sulfide (Al2S3), and the aluminium halides (AlX3). It also forms a wide range of intermetallic compounds involving metals from every group on the periodic table.\nInorganic compounds.\nThe vast majority of compounds, including all aluminium-containing minerals and all commercially significant aluminium compounds, feature aluminium in the oxidation state 3+. The coordination number of such compounds varies, but generally Al3+ is either six- or four-coordinate. Almost all compounds of aluminium(III) are colorless.\nIn aqueous solution, Al3+ exists as the hexaaqua cation [Al(H2O)6]3+, which has an approximate Ka of 10\u22125. Such solutions are acidic as this cation can act as a proton donor and progressively hydrolyze until a precipitate of aluminium hydroxide, Al(OH)3, forms. This is useful for clarification of water, as the precipitate nucleates on suspended particles in the water, hence removing them. Increasing the pH even further leads to the hydroxide dissolving again as aluminate, [Al(H2O)2(OH)4]\u2212, is formed.\nAluminium hydroxide forms both salts and aluminates and dissolves in acid and alkali, as well as on fusion with acidic and basic oxides. This behavior of Al(OH)3 is termed amphoterism and is characteristic of weakly basic cations that form insoluble hydroxides and whose hydrated species can also donate their protons. One effect of this is that aluminium salts with weak acids are hydrolyzed in water to the aquated hydroxide and the corresponding nonmetal hydride: for example, aluminium sulfide yields hydrogen sulfide. However, some salts like aluminium carbonate exist in aqueous solution but are unstable as such; and only incomplete hydrolysis takes place for salts with strong acids, such as the halides, nitrate, and sulfate. For similar reasons, anhydrous aluminium salts cannot be made by heating their \"hydrates\": hydrated aluminium chloride is in fact not AlCl3\u00b76H2O but [Al(H2O)6]Cl3, and the Al\u2013O bonds are so strong that heating is not sufficient to break them and form Al\u2013Cl bonds instead:\nAll four trihalides are well known. Unlike the structures of the three heavier trihalides, aluminium fluoride (AlF3) features six-coordinate aluminium, which explains its involatility and insolubility as well as high heat of formation. Each aluminium atom is surrounded by six fluorine atoms in a distorted octahedral arrangement, with each fluorine atom being shared between the corners of two octahedra. Such {AlF6} units also exist in complex fluorides such as cryolite, Na3AlF6. AlF3 melts at and is made by reaction of aluminium oxide with hydrogen fluoride gas at .\nWith heavier halides, the coordination numbers are lower. The other trihalides are dimeric or polymeric with tetrahedral four-coordinate aluminium centers. Aluminium trichloride (AlCl3) has a layered polymeric structure below its melting point of but transforms on melting to Al2Cl6 dimers. At higher temperatures those increasingly dissociate into trigonal planar AlCl3 monomers similar to the structure of BCl3. Aluminium tribromide and aluminium triiodide form Al2X6 dimers in all three phases and hence do not show such significant changes of properties upon phase change. These materials are prepared by treating aluminium with the halogen. The aluminium trihalides form many addition compounds or complexes; their Lewis acidic nature makes them useful as catalysts for the Friedel\u2013Crafts reactions. Aluminium trichloride has major industrial uses involving this reaction, such as in the manufacture of anthraquinones and styrene; it is also often used as the precursor for many other aluminium compounds and as a reagent for converting nonmetal fluorides into the corresponding chlorides (a transhalogenation reaction).\nAluminium forms one stable oxide with the chemical formula Al2O3, commonly called alumina. It can be found in nature in the mineral corundum, \u03b1-alumina; there is also a \u03b3-alumina phase. Its crystalline form, corundum, is very hard (Mohs hardness 9), has a high melting point of , has very low volatility, is chemically inert, and a good electrical insulator, it is often used in abrasives (such as toothpaste), as a refractory material, and in ceramics, as well as being the starting material for the electrolytic production of aluminium. Sapphire and ruby are impure corundum contaminated with trace amounts of other metals. The two main oxide-hydroxides, AlO(OH), are boehmite and diaspore. There are three main trihydroxides: bayerite, gibbsite, and nordstrandite, which differ in their crystalline structure (polymorphs). Many other intermediate and related structures are also known. Most are produced from ores by a variety of wet processes using acid and base. Heating the hydroxides leads to formation of corundum. These materials are of central importance to the production of aluminium and are themselves extremely useful. Some mixed oxide phases are also very useful, such as spinel (MgAl2O4), Na-\u03b2-alumina (NaAl11O17), and tricalcium aluminate (Ca3Al2O6, an important mineral phase in Portland cement).\nThe only stable chalcogenides under normal conditions are aluminium sulfide (Al2S3), selenide (Al2Se3), and telluride (Al2Te3). All three are prepared by direct reaction of their elements at about and quickly hydrolyze completely in water to yield aluminium hydroxide and the respective hydrogen chalcogenide. As aluminium is a small atom relative to these chalcogens, these have four-coordinate tetrahedral aluminium with various polymorphs having structures related to wurtzite, with two-thirds of the possible metal sites occupied either in an orderly (\u03b1) or random (\u03b2) fashion; the sulfide also has a \u03b3 form related to \u03b3-alumina, and an unusual high-temperature hexagonal form where half the aluminium atoms have tetrahedral four-coordination and the other half have trigonal bipyramidal five-coordination.\nFour pnictides \u2013 aluminium nitride (AlN), aluminium phosphide (AlP), aluminium arsenide (AlAs), and aluminium antimonide (AlSb) \u2013 are known. They are all III-V semiconductors isoelectronic to silicon and germanium, all of which but AlN have the zinc blende structure. All four can be made by high-temperature (and possibly high-pressure) direct reaction of their component elements.\nAluminium alloys well with most other metals (with the exception of most alkali metals and group 13 metals) and over 150 intermetallics with other metals are known. Preparation involves heating fixed metals together in certain proportion, followed by gradual cooling and annealing. Bonding in them is predominantly metallic and the crystal structure primarily depends on efficiency of packing.\nThere are few compounds with lower oxidation states. A few aluminium(I) compounds exist: AlF, AlCl, AlBr, and AlI exist in the gaseous phase when the respective trihalide is heated with aluminium, and at cryogenic temperatures. A stable derivative of aluminium monoiodide is the cyclic adduct formed with triethylamine, Al4I4(NEt3)4. Al2O and Al2S also exist but are very unstable. Very simple aluminium(II) compounds are invoked or observed in the reactions of Al metal with oxidants. For example, aluminium monoxide, AlO, has been detected in the gas phase after explosion and in stellar absorption spectra. More thoroughly investigated are compounds of the formula R4Al2 which contain an Al\u2013Al bond and where R is a large organic ligand.\nOrganoaluminium compounds and related hydrides.\nA variety of compounds of empirical formula AlR3 and AlR1.5Cl1.5 exist. The aluminium trialkyls and triaryls are reactive, volatile, and colorless liquids or low-melting solids. They catch fire spontaneously in air and react with water, thus necessitating precautions when handling them. They often form dimers, unlike their boron analogues, but this tendency diminishes for branched-chain alkyls (e.g. Pr\"i\", Bu\"i\", Me3CCH2); for example, triisobutylaluminium exists as an equilibrium mixture of the monomer and dimer. These dimers, such as trimethylaluminium (Al2Me6), usually feature tetrahedral Al centers formed by dimerization with some alkyl group bridging between both aluminium atoms. They are hard acids and react readily with ligands, forming adducts. In industry, they are mostly used in alkene insertion reactions, as discovered by Karl Ziegler, most importantly in \"growth reactions\" that form long-chain unbranched primary alkenes and alcohols, and in the low-pressure polymerization of ethene and propene. There are also some heterocyclic and cluster organoaluminium compounds involving Al\u2013N bonds.\nThe industrially most important aluminium hydride is lithium aluminium hydride (LiAlH4), which is used as a reducing agent in organic chemistry. It can be produced from lithium hydride and aluminium trichloride. The simplest hydride, aluminium hydride or alane, is not as important. It is a polymer with the formula (AlH3)\"n\", in contrast to the corresponding boron hydride that is a dimer with the formula (BH3)2.\nNatural occurrence.\nSpace.\nAluminium's per-particle abundance in the Solar System is 3.15 ppm (parts per million). It is the twelfth most abundant of all elements and third most abundant among the elements that have odd atomic numbers, after hydrogen and nitrogen. The only stable isotope of aluminium, 27Al, is the eighteenth most abundant nucleus in the universe. It is created almost entirely after fusion of carbon in massive stars that will later become Type II supernovas: this fusion creates 26Mg, which upon capturing free protons and neutrons, becomes aluminium. Some smaller quantities of 27Al are created in hydrogen burning shells of evolved stars, where 26Mg can capture free protons. Essentially all aluminium now in existence is 27Al. 26Al was present in the early Solar System with abundance of 0.005% relative to 27Al but its half-life of 728,000 years is too short for any original nuclei to survive; 26Al is therefore extinct. Unlike for 27Al, hydrogen burning is the primary source of 26Al, with the nuclide emerging after a nucleus of 25Mg catches a free proton. However, the trace quantities of 26Al that do exist are the most common gamma ray emitter in the interstellar gas; if the original 26Al were still present, gamma ray maps of the Milky Way would be brighter.\nEarth.\nOverall, the Earth is about 1.59% aluminium by mass (seventh in abundance by mass). Aluminium occurs in greater proportion in the Earth's crust than in the universe at large. This is because aluminium easily forms the oxide and becomes bound into rocks and stays in the Earth's crust, while less reactive metals sink to the core. In the Earth's crust, aluminium is the most abundant metallic element (8.23% by mass) and the third most abundant of all elements (after oxygen and silicon). A large number of silicates in the Earth's crust contain aluminium. In contrast, the Earth's mantle is only 2.38% aluminium by mass. Aluminium also occurs in seawater at a concentration of 0.41 \u00b5g/kg.\nBecause of its strong affinity for oxygen, aluminium is almost never found in the elemental state; instead it is found in oxides or silicates. Feldspars, the most common group of minerals in the Earth's crust, are aluminosilicates. Aluminium also occurs in the minerals beryl, cryolite, garnet, spinel, and turquoise. Impurities in Al2O3, such as chromium and iron, yield the gemstones ruby and sapphire, respectively. Native aluminium metal is extremely rare and can only be found as a minor phase in low oxygen fugacity environments, such as the interiors of certain volcanoes. Native aluminium has been reported in cold seeps in the northeastern continental slope of the South China Sea. It is possible that these deposits resulted from bacterial reduction of tetrahydroxoaluminate Al(OH)4\u2212.\nAlthough aluminium is a common and widespread element, not all aluminium minerals are economically viable sources of the metal. Almost all metallic aluminium is produced from the ore bauxite (AlO\"x\"(OH)3\u20132\"x\"). Bauxite occurs as a weathering product of low iron and silica bedrock in tropical climatic conditions. In 2017, most bauxite was mined in Australia, China, Guinea, and India.\nHistory.\nThe history of aluminium has been shaped by usage of alum. The first written record of alum, made by Greek historian Herodotus, dates back to the 5th century BCE. The ancients are known to have used alum as a dyeing mordant and for city defense. After the Crusades, alum, an indispensable good in the European fabric industry, was a subject of international commerce; it was imported to Europe from the eastern Mediterranean until the mid-15th century.\nThe nature of alum remained unknown. Around 1530, Swiss physician Paracelsus suggested alum was a salt of an earth of alum. In 1595, German doctor and chemist Andreas Libavius experimentally confirmed this. In 1722, German chemist Friedrich Hoffmann announced his belief that the base of alum was a distinct earth. In 1754, German chemist Andreas Sigismund Marggraf synthesized alumina by boiling clay in sulfuric acid and subsequently adding potash.\nAttempts to produce aluminium date back to 1760. The first successful attempt, however, was completed in 1824 by Danish physicist and chemist Hans Christian \u00d8rsted. He reacted anhydrous aluminium chloride with potassium amalgam, yielding a lump of metal looking similar to tin. He presented his results and demonstrated a sample of the new metal in 1825. In 1827, German chemist Friedrich W\u00f6hler repeated \u00d8rsted's experiments but did not identify any aluminium. (The reason for this inconsistency was only discovered in 1921.) He conducted a similar experiment in the same year by mixing anhydrous aluminium chloride with potassium (the W\u00f6hler process) and produced a powder of aluminium. In 1845, he was able to produce small pieces of the metal and described some physical properties of this metal. For many years thereafter, W\u00f6hler was credited as the discoverer of aluminium.\nAs W\u00f6hler's method could not yield great quantities of aluminium, the metal remained rare; its cost exceeded that of gold. The first industrial production of aluminium was established in 1856 by French chemist Henri Etienne Sainte-Claire Deville and companions. Deville had discovered that aluminium trichloride could be reduced by sodium, which was more convenient and less expensive than potassium, which W\u00f6hler had used. Even then, aluminium was still not of great purity and produced aluminium differed in properties by sample. Because of its electricity-conducting capacity, aluminium was used as the cap of the Washington Monument, completed in 1885, the tallest building in the world at the time. The non-corroding metal cap was intended to serve as a lightning rod peak.\nThe first industrial large-scale production method was independently developed in 1886 by French engineer Paul H\u00e9roult and American engineer Charles Martin Hall; it is now known as the Hall\u2013H\u00e9roult process. The Hall\u2013H\u00e9roult process converts alumina into metal. Austrian chemist Carl Joseph Bayer discovered a way of purifying bauxite to yield alumina, now known as the Bayer process, in 1889. Modern production of aluminium is based on the Bayer and Hall\u2013H\u00e9roult processes.\nAs large-scale production caused aluminium prices to drop, the metal became widely used in jewelry, eyeglass frames, optical instruments, tableware, and foil, and other everyday items in the 1890s and early 20th century. Aluminium's ability to form hard yet light alloys with other metals provided the metal with many uses at the time. During World War I, major governments demanded large shipments of aluminium for light strong airframes; during World War II, demand by major governments for aviation was even higher.\nBy the mid-20th century, aluminium had become a part of everyday life and an essential component of housewares. In 1954, production of aluminium surpassed that of copper, historically second in production only to iron, making it the most produced non-ferrous metal. During the mid-20th century, aluminium emerged as a civil engineering material, with building applications in both basic construction and interior finish work, and increasingly being used in military engineering, for both airplanes and land armor vehicle engines. Earth's first artificial satellite, launched in 1957, consisted of two separate aluminium semi-spheres joined and all subsequent space vehicles have used aluminium to some extent. The aluminium can was invented in 1956 and employed as a storage for drinks in 1958.\nThroughout the 20th century, the production of aluminium rose rapidly: while the world production of aluminium in 1900 was 6,800 metric tons, the annual production first exceeded 100,000 metric tons in 1916; 1,000,000 tons in 1941; 10,000,000 tons in 1971. In the 1970s, the increased demand for aluminium made it an exchange commodity; it entered the London Metal Exchange, the oldest industrial metal exchange in the world, in 1978. The output continued to grow: the annual production of aluminium exceeded 50,000,000 metric tons in 2013.\nThe real price for aluminium declined from $14,000 per metric ton in 1900 to $2,340 in 1948 (in 1998 United States dollars). Extraction and processing costs were lowered over technological progress and the scale of the economies. However, the need to exploit lower-grade poorer quality deposits and the use of fast increasing input costs (above all, energy) increased the net cost of aluminium; the real price began to grow in the 1970s with the rise of energy cost. Production moved from the industrialized countries to countries where production was cheaper. Production costs in the late 20th century changed because of advances in technology, lower energy prices, exchange rates of the United States dollar, and alumina prices. The BRIC countries' combined share in primary production and primary consumption grew substantially in the first decade of the 21st century. China is accumulating an especially large share of the world's production thanks to an abundance of resources, cheap energy, and governmental stimuli; it also increased its consumption share from 2% in 1972 to 40% in 2010. In the United States, Western Europe, and Japan, most aluminium was consumed in transportation, engineering, construction, and packaging. In 2021, prices for industrial metals such as aluminium have soared to near-record levels as energy shortages in China drive up costs for electricity.\nEtymology.\nThe names \"aluminium\" and \"aluminum\" are derived from the word \"alumine\", an obsolete term for \"alumina\", the primary naturally occurring oxide of aluminium. \"Alumine\" was borrowed from French, which in turn derived it from \"alumen\", the classical Latin name for alum, the mineral from which it was collected. The Latin word \"alumen\" stems from the Proto-Indo-European root \"*alu-\" meaning \"bitter\" or \"beer\".\nOrigins.\nBritish chemist Humphry Davy, who performed a number of experiments aimed to isolate the metal, is credited as the person who named the element. The first name proposed for the metal to be isolated from alum was \"alumium\", which Davy suggested in an 1808 article on his electrochemical research, published in Philosophical Transactions of the Royal Society. It appeared that the name was created from the English word \"alum\" and the Latin suffix \"-ium\"; but it was customary then to give elements names originating in Latin, so this name was not adopted universally. This name was criticized by contemporary chemists from France, Germany, and Sweden, who insisted the metal should be named for the oxide, alumina, from which it would be isolated. The English name \"alum\" does not come directly from Latin, whereas \"alumine\"/\"alumina\" comes from the Latin word \"alumen\" (upon declension, \"alumen\" changes to \"alumin-\").\nOne example was \"Essai sur la Nomenclature chimique\" (July 1811), written in French by a Swedish chemist, J\u00f6ns Jacob Berzelius, in which the name \"aluminium\" is given to the element that would be synthesized from alum. (Another article in the same journal issue also refers to the metal whose oxide is the basis of sapphire, i.e. the same metal, as to \"aluminium\".) A January 1811 summary of one of Davy's lectures at the Royal Society mentioned the name \"aluminium\" as a possibility. The next year, Davy published a chemistry textbook in which he used the spelling \"aluminum\". Both spellings have coexisted since. Their usage is currently regional: \"aluminum\" dominates in the United States and Canada; \"aluminium\" is prevalent in the rest of the English-speaking world.\nSpelling.\nIn 1812, British scientist Thomas Young wrote an anonymous review of Davy's book, in which he proposed the name \"aluminium\" instead of \"aluminum\", which he thought had a \"less classical sound\". This name persisted: although the ' spelling was occasionally used in Britain, the American scientific language used ' from the start.\nLudwig Wilhelm Gilbert had proposed \"Thonerde-metall\", after the German \"Thonerde\" for alumina, in his \"Annalen der Physik\" but that name never caught on at all even in Germany. Joseph W. Richards in 1891 found just one occurrence of \"argillium\" in Swedish, from the French \"argille\" for clay. The French themselves had used \"aluminium\" from the start. However, in England and Germany Davy's spelling \"aluminum\" was initially used; until German chemist Friedrich W\u00f6hler published his account of the W\u00f6hler process in 1827 in which he used the spelling \"aluminium\", which caused that spelling's largely wholesale adoption in England and Germany, with the exception of a small number of what Richards characterized as \"patriotic\" English chemists that were \"averse to foreign innovations\" who occasionally still used \"aluminum\".\nMost scientists throughout the world used \"\" in the 19th century; and it was entrenched in several other European languages, such as French, German, and Dutch.\nIn 1828, an American lexicographer, Noah Webster, entered only the \"aluminum\" spelling in his \"American Dictionary of the English Language\". In the 1830s, the ' spelling gained usage in the United States; by the 1860s, it had become the more common spelling there outside science. In 1892, Hall used the ' spelling in his advertising handbill for his new electrolytic method of producing the metal, despite his constant use of the ' spelling in all the patents he filed between 1886 and 1903. It is unknown whether this spelling was introduced by mistake or intentionally, but Hall preferred \"aluminum\" since its introduction because it resembled \"platinum\", the name of a prestigious metal. By 1890, both spellings had been common in the United States, the ' spelling being slightly more common; by 1895, the situation had reversed; by 1900, \"aluminum\" had become twice as common as \"aluminium\"; in the next decade, the \"\" spelling dominated American usage. In 1925, the American Chemical Society adopted this spelling.\nThe International Union of Pure and Applied Chemistry (IUPAC) adopted \"aluminium\" as the standard international name for the element in 1990. In 1993, they recognized \"aluminum\" as an acceptable variant; the most recent 2005 edition of the IUPAC nomenclature of inorganic chemistry also acknowledges this spelling. IUPAC official publications use the \"\" spelling as primary, and they list both where it is appropriate.\nProduction and refinement.\nThe production of aluminium starts with the extraction of bauxite rock from the ground. The bauxite is processed and transformed using the Bayer process into alumina, which is then processed using the Hall\u2013H\u00e9roult process, resulting in the final aluminium.\nAluminium production is highly energy-consuming, and so the producers tend to locate smelters in places where electric power is both plentiful and inexpensive. Production of one\u00a0kilogram of aluminium requires 7\u00a0kilograms of oil energy equivalent, as compared to 1.5\u00a0kilograms for steel and 2\u00a0kilograms for plastic. As of 2023, the world's largest producers of aluminium were China, Russia, India, Canada, and the United Arab Emirates, while China is by far the top producer of aluminium with a world share of over 55%.\nAccording to the International Resource Panel's Metal Stocks in Society report, the global per capita stock of aluminium in use in society (i.e. in cars, buildings, electronics, etc.) is . Much of this is in more-developed countries ( per capita) rather than less-developed countries ( per capita).\nBayer process.\nBauxite is converted to alumina by the Bayer process. Bauxite is blended for uniform composition and then is grounded. The resulting slurry is mixed with a hot solution of sodium hydroxide; the mixture is then treated in a digester vessel at a pressure well above atmospheric, dissolving the aluminium hydroxide in bauxite while converting impurities into relatively insoluble compounds:\nAfter this reaction, the slurry is at a temperature above its atmospheric boiling point. It is cooled by removing steam as pressure is reduced. The bauxite residue is separated from the solution and discarded. The solution, free of solids, is seeded with small crystals of aluminium hydroxide; this causes decomposition of the [Al(OH)4]\u2212 ions to aluminium hydroxide. After about half of aluminium has precipitated, the mixture is sent to classifiers. Small crystals of aluminium hydroxide are collected to serve as seeding agents; coarse particles are converted to alumina by heating; the excess solution is removed by evaporation, (if needed) purified, and recycled.\nHall\u2013H\u00e9roult process.\nThe conversion of alumina to aluminium is achieved by the Hall\u2013H\u00e9roult process. In this energy-intensive process, a solution of alumina in a molten () mixture of cryolite (Na3AlF6) with calcium fluoride is electrolyzed to produce metallic aluminium. The liquid aluminium sinks to the bottom of the solution and is tapped off, and usually cast into large blocks called aluminium billets for further processing.\nAnodes of the electrolysis cell are made of carbon\u2014the most resistant material against fluoride corrosion\u2014and either bake at the process or are prebaked. The former, also called S\u00f6derberg anodes, are less power-efficient and fumes released during baking are costly to collect, which is why they are being replaced by prebaked anodes even though they save the power, energy, and labor to prebake the cathodes. Carbon for anodes should be preferably pure so that neither aluminium nor the electrolyte is contaminated with ash. Despite carbon's resistivity against corrosion, it is still consumed at a rate of 0.4\u20130.5\u00a0kg per each kilogram of produced aluminium. Cathodes are made of anthracite; high purity for them is not required because impurities leach only very slowly. The cathode is consumed at a rate of 0.02\u20130.04\u00a0kg per each kilogram of produced aluminium. A cell is usually terminated after 2\u20136 years following a failure of the cathode.\nThe Hall\u2013Heroult process produces aluminium with a purity of above 99%. Further purification can be done by the Hoopes process. This process involves the electrolysis of molten aluminium with a sodium, barium, and aluminium fluoride electrolyte. The resulting aluminium has a purity of 99.99%.\nElectric power represents about 20 to 40% of the cost of producing aluminium, depending on the location of the smelter. Aluminium production consumes roughly 5% of electricity generated in the United States. Because of this, alternatives to the Hall\u2013H\u00e9roult process have been researched, but none has turned out to be economically feasible.\nRecycling.\nRecovery of the metal through recycling has become an important task of the aluminium industry. Recycling was a low-profile activity until the late 1960s, when the growing use of aluminium beverage cans brought it to public awareness. Recycling involves melting the scrap, a process that requires only 5% of the energy used to produce aluminium from ore, though a significant part (up to 15% of the input material) is lost as dross (ash-like oxide). An aluminium stack melter produces significantly less dross, with values reported below 1%.\nWhite dross from primary aluminium production and from secondary recycling operations still contains useful quantities of aluminium that can be extracted industrially. The process produces aluminium billets, together with a highly complex waste material. This waste is difficult to manage. It reacts with water, releasing a mixture of gases including, among others, acetylene, hydrogen sulfide and significant amounts of ammonia. Despite these difficulties, the waste is used as a filler in asphalt and concrete. Its potential for hydrogen production has also been considered and researched.\nApplications.\nMetal.\nThe global production of aluminium in 2016 was 58.8\u00a0million metric tons. It exceeded that of any other metal except iron (1,231\u00a0million metric tons).\nAluminium is almost always alloyed, which markedly improves its mechanical properties, especially when tempered. For example, the common aluminium foils and beverage cans are alloys of 92% to 99% aluminium. The main alloying agents are copper, zinc, magnesium, manganese, and silicon (e.g., duralumin) with the levels of other metals in a few percent by weight. Aluminium, both wrought and cast, has been alloyed with: manganese, silicon, magnesium, copper and zinc among others.\nThe major uses for aluminium are in:\nCompounds.\nThe great majority (about 90%) of aluminium oxide is converted to metallic aluminium. Being a very hard material (Mohs hardness 9), alumina is widely used as an abrasive; being extraordinarily chemically inert, it is useful in highly reactive environments such as high pressure sodium lamps. Aluminium oxide is commonly used as a catalyst for industrial processes; e.g. the Claus process to convert hydrogen sulfide to sulfur in refineries and to alkylate amines. Many industrial catalysts are supported by alumina, meaning that the expensive catalyst material is dispersed over a surface of the inert alumina. Another principal use is as a drying agent or absorbent.\nSeveral sulfates of aluminium have industrial and commercial application. Aluminium sulfate (in its hydrate form) is produced on the annual scale of several millions of metric tons. About two-thirds is consumed in water treatment. The next major application is in the manufacture of paper. It is also used as a mordant in dyeing, in pickling seeds, deodorizing of mineral oils, in leather tanning, and in production of other aluminium compounds. Two kinds of alum, ammonium alum and potassium alum, were formerly used as mordants and in leather tanning, but their use has significantly declined following availability of high-purity aluminium sulfate. Anhydrous aluminium chloride is used as a catalyst in chemical and petrochemical industries, the dyeing industry, and in synthesis of various inorganic and organic compounds. Aluminium hydroxychlorides are used in purifying water, in the paper industry, and as antiperspirants. Sodium aluminate is used in treating water and as an accelerator of solidification of cement.\nMany aluminium compounds have niche applications, for example:\nBiology.\nDespite its widespread occurrence in the Earth's crust, aluminium has no known function in biology. At pH 6\u20139 (relevant for most natural waters), aluminium precipitates out of water as the hydroxide and is hence not available; most elements behaving this way have no biological role or are toxic. Aluminium sulfate has an LD50 of 6207\u00a0mg/kg (oral, mouse), which corresponds to 435 grams (about one pound) for a mouse.\nToxicity.\nAluminium is classified as a non-carcinogen by the United States Department of Health and Human Services. A review published in 1988 said that there was little evidence that normal exposure to aluminium presents a risk to healthy adult, and a 2014 multi-element toxicology review was unable to find deleterious effects of aluminium consumed in amounts not greater than 40\u00a0mg/day per kg of body mass. Most aluminium consumed will leave the body in feces; most of the small part of it that enters the bloodstream, will be excreted via urine; nevertheless some aluminium does pass the blood-brain barrier and is lodged preferentially in the brains of Alzheimer's patients. Evidence published in 1989 indicates that, for Alzheimer's patients, aluminium may act by electrostatically crosslinking proteins, thus down-regulating genes in the superior temporal gyrus.\nEffects.\nAluminium, although rarely, can cause vitamin D-resistant osteomalacia, erythropoietin-resistant microcytic anemia, and central nervous system alterations. People with kidney insufficiency are especially at a risk. Chronic ingestion of hydrated aluminium silicates (for excess gastric acidity control) may result in aluminium binding to intestinal contents and increased elimination of other metals, such as iron or zinc; sufficiently high doses (&gt;50 g/day) can cause anemia.\nDuring the 1988 Camelford water pollution incident people in Camelford had their drinking water contaminated with aluminium sulfate for several weeks. A final report into the incident in 2013 concluded it was unlikely that this had caused long-term health problems.\nAluminium has been suspected of being a possible cause of Alzheimer's disease, but research into this for over 40 years has found, , no good evidence of causal effect.\nAluminium increases estrogen-related gene expression in human breast cancer cells cultured in the laboratory. In very high doses, aluminium is associated with altered function of the blood\u2013brain barrier. A small percentage of people have contact allergies to aluminium and experience itchy red rashes, headache, muscle pain, joint pain, poor memory, insomnia, depression, asthma, irritable bowel syndrome, or other symptoms upon contact with products containing aluminium.\nExposure to powdered aluminium or aluminium welding fumes can cause pulmonary fibrosis. Fine aluminium powder can ignite or explode, posing another workplace hazard.\nExposure routes.\nFood is the main source of aluminium. Drinking water contains more aluminium than solid food; however, aluminium in food may be absorbed more than aluminium from water. Major sources of human oral exposure to aluminium include food (due to its use in food additives, food and beverage packaging, and cooking utensils), drinking water (due to its use in municipal water treatment), and aluminium-containing medications (particularly antacid/antiulcer and buffered aspirin formulations). Dietary exposure in Europeans averages to 0.2\u20131.5\u00a0mg/kg/week but can be as high as 2.3\u00a0mg/kg/week. Higher exposure levels of aluminium are mostly limited to miners, aluminium production workers, and dialysis patients.\nConsumption of antacids, antiperspirants, vaccines, and cosmetics provide possible routes of exposure. Consumption of acidic foods or liquids with aluminium enhances aluminium absorption, and maltol has been shown to increase the accumulation of aluminium in nerve and bone tissues.\nTreatment.\nIn case of suspected sudden intake of a large amount of aluminium, the only treatment is deferoxamine mesylate which may be given to help eliminate aluminium from the body by chelation therapy. However, this should be applied with caution as this reduces not only aluminium body levels, but also those of other metals such as copper or iron.\nEnvironmental effects.\nHigh levels of aluminium occur near mining sites; small amounts of aluminium are released to the environment at coal-fired power plants or incinerators. Aluminium in the air is washed out by the rain or normally settles down but small particles of aluminium remain in the air for a long time.\nAcidic precipitation is the main natural factor to mobilize aluminium from natural sources and the main reason for the environmental effects of aluminium; however, the main factor of presence of aluminium in salt and freshwater are the industrial processes that also release aluminium into air.\nIn water, aluminium acts as a toxi\u0441 agent on gill-breathing animals such as fish when the water is acidic, in which aluminium may precipitate on gills, which causes loss of plasma- and hemolymph ions leading to osmoregulatory failure. Organic complexes of aluminium may be easily absorbed and interfere with metabolism in mammals and birds, even though this rarely happens in practice.\nAluminium is primary among the factors that reduce plant growth on acidic soils. Although it is generally harmless to plant growth in pH-neutral soils, in acid soils the concentration of toxic Al3+ cations increases and disturbs root growth and function. Wheat has developed a tolerance to aluminium, releasing organic compounds that bind to harmful aluminium cations. Sorghum is believed to have the same tolerance mechanism.\nAluminium production possesses its own challenges to the environment on each step of the production process. The major challenge is the greenhouse gas emissions. These gases result from electrical consumption of the smelters and the byproducts of processing. The most potent of these gases are perfluorocarbons from the smelting process. Released sulfur dioxide is one of the primary precursors of acid rain.\nBiodegradation of metallic aluminium is extremely rare; most aluminium-corroding organisms do not directly attack or consume the aluminium, but instead produce corrosive wastes. The fungus \"Geotrichum candidum\" can consume the aluminium in compact discs. The bacterium \"Pseudomonas aeruginosa\" and the fungus \"Cladosporium resinae\" are commonly detected in aircraft fuel tanks that use kerosene-based fuels (not avgas), and laboratory cultures can degrade aluminium."}
{"id": "905", "revid": "20611691", "url": "https://en.wikipedia.org/wiki?curid=905", "title": "Advanced Chemistry", "text": "Advanced Chemistry is a German hip hop group from Heidelberg in Baden-W\u00fcrttemberg, South Germany. Advanced Chemistry was founded in 1987 by Toni L, Linguist, Gee-One, DJ Mike MD (Mike Dippon) and MC Torch. Each member of the group holds German citizenship, and Toni L, Linguist, and Torch are of Italian, Ghanaian, and Haitian backgrounds, respectively.\nInfluenced by North American socially conscious rap and the Native tongues movement, Advanced Chemistry is regarded as one of the main pioneers in German hip hop. They were one of the first groups to rap in German (although their name is in English). Furthermore, their songs tackled controversial social and political issues, distinguishing them from early German hip hop group \"Die Fantastischen Vier\" (The Fantastic Four), which had a more light-hearted, playful, party image.\nCareer.\nAdvanced Chemistry frequently rapped about their lives and experiences as children of immigrants, exposing the marginalization experienced by most ethnic minorities in Germany, and the feelings of frustration and resentment that being denied a German identity can cause. The song \"Fremd im eigenen Land\" (Foreign in your own nation) was released by Advanced Chemistry in November 1992. The single became a staple in the German hip hop scene. It made a strong statement about the status of immigrants throughout Germany, as the group was composed of multi-national and multi-racial members. The video shows several members brandishing their German passports as a demonstration of their German citizenship to skeptical and unaccepting 'ethnic' Germans.\nThis idea of national identity is important, as many rap artists in Germany have been of foreign origin. These so-called \"Gastarbeiter\" (guest workers) children saw breakdance, graffiti, rap music, and hip hop culture as a means of expressing themselves. Since the release of \"Fremd im eigenen Land\", many other German-language rappers have also tried to confront anti-immigrant ideas and develop themes of citizenship. However, though many ethnic minority youth in Germany find these German identity themes appealing, others view the desire of immigrants to be seen as German negatively, and they have actively sought to revive and recreate concepts of identity in connection to traditional ethnic origins.\nAdvanced Chemistry helped to found the German chapter of the Zulu nation.\nThe rivalry between Advanced Chemistry and Die Fantastischen Vier has served to highlight a dichotomy in the routes that hip hop has taken in becoming a part of the German soundscape. While Die Fantastischen Vier may be said to view hip hop primarily as an aesthetic art form, Advanced Chemistry understand hip hop as being inextricably linked to the social and political circumstances under which it is created. For Advanced Chemistry, hip hop is a \u201cvehicle of general human emancipation\u201d. In their undertaking of social and political issues, the band introduced the term \"Afro-German\" into the context of German hip hop, and the theme of race is highlighted in much of their music.\nWith the release of the single \u201cFremd im eigenen Land\u201d, Advanced Chemistry separated itself from the rest of the rap being produced in Germany. This single was the first of its kind to go beyond simply imitating US rap and addressed the current issues of the time. Fremd im eigenen Land which translates to \u201cforeign in my own country\u201d dealt with the widespread racism that non-white German citizens faced. This change from simple imitation to political commentary was the start of German identification with rap. The sound of \u201cFremd im eigenen Land\u201d was influenced by the 'wall of noise' created by Public Enemy's producers, The Bomb Squad.\nAfter the reunification of Germany, an abundance of anti-immigrant sentiment emerged, as well as attacks on the homes of refugees in the early 1990s. Advanced Chemistry came to prominence in the wake of these actions because of their pro-multicultural society stance in their music. Advanced Chemistry's attitudes revolve around their attempts to create a distinct \"Germanness\" in hip hop, as opposed to imitating American hip hop as other groups had done. Torch has said, \"What the Americans do is exotic for us because we don't live like they do. What they do seems to be more interesting and newer. But not for me. For me it's more exciting to experience my fellow Germans in new contexts...For me, it's interesting to see what the kids try to do that's different from what I know.\" Advanced Chemistry were the first to use the term \"Afro-German\" in a hip hop context. This was part of the pro-immigrant political message they sent via their music.\nWhile Advanced Chemistry's use of the German language in their rap allows them to make claims to authenticity and true German heritage, bolstering pro-immigration sentiment, their style can also be problematic for immigrant notions of any real ethnic roots. Indeed, part of the Turkish ethnic minority of Frankfurt views Advanced Chemistry's appeal to the German image as a \"symbolic betrayal of the right of ethnic minorities to 'roots' or to any expression of cultural heritage.\" In this sense, their rap represents a complex social discourse internal to the German soundscape in which they attempt to negotiate immigrant assimilation into a xenophobic German culture with the maintenance of their own separate cultural traditions. It is quite possibly the feelings of alienation from the pure-blooded German demographic that drive Advanced Chemistry to attack nationalistic ideologies by asserting their \"Germanness\" as a group composed primarily of ethnic others. The response to this pseudo-German authenticity can be seen in what Andy Bennett refers to as \"alternative forms of local hip hop culture which actively seek to rediscover and, in many cases, reconstruct notions of identity tied to cultural roots.\" These alternative local hip hop cultures include oriental hip hop, the members of which cling to their Turkish heritage and are confused by Advanced Chemistry's elicitation of a German identity politics to which they technically do not belong. This cultural binary illustrates that rap has taken different routes in Germany and that, even among an already isolated immigrant population, there is still disunity and, especially, disagreement on the relative importance of assimilation versus cultural defiance. According to German hip hop enthusiast 9@home, Advanced Chemistry is part of a \"hip-hop movement [which] took a clear stance for the minorities and against the [marginalization] of immigrants who...might be German on paper, but not in real life,\" which speaks to the group's hope of actually being recognized as German citizens and not foreigners, despite their various other ethnic and cultural ties.\nInfluences.\nAdvanced Chemistry's work was rooted in German history and the country's specific political realities. However, they also drew inspiration from African-American hip-hop acts like A Tribe Called Quest and Public Enemy, who had helped bring a soulful sound and political consciousness to American hip-hop. One member, Torch, later explicitly listed his references on his solo song \"Als (When I Was in School):\" \"My favorite subject, which was quickly discovered poetry in load Poets, awakens the intellect or policy at Chuck D I'll never forget the lyrics by Public Enemy.\" Torch goes on to list other American rappers like Biz Markie, Big Daddy Kane and Dr. Dre as influences.\nBibliography.\nEl-Tayeb, Fatima \u201c\u2018If You Cannot Pronounce My Name, You Can Just Call Me \nPride.\u2019 Afro-German Activism, Gender, and Hip Hop,\u201d \"Gender &amp; History\"15/3(2003):459-485.\nFelbert, Oliver von. \u201cDie Unbestechlichen.\u201d \"Spex\" (March 1993): 50\u201353.\nWeheliye, Alexander G. \"Phonographies:Grooves in Sonic Afro-Modernity\", Duke University Press, 2005."}
{"id": "907", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=907", "title": "Awk", "text": ""}
{"id": "908", "revid": "52", "url": "https://en.wikipedia.org/wiki?curid=908", "title": "AgoraNomic", "text": ""}
{"id": "909", "revid": "42863980", "url": "https://en.wikipedia.org/wiki?curid=909", "title": "Anglican Communion", "text": "The Anglican Communion is the third largest Christian communion after the Roman Catholic and Eastern Orthodox churches. Formally founded in 1867 in London, the communion has more than 85\u00a0million members within the Church of England and other autocephalous national and regional churches in full communion. The traditional origins of Anglican doctrine are summarised in the Thirty-nine Articles (1571) and \"The Books of Homilies\". The archbishop of Canterbury in England acts as a focus of unity, recognised as \"\" (\"first among equals\"), but does not exercise authority in Anglican provinces outside of the Church of England. Most, but not all, member churches of the communion are the historic national or regional Anglican churches.\nThe Anglican Communion was officially and formally organised and recognised as such at the Lambeth Conference in 1867 in London under the leadership of Charles Longley, Archbishop of Canterbury. The churches of the Anglican Communion consider themselves to be part of the one, holy, catholic and apostolic church, with worship being based on the \"Book of Common Prayer\". As in the Church of England itself, the Anglican Communion includes the broad spectrum of beliefs and liturgical practises found in the Evangelical, Central and Anglo-Catholic traditions of Anglicanism; both the larger Reformed Anglican and the smaller Arminian Anglican theological perspectives have been represented. Each national or regional church is fully independent, retaining its own legislative process and episcopal polity under the leadership of local primates. For many adherents, Anglicanism represents a distinct form of Reformed Protestantism that emerged under the influence of the Reformer Thomas Cranmer, or for yet others, a \"via media\" between two branches of Protestantism\u2014Lutheranism and Calvinism\u2014and for others, a denomination that is both Catholic and Reformed.\nMost of its members live in the Anglosphere of former British territories. Full participation in the sacramental life of each church is available to all communicant members. Because of their historical link to England (\"ecclesia anglicana\" means \"English church\"), some of the member churches are known as \"Anglican\", such as the Anglican Church of Canada. Others, for example the Church of Ireland and the Scottish and American Episcopal churches, have official names that do not include \"Anglican\". Conversely, some churches that do use the name \"Anglican\" are not part of the communion. These have generally disaffiliated over disagreement with the direction of the communion.\nHistory.\nThe Anglican Communion traces much of its growth to the older mission organisations of the Church of England such as the Society for Promoting Christian Knowledge (founded 1698), the Society for the Propagation of the Gospel in Foreign Parts (founded 1701) and the Church Missionary Society (founded 1799). The Church of England (which until the 20th century included the Church in Wales) initially separated from the Roman Catholic Church in 1534 in the reign of Henry VIII, reunited briefly in 1555 under Mary I and then separated again in 1570 under Elizabeth I (the Roman Catholic Church excommunicated Elizabeth I in 1570 in response to the Act of Supremacy 1559).\nThe Church of England has always thought of itself not as a new foundation but rather as a reformed continuation of the ancient \"English Church\" (\"Ecclesia Anglicana\") and a reassertion of that church's rights. As such it was a distinctly national phenomenon. The Church of Scotland was formed as a separate church from the Roman Catholic Church as a result of the Scottish Reformation in 1560 and the later formation of the Scottish Episcopal Church began in 1582 in the reign of James VI over disagreements about the role of bishops.\nThe oldest-surviving Anglican church building outside the British Isles (Britain and Ireland) is St Peter's Church in St George's, Bermuda, established in 1612 (though the actual building had to be rebuilt several times over the following century). This is also the oldest surviving non-Roman Catholic church in the New World. It remained part of the Church of England until 1978 when the Anglican Church of Bermuda was formed. The Church of England was the established church not only in England, but in its trans-Oceanic colonies. Thus the only member churches of the present Anglican Communion existing by the mid-18th century were the Church of England, its closely linked sister church the Church of Ireland (which also separated from Roman Catholicism under Henry VIII) and the Scottish Episcopal Church which for parts of the 17th and 18th centuries was partially underground (it was suspected of Jacobite sympathies).\nGlobal spread of Anglicanism.\nThe enormous expansion in the 18th and 19th centuries of the British Empire brought Anglicanism along with it. At first all these colonial churches were under the jurisdiction of the bishop of London. After the American Revolution, the parishes in the newly independent country found it necessary to break formally from a church whose supreme governor was (and remains) the British monarch. Thus they formed their own dioceses and national church, the Episcopal Church in the United States of America, in a mostly amicable separation.\nAt about the same time, in the colonies which remained linked to the crown, the Church of England began to appoint colonial bishops. In 1787, Charles Inglis (Bishop of Nova Scotia) was appointed with a jurisdiction over all of British North America; in time several more colleagues were appointed to other cities in present-day Canada. In 1814, a bishop of Calcutta was made; in 1824 the first bishop was sent to the West Indies and in 1836 to Australia. By 1840 there were still only ten colonial bishops for the Church of England; but even this small beginning greatly facilitated the growth of Anglicanism around the world. In 1841, a \"Colonial Bishoprics Council\" was set up and soon many more dioceses were created.\nIn time, it became natural to group these into provinces and a metropolitan bishop was appointed for each province. Although it had at first been somewhat established in many colonies, in 1861 it was ruled that, except where specifically established, the Church of England had just the same legal position as any other church. Thus a colonial bishop and colonial diocese was by nature quite a different thing from their counterparts back home. In time bishops came to be appointed locally rather than from England and eventually national synods began to pass ecclesiastical legislation independent of England.\nA crucial step in the development of the modern communion was the idea of the Lambeth Conferences (discussed above). These conferences demonstrated that the bishops of disparate churches could manifest the unity of the church in their episcopal collegiality despite the absence of universal legal ties. Some bishops were initially reluctant to attend, fearing that the meeting would declare itself a council with power to legislate for the church; but it agreed to pass only advisory resolutions. These Lambeth Conferences have been held roughly every ten years since 1878 (the second such conference) and remain the most visible coming-together of the whole communion.\nThe Lambeth Conference of 1998 included what has been seen by Philip Jenkins and others as a \"watershed in global Christianity\". The 1998 Lambeth Conference considered the issue of the theology of same-sex attraction in relation to human sexuality. At this 1998 conference for the first time in centuries the Christians of developing regions, especially, Africa, Asia and Latin America, prevailed over the bishops of more prosperous countries (many from the US, Canada and the UK) who supported a redefinition of Anglican doctrine. Seen in this light, 1998 is a date that marked the shift from a West-dominated Christianity to one wherein the growing churches of the two-thirds world are predominant.\n21st-century \"de facto\" schisms.\nMany of the provinces in developed countries have continued to adopt more liberal stances on sexuality and other issues, resulting in a number of de facto schisms, such the series of splits which led to the creation of the Anglican Church in North America. Many churches are now in full communion with only some other churches but not others, although all churches continue to claim to be part of the Anglican Communion.\nIn a watershed moment, on 20 February 2023, following the decision of the Church of England to allow priests to bless same-sex partnerships, ten communion provinces and Anglican realignment churches within the Global South Fellowship of Anglican Churches released a statement stating that they had declared \"impaired communion\" with the Church of England and no longer recognised Justin Welby as \"first among equals\" among the bishops of the communion.\nDifferences and controversies.\nSome effects of the Anglican Communion's dispersed authority have been differences of opinion (and conflicts) arising over divergent practices and doctrines in parts of the communion. Disputes that had been confined to the Church of England could be dealt with legislatively in that realm, but as the communion spread out into new countries and territories, and disparate cultures, controversies often multiplied and intensified. These controversies have generally been of two types: liturgical and social.\nRapid social change and the dissipation of British cultural hegemony over its former colonies contributed to disputes over the role of women, and the parameters of marriage and divorce. In the late 1970s, the Continuing Anglican movement produced a number of new church bodies in opposition to women's ordination, prayer book changes, and the new understandings concerning marriage.\nAnglo-Catholicism.\nThe first such controversy of note concerned that of the growing influence of the Catholic Revival manifested in the Tractarian and so-called Ritualist controversies of the late 19th and early 20th centuries. This controversy produced the Free Church of England and, in the United States and Canada, the Reformed Episcopal Church.\nAbortion and euthanasia.\nWhile individual Anglicans and member churches within the communion differ in good faith over the circumstances in which abortion should or should not be permitted, Lambeth Conference resolutions have consistently held to a conservative view on the issue. The 1930 conference, the first to be held since the initial legalisation of abortion in Europe (in Russia in 1920), stated:\nThe 1958 conference's \"Family in Contemporary Society\" report affirmed the following position on abortion and was commended by the 1968 conference:\nThe subsequent Lambeth Conference, in 1978, made no change to this position and commended the need for \"programmes at diocesan level, involving both men and women ... to emphasise the sacredness of all human life, the moral issues inherent in clinical abortion, and the possible implications of genetic engineering.\"\nIn the context of debates around and proposals for the legalisation of euthanasia and assisted suicide, the 1998 conference affirmed that \"life is God-given and has intrinsic sanctity, significance and worth\".\nSame-sex unions and LGBT clergy.\nMore recently, disagreements over homosexuality have strained the unity of the communion as well as its relationships with other Christian denominations, leading to another round of withdrawals from the Anglican Communion. Some churches were founded outside the Anglican Communion in the late 20th and early 21st centuries, largely in opposition to the ordination of openly homosexual bishops and other clergy and are usually referred to as belonging to the Anglican realignment movement, or else as \"orthodox\" Anglicans. These disagreements were especially noted when The Episcopal Church (US) consecrated an openly gay bishop in a same-sex relationship, Gene Robinson, in 2003, which led some Episcopalians to defect and found the Anglican Church in North America (ACNA); then, the debate reignited when the Church of England agreed to allow clergy to enter into same-sex civil partnerships, as long as they remained celibate, in 2005. The Church of Nigeria opposed the Episcopal Church's decision as well as the Church of England's approval for celibate civil partnerships.\n\"The more liberal provinces that are open to changing Church doctrine on marriage in order to allow for same-sex unions include Brazil, Canada, New Zealand, Scotland, South India, South Africa, the US and Wales\". In 2023, the Church of England announced that it will authorise \"prayers of thanksgiving, dedication and for God's blessing for same-sex couples\". The Church of England also permits clergy to enter into same-sex civil partnerships. In 2024, the Church of England's General Synod voted to support allowing clergy to enter in civil same-sex marriages. In 2023, the Anglican Church of Southern Africa's bishops approved the drafting of prayers that could be said with same-sex couples and the draft prayers were published for consideration in 2024. The Church of Ireland has no official position on civil unions, and one senior cleric has entered into a same-sex civil partnership. The Church of Ireland recognised that it will \"treat civil partners the same as spouses\". The Anglican Church of Australia does not have an official position on homosexuality.\nThe conservative Anglican churches encouraging the realignment movement are more concentrated in the Global South. For example, the Anglican Church of Kenya, the Church of Nigeria and the Church of Uganda have opposed homosexuality. GAFCON, a fellowship of conservative Anglican churches, has appointed \"missionary bishops\" in response to the disagreements with the perceived liberalisation in the Anglican churches in North America and Europe. In 2023, ten archbishops within the Anglican Communion and two breakaway churches in North America and Brazil from the Global South Fellowship of Anglican Churches (GSFA) declared a state of impaired communion with the Church of England and announced that they would no longer recognise the archbishop of Canterbury as the \"first among equals\" among the bishops in the Anglican Communion. However, in the same statement, the ten archbishops said that they would not leave the Anglican Communion. In 2024, the GSFA met again establishing \"a new structure,\" no longer recognising the Archbishop of Canterbury \"as the \"de facto\" leader\" of the Anglican Communion, but the GSFA reiterated that they intend to remain in the Anglican Communion.\nDebates about social theology and ethics have occurred at the same time as debates on prayer book revision and the acceptable grounds for achieving full communion with non-Anglican churches.\nEcclesiology, polity and ethos.\nThe Anglican Communion has no official legal existence nor any governing structure that might exercise authority over the member churches. There is an Anglican Communion Office in London, under the aegis of the archbishop of Canterbury, but it serves only in a supporting and organisational role. The communion is held together by a shared history, expressed in its ecclesiology, polity and ethos, and also by participation in international consultative bodies.\nThree elements have been important in holding the communion together: first, the shared ecclesial structure of the component churches, manifested in an episcopal polity maintained through the apostolic succession of bishops and synodical government; second, the principle of belief expressed in worship, investing importance in approved prayer books and their rubrics; and third, the historical documents and the writings of early Anglican divines that have influenced the ethos of the communion.\nOriginally, the Church of England was self-contained and relied for its unity and identity on its own history, its traditional legal and episcopal structure, and its status as an established church of the state. As such, Anglicanism was from the outset a movement with an explicitly episcopal polity, a characteristic that has been vital in maintaining the unity of the communion by conveying the episcopate's role in manifesting visible catholicity and ecumenism.\nEarly in its development following the English Reformation, Anglicanism developed a vernacular prayer book, called the \"Book of Common Prayer\". Unlike other traditions, Anglicanism has never been governed by a magisterium nor by appeal to one founding theologian, nor by an extra-credal summary of doctrine (such as the Westminster Confession of the Presbyterian churches). Instead, Anglicans have typically appealed to the \"Book of Common Prayer\" (1662) and its offshoots as a guide to Anglican theology and practise. This has had the effect of inculcating in Anglican identity and confession the principle of (\"the law of praying [is] the law of believing\").\nProtracted conflict through the 17th century, with radical Protestants on the one hand and Roman Catholics who recognised the primacy of the Pope on the other, resulted in an association of churches that was both deliberately vague about doctrinal principles, yet bold in developing parameters of acceptable deviation. These parameters were most clearly articulated in the various rubrics of the successive prayer books, as well as the Thirty-nine Articles of Religion (1563). These articles have historically shaped and continue to direct the ethos of the communion, an ethos reinforced by its interpretation and expansion by such influential early theologians such as Richard Hooker, Lancelot Andrewes and John Cosin.\nWith the expansion of the British Empire and the growth of Anglicanism outside Great Britain and Ireland, the communion sought to establish new vehicles of unity. The first major expressions of this were the Lambeth Conferences of the communion's bishops, first convened in 1867 by Charles Longley, the archbishop of Canterbury. From the beginning, these were not intended to displace the autonomy of the emerging provinces of the communion, but to \"discuss matters of practical interest, and pronounce what we deem expedient in resolutions which may serve as safe guides to future action\".\nChicago Lambeth Quadrilateral.\nOne of the enduringly influential early resolutions of the conference was the so-called Chicago-Lambeth Quadrilateral of 1888. Its intent was to provide the basis for discussions of reunion with the Roman Catholic and Orthodox churches, but it had the ancillary effect of establishing parameters of Anglican identity. It establishes four principles with these words:\nInstruments of communion.\nAs mentioned above, the Anglican Communion has no international juridical organisation. The archbishop of Canterbury's role is strictly symbolic and unifying and the communion's three international bodies are consultative and collaborative, their resolutions having no legal effect on the autonomous provinces of the communion. Taken together, however, the four do function as \"instruments of communion\", since all churches of the communion participate in them. In order of antiquity, they are:\nSince there is no binding authority in the Anglican Communion, these international bodies are a vehicle for consultation and persuasion. In recent times, persuasion has tipped over into debates over conformity in certain areas of doctrine, discipline, worship and ethics. The most notable example has been the objection of many provinces of the communion (particularly in Africa and Asia) to the changing acceptance of LGBTQ+ individuals in the North American churches (e.g., by blessing same-sex unions and ordaining and consecrating same-sex relationships) and to the process by which changes were undertaken. (See Anglican realignment)\nThose who objected condemned these actions as unscriptural, unilateral, and without the agreement of the communion prior to these steps being taken. In response, the American Episcopal Church and the Anglican Church of Canada answered that the actions had been undertaken after lengthy scriptural and theological reflection, legally in accordance with their own canons and constitutions and after extensive consultation with the provinces of the communion.\nThe Primates' Meeting voted to request the two churches to withdraw their delegates from the 2005 meeting of the Anglican Consultative Council. Canada and the United States decided to attend the meeting but without exercising their right to vote. They have not been expelled or suspended, since there is no mechanism in this voluntary association to suspend or expel an independent province of the communion. Since membership is based on a province's communion with Canterbury, expulsion would require the archbishop of Canterbury's refusal to be in communion with the affected jurisdictions. In line with the suggestion of the Windsor Report, Rowan Williams (the then archbishop of Canterbury) established a working group to examine the feasibility of an Anglican covenant which would articulate the conditions for communion in some fashion.\nOrganisation.\nProvinces.\nThe Anglican Communion consists of forty-two autonomous provinces each with its own primate and governing structure. These provinces may take the form of national churches (such as in Canada, Uganda, or Japan) or a collection of nations (such as the West Indies, Central Africa, or Southeast Asia).\nExtraprovincial churches.\nIn addition to the forty-two provinces, there are five extraprovincial churches under the metropolitical authority of the archbishop of Canterbury.\nNew provinces in formation.\nIn September 2020, the Archbishop of Canterbury announced that he had asked the bishops of the Church of Ceylon to begin planning for the formation of an autonomous province of Ceylon, so as to end his current position as metropolitan of the two dioceses in that country.\nChurches in full communion.\nIn addition to other member churches, the churches of the Anglican Communion are in full communion with the Old Catholic churches of the Union of Utrecht and the Scandinavian Lutheran churches of the Porvoo Communion in Europe, the India-based Malankara Mar Thoma Syrian and Malabar Independent Syrian churches and the Philippine Independent Church, also known as the Aglipayan Church.\nHistoric episcopate.\nThe churches of the Anglican Communion have traditionally held that ordination in the historic episcopate is a core element in the validity of clerical ordinations. The Roman Catholic Church, however, does not recognise Anglican orders (see \"Apostolicae curae\"). Some Eastern Orthodox churches have issued statements to the effect that Anglican orders could be accepted, yet have still reordained former Anglican clergy; other Eastern Orthodox churches have rejected Anglican orders altogether. Orthodox bishop Kallistos Ware explains this apparent discrepancy as follows:"}
{"id": "910", "revid": "1544984", "url": "https://en.wikipedia.org/wiki?curid=910", "title": "Arne Kaijser", "text": "Arne Kaijser (born 1950) is a professor emeritus of history of technology at the KTH Royal Institute of Technology in Stockholm, and a former president of the Society for the History of Technology.\nKaijser has published two books in Swedish: \"Stadens ljus. Etableringen av de f\u00f6rsta svenska gasverken\" and \"I f\u00e4drens sp\u00e5r. Den svenska infrastrukturens historiska utveckling och framtida utmaningar\", and has co-edited several anthologies. Kaijser is a member of the Royal Swedish Academy of Engineering Sciences since 2007 and also a member of the editorial board of two scientific journals: \"Journal of Urban Technology\" and \"Centaurus\". Lately, he has been occupied with the history of Large Technical Systems."}
{"id": "911", "revid": "47570707", "url": "https://en.wikipedia.org/wiki?curid=911", "title": "Archipelago", "text": "An archipelago ( ), sometimes called an island group or island chain, is a chain, cluster, or collection of islands, or a sea containing a small number of scattered islands. An archipelago may be on a lake, river, or an ocean. The list of archipelagos includes the Canadian Arctic Archipelago, the Stockholm Archipelago, the Malay Archipelago (which includes the Indonesian and Philippine Archipelagos), the Bahamian Archipelago, the nation of Japan and the state of Hawaii.\nEtymology.\nThe word \"archipelago\" is derived from the Italian \"arcipelago\", used as a proper name for the Aegean Sea, itself perhaps a deformation of the Greek \u0391\u03b9\u03b3\u03b1\u03af\u03bf\u03bd \u03a0\u03ad\u03bb\u03b1\u03b3\u03bf\u03c2. Later, usage shifted to refer to the Aegean Islands (since the sea has a large number of islands). The erudite paretymology deriving the word from Ancient Greek \u1f04\u03c1\u03c7\u03b9-(\"arkhi-\", \"chief\") and \u03c0\u03ad\u03bb\u03b1\u03b3\u03bf\u03c2 (\"p\u00e9lagos\", \"sea\"), proposed by Buondelmonti, can still be found here and there.\nGeographic types.\nArchipelagos may be found isolated in large amounts of water or neighboring a large land mass. For example, Scotland has more than 700\u00a0islands surrounding its mainland, which form an archipelago.\nDepending on their geological origin, islands forming archipelagos can be referred to as \"oceanic islands\", \"continental fragments\", or \"continental islands\".\nOceanic islands.\nOceanic islands are formed by volcanoes erupting from the ocean floor. The Hawaiian Islands and Galapagos Islands in the Pacific, and Mascarene Islands in the south Indian Ocean are examples.\nContinental fragments.\nContinental fragments are islands that were once part of a continent, and became separated due to natural disasters. The fragments may also be formed by moving glaciers which cut out land, which then fills with water. The Farallon Islands off the coast of California are examples of continental islands.\nContinental Islands.\nContinental islands are islands that were once part of a continent and still sit on the continental shelf, which is the edge of a continent that lies under the ocean. The islands of the Inside Passage off the coast of British Columbia and the Canadian Arctic Archipelago are examples.\nArtificial archipelagos.\nArtificial archipelagos have been created in various countries for different purposes. Palm Islands and The World Islands in Dubai were or are being created for leisure and tourism purposes. Marker Wadden in the Netherlands is being built as a conservation area for birds and other wildlife.\nSuperlatives.\nThe largest archipelago in the world by number of islands is the Archipelago Sea, which is part of Finland. There are approximately 40,000 islands, mostly uninhabited. \nThe largest archipelagic state in the world by area, and by population, is Indonesia."}
{"id": "914", "revid": "49126472", "url": "https://en.wikipedia.org/wiki?curid=914", "title": "Author", "text": "In legal discourse, an author is the creator of an original work that has been published, whether that work is in written, graphic, or recorded medium. The creation of such a work is an act of authorship. Thus, a sculptor, painter, or composer, is an author of their respective sculptures, paintings, or compositions, even though in common parlance, an author is often thought of as the writer of a book, article, play, or other written work. In the case of a work for hire, the employer or commissioning party is considered the author of the work, even if they did not write or otherwise create the work, but merely instructed another individual to do so.\nTypically, the first owner of a copyright is the person who created the work, i.e. the author. If more than one person created the work, then a case of joint authorship takes place. Copyright laws differ around the world. The United States Copyright Office, for example, defines copyright as \"a form of protection provided by the laws of the United States (title 17, U.S. Code) to authors of 'original works of authorship.\nSome works are considered to be author-less. For example, the monkey selfie copyright dispute in the 2010s involved photographs taken by Celebes crested macaques using equipment belonging to a nature photographer. The photographer asserted authorship of the photographs, which the United States Copyright Office denied, stating: \"To qualify as a work of 'authorship' a work must be created by a human being\". More recently, questions have arisen as to whether images or text created by a generative artificial intelligence have an author.\nLegal significance of authorship.\nHolding the title of \"author\" over any \"literary, dramatic, musical, artistic, [or] certain other intellectual works\" gives rights to this person, the owner of the copyright, especially the exclusive right to engage in or authorize any production or distribution of their work. Any person or entity wishing to use intellectual property held under copyright must receive permission from the copyright holder to use this work, and often will be asked to pay for the use of copyrighted material.\nThe copyrights on intellectual work expire after a certain time. It enters the public domain, where it can be used without limit. Copyright laws in many jurisdictions \u2013 mostly following the lead of the United States, in which the entertainment and publishing industries have very strong lobbying power \u2013 have been amended repeatedly since their inception, to extend the length of this fixed period where the work is exclusively controlled by the copyright holder. Technically, someone owns their work from the time it's created. A notable aspect of authorship emerges with copyright in that, in many jurisdictions, it can be passed down to another, upon one's death. The person who inherits the copyright is not the author, but has access to the same legal benefits.\nIntellectual property laws are complex. Works of fiction involve trademark law, likeness rights, fair use rights held by the public (including the right to parody or satirize), and many other interacting complications.\nAuthors may portion out the different rights that they hold to different parties at different times, and for different purposes or uses, such as the right to adapt a plot into a film, television series, or video game. If another party chooses to adapt the work, they may have to alter plot elements or character names in order to avoid infringing previous adaptations. An author may also not have rights when working under contract that they would otherwise have, such as when creating a work for hire (e.g., hired to write a city tour guide by a municipal government that totally owns the copyright to the finished work), or when writing material using intellectual property owned by others (such as when writing a novel or screenplay that is a new installment in an already established media franchise).\nIn the United States, the Copyright Clause of the Constitution of the United States () provides the Congress with the power of \"securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries\". The language regarding authors was derived from proposals by Charles Pinckney, \"to secure to authors exclusive rights for a limited time\", and by James Madison, \"to secure to literary authors their copyrights for a limited time\", or, in the alternative, \"to encourage, by proper premiums &amp; Provisions, the advancement of useful knowledge and discoveries\". Both proposals were referred to the Committee of Detail, which reported back a proposal containing the final language, which was incorporated into the Constitution by unanimous agreement of the convention.\nPhilosophical views of the nature of authorship.\nThe Statute of Anne in 1710 set a legal precedent which laid the foundations of copyright, further establishing an author as the sole creator of a literary work. While this legislation acknowledged that an author\u2019s words were their Intellectual property, it in no way protected that author's ideas. For example, one writer could legally copy another writer\u2019s plot exactly, as long as the words were not copied verbatim. In other words, the Statue of Anne protected an author's form of expression but not the thoughts behind their words.\nIn literary theory, critics find complications in the term \"author\" beyond what constitutes authorship in a legal setting. In the wake of postmodern literature, critics such as Roland Barthes and Michel Foucault have examined the role and relevance of authorship to the meaning or interpretation of a literary text.\nBarthes challenges the idea that a text can be attributed to any single author. He writes, in his essay \"Death of the Author\" (1968), that \"it is language which speaks, not the author.\" The words and language of a text itself determine and expose meaning for Barthes, and not someone possessing legal responsibility for the process of its production. Every line of written text is a mere reflection of references from any of a multitude of traditions, or, as Barthes puts it, \"the text is a tissue of quotations drawn from the innumerable centers of culture\"; it is never original. With this, the perspective of the author is removed from the text, and the limits formerly imposed by the idea of one authorial voice, one ultimate and universal meaning, are destroyed. The explanation and meaning of a work does not have to be sought in the one who produced it, \"as if it were always in the end, through the more or less transparent allegory of the fiction, the voice of a single person, the author 'confiding' in us.\" The psyche, culture, fanaticism of an author can be disregarded when interpreting a text, because the words are rich enough themselves with all of the traditions of language. To expose meanings in a written work without appealing to the celebrity of an author, their tastes, passions, vices, is, to Barthes, to allow language to speak, rather than author.\nMichel Foucault argues in his essay \"What is an author?\" (1969) that all authors are writers, but not all writers are authors. He states that \"a private letter may have a signatory\u2014it does not have an author.\" For a reader to assign the title of author upon any written work is to attribute certain standards upon the text which, for Foucault, are working in conjunction with the idea of \"the author function.\" Foucault's author function is the idea that an author exists only as a function of a written work, a part of its structure, but not necessarily part of the interpretive process. The author's name \"indicates the status of the discourse within a society and culture,\" and at one time was used as an anchor for interpreting a text, a practice which Barthes would argue is not a particularly relevant or valid endeavor.\nExpanding upon Foucault's position, Alexander Nehamas writes that Foucault suggests \"an author [...] is whoever can be understood to have produced a particular text as we interpret it,\" not necessarily who penned the text. It is this distinction between producing a written work and producing the interpretation or meaning in a written work that both Barthes and Foucault are interested in. Foucault warns of the risks of keeping the author's name in mind during interpretation, because it could affect the value and meaning with which one handles an interpretation.\nLiterary critics Barthes and Foucault suggest that readers should not rely on or look for the notion of one overarching voice when interpreting a written work, because of the complications inherent with a writer's title of \"author.\" They warn of the dangers interpretations could suffer from when associating the subject of inherently meaningful words and language with the personality of one authorial voice. Instead, readers should allow a text to be interpreted in terms of the language as \"author.\"\nRelationship with publisher.\nSelf-publishing.\nSelf-publishing is a model where the author takes full responsibility and control of arranging financing, editing, printing, and distribution of their own work. In other words, the author also acts as the publisher of their work.\nTraditional publishing.\nWith commissioned publishing, the publisher makes all the publication arrangements and the author covers all expenses.\nThe author of a work may receive a percentage calculated on a wholesale or a specific price or a fixed amount on each book sold. Publishers, at times, reduced the risk of this type of arrangement, by agreeing only to pay this after a certain number of copies had sold. In Canada, this practice occurred during the 1890s, but was not commonplace until the 1920s. Established and successful authors may receive advance payments, set against future royalties, but this is no longer common practice. Most independent publishers pay royalties as a percentage of net receipts \u2013 how net receipts are calculated varies from publisher to publisher. Under this arrangement, the author does not pay anything towards the expense of publication. The costs and financial risk are all carried by the publisher, who will then take the greatest percentage of the receipts. See Compensation for more.\nVanity publishing.\nVanity publishers normally charge a flat fee for arranging publication, offer a platform for selling, and then take a percentage of the sale of every copy of a book. The author receives the rest of the money made. Most materials published this way are for niche groups and not for large audiences.\nVanity publishing, or subsidy publishing, is stigmatized in the professional world. In 1983, Bill Henderson defined vanity publishers as people who would \"publish anything for which an author will pay, usually at a loss for the author and a nice profit for the publisher.\" In subsidy publishing, the book sales are not the publishers' main source of income, but instead the fees that the authors are charged to initially produce the book are. Because of this, the vanity publishers need not invest in making books marketable as much as other publishers need to. This leads to low quality books being introduced to the market.\nRelationship with editor.\nThe relationship between the author and the editor, often the author's only liaison to the publishing company, is typically characterized as the site of tension. For the author to reach their audience, often through publication, the work usually must attract the attention of the editor. The idea of the author as the sole meaning-maker of necessity changes to include the influences of the editor and the publisher to engage the audience in writing as a social act. \nThere are three principal kinds of editing: \nPierre Bourdieu's essay \"The Field of Cultural Production\" depicts the publishing industry as a \"space of literary or artistic position-takings,\" also called the \"field of struggles,\" which is defined by the tension and movement inherent among the various positions in the field. Bourdieu claims that the \"field of position-takings [...] is not the product of coherence-seeking intention or objective consensus,\" meaning that an industry characterized by position-takings is not one of harmony and neutrality. In particular for the writer, their authorship in their work makes their work part of their identity, and there is much at stake personally over the negotiation of authority over that identity. However, it is the editor who has \"the power to impose the dominant definition of the writer and therefore to delimit the population of those entitled to take part in the struggle to define the writer\". As \"cultural investors,\" publishers rely on the editor position to identify a good investment in \"cultural capital\" which may grow to yield economic capital across all positions.\nAccording to the studies of James Curran, the system of shared values among editors in Britain has generated a pressure among authors to write to fit the editors' expectations, removing the focus from the reader-audience and putting a strain on the relationship between authors and editors and on writing as a social act. Even the book review by the editors has more significance than the readership's reception.\nCompensation.\nAuthors rely on advance fees, royalty payments, adaptation of work to a screenplay, and fees collected from giving speeches.\nA standard contract for an author will usually include provision for payment in the form of an advance and royalties.\nUsually, an author's book must earn the advance before any further royalties are paid. For example, if an author is paid a modest advance of $2000, and their royalty rate is 10% of a book priced at $20 \u2013 that is, $2 per book \u2013 the book will need to sell 1000 copies before any further payment will be made. Publishers typically withhold payment of a percentage of royalties earned against returns.\nIn some countries, authors also earn income from a government scheme such as the ELR (educational lending right) and PLR (public lending right) schemes in Australia. Under these schemes, authors are paid a fee for the number of copies of their books in educational and/or public libraries.\nThese days, many authors supplement their income from book sales with public speaking engagements, school visits, residencies, grants, and teaching positions.\nGhostwriters, technical writers, and textbooks writers are typically paid in a different way: usually a set fee or a per word rate rather than on a percentage of sales.\nIn the year 2016, according to the U.S. Bureau of Labor Statistics, nearly 130,000 people worked in the country as authors, making an average of $61,240 per year."}
{"id": "915", "revid": "43237527", "url": "https://en.wikipedia.org/wiki?curid=915", "title": "Andrey Markov", "text": "Andrey Andreyevich Markov (14 June 1856 \u2013 20 July 1922) was a Russian mathematician best known for his work on stochastic processes. A primary subject of his research later became known as the Markov chain. He was also a strong, close to master-level, chess player.\nMarkov and his younger brother Vladimir Andreyevich Markov (1871\u20131897) proved the Markov brothers' inequality.\nHis son, another Andrey Andreyevich Markov (1903\u20131979), was also a notable mathematician, making contributions to constructive mathematics and recursive function theory.\nBiography.\nAndrey Markov was born on 14 June 1856 in Russia. He attended the St. Petersburg Grammar School, where some teachers saw him as a rebellious student. In his academics he performed poorly in most subjects other than mathematics. Later in life he attended Saint Petersburg Imperial University (now Saint Petersburg State University). Among his teachers were Yulian Sokhotski (differential calculus, higher algebra), Konstantin Posse (analytic geometry), Yegor Zolotarev (integral calculus), Pafnuty Chebyshev (number theory and probability theory), Aleksandr Korkin (ordinary and partial differential equations), Mikhail Okatov (mechanism theory), Osip Somov (mechanics), and Nikolai Budajev (descriptive and higher geometry). He completed his studies at the university and was later asked if he would like to stay and have a career as a mathematician. He later taught at high schools and continued his own mathematical studies. In this time he found a practical use for his mathematical skills. He figured out that he could use chains to model the alliteration of vowels and consonants in Russian literature. He also contributed to many other mathematical aspects in his time. He died at age 66 on 20 July 1922.\nTimeline.\nIn 1877, Markov was awarded a gold medal for his outstanding solution of the problem\n\"About Integration of Differential Equations by Continued Fractions with an Application to the Equation\" formula_1.\nDuring the following year, he passed the candidate's examinations, and he remained at the university to prepare for a lecturer's position.\nIn April 1880, Markov defended his master's thesis \"On the Binary Square Forms with Positive Determinant\", which was directed by Aleksandr Korkin and Yegor Zolotarev. Four years later in 1884, he defended his doctoral thesis titled \"On Certain Applications of the Algebraic Continuous Fractions\".\nHis pedagogical work began after the defense of his master's thesis in autumn 1880. As a privatdozent he lectured on differential and integral calculus. Later he lectured alternately on \"introduction to analysis\", probability theory (succeeding Chebyshev, who had left the university in 1882) and the calculus of differences. From 1895 through 1905 he also lectured in differential calculus.\nOne year after the defense of his doctoral thesis, Markov was appointed extraordinary professor (1886) and in the same year he was elected adjunct to the Academy of Sciences. In 1890, after the death of Viktor Bunyakovsky, Markov became an extraordinary member of the academy. His promotion to an ordinary professor of St. Petersburg University followed in the fall of 1894.\nIn 1896, Markov was elected an ordinary member of the academy as the successor of Chebyshev. In 1905, he was appointed merited professor and was granted the right to retire, which he did immediately. Until 1910, however, he continued to lecture in the calculus of differences.\nIn connection with student riots in 1908, professors and lecturers of St. Petersburg University were ordered to monitor their students. Markov refused to accept this decree, and he wrote an explanation in which he declined to be an \"agent of the governance\". Markov was removed from further teaching duties at St. Petersburg University, and hence he decided to retire from the university.\nMarkov was an atheist. In 1912, he responded to Leo Tolstoy's excommunication from the Russian Orthodox Church by requesting his own excommunication. The Church complied with his request.\nIn 1913, the council of St. Petersburg elected nine scientists honorary members of the university. Markov was among them, but his election was not affirmed by the minister of education. The affirmation only occurred four years later, after the February Revolution in 1917. Markov then resumed his teaching activities and lectured on probability theory and the calculus of differences until his death in 1922."}
{"id": "918", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=918", "title": "Anti-semitism", "text": ""}
{"id": "919", "revid": "988682006", "url": "https://en.wikipedia.org/wiki?curid=919", "title": "Anti-semitic", "text": ""}
{"id": "921", "revid": "1273141165", "url": "https://en.wikipedia.org/wiki?curid=921", "title": "Angst", "text": "Angst is a feeling of anxiety, apprehension, or insecurity. \"Anguish\" is its Latinate equivalent, and the words \"anxious\" and \"anxiety\" are of similar origin.\nEtymology.\nThe word \"angst\" was introduced into English from the Danish, Norwegian, and Dutch word and the German word . It is attested since the 19th century in English translations of the works of S\u00f8ren Kierkegaard and Sigmund Freud. It is used in English to describe an intense feeling of apprehension, anxiety, or inner turmoil.\nIn other languages (with words from the Latin for \"fear\" or \"panic\"), the derived words differ in meaning; for example, as in the French and . The word \"angst\" has existed in German since the 8th century, from the Proto-Indo-European root , \"restraint\" from which Old High German developed. It is pre-cognate with the Latin , \"tensity, tightness\" and , \"choking, clogging\"; compare to the Ancient Greek () \"strangle\". It entered English in the 19th century as a technical term used in Psychiatry, though earlier cognates existed, such as \"ange\".\nExistentialism.\nIn existentialist philosophy, the term \"angst\" carries a specific conceptual meaning. The use of the term was first attributed to Danish philosopher S\u00f8ren Kierkegaard (1813\u20131855). In \"The Concept of Anxiety\" (originally translated as \"The Concept of Dread\"), Kierkegaard used the word \"Angest\" (in common Danish, \"angst\", meaning \"dread\" or \"anxiety\") to describe a profound and deep-seated condition. Where non-human animals are guided solely by instinct, said Kierkegaard, human beings enjoy a freedom of choice that we find both appealing and terrifying. It is the anxiety of understanding of being free when considering undefined possibilities of one's life and the immense responsibility of having the power of choice over them. Kierkegaard's concept of angst reappeared in the works of existentialist philosophers who followed, such as Friedrich Nietzsche, Jean-Paul Sartre, and Martin Heidegger, each of whom developed the idea further in individual ways. While Kierkegaard's angst referred mainly to ambiguous feelings about moral freedom within a religious personal belief system, later existentialists discussed conflicts of personal principles, cultural norms, and existential despair.\nMusic.\nExistential angst makes its appearance in classical musical composition in the early twentieth century as a result of both philosophical developments and as a reflection of the war-torn times. Notable composers whose works are often linked with the concept include Gustav Mahler, Richard Strauss (operas ' and '), Claude Debussy (opera \"\", ballet \"Jeux\"), Jean Sibelius (especially the Fourth Symphony), Arnold Schoenberg (\"A Survivor from Warsaw\"), Alban Berg, Francis Poulenc (opera \"Dialogues of the Carmelites\"), Dmitri Shostakovich (opera \"Lady Macbeth of Mtsensk\", symphonies and chamber music), B\u00e9la Bart\u00f3k (opera \"Bluebeard's Castle\"), and Krzysztof Penderecki (especially \"Threnody to the Victims of Hiroshima\").\nAngst began to be discussed in reference to popular music in the mid- to late 1950s, amid widespread concerns over international tensions and nuclear proliferation. Jeff Nuttall's book \"Bomb Culture\" (1968) traced angst in popular culture to Hiroshima. Dread was expressed in works of folk rock such as Bob Dylan's \"Masters of War\" (1963) and \"A Hard Rain's a-Gonna Fall\". The term often makes an appearance in reference to punk rock, grunge, nu metal, and works of emo where expressions of melancholy, existential despair, or nihilism predominate."}
{"id": "922", "revid": "39494265", "url": "https://en.wikipedia.org/wiki?curid=922", "title": "Anxiety", "text": "Anxiety is an emotion characterised by an unpleasant state of inner turmoil and includes feelings of dread over anticipated events. Anxiety is different from fear in that fear is defined as the emotional response to a present threat, whereas anxiety is the anticipation of a future one. It is often accompanied by nervous behavior such as pacing back and forth, somatic complaints, and rumination.\nAnxiety is a feeling of uneasiness and worry, usually generalized and unfocused as an overreaction to a situation that is only subjectively seen as menacing. It is often accompanied by muscular tension, restlessness, fatigue, inability to catch one's breath, tightness in the abdominal region, nausea, and problems in concentration. Anxiety is closely related to fear, which is a response to a real or perceived immediate threat (fight-or-flight response); anxiety involves the expectation of a future threat including dread. People facing anxiety may withdraw from situations which have provoked anxiety in the past.\nThe emotion of anxiety can persist beyond the developmentally appropriate time-periods in response to specific events, and thus turning into one of the multiple anxiety disorders (e.g. generalized anxiety disorder, panic disorder). The difference between \"anxiety disorder\" (as mental disorder) and \"anxiety\" (as normal emotion), is that people with an anxiety disorder experience anxiety excessively or persistently during approximately 6 months, or even during shorter time-periods in children. Anxiety disorders are among the most persistent mental problems and often last decades. Anxiety can also be experienced within other mental disorders, e.g., obsessive-compulsive disorder, post-traumatic stress disorder.\nAnxiety vs. fear.\nAnxiety is distinguished from fear, which is an appropriate cognitive and emotional response to a perceived threat. Anxiety is related to the specific behaviors of fight-or-flight responses, defensive behavior or escape. There is a false presumption that often circulates that anxiety only occurs in situations perceived as uncontrollable or unavoidable, but this is not always so. David Barlow defines anxiety as \"a future-oriented mood state in which one is not ready or prepared to attempt to cope with upcoming negative events,\" and that it is a distinction between future and present dangers which divides anxiety and fear. Another description of anxiety is agony, dread, terror, or even apprehension. In positive psychology, anxiety is described as the mental state that results from a difficult challenge for which the subject has insufficient coping skills.\nFear and anxiety can be differentiated into four domains: (1) duration of emotional experience, (2) temporal focus, (3) specificity of the threat, and (4) motivated direction. Fear is short-lived, present-focused, geared towards a specific threat, and facilitating escape from threat. On the other hand, anxiety is long-acting, future-focused, broadly focused towards a diffuse threat, and promoting excessive caution while approaching a potential threat and interferes with constructive coping.\nJoseph E. LeDoux and Lisa Feldman Barrett have both sought to separate automatic threat responses from additional associated cognitive activity within anxiety.\nSymptoms.\nAnxiety can be experienced with long, drawn-out daily symptoms that reduce quality of life, known as chronic (or generalized) anxiety, or it can be experienced in short spurts with sporadic, stressful panic attacks, known as acute anxiety. Symptoms of anxiety can range in number, intensity, and frequency, depending on the person. However, most people do not suffer from chronic anxiety.\nAnxiety can induce several psychological pains (e.g. depression) or mental disorders, and may lead to self-harm or suicide.\nThe behavioral effects of anxiety may include withdrawal from situations which have provoked anxiety or negative feelings in the past. Other effects may include changes in sleeping patterns, changes in habits, increase or decrease in food intake, and increased motor tension (such as foot tapping).\nThe emotional effects of anxiety may include feelings of apprehension or dread, trouble concentrating, feeling tense or jumpy, anticipating the worst, irritability, restlessness, watching for signs of danger, and a feeling of empty mindedness. as well as \"nightmares/bad dreams, obsessions about sensations, d\u00e9j\u00e0 vu, a trapped-in-your-mind feeling, and feeling like everything is scary.\" It may include a vague experience and feeling of helplessness.\nThe cognitive effects of anxiety may include thoughts about suspected dangers, such as an irrational fear of dying or having a heart attack, when in reality all one is experiencing is mild chest pain, for example.\nThe physiological symptoms of anxiety may include:\nTypes.\nThere are various types of anxiety. Existential anxiety can occur when a person faces angst, an existential crisis, or nihilistic feelings. People can also face mathematical anxiety, somatic anxiety, stage fright, or test anxiety. Social anxiety refers to a fear of rejection and negative evaluation (being judged) by other people.\nExistential.\nThe philosopher S\u00f8ren Kierkegaard, in \"The Concept of Anxiety\" (1844), described anxiety or dread associated with the \"dizziness of freedom\" and suggested the possibility for positive resolution of anxiety through the self-conscious exercise of responsibility and choosing. In \"Art and Artist\" (1932), the psychologist Otto Rank wrote that the psychological trauma of birth was the pre-eminent human symbol of existential anxiety and encompasses the creative person's simultaneous fear of \u2013 and desire for \u2013 separation, individuation, and differentiation.\nThe theologian Paul Tillich characterized existential anxiety as \"the state in which a being is aware of its possible nonbeing\" and he listed three categories for the nonbeing and resulting anxiety: ontic (fate and death), moral (guilt and condemnation), and spiritual (emptiness and meaninglessness). According to Tillich, the last of these three types of existential anxiety, i.e. spiritual anxiety, is predominant in modern times while the others were predominant in earlier periods. Tillich argues that this anxiety can be accepted as part of the human condition or it can be resisted but with negative consequences. In its pathological form, spiritual anxiety may tend to \"drive the person toward the creation of certitude in systems of meaning which are supported by tradition and authority\" even though such \"undoubted certitude is not built on the rock of reality\".\nAccording to Viktor Frankl, the author of \"Man's Search for Meaning\", when a person is faced with extreme mortal dangers, the most basic of all human wishes is to find a meaning of life to combat the \"trauma of nonbeing\" as death is near.\nDepending on the source of the threat, psychoanalytic theory distinguishes three types of anxiety: realistic, neurotic and moral.\nTest, performance, and competitive.\nTest.\nAccording to Yerkes-Dodson law, an optimal level of arousal is necessary to best complete a task such as an exam, performance, or competitive event. However, when the anxiety or level of arousal exceeds that optimum, the result is a decline in performance.\nTest anxiety is the uneasiness, apprehension, or nervousness felt by students who have a fear of failing an exam. Students who have test anxiety may experience any of the following: the association of grades with personal worth; fear of embarrassment by a teacher; fear of alienation from parents or friends; time pressures; or feeling a loss of control. Sweating, dizziness, headaches, racing heartbeats, nausea, fidgeting, uncontrollable crying or laughing and drumming on a desk are all common. Because test anxiety hinges on fear of negative evaluation, debate exists as to whether test anxiety is itself a unique anxiety disorder or whether it is a specific type of social phobia. The DSM-IV classifies test anxiety as a type of social phobia.\nResearch indicates that test anxiety among U.S. high-school and college students has been rising since the late 1950s. Test anxiety remains a challenge for students, regardless of age, and has considerable physiological and psychological impacts. Management of test anxiety focuses on achieving relaxation and developing mechanisms to manage anxiety. The routine practice of slow, Device-Guided Breathing (DGB) is a\nmajor component of behavioral treatments for anxiety conditions.\nPerformance and competitive.\nPerformance anxiety and competitive anxiety () happen when an individual's performance is measured against others. An important distinction between competitive and non-competitive anxiety is that competitive anxiety makes people view their performance as a threat. As a result, they experience a drop in their ordinary ability, whether physical or mental, due to that perceived stress.\nCompetitive anxiety is caused by a range of internal factors including high expectations, outside pressure, lack of experience, and external factors like the location of a competition. It commonly occurs in those participating in high pressure activities like sports and debates. Some common symptoms of competitive anxiety include muscle tension, fatigue, weakness, sense of panic, apprehensiveness, and panic attacks.\nThere are 4 major theories of how anxiety affects performance: Drive theory, Inverted U theory, Reversal theory, and The Zone of Optimal Functioning theory.\n\"Drive theory\" believes that anxiety is positive and performance improves proportionally to the level of anxiety. This theory is not well accepted.\nThe \"Inverted U theory\" is based on the idea that performance peaks at a moderate stress level. It is called Inverted U theory because the graph that plots performance against anxiety looks like an inverted \"U\".\n\"Reversal theory\" suggests that performance increases in relation to the individual's interpretation of their arousal levels. If they believed their physical arousal level would help them, their performance would increase, if they didn't, their performance would decrease. For example: Athletes were shown to worry more when focusing on results and perfection rather than the effort and growth involved.\nThe \"Zone of Optimal Functioning theory\" proposes that there is a zone where positive and negative emotions are in a balance which lead to feelings of dissociation and intense concentration, optimizing the individual's performance levels.\nStranger, social, and intergroup anxiety.\nHumans generally require social acceptance and thus sometimes dread the disapproval of others. Apprehension of being judged by others may cause anxiety in social environments.\nAnxiety during social interactions, particularly between strangers, is common among young people. It may persist into adulthood and become social anxiety or social phobia. \"Stranger anxiety\" in small children is not considered a phobia. In adults, an excessive fear of other people is not a developmentally common stage; it is called social anxiety. According to Cutting, social phobics do not fear the crowd but the fact that they may be judged negatively.\nSocial anxiety varies in degree and severity. For some people, it is characterized by experiencing discomfort or awkwardness during physical social contact (e.g. embracing, shaking hands, etc.), while in other cases it can lead to a fear of interacting with unfamiliar people altogether. Those with this condition may restrict their lifestyles to accommodate the anxiety, minimizing social interaction whenever possible. Social anxiety also forms a core aspect of certain personality disorders, including avoidant personality disorder.\nTo the extent that a person is fearful of social encounters with unfamiliar others, some people may experience anxiety particularly during interactions with outgroup members, or people who share different group memberships (i.e., by race, ethnicity, class, gender, etc.). Depending on the nature of the antecedent relations, cognitions, and situational factors, intergroup contact may be stressful and lead to feelings of anxiety. This apprehension or fear of contact with outgroup members is often called interracial or intergroup anxiety.\nAs is the case with the more generalized forms of social anxiety, intergroup anxiety has behavioral, cognitive, and affective effects. For instance, increases in schematic processing and simplified information processing can occur when anxiety is high. Indeed, such is consistent with related work on attentional bias in implicit memory. Additionally recent research has found that implicit racial evaluations (i.e. automatic prejudiced attitudes) can be amplified during intergroup interaction. Negative experiences have been illustrated in producing not only negative expectations, but also avoidant, or antagonistic, behavior such as hostility. Furthermore, when compared to anxiety levels and cognitive effort (e.g., impression management and self-presentation) in intragroup contexts, levels and depletion of resources may be exacerbated in the intergroup situation.\nTrait.\nAnxiety can be either a short-term \"state\" or a long-term \"personality trait\". Trait anxiety reflects a stable tendency across the lifespan of responding with acute, state anxiety in the anticipation of threatening situations (whether they are actually deemed threatening or not). A meta-analysis showed that a high level of neuroticism is a risk factor for development of anxiety symptoms and disorders. Such anxiety may be conscious or unconscious.\nPersonality can also be a trait leading to anxiety and depression and their persistence. Through experience, many find it difficult to collect themselves due to their own personal nature.\nChoice or decision.\nAnxiety induced by the need to choose between similar options is recognized as a problem for some individuals and for organizations. In 2004, Capgemini wrote: \"Today we're all faced with greater choice, more competition and less time to consider our options or seek out the right advice.\" Overthinking a choice is called analysis paralysis.\nIn a decision context, unpredictability or uncertainty may trigger emotional responses in anxious individuals that systematically alter decision-making. There are primarily two forms of this anxiety type. The first form refers to a choice in which there are multiple potential outcomes with known or calculable probabilities. The second form refers to the uncertainty and ambiguity related to a decision context in which there are multiple possible outcomes with unknown probabilities.\nPanic disorder.\nPanic disorder may share symptoms of stress and anxiety, but it is actually very different. Panic disorder is an anxiety disorder that occurs without any triggers. According to the U.S. Department of Health and Human Services, this disorder can be distinguished by unexpected and repeated episodes of intense fear. Someone with panic disorder will eventually develop constant fear of another attack and as this progresses it will begin to affect daily functioning and an individual's general quality of life. It is reported by the Cleveland Clinic that panic disorder affects 2 to 3 percent of adult Americans and can begin around the time of the teenage and early adult years. Some symptoms include: difficulty breathing, chest pain, dizziness, trembling or shaking, feeling faint, nausea, fear that you are losing control or are about to die. Even though they have these symptoms during an attack, the main symptom is the persistent fear of having future panic attacks.\nAnxiety disorders.\nAnxiety disorders are a group of mental disorders characterized by exaggerated feelings of anxiety and fear responses. Anxiety is a worry about future events and fear is a reaction to current events. These feelings may cause physical symptoms, such as a fast heart rate and shakiness. There are a number of anxiety disorders: including generalized anxiety disorder, specific phobia, social anxiety disorder, separation anxiety disorder, agoraphobia, panic disorder, and selective mutism. The disorder differs by what results in the symptoms. People often have more than one anxiety disorder.\nAnxiety disorders are caused by a complex combination of genetic and environmental factors. To be diagnosed, symptoms typically need to be present for at least six months, be more than would be expected for the situation, and decrease a person's ability to function in their daily lives. Other problems that may result in similar symptoms include hyperthyroidism, heart disease, caffeine, alcohol, or cannabis use, and withdrawal from certain drugs, among others.\nWithout treatment, anxiety disorders tend to remain. Treatment may include lifestyle changes, counselling, and medications. Counselling is typically with a type of cognitive behavioral therapy. Medications, such as antidepressants or beta blockers, may improve symptoms. A 2023 review found that regular physical activity is effective for reducing anxiety.\nAbout 12% of people are affected by an anxiety disorder in a given year and between 12% and 30% are affected at some point in their life. They occur about twice as often in women than they do in men, and generally begin before the age of 25. The most common anxiety disorders are specific phobias, which affect nearly 12% of people, and social anxiety disorder, which affects 10% of people at some point in their life. They affect those between the ages of 15 and 35 the most and become less common after the age of 55. Rates appear to be higher in the United States and Europe.\nShort- and long-term anxiety.\nAnxiety can be either a short-term \"state\" or a long-term \"trait\". Whereas trait anxiety represents worrying about future events, anxiety disorders are a group of mental disorders characterized by feelings of anxiety and fears.\nFour ways to be anxious.\nIn his book \"Anxious: The Modern Mind in the Age of Anxiety\" Joseph LeDoux examines four experiences of anxiety through a brain-based lens:\nCo-morbidity.\nAnxiety disorders often occur with other mental health disorders, particularly major depressive disorder, bipolar disorder, eating disorders, or certain personality disorders. It also commonly occurs with personality traits such as neuroticism. This observed co-occurrence is partly due to genetic and environmental influences shared between these traits and anxiety.\nIt is common for those with obsessive\u2013compulsive disorder to experience anxiety. Anxiety is also commonly found in those who experience panic disorders, phobic anxiety disorders, severe stress, dissociative disorders, somatoform disorders, and some neurotic disorders.\nAnxiety has also been linked to the experience of intrusive thoughts. Studies have revealed that individuals who experience high levels of anxiety (also known as clinical anxiety) are highly vulnerable to the experience of intense intrusive thoughts or psychological disorders that are characterised by intrusive thoughts.\nRisk factors.\nAnxiety disorders are partly genetic, with twin studies suggesting 30-40% genetic influence on individual differences in anxiety. Environmental factors are also important. Twin studies show that individual-specific environments have a large influence on anxiety, whereas shared environmental influences (environments that affect twins in the same way) operate during childhood but decline through adolescence. Specific measured 'environments' that have been associated with anxiety include child abuse, family history of mental health disorders, and poverty. Anxiety is also associated with drug use, including alcohol, caffeine, and benzodiazepines, which are often prescribed to treat anxiety.\nNeuroanatomy.\nNeural circuitry involving the amygdala, which regulates emotions like anxiety and fear, stimulating the HPA axis and sympathetic nervous system, and hippocampus, which is implicated in emotional memory along with the amygdala, is thought to underlie anxiety. People who have anxiety tend to show high activity in response to emotional stimuli in the amygdala. Some writers believe that excessive anxiety can lead to an overpotentiation of the limbic system (which includes the amygdala and nucleus accumbens), giving increased future anxiety, but this does not appear to have been proven.\nResearch upon adolescents who as infants had been highly apprehensive, vigilant, and fearful finds that their nucleus accumbens is more sensitive than that in other people when deciding to make an action that determined whether they received a reward. This suggests a link between circuits responsible for fear and also reward in anxious people. As researchers note, \"a sense of 'responsibility', or self-agency, in a context of uncertainty (probabilistic outcomes) drives the neural system underlying appetitive motivation (i.e., nucleus accumbens) more strongly in temperamentally inhibited than noninhibited adolescents\".\nThe gut-brain axis.\nThe microbes of the gut can connect with the brain to affect anxiety. There are various pathways along which this communication can take place. One is through the major neurotransmitters. The gut microbes such as \"Bifidobacterium\" and \"Bacillus\" produce the neurotransmitters GABA and dopamine, respectively. The neurotransmitters signal to the nervous system of the gastrointestinal tract, and those signals will be carried to the brain through the vagus nerve or the spinal system. This is demonstrated by the fact that altering the microbiome has shown anxiety- and depression-reducing effects in mice, but not in subjects without vagus nerves.\nAnother key pathway is the HPA axis, as mentioned above. The microbes can control the levels of cytokines in the body, and altering cytokine levels creates direct effects on areas of the brain such as the hypothalamus, the area that triggers HPA axis activity. The HPA axis regulates production of cortisol, a hormone that takes part in the body's stress response. When HPA activity spikes, cortisol levels increase, processing and reducing anxiety in stressful situations. These pathways, as well as the specific effects of individual taxa of microbes, are not yet completely clear, but the communication between the gut microbiome and the brain is undeniable, as is the ability of these pathways to alter anxiety levels.\nWith this communication comes the potential to treat. Prebiotics and probiotics have been shown to reduce anxiety. For example, experiments in which mice were given fructo- and galacto-oligosaccharide prebiotics and \"Lactobacillus\" probiotics have both demonstrated a capability to reduce anxiety. In humans, results are not as concrete, but promising.\nGenetics.\nGenetics and family history (e.g. parental anxiety) may put an individual at increased risk of an anxiety disorder, but generally external stimuli will trigger its onset or exacerbation. Estimates of genetic influence on anxiety, based on studies of twins, range from 25 to 40% depending on the specific type and age-group under study. For example, genetic differences account for about 43% of variance in panic disorder and 28% in generalized anxiety disorder. Longitudinal twin studies have shown the moderate stability of anxiety from childhood through to adulthood is mainly influenced by stability in genetic influence. When investigating how anxiety is passed on from parents to children, it is important to account for sharing of genes as well as environments, for example using the intergenerational children-of-twins design.\nMany studies in the past used a candidate gene approach to test whether single genes were associated with anxiety. These investigations were based on hypotheses about how certain known genes influence neurotransmitters (such as serotonin and norepinephrine) and hormones (such as cortisol) that are implicated in anxiety. None of these findings are well replicated, with the possible exception of TMEM132D, COMT and MAO-A. The epigenetic signature of \"BDNF\", a gene that codes for a protein called \"brain derived neurotrophic factor\" that is found in the brain, has also been associated with anxiety and specific patterns of neural activity. and a receptor gene for \"BDNF\" called \"NTRK2\" was associated with anxiety in a large genome-wide investigation. The reason that most candidate gene findings have not replicated is that anxiety is a complex trait that is influenced by many genomic variants, each of which has a small effect on its own. Increasingly, studies of anxiety are using a hypothesis-free approach to look for parts of the genome that are implicated in anxiety using big enough samples to find associations with variants that have small effects. The largest explorations of the common genetic architecture of anxiety have been facilitated by the UK Biobank, the ANGST consortium and the CRC Fear, Anxiety and Anxiety Disorders.\nMedical conditions.\nMany medical conditions can cause anxiety. This includes conditions that affect the ability to breathe, like COPD and asthma, and the difficulty in breathing that often occurs near death. Conditions that cause abdominal pain or chest pain can cause anxiety and may in some cases be a somatization of anxiety; the same is true for some sexual dysfunctions. Conditions that affect the face or the skin can cause social anxiety especially among adolescents, and developmental disabilities often lead to social anxiety for children as well. Life-threatening conditions like cancer also cause anxiety.\nFurthermore, certain organic diseases may present with anxiety or symptoms that mimic anxiety. These disorders include certain endocrine diseases (hypo- and hyperthyroidism, hyperprolactinemia), metabolic disorders (diabetes), deficiency states (low levels of vitamin D, B2, B12, folic acid), gastrointestinal diseases (celiac disease, non-celiac gluten sensitivity, inflammatory bowel disease), heart diseases, blood diseases (anemia), cerebral vascular accidents (transient ischemic attack, stroke), and brain degenerative diseases (Parkinson's disease, dementia, multiple sclerosis, Huntington's disease), among others.\nSubstance-induced.\nSeveral drugs can cause or worsen anxiety, whether in intoxication, withdrawal or as side effect. These include alcohol, tobacco, sedatives (including prescription benzodiazepines), opioids (including prescription pain killers and illicit drugs like heroin), stimulants (such as caffeine, cocaine and amphetamines), hallucinogens, and inhalants.\nWhile many often report self-medicating anxiety with these substances, improvements in anxiety from drugs are usually short-lived (with worsening of anxiety in the long term, sometimes with acute anxiety as soon as the drug effects wear off) and tend to be exaggerated. Acute exposure to toxic levels of benzene may cause euphoria, anxiety, and irritability lasting up to 2 weeks after the exposure.\nPsychological.\nPoor coping skills (e.g., rigidity/inflexible problem solving, denial, avoidance, impulsivity, extreme self-expectation, negative thoughts, affective instability, and inability to focus on problems) are associated with anxiety. Anxiety is also linked and perpetuated by the person's own pessimistic outcome expectancy and how they cope with feedback negativity. Temperament (e.g., neuroticism) and attitudes (e.g. pessimism) have been found to be risk factors for anxiety.\nCognitive distortions such as overgeneralizing, catastrophizing, mind reading, emotional reasoning, binocular trick, and mental filter can result in anxiety. For example, an overgeneralized belief that something bad \"always\" happens may lead someone to have excessive fears of even minimally risky situations and to avoid benign social situations due to anticipatory anxiety of embarrassment. In addition, those who have high anxiety can also create future stressful life events. Together, these findings suggest that anxious thoughts can lead to anticipatory anxiety as well as stressful events, which in turn cause more anxiety. Such unhealthy thoughts can be targets for successful treatment with cognitive therapy.\nPsychodynamic theory posits that anxiety is often the result of opposing unconscious wishes or fears that manifest via maladaptive defense mechanisms (such as suppression, repression, anticipation, regression, somatization, passive aggression, dissociation) that develop to adapt to problems with early objects (e.g., caregivers) and empathic failures in childhood. For example, persistent parental discouragement of anger may result in repression/suppression of angry feelings which manifests as gastrointestinal distress (somatization) when provoked by another while the anger remains unconscious and outside the individual's awareness. Such conflicts can be targets for successful treatment with psychodynamic therapy. While psychodynamic therapy tends to explore the underlying roots of anxiety, cognitive behavioral therapy has also been shown to be a successful treatment for anxiety by altering irrational thoughts and unwanted behaviors.\nEvolutionary psychology.\nAn evolutionary psychology explanation is that increased anxiety serves the purpose of increased vigilance regarding potential threats in the environment as well as increased tendency to take proactive actions regarding such possible threats. This may cause false positive reactions but an individual with anxiety may also avoid real threats. This may explain why anxious people are less likely to die due to accidents. There is ample empirical evidence that anxiety can have adaptive value. Within a school, timid fish are more likely than bold fish to survive a predator.\nWhen people are confronted with unpleasant and potentially harmful stimuli such as foul odors or tastes, PET-scans show increased blood flow in the amygdala. In these studies, the participants also reported moderate anxiety. This might indicate that anxiety is a protective mechanism designed to prevent the organism from engaging in potentially harmful behaviors.\nSocial.\nSocial risk factors for anxiety include a history of trauma (e.g., physical, sexual or emotional abuse or assault), bullying, early life experiences and parenting factors (e.g., rejection, lack of warmth, high hostility, harsh discipline, high parental negative affect, anxious childrearing, modelling of dysfunctional and drug-abusing behaviour, discouragement of emotions, poor socialization, poor attachment, and child abuse and neglect), cultural factors (e.g., stoic families/cultures, persecuted minorities including those with disabilities), and socioeconomics (e.g., uneducated, unemployed, impoverished although developed countries have higher rates of anxiety disorders than developing countries). \nA 2019 comprehensive systematic review of over 50 studies showed that food insecurity in the United States is strongly associated with depression, anxiety, and sleep disorders. Food-insecure individuals had an almost 3 fold risk increase of testing positive for anxiety when compared to food-secure individuals.\nGender socialization.\nContextual factors that are thought to contribute to anxiety include gender socialization and learning experiences. In particular, learning mastery (the degree to which people perceive their lives to be under their own control) and instrumentality, which includes such traits as self-confidence, self-efficacy, independence, and competitiveness fully mediate the relation between gender and anxiety. That is, though gender differences in anxiety exist, with higher levels of anxiety in women compared to men, gender socialization and learning mastery explain these gender differences.\nTreatment.\nThe first step in the management of a person with anxiety symptoms involves evaluating the possible presence of an underlying medical cause, the recognition of which is essential in order to decide the correct treatment. Anxiety symptoms may mask an organic disease, or appear associated with or as a result of a medical disorder.\nCognitive behavioral therapy (CBT) is effective for anxiety disorders and is a first line treatment. CBT appears to be equally effective when carried out via the internet. While evidence for mental health apps is promising, it is preliminary.\nAnxiety often affects relationships, and interpersonal psychotherapy addresses these issues by improving communication and relationship skills.\nPsychopharmacological treatment can be used in parallel to CBT or can be used alone. As a general rule, most anxiety disorders respond well to first-line agents. Such drugs, also used as anti-depressants, are the selective serotonin reuptake inhibitors and serotonin-norepinephrine reuptake inhibitors, that work by blocking the reuptake of specific neurotransmitters and resulting in the increase in availability of these neurotransmitters. Additionally, benzodiazepines are often prescribed to individuals with anxiety disorder. Benzodiazepines produce an anxiolytic response by modulating GABA and increasing its receptor binding. A third common treatment involves a category of drug known as serotonin agonists. This category of drug works by initiating a physiological response at 5-HT1A receptor by increasing the action of serotonin at this receptor. Other treatment options include pregabalin, tricyclic antidepressants, and moclobemide, among others.\nAnxiety is considered to be a serious psychiatric illness that has an unknown true pervasiveness due to affected individuals not asking for proper treatment or aid, and due to professionals missing the diagnosis.\nPrevention.\nThe above risk factors give natural avenues for prevention. A 2017 review found that psychological or educational interventions have a small yet statistically significant benefit for the prevention of anxiety in varied population types.\nPathophysiology.\nAnxiety disorder appears to be a genetically inherited neurochemical dysfunction that may involve autonomic imbalance; decreased GABA-ergic tone; allelic polymorphism of the catechol-O-methyltransferase (COMT) gene; increased adenosine receptor function; increased cortisol.\nIn the central nervous system (CNS), the major mediators of the symptoms of anxiety disorders appear to be norepinephrine, serotonin, dopamine, and gamma-aminobutyric acid (GABA). Other neurotransmitters and peptides, such as corticotropin-releasing factor, may be involved. Peripherally, the autonomic nervous system, especially the sympathetic nervous system, mediates many of the symptoms. Increased flow in the right parahippocampal region and reduced serotonin type 1A receptor binding in the anterior and posterior cingulate and raphe of patients are the diagnostic factors for prevalence of anxiety disorder.\nThe amygdala is central to the processing of fear and anxiety, and its function may be disrupted in anxiety disorders. Anxiety processing in the basolateral amygdala has been implicated with expansion of dendritic arborization of the amygdaloid neurons. SK2 potassium channels mediate inhibitory influence on action potentials and reduce arborization."}
{"id": "923", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=923", "title": "A.A. Milne", "text": ""}
{"id": "924", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=924", "title": "A. A. Milne", "text": "Alan Alexander Milne (; 18 January 1882 \u2013 31 January 1956) was an English writer best known for his books about the teddy bear Winnie-the-Pooh, as well as children's poetry. Milne was primarily a playwright before the huge success of Winnie-the-Pooh overshadowed his previous work. He served as a lieutenant in the Royal Warwickshire Regiment in the First World War and as a captain in the Home Guard in the Second World War.\nMilne was the father of bookseller Christopher Robin Milne, upon whom the character Christopher Robin is based. It was during a visit to London Zoo, where Christopher became enamoured with the tame and amiable bear Winnipeg, that Milne was inspired to write the story of Winnie-the-Pooh for his son. Milne bequeathed the original manuscripts of the Winnie-the-Pooh stories to the Wren Library at Trinity College, Cambridge, his alma mater.\nEarly life and military career.\nAlan Alexander Milne was born in Kilburn, London, to John Vine Milne, who was born in Jamaica, and Sarah Marie Milne (n\u00e9e Heginbotham), on 18 January 1882. He grew up at Henley House School, 6/7 Mortimer Road (now Crescent), Kilburn, a small independent school run by his father. He taught himself to read at the age of two. One of his teachers was H. G. Wells, who taught there in 1889\u201390. Milne attended Westminster School and Trinity College, Cambridge, where he studied on a mathematics scholarship, graduating with a B.A. in Mathematics in 1903, though he was always interested in writing. He edited and wrote for \"Granta\", a student magazine. He collaborated with his brother Kenneth and their articles appeared over the initials AKM. Milne's work came to the attention of the leading British humour magazine \"Punch\", where Milne was to become a contributor and later an assistant editor. Considered a talented cricket fielder, Milne played for two amateur teams that were largely composed of British writers: the Allahakbarries and the Authors XI. His teammates included fellow writers J. M. Barrie, Arthur Conan Doyle and P. G. Wodehouse.\nMilne joined the British Army during World War I and served as an officer in the Royal Warwickshire Regiment. He was commissioned into the 4th Battalion, Royal Warwickshire Regiment, on 1 February 1915 as a second lieutenant (on probation). His commission was confirmed on 20 December 1915. He served on the Somme as a signals officer from July\u2013November 1916, but caught trench fever and was invalided back to England. Having recuperated, he worked as a signals instructor, before being recruited into military intelligence to write propaganda articles for MI7 (b) between 1917 and 1918. He was discharged on 14 February 1919, and settled in Mallord Street, Chelsea. He relinquished his commission on 19 February 1920, retaining the rank of lieutenant.\nAfter the war, he wrote a denunciation of war titled \"Peace with Honour\" (1934), which he retracted somewhat with 1940's \"War with Honour\". During World War II, Milne was one of the most prominent critics of fellow English writer (and Authors XI cricket teammate) P. G. Wodehouse, who was captured at his country home in France by the Nazis and imprisoned for a year. Wodehouse made radio broadcasts about his internment, which were broadcast from Berlin. Although the light-hearted broadcasts made fun of the Germans, Milne accused Wodehouse of committing an act of near treason by cooperating with his country's enemy. Wodehouse got some revenge on his former friend (e.g. in \"The Mating Season\") by creating fatuous parodies of the Christopher Robin poems in some of his later stories, and claiming that Milne \"was probably jealous of all other writers... But I loved his stuff.\"\nMilne married Dorothy \"Daphne\" de S\u00e9lincourt (1890\u20131971) in 1913 and their son Christopher Robin Milne was born in 1920. In 1925, Milne bought a country home, Cotchford Farm, in Hartfield, East Sussex.\nDuring World War II, Milne was a captain in the British Home Guard in Hartfield &amp; Forest Row, insisting on being plain \"Mr. Milne\" to the members of his platoon. He retired to the farm after a stroke and brain surgery in 1952 left him an invalid; and by August 1953, \"he seemed very old and disenchanted.\" Milne died in January 1956, aged 74.\nLiterary career.\n1903 to 1925.\nAfter graduating from Cambridge University in 1903, A. A. Milne contributed humorous verse and whimsical essays to \"Punch\", joining the staff in 1906 and becoming an assistant editor.\nDuring this period he published 18 plays and three novels, including the murder mystery \"The Red House Mystery\" (1922). His son was born in August 1920 and in 1924 Milne produced a collection of children's poems, \"When We Were Very Young\", which were illustrated by \"Punch\" staff cartoonist E. H. Shepard. A collection of short stories for children \"A Gallery of Children\", and other stories that became part of the Winnie-the-Pooh books, were first published in 1925.\nMilne was an early screenwriter for the nascent British film industry, writing four stories filmed in 1920 for the company Minerva Films (founded in 1920 by the actor Leslie Howard and his friend and story editor Adrian Brunel). These were \"The Bump\", starring Aubrey Smith; \"Twice Two\"; \"Five Pound Reward\"; and \"Bookworms\". Some of these films survive in the archives of the British Film Institute. Milne had met Howard when the actor starred in Milne's play \"Mr Pim Passes By\" in London.\nLooking back on this period (in 1926), Milne observed that when he told his agent that he was going to write a detective story, he was told that what the country wanted from a \"\"Punch\" humorist\" was a humorous story; when two years later he said he was writing nursery rhymes, his agent and publisher were convinced he should write another detective story; and after another two years, he was being told that writing a detective story would be in the worst of taste given the demand for children's books. He concluded that \"the only excuse which I have yet discovered for writing anything is that I want to write it; and I should be as proud to be delivered of a Telephone Directory \"con amore\" as I should be ashamed to create a Blank Verse Tragedy at the bidding of others.\"\n1926 to 1928.\nMilne is most famous for his two \"Pooh\" books about a boy named Christopher Robin after his son, Christopher Robin Milne (1920\u20131996), and various characters inspired by his son's stuffed animals, most notably the bear named Winnie-the-Pooh. Christopher Robin Milne's stuffed bear, originally named Edward, was renamed Winnie after a Canadian black bear named Winnie (after Winnipeg), which was used as a military mascot in World War I, and left to London Zoo during the war. \"The Pooh\" comes from a swan the young Milne named \"Pooh\". E. H. Shepard illustrated the original Pooh books, using his own son's teddy Growler (\"a magnificent bear\") as the model. The rest of Christopher Robin Milne's toys, Piglet, Eeyore, Kanga, Roo and Tigger, were incorporated into A. A. Milne's stories, and two more characters\u00a0\u2013 Rabbit and Owl\u00a0\u2013 were created by Milne's imagination. Christopher Robin Milne's own toys are now on display in New York where 750,000 people visit them every year.\nThe fictional Hundred Acre Wood of the Pooh stories derives from Five Hundred Acre Wood in Ashdown Forest in East Sussex, South East England, where the Pooh stories were set. Milne lived on the northern edge of the forest at Cotchford Farm, , and took his son on walking trips there. E. H. Shepard drew on the landscapes of Ashdown Forest as inspiration for many of the illustrations he provided for the Pooh books. The adult Christopher Robin commented: \"Pooh's Forest and Ashdown Forest are identical.\" Popular tourist locations at Ashdown Forest include: \"Galleon's Lap\", \"The Enchanted Place\", the \"Heffalump Trap\" and \"Lone Pine\", \"Eeyore's Sad and Gloomy Place\", and the wooden \"Pooh Bridge\" where Pooh and Piglet invented Poohsticks.\nNot yet known as Pooh, he made his first appearance in a poem, \"Teddy Bear\", published in \"Punch\" magazine in February 1924 and republished that year in \"When We Were Very Young\". Pooh first appeared in the \"London Evening News\" on Christmas Eve, 1925, in a story called \"The Wrong Sort of Bees\". \"Winnie-the-Pooh\" was published in 1926, followed by \"The House at Pooh Corner\" in 1928. A second collection of nursery rhymes, \"Now We Are Six\", was published in 1927. All four books were illustrated by E. H. Shepard. Milne also published four plays in this period. He also \"gallantly stepped forward\" to contribute a quarter of the costs of dramatising P. G. Wodehouse's \"A Damsel in Distress\". \"The World of Pooh\" won the Lewis Carroll Shelf Award in 1958.\n1929 onward.\nThe success of his children's books was to become a source of considerable annoyance to Milne, whose self-avowed aim was to write whatever he pleased and who had, until then, found a ready audience for each change of direction: he had freed pre-war \"Punch\" from its ponderous facetiousness; he had made a considerable reputation as a playwright (like his idol J. M. Barrie) on both sides of the Atlantic; he had produced a witty piece of detective writing in \"The Red House Mystery\" (although this was severely criticised by Raymond Chandler for the implausibility of its plot in his essay \"The Simple Art of Murder\" in the eponymous collection that appeared in 1950). But once Milne had, in his own words, \"said goodbye to all that in 70,000 words\" (the approximate length of his four principal children's books), he had no intention of producing any reworkings lacking in originality, given that one of the sources of inspiration, his son, was growing older.\nAnother reason Milne stopped writing children's books, and especially about Winnie-the-Pooh, was that he felt \"amazement and disgust\" over the immense fame his son was exposed to, and said that \"I feel that the legal Christopher Robin has already had more publicity than I want for him. I do not want CR Milne to ever wish that his name were Charles Robert.\"\nIn his literary home, \"Punch\", where the \"When We Were Very Young\" verses had first appeared, Methuen continued to publish whatever Milne wrote, including the long poem \"The Norman Church\" and an assembly of articles entitled \"Year In, Year Out\" (which Milne likened to a benefit night for the author).\nIn 1929, Milne adapted Kenneth Grahame's novel \"The Wind in the Willows\" for the stage as \"Toad of Toad Hall\". The title was an implicit admission that such chapters as Chapter 7, \"The Piper at the Gates of Dawn,\" could not survive translation to the theatre. A special introduction written by Milne is included in some editions of Grahame's novel. It was first performed at the Playhouse Theatre, Liverpool, on 21 December 1929 before it made its West End debut the following year at the Lyric Theatre on 17 December 1930. The play was revived in the West End from 1931 to 1935, and since the 1960s there have been West End revivals during the Christmas season; actors who have performed in the play include Judi Dench and Ian McKellen.\nMilne and his wife became estranged from their son, who came to resent what he saw as his father's exploitation of his childhood and came to hate the books that had thrust him into the public eye. Christopher's marriage to his first cousin, Lesley de S\u00e9lincourt, distanced him still further from his parents \u2013 Lesley's father and Christopher's mother had not spoken to each other for 30 years.\nDeath and legacy.\nCommemoration.\nA. A. Milne died at his home in Hartfield, Sussex, on 31 January 1956, aged 74. A memorial service took place on 10 February at All Hallows-by-the-Tower church in London.\nThe rights to A. A. Milne's Pooh books were left to four beneficiaries: his family, the Royal Literary Fund, Westminster School and the Garrick Club. After Milne's death in 1956, his widow sold her rights to the Pooh characters to Stephen Slesinger, whose widow sold the rights after Slesinger's death to Walt Disney Productions, which has made many Pooh cartoon movies, a Disney Channel television show, as well as Pooh-related merchandise. In 2001, the other beneficiaries sold their interest in the estate to the Disney Corporation for $350m. Previously Disney had been paying twice-yearly royalties to these beneficiaries. The estate of E. H. Shepard also received a sum in the deal. The UK copyright on the text of the original Winnie the Pooh books expires on 1 January 2027; at the beginning of the year after the 70th anniversary of the author's death (PMA-70), and has already expired in those countries with a PMA-50 rule. This applies to all of Milne's works except those first published posthumously. The illustrations in the Pooh books will remain under copyright until the same amount of time after the illustrator's death has passed; in the UK, this will be 1 January 2047.\nIn the US, copyright on the four children's books (including the illustrations) expired 95 years after publication of each of the books. Specifically: copyright on the book \"When We Were Very Young\" expired in 2020; copyright on the book \"Winnie-the-Pooh\" expired in 2022; copyright on the book \"Now We Are Six\" expired in 2023; and copyright on the book \"The House at Pooh Corner\" expired in 2024.\nIn 2008, a collection of original illustrations featuring Winnie-the-Pooh and his animal friends sold for more than \u00a31.2 million at auction at Sotheby's, London. \"Forbes\" magazine ranked Winnie the Pooh the most valuable fictional character in 2002; Winnie the Pooh merchandising products alone had annual sales of more than $5.9 billion. In 2005, Winnie the Pooh generated $6 billion, a figure surpassed only by Mickey Mouse.\nA memorial plaque in Ashdown Forest, unveiled by Christopher Robin in 1979, commemorates the work of A. A. Milne and Shepard in creating the world of Pooh. The inscription states they \"captured the magic of Ashdown Forest, and gave it to the world\". Milne once wrote of Ashdown Forest: \"In that enchanted place on the top of the forest a little boy and his bear will always be playing.\"\nIn 2003, \"Winnie-the-Pooh\" was ranked number 7 on the BBC's The Big Read poll which determined the UK's \"best-loved novels\". In 2006, Winnie-the-Pooh received a star on the Hollywood Walk of Fame, marking the 80th birthday of Milne's creation.\nMarking the 90th anniversary of Milne's creation of the character, and the 90th birthday of Queen Elizabeth II, \"Winnie-the-Pooh Meets the Queen\" (2016) sees Pooh meet the Queen at Buckingham Palace. The illustrated and audio adventure is narrated by the actor Jim Broadbent. Also in 2016, a new character, a Penguin, was unveiled in \"The Best Bear in All the World\", which was inspired by a long-lost photograph of Milne and his son Christopher with a toy penguin.\nAn exhibition entitled \"\" appeared at the Victoria and Albert Museum in London from 9 December 2017 to 8 April 2018.\nThe composer Harold Fraser-Simson, a near neighbour, produced six books of Milne songs between 1924 and 1932. The poems have been parodied many times, including in the books \"When We Were Rather Older\" and \"Now We Are Sixty\". The 1963 film \"The King's Breakfast\" was based on Milne's poem of the same name.\nMilne has been portrayed in television and film. Domhnall Gleeson plays him in \"Goodbye Christopher Robin\", a 2017 biographical drama film. In the 2018 fantasy film \"Christopher Robin\", an extension of the Disney Winnie the Pooh franchise, Tristan Sturrock plays Milne, and filming took place at Ashdown Forest.\nAn elementary school in Houston, Texas, operated by the Houston Independent School District (HISD), is named after Milne. The school, A. A. Milne Elementary School in Brays Oaks, opened in 1991.\nArchive.\nThe original manuscripts for \"Winnie-the-Pooh\" and \"The House at Pooh Corner\" are archived at Trinity College Library, Cambridge.\nThe bulk of A. A. Milne's papers are housed at the Harry Ransom Center at the University of Texas at Austin. The collection, established at the centre in 1964, consists of manuscript drafts and fragments for over 150 of Milne's works, as well as correspondence, legal documents, genealogical records, and some personal effects. The library division holds several books formerly belonging to Milne and his wife Dorothy. The center also has small collections of correspondence from Christopher Robin Milne and Milne's frequent illustrator E. H. Shepard.\nReligious views.\nMilne did not speak out much on the subject of religion, although he used religious terms to explain his decision, while remaining a pacifist, to join the British Home Guard. He wrote: \"In fighting Hitler we are truly fighting the Devil, the Anti-Christ ... Hitler was a crusader against God.\"\nHis best known comment on the subject was recalled on his death:\nHe wrote in the poem \"Explained\":\nHe also wrote in the poem \"Vespers\":"}
{"id": "925", "revid": "1057393", "url": "https://en.wikipedia.org/wiki?curid=925", "title": "Asociaci\u00f3n Alumni", "text": "Asociaci\u00f3n Alumni, usually just Alumni, is an Argentine rugby union club located in Tortuguitas, Greater Buenos Aires. The senior squad currently competes at Top 12, the first division of the Uni\u00f3n de Rugby de Buenos Aires league system.\nThe club has ties with former football club Alumni because both were established by Buenos Aires English High School students.\nHistory.\nBackground.\nThe first club with the name \"Alumni\" played association football, having been found in 1898 by students of Buenos Aires English High School (BAEHS) along with director Alexander Watson Hutton. Originally under the name \"English High School A.C.\", the team would be later obliged by the Association to change its name, therefore \"Alumni\" was chosen, following a proposal by Carlos Bowers, a former student of the school.\nAlumni was the most successful team during the first years of Argentine football, winning 10 of 14 league championships contested. Alumni is still considered the first great football team in the country. Alumni was reorganised in 1908, \"in order to encourage people to practise all kinds of sports, specially football\". This was the last try to develop itself as a sports club rather than just as a football team, as Lomas, Belgrano and Quilmes had successfully done in the past, but the efforts were not enough. Alumni played its last game in 1911 and was definitely dissolved on April 24, 1913.\nRebirth through rugby.\nIn 1951, two guards of the BAEHS, Daniel Ginhson (also a former player of Buenos Aires F.C.) and Guillermo Cubelli, supported by the school's alumni and fathers of the students, decided to establish a club focused on rugby union exclusively. Former players of Alumni football club and descendants of other players already dead gave their permission to use the name \"Alumni\".\nOn December 13, in a meeting presided by Carlos Bowers himself (who had proposed the name \"Alumni\" to the original football team 50 years before), the club was officially established under the name \"Asociaci\u00f3n Juvenil Alumni\", also adopting the same colors as its predecessor.\nThe team achieved good results and in 1960 the club presented a team that won the third division of the Buenos Aires league, reaching the second division. Since then, Alumni has played at the highest level of Argentine rugby and its rivalry with Belgrano Athletic Club is one of the fiercest local derbies in Buenos Aires. Alumni would later climb up to the first division winning 5 titles: 4 consecutive between 1989 and 1992, and the other in 2001.\nIn 2002, Alumni won its first Nacional de Clubes title, defeating Jockey Club de Rosario 23\u201321 in the final.\nPlayers.\nCurrent roster.\nAs of January 2018:"}
{"id": "926", "revid": "6320553", "url": "https://en.wikipedia.org/wiki?curid=926", "title": "Alumna", "text": ""}
