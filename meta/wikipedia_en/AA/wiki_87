{"id": "9695", "revid": "3048957", "url": "https://en.wikipedia.org/wiki?curid=9695", "title": "Elizabeth Garrett Anderson", "text": "Elizabeth Garrett Anderson (9 June 1836 \u2013 17 December 1917) was an English physician and suffragist. She is known for being the first woman to qualify in Britain as a physician and surgeon and as a co-founder and dean of the London School of Medicine for Women, which was the first medical school in Britain to train women as doctors. She was the first female dean of a British medical school, the first woman in Britain to be elected to a school board and, as mayor of Aldeburgh, the first female mayor in Britain.\nEarly life.\nElizabeth was born in Whitechapel, London, and was the second of eleven children of Newson Garrett (1812\u20131893), from Leiston, Suffolk, and his wife, Louisa (born Dunnell; 1813\u20131903), from London.\nHer paternal ancestors had been ironworkers in East Suffolk since the early seventeenth century. Newson was the youngest of three sons and not academically inclined, although he possessed the family's entrepreneurial spirit. When he finished school, Newson found few opportunities in Leiston, so he moved to London to make his fortune. There, he fell in love with his brother's sister-in-law, Louisa Dunnell, the daughter of an innkeeper of Suffolk origin. After their wedding, the couple went to live in a pawnbroker's shop at 1 Commercial Road, Whitechapel. The Garretts had their first three children in quick succession: Louie, Elizabeth, and a son, Dunnell, who died at the age of six months. When Garrett was three years old, the family moved to 142 Long Acre, where they lived for two years, while one more child was born and her father advanced in his career, becoming not only the manager of a larger pawnbroker's shop, but also a silversmith. Garrett's grandfather, owner of the family engineering works, Richard Garrett &amp; Sons, had died in 1837, leaving the business to his eldest son, Garrett's uncle. Despite his lack of capital, Newson was determined to be successful and in 1841, at the age of 29, he moved his family to Suffolk, where he bought a barley and coal merchants business in Snape, constructing Snape Maltings from 1846.\nThe Garretts lived in a square Georgian house opposite the church in Aldeburgh until 1852. Newson's malting business expanded and more children were born, Edmund (1840), Alice (1842), Agnes (1845), Millicent (1847), who was to become a leader in the constitutional campaign for women's suffrage, Sam (1850), Josephine (1853) and George (1854). By 1850, Newson was a prosperous businessman and was able to build Alde House, a mansion on a hill behind Aldeburgh. A \"by-product of the industrial revolution\", Garrett grew up in an atmosphere of \"triumphant economic pioneering\" and the Garrett children were to grow up to become achievers in the professional classes of late-Victorian England. Elizabeth was encouraged to take an interest in local politics and, contrary to practices at the time, was allowed the freedom to explore the town with its nearby salt-marshes, beach and the small port of Slaughden with its boatbuilders' yards and sailmakers' lofts.\nEarly education.\nThere was no school in Aldeburgh, so Garrett learned reading, writing, and arithmetic from her mother. When she was 10 years old, a governess, Miss Edgeworth, a poor gentlewoman, was employed to educate Garrett and her sister. Mornings were spent in the schoolroom; there were regimented afternoon walks; educating the young ladies continued at mealtimes when Edgeworth ate with the family; at night, the governess slept in a curtained off area in the girls' bedroom. Garrett reportedly despised her governess and sought to outwit the teacher in the classroom. When Garrett was 13 and her sister 15, they were sent to a private school, the Boarding School for Ladies in Blackheath, London, which was run by the step aunts of the poet Robert Browning. There, English literature, French, Italian and German as well as deportment, were taught.\nLater in life, Garrett recalled the stupidity of her teachers there, though her schooling there did help establish a love of reading. Her main complaint about the school was the lack of science and mathematics instruction. Her reading there included works of Tennyson, Wordsworth, Milton, Coleridge, Trollope, Thackeray and George Eliot. Elizabeth and Louie were known as \"the bathing Garretts\", as their father had insisted they be allowed a hot bath once a week. However, they made what were to be lifelong friends there. When they finished in 1851, they were sent on a short tour abroad, ending with a memorable visit to the Great Exhibition in Hyde Park, London.\nAfter this formal education, Garrett spent the next nine years tending to domestic duties, but she continued to study Latin and arithmetic in the mornings and also read widely. Her sister Millicent recalled Garrett's weekly lectures, \"Talks on Things in General\", when her younger siblings would gather while she discussed politics and current affairs from Garibaldi to Macaulay's \"History of England\". In 1854, when she was eighteen, Garrett and her sister went on a long visit to their school friends, Jane and Anne Crow, in Gateshead where she met Emily Davies, the early feminist and future co-founder of Girton College, Cambridge. Davies was to be a lifelong friend and confidante, always ready to give sound advice during the important decisions of Garrett's career. It may have been in the \"English Woman's Journal\", first issued in 1858, that Garrett first read of Elizabeth Blackwell, who had become the first female doctor in the United States in 1849. When Blackwell visited London in 1859, Garrett travelled to the capital. By then, her sister Louie was married and living in London. Garrett joined the Society for Promoting the Employment of Women, which organised Blackwell's lectures on \"Medicine as a Profession for Ladies\" and set up a private meeting between Garrett and the doctor. It is said that during a visit to Alde House around 1860, one evening while sitting by the fireside, Garrett and Davies selected careers for advancing the frontiers of women's rights; Garrett was to open the medical profession to women, Davies the doors to a university education for women, while 13-year-old Millicent was allocated politics and votes for women. At first Newson was opposed to the radical idea of his daughter becoming a physician but came round and agreed to do all in his power, both financially and otherwise, to support Garrett.\nMedical education.\nAfter an initial unsuccessful visit to leading doctors in Harley Street, Garrett decided to first spend six months as a surgery nurse at Middlesex Hospital, London in August 1860. On proving to be a good nurse, she was allowed to attend an outpatients' clinic, then her first operation. She unsuccessfully attempted to enroll in the hospital's Medical School but was allowed to attend private tuition in Latin, Greek and pharmacology with the hospital's apothecary, while continuing her work as a nurse. She also employed a tutor to study anatomy and physiology three evenings a week. Eventually she was allowed into the dissecting room and the chemistry lectures. Gradually, Garrett became an unwelcome presence among the male students, who in 1861 presented a memorial to the school against her admittance as a fellow student, despite the support she enjoyed from the administration. She was obliged to leave the Middlesex Hospital but she did so with an honours certificate in chemistry and \"materia medica\". Garrett then applied to several medical schools, including Oxford, Cambridge, Glasgow, Edinburgh, St Andrews and the Royal College of Surgeons, all of which refused her admittance.\nA companion to Garrett in this effort was the lesser known Sophia Jex-Blake. While both are considered \"outstanding\" medical figures of the late 19th century, Garrett was able to obtain her credentials by way of a \"side door\" through a loophole in admissions at the Worshipful Society of Apothecaries. Having privately obtained a certificate in anatomy and physiology, she was admitted in 1862 by the Society of Apothecaries who, as a condition of their charter, could not legally exclude her on account of her sex. She was the only woman in the Apothecaries Hall who sat the exam that year. Among the 51 male candidates was William Heath Strange, who went on to found the Hampstead General Hospital, which was on the site now occupied by the Royal Free Hospital. She continued her battle to qualify by studying privately with various professors, including some at the University of St Andrews, the Edinburgh Royal Maternity and the London Hospital Medical School.\nIn 1865, Garrett finally took her exam and obtained a licence (LSA) from the Society of Apothecaries to practise medicine, the first woman qualified in Britain to do so openly (previously there was Dr James Barry who was born and raised female but presented as male from the age of 20). On the day, three out of seven candidates passed the exam, Garrett with the highest marks. The Society of Apothecaries immediately amended its regulations to prevent other women obtaining a licence meaning that Jex-Blake could not follow this same path; the new rule disallowed privately educated women to be eligible for examination. It was not until 1876 that the new Medical Act (39 and 40 Vict, Ch. 41) passed, which allowed British medical authorities to license all qualified applicants whatever their gender.\nCareer.\nThough she was now a licentiate of the Society of Apothecaries, as a woman, Garrett could not hold a medical post in any hospital. So in late 1865, Garrett opened her own practice at 20 Upper Berkeley Street, London. At first patients were scarce, but the practice gradually grew. After six months in practice, she wished to open an outpatients dispensary, to enable poor women to obtain medical help from a qualified practitioner of their own gender. In 1865, there was an outbreak of cholera in Britain, affecting both rich and poor, and in their panic, some people forgot any prejudices they had in relation to a female physician. The first death due to cholera occurred in 1866, but by then Garrett had already opened St Mary's Dispensary for Women and Children, at 69 Seymour Place. In the first year, she tended to 3,000 new patients, who made 9,300 outpatient visits to the dispensary. On hearing that the Dean of the faculty of medicine at the University of Sorbonne, Paris was in favour of admitting women as medical students, Garrett studied French so that she could apply for a medical degree, which she obtained in 1870 after some difficulty.\nThe same year she was elected to the first London School Board, an office newly opened to women; Garrett's was the highest vote among all the candidates. Also in that year, she was made a visiting physician of the East London Hospital for Children (later the Queen Elizabeth Hospital for Children), becoming the first woman in Britain to be appointed to a medical post, but she found the duties of these two positions to be incompatible with her principal work in her private practice and the dispensary, as well as her role as a new mother, so she resigned from these posts by 1873. In 1872, the dispensary became the New Hospital for Women and Children, treating women from all over London for gynaecological conditions; the hospital moved to new premises in Marylebone Street in 1874. Around this time, Garrett also entered into discussion with male medical views regarding women. In 1874, Henry Maudsley's article on Sex and Mind in Education appeared, which argued that education for women caused over-exertion and thus reduced their reproductive capacity, sometimes causing \"nervous and even mental disorders\". Garrett's counter-argument was that the real danger for women was not education but boredom and that fresh air and exercise were preferable to sitting by the fire with a novel. In the same year, she co-founded the London School of Medicine for Women with Sophia Jex-Blake and became a lecturer in what was then the only teaching hospital in Britain to offer courses for women. She continued to work there for the rest of her career and was dean of the school from 1883 to 1902. This school was later called the Royal Free Hospital School of Medicine, and became part of the medical school of University College London.\nBMA membership.\nIn 1873, Garrett gained membership of the British Medical Association (BMA). In 1878, a motion was proposed to exclude women following the election of Garrett Anderson and Frances Hoggan. The motion was opposed by Dr Norman Kerr who maintained the equal rights of members. This was \"one of several instances where Garrett, uniquely, was able to enter a hitherto all male medical institution which subsequently moved formally to exclude any women who might seek to follow her.\" In 1892, women were again admitted to the British Medical Association following a long campaign by Anderson and others. She, along with Dr Sarah Gray and Dr Eliza Walker Dunbar attended the BMA meeting at Nottingham that year, lobbying successfully for the readmission of women to the association. In 1897, Garrett Anderson was elected president of the East Anglian branch of the BMA.\nGarrett Anderson worked steadily at the development of the New Hospital for Women and Children and in 1874 co-founded and served as dean of the London School of Medicine for Women (LSMW). Both institutions were handsomely and suitably housed and equipped. The New Hospital for Women commissioned a building in the Euston Road; the architect was J. M. Brydon, who took into his employment Anderson's sister Agnes Garrett and her cousin Rhoda Garrett, who contributed to its design. For many years, the hospital was staffed entirely by medical women. The schools (in Hunter Street, WC1) had over 200 students, most of them preparing for the medical degree of London University, which was opened to women in 1877.\nWomen\u2019s suffrage movement.\nGarrett Anderson was also active in the women's suffrage movement. In 1866, Garrett Anderson and Davies presented petitions with more than 1,500 signatures asking that female heads of household be given the right to vote. That year, Garrett Anderson joined the first British Women's Suffrage Committee. She was not as active as her sister, Millicent Garrett Fawcett, though Garrett Anderson became a member of the Central Committee of the National Society for Women's Suffrage in 1889. After her husband's death in 1907, she became more active. As mayor of Aldeburgh, she gave speeches for suffrage, before the increasing militant activity in the movement led to her withdrawal in 1911. Her daughter Louisa, also a physician, was more active and more militant, spending time in prison in 1912 for her suffrage activities.\nPersonal life.\nElizabeth Garrett Anderson once remarked that \"a doctor leads two lives, the professional and the private, and the boundaries between the two are never traversed\". In 1871, she married James George Skelton Anderson (died 1907) of the Orient Steamship Company, but she did not give up her medical practice. She had three children, Louisa (1873\u20131943), Margaret (1874\u20131875), who died of meningitis, and Alan (1877\u20131952). Louisa also became a pioneering doctor of medicine and feminist activist.\nThey retired to Aldeburgh in 1902, moving to Alde House in 1903, after the death of Elizabeth's mother. Skelton died of a stroke in 1907. She enjoyed a happy marriage and in later life, devoted time to Alde House, gardening, and travelling with younger members of the extended family.\nOn 9 November 1908, she was elected mayor of Aldeburgh, the first female mayor in England. Her father had been mayor in 1889.\nShe died in 1917 and is buried in the churchyard of St Peter and St Paul's Church, Aldeburgh.\nLegacy.\nThe New Hospital for Women was renamed the Elizabeth Garrett Anderson Hospital in 1918 and amalgamated with the Obstetric Hospital in 2001 to form the Elizabeth Garrett Anderson and Obstetric Hospital before relocating to become the University College Hospital Elizabeth Garrett Anderson Wing at UCH.\nThe former Elizabeth Garrett Anderson Hospital buildings are incorporated into the new National Headquarters for the public service trade union UNISON. The Elizabeth Garrett Anderson Gallery, a permanent installation set within the restored hospital building, uses a variety of media to set the story of Garrett Anderson, her hospital, and women's struggle to achieve equality in the field of medicine within the wider framework of 19th and 20th century social history.\nThe critical care centre at Ipswich Hospital was named the Garrett Anderson Centre in her honour and in recognition of her connection to the county of Suffolk.\nThe new medical school at the University of Worcester, due to accept its first students in 2023, is to be called the Elizabeth Garrett Anderson Building.\nElizabeth Garrett Anderson School, a secondary school for girls in Islington, London, is named after her.\nThe archives of Elizabeth Garrett Anderson are held at the Women's Library at the London School of Economics. The archives of the Elizabeth Garrett Anderson Hospital (formerly the New Hospital for Women) are held at the London Metropolitan Archives.\nOn 9 June 2016, Google Doodle commemorated her 180th birthday.\nThe Elizabeth Garrett Anderson Programme of the NHS Leadership Academy is a master's degree in leadership and management."}
{"id": "9696", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=9696", "title": "Erosion", "text": "Erosion is the action of surface processes (such as water flow or wind) that removes soil, rock, or dissolved material from one location on the Earth's crust and then transports it to another location where it is deposited. Erosion is distinct from weathering which involves no movement. Removal of rock or soil as clastic sediment is referred to as \"physical\" or \"mechanical\" erosion; this contrasts with \"chemical\" erosion, where soil or rock material is removed from an area by dissolution. Eroded sediment or solutes may be transported just a few millimetres, or for thousands of kilometres.\nAgents of erosion include rainfall; bedrock wear in rivers; coastal erosion by the sea and waves; glacial plucking, abrasion, and scour; areal flooding; wind abrasion; groundwater processes; and mass movement processes in steep landscapes like landslides and debris flows. The rates at which such processes act control how fast a surface is eroded. Typically, physical erosion proceeds the fastest on steeply sloping surfaces, and rates may also be sensitive to some climatically controlled properties including amounts of water supplied (e.g., by rain), storminess, wind speed, wave fetch, or atmospheric temperature (especially for some ice-related processes). Feedbacks are also possible between rates of erosion and the amount of eroded material that is already carried by, for example, a river or glacier. The transport of eroded materials from their original location is followed by deposition, which is arrival and emplacement of material at a new location.\nWhile erosion is a natural process, human activities have increased by 10\u201340 times the rate at which soil erosion is occurring globally. At agriculture sites in the Appalachian Mountains, intensive farming practices have caused erosion at up to 100 times the natural rate of erosion in the region. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, this leads to desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.\nIntensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion. However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.\nPhysical processes.\nRainfall and surface runoff.\nRainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: \"splash erosion\", \"sheet erosion\", \"rill erosion\", and \"gully erosion\". Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).\nIn \"splash erosion\", the impact of a falling raindrop creates a small crater in the soil, ejecting soil particles. The distance these soil particles travel can be as much as vertically and horizontally on level ground.\nIf the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope. \"Sheet erosion\" is the transport of loosened soil particles by overland flow.\n\"Rill erosion\" refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.\n\"Gully erosion\" occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth. A gully is distinguished from a rill based on a critical cross-sectional area of at least one square foot, i.e. the size of a channel that can no longer be erased via normal tillage operations.\nExtreme gully erosion can progress to formation of badlands. These form under conditions of high relief on easily eroded bedrock in climates favorable to erosion. Conditions or disturbances that limit the growth of protective vegetation (rhexistasy) are a key element of badland formation.\nRivers and streams.\n\"Valley\" or \"stream erosion\" occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V-shaped cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles, and boulders can also act erosively as they traverse a surface, in a process known as \"traction\".\n\"Bank erosion\" is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as \"scour\". Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.\n\"Thermal erosion\" is the result of melting and weakening permafrost due to moving water. It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials. Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a segment of the Beaufort Sea shoreline averaged per year from 1955 to 2002.\nMost river erosion happens nearer to the mouth of a river. On a river bend, the longest least sharp side has slower moving water. Here deposits build up. On the narrowest sharpest side of the bend, there is faster moving water so this side tends to erode away mostly.\nRapid erosion by a large river can remove enough sediments to produce a river anticline, as isostatic rebound raises rock beds unburdened by erosion of overlying beds.\nCoastal erosion.\nShoreline erosion, which occurs on both exposed and sheltered coasts, primarily occurs through the action of currents and waves but sea level (tidal) change can also play a role.\n\"Hydraulic action\" takes place when the air in a joint is suddenly compressed by a wave closing the entrance of the joint. This then cracks it. \"Wave pounding\" is when the sheer energy of the wave hitting the cliff or rock breaks pieces off. \"Abrasion\" or \"corrasion\" is caused by waves launching sea load at the cliff. It is the most effective and rapid form of shoreline erosion (not to be confused with \"corrosion\"). \"Corrosion\" is the dissolving of rock by carbonic acid in sea water. Limestone cliffs are particularly vulnerable to this kind of erosion. \"Attrition\" is where particles/sea load carried by the waves are worn down as they hit each other and the cliffs. This then makes the material easier to wash away. The material ends up as shingle and sand. Another significant source of erosion, particularly on carbonate coastlines, is boring, scraping and grinding of organisms, a process termed \"bioerosion\".\nSediment is transported along the coast in the direction of the prevailing current (longshore drift). When the upcurrent supply of sediment is less than the amount being carried away, erosion occurs. When the upcurrent amount of sediment is greater, sand or gravel banks will tend to form as a result of deposition. These banks may slowly migrate along the coast in the direction of the longshore drift, alternately protecting and exposing parts of the coastline. Where there is a bend in the coastline, quite often a buildup of eroded material occurs forming a long narrow bank (a spit). Armoured beaches and submerged offshore sandbanks may also protect parts of a coastline from erosion. Over the years, as the shoals gradually shift, the erosion may be redirected to attack different parts of the shore.\nErosion of a coastal surface, followed by a fall in sea level, can produce a distinctive landform called a raised beach.\nChemical erosion.\nChemical erosion is the loss of matter in a landscape in the form of solutes. Chemical erosion is usually calculated from the solutes found in streams. Anders Rapp pioneered the study of chemical erosion in his work about K\u00e4rkevagge published in 1960.\nFormation of sinkholes and other features of karst topography is an example of extreme chemical erosion.\nGlaciers.\nGlaciers erode predominantly by three different processes: abrasion/scouring, plucking, and ice thrusting. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood. Scientists have shown that, in addition to the role of temperature played in valley-deepening, other glaciological processes, such as erosion also control cross-valley variations. In a homogeneous bedrock erosion pattern, curved channel cross-section beneath the ice is created. Though the glacier continues to incise vertically, the shape of the channel beneath the ice eventually remain constant, reaching a U-shaped parabolic steady-state shape as we now see in glaciated valleys. Scientists also provide a numerical estimate of the time required for the ultimate formation of a steady-shaped U-shaped valley\u2014approximately 100,000 years. In a weak bedrock (containing material more erodible than the surrounding rocks) erosion pattern, on the contrary, the amount of over deepening is limited because ice velocities and erosion rates are reduced.\nGlaciers can also cause pieces of bedrock to crack off in the process of plucking. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. This method produced some of the many thousands of lake basins that dot the edge of the Canadian Shield. Differences in the height of mountain ranges are not only being the result tectonic forces, such as rock uplift, but also local climate variations. Scientists use global analysis of topography to show that glacial erosion controls the maximum height of mountains, as the relief between mountain peaks and the snow line are generally confined to altitudes less than 1500\u00a0m. The erosion caused by glaciers worldwide erodes mountains so effectively that the term \"glacial buzzsaw\" has become widely used, which describes the limiting effect of glaciers on the height of mountain ranges. As mountains grow higher, they generally allow for more glacial activity (especially in the accumulation zone above the glacial equilibrium line altitude), which causes increased rates of erosion of the mountain, decreasing mass faster than isostatic rebound can add to the mountain. This provides a good example of a negative feedback loop. Ongoing research is showing that while glaciers tend to decrease mountain size, in some areas, glaciers can actually reduce the rate of erosion, acting as a \"glacial armor\". Ice can not only erode mountains but also protect them from erosion. Depending on glacier regime, even steep alpine lands can be preserved through time with the help of ice. Scientists have proved this theory by sampling eight summits of northwestern Svalbard using Be10 and Al26, showing that northwestern Svalbard transformed from a glacier-erosion state under relatively mild glacial maxima temperature, to a glacier-armor state occupied by cold-based, protective ice during much colder glacial maxima temperatures as the Quaternary ice age progressed.\nThese processes, combined with erosion and transport by the water network beneath the glacier, leave behind glacial landforms such as moraines, drumlins, ground moraine (till), glaciokarst, kames, kame deltas, moulins, and glacial erratics in their wake, typically at the terminus or during glacier retreat.\nThe best-developed glacial valley morphology appears to be restricted to landscapes with low rock uplift rates (less than or equal to 2mm per year) and high relief, leading to long-turnover times. Where rock uplift rates exceed 2mm per year, glacial valley morphology has generally been significantly modified in postglacial time. Interplay of glacial erosion and tectonic forcing governs the morphologic impact of glaciations on active orogens, by both influencing their height, and by altering the patterns of erosion during subsequent glacial periods via a link between rock uplift and valley cross-sectional shape.\nFloods.\nAt extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.\nWind erosion.\nWind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage\u2014especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.\nWind erosion is of two primary varieties: \"deflation\", where the wind picks up and carries away loose particles; and \"abrasion\", where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) \"surface creep\", where larger, heavier particles slide or roll along the ground; (2) \"saltation\", where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) \"suspension\", where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50\u201370%) of wind erosion, followed by suspension (30\u201340%), and then surface creep (5\u201325%).\nWind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.\nMass wasting.\n\"Mass wasting\" or \"mass movement\" is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.\nMass wasting is an important part of the erosional process and is often the first stage in the breakdown and transport of weathered materials in mountainous areas. It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-wasting processes are always occurring continuously on all slopes; some mass-wasting processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.\n\"Slumping\" happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.\n\"Surface creep\" is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles in diameter by wind along the soil surface.\nSubmarine sediment gravity flows.\nOn the continental slope, erosion of the ocean floor to create channels and submarine canyons can result from the rapid downslope flow of sediment gravity flows, bodies of sediment-laden water that move rapidly downslope as turbidity currents. Where erosion by turbidity currents creates oversteepened slopes it can also trigger underwater landslides and debris flows. Turbidity currents can erode channels and canyons into substrates ranging from recently deposited unconsolidated sediments to hard crystalline bedrock. Almost all continental slopes and deep ocean basins display such channels and canyons resulting from sediment gravity flows and submarine canyons act as conduits for the transfer of sediment from the continents and shallow marine environments to the deep sea. Turbidites, which are the sedimentary deposits resulting from turbidity currents, comprise some of the thickest and largest sedimentary sequences on Earth, indicating that the associated erosional processes must also have played a prominent role in Earth's history.\nFactors affecting erosion rates.\nClimate.\nThe amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.\nIn some areas of the world (e.g. the mid-western US), rainfall intensity is the primary determinant of erosivity (for a definition of \"erosivity\" check,) with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.\nIn other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto the previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water. According to the climate change projections, erosivity will increase significantly in Europe and soil erosion may increase by 13\u201322.5% by 2050 \nIn Taiwan, where typhoon frequency increased significantly in the 21st century, a strong link has been drawn between the increase in storm frequency with an increase in sediment load in rivers and reservoirs, highlighting the impacts climate change can have on erosion.\nVegetative cover.\nVegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.\nTopography.\nThe topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.\nTectonics.\nTectonic processes control rates and distributions of erosion at the Earth's surface. If the tectonic action causes part of the Earth's surface (e.g., a mountain range) to be raised or lowered relative to surrounding areas, this must necessarily change the gradient of the land surface. Because erosion rates are almost always sensitive to the local slope (see above), this will change the rates of erosion in the uplifted area. Active tectonics also brings fresh, unweathered rock towards the surface, where it is exposed to the action of erosion.\nHowever, erosion can also affect tectonic processes. The removal by erosion of large amounts of rock from a particular region, and its deposition elsewhere, can result in a lightening of the load on the lower crust and mantle. Because tectonic processes are driven by gradients in the stress field developed in the crust, this unloading can in turn cause tectonic or isostatic uplift in the region. In some cases, it has been hypothesised that these twin feedbacks can act to localize and enhance zones of very rapid exhumation of deep crustal rocks beneath places on the Earth's surface with extremely high erosion rates, for example, beneath the extremely steep terrain of Nanga Parbat in the western Himalayas. Such a place has been called a \"tectonic aneurysm\".\nDevelopment.\nHuman land development, in forms including agricultural and urban development, is considered a significant factor in erosion and sediment transport, which aggravate food insecurity. In Taiwan, increases in sediment load in the northern, central, and southern regions of the island can be tracked with the timeline of development for each region throughout the 20th century. The intentional removal of soil and rock by humans is a form of erosion that has been named \"lisasion\".\nErosion at various scales.\nMountain ranges.\nMountain ranges take millions of years to erode to the degree they effectively cease to exist. Scholars Pitman and Golovchenko estimate that it takes probably more than 450 million years to erode a mountain mass similar to the Himalaya into an almost-flat peneplain if there are no significant sea-level changes. Erosion of mountains massifs can create a pattern of equally high summits called summit accordance. It has been argued that extension during post-orogenic collapse is a more effective mechanism of lowering the height of orogenic mountains than erosion.\nExamples of heavily eroded mountain ranges include the Timanides of Northern Russia. Erosion of this orogen has produced sediments that are now found in the East European Platform, including the Cambrian Sablya Formation near Lake Ladoga. Studies of these sediments indicate that it is likely that the erosion of the orogen began in the Cambrian and then intensified in the Ordovician.\nSoils.\nIf the erosion rate exceeds soil formation, erosion destroys the soil. Lower rates of erosion can prevent the formation of soil features that take time to develop. Inceptisols develop on eroded landscapes that, if stable, would have supported the formation of more developed Alfisols.\nWhile erosion of soils is a natural process, human activities have increased by 10-40 times the rate at which erosion occurs globally. Excessive (or accelerated) erosion causes both \"on-site\" and \"off-site\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems.\nOften in the United States, farmers cultivating highly erodible land must comply with a conservation plan to be eligible for agricultural assistance."}
{"id": "9697", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=9697", "title": "Euclidean space", "text": "Euclidean space is the fundamental space of geometry, intended to represent physical space. Originally, in Euclid's \"Elements\", it was the three-dimensional space of Euclidean geometry, but in modern mathematics there are \"Euclidean spaces\" of any positive integer dimension \"n\", which are called Euclidean \"n\"-spaces when one wants to specify their dimension. For \"n\" equal to one or two, they are commonly called respectively Euclidean lines and Euclidean planes. The qualifier \"Euclidean\" is used to distinguish Euclidean spaces from other spaces that were later considered in physics and modern mathematics.\nAncient Greek geometers introduced Euclidean space for modeling the physical space. Their work was collected by the ancient Greek mathematician Euclid in his \"Elements\", with the great innovation of \"proving\" all properties of the space as theorems, by starting from a few fundamental properties, called \"postulates\", which either were considered as evident (for example, there is exactly one straight line passing through two points), or seemed impossible to prove (parallel postulate).\nAfter the introduction at the end of the 19th century of non-Euclidean geometries, the old postulates were re-formalized to define Euclidean spaces through axiomatic theory. Another definition of Euclidean spaces by means of vector spaces and linear algebra has been shown to be equivalent to the axiomatic definition. It is this definition that is more commonly used in modern mathematics, and detailed in this article. In all definitions, Euclidean spaces consist of points, which are defined only by the properties that they must have for forming a Euclidean space.\nThere is essentially only one Euclidean space of each dimension; that is, all Euclidean spaces of a given dimension are isomorphic. Therefore, it is usually possible to work with a specific Euclidean space, denoted formula_1 or formula_2, which can be represented using Cartesian coordinates as the real -space formula_3 equipped with the standard dot product.\nDefinition.\nHistory of the definition.\nEuclidean space was introduced by ancient Greeks as an abstraction of our physical space. Their great innovation, appearing in Euclid's \"Elements\" was to build and \"prove\" all geometry by starting from a few very basic properties, which are abstracted from the physical world, and cannot be mathematically proved because of the lack of more basic tools. These properties are called postulates, or axioms in modern language. This way of defining Euclidean space is still in use under the name of synthetic geometry.\nIn 1637, Ren\u00e9 Descartes introduced Cartesian coordinates, and showed that these allow reducing geometric problems to algebraic computations with numbers. This reduction of geometry to algebra was a major change in point of view, as, until then, the real numbers were defined in terms of lengths and distances.\nEuclidean geometry was not applied in spaces of dimension more than three until the 19th century. Ludwig Schl\u00e4fli generalized Euclidean geometry to spaces of dimension , using both synthetic and algebraic methods, and discovered all of the regular polytopes (higher-dimensional analogues of the Platonic solids) that exist in Euclidean spaces of any dimension.\nDespite the wide use of Descartes' approach, which was called analytic geometry, the definition of Euclidean space remained unchanged until the end of 19th century. The introduction of abstract vector spaces allowed their use in defining Euclidean spaces with a purely algebraic definition. This new definition has been shown to be equivalent to the classical definition in terms of geometric axioms. It is this algebraic definition that is now most often used for introducing Euclidean spaces.\nMotivation of the modern definition.\nOne way to think of the Euclidean plane is as a set of points satisfying certain relationships, expressible in terms of distance and angles. For example, there are two fundamental operations (referred to as motions) on the plane. One is translation, which means a shifting of the plane so that every point is shifted in the same direction and by the same distance. The other is rotation around a fixed point in the plane, in which all points in the plane turn around that fixed point through the same angle. One of the basic tenets of Euclidean geometry is that two figures (usually considered as subsets) of the plane should be considered equivalent (congruent) if one can be transformed into the other by some sequence of translations, rotations and reflections (see below).\nIn order to make all of this mathematically precise, the theory must clearly define what is a Euclidean space, and the related notions of distance, angle, translation, and rotation. Even when used in physical theories, Euclidean space is an abstraction detached from actual physical locations, specific reference frames, measurement instruments, and so on. A purely mathematical definition of Euclidean space also ignores questions of units of length and other physical dimensions: the distance in a \"mathematical\" space is a number, not something expressed in inches or metres.\nThe standard way to mathematically define a Euclidean space, as carried out in the remainder of this article, is as a set of points on which a real vector space acts \u2014 the \"space of translations\" which is equipped with an inner product. The action of translations makes the space an affine space, and this allows defining lines, planes, subspaces, dimension, and parallelism. The inner product allows defining distance and angles.\nThe set formula_3 of -tuples of real numbers equipped with the dot product is a Euclidean space of dimension . Conversely, the choice of a point called the \"origin\" and an orthonormal basis of the space of translations is equivalent with defining an isomorphism between a Euclidean space of dimension and formula_3 viewed as a Euclidean space.\nIt follows that everything that can be said about a Euclidean space can also be said about formula_6 Therefore, many authors, especially at elementary level, call formula_3 the standard Euclidean space of dimension , or simply \"the\" Euclidean space of dimension .\nA reason for introducing such an abstract definition of Euclidean spaces, and for working with formula_2 instead of formula_3 is that it is often preferable to work in a \"coordinate-free\" and \"origin-free\" manner (that is, without choosing a preferred basis and a preferred origin). Another reason is that there is no standard origin nor any standard basis in the physical world.\nTechnical definition.\nA is a finite-dimensional inner product space over the real numbers.\nA Euclidean space is an affine space over the reals such that the associated vector space is a Euclidean vector space. Euclidean spaces are sometimes called \"Euclidean affine spaces\" to distinguish them from Euclidean vector spaces.\nIf is a Euclidean space, its associated vector space (Euclidean vector space) is often denoted formula_10 The \"dimension\" of a Euclidean space is the dimension of its associated vector space.\nThe elements of are called \"points\", and are commonly denoted by capital letters. The elements of formula_11 are called \"Euclidean vectors\" or \"free vectors\". They are also called \"translations\", although, properly speaking, a translation is the geometric transformation resulting from the action of a Euclidean vector on the Euclidean space.\nThe action of a translation on a point provides a point that is denoted . This action satisfies\nformula_12\nNote: The second in the left-hand side is a vector addition; each other denotes an action of a vector on a point. This notation is not ambiguous, as, to distinguish between the two meanings of , it suffices to look at the nature of its left argument.\nThe fact that the action is free and transitive means that, for every pair of points , there is exactly one displacement vector such that . This vector is denoted or formula_13\nAs previously explained, some of the basic properties of Euclidean spaces result from the structure of affine space. They are described in and its subsections. The properties resulting from the inner product are explained in and its subsections.\nPrototypical examples.\nFor any vector space, the addition acts freely and transitively on the vector space itself. Thus a Euclidean vector space can be viewed as a Euclidean space that has itself as the associated vector space.\nA typical case of Euclidean vector space is formula_3 viewed as a vector space equipped with the dot product as an inner product. The importance of this particular example of Euclidean space lies in the fact that every Euclidean space is isomorphic to it. More precisely, given a Euclidean space of dimension , the choice of a point, called an \"origin\" and an orthonormal basis of formula_11 defines an isomorphism of Euclidean spaces from to formula_6\nAs every Euclidean space of dimension is isomorphic to it, the Euclidean space formula_3 is sometimes called the \"standard Euclidean space\" of dimension .\nAffine structure.\nSome basic properties of Euclidean spaces depend only on the fact that a Euclidean space is an affine space. They are called affine properties and include the concepts of lines, subspaces, and parallelism, which are detailed in next subsections.\nSubspaces.\nLet be a Euclidean space and formula_11 its associated vector space.\nA \"flat\", \"Euclidean subspace\" or \"affine subspace\" of is a subset of such that\nformula_19\nas the associated vector space of is a linear subspace (vector subspace) of formula_10 A Euclidean subspace is a Euclidean space with formula_21 as the associated vector space. This linear subspace formula_21 is also called the \"direction\" of .\nIf is a point of then\nformula_23\nConversely, if is a point of and formula_24 is a linear subspace of formula_25 then\nformula_26\nis a Euclidean subspace of direction formula_24. (The associated vector space of this subspace is formula_24.)\nA Euclidean vector space formula_11 (that is, a Euclidean space that is equal to formula_11) has two sorts of subspaces: its Euclidean subspaces and its linear subspaces. Linear subspaces are Euclidean subspaces and a Euclidean subspace is a linear subspace if and only if it contains the zero vector.\nLines and segments.\nIn a Euclidean space, a \"line\" is a Euclidean subspace of dimension one. Since a vector space of dimension one is spanned by any nonzero vector, a line is a set of the form\nformula_31\nwhere and are two distinct points of the Euclidean space as a part of the line.\nIt follows that \"there is exactly one line that passes through (contains) two distinct points.\" This implies that two distinct lines intersect in at most one point.\nA more symmetric representation of the line passing through and is\nformula_32\nwhere is an arbitrary point (not necessary on the line).\nIn a Euclidean vector space, the zero vector is usually chosen for ; this allows simplifying the preceding formula into\nformula_33\nA standard convention allows using this formula in every Euclidean space, see .\nThe \"line segment\", or simply \"segment\", joining the points and is the subset of points such that in the preceding formulas. It is denoted or ; that is\nformula_34\nParallelism.\nTwo subspaces and of the same dimension in a Euclidean space are \"parallel\" if they have the same direction (i.e., the same associated vector space). Equivalently, they are parallel, if there is a translation vector that maps one to the other:\nformula_35\nGiven a point and a subspace , there exists exactly one subspace that contains and is parallel to , which is formula_36 In the case where is a line (subspace of dimension one), this property is Playfair's axiom.\nIt follows that in a Euclidean plane, two lines either meet in one point or are parallel.\nThe concept of parallel subspaces has been extended to subspaces of different dimensions: two subspaces are parallel if the direction of one of them is contained in the direction to the other.\nMetric structure.\nThe vector space formula_11 associated to a Euclidean space is an inner product space. This implies a symmetric bilinear form\nformula_38\nthat is positive definite (that is formula_39 is always positive for ).\nThe inner product of a Euclidean space is often called \"dot product\" and denoted . This is specially the case when a Cartesian coordinate system has been chosen, as, in this case, the inner product of two vectors is the dot product of their coordinate vectors. For this reason, and for historical reasons, the dot notation is more commonly used than the bracket notation for the inner product of Euclidean spaces. This article will follow this usage; that is formula_40 will be denoted in the remainder of this article.\nThe Euclidean norm of a vector is\nformula_41\nThe inner product and the norm allows expressing and proving metric and topological properties of Euclidean geometry. The next subsection describe the most fundamental ones. \"In these subsections,\" \"denotes an arbitrary Euclidean space, and formula_11 denotes its vector space of translations.\"\nDistance and length.\nThe \"distance\" (more precisely the \"Euclidean distance\") between two points of a Euclidean space is the norm of the translation vector that maps one point to the other; that is\nformula_43\nThe \"length\" of a segment is the distance between its endpoints \"P\" and \"Q\". It is often denoted formula_44.\nThe distance is a metric, as it is positive definite, symmetric, and satisfies the triangle inequality\nformula_45\nMoreover, the equality is true if and only if a point belongs to the segment . This inequality means that the length of any edge of a triangle is smaller than the sum of the lengths of the other edges. This is the origin of the term \"triangle inequality\".\nWith the Euclidean distance, every Euclidean space is a complete metric space.\nOrthogonality.\nTwo nonzero vectors and of formula_11 (the associated vector space of a Euclidean space ) are \"perpendicular\" or \"orthogonal\" if their inner product is zero:\nformula_47\nTwo linear subspaces of formula_11 are orthogonal if every nonzero vector of the first one is perpendicular to every nonzero vector of the second one. This implies that the intersection of the linear subspaces is reduced to the zero vector.\nTwo lines, and more generally two Euclidean subspaces (A line can be considered as one Euclidean subspace.) are orthogonal if their directions (the associated vector spaces of the Euclidean subspaces) are orthogonal. Two orthogonal lines that intersect are said \"perpendicular\".\nTwo segments and that share a common endpoint are \"perpendicular\" or \"form a right angle\" if the vectors formula_49 and formula_50 are orthogonal.\nIf and form a right angle, one has\nformula_51\nThis is the Pythagorean theorem. Its proof is easy in this context, as, expressing this in terms of the inner product, one has, using bilinearity and symmetry of the inner product:\nformula_52\nHere, formula_53 is used since these two vectors are orthogonal.\nAngle.\nThe (non-oriented) \"angle\" between two nonzero vectors and in formula_11 is\nformula_55\nwhere is the principal value of the arccosine function. By Cauchy\u2013Schwarz inequality, the argument of the arccosine is in the interval . Therefore is real, and (or if angles are measured in degrees).\nAngles are not useful in a Euclidean line, as they can be only 0 or .\nIn an oriented Euclidean plane, one can define the \"oriented angle\" of two vectors. The oriented angle of two vectors and is then the opposite of the oriented angle of and . In this case, the angle of two vectors can have any value modulo an integer multiple of . In particular, a reflex angle equals the negative angle .\nThe angle of two vectors does not change if they are multiplied by positive numbers. More precisely, if and are two vectors, and and are real numbers, then\nformula_56\nIf , , and are three points in a Euclidean space, the angle of the segments and is the angle of the vectors formula_57 and formula_58 As the multiplication of vectors by positive numbers do not change the angle, the angle of two half-lines with initial point can be defined: it is the angle of the segments and , where and are arbitrary points, one on each half-line. Although this is less used, one can define similarly the angle of segments or half-lines that do not share an initial point.\nThe angle of two lines is defined as follows. If is the angle of two segments, one on each line, the angle of any two other segments, one on each line, is either or . One of these angles is in the interval , and the other being in . The \"non-oriented angle\" of the two lines is the one in the interval . In an oriented Euclidean plane, the \"oriented angle\" of two lines belongs to the interval .\nCartesian coordinates.\nEvery Euclidean vector space has an orthonormal basis (in fact, infinitely many in dimension higher than one, and two in dimension one), that is a basis formula_59 of unit vectors (formula_60) that are pairwise orthogonal (formula_61 for ). More precisely, given any basis formula_62 the Gram\u2013Schmidt process computes an orthonormal basis such that, for every , the linear spans of formula_63 and formula_64 are equal.\nGiven a Euclidean space , a \"Cartesian frame\" is a set of data consisting of an orthonormal basis of formula_25 and a point of , called the \"origin\" and often denoted . A Cartesian frame formula_66 allows defining Cartesian coordinates for both and formula_11 in the following way.\nThe Cartesian coordinates of a vector of formula_11 are the coefficients of on the orthonormal basis formula_69 For example, the Cartesian coordinates of a vector formula_70 on an orthonormal basis formula_71 (that may be named as formula_72 as a convention) in a 3-dimensional Euclidean space is formula_73 if formula_74. As the basis is orthonormal, the -th coefficient formula_75 is equal to the dot product formula_76\nThe Cartesian coordinates of a point of are the Cartesian coordinates of the vector formula_77\nOther coordinates.\nAs a Euclidean space is an affine space, one can consider an affine frame on it, which is the same as a Euclidean frame, except that the basis is not required to be orthonormal. This define affine coordinates, sometimes called \"skew coordinates\" for emphasizing that the basis vectors are not pairwise orthogonal.\nAn affine basis of a Euclidean space of dimension is a set of points that are not contained in a hyperplane. An affine basis define barycentric coordinates for every point.\nMany other coordinates systems can be defined on a Euclidean space of dimension , in the following way. Let be a homeomorphism (or, more often, a diffeomorphism) from a dense open subset of to an open subset of formula_6 The \"coordinates\" of a point of are the components of . The polar coordinate system (dimension 2) and the spherical and cylindrical coordinate systems (dimension 3) are defined this way.\nFor points that are outside the domain of , coordinates may sometimes be defined as the limit of coordinates of neighbour points, but these coordinates may be not uniquely defined, and may be not continuous in the neighborhood of the point. For example, for the spherical coordinate system, the longitude is not defined at the pole, and on the antimeridian, the longitude passes discontinuously from \u2013180\u00b0 to +180\u00b0.\nThis way of defining coordinates extends easily to other mathematical structures, and in particular to manifolds.\nIsometries.\nAn isometry between two metric spaces is a bijection preserving the distance, that is\nformula_79\nIn the case of a Euclidean vector space, an isometry that maps the origin to the origin preserves the norm\nformula_80\nsince the norm of a vector is its distance from the zero vector. It preserves also the inner product\nformula_81\nsince\nformula_82\nAn isometry of Euclidean vector spaces is a linear isomorphism.\nAn isometry formula_83 of Euclidean spaces defines an isometry formula_84 of the associated Euclidean vector spaces. This implies that two isometric Euclidean spaces have the same dimension. Conversely, if and are Euclidean spaces, , , and formula_85 is an isometry, then the map formula_83 defined by\nformula_87\nis an isometry of Euclidean spaces.\nIt follows from the preceding results that an isometry of Euclidean spaces maps lines to lines, and, more generally Euclidean subspaces to Euclidean subspaces of the same dimension, and that the restriction of the isometry on these subspaces are isometries of these subspaces.\nIsometry with prototypical examples.\nIf is a Euclidean space, its associated vector space formula_11 can be considered as a Euclidean space. Every point defines an isometry of Euclidean spaces\nformula_89\nwhich maps to the zero vector and has the identity as associated linear map. The inverse isometry is the map\nformula_90\nA Euclidean frame allows defining the map\nformula_91\nwhich is an isometry of Euclidean spaces. The inverse isometry is\nformula_92\n\"This means that, up to an isomorphism, there is exactly one Euclidean space of a given dimension.\"\nThis justifies that many authors talk of formula_3 as \"the\" Euclidean space of dimension .\nEuclidean group.\nAn isometry from a Euclidean space onto itself is called \"Euclidean isometry\", \"Euclidean transformation\" or \"rigid transformation\". The rigid transformations of a Euclidean space form a group (under composition), called the \"Euclidean group\" and often denoted of .\nThe simplest Euclidean transformations are translations\nformula_94\nThey are in bijective correspondence with vectors. This is a reason for calling \"space of translations\" the vector space associated to a Euclidean space. The translations form a normal subgroup of the Euclidean group.\nA Euclidean isometry of a Euclidean space defines a linear isometry formula_95 of the associated vector space (by \"linear isometry\", it is meant an isometry that is also a linear map) in the following way: denoting by the vector formula_96 if is an arbitrary point of , one has\nformula_97\nIt is straightforward to prove that this is a linear map that does not depend from the choice of \nThe map formula_98 is a group homomorphism from the Euclidean group onto the group of linear isometries, called the orthogonal group. The kernel of this homomorphism is the translation group, showing that it is a normal subgroup of the Euclidean group.\nThe isometries that fix a given point form the stabilizer subgroup of the Euclidean group with respect to . The restriction to this stabilizer of above group homomorphism is an isomorphism. So the isometries that fix a given point form a group isomorphic to the orthogonal group.\nLet be a point, an isometry, and the translation that maps to . The isometry formula_99 fixes . So formula_100 and \"the Euclidean group is the semidirect product of the translation group and the orthogonal group.\"\nThe special orthogonal group is the normal subgroup of the orthogonal group that preserves handedness. It is a subgroup of index two of the orthogonal group. Its inverse image by the group homomorphism formula_98 is a normal subgroup of index two of the Euclidean group, which is called the \"special Euclidean group\" or the \"displacement group\". Its elements are called \"rigid motions\" or \"displacements\".\nRigid motions include the identity, translations, rotations (the rigid motions that fix at least a point), and also screw motions.\nTypical examples of rigid transformations that are not rigid motions are reflections, which are rigid transformations that fix a hyperplane and are not the identity. They are also the transformations consisting in changing the sign of one coordinate over some Euclidean frame.\nAs the special Euclidean group is a subgroup of index two of the Euclidean group, given a reflection , every rigid transformation that is not a rigid motion is the product of and a rigid motion. A glide reflection is an example of a rigid transformation that is not a rigid motion or a reflection.\nAll groups that have been considered in this section are Lie groups and algebraic groups.\nTopology.\nThe Euclidean distance makes a Euclidean space a metric space, and thus a topological space. This topology is called the Euclidean topology. In the case of formula_102 this topology is also the product topology.\nThe open sets are the subsets that contains an open ball around each of their points. In other words, open balls form a base of the topology.\nThe topological dimension of a Euclidean space equals its dimension. This implies that Euclidean spaces of different dimensions are not homeomorphic. Moreover, the theorem of invariance of domain asserts that a subset of a Euclidean space is open (for the subspace topology) if and only if it is homeomorphic to an open subset of a Euclidean space of the same dimension.\nEuclidean spaces are complete and locally compact. That is, a closed subset of a Euclidean space is compact if it is bounded (that is, contained in a ball). In particular, closed balls are compact.\nAxiomatic definitions.\nThe definition of Euclidean spaces that has been described in this article differs fundamentally of Euclid's one. In reality, Euclid did not define formally the space, because it was thought as a description of the physical world that exists independently of human mind. The need of a formal definition appeared only at the end of 19th century, with the introduction of non-Euclidean geometries.\nTwo different approaches have been used. Felix Klein suggested to define geometries through their symmetries. The presentation of Euclidean spaces given in this article, is essentially issued from his Erlangen program, with the emphasis given on the groups of translations and isometries.\nOn the other hand, David Hilbert proposed a set of axioms, inspired by Euclid's postulates. They belong to synthetic geometry, as they do not involve any definition of real numbers. Later G. D. Birkhoff and Alfred Tarski proposed simpler sets of axioms, which use real numbers (see Birkhoff's axioms and Tarski's axioms).\nIn \"Geometric Algebra\", Emil Artin has proved that all these definitions of a Euclidean space are equivalent. It is rather easy to prove that all definitions of Euclidean spaces satisfy Hilbert's axioms, and that those involving real numbers (including the above given definition) are equivalent. The difficult part of Artin's proof is the following. In Hilbert's axioms, congruence is an equivalence relation on segments. One can thus define the \"length\" of a segment as its equivalence class. One must thus prove that this length satisfies properties that characterize nonnegative real numbers. Artin proved this with axioms equivalent to those of Hilbert.\nUsage.\nSince the ancient Greeks, Euclidean space has been used for modeling shapes in the physical world. It is thus used in many sciences, such as physics, mechanics, and astronomy. It is also widely used in all technical areas that are concerned with shapes, figure, location and position, such as architecture, geodesy, topography, navigation, industrial design, or technical drawing.\nSpace of dimensions higher than three occurs in several modern theories of physics; see Higher dimension. They occur also in configuration spaces of physical systems.\nBeside Euclidean geometry, Euclidean spaces are also widely used in other areas of mathematics. Tangent spaces of differentiable manifolds are Euclidean vector spaces. More generally, a manifold is a space that is locally approximated by Euclidean spaces. Most non-Euclidean geometries can be modeled by a manifold, and embedded in a Euclidean space of higher dimension. For example, an elliptic space can be modeled by an ellipsoid. It is common to represent in a Euclidean space mathematical objects that are \"a priori\" not of a geometrical nature. An example among many is the usual representation of graphs.\nOther geometric spaces.\nSince the introduction, at the end of 19th century, of non-Euclidean geometries, many sorts of spaces have been considered, about which one can do geometric reasoning in the same way as with Euclidean spaces. In general, they share some properties with Euclidean spaces, but may also have properties that could appear as rather strange. Some of these spaces use Euclidean geometry for their definition, or can be modeled as subspaces of a Euclidean space of higher dimension. When such a space is defined by geometrical axioms, embedding the space in a Euclidean space is a standard way for proving consistency of its definition, or, more precisely for proving that its theory is consistent, if Euclidean geometry is consistent (which cannot be proved).\nAffine space.\nA Euclidean space is an affine space equipped with a metric. Affine spaces have many other uses in mathematics. In particular, as they are defined over any field, they allow doing geometry in other contexts.\nAs soon as non-linear questions are considered, it is generally useful to consider affine spaces over the complex numbers as an extension of Euclidean spaces. For example, a circle and a line have always two intersection points (possibly not distinct) in the complex affine space. Therefore, most of algebraic geometry is built in complex affine spaces and affine spaces over algebraically closed fields. The shapes that are studied in algebraic geometry in these affine spaces are therefore called affine algebraic varieties.\nAffine spaces over the rational numbers and more generally over algebraic number fields provide a link between (algebraic) geometry and number theory. For example, the Fermat's Last Theorem can be stated \"a Fermat curve of degree higher than two has no point in the affine plane over the rationals.\"\nGeometry in affine spaces over a finite fields has also been widely studied. For example, elliptic curves over finite fields are widely used in cryptography.\nProjective space.\nOriginally, projective spaces have been introduced by adding \"points at infinity\" to Euclidean spaces, and, more generally to affine spaces, in order to make true the assertion \"two coplanar lines meet in exactly one point\". Projective space share with Euclidean and affine spaces the property of being isotropic, that is, there is no property of the space that allows distinguishing between two points or two lines. Therefore, a more isotropic definition is commonly used, which consists as defining a projective space as the set of the vector lines in a vector space of dimension one more.\nAs for affine spaces, projective spaces are defined over any field, and are fundamental spaces of algebraic geometry.\nNon-Euclidean geometries.\n\"Non-Euclidean geometry\" refers usually to geometrical spaces where the parallel postulate is false. They include elliptic geometry, where the sum of the angles of a triangle is more than 180\u00b0, and hyperbolic geometry, where this sum is less than 180\u00b0. Their introduction in the second half of 19th century, and the proof that their theory is consistent (if Euclidean geometry is not contradictory) is one of the paradoxes that are at the origin of the foundational crisis in mathematics of the beginning of 20th century, and motivated the systematization of axiomatic theories in mathematics.\nCurved spaces.\nA manifold is a space that in the neighborhood of each point resembles a Euclidean space. In technical terms, a manifold is a topological space, such that each point has a neighborhood that is homeomorphic to an open subset of a Euclidean space. Manifolds can be classified by increasing degree of this \"resemblance\" into topological manifolds, differentiable manifolds, smooth manifolds, and analytic manifolds. However, none of these types of \"resemblance\" respect distances and angles, even approximately.\nDistances and angles can be defined on a smooth manifold by providing a smoothly varying Euclidean metric on the tangent spaces at the points of the manifold (these tangent spaces are thus Euclidean vector spaces). This results in a Riemannian manifold. Generally, straight lines do not exist in a Riemannian manifold, but their role is played by geodesics, which are the \"shortest paths\" between two points. This allows defining distances, which are measured along geodesics, and angles between geodesics, which are the angle of their tangents in the tangent space at their intersection. So, Riemannian manifolds behave locally like a Euclidean space that has been bent.\nEuclidean spaces are trivially Riemannian manifolds. An example illustrating this well is the surface of a sphere. In this case, geodesics are arcs of great circle, which are called orthodromes in the context of navigation. More generally, the spaces of non-Euclidean geometries can be realized as Riemannian manifolds.\nPseudo-Euclidean space.\nAn inner product of a real vector space is a positive definite bilinear form, and so characterized by a positive definite quadratic form. A pseudo-Euclidean space is an affine space with an associated real vector space equipped with a non-degenerate quadratic form (that may be indefinite).\nA fundamental example of such a space is the Minkowski space, which is the space-time of Einstein's special relativity. It is a four-dimensional space, where the metric is defined by the quadratic form\nformula_103\nwhere the last coordinate (\"t\") is temporal, and the other three (\"x\", \"y\", \"z\") are spatial.\nTo take gravity into account, general relativity uses a pseudo-Riemannian manifold that has Minkowski spaces as tangent spaces. The curvature of this manifold at a point is a function of the value of the gravitational field at this point."}
{"id": "9700", "revid": "5229428", "url": "https://en.wikipedia.org/wiki?curid=9700", "title": "Edwin Austin Abbey", "text": "Edwin Austin Abbey (April 1, 1852August 1, 1911) was an American muralist, illustrator, and painter. He flourished at the beginning of what is now referred to as the \"golden age\" of illustration, and is best known for his drawings and paintings of Shakespearean and Victorian subjects, as well as for his painting of Edward VII's coronation. His most famous set of murals, \"The Quest and Achievement of the Holy Grail\", adorns the Boston Public Library.\nEarly life and education.\nAbbey was born in Philadelphia, on April 1, 1852, to commercial broker William Maxwell Abbey and Margery Ann Kiple.\nHe studied art at the Pennsylvania Academy of the Fine Arts in Philadelphia under Christian Schuessele.\nCareer.\nAbbey began as an illustrator, producing numerous illustrations and sketches magazines, including \"Harper's Weekly\" (1871\u20131874) and \"Scribner's Magazine\". His illustrations began appearing in Harper's Weekly before Abbey was twenty years old. He moved to New York City in 1871. His illustrations were strongly influenced by French and German black and white art. He also illustrated several best-selling books, including \"Christmas Stories\" by Charles Dickens (1875), \"Selections from the Poetry of Robert Herrick\" (1882), and \"She Stoops to Conquer\" by Oliver Goldsmith (1887). Abbey also illustrated a four-volume set of \"The Comedies of Shakespeare\" for Harper &amp; Brothers in 1896.\nIn 1878, he moved to England at the request of his employers to gather material for illustrations of the poems of Robert Herrick, published in 1882, and he settled permanently there in 1883.\nIn 1883, he was elected to the Royal Institute of Painters in Water-Colours. About this time, he was appraised critically by the American writer, S.G.W. Benjamin:\nHe also created illustrations for Goldsmith's \"She Stoops to Conquer\" (1887), for a volume of \"Old Songs\" (1889), and for the comedies (and a few of the tragedies) of Shakespeare. Among his water-colours are \"The Evil Eye\" (1877), \"The Rose in October\" (1879), \"An Old Song\" (1886), \"The Visitors\" (1890), and \"The Jongleur\" (1892). Possibly his best known pastels are \"Beatrice\", \"Phyllis\", and \"Two Noble Kinsmen\".\nIn 1890, he made his first appearance with an oil painting, \"A May Day Morn\", at the Royal Academy in London. He exhibited \"Richard duke of Gloucester and the Lady Anne\" there in 1896, and in that year was elected A.R.A., becoming a full member in 1898. He received a gold medal at the Pan-American Exposition and was commissioned to paint the coronation of King Edward VII. in 1901; in the next year, he was chosen to paint the coronation. It was the official painting of the occasion and, hence, resides at Buckingham Palace. He did receive a knighthood, although some say he refused it in 1907. Friendly with other expatriate American artists, he summered at Broadway, Worcestershire, England, where he painted and vacationed alongside John Singer Sargent at the home of Francis Davis Millet.\nHe completed murals for the Boston Public Library in the 1890s. The frieze for the Library was titled \"The Quest and Achievement of the Holy Grail\". It took Abbey eleven years to complete this series of murals in his England studio. In 1897 he received the honorary degree of A.M. from Yale university. In 2024, Yale University Art Gallery completed restoration of his \"Study for the Apotheosis of Pennsylvania\" using a technique known as \"mist lining\" which repaired structural defects in the canvas.\nIn 1904 he painted a mural for the Royal Exchange, London \"Reconciliation of the Skinners &amp; Merchant Taylors' Companies by Lord Mayor Billesden, 1484\".\nPennsylvania State Capitol.\nIn 1908\u201309, Abbey began an ambitious program of murals and other artworks for the newly completed Pennsylvania State Capitol in Harrisburg, Pennsylvania. These included allegorical medallion murals representing \"Science\", \"Art\", \"Justice\", and \"Religion\" for the dome of the Rotunda, four large lunette murals beneath the dome, and multiple works for the House and Senate Chambers. For the Senate chamber he finished only one painting, \"Von Steuben Training the American Soldiers at Valley Forge\", and he was working on the \"Reading of the Declaration of Independence\" mural in early 1911, when his health began to fail. He was diagnosed with cancer. Studio assistant William Simmonds continued work on the mural with little supervision from Abbey, and with small contributions by John Singer Sargent.\nDeath.\nOn August 11, 1911, Abbey died in London. William Simmonds travelled from England to install the completed murals with Abbey's widow Gertrude. The remaining two rooms, which Abbey had been unable to finish, were given to Violet Oakley, who completed the commission using her own designs.\nLegacy.\nAbbey was elected to the National Academy of Design, in 1902, and The American Academy of Arts and Letters. He was honorary member of the Royal Bavarian Society and the Soci\u00e9t\u00e9 Nationale des Beaux-Arts, and was made a chevalier of the French Legion of Honour. He was a prolific illustrator, and attention to detail, including historical accuracy, influenced successive generations of illustrators.\nIn 1890, Edwin married Gertrude Mead, the daughter of a wealthy New York merchant. Mrs Abbey encouraged her husband to secure more ambitious commissions, although with their marriage commencing when both were in their forties, the couple remained childless. After her husband's death, Gertrude was active in preserving her husband's legacy, writing about his work and giving her substantial collection and archive to Yale. In 1932, through the Edwin Austin Abbey Memorial Fund for Mural Painting, she endowed the Abbey Mural Prize to support the creation and restoration of public murals in the United States. It is awarded each year by a jury of National Academicians through the National Academy of Design. She was a sponsor of the Survey of London.\nEdwin had been a keen supporter of the newly founded British School at Rome (BSR), so, in his memory, she donated \u00a36000 to assist in building the artists' studio block and, in 1926, founded the Incorporated Edwin Austin Abbey Memorial Scholarships. The scholarships were established to enable British and American painters to pursue their practice. Recipients of Abbey funding \u2013 Scholars and, more recently, Fellows \u2013 devote their scholarship to working in the studios at the BSR, where there has, ever since, been at least one Abbey-funded artist in residence. Previous award holders include Stephen Farthing, Chantal Joffe and Spartacus Chetwynd. The Abbey Fellowships (formerly 'Awards') were established in their present form in 1990, and the Abbey studios also host the BSR's other Fine Art residencies, such as the Derek Hill Foundation Scholarship and the Sainsbury Scholarship in Painting and Drawing. A bust of Edwin Abbey, by Sir Thomas Brock, stands in the courtyard of the BSR.\nEdwin also left bequests of his works to the Metropolitan Museum of Art in New York, to the Museum of Fine Arts, Boston and to the National Gallery in London.\nAbbey is buried in the churchyard of Old St Andrew's Church in Kingsbury, London. His grave is Grade II listed."}
{"id": "9703", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=9703", "title": "Evolutionary psychology", "text": "Evolutionary psychology is a theoretical approach in psychology that examines cognition and behavior from a modern evolutionary perspective. It seeks to identify human psychological adaptations with regards to the ancestral problems they evolved to solve. In this framework, psychological traits and mechanisms are either functional products of natural and sexual selection or non-adaptive by-products of other adaptive traits. \nAdaptationist thinking about physiological mechanisms, such as the heart, lungs, and the liver, is common in evolutionary biology. Evolutionary psychologists apply the same thinking in psychology, arguing that just as the heart evolved to pump blood, the liver evolved to detoxify poisons, and the kidneys evolved to filter turbid fluids there is modularity of mind in that different psychological mechanisms evolved to solve different adaptive problems. These evolutionary psychologists argue that much of human behavior is the output of psychological adaptations that evolved to solve recurrent problems in human ancestral environments.\nSome evolutionary psychologists argue that evolutionary theory can provide a foundational, metatheoretical framework that integrates the entire field of psychology in the same way evolutionary biology has for biology.\nEvolutionary psychologists hold that behaviors or traits that occur universally in all cultures are good candidates for evolutionary adaptations, including the abilities to infer others' emotions, discern kin from non-kin, identify and prefer healthier mates, and cooperate with others. Findings have been made regarding human social behaviour related to infanticide, intelligence, marriage patterns, promiscuity, perception of beauty, bride price, and parental investment. The theories and findings of evolutionary psychology have applications in many fields, including economics, environment, health, law, management, psychiatry, politics, and literature.\nCriticism of evolutionary psychology involves questions of testability, cognitive and evolutionary assumptions (such as modular functioning of the brain, and large uncertainty about the ancestral environment), importance of non-genetic and non-adaptive explanations, as well as political and ethical issues due to interpretations of research results. Evolutionary psychologists frequently engage with and respond to such criticisms.\nScope.\nPrinciples.\nIts central assumption is that the human brain is composed of a large number of specialized mechanisms that were shaped by natural selection over a vast period of time to solve the recurrent information-processing problems faced by our ancestors. These problems involve food choices, social hierarchies, distributing resources to offspring, and selecting mates. Proponents suggest that it seeks to integrate psychology into the other natural sciences, rooting it in the organizing theory of biology (evolutionary theory), and thus understanding psychology as a branch of biology. Anthropologist John Tooby and psychologist Leda Cosmides note:\nJust as human physiology and evolutionary physiology have worked to identify physical adaptations of the body that represent \"human physiological nature,\" the purpose of evolutionary psychology is to identify evolved emotional and cognitive adaptations that represent \"human psychological nature.\" According to Steven Pinker, it is \"not a single theory but a large set of hypotheses\" and a term that \"has also come to refer to a particular way of applying evolutionary theory to the mind, with an emphasis on adaptation, gene-level selection, and modularity.\" Evolutionary psychology adopts an understanding of the mind that is based on the computational theory of mind. It describes mental processes as computational operations, so that, for example, a fear response is described as arising from a neurological computation that inputs the perceptional data, e.g. a visual image of a spider, and outputs the appropriate reaction, e.g. fear of possibly dangerous animals. Under this view, any domain-general learning is impossible because of the combinatorial explosion. Evolutionary Psychology specifies the domain as the problems of survival and reproduction.\nWhile philosophers have generally considered the human mind to include broad faculties, such as reason and lust, evolutionary psychologists describe evolved psychological mechanisms as narrowly focused to deal with specific issues, such as catching cheaters or choosing mates. The discipline sees the human brain as having evolved specialized functions, called cognitive modules, or \"psychological adaptations\" which are shaped by natural selection. Examples include language-acquisition modules, incest-avoidance mechanisms, cheater-detection mechanisms, intelligence and sex-specific mating preferences, foraging mechanisms, alliance-tracking mechanisms, agent-detection mechanisms, and others. Some mechanisms, termed \"domain-specific\", deal with recurrent adaptive problems over the course of human evolutionary history. \"Domain-general\" mechanisms, on the other hand, are proposed to deal with evolutionary novelty.\nEvolutionary psychology has roots in cognitive psychology and evolutionary biology but also draws on behavioral ecology, artificial intelligence, genetics, ethology, anthropology, archaeology, biology, ecopsycology and zoology. It is closely linked to sociobiology, but there are key differences between them including the emphasis on \"domain-specific\" rather than \"domain-general\" mechanisms, the relevance of measures of current fitness, the importance of mismatch theory, and psychology rather than behavior.\nNikolaas Tinbergen's four categories of questions can help to clarify the distinctions between several different, but complementary, types of explanations. Evolutionary psychology focuses primarily on the \"why?\" questions, while traditional psychology focuses on the \"how?\" questions.\nPremises.\nEvolutionary psychology is founded on several core premises.\nHistory.\nEvolutionary psychology has its historical roots in Charles Darwin's theory of natural selection. In \"The Origin of Species\", Darwin predicted that psychology would develop an evolutionary basis:\nTwo of his later books were devoted to the study of animal emotions and psychology; \"The Descent of Man, and Selection in Relation to Sex\" in 1871 and \"The Expression of the Emotions in Man and Animals\" in 1872. Darwin's work inspired William James's functionalist approach to psychology. Darwin's theories of evolution, adaptation, and natural selection have provided insight into why brains function the way they do.\nThe content of evolutionary psychology has derived from, on the one hand, the biological sciences (especially evolutionary theory as it relates to ancient human environments, the study of paleoanthropology and animal behavior) and, on the other, the human sciences, especially psychology.\nEvolutionary biology as an academic discipline emerged with the modern synthesis in the 1930s and 1940s. In the 1930s the study of animal behavior (ethology) emerged with the work of the Dutch biologist Nikolaas Tinbergen and the Austrian biologists Konrad Lorenz and Karl von Frisch.\nW.D. Hamilton's (1964) papers on inclusive fitness and Robert Trivers's (1972) theories on reciprocity and parental investment helped to establish evolutionary thinking in psychology and the other social sciences. In 1975, Edward O. Wilson combined evolutionary theory with studies of animal and social behavior, building on the works of Lorenz and Tinbergen, in his book \"\".\nIn the 1970s, two major branches developed from ethology. Firstly, the study of animal \"social\" behavior (including humans) generated sociobiology, defined by its pre-eminent proponent Edward O. Wilson in 1975 as \"the systematic study of the biological basis of all social behavior\" and in 1978 as \"the extension of population biology and evolutionary theory to social organization.\" Secondly, there was behavioral ecology which placed less emphasis on \"social\" behavior; it focused on the ecological and evolutionary basis of animal and human behavior.\nIn the 1970s and 1980s university departments began to include the term \"evolutionary biology\" in their titles. The modern era of evolutionary psychology was ushered in, in particular, by Donald Symons' 1979 book \"The Evolution of Human Sexuality\" and Leda Cosmides and John Tooby's 1992 book \"The Adapted Mind\". David Buller observed that the term \"evolutionary psychology\" is sometimes seen as denoting research based on the specific methodological and theoretical commitments of certain researchers from the Santa Barbara school (University of California), thus some evolutionary psychologists prefer to term their work \"human ecology\", \"human behavioural ecology\" or \"evolutionary anthropology\" instead.\nFrom psychology there are the primary streams of developmental, social and cognitive psychology. Establishing some measure of the relative influence of genetics and environment on behavior has been at the core of behavioral genetics and its variants, notably studies at the molecular level that examine the relationship between genes, neurotransmitters and behavior. Dual inheritance theory (DIT), developed in the late 1970s and early 1980s, has a slightly different perspective by trying to explain how human behavior is a product of two different and interacting evolutionary processes: genetic evolution and cultural evolution. DIT is seen by some as a \"middle-ground\" between views that emphasize human universals versus those that emphasize cultural variation.\nTheoretical foundations.\nThe theories on which evolutionary psychology is based originated with Charles Darwin's work, including his speculations about the evolutionary origins of social instincts in humans. Modern evolutionary psychology, however, is possible only because of advances in evolutionary theory in the 20th century.\nEvolutionary psychologists say that natural selection has provided humans with many psychological adaptations, in much the same way that it generated humans' anatomical and physiological adaptations. As with adaptations in general, psychological adaptations are said to be specialized for the environment in which an organism evolved, the environment of evolutionary adaptedness. Sexual selection provides organisms with adaptations related to mating. For male mammals, which have a relatively high maximal potential reproduction rate, sexual selection leads to adaptations that help them compete for females. For female mammals, with a relatively low maximal potential reproduction rate, sexual selection leads to choosiness, which helps females select higher quality mates. Charles Darwin described both natural selection and sexual selection, and he relied on group selection to explain the evolution of altruistic (self-sacrificing) behavior. But group selection was considered a weak explanation, because in any group the less altruistic individuals will be more likely to survive, and the group will become less self-sacrificing as a whole.\nIn 1964, the evolutionary biologist William D. Hamilton proposed inclusive fitness theory, emphasizing a gene-centered view of evolution. Hamilton noted that genes can increase the replication of copies of themselves into the next generation by influencing the organism's social traits in such a way that (statistically) results in helping the survival and reproduction of other copies of the same genes (most simply, identical copies in the organism's close relatives). According to Hamilton's rule, self-sacrificing behaviors (and the genes influencing them) can evolve if they typically help the organism's close relatives so much that it more than compensates for the individual animal's sacrifice. Inclusive fitness theory resolved the issue of how altruism can evolve. Other theories also help explain the evolution of altruistic behavior, including evolutionary game theory, tit-for-tat reciprocity, and generalized reciprocity. These theories help to explain the development of altruistic behavior, and account for hostility toward cheaters (individuals that take advantage of others' altruism).\nSeveral mid-level evolutionary theories inform evolutionary psychology. The r/K selection theory proposes that some species prosper by having many offspring, while others follow the strategy of having fewer offspring but investing much more in each one. Humans follow the second strategy. Parental investment theory explains how parents invest more or less in individual offspring based on how successful those offspring are likely to be, and thus how much they might improve the parents' inclusive fitness. According to the Trivers\u2013Willard hypothesis, parents in good conditions tend to invest more in sons (who are best able to take advantage of good conditions), while parents in poor conditions tend to invest more in daughters (who are best able to have successful offspring even in poor conditions). According to life history theory, animals evolve life histories to match their environments, determining details such as age at first reproduction and number of offspring. Dual inheritance theory posits that genes and human culture have interacted, with genes affecting the development of culture, and culture, in turn, affecting human evolution on a genetic level, in a similar way to the Baldwin effect.\nEvolved psychological mechanisms.\nEvolutionary psychology is based on the hypothesis that, just like hearts, lungs, livers, kidneys, and immune systems, cognition has a functional structure that has a genetic basis, and therefore has evolved by natural selection. Like other organs and tissues, this functional structure should be universally shared amongst a species and should solve important problems of survival and reproduction.\nEvolutionary psychologists seek to understand psychological mechanisms by understanding the survival and reproductive functions they might have served over the course of evolutionary history. These might include abilities to infer others' emotions, discern kin from non-kin, identify and prefer healthier mates, cooperate with others and follow leaders. Consistent with the theory of natural selection, evolutionary psychology sees humans as often in conflict with others, including mates and relatives. For instance, a mother may wish to wean her offspring from breastfeeding earlier than does her infant, which frees up the mother to invest in additional offspring. Evolutionary psychology also recognizes the role of kin selection and reciprocity in evolving prosocial traits such as altruism. Like chimpanzees and bonobos, humans have subtle and flexible social instincts, allowing them to form extended families, lifelong friendships, and political alliances. In studies testing theoretical predictions, evolutionary psychologists have made modest findings on topics such as infanticide, intelligence, marriage patterns, promiscuity, perception of beauty, bride price and parental investment.\nAnother example would be the evolved mechanism in depression. Clinical depression is maladaptive and should have evolutionary approaches so it can become adaptive. Over the centuries animals and humans have gone through hard times to stay alive, which made our fight or flight senses evolve tremendously. For instances, mammalians have separation anxiety from their guardians which causes distress and sends signals to their hypothalamic pituitary adrenal axis, and emotional/behavioral changes. Going through these types of circumstances helps mammals cope with separation anxiety.\nHistorical topics.\nProponents of evolutionary psychology in the 1990s made some explorations in historical events, but the response from historical experts was highly negative and there has been little effort to continue that line of research. Historian Lynn Hunt says that the historians complained that the researchers:\nHunt states that \"the few attempts to build up a subfield of psychohistory collapsed under the weight of its presuppositions.\" She concludes that, as of 2014, the \"'iron curtain' between historians and psychology...remains standing.\"\nProducts of evolution: adaptations, exaptations, byproducts, and random variation.\nNot all traits of organisms are evolutionary adaptations. As noted in the table below, traits may also be exaptations, byproducts of adaptations (sometimes called \"spandrels\"), or random variation between individuals.\nPsychological adaptations are hypothesized to be innate or relatively easy to learn and to manifest in cultures worldwide. For example, the ability of toddlers to learn a language with virtually no training is likely to be a psychological adaptation. On the other hand, ancestral humans did not read or write, thus today, learning to read and write requires extensive training, and presumably involves the repurposing of cognitive capacities that evolved in response to selection pressures unrelated to written language. However, variations in manifest behavior can result from universal mechanisms interacting with different local environments. For example, Caucasians who move from a northern climate to the equator will have darker skin. The mechanisms regulating their pigmentation do not change; rather the input to those mechanisms change, resulting in different outputs.\nOne of the tasks of evolutionary psychology is to identify which psychological traits are likely to be adaptations, byproducts or random variation. George C. Williams suggested that an \"adaptation is a special and onerous concept that should only be used where it is really necessary.\" As noted by Williams and others, adaptations can be identified by their improbable complexity, species universality, and adaptive functionality.\nObligate and facultative adaptations.\nA question that may be asked about an adaptation is whether it is generally obligate (relatively robust in the face of typical environmental variation) or facultative (sensitive to typical environmental variation). The sweet taste of sugar and the pain of hitting one's knee against concrete are the result of fairly obligate psychological adaptations; typical environmental variability during development does not much affect their operation. By contrast, facultative adaptations are somewhat like \"if-then\" statements. For example, The adaptation for skin to tan is conditional to exposure to sunlight; this is an example of another facultative adaptation. When a psychological adaptation is facultative, evolutionary psychologists concern themselves with how developmental and environmental inputs influence the expression of the adaptation.\nCultural universals.\nEvolutionary psychologists hold that behaviors or traits that occur universally in all cultures are good candidates for evolutionary adaptations. Cultural universals include behaviors related to language, cognition, social roles, gender roles, and technology. Evolved psychological adaptations (such as the ability to learn a language) interact with cultural inputs to produce specific behaviors (e.g., the specific language learned).\nBasic gender differences, such as greater eagerness for sex among men and greater coyness among women, are explained as sexually dimorphic psychological adaptations that reflect the different reproductive strategies of males and females. It has been found that both male and female personality traits differ on a large spectrum. Males had a higher rate of traits relating to dominance, tension, and directness. Females had higher rates organizational behavior and more emotional based characteristics.\nEvolutionary psychologists contrast their approach to what they term the \"standard social science model,\" according to which the mind is a general-purpose cognition device shaped almost entirely by culture.\nEnvironment of evolutionary adaptedness.\nEvolutionary psychology argues that to properly understand the functions of the brain, one must understand the properties of the environment in which the brain evolved. That environment is often referred to as the \"environment of evolutionary adaptedness\".\nThe idea of an \"environment of evolutionary adaptedness\" was first explored as a part of attachment theory by John Bowlby. This is the environment to which a particular evolved mechanism is adapted. More specifically, the environment of evolutionary adaptedness is defined as the set of historically recurring selection pressures that formed a given adaptation, as well as those aspects of the environment that were necessary for the proper development and functioning of the adaptation.\nHumans, the genus \"Homo\", appeared between 1.5 and 2.5 million years ago, a time that roughly coincides with the start of the Pleistocene 2.6 million years ago. Because the Pleistocene ended a mere 12,000 years ago, most human adaptations either newly evolved during the Pleistocene, or were maintained by stabilizing selection during the Pleistocene. Evolutionary psychology, therefore, proposes that the majority of human psychological mechanisms are adapted to reproductive problems frequently encountered in Pleistocene environments. In broad terms, these problems include those of growth, development, differentiation, maintenance, mating, parenting, and social relationships.\nThe environment of evolutionary adaptedness is significantly different from modern society. The ancestors of modern humans lived in smaller groups, had more cohesive cultures, and had more stable and rich contexts for identity and meaning. Researchers look to existing hunter-gatherer societies for clues as to how hunter-gatherers lived in the environment of evolutionary adaptedness. Unfortunately, the few surviving hunter-gatherer societies are different from each other, and they have been pushed out of the best land and into harsh environments, so it is not clear how closely they reflect ancestral culture. However, all around the world small-band hunter-gatherers offer a similar developmental system for the young (\"hunter-gatherer childhood model,\" Konner, 2005; \n\"evolved developmental niche\" or \"evolved nest;\" Narvaez et al., 2013). The characteristics of the niche are largely the same as for social mammals, who evolved over 30 million years ago: soothing perinatal experience, several years of on-request breastfeeding, nearly constant affection or physical proximity, responsiveness to need (mitigating offspring distress), self-directed play, and for humans, multiple responsive caregivers. Initial studies show the importance of these components in early life for positive child outcomes.\nEvolutionary psychologists sometimes look to chimpanzees, bonobos, and other great apes for insight into human ancestral behavior.\nMismatches.\nSince an organism's adaptations were suited to its ancestral environment, a new and different environment can create a mismatch. Because humans are mostly adapted to Pleistocene environments, psychological mechanisms sometimes exhibit \"mismatches\" to the modern environment. One example is the fact that although over 20,000 people are murdered by guns in the US annually, whereas spiders and snakes kill only a handful, people nonetheless learn to fear spiders and snakes about as easily as they do a pointed gun, and more easily than an unpointed gun, rabbits or flowers. A potential explanation is that spiders and snakes were a threat to human ancestors throughout the Pleistocene, whereas guns (and rabbits and flowers) were not. There is thus a mismatch between humans' evolved fear-learning psychology and the modern environment.\nThis mismatch also shows up in the phenomena of the supernormal stimulus, a stimulus that elicits a response more strongly than the stimulus for which the response evolved. The term was coined by Niko Tinbergen to refer to non-human animal behavior, but psychologist Deirdre Barrett said that supernormal stimulation governs the behavior of humans as powerfully as that of other animals. She explained junk food as an exaggerated stimulus to cravings for salt, sugar, and fats, and she says that television is an exaggeration of social cues of laughter, smiling faces and attention-grabbing action. Magazine centerfolds and double cheeseburgers pull instincts intended for an environment of evolutionary adaptedness where breast development was a sign of health, youth and fertility in a prospective mate, and fat was a rare and vital nutrient. The psychologist Mark van Vugt recently argued that modern organizational leadership is a mismatch. His argument is that humans are not adapted to work in large, anonymous bureaucratic structures with formal hierarchies. The human mind still responds to personalized, charismatic leadership primarily in the context of informal, egalitarian settings. Hence the dissatisfaction and alienation that many employees experience. Salaries, bonuses and other privileges exploit instincts for relative status, which attract particularly males to senior executive positions.\nResearch methods.\nEvolutionary theory is heuristic in that it may generate hypotheses that might not be developed from other theoretical approaches. One of the main goals of adaptationist research is to identify which organismic traits are likely to be adaptations, and which are byproducts or random variations. As noted earlier, adaptations are expected to show evidence of complexity, functionality, and species universality, while byproducts or random variation will not. In addition, adaptations are expected to be presented as proximate mechanisms that interact with the environment in either a generally obligate or facultative fashion (see above). Evolutionary psychologists are also interested in identifying these proximate mechanisms (sometimes termed \"mental mechanisms\" or \"psychological adaptations\") and what type of information they take as input, how they process that information, and their outputs. Evolutionary developmental psychology, or \"evo-devo,\" focuses on how adaptations may be activated at certain developmental times (e.g., losing baby teeth, adolescence, etc.) or how events during the development of an individual may alter life-history trajectories.\nEvolutionary psychologists use several strategies to develop and test hypotheses about whether a psychological trait is likely to be an evolved adaptation. Buss (2011) notes that these methods include:\nEvolutionary psychologists also use various sources of data for testing, including experiments, archaeological records, data from hunter-gatherer societies, observational studies, neuroscience data, self-reports and surveys, public records, and human products.\nRecently, additional methods and tools have been introduced based on fictional scenarios, mathematical models, and multi-agent computer simulations.\nMain areas of research.\nFoundational areas of research in evolutionary psychology can be divided into broad categories of adaptive problems that arise from evolutionary theory itself: survival, mating, parenting, family and kinship, interactions with non-kin, and cultural evolution.\nSurvival and individual-level psychological adaptations.\nProblems of survival are clear targets for the evolution of physical and psychological adaptations. Major problems the ancestors of present-day humans faced included food selection and acquisition; territory selection and physical shelter; and avoiding predators and other environmental threats.\nConsciousness.\nConsciousness meets George Williams' criteria of species universality, complexity, and functionality, and it is a trait that apparently increases fitness.\nIn his paper \"Evolution of consciousness,\" John Eccles argues that special anatomical and physical adaptations of the mammalian cerebral cortex gave rise to consciousness. In contrast, others have argued that the recursive circuitry underwriting consciousness is much more primitive, having evolved initially in pre-mammalian species because it improves the capacity for interaction with both social \"and\" natural environments by providing an energy-saving \"neutral\" gear in an otherwise energy-expensive motor output machine. Once in place, this recursive circuitry may well have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms, as outlined by Bernard J. Baars. Richard Dawkins suggested that humans evolved consciousness in order to make themselves the subjects of thought. Daniel Povinelli suggests that large, tree-climbing apes evolved consciousness to take into account one's own mass when moving safely among tree branches. Consistent with this hypothesis, Gordon Gallup found that chimpanzees and orangutans, but not little monkeys or terrestrial gorillas, demonstrated self-awareness in mirror tests.\nThe concept of consciousness can refer to voluntary action, awareness, or wakefulness. However, even voluntary behavior involves unconscious mechanisms. Many cognitive processes take place in the cognitive unconscious, unavailable to conscious awareness. Some behaviors are conscious when learned but then become unconscious, seemingly automatic. Learning, especially implicitly learning a skill, can take place seemingly outside of consciousness. For example, plenty of people know how to turn right when they ride a bike, but very few can accurately explain how they actually do so.\nEvolutionary psychology approaches self-deception as an adaptation that can improve one's results in social exchanges.\nSleep may have evolved to conserve energy when activity would be less fruitful or more dangerous, such as at night, and especially during the winter season.\nSensation and perception.\nMany experts, such as Jerry Fodor, write that the purpose of perception is knowledge, but evolutionary psychologists hold that its primary purpose is to guide action. For example, they say, depth perception seems to have evolved not to help us know the distances to other objects but rather to help us move around in space. Evolutionary psychologists say that animals from fiddler crabs to humans use eyesight for collision avoidance, suggesting that vision is basically for directing action, not providing knowledge.\nBuilding and maintaining sense organs is metabolically expensive, so these organs evolve only when they improve an organism's fitness. More than half the brain is devoted to processing sensory information, and the brain itself consumes roughly one-fourth of one's metabolic resources, so the senses must provide exceptional benefits to fitness. Perception accurately mirrors the world; animals get useful, accurate information through their senses.\nScientists who study perception and sensation have long understood the human senses as adaptations to their surrounding worlds. Depth perception consists of processing over half a dozen visual cues, each of which is based on a regularity of the physical world. Vision evolved to respond to the narrow range of electromagnetic energy that is plentiful and that does not pass through objects. Sound waves go around corners and interact with obstacles, creating a complex pattern that includes useful information about the sources of and distances to objects. Larger animals naturally make lower-pitched sounds as a consequence of their size. The range over which an animal hears, on the other hand, is determined by adaptation. Homing pigeons, for example, can hear the very low-pitched sound (infrasound) that carries great distances, even though most smaller animals detect higher-pitched sounds. Taste and smell respond to chemicals in the environment that are thought to have been significant for fitness in the environment of evolutionary adaptedness. For example, salt and sugar were apparently both valuable to the human or pre-human inhabitants of the environment of evolutionary adaptedness, so present-day humans have an intrinsic hunger for salty and sweet tastes. The sense of touch is actually many senses, including pressure, heat, cold, tickle, and pain. Pain, while unpleasant, is adaptive. An important adaptation for senses is range shifting, by which the organism becomes temporarily more or less sensitive to sensation. For example, one's eyes automatically adjust to dim or bright ambient light. Sensory abilities of different organisms often coevolve, as is the case with the hearing of echolocating bats and that of the moths that have evolved to respond to the sounds that the bats make.\nEvolutionary psychologists contend that perception demonstrates the principle of modularity, with specialized mechanisms handling particular perception tasks. For example, people with damage to a particular part of the brain have the specific defect of not being able to recognize faces (prosopagnosia). Evolutionary psychology suggests that this indicates a so-called face-reading module.\nLearning and facultative adaptations.\nIn evolutionary psychology, learning is said to be accomplished through evolved capacities, specifically facultative adaptations. Facultative adaptations express themselves differently depending on input from the environment. Sometimes the input comes during development and helps shape that development. For example, migrating birds learn to orient themselves by the stars during a critical period in their maturation. Evolutionary psychologists believe that humans also learn language along an evolved program, also with critical periods. The input can also come during daily tasks, helping the organism cope with changing environmental conditions. For example, animals evolved Pavlovian conditioning in order to solve problems about causal relationships. Animals accomplish learning tasks most easily when those tasks resemble problems that they faced in their evolutionary past, such as a rat learning where to find food or water. Learning capacities sometimes demonstrate differences between the sexes. In many animal species, for example, males can solve spatial problems faster and more accurately than females, due to the effects of male hormones during development. The same might be true of humans.\nEmotion and motivation.\nMotivations direct and energize behavior, while emotions provide the affective component to motivation, positive or negative. In the early 1970s, Paul Ekman and colleagues began a line of research which suggests that many emotions are universal. He found evidence that humans share at least five basic emotions: fear, sadness, happiness, anger, and disgust. Social emotions evidently evolved to motivate social behaviors that were adaptive in the environment of evolutionary adaptedness. For example, spite seems to work against the individual but it can establish an individual's reputation as someone to be feared. Shame and pride can motivate behaviors that help one maintain one's standing in a community, and self-esteem is one's estimate of one's status.\nMotivation has a neurobiological basis in the reward system of the brain. Recently, it has been suggested that reward systems may evolve in such a way that there may be an inherent or unavoidable trade-off in the motivational system for activities of short versus long duration.\nCognition.\nCognition refers to internal representations of the world and internal information processing. From an evolutionary psychology perspective, cognition is not \"general purpose\". Cognition uses heuristics, or strategies, that generally increase the likelihood of solving problems that the ancestors of present-day humans routinely faced in their lives. For example, present-day humans are far more likely to solve logic problems that involve detecting cheating (a common problem given humans' social nature) than the same logic problem put in purely abstract terms. Since the ancestors of present-day humans did not encounter truly random events and lived under simpler life terms, present-day humans may be cognitively predisposed to incorrectly identify patterns in random sequences. \"Gamblers' Fallacy\" is one example of this. Gamblers may falsely believe that they have hit a \"lucky streak\" even when each outcome is actually random and independent of previous trials. Most people believe that if a fair coin has been flipped 9 times and Heads appears each time, that on the tenth flip, there is a greater than 50% chance of getting Tails. Humans find it far easier to make diagnoses or predictions using frequency data than when the same information is presented as probabilities or percentages. This could be due to the ancestors of present-day humans living in relatively small tribes (usually with fewer than 150 people) where frequency information was more readily available and experienced less random occurrences in their lives.\nPersonality.\nEvolutionary psychology is primarily interested in finding commonalities between people, or basic human psychological nature. From an evolutionary perspective, the fact that people have fundamental differences in personality traits initially presents something of a puzzle. (Note: The field of behavioral genetics is concerned with statistically partitioning differences between people into genetic and environmental sources of variance. However, understanding the concept of heritability can be tricky \u2013 heritability refers only to the differences between people, never the degree to which the traits of an individual are due to environmental or genetic factors, since traits are always a complex interweaving of both.)\nPersonality traits are conceptualized by evolutionary psychologists as due to normal variation around an optimum, due to frequency-dependent selection (behavioral polymorphisms), or as facultative adaptations. Like variability in height, some personality traits may simply reflect inter-individual variability around a general optimum. Or, personality traits may represent different genetically predisposed \"behavioral morphs\" \u2013 alternate behavioral strategies that depend on the frequency of competing behavioral strategies in the population. For example, if most of the population is generally trusting and gullible, the behavioral morph of being a \"cheater\" (or, in the extreme case, a sociopath) may be advantageous. Finally, like many other psychological adaptations, personality traits may be facultative \u2013 sensitive to typical variations in the social environment, especially during early development. For example, later-born children are more likely than firstborns to be rebellious, less conscientious and more open to new experiences, which may be advantageous to them given their particular niche in family structure.\nShared environmental influences do play a role in personality and are not always of less importance than genetic factors. However, shared environmental influences often decrease to near zero after adolescence but do not completely disappear.\nLanguage.\nAccording to Steven Pinker, who builds on the work by Noam Chomsky, the universal human ability to learn to talk between the ages of 1 \u2013 4, basically without training, suggests that language acquisition is a distinctly human psychological adaptation (see, in particular, Pinker's \"The Language Instinct\"). Pinker and Bloom (1990) argue that language as a mental faculty shares many likenesses with the complex organs of the body which suggests that, like these organs, language has evolved as an adaptation, since this is the only known mechanism by which such complex organs can develop.\nPinker follows Chomsky in arguing that the fact that children can learn any human language with no explicit instruction suggests that language, including most of grammar, is basically innate and that it only needs to be activated by interaction. Chomsky himself does not believe language to have evolved as an adaptation, but suggests that it likely evolved as a byproduct of some other adaptation, a so-called spandrel. But Pinker and Bloom argue that the organic nature of language strongly suggests that it has an adaptational origin.\nEvolutionary psychologists hold that the FOXP2 gene may well be associated with the evolution of human language. In the 1980s, psycholinguist Myrna Gopnik identified a dominant gene that causes language impairment in the KE family of Britain. This gene turned out to be a mutation of the FOXP2 gene. Humans have a unique allele of this gene, which has otherwise been closely conserved through most of mammalian evolutionary history. This unique allele seems to have first appeared between 100 and 200 thousand years ago, and it is now all but universal in humans. However, the once-popular idea that FOXP2 is a 'grammar gene' or that it triggered the emergence of language in \"Homo sapiens\" is now widely discredited.\nCurrently, several competing theories about the evolutionary origin of language coexist, none of them having achieved a general consensus. Researchers of language acquisition in primates and humans such as Michael Tomasello and Talmy Giv\u00f3n, argue that the innatist framework has understated the role of imitation in learning and that it is not at all necessary to posit the existence of an innate grammar module to explain human language acquisition. Tomasello argues that studies of how children and primates actually acquire communicative skills suggest that humans learn complex behavior through experience, so that instead of a module specifically dedicated to language acquisition, language is acquired by the same cognitive mechanisms that are used to acquire all other kinds of socially transmitted behavior.\nOn the issue of whether language is best seen as having evolved as an adaptation or as a spandrel, evolutionary biologist W. Tecumseh Fitch, following Stephen J. Gould, argues that it is unwarranted to assume that every aspect of language is an adaptation, or that language as a whole is an adaptation. He criticizes some strands of evolutionary psychology for suggesting a pan-adaptionist view of evolution, and dismisses Pinker and Bloom's question of whether \"Language has evolved as an adaptation\" as being misleading. He argues instead that from a biological viewpoint the evolutionary origins of language is best conceptualized as being the probable result of a convergence of many separate adaptations into a complex system. A similar argument is made by Terrence Deacon who in \"The Symbolic Species\" argues that the different features of language have co-evolved with the evolution of the mind and that the ability to use symbolic communication is integrated in all other cognitive processes.\nIf the theory that language could have evolved as a single adaptation is accepted, the question becomes which of its many functions has been the basis of adaptation. Several evolutionary hypotheses have been posited: that language evolved for the purpose of social grooming, that it evolved as a way to show mating potential or that it evolved to form social contracts. Evolutionary psychologists recognize that these theories are all speculative and that much more evidence is required to understand how language might have been selectively adapted.\nMating.\nGiven that sexual reproduction is the means by which genes are propagated into future generations, sexual selection plays a large role in human evolution. Human mating, then, is of interest to evolutionary psychologists who aim to investigate evolved mechanisms to attract and secure mates. Several lines of research have stemmed from this interest, such as studies of mate selection mate poaching, mate retention, mating preferences and conflict between the sexes.\nIn 1972 Robert Trivers published an influential paper on sex differences that is now referred to as parental investment theory. The size differences of gametes (anisogamy) is the fundamental, defining difference between males (small gametes \u2013 sperm) and females (large gametes \u2013 ova). Trivers noted that anisogamy typically results in different levels of parental investment between the sexes, with females initially investing more. Trivers proposed that this difference in parental investment leads to the sexual selection of different reproductive strategies between the sexes and to sexual conflict. For example, he suggested that the sex that invests less in offspring will generally compete for access to the higher-investing sex to increase their inclusive fitness. Trivers posited that differential parental investment led to the evolution of sexual dimorphisms in mate choice, intra- and inter- sexual reproductive competition, and courtship displays. In mammals, including humans, females make a much larger parental investment than males (i.e. gestation followed by childbirth and lactation). Parental investment theory is a branch of life history theory.\nBuss and Schmitt's (1993) sexual strategies theory proposed that, due to differential parental investment, humans have evolved sexually dimorphic adaptations related to \"sexual accessibility, fertility assessment, commitment seeking and avoidance, immediate and enduring resource procurement, paternity certainty, assessment of mate value, and parental investment.\" Their strategic interference theory suggested that conflict between the sexes occurs when the preferred reproductive strategies of one sex interfere with those of the other sex, resulting in the activation of emotional responses such as anger or jealousy.\nWomen are generally more selective when choosing mates, especially under long-term mating conditions. However, under some circumstances, short term mating can provide benefits to women as well, such as fertility insurance, trading up to better genes, reducing the risk of inbreeding, and insurance protection of her offspring.\nDue to male paternity uncertainty, sex differences have been found in the domains of sexual jealousy. Females generally react more adversely to emotional infidelity and males will react more to sexual infidelity. This particular pattern is predicted because the costs involved in mating for each sex are distinct. Women, on average, should prefer a mate who can offer resources (e.g., financial, commitment), thus, a woman risks losing such resources with a mate who commits emotional infidelity. Men, on the other hand, are never certain of the genetic paternity of their children because they do not bear the offspring themselves. This suggests that for men sexual infidelity would generally be more aversive than emotional infidelity because investing resources in another man's offspring does not lead to the propagation of their own genes.\nAnother interesting line of research is that which examines women's mate preferences across the ovulatory cycle. The theoretical underpinning of this research is that ancestral women would have evolved mechanisms to select mates with certain traits depending on their hormonal status. Known as the ovulatory shift hypothesis, the theory posits that, during the ovulatory phase of a woman's cycle (approximately days 10\u201315 of a woman's cycle), a woman who mated with a male with high genetic quality would have been more likely, on average, to produce and bear a healthy offspring than a woman who mated with a male with low genetic quality. These putative preferences are predicted to be especially apparent for short-term mating domains because a potential male mate would only be offering genes to a potential offspring. This hypothesis allows researchers to examine whether women select mates who have characteristics that indicate high genetic quality during the high fertility phase of their ovulatory cycles. Indeed, studies have shown that women's preferences vary across the ovulatory cycle. In particular, Haselton and Miller (2006) showed that highly fertile women prefer creative but poor men as short-term mates. Creativity may be a proxy for good genes. Research by Gangestad et al. (2004) indicates that highly fertile women prefer men who display social presence and intrasexual competition; these traits may act as cues that would help women predict which men may have, or would be able to acquire, resources.\nParenting.\nReproduction is always costly for women, and can also be for men. Individuals are limited in the degree to which they can devote time and resources to producing and raising their young, and such expenditure may also be detrimental to their future condition, survival and further reproductive output.\nParental investment is any parental expenditure (time, energy etc.) that benefits one offspring at a cost to parents' ability to invest in other components of fitness (Clutton-Brock 1991: 9; Trivers 1972). Components of fitness (Beatty 1992) include the well-being of existing offspring, parents' future reproduction, and inclusive fitness through aid to kin (Hamilton, 1964). Parental investment theory is a branch of life history theory.\nThe benefits of parental investment to the offspring are large and are associated with the effects on condition, growth, survival, and ultimately, on the reproductive success of the offspring. However, these benefits can come at the cost of the parent's ability to reproduce in the future e.g. through the increased risk of injury when defending offspring against predators, the loss of mating opportunities whilst rearing offspring, and an increase in the time to the next reproduction. Overall, parents are selected to maximize the difference between the benefits and the costs, and parental care will likely evolve when the benefits exceed the costs.\nThe Cinderella effect is an alleged high incidence of stepchildren being physically, emotionally or sexually abused, neglected, murdered, or otherwise mistreated at the hands of their stepparents at significantly higher rates than their genetic counterparts. It takes its name from the fairy tale character Cinderella, who in the story was cruelly mistreated by her stepmother and stepsisters. Daly and Wilson (1996) noted: \"Evolutionary thinking led to the discovery of the most important risk factor for child homicide \u2013 the presence of a stepparent. Parental efforts and investments are valuable resources, and selection favors those parental psyches that allocate effort effectively to promote fitness. The adaptive problems that challenge parental decision-making include both the accurate identification of one's offspring and the allocation of one's resources among them with sensitivity to their needs and abilities to convert parental investment into fitness increments\u2026. Stepchildren were seldom or never so valuable to one's expected fitness as one's own offspring would be, and those parental psyches that were easily parasitized by just any appealing youngster must always have incurred a selective disadvantage\"(Daly &amp; Wilson, 1996, pp.\u00a064\u201365). However, they note that not all stepparents will \"want\" to abuse their partner's children, or that genetic parenthood is any insurance against abuse. They see step parental care as primarily \"mating effort\" towards the genetic parent.\nFamily and kin.\nInclusive fitness is the sum of an organism's classical fitness (how many of its own offspring it produces and supports) and the number of equivalents of its own offspring it can add to the population by supporting others. The first component is called classical fitness by Hamilton (1964).\nFrom the gene's point of view, evolutionary success ultimately depends on leaving behind the maximum number of copies of itself in the population. Until 1964, it was generally believed that genes only achieved this by causing the individual to leave the maximum number of viable offspring. However, in 1964 W. D. Hamilton proved mathematically that, because close relatives of an organism share some identical genes, a gene can also increase its evolutionary success by promoting the reproduction and survival of these related or otherwise similar individuals. Hamilton concluded that this leads natural selection to favor organisms that would behave in ways that maximize their inclusive fitness. It is also true that natural selection favors behavior that maximizes personal fitness.\nHamilton's rule describes mathematically whether or not a gene for altruistic behavior will spread in a population:\nwhere\nThe concept serves to explain how natural selection can perpetuate altruism. If there is an \"altruism gene\" (or complex of genes) that influences an organism's behavior to be helpful and protective of relatives and their offspring, this behavior also increases the proportion of the altruism gene in the population, because relatives are likely to share genes with the altruist due to common descent. Altruists may also have some way to recognize altruistic behavior in unrelated individuals and be inclined to support them. As Dawkins points out in \"The Selfish Gene\" (Chapter 6) and \"The Extended Phenotype\", this must be distinguished from the green-beard effect.\nAlthough it is generally true that humans tend to be more altruistic toward their kin than toward non-kin, the relevant proximate mechanisms that mediate this cooperation have been debated (see kin recognition), with some arguing that kin status is determined primarily via social and cultural factors (such as co-residence, maternal association of sibs, etc.), while others have argued that kin recognition can also be mediated by biological factors such as facial resemblance and immunogenetic similarity of the major histocompatibility complex (MHC). For a discussion of the interaction of these social and biological kin recognition factors see Lieberman, Tooby, and Cosmides (2007) (PDF).\nWhatever the proximate mechanisms of kin recognition there is substantial evidence that humans act generally more altruistically to close genetic kin compared to genetic non-kin.\nInteractions with non-kin / reciprocity.\nAlthough interactions with non-kin are generally less altruistic compared to those with kin, cooperation can be maintained with non-kin via mutually beneficial reciprocity as was proposed by Robert Trivers. If there are repeated encounters between the same two players in an evolutionary game in which each of them can choose either to \"cooperate\" or \"defect\", then a strategy of mutual cooperation may be favored even if it pays each player, in the short term, to defect when the other cooperates. Direct reciprocity can lead to the evolution of cooperation only if the probability, w, of another encounter between the same two individuals exceeds the cost-to-benefit ratio of the altruistic act:\nReciprocity can also be indirect if information about previous interactions is shared. Reputation allows evolution of cooperation by indirect reciprocity. Natural selection favors strategies that base the decision to help on the reputation of the recipient: studies show that people who are more helpful are more likely to receive help. The calculations of indirect reciprocity are complicated and only a tiny fraction of this universe has been uncovered, but again a simple rule has emerged. Indirect reciprocity can only promote cooperation if the probability, q, of knowing someone's reputation exceeds the cost-to-benefit ratio of the altruistic act:\nOne important problem with this explanation is that individuals may be able to evolve the capacity to obscure their reputation, reducing the probability, q, that it will be known.\nTrivers argues that friendship and various social emotions evolved in order to manage reciprocity. Liking and disliking, he says, evolved to help present-day humans' ancestors form coalitions with others who reciprocated and to exclude those who did not reciprocate. Moral indignation may have evolved to prevent one's altruism from being exploited by cheaters, and gratitude may have motivated present-day humans' ancestors to reciprocate appropriately after benefiting from others' altruism. Likewise, present-day humans feel guilty when they fail to reciprocate. These social motivations match what evolutionary psychologists expect to see in adaptations that evolved to maximize the benefits and minimize the drawbacks of reciprocity.\nEvolutionary psychologists say that humans have psychological adaptations that evolved specifically to help us identify nonreciprocators, commonly referred to as \"cheaters.\" In 1993, Robert Frank and his associates found that participants in a prisoner's dilemma scenario were often able to predict whether their partners would \"cheat\", based on a half-hour of unstructured social interaction. In a 1996 experiment, for example, Linda Mealey and her colleagues found that people were better at remembering the faces of people when those faces were associated with stories about those individuals cheating (such as embezzling money from a church).\nStrong reciprocity (or \"tribal reciprocity\").\nHumans may have an evolved set of psychological adaptations that predispose them to be more cooperative than otherwise would be expected with members of their tribal in-group, and, more nasty to members of tribal out groups. These adaptations may have been a consequence of tribal warfare. Humans may also have predispositions for \"altruistic punishment\" \u2013 to punish in-group members who violate in-group rules, even when this altruistic behavior cannot be justified in terms of helping those you are related to (kin selection), cooperating with those who you will interact with again (direct reciprocity), or cooperating to better your reputation with others (indirect reciprocity).\nEvolutionary psychology and culture.\nThough evolutionary psychology has traditionally focused on individual-level behaviors, determined by species-typical psychological adaptations, considerable work has been done on how these adaptations shape and, ultimately govern, culture (Tooby and Cosmides, 1989). Tooby and Cosmides (1989) argued that the mind consists of many domain-specific psychological adaptations, some of which may constrain what cultural material is learned or taught. As opposed to a domain-general cultural acquisition program, where an individual passively receives culturally-transmitted material from the group, Tooby and Cosmides (1989), among others, argue that: \"the psyche evolved to generate adaptive rather than repetitive behavior, and hence critically analyzes the behavior of those surrounding it in highly structured and patterned ways, to be used as a rich (but by no means the only) source of information out of which to construct a 'private culture' or individually tailored adaptive system; in consequence, this system may or may not mirror the behavior of others in any given respect.\" (Tooby and Cosmides 1989).\nBiological explanations of human culture also brought criticism to evolutionary psychology: Evolutionary psychologists see the human psyche and physiology as a genetic product and assume that genes contain the information for the development and control of the organism and that this information is transmitted from one generation to the next via genes. Evolutionary psychologists thereby see physical and psychological characteristics of humans as genetically programmed. Even then, when evolutionary psychologists acknowledge the influence of the environment on human development, they understand the environment only as an activator or trigger for the programmed developmental instructions encoded in genes. Evolutionary psychologists, for example, believe that the human brain is made up of innate modules, each of which is specialised only for very specific tasks, e.\u00a0g. an anxiety module. According to evolutionary psychologists, these modules are given before the organism actually develops and are then activated by some environmental event. Critics object that this view is reductionist and that cognitive specialisation only comes about through the interaction of humans with their real environment, rather than the environment of distant ancestors. Interdisciplinary approaches are increasingly striving to mediate between these opposing points of view and to highlight that biological and cultural causes need not be antithetical in explaining human behaviour and even complex cultural achievements.\nIn psychology sub-fields.\nDevelopmental psychology.\nAccording to Paul Baltes, the benefits granted by evolutionary selection decrease with age. Natural selection has not eliminated many harmful conditions and nonadaptive characteristics that appear among older adults, such as Alzheimer disease. If it were a disease that killed 20-year-olds instead of 70-year-olds this might have been a disease that natural selection could have eliminated ages ago. Thus, unaided by evolutionary pressures against nonadaptive conditions, modern humans suffer the aches, pains, and infirmities of aging and as the benefits of evolutionary selection decrease with age, the need for modern technological mediums against non-adaptive conditions increases.\nSocial psychology.\nAs humans are a highly social species, there are many adaptive problems associated with navigating the social world (e.g., maintaining allies, managing status hierarchies, interacting with outgroup members, coordinating social activities, collective decision-making). Researchers in the emerging field of evolutionary social psychology have made many discoveries pertaining to topics traditionally studied by social psychologists, including person perception, social cognition, attitudes, altruism, emotions, group dynamics, leadership, motivation, prejudice, intergroup relations, and cross-cultural differences.\nWhen endeavouring to solve a problem humans at an early age show determination while chimpanzees have no comparable facial expression. Researchers suspect the human determined expression evolved because when a human is determinedly working on a problem other people will frequently help.\nAbnormal psychology.\nAdaptationist hypotheses regarding the etiology of psychological disorders are often based on analogies between physiological and psychological dysfunctions, as noted in the table below. Prominent theorists and evolutionary psychiatrists include Michael T. McGuire, Anthony Stevens, and Randolph M. Nesse. They, and others, suggest that mental disorders are due to the interactive effects of both nature and nurture, and often have multiple contributing causes.\nEvolutionary psychologists have suggested that schizophrenia and bipolar disorder may reflect a side-effect of genes with fitness benefits, such as increased creativity. (Some individuals with bipolar disorder are especially creative during their manic phases and the close relatives of people with schizophrenia have been found to be more likely to have creative professions.) A 1994 report by the American Psychiatry Association found that people with schizophrenia at roughly the same rate in Western and non-Western cultures, and in industrialized and pastoral societies, suggesting that schizophrenia is not a disease of civilization nor an arbitrary social invention. Sociopathy may represent an evolutionarily stable strategy, by which a small number of people who cheat on social contracts benefit in a society consisting mostly of non-sociopaths. Mild depression may be an adaptive response to withdraw from, and re-evaluate, situations that have led to disadvantageous outcomes (the \"analytical rumination hypothesis\") (see Evolutionary approaches to depression).\nTrofimova reviewed the most consistent psychological and behavioural sex differences in psychological abilities and disabilities and linked them to the Geodakyan's evolutionary theory of sex (ETS). She pointed out that a pattern of consistent sex differences in physical, verbal and social dis/abilities corresponds to the idea of the ETS considering sex dimorphism as a functional specialization of a species. Sex differentiation, according to the ETS, creates two partitions within a species, (1) conservational (females), and (2) variational (males). In females, superiority in verbal abilities, higher rule obedience, socialisation, empathy and agreeableness can be presented as a reflection of the systemic conservation function of the female sex. Male superiority is mostly noted in exploratory abilities - in risk- and sensation seeking, spacial orientation, physical strength and higher rates in physical aggression. In combination with higher birth and accidental death rates this pattern might be a reflection of the systemic variational function (testing the boundaries of beneficial characteristics) of the male sex. As a result, psychological sex differences might be influenced by a global tendency within a species to expand its norm of reaction, but at the same time to preserve the beneficial properties of the species. Moreover, Trofimova suggested a \"redundancy pruning\" hypothesis as an upgrade of the ETS theory. She pointed out to higher rates of psychopathy, dyslexia, autism and schizophrenia in males, in comparison to females. She suggested that the variational function of the \"male partition\" might also provide irrelevance/redundancy pruning of an excess in a bank of beneficial characteristics of a species, with a continuing resistance to any changes from the norm-driven conservational partition of species. This might explain a contradictory allocation of a high drive for social status/power in the male sex with the their least (among two sexes) abilities for social interaction. The high rates of communicative disorders and psychopathy in males might facilitate their higher rates of disengagement from normative expectations and their insensitivity to social disapproval, when they deliberately do not follow social norms.\nSome of these speculations have yet to be developed into fully testable hypotheses, and a great deal of research is required to confirm their validity.\nAntisocial and criminal behavior.\nEvolutionary psychology has been applied to explain criminal or otherwise immoral behavior as being adaptive or related to adaptive behaviors. Males are generally more aggressive than females, who are more selective of their partners because of the far greater effort they have to contribute to pregnancy and child-rearing. Males being more aggressive is hypothesized to stem from the more intense reproductive competition faced by them. Males of low status may be especially vulnerable to being childless. It may have been evolutionary advantageous to engage in highly risky and violently aggressive behavior to increase their status and therefore reproductive success. This may explain why males are generally involved in more crimes, and why low status and being unmarried are associated with criminality. Furthermore, competition over females is argued to have been particularly intensive in late adolescence and young adulthood, which is theorized to explain why crime rates are particularly high during this period. Some sociologists have underlined differential exposure to androgens as the cause of these behaviors, notably Lee Ellis in his evolutionary neuroandrogenic (ENA) theory.\nMany conflicts that result in harm and death involve status, reputation, and seemingly trivial insults. Steven Pinker in his book \"The Better Angels of Our Nature\" argues that in non-state societies without a police it was very important to have a credible deterrence against aggression. Therefore, it was important to be perceived as having a credible reputation for retaliation, resulting in humans developing instincts for revenge as well as for protecting reputation (\"honor\"). Pinker argues that the development of the state and the police have dramatically reduced the level of violence compared to the ancestral environment. Whenever the state breaks down, which can be very locally such as in poor areas of a city, humans again organize in groups for protection and aggression and concepts such as violent revenge and protecting honor again become extremely important.\nRape is theorized to be a reproductive strategy that facilitates the propagation of the rapist's progeny. Such a strategy may be adopted by men who otherwise are unlikely to be appealing to women and therefore cannot form legitimate relationships, or by high-status men on socially vulnerable women who are unlikely to retaliate to increase their reproductive success even further. The sociobiological theories of rape are highly controversial, as traditional theories typically do not consider rape to be a behavioral adaptation, and objections to this theory are made on ethical, religious, political, as well as scientific grounds.\nPsychology of religion.\nAdaptationist perspectives on religious belief suggest that, like all behavior, religious behaviors are a product of the human brain. As with all other organ functions, cognition's functional structure has been argued to have a genetic foundation, and is therefore subject to the effects of natural selection and sexual selection. Like other organs and tissues, this functional structure should be universally shared amongst humans and should have solved important problems of survival and reproduction in ancestral environments. However, evolutionary psychologists remain divided on whether religious belief is more likely a consequence of evolved psychological adaptations, or a byproduct of other cognitive adaptations.\nCoalitional psychology.\nCoalitional psychology is an approach to explain political behaviors between different coalitions and the conditionality of these behaviors in evolutionary psychological perspective. This approach assumes that since human beings appeared on the earth, they have evolved to live in groups instead of living as individuals to achieve benefits such as more mating opportunities and increased status. Human beings thus naturally think and act in a way that manages and negotiates group dynamics.\nCoalitional psychology offers falsifiable ex ante prediction by positing five hypotheses on how these psychological adaptations operate:\nReception and criticism.\nCritics of evolutionary psychology accuse it of promoting genetic determinism, pan-adaptationism (the idea that all behaviors and anatomical features are adaptations), unfalsifiable hypotheses, distal or ultimate explanations of behavior when proximate explanations are superior, and malevolent political or moral ideas.\nEthical implications.\nCritics have argued that evolutionary psychology might be used to justify existing social hierarchies and reactionary policies. It has also been suggested by critics that evolutionary psychologists' theories and interpretations of empirical data rely heavily on ideological assumptions about race and gender.\nIn response to such criticism, evolutionary psychologists often caution against committing the naturalistic fallacy \u2013 the assumption that \"what is natural\" is necessarily a moral good. However, their caution against committing the naturalistic fallacy has been criticized as means to stifle legitimate ethical discussions.\nContradictions in models.\nSome criticisms of evolutionary psychology point at contradictions between different aspects of adaptive scenarios posited by evolutionary psychology. One example is the evolutionary psychology model of extended social groups selecting for modern human brains, a contradiction being that the synaptic function of modern human brains require high amounts of many specific essential nutrients so that such a transition to higher requirements of the same essential nutrients being shared by all individuals in a population would decrease the possibility of forming large groups due to bottleneck foods with rare essential nutrients capping group sizes. It is mentioned that some insects have societies with different ranks for each individual and that monkeys remain socially functioning after the removal of most of the brain as additional arguments against big brains promoting social networking. The model of males as both providers and protectors is criticized for the impossibility of being in two places at once, the male cannot both protect his family at home and be out hunting at the same time. In the case of the claim that a provider male could buy protection service for his family from other males by bartering food that he had hunted, critics point at the fact that the most valuable food (the food that contained the rarest essential nutrients) would be different in different ecologies and as such vegetable in some geographical areas and animal in others, making it impossible for hunting styles relying on physical strength or risk-taking to be universally of similar value in bartered food and instead of making it inevitable that in some parts of Africa, food gathered with no need for major physical strength would be the most valuable to barter for protection. A contradiction between evolutionary psychology's claim of men needing to be more sexually visual than women for fast speed of assessing women's fertility than women needed to be able to assess the male's genes and its claim of male sexual jealousy guarding against infidelity is also pointed at, as it would be pointless for a male to be fast to assess female fertility if he needed to assess the risk of there being a jealous male mate and in that case his chances of defeating him before mating anyway (pointlessness of assessing one necessary condition faster than another necessary condition can possibly be assessed).\nStandard social science model.\nEvolutionary psychology has been entangled in the larger philosophical and social science controversies related to the debate on nature versus nurture. Evolutionary psychologists typically contrast evolutionary psychology with what they call the standard social science model (SSSM). They characterize the SSSM as the \"blank slate\", \"relativist\", \"social constructionist\", and \"cultural determinist\" perspective that they say dominated the social sciences throughout the 20th century and assumed that the mind was shaped almost entirely by culture.\nCritics have argued that evolutionary psychologists created a false dichotomy between their own view and the caricature of the SSSM. Other critics regard the SSSM as a rhetorical device or a straw man and suggest that the scientists whom evolutionary psychologists associate with the SSSM did not believe that the mind was a blank state devoid of any natural predispositions.\nReductionism and determinism.\nSome critics view evolutionary psychology as a form of genetic reductionism and genetic determinism, a common critique being that evolutionary psychology does not address the complexity of individual development and experience and fails to explain the influence of genes on behavior in individual cases. Evolutionary psychologists respond that they are working within a nature-nurture interactionist framework that acknowledges that many psychological adaptations are facultative (sensitive to environmental variations during individual development). The discipline is generally not focused on proximate analyses of behavior, but rather its focus is on the study of distal/ultimate causality (the evolution of psychological adaptations). The field of behavioral genetics is focused on the study of the proximate influence of genes on behavior.\nTestability of hypotheses.\nA frequent critique of the discipline is that the hypotheses of evolutionary psychology are frequently arbitrary and difficult or impossible to adequately test, thus questioning its status as an actual scientific discipline, for example because many current traits probably evolved to serve different functions than they do now. Thus because there are a potentially infinite number of alternative explanations for why a trait evolved, critics contend that it is impossible to determine the exact explanation. While evolutionary psychology hypotheses are difficult to test, evolutionary psychologists assert that it is not impossible. Part of the critique of the scientific base of evolutionary psychology includes a critique of the concept of the Environment of Evolutionary Adaptation (EEA). Some critics have argued that researchers know so little about the environment in which \"Homo sapiens\" evolved that explaining specific traits as an adaption to that environment becomes highly speculative. Evolutionary psychologists respond that they do know many things about this environment, including the facts that present day humans' ancestors were hunter-gatherers, that they generally lived in small tribes, etc. Edward Hagen argues that the human past environments were not radically different in the same sense as the Carboniferous or Jurassic periods and that the animal and plant taxa of the era were similar to those of the modern world, as was the geology and ecology. Hagen argues that few would deny that other organs evolved in the EEA (for example, lungs evolving in an oxygen rich atmosphere) yet critics question whether or not the brain's EEA is truly knowable, which he argues constitutes selective scepticism. Hagen also argues that most evolutionary psychology research is based on the fact that females can get pregnant and males cannot, which Hagen observes was also true in the EEA.\nJohn Alcock describes this as the \"No Time Machine Argument\", as critics are arguing that since it is not possible to travel back in time to the EEA, then it cannot be determined what was going on there and thus what was adaptive. Alcock argues that present-day evidence allows researchers to be reasonably confident about the conditions of the EEA and that the fact that so many human behaviours are adaptive in the \"current\" environment is evidence that the ancestral environment of humans had much in common with the present one, as these behaviours would have evolved in the ancestral environment. Thus Alcock concludes that researchers can make predictions on the adaptive value of traits. Similarly, Dominic Murphy argues that alternative explanations cannot just be forwarded but instead need their own evidence and predictions - if one explanation makes predictions that the others cannot, it is reasonable to have confidence in that explanation. In addition, Murphy argues that other historical sciences also make predictions about modern phenomena to come up with explanations about past phenomena, for example, cosmologists look for evidence for what we would expect to see in the modern-day if the Big Bang was true, while geologists make predictions about modern phenomena to determine if an asteroid wiped out the dinosaurs. Murphy argues that if other historical disciplines can conduct tests without a time machine, then the onus is on the critics to show why evolutionary psychology is untestable if other historical disciplines are not, as \"methods should be judged across the board, not singled out for ridicule in one context.\"\nModularity of mind.\nEvolutionary psychologists generally presume that, like the body, the mind is made up of many evolved modular adaptations, although there is some disagreement within the discipline regarding the degree of general plasticity, or \"generality,\" of some modules. It has been suggested that modularity evolves because, compared to non-modular networks, it would have conferred an advantage in terms of fitness and because connection costs are lower.\nIn contrast, some academics argue that it is unnecessary to posit the existence of highly domain specific modules, and, suggest that the neural anatomy of the brain supports a model based on more domain general faculties and processes. Moreover, empirical support for the domain-specific theory stems almost entirely from performance on variations of the Wason selection task which is extremely limited in scope as it only tests one subtype of deductive reasoning.\nCultural rather than genetic development of cognitive tools.\nPsychologist Cecilia Heyes has argued that the picture presented by some evolutionary psychology of the human mind as a collection of cognitive instinctsorgans of thought shaped by genetic evolution over very long time periodsdoes not fit research results. She posits instead that humans have cognitive gadgets\"special-purpose organs of thought\" built in the course of development through social interaction. Similar criticisms are articulated by Subrena E. Smith of the University of New Hampshire.\nResponse by evolutionary psychologists.\nEvolutionary psychologists have addressed many of their critics (e.g. in books by Segerstr\u00e5le (2000), Barkow (2005), and Alcock (2001)). Among their rebuttals are that some criticisms are straw men, or are based on an incorrect nature versus nurture dichotomy or on basic misunderstandings of the discipline. \nRobert Kurzban suggested that \"...critics of the field, when they err, are not slightly missing the mark. Their confusion is deep and profound. It's not like they are marksmen who can't quite hit the center of the target; they're holding the gun backwards.\" Many have written specifically to correct basic misconceptions."}
{"id": "9705", "revid": "35041181", "url": "https://en.wikipedia.org/wiki?curid=9705", "title": "Languages of Europe", "text": "There are over 250 languages indigenous to Europe, and most belong to the Indo-European language family. Out of a total European population of 744 million as of 2018, some 94% are native speakers of an Indo-European language. The three largest phyla of the Indo-European language family in Europe are Romance, Germanic, and Slavic; they have more than 200 million speakers each, and together account for close to 90% of Europeans.\nSmaller phyla of Indo-European found in Europe include Hellenic (Greek, 13 million), Baltic ( 4.5 million), Albanian ( 7.5 million), Celtic ( 4 million), and Armenian ( 4 million). Indo-Aryan, though a large subfamily of Indo-European, has a relatively small number of languages in Europe, and a small number of speakers (Romani, 1.5 million). However, a number of Indo-Aryan languages not native to Europe are spoken in Europe today.\nOf the approximately 45 million Europeans speaking non-Indo-European languages, most speak languages within either the Uralic or Turkic families. Still smaller groups \u2014 such as Basque (language isolate), Semitic languages (Maltese, 0.5 million), and various languages of the Caucasus \u2014 account for less than 1% of the European population among them. Immigration has added sizeable communities of speakers of African and Asian languages, amounting to about 4% of the population, with Arabic being the most widely spoken of them.\nFive languages have more than 50 million native speakers in Europe: Russian, German, French, Italian, and English. Russian is the most-spoken native language in Europe, and English has the largest number of speakers in total, including some 200 million speakers of English as a second or foreign language. (See English language in Europe.)\nIndo-European languages.\nThe Indo-European language family is descended from Proto-Indo-European, which is believed to have been spoken thousands of years ago. Early speakers of Indo-European daughter languages most likely expanded into Europe with the incipient Bronze Age, around 4,000 years ago (Bell-Beaker culture).\nGermanic.\nThe Germanic languages make up the predominant language family in Western, Northern and Central Europe. It is estimated that over 500 million Europeans are speakers of Germanic languages, the largest groups being German ( 95 million), English ( 400 million), Dutch ( 24 million), Swedish ( 10 million), Danish ( 6 million), Norwegian ( 5 million) and Limburgish (c. 1.3 million).\nThere are two extant major sub-divisions: \"West Germanic\" and \"North Germanic\". A third group, East Germanic, is now extinct; the only known surviving East Germanic texts are written in the Gothic language. West Germanic is divided into Anglo-Frisian (including English), Low German, Low Franconian (including Dutch) and High German (including Standard German).\nAnglo-Frisian.\nThe Anglo-Frisian language family is now mostly represented by English (Anglic), descended from the Old English language spoken by the Anglo-Saxons:\nThe Frisian languages are spoken by about 400,000 () Frisians, who live on the southern coast of the North Sea in the Netherlands and Germany. These languages include West Frisian, East Frisian (of which the only surviving dialect is Saterlandic) and North Frisian.\nDutch.\nDutch is spoken throughout the Netherlands, the northern half of Belgium, as well as the Nord-Pas de Calais region of France. The traditional dialects of the Lower Rhine region of Germany are linguistically more closely related to Dutch than to modern German. In Belgian and French contexts, Dutch is sometimes referred to as Flemish. Dutch dialects are numerous and varied.\nGerman.\nGerman is spoken throughout Germany, Austria, Liechtenstein, much of Switzerland (including the northeast areas bordering on Germany and Austria), northern Italy (South Tyrol), Luxembourg, the East Cantons of Belgium and the Alsace and Lorraine regions of France.\nThere are several groups of German dialects:\nLow German.\nLow German is spoken in various regions throughout Northern Germany and the northern and eastern parts of the Netherlands. It may be separated into West Low German and East Low German.\nNorth Germanic (Scandinavian).\nThe \"North Germanic languages\" are spoken in Nordic countries and include \nSwedish (Sweden and parts of Finland), \nDanish (Denmark), \nNorwegian (Norway), \nIcelandic (Iceland),\nFaroese (Faroe Islands), \nand Elfdalian (in a small part of central Sweden).\nEnglish has a long history of contact with Scandinavian languages, given the immigration of Scandinavians early in the history of Britain, and shares various features with the Scandinavian languages. Even so, especially Dutch and Swedish, but also Danish and Norwegian, have strong vocabulary connections to the German language.\nLimburgish.\nLimburgish (also called Limburgan, Limburgian, or Limburgic) Is a West Germanic language spoken in the province of Limburg in the Netherlands, Belgium and neighboring regions of Germany. It is distinct from German and Dutch, but originates from areas near where both are spoken.\nRomance.\nRoughly 215 million Europeans (primarily in Southern and Western Europe) are native speakers of Romance languages, the largest groups including:\nFrench ( 72 million),\nItalian ( 65 million),\nSpanish ( 40 million), \nRomanian ( 24 million),\nPortuguese ( 10 million),\nCatalan ( 7 million),\nNeapolitan ( 6 million), \nSicilian ( 5 million), \nVenetian ( 4 million),\nGalician ( 2 million),\nSardinian ( 1 million),\nOccitan ( 500,000), besides numerous smaller communities.\nThe Romance languages evolved from varieties of Vulgar Latin spoken in the various parts of the Roman Empire in Late Antiquity. Latin was itself part of the (otherwise extinct) Italic branch of Indo-European.\nRomance languages are divided phylogenetically into \"Italo-Western\", \"Eastern Romance\" (including Romanian) and \"Sardinian\". The Romance-speaking area of Europe is occasionally referred to as \"Latin Europe\".\nItalo-Western can be further broken down into the \"Italo-Dalmatian languages\" (sometimes grouped with Eastern Romance), including the Tuscan-derived Italian and numerous local Romance languages in Italy as well as Dalmatian, and the \"Western Romance languages\". The Western Romance languages in turn separate into the Gallo-Romance languages, including Langues d'o\u00efl such as French, the Francoprovencalic languages Arpitan and Faetar, the Rhaeto-Romance languages, and the Gallo-Italic languages; the Occitano-Romance languages, grouped with either Gallo-Romance or East Iberian, including Occitanic languages such as Occitan and Gardiol, and Catalan; Aragonese, grouped in with either Occitano-Romance or West Iberian, and finally the West Iberian languages, including the Astur-Leonese languages, the Galician-Portuguese languages, and the Castilian languages.\nSlavic.\nSlavic languages are spoken in large areas of Southern, Central and Eastern Europe. An estimated 315 million people speak a Slavic language, the largest groups being \nRussian ( 110 million in European Russia and adjacent parts of Eastern Europe, Russian forming the largest linguistic community in Europe),\nPolish ( 40 million),\nUkrainian ( 33 million), \nSerbo-Croatian ( 18 million),\nCzech ( 11 million),\nBulgarian ( 8 million), \nSlovak ( 5 million),\nBelarusian (c. 3.7 million), Slovene ( 2.3 million)\nand Macedonian ( 1.6 million).\nPhylogenetically, Slavic is divided into three subgroups:\nNon-Indo-European languages.\nUralic.\nUralic language family is native to northern Eurasia.\nFinnic languages include Finnish ( 5 million) and Estonian ( 1 million), as well as smaller languages such as Kven ( 8,000). Other languages of the Finno-Permic branch of the family include e.g. Mari (c. 400,000), and the Sami languages ( 30,000).\nThe Ugric branch of the language family is represented in Europe by the Hungarian language ( 13 million), historically introduced with the Hungarian conquest of the Carpathian Basin of the 9th century.\nThe Samoyedic Nenets language is spoken in Nenets Autonomous Okrug of Russia, located in the far northeastern corner of Europe (as delimited by the Ural Mountains).\nSign languages.\nSeveral dozen manual languages exist across Europe, with the most widespread sign language family being the Francosign languages, with its languages found in countries from Iberia to the Balkans and the Baltics. Accurate historical information of sign and tactile languages is difficult to come by, with folk histories noting the existence signing communities across Europe hundreds of years ago. British Sign Language (BSL) and French Sign Language (LSF) are probably the oldest confirmed, continuously used sign languages. Alongside German Sign Language (DGS) according to Ethnologue, these three have the most numbers of signers, though very few institutions take appropriate statistics on contemporary signing populations, making legitimate data hard to find.\nNotably, few European sign languages have overt connections with the local majority/oral languages, aside from standard language contact and borrowing, meaning grammatically the sign languages and the oral languages of Europe are quite distinct from one another. Due to (visual/aural) modality differences, most sign languages are named for the larger ethnic nation in which they are spoken, plus the words \"sign language\", rendering what is spoken across much of France, Wallonia and Romandy as French Sign Language or LSF for: \"langue des signes fran\u00e7aise\".\nRecognition of non-oral languages varies widely from region to region. Some countries afford legal recognition, even to official on a state level, whereas others continue to be actively suppressed.\nThough \"there is a widespread belief\u2014among both Deaf people and sign language linguists\u2014that there \"are\" sign language families,\" the actual relationship between sign languages is difficult to ascertain. Concepts and methods used in historical linguistics to describe language families for written and spoken languages are not easily mapped onto signed languages. Some of the current understandings of sign language relationships, however, provide some reasonable estimates about potential sign language families:\nHistory of standardization.\nLanguage and identity, standardization processes.\nIn the Middle Ages the two most important defining elements of Europe were \"Christianitas\" and \"Latinitas\".\nThe earliest dictionaries were glossaries: more or less structured lists of lexical pairs (in alphabetical order or according to conceptual fields). The Latin-German (Latin-Bavarian) \"Abrogans\" was among the first. A new wave of lexicography can be seen from the late 15th century onwards (after the introduction of the printing press, with the growing interest in standardisation of languages).\nThe concept of the nation state began to emerge in the early modern period. Nations adopted particular dialects as their national language. This, together with improved communications, led to official efforts to standardise the national language, and a number of language academies were established: 1582 \"Accademia della Crusca\" in Florence, 1617 \"Fruchtbringende Gesellschaft\" in Weimar, 1635 \"Acad\u00e9mie fran\u00e7aise\" in Paris, 1713 \"Real Academia Espa\u00f1ola\" in Madrid. Language became increasingly linked to nation as opposed to culture, and was also used to promote religious and ethnic identity: e.g. different Bible translations in the same language for Catholics and Protestants.\nThe first languages whose standardisation was promoted included Italian (\"questione della lingua\": Modern Tuscan/Florentine vs. Old Tuscan/Florentine vs. Venetian \u2192 Modern Florentine + archaic Tuscan + Upper Italian), French (the standard is based on Parisian), English (the standard is based on the London dialect) and (High) German (based on the dialects of the chancellery of Meissen in Saxony, Middle German, and the chancellery of Prague in Bohemia (\"Common German\")). But several other nations also began to develop a standard variety in the 16th century.\nLingua franca.\nEurope has had a number of languages that were considered linguae francae over some ranges for some periods according to some historians. Typically in the rise of a national language the new language becomes a lingua franca to peoples in the range of the future nation until the consolidation and unification phases. If the nation becomes internationally influential, its language may become a lingua franca among nations that speak their own national languages. Europe has had no lingua franca ranging over its entire territory spoken by all or most of its populations during any historical period. Some linguae francae of past and present over some of its regions for some of its populations are:\nLinguistic minorities.\nHistorical attitudes towards linguistic diversity are illustrated by two French laws: the Ordonnance de Villers-Cotter\u00eats (1539), which said that every document in France should be written in French (neither in Latin nor in Occitan) and the Loi Toubon (1994), which aimed to eliminate anglicisms from official documents. States and populations within a state have often resorted to war to settle their differences. There have been attempts to prevent such hostilities: two such initiatives were promoted by the Council of Europe, founded in 1949, which affirms the right of minority language speakers to use their language fully and freely. The Council of Europe is committed to protecting linguistic diversity. Currently all European countries except France, Andorra and Turkey have signed the Framework Convention for the Protection of National Minorities, while Greece, Iceland and Luxembourg have signed it, but have not ratified it; this framework entered into force in 1998. Another European treaty, the European Charter for Regional or Minority Languages, was adopted in 1992 under the auspices of the Council of Europe: it entered into force in 1998, and while it is legally binding for 24 countries, France, Iceland, Italy, North Macedonia, Moldova and Russia have chosen to sign without ratifying the convention.\nScripts.\nThe main scripts used in Europe today are the Latin and Cyrillic.\nThe Greek alphabet was derived from the Phoenician alphabet, and Latin was derived from the Greek via the Old Italic alphabet. In the Early Middle Ages, Ogham was used in Ireland and runes (derived from Old Italic script) in Scandinavia. Both were replaced in general use by the Latin alphabet by the Late Middle Ages. The Cyrillic script was derived from the Greek with the first texts appearing around 940\u00a0AD.\nAround 1900 there were mainly two typeface variants of the Latin alphabet used in Europe: Antiqua and Fraktur. Fraktur was used most for German, Estonian, Latvian, Norwegian and Danish whereas Antiqua was used for Italian, Spanish, French, Polish, Portuguese, English, Romanian, Swedish and Finnish. The Fraktur variant was banned by Hitler in 1941, having been described as \"Schwabacher Jewish letters\". Other scripts have historically been in use in Europe, including Phoenician, from which modern Latin letters descend, Ancient Egyptian hieroglyphs on Egyptian artefacts traded during Antiquity, various runic systems used in Northern Europe preceding Christianisation, and Arabic during the era of the Ottoman Empire.\nHungarian rov\u00e1s was used by the Hungarian people in the early Middle Ages, but it was gradually replaced with the Latin-based Hungarian alphabet when Hungary became a kingdom, though it was revived in the 20th century and has certain marginal, but growing area of usage since then.\nEuropean Union.\nThe European Union (as of 2021) had 27 member states accounting for a population of 447 million, or about 60% of the population of Europe.\nThe European Union has designated by agreement with the member states 24 languages as \"official and working\": Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish. This designation provides member states with two \"entitlements\": the member state may communicate with the EU in any of the designated languages, and view \"EU regulations and other legislative documents\" in that language.\nThe European Union and the Council of Europe have been collaborating in education of member populations in languages for \"the promotion of plurilingualism\" among EU member states. The joint document, \"Common European Framework of Reference for Languages: Learning, Teaching, Assessment (CEFR)\", is an educational standard defining \"the competencies necessary for communication\" and related knowledge for the benefit of educators in setting up educational programs. \nIn a 2005 independent survey requested by the EU's Directorate-General for Education and Culture regarding the extent to which major European languages were spoken in member states. The results were published in a 2006 document, \"Europeans and Their Languages\", or \"Eurobarometer\u00a0243\". In this study, statistically relevant samples of the population in each country were asked to fill out a survey form concerning the languages that they spoke with sufficient competency \"to be able to have a conversation\".\nList of languages.\nThe following is a table of European languages. The number of speakers as a first or second language (L1 and L2 speakers) listed are speakers in Europe only; see list of languages by number of native speakers and list of languages by total number of speakers for global estimates on numbers of speakers.\nThe list is intended to include any language variety with an ISO 639 code. However, it omits sign languages. Because the ISO-639-2 and ISO-639-3 codes have different definitions, this means that some communities of speakers may be listed more than once. For instance, speakers of Bavarian are listed both under \"Bavarian\" (ISO-639-3 code \"bar\") as well as under \"German\" (ISO-639-2 code \"de\").\nLanguages spoken in Armenia, Azerbaijan, Cyprus, Georgia, and Turkey.\nThere are various definitions of Europe, which may or may not include all or parts of Turkey, Cyprus, Armenia, Azerbaijan, and Georgia. For convenience, the languages and associated statistics for all five of these countries are grouped together on this page, as they are usually presented at a national, rather than subnational, level.\nImmigrant communities.\nRecent (post\u20131945) immigration to Europe introduced substantial communities of speakers of non-European languages.\nThe largest such communities include Arabic speakers (see Arabs in Europe)\nand Turkish speakers (beyond European Turkey and the historical sphere of influence of the Ottoman Empire, see Turks in Europe).\nArmenians, Berbers, and Kurds have diaspora communities of 1\u20132,000,000 each. The various languages of Africa and languages of India form numerous smaller diaspora communities."}
{"id": "9706", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=9706", "title": "Eindhoven University of Technology", "text": "The Eindhoven University of Technology (), abbr. TU/e, is a public technical university in the Netherlands, situated in Eindhoven. In 2020\u201321, around 14,000 students were enrolled in its BSc and MSc programs and around 1350 students were enrolled in its PhD and EngD programs. In 2021, the TU/e employed around 3900 people.\nTU/e is the Dutch member of the EuroTech Universities Alliance, a partnership of European universities of science &amp; technology. The other members are Technical University of Denmark (DTU), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), \u00c9cole Polytechnique (L\u2019X), The Technion, and Technical University of Munich (TUM).\nHistory.\nThe Eindhoven University of Technology was founded as the \"Technische Hogeschool Eindhoven\" (THE) on 23 June 1956 by the Dutch government. It was the second institute of its kind in the Netherlands, after the Delft University of Technology.\nUndergraduate education was given in four- or five-year programs until 2002, styled along the lines of the German system of education; graduates of these programs were granted an engineering title and allowed to prefix their name with the title \"ir.\" (an abbreviation of ingenieur; not to be confused with graduates of technical \"hogescholen\", who were engineers abbreviated \"ing.\"). Starting in 2002, following the entry into force of the Bologna Accords, the university switched to the bachelor/master structure (students graduating in 2002 were given both an old-style engineering title and a new master's title). The undergraduate programs are now split into two parts, a three-year bachelor program and a two-year master program.\n2011-2020 Plans.\nOn 3 January 2011, the university's plans for the period up to 2020, the \"Strategic Plan 2020\", was presented. The plan included establishing a University College with relevance in engineering education; establishing a Graduate School to manage the graduate programs; increasing the student body and annual PhDs awarded by 50 percent; increasing knowledge \"valorisation\" (practical usage) to a campus-wide score of 4.2; increasing the international position of the university to the top 100; and improving the campus, including adding a costly science park.\nOrganization.\nAs a public university of the Netherlands, TU/e's general structure and management is determined by the (Law on Higher Education and Scientific Research). Between that law and the statutes of the university itself, the management of the university is organized according to the following chart:\nExecutive board.\nThe day-to-day running of the university is in the hands of the executive board \"()\". The executive board (EB) monitors the academic departments and service organizations, in addition to the local activities of the Stan Ackermans Institute. The EB consists of the president, the rector magnificus, and the vice president, in addition to a secretary for clerical tasks, who is usually the secretary of the entire university. The rector magnificus is the only member of the EB whose membership is mandated by law. The law allows anyone to be appointed rector, but in practice the university appoints a former department dean as rector. The rector represents the university's academic staff and academic interests of the university. The current president is Robert-Jan Smits, the rector is Silvia Lenaerts, the vice president is Nicole Ummelen, and the secretary is Susanne van Weelden.\nOversight of the executive board.\nThere are two bodies that supervise the Executive Board:\nDepartments and service organizations.\nMost of the work at the university is done in the departments and service organizations. In both the departments and the service organizations, the staff (and students) are involved with the running of the body. Both the bodies also have advisory councils.\nThe departments take care of most of the research and education at the university. Each department is run by its professors and headed by a dean. The deans are all members of the executive deliberation meeting, which is a regular meeting of the deans and the rector.\nThe service organizations are involved in further activities that are part of running the university.\nThe university has the following service organizations:\nTU/e Holding B.V..\nTU/e is involved in commercial interests and off-campus ties. These include commercial agreements between the university and external companies, in addition to interests in spinoff companies. In 1997 the TU/e Holding B.V., a limited company, was created to manage these commercial interests.\nAcademics.\nRankings.\nAs of 2018, Eindhoven was ranked between 51 and 141 in the world (the university itself provides a survey), and a top ten technical university in Europe.\nIn a 2003 European Commission report, TU/e was ranked as third among European research universities (after Cambridge and Oxford, tied with TU Munich and thus tied for the highest ranked Technical University in Europe), based on the impact of its scientific research. In the 2011 ARWU (Academic Ranking of World Universities) rankings, TU/e was placed at the 52-75 bracket internationally in the Engineering/Technology and Computer Science (ENG) category and at 34th place internationally in the Computer Science subject field.\nEducation.\nThe scientific departments (or faculties) are the main divisions involved in teaching and research in the university. They employ the majority of the academic staff, are responsible for teaching the students, and sponsor the research schools and institutions.\nThe departments also offer PhD programs () for qualified masters. Unlike in Anglo-Saxon countries, the PhD program is not educational, rather, the university employs those aiming for a PhD as researchers.\nThe TU/e has nine departments:\nHonors programs.\nThe university offers honors programs for both bachelor and master students. At the bachelor level it consists of intensive study within eight possible tracks. At the master level it consists of extra leadership and professional development work.\nPostgraduate doctorate of engineering (PDEng).\nIn 1986, the university, together with two other Dutch technological universities (TU Delft and University of Twente), started various programs for earning a postgraduate doctorate of engineering (PDEng). These programs are managed by the Stan Ackermans Institute on behalf of the 4TU Federation. Nationally, 3,500 students have earned the postgraduate PDEng degree through these programs. There are ten programs at TU/e, each two years long.\nOther educational programs.\nThe university hosts a number of other educational programs that are in some way related to the main educational programs. These include the teacher's program and an MBA program.\nInternational connections.\nThe TU/e has connections with sister institutions in different countries, for example:\nThe TU/e also provides education to foreign students and graduates. According to the 2009 annual report in the academic year 2008\u20132009 there were 490 exchange students, 103 foreign nationals registered in a bachelor program, 430 in a master program, 158 in a professional doctorate program (79% of the total). In 2009 the university employed 37 foreign professors (15.9% of the total) and 16 foreign associate professors (12.8%). Overall, 29.5% of the university staff was non-Dutch.\nAs of 2011/2012, the TU/e had Erasmus agreements with universities in 30 countries across Europe in a range of subjects for student exchanges.\nRegional effect.\nThe TU/e plays a role in the academic, economic and social life of Eindhoven and the surrounding region.\nThe TU/e is important to the economy of the Eindhoven region, as well as the wider areas of BrabantStad and the Samenwerkingsverband Regio Eindhoven. It provides skilled labor for local businesses and partners with technology companies in the area.\nRegional history.\nThe university's role in the economy started with the interaction with the Philips company. The university was founded primarily to address Philips's need for local employees with higher levels of education in electronics, physics, chemistry and later computer science. Later that interest spread to DAF and Royal Dutch Shell. Often, senior personnel from these companies were hired to form the academic staff of the university (an Eindhoven joke was said that the university trains the engineers and Philips trains the professors).\nThe relationship changed during the 1980s and 1990s as Philips moved away from the region. The university was forced to seek closer ties with the city of Eindhoven, resulting in the Brainport initiative, a move to draw high tech industry to the region. The university started expending more effort in making practical use of its research and providing support for local companies and startups.\nCurrent effect.\nThe TU/e is host (and in some cases also commissioner) of a number of research schools, including the ESI and the DPI. These research schools are a source of knowledge for tech companies in the area such as ASML, NXP and FEI. As of summer 2010, the TU/e was also host to the Eindhoven Energy Institute (EEI), a co-location of the European Institute of Innovation and Technology's KIC on Sustainable Energy (InnoEnergy). The university also plays a large role in providing knowledge and personnel to other companies in the High Tech Campus Eindhoven and helps support startups through the Eindhoven Twinning Center and The Gate. The valorisation of TU/e has led to various spin-offs, including Lusoco, NC Biomatrix, Taylor, SMART Photonics, EFFECT Photonics and MicroAlign.\nIn the extended region, the TU/e is a part of the Eindhoven-Leuven-Aachen triangle. The agreement between these three cities from three different countries formed a region that is among the highest in the European Union in terms of investment in technology and knowledge economy. The agreement includes cooperation between the three technical universities in the cities.\nStudent life.\nCommunity.\nThe TU/e has over 110 community bodies for its members. They are related to sports, culture, faith, staff, international students and hobbies, as well as university political parties, student teams, and study associations for each faculty.\nTechnological sports.\nIn addition to the regular sports played by the students and staff, the university has some \"technology sporting efforts\". Some examples include:\nAnother student racing program is the Automotive Technology InMotion team, a collaboration between the TU/e and Fontys University of Applied Sciences. The team has the aim to compete in the 2020 24 Hours of Le Mans.\nStudent teams.\nTU/e has various student teams which work on problems in the fields of sustainability, AI, health and mobility."}
{"id": "9707", "revid": "47695301", "url": "https://en.wikipedia.org/wiki?curid=9707", "title": "Electronegativity", "text": "Electronegativity, symbolized as \"\u03c7\", is the tendency for an atom of a given chemical element to attract shared electrons (or electron density) when forming a chemical bond. An atom's electronegativity is affected by both its atomic number and the distance at which its valence electrons reside from the charged nucleus. The higher the associated electronegativity, the more an atom or a substituent group attracts electrons. Electronegativity serves as a simple way to quantitatively estimate the bond energy, and the sign and magnitude of a bond's chemical polarity, which characterizes a bond along the continuous scale from covalent to ionic bonding. The loosely defined term electropositivity is the opposite of electronegativity: it characterizes an element's tendency to donate valence electrons.\nOn the most basic level, electronegativity is determined by factors like the nuclear charge (the more protons an atom has, the more \"pull\" it will have on electrons) and the number and location of other electrons in the atomic shells (the more electrons an atom has, the farther from the nucleus the valence electrons will be, and as a result, the less positive charge they will experience\u2014both because of their increased distance from the nucleus and because the other electrons in the lower energy core orbitals will act to shield the valence electrons from the positively charged nucleus).\nThe term \"electronegativity\" was introduced by J\u00f6ns Jacob Berzelius in 1811,\nthough the concept was known before that and was studied by many chemists including Avogadro.\nIn spite of its long history, an accurate scale of electronegativity was not developed until 1932, when Linus Pauling proposed an electronegativity scale which depends on bond energies, as a development of valence bond theory. It has been shown to correlate with a number of other chemical properties. Electronegativity cannot be directly measured and must be calculated from other atomic or molecular properties. Several methods of calculation have been proposed, and although there may be small differences in the numerical values of the electronegativity, all methods show the same periodic trends between elements.\nThe most commonly used method of calculation is that originally proposed by Linus Pauling. This gives a dimensionless quantity, commonly referred to as the Pauling scale (\"\u03c7\"r), on a relative scale running from 0.79 to 3.98 (hydrogen\u00a0= 2.20). When other methods of calculation are used, it is conventional (although not obligatory) to quote the results on a scale that covers the same range of numerical values: this is known as an electronegativity in \"Pauling units\".\nAs it is usually calculated, electronegativity is not a property of an atom alone, but rather a property of an atom in a molecule. Even so, the electronegativity of an atom is strongly correlated with the first ionization energy. The electronegativity is slightly negatively correlated (for smaller electronegativity values) and rather strongly positively correlated (for most and larger electronegativity values) with the electron affinity. It is to be expected that the electronegativity of an element will vary with its chemical environment, but it is usually considered to be a transferable property, that is to say that similar values will be valid in a variety of situations.\nCaesium is the least electronegative element (0.79); fluorine is the most (3.98).\nMethods of calculation.\nPauling electronegativity.\nPauling first proposed the concept of electronegativity in 1932 to explain why the covalent bond between two different atoms (A\u2013B) is stronger than the average of the A\u2013A and the B\u2013B bonds. According to valence bond theory, of which Pauling was a notable proponent, this \"additional stabilization\" of the heteronuclear bond is due to the contribution of ionic canonical forms to the bonding.\nThe difference in electronegativity between atoms A and B is given by:\nformula_1\nwhere the dissociation energies, \"E\"d, of the A\u2013B, A\u2013A and B\u2013B bonds are expressed in electronvolts, the factor (eV)\u2212 being included to ensure a dimensionless result. Hence, the difference in Pauling electronegativity between hydrogen and bromine is 0.73 (dissociation energies: H\u2013Br, 3.79\u00a0eV; H\u2013H, 4.52\u00a0eV; Br\u2013Br 2.00\u00a0eV)\nAs only differences in electronegativity are defined, it is necessary to choose an arbitrary reference point in order to construct a scale. Hydrogen was chosen as the reference, as it forms covalent bonds with a large variety of elements: its electronegativity was fixed first at 2.1, later revised to 2.20. It is also necessary to decide which of the two elements is the more electronegative (equivalent to choosing one of the two possible signs for the square root). This is usually done using \"chemical intuition\": in the above example, hydrogen bromide dissolves in water to form H+ and Br\u2212 ions, so it may be assumed that bromine is more electronegative than hydrogen. However, in principle, since the same electronegativities should be obtained for any two bonding compounds, the data are in fact overdetermined, and the signs are unique once a reference point has been fixed (usually, for H or F).\nTo calculate Pauling electronegativity for an element, it is necessary to have data on the dissociation energies of at least two types of covalent bonds formed by that element. A. L. Allred updated Pauling's original values in 1961 to take account of the greater availability of thermodynamic data, and it is these \"revised Pauling\" values of the electronegativity that are most often used.\nThe essential point of Pauling electronegativity is that there is an underlying, quite accurate, semi-empirical formula for dissociation energies, namely:\nformula_2\nor sometimes, a more accurate fit\nformula_3\nThese are approximate equations but they hold with good accuracy. Pauling obtained the first equation by noting that a bond can be approximately represented as a quantum mechanical superposition of a covalent bond and two ionic bond-states. The covalent energy of a bond is approximate, by quantum mechanical calculations, the geometric mean of the two energies of covalent bonds of the same molecules, and there is additional energy that comes from ionic factors, i.e. polar character of the bond.\nThe geometric mean is approximately equal to the arithmetic mean\u2014which is applied in the first formula above\u2014when the energies are of a similar value, e.g., except for the highly electropositive elements, where there is a larger difference of two dissociation energies; the geometric mean is more accurate and almost always gives positive excess energy, due to ionic bonding. The square root of this excess energy, Pauling notes, is approximately additive, and hence one can introduce the electronegativity. Thus, it is these semi-empirical formulas for bond energy that underlie the concept of Pauling electronegativity.\nThe formulas are approximate, but this rough approximation is in fact relatively good and gives the right intuition, with the notion of the polarity of the bond and some theoretical grounding in quantum mechanics. The electronegativities are then determined to best fit the data.\nIn more complex compounds, there is an additional error since electronegativity depends on the molecular environment of an atom. Also, the energy estimate can be only used for single, not for multiple bonds. The enthalpy of formation of a molecule containing only single bonds can subsequently be estimated based on an electronegativity table, and it depends on the constituents and the sum of squares of differences of electronegativities of all pairs of bonded atoms. Such a formula for estimating energy typically has a relative error on the order of 10% but can be used to get a rough qualitative idea and understanding of a molecule.\nMulliken electronegativity.\nRobert S. Mulliken proposed that the arithmetic mean of the first ionization energy (Ei) and the electron affinity (Eea) should be a measure of the tendency of an atom to attract electrons:\nformula_4\nAs this definition is not dependent on an arbitrary relative scale, it has also been termed absolute electronegativity, with the units of kilojoules per mole or electronvolts. However, it is more usual to use a linear transformation to transform these absolute values into values that resemble the more familiar Pauling values. For ionization energies and electron affinities in electronvolts,\nformula_5\nand for energies in kilojoules per mole,\nformula_6\nThe Mulliken electronegativity can only be calculated for an element whose electron affinity is known. Measured values are available for 72 elements, while approximate values have been estimated or calculated for the remaining elements.\nThe Mulliken electronegativity of an atom is sometimes said to be the negative of the chemical potential. By inserting the energetic definitions of the ionization potential and electron affinity into the Mulliken electronegativity, it is possible to show that the Mulliken chemical potential is a finite difference approximation of the electronic energy with respect to the number of electrons., i.e.,\nformula_7\nAllred\u2013Rochow electronegativity.\nA. Louis Allred and Eugene G. Rochow considered that electronegativity should be related to the charge experienced by an electron on the \"surface\" of an atom: The higher the charge per unit area of atomic surface the greater the tendency of that atom to attract electrons. The effective nuclear charge, \"Z\"eff, experienced by valence electrons can be estimated using Slater's rules, while the surface area of an atom in a molecule can be taken to be proportional to the square of the covalent radius, \"r\"cov. When \"r\"cov is expressed in picometres,\nformula_8\nSanderson electronegativity equalization.\nR.T. Sanderson has also noted the relationship between Mulliken electronegativity and atomic size, and has proposed a method of calculation based on the reciprocal of the atomic volume. With a knowledge of bond lengths, Sanderson's model allows the estimation of bond energies in a wide range of compounds. Sanderson's model has also been used to calculate molecular geometry, \"s\"-electron energy, NMR spin-spin coupling constants and other parameters for organic compounds. This work underlies the concept of electronegativity equalization, which suggests that electrons distribute themselves around a molecule to minimize or to equalize the Mulliken electronegativity. This behavior is analogous to the equalization of chemical potential in macroscopic thermodynamics.\nAllen electronegativity.\nPerhaps the simplest definition of electronegativity is that of Leland C. Allen, who has proposed that it is related to the average energy of the valence electrons in a free atom,\nformula_9\nwhere \"\u03b5\"s,p are the one-electron energies of s- and p-electrons in the free atom and \"n\"s,p are the number of s- and p-electrons in the valence shell.\nThe one-electron energies can be determined directly from spectroscopic data, and so electronegativities calculated by this method are sometimes referred to as spectroscopic electronegativities. The necessary data are available for almost all elements, and this method allows the estimation of electronegativities for elements that cannot be treated by the other methods, e.g. francium, which has an Allen electronegativity of 0.67. However, it is not clear what should be considered to be valence electrons for the d- and f-block elements, which leads to an ambiguity for their electronegativities calculated by the Allen method.\nOn this scale, neon has the highest electronegativity of all elements, followed by fluorine, helium, and oxygen.\nCorrelation of electronegativity with other properties.\nThe wide variety of methods of calculation of electronegativities, which all give results that correlate well with one another, is one indication of the number of chemical properties that might be affected by electronegativity. The most obvious application of electronegativities is in the discussion of bond polarity, for which the concept was introduced by Pauling. In general, the greater the difference in electronegativity between two atoms the more polar the bond that will be formed between them, with the atom having the higher electronegativity being at the negative end of the dipole. Pauling proposed an equation to relate the \"ionic character\" of a bond to the difference in electronegativity of the two atoms, although this has fallen somewhat into disuse.\nSeveral correlations have been shown between infrared stretching frequencies of certain bonds and the electronegativities of the atoms involved: however, this is not surprising as such stretching frequencies depend in part on bond strength, which enters into the calculation of Pauling electronegativities. More convincing are the correlations between electronegativity and chemical shifts in NMR spectroscopy or isomer shifts in M\u00f6ssbauer spectroscopy (see figure). Both these measurements depend on the s-electron density at the nucleus, and so are a good indication that the different measures of electronegativity really are describing \"the ability of an atom in a molecule to attract electrons to itself\".\nTrends in electronegativity.\nPeriodic trends.\nIn general, electronegativity increases on passing from left to right along a period and decreases on descending a group. Hence, fluorine is the most electronegative of the elements (not counting noble gases), whereas caesium is the least electronegative, at least of those elements for which substantial data is available.\nThere are some exceptions to this general rule. Gallium and germanium have higher electronegativities than aluminium and silicon, respectively, because of the d-block contraction. Elements of the fourth period immediately after the first row of the transition metals have unusually small atomic radii because the 3d-electrons are not effective at shielding the increased nuclear charge, and smaller atomic size correlates with higher electronegativity (see Allred-Rochow electronegativity and Sanderson electronegativity above). The anomalously high electronegativity of lead, in particular when compared to thallium and bismuth, is an artifact of electronegativity varying with oxidation state: its electronegativity conforms better to trends if it is quoted for the +2 state with a Pauling value of 1.87 instead of the +4 state.\nVariation of electronegativity with oxidation number.\nIn inorganic chemistry, it is common to consider a single value of electronegativity to be valid for most \"normal\" situations. While this approach has the advantage of simplicity, it is clear that the electronegativity of an element is \"not\" an invariable atomic property and, in particular, increases with the oxidation state of the element.\nAllred used the Pauling method to calculate separate electronegativities for different oxidation states of the handful of elements (including tin and lead) for which sufficient data were available. However, for most elements, there are not enough different covalent compounds for which bond dissociation energies are known to make this approach feasible.\nThe chemical effects of this increase in electronegativity can be seen both in the structures of oxides and halides and in the acidity of oxides and oxoacids. Hence CrO3 and Mn2O7 are acidic oxides with low melting points, while Cr2O3 is amphoteric and Mn2O3 is a completely basic oxide.\nThe effect can also be clearly seen in the dissociation constants p\"K\"a of the oxoacids of chlorine. The effect is much larger than could be explained by the negative charge being shared among a larger number of oxygen atoms, which would lead to a difference in p\"K\"a of log10()\u00a0= \u20130.6 between hypochlorous acid and perchloric acid. As the oxidation state of the central chlorine atom increases, more electron density is drawn from the oxygen atoms onto the chlorine, diminishing the partial negative charge of individual oxygen atoms. At the same time, the positive partial charge on the hydrogen increases with a higher oxidation state. This explains the observed increased acidity with an increasing oxidation state in the oxoacids of chlorine.\nElectronegativity and hybridization scheme.\nThe electronegativity of an atom changes depending on the hybridization of the orbital employed in bonding. Electrons in s orbitals are held more tightly than electrons in p orbitals. Hence, a bond to an atom that employs an sp\"x\" hybrid orbital for bonding will be more heavily polarized to that atom when the hybrid orbital has more s character. That is, when electronegativities are compared for different hybridization schemes of a given element, the order holds (the trend should apply to non-integer hybridization indices as well). \nGroup electronegativity.\nIn organic chemistry, electronegativity is associated more with different functional groups than with individual atoms. The terms group electronegativity and substituent electronegativity are used synonymously. However, it is common to distinguish between the inductive effect and the resonance effect, which might be described as \u03c3- and \u03c0-electronegativities, respectively. There are a number of linear free-energy relationships that have been used to quantify these effects, of which the Hammett equation is the best known. Kabachnik Parameters are group electronegativities for use in organophosphorus chemistry.\nElectropositivity.\nElectropositivity is a measure of an element's ability to donate electrons, and therefore form positive ions; thus, it is antipode to electronegativity.\nMainly, this is an attribute of metals, meaning that, in general, the greater the metallic character of an element the greater the electropositivity. Therefore, the alkali metals are the most electropositive of all. This is because they have a single electron in their outer shell and, as this is relatively far from the nucleus of the atom, it is easily lost; in other words, these metals have low ionization energies.\nWhile electronegativity increases along periods in the periodic table, and decreases down groups, electropositivity \"decreases\" along periods (from left to right) and \"increases\" down groups. This means that elements in the upper right of the periodic table of elements (oxygen, sulfur, chlorine, etc.) will have the greatest electronegativity, and those in the lower-left (rubidium, caesium, and francium) the greatest electropositivity."}
{"id": "9708", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=9708", "title": "European Charter for Regional or Minority Languages", "text": "The European Charter for Regional or Minority Languages (ECRML) is a European treaty (CETS 148) adopted in 1992 under the auspices of the Council of Europe to protect and promote historical regional and minority languages in Europe. However, the charter does not provide any criterion or definition for an idiom to be a minority or a regional language, and the classification stays in the hands of the national state.\nThe preparation for the charter was undertaken by the predecessor to the current Congress of Local and Regional Authorities, the Standing Conference of Local and Regional Authorities of Europe because involvement of local and regional government was essential. The actual charter was written in the Parliamentary Assembly based on the Congress' Recommendations. It only applies to languages traditionally used by the nationals of the State Parties (thus excluding languages used by recent immigrants from other states, see immigrant languages), which significantly differ from the majority or official language (thus excluding what the state party wishes to consider as mere local dialects of the official or majority language) and that either have a territorial basis (and are therefore traditionally spoken by populations of regions or areas within the State) or are used by linguistic minorities within the State as a whole (thereby including such languages as Yiddish, Romani and Lemko, which are used over a wide geographic area).\nSome states, such as Ukraine and Sweden, have tied the status of minority language to the recognized national minorities, which are defined by ethnic, cultural and/or religious criteria, thereby circumventing the Charter's notion of linguistic minority.\nLanguages that are official within regions, provinces or federal units within a State (for example Catalan in Spain) are not classified as official languages of the State and may therefore benefit from the Charter. On the other hand, Ireland has been unable to sign the Charter on behalf of the Irish language (although a minority language) as it is defined as the first official language of the state. The United Kingdom has ratified the Charter in respect to (among other languages) Welsh in Wales, Scots and Gaelic in Scotland, and Irish in Northern Ireland. France, although a signatory, has been constitutionally blocked from ratifying the Charter in respect to the languages of France.\nThe charter provides many actions state parties can take to protect and promote historical regional and minority languages. There are two levels of protection\u2014all signatories must apply the lower level of protection to qualifying languages. Signatories may further declare that a qualifying language or languages will benefit from the higher level of protection, which lists a range of actions from which states must agree to undertake at least 35.\nProtections.\nCountries can ratify the charter in respect of its minority languages based on Part II or Part III of the charter, which contain varying principles. Countries can treat languages differently under the charter, for example, in the United Kingdom, the Welsh language is ratified under the general Part II principles as well as the more specific Part III commitments, while the Cornish language is ratified only under Part II.\nPart II.\nPart II of the Charter details eight main principles and objectives upon which States must base their policies and legislation. They are seen as a framework for the preservation of the languages concerned.\nPart III.\nPart III details comprehensive rules, across a number of sectors, by which states agree to abide. Each language to which Part III of the Charter is applied must be named specifically by the government. States must select at least thirty-five of the undertakings in respect to each language. Many provisions contain several options, of varying degrees of stringency, one of which has to be chosen \"according to the situation of each language\". The areas from which these specific undertakings must be chosen are as follows:"}
{"id": "9709", "revid": "40976397", "url": "https://en.wikipedia.org/wiki?curid=9709", "title": "English Civil War", "text": " \nThe English Civil War was a series of civil wars and political machinations between Royalists and Parliamentarians in the Kingdom of England from 1642 to 1651. Part of the wider 1639 to 1653 Wars of the Three Kingdoms, the struggle consisted of the First English Civil War and the Second English Civil War. The Anglo-Scottish War of 1650 to 1652 is sometimes referred to as the \"Third English Civil War.\"\nWhile the conflicts in the three kingdoms of England, Scotland and Ireland had similarities, each had their own specific issues and objectives. The First English Civil War was fought primarily over the correct balance of power between Parliament and Charles I. It ended in June 1646 with Royalist defeat and the king in custody.\nHowever, victory exposed Parliamentarian divisions over the nature of the political settlement. The vast majority went to war in 1642 to assert Parliament's right to participate in government, not abolish the monarchy, which meant Charles' refusal to make concessions led to a stalemate. Concern over the political influence of radicals within the New Model Army like Oliver Cromwell led to an alliance between moderate Parliamentarians and Royalists, supported by the Covenanter Scots. Royalist defeat in the 1648 Second English Civil War resulted in the execution of Charles I in January 1649, and establishment of the Commonwealth of England.\nIn 1650, Charles II was crowned King of Scotland, in return for agreeing to create a Presbyterian church in both England and Scotland. The subsequent Anglo-Scottish war ended with Parliamentarian victory at Worcester on 3 September 1651. Both Ireland and Scotland were incorporated into the Commonwealth, and Britain became a unitary state until the Stuart Restoration in 1660.\nTerminology.\nThe term \"English Civil War\" appears most often in the singular, but historians often divide the conflict into two or three separate wars. These were not restricted to England alone, as Wales (having been annexed into the Kingdom of England) was affected by the same political instabilities. The conflicts also involved wars with Scotland and Ireland and civil wars within them. Some historians have favoured the term \"The British Civil Wars\". From the Restoration to the 19th century, the common phrase for the civil wars was \"the rebellion\" or \"the great rebellion\".\nThe wars spanning all four countries are known as the Wars of the Three Kingdoms. In the early 19th century, Sir Walter Scott referred to it as \"The Great Civil War\". The 1911 \"Encyclop\u00e6dia Britannica\" called the series of conflicts the \"Great Rebellion\". Some historians, notably Marxists such as Christopher Hill (1912\u20132003), favoured the term \"English Revolution\".\nGeography.\nEach side had a geographical stronghold, such that minority elements were silenced or fled. The Royalist areas included the countryside, the shires, the cathedral city of Oxford, and the less economically developed areas of northern and western England and Wales. Parliament's strengths spanned the industrial centres, ports, and economically advanced regions of southern and eastern England, including the remaining cathedral cities (except York, Chester, Worcester). Lacey Baldwin Smith says, \"the words \"populous, rich, and rebellious\" seemed to go hand in hand\".\nStrategy and tactics.\nMany officers and veteran soldiers had fought in European wars, notably the Eighty Years' War between the Spanish and the Dutch, which began in 1568, as well as earlier phases of the Thirty Years' War which began in 1618 and concluded in 1648.\nThe war was of unprecedented scale for the English. During the campaign seasons, 120,000 to 150,000 soldiers would be in the field, a higher proportion of the population than were fighting in Germany in the Thirty Years' War.\nThe main battle tactic came to be known as pike and shot infantry. The two sides would line up opposite one another, with infantry brigades of musketeers in the centre. These carried matchlock muskets, an inaccurate weapon which nevertheless could be lethal at a range of up to 300 yards. Musketeers would assemble three rows deep, the first kneeling, second crouching, and third standing. At times, troops divided into two groups, allowing one to reload while the other fired. Among the musketeers were pike men, carrying pikes of to long, whose main purpose was to protect the musketeers from cavalry charges. Positioned on each side of the infantry were cavalry, with a right wing led by the lieutenant-general and left by the commissary general. Its main aim was to rout the opponents' cavalry, then turn and overpower their infantry.\nThe Royalist cavaliers' skill and speed on horseback led to many early victories. Prince Rupert, commanding the king's cavalry, used a tactic learned while fighting in the Dutch army, where cavalry would charge at full speed into the opponent's infantry, firing their pistols just before impact.\nHowever, with Oliver Cromwell and the introduction of the more disciplined New Model Army, a group of disciplined pike men would stand its ground, which could have a devastating effect. The Royalist cavalry had a tendency to chase down individual targets after the initial charge, leaving their forces scattered and tired, whereas Cromwell's cavalry was slower but better disciplined. Trained to operate as a single unit, it went on to win many decisive victories.\nBackground.\nThe King's rule.\nThe English Civil War broke out in 1642, less than 40 years after the death of Queen Elizabeth I. Elizabeth had been succeeded by her first cousin twice-removed, King James VI of Scotland, as James I of England, creating the first personal union of the Scottish and English kingdoms. As King of Scots, James had become accustomed to Scotland's weak parliamentary tradition since assuming control of the Scottish government in 1583, so that upon assuming power south of the border, the new King of England was affronted by the constraints the English Parliament attempted to place on him in exchange for money. Consequently, James's personal extravagance, which resulted in him being perennially short of money, meant that he had to resort to extra-parliamentary sources of income. Moreover, increasing inflation during this period meant that even though Parliament was granting the King the same nominal value of subsidy, the income was actually worth less.\nThis extravagance was tempered by James's peaceful disposition, so that by the succession of his son Charles I in 1625 the two kingdoms had both experienced relative peace, internally and in their relations with each other. Charles followed his father's dream in hoping to unite the kingdoms of England, Scotland and Ireland into a single kingdom. Many English Parliamentarians were suspicious of such a move, fearing that such a new kingdom might destroy old English traditions that had bound the English monarchy. Because James had described kings as \"little gods on Earth\", chosen by God to rule in accordance with the doctrine of the Divine Right of Kings, and Charles shared his father's position, the suspicions of the Parliamentarians had some justification.\nParliament in an English constitutional framework.\nAt the time, the Parliament of England did not have a large permanent role in the English system of government. Instead, it functioned as a temporary advisory committee and was summoned only if and when the monarch saw fit. Once summoned, a Parliament's continued existence was at the King's pleasure since it was subject to dissolution by him at any time.\nYet in spite of this limited role, Parliament had acquired over the centuries \"de facto\" powers of enough significance that monarchs could not simply ignore them indefinitely. For a monarch, Parliament's most indispensable power was its ability to raise tax revenues far in excess of all other sources of revenue at the Crown's disposal. By the 17th century, Parliament's tax-raising powers had come to be derived from the fact that the gentry was the only stratum of society with the ability and authority to collect and remit the most meaningful forms of taxation then available at the local level. So, if the king wanted to ensure smooth revenue collection, he needed the gentry's cooperation. For all of the Crown's legal authority, its resources were limited by any modern standard to the extent that if the gentry refused to collect the king's taxes on a national scale, the Crown lacked a practical means of compelling them.\nFrom the thirteenth century, monarchs ordered the election of representatives to sit in the House of Commons, with most voters being the owners of property, although in some potwalloper boroughs every male householder could vote. When assembled along with the House of Lords, these elected representatives formed a Parliament. So the concept of Parliaments allowed representatives of the property-owning class to meet, primarily, at least from the point of view of the monarch, to sanction whatever taxes the monarch wished to collect. In the process, the representatives could debate and enact statutes, or acts. However, Parliament lacked the power to force its will upon the monarch; its only leverage was the threat of withholding the financial means required to implement his plans.\nParliamentary concerns and the Petition of Right.\nMany concerns were raised over Charles's marriage in 1625 to a Roman Catholic French princess, Henrietta Maria. Parliament refused to assign him the traditional right to collect customs duties for his entire reign, deciding instead to grant it only on a provisional basis and negotiate with him.\nCharles, meanwhile, decided to send an expeditionary force to relieve the French Huguenots, whom French royal troops held besieged in La Rochelle. Such military support for Protestants on the Continent potentially alleviated concerns about the King's marriage to a Catholic. However, Charles's insistence on giving command of the English force to his unpopular royal favourite George Villiers, the Duke of Buckingham, undermined that support. Unfortunately for Charles and Buckingham, the relief expedition proved a fiasco (1627), and Parliament, already hostile to Buckingham for his monopoly on royal patronage, opened impeachment proceedings against him. Charles responded by dissolving Parliament. This saved Buckingham but confirmed the impression that Charles wanted to avoid Parliamentary scrutiny of his ministers.\nHaving dissolved Parliament and unable to raise money without it, the king assembled a new one in 1628. (The elected members included Oliver Cromwell, John Hampden, and Edward Coke.) The new Parliament drew up a Petition of Right, which Charles accepted as a concession to obtain his subsidy. The Petition made reference to Magna Carta, but did not grant him the right of tonnage and poundage, which Charles had been collecting without Parliamentary authorisation since 1625. Several more active members of the opposition were imprisoned, which caused outrage; one, John Eliot, subsequently died in prison and came to be seen as a martyr for the rights of Parliament.\nPersonal rule.\nCharles avoided calling a Parliament for the next decade, a period known as the \"personal rule of Charles I\", or by its critics as the \"Eleven Years' Tyranny\". During this period, Charles's policies were determined by his lack of money. First and foremost, to avoid Parliament, the King needed to avoid war. Charles made peace with France and Spain, effectively ending England's involvement in the Thirty Years' War. However, that in itself was far from enough to balance the Crown's finances.\nUnable to raise revenue without Parliament and unwilling to convene it, Charles resorted to other means. One was to revive conventions, often outdated. For example, a failure to attend and receive knighthood at Charles's coronation became a finable offence with the fine paid to the Crown. The King also tried to raise revenue through ship money, demanding in 1634\u20131636 that the inland English counties pay a tax for the Royal Navy to counter the threat of privateers and pirates in the English Channel. Established law supported the policy of coastal counties and inland ports such as London paying ship money in times of need, but it had not been applied to inland counties before.\nAuthorities had ignored it for centuries, and many saw it as yet another extra-Parliamentary, illegal tax, which prompted some prominent men to refuse to pay it. Charles issued a writ against John Hampden for his failure to pay, and although five judges including Sir George Croke supported Hampden, seven judges found in favour of the King in 1638. The fines imposed on people who refused to pay ship money and standing out against its illegality aroused widespread indignation.\nDuring his \"Personal Rule\", Charles aroused most antagonism through his religious measures. He believed in High Anglicanism, a sacramental version of the Church of England, theologically based upon Arminianism, a creed shared with his main political adviser, Archbishop William Laud. In 1633, Charles appointed Laud Archbishop of Canterbury and started making the Church more ceremonial, replacing the wooden communion tables with stone altars. Puritans accused Laud of reintroducing Catholicism, and when they complained he had them arrested. In 1637, John Bastwick, Henry Burton, and William Prynne had their ears cut off for writing pamphlets attacking Laud's views \u2013 a rare penalty for gentlemen, and one that aroused anger. Moreover, the Church authorities revived statutes from the time of Elizabeth I about church attendance and fined Puritans for not attending Anglican services.\nRebellion in Scotland.\nThe end of Charles's independent governance came when he attempted to apply the same religious policies in Scotland. The Church of Scotland, reluctantly episcopal in structure, had independent traditions. Charles wanted one uniform Church throughout Britain and introduced a new, High Anglican version of the English Book of Common Prayer to Scotland in the middle of 1637. This was violently resisted. A riot broke out in Edinburgh, which may have been started in St Giles' Cathedral, according to legend, by Jenny Geddes. In February 1638, the Scots formulated their objections to royal policy in the National Covenant. This document took the form of a \"loyal protest\", rejecting all innovations not first tested by free Parliaments and General Assemblies of the Church.\nIn the spring of 1639, King Charles I accompanied his forces to the Scottish border to end the rebellion known as the Bishops' War, but after an inconclusive campaign, he accepted the offered Scottish truce: the Pacification of Berwick. This truce proved temporary, and a second war followed in mid-1640. A Scots army defeated Charles's forces in the north, then captured Newcastle. Charles eventually agreed not to interfere in Scotland's religion.\nRecall of the English Parliament.\nCharles needed to suppress the rebellion in Scotland but had insufficient funds to do so. He needed to seek money from a newly elected English Parliament in 1640. Its majority faction, led by John Pym, used this appeal for money as a chance to discuss grievances against the Crown and oppose the idea of an English invasion of Scotland. Charles took exception to this \"l\u00e8se-majest\u00e9\" (offense against the ruler) and, after negotiations went nowhere, dissolved the Parliament after only a few weeks; hence its name, \"the Short Parliament\".\nWithout Parliament's support, Charles attacked Scotland again, breaking the truce at Berwick, and suffered comprehensive defeat. The Scots went on to invade England, occupying Northumberland and Durham. Meanwhile, another of Charles's chief advisers, Thomas Wentworth, 1st Viscount Wentworth, had risen to the role of Lord Deputy of Ireland in 1632, and brought in much-needed revenue for Charles by persuading the Irish Catholic gentry to pay new taxes in return for promised religious concessions.\nIn 1639, Charles had recalled Wentworth to England and in 1640 made him Earl of Strafford, attempting to have him achieve similar results in Scotland. This time he proved less successful and the English forces fled the field at their second encounter with the Scots in 1640. Almost the whole of Northern England was occupied and Charles forced to pay \u00a3850 per day to keep the Scots from advancing. Had he not done so they would have pillaged and burnt the cities and towns of Northern England.\nAll this put Charles in a desperate financial state. As King of Scots, he had to find money to pay the Scottish army in England; as King of England, he had to find money to pay and equip an English army to defend England. His means of raising English revenue without an English Parliament fell critically short of achieving this. Against this backdrop, and according to advice from the Magnum Concilium (the House of Lords, but without the Commons, so not a Parliament), Charles finally bowed to pressure and summoned another English Parliament in November 1640.\nThe Long Parliament.\nThe new Parliament proved even more hostile to Charles than its predecessor. It immediately began to discuss grievances against him and his government, with Pym and Hampden (of ship money fame) in the lead. They took the opportunity presented by the King's troubles to force various reforming measures \u2013 including many with strong \"anti-Papist\" themes \u2013 upon him. The members passed a law stating that a new Parliament would convene at least once every three years \u2013 without the King's summons if need be. Other laws passed making it illegal for the king to impose taxes without Parliamentary consent and later gave Parliament control over the King's ministers.\nFinally, the Parliament passed a law forbidding the King to dissolve it without its consent, even if the three years were up. These laws equated to a tremendous increase in Parliamentary power. Ever since, this Parliament has been known as the Long Parliament. However, Parliament did attempt to avert conflict by requiring all adults to sign The Protestation, an oath of allegiance to Charles.\nEarly in the Long Parliament, the house overwhelmingly accused Thomas Wentworth, Earl of Strafford, of high treason and other crimes and misdemeanors. Henry Vane the Younger supplied evidence of Strafford's claimed improper use of the army in Ireland, alleging that he had encouraged the King to use his Ireland-raised forces to threaten England into compliance. This evidence was obtained from Vane's father, Henry Vane the Elder, a member of the King's Privy Council, who refused to confirm it in Parliament out of loyalty to Charles. On 10 April 1641, Pym's case collapsed, but Pym made a direct appeal to the Younger Vane to produce a copy of the notes from the King's Privy Council, discovered by the Younger Vane and secretly turned over to Pym, to the great anguish of the Elder Vane. These notes contained evidence that Strafford had told the King, \"Sir, you have done your duty, and your subjects have failed in theirs; and therefore you are absolved from the rules of government, and may supply yourself by extraordinary ways; you have an army in Ireland, with which you may reduce the kingdom.\"\nPym immediately launched a Bill of Attainder stating Strafford's guilt and demanding that he be put to death. Unlike a guilty verdict in a court case, attainder did not require a legal burden of proof to be met, but it did require the king's approval. Charles, however, guaranteed Strafford that he would not sign the attainder, without which the bill could not be passed. Furthermore, the Lords opposed the severity of a death sentence on Strafford. Yet increased tensions and a plot in the army to support Strafford began to sway the issue.\nOn 21 April, the Commons passed the Bill (204 in favour, 59 opposed, and 250 abstained), and the Lords acquiesced. Charles, still incensed over the Commons' handling of Buckingham, refused his assent. Strafford himself, hoping to head off the war he saw looming, wrote to the king and asked him to reconsider. Charles, fearing for the safety of his family, signed on 10 May. Strafford was beheaded two days later. In the meantime, both Parliament and the King agreed to an independent investigation into the king's involvement in Strafford's plot.\nThe Long Parliament then passed the Triennial Act 1640, also known as the Dissolution Act, in May 1641, to which royal assent was readily granted. The Triennial Act required Parliament to be summoned at least once in three years. When the king failed to issue a proper summons, the members could assemble on their own. This act also forbade ship money without Parliament's consent, fines in distraint of knighthood, and forced loans. Monopolies were cut back sharply, the courts of the Star Chamber and High Commission abolished by the Habeas Corpus Act 1640, and the Triennial Act respectively.\nAll remaining forms of taxation were legalised and regulated by the Tonnage and Poundage Act 1640. On 3 May, Parliament decreed The Protestation, attacking the 'wicked counsels' of Charles's government, whereby those who signed the petition undertook to defend 'the true reformed religion', Parliament, and the king's person, honour and estate. Throughout May, the House of Commons launched several bills attacking bishops and Episcopalianism in general, each time defeated in the Lords.\nCharles and his Parliament hoped that the execution of Strafford and the Protestation would end the drift towards war, but in fact, they encouraged it. Charles and his supporters continued to resent Parliament's demands, and Parliamentarians continued to suspect Charles of wanting to impose episcopalianism and unfettered royal rule by military force. Within months, the Irish Catholics, fearing a resurgence of Protestant power, struck first, and all Ireland soon descended into chaos. Rumours circulated that the King supported the Irish, and Puritan members of the Commons soon started murmuring that this exemplified the fate that Charles had in store for them all.\nOn 4 January 1642, Charles, followed by 400 soldiers, entered the House of Commons and attempted to arrest five members on a charge of treason. The members had learned that he was coming and escaped. Charles not only failed to arrest them but turned more people against him.\nLocal grievances.\nIn the summer of 1642, these national troubles helped to polarise opinion, ending indecision about which side to support or what action to take. Opposition to Charles also arose from many local grievances. For example, imposed drainage schemes in The Fens disrupted the livelihood of thousands after the King awarded a number of drainage contracts. Many saw the King as indifferent to public welfare, and this played a role in bringing much of eastern England into the Parliamentarian camp. This sentiment brought with it such people as the Earl of Manchester and Oliver Cromwell, each a notable wartime adversary of the King. Conversely, one of the leading drainage contractors, the Earl of Lindsey, was to die fighting for the King at the Battle of Edgehill.\nFirst English Civil War (1642\u20131646).\nIn early January 1642, a few days after failing to capture five members of the House of Commons, Charles feared for the safety of his family and retinue and left the London area for the north country.\nFurther frequent negotiations by letter between the King and the Long Parliament, through to early summer, proved fruitless. On 1 June 1642 the English Lords and Commons approved a list of proposals known as the Nineteen Propositions. In these demands, the Parliament sought a larger share of power in the governance of the kingdom. Before the end of the month the King rejected the Propositions.\nAs the summer progressed, cities and towns declared their sympathies for one faction or the other: for example, the garrison of Portsmouth commanded by Sir George Goring declared for the King, but when Charles tried to acquire arms from Kingston upon Hull, the weaponry depository used in the previous Scottish campaigns, Sir John Hotham, the military governor appointed by Parliament in January, refused to let Charles enter the town, and when Charles returned with more men later, Hotham drove them off. Charles issued a warrant for Hotham's arrest as a traitor but was powerless to enforce it. Throughout the summer, tensions rose and there was brawling in several places, the first death from the conflict taking place in Manchester.\nAt the outset of the conflict, much of the country remained neutral, though the Royal Navy and most English cities favoured Parliament, while the King found marked support in rural communities. The war quickly spread and eventually involved every level of society. Many areas attempted to remain neutral. Some formed bands of Clubmen to protect their localities from the worst excesses of the armies of both sides, but most found it impossible to withstand both King and Parliament.\nOn one side, the King and his supporters fought for what they saw as traditional government in church and state. On the other, most Parliamentarians initially took up arms to defend what they viewed as a traditional balance of government in church and state, and which they felt had been undermined by bad advice the King received from his advisers \u2014 such as George Villiers, Duke of Buckingham \u2014 and during his Personal Rule (the \"Eleven Years' Tyranny\"). The views of the members of Parliament ranged from unquestioning support of the King \u2013 at one point during the First Civil War, more members of the Commons and Lords gathered in the King's Oxford Parliament than at Westminster \u2014 through to radicals who sought major reforms in religious independence and redistribution of power at a national level.\nAfter the debacle at Hull, Charles moved on to Nottingham, raising the royal standard there on 22 August 1642. At the time, Charles had with him about 2,000 cavalry and a small number of Yorkshire infantrymen, and using the archaic system of a Commission of Array, his supporters started to build a larger army around the standard. Charles moved in a westerly direction, first to Stafford, then on to Shrewsbury, as support for his cause seemed particularly strong in the Severn valley area and in North Wales. While passing through Wellington, he declared in what became known as the \"Wellington Declaration\" that he would uphold the \"Protestant religion, the laws of England, and the liberty of Parliament\".\nThe Parliamentarians who opposed the King did not remain passive in this pre-war period. As in Hull, they took measures to secure strategic towns and cities by appointing to office men sympathetic to their cause. On 9 June they voted to raise an army of 10,000 volunteers and appointed Robert Devereux, 3rd Earl of Essex its commander three days later. He received orders \"to rescue His Majesty's person, and the persons of the Prince [of Wales] and the Duke of York [James II] out of the hands of those desperate persons who were about them.\" The Lords Lieutenant whom Parliament appointed used the Militia Ordinance to order the militia to join Essex's army.\nTwo weeks after the King had raised his standard at Nottingham, Essex led his army north towards Northampton, picking up support along the way (including a detachment of Huntingdonshire cavalry raised and commanded by Oliver Cromwell). By mid-September Essex's forces had grown to 21,000 infantry and 4,200 cavalry and dragoons. On 14 September he moved his army to Coventry and then to the north of the Cotswolds, a strategy that placed it between the Royalists and London. With the size of both armies now in the tens of thousands and only Worcestershire between them, it was inevitable that cavalry reconnaissance units would meet sooner or later. This happened in the first major skirmish of the Civil War, when a troop of about 1,000 Royalist cavalry under Prince Rupert, a German nephew of the King and one of the outstanding cavalry commanders of the war, defeated a Parliamentary cavalry detachment under Colonel John Brown at the Battle of Powick Bridge, which crossed the River Teme close to Worcester.\nRupert withdrew to Shrewsbury, where a council-of-war discussed two courses of action: whether to advance towards Essex's new position near Worcester, or march down the now open road towards London. The Council decided on the London route, but not to avoid a battle, for the Royalist generals wanted to fight Essex before he grew too strong, and the temper of both sides made it impossible to postpone the decision. In the Earl of Clarendon's words, \"it was considered more counsellable to march towards London, it being morally sure that the earl of Essex would put himself in their way.\" Hence, the army left Shrewsbury on 12 October, gaining two days' start on the enemy, and moved south-east. This had the desired effect of forcing Essex to move to intercept them.\nThe first pitched battle of the war, at Edgehill on 23 October 1642, proved inconclusive, both Royalists and Parliamentarians claiming victory. The second field action, the stand-off at Turnham Green, saw Charles forced to withdraw to Oxford, which would serve as his base for the rest of the war.\nIn 1643, Royalist forces won at Adwalton Moor, gaining control of most of Yorkshire. In the Midlands, a Parliamentary force under Sir John Gell besieged and captured the cathedral city of Lichfield, after the death of the original commander, Lord Brooke. This group then joined forces with Sir William Brereton at the inconclusive Battle of Hopton Heath (19 March 1643), where the Royalist commander, the Earl of Northampton, was killed. John Hampden died after being wounded in the Battle of Chalgrove Field (18 June 1643). Subsequent battles in the west of England at Lansdowne and Roundway Down also went to the Royalists. Prince Rupert could then take Bristol. In the same year, however, Cromwell formed his troop of \"Ironsides\", a disciplined unit that demonstrated his military leadership ability. With their assistance he won a victory at the Battle of Gainsborough in July.\nAt this stage, from 7 to 9 August 1643, there were some popular demonstrations in London \u2013 both for and against war. They were protesting at Westminster. A peace demonstration by London women, which turned violent, was suppressed; the women were beaten and fired upon with live ammunition, leaving several dead. Many were arrested and incarcerated in Bridewell and other prisons. After these August events, the Venetian ambassador in England reported to the doge that the London government took considerable measures to stifle dissent.\nIn general, the early part of the war went well for the Royalists. The turning point came in the late summer and early autumn of 1643, when the Earl of Essex's army forced the king to raise the Siege of Gloucester and then brushed the Royalists aside at the First Battle of Newbury (20 September 1643), to return triumphantly to London. Parliamentarian forces led by the Earl of Manchester besieged the port of King's Lynn, Norfolk, which under Sir Hamon L'Estrange held out until September. Other forces won the Battle of Winceby, giving them control of Lincoln. Political manoeuvring to gain an advantage in numbers led Charles to negotiate a ceasefire in Ireland, freeing up English troops to fight on the Royalist side in England, while Parliament offered concessions to the Scots in return for aid and assistance.\nHelped by the Scots, Parliament won at Marston Moor (2 July 1644), gaining York and the north of England. Cromwell's conduct in the battle proved decisive, and showed his potential as a political and as an important military leader. The defeat at the Battle of Lostwithiel in Cornwall, however, marked a serious reverse for Parliament in the south-west of England. Subsequent fighting around Newbury (27 October 1644), though tactically indecisive, strategically gave another check to Parliament.\nIn 1645, Parliament reaffirmed its determination to fight the war to a finish. It passed the Self-denying Ordinance, by which all members of either House of Parliament laid down their commands and re-organised its main forces into the New Model Army, under the command of Sir Thomas Fairfax, with Cromwell as his second-in-command and Lieutenant-General of Horse. In two decisive engagements \u2013 the Battle of Naseby on 14 June and the Battle of Langport on 10 July \u2013 the Parliamentarians effectively destroyed Charles's armies.\nIn the remains of his English realm, Charles tried to recover a stable base of support by consolidating the Midlands. He began to form an axis between Oxford and Newark-on-Trent in Nottinghamshire. These towns had become fortresses and showed more reliable loyalty to him than others. He took Leicester, which lies between them, but found his resources exhausted. Having little opportunity to replenish them, in May 1646 he sought shelter with a Presbyterian Scottish army at Southwell in Nottinghamshire. Charles was eventually handed over to the English Parliament by the Scots and imprisoned. This marked the end of the First English Civil War.\nInterbellum.\nThe end of the First Civil War, in 1646, left a partial power vacuum in which any combination of the three English factions, Royalists, Independents of the New Model Army (\"the Army\"), and Presbyterians of the English Parliament, as well as the Scottish Parliament allied with the Scottish Presbyterians (the \"Kirk\"), could prove strong enough to dominate the rest. Armed political Royalism was at an end, but despite being a prisoner, Charles I was considered by himself and his opponents (almost to the last) as necessary to ensure the success of whichever group could come to terms with him. Thus, he passed successively into the hands of the Scots, the Parliament and the Army.\nThe King attempted to reverse the verdict of arms by \"coquetting\" with each in turn. On 3 June 1647, Cornet George Joyce of Sir Thomas Fairfax's cavalry seized the King for the New Model Army; following the seizure, the English Presbyterians and the Scots began to prepare for a fresh civil war, less than two years after the conclusion of the first, this time against \"Independency\" as embodied in the Army. After making use of the Army, its opponents attempted to disband it, send it onward to foreign service, and to cut off its arrears of pay.\nThe result was that the Army leadership was exasperated beyond control, and, remembering not merely its grievances but also the principle for which the Army had fought, it soon became the most powerful political force in the realm. From 1646 to 1648 the breach between Army and Parliament widened day by day, until finally the Presbyterian party, combined with the Scots and the remaining Royalists, felt itself strong enough to begin a Second Civil War.\nSecond English Civil War (1648\u20131649).\nCharles I took advantage of the deflection of attention away from himself to negotiate on 28 December 1647 a secret treaty with the Scots, again promising church reform. Under the agreement, called the \"Engagement\", the Scots undertook to invade England on Charles's behalf and restore him to the throne.\nA series of Royalist uprisings throughout England and a Scottish invasion occurred in the summer of 1648. Forces loyal to Parliament put down most of those in England after little more than a skirmish, but uprisings in Kent, Essex and Cumberland, the rebellion in Wales, and the Scottish invasion involved pitched battles and prolonged sieges.\nIn the spring of 1649, unpaid Parliamentarian troops in Wales changed sides. Colonel Thomas Horton defeated the Royalist rebels at the Battle of St Fagans (8 May) and the rebel leaders surrendered to Cromwell on 11 July after a protracted two-month siege of Pembroke. Sir Thomas Fairfax defeated a Royalist uprising in Kent at the Battle of Maidstone on 1 June. Fairfax, after his success at Maidstone and the pacification of Kent, turned north to reduce Essex, where, under an ardent, experienced and popular leader, Sir Charles Lucas, the Royalists had taken up arms in great numbers. Fairfax soon drove the enemy into Colchester, but his first attack on the town met with a repulse and he had to settle down to a long siege.\nIn the North of England, Major-General John Lambert fought a successful campaign against several Royalist uprisings, the largest being that of Sir Marmaduke Langdale in Cumberland. Thanks to Lambert's successes, the Scottish commander, the Duke of Hamilton, had to take a western route through Carlisle in his pro-Royalist Scottish invasion of England. The Parliamentarians under Cromwell engaged the Scots at the Battle of Preston (17\u201319 August). The battle took place largely at Walton-le-Dale near Preston, Lancashire, and resulted in a victory for Cromwell's troops over the Royalists and Scots commanded by Hamilton. This victory marked the end of the Second English Civil War.\nNearly all the Royalists who had fought in the First Civil War had given their word not to bear arms against Parliament, and many, like Lord Astley, were therefore bound by oath not to take any part in the second conflict. So, the victors in the Second Civil War showed little mercy to those who had brought war into the land again. On the evening of the surrender of Colchester, Parliamentarians had Sir Charles Lucas and Sir George Lisle shot. Parliamentary authorities sentenced the leaders of the Welsh rebels, Major-General Rowland Laugharne, Colonel John Poyer and Colonel Rice Powel to death, but executed only Poyer (25 April 1649), having selected him by lot. Of five prominent Royalist peers who had fallen into Parliamentary hands, three \u2013 the Duke of Hamilton, the Earl of Holland, and Lord Capel, one of the Colchester prisoners and a man of high character \u2013 were beheaded at Westminster on 9 March.\nTrial of Charles I for treason.\nCharles's secret pacts and encouragement of supporters to break their parole caused Parliament to debate whether to return the King to power at all. Those who still supported Charles's place on the throne, such as the army leader and moderate Fairfax, tried again to negotiate with him. The Army, furious that Parliament continued to countenance Charles as a ruler, then marched on Parliament and conducted \"Pride's Purge\", named after the commanding officer of the operation, Thomas Pride, in December 1648.\nTroops arrested 45 members and kept 146 out of the chamber. They allowed only 75 members in, and then only at the Army's bidding. This Rump Parliament received orders to set up, in the name of the people of England, a High Court of Justice for the trial of Charles I for treason. Fairfax, a constitutional monarchist, declined to have anything to do with the trial. He resigned as head of the army, so clearing Cromwell's road to power.\nAt the end of the trial the 59 Commissioners (judges) found Charles I guilty of high treason as a \"tyrant, traitor, murderer and public enemy\". His beheading took place on a scaffold in front of the Banqueting House of the Palace of Whitehall on 30 January 1649. After the Restoration in 1660, nine of the surviving regicides not living in exile were executed and most others sentenced to life imprisonment.\nAfter the regicide, Charles, Prince of Wales as the eldest son was publicly proclaimed King Charles II in the Royal Square of St. Helier, Jersey, on 17 February 1649 (after a first such proclamation in Edinburgh on 5 February 1649). It took longer for the news to reach the trans-Atlantic colonies, with the Somers Isles (also known as Bermuda) becoming the first to proclaim Charles II King on 5 July 1649.\nThird English Civil War (1649\u20131651).\nIreland.\nIreland had undergone continual war since the rebellion of 1641, with most of the island controlled by the Irish Confederates. Increasingly threatened by the armies of the English Parliament after Charles I's arrest in 1648, the Confederates signed a treaty of alliance with the English Royalists. The joint Royalist and Confederate forces under the Duke of Ormonde tried to eliminate the Parliamentary army holding Dublin by laying siege in 1649, but their opponents routed them at the Battle of Rathmines (2 August 1649). Admiral Robert Blake, a former Member of Parliament, had blockaded Prince Rupert's fleet in Kinsale, enabling Oliver Cromwell to land at Dublin on 15 August 1649 with an army to quell the Royalist alliance.\nCromwell's suppression of the Royalists in Ireland in 1649 is still remembered by many Irish people. After the Siege of Drogheda, the massacre of nearly 3,500 people \u2013 around 2,700 Royalist soldiers and 700 others, including civilians, prisoners, and Catholic priests (all of whom Cromwell claimed had carried arms) \u2013 became one of the historical memories that has driven Irish-English and Catholic-Protestant strife during the last three centuries. The Parliamentarian conquest of Ireland ground on for another four years until 1653, when the last Irish Confederate and Royalist troops surrendered. In the wake of the conquest, the victors confiscated almost all Irish Catholic-owned land and distributed it to Parliament's creditors, to Parliamentary soldiers who served in Ireland, and to English who had settled there before the war.\nScotland.\nThe execution of Charles I altered the dynamics of the Civil War in Scotland, which had raged between Royalists and Covenanters since 1644. By 1649, the struggle had left the Royalists there in disarray and their erstwhile leader, the Marquess of Montrose, had gone into exile. At first, Charles II encouraged Montrose to raise a Highland army to fight on the Royalist side. When the Scottish Covenanters, who did not agree with the execution of Charles I and who feared for the future of Presbyterianism under the new Commonwealth, offered him the crown of Scotland, Charles abandoned Montrose to his enemies.\nMontrose, who had raised a mercenary force in Norway, had already landed and could not abandon the fight. He did not succeed in raising many Highland clans and the Covenanters defeated his army at the Battle of Carbisdale in Ross-shire on 27 April 1650. The victors captured Montrose shortly afterwards and took him to Edinburgh. On 20 May the Scottish Parliament sentenced him to death and had him hanged the next day.\nCharles II landed in Scotland at Garmouth in Morayshire on 23 June 1650 and signed the 1638 National Covenant and the 1643 Solemn League and Covenant shortly after coming ashore. With his original Scottish Royalist followers and his new Covenanter allies, Charles II became the greatest threat facing the new English republic. In response to the threat, Cromwell left some of his lieutenants in Ireland to continue the suppression of the Irish Royalists and returned to England.\nHe arrived in Scotland on 22 July 1650 and proceeded to lay siege to Edinburgh. By the end of August, disease and a shortage of supplies had reduced his army, and he had to order a retreat towards his base at Dunbar. A Scottish army under the command of David Leslie tried to block the retreat, but Cromwell defeated them at the Battle of Dunbar on 3 September. Cromwell's army then took Edinburgh, and by the end of the year his army had occupied much of southern Scotland.\nIn July 1651, Cromwell's forces crossed the Firth of Forth into Fife and defeated the Scots at the Battle of Inverkeithing (20 July 1651). The New Model Army advanced towards Perth, which allowed Charles, at the head of the Scottish army, to move south into England. Cromwell followed Charles into England, leaving George Monck to finish the campaign in Scotland. Monck took Stirling on 14 August and Dundee on 1 September. The next year, 1652, saw a mopping up of the remnants of Royalist resistance, and under the terms of the \"Tender of Union\", the Scots received 30 seats in a united Parliament in London, with General Monck as the military governor of Scotland.\nEngland.\nAlthough Cromwell's New Model Army had defeated a Scottish army at Dunbar, Cromwell could not prevent Charles II from marching from Scotland deep into England at the head of another Royalist army. They marched to the west of England where English Royalist sympathies were strongest, but although some English Royalists joined the army, they were far fewer in number than Charles and his Scottish supporters had hoped. Cromwell finally engaged and defeated the new Scottish king at Worcester on 3 September 1651.\nWales.\nFor several reasons most of Wales was not as engaged in the English Civil Wars to the same degree as other parts of the British Isles. Wales was isolated from England, both physically and linguistically, so the Welsh were not as much engaged as England in the issues between the king and Parliament.\u00a0 The English considered Wales a remote land, with Welsh, not English, as the primary language. Since England had formally assimilated Wales into the kingdom, starting in 1536 formal agreements had been put in place under Henry VIII and continued under Charles I that allowed for Welsh local administrative authority and economic control, which allowed the Welsh to function to some degree independently.\u00a0 Another factor was the Puritan religion, which played a major role in the English Civil Wars but was not widely practised throughout Wales.\u00a0 Welsh Puritan religious dominance was found in northeast Wales near Wrexham, Denbighshire, and an indirect Puritan influence found along the southwestern coast near Haverfordwest, Pembroke, and Tenby due to a combination of a strong influence by the third earl of Essex and their strong trade relations with Bristol, England, a fervent Puritan stronghold. In addition, Wales comparatively more rural in character than England at this time, and thereby lacking the large number of urban settlements home to mercantile, trade, and manufacturing interests who were a bulwark of support for both Puritanism and eventually the Parliamentarian cause.\nMany of the key Welsh Civil Wars leaders were from the gentry class holding Royalist sympathies, or from the Church. Those Welsh who did participate in the Civil Wars battles were underequipped, underfed, and not properly trained for warfare.\u00a0 The majority of Welsh followed the Protestant faith with a religious perspective that differed from the English puritan zeal. They were also leery of the Irish Catholics invading Wales.\u00a0 The Welsh also did not want to lose what they had, for the gentry were aware of the destruction the Thirty Years' War caused in Europe.\nMost of those English Civil War battles where Wales was impacted occurred near the border with England and in south Wales. Some of the more significant engagements were:\nIn addition to the Civil Wars' impact on the monarchy and the changes in national leadership, unexpected outcomes of the English Civil Wars to Wales included a significant degradation of the country's road system, a deterioration of government administrative functions to the general population, destruction of castles with only the remnants of them remaining, and the desecration of churches.\nImmediate aftermath.\nAfter the Royalist defeat at Worcester, Charles II escaped to France via safe houses and an oak tree. Parliament was left in \"de facto\" control of England. Resistance continued for a time in Ireland and Scotland, but with the pacification of England, resistance elsewhere did not threaten the military supremacy of the New Model Army and its Parliamentary paymasters.\nPolitical control.\nDuring the Wars, the Parliamentarians established a number of successive committees to oversee the war effort. The first, the Committee of Safety set up in July 1642, comprised 15 members of Parliament. After the Anglo-Scottish alliance against the Royalists, the Committee of Both Kingdoms replaced the Committee of Safety between 1644 and 1648. Parliament dissolved the Committee of Both Kingdoms when the alliance ended, but its English members continued to meet as the Derby House Committee. A second Committee of Safety then replaced it.\nEpiscopacy.\nDuring the English Civil War, the role of bishops as wielders of political power and upholders of the established church became a matter of heated political controversy. John Calvin of Geneva had formulated a doctrine of Presbyterianism, which held that the offices of \"presbyter\" and \"episkopos\" in the New Testament were identical; he rejected the doctrine of apostolic succession. Calvin's follower John Knox brought Presbyterianism to Scotland when the Scottish church was reformed in 1560. In practice, Presbyterianism meant that committees of lay elders had a substantial voice in church government, as opposed to merely being subjects to a ruling hierarchy.\nThis vision of at least partial democracy in ecclesiology paralleled the struggles between Parliament and the King. A body within the Puritan movement in the Church of England sought to abolish the office of bishop and remake the Church of England along Presbyterian lines. The Martin Marprelate tracts (1588\u20131589), applying the pejorative name of \"prelacy\" to the church hierarchy, attacked the office of bishop with satire that deeply offended Elizabeth I and her Archbishop of Canterbury John Whitgift. The vestments controversy also related to this movement, seeking further reductions in church ceremony, and labelling the use of elaborate vestments as \"unedifying\" and even idolatrous.\nKing James I, reacting against the perceived contumacy of his Presbyterian Scottish subjects, adopted \"No Bishop, no King\" as a slogan. He tied the hierarchical authority of the bishop to the absolute authority he sought as King and viewed attacks on the authority of the bishops as attacks on his authority. Matters came to a head when Charles I appointed William Laud as Archbishop of Canterbury. Laud aggressively attacked the Presbyterian movement and sought to impose the full Book of Common Prayer. The controversy eventually led to Laud's impeachment for treason by a bill of attainder in 1645 and subsequent execution. Charles also attempted to impose episcopacy on Scotland. The Scots' violent rejection of bishops and liturgical worship sparked the Bishops' Wars in 1639\u20131640.\nDuring the height of Puritan power under the Commonwealth and the Protectorate, episcopacy was formally abolished in the Church of England on 9 October 1646. The Church of England remained Presbyterian until the Restoration of the monarchy.\nEnglish overseas possessions.\nDuring the English Civil War, the English overseas possessions became highly involved. In the Channel Islands, the island of Jersey and Castle Cornet in Guernsey supported the King until a surrender with honour in December 1651.\nAlthough the newer, Puritan settlements in North America, notably Massachusetts, were dominated by Parliamentarians, the older colonies sided with the Crown. Friction between Royalists and Puritans in Maryland came to a head in the Battle of the Severn. The Virginia Company's settlements, Bermuda and Virginia, as well as Antigua and Barbados, were conspicuous in their loyalty to the Crown. Bermuda's Independent Puritans were expelled, settling the Bahamas under William Sayle as the Eleutheran Adventurers. Parliament passed An Act for prohibiting Trade with the Barbadoes, Virginia, Bermuda and Antego in October 1650, which stated that:\nThe Act also authorised Parliamentary privateers to act against English vessels trading with the rebellious colonies:\nFar to the North, Bermuda's regiment of Militia and its coastal batteries prepared to resist an invasion that never came. Built-up inside the natural defence of a nearly impassable barrier reef, to fend off the might of Spain, these defences would have been a formidable obstacle for the Parliamentary fleet sent in 1651 under the command of Admiral Sir George Ayscue to subdue the trans-Atlantic colonies, but after the fall of Barbados, the Bermudians made a separate peace that respected the internal status quo. The Parliament of Bermuda avoided the Parliament of England's fate during The Protectorate, becoming one of the oldest continuous legislatures in the world.\nVirginia's population swelled with Cavaliers during and after the English Civil War. Even so, Virginia Puritan Richard Bennett was made Governor answering to Cromwell in 1652, followed by two more nominal \"Commonwealth Governors\". The loyalty of Virginia's Cavaliers to the Crown was rewarded after the 1660 Restoration of the Monarchy when Charles II dubbed it the \"Old Dominion\".\nCasualties.\nFigures for casualties during this period are unreliable. Some attempt has been made to provide rough estimates.\nIn England, a conservative estimate is that roughly 100,000 people died from war-related disease during the three civil wars. Historical records count 84,830 combat dead from the wars themselves. Counting in accidents and the two Bishops' wars, an estimate of 190,000 dead is achieved, out of a total population of about five million. It is estimated that from 1638 to 1651, 15%\u201320% of all adult males in England and Wales served in the military. Around 4% of the total population died from war-related causes, compared to 2.23% in the First World War.\nAs was typical for the era, most combat deaths occurred in minor skirmishes rather than large, pitched battles. There were a total of 645 engagements throughout the wars: 588 of these involved fewer than 250 casualties in total, with these 588 accounting for 39,838 fatalities (average count of less than 68) or nearly half of the conflict's combat deaths. There were only 9 major pitched battles (at least 1,000 fatalities) which in total accounted for 15% of casualties.\nAn anecdotal example of how high casualties in England may have been perceived is to be found in the posthumously published writing (generally titled \"The History of Myddle\"), by a Shropshire man, Richard Gough (lived 1635\u20131723) of Myddle near Shrewsbury, who, writing in about 1701, commented of men from his rural home parish who joined the Royalist forces: \"And out of these three townes [\"sic\" - ie townships], Myddle, Marton and Newton, there went noe less than twenty men, of which number thirteen were kill'd in the warrs\". After listing those he recalled did not return home, four of whose exact fates were unknown, he concluded: \"And if soe many dyed out of these 3 townes [townships] wee may reasonably guess that many thousands dyed in England in that warre.\"\nFigures for Scotland are less reliable and should be treated with caution. Casualties include the deaths of prisoners-of-war in conditions that accelerated their deaths, with estimates of 10,000 prisoners not surviving or not returning home (8,000 captured during and immediately after the Battle of Worcester were deported to New England, Bermuda and the West Indies to work for landowners as indentured labourers). There are no figures to calculate how many died from war-related diseases, but if the same ratio of disease to battle deaths from English figures is applied to the Scottish figures, a not unreasonable estimate of 60,000 people is achieved, from a population of about one million.\nFigures for Ireland are described as \"miracles of conjecture\". Certainly, the devastation inflicted on Ireland was massive, with the best estimate provided by Sir William Petty, the father of English demography. Petty estimated that 112,000 Protestants and 504,000 Catholics were killed through plague, war and famine, giving an estimated total of 616,000 dead, out of a pre-war population of about one and a half million. Although Petty's figures are the best available, they are still acknowledged as tentative; they do not include an estimated 40,000 driven into exile, some of whom served as soldiers in European continental armies, while others were sold as indentured servants to New England and the West Indies. Many of those sold to landowners in New England eventually prospered, but many sold to landowners in the West Indies were worked to death.\nThese estimates indicate that England suffered a 4 per cent loss of population, Scotland a loss of 6 per cent, while Ireland suffered a loss of 41 per cent of its population. Putting these numbers into the context of other catastrophes helps to understand the devastation of Ireland in particular. The Great Famine of 1845\u20131852 resulted in a loss of 16 per cent of the population, while during the Soviet famine and Holodomor of 1932\u201333 the population of the Soviet Ukraine fell by 14 per cent.\nPopular gains.\nOrdinary people took advantage of the dislocation of civil society in the 1640s to gain personal advantages. The contemporary guild democracy movement won its greatest successes among London's transport workers. Rural communities seized timber and other resources on the sequestrated estates of Royalists and Catholics, and on the estates of the royal family and church hierarchy. Some communities improved their conditions of tenure on such estates.\nThe old \"status quo\" began a retrenchment after the end of the First Civil War in 1646, and more especially after the Restoration in 1660, but some gains were long-term. The democratic element introduced into the watermen's company in 1642, for example, survived with vicissitudes until 1827.\nAftermath.\nThe wars left England, Scotland, and Ireland among the few countries in Europe without a monarch. In the wake of victory, many of the ideals (and many idealists) became sidelined. The republican government of the Commonwealth of England ruled England (and later all of Scotland and Ireland) from 1649 to 1653 and from 1659 to 1660. Between the two periods, and due to in-fighting among various factions in Parliament, Oliver Cromwell ruled over the Protectorate as Lord Protector (effectively a military dictator) until his death in 1658.\nOn Oliver Cromwell's death, his son Richard became Lord Protector, but the Army had little confidence in him. After seven months the Army removed Richard. In May 1659 it re-installed the Rump. Military force shortly afterward dissolved this as well. After the second dissolution of the Rump, in October 1659, the prospect of a total descent into anarchy loomed, as the Army's pretense of unity dissolved into factions.\nInto this atmosphere General George Monck, Governor of Scotland under the Cromwells, marched south with his army from Scotland. On 4 April 1660, in the Declaration of Breda, Charles II made known the conditions of his acceptance of the Crown of England. Monck organised the Convention Parliament, which met for the first time on 25 April 1660.\nOn 8 May 1660, it declared that Charles II had reigned as the lawful monarch since the execution of Charles I in January 1649. Charles returned from exile on 23 May 1660. On 29 May 1660, the populace in London acclaimed him as king. His coronation took place at Westminster Abbey on 23 April 1661. These events became known as the \"Restoration\".\nAlthough the monarchy was restored, it was still with the consent of Parliament. So the civil wars effectively set England and Scotland on course towards a parliamentary monarchy form of government. The outcome of this system was that the future Kingdom of Great Britain, formed in 1707 under the Acts of Union, managed to forestall the kind of revolution typical of European republican movements which generally resulted in total abolition of their monarchies. Thus, the United Kingdom was spared the wave of revolutions that occurred in Europe in the 1840s. Specifically, future monarchs became wary of pushing Parliament too hard, and Parliament effectively chose the line of royal succession in 1688 with the Glorious Revolution.\nHistorical interpretations.\nHobbes' \"Behemoth\".\nThomas Hobbes gave an early historical account of the English Civil War in his \"Behemoth\", written in 1668 and published in 1681. He assessed the causes of the war to be the conflicting political doctrines of the time. \"Behemoth\" offered a uniquely historical and philosophical approach to naming the catalysts for the war. It also attempted to explain why Charles I could not hold his throne and maintain peace in his kingdom.\nHobbes analysed the following aspects of English thought during the war: the opinions of divinity and politics that spurred rebellion; rhetoric and doctrine used by the rebels against the king; and how opinions about \"taxation, the conscription of soldiers, and military strategy\" affected the outcomes of battles and shifts of sovereignty.\nHobbes attributed the war to the novel theories of intellectuals and divines spread for their own pride of reputation. He held that clerical pretensions had contributed significantly to the troubles \u2014 \"whether those of puritan fundamentalists, papal supremacists or divine right Episcopalians\". Hobbes wanted to abolish the independence of the clergy and bring it under the control of the civil state.\nSome scholars suggest that Hobbes's \"Behemoth\" has not received its due as an academic work, being comparatively overlooked and under-rated in the shadow of the same author's \"Leviathan\". Its scholarly reputation may have suffered because it takes the form of a dialogue, which, while common in philosophy, is rarely adopted by historians. Other factors that hindered its success include Charles II's refusing its publication and Hobbes' lack of empathy with views different from his own.\nWhig and Marxist views.\nIn the early decades of the 20th century, the Whig school was the dominant theoretical view. It explained the Civil War as resulting from centuries of struggle between Parliament (notably the House of Commons) and the Monarchy, with Parliament defending the traditional rights of Englishmen, while the Stuart monarchy continually attempted to expand its right to dictate law arbitrarily. The major Whig historian, S. R. Gardiner, popularised the idea that the English Civil War was a \"Puritan Revolution\" that challenged the repressive Stuart Church and prepared the way for religious toleration. Thus, Puritanism was seen as the natural ally of a people preserving their traditional rights against arbitrary monarchical power.\nThe Whig view was challenged and largely superseded by the Marxist school, which became popular in the 1940s, and saw the English Civil War as a bourgeois revolution. According to Marxist historian Christopher Hill:\nLater views.\nIn the 1970s, revisionist historians challenged both the Whig and the Marxist theories, notably in the 1973 anthology \"The Origins of the English Civil War\" (Conrad Russell ed.). These historians focused on the minutiae of the years immediately before the civil war, returning to the contingency-based historiography of Clarendon's \"History of the Rebellion and Civil Wars in England\". This, it was claimed, demonstrated that patterns of war allegiance did not fit either Whig or Marxist theories. Parliament was not inherently progressive, nor the events of 1640 a precursor for the Glorious Revolution. Many members of the bourgeoisie fought for the King, while many landed aristocrats supported Parliament.\nFrom the 1990s, a number of historians replaced the historical title \"English Civil War\" with \"Wars of the Three Kingdoms\" and \"British Civil Wars\", positing that the civil war in England cannot be understood apart from events in other parts of Britain and Ireland. King Charles I remains crucial, not just as King of England, but through his relationship with the peoples of his other realms. For example, the wars began when Charles forced an Anglican Prayer Book upon Scotland, and when this was met with resistance from the Covenanters, he needed an army to impose his will. However, this need of military funds forced Charles I to call an English Parliament, which was not willing to grant the needed revenue unless he addressed their grievances.\nBy the early 1640s, Charles was left in a state of near-permanent crisis management, confounded by the demands of the various factions. For example, Charles finally made terms with the Covenanters in August 1641, but although this might have weakened the position of the English Parliament, the Irish Rebellion of 1641 broke out in October 1641, largely negating the political advantage he had obtained by relieving himself of the cost of the Scottish invasion.\nA number of revisionist historians such as William M. Lamont regarded the conflict as a religious war, with John Morrill (1993) stating: 'The English Civil War was not the first European revolution: it was the last of the Wars of Religion.' This view has been criticised by various pre-, post- and anti-revisionist historians. Glen Burgess (1998) examined political propaganda written by the Parliamentarian politicians and clerics at the time, noting that many were or may have been motivated by their Puritan religious beliefs to support the war against the 'Catholic' king Charles I, but tried to express and legitimise their opposition and rebellion in terms of a legal revolt against a monarch who had violated crucial constitutional principles and thus had to be overthrown. They even warned their Parliamentarian allies to not make overt use of religious arguments in making their case for war against the king.\nHowever, in some cases it may be argued that they hid their pro-Anglican and anti-Catholic motives behind legal parliance, for example by emphasising that the Church of England was the \"legally established\" religion: 'Seen in this light, the defences of Parliament's war, with their apparent legal-constitutional thrust, are not at all ways of saying that the struggle was not religious. On the contrary, they are ways of saying that it was.' Burgess concluded: '[T]he Civil War left behind it just the sort of evidence that we could reasonably expect a war of religion to leave.'\nRe-enactments.\nTwo large historical societies exist, The Sealed Knot and The English Civil War Society, which regularly re-enact events and battles of the Civil War in full period costume.\nReferences.\nSources.\nAttribution:"}
{"id": "9710", "revid": "11435369", "url": "https://en.wikipedia.org/wiki?curid=9710", "title": "Elementary algebra", "text": "Elementary algebra, also known as high school algebra or college algebra, encompasses the basic concepts of algebra. It is often contrasted with arithmetic: arithmetic deals with specified numbers, whilst algebra introduces variables (quantities without fixed values).\nThis use of variables entails use of algebraic notation and an understanding of the general rules of the operations introduced in arithmetic: addition, subtraction, multiplication, division, etc. Unlike abstract algebra, elementary algebra is not concerned with algebraic structures outside the realm of real and complex numbers.\nIt is typically taught to secondary school students and at introductory college level in the United States, and builds on their understanding of arithmetic. The use of variables to denote quantities allows general relationships between quantities to be formally and concisely expressed, and thus enables solving a broader scope of problems. Many quantitative relationships in science and mathematics are expressed as algebraic equations.\nAlgebraic notation.\nAlgebraic notation describes the rules and conventions for writing mathematical expressions, as well as the terminology used for talking about parts of expressions. For example, the expression formula_1 has the following components:\nA \"coefficient\" is a numerical value, or letter representing a numerical constant, that multiplies a variable (the operator is omitted). A \"term\" is an addend or a summand, a group of coefficients, variables, constants and exponents that may be separated from the other terms by the plus and minus operators. Letters represent variables and constants. By convention, letters at the beginning of the alphabet (e.g. formula_2) are typically used to represent constants, and those toward the end of the alphabet (e.g. formula_3 and ) are used to represent variables. They are usually printed in italics.\nAlgebraic operations work in the same way as arithmetic operations, such as addition, subtraction, multiplication, division and exponentiation, and are applied to algebraic variables and terms. Multiplication symbols are usually omitted, and implied when there is no space between two variables or terms, or when a coefficient is used. For example, formula_4 is written as formula_5, and formula_6 may be written formula_7.\nUsually terms with the highest power (exponent), are written on the left, for example, formula_8 is written to the left of . When a coefficient is one, it is usually omitted (e.g. formula_9 is written formula_8). Likewise when the exponent (power) is one, (e.g. formula_11 is written formula_12). When the exponent is zero, the result is always 1 (e.g. formula_13 is always rewritten to ). However formula_14, being undefined, should not appear in an expression, and care should be taken in simplifying expressions in which variables may appear in exponents.\nAlternative notation.\nOther types of notation are used in algebraic expressions when the required formatting is not available, or can not be implied, such as where only letters and symbols are available. As an illustration of this, while exponents are usually formatted using superscripts, e.g., formula_8, in plain text, and in the TeX mark-up language, the caret symbol represents exponentiation, so formula_8 is written as \"x^2\". This also applies to some programming languages such as Lua. In programming languages such as Ada, Fortran, Perl, Python and Ruby, a double asterisk is used, so formula_8 is written as \"x**2\". Many programming languages and calculators use a single asterisk to represent the multiplication symbol, and it must be explicitly used, for example, formula_12 is written \"3*x\".\nConcepts.\nVariables.\nElementary algebra builds on and extends arithmetic by introducing letters called variables to represent general (non-specified) numbers. This is useful for several reasons.\nSimplifying expressions.\nAlgebraic expressions may be evaluated and simplified, based on the basic properties of arithmetic operations (addition, subtraction, multiplication, division and exponentiation). For example,\nEquations.\nAn equation states that two expressions are equal using the symbol for equality, (the equals sign). One of the best-known equations describes Pythagoras' law relating the length of the sides of a right angle triangle:\nThis equation states that formula_39, representing the square of the length of the side that is the hypotenuse, the side opposite the right angle, is equal to the sum (addition) of the squares of the other two sides whose lengths are represented by and .\nAn equation is the claim that two expressions have the same value and are equal. Some equations are true for all values of the involved variables (such as formula_40); such equations are called identities. Conditional equations are true for only some values of the involved variables, e.g. formula_41 is true only for formula_42 and formula_43. The values of the variables which make the equation true are the solutions of the equation and can be found through equation solving.\nAnother type of equation is inequality. Inequalities are used to show that one side of the equation is greater, or less, than the other. The symbols used for this are: formula_44 where formula_45 represents 'greater than', and formula_46 where formula_47 represents 'less than'. Just like standard equality equations, numbers can be added, subtracted, multiplied or divided. The only exception is that when multiplying or dividing by a negative number, the inequality symbol must be flipped.\nProperties of equality.\nBy definition, equality is an equivalence relation, meaning it is reflexive (i.e. formula_48), symmetric (i.e. if formula_49 then formula_50), and transitive (i.e. if formula_49 and formula_52 then formula_53). It also satisfies the important property that if two symbols are used for equal things, then one symbol can be substituted for the other in any true statement about the first and the statement will remain true. This implies the following properties:\nProperties of inequality.\nThe relations \"less than\" formula_47 and greater than formula_45 have the property of transitivity:\nBy reversing the inequation, formula_47 and formula_45 can be swapped, for example:\nSubstitution.\nSubstitution is replacing the terms in an expression to create a new expression. Substituting 3 for in the expression makes a new expression with meaning . Substituting the terms of a statement makes a new statement. When the original statement is true independently of the values of the terms, the statement created by substitutions is also true. Hence, definitions can be made in symbolic terms and interpreted through substitution: if formula_81 is meant as the definition of formula_82 as the product of with itself, substituting for informs the reader of this statement that formula_83 means . Often it's not known whether the statement is true independently of the values of the terms. And, substitution allows one to derive restrictions on the possible values, or show what conditions the statement holds under. For example, taking the statement , if is substituted with , this implies , which is false, which implies that if then cannot be .\nIf and are integers, rationals, or real numbers, then implies or . Consider . Then, substituting for and for , we learn or . Then we can substitute again, letting and , to show that if then or . Therefore, if , then or ( or ), so implies or or .\nIf the original fact were stated as \" implies or \", then when saying \"consider ,\" we would have a conflict of terms when substituting. Yet the above logic is still valid to show that if then or or if, instead of letting and , one substitutes for and for (and with , substituting for and for ). This shows that substituting for the terms in a statement isn't always the same as letting the terms from the statement equal the substituted terms. In this situation it's clear that if we substitute an expression into the term of the original equation, the substituted does not refer to the in the statement \" implies or .\"\nSolving algebraic equations.\nThe following sections lay out examples of some of the types of algebraic equations that may be encountered.\nLinear equations with one variable.\nLinear equations are so-called, because when they are plotted, they describe a straight line. The simplest equations to solve are linear equations that have only one variable. They contain only constant numbers and a single variable without an exponent. As an example, consider:\nTo solve this kind of equation, the technique is add, subtract, multiply, or divide both sides of the equation by the same number in order to isolate the variable on one side of the equation. Once the variable is isolated, the other side of the equation is the value of the variable. This problem and its solution are as follows:\nIn words: the child is 4 years old.\nThe general form of a linear equation with one variable, can be written as: formula_85\nFollowing the same procedure (i.e. subtract from both sides, and then divide by ), the general solution is given by formula_86\nLinear equations with two variables.\nA linear equation with two variables has many (i.e. an infinite number of) solutions. For example:\nThat cannot be worked out by itself. If the son's age was made known, then there would no longer be two unknowns (variables). The problem then becomes a linear equation with just one variable, that can be solved as described above.\nTo solve a linear equation with two variables (unknowns), requires two related equations. For example, if it was also revealed that:\nNow there are two related linear equations, each with two unknowns, which enables the production of a linear equation with just one variable, by subtracting one from the other (called the elimination method):\nIn other words, the son is aged 12, and since the father 22 years older, he must be 34. In 10 years, the son will be 22, and the father will be twice his age, 44. This problem is illustrated on the associated plot of the equations.\nFor other ways to solve this kind of equations, see below, System of linear equations.\nQuadratic equations.\nA quadratic equation is one which includes a term with an exponent of 2, for example, formula_30, and no term with higher exponent. The name derives from the Latin \"quadrus\", meaning square. In general, a quadratic equation can be expressed in the form formula_92, where is not zero (if it were zero, then the equation would not be quadratic but linear). Because of this a quadratic equation must contain the term formula_93, which is known as the quadratic term. Hence formula_94, and so we may divide by and rearrange the equation into the standard form\nwhere formula_96 and formula_97. Solving this, by a process known as completing the square, leads to the quadratic formula\nwhere the symbol \"\u00b1\" indicates that both\nare solutions of the quadratic equation.\nQuadratic equations can also be solved using factorization (the reverse process of which is expansion, but for two linear terms is sometimes denoted foiling). As an example of factoring:\nwhich is the same thing as\nIt follows from the zero-product property that either formula_102 or formula_103 are the solutions, since precisely one of the factors must be equal to zero. All quadratic equations will have two solutions in the complex number system, but need not have any in the real number system. For example,\nhas no real number solution since no real number squared equals \u22121.\nSometimes a quadratic equation has a root of multiplicity 2, such as:\nFor this equation, \u22121 is a root of multiplicity 2. This means \u22121 appears twice, since the equation can be rewritten in factored form as\nComplex numbers.\nAll quadratic equations have exactly two solutions in complex numbers (but they may be equal to each other), a category that includes real numbers, imaginary numbers, and sums of real and imaginary numbers. Complex numbers first arise in the teaching of quadratic equations and the quadratic formula. For example, the quadratic equation\nhas solutions\nSince formula_109 is not any real number, both of these solutions for \"x\" are complex numbers.\nExponential and logarithmic equations.\nAn exponential equation is one which has the form formula_110 for formula_111, which has solution\nwhen formula_113. Elementary algebraic techniques are used to rewrite a given equation in the above way before arriving at the solution. For example, if\nthen, by subtracting 1 from both sides of the equation, and then dividing both sides by 3 we obtain\nwhence\nor\nA logarithmic equation is an equation of the form formula_118 for formula_111, which has solution\nFor example, if\nthen, by adding 2 to both sides of the equation, followed by dividing both sides by 4, we get\nwhence\nfrom which we obtain\nRadical equations.\nA radical equation is one that includes a radical sign, which includes square roots, formula_125 cube roots, formula_126, and \"n\"th roots, formula_127. Recall that an \"n\"th root can be rewritten in exponential format, so that formula_127 is equivalent to formula_129. Combined with regular exponents (powers), then formula_130 (the square root of cubed), can be rewritten as formula_131. So a common form of a radical equation is formula_132 (equivalent to formula_133) where and are integers. It has real solution(s):\nFor example, if:\nthen\nand thus \nSystem of linear equations.\nThere are different methods to solve a system of linear equations with two variables.\nElimination method.\nAn example of solving a system of linear equations is by using the elimination method:\nMultiplying the terms in the second equation by 2:\nAdding the two equations together to get:\nwhich simplifies to\nSince the fact that formula_102 is known, it is then possible to deduce that formula_143 by either of the original two equations (by using \"2\" instead of ) The full solution to this problem is then\nThis is not the only way to solve this specific system; could have been resolved before .\nSubstitution method.\nAnother way of solving the same system of linear equations is by substitution.\nAn equivalent for can be deduced by using one of the two equations. Using the second equation:\nSubtracting formula_147 from each side of the equation:\nand multiplying by \u22121:\nUsing this value in the first equation in the original system:\nAdding \"2\" on each side of the equation:\nwhich simplifies to\nUsing this value in one of the equations, the same solution as in the previous method is obtained.\nThis is not the only way to solve this specific system; in this case as well, could have been solved before .\nOther types of systems of linear equations.\nInconsistent systems.\nIn the above example, a solution exists. However, there are also systems of equations which do not have any solution. Such a system is called inconsistent. An obvious example is\nAs 0\u22602, the second equation in the system has no solution. Therefore, the system has no solution.\nHowever, not all inconsistent systems are recognized at first sight. As an example, consider the system \nMultiplying by 2 both sides of the second equation, and adding it to the first one results in\nwhich clearly has no solution.\nUndetermined systems.\nThere are also systems which have infinitely many solutions, in contrast to a system with a unique solution (meaning, a unique pair of values for and ) For example:\nIsolating in the second equation:\nAnd using this value in the first equation in the system:\nThe equality is true, but it does not provide a value for . Indeed, one can easily verify (by just filling in some values of ) that for any there is a solution as long as formula_160. There is an infinite number of solutions for this system.\nOver- and underdetermined systems.\nSystems with more variables than the number of linear equations are called underdetermined. Such a system, if it has any solutions, does not have a unique one but rather an infinitude of them. An example of such a system is\nWhen trying to solve it, one is led to express some variables as functions of the other ones if any solutions exist, but cannot express \"all\" solutions numerically because there are an infinite number of them if there are any.\nA system with a higher number of equations than variables is called overdetermined. If an overdetermined system has any solutions, necessarily some equations are linear combinations of the others."}
{"id": "9711", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=9711", "title": "Electromagnetic interaction", "text": ""}
{"id": "9712", "revid": "1302184", "url": "https://en.wikipedia.org/wiki?curid=9712", "title": "ERP", "text": "ERP or Erp may refer to:"}
{"id": "9713", "revid": "3091149", "url": "https://en.wikipedia.org/wiki?curid=9713", "title": "Ernest Thayer", "text": "Ernest Lawrence Thayer (; August 14, 1863 \u2013 August 21, 1940) was an American writer and poet who wrote the poem \"Casey\" (or \"Casey at the Bat\"), which is \"the single most famous baseball poem ever written\" according to the Baseball Almanac, and \"the nation\u2019s best-known piece of comic verse\u2014a ballad that began a native legend as colorful and permanent as that of Johnny Appleseed or Paul Bunyan\".\nBiography.\nThayer was born in Lawrence, Massachusetts, and raised in nearby Worcester. He graduated \"magna cum laude\" in philosophy from Harvard University in 1885, where he had been editor of the \"Harvard Lampoon\" and a member of the theatrical society Hasty Pudding. William Randolph Hearst, a friend from both activities, hired Thayer as humor columnist for \"The San Francisco Examiner\" 1886\u201388.\nThayer's last piece for the \"Examiner\", dated June 3, 1888, was a ballad entitled \"Casey\" (\"Casey at the Bat\") which made him \"a prize specimen of the one-poem poet\" according to \"American Heritage\".\nIt was not until several months after the publication of the poem that Thayer became famous for it, since he was hardly the boastful type and had signed the June 24 poem with the nickname \"Phin\" which he had used since his time as a writer for the \"Harvard Lampoon\". Two mysteries remain about the poem: whether Casey and Mudville were based on a real person or place, and, if so, their actual identities. On March 31, 2007, Katie Zezima of \"The New York Times\" wrote an article called \"In 'Casey' Rhubarb, 2 Cities Cry 'Foul!'\" on the competing claims of two towns to such renown: Stockton, California, and Holliston, Massachusetts.\nOn the possible model for Casey, Thayer dismissed the notion that any single living baseball player was an influence. However, late 1880s Boston star Mike \"King\" Kelly is likely as a model for Casey's baseball situations. Besides being a native of a town close to Boston, Thayer, as a \"San Francisco Examiner\" baseball reporter in the off-season of 1887\u201388, covered exhibition games featuring Kelly. During November 1887, some of his reportage about a Kelly at-bat has the same ring as Casey's famous at-bat in the poem. A 2004 book by Howard W. Rosenberg, \"Cap Anson 2: The Theatrical and Kingly Mike Kelly: U.S. Team Sport's First Media Sensation and Baseball's Original Casey at the Bat,\" reprints a 1905 Thayer letter to a Baltimore scribe who was asking about the poem's roots. In the letter, Thayer named Kelly (d. 1894), as having shown \"impudence\" in claiming to have inspired it. Rosenberg argues that if Thayer still felt offended, Thayer may have later denied Kelly as an influence. Kelly had also performed as a vaudeville actor, and recited the poem dozens of times.\nThe first public performance of the poem was on August 14, 1888, by actor De Wolf Hopper, on Thayer's 25th birthday. Thayer recited of the poem at a Harvard class reunion in 1895.\nDuring the mid-1890s, Thayer contributed several other comic poems for Hearst's newspaper \"New York Journal\" and then began overseeing his family's mills in Worcester full-time. Thayer relocated to Santa Barbara in 1912, where he married Rosalind Buel Hammett and retired. He died in 1940, seven days after his 77th birthday.\n\"The New York Times\"' obituary of Thayer on August 22, 1940, p.\u00a019 quotes comedian DeWolf Hopper, who helped make the poem famous: "}
{"id": "9714", "revid": "47965501", "url": "https://en.wikipedia.org/wiki?curid=9714", "title": "List of English-language poets", "text": "This is a list of English-language poets, who have written much of their poetry in English. Main country of residence as a poet (not place of birth): A = Australia, Ag = Antigua, B = Barbados, Bo = Bosnia, C = Canada, Ch = Chile, Cu = Cuba, D = Dominica, De = Denmark, E = England, F = France, G = Germany, Ga = Gambia, Gd = Grenada, Gh = Ghana/Gold Coast, Gr = Greece, Gu = Guyana/British Guiana, Gy = Guernsey, HK = Hong Kong, In = India, IoM = Isle of Man, Is = Israel, Ir = Ireland, It = Italy, J = Jamaica, Je = Jersey, Jp = Japan, K = Kenya, L = Lebanon, M = Malta, Me = Mexico, Mo = Montserrat, Ne = Nepal, Nf = Newfoundland (colony), Ni = Nigeria, NI = Northern Ireland, Nt = Netherlands, NZ = New Zealand, P = Pakistan, Pa = Palestine, Ph = Philippines, PI = Pitcairn Islands, RE = Russian Empire, S = Scotland, SA = South Africa, Se = Serbia, SL = Saint Lucia, SLe = Sierra Leone, SLk = Sri Lanka, So = Somalia, Sw = Sweden, T = Trinidad and Tobago, US = United States/preceding colonies, W = Wales, Z = Zimbabwe/Rhodesia"}
{"id": "9715", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9715", "title": "Endangered Species", "text": ""}
{"id": "9716", "revid": "7523687", "url": "https://en.wikipedia.org/wiki?curid=9716", "title": "Environmental Modification", "text": ""}
{"id": "9717", "revid": "1271569183", "url": "https://en.wikipedia.org/wiki?curid=9717", "title": "Excalibur", "text": "Excalibur is the mythical sword of King Arthur that may possess magical powers or be associated with the rightful sovereignty of Britain. Its first reliably datable appearance is found in Geoffrey of Monmouth's \"Historia Regum Britanniae\". Excalibur as the \"sword in the stone\" functioning as the proof of Arthur's lineage is an iconic motif featured throughout great most of works dealing with Arthur's youth since its introduction in Robert de Boron's \"Merlin\". The sword given to the young Arthur by the Lady of the Lake in the tradition that began soon afterwards with the \"Post-Vulgate Cycle\" is not the same weapon, but in \"Le Morte d'Arthur\" both of them share the name of Excalibur. Several similar swords and other weapons also appear within Arthurian texts, as well as in other legends.\nForms and etymology.\nThe name \"Excalibur\" ultimately derives from the Welsh (Breton , Middle Cornish ), which is a compound of , , and , . Caledfwlch appears in several early Welsh works, including the prose tale \"Culhwch and Olwen\" (). The name was later used in Welsh adaptations of foreign material such as the s (chronicles), which were based on Geoffrey of Monmouth. It is often considered to be related to the phonetically similar , a sword borne by several figures from Irish mythology, although a borrowing of from the Irish has been considered unlikely by Rachel Bromwich and D. Simon Evans. They suggest instead that both names \"may have similarly arisen at a very early date as generic names for a sword\". In the late 15th to early 16th-century Middle Cornish play , Arthur's sword is called , which is etymologically an exact Middle Cornish cognate of the Welsh . It is unclear if the name was borrowed from the Welsh (if so, it must have been an early loan, for phonological reasons), or represents an early, pan-Brittonic traditional name for Arthur's sword.\nWelsh author Geoffrey of Monmouth, in his Latin chronicle (\"The History of the Kings of Britain\", ), Latinised the name of Arthur's sword as (possibly influenced by the Medieval Latin spelling of Classical Latin , from the Greek (), ). Most Celticists consider Geoffrey's to be derivative of a lost Old Welsh text in which (Old Welsh ) had not yet been lenited to (Middle Welsh or ). Geoffrey Gaimar, in his Old French chronicle (1134\u20131140), mentions Arthur and his sword: \"this Constantine was the nephew of Arthur, who had the sword Caliburc\" (\"\"). In Wace's (), composed in Old French, the sword is called (, , ), , , , , and (with additional variant spellings such as , , , , , found in various continental manuscripts). Various other spellings in the later medieval Arthurian literature have included \"Calibourch\", \"Calibourn\", \"Calibourne\", \"Caliburc\", \"Escaliber\", \"Escalibur\", \"Excalibor\", and finally the familiar \"Excalibur\".\nLegend.\nThe Sword in the Stone and the Sword in the Lake.\nRomance tradition elaborates on how Arthur came into possession of Excalibur. In Robert de Boron's c. 1200 French poem \"Merlin\", the first known tale to mention the \"sword in the stone\" motif, Arthur obtained the British throne by pulling a sword from an anvil sitting atop a stone that appeared in a churchyard on Christmas Eve. In this account, as foretold by Merlin, the act could not be performed except by \"the true king\", meaning the divinely appointed king or true heir of Uther Pendragon. (As Thomas Malory related in his English-language Arthurian compilation, the 15th-century \"Le Morte d'Arthur\", \"whoso pulleth out this sword of this stone and anvil, is rightwise king born of all England.\") The scene is set by different authors at either explicitly London (historical Londinium) or generally in the land of Logres (which can be a city and also associated with London), and might have been inspired by a miracle attributed to the 11th-century bishop Wulfstan of Worcester. After many of the gathered nobles try and fail to complete Merlin's challenge, the teenage Arthur, who up to this point had believed himself to be biological son of Ector and went there as a squire to his foster brother Kay, succeeds effortlessly. Arthur first achieves this feat by accident while unaware of the contest and unseen. He then returns the sword to its place in the anvil on a stone, and later repeats the act publicly as Merlin comes to announce his true parentage.\nThe identity of this sword as Excalibur is made explicit in the Prose \"Merlin\", a part of the 13th-century \"Lancelot-Grail\" cycle of French romances also known as the Vulgate Cycle. Eventually, in the cycle's finale Vulgate \"Mort Artu\", when Arthur is at the brink of death, he enigmatically orders his surviving knight Griflet to cast Excalibur into a nearby lake. After two failed attempts to deceive Arthur, since Griflet felt that such a great sword should not be thrown away, he finally does comply with the wounded king's request. A woman's hand emerges from the lake to catch Excalibur, after which Morgan appears in a boat to take Arthur to Avalon. This motif then became attached to Bedivere (or Yvain in the chronicle \"Scalacronica\"), instead of Griflet, in the English Arthurian tradition. \nHowever, in the subsequent Post-Vulgate Cycle variants of the \"Merlin\" and the \"Merlin Continuation\", written soon afterwards, Arthur's sword drawn from the stone is unnamed. Furthermore, the young Arthur promptly breaks it in his duel against King Pellinore very early in his reign. On Merlin's advice, Arthur then goes with him to be given the actual Excalibur by a Lady of the Lake in exchange for a later boon for her (some time later, she arrives at Arthur's court to demand the head of Balin). In the Post-Vulgate \"Mort Artu\", it is this sword that is eventually hurled into the pool at Camlann (or actually Salisbury Plain where both cycles locate the battle, as do the English romances) by Griflet in the same circumstances as told in the story's Vulgate version. Malory included both of these stories in his now-iconic \"Le Morte d'Arthur\" while naming each of the swords as Excalibur: both the first one (from the stone), soon shattered in combat in a story taken from the Post-Vulgate \"Merlin Continuation\", and its replacement (from the lake), returned by Bedivere in the end.\nOther roles and attributes.\nIn the Welsh tales, Arthur's sword is known as \"Caledfwlch\". In \"Culhwch and Olwen\", it is one of Arthur's most valuable possessions and is used by Arthur's warrior Llenlleawg the Irishman to kill the Irish king Diwrnach while stealing his magical cauldron. Though not named as Caledfwlch, Arthur's sword is described vividly in \"The Dream of Rhonabwy\", one of the tales associated with the \"Mabinogion\" (as translated by Jeffrey Gantz): \"Then they heard Cadwr Earl of Cornwall being summoned, and saw him rise with Arthur's sword in his hand, with a design of two chimeras on the golden hilt; when the sword was unsheathed what was seen from the mouths of the two chimeras was like two flames of fire, so dreadful that it was not easy for anyone to look.\"\nGeoffrey's \"Historia\" is the first non-Welsh text to speak of the sword. Geoffrey says the sword was forged in Avalon and Latinises the name Caledfwlch as \"Caliburnus\". When his influential pseudo-history made it to continental Europe, writers altered the name further until it finally took on the popular form \"Excalibur\". Its role was expanded upon in the Vulgate Cycle and in the Post-Vulgate Cycle which emerged in its wake. Both of these prose cycles incorporated the Prose \"Merlin\". However, the Post-Vulgate authors left out the original \"Merlin\" continuation from the earlier cycle, choosing to add an original account of Arthur's early days including a new origin for Excalibur. In some versions, Excalibur's blade was engraved with phrases on opposite sides: \"Take me up\" and \"Cast me away\" (or similar). In addition, it said that when Excalibur was first drawn in combat, in the first battle testing Arthur's sovereignty, its blade shone so bright it blinded his enemies.\nIn Chr\u00e9tien de Troyes' late 12th-century Old French \"Perceval\", Arthur's nephew and best knight Gawain carries Excalibur, \"for at his belt hung Escalibor, the finest sword that there was, which sliced through iron as through wood\" (\"\"). This statement was probably picked up by the author of the \"Estoire Merlin\", or Vulgate \"Merlin\", where the author asserts that Escalibor \"is a Hebrew name which means in French 'cuts iron, steel, and wood (\"\"; the word for 'steel' here, \"achier\", also means 'blade' or 'sword') and comes from medieval Latin , a derivative of 'sharp', so there is no direct connection with Latin ). It is from this fanciful etymological musing that Thomas Malory got the notion that Excalibur meant 'cut steel' (\"the name of it,' said the lady, 'is Excalibur, that is as moche to say, as cut stele\").\nIn the Post-Vulgate version, used in Malory's \"Le Morte d'Arthur\" for the second Excalibur, the sword's scabbard is also said to have powers of its own, as any wounds received while wearing it would not bleed at all, thus preventing the wearer from ever bleeding to death in battle. For this reason, Merlin chides Arthur for preferring Excalibur over its sheath, saying that the latter is the greater treasure. The scabbard is, however, soon stolen from Arthur by his half-sister Morgan le Fay in revenge for the death of her beloved Accolon, he having been slain by Arthur with Excalibur in a duel involving a false Excalibur (Morgan also secretly makes at least one duplicate of Excalibur during the time when the sword is entrusted to her by Arthur earlier in the different French, Iberian and English variants of that story). During Morgan's flight from the pursuit by Arthur, the sheath is then thrown by her into a deep lake and lost. This act later enables the death of Arthur, deprived of its magical protection, many years later in his final battle. In Malory's telling, the scabbard is never found again. In the Post-Vulgate, however, it is recovered and claimed by another fay, Marsique, who then briefly gives it to Gawain to help him fight Naborn the Enchanter (a Mabon figure).\nAs mentioned above, Excalibur is wielded also by Gawain in some French romances, including the Vulgate \"Lancelot\". The Prose \"Merlin\" also uniquely tells of Gawain killing the Roman leader Lucius with Excalibur. This is, however, in contrast to most versions, where Excalibur belongs solely to Arthur. A few texts, such as the English Alliterative \"Morte Arthure\" and one copy of the Welsh \"Ymddiddan Arthur a'r Eryr\", tell of Arthur using Excalibur to kill his son Mordred (in the first of these, he also uses it to kill Lucius). In the Iberian post-Arthurian romance \"Florambel de Lucea\", Morgan later gifts Excalibur (\"Esclariber\") to the eponymous hero. Another late Iberian romance, \"Tirant lo Blanch\", features Arthur who was brought back to life by Morgan and then wandered the world for a long time while mad and able to talk only when having Excalibur in his hands. Finally, Morgan finds her brother imprisoned in the contemporary (15th-century) Constantinople, where she restores him to his mind by making him gaze upon his reflection in Excalibur's blade.\nConnections and analogues.\nSimilar weapons.\nThe challenge of drawing a sword from a stone (placed on the river just outside Camelot) also appears in the later Arthurian story of Galahad, whose achievement of the task indicates that he is destined to find the Holy Grail, as also foretold in Merlin's prophecies. This powerful yet cursed weapon, known as the Adventurous Sword among other names, has also come from Avalon; it is first stolen and wielded by Balin until his death while killing his own brother, then is briefly taken up by Galahad, and eventually is used by Lancelot to give his former friend Gawain a mortal wound in their long final duel. In the Old French \"Perlesvaus\", Lancelot pulls other weapons from stone on two occasions. In the Post-Vulgate \"Merlin\", Morgan creates the copies of Excalibur itself as well as of its scabbard.\nIn Welsh mythology, the Dyrnwyn (\"White-Hilt\"), one of the Thirteen Treasures of the Island of Britain, is said to be a powerful sword belonging to Rhydderch Hael, one of the Three Generous Men of Britain mentioned in the Welsh Triads. When drawn by a worthy or well-born man, the entire blade would blaze with fire. Rhydderch was never reluctant to hand the weapon to anyone, hence his nickname Hael \"the Generous\", but the recipients, as soon as they had learned of its peculiar properties, always rejected the sword. There are other similar weapons described in other mythologies as well. Irish mythology features Caladbolg, the sword of Fergus mac R\u00f3ich, which was also known for its incredible power and was carried by some of Ireland's greatest heroes. The name, which can also mean \"hard cleft\" in Irish, appears in the plural, \"caladbuilc\", as a generic term for \"great swords\" in \"Togail Troi\" (\"The Destruction of Troy\"), a 10th-century Irish translation of the classical tale. A sword named Cla\u00edomh Solais, which is an Irish term meaning \"sword of light\", or \"shining sword\", appears in a number of orally transmitted Irish folk-tales. The Sword in the Stone has an analogue in some versions of the story of Sigurd, whose father, Sigmund, draws the sword Gram out of the tree Barnstokkr where it is embedded by the Norse god Odin. Apart from legendary swords, the only real ancient Sword in the Stone which still exists nowadays is kept since the medieval ages in the Chapel of Saint Galgano at Montesiepi in Tuscany, Italy; it is associated with the 12th-century Italian legend of that saint in the tale of \"Tuscany's Excalibur\".\nArthur's other weapons.\nA number of different swords and other weapons have been also associated with Arthur. In the Alliterative \"Morte Arthure\", Clarent is the royal sword of peace meant for knighting and ceremonies as opposed to battle, which Mordred stole and then used to kill Arthur at Camlann. The Prose \"Lancelot\" of the Vulgate Cycle mentions a sword called Sequence (also \"Secace\" or \"Seure\") as borrowed from Arthur by Lancelot. In the Vulgate \"Merlin\", Arthur captures Marmiadoise (Marmydoyse), the marvelous sword of Hercules, from the latter's descendant King Rions. Marmiadoise's powers (such as causing wounds that would never heal) are in fact so superior compared to those of Excalibur that Arthur gives his old sword to Gawain.\nEarly-Arthurian Welsh tradition knew of a dagger named Carnwennan and a spear named Rhongomyniad that belonged to him. Carnwennan (\"little white-hilt\") first appears in \"Culhwch and Olwen\", where Arthur uses it to slice the witch Orddu in half. Rhongomyniad (\"spear\" + \"striker, slayer\") is also mentioned in \"Culhwch\", although only in passing; it appears as simply Ron (\"spear\") in Geoffrey's \"Historia\". Geoffrey also names Arthur's shield as Pridwen; in \"Culhwch\", however, Prydwen (\"fair face\") is the name of Arthur's ship while his shield is named Wynebgwrthucher (\"face of evening\").\nExcalibur as a relic.\nHistorically, a sword identified as Excalibur (Caliburn) was supposedly discovered during the exhumation of Arthur's purported grave at Glastonbury Abbey in 1191. On 6 March 1191, after the Treaty of Messina, either this or another claimed Excalibur was given as a gift of goodwill by the English king Richard I of England (Richard the Lionheart) to his ally Tancred, King of Sicily. It was one of a series of symbolic Arthurian acts by the Anglo-Norman monarchs, such as their association of the crown of King Arthur with the crown they won from the slain Welsh prince Llywelyn ap Gruffudd."}
{"id": "9719", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=9719", "title": "Eight-bar blues", "text": "In music, an eight-bar blues is a common blues chord progression. Music writers have described it as \"the second most common blues form\" being \"common to folk, rock, and jazz forms of the blues\". It is often notated in or time with eight bars to the verse.\nOverview.\nEarly examples of eight-bar blues standards include:\nOne variant using this progression is to couple one eight-bar blues melody with a different eight-bar blues bridge to create a blues variant of the standard 32-bar song: \"I Want a Little Girl\" (T-Bone Walker) and \"Great Balls of Fire\" (Jerry Lee Lewis)(\nEight-bar blues progressions have more variations than the more rigidly defined twelve bar format. The move to the IV chord usually happens at bar 3 (as opposed to 5 in twelve bar); however, \"the I chord moving to the V chord right away, in the second measure, is a characteristic of the eight-bar blues.\"\nIn the following examples each box represents a 'bar' of music (the specific time signature is not relevant). The chord in the box is played for the full bar. If two chords are in the box they are each played for half a bar, etc. The chords are represented as scale degrees in Roman numeral analysis. Roman numerals are used so the musician may understand the progression of the chords regardless of the key it is played in.\n\"Eight-bar blues chord progression\":\n\"Worried Life Blues\" (probably the most common eight-bar blues progression):\n\"Heartbreak Hotel\" (variation with the I on the first half):\nJ. B. Lenoir's \"Slow Down\" and \"Key to the Highway\" (variation with the V at bar 2):\n\"Get a Haircut\" by George Thorogood (simple progression):\nJimmy Rogers' \"Walkin' By Myself\" (somewhat unorthodox example of the form):\nHowlin Wolf's version of \"Sitting on Top of the World\" is actually a 9 bar blues that adds an extra \"V\" chord at the end of the progression. The song uses movement between major and dominant 7th and major and minor fourth:\nThe first four bar progression used by Wolf is also used in Nina Simone's 1965 version of \"Trouble in Mind\", but with a more uptempo beat than \"Sitting on Top of the World\":\nThe progression may be created by dropping the first four bars from the twelve-bar blues, as in the solo section of Bonnie Raitt's \"Love Me Like a Man\" and Buddy Guy's \"Mary Had a Little Lamb\":\nThere are at least a few very successful songs using somewhat unusual chord progressions as well. For example, the song \"Ain't Nobody's Business\" as performed by Freddie King at least, uses a I\u2013III\u2013IV\u2013iv progression in each of the first four bars. The same four bar progression is used by the band Radiohead to make up the bulk of the song \"Creep\".\nThe same chord progression can also be called a sixteen-bar blues, if each symbol above is taken to be a half note in or time. Examples are \"Nine Pound Hammer\" and Ray Charles's original instrumental \"Sweet Sixteen Bars\"."}
{"id": "9720", "revid": "43237577", "url": "https://en.wikipedia.org/wiki?curid=9720", "title": "Echidna (disambiguation)", "text": "Echidnas are Australian egg-laying mammals also known as spiny anteaters.\nEchidna may also refer to:"}
{"id": "9722", "revid": "13054498", "url": "https://en.wikipedia.org/wiki?curid=9722", "title": "Eigenvalue", "text": ""}
{"id": "9723", "revid": "2308770", "url": "https://en.wikipedia.org/wiki?curid=9723", "title": "Edward Waring", "text": "Edward Waring (15 August 1798) was a British mathematician. He entered Magdalene College, Cambridge as a sizar and became Senior wrangler in 1757. He was elected a Fellow of Magdalene and in 1760 Lucasian Professor of Mathematics, holding the chair until his death. He made the assertion known as Waring's problem without proof in his writings \"Meditationes Algebraicae\". Waring was elected a Fellow of the Royal Society in 1763 and awarded the Copley Medal in 1784.\nEarly years.\nWaring was the eldest son of John and Elizabeth Waring, a prosperous farming couple. He received his early education in Shrewsbury School under a Mr Hotchkin and was admitted as a sizar at Magdalene College, Cambridge, on 24 March 1753, being also Millington exhibitioner. \nHis extraordinary talent for mathematics was recognised from his early years in Cambridge. In 1757 he graduated BA as senior wrangler and on 24 April 1758 was elected to a fellowship at Magdalene. He belonged to the Hyson Club, whose members included William Paley.\nCareer.\nAt the end of 1759 Waring published the first chapter of \"Miscellanea Analytica\". On 28 January the next year he was appointed Lucasian professor of mathematics, one of the highest positions in Cambridge. William Samuel Powell, then tutor in St John's College, Cambridge opposed Waring's election and instead supported the candidacy of William Ludlam. In the polemic with Powell, Waring was backed by John Wilson. In fact Waring was very young and did not hold the MA, necessary for qualifying for the Lucasian chair, but this was granted him in 1760 by royal mandate. In 1762 he published the full \"Miscellanea Analytica\", mainly devoted to the theory of numbers and algebraic equations. In 1763 he was elected to the Royal Society. He was awarded its Copley Medal in 1784 but withdrew from the society in 1795, after he had reached sixty, 'on account of [his] age'. Waring was also a member of the academies of sciences of G\u00f6ttingen and Bologna. In 1767 he took an MD degree, but his activity in medicine was quite limited. He carried out dissections with Richard Watson, professor of chemistry and later bishop of Llandaff. From about 1770 he was physician at Addenbrooke's Hospital at Cambridge, and he also practised at St Ives, Huntingdonshire, where he lived for some years after 1767. His career as a physician was not very successful since he was seriously short-sighted and a very shy man.\nPersonal life.\nWaring had a younger brother, Humphrey, who obtained a fellowship at Magdalene in 1775. In 1776 Waring married Mary Oswell, sister of a draper in Shrewsbury; they moved to Shrewsbury and then retired to Plealey, 8 miles out of the town, where Waring owned an estate of 215 acres in 1797\nWork.\nWaring wrote a number of papers in the \"Philosophical Transactions of the Royal Society\", dealing with the resolution of algebraic equations, number theory, series, approximation of roots, interpolation, the geometry of conic sections, and dynamics. The \"Meditationes Algebraicae\" (1770), where many of the results published in \"Miscellanea Analytica\" were reworked and expanded, was described by Joseph-Louis Lagrange as 'a work full of excellent researches'. In this work Waring published many theorems concerning the solution of algebraic equations which attracted the attention of continental mathematicians, but his best results are in number theory. Included in this work was the so-called Goldbach conjecture (every even integer is the sum of two primes), and also the following conjecture: every odd integer is a prime or the sum of three primes. Lagrange had proved that every positive integer is the sum of not more than four squares; Waring suggested that every positive integer is either a cube or the sum of not more than nine cubes. He also advanced the hypothesis that every positive integer is either a biquadrate (fourth power) or the sum of not more than nineteen biquadrates. These hypotheses form what is known as Waring's problem. He also published a theorem, due to his friend John Wilson, concerning prime numbers; it was later proven rigorously by Lagrange.\nIn \"Proprietates Algebraicarum Curvarum\" (1772) Waring reissued in a much revised form the first four chapters of the second part of \"Miscellanea Analytica\". He devoted himself to the classification of higher plane curves, improving results obtained by Isaac Newton, James Stirling, Leonhard Euler, and Gabriel Cramer. In 1794 he published a few copies of a philosophical work entitled \"An Essay on the Principles of Human Knowledge\", which were circulated among his friends.\nWaring's mathematical style is highly analytical. In fact he criticised those British mathematicians who adhered too strictly to geometry. It is indicative that he was one of the subscribers of John Landen's \"Residual Analysis\" (1764), one of the works in which the tradition of the Newtonian fluxional calculus was more severely criticised. In the preface of \"Meditationes Analyticae\" Waring showed a good knowledge of continental mathematicians such as Alexis Clairaut, Jean le Rond d'Alembert, and Euler. He lamented the fact that in Great Britain mathematics was cultivated with less interest than on the continent, and clearly desired to be considered as highly as the great names in continental mathematics\u2014there is no doubt that he was reading their work at a level never reached by any other eighteenth-century British mathematician. Most notably, at the end of chapter three of \"Meditationes Analyticae\" Waring presents some partial fluxional equations (partial differential equations in Leibnizian terminology); such equations are a mathematical instrument of great importance in the study of continuous bodies which was almost completely neglected in Britain before Waring's researches. One of the most interesting results in \"Meditationes Analyticae\" is a test for the convergence of series generally attributed to d'Alembert (the 'ratio test'). The theory of convergence of series (the object of which is to establish when the summation of an infinite number of terms can be said to have a finite 'sum') was not much advanced in the eighteenth century.\nWaring's work was known both in Britain and on the continent, but it is difficult to evaluate his impact on the development of mathematics. His work on algebraic equations contained in \"Miscellanea Analytica\" was translated into Italian by Vincenzo Riccati in 1770. Waring's style is not systematic and his exposition is often obscure. It seems that he never lectured and did not habitually correspond with other mathematicians. After J\u00e9r\u00f4me Lalande in 1796 observed, in \"Notice sur la vie de Condorcet\", that in 1764 there was not a single first-rate analyst in England, Waring's reply, published after his death as 'Original letter of Dr Waring' in the \"Monthly Magazine\", stated that he had given 'somewhere between three and four hundred new propositions of one kind or another'.\nDeath.\nDuring his last years he sank into a deep religious melancholy, and a violent cold caused his death, in Plealey, on 15 August 1798. He was buried in the churchyard at Fitz, Shropshire."}
{"id": "9724", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=9724", "title": "Eden Phillpotts", "text": "Eden Phillpotts (4 November 1862 \u2013 29 December 1960) was an English author, poet and dramatist. He was born in Mount Abu, India, was educated in Plymouth, Devon, and worked as an insurance officer for ten years before studying for the stage and eventually becoming a writer.\nLife.\nEden Phillpotts was a great-nephew of Henry Phillpotts, Bishop of Exeter. His father Henry Phillpotts was a son of the bishop's younger brother Thomas Phillpotts. James Surtees Phillpotts the reforming headmaster of Bedford School was his second cousin.\nEden Phillpotts was born on 4 November 1862 at Mount Abu in Rajasthan. His father Henry was an officer in the Indian Army, while his mother Adelaide was the daughter of an Indian Civil Service officer posted in Madras, George Jenkins Waters.\nHenry Phillpotts died in 1865, leaving Adelaide a widow at the age of 21. With her three small sons, of whom Eden was the eldest, she returned to England and settled in Plymouth.\nPhillpotts was educated at Mannamead School in Plymouth. At school he showed no signs of a literary bent. In 1879, aged 17, he left home and went to London to earn his living. He found a job as a clerk with the Sun Fire Office.\nPhillpotts' ambition was to be an actor and he attended evening classes at a drama school for two years. He came to the conclusion that he would never make a name as an actor but might have success as a writer. In his spare time out of office hours he proceeded to create a stream of small works which he was able to sell. In due course he left the insurance company to concentrate on his writing, while also working part-time as assistant editor for the weekly \"Black and White\" magazine.\nEden Phillpotts maintained a steady output of three or four books a year for the next half century. He produced poetry, short stories, novels, plays and mystery tales. Many of his novels were about rural Devon life and some of his plays were distinguished by their effective use of regional dialect.\nEden Phillpotts died at his home in Broadclyst near Exeter, Devon, on 29 December 1960.\nPersonal life.\nPhillpotts was for many years the President of the Dartmoor Preservation Association and cared passionately about the conservation of Dartmoor. He was an agnostic and a supporter of the Rationalist Press Association.\nPhillpotts was a friend of Agatha Christie, who was an admirer of his work and a regular visitor to his home. She dedicated her 1932 novel \"Peril at End House\" to Phillpotts, and in her autobiography, she expressed gratitude for his early advice on fiction writing and quoted some of it. Jorge Luis Borges was another Phillpotts admirer. Borges mentioned him numerous times, wrote at least two reviews of his novels, and included him in his \"Personal Library\", a collection of works selected to reflect his personal literary preferences.\nPhilpotts allegedly sexually abused his daughter Adelaide. In a 1976 interview for a book about her father, Adelaide described an incestuous \"relationship\" with him that she says lasted from the age of five or six until her early thirties, when he remarried. When she herself finally married at the age of 55 her father never forgave her, and never communicated with her again.\nWritings.\nPhillpotts wrote a great many books with a Dartmoor setting. One of his novels, \"Widecombe Fair\" (1913), inspired by an annual fair at the village of Widecombe-in-the-Moor, provided the scenario for his comic play \"The Farmer's Wife\" (1916). It went on to become a 1928 silent film of the same name, directed by Alfred Hitchcock. It was followed by a 1941 remake, directed by Norman Lee and Leslie Arliss. It became a BBC TV drama in 1955, directed by Owen Reed. Jan Stewer played Churdles Ash. The BBC had broadcast the play in 1934.\nHe co-wrote several plays with his daughter Adelaide Phillpotts, \"The Farmer's Wife\" and \"Yellow Sands\" (1926); she later claimed their relationship was incestuous. Eden is best known as the author of many novels, plays and poems about Dartmoor. His Dartmoor cycle of 18 novels and two volumes of short stories still has many avid readers despite the fact that many titles are out of print.\nPhilpotts also wrote a series of novels, each set against the background of a different trade or industry. Titles include: \"Brunel's Tower\" (a pottery) and \"Storm in a Teacup\" (hand-papermaking). Among his other works is \"The Grey Room\", the plot of which is centred on a haunted room in an English manor house. He also wrote a number of other mystery novels, both under his own name and the pseudonym Harrington Hext. These include: \"The Thing at Their Heels\", \"The Red Redmaynes\", \"The Monster\", \"The Clue from the Stars\", and \"The Captain's Curio\". \"The Human Boy\" was a collection of schoolboy stories in the same genre as Rudyard Kipling's \"Stalky &amp; Co.\", though different in mood and style. Late in his long writing career he wrote a few books of interest to science fiction and fantasy readers, the most noteworthy being \"Saurus\", which involves an alien reptilian observing human life.\nEric Partridge praised the immediacy and impact of his dialect writing.\nWorks.\nNovels\nShort Fiction Books\nPoetry\nPlays\nNonfiction"}
{"id": "9725", "revid": "2127217", "url": "https://en.wikipedia.org/wiki?curid=9725", "title": "Ecuador\u2013United States relations", "text": "Ecuador and the United States maintained close ties based on mutual interests in maintaining democratic institutions; combating cannabis and cocaine; building trade, investment, and financial ties; cooperating in fostering Ecuador's economic development; and participating in inter-American organizations. Ties are further strengthened by the presence of an estimated 150,000-200,000 Ecuadorians living in the United States and by 24,000 U.S. citizens visiting Ecuador annually, and by approximately 15,000 U.S. citizens living in Ecuador.\nRelations between the two nations have been strained following Julian Assange's bid to seek political asylum in the Ecuadorian embassy in London following repeated claims that the US government was pursuing his extradition due to his work with Wikileaks.\n Ecuador first offered political asylum to Julian Assange in November 2010, which he then invoked by entering their London embassy in June 2012. This was then revoked in 2019, following negotiations between the Moreno administration and the British Government. Relations have since improved following the ouster of Rafael Correa from office as President of Ecuador. \nHistory.\nBoth nations were early signatories of the Inter-American Treaty of Reciprocal Assistance (the \"Rio Treaty\") of 1947, the Western Hemisphere's regional mutual security treaty. However, under the Correa administration, Ecuador denounced the treaty in February 2014, a legal prerequisite by which Ecuador would leave the treaty in 2016. Ecuador shares U.S. concern over increasing narcotrafficking and international terrorism and has energetically condemned terrorist actions, whether directed against government officials or private citizens. The government has maintained Ecuador virtually free of coca production since the mid-1980s and is working to combat money laundering and the transhipment of drugs and chemicals essential to the processing of cocaine.\nAccording to CIA critic and former CIA agent who was stationed in Ecuador Philip Agee, the CIA carried out extensive operations and political manipulation in Ecuador in the early 1960s. For instance the CIA was involved in the group the Ecuadorian Anti-Communist Action.\nEcuador and the U.S. agreed in 1999 to a 10-year arrangement whereby U.S. military surveillance aircraft could use the airbase at Manta, Ecuador, as a \"Forward Operating Location\" to detect drug trafficking flights through the region. The arrangement expired in 2009; former president Rafael Correa vowed not to renew it, and since then the Ecuador has not had any foreign military facilities in the country.\nIn fisheries issues, the United States claims jurisdiction for the management of coastal fisheries up to 200 mile (370\u00a0km) from its coast, but excludes highly migratory species; Ecuador, on the other hand, claims a 200-mile (370-km) territorial sea, and imposes license fees and fines on foreign fishing vessels in the area, making no exceptions for catches of migratory species. In the early 1970s, Ecuador seized about 100 foreign-flag vessels (many of them U.S.) and collected fees and fines of more than $6 million. After a drop-off in such seizures for some years, several U.S. tuna boats were again detained and seized in 1980 and 1981.\nThe U.S. Magnuson Fishery Conservation and Management Act then triggered an automatic prohibition of U.S. imports of tuna products from Ecuador. The prohibition was lifted in 1983, and although fundamental differences between U.S. and Ecuadorian legislation still exist, there is no current conflict. During the period that has elapsed since seizures which triggered the tuna import ban, successive Ecuadorian governments have declared their willingness to explore possible solutions to this problem with mutual respect for longstanding positions and principles of both sides. The election of Rafael Correa in October 2006, has strained relations between the two countries and relations have since been fraught with tension. Rafael Correa was heavily critical of U.S. foreign policy whilst in office.\nIn April 2011, relations between Ecuador and the United States soured particularly after Ecuador expelled the U.S. ambassador after a leaked diplomatic cable was shown accusing president Correa of knowingly ignoring police corruption. In reciprocation, the Ecuadorian ambassador Luis Gallegos was expelled from the United States.\nIn 2013, when Ecuador unilaterally pulled out of a preferential trade pact with the United States over claiming the U.S. used it as blackmail in regards to the asylum request of Edward Snowden, relations between Ecuador and the United States reached an all-time low. The pact offered Ecuador US$23 million, which it offered to the U.S. for human rights training. Tariff free imports had been offered to Ecuador in exchange for drug elimination efforts.\nJulian Assange applied for Ecuadorian citizenship on 16 September 2017, which Ecuador granted on 12 December 2017. However, this development was not announced until 25 January 2018.\nIn April 2019, Assange was arrested by the Metropolitan Police. President of Ecuador, Lenin Moreno, stated that he had 'violated the terms of his asylum'. British Foreign Secretary, Jeremy Hunt stated that the British and Ecuadorian governments had been co-operating since Moreno's inauguration and aimed to resolve the situation. Assange extradition to the United States was denied, due to a combination of his ill health and the nature of the US carceral system.\nThe relations with the United States improved significantly during the presidency of Lenin Moreno since 2017. In February 2020, his visit to Washington was the first meeting between an Ecuadorian and U.S. president in 17 years. In June 2019, Ecuador had agreed to allow US military planes to operate from an airport on the Galapagos Islands.\nEducation.\nAmerican schools in Ecuador:"}
{"id": "9727", "revid": "33528312", "url": "https://en.wikipedia.org/wiki?curid=9727", "title": "Eight-ball", "text": "Eight-ball (also spelled 8-ball or eightball, and sometimes called solids and stripes, spots and stripes, big ones and little ones, or rarely highs and lows) is a discipline of pool played on a billiard table with six pockets, cue sticks, and sixteen billiard balls (a and fifteen ). The object balls include seven solid-colored balls numbered 1 through 7, seven striped balls numbered 9 through 15, and the black 8 ball. After the balls are scattered with a shot, a player is assigned either the group of solid or striped balls once they have legally pocketed a ball from that group. The object of the game is to legally pocket the 8-ball in a \"called\" pocket, which can only be done after all of the balls from a player's assigned group have been cleared from the table.\nThe game is the most frequently played discipline of pool, and is often thought of as synonymous with \"pool\". The game has numerous variations, mostly regional. It is the second most played professional pool game, after nine-ball, and for the last several decades ahead of straight pool.\nHistory.\nThe game of eight-ball arose around 1900 in the United States as a development of pyramid pool, which allows any eight of the fifteen object balls to be pocketed to win. The game arose from two changes made, namely that the 8 ball must be pocketed last to win, and that each player may pocket only half of the other object balls. By 1925, the game was popular enough for the Brunswick-Balke-Collender Company to introduce purpose-made ball sets with seven , seven , one , and the cue ball, which allowed spectators to more easily see which suit each ball belonged to. (Such colors became standard in the later British-originating variant.) The rules, as officially codified in the Billiard Congress of America's rule book, were periodically revised in the years following.\nStandardized rules of play.\nAmerican-style eight-ball is played around the world by professionals and in many amateur leagues. Nevertheless, the rules for eight-ball may be the most inconsistent of any billiard game, as there are several competing sets of \"official\" rules.\nThe World Pool-Billiard Association (WPA), the governing body of pool which has continental and national affiliates around the world, promulgates standardized rules as \"Pool Billiards \u2013 The Rules of Play\". These are used for amateur and professional play.\nMeanwhile, many amateur leagues \u2013 such as the American Poolplayers Association (APA) and its affiliate the Canadian Poolplayers Association (CPA), the Valley National Eight-ball Association (VNEA) and the BCA Pool League (BCAPL) \u2013 use their own rulesets which have slight differences from WPA rules and from each other. Millions of individuals play casually, using informal \"house rules\" which vary not only from area to area but even from venue to venue.\nEquipment.\nThe regulation size of a table's playing surface is , with the between-cushion area being , though exact dimensions may vary slightly by manufacturer. Some leagues and tournaments using the World Standardized Rules may allow smaller sizes, down to . Early 20th-century models are occasionally also still used. Professional competition generally employs regulation tables, while the amateur championships of various leagues, including BCAPL, VNEA, and APA, use the seven-foot tables in order to fit more of them into the hosting venue.\nThere are seven numbered 1 through 7, seven numbered 9 through 15, an , and a . The balls are usually colored as follows:\nSpecial sets designed to be more easily discernible on television substitute pink for the dark purple of the 4 and 12 and light tan for the darker maroon of the 7 and 15 balls, and these alternative-color sets are now also available to consumers.\nSetup.\nTo start the game, the s are placed in a triangular rack. The base of the rack is parallel to the (the short end of the pool table) and positioned so the apex ball of the rack is located on the . The balls in the rack are ideally placed so that they are all in contact with one another; this is accomplished by pressing the balls together toward the apex ball. The order of the balls should be random, with the exceptions of the 8-ball, which must be placed in the center of the rack (i.e., the middle of the third row), and the two back corner balls, one of which must be a stripe and the other a solid. The cue ball is placed anywhere the breaker desires behind the .\nBreak.\nOne person is chosen by some predetermined method (e.g., coin toss, , or win or loss of previous game or match) to shoot first, using the cue ball to the object-ball rack apart. In most leagues, it is the breaker's opponent who racks the balls, but in some, players break their own racks. If the breaker fails to make a successful break\u2014usually defined as at least four balls hitting cushions or an object ball being pocketed\u2014then the opponent can opt either to play from the current position or to call for a and either re-break or have the original breaker repeat the break.\nIf the 8 ball is pocketed on the break, then the breaker can choose either to the 8 ball and play from the current position or to re-rack and re-break; but if the cue ball is also pocketed on the break (colloquially referred to as a \"scratch\") then the opponent is the one who has the choice: either to re-spot the 8 ball and shoot with behind the , accepting the current position, or to re-break or have the breaker re-break.\nTurn-taking.\nA player (or team) continues to shoot until committing a or failing to legally pocket an object ball (whether or not); thereupon it is the turn of the opposing players. Play alternates in this manner for the remainder of the game. Following a foul, the incoming player has anywhere on the table, unless the foul occurred on the break shot, as noted previously.\nSelection of the target group.\nThe table is \"open\" at the start of the game, meaning that either player may shoot at any ball. It remains open until one player legally pockets any called ball other than the 8 after the break. That player is assigned the \"group\", or \"suit\", of the pocketed and the other suit is assigned to the opponent. Balls pocketed on the break, or as the result of a foul while the table is still open, are not used to assign the suits. Once the suits are assigned, they remain fixed throughout the game. If any balls from a player's suit are on the table, the player must hit one of them first on every shot; otherwise a foul is called and the turn ends. After all balls from the suit have been pocketed, the player's target becomes the 8 for the remainder of the game.\nPocketing the 8 ball.\nOnce all of a player's (or team's) group of object balls are pocketed, the player attempts to sink the 8 ball. In order to win the game, the player first designates which pocket the 8 ball will be pocketed into and then successfully pockets the 8 ball into that pocket. If the player knocks the 8 ball off the table, the player loses the game. If the player pockets the 8 ball and commits a foul or pockets it into another pocket than the one designated, the player loses the game. Otherwise (i.e., if the 8 ball is neither pocketed nor knocked off the table), the shooter's turn is simply over, even if a foul occurs. In short, a world-standardized rules game of eight-ball, like a game of nine-ball, is not over until the \"\" is no longer on the table. The rule has been increasingly adopted by amateur leagues.\nWinning.\nA player wins the game if that player legally pockets the 8 ball into a designated pocket after all of their object balls have been pocketed. Because of this, it is possible for a game to end with only one of the players having shot, which is known as \"running the table\" or a \"denial\"; conversely, it's also possible to win a game \"without\" taking a shot; such a scenario may occur if the opposing player illegally pockets the 8 ball on any shot other than the break (such as sinking the 8 ball in an uncalled pocket, knocking the 8 ball off the table, sinking the 8 ball when a player is not yet on the black ball, or sinking both the 8 ball and the cue ball off a single shot). The rules on what happens when the 8 ball is pocketed off the break vary by the rules in question .\nFouls.\nThe general rules of pool apply to eight-ball, such as the requirements that the cue ball not be pocketed and that a cushion be hit by any of the balls after the cue ball has struck an object ball. Fouls specific to eight-ball are:\nVariants.\nUnited Kingdom.\nThe British version of eight-ball, known internationally as either blackball or simply eight-ball, has evolved into a separate game, retaining significant elements of earlier pub versions of the game, with additional influences from English billiards and snooker. It is popular in amateur and professional competition in the UK, Ireland, Australia and some other countries.\nThe game uses unnumbered, solid-colored object balls, typically red and yellow, with one black 8 ball. They are usually or in diameter, the latter being the same size as the balls used in snooker and English billiards. Tables are usually long, and feature pockets with rounded cushion openings, like snooker tables. Smaller tables are sometimes used in places where a larger table would be too large.\nThe rules of blackball differ from standard eight-ball in numerous ways, including the handling of fouls, which may give the opponent two shots, racking (the 8 ball, not the apex ball, goes on the spot), selection of which group of balls will be shot by which player, handling of balls and s, and many other details.\nInternationally, the World Pool-Billiard Association and the World Eightball Pool Federation both publish rules and promote events. The two rule sets differ in some details regarding the penalties for fouls.\nChinese eight-ball (Heyball).\nThe version of eight-ball played in China uses rules that are essentially the same as standard WPA rules; and the game is played with standard solids-and-stripes balls. However, the tables are constructed similarly to snooker tables, with rounded pocket openings, napped cloth and flat-faced rail cushions. This results in some differences in gameplay approach. The variant arose in the mid-1980s and 1990s as eight-ball gained popularity in China, where snooker was the most popular cue sport at the time. With standard American-style pool tables rare, Chinese players made do with playing eight-ball on small snooker tables. It has since become the most popular cue sport in China, and the major tournaments have some of the largest prize money in pool.\nEight-ball rotation.\nThe hybrid game eight-ball rotation is a combination of eight-ball and rotation, in which the players must pocket their balls (other than the 8, which remains last) in numerical order. Specifically, the solids player starts by pocketing the 1 ball and ascends to the 7 ball, and the stripes player starts by pocketing the 15 ball and descends to the 9 ball.\nBackwards eight-ball.\nBackwards eight-ball, also called reverse eight-ball, is a variant in which, instead of shooting the cue ball at an object ball to force the object ball into a pocket, the player strikes the object ball with their cue so it s off the cue ball and into a pocket, in a fashion similar to Russian pyramid."}
{"id": "9728", "revid": "19678760", "url": "https://en.wikipedia.org/wiki?curid=9728", "title": "Earned value management", "text": "Earned value management (EVM), earned value project management, or earned value performance management (EVPM) is a project management technique for measuring project performance and progress in an objective manner.\nOverview.\nEarned value management is a project management technique for measuring project performance and progress. It has the ability to combine measurements of the project management triangle: scope, time, and costs.\nIn a single integrated system, EVM is able to provide accurate forecasts of project performance problems, which is an important aspect of project management.\nEarly EVM research showed that the areas of planning and control are significantly impacted by its use; and similarly, using the methodology improves both scope definition as well as the analysis of overall project performance. More recent research studies have shown that the principles of EVM are positive predictors of project success. The popularity of EVM has grown in recent years beyond government contracting, a sector in which its importance continues to rise (e.g. recent new DFARS rules), in part because EVM can also surface in and help substantiate contract disputes.\nEVM features.\nEssential features of any EVM implementation include:\nEVM implementations for large or complex projects include many more features, such as indicators and forecasts of cost performance (over budget or under budget) and schedule performance (behind schedule or ahead of schedule). Large projects usually need to use quantitative forecasts associated with earned value management. Although deliverables in these large projects can use adaptive development methods, the forecasting metrics found in earned value management are mostly used in projects using the predictive approach. However, the most basic requirement of an EVM system is that it quantifies progress using PV and EV.\nApplication example.\nProject A has been approved for a duration of one year and with a budget. It was also planned that the project spends 50% of the approved budget and expects 50% of the work to be complete in the first six months. If now, six months after the start of the project, a project manager reports that he has spent 50% of the budget, one may presume that the project is perfectly on plan. However, in reality the provided information is not sufficient to come to such a conclusion. The project can spend 50% of the budget, whilst finishing only 25% of the work, which would mean the project is not doing well; or the project can spend 50% of the budget, whilst completing 75% of the work, which would mean that project is doing better than planned. EVM is meant to address such and similar issues.\nHistory.\nEVM emerged as a financial analysis specialty in United States government programs in the 1960s, with the government requiring contractors to implement an EVM system (EVMS). It has since become a significant branch of project management and cost engineering. Project management research investigating the contribution of EVM to project success suggests a moderately strong positive relationship. Implementations of EVM can be scaled to fit projects of all sizes and complexities.\nThe genesis of EVM occurred in industrial manufacturing at the turn of the 20th century, based largely on the principle of \"earned time\" popularized by Frank and Lillian Gilbreth.\nIn 1979, EVM was introduced to the architecture and engineering industry in a \"Public Works Magazine\" article by David Burstein, a project manager with a national engineering firm. In the late 1980s and early 1990s, EVM emerged more widely as a project management methodology to be understood and used by managers and executives, not just EVM specialists. Many industrialized nations also began to utilize EVM in their own procurement programs.\nAn overview of EVM was included in the Project Management Institute (PMI)'s first Project Management Body of Knowledge (PMBOK) Guide in 1987 and was expanded in subsequent editions. In the most recent edition of the PMBOK guide, EVM is listed among the general tools and techniques for processes to control project costs.\nThe construction industry was an early commercial adopter of EVM. Closer integration of EVM with the practice of project management accelerated in the 1990s. In 1999, the Performance Management Association merged with the PMI to become its first college, the College of Performance Management (CPM). The United States Office of Management and Budget began to mandate the use of EVM across all government agencies, and, for the first time, for certain internally managed projects (not just for contractors). EVM also received greater attention by publicly traded companies in response to the Sarbanes\u2013Oxley Act of 2002.\nIn Australia, EVM has been codified as the standards AS 4817-2003 and AS 4817\u20132006.\nUS defense industry.\nThe EVM concept took root in the United States Department of Defense in the 1960s. The original concept was called the Program Evaluation and Review Technique, but it was considered overly burdensome and not very adaptable by contractors whom were mandated to use it, and many variations of it began to proliferate among various procurement programs. In 1967, the DoD established a criterion-based approach, using a set of 35 criteria, called the Cost/Schedule Control Systems Criteria (C/SCSC). In the 1970s and early 1980s, a subculture of C/SCSC analysis grew, but the technique was often ignored or even actively resisted by project managers in both government and industry. C/SCSC was often considered a financial control tool that could be delegated to analytical specialists.\nIn 1989, EVM leadership was elevated to the Undersecretary of Defense for Acquisition, thus making EVM an element of program management and procurement. In 1991, Secretary of Defense Dick Cheney canceled the Navy A-12 Avenger II Program because of performance problems detected by EVM. This demonstrated that EVM mattered to secretary-level leadership. In the 1990s, many U.S. Government regulations were eliminated or streamlined. However, EVM not only survived the acquisition reform movement, but became strongly associated with the acquisition reform movement itself. Most notably, from 1995 to 1998, ownership of EVM criteria (reduced to 32) was transferred to industry by adoption of ANSI EIA 748-A standard.\nThe use of EVM has expanded beyond the U.S. Department of Defense. It was adopted by the National Aeronautics and Space Administration, the United States Department of Energy and other technology-related agencies.\nProject tracking.\nIt is helpful to see an example of project tracking that does not include earned value performance management. Consider a project that has been planned in detail, including a time-phased spend plan for all elements of work. Figure 1 shows the cumulative budget (cost) for this project as a function of time (the blue line, labeled PV). It also shows the cumulative actual cost of the project (red line, labeled AC) through week 8. To those unfamiliar with EVM, it might appear that this project was over budget through week 4 and then under budget from week 6 through week 8. However, what is missing from this chart is any understanding of how much work has been accomplished during the project. If the project was actually completed at week 8, then the project would actually be well under budget and well ahead of schedule. If, on the other hand, the project is only 10% complete at week 8, the project is significantly over budget and behind schedule. A method is needed to measure technical performance objectively and quantitatively, and that is what EVM accomplishes.\nProgress measurement sheet.\nProgress can be measured using a measurement sheet and employing various techniques including milestones, weighted steps, value of work done, physical percent complete, earned value, Level of Effort, earn as planned, and more. Progress can be tracked based on any measure \u2013 cost, hours, quantities, schedule, directly input percent complete, and more.\nProgress can be assessed using fundamental earned value calculations and variance analysis (Planned Cost, Actual Cost, and Earned Value); these calculations can determine where project performance currently is using the estimated project baseline's cost and schedule information.\nWith EVM.\nConsider the same project, except this time the project plan includes pre-defined methods of quantifying the accomplishment of work. At the end of each week, the project manager identifies every detailed element of work that has been completed, and sums the EV for each of these completed elements. Earned value may be accumulated monthly, weekly, or as progress is made. The Value of Work Done (VOWD) is mainly used in Oil &amp; Gas and is similar to the Actual Cost in EVM.\nEarned value (EV).\nformula_1\nEV is calculated by multiplying %complete of each task (completed or in progress) by its planned value\nFigure 2 shows the EV curve (in green) along with the PV curve from Figure 1. The chart indicates that technical performance (i.e. progress) started more rapidly than planned, but slowed significantly and fell behind schedule at week 7 and 8. This chart illustrates the schedule performance aspect of EVM. It is complementary to critical path or critical chain schedule management.\nFigure 3 shows the same EV curve (green) with the actual cost data from Figure 1 (in red). It can be seen that the project was actually under budget, relative to the amount of work accomplished, since the start of the project. This is a much better conclusion than might be derived from Figure 1.\nFigure 4 shows all three curves together \u2013 which is a typical EVM line chart. The best way to read these three-line charts is to identify the EV curve first, then compare it to PV (for schedule performance) and AC (for cost performance). It can be seen from this illustration that a true understanding of cost performance and schedule performance \"relies first on measuring technical performance objectively.\" This is the \"foundational principle\" of EVM.\nScaling EVM from simple to advanced implementations.\nThe \"foundational principle\" of EVM, mentioned above, does not depend on the size or complexity of the project. However, the \"implementations\" of EVM can vary significantly depending on the circumstances. In many cases, organizations establish an all-or-nothing threshold; projects above the threshold require a full-featured (complex) EVM system and projects below the threshold are exempted. Another approach that is gaining favor is to scale EVM implementation according to the project at hand and skill level of the project team.\nSimple implementations (emphasizing only technical performance).\nThere are many more small and simple projects than there are large and complex ones, yet historically only the largest and most complex have enjoyed the benefits of EVM. Still, lightweight implementations of EVM are achievable by any person who has basic spreadsheet skills. In fact, spreadsheet implementations are an excellent way to learn basic EVM skills.\nThe \"first step\" is to define the work. This is typically done in a hierarchical arrangement called a work breakdown structure (WBS), although the simplest projects may use a simple list of tasks. In either case, it is important that the WBS or list be comprehensive. It is also important that the elements be mutually exclusive, so that work is easily categorized into one and only one element of work. The most detailed elements of a WBS hierarchy (or the items in a list) are called work packages. Work packages are then often devolved further in the project schedule into tasks or activities.\nThe \"second step\" is to assign a value, called planned value (PV), to each work package. For large projects, PV is almost always an allocation of the total project budget, and may be in units of currency (e.g. dollar, euro or naira) or in labor hours, or both. However, in very simple projects, each activity may be assigned a weighted \"point value\" which might not be a budget number. Assigning weighted values and achieving consensus on all PV quantities yields an important benefit of EVM, because it exposes misunderstandings and miscommunications about the scope of the project, and resolving these differences should always occur as early as possible. Some terminal elements can not be known (planned) in great detail in advance, and that is expected, because they can be further refined at a later time.\nThe \"third step\" is to define \"earning rules\" for each work package. The simplest method is to apply just one earning rule, such as the 0/100 rule, to all activities. Using the 0/100 rule, no credit is earned for an element of work until it is finished. A related rule is called the 50/50 rule, which means 50% credit is earned when an element of work is started, and the remaining 50% is earned upon completion. Other fixed earning rules such as a 25/75 rule or 20/80 rule are gaining favor, because they assign more weight to finishing work than for starting it, but they also motivate the project team to identify when an element of work is started, which can improve awareness of work-in-progress. These simple earning rules work well for small or simple projects because generally, each activity tends to be fairly short in duration.\nThese initial three steps define the minimal amount of planning for simplified EVM. The \"final step\" is to execute the project according to the plan and measure progress. When activities are started or finished, EV is accumulated according to the earning rule. This is typically done at regular intervals (e.g. weekly or monthly), but there is no reason why EV cannot be accumulated in near real-time, when work elements are started/completed. In fact, waiting to update EV only once per month (simply because that is when cost data are available) only detracts from a primary benefit of using EVM, which is to create a technical performance scoreboard for the project team.\nIn a lightweight implementation such as described here, the project manager has not accumulated cost nor defined a detailed project schedule network (i.e. using a critical path or critical chain methodology). While such omissions are inappropriate for managing large projects, they are a common and reasonable occurrence in many very small or simple projects. Any project can benefit from using EV alone as a real-time score of progress. One useful result of this very simple approach (without schedule models and actual cost accumulation) is to compare EV curves of similar projects, as illustrated in Figure 5. In this example, the progress of three residential construction projects are compared by aligning the starting dates. If these three home construction projects were measured with the same PV valuations, the \"relative\" schedule performance of the projects can be easily compared.\nMaking earned value schedule metrics concordant with the CPM schedule.\nThe actual critical path is ultimately the determining factor of every project's duration. Because earned value schedule metrics take no account of critical path data, big budget activities that are not on the critical path have the potential to dwarf the impact of performing small budget critical path activities. This can lead to gaming the SV and Schedule Performance Index (SPI) metrics by ignoring critical path activities in favor of big-budget activities that may have more float. This can sometimes even lead to performing activities out-of-sequence just to improve the schedule tracking metrics, which can cause major problems with quality.\nA simple two-step process has been suggested to fix this:\nIn this way, the distorting aspect of float would be eliminated. There would be no benefit to performing a non-critical activity with many floats until it is due in proper sequence. Also, an activity would not generate a negative schedule variance until it had used up its float. Under this method, one way of gaming the schedule metrics would be eliminated. The only way of generating a positive schedule variance (or SPI over 1.0) would be by completing work on the current critical path ahead of schedule, which is in fact the only way for a project to get ahead of schedule.\nAdvanced implementations.\nIn addition to managing technical and schedule performance, large and complex projects require cost performance to be monitored and reviewed at regular intervals. To measure cost performance, planned value (BCWS) and earned value (BCWP) must be in the same currency units as actual costs.\nIn large implementations, the planned value curve is commonly called a Performance Measurement Baseline (PMB) and may be arranged in control accounts, summary-level planning packages, planning packages and work packages.\nIn large projects, establishing control accounts is the primary method of delegating responsibility and authority to various parts of the performing organization. Control accounts are cells of a responsibility assignment (RACI) matrix, which is the intersection of the project WBS and the organizational breakdown structure (OBS). Control accounts are assigned to Control Account Managers (CAMs).\nLarge projects require more elaborate processes for controlling baseline revisions, more thorough integration with subcontractor EVM systems, and more elaborate management of procured materials.\nIn the United States, the primary standard for full-featured EVM systems is the ANSI/EIA-748A standard, published in May 1998 and reaffirmed in August 2002. The standard defines 32 criteria for full-featured EVM system compliance. As of the year 2007, a draft of ANSI/EIA-748B, a revision to the original is available from ANSI. Other countries have established similar standards.\nIn addition to using BCWS and BCWP, implementations often use the term actual cost of work performed (ACWP) instead of AC. Additional acronyms and formulas include:\nBudget at completion (BAC).\nAccording to the PMBOK (7th edition) by the Project Management Institute (PMI), Budget at Completion (BAC) is the \"sum of all budgets established for the work to be performed.\"\nIt is the total planned value (PV or BCWS) at the end of the project. If a project has a management reserve (MR), it is typically \"not\" included in the BAC, and respectively, in the performance measurement baseline.\nCost variance (CV).\nAccording to the PMBOK (7th edition) by the Project Management Institute (PMI), Cost variance (CV) is a \"The amount of budget deficit or surplus at a given point in time, expressed as the difference between the earned value and the actual cost.\" Cost variance compares the estimated cost of a deliverable with the actual cost.\nformula_2\nCV greater than 0 is good (under budget).\nCost performance index (CPI).\nAccording to the PMBOK (7th edition) by the Project Management Institute (PMI), Cost performance index is a \"measure of the cost efficiency of budgeted resources expressed at the ratio of earned value to actual cost.\"\nformula_3\nCPI greater than 1 is favorable (under budget).\nCPI that is less than 1 means that the cost of completing the work is higher than planned (bad).\nWhen CPI is equal to 1, it means that the cost of completing the work is right on plan (good).\nCPI greater than 1 means that the cost of completing the work is less than planned (good or sometimes bad).\nHaving a CPI that is very high (in some cases, very high is only 1.2) may mean that the plan was too conservative, and thus a very high number may in fact not be good, as the CPI is being measured against a poor baseline. Management or the customer may be upset with the planners as an overly conservative baseline ties up available funds for other purposes, and the baseline is also used for manpower planning.\nEstimate at completion (EAC).\nAccording to the PMBOK (7th edition) by the Project Management Institute (PMI), Estimate at completion (EAC) is the \"expected total cost of completing all work expressed as the sum of the actual cost to date and the estimate to complete.\"\nEAC is the manager's projection of total cost of the project at completion.\nformula_4\nThis formula is based on the assumption, that the performance of the project (or rather a deviation of the actual performance from a baseline) to date gives a good indication of what a performance (or rather deviation of a performance from a baseline) will be in the future. In other words, this formula is using statistics of the project to date to predict future results. Therefore, it has to be used carefully, when the nature of the project in the future is likely to be different from the one to date (e.g. performance of the project compare to baseline at the design phase may not be a good indication of what it will be during a construction phase).\nEstimate to complete (ETC).\nAccording to the PMBOK (7th edition) by the Project Management Institute (PMI), Estimate to complete (ETC) is the \"expected cost to finish all the remaining project work.\"\nETC is the estimate to complete the remaining work of the project. ETC must be based on objective measures of the outstanding work remaining, typically based on the measures or estimates used to create the original planned value (PV) profile, including any adjustments to predict performance based on historical performance, actions being taken to improve performance, or acknowledgement of degraded performance.\nWhile algebraically, ETC = EAC-AC is correct, ETC should \"never\" be computed using either EAC or AC.\nIn the following equation:\nformula_5\nETC is the independent variable, EAC is the dependent variable, and AC is fixed based on expenditures to date. ETC should always be reported truthfully to reflect the project team estimate to complete the outstanding work. If ETC pushes EAC to exceed BAC, then project management skills are employed to either recommend performance improvements or scope change, but never force ETC to give the \"correct\" answer so that EAC=BAC. Managing project activities to keep the project within budget is a human factors activity, not a mathematical function.\nTo-complete performance index (TCPI).\nTo-complete performance index (TCPI) is an earned value management measure that estimates the cost performance needed to achieve a particular management objective.\nThe TCPI provides a projection of the anticipated performance required to achieve either the BAC or the EAC. TCPI indicates the future required cost efficiency needed to achieve a target BAC (Budget At Complete) or EAC (Estimate At Complete). Any significant difference between CPI, the cost performance to date, and the TCPI, the cost performance needed to meet the BAC or the EAC, should be accounted for by management in their forecast of the final cost.\nFor the TCPI based on BAC (describing the performance required to meet the original BAC budgeted total):\nformula_6\nor for the TCPI based on EAC (describing the performance required to meet a new, revised budget total EAC):\nformula_7\nThis implies, that if revised budget (EAC) is calculated using Earned Value methodology formula (BAC/CPI), then at the moment, when TCPI based on EAC is first time calculated, it will always be equal to CPI of a project at that moment. This happens because when EAC is calculated using formula BAC/CPI it is assumed, that cost performance of the remaining part of the project will be the same as the cost performance of the project to date.\nThe graph illustrates three scenarios outlined in PMI's \"Process Group: A Practice Guide\" (2022 edition, p. 311):\nIndependent estimate at completion (IEAC).\nThe IEAC is a metric to project total cost using the performance to date to project overall performance. This can be compared to the EAC, which is the manager's projection.\nformula_8\nLimitations.\nProponents of EVM note a number of issues with implementing it, and further limitations may be inherent to the concept itself.\nBecause EVM requires quantification of a project plan, it is often perceived to be inapplicable to discovery-driven or Agile software development projects. For example, it may be impossible to plan certain research projects far in advance, because research itself uncovers some opportunities (research paths) and actively eliminates others. However, another school of thought holds that all work can be planned, even if in weekly timeboxes or other short increments.\nTraditional EVM is not intended for non-discrete (continuous) effort. In traditional EVM standards, non-discrete effort is called \"level of effort\" (LOE). If a project plan contains a significant portion of LOE, and the LOE is intermixed with discrete effort, EVM results will be contaminated. This is another area of EVM research.\nTraditional definitions of EVM typically assume that project accounting and project network schedule management are prerequisites to achieving any benefit from EVM. Many small projects don't satisfy either of these prerequisites, but they too can benefit from EVM, as described for simple implementations, above. Other projects can be planned with a project network, but do not have access to true and timely actual cost data. In practice, the collection of true and timely actual cost data can be the most difficult aspect of EVM. Such projects can benefit from EVM, as described for intermediate implementations, above, and earned schedule.\nAs a means of overcoming objections to EVM's lack of connection to qualitative performance issues, the Naval Air Systems Command (NAVAIR) PEO(A) organization initiated a project in the late 1990s to integrate true technical achievement into EVM projections by utilizing risk profiles. These risk profiles anticipate opportunities that may be revealed and possibly be exploited as development and testing proceeds. The published research resulted in a Technical Performance Management (TPM) methodology and software application that is still used by many DoD agencies in informing EVM estimates with technical achievement.\nThe research was peer-reviewed and was the recipient of the Defense Acquisition University Acquisition Research Symposium 1997 Acker Award for excellence in the exchange of information in the field of acquisition research.\nThere is the difficulty inherent for any periodic monitoring of synchronizing data timing: actual deliveries, actual invoicing, and the date the EVM analysis is done are all independent, so that some items have arrived but their invoicing has not and by the time analysis is delivered the data will likely be weeks behind events. This may limit EVM to a less tactical or less definitive role where use is combined with other forms to explain why or add recent news and manage future expectations.\nThere is a measurement limitation for how precisely EVM can be used, stemming from classic conflict between accuracy and precision, as the mathematics can calculate deceptively far beyond the precision of the measurements of data and the approximation that is the plan estimation. The limitation on estimation is commonly understood (such as the ninety\u2013ninety rule in software) but is not visible in any margin of error. The limitations on measurement are largely a form of digitization error as EVM measurements ultimately can be no finer than by item, which may be the work breakdown structure terminal element size, to the scale of reporting period, typically end summary of a month, and by the means of delivery measure. (The delivery measure may be actual deliveries, may include estimates of partial work done at the end of month subject to estimation limits, and typically does not include QC check or risk offsets.)\nAs traditionally implemented, EVM deals with, and is based in, budget and cost. It has no relationship to the investment value or benefit for which the project has been funded and undertaken. Yet due to the use of the word \"value\" in the name, this fact is often misunderstood. However, earned value metrics can be used to compute the cost and schedule inputs to Devaux's Index of Project Performance (the DIPP), which integrates schedule and cost performance with the planned investment value of the project's scope across the project management triangle.\nDarling &amp; Whitty (2019) conducted an ethnographic study to see how EVM is implemented, applying Goffman's Dramaturgy (sociology), they found there is a sham act occurring through impressionable acts presenting statistical data as fact even when the data may be worthless. Findings include sham progress reporting can emerge in an environment where senior management's ignorance of project work creates unworkable binds for project staff. Moreover, the sham behaviour succeeds at its objective because senior management are vulnerable to false impressions. This situation raises ethical issues for those involved, and creates an overhead in dealing with the reality of project work. Further the Darling &amp; Whitty study is pertinent as it provides sociological insight to how a scientific management technique has been implemented."}
{"id": "9730", "revid": "33839581", "url": "https://en.wikipedia.org/wiki?curid=9730", "title": "Electron microscope", "text": "An electron microscope is a microscope that uses a beam of electrons as a source of illumination. They use electron optics that are analogous to the glass lenses of an optical light microscope to control the electron beam, for instance focusing them to produce magnified images or electron diffraction patterns. As the wavelength of an electron can be up to 100,000 times smaller than that of visible light, electron microscopes have a much higher resolution of about 0.1 nm, which compares to about 200 nm for light microscopes. \"Electron microscope\" may refer to:\nAdditional details can be found in the above links. This article contains some general information mainly about transmission electron microscopes.\nHistory.\nMany developments laid the groundwork of the electron optics used in microscopes. One significant step was the work of Hertz in 1883 who made a cathode-ray tube with electrostatic and magnetic deflection, demonstrating manipulation of the direction of an electron beam. Others were focusing of the electrons by an axial magnetic field by Emil Wiechert in 1899, improved oxide-coated cathodes which produced more electrons by Arthur Wehnelt in 1905 and the development of the electromagnetic lens in 1926 by Hans Busch. According to Dennis Gabor, the physicist Le\u00f3 Szil\u00e1rd tried in 1928 to convince him to build an electron microscope, for which Szil\u00e1rd had filed a patent. \nTo this day the issue of who invented the transmission electron microscope is controversial. In 1928, at the Technische Hochschule in Charlottenburg (now Technische Universit\u00e4t Berlin), Adolf Matthias (Professor of High Voltage Technology and Electrical Installations) appointed Max Knoll to lead a team of researchers to advance research on electron beams and cathode-ray oscilloscopes. The team consisted of several PhD students including Ernst Ruska. In 1931, Max Knoll and Ernst Ruska successfully generated magnified images of mesh grids placed over an anode aperture. The device, a replicate of which is shown in the figure, used two magnetic lenses to achieve higher magnifications, the first electron microscope. (Max Knoll died in 1969, so did not receive a share of the 1986 Nobel prize for the invention of electron microscopes.)\nApparently independent of this effort was work at Siemens-Schuckert by Reinhold R\u00fcdenberg. According to patent law (U.S. Patent No. 2058914 and 2070318, both filed in 1932), he is the inventor of the electron microscope, but it is not clear when he had a working instrument. He stated in a very brief article in 1932 that Siemens had been working on this for some years before the patents were filed in 1932, claiming that his effort was parallel to the university development. He died in 1961, so similar to Max Knoll, was not eligible for a share of the 1986 Nobel prize.\nIn the following year, 1933, Ruska and Knoll built the first electron microscope that exceeded the resolution of an optical (light) microscope. Four years later, in 1937, Siemens financed the work of Ernst Ruska and Bodo von Borries, and employed Helmut Ruska, Ernst's brother, to develop applications for the microscope, especially with biological specimens. Also in 1937, Manfred von Ardenne pioneered the scanning electron microscope. Siemens produced the first commercial electron microscope in 1938. The first North American electron microscopes were constructed in the 1930s, at the Washington State University by Anderson and Fitzsimmons and at the University of Toronto by Eli Franklin Burton and students Cecil Hall, James Hillier, and Albert Prebus. Siemens produced a transmission electron microscope (TEM) in 1939. Although current transmission electron microscopes are capable of two million times magnification, as scientific instruments they remain similar but with improved optics.\nIn the 1940s, high-resolution electron microscopes were developed, enabling greater magnification and resolution. By 1965, Albert Crewe at the University of Chicago introduced the scanning transmission electron microscope using a field emission source, enabling scanning microscopes at high resolution. By the early 1980s improvements in mechanical stability as well as the use of higher accelerating voltages enabled imaging of materials at the atomic scale. In the 1980s, the field emission gun became common for electron microscopes, improving the image quality due to the additional coherence and lower chromatic aberrations. The 2000s were marked by advancements in aberration-corrected electron microscopy, allowing for significant improvements in resolution and clarity of images.\nTypes.\nTransmission electron microscope (TEM).\nThe original form of the electron microscope, the transmission electron microscope (TEM), uses a high voltage electron beam to illuminate the specimen and create an image. An electron beam is produced by an electron gun, with the electrons typically having energies in the range 20 to 400 keV, focused by electromagnetic lenses, and transmitted through the specimen. When it emerges from the specimen, the electron beam carries information about the structure of the specimen that is magnified by lenses of the microscope. The spatial variation in this information (the \"image\") may be viewed by projecting the magnified electron image onto a detector. For example, the image may be viewed directly by an operator using a fluorescent viewing screen coated with a phosphor or scintillator material such as zinc sulfide. A high-resolution phosphor may also be coupled by means of a lens optical system or a fibre optic light-guide to the sensor of a digital camera. Direct electron detectors have no scintillator and are directly exposed to the electron beam, which addresses some of the limitations of scintillator-coupled cameras.\nThe resolution of TEMs is limited primarily by spherical aberration, but a new generation of hardware correctors can reduce spherical aberration to increase the resolution in high-resolution transmission electron microscopy (HRTEM) to below 0.5 angstrom (50 picometres), enabling magnifications above 50 million times. The ability of HRTEM to determine the positions of atoms within materials is useful for nano-technologies research and development.\nScanning transmission electron microscope (STEM).\nThe STEM rasters a focused incident probe across a specimen. The high resolution of the TEM is thus possible in STEM. The focusing action (and aberrations) occur before the electrons hit the specimen in the STEM, but afterward in the TEM. The STEMs use of SEM-like beam rastering simplifies annular dark-field imaging, and other analytical techniques, but also means that image data is acquired in serial rather than in parallel fashion.\nScanning electron microscope (SEM).\nThe SEM produces images by probing the specimen with a focused electron beam that is scanned across the specimen (raster scanning). When the electron beam interacts with the specimen, it loses energy by a variety of mechanisms. These interactions lead to, among other events, emission of low-energy secondary electrons and high-energy backscattered electrons, light emission (cathodoluminescence) or X-ray emission, all of which provide signals carrying information about the properties of the specimen surface, such as its topography and composition. The image displayed by SEM represents the varying intensity of any of these signals into the image in a position corresponding to the position of the beam on the specimen when the signal was generated.\nSEMs are different from TEMs in that they use electrons with much lower energy, generally below 20 keV, while TEMs generally use electrons with energies in the range of 80-300 keV. Thus, the electron sources and optics of the two microscopes have different designs, and they are normally separate instruments.\nMain operating modes.\nDiffraction contrast imaging.\nDiffraction contrast uses the variation in either or both the direction of diffracted electrons or their amplitude as the contrast mechanism. \nPhase contrast imaging.\nPhase contrast imaging involves generating contrast, for instance around edges, by defocusing the micriscope.\nElectron diffraction.\nTransmission electron microscopes can be used in electron diffraction mode where a map of the angles of the electrons leaving the sample is produced. The advantages of electron diffraction over X-ray crystallography are primarily in the size of the crystals. In X-ray crystallography, crystals are commonly visible by the naked eye and are generally in the hundreds of micrometers in length. In comparison, crystals for electron diffraction must be less than a few hundred nanometers in thickness, and have no lower boundary of size. Additionally, electron diffraction is done on a TEM, which can also be used to obtain many other types of information, rather than requiring a separate instrument.\nSample preparation.\nSamples for electron microscopes mostly cannot be observed directly. The samples need to be prepared to stabilize the sample and enhance contrast. Preparation techniques differ vastly in respect to the sample and its specific qualities to be observed as well as the specific microscope used.\nScanning Electron Microscope (SEM).\nTo prevent charging and enhance the signal in SEM, non-conductive samples (e.g. biological samples as in figure) can be sputter-coated in a thin film of metal.\nTransmission electron microscope.\nMaterials to be viewed in a transmission electron microscope (TEM) may require processing to produce a suitable sample. The technique required varies depending on the specimen and the analysis required:\nEM workflows.\nIn their most common configurations, electron microscopes produce images with a single brightness value per pixel, with the results usually rendered in greyscale. However, often these images are then colourized through the use of feature-detection software, or simply by hand-editing using a graphics editor. This may be done to clarify structure or for aesthetic effect and generally does not add new information about the specimen.\nElectron microscopes are now frequently used in more complex workflows, with each workflow typically using multiple technologies to enable more complex and/or more quantitative analyses of a sample. A few examples are outlined below, but this should not be considered an exhaustive list. The choice of workflow will be highly dependent on the application and the requirements of the corresponding scientific questions, such as resolution, volume, nature of the target molecule, etc.\nFor example, images from light and electron microscopy of the same region of a sample can be overlaid to correlate the data from the two modalities. This is commonly used to provide higher resolution contextual EM information about a fluorescently labelled structure. This correlative light and electron microscopy (CLEM) is one of a range of correlative workflows now available. Another example is high resolution mass spectrometry (ion microscopy), which has been used to provide correlative information about subcellular antibiotic localisation, data that would be difficult to obtain by other means.\nThe initial role of electron microscopes in imaging two-dimensional slices (TEM) or a specimen surface (SEM with secondary electrons) has also increasingly expanded into the depth of samples. An early example of these \u2018volume EM\u2019 workflows was simply to stack TEM images of serial sections cut through a sample. The next development was virtual reconstruction of a thick section (200-500 nm) volume by backprojection of a set of images taken at different tilt angles - TEM tomography.\nSerial imaging for volume EM.\nTo acquire volume EM datasets of larger depths than TEM tomography (micrometers or millimeters in the z axis), a series of images taken through the sample depth can be used. For example, ribbons of serial sections can be imaged in a TEM as described above, and when thicker sections are used, serial TEM tomography can be used to increase the z-resolution. More recently, back scattered electron (BSE) images can be acquired of a larger series of sections collected on silicon wafers, known as SEM array tomography. An alternative approach is to use BSE SEM to image the block surface instead of the section, after each section has been removed. By this method, an ultramicrotome installed in an SEM chamber can increase automation of the workflow; the specimen block is loaded in the chamber and the system programmed to continuously cut and image through the sample. This is known as serial block face SEM. A related method uses focused ion beam milling instead of an ultramicrotome to remove sections. In these serial imaging methods, the output is essentially a sequence of images through a specimen block that can be digitally aligned in sequence and thus reconstructed into a volume EM dataset. The increased volume available in these methods has expanded the capability of electron microscopy to address new questions, such as mapping neural connectivity in the brain, and membrane contact sites between organelles.\nDisadvantages.\nElectron microscopes are expensive to build and maintain. Microscopes designed to achieve high resolutions must be housed in stable buildings (sometimes underground) with special services such as magnetic field canceling systems.\nThe samples largely have to be viewed in vacuum, as the molecules that make up air would scatter the electrons. An exception is liquid-phase electron microscopy using either a closed liquid cell or an environmental chamber, for example, in the environmental scanning electron microscope, which allows hydrated samples to be viewed in a low-pressure (up to ) wet environment. Various techniques for in situ electron microscopy of gaseous samples have been developed.\nScanning electron microscopes operating in conventional high-vacuum mode usually image conductive specimens; therefore non-conductive materials require conductive coating (gold/palladium alloy, carbon, osmium, etc.). The low-voltage mode of modern microscopes makes possible the observation of non-conductive specimens without coating. Non-conductive materials can be imaged also by a variable pressure (or environmental) scanning electron microscope.\nSmall, stable specimens such as carbon nanotubes, diatom frustules and small mineral crystals (asbestos fibres, for example) require no special treatment before being examined in the electron microscope. Samples of hydrated materials, including almost all biological specimens, have to be prepared in various ways to stabilize them, reduce their thickness (ultrathin sectioning) and increase their electron optical contrast (staining). These processes may result in \"artifacts\", but these can usually be identified by comparing the results obtained by using radically different specimen preparation methods. Since the 1980s, analysis of cryofixed, vitrified specimens has also become increasingly used by scientists, further confirming the validity of this technique."}
{"id": "9731", "revid": "5839411", "url": "https://en.wikipedia.org/wiki?curid=9731", "title": "List of extinct bird species since 1500", "text": "About 129 species of birds have become extinct since 1500, and the rate of extinction seems to be increasing. The situation is exemplified by Hawaii, where 30% of all known recently extinct bird taxa originally lived. Other areas, such as Guam, have also been hit hard; Guam has lost over 60% of its native bird taxa in the last 30 years, many of them due to the introduced brown tree snake (\"Boiga irregularis\").\nCurrently there are approximately 10,000 living species of birds, with over 1,480 at risk of extinction and 223 critically endangered.\nIsland species in general, and flightless island species in particular, are most at risk. The disproportionate number of rails in this list reflects the tendency of that family to lose the ability to fly when geographically isolated. Even more rails became extinct before they could be described by scientists; these taxa are listed in List of Late Quaternary prehistoric bird species.\nThe extinction dates given below are usually approximations of the actual date of extinction. In some cases, more exact dates are given as it is sometimes possible to pinpoint the date of extinction to a specific year or even day (the San Benedicto rock wren is possibly the most extreme exampleits extinction could be timed with an accuracy of maybe half an hour). Extinction dates in the literature are usually the dates of the last verified record (credible observation or specimen taken); for many Pacific birds that became extinct shortly after European contact, however, this leaves an uncertainty period of over 100 years, because the islands on which they lived were only rarely visited by scientists.\nExtinct bird species.\nPaleognathes.\n\u2020Dinornithiformes.\nThe moa of New Zealand\nApterygiformes.\nThe kiwis of New Zealand\n\u2020Aepyornithiformes.\nThe elephant birds of Madagascar \nAnseriformes.\nDucks, geese and swans\nGalliformes.\nQuails and relatives\nSee also Bokaak \"bustard\" under Gruiformes below\nPodicipediformes.\nGrebes\nCharadriiformes.\nShorebirds, gulls and auks\nGruiformes.\nRails and allies - probably paraphyletic\nProcellariiformes.\nPetrels, storm petrels, shearwaters and albatrosses\nSphenisciformes.\nPenguins\nSuliformes.\nBoobies and related birds\nPelecaniformes.\nPelicans and related birds\nColumbiformes.\nPigeons, doves and dodos\nFor the \"R\u00e9union solitaire\", see R\u00e9union ibis.\nCuculiformes.\nCuckoos\nCathartiformes.\nNew World vultures\nStrigiformes.\nTrue owls and barn owls\nStrigidae - true owls\nTytonidae - barn owls\nCaprimulgiformes.\nCaprimulgidae - nightjars and nighthawks\nAegotheliformes.\nAegothelidae\nApodiformes.\nSwifts and hummingbirds\nCoraciiformes.\nKingfishers and related birds\nPiciformes.\nWoodpeckers and related birds\nFalconiformes.\nBirds of prey\nPsittaciformes.\nParrots\nPasseriformes.\nPerching birds\nTyrannidaetyrant flycatchers\nFurnariidaeovenbirds\nAcanthisittidaeNew Zealand \"wrens\"\nMohoidaeHawaiian honeyeaters. Family established in 2008, previously in Meliphagidae.\nMeliphagidaehoneyeaters and Australian chats\nAcanthizidaescrubwrens, thornbills, and gerygones\nPachycephalidaewhistlers, shrike-thrushes, pitohuis and allies\nDicruridaemonarch flycatchers and allies\nOriolidaeOld World orioles and allies\nCorvidaecrows, ravens, jays and magpies\nCallaeidaeNew Zealand wattlebirds\nHirundinidaeswallows and martins\nAcrocephalidaeacrocephalid warblers or marsh warblers, tree warblers and reed warblers\nMuscicapidaeOld World flycatchers and chats\nMegaluridaemegalurid warblers or grass warblers\nCisticolidaecisticolas and allies\nZosteropidaewhite-eyes. Probably belong in Timaliidae.\nPycnonotidaebulbuls\nSylvioidea \"incertae sedis\"\nSturnidaestarlings\nTurdidaethrushes and allies\nMimidaemockingbirds and thrashers\nEstrildidaeestrildid finches (waxbills, munias, etc.)\nIcteridaeNew World blackbirds and allies\nParulidaeNew World warblers\nPloceidaeweavers\nCardinalidaecardinals\nFringillidaetrue finches and Hawaiian honeycreepers\nEmberizidaebuntings and New World sparrows\nPossibly extinct bird subspecies or status unknown.\nThe extinction of subspecies is a subject that is very dependent on guesswork. National and international conservation projects and research publications such as red lists usually focus on species as a whole. Reliable information on the status of vulnerable, endangered or critically endangered subspecies usually has to be assembled piecemeal from published observations, such as regional checklists. Therefore, the following listing contains a high proportion of bird taxa that may still exist, but are listed here due to any one of, or any combination of, these three factors: absence of recent records, a known threat such as habitat destruction, or an observed decline.\nStruthioniformes.\nRatites and related birds\nAnseriformes.\nDucks, geese and swans\nGalliformes.\nQuails and relatives\nCharadriiformes.\nShorebirds, gulls and auks\nScolopacidaesandpipers\nTurnicidaebuttonquails\nGruiformes.\nRails and alliesprobably paraphyletic\nPelecaniformes.\nHerons and related birdspossibly paraphyletic\nColumbiformes.\nPigeons, doves and dodos\nCuculiformes.\nCuckoos\nStrigiformes.\nTrue owls and barn owls\nStrigidaetrue owls\nTytonidaebarn owls\nApodiformes.\nSwifts and hummingbirds\nCoraciiformes.\nKingfishers and related birds\nPiciformes.\nWoodpeckers and related birds\nAccipitriformes.\nBirds of prey\nFalconiformes.\nFalcons\nPsittaciformes.\nParrots\nPasseriformes.\nPerching birds\nPittidaepittas\nTyrannidaetyrant flycatchers\nFurnariidaeovenbirds\nFormicariidaeantpittas and antthrushes\nMaluridaeAustralasian \"wrens\"\nPardalotidaepardalotes, scrubwrens, thornbills and gerygones\nPetroicidaeAustralasian \"robins\"\nCinclosomatidaewhipbirds and allies\nArtamidaewoodswallows, currawongs and allies\nMonarchidaemonarch flycatchers\nRhipiduridaefantails\nCampephagidaecuckooshrikes and trillers\nOriolidaeOld World orioles and allies\nCorvidaecrows, ravens, jays and magpies\nRegulidaekinglets\nHirundinidaeswallows and martins\nPhylloscopidaephylloscopid warblers or leaf warblers\nCettiidaecettiid warblers or typical bush warblers\nAcrocephalidaeacrocephalid warblers or marsh warblers, tree warblers and reed warblers\nPycnonotidaebulbuls\nCisticolidaecisticolas and allies\nSylviidaesylviid (\"true\") warblers and parrotbills\nZosteropidaewhite-eyes. Probably belong in Timaliidae.\nTimaliidaeOld World babblers\n\"African warblers\"\nSylvioidea \"incertae sedis\"\nTroglodytidaewrens\nParidaetits, chickadees and titmice\nCinclidaedippers\nMuscicapidaeOld World flycatchers and chats\nTurdidaethrushes and allies\nMimidaemockingbirds and thrashers\nEstrildidaeestrildid finches (waxbills, munias, etc.)\nFringillidaetrue finches and Hawaiian honeycreepers\nIcteridaeNew World blackbirds and allies\nParulidaeNew World warblers\nThraupidaetanagers\nEmberizoideabuntings and New World sparrows"}
{"id": "9732", "revid": "48774147", "url": "https://en.wikipedia.org/wiki?curid=9732", "title": "Eli Whitney", "text": "Eli Whitney Jr. (December 8, 1765January 8, 1825) was an American inventor, widely known for inventing the cotton gin in 1793, one of the key inventions of the Industrial Revolution that shaped the economy of the Antebellum South.\nWhitney's invention made upland short cotton into a profitable crop, which strengthened the economic foundation of slavery in the United States and prolonged the institution. Despite the social and economic impact of his invention, Whitney lost much of his profits in legal battles over patent infringement for the cotton gin. Thereafter, he turned his attention to securing contracts with the government in the manufacture of muskets for the newly formed United States Army. He continued making arms and inventing until his death in 1825.\nEarly life and education.\nWhitney was born in Westborough, Massachusetts, on December 8, 1765, the eldest child of Eli Whitney Sr., a prosperous farmer, and his wife Elizabeth Fay, also of Westborough.\nThe younger Eli was famous during his lifetime and after his death by the name \"Eli Whitney\", though he was technically Eli Whitney Jr. His son, born in 1820, also named Eli, was known during his lifetime and afterward by the name \"Eli Whitney Jr.\"\nWhitney's mother, Elizabeth Fay, died in 1777, when he was 11. At age 14 he operated a profitable nail manufacturing operation in his father's workshop during the Revolutionary War.\nBecause his stepmother opposed his wish to attend college, Whitney worked as a farm laborer and school teacher to save money. He prepared for Yale at Leicester Academy (later Becker College) and under the tutelage of Rev. Elizur Goodrich of Durham, Connecticut, he entered Yale in the fall of 1789 and graduated Phi Beta Kappa in 1792. Whitney expected to study law but, finding himself short of funds, accepted an offer to go to South Carolina as a private tutor.\nInstead of reaching his destination, he was convinced to visit Georgia. In the closing years of the 18th century, Georgia was a magnet for New Englanders seeking their fortunes (its Revolutionary-era governor had been Lyman Hall, a migrant from Connecticut). When he initially sailed for South Carolina, among his shipmates were the widow (Catherine Littlefield Greene) and family of the Revolutionary hero Gen. Nathanael Greene of Rhode Island. Mrs. Greene invited Whitney to visit her Georgia plantation, Mulberry Grove. Her plantation manager and husband-to-be was Phineas Miller, another Connecticut migrant and Yale graduate (class of 1785), who would become Whitney's business partner.\nCareer.\nWhitney is most famous for two innovations which came to have significant impacts on the United States in the mid-19th century: the cotton gin (1793) and his advocacy of interchangeable parts. In the South, the cotton gin revolutionized the way cotton was harvested and reinvigorated slavery. Conversely, in the North the adoption of interchangeable parts revolutionized the manufacturing industry, contributing greatly to the U.S. victory in the Civil War.\nCotton gin.\nThe cotton gin is a mechanical device that removes the seeds from cotton, a process that had previously been extremely labor-intensive. The word \"gin\" is short for \"engine.\" While staying at Mulberry Grove, Whitney constructed several ingenious household devices which led Mrs Greene to introduce him to some businessmen who were discussing the desirability of a machine to\nseparate the short staple upland cotton from its seeds, work that was then done by hand at the rate of a pound of lint a day. In a few weeks Whitney produced a model. The cotton gin was a wooden drum stuck with hooks that pulled the cotton fibers through a mesh. The cotton seeds would not fit through the mesh and fell outside. Whitney occasionally told a story wherein he was pondering an improved method of seeding the cotton when he was inspired by observing a cat attempting to pull a chicken through a fence, and able to only pull through some of the feathers.\nA single cotton gin could generate up to of cleaned cotton daily. This contributed to the economic development of the Southern United States, a prime cotton growing area; some historians believe that this invention allowed for the African slavery system in the Southern United States to become more sustainable at a critical point in its development.\nWhitney applied for the patent for his cotton gin on October 28, 1793, and received the patent (later numbered as X72) on March 14, 1794, but it was not validated until 1807. Whitney and his partner, Miller, did not intend to sell the gins. Rather, like the proprietors of gristmills and sawmills, they expected to charge farmers for cleaning their cotton \u2013 two-fifths of the value, paid in cotton. Resentment at this scheme, the mechanical simplicity of the device and the primitive state of patent law, made infringement inevitable. Whitney and Miller could not build enough gins to meet demand, so gins from other makers found ready sale. Ultimately, patent infringement lawsuits consumed the profits (one patent, later annulled, was granted in 1796 to Hogden Holmes for a gin which substituted circular saws for the spikes) and their cotton gin company went out of business in 1797. One oft-overlooked point is that there were drawbacks to Whitney's first design. There are claims that the use of wires rather than pegs was proposed by Mrs. Greene, but these are disputed.\nAfter validation of the patent, the legislature of South Carolina voted $50,000 for the rights for that state, while North Carolina levied a license tax for five years, from which about $30,000 was realized. There is a claim that Tennessee paid about $10,000.\nWhile the cotton gin did not earn Whitney the fortune he had hoped for, it did give him fame. It has been argued by some historians that Whitney's cotton gin was an important if unintended cause of the American Civil War. After Whitney's invention, the plantation slavery industry was rejuvenated, eventually culminating in the Civil War.\nThe cotton gin transformed Southern agriculture and the national economy. Southern cotton found ready markets in Europe and in the burgeoning textile mills of New England. Cotton exports from the U.S. boomed after the cotton gin's appearance \u2013 from less than in 1793 to by 1810. Cotton was a staple that could be stored for long periods and shipped long distances, unlike most agricultural products. It became the U.S.'s chief export, representing over half the value of U.S. exports from 1820 to 1860.\nWhitney believed that his cotton gin would reduce the demand for enslaved labor and would help hasten the end of southern slavery. Paradoxically, the cotton gin, a labor-saving device, helped preserve and prolong slavery in the United States for another 70 years. Before the 1790s, slave labor was primarily employed in growing rice, tobacco, and indigo, none of which were especially profitable anymore. Neither was cotton, due to the difficulty of seed removal. But with the invention of the gin, growing cotton with slave labor became highly profitable \u2013 the chief source of wealth in the American South, and the basis of frontier settlement from Georgia to Texas. \"King Cotton\" became a dominant economic force, and slavery was sustained as a key institution of Southern society.\nInterchangeable parts.\nEli Whitney has often been incorrectly credited with inventing the idea of interchangeable parts, which he championed for years as a maker of muskets; however, the idea predated Whitney, and Whitney's role in it was one of promotion and popularizing, not invention. Successful implementation of the idea eluded Whitney until near the end of his life, occurring first in others' armories.\nAttempts at interchangeability of parts can be traced back as far as the Punic Wars through both archaeological remains of boats now in Museo Archeologico Baglio Anselmi and contemporary written accounts. In modern times the idea developed over decades among many people. An early leader was Jean-Baptiste Vaquette de Gribeauval, an 18th-century French artillerist who created a fair amount of standardization of artillery pieces, although not true interchangeability of parts. He inspired others, including Honor\u00e9 Blanc and Louis de Tousard, to work further on the idea, and on shoulder weapons as well as artillery. In the 19th century these efforts produced the \"armory system,\" or American system of manufacturing. Certain other New Englanders, including Captain John H. Hall and Simeon North, arrived at successful interchangeability before Whitney's armory did. The Whitney armory finally succeeded not long after his death in 1825.\nThe motives behind Whitney's acceptance of a contract to manufacture muskets in 1798 were mostly monetary. By the late 1790s, Whitney was on the verge of bankruptcy and the cotton gin litigation had left him deeply in debt. His New Haven cotton gin factory had burned to the ground, and litigation sapped his remaining resources. The French Revolution had ignited new conflicts between Great Britain, France, and the United States. The new American government, realizing the need to prepare for war, began to rearm. The War Department issued contracts for the manufacture of 10,000 muskets. Whitney, who had never made a gun in his life, obtained a contract in January 1798 to deliver 10,000 to 15,000 muskets in 1800. He had not mentioned interchangeable parts at that time. Ten months later, the Treasury Secretary, Oliver Wolcott Jr., sent him a \"foreign pamphlet on arms manufacturing techniques,\" possibly one of Honor\u00e9 Blanc's reports, after which Whitney first began to talk about interchangeability.\nIn May 1798, Congress voted for legislation that would use 800,000 dollars in order to pay for small arms and cannons in case war with France erupted. It offered a 5,000 dollar incentive with an additional 5,000 dollars once that money was exhausted for the person that was able to accurately produce arms for the government. Because the cotton gin had not brought Whitney the rewards he believed it promised, he accepted the offer. Although the contract was for one year, Whitney did not deliver the arms until 1809, using multiple excuses for the delay. Recently, historians have found that during 1801\u20131806, Whitney took the money and headed into South Carolina in order to profit from the cotton gin.\nAlthough Whitney's demonstration of 1801 appeared to show the feasibility of creating interchangeable parts, Merritt Roe Smith concludes that it was \"staged\" and \"duped government authorities\" into believing that he had been successful. The charade gained him time and resources toward achieving that goal.\nWhen the government complained that Whitney's price per musket compared unfavorably with those produced in government armories, he was able to calculate an actual price per musket by including fixed costs such as insurance and machinery, which the government had not accounted for. He thus made early contributions to both the concepts of cost accounting, and economic efficiency in manufacturing.\nMilling machine.\nMachine tool historian Joseph W. Roe credited Whitney with inventing the first milling machine circa 1818. Subsequent work by other historians (Woodbury; Smith; Muir; Battison [cited by Baida]) suggests that Whitney was among a group of contemporaries all developing milling machines at about the same time (1814 to 1818), and that the others were more important to the innovation than Whitney was. (The machine that excited Roe may not have been built until 1825, after Whitney's death.) Therefore, no one person can properly be described as the inventor of the milling machine.\nLater life and legacy.\nDespite his humble origins, Whitney was keenly aware of the value of social and political connections. In building his arms business, he took full advantage of the access that his status as a Yale alumnus gave him to other well-placed graduates, such as Oliver Wolcott Jr., Secretary of the Treasury (class of 1778), and James Hillhouse, a New Haven developer and political leader.\nHis 1817 marriage to Henrietta Edwards, granddaughter of the famed evangelist Jonathan Edwards, daughter of Pierpont Edwards, head of the Democratic Party in Connecticut, and first cousin of Yale's president, Timothy Dwight, the state's leading Federalist, further tied him to Connecticut's ruling elite. In a business dependent on government contracts, such connections were essential to success.\nWhitney died of prostate cancer on January 8, 1825, in New Haven, Connecticut, just a month after his 59th birthday. He left a widow and his four children behind. One of his offspring, Eli Whitney III (known as Eli Whitney Jr.), was instrumental in building New Haven, Connecticut's waterworks. During the course of his illness, he reportedly invented and constructed several devices to mechanically ease his pain.\nThe Eli Whitney Students Program, Yale University's admissions program for non-traditional students, is named in honor of Whitney, who not only began his studies there when he was 23, but also went on to graduate Phi Beta Kappa in just three years."}
{"id": "9734", "revid": "41865877", "url": "https://en.wikipedia.org/wiki?curid=9734", "title": "The American Prisoner", "text": "The American Prisoner is a British novel written by Eden Phillpotts and published in 1904 and adapted into a film by the same name in 1929. The story concerns an English woman who lives at Fox Tor farm, and an American captured during the American War of Independence and held at the prison at Princetown on Dartmoor.\nIn the novel \"Malherb\" is a miscreant who destroys Childe's tomb and beats his servant. He is depicted as a victim of his own bad temper rather than a sadist.\nMalherb is introduced as the younger son of a noble family and he builds the Fox Tor house to be the impressive gentleman's residence suggested by William Crossing rather than the humble cottage which it actually is."}
{"id": "9735", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=9735", "title": "Electromagnetic field", "text": "An electromagnetic field (also EM field) is a physical field, mathematical functions of position and time, representing the influences on and due to electric charges. The field at any point in space and time can be regarded as a combination of an electric field and a magnetic field. \nBecause of the interrelationship between the fields, a disturbance in the electric field can create a disturbance in the magnetic field which in turn affects the electric field, leading to an oscillation that propagates through space, known as an \"electromagnetic wave\".\nThe way in which charges and currents (i.e. streams of charges) interact with the electromagnetic field is described by Maxwell's equations and the Lorentz force law. Maxwell's equations detail how the electric field converges towards or diverges away from electric charges, how the magnetic field curls around electrical currents, and how changes in the electric and magnetic fields influence each other. The Lorentz force law states that a charge subject to an electric field feels a force along the direction of the field, and a charge moving through a magnetic field feels a force that is perpendicular both to the magnetic field and to its direction of motion. \nThe electromagnetic field is described by classical electrodynamics, an example of a classical field theory. This theory describes many macroscopic physical phenomena accurately. However, it was unable to explain the photoelectric effect and atomic absorption spectroscopy, experiments at the atomic scale. That required the use of quantum mechanics, specifically the quantization of the electromagnetic field and the development of quantum electrodynamics.\nHistory.\nThe empirical investigation of electromagnetism is at least as old as the ancient Greek philosopher, mathematician and scientist Thales of Miletus, who around 600\u00a0BCE described his experiments rubbing fur of animals on various materials such as amber creating static electricity. By the 18th century, it was understood that objects can carry positive or negative electric charge, that two objects carrying charge of the same sign repel each other, that two objects carrying charges of opposite sign attract one another, and that the strength of this force falls off as the square of the distance between them. Michael Faraday visualized this in terms of the charges interacting via the electric field. An electric field is produced when the charge is stationary with respect to an observer measuring the properties of the charge, and a magnetic field as well as an electric field are produced when the charge moves, creating an electric current with respect to this observer. Over time, it was realized that the electric and magnetic fields are better thought of as two parts of a greater whole\u2014the electromagnetic field. In 1820, Hans Christian \u00d8rsted showed that an electric current can deflect a nearby compass needle, establishing that electricity and magnetism are closely related phenomena. Faraday then made the seminal observation that time-varying magnetic fields could induce electric currents in 1831. \nIn 1861, James Clerk Maxwell synthesized all the work to date on electrical and magnetic phenomena into a single mathematical theory, from which he then deduced that light is an electromagnetic wave. Maxwell's continuous field theory was very successful until evidence supporting the atomic model of matter emerged. Beginning in 1877, Hendrik Lorentz developed an atomic model of electromagnetism and in 1897 J. J. Thomson completed experiments that defined the electron. The Lorentz theory works for free charges in electromagnetic fields, but fails to predict the energy spectrum for bound charges in atoms and molecules. For that problem, quantum mechanics is needed, ultimately leading to the theory of quantum electrodynamics.\nPractical applications of the new understanding of electromagnetic fields emerged in the late 1800s. The electrical generator and motor were invented using only the empirical findings like Faraday's and Ampere's laws combined with practical experience.\nMathematical description.\nThere are different mathematical ways of representing the electromagnetic field. The first one views the electric and magnetic fields as three-dimensional vector fields. These vector fields each have a value defined at every point of space and time and are thus often regarded as functions of the space and time coordinates. As such, they are often written as (electric field) and (magnetic field).\nIf only the electric field () is non-zero, and is constant in time, the field is said to be an electrostatic field. Similarly, if only the magnetic field () is non-zero and is constant in time, the field is said to be a magnetostatic field. However, if either the electric or magnetic field has a time-dependence, then both fields must be considered together as a coupled electromagnetic field using Maxwell's equations.\nWith the advent of special relativity, physical laws became amenable to the formalism of tensors. Maxwell's equations can be written in tensor form, generally viewed by physicists as a more elegant means of expressing physical laws.\nThe behavior of electric and magnetic fields, whether in cases of electrostatics, magnetostatics, or electrodynamics (electromagnetic fields), is governed by Maxwell's equations. In the vector field formalism, these are:\nwhere formula_5 is the charge density, which is a function of time and position, formula_6 is the vacuum permittivity, formula_7 is the vacuum permeability, and is the current density vector, also a function of time and position. Inside a linear material, Maxwell's equations change by switching the permeability and permittivity of free space with the permeability and permittivity of the linear material in question. Inside other materials which possess more complex responses to electromagnetic fields, these terms are often represented by complex numbers, or tensors.\nThe Lorentz force law governs the interaction of the electromagnetic field with charged matter.\nWhen a field travels across to different media, the behavior of the field changes according to the properties of the media.\nProperties of the field.\nElectrostatics and magnetostatics.\nThe Maxwell equations simplify when the charge density at each point in space does not change over time and all electric currents likewise remain constant. All of the time derivatives vanish from the equations, leaving two expressions that involve the electric field,\nformula_8\nand\nformula_9\nalong with two formulae that involve the magnetic field:\nformula_10\nand\nformula_11\nThese expressions are the basic equations of electrostatics, which focuses on situations where electrical charges do not move, and magnetostatics, the corresponding area of magnetic phenomena.\nTransformations of electromagnetic fields.\nWhether a physical effect is attributable to an electric field or to a magnetic field is dependent upon the observer, in a way that special relativity makes mathematically precise. For example, suppose that a laboratory contains a long straight wire that carries an electrical current. In the frame of reference where the laboratory is at rest, the wire is motionless and electrically neutral: the current, composed of negatively charged electrons, moves against a background of positively charged ions, and the densities of positive and negative charges cancel each other out. A test charge near the wire would feel no electrical force from the wire. However, if the test charge is in motion parallel to the current, the situation changes. In the rest frame of the test charge, the positive and negative charges in the wire are moving at different speeds, and so the positive and negative charge distributions are Lorentz-contracted by different amounts. Consequently, the wire has a nonzero net charge density, and the test charge must experience a nonzero electric field and thus a nonzero force. In the rest frame of the laboratory, there is no electric field to explain the test charge being pulled towards or pushed away from the wire. So, an observer in the laboratory rest frame concludes that a field must be present.\nIn general, a situation that one observer describes using only an electric field will be described by an observer in a different inertial frame using a combination of electric and magnetic fields. Analogously, a phenomenon that one observer describes using only a magnetic field will be, in a relatively moving reference frame, described by a combination of fields. The rules for relating the fields required in different reference frames are the Lorentz transformations of the fields.\nThus, electrostatics and magnetostatics are now seen as studies of the static EM field when a particular frame has been selected to suppress the other type of field, and since an EM field with both electric and magnetic will appear in any other frame, these \"simpler\" effects are merely a consequence of different frames of measurement. The fact that the two field variations can be reproduced just by changing the motion of the observer is further evidence that there is only a single actual field involved which is simply being observed differently.\nReciprocal behavior of electric and magnetic fields.\nThe two Maxwell equations, Faraday's Law and the Amp\u00e8re\u2013Maxwell Law, illustrate a very practical feature of the electromagnetic field. Faraday's Law may be stated roughly as \"a changing magnetic field inside a loop creates an electric voltage around the loop\". This is the principle behind the electric generator.\nAmpere's Law roughly states that \"an electrical current around a loop creates a magnetic field through the loop\". Thus, this law can be applied to generate a magnetic field and run an electric motor.\nBehavior of the fields in the absence of charges or currents.\nMaxwell's equations can be combined to derive wave equations. The solutions of these equations take the form of an electromagnetic wave. In a volume of space not containing charges or currents (free space) \u2013 that is, where formula_5 and are zero, the electric and magnetic fields satisfy these electromagnetic wave equations:\nJames Clerk Maxwell was the first to obtain this relationship by his completion of Maxwell's equations with the addition of a displacement current term to Ampere's circuital law. This unified the physical understanding of electricity, magnetism, and light: visible light is but one portion of the full range of electromagnetic waves, the electromagnetic spectrum.\nTime-varying EM fields in Maxwell's equations.\nAn electromagnetic field very far from currents and charges (sources) is called electromagnetic radiation (EMR) since it radiates from the charges and currents in the source. Such radiation can occur across a wide range of frequencies called the electromagnetic spectrum, including radio waves, microwave, infrared, visible light, ultraviolet light, X-rays, and gamma rays. The many commercial applications of these radiations are discussed in the named and linked articles.\nA notable application of visible light is that this type of energy from the Sun powers all life on Earth that either makes or uses oxygen.\nA changing electromagnetic field which is physically close to currents and charges (see near and far field for a definition of \"close\") will have a dipole characteristic that is dominated by either a changing electric dipole, or a changing magnetic dipole. This type of dipole field near sources is called an electromagnetic \"near-field\".\nChanging dipole fields, as such, are used commercially as near-fields mainly as a source of dielectric heating. Otherwise, they appear parasitically around conductors which absorb EMR, and around antennas which have the purpose of generating EMR at greater distances.\nChanging dipole fields (i.e., magnetic near-fields) are used commercially for many types of magnetic induction devices. These include motors and electrical transformers at low frequencies, and devices such as RFID tags, metal detectors, and MRI scanner coils at higher frequencies.\nHealth and safety.\nThe potential effects of electromagnetic fields on human health vary widely depending on the frequency, intensity of the fields, and the length of the exposure. Low frequency, low intensity, and short duration exposure to electromagnetic radiation is generally considered safe. On the other hand, radiation from other parts of the electromagnetic spectrum, such as ultraviolet light and gamma rays, are known to cause significant harm in some circumstances."}
{"id": "9736", "revid": "764861", "url": "https://en.wikipedia.org/wiki?curid=9736", "title": "Empire State Building", "text": "The Empire State Building is a 102-story Art Deco skyscraper in the Midtown South neighborhood of Manhattan in New York City. The building was designed by Shreve, Lamb &amp; Harmon and built from 1930 to 1931. Its name is derived from \"Empire State\", the nickname of the state of New York. The building has a roof height of and stands a total of tall, including its antenna. The Empire State Building was the world's tallest building until the first tower of the World Trade Center was topped out in 1970; following the September 11 attacks in 2001, the Empire State Building was New York City's tallest building until it was surpassed in 2012 by One World Trade Center. , the building is the seventh-tallest building in New York City, the ninth-tallest completed skyscraper in the United States, and the 57th-tallest completed skyscraper in the world.\nThe site of the Empire State Building, on the west side of Fifth Avenue between West 33rd and 34th Streets, was developed in 1893 as the Waldorf\u2013Astoria Hotel. In 1929, Empire State Inc. acquired the site and devised plans for a skyscraper there. The design for the Empire State Building was changed fifteen times until it was ensured to be the world's tallest building. Construction started on March 17, 1930, and the building opened thirteen and a half months afterward on May 1, 1931. Despite favorable publicity related to the building's construction, because of the Great Depression and World War II, its owners did not make a profit until the early 1950s.\nThe building's Art Deco architecture, height, and observation decks have made it a popular attraction. Around four\u00a0million tourists from around the world annually visit the building's 86th- and 102nd-floor observatories; an additional indoor observatory on the 80th floor opened in 2019. The Empire State Building is an international cultural icon: it has been featured in more than 250\u00a0television series and films since the film \"King Kong\" was released in 1933. The building's size has been used as a standard of reference to describe the height and length of other structures. A symbol of New York City, the building has been named as one of the Seven Wonders of the Modern World by the American Society of Civil Engineers. It was ranked first on the American Institute of Architects' List of America's Favorite Architecture in 2007. Additionally, the Empire State Building and its ground-floor interior were designated city landmarks by the New York City Landmarks Preservation Commission in 1980, and were added to the National Register of Historic Places as a National Historic Landmark in 1986.\nSite.\nThe Empire State Building is located on the west side of Fifth Avenue, between 33rd Street to the south and 34th Street to the north, in the Midtown South neighborhood of Manhattan in New York City. Tenants enter the building through the Art Deco lobby located at 350 Fifth Avenue. Visitors to the observatories use an entrance at 20 West 34th Street; prior to August 2018, visitors entered through the Fifth Avenue lobby. Although physically located in South Midtown, a mixed residential and commercial area, the building is so large that it was assigned its own ZIP Code, 10118; , it is one of 43 buildings in New York City that have their own ZIP codes.\nThe areas surrounding the Empire State Building are home to other major points of interest, including Macy's at Herald Square on Sixth Avenue and 34th Street, and Koreatown on 32nd Street between Madison and Sixth avenues. To the east of the Empire State Building is Murray Hill, a neighborhood with a mix of residential, commercial, and entertainment activity. The block directly to the northeast contains the B. Altman and Company Building, which houses the City University of New York's Graduate Center. The nearest New York City Subway stations are 34th Street\u2013Herald Square, one block west, and 33rd Street at Park Avenue, two blocks east; there is also a PATH station at 33rd Street and Sixth Avenue.\nArchitecture.\nThe Empire State Building was designed by Shreve, Lamb and Harmon in the Art Deco style. The Empire State Building is tall to its 102nd floor, or including its pinnacle. It was the first building in the world to be more than 100 stories tall, though only the lowest 86 stories are usable. The first through 85th floors contain of commercial and office space, while the 86th floor contains an observatory. The remaining 16 stories are part of the spire, which is capped by an observatory on the 102nd floor; the spire does not contain any intermediate levels and is used mostly for mechanical purposes. Atop the 102nd story is the pinnacle, much of which is covered by broadcast antennas, and surmounted with a lightning rod.\nForm.\nThe Empire State Building has a symmetrical massing because of its large lot and relatively short base. Its articulation consists of three horizontal sections\u2014a base, shaft, and capital\u2014similar to the components of a column. The five-story base occupies the entire lot, while the 81-story shaft above it is set back sharply from the base. The setback above the 5th story is deep on all sides. There are smaller setbacks on the upper stories, allowing sunlight to illuminate the interiors of the top floors while also positioning these floors away from the noisy streets below. The setbacks are located at the 21st, 25th, 30th, 72nd, 81st, and 85th stories. The setbacks correspond to the tops of elevator shafts, allowing interior spaces to be at most deep .\nThe setbacks were mandated by the 1916 Zoning Resolution, which was intended to allow sunlight to reach the streets as well. Normally, a building of the Empire State's dimensions would be permitted to build up to 12 stories on the Fifth Avenue side, and up to 17 stories on the 33rd Street and 34th Street sides, before it would have to utilize setbacks. However, with the largest setback being located above the base, the tower stories could contain a uniform shape. According to architectural writer Robert A. M. Stern, the building's form contrasted with the nearly contemporary, similarly designed 500 Fifth Avenue eight blocks north, which had an asymmetrical massing on a smaller lot.\nFacade.\nThe Empire State Building's Art Deco design is typical of pre\u2013World War II architecture in New York City. The facade is clad in Indiana limestone panels made by the Indiana Limestone Company and sourced from a quarry in south-central Indiana; the panels give the building its signature blonde color. According to official fact sheets, the facade uses of limestone and granite, ten million bricks, and of aluminum and stainless steel. The building also contains 6,514 windows. The decorative features on the facade are largely geometric, in contrast with earlier buildings, whose decorations often were intended to represent a specific narrative.\nThe main entrance, composed of three sets of metal doors, is at the center of the facade's Fifth Avenue elevation, flanked by molded piers that are topped with eagles. Above the main entrance is a transom, a triple-height transom window with geometric patterns, and the golden letters \"Empire State\" above the fifth-floor windows. There are two entrances each on 33rd and 34th streets, with modernistic, stainless steel canopies projecting from the entrances on 33rd and 34th streets there. Above the secondary entrances are triple windows, less elaborate in design than those on Fifth Avenue.\nThe storefronts on the first floor contain aluminum-framed doors and windows within a black granite cladding. The second through fourth stories consist of windows alternating with wide stone piers and narrower stone mullions. The fifth story contains windows alternating with wide and narrow mullions, and is topped by a horizontal stone sill.\nThe facade of the tower stories is split into several vertical bays on each side, with windows projecting slightly from the limestone cladding. The bays are arranged into sets of one, two, or three windows on each floor. The bays are separated by alternating narrow and wide piers, the inclusion of which may have been influenced by the design of the contemporary Daily News Building. The windows in each bay are separated by vertical nickel-chrome steel mullions and connected by horizontal aluminum spandrels between each floor. The windows are placed within stainless-steel frames, which saved money by eliminating the need to apply a stone finish around the windows. In addition, the use of aluminum spandrels obviated the need for cross-bonding, which would have been required if stone had been used instead.\nLights.\nThe building was originally equipped with white searchlights at the top. They were first used in November 1932 when they lit up to signal Roosevelt's victory over Hoover in the presidential election of that year. These were later swapped for four \"Freedom Lights\" in 1956. In February 1964, flood lights were added on the 72nd floor to illuminate the top of the building at night so that the building could be seen from the World Fair later that year. The lights were shut off from November 1973 to July 1974 because of the energy crisis at the time. In 1976, the businessman Douglas Leigh suggested that Wien and Helmsley install 204 metal-halide lights, which were four times as bright as the 1,000 incandescent lights they were to replace. New red, white, and blue metal-halide lights were installed in time for the country's bicentennial that July. After the bicentennial, Helmsley retained the new lights due to the reduced maintenance cost, about $116 a year.\nSince October 12, 1977, the spire has been lit in colors chosen to match seasonal events and holidays. Organizations are allowed to make requests through the building's website. The building is also lit in the colors of New York-based sports teams on nights when they host games: for example, orange, blue, and white for the New York Knicks; red, white, and blue for the New York Rangers. The spire can also be lit to commemorate events including disasters, anniversaries, or deaths, as well as for celebrations such as Pride and Halloween. In 1998, the building was lit in blue after the death of singer Frank Sinatra, who was nicknamed \"Ol' Blue Eyes\".\nThe structure was lit in red, white, and blue for several months after the September 11 attacks in 2001. On January 13, 2012, the building was lit in red, orange, and yellow to honor the 60th anniversary of the NBC program \"The Today Show\". After retired basketball player Kobe Bryant's January 2020 death, the building was lit in purple and gold, signifying the colors of his former team, the Los Angeles Lakers. The evening after iconic actor James Earl Jones died, September 9, 2024, the building was lit up to look like Jones's iconic Darth Vader villain from \"Star Wars.\"\nIn addition to lightings, the Empire State Building is able to do immersive visual projections on the building's exterior. It partnered with Netflix in May 2022 to celebrate the return of Stranger Things fourth season by projecting the Upside Down onto the Empire State Building.\nIn 2012, the building's four hundred metal halide lamps and floodlights were replaced with 1,200 LED fixtures, increasing the available colors from nine to over 16\u00a0million. The computer-controlled system allows the building to be illuminated in ways that were unable to be done previously with plastic gels. For instance, CNN used the top of the Empire State Building as a scoreboard during the 2012 United States presidential election, using red and blue lights to represent Republican and Democratic electoral votes respectively. Also, on November 26, 2012, the building had its first synchronized light show, using music from recording artist Alicia Keys. Artists such as Eminem and OneRepublic have been featured in later shows, including the building's annual Holiday Music-to-Lights Show. The building's owners adhere to strict standards in using the lights; for instance, they do not use the lights to play advertisements.\nInterior.\nAccording to official fact sheets, the Empire State Building weighs and has an internal volume of . The interior required of elevator cable and of electrical wires. It has a total floor area of , and each of the floors in the base cover . This gives the building capacity for 20,000 tenants and 15,000 visitors.\nThe riveted steel frame of the building was originally designed to handle all of the building's gravitational stresses and wind loads. The amount of material used in the building's construction resulted in a very stiff structure when compared to other skyscrapers, with a structural stiffness of versus the Willis Tower's and the John Hancock Center's . A December 1930 feature in \"Popular Mechanics\" estimated that a building with the Empire State's dimensions would still stand even if hit with an impact of .\nUtilities are grouped in a central shaft. On the 6th through 86th stories, the central shaft is surrounded by a main corridor on all four sides. Per the final specifications of the building, the corridor is surrounded in turn by office space deep, maximizing office space at a time before air conditioning became commonplace. Each of the floors has 210 structural columns that pass through it, which provide structural stability but limits the amount of open space on these floors. The relative dearth of stone in the Empire State Building allows for more space overall, with a 1:200 stone-to-building ratio compared to a 1:50 ratio in similar buildings.\nLobby.\nThe original main lobby is accessed from Fifth Avenue, on the building's east side, and is the only place in the building where the design contains narrative motifs. It contains an entrance with one set of double doors between a pair of revolving doors. At the top of each doorway is a bronze motif depicting one of three \"crafts or industries\" used in the building's construction\u2014Electricity, Masonry, and Heating. The three-story-high space runs parallel to 33rd and 34th Streets. The lobby contains two tiers of marble: a wainscoting of darker marble, topped by lighter marble. There is a pattern of zigzagging terrazzo tiles on the lobby floor, which leads from east to west. To the north and south are storefronts, which are flanked by tubes of dark rounded marble and topped by a vertical band of grooves set into the marble. Until the 1960s, there was a Longchamps restaurant next to the lobby, with six oval murals designed by Winold Reiss; these murals were placed in storage when the Longchamps closed.\nThe western ends of the north and south walls include escalators to a mezzanine level. At the west end of the lobby, behind the security desk, is an aluminum relief of the skyscraper as it was originally built (without the antenna). The relief, which was intended to provide a welcoming effect, contains an embossed outline of the building, with rays radiating from the spire and the sun behind it. In the background is a state map of New York with the building's location marked by a \"medallion\" in the very southeast portion of the outline. A compass is depicted in the bottom right and a plaque to the building's major developers is on the bottom left. A scale model of the building was also placed south of the security desk.\nThe plaque at the western end of the lobby is on the eastern interior wall of a one-story-tall rectangular-shaped corridor that surrounds the banks of escalators, with a similar design to the lobby. The rectangular-shaped corridor actually consists of two long hallways on the northern and southern sides of the rectangle, as well as a shorter hallway on the eastern side and another long hallway on the western side. At both ends of the northern and southern corridors, there is a bank of four low-rise elevators in between the corridors. The western side of the rectangular elevator-bank corridor extends north to the 34th Street entrance and south to the 33rd Street entrance. It borders three large storefronts and leads to escalators (originally stairs), which go both to the second floor and to the basement. Going from west to east, there are secondary entrances to 34th and 33rd Streets from the northern and southern corridors, respectively. The side entrances from 33rd and 34th Street lead to two-story-high corridors around the elevator core, crossed by stainless steel-and-glass-enclosed bridges at the mezzanine floor.\nUntil the 1960s, an Art Deco mural, inspired by both the sky and the Machine Age, was installed in the lobby ceilings. Subsequent damage to these murals, designed by artist Leif Neandross, resulted in reproductions being installed. Renovations to the lobby in 2009, such as replacing the clock over the information desk in the Fifth Avenue lobby with an anemometer and installing two chandeliers intended to be part of the building when it originally opened, revived much of its original grandeur. The north corridor contained eight illuminated panels created in 1963 by Roy Sparkia and Ren\u00e9e Nemorov, in time for the 1964 World's Fair, depicting the building as the Eighth Wonder of the World alongside the traditional seven. The building's owners installed a series of paintings by the New York artist Kysa Johnson in the concourse level. Johnson later filed a federal lawsuit, in January 2014, under the Visual Artists Rights Act alleging the negligent destruction of the paintings and damage to her reputation as an artist. As part of the building's 2010 renovation, Denise Amses commissioned a work consisting of 15,000 stars and 5,000 circles, superimposed on a etched-glass installation, in the lobby.\nElevators.\nThe Empire State Building has 73 elevators in all, including service elevators. Its original 64 elevators, built by the Otis Elevator Company, in a central core and are of varying heights, with the longest of these elevators reaching from the lobby to the 80th floor. As originally built, there were four \"express\" elevators that connected the lobby, 80th floor, and several landings in between; the other 60 \"local\" elevators connected the landings with the floors above these intermediate landings. Of the 64 total elevators, 58 were for passenger use (comprising the four express elevators and 54 local elevators), and eight were for freight deliveries. The elevators were designed to move at . At the time of the skyscraper's construction, their practical speed was limited to per city law, but this limit was removed shortly after the building opened.\nAdditional elevators connect the 80th floor to the six floors above it, as the six extra floors were built after the original 80 stories were approved. The elevators were mechanically operated until 2011, when they were replaced with automatic elevators during the $550\u00a0million renovation of the building. An additional elevator connects the 86th and 102nd floor observatories, which allows visitors access to the 102nd floor observatory after having their tickets scanned. It also allows employees to access the mechanical floors located between the 87th and 101st floors.\nObservation decks.\nThe 80th, 86th, and 102nd floors contain observatories. The latter two observatories saw a combined average of four\u00a0million visitors per year in 2010. Since opening, the observatories have been more popular than similar observatories at 30 Rockefeller Plaza, the Chrysler Building, the first One World Trade Center, or the Woolworth Building, despite being more expensive. There are variable charges to enter the observatories; one ticket allows visitors to go as high as the 86th floor, and there is an additional charge to visit the 102nd floor. Other ticket options for visitors include scheduled access to view the sunrise from the observatory, a \"premium\" guided tour with VIP access, and the \"AM/PM\" package which allows for two visits in the same day.\nThe 86th floor observatory contains both an enclosed viewing gallery and an open-air outdoor viewing area, allowing for it to remain open 365 days a year regardless of the weather. The 102nd floor observatory is completely enclosed and much smaller in size. The 102nd floor observatory was closed to the public from the late 1990s to 2005 due to limited viewing capacity and long lines. The observation decks were redesigned in mid-1979. The 102nd floor was again redesigned in a project that was completed in 2019, allowing the windows to be extended from floor to ceiling and widening the space in the observatory overall. An observatory on the 80th floor, opened in 2019, includes various exhibits as well as a mural of the skyline drawn by British artist Stephen Wiltshire. An interactive multimedia museum, with multiple hands-on exhibitions about the building's history, was added during this project. The design of the Observatory Experience was inspired by the plans and designs of the original Empire State Building.\nAccording to a 2010 report by Concierge.com, the five lines to enter the observation decks are \"as legendary as the building itself\". Concierge.com stated that there were five lines: the sidewalk line, the lobby elevator line, the ticket purchase line, the second elevator line, and the line to get off the elevator and onto the observation deck. In 2016, New York City's official tourism website made note of only three lines: the security check line, the ticket purchase line, and the second elevator line. Following renovations completed in 2019, designed to streamline queuing and reduce wait times, guests enter from a single entrance on 34th Street, where they make their way through exhibits on their way up to the observatories. Guests were offered a variety of ticket packages, including a package that enables them to skip the lines throughout the duration of their stay. The Empire State Building garners significant revenue from ticket sales for its observation decks, making more money from ticket sales than it does from renting office space during some years.\nNew York Skyride.\nIn early 1994, a motion simulator attraction was built on the 2nd floor, as a complement to the observation deck. The original cinematic presentation lasted approximately 25\u00a0minutes, while the simulation was about eight minutes. The ride had two incarnations. The original version, which ran from 1994 until around 2002, featured James Doohan, \"\" Scotty, as the airplane's pilot who humorously tried to keep the flight under control during a storm. After the September 11 attacks in 2001, the ride was closed. An updated version debuted in mid-2002, featuring actor Kevin Bacon as the pilot, with the new flight also going haywire. This new version served a more informative goal, as opposed to the old version's main purpose of entertainment, and contained details about the 9/11 attacks. The simulator received mixed reviews, with assessments of the ride ranging from \"great\" to \"satisfactory\" to \"corny\".\nSpire.\nAbove the 102nd floor.\nThe final stage of the building was the installation of a hollow mast, a steel shaft fitted with elevators and utilities, above the 86th floor. The spire of the Empire State Building was originally intended to serve as a mooring mast for zeppelins and other airships, although the plan was abandoned after high winds made that impossible. At the top would be a conical roof and the 102nd-floor docking station. Inside, the elevators would ascend from the 86th-floor ticket offices to a 101st-floor waiting room. From there, stairs would lead to the 102nd floor, where passengers would enter the airships. The airships would have been moored to the spire at the equivalent of the building's 106th floor.\nAs constructed, the mast contains four rectangular tiers topped by a cylindrical shaft with a conical pinnacle. On the 102nd floor (formerly the 101st floor), there is a door with stairs ascending to the 103rd floor (formerly the 102nd). This was built as a disembarkation floor for airships tethered to the building's spire, and has a circular balcony outside. It is now an access point to reach the spire for maintenance. The room now contains electrical equipment, but celebrities and dignitaries may also be given permission to take pictures there. A set of stairs and a ladder ascend to the spire and are used by maintenance workers. The mast's 480 windows were all replaced in 2015. The mast serves as the base of the building's broadcasting antenna.\nInflatable objects have sometimes been mounted to the spire for promotional purposes. For example, a King Kong balloon was attached to the spire in 1983 to mark the 50th anniversary of the character's introduction, and an inflatable dragon was placed on the spire in 2024 to promote the TV series \"House of Dragon\".\nBroadcast stations.\nBroadcasting began at the Empire State Building on December 22, 1931, when NBC and RCA began transmitting experimental television broadcasts from a small antenna erected atop the mast, with two separate transmitters for the visual and audio data. They leased the 85th floor and built a laboratory there. In 1934, RCA was joined by Edwin Howard Armstrong in a cooperative venture to test his FM system from the building's antenna. This setup, which entailed the installation of the world's first FM transmitter, continued only until October of the next year due to disputes between RCA and Armstrong. Specifically, NBC wanted to install more TV equipment in the room where Armstrong's transmitter was located.\nAfter some time, the 85th floor became home to RCA's New York television operations initially as experimental station W2XBS channel 1 then, from 1941, as commercial station WNBT channel 1 (now WNBC channel 4). NBC's FM station, W2XDG, began transmitting from the antenna in 1940. NBC retained exclusive use of the top of the building until 1950 when the Federal Communications Commission (FCC) ordered the exclusive deal be terminated. The FCC directive was based on consumer complaints that a common location was necessary for the seven extant New York-area television stations to transmit from so that receiving antennas would not have to be constantly adjusted. Other television broadcasters would later join RCA at the building on the 81st through 83rd floors, often along with sister FM stations. Construction of a dedicated broadcast tower began on July 27, 1950, with TV, and FM, transmissions starting in 1951. The broadcast tower was completed in 1953. From 1951, six broadcasters agreed to pay a combined $600,000 per year for the use of the antenna. In 1965, a separate set of FM antennae was constructed ringing the 103rd floor observation area to act as a master antenna.\nThe placement of the stations in the Empire State Building became a major issue with the construction of the World Trade Center's Twin Towers in the late 1960s, and early 1970s. The greater height of the Twin Towers would reflect radio waves broadcast from the Empire State Building, eventually resulting in some broadcasters relocating to the newer towers instead of suing the developer, the Port Authority of New York and New Jersey. Even though the nine stations who were broadcasting from the Empire State Building were leasing their broadcast space until 1984, most of these stations moved to the World Trade Center as soon as it was completed in 1971. The broadcasters obtained a court order stipulating that the Port Authority had to build a mast and transmission equipment in the North Tower, as well as pay the broadcasters' leases in the Empire State Building until 1984. Only a few broadcasters renewed their leases in the Empire State Building.\nThe September 11 attacks destroyed the World Trade Center and the broadcast centers atop it, leaving most of the city's stations without a transmitter for ten days until the Armstrong Tower in Alpine, New Jersey, was re-activated temporarily. By October 2001, nearly all of the city's commercial broadcast stations (both television and FM radio) were again transmitting from the top of the Empire State Building. In a report that Congress commissioned about the transition from analog television to digital television, it was stated that the placement of broadcast stations in the Empire State Building was considered \"problematic\" due to interference from nearby buildings. In comparison, the congressional report stated that the former Twin Towers had very few buildings of comparable height nearby thus signals suffered little interference. In 2003, a few FM stations were relocated to the nearby Cond\u00e9 Nast Building to reduce the number of broadcast stations using the Empire State Building. Eleven television stations and twenty-two FM stations had signed 15-year leases in the building by May 2003. It was expected that a taller broadcast tower in Bayonne, New Jersey, or Governors Island, would be built in the meantime with the Empire State Building being used as a \"backup\" since signal transmissions from the building were generally of poorer quality. Following the construction of One World Trade Center in the late 2000s and early 2010s, some TV stations began moving their transmitting facilities there.\n, the Empire State Building is home to the following stations:\nHistory.\nThe site was previously owned by John Jacob Astor of the prominent Astor family, who had owned the site since the mid-1820s. In 1893, John Jacob Astor Sr.'s grandson William Waldorf Astor opened the Waldorf Hotel on the site. Four years later, his cousin, John Jacob Astor IV, opened the 16-story Astoria Hotel on an adjacent site. The two portions of the Waldorf\u2013Astoria hotel had 1,300 bedrooms, making it the largest hotel in the world at the time. After the death of its founding proprietor, George Boldt, in early 1918, the hotel lease was purchased by Thomas Coleman du Pont. By the 1920s, the old Waldorf\u2013Astoria was becoming dated and the elegant social life of New York had moved much farther north. Additionally, many stores had opened on Fifth Avenue north of 34th Street. The Astor family decided to build a replacement hotel on Park Avenue and sold the hotel to Bethlehem Engineering Corporation in 1928 for $14\u201316\u00a0million. The hotel closed shortly thereafter on May 3, 1929.\nPlanning.\nEarly plans.\nBethlehem Engineering Corporation originally intended to build a 25-story office building on the Waldorf\u2013Astoria site. The company's president, Floyd De L. Brown, paid $100,000 of the $1\u00a0million down payment required to start construction on the building, with the promise that the difference would be paid later. Brown borrowed $900,000 from a bank but defaulted on the loan.\nAfter Brown was unable to secure additional funding, the land was resold to Empire State Inc., a group of wealthy investors that included Louis G. Kaufman, Ellis P. Earle, John J. Raskob, Coleman du Pont, and Pierre S. du Pont. The name came from the state nickname for New York. Alfred E. Smith, a former Governor of New York and U.S. presidential candidate whose 1928 campaign had been managed by Raskob, was appointed head of the company. The group also purchased nearby land so they would have the needed for the base, with the combined plot measuring wide by long. The Empire State Inc. consortium was announced to the public in August 1929. Concurrently, Smith announced the construction of an 80-story building on the site, to be taller than any other buildings in existence.\nEmpire State Inc. contracted William F. Lamb, of architectural firm Shreve, Lamb and Harmon, to create the building design. Lamb produced the initial building design using the firm's earlier designs for the Reynolds Building in Winston-Salem, North Carolina, as the basis. He had also been inspired by Raymond Hood's design for the Daily News Building, which was being constructed at the same time. Concurrently, Lamb's partner Richmond Shreve created \"bug diagrams\" of the project requirements. The 1916 Zoning Act forced Lamb to design a structure that incorporated setbacks resulting in the lower floors being larger than the upper floors. Consequently, the building was conceived from the top down, giving it a pencil-like shape. The plans were devised within a budget of $50 million and a stipulation that the building be ready for occupancy within 18 months of the start of construction. Design drawings and construction were concurrent. Steel drawings were completed in mid-January 1930, when foundations were underway.\nDesign changes.\nThe original plan of the building was 50 stories, but was later increased to 60 and then 80 stories. Height restrictions were placed on nearby buildings to ensure that the top fifty floors of the planned 80-story, building would have unobstructed views of the city. \"The New York Times\" lauded the site's proximity to mass transit, with the Brooklyn\u2013Manhattan Transit's 34th Street station and the Hudson and Manhattan Railroad's 33rd Street terminal one block away, as well as Penn Station two blocks away and Grand Central Terminal nine blocks away at its closest. It also praised the of proposed floor space near \"one of the busiest sections in the world\". The Empire State Building was to be a typical office building, but Raskob intended to build it \"better and in a bigger way\", according to architectural writer Donald J. Reynolds.\nWhile plans for the Empire State Building were being finalized, an intense competition in New York for the title of \"world's tallest building\" was underway. 40 Wall Street (then the Bank of Manhattan Building) and the Chrysler Building in Manhattan both vied for this distinction and were already under construction when work began on the Empire State Building. The \"Race into the Sky\", as popular media called it at the time, was representative of the country's optimism in the 1920s, fueled by the building boom in major cities. The race was defined by at least five other proposals, although only the Empire State Building would survive the Wall Street Crash of 1929. The 40 Wall Street tower was revised, in April 1929, from to making it the world's tallest. The Chrysler Building added its steel tip to its roof in October 1929, thus bringing it to a height of and greatly exceeding the height of 40 Wall Street. The Chrysler Building's developer, Walter Chrysler, realized that his tower's height would exceed the Empire State Building's as well, having instructed his architect, William Van Alen, to change the Chrysler's original roof from a stubby Romanesque dome to a narrow steel spire. Raskob, wishing to have the Empire State Building be the world's tallest, reviewed the plans and had five floors added as well as a spire; however, the new floors would need to be set back because of projected wind pressure on the extension. On November 18, 1929, Smith acquired a lot at 27\u201331 West 33rd Street, adding to the width of the proposed office building's site. Two days later, Smith announced the updated plans for the skyscraper. The plans included an observation deck on the 86th-floor roof at a height of , higher than the Chrysler's 71st-floor observation deck.\nThe 1,050-foot Empire State Building would only be taller than the Chrysler Building, and Raskob was afraid that Chrysler might try to \"pull a trick like hiding a rod in the spire and then sticking it up at the last minute.\" The plans were revised one last time in December 1929, to include a 16-story, metal \"crown\" and an additional mooring mast intended for dirigibles. The roof height was now , making it the tallest building in the world by far, even without the antenna. The addition of the dirigible station meant that another floor, the 86th, would have to be built below the crown; however, unlike the Chrysler's spire, the Empire State's mast would serve a practical purpose. A revised plan was announced to the public in late December 1929, just before the start of construction. The final plan was sketched within two hours, the night before the plan was supposed to be presented to the site's owners in January 1930. \"The New York Times\" reported that the spire was facing some \"technical problems\", but they were \"no greater than might be expected under such a novel plan.\" By this time the blueprints for the building had gone through up to fifteen versions before they were approved. Lamb described the other specifications he was given for the final, approved plan:\nConstruction.\nThe contractors were Starrett Brothers and Eken, which were composed of Paul and William A. Starrett and Andrew J. Eken. The project was financed primarily by Raskob and Pierre du Pont, while James Farley's General Builders Supply Corporation supplied the building materials. John W. Bowser was the construction superintendent of the project, and the structural engineer of the building was Homer G. Balcom. The tight completion schedule necessitated the commencement of construction even though the design had yet to be finalized.\nHotel demolition.\nDemolition of the old Waldorf\u2013Astoria began on October 1, 1929. Stripping the building down was an arduous process, as the hotel had been constructed using more rigid material than earlier buildings had been. Furthermore, the old hotel's granite, wood chips, and \"'precious' metals such as lead, brass, and zinc\" were not in high demand, resulting in issues with disposal. Most of the wood was deposited into a woodpile on nearby 30th Street or was burned in a swamp elsewhere. Much of the other materials that made up the old hotel, including the granite and bronze, were dumped into the Atlantic Ocean near Sandy Hook, New Jersey.\nBy the time the hotel's demolition started, Raskob had secured the required funding for the construction of the building. The plan was to start construction later that year but, on October 24, the New York Stock Exchange experienced the major and sudden Wall Street Crash, marking the beginning of the decade-long Great Depression. Despite the economic downturn, Raskob refused to cancel the project because of the progress that had been made up to that point. Neither Raskob, who had ceased speculation in the stock market the previous year, nor Smith, who had no stock investments, suffered financially in the crash. However, most of the investors were affected and as a result, in December 1929, Empire State Inc. obtained a $27.5\u00a0million loan from Metropolitan Life Insurance Company so construction could begin. The stock market crash resulted in no demand for new office space; Raskob and Smith nonetheless started construction, as canceling the project would have resulted in greater losses for the investors.\nSteel structure.\nA structural steel contract was awarded on January 12, 1930, with excavation of the site beginning ten days later on January 22, before the old hotel had been completely demolished. Two twelve-hour shifts, consisting of 300 men each, worked continuously to dig the deep foundation. Small pier holes were sunk into the ground to house the concrete footings that would support the steelwork. Excavation was nearly complete by early March, and construction on the building itself started on March 17, with the builders placing the first steel columns on the completed footings before the rest of the footings had been finished. Around this time, Lamb held a press conference on the building plans. He described the reflective steel panels parallel to the windows, the large-block Indiana Limestone facade that was slightly more expensive than smaller bricks, and the building's vertical lines. Four colossal columns, intended for installation in the center of the building site, were delivered; they would support a combined when the building was finished.\nThe structural steel was pre-ordered and pre-fabricated in anticipation of a revision to the city's building code that would have allowed the Empire State Building's structural steel to carry , up from , thus reducing the amount of steel needed for the building. Although the 18,000-psi regulation had been safely enacted in other cities, Mayor Jimmy Walker did not sign the new codes into law until March 26, 1930, just before construction was due to commence. The first steel framework was installed on April 1, 1930. From there, construction proceeded at a rapid pace; during one stretch of 10 working days, the builders erected fourteen floors. This was made possible through precise coordination of the building's planning, as well as the mass production of common materials such as windows and spandrels. On one occasion, when a supplier could not provide timely delivery of dark Hauteville marble, Starrett switched to using Rose Famosa marble from a German quarry that was purchased specifically to provide the project with sufficient marble.\nThe scale of the project was massive, with trucks carrying \"16,000 partition tiles, 5,000 bags of cement, of sand and 300 bags of lime\" arriving at the construction site every day. There were also cafes and concession stands on five of the incomplete floors so workers did not have to descend to the ground level to eat lunch. Temporary water taps were installed so workers did not waste time buying water bottles from the ground level. Carts running on a small railway system transported materials from the basement storage to elevators that brought the carts to the desired floors where they would then be distributed throughout that level using another set of tracks. The of steel ordered for the project was the largest-ever single order of steel at the time, comprising more steel than was ordered for the Chrysler Building and 40 Wall Street combined. According to historian John Tauranac, building materials were sourced from numerous, and distant, sources with \"limestone from Indiana, steel girders from Pittsburgh, cement and mortar from upper New York State, marble from Italy, France, and England, wood from northern and Pacific Coast forests, [and] hardware from New England.\" The facade, too, used a variety of material\u2014most prominently Indiana limestone but also architectural terracotta, brick, and black granite from Sweden.\nBy June 20, the skyscraper's supporting steel structure had risen to the 26th floor, and by July 27, half of the steel structure had been completed. Starrett Bros. and Eken endeavored to build one floor a day in order to speed up construction, achieving a pace of four and a half stories per week; prior to this, the fastest pace of construction for a building of similar height had been three and a half stories per week. While construction progressed, the final designs for the floors were being designed from the ground up (as opposed to the general design, which had been from the roof down). Some of the levels were still undergoing final approval, with several orders placed within an hour of a plan being finalized. On September 10, as steelwork was nearing completion, Smith laid the building's cornerstone during a ceremony attended by thousands. The stone contained a box with contemporary artifacts including the previous day's \"New York Times\", a U.S. currency set containing all denominations of notes and coins minted in 1930, a history of the site and building, and photographs of the people involved in construction. The steel structure was topped out at on September 19, twelve days ahead of schedule and 23 weeks after the start of construction. Workers raised a flag atop the 86th floor to signify this milestone.\nCompletion and scale.\nWork on the building's interior and crowning mast commenced after the topping out. The mooring mast topped out on November 21, two months after the steelwork had been completed. Meanwhile, work on the walls and interior was progressing at a quick pace, with exterior walls built up to the 75th floor by the time steelwork had been built to the 95th floor. The majority of the facade was already finished by the middle of November. Because of the building's height, it was deemed infeasible to have many elevators or large elevator cabins, so the builders contracted with the Otis Elevator Company to make 66 cars that could speed at , which represented the largest-ever elevator order at the time.\nIn addition to the time constraint builders had, there were also space limitations because construction materials had to be delivered quickly, and trucks needed to drop off these materials without congesting traffic. This was solved by creating a temporary driveway for the trucks between 33rd and 34th Streets, and then storing the materials in the building's first floor and basements. Concrete mixers, brick hoppers, and stone hoists inside the building ensured that materials would be able to ascend quickly and without endangering or inconveniencing the public. At one point, over 200 trucks made material deliveries at the building site every day. A series of relay and erection derricks, placed on platforms erected near the building, lifted the steel from the trucks below and installed the beams at the appropriate locations. The Empire State Building was structurally completed on April 11, 1931, twelve days ahead of schedule and 410\u00a0days after construction commenced. Al Smith shot the final rivet, which was made of solid gold.\nThe project involved more than 3,500 workers at its peak, including 3,439 on a single day, August 14, 1930. Many of the workers were Irish and Italian immigrants, with a sizable minority of Mohawk ironworkers from the Kahnawake reserve near Montreal. According to official accounts, five workers died during the construction, although the \"New York Daily News\" gave reports of 14 deaths and a headline in the socialist magazine \"The New Masses\" spread unfounded rumors of up to 42 deaths. The Empire State Building cost $40,948,900 to build (equivalent to $ in ), including demolition of the Waldorf\u2013Astoria. This was lower than the $60\u00a0million budgeted for construction.\nLewis Hine captured many photographs of the construction, documenting not only the work itself but also providing insight into the daily life of workers in that era. Hine's images were used extensively by the media to publish daily press releases. According to the writer Jim Rasenberger, Hine \"climbed out onto the steel with the ironworkers and dangled from a derrick cable hundreds of feet above the city to capture, as no one ever had before (or has since), the dizzy work of building skyscrapers\". In Rasenberger's words, Hine turned what might have been an assignment of \"corporate flak\" into \"exhilarating art\". These images were later organized into their own collection. Onlookers were enraptured by the sheer height at which the steelworkers operated. \"New York\" magazine wrote of the steelworkers: \"Like little spiders they toiled, spinning a fabric of steel against the sky\".\nOpening and early years.\nThe Empire State Building officially opened on May 1, 1931, forty-five days ahead of its projected opening date, and eighteen months from the start of construction. The opening was marked with an event featuring United States President Herbert Hoover, who turned on the building's lights with the ceremonial button push from Washington, D.C. Over 350 guests attended the opening ceremony, and following luncheon, at the 86th floor including Jimmy Walker, Governor Franklin D. Roosevelt, and Al Smith. An account from that day stated that the view from the luncheon was obscured by a fog, with other landmarks such as the Statue of Liberty being \"lost in the mist\" enveloping New York City. The Empire State Building officially opened the next day. Advertisements for the building's observatories were placed in local newspapers, while nearby hotels also capitalized on the events by releasing advertisements that lauded their proximity to the newly opened building.\nAccording to \"The New York Times\", builders and real estate speculators predicted that the Empire State Building would be the world's tallest building \"for many years\", thus ending the great New York City skyscraper rivalry. At the time, most engineers agreed that it would be difficult to build a building taller than , even with the hardy Manhattan bedrock as a foundation. Technically, it was believed possible to build a tower of up to , but it was deemed uneconomical to do so, especially during the Great Depression. As the tallest building in the world, at that time, and the first one to exceed 100 floors, the Empire State Building became an icon of the city and, ultimately, of the nation.\nIn 1932, the Fifth Avenue Association gave the building its 1931 \"gold medal\" for architectural excellence, signifying that the Empire State had been the best-designed building on Fifth Avenue to open in 1931. A year later, on March 2, 1933, the movie \"King Kong\" was released. The movie, which depicted a large stop motion ape named Kong climbing the Empire State Building, made the still-new building into a cinematic icon.\nTenants and tourism.\nAt the beginning of 1931, Fifth Avenue was experiencing high demand for storefront space, with only 12 of 224 stores being unoccupied. The Empire State Building, along with 500 Fifth Avenue and 608 Fifth Avenue, were expected to add a combined 11 stores. The office space was less successful, as the Empire State Building's opening had coincided with the Great Depression in the United States. In the first year, only 23\u00a0percent of the available space was rented, as compared to the early 1920s, where the average building would be 52\u00a0percent occupied upon opening and 90\u00a0percent occupied within five years. The lack of renters led New Yorkers to deride the building as the \"Empty State Building\" or \"Smith's Folly\".\nThe earliest tenants in the Empire State Building were large companies, banks, and garment industries. Jack Brod, one of the building's longest resident tenants, co-established the Empire Diamond Corporation with his father in the building in mid-1931 and rented space in the building until he died in 2008. Brod recalled that there were only about 20 tenants at the time of opening, including him, and that Al Smith was the only real tenant in the space above his seventh-floor offices. Generally, during the early 1930s, it was rare for more than a single office space to be rented in the building, despite Smith's and Raskob's aggressive marketing efforts in the newspapers and to anyone they knew. The building's lights were continuously left on, even in the unrented spaces, to give the impression of occupancy. This was exacerbated by competition from Rockefeller Center as well as from buildings on 42nd Street, which, when combined with the Empire State Building, resulted in surplus of office space in a slow market during the 1930s.\nAggressive marketing efforts served to reinforce the Empire State Building's status as the world's tallest. The observatory was advertised in local newspapers as well as on railroad tickets. The building became a popular tourist attraction, with one million people each paying one dollar to ride elevators to the observation decks in 1931. In its first year of operation, the observation deck made approximately $2\u00a0million in revenue, as much as its owners made in rent that year. By 1936, the observation deck was crowded on a daily basis, with food and drink available for purchase at the top, and by 1944 the building had received its five-millionth visitor. In 1931, NBC took up tenancy, leasing space on the 85th floor for radio broadcasts. From the outset the building was in debt, losing $1\u00a0million per year by 1935. Real estate developer Seymour Durst recalled that the building was so underused in 1936 that there was no elevator service above the 45th floor, as the building above the 41st floor was empty except for the NBC offices and the Raskob/Du Pont offices on the 81st floor.\nOther events.\nPer the original plans, the Empire State Building's spire was intended to be an airship docking station. Raskob and Smith had proposed dirigible ticketing offices and passenger waiting rooms on the 86th floor, while the airships themselves would be tied to the spire at the equivalent of the building's 106th floor. An elevator would ferry passengers from the 86th to the 101st floor after they had checked in on the 86th floor, after which passengers would have climbed steep ladders to board the airship. The idea was impractical and dangerous due to powerful updrafts caused by the building itself, the wind currents across Manhattan, and the spires of nearby skyscrapers. Even if the airship could successfully navigate all these obstacles, its crew would have to jettison some ballast by releasing water onto the streets below in order to maintain stability, and then tie the craft's nose to the spire with no mooring lines securing the tail end of the craft. On September 15, 1931, a small commercial United States Navy airship circled 25 times in winds. The airship then attempted to dock at the mast, but its ballast spilled and the craft was rocked by unpredictable eddies. The near-disaster scuttled plans to turn the building's spire into an airship terminal, although one blimp did manage to make a single newspaper delivery afterward.\nOn July 28, 1945, a B-25 Mitchell bomber crashed into the north side of the Empire State Building, between the 79th and 80th floors. One engine completely penetrated the building and landed in a neighboring block, while the other engine and part of the landing gear plummeted down an elevator shaft. Fourteen people were killed in the incident, but the building escaped severe damage and was reopened two days later.\nProfitability.\nBy the 1940s, the Empire State Building was 98 percent occupied. The structure broke even for the first time in the 1950s. At the time, mass transit options in the building's vicinity were limited compared to the present day. Despite this challenge, the Empire State Building began to attract renters due to its reputation. A radio antenna was erected on top of the towers starting in 1950, allowing the area's television stations to be broadcast from the building.\nDespite the turnaround in the building's fortunes, Raskob listed it for sale in 1951, with a minimum asking price of $50\u00a0million. The property was purchased by business partners Roger L. Stevens, Henry Crown, Alfred R. Glancy and Ben Tobin. The sale was brokered by the Charles F. Noyes Company, a prominent real estate firm in upper Manhattan, for $51\u00a0million, the highest price paid for a single structure at the time. By this time, the Empire State had been fully leased for several years with a waiting list of parties looking to lease space in the building, according to the \"Cortland Standard\". That same year, six news companies formed a partnership to pay a combined annual fee of $600,000 to use the building's antenna, which was completed in 1953. Crown bought out his partners' ownership stakes in 1954, becoming the sole owner. The following year, the American Society of Civil Engineers named the building one of the \"Seven Modern Civil Engineering Wonders\".\nIn 1961, Lawrence A. Wien signed a contract to purchase the Empire State Building for $65\u00a0million, with Harry B. Helmsley acting as partners in the building's operating lease. This became the new highest price for a single structure. Over 3,000 people paid $10,000 for one share each in a company called Empire State Building Associates. The company in turn subleased the building to another company headed by Helmsley and Wien, raising $33\u00a0million of the funds needed to pay the purchase price. In a separate transaction, the land underneath the building was sold to Prudential Insurance for $29\u00a0million. Helmsley, Wien, and Peter Malkin quickly started a program of minor improvement projects, including the first-ever full-building facade refurbishment and window-washing in 1962, the installation of new flood lights on the 72nd floor in 1964, and replacement of the manually operated elevators with automatic units in 1966. The little-used western end of the second floor was used as a storage space until 1964, at which point it received escalators to the first floor as part of its conversion into a highly sought retail area.\nLoss of \"tallest building\" title.\nIn 1961, the same year that Helmsley, Wien, and Malkin had purchased the Empire State Building, the Port Authority of New York and New Jersey formally backed plans for a new World Trade Center in Lower Manhattan. The plan originally included 66-story twin towers with column-free open spaces. The Empire State's owners and real estate speculators were worried that the twin towers' of office space would create a glut of rentable space in Manhattan as well as take away the Empire State Building's profits from lessees. A revision in the World Trade Center's plan brought the twin towers to each or 110 stories, taller than the Empire State. Opponents of the new project included prominent real-estate developer Robert Tishman, as well as Wien's Committee for a Reasonable World Trade Center. In response to Wien's opposition, Port Authority executive director Austin J. Tobin said that Wien was only opposing the project because it would overshadow his Empire State Building as the world's tallest building.\nThe World Trade Center's twin towers started construction in 1966. The following year, the Ostankino Tower succeeded the Empire State Building as the tallest freestanding structure in the world. In 1970, the Empire State surrendered its position as the world's tallest building, when the World Trade Center's still-under-construction North Tower surpassed it, on October 19; the North Tower was topped out on December 23, 1970.\nIn December 1975, the observation deck was opened on the 110th floor of the Twin Towers, significantly higher than the 86th floor observatory on the Empire State Building. The latter was also losing revenue during this period, particularly as a number of broadcast stations had moved to the World Trade Center in 1971; although the Port Authority continued to pay the broadcasting leases for the Empire State until 1984. The Empire State Building was still seen as prestigious, having seen its forty-millionth visitor in March 1971.\n1980s and 1990s.\nBy 1980, there were nearly two million annual visitors, although a building official had previously estimated between 1.5\u00a0million and 1.75\u00a0million annual visitors. The building received its own ZIP code in May 1980 in a roll out of 63 new postal codes in Manhattan. At the time, its tenants collectively received 35,000 pieces of mail daily. The Empire State Building celebrated its 50th anniversary on May 1, 1981, with a much-publicized, but poorly received, laser light show, as well as an \"Empire State Building Week\" that ran through to May 8. The New York City Landmarks Preservation Commission (LPC) voted to designate the building and its lobby as city landmarks on May 19, 1981,\nCapital improvements were made to the Empire State Building during the early to mid-1990s at a cost of $55\u00a0million. Because all of the building's windows were being replaced at the same time, the LPC mandated a paint-color test for the windows; the test revealed that the Empire State Building's original windows were actually red. The improvements also entailed replacing alarm systems, elevators, windows, and air conditioning; making the observation deck compliant with the Americans with Disabilities Act of 1990 (ADA); and refurbishing the limestone facade. The observation deck renovation was added after disability rights groups and the United States Department of Justice filed a lawsuit against the building in 1992, in what was the first lawsuit filed by an organization under the new law. A settlement was reached in 1994, in which Empire State Building Associates agreed to add ADA-compliant elements, such as new elevators, ramps, and automatic doors, during the renovation.\nPrudential sold the land under the building in 1991 for $42\u00a0million to a buyer representing hotelier , who was imprisoned at the time in connection with the deadly at the in Tokyo. In 1994, Donald Trump entered into a joint-venture agreement with Yokoi, with a shared goal of breaking the Empire State Building's lease on the land in an effort to gain total ownership of the building so that, if successful, the two could reap the potential profits of merging the ownership of the building with the land beneath it. Having secured a half-ownership of the land, Trump devised plans to take ownership of the building itself so he could renovate it, even though Helmsley and Malkin had already started their refurbishment project. He sued Empire State Building Associates in February 1995, claiming that the latter had caused the building to become a \"high-rise slum\" and a \"second-rate, rodent-infested\" office tower. Trump had intended to have Empire State Building Associates evicted for violating the terms of their lease, but was denied. This led to Helmsley's companies countersuing Trump in May. This sparked a series of lawsuits and countersuits that lasted several years, partly arising from Trump's desire to obtain the building's master lease by taking it from Empire State Building Associates. Upon Harry Helmsley's death in 1997, the Malkins sued Helmsley's widow, Leona Helmsley, for control of the building.\n21st century.\n2000s.\nFollowing the destruction of the World Trade Center during the September 11 attacks, the Empire State Building again became the tallest building in New York City, but was only the second-tallest building in the Americas after the Sears (later Willis) Tower in Chicago. As a result of the attacks, transmissions from nearly all of the city's commercial television and FM radio stations were again broadcast from the Empire State Building. The attacks also led to an increase in security due to persistent terror threats against prominent sites in New York City.\nIn 2002, Trump and Yokoi sold their land claim to the Empire State Building Associates, now headed by Malkin, in a $57.5\u00a0million transaction. This action merged the building's title and lease for the first time in half a century. Despite the lingering threat posed by the 9/11 attacks, the Empire State Building remained popular with 3.5\u00a0million visitors to the observatories in 2004, compared to about 2.8\u00a0million in 2003.\nEven though she maintained her ownership stake in the building until the post-consolidation IPO in October 2013, Leona Helmsley handed over day-to-day operations of the building in 2006 to Peter Malkin's company. In 2008, the building was temporarily \"stolen\" by the \"New York Daily News\" to show how easy it was to transfer the deed on a property, since city clerks were not required to validate the submitted information, as well as to help demonstrate how fraudulent deeds could be used to obtain large mortgages and then have individuals disappear with the money. The paperwork submitted to the city included the names of Fay Wray, the famous star of \"King Kong\", and Willie Sutton, a notorious New York bank robber. The newspaper then transferred the deed back over to the legitimate owners, who at that time were Empire State Land Associates.\n2010s to present.\nStarting in 2009, the building's public areas received a $550\u00a0million renovation, with improvements to the air conditioning and waterproofing, renovations to the observation deck and main lobby, and relocation of the gift shop to the 80th floor. About $120\u00a0million was spent on improving the energy efficiency of the building, with the goal of reducing energy emissions by 38% within five years. For example, all of the windows were refurbished onsite into film-coated \"superwindows\" which block heat but pass light. Air conditioning operating costs on hot days were reduced, saving $17\u00a0million of the project's capital cost immediately and partially funding some of the other retrofits. The Empire State Building won the Leadership in Energy and Environmental Design (LEED) Gold for Existing Buildings rating in September 2011, as well as the World Federation of Great Towers' Excellence in Environment Award for 2010. For the LEED Gold certification, the building's energy reduction was considered, as was a large purchase of carbon offsets. Other factors included low-flow bathroom fixtures, green cleaning supplies, and use of recycled paper products.\nOn April 30, 2012, One World Trade Center topped out, surpassing the Empire State Building as the city's tallest skyscraper. By 2014, the building was owned by the Empire State Realty Trust (ESRT), with Anthony Malkin as chairman, CEO, and president. The ESRT was a public company, having begun trading publicly on the New York Stock Exchange the previous year. In August 2016, the Qatar Investment Authority (QIA) was issued new fully diluted shares equivalent to 9.9% of the trust; this investment gave them partial ownership of the entirety of the ESRT's portfolio, and as a result, partial ownership of the Empire State Building. The trust's president John Kessler called it an \"endorsement of the company's irreplaceable assets\". The investment has been described by the real-estate magazine \"The Real Deal\" as \"an unusual move for a sovereign wealth fund\", as these funds typically buy direct stakes in buildings rather than real estate companies. Other foreign entities that have a stake in the ESRT include investors from Norway, Japan, and Australia.\nA renovation of the Empire State Building was commenced in the 2010s to further improve energy efficiency, public areas, and amenities. In August 2018, to improve the flow of visitor traffic, the main visitor's entrance was shifted to 20 West 34th Street as part of a major renovation of the observatory lobby. The new lobby includes several technological features, including large LED panels, digital ticket kiosks in nine languages, and a two-story architectural model of the building surrounded by two metal staircases. The first phase of the renovation, completed in 2019, features an updated exterior lighting system and digital hosts. The new lobby also features free Wi-Fi provided for those waiting. A exhibit with nine galleries opened in July 2019. The 102nd floor observatory, the third phase of the redesign, reopened to the public on October 12, 2019. That portion of the project included outfitting the space with floor-to-ceiling glass windows and a brand-new glass elevator. The final portion of the renovations to be completed was a new observatory on the 80th floor, which opened on December 2, 2019. In total, the renovation cost $160 million or $165\u00a0million and took four years to finish.\nA comprehensive restoration of the building's mooring and antenna masts also began in June 2019. Antennas on the mooring mast were removed or relocated to the upper mast, while the aluminum panels were cleaned and coated with silver paint. To minimize disruption to the observation decks, the restoration work took place at night. The project was completed by late 2020.\nHeight records.\nThe longest world record held by the Empire State Building was for the tallest skyscraper (to structural height), which it held for 42\u00a0years until it was surpassed by the North Tower of the World Trade Center in October 1970. The Empire State Building was also the tallest human-made structure in the world before it was surpassed by the Griffin Television Tower Oklahoma (KWTV Mast) in 1954, and the tallest freestanding structure in the world until the completion of the Ostankino Tower in 1967. An early-1970s proposal to dismantle the spire and replace it with an additional 11 floors, which would have brought the building's height to 1,494\u00a0feet (455\u00a0m) and made it once again the world's tallest at the time, was considered but ultimately rejected.\nWith the destruction of the World Trade Center in the September 11 attacks, the Empire State Building again became the tallest building in New York City, and the second-tallest building in the Americas, surpassed only by the Willis Tower in Chicago. The Empire State Building remained the tallest building in New York until the new One World Trade Center reached a greater height in April 2012. , it is the seventh-tallest building in New York City and the tenth-tallest in the United States. The Empire State Building is the 49th-tallest in the world . It is also the eleventh-tallest freestanding structure in the Americas behind the tallest U.S. buildings and the CN Tower.\nNotable tenants.\n, the building housed around 1,000 businesses. Current tenants include:\nFormer tenants include:\nIncidents.\n1945 plane crash.\nAt 9:40\u00a0am on July 28, 1945, a B-25 Mitchell bomber, piloted in thick fog by Lieutenant Colonel William Franklin Smith Jr., crashed into the north side of the Empire State Building between the 79th and 80th floors (then the offices of the National Catholic Welfare Council). One engine completely penetrated the building, landing on the roof of a nearby building where it started a fire that destroyed a penthouse. The other engine and part of the landing gear plummeted down an elevator shaft, causing a fire that was extinguished in 40\u00a0minutes. Fourteen people were killed in the incident. Elevator operator Betty Lou Oliver fell 75 stories and survived, which still holds the Guinness World Record for the longest survived elevator fall recorded.\nDespite the damage and loss of life, many floors were open two days later. The crash helped spur the passage of the long-pending Federal Tort Claims Act of 1946, as well as the insertion of retroactive provisions into the law, allowing people to sue the government for the incident. Also as a result of the crash, the Civil Aeronautics Administration enacted strict regulations regarding flying over New York City, setting a minimum flying altitude of above sea level regardless of the weather conditions.\nA year later, on July 24, 1946, another airplane narrowly missed striking the building. The unidentified twin-engine plane scraped past the observation deck, frightening the tourists there.\n2000 elevator plunge.\nOn January 24, 2000, an elevator in the building suddenly descended 40 stories after a cable that controlled the cabin's maximum speed was severed. The elevator fell from the 44th floor to the fourth floor, where a narrowed elevator shaft provided a second safety system. Despite the 40-floor fall, both of the passengers in the cabin at the time were only slightly injured. After the fall, building inspectors reviewed all of the building's elevators.\nSuicide attempts.\nBecause of the building's iconic status, it and other Midtown landmarks are common locations for suicide attempts. More than 30 people have attempted suicide over the years by jumping from the upper parts of the building, with most attempts being successful.\nThe first suicide from the building occurred on April 7, 1931, before it was even completed, when a carpenter who had been laid-off went to the 58th floor and jumped. The first suicide after the building's opening occurred from the 86th floor observatory in February 1935, when Irma P. Eberhardt fell onto a marquee sign. On December 16, 1943, William Lloyd Rambo jumped to his death from the 86th floor, landing amidst Christmas shoppers on the street below. In the early morning of September 27, 1946, shell-shocked Marine Douglas W. Brashear Jr. jumped from the 76th-floor window of the Grant Advertising Agency; police found his shoes from his body.\nOn May 1, 1947, Evelyn McHale leapt to her death from the 86th floor observation deck and landed on a limousine parked at the curb. Photography student Robert Wiles took a photo of McHale's oddly intact corpse a few minutes after her death. The police found a suicide note among possessions that she left on the observation deck: \"He is much better off without me... I wouldn't make a good wife for anybody\". The photo ran in the May 12, 1947, edition of \"Life\" magazine and is often referred to as \"The Most Beautiful Suicide\". It was later used by visual artist Andy Warhol in one of his prints entitled \"Suicide (Fallen Body)\". A mesh fence was put up around the 86th floor terrace in December 1947 after five people tried to jump during a three-week span in October and November of that year. By then, sixteen people had died from suicide jumps.\nOnly one person has jumped from the upper observatory. Frederick Eckert of Astoria ran past a guard in the enclosed 102nd-floor gallery on November 3, 1932, and jumped a gate leading to an outdoor catwalk intended for dirigible passengers. He landed and died on the roof of the 86th floor observation promenade.\nTwo people have survived falls by not falling more than a floor. On December 2, 1979, Elvita Adams jumped from the 86th floor, only to be blown back onto a ledge on the 85th floor by a gust of wind and left with a broken hip. On April 25, 2013, a man fell from the 86th floor observation deck, but he landed alive with minor injuries on an 85th-floor ledge where security guards brought him inside and paramedics transferred him to a hospital for a psychiatric evaluation.\nShootings.\nTwo fatal shootings have occurred in the direct vicinity of the Empire State Building. Abu Kamal, a 69-year-old Palestinian teacher, shot seven people on the 86th floor observation deck during the afternoon of February 23, 1997. He killed one person and wounded six others before committing suicide. Kamal reportedly committed the shooting in response to events happening in Palestine and Israel.\nOn the morning of August 24, 2012, 58-year-old Jeffrey T. Johnson shot and killed a former co-worker on the building's Fifth Avenue sidewalk. He had been laid off from his job in 2011. Two police officers confronted the gunman, and he aimed his firearm at them. They responded by firing 16 shots, killing him but also wounding nine bystanders. Most of the injured were hit by bullet fragments, although three took direct hits from bullets.\nImpact.\nAs the tallest building in the world and the first one to exceed 100 floors, the Empire State Building immediately became an icon of the city and of the nation. In 2013, \"Time\" magazine noted that the Empire State Building \"seems to completely embody the city it has become synonymous with\". The historian John Tauranac called it \"'the' twentieth-century New York building\", despite the existence of taller and more modernist buildings.\nThe New York City Landmarks Preservation Commission voted to designate the building and its lobby as city landmarks on May 19, 1981, citing the historic nature of the first and second floors, as well as \"the fixtures and interior components\" of the upper floors. The New York City Planning Commission endorsed the landmark status. The building became a National Historic Landmark in 1986 in close alignment with the New York City Landmarks report. The Empire State Building was added to the National Register of Historic Places the following year due to its architectural significance.\nContemporary reception.\nEarly architectural critics also focused on the Empire State Building's exterior ornamentation. Architectural critic Talbot Hamlin wrote in 1931, \"That it is the world's tallest building is purely incidental.\" George Shepard Chappell, writing in \"The New Yorker\" under the pseudonym \"T-Square\", wrote the same year that the Empire State Building had a \"palpably enormous\" appeal to the general public, and that \"its difference and distinction [lay] in the extreme sensitiveness of its entire design\". Edmund Wilson of \"The New Republic\" wrote that the building's neutral color palette made it \"New York's handsomest skyscraper\".\nArchitectural critics also wrote negatively of the mast, especially in light of its failure to become a real air terminal. Chappell called the mast \"a silly gesture\", and Lewis Mumford called it \"a public comfort station for migratory birds\". Nevertheless, architecture critic Douglas Haskell said the Empire State Building's appeal came from the fact that it was \"caught at the exact moment of transition\u2014caught between metal and stone, between the idea of 'monumental mass' and that of airy volume, between handicraft and machine design, and in the swing from what was essentially handicraft to what will be essentially industrial methods of fabrication.\"\nAs icon.\nEarly in the building's history, travel companies such as Short Line Motor Coach Service and New York Central Railroad used the building as an icon to symbolize the city. In a 1932 survey of 50 American architects, fourteen ranked the Empire State Building as the United States' best building; the Empire State Building received more votes than any building except the Lincoln Memorial. After the construction of the first World Trade Center, architect Paul Goldberger noted that the Empire State Building \"is famous for being tall, but it is good enough to be famous for being good.\"\nAs an icon of the United States, it is also very popular among Americans. In a 2007 survey, the American Institute of Architects found that the Empire State Building was \"America's favorite building\". The building was originally a symbol of hope in a country devastated by the Depression, as well as a work of accomplishment by newer immigrants. The writer Benjamin Flowers states that the Empire State was \"a building intended to celebrate a new America, built by men (both clients and construction workers) who were themselves new Americans.\" The architectural critic Jonathan Glancey refers to the building as an \"icon of American design\". Additionally, in 2007, the Empire State Building was first on the AIA's List of America's Favorite Architecture.\nThe Empire State Building has been hailed as an example of a \"wonder of the world\" due to the massive effort expended during construction. \"The Washington Star\" listed it as part of one of the \"seven wonders of the modern world\" in 1931, while \"Holiday\" magazine wrote in 1958 that the Empire State's height would be taller than the combined heights of the Eiffel Tower and the Great Pyramid of Giza. The American Society of Civil Engineers also declared the building \"A Modern Civil Engineering Wonder of the United States\" in 1958 and one of the Seven Wonders of the Modern World in 1994. Ron Miller, in a 2010 book, also described the Empire State Building as one of the \"seven wonders of engineering\". It has often been called the Eighth Wonder of the World as well, an appellation that it has held since shortly after opening. The panels installed in the lobby in 1963 reflected this, showing the seven original wonders alongside the Empire State Building. The Empire State Building also became the standard of reference to describe the height and length of other structures globally, both natural and human-made.\nThe building has also inspired replicas. The New York-New York Hotel and Casino in Paradise, Nevada, contains the \"Empire Tower\", a 47-story replica of the Empire State Building. A portion of the hotel's interior was also designed to resemble the Empire State Building's interior.\nIn media.\nAs an icon of New York City, the Empire State Building has been featured in various films, books, TV shows, and video games. According to the building's official website, more than 250 movies contain depictions of the Empire State Building. In his book about the building, John Tauranac writes that its first documented appearance in popular culture was \"Swiss Family Manhattan\", a 1932 children's story by Christopher Morley. A year later, the film \"King Kong\" depicted Kong, a giant stop motion ape that climbs the Empire State Building during the film's climax, bringing the building into the popular imagination. Later movies such as \"An Affair to Remember\" (1957), \"Sleepless in Seattle\" (1993), and \"Independence Day\" (1996) also prominently featured the building. The building has also been featured in other works, such as \"Daleks in Manhattan\", a 2007 episode of the TV series \"Doctor Who\"; and \"Empire\", an eight-hour black-and-white silent film by Andy Warhol, which was later added to the Library of Congress's National Film Registry.\nThroughout its history, the Empire State Building has welcomed celebrities, royalty, and dignitaries to visit the observation deck. From celebrities like Taylor Swift and Zendaya to royalty such as Prince William, the Empire State Building hosts notable figures every year.\nEmpire State Building Run-Up.\nThe Empire State Building Run-Up, a foot race from ground level to the 86th-floor observation deck, has been held annually since 1978. It is organized by NYCRUNS. Its participants are referred to both as runners and as climbers, and are often tower running enthusiasts. The race covers a vertical distance of and takes in 1,576 steps. The record time is 9\u00a0minutes and 33\u00a0seconds, achieved by Australian professional cyclist Paul Crake in 2003, at a climbing rate of per hour."}
{"id": "9737", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=9737", "title": "Eugenics", "text": "Eugenics ( ; ) is a set of beliefs and practices that aim to improve the genetic quality of a human population. Historically, eugenicists have attempted to alter the frequency of various human phenotypes by inhibiting the fertility of people and groups they considered inferior, or promoting that of those considered superior.\nThe contemporary history of eugenics began in the late 19th century, when a popular eugenics movement emerged in the United Kingdom, and then spread to many countries, including the United States, Canada, Australia, and most European countries (e.g. Sweden and Germany). In this period, people from across the political spectrum espoused eugenic ideas. Consequently, many countries adopted eugenic policies, intended to improve the quality of their populations' genetic stock.\nHistorically, the idea of \"eugenics\" has been used to argue for a broad array of practices ranging from prenatal care for mothers deemed genetically desirable to the forced sterilization and murder of those deemed unfit. To population geneticists, the term has included the avoidance of inbreeding without altering allele frequencies; for example, British-Indian scientist J. B. S. Haldane wrote in 1940 that \"the motor bus, by breaking up inbred village communities, was a powerful eugenic agent.\" Debate as to what exactly counts as eugenics continues today. Early eugenicists were mostly concerned with factors of measured intelligence that often correlated strongly with social class.\nAlthough it originated as a progressive social movement in the 19th century, in contemporary usage in the 21st century, the term is closely associated with scientific racism. New, liberal eugenics seeks to dissociate itself from old, authoritarian eugenics by rejecting coercive state programs and relying on parental choice.\nCommon distinctions.\n Eugenic programs included both \"positive\" measures, such as encouraging individuals deemed particularly \"fit\" to reproduce, and \"negative\" measures, such as marriage prohibitions and forced sterilization of people deemed unfit for reproduction.\nIn other words, positive eugenics is aimed at encouraging reproduction among the genetically advantaged, for example, the eminently intelligent, the healthy, and the successful. Possible approaches include financial and political stimuli, targeted demographic analyses, \"in vitro\" fertilization, egg transplants, and cloning. Negative eugenics aimed to eliminate, through sterilization or segregation, those deemed physically, mentally, or morally \"undesirable\". This includes abortions, sterilization, and other methods of family planning. Both positive and negative eugenics can be coercive; in Nazi Germany, for example, abortion was illegal for women deemed by the state to be fit.\nHistorical eugenics.\nAcademic origins.\nThe term \"eugenics\" and its modern field of study were first formulated by Francis Galton in 1883, directly drawing on the recent work delineating natural selection by his half-cousin Charles Darwin. He published his observations and conclusions chiefly in his influential book \"Inquiries into Human Faculty and Its Development\". Galton himself defined it as \"the study of all agencies under human control which can improve or impair the racial quality of future generations\". The first to systematically apply Darwinism theory to human relations, Galton believed that various desirable human qualities were also hereditary ones, although Darwin strongly disagreed with this elaboration of his theory.\nEugenics became an academic discipline at many colleges and universities and received funding from various sources. Organizations were formed to win public support for and to sway opinion towards responsible eugenic values in parenthood, including the British Eugenics Education Society of 1907 and the American Eugenics Society of 1921. Both sought support from leading clergymen and modified their message to meet religious ideals. In 1909, the Anglican clergymen William Inge and James Peile both wrote for the Eugenics Education Society. Inge was an invited speaker at the 1921 International Eugenics Conference, which was also endorsed by the Roman Catholic Archbishop of New York Patrick Joseph Hayes.\nThree International Eugenics Conferences presented a global venue for eugenicists, with meetings in 1912 in London, and in 1921 and 1932 in New York City. Eugenic policies in the United States were first implemented by state-level legislators in the early 1900s. Eugenic policies also took root in France, Germany, and Great Britain. Later, in the 1920s and 1930s, the eugenic policy of sterilizing certain mental patients was implemented in other countries including Belgium, Brazil, Canada, Japan and Sweden.\nFrederick Osborn's 1937 journal article \"Development of a Eugenic Philosophy\" framed eugenics as a social philosophy\u2014a philosophy with implications for social order. That definition is not universally accepted. Osborn advocated for higher rates of sexual reproduction among people with desired traits (\"positive eugenics\") or reduced rates of sexual reproduction or sterilization of people with less-desired or undesired traits (\"negative eugenics\").\nIn addition to being practiced in a number of countries, eugenics was internationally organized through the International Federation of Eugenics Organizations. Its scientific aspects were carried on through research bodies such as the Kaiser Wilhelm Institute of Anthropology, Human Heredity, and Eugenics, the Cold Spring Harbor Carnegie Institution for Experimental Evolution, and the Eugenics Record Office. Politically, the movement advocated measures such as sterilization laws. In its moral dimension, eugenics rejected the doctrine that all human beings are born equal and redefined moral worth purely in terms of genetic fitness. Its racist elements included pursuit of a pure \"Nordic race\" or \"Aryan\" genetic pool and the eventual elimination of \"unfit\" races.\nMany leading British politicians subscribed to the theories of eugenics. Winston Churchill supported the British Eugenics Society and was an honorary vice president for the organization. Churchill believed that eugenics could solve \"race deterioration\" and reduce crime and poverty.\nAs a social movement, eugenics reached its greatest popularity in the early decades of the 20th century, when it was practiced around the world and promoted by governments, institutions, and influential individuals. Many countries enacted various eugenics policies, including: genetic screenings, birth control, promoting differential birth rates, marriage restrictions, segregation (both racial segregation and sequestering the mentally ill), compulsory sterilization, forced abortions or forced pregnancies, ultimately culminating in genocide. By 2014, gene selection (rather than \"people selection\") was made possible through advances in genome editing, leading to what is sometimes called \"new eugenics\", also known as \"neo-eugenics\", \"consumer eugenics\", or \"liberal eugenics\"; which focuses on individual freedom and allegedly pulls away from racism, sexism or a focus on intelligence.\nEarly opposition.\nEarly critics of the philosophy of eugenics included the American sociologist Lester Frank Ward, the English writer G. K. Chesterton, and Scottish tuberculosis pioneer and author Halliday Sutherland. Ward's 1913 article \"Eugenics, Euthenics, and Eudemics\", Chesterton's 1917 book , and Franz Boas' 1916 article \"\" (published in \"The Scientific Monthly\") were all harshly critical of the rapidly growing movement.\nSeveral biologists were also antagonistic to the eugenics movement, including Lancelot Hogben. Other biologists who were themselves eugenicists, such as J. B. S. Haldane and R. A. Fisher, however, also expressed skepticism in the belief that sterilization of \"defectives\" (i.e. a purely negative eugenics) would lead to the disappearance of undesirable genetic traits.\nAmong institutions, the Catholic Church was an opponent of state-enforced sterilizations, but accepted isolating people with hereditary diseases so as not to let them reproduce. Attempts by the Eugenics Education Society to persuade the British government to legalize voluntary sterilization were opposed by Catholics and by the Labour Party. The American Eugenics Society initially gained some Catholic supporters, but Catholic support declined following the 1930 papal encyclical \"Casti connubii\". In this, Pope Pius XI explicitly condemned sterilization laws: \"Public magistrates have no direct power over the bodies of their subjects; therefore, where no crime has taken place and there is no cause present for grave punishment, they can never directly harm, or tamper with the integrity of the body, either for the reasons of eugenics or for any other reason.\"\nIn fact, more generally, \"[m]uch of the opposition to eugenics during that era, at least in Europe, came from the right.\" The eugenicists' political successes in Germany and Scandinavia were not at all matched in such countries as Poland and Czechoslovakia, even though measures had been proposed there, largely because of the Catholic church's moderating influence.\nNazism and the decline of eugenics.\nThe scientific reputation of eugenics started to decline in the 1930s, a time when Ernst R\u00fcdin used eugenics as a justification for the racial policies of Nazi Germany. Adolf Hitler had praised and incorporated eugenic ideas in in 1925 and emulated eugenic legislation for the sterilization of \"defectives\" that had been pioneered in the United States once he took power. Some common early 20th century eugenics methods involved identifying and classifying individuals and their families, including the poor, mentally ill, blind, deaf, developmentally disabled, promiscuous women, homosexuals, and racial groups (such as the Roma and Jews in Nazi Germany) as \"degenerate\" or \"unfit\", and therefore led to segregation, institutionalization, sterilization, and even mass murder. The Nazi policy of identifying German citizens deemed mentally or physically unfit and then systematically killing them with poison gas, referred to as the Aktion T4 campaign, is understood by historians to have paved the way for the Holocaust.\nBy the end of World War II, many eugenics laws were abandoned, having become associated with Nazi Germany. H. G. Wells, who had called for \"the sterilization of failures\" in 1904, stated in his 1940 book \"The Rights of Man: Or What Are We Fighting For?\" that among the human rights, which he believed should be available to all people, was \"a prohibition on mutilation, sterilization, torture, and any bodily punishment\". After World War II, the practice of \"imposing measures intended to prevent births within [a national, ethnical, racial or religious] group\" fell within the definition of the new international crime of genocide, set out in the Convention on the Prevention and Punishment of the Crime of Genocide. The Charter of Fundamental Rights of the European Union also proclaims \"the prohibition of eugenic practices, in particular those aiming at selection of persons\".\nIn Singapore.\nLee Kuan Yew, the founding father of Singapore, actively promoted eugenics as late as 1983. In 1984, Singapore began providing financial incentives to highly educated women to encourage them to have more children. For this purpose was introduced the \"Graduate Mother Scheme\" that incentivized graduate women to get married as much as the rest of their populace. The incentives were extremely unpopular and regarded as eugenic, and were seen as discriminatory towards Singapore's non-Chinese ethnic population. In 1985, the incentives were partly abandoned as ineffective, while the government matchmaking agency, the Social Development Network, remains active.\nModern eugenics.\nDevelopments in genetic, genomic, and reproductive technologies at the beginning of the 21st century have raised numerous questions regarding the ethical status of eugenics, sparking renewed interest in the topic.\nLiberal eugenics, also called new eugenics, aims to make genetic interventions morally acceptable by rejecting coercive state programs and relying on parental choice. Bioethicist Nicholas Agar, who coined the term, argues for example that the state should only intervene to forbid interventions that excessively limit a child\u2019s ability to shape their own future. Unlike \"authoritarian\" or \"old\" eugenics, liberal eugenics draws on modern scientific knowledge of genomics to enable informed choices aimed at improving well-being. Julien Savulescu further argues that some eugenic practices like prenatal screening for Down syndrome are already widely practiced, without being labeled \"eugenics\", as they are seen as enhancing freedom rather than restricting it.\nSome critics, such as UC Berkeley sociologist Troy Duster, have argued that modern genetics is a \"back door to eugenics\". This view was shared by then-White House Assistant Director for Forensic Sciences, Tania Simoncelli, who stated in a 2003 publication by the Population and Development Program at Hampshire College that advances in pre-implantation genetic diagnosis (PGD) are moving society to a \"new era of eugenics\", and that, unlike the Nazi eugenics, modern eugenics is consumer driven and market based, \"where children are increasingly regarded as made-to-order consumer products\". The United Nations' International Bioethics Committee also noted that while human genetic engineering should not be confused with the 20th century eugenics movements, it nonetheless challenges the idea of human equality and opens up new forms of discrimination and stigmatization for those who do not want or cannot afford the technology.\nIn 2025, geneticist Peter Visscher published a paper in \"Nature,\" arguing genome editing of human embryos and germ cells may become feasible in the 21st century, and raising ethical considerations in the context of previous eugenics movements. A response argued that human embryo genetic editing is \"unsafe and unproven\". \"Nature\" also published an editorial, stating: \"The fear that polygenic gene editing could be used for eugenics looms large among them, and is, in part, why no country currently allows genome editing in a human embryo, even for single variants\".\nContested scientific status.\nOne general concern that many bring to the table, is that the reduced genetic diversity some argue to be a likely feature of long-term, species-wide eugenics plans, could eventually result in inbreeding depression, increased spread of infectious disease, and decreased resilience to changes in the environment.\nArguments for scientific validity.\nIn his original lecture \"Darwinism, Medical Progress and Eugenics\", Karl Pearson claimed that everything concerning eugenics fell into the field of medicine. Anthropologist Ale\u0161 Hrdli\u010dka said in 1918 that \"[t]he growing science of eugenics will essentially become applied anthropology.\" The economist John Maynard Keynes was a lifelong proponent of eugenics and described it as a branch of sociology.\nIn a 2006 newspaper article, Richard Dawkins said that discussion regarding eugenics was inhibited by the shadow of Nazi misuse, to the extent that some scientists would not admit that breeding humans for certain abilities is at all possible. He believes that it is not physically different from breeding domestic animals for traits such as speed or herding skill. Dawkins felt that enough time had elapsed to at least ask just what the ethical differences were between breeding for ability versus training athletes or forcing children to take music lessons, though he could think of persuasive reasons to draw the distinction.\nObjections to scientific validity.\nAmanda Caleb, Professor of Medical Humanities at Geisinger Commonwealth School of Medicine, says \"Eugenic laws and policies are now understood as part of a specious devotion to a pseudoscience that actively dehumanizes to support political agendas and not true science or medicine.\"\nThe first major challenge to conventional eugenics based on genetic inheritance was made in 1915 by Thomas Hunt Morgan. He demonstrated the event of genetic mutation occurring outside of inheritance involving the discovery of the hatching of a fruit fly (\"Drosophila melanogaster\") with white eyes from a family with red eyes, demonstrating that major genetic changes occurred outside of inheritance. Additionally, Morgan criticized the view that certain traits, such as intelligence and criminality, were hereditary because these traits were subjective.\nPleiotropy occurs when one gene influences multiple, seemingly unrelated phenotypic traits, an example being phenylketonuria, which is a human disease that affects multiple systems but is caused by one gene defect. Andrzej P\u0119kalski, from the University of Wroclaw, argues that eugenics can cause harmful loss of genetic diversity if a eugenics program selects a pleiotropic gene that could possibly be associated with a positive trait. P\u0119kalski uses the example of a coercive government eugenics program that prohibits people with myopia from breeding but has the unintended consequence of also selecting against high intelligence since the two go together.\nWhile the science of genetics has increasingly provided means by which certain characteristics and conditions can be identified and understood, given the complexity of human genetics, culture, and psychology, at this point there is no agreed objective means of determining which traits might be ultimately desirable or undesirable. Some conditions such as sickle-cell disease and cystic fibrosis respectively confer immunity to malaria and resistance to cholera when a single copy of the recessive allele is contained within the genotype of the individual, so eliminating these genes is undesirable in places where such diseases are common.\nEdwin Black, journalist, historian, and author of \"War Against the Weak\", argues that eugenics is often deemed a pseudoscience because what is defined as a genetic improvement of a desired trait is a cultural choice rather than a matter that can be determined through objective scientific inquiry. This aspect of eugenics is often considered to be tainted with scientific racism and pseudoscience.\nContested ethical status.\nContemporary ethical opposition.\nIn a book directly addressed at socialist eugenicist J.B.S. Haldane and his once-influential \"Daedalus\", Betrand Russell, had one serious objection of his own: eugenic policies might simply end up being used to reproduce existing power relations \"rather than to make men happy.\"\nEnvironmental ethicist Bill McKibben argued against germinal choice technology and other advanced biotechnological strategies for human enhancement. He writes that it would be morally wrong for humans to tamper with fundamental aspects of themselves (or their children) in an attempt to overcome universal human limitations, such as vulnerability to aging, maximum life span and biological constraints on physical and cognitive ability. Attempts to \"improve\" themselves through such manipulation would remove limitations that provide a necessary context for the experience of meaningful human choice. He claims that human lives would no longer seem meaningful in a world where such limitations could be overcome with technology. Even the goal of using germinal choice technology for clearly therapeutic purposes should be relinquished, he argues, since it would inevitably produce temptations to tamper with such things as cognitive capacities. He argues that it is possible for societies to benefit from renouncing particular technologies, using Ming China, Tokugawa Japan and the contemporary Amish as examples.\nContemporary ethical advocacy.\nBioethicist Stephen Wilkinsonhas said that some aspects of modern genetics can be classified as eugenics, but that this classification does not inherently make modern genetics immoral.\nHistorian Nathaniel C. Comfort has claimed that the change from state-led reproductive-genetic decision-making to individual choice has moderated the worst abuses of eugenics by transferring the decision-making process from the state to patients and their families. \nIn their book published in 2000, \"From Chance to Choice: Genetics and Justice\", bioethicists Allen Buchanan, Dan Brock, Norman Daniels and Daniel Wikler argued that liberal societies have an obligation to encourage as wide an adoption of eugenic enhancement technologies as possible (so long as such policies do not infringe on individuals' reproductive rights or exert undue pressures on prospective parents to use these technologies) in order to maximize public health and minimize the inequalities that may result from both natural genetic endowments and unequal access to genetic enhancements.\nIn science fiction.\nThe novel \"Brave New World\" by the English author Aldous Huxley (1931), is a dystopian social science fiction novel which is set in a futuristic World State, whose citizens are environmentally engineered into an intelligence-based social hierarchy.\nVarious works by the author Robert A. Heinlein mention the Howard Foundation, a group which attempts to improve human longevity through selective breeding.\nAmong Frank Herbert's other works, the \"Dune\" series, starting with the eponymous 1965 novel, describes selective breeding by a powerful sisterhood, the \"Bene Gesserit\", to produce a supernormal male being, the \"Kwisatz Haderach\".\nThe Star Trek franchise features a race of genetically engineered humans which is known as \"Augments\", the most notable of them is Khan Noonien Singh. These \"supermen\" were the cause of the Eugenics Wars, a dark period in Earth's fictional history, before they were deposed and exiled. They appear in many of the franchise's story arcs, most frequently, they appear as villains.\n&lt;section begin=Gattaca1997/&gt;The film \"Gattaca\" (1997) provides a fictional example of a dystopian society that uses eugenics to decide what people are capable of and their place in the world. The title alludes to the letters G, A, T and C, the four nucleobases of DNA, and depicts the possible consequences of genetic discrimination in the present societal framework. Relegated to the role of a cleaner owing to his genetically projected death at age 32 due to a heart condition (being told: \"The only way you'll see the inside of a spaceship is if you were cleaning it\"), the protagonist observes enhanced astronauts as they are demonstrating their superhuman athleticism. Although it was not a box office success, it was critically acclaimed and influenced the debate over human genetic engineering in the public consciousness. As to its accuracy, its production company, Sony Pictures, consulted with a gene therapy researcher and prominent critic of eugenics known to have stated that \"[w]e should not step over the line that delineates treatment from enhancement\", W. French Anderson, to ensure that the portrayal of science was realistic. Disputing their success in this mission, Philim Yam of \"Scientific American\" called the film \"science bashing\" and \"Nature's\" Kevin Davies called it a \"surprisingly pedestrian affair\", while molecular biologist Lee Silver described its extreme determinism as \"a straw man\".\nIn his 2018 book \"Blueprint\", the behavioral geneticist Robert Plomin writes that while \"Gattaca\" warned of the dangers of genetic information being used by a totalitarian state, genetic testing could also favor better meritocracy in democratic societies which already administer a variety of standardized tests to select people for education and employment. He suggests that polygenic scores might supplement testing in a manner that is essentially free of biases."}
{"id": "9738", "revid": "48022469", "url": "https://en.wikipedia.org/wiki?curid=9738", "title": "Email", "text": "Electronic mail (usually shortened to email; alternatively hyphenated e-mail) is a method of transmitting and receiving digital messages using electronic devices over a computer network. It was conceived in the late\u201320th century as the digital version of, or counterpart to, mail (hence \"e- + mail\"). Email is a ubiquitous and very widely used communication medium; in current use, an email address is often treated as a basic and necessary part of many processes in business, commerce, government, education, entertainment, and other spheres of daily life in most countries.\nEmail operates across computer networks, primarily the Internet, and also local area networks. Today's email systems are based on a store-and-forward model. Email servers accept, forward, deliver, and store messages. Neither the users nor their computers are required to be online simultaneously; they need to connect, typically to a mail server or a webmail interface to send or receive messages or download it.\nOriginally a text-only ASCII communications medium, Internet email was extended by MIME to carry text in expanded character sets and multimedia content such as images. International email, with internationalized email addresses using UTF-8, is standardized but not widely adopted.\nTerminology.\nThe term \"electronic mail\" has been in use with its modern meaning since 1975, and variations of the shorter \"E-mail\" have been in use since 1979:\nThe service is often simply referred to as \"mail\", and a single piece of electronic mail is called a \"message\". The conventions for fields within emails\u2014the \"To\", \"From\", \"CC\", \"BCC\" etc.\u2014began with RFC-680 in 1975.\nAn Internet email consists of an \"envelope\" and \"content\"; the content consists of a \"header\" and a \"body\".\nHistory.\nComputer-based messaging between users of the same system became possible after the advent of time-sharing in the early 1960s, with a notable implementation by MIT's CTSS project in 1965. Most developers of early mainframes and minicomputers developed similar, but generally incompatible, mail applications. In 1971 the first ARPANET network mail was sent, introducing the now-familiar address syntax with the '@' symbol designating the user's system address. Over a series of RFCs, conventions were refined for sending mail messages over the File Transfer Protocol.\nProprietary electronic mail systems soon began to emerge. IBM, CompuServe and Xerox used in-house mail systems in the 1970s; CompuServe sold a commercial intraoffice mail product in 1978 to IBM and to Xerox from 1981. DEC's ALL-IN-1 and Hewlett-Packard's HPMAIL (later HP DeskManager) were released in 1982; development work on the former began in the late 1970s and the latter became the world's largest selling email system.\nThe Simple Mail Transfer Protocol (SMTP) was implemented on the ARPANET in 1983. LAN email systems emerged in the mid-1980s. For a time in the late 1980s and early 1990s, it seemed likely that either a proprietary commercial system or the X.400 email system, part of the Government Open Systems Interconnection Profile (GOSIP), would predominate. However, once the final restrictions on carrying commercial traffic over the Internet ended in 1995, a combination of factors made the current Internet suite of SMTP, POP3 and IMAP email protocols the standard (see Protocol Wars).\nOperation.\nThe following is a typical sequence of events that takes place when sender Alice transmits a message using a mail user agent (MUA) addressed to the email address of the recipient.\nIn addition to this example, alternatives and complications exist in the email system:\nMany MTAs used to accept messages for any recipient on the Internet and do their best to deliver them. Such MTAs are called \"open mail relays\". This was very important in the early days of the Internet when network connections were unreliable. However, this mechanism proved to be exploitable by originators of unsolicited bulk email and as a consequence open mail relays have become rare, and many MTAs do not accept messages from open mail relays.\nMessage format.\nThe basic Internet message format used for email is defined by , with encoding of non-ASCII data and multimedia content attachments defined in RFC 2045 through RFC 2049, collectively called \"Multipurpose Internet Mail Extensions\" or \"MIME\". The extensions in International email apply only to email. RFC 5322 replaced RFC 2822 in 2008. Earlier, in 2001, RFC 2822 had in turn replaced RFC 822, which had been the standard for Internet email for decades. Published in 1982, RFC 822 was based on the earlier RFC 733 for the ARPANET.\nInternet email messages consist of two sections, \"header\" and \"body\". These are known as \"content\". The header is structured into fields such as From, To, CC, Subject, Date, and other information about the email. In the process of transporting email messages between systems, SMTP communicates delivery parameters and information using message header fields. The body contains the message, as unstructured text, sometimes containing a signature block at the end. The header is separated from the body by a blank line.\nMessage header.\nRFC 5322 specifies the syntax of the email header. Each email message has a header (the \"header section\" of the message, according to the specification), comprising a number of fields (\"header fields\"). Each field has a name (\"field name\" or \"header field name\"), followed by the separator character \":\", and a value (\"field body\" or \"header field body\").\nEach field name begins in the first character of a new line in the header section, and begins with a non-whitespace printable character. It ends with the separator character \":\". The separator is followed by the field value (the \"field body\"). The value can continue onto subsequent lines if those lines have space or tab as their first character. Field names and, without SMTPUTF8, field bodies are restricted to 7-bit ASCII characters. Some non-ASCII values may be represented using MIME encoded words.\nHeader fields.\nEmail header fields can be multi-line, with each line recommended to be no more than 78 characters, although the limit is 998 characters. Header fields defined by RFC 5322 contain only US-ASCII characters; for encoding characters in other sets, a syntax specified in RFC 2047 may be used. In some examples, the IETF EAI working group defines some standards track extensions, replacing previous experimental extensions so UTF-8 encoded Unicode characters may be used within the header. In particular, this allows email addresses to use non-ASCII characters. Such addresses are supported by Google and Microsoft products, and promoted by some government agents.\nThe message header must include at least the following fields:\nRFC 3864 describes registration procedures for message header fields at the IANA; it provides for permanent and provisional field names, including also fields defined for MIME, netnews, and HTTP, and referencing relevant RFCs. Common header fields for email include:\nThe \"To:\" field may be unrelated to the addresses to which the message is delivered. The delivery list is supplied separately to the transport protocol, SMTP, which may be extracted from the header content. The \"To:\" field is similar to the addressing at the top of a conventional letter delivered according to the address on the outer envelope. In the same way, the \"From:\" field may not be the sender. Some mail servers apply email authentication systems to messages relayed. Data pertaining to the server's activity is also part of the header, as defined below.\nSMTP defines the \"trace information\" of a message saved in the header using the following two fields:\nOther fields added on top of the header by the receiving server may be called \"trace fields\".\nMessage body.\nContent encoding.\nInternet email was designed for 7-bit ASCII. Most email software is 8-bit clean, but must assume it will communicate with 7-bit servers and mail readers. The MIME standard introduced character set specifiers and two content transfer encodings to enable transmission of non-ASCII data: quoted printable for mostly 7-bit content with a few characters outside that range and base64 for arbitrary binary data. The 8BITMIME and BINARY extensions were introduced to allow transmission of mail without the need for these encodings, but many mail transport agents may not support them. In some countries, e-mail software violates by sending raw non-ASCII text and several encoding schemes co-exist; as a result, by default, the message in a non-Latin alphabet language appears in non-readable form (the only exception is a coincidence if the sender and receiver use the same encoding scheme). Therefore, for international character sets, Unicode is growing in popularity.\nPlain text and HTML.\nMost modern graphic email clients allow the use of either plain text or HTML for the message body at the option of the user. HTML email messages often include an automatic-generated plain text copy for compatibility.\nAdvantages of HTML include the ability to include in-line links and images, set apart previous messages in block quotes, wrap naturally on any display, use emphasis such as underlines and italics, and change font styles. Disadvantages include the increased size of the email, privacy concerns about web bugs, abuse of HTML email as a vector for phishing attacks and the spread of malicious software.\nSome e-mail clients interpret the body as HTML even in the absence of a codice_1 header field; this may cause various problems.\nSome web-based mailing lists recommend all posts be made in plain text, with 72 or 80 characters per line for all the above reasons, and because they have a significant number of readers using text-based email clients such as Mutt.\nVarious informal conventions evolved for marking up plain text in email and usenet posts, which later led to the development of formal languages like setext \"(c. 1992)\" and many others, the most popular of them being markdown.\nSome Microsoft email clients may allow rich formatting using their proprietary Rich Text Format (RTF), but this should be avoided unless the recipient is guaranteed to have a compatible email client.\nServers and client applications.\nMessages are exchanged between hosts using the Simple Mail Transfer Protocol with software programs called mail transfer agents (MTAs); and delivered to a mail store by programs called mail delivery agents (MDAs, also sometimes called local delivery agents, LDAs). Accepting a message obliges an MTA to deliver it, and when a message cannot be delivered, that MTA must send a bounce message back to the sender, indicating the problem.\nUsers can retrieve their messages from servers using standard protocols such as POP or IMAP, or, as is more likely in a large corporate environment, with a proprietary protocol specific to Novell Groupwise, Lotus Notes or Microsoft Exchange Servers. Programs used by users for retrieving, reading, and managing email are called mail user agents (MUAs).\nWhen opening an email, it is marked as \"read\", which typically visibly distinguishes it from \"unread\" messages on clients' user interfaces. Email clients may allow hiding read emails from the inbox so the user can focus on the unread.\nMail can be stored on the client, on the server side, or in both places. Standard formats for mailboxes include Maildir and mbox. Several prominent email clients use their own proprietary format and require conversion software to transfer email between them. Server-side storage is often in a proprietary format but since access is through a standard protocol such as IMAP, moving email from one server to another can be done with any MUA supporting the protocol.\nMany current email users do not run MTA, MDA or MUA programs themselves, but use a web-based email platform, such as Gmail or Yahoo! Mail, that performs the same tasks. Such webmail interfaces allow users to access their mail with any standard web browser, from any computer, rather than relying on a local email client.\nFilename extensions.\nUpon reception of email messages, email client applications save messages in operating system files in the file system. Some clients save individual messages as separate files, while others use various database formats, often proprietary, for collective storage. A historical standard of storage is the \"mbox\" format. The specific format used is often indicated by special filename extensions:\nSome applications (like Apple Mail) leave attachments encoded in messages for searching while also saving separate copies of the attachments. Others separate attachments from messages and save them in a specific directory.\nURI scheme mailto.\nThe URI scheme, as registered with the IANA, defines the codice_6 scheme for SMTP email addresses. Though its use is not strictly defined, URLs of this form are intended to be used to open the new message window of the user's mail client when the URL is activated, with the address as defined by the URL in the \"To:\" field. Many clients also support query string parameters for the other email fields, such as its subject line or carbon copy recipients.\nTypes.\nWeb-based email.\nMany email providers have a web-based email client. This allows users to log into the email account by using any compatible web browser to send and receive their email. Mail is typically not downloaded to the web client, so it cannot be read without a current Internet connection.\nPOP3 email servers.\nThe Post Office Protocol 3 (POP3) is a mail access protocol used by a client application to read messages from the mail server. Received messages are often deleted from the server. POP supports simple download-and-delete requirements for access to remote mailboxes (termed maildrop in the POP RFC's). POP3 allows downloading messages on a local computer and reading them even when offline.\nIMAP email servers.\nThe Internet Message Access Protocol (IMAP) provides features to manage a mailbox from multiple devices. Small portable devices like smartphones are increasingly used to check email while traveling and to make brief replies, larger devices with better keyboard access being used to reply at greater length. IMAP shows the headers of messages, the sender and the subject and the device needs to request to download specific messages. Usually, the mail is left in folders in the mail server.\nMAPI email servers.\nMessaging Application Programming Interface (MAPI) is used by Microsoft Outlook to communicate to Microsoft Exchange Server\u2014and to a range of other email server products such as Axigen Mail Server, Kerio Connect, Scalix, Zimbra, HP OpenMail, IBM Lotus Notes, Zarafa, and Bynari where vendors have added MAPI support to allow their products to be accessed directly via Outlook.\nUses.\nBusiness and organizational use.\nEmail has been widely accepted by businesses, governments and non-governmental organizations in the developed world, and it is one of the key parts of an 'e-revolution' in workplace communication (with the other key plank being widespread adoption of highspeed Internet). A sponsored 2010 study on workplace communication found 83% of U.S. knowledge workers felt email was critical to their success and productivity at work.\nIt has some key benefits to business and other organizations, including:\nEmail marketing.\nEmail marketing via \"opt-in\" is often successfully used to send special sales offerings and new product information. Depending on the recipient's culture, email sent without permission\u2014such as an \"opt-in\"\u2014is likely to be viewed as unwelcome \"email spam\".\nPersonal use.\nPersonal computer.\nMany users access their personal emails from friends and family members using a personal computer in their house or apartment.\nMobile.\nEmail has become used on smartphones and on all types of computers. Mobile \"apps\" for email increase accessibility to the medium for users who are out of their homes. While in the earliest years of email, users could only access email on desktop computers, in the 2010s, it is possible for users to check their email when they are away from home, whether they are across town or across the world. Alerts can also be sent to the smartphone or other devices to notify them immediately of new messages. This has given email the ability to be used for more frequent communication between users and allowed them to check their email and write messages throughout the day. , there were approximately 1.4 billion email users worldwide and 50 billion non-spam emails that were sent daily.\nIndividuals often check emails on smartphones for both personal and work-related messages. It was found that US adults check their email more than they browse the web or check their Facebook accounts, making email the most popular activity for users to do on their smartphones. 78% of the respondents in the study revealed that they check their email on their phone. It was also found that 30% of consumers use only their smartphone to check their email, and 91% were likely to check their email at least once per day on their smartphone. However, the percentage of consumers using email on a smartphone ranges and differs dramatically across different countries. For example, in comparison to 75% of those consumers in the US who used it, only 17% in India did.\nDeclining use among young people.\n, the number of Americans visiting email web sites had fallen 6 percent after peaking in November 2009. For persons 12 to 17, the number was down 18 percent. Young people preferred instant messaging, texting and social media. Technology writer Matt Richtel said in \"The New York Times\" that email was like the VCR, vinyl records and film cameras\u2014no longer cool and something older people do.\nA 2015 survey of Android users showed that persons 13 to 24 used messaging apps 3.5 times as much as those over 45, and were far less likely to use email.\nIssues.\nAttachment size limitation.\nEmail messages may have one or more attachments, which are additional files that are appended to the email. Typical attachments include Microsoft Word documents, PDF documents, and scanned images of paper documents. In principle, there is no technical restriction on the size or number of attachments. However, in practice, email clients, servers, and Internet service providers implement various limitations on the size of files, or complete email \u2013 typically to 25MB or less. Furthermore, due to technical reasons, attachment sizes as seen by these transport systems can differ from what the user sees, which can be confusing to senders when trying to assess whether they can safely send a file by email. Where larger files need to be shared, various file hosting services are available and commonly used.\nInformation overload.\nThe ubiquity of email for knowledge workers and \"white collar\" employees has led to concerns that recipients face an \"information overload\" in dealing with increasing volumes of email. With the growth in mobile devices, by default employees may also receive work-related emails outside of their working day. This can lead to increased stress and decreased satisfaction with work. Some observers even argue it could have a significant negative economic effect, as efforts to read the many emails could reduce productivity.\nSpam.\nEmail \"spam\" is unsolicited bulk email. The low cost of sending such email meant that, by 2003, up to 30% of total email traffic was spam, and was threatening the usefulness of email as a practical tool. The US CAN-SPAM Act of 2003 and similar laws elsewhere had some impact, and a number of effective anti-spam techniques now largely mitigate the impact of spam by filtering or rejecting it for most users, but the volume sent is still very high\u2014and increasingly consists not of advertisements for products, but malicious content or links. In September 2017, for example, the proportion of spam to legitimate email rose to 59.56%. The percentage of spam email in 2021 is estimated to be 85%.\nMalware.\nEmails are a major vector for the distribution of malware. This is often achieved by attaching malicious programs to the message and persuading potential victims to open the file. Types of malware distributed via email include computer worms and ransomware.\nEmail spoofing.\nEmail spoofing occurs when the email message header is designed to make the message appear to come from a known or trusted source. Email spam and phishing methods typically use spoofing to mislead the recipient about the true message origin. Email spoofing may be done as a prank, or as part of a criminal effort to defraud an individual or organization. An example of a potentially fraudulent email spoofing is if an individual creates an email that appears to be an invoice from a major company, and then sends it to one or more recipients. In some cases, these fraudulent emails incorporate the logo of the purported organization and even the email address may appear legitimate.\nEmail bombing.\nEmail bombing is the intentional sending of large volumes of messages to a target address. The overloading of the target email address can render it unusable and can even cause the mail server to crash.\nPrivacy concerns.\nToday it can be important to distinguish between the Internet and internal email systems. Internet email may travel and be stored on networks and computers without the sender's or the recipient's control. During the transit time it is possible that third parties read or even modify the content. Internal mail systems, in which the information never leaves the organizational network, may be more secure, although information technology personnel and others whose function may involve monitoring or managing may be accessing the email of other employees.\nEmail privacy, without some security precautions, can be compromised because:\nThere are cryptography applications that can serve as a remedy to one or more of the above. For example, Virtual Private Networks or the Tor network can be used to encrypt traffic from the user machine to a safer network while GPG, PGP, SMEmail, or S/MIME can be used for end-to-end message encryption, and SMTP STARTTLS or SMTP over Transport Layer Security/Secure Sockets Layer can be used to encrypt communications for a single mail hop between the SMTP client and the SMTP server.\nAdditionally, many mail user agents do not protect logins and passwords, making them easy to intercept by an attacker. Encrypted authentication schemes such as SASL prevent this. Finally, the attached files share many of the same hazards as those found in peer-to-peer filesharing. Attached files may contain trojans or viruses.\nLegal contracts.\nIt is possible for an exchange of emails to form a binding contract, so users must be careful about what they send through email correspondence. A signature block on an email may be interpreted as satisfying a signature requirement for a contract.\nFlaming.\nFlaming occurs when a person sends a message (or many messages) with angry or antagonistic content. The term is derived from the use of the word \"incendiary\" to describe particularly heated email discussions. The ease and impersonality of email communications mean that the social norms that encourage civility in person or via telephone do not exist and civility may be forgotten.\nEmail bankruptcy.\nAlso known as \"email fatigue\", email bankruptcy is when a user ignores a large number of email messages after falling behind in reading and answering them. The reason for falling behind is often due to information overload and a general sense there is so much information that it is not possible to read it all. As a solution, people occasionally send a \"boilerplate\" message explaining that their email inbox is full, and that they are in the process of clearing out all the messages. Harvard University law professor Lawrence Lessig is credited with coining this term, but he may only have popularized it.\nInternationalization.\nOriginally Internet email was completely ASCII text-based. MIME now allows body content text and some header content text in international character sets, but other headers and email addresses using UTF-8, while standardized have yet to be widely adopted.\nTracking of sent mail.\nThe original SMTP mail service provides limited mechanisms for tracking a transmitted message, and none for verifying that it has been delivered or read. It requires that each mail server must either deliver it onward or return a failure notice (bounce message), but both software bugs and system failures can cause messages to be lost. To remedy this, the IETF introduced Delivery Status Notifications (delivery receipts) and Message Disposition Notifications (return receipts); however, these are not universally deployed in production.\nMany ISPs now deliberately disable non-delivery reports (NDRs) and delivery receipts due to the activities of spammers:\nIn the absence of standard methods, a range of system based around the use of web bugs have been developed. However, these are often seen as underhand or raising privacy concerns, and only work with email clients that support rendering of HTML. Many mail clients now default to not showing \"web content\". Webmail providers can also disrupt web bugs by pre-caching images."}
{"id": "9739", "revid": "1270272236", "url": "https://en.wikipedia.org/wiki?curid=9739", "title": "Emoticon", "text": "An emoticon (, , rarely , ), short for emotion icon, is a pictorial representation of a facial expression using characters\u2014usually punctuation marks, numbers and letters\u2014to express a person's feelings, mood or reaction, without needing to describe it in detail.\nThe first ASCII emoticons are generally credited to computer scientist Scott Fahlman, who proposed what came to be known as \"smileys\"\u2014codice_1 and \u2014in a message on the bulletin board system (BBS) of Carnegie Mellon University in 1982. In Western countries, emoticons are usually written at a right angle to the direction of the text. Users from Japan popularized a kind of emoticon called \"kaomoji\", using Japanese's larger character sets. This style arose on ASCII NET of Japan in 1986. They are also known as \"verticons\" (from \"vertical emoticon\") due to their readability without rotations.\nAs SMS mobile text messaging and the Internet became widespread in the late 1990s, emoticons became increasingly popular and were commonly used in texting, Internet forums and emails. Emoticons have played a significant role in communication through technology, and some devices and applications have provided stylized pictures that do not use text punctuation. They offer another range of \"tone\" through texting through facial gestures. Emoticons were the precursors to modern emojis.\nHistory.\nDifferent uses of text characters (pre-1981).\nIn 1648, poet Robert Herrick wrote, \"Tumble me down, and I will sit Upon my ruins, (smiling yet:).\" Herrick's work predated any other recorded use of brackets as a smiling face by around 200 years. However, experts doubted the inclusion of the colon in the poem was deliberate and if it was meant to represent a smiling face. English professor Alan Jacobs argued that \"punctuation, in general, was unsettled in the seventeenth century ... Herrick was unlikely to have consistent punctuational practices himself, and even if he did he couldn't expect either his printers or his readers to share them.\" 17th century typography practice often placed colons and semicolons within parentheses, including 14 instances of \"\" in Richard Baxter's 1653 \"Plain Scripture Proof of Infants Church-membership and Baptism\".\nPrecursors to modern emoticons have existed since the 19th century. The \"National Telegraphic Review and Operators Guide\" in April 1857 documented the use of the number 73 in Morse code to express \"love and kisses\" (later reduced to the more formal \"best regards\"). \"Dodge's Manual\" in 1908 documented the reintroduction of \"love and kisses\" as the number 88. New Zealand academics Joan Gajadhar and John Green comment that both Morse code abbreviations are more succinct than modern abbreviations such as LOL.\nThe transcript of one of Abraham Lincoln's speeches in 1862 recorded the audience's reaction as: \"(applause and laughter ;)\". There has been some debate whether the glyph in Lincoln's speech was a typo, a legitimate punctuation construct or the first emoticon. Linguist Philip Seargeant argues that it was a simple typesetting error.\nBefore March 1881, the examples of \"typographical art\" appeared in at least three newspaper articles, including \"Kurjer warszawski\" (published in Warsaw) from March 5, 1881, using punctuation to represent the emotions of joy, melancholy, indifference and astonishment.\nIn a 1912 essay titled \"For Brevity and Clarity\", American author Ambrose Bierce suggested facetiously that a bracket could be used to represent a smiling face, proposing \"an improvement in punctuation\" with which writers could convey \"cachinnation\", loud or immoderate laughter: \"it is written thus\u00a0\u203f and presents a smiling mouth. It is to be appended, with the full stop, to every jocular or ironical sentence\". In a 1936 \"Harvard Lampoon\" article, writer Alan Gregg proposed combining brackets with various other punctuation marks to represent various moods. Brackets were used for the sides of the mouth or cheeks, with other punctuation used between the brackets to display various emotions: for a smile, (showing more \"teeth\") for laughter, for a frown and for a wink. An instance of text characters representing a sideways smiling and frowning face could be found in the \"New York Herald Tribune\" on March 10, 1953, promoting the film \"Lili\" starring Leslie Caron.\nThe September 1962 issue of \"MAD\" magazine included an article titled \"Typewri-toons\". The piece, featuring typewriter-generated artwork credited to \"Royal Portable\", was entirely made up of repurposed typography, including a capital letter P having a bigger 'bust' than a capital I, a lowercase b and d discussing their pregnancies, an asterisk on top of a letter to indicate the letter had just come inside from snowfall, and a classroom of lowercase n's interrupted by a lowercase h \"raising its hand\". A further example attributed to a \"Baltimore Sunday Sun\" columnist appeared in a 1967 article in \"Reader's Digest\", using a dash and right bracket to represent a tongue in one's cheek: ). Prefiguring the modern \"smiley\" emoticon, writer Vladimir Nabokov told an interviewer from \"The New York Times\" in 1969, \"I often think there should exist a special typographical sign for a smile\u2014some sort of concave mark, a supine round bracket, which I would now like to trace in reply to your question.\"\nIn the 1970s, the PLATO IV computer system was launched. It was one of the first computers used throughout educational and professional institutions, but rarely used in a residential setting. On the computer system, a student at the University of Illinois developed pictograms that resembled different smiling faces. Mary Kalantzis and Bill Cope stated this likely took place in 1972, and they claimed these to be the first emoticons.\nASCII emoticons use in digital communication (1982\u2013mid-1990s).\nCarnegie Mellon computer scientist Scott Fahlman is generally credited with the invention of the digital text-based emoticon in 1982. The use of ASCII symbols, a standard set of codes representing typographical marks, was essential to allow the symbols to be displayed on any computer. In Carnegie Mellon's bulletin board system, Fahlman proposed colon\u2013hyphen\u2013right bracket as a label for \"attempted humor\" to try to solve the difficulty of conveying humor or sarcasm in plain text. Fahlman sent the following message after an incident where a humorous warning about a mercury spill in an elevator was misunderstood as serious:\nWithin a few months, the smiley had spread to the ARPANET and Usenet. Other suggestions on the forum included an asterisk and an ampersand , the latter meant to represent a person doubled over in laughter, as well as a percent sign and a pound sign . Scott Fahlman suggested that not only could his emoticon communicate emotion, but also replace language. Since the 1990s, emoticons (colon, hyphen and bracket) have become integral to digital communications, and have inspired a variety of other emoticons, including the \"winking\" face using a semicolon , , a representation of the Face with Tears of Joy emoji and the acronym LOL.\nIn 1996, The Smiley Company was established by Nicolas Loufrani and his father Franklin as a way of commercializing the smiley trademark. As part of this, The Smiley Dictionary website focused on ASCII emoticons, where a catalogue was made of them. Many other people did similar to Loufrani from 1995 onwards, including David Sanderson creating the book \"Smileys\" in 1997. James Marshall also hosted an online collection of ASCII emoticons that he completed in 2008.\nA researcher at Stanford University surveyed the emoticons used in four million Twitter messages and found that the smiling emoticon without a hyphen \"nose\" was much more common than the original version with the hyphen . Linguist Vyvyan Evans argues that this represents a shift in usage by younger users as a form of \"covert prestige\": rejecting a standard usage in order to demonstrate in-group membership.\nGraphical emoticons and other developments (1990s\u2013present).\nLoufrani began to use the basic text designs and turned them into graphical representations. They are now known as graphical emoticons. His designs were registered at the United States Copyright Office in 1997 and appeared online as GIF files in 1998. For ASCII emoticons that did not exist to convert into graphical form, Loufrani also backward engineered new ASCII emoticons from the graphical versions he created. These were the first graphical representations of ASCII emoticons. He published his Smiley icons as well as emoticons created by others, along with their ASCII versions, in an online Smiley Dictionary in 2001. This dictionary included 640 different smiley icons and was published as a book called \"Dico Smileys\" in 2002. In 2017, British magazine \"The Drum\" referred to Loufrani as the \"godfather of the emoji\" for his work in the field.\nOn September 23, 2021, it was announced that Scott Fahlman was holding an auction for the original emoticons he created in 1982. The auction was held in Dallas, United States, and sold the two designs as non-fungible tokens (NFT). The online auction ended later that month, with the originals selling for US$237,500.\nIn some programming languages, certain operators are known informally by their emoticon-like appearance. This includes the Spaceship operator codice_2 (a comparison), the Diamond operator codice_3 (for type hinting) and the Elvis operator codice_4 (a shortened ternary operator).\nStyles.\nWestern.\nUsually, emoticons in Western style have the eyes on the left, followed by the nose and the mouth. It is commonly placed at the end of a sentence, replacing the full stop. The two-character version codice_5, which omits the nose, is very popular. The most basic emoticons are relatively consistent in form, but some can be rotated (making them tiny ambigrams). There are also some variations to emoticons to get new definitions, like changing a character to express another feeling. For example, equals sad and equals very sad. Weeping can be written as codice_6. A blush can be expressed as codice_7. Others include wink codice_8, a grin codice_9, codice_10 for tongue out, and smug ; they can be used to denote a flirting or joking tone, or may be implying a second meaning in the sentence preceding it. codice_11, such as when blowing a raspberry. An often used combination is also codice_12 for a heart and codice_13 for a broken heart. codice_14 is also sometimes used to depict shock. codice_15 is used to depict melancholy, disappointment or disapproval. codice_16 may be used to depict a neutral face.\nA broad grin is sometimes shown with crinkled eyes to express further amusement; codice_17 and the addition of further \"D\" letters can suggest laughter or extreme amusement, e.g., codice_18. The \"3\" in codice_19 and codice_20 represents an animal's mouth. An equal sign is often used for the eyes in place of the colon, seen as codice_21. It has become more acceptable to omit the hyphen, whether a colon or an equal sign is used for the eyes. One linguistic study has indicated that the use of a nose in an emoticon may be related to the user's age, with younger people less likely to use a nose.\nSome variants are also more common in certain countries due to keyboard layouts. For example, the smiley codice_21 may occur in Scandinavia. Diacritical marks are sometimes used. The letters codice_23 and codice_24 can be seen as emoticons, as the upright versions of codice_14 (meaning that one is surprised) and codice_9 (meaning that one is very happy), respectively. In countries where the Cyrillic alphabet is used, the right parenthesis codice_27 is used as a smiley. Multiple parentheses codice_28 are used to express greater happiness, amusement or laughter. The colon is omitted due to being in a lesser-known position on the \u0419\u0426\u0423\u041a\u0415\u041d keyboard layout. The 'shrug' emoticon, uses the glyph \u30c4 from the Japanese katakana writing system.\nKaomoji (Japan ASCII movement).\nKaomoji are often seen as the Japanese development of emoticons that is separate to the Scott Fahlman movement, which started in 1982. In 1986, a designer began to use brackets and other ASCII text characters to form faces. Over time, they became more often differentiated from each other, although both use ASCII characters. However, more westernised Kaomojis have dropped the brackets, such as codice_29, codice_30 and codice_31, popularised in internet subcultures such as the anime and furry communities.\n2channel.\nUsers of the Japanese discussion board 2channel, in particular, have developed a variety emoticons using characters from various scripts, such as Kannada, as in codice_32 (for a look of disapproval, disbelief or confusion). Similarly, the letter \u0cb0\u0cc3 was used in emoticons to represent a monocle and \u0ca5 to represent a tearing eye. They were picked up by 4chan and spread to other Western sites soon after. Some have become characters in their own right like Mon\u0101.\nKorean.\nIn South Korea, emoticons use Korean Hangul letters, and the Western style is rarely used. The structures of Korean and Japanese emoticons are somewhat similar, but they have some differences. Korean style contains Korean jamo (letters) instead of other characters.\nThe consonant jamos codice_33, codice_34 or codice_35 can be used as the mouth or nose component and codice_36, codice_37 or codice_38 for the eyes. Using quotation marks codice_39 and apostrophes codice_40 are also commonly used combinations. Vowel jamos such as \u315c and \u3160 can depict a crying face. Example: (same function as T in Western style). Sometimes \u3161 (not an em-dash \"\u2014\", but a vowel jamo), a comma (codice_41) or an underscore (codice_42) is added, and the two character sets can be mixed together, as in and Also, semicolons and carets are commonly used in Korean emoticons; semicolons can mean sweating, examples of it are codice_43, and .\nChinese ideographic.\nThe character \u56e7 (U+56E7), which means , may be combined with the posture emoticon Orz, such as The character existed in Oracle bone script but was rarely used until its use as an emoticon, documented as early as January 20, 2005.\nOther variants of \u56e7 include \u5d2e (king \u56e7), \u8394 (queen \u56e7), \u5546 (\u56e7 with a hat), \u56e7\u8208 (turtle) and \u5363 (\"Bomberman\"). The character \u69d1 (U+69D1), a variant of \u6885 , is used to represent a double of \u5446 or further magnitude of dullness. In Chinese, normally full characters (as opposed to the stylistic use of \u69d1) might be duplicated to express emphasis.\nPosture emoticons.\nOrz.\nOrz (other forms include: , , , , , , , and ) is an emoticon representing a kneeling or bowing person (the Japanese version of which is called \"dogeza\"), with the \"o\" being the head, the \"r\" being the arms and part of the body, and the \"z\" being part of the body and the legs. This stick figure can represent respect or \"kowtowing\", but commonly appears along a range of responses, including \"frustration, despair, sarcasm, or grudging respect\".\nIt was first used in late 2002 at the forum on Techside, a Japanese personal website. At the \"Techside FAQ Forum\" (), a poster asked about a cable cover, typing \"\" to show a cable and its cover. Others commented that it looked like a kneeling person, and the symbol became popular. These comments were soon deleted as they were considered off-topic. By 2005, Orz spawned a subculture: blogs have been devoted to the emoticon, and URL shortening services have been named after it. In Taiwan, Orz is associated with the concept of nice guys.\no7.\no7, or O7, is an emoticon that depicts a person saluting, with the \"o\" being the head and the \"7\" being its arm.\nMultimedia variations.\nA portmanteau of \"emotion\" and \"sound\", an emotisound is a brief sound transmitted and played back during the viewing of a message, typically an IM message or email message. The sound is intended to communicate an emotional subtext. Some services, such as MuzIcons, combine emoticons and music players in an Adobe Flash-based widget. In 2004, the Trillian chat application introduced a feature called \"emotiblips\", which allows Trillian users to stream files to their instant message recipients \"as the voice and video equivalent of an emoticon\".\nIn 2007, MTV and Paramount Home Entertainment promoted the \"emoticlip\" as a form of viral marketing for the second season of the show \"The Hills\". The emoticlips were twelve short snippets of dialogue from the show, uploaded to YouTube. The emoticlip concept is credited to the Bradley &amp; Montgomery advertising firm, which wrote that they hoped it would be widely adopted as \"greeting cards that just happen to be selling something\".\nIntellectual property rights.\nIn 2000, Despair, Inc. obtained a U.S. trademark registration for the \"frowny\" emoticon when used on \"greeting cards, posters and art prints\". In 2001, they issued a satirical press release, announcing that they would sue Internet users who typed the frowny; the company received protests when its mock release was posted on technology news website Slashdot.\nA number of patent applications have been filed on inventions that assist in communicating with emoticons. A few of these have been issued as US patents. US 6987991, for example, discloses a method developed in 2001 to send emoticons over a cell phone using a drop-down menu. The stated advantage was that it eases entering emoticons.\nThe emoticon codice_1 was also filed in 2006 and registered in 2008 as a European Community Trademark (CTM). In Finland, the Supreme Administrative Court ruled in 2012 that the emoticon cannot be trademarked, thus repealing a 2006 administrative decision trademarking the emoticons codice_1, codice_21, codice_47, codice_5 and In 2005, a Russian court rejected a legal claim against Siemens by a man who claimed to hold a trademark on the codice_49 emoticon. In 2008, Russian entrepreneur Oleg Teterin claimed to have been granted the trademark on the codice_49 emoticon. A license would not \"cost that much\u2014tens of thousands of dollars\" for companies but would be free of charge for individuals.\nUnicode.\nA different, but related, use of the term \"emoticon\" is found in the Unicode Standard, referring to a subset of emoji that display facial expressions. The standard explains this usage with reference to existing systems, which provided functionality for substituting certain textual emoticons with images or emoji of the expressions in question.\nSome smiley faces were present in Unicode since 1.1, including a white frowning face, a white smiling face and a black smiling face (\"black\" refers to a glyph which is filled, \"white\" refers to a glyph which is unfilled).\nThe Emoticons block was introduced in Unicode Standard version 6.0 (published in October 2010) and extended by 7.0. It covers Unicode range from U+1F600 to U+1F64F fully.\nAfter that block had been filled, Unicode 8.0 (2015), 9.0 (2016) and 10.0 (2017) added additional emoticons in the range from U+1F910 to U+1F9FF. Currently, U+1F90CU+1F90F, U+1F93F, U+1F94DU+1F94F, U+1F96CU+1F97F, U+1F998U+1F9CF (excluding U+1F9C0 which contains the \ud83e\uddc0 emoji) and U+1F9E7U+1F9FF do not contain any emoticons since Unicode 10.0.\nFor historic and compatibility reasons, some other heads and figures, which mostly represent different aspects like genders, activities, and professions instead of emotions, are also found in Miscellaneous Symbols and Pictographs (especially U+1F466U+1F487) and Transport and Map Symbols. Body parts, mostly hands, are also encoded in the Dingbat and Miscellaneous Symbols blocks."}
{"id": "9740", "revid": "6675779", "url": "https://en.wikipedia.org/wiki?curid=9740", "title": "Epoch (disambiguation)", "text": "An epoch is an instant in time chosen as the origin of a particular calendar era.\nEpoch or EPOCH may also refer to:"}
{"id": "9741", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9741", "title": "E.B. White", "text": ""}
{"id": "9742", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=9742", "title": "Erd\u0151s number", "text": "The Erd\u0151s number () describes the \"collaborative distance\" between mathematician Paul Erd\u0151s and another person, as measured by authorship of mathematical papers. The same principle has been applied in other fields where a particular individual has collaborated with a large and broad number of peers.\nOverview.\nPaul Erd\u0151s (1913\u20131996) was an influential Hungarian mathematician who in the latter part of his life spent a great deal of time writing papers with a large number of colleagues\u2014over 500\u2014working on solutions to outstanding mathematical problems. He published more papers during his lifetime (at least 1,525) than any other mathematician in history. (Leonhard Euler published more total pages of mathematics but fewer separate papers: about 800.) Erd\u0151s spent most of his career with no permanent home or job. He traveled with everything he owned in two suitcases, and would visit mathematicians he wanted to collaborate with, often unexpectedly, and expect to stay with them.\nThe idea of the Erd\u0151s number was originally created by the mathematician's friends as a tribute to his enormous output. Later it gained prominence as a tool to study how mathematicians cooperate to find answers to unsolved problems. Several projects are devoted to studying connectivity among researchers, using the Erd\u0151s number as a proxy. For example, Erd\u0151s collaboration graphs can tell us how authors cluster, how the number of co-authors per paper evolves over time, or how new theories propagate.\nSeveral studies have shown that leading mathematicians tend to have particularly low Erd\u0151s numbers (i.e. high proximity). The median Erd\u0151s number of Fields Medalists is 3. Only 7,097 (about 5% of mathematicians with a collaboration path) have an Erd\u0151s number of 2 or lower. As time passes, the lowest Erd\u0151s number that can still be achieved will necessarily increase, as mathematicians with low Erd\u0151s numbers die and become unavailable for collaboration. Still, historical figures can have low Erd\u0151s numbers. For example, renowned Indian mathematician Srinivasa Ramanujan has an Erd\u0151s number of only 3 (through G. H. Hardy, Erd\u0151s number 2), even though Paul Erd\u0151s was only 7 years old when Ramanujan died.\nDefinition and application in mathematics.\nTo be assigned an Erd\u0151s number, someone must be a coauthor of a research paper with another person who has a finite Erd\u0151s number. Paul Erd\u0151s himself is assigned an Erd\u0151s number of zero. A certain author's Erd\u0151s number is one greater than the lowest Erd\u0151s number of any of their collaborators; for example, an author who has coauthored a publication with Erd\u0151s would have an Erd\u0151s number of 1. The American Mathematical Society provides a free online tool to determine the collaboration distance between two mathematical authors listed in the \"Mathematical Reviews\" catalogue.\nErd\u0151s wrote around 1,500 mathematical articles in his lifetime, mostly co-written. He had 509 direct collaborators; these are the people with Erd\u0151s number 1. The people who have collaborated with them (but not with Erd\u0151s himself) have an Erd\u0151s number of 2 (12,600 people as of 7 August 2020), those who have collaborated with people who have an Erd\u0151s number of 2 (but not with Erd\u0151s or anyone with an Erd\u0151s number of 1) have an Erd\u0151s number of 3, and so forth. A person with no such coauthorship chain connecting to Erd\u0151s has an Erd\u0151s number of infinity (or an undefined one). Since the death of Paul Erd\u0151s, the lowest Erd\u0151s number that a new researcher can obtain is 2.\nThere is room for ambiguity over what constitutes a link between two authors. The American Mathematical Society collaboration distance calculator uses data from \"Mathematical Reviews\", which includes most mathematics journals but covers other subjects only in a limited way, and which also includes some non-research publications. The Erd\u0151s Number Project web site says: It also says:\nbut excludes non-research publications such as elementary textbooks, joint editorships, obituaries, and the like. The \"Erd\u0151s number of the second kind\" restricts assignment of Erd\u0151s numbers to papers with only two collaborators.\nThe Erd\u0151s number was most likely first defined in print by Casper Goffman, an analyst whose own Erd\u0151s number is 2. Goffman published his observations about Erd\u0151s' prolific collaboration in a 1969 article entitled \"And what is your Erd\u0151s number?\" See also some comments in an obituary by Michael Golomb.\nThe median Erd\u0151s number among Fields medalists is as low as 3. Fields medalists with Erd\u0151s number 2 include Atle Selberg, Kunihiko Kodaira, Klaus Roth, Alan Baker, Enrico Bombieri, David Mumford, Charles Fefferman, William Thurston, Shing-Tung Yau, Jean Bourgain, Richard Borcherds, Manjul Bhargava, Jean-Pierre Serre and Terence Tao. There are no Fields medalists with Erd\u0151s number 1; however, Endre Szemer\u00e9di is an Abel Prize Laureate with Erd\u0151s number 1.\nMost frequent Erd\u0151s collaborators.\nWhile Erd\u0151s collaborated with hundreds of co-authors, there were some individuals with whom he co-authored dozens of papers. This is a list of the ten persons who most frequently co-authored with Erd\u0151s and their number of papers co-authored with Erd\u0151s (i.e. their number of collaborations).\nRelated fields.\n, all Fields Medalists have a finite Erd\u0151s number, with values that range between 2 and 6, and a median of 3. In contrast, the median Erd\u0151s number across all mathematicians (with a finite Erd\u0151s number) is 5, with an extreme value of 13. The table below summarizes the Erd\u0151s number statistics for Nobel prize laureates in Physics, Chemistry, Medicine, and Economics. The first column counts the number of laureates. The second column counts the number of winners with a finite Erd\u0151s number. The third column is the percentage of winners with a finite Erd\u0151s number. The remaining columns report the minimum, maximum, average, and median Erd\u0151s numbers among those laureates.\nPhysics.\nAmong the Nobel Prize laureates in Physics, Albert Einstein and Sheldon Glashow have an Erd\u0151s number of 2. Nobel Laureates with an Erd\u0151s number of 3 include Enrico Fermi, Otto Stern, Wolfgang Pauli, Max Born, Willis E. Lamb, Eugene Wigner, Richard P. Feynman, Hans A. Bethe, Murray Gell-Mann, Abdus Salam, Steven Weinberg, Norman F. Ramsey, Frank Wilczek, David Wineland, and Giorgio Parisi. Fields Medal-winning physicist Ed Witten has an Erd\u0151s number of 3.\nBiology.\nComputational biologist Lior Pachter has an Erd\u0151s number of 2. Evolutionary biologist Richard Lenski has an Erd\u0151s number of 3, having co-authored a publication with Lior Pachter and with mathematician Bernd Sturmfels, each of whom has an Erd\u0151s number of 2.\nFinance and economics.\nThere are at least two winners of the Nobel Prize in Economics with an Erd\u0151s number of 2: Harry M. Markowitz (1990) and Leonid Kantorovich (1975). Other financial mathematicians with Erd\u0151s number of 2 include David Donoho, Marc Yor, Henry McKean, Daniel Stroock, and Joseph Keller.\nNobel Prize laureates in Economics with an Erd\u0151s number of 3 include Kenneth J. Arrow (1972), Milton Friedman (1976), Herbert A. Simon (1978), Gerard Debreu (1983), John Forbes Nash, Jr. (1994), James Mirrlees (1996), Daniel McFadden (2000), Daniel Kahneman (2002), Robert J. Aumann (2005), Leonid Hurwicz (2007), Roger Myerson (2007), Alvin E. Roth (2012), and Lloyd S. Shapley (2012) and Jean Tirole (2014).\nSome investment firms have been founded by mathematicians with low Erd\u0151s numbers, among them James B. Ax of Axcom Technologies, and James H. Simons of Renaissance Technologies, both with an Erd\u0151s number of 3.\nPhilosophy.\nSince the more formal versions of philosophy share reasoning with the basics of mathematics, these fields overlap considerably, and Erd\u0151s numbers are available for many philosophers. Philosophers John P. Burgess and Brian Skyrms have an Erd\u0151s number of 2. Jon Barwise and Joel David Hamkins, both with Erd\u0151s number 2, have also contributed extensively to philosophy, but are primarily described as mathematicians.\nLaw.\nJudge Richard Posner, having coauthored with Alvin E. Roth, has an Erd\u0151s number of at most 4. Roberto Mangabeira Unger, a politician, philosopher, and legal theorist who teaches at Harvard Law School, has an Erd\u0151s number of at most 4, having coauthored with Lee Smolin.\nPolitics.\nAngela Merkel, Chancellor of Germany from 2005 to 2021, has an Erd\u0151s number of at most 5.\nEngineering.\nSome fields of engineering, in particular communication theory and cryptography, make direct use of the discrete mathematics championed by Erd\u0151s. It is therefore not surprising that practitioners in these fields have low Erd\u0151s numbers. For example, Robert McEliece, a professor of electrical engineering at Caltech, had an Erd\u0151s number of 1, having collaborated with Erd\u0151s himself. Cryptographers Ron Rivest, Adi Shamir, and Leonard Adleman, inventors of the RSA cryptosystem, all have Erd\u0151s number 2.\nLinguistics.\nThe Romanian mathematician and computational linguist Solomon Marcus had an Erd\u0151s number of 1 for a paper in \"Acta Mathematica Hungarica\" that he co-authored with Erd\u0151s in 1957.\nImpact.\nErd\u0151s numbers have been a part of the folklore of mathematicians throughout the world for many years. Among all working mathematicians at the turn of the millennium who have a finite Erd\u0151s number, the numbers range up to 15, the median is 5, and the mean is 4.65; almost everyone with a finite Erd\u0151s number has a number less than 8. Due to the very high frequency of interdisciplinary collaboration in science today, very large numbers of non-mathematicians in many other fields of science also have finite Erd\u0151s numbers. For example, political scientist Steven Brams has an Erd\u0151s number of 2. In biomedical research, it is common for statisticians to be among the authors of publications, and many statisticians can be linked to Erd\u0151s via John Tukey, who has an Erd\u0151s number of 2. Similarly, the prominent geneticist Eric Lander and the mathematician Daniel Kleitman have collaborated on papers, and since Kleitman has an Erd\u0151s number of 1, a large fraction of the genetics and genomics community can be linked via Lander and his numerous collaborators. Similarly, collaboration with Gustavus Simmons opened the door for \nErd\u0151s numbers within the cryptographic research community, and many linguists have finite Erd\u0151s numbers, many due to chains of collaboration with such notable scholars as Noam Chomsky (Erd\u0151s number 4), William Labov (3), Mark Liberman (3), Geoffrey Pullum (3), or Ivan Sag (4). There are also connections with arts fields.\nAccording to Alex Lopez-Ortiz, all the Fields and Nevanlinna prize winners during the three cycles in 1986 to 1994 have Erd\u0151s numbers of at most 9.\nEarlier mathematicians published fewer papers than modern ones, and more rarely published jointly written papers. The earliest person known to have a finite Erd\u0151s number is either Antoine Lavoisier (born 1743, Erd\u0151s number 13), Richard Dedekind (born 1831, Erd\u0151s number 7), or Ferdinand Georg Frobenius (born 1849, Erd\u0151s number 3), depending on the standard of publication eligibility.\nMartin Tompa proposed a directed graph version of the Erd\u0151s number problem, by orienting edges of the collaboration graph from the alphabetically earlier author to the alphabetically later author and defining the \"monotone Erd\u0151s number\" of an author to be the length of a longest path from Erd\u0151s to the author in this directed graph. He finds a path of this type of length 12.\nAlso, Michael Barr suggests \"rational Erd\u0151s numbers\", generalizing the idea that a person who has written \"p\" joint papers with Erd\u0151s should be assigned Erd\u0151s number 1/\"p\". From the collaboration multigraph of the second kind (although he also has a way to deal with the case of the first kind)\u2014with one edge between two mathematicians for \"each\" joint paper they have produced\u2014form an electrical network with a one-ohm resistor on each edge. The total resistance between two nodes tells how \"close\" these two nodes are.\nIt has been argued that \"for an individual researcher, a measure such as Erd\u0151s number captures the structural properties of [the] network whereas the \"h\"-index captures the citation impact of the publications,\" and that \"One can be easily convinced that ranking in coauthorship networks should take into account both measures to generate a realistic and acceptable ranking.\"\nIn 2004 William Tozier, a mathematician with an Erd\u0151s number of 4 auctioned off a co-authorship on eBay, hence providing the buyer with an Erd\u0151s number of 5. The winning bid of $1031 was posted by a Spanish mathematician, who refused to pay and only placed the bid to stop what he considered a mockery.\nVariations.\nA number of variations on the concept have been proposed to apply to other fields, notably the Bacon number (as in the game Six Degrees of Kevin Bacon), connecting actors to the actor Kevin Bacon by a chain of joint appearances in films. It was created in 1994, 25 years after Goffman's article on the Erd\u0151s number.\nA small number of people are connected to both Erd\u0151s and Bacon and thus have an Erd\u0151s\u2013Bacon number, which combines the two numbers by taking their sum. One example is the actress-mathematician Danica McKellar, best known for playing Winnie Cooper on the TV series \"The Wonder Years\". \nHer Erd\u0151s number is 4, and her Bacon number is 2.\nFurther extension is possible. For example, the \"Erd\u0151s\u2013Bacon\u2013Sabbath number\" is the sum of the Erd\u0151s\u2013Bacon number and the collaborative distance to the band Black Sabbath in terms of singing in public. Physicist Stephen Hawking had an Erd\u0151s\u2013Bacon\u2013Sabbath number of 8, and actress Natalie Portman has one of 11 (her Erd\u0151s number is 5).\nIn chess, the Morphy number describes a player's connection to Paul Morphy, widely considered the greatest chess player of his time and an unofficial World Chess Champion.\nIn go, the Shusaku number describes a player's connection to Honinbo Shusaku, the strongest player of his time.\nIn video games, the Ryu number describes a video game character's connection to the Street Fighter character Ryu."}
{"id": "9743", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=9743", "title": "Education vouchers", "text": ""}
{"id": "9744", "revid": "3127387", "url": "https://en.wikipedia.org/wiki?curid=9744", "title": "Edgar Allen Poe/The Black Cat", "text": ""}
{"id": "9745", "revid": "197953", "url": "https://en.wikipedia.org/wiki?curid=9745", "title": "Edgar Allan Poe/The Black Cat", "text": ""}
{"id": "9750", "revid": "45741021", "url": "https://en.wikipedia.org/wiki?curid=9750", "title": "School voucher", "text": "A school voucher, also called an education voucher in a voucher system, is a certificate of government funding for students at schools chosen by themselves or their parents. Funding is usually for a particular year, term, or semester. In some countries, states, or local jurisdictions, the voucher can be used to cover or reimburse home schooling expenses. In some countries, vouchers only exist for tuition at private schools.\nA 2017 review of the economics literature on school vouchers concluded that \"the evidence to date is not sufficient to warrant recommending that vouchers be adopted on a widespread basis; however, multiple positive findings support continued exploration\". However many oppose school vouchers, especially people that adhere to the principle of the separation of church and state, as government or taxpayer funds would go toward non-secular schools.\nHistory.\nWhen France lost the Franco-Prussian War (1870\u20131871) many blamed the loss on its inferior military education system. Following this defeat, the French Assembly proposed a voucher that they hoped would improve schools by allowing students to seek out the best. This proposal never moved forward due to the reluctance of the French to subsidize religious education. Despite its failure, this proposal closely resembles voucher systems proposed and used today in many countries.\nThe oldest extant school voucher programs in the United States are the Town Tuitioning programs in Vermont and Maine, beginning in 1869 and 1873 respectively. Because some towns in these states operate neither local high schools nor elementary schools, students in these towns \"are eligible for a voucher to attend [either] public schools in other towns or non-religious private schools. In these cases, the 'sending' towns pay tuition directly to the 'receiving' schools\".\nA system of educational vouchers was introduced in the Netherlands in 1917. Today, more than 70% of pupils attend privately run but publicly funded schools, mostly split along denominational lines.\nMilton Friedman argued for the modern concept of vouchers in the 1950s, stating that competition would improve schools, cost less and yield superior educational outcomes. Friedman's reasoning in favor of vouchers gained additional attention in 1980 with the broadcast of his ten-part television series \"Free to Choose\" and the publication of its companion book of the same name (co-written with his wife Rose Friedman, who was also an economist). Episode 6 of the series and chapter 6 of the book were both entitled \"What's Wrong with Our Schools\", and asserted that permitting parents and students to use vouchers to choose their schools would expand freedom of choice and produce more well-educated students.\nIn some Southern states during the 1960s, school vouchers were used as a way to perpetuate segregation. In a few instances, public schools were closed outright and vouchers were issued to parents. The vouchers, known as tuition grants, in many cases, were only good at new, private and segregated schools, known as segregation academies.\nDefinitions.\nThere are distinctions between different kinds of schools:\nEconomics.\nBackground.\nEducation as a tool for human capital accumulation is often crucial to the development and progression of societies and thus governments have large incentives to continually intervene and improve public education. Additionally, education is often the tool with which societies instill a common set of values that underlie the basic norms of the society. Furthermore, there are positive externalities to society from education. These positive externalities can be in the form of reduced crime, more informed citizens and economic development, known as the neighborhood effect.\nIn terms of economic theory, families face a bundle of consumption choices that determine how much they will spend on education and private consumption. Any number of consumption bundles are available as long as they fit within the budget constraint. This means that any bundle of consumption of education and private consumption must not exceed budgetary constraints. Indifference curves represent the preferences of one good over another. The indifference curve determines how much education an individual will want to consume versus how much private consumption an individual will want to consume.\nGovernment intervention in education typically takes two forms. The first approach can be broad, such as instituting charter schools, magnet schools, or for-profit schools and increasing competition. The second approach can be individually focused such as providing subsidies or loans for individuals to attend college or school vouchers for K-12.\nVouchers are typically instituted for two broad economic reasons. The first reason is consumer choice. A family can choose to where their child goes to school and pick the school that is closest to their preference of education provider.\nThe second reason vouchers are proposed is to increase market competition amongst schools. Similar to the free market theorem, vouchers are intended to make schools more competitive while lowering costs for schools and increasing the educational quality for consumers, the families. It ensures educational access to the public.\nEffects.\nNegative effects.\nBesides the general lack of results, critics of school vouchers argue that vouchers will lead to segregation. Empirical studies show that there is some evidence that school vouchers can lead to racial or income segregation. However, research on this topic is inconclusive, as there is also valid research that shows under certain circumstances, income and racial segregation can be reduced indirectly by increasing school choice.\nAdditionally, since school vouchers are funded by the government, the implementation could cause the funds for public schools to be reduced. Private-school vouchers affect government budgets through two channels: additional direct voucher expenditures, and public school cost savings from lower enrollments. Voucher programs would be paid for by the government's education budget, which would be subtracted from the public school's budget. This might affect the public school system by giving them less to spend and use for their student's education.\nA 2018 study by Abdulkadiro\u011flu et al. found that disadvantaged students who won a lottery (the Louisiana Scholarship Program) to get vouchers to attend private schools had worse education outcomes than disadvantaged students who did not win vouchers: \"LSP participation lowers math scores by 0.4 standard deviations and also reduces achievement in reading, science, and social studies. These effects may be due in part to selection of low-quality private schools into the program\".\nPositive effects.\nA 2021 meta-analysis by Shakeel et al., published in the journal \" School Effectiveness and School Improvement\", evaluated evidence from randomized controlled trials assessing \"student-level math and reading test score effects of school vouchers internationally.\" After evaluating 21 studies addressing 11 different voucher programs, the meta-analysis authors found \"moderate evidence of positive achievement impacts of private school vouchers, with substantial effect heterogeneity across programs and outcome years\" as well as evidence suggesting that \"voucher interventions may be cost-effective even for null achievement impacts.\" The study authors noted that future experimental studies might yield more facts on whether and how \"long-term, scaled-up voucher interventions\" affect student achievement.\nImplementations.\nColombia.\nThe PACES voucher program was established by the Colombian government in late 1991. It aimed to assist low-income households by distributing school vouchers to students living in neighborhoods situated in the two lowest socioeconomic strata. Between 1991 and 1997, the PACES program awarded 125,000 vouchers to lower-income secondary school students. Those vouchers were worth about US$190 in 1998, and data shows that matriculation fees and other monthly expenses incurred by voucher students attending private schools averaged about US$340 in 1998, so a majority of voucher recipients supplemented the voucher with personal funds.\nThe students selected to be in the program were selected by lottery. The vouchers were able to be renewed annually, conditional on students achieving satisfactory academic success as indicated by scheduled grade promotion. The program also included incentives to study harder as well as widening schooling options. Empirical evidence showed that the program had some success. Joshua Angrist shows that after three years into the program, lottery winners were 15 percentage points more likely to attend private school and complete 0.1 more years of schooling, and were about 10 percentage points more likely to have finished the 8th grade. The study also reported that there were larger voucher effects for boys than for girls, especially in mathematics performance. The program did not have a significant impact on dropout rates. Angrist reports that lottery winners scored 0.2 standard deviations higher on standardized tests. The voucher program also reported some social effects. Lottery winners worked less on average than non-lottery winners. Angrist reports that this was correlated with a decreased likelihood to marry or cohabit as teenagers.\nChile.\nIn 1981, Chile implemented a universal school voucher system for both elementary and secondary school students. As a result, over 1,000 private schools entered the market, and private enrollment increased by 20\u201340% by 1998, surpassing 50% in some urban areas. From 1981 to 1988, the private school enrollment rate in urban areas grew 11% more than the private school enrollment rate in rural areas. This change coincided with the transfer of public school administration from the central government to local municipalities. The financial value of a voucher did not depend on the income of the family receiving it, and the program allowed private voucher schools to be selective, while public schools had to accept and enroll every interested student. At the turn of the 21st century, student achievement in Chile was low compared to students in other nations based on international test scores. This disparity led to the Chilean government enacting substantial educational reforms in 2008, including major changes in the school voucher system.\nThe Chilean government passed the Preferential School Subsidy Law (SEP) in January 2008. This piece of legislation made the educational voucher system much more like the regulated compensatory model championed by Christopher Jencks. Under SEP, the voucher system was altered to take family incomes into account. The vouchers provided to \"priority students\"\u00a0\u2013 those whose family income was in the lower than 40% of Chileans\u00a0\u2013 were worth 50% more than those given to the families with higher income. Schools with larger numbers of priority students were eligible to receive per-student bonuses, the size of which was tied to the percentage of priority students in the student body. When SEP was started, it covered preschool to fourth grade, and an additional school year of coverage was added each subsequent year. Almost every public school chose to participate in SEP in 2008, as well as almost two-thirds of private subsidized elementary schools.\nThere were three important requirements attached to the program. The first requirement stipulated that participating schools could not charge fees to priority students, although private schools in the voucher system could do so for non-priority students. The second requirement ensured that schools could not select students based on their academic ability, nor expel them on academic grounds. The third requirement postulated that schools had to self-enroll themselves in an accountability system that ensured that schools were responsible for the use of financial resources and student test scores.\nEurope.\nIn most European countries, education for all primary and secondary schools is fully subsidized. In some countries (e.g., Belgium or France), parents are free to choose which school their child attends.\nFrance.\nParents can choose either a private school or a public school. Most private schools are under contract to the French government in which case the French government pays teachers' salaries and they are considered state employees. Other costs at private schools are paid through fees which are usually low. Schools under contract follow the French national curriculum. Some private schools are not under contract giving them more freedom to teach different curricula although the state still monitors educational standards. Teachers' salaries at private schools not 'under contract' are paid through fees that are therefore much higher than those under contract. About 20% of French schoolchildren attend private schools. Homeschooling is possible but restricted in France. Indeed, on October 2, 2022, Emmanuel Macron reinforced secularism by allowing homeschooling only under specific circumstances, such as for individuals with disabilities, high-level athletes or artists, or those belonging to nomadic communities, as part of measures to combat the spread of obscurantism in some families.\nIreland.\nMost schools in the Republic of Ireland are state-aided Catholic parish schools, established under diocesan patronage but with capital costs, teachers' salaries, and a fee per head paid to the school. These are given to the school regardless of whether or not it requires its students to pay fees. (Although fee-paying schools are in the minority, there has been much criticism over the state aid they receive. Opponents claim that the aid gives them an unfair advantage.)\nThere is a recent trend towards multi-denominational schools established by parents and organised as limited companies without share capital. Parents and students are free to choose their own schools. If a school fails to attract students, it immediately loses its fees and eventually loses its teaching posts, and teachers are moved to other schools that are attracting students. The system is perceived to have achieved very successful outcomes for most Irish children.\nThe 1995\u201397 \"Rainbow Coalition\" government, containing ministers from parties of the center-right and the left, introduced free third-level education to primary degree level. Critics charge that this has not increased the number of students from economically deprived backgrounds attending university. However, studies have shown that the removal of tuition fees at third level has increased the numbers of students overall and of students from lower socioeconomic backgrounds. Since the economic crisis of 2008, there has been extensive debate regarding the possible reintroduction of third-level fees.\nSweden.\nIn Sweden, a system of school vouchers (called \"skolpeng\") was introduced in 1992 at primary and secondary school level, enabling free choice among publicly run schools and privately run \"frist\u00e5ende skolor\" (\"independent schools\"). The voucher is paid with public funds from the local municipality (\"kommun\") directly to a school based solely on its number of students. Both public schools and independent schools are funded the same way. Independent schools can be run by not-for-profit groups as well as by for-profit companies, but may not charge top-up fees or select students other than on a first-come, first-served basis. Over 10% of Swedish students were enrolled in independent schools in 2008 and the number is growing fast, leading the country to be viewed as a pioneer of the model.\nPer Unckel, governor of Stockholm and former Minister of Education, has promoted the system, saying \"Education is so important that you can't just leave it to one producer, because we know from monopoly systems that they do not fulfill all wishes.\" The Swedish system has been recommended to Barack Obama by some commentators, including the Pacific Research Institute, which has released a documentary called \"Not As Good As You Think: Myth of the Middle Class Schools\", a movie depicting positive benefits for middle class schools resulting from Sweden's voucher programs.\nA 2004 study concluded that school results in public schools improved due to increased competition. However, Per Thulberg, director general of the Swedish National Agency for Education, has said that the system \"has not led to better results\" and in the 2000s Sweden's ranking in the PISA league tables worsened. Though Rachel Wolf, director of the New Schools Network, has suggested that Sweden's education standards had slipped for reasons other than as a result of independent schools.\nA 2015 study was able to show that \"an increase in the share of independent school students improves average short\u2010 and long\u2010run outcomes, explained primarily by external effects (e.g., school competition)\".\nHong Kong.\nA voucher system for children three to six years old who attend a non-profit kindergarten was implemented in Hong Kong in 2007. Each child will get HK$13,000 per year. The $13,000 subsidy will be separated into two parts: $10,000 is used to subsidize the school fee, and the remaining $3,000 is used for kindergarten teachers to pursue further education and obtain a certificate in education. Also, there are some restrictions on the voucher system. Parents can only choose non-profit schools with a yearly fee of less than $24,000. The government hoped that all kindergarten teachers can obtain an education certificate by the year 2011\u201312, at which point the subsidies are to be adjusted to $16,000 for each student, all of which will go toward the school fee.\nMilton Friedman criticised the system, saying \"I do not believe that CE Mr. Tsang's proposal is properly structured.\" He said that the whole point of a voucher system is to provide a competitive marketplace so should not be limited to non-profit kindergartens. \nAfter protests by parents with children enrolled in for-profit kindergartens, the program was extended to children in for-profit kindergartens, but only for children enrolled in or before September 2007. The government will also provide up to HK$30,000 subsidy to for-profit kindergartens wanting to convert to non-profit.\nPakistan.\nIn Pakistani Punjab, the Education Voucher Scheme (EVS) was introduced by Dr. Allah Bakhsh Malik, managing director and chief executive of the Punjab Education Foundation (PEF), especially in urban slums and the poorest of the poor in 2005. The initial study was sponsored by Open Society Institute New York USA. Professor Henry M. Levin extended pro-bono services for children of poor families from Punjab. To ensure educational justice and integration, the government must ensure that the poorest families have equal access to quality education. The voucher scheme was designed by the Teachers College, Columbia University, and the Open Society Institute. It aims to promote freedom of choice, efficiency, equity, and social cohesion.\nA pilot project was started in 2006 in the urban slums of Sukhnehar, Lahore, where a survey showed that all households lived below the poverty line. Through the EVS, the foundation would deliver education vouchers to every household with children 5\u201316 years of age. The vouchers would be redeemable against tuition payments at participating private schools. In the pilot stage, 1,053 households were given an opportunity to send their children to a private school of their choice. The EVS makes its partner schools accountable to the parents rather than to the bureaucrats at the Ministry of Education. In the FAS program, every school principal has the choice to admit a student or not. However, in the EVS, a partner school cannot refuse a student if the student has a voucher, and the family has chosen that school. The partner schools are also accountable to the PEF: they are subject to periodic reviews of their student learning outcomes, additional private investments, and improvements in the working conditions of the teachers. The EVS provides an incentive to parents to send their children to school, and so it has become a source of competition among private schools seeking to join the program.\nWhen it comes to the selection of schools, the following criteria are applied across the board: (i) The fee paid by the PEF to EVS partner schools is PKR 550 per child per month. Schools charging higher fees can also apply to the program, but they will not be paid more than PKR 1200, and they will not be entitled to charge the difference to students' families. (ii) Total school enrollment should be at least 50 children. (iii) The school should have adequate infrastructure and a good learning environment. (iv) EVS partner schools should be located within a half-kilometer radius of the residences of voucher holders. However, if the parents prefer a particular school farther away, the PEF will not object, provided that the school fulfills the EVS selection criteria. (v) The PEF advertises to stimulate the interest of potential partner schools. It then gives students at short-listed schools preliminary tests in selected subjects and conducts physical inspections of these schools. PEF offices display a list of all the EVS partner schools so that parents may consult it and choose a school for their children.\nBy now more than 500,000 students are benefiting from EVS and the program is being scaled up by financing from the Government of Punjab.\nSchool voucher public policy in the United States.\nIn the 1980s, the Reagan administration pushed for vouchers, as did the George W. Bush administration in the initial education reform proposals leading up to the No Child Left Behind Act. As of December 2016, 14 states had traditional school voucher programs. These states consist of: Arkansas, Florida, Georgia, Indiana, Louisiana, Maine, Maryland, Mississippi, North Carolina, Ohio, Oklahoma, Utah, Vermont, and Wisconsin. The capital of the United States, Washington, D.C., also had operating school voucher programs as of December 2016. When including scholarship tax credits and education savings accounts \u2013 two alternatives to vouchers \u2013 there are 27 states plus the District of Columbia with private school choice programs. Most of these programs were offered to students in low-income families, low-performing schools, or students with disabilities. By 2014, the number participating in either vouchers or tax-credit scholarships increased to 250,000, a 30% increase from 2010, but still a small fraction compared to the 55 million in traditional schools.\nIn 1990, the city of Milwaukee, Wisconsin's public schools implemented a program called the Milwaukee Parental Choice Program. Originally, this funded school vouchers for nonreligious, private institutions. It was, however, eventually expanded to include private, religious institutions after it saw success with nonreligious, private institutions. The 2006/07 school year marked the first time in Milwaukee that more than $100\u00a0million was paid in vouchers. Twenty-six percent of Milwaukee students will receive public funding to attend schools outside the traditional Milwaukee Public School system. In fact, if the voucher program alone were considered a school district, it would mark the sixth-largest district in Wisconsin. St. Anthony Catholic School, located on Milwaukee's south side, boasts 966 voucher students, meaning that it very likely receives more public money for general school support of a parochial elementary or high school than any before it in American history. A 2013 study of Milwaukee's program posited that the use of vouchers increased the probability that a student would graduate from high school, go to college, and stay in college. A 2015 paper published by the National Bureau of Economic Research found that participation in Louisiana's voucher program \"substantially reduces academic achievement\" although that the result may be reflective of the poor quality of private schools in the program.\nA recent analysis of the competitive effects of school vouchers in Florida suggests that more competition improves performance in the regular public schools.\nThe largest school voucher program in the United States is the Indiana Choice Scholarships program.\nOpponents.\nThe main critique of school vouchers and education tax credits is that they put public education in competition with private education, threatening to reduce and reallocate public school funding to private schools. Opponents question the belief that private schools are more efficient.\nPublic school teachers and teacher unions have also fought against school vouchers. In the United States, public school teacher unions, most notably the National Education Association (the largest labor union in the US), argue that school vouchers erode educational standards and reduce funding and that giving money to parents who choose to send their child to a religious or other school is unconstitutional. The latter issue was struck down by the Supreme Court case \"Zelman v. Simmons-Harris\", which upheld Ohio's voucher plan in a 5\u20134 ruling. In contrast, the use of public-school funding for vouchers to private schools was disallowed by the Louisiana Supreme Court in 2013. The Louisiana Supreme Court did not declare vouchers unconstitutional, just the use of money earmarked for public schools via the Louisiana Constitution for funding Louisiana's voucher program. The National Education Association also points out that access to vouchers is just like \"a chance in a lottery\" where parents had to be lucky to get a space in this program. Since almost all students and their families would like to choose the best schools, those schools, as a result, quickly reach its maximum capacity number for students that state law permits. Those who did not get vouchers then have to compete again to look for some other less preferred and competitive schools or give up searching and go back to their assigned local schools. Jonathan Kozol, a prominent public school reform thinker and former public-school teacher called vouchers the \"single worst, most dangerous idea to have entered education discourse in my adult life\".\nThe National Education Association additionally argues that more money should go towards public education to help the schools struggling and improve the schools overall, instead of reducing the public school's fund to go towards school vouchers. Their argument claims that increasing that amount of money that goes towards public education would also increase the amount of resources put into public schools, therefore, improving the education. This argument made towards school vouchers reflects the way the organization values public education. For example, in an interview in May 2017 regarding Donald Trump's 2018 Budget Proposal, the organization's president, Lily Eskelsen Garc\u00eda, claimed:\n\"We should invest in what makes schools great, the things that build curiosity and instill a love of learning. That is what every student deserves and what every parent wants for his or her child. It should not depend on how much their parents make, what language they speak at home, and certainly, not what neighborhood they live in.\" \u2013 National Education Association President Lily Eskelsen Garc\u00eda.\nFurthermore, there are multiple studies that support the arguments made by opponents of school vouchers. One of these studies, conducted by the Tulane University's Education Research Alliance, consists of observing the relationship between voucher programs and students' test scores. They found that students in the Louisiana voucher program initially had lower test scores, but after three years, their scores matched those of students who stayed in public schools from standardized test scores spanning from 2012 to 2015.\nPeople who can benefit from vouchers may not know it. In April 2012, a bill passed in Louisiana that made vouchers available to low-income families whose children attended poorly ranked schools. A student whose household income was low (up to about $44,000 for a family of three) and who attended a school ranked \"C\", \"D\", or \"F\" could apply for vouchers to attend another. Of the estimated 380,000 eligible students during the school year when the bill was passed (2012/13), only 5,000 students knew about and applied for the vouchers, and accepted them.\nIn 2006, the United States Department of Education released a report concluding that average test scores for reading and mathematics, when adjusted for student and school characteristics, tend to be very similar among public schools and private schools. Private schools performed significantly better than public schools only if results were not adjusted for factors such as race, gender, and free or reduced-price lunch program eligibility. Other research questions assumptions that large improvements would result from a more comprehensive voucher system.\nGiven the limited budget for schools, it is claimed that a voucher system would weaken public schools while not providing enough money for people to attend private schools. 76% of the money given in Arizona's voucher program went to children already in private schools.\nSome sources claim that public schools' higher per-pupil spending is due to having a higher proportion of students with behavioral, physical, and emotional problems since in the United States, public schools must by law accept any student regardless of race, gender, religion, disability, educational aptitude, and so forth, while private schools are not so bound. They argue that some, if not all, of the cost difference between public and private schools comes from \"cream skimming\", whereby the private schools select only those students who belong to a preferred group \u2013 whether economic, religious, educational aptitude level, or ethnicity \u2013 rather than from differences in administration. The result, it has been argued, is that a voucher system has led or would lead students who do not belong to the private schools' preferred groupings to become concentrated at public schools. However, of the ten state-run voucher programs in the United States at the beginning of 2011, four targeted low-income students, two targeted students in failing schools, and six targeted students with special needs. (Louisiana ran a single program targeting all three groups.)\nIt is also argued that voucher programs are often implemented without the necessary safeguards that prevent institutions from discriminating against marginalized communities. In the United States, as of 2016, there are currently no state laws that require voucher programs to not discriminate against marginalized communities. Further, while some voucher programs may explicitly be aimed at marginalized communities, this is not necessarily always the case. A common argument for school vouchers is that it allows for marginalized communities of color to be uplifted from poverty. Historically, however, data suggests that voucher programs have been used to further segregate Americans. Further, some data has shown that the effects of voucher programs such as the New York City School Choice Scholarship Program, are marginal when it comes to increasing student achievement.\nAnother argument against a school voucher system is its lack of accountability to taxpayers. In many states, members of a community's board of education are elected by voters. Similarly, a school budget faces a referendum. Meetings of the Board of Education must be announced in advance, and members of the public are permitted to voice their concerns directly to board members. By contrast, although vouchers may be used in private and religious schools, taxpayers cannot vote on budget issues, elect members of the board or even attend board meetings. Even voucher proponents acknowledge that decreased transparency and accountability for public funds are problematic features of the voucher system, and some have suggested a 'sliding scale' approach wherein oversight and accountability increase in proportion to the number of taxpayer dollars (in the form of vouchers) received by the private school.\nKevin Welner points out that vouchers funded through a convoluted tax credit system \u2013 a policy he calls \"neovouchers\" \u2013 present additional accountability concerns. With neovoucher systems, a taxpayer owing money to the state instead donates that money to a private, nonprofit organization. That organization then bundles donations and gives them to parents as vouchers to be used for private school tuition. The state then steps in and forgives (through a tax credit) some or all of the taxes that the donor has given to the organization. While conventional tax credit systems are structured to treat all private school participants equally, neovoucher systems effectively delegate to individual private taxpayers (those owing money to the state) the power to decide which private schools will benefit.\nAn example of a lack of accountability is the voucher situation in Louisiana. In 2012, Louisiana State Superintendent of Education John White selected private schools to receive vouchers, then tried to fabricate criteria (including site visits) after schools had already received approval letters. One school of note, New Living Word in Ruston, Louisiana, did not have sufficient facilities for the over 300 students White and the state board of education had approved. Following a voucher audit in 2013, New Living Word had overcharged the state $395,000. White referred to the incident as a \"lone substantive issue\". However, most voucher schools did not undergo a complete audit for not having a separate checking account for state voucher money.\nAccording to Susanne Wiborg, an expert on comparative education, Sweden's voucher system introduced in 1992 has \"augmented social and ethnic segregation, particularly in relation to schools in deprived areas\".\nTax-credit scholarships which are in most part disbursed to current private school students or to families which made substantial donations to the scholarship fund, rather than to low-income students attempting to escape from failing schools, amount to nothing more than a mechanism to use public funds in the form of foregone taxes to support private, often religiously based, private schools.\nProponents.\nProponents of school vouchers and education tax credit systems argue that those systems promote free market competition among both private and public schools by allowing parents and students to choose the school to use the vouchers. This choice available to parents' forces schools to perpetually improve to maintain enrollment. Thus, proponents argue that a voucher system increases school performance and accountability because it provides consumer sovereignty \u2013 allowing individuals to choose what product to buy, as opposed to a bureaucracy.\nThis argument is supported by studies such as \"When Schools Compete: The Effects of Vouchers on Florida Public School Achievement\" (Manhattan Institute for Policy Research, 2003), which concluded that public schools located near private schools that were eligible to accept voucher students made significantly more improvements than did similar schools not located near eligible private schools. Stanford's Caroline Hoxby, who has researched the systemic effects of school choice, determined that areas with greater residential school choice have consistently higher test scores at a lower per-pupil cost than areas with very few school districts. Hoxby studied the effects of vouchers in Milwaukee and of charter schools in Arizona and Michigan on nearby public schools. Public schools forced to compete made greater test-score gains than schools not faced with such competition, and that the so-called effect of cream skimming did not exist in any of the voucher districts examined. Hoxby's research has found that both private and public schools improved through the use of vouchers.\nSimilarly, it is argued that such competition has helped in higher education, with publicly funded universities directly competing with private universities for tuition money provided by the Government, such as the GI Bill and the Pell Grant in the United States. The Foundation for Educational Choice alleges that a school voucher plan \"embodies exactly the same principle as the GI bills that provide for educational benefits to military veterans. The veteran gets a voucher good only for educational expense and he is completely free to choose the school at which he uses it, provided that it satisfies certain standards\". The Pell Grant, a need-based aid, like the Voucher, can only be used for authorized school expenses at qualified schools, and, like the Pell, the money follows the student, for use against those authorized expenses (not all expenses are covered).\nProponents are encouraged by private school sector growth, as they believe that private schools are typically more efficient at achieving results at a much lower per-pupil cost than public schools. A CATO Institute study of public and private school per pupil spending in Phoenix, Los Angeles, D.C., Chicago, New York City, and Houston found that public schools spend 93% more than the estimated median private schools.\nProponents claim that institutions often are forced to operate more efficiently when they are made to compete and that any resulting job losses in the public sector would be offset by the increased demand for jobs in the private sector.\nFriedrich von Hayek on the privatizing of education:\nOther notable supporters include New Jersey Senator Cory Booker, former governor of South Carolina Mark Sanford, billionaire and American philanthropist John T. Walton, Former mayor of Baltimore Kurt L. Schmoke, Former Massachusetts Governor Mitt Romney and John McCain. A random survey of 210 Ph.D.-holding members of the American Economic Association, found that over two-thirds of economists support giving parents educational vouchers that can be used at government-operated or privately operated schools, and that support is greater if the vouchers are to be used by parents with low-incomes or parents with children in poorly performing schools.\nAnother prominent proponent of the voucher system was Apple co-founder and CEO, Steve Jobs, who said:\nAs a practical matter, proponents note, most U.S. programs only offer poor families the same choice more affluent families already have, by providing them with the means to leave a failing school and attend one where the child can get an education. Because public schools are funded on a per-pupil basis, the money simply follows the child, but the cost to taxpayers is less because the voucher generally is less than the actual cost.\nIn addition, they say, the comparisons of public and private schools on average are meaningless. Vouchers usually are used by children in failing schools, so they can hardly be worse off even if the parents fail to choose a better school. Also, focusing on the effect on public school suggests that is more important than the education of children.\nSome proponents of school vouchers, including the Sutherland Institute and many supporters of the Utah voucher effort, see it as a remedy for the negative cultural impact caused by underperforming public schools, which falls disproportionately on demographic minorities. During the run-up to the November referendum election, Sutherland issued a controversial publication: Voucher, Vows, &amp; Vexations. Sutherland called the publication an important review of the history of education in Utah, while critics just called it revisionist history. Sutherland then released a companion article in a law journal as part of an academic conference about school choice.\nEdChoice, founded by Milton and Rose Friedman in 1996, is a non-profit organization that promotes universal school vouchers and other forms of school choice. In defense of vouchers, it cites empirical research showing that students who were randomly assigned to receive vouchers had higher academic outcomes than students who applied for vouchers but lost a random lottery and did not receive them; and that vouchers improve academic outcomes at public schools, reduce racial segregation, deliver better services to special education students, and do not drain money from public schools.\nEdChoice also argues that education funding should belong to children, not a specific school type or building. Their purpose for the argument is to try to argue that people should prioritize a student's education and their opportunity over making a specific type of school better. They also emphasize that if a family chooses a public school, the funds also go to that school. This would mean that it would also benefit those who value the public education system.\nLegal challenges.\nThe school voucher question in the United States also received a considerable amount of judicial review in the early 2000s.\nA program launched in the city of Cleveland in 1995 and authorized by the state of Ohio was challenged in court on the grounds that it violated both the federal constitutional principle of separation of church and state and the guarantee of religious liberty in the Ohio Constitution. These claims were rejected by the Ohio Supreme Court, but the federal claims were upheld by the local federal district court and by the Sixth Circuit appeals court. The fact that nearly all of the families using vouchers attended Catholic schools in the Cleveland area was cited in the decisions.\nThis was later reversed in 2002 in a landmark case before the US Supreme Court, \"Zelman v. Simmons-Harris\", in which the divided court, in a 5\u20134 decision, ruled the Ohio school voucher plan constitutional and removed any constitutional barriers to similar voucher plans in the future, with conservative justices Anthony Kennedy, Sandra Day O'Connor, William Rehnquist, Antonin Scalia, and Clarence Thomas in the majority.\nChief Justice William Rehnquist, writing for the majority, stated that \"The incidental advancement of a religious mission, or the perceived endorsement of a religious message, is reasonably attributable to the individual aid recipients, not the government, whose role ends with the disbursement of benefits.\" The Supreme Court ruled that the Ohio program did not violate the Establishment Clause, because it passed a five-part test developed by the Court in this case, titled the Private Choice Test.\nDissenting opinions included Justice Stevens's, who wrote \"...the voluntary character of the private choice to prefer a parochial education over an education in the public school system seems to me quite irrelevant to the question whether the government's choice to pay for religious indoctrination is constitutionally permissible\" and Justice Souter's, whose opinion questioned how the Court could keep \"Everson v. Board of Education\" on as precedent and decide this case in the way they did, feeling it was contradictory.\nIn 2006, the Florida Supreme Court struck down legislation known as the Florida Opportunity Scholarship Program (OSP), which would have implemented a system of school vouchers in Florida. The court ruled that the OSP violated article IX, section 1(a) of the Florida Constitution: \"Adequate provision shall be made by law for a uniform, efficient, safe, secure, and high-quality system of free public schools.\" This decision was criticized by Clark Neily, Institute for Justice senior attorney and legal counsel to Pensacola families using Florida Opportunity Scholarships, as \"educational policymaking\".\nPolitical support.\nPolitical support for school vouchers in the United States is mixed. On the left/right spectrum, conservatives are more likely to support vouchers. Some state legislatures have enacted voucher laws. In New Mexico, then-Republican Gary Johnson made school voucher provision the major issue of his second term as governor. The federal government provided a voucher program for 7,500 residents of Washington, D.C., called the D.C. Opportunity Scholarship Program. The program operated until in early March 2009, when congressional Democrats moved to close down the program and remove children from their voucher-funded school places at the end of the 2009/10 school year under the $410\u00a0billion Omnibus Appropriations Act of 2009 which, as of March 7 had passed the House and was pending in the Senate. The Obama administration stated that it preferred to allow children already enrolled in the program to finish their schooling while closing the program to new entrants. However, its preference on this matter was not strong enough to prevent the president from signing the bill.\nWhether or not the public generally supports vouchers is debatable. Majorities seem to favor improving existing schools over providing vouchers, yet as many as 40% of those surveyed admit that they do not know enough to form an opinion or do not understand the system of school vouchers.\nIn November 2000, a voucher system proposed by Tim Draper was placed on the California ballot as Proposition 38. It was unusual among school voucher proposals in that it required neither accreditation on the part of schools accepting vouchers, nor proof of need on the part of families applying for them; neither did it have any requirement that schools accept vouchers as payment-in-full, nor any other provision to guarantee a reduction in the real cost of private school tuition. The measure was defeated by a final percentage tally of 70.6 to 29.4.\nA statewide universal school voucher system providing a maximum tuition subsidy of $3,000 was passed in Utah in 2007, but 62% of voters repealed it in a statewide referendum before it took effect. On April 27, 2011, Indiana passed a statewide voucher program, the largest in the U.S. It offers up to $4,500 to students with household incomes under $41,000, and lesser benefits to households with higher incomes. The vouchers can be used to fund a variety of education options outside the public school system. In March 2013, the Indiana Supreme Court found that the program does not violate the state constitution.\nTrump's 2018 Budget.\nPresident Donald Trump proposed a 2018 budget that included $250\u00a0million for voucher initiatives, state-funded programs that pay for students to go to private school. This 2018 budget served the purpose of \"Expanding school choice, ensuring more children have an equal opportunity to receive a great education, maintaining strong support for the Nation's most vulnerable students, simplifying funding for post-secondary education, continuing to build evidence around educational innovation, and eliminating or reducing Department programs consistent with the limited Federal role in education.\" The Budget reduced more than 30 programs that duplicated other programs; that were deemed ineffective; or that were more appropriately supported with state, local, or private funds. Another $1 billion was set aside for encouraging schools to adopt school choice-friendly policies.\nBetsy DeVos, Trump's education secretary, is also an advocate for voucher programs and has argued that they would lead to better educational outcomes for students. Both Trump and DeVos proposed cutting the Education Department's budget by about $3.6\u00a0billion and spend more than $1\u00a0billion on private school vouchers and other school choice plans.\nRegarding the purpose and importance of the budget, DeVos claimed:\nThis budget makes an historic investment in America's students. President Trump is committed to ensuring the Department focuses on returning decision-making power back to the States, where it belongs, and on giving parents more control over their child's education. By refocusing the Department's funding priorities on supporting students, we can usher in a new era of creativity and ingenuity and lay a new foundation for American greatness. \u2013 Betsy DeVos, U.S. Secretary of Education\nTeaching creationism instead of evolution.\nSome private religious schools in voucher programs teach creationism instead of the theory of evolution, including religious schools that teach religious theology side by side with or in place of science. Over 300 schools in the U.S. have been documented as teaching creationism and receiving taxpayer money. A strict definition of state-funded religious education was narrowly deemed constitutional in \"Zelman v. Simmons-Harris\" (2002). At least 35 states have passed various Blaine Amendments restricting or prohibiting public funding of religious education. However, \"Espinoza v. Montana Department of Revenue\" (2020) ruled that it is unconstitutional to disqualify all religious schools from receiving public funds that other private schools are eligible to get."}
{"id": "9751", "revid": "268817", "url": "https://en.wikipedia.org/wiki?curid=9751", "title": "E. B. White", "text": "Elwyn Brooks White (July 11, 1899\u00a0\u2013 October 1, 1985) was an American writer. He was the author of several highly popular books for children, including \"Stuart Little\" (1945), \"Charlotte's Web\" (1952), and \"The Trumpet of the Swan\" (1970). \nIn a 2012 survey of \"School Library Journal\" readers, \"Charlotte's Web\" was ranked first in their poll of the top one hundred children's novels. White also was a contributing editor to \"The New Yorker\" magazine and co-author of \"The Elements of Style\", an English language style guide.\nEarly life, family and education.\nWhite was born in Mount Vernon, New York, on July 11, 1899, the sixth and youngest child of Samuel Tilly White, the president of a piano firm, and Jessie Hart White, the daughter of Scottish-American painter William Hart. Elwyn's older brother Stanley Hart White, known as Stan, a professor of landscape architecture and the inventor of the vertical garden, taught E.B. White to read and explore the natural world.\nWhite attended Cornell University, where he was briefly a private in the Student Army Training Corps (SATC), created by the US Department of War in 1918 to hasten the training of US soldiers for World War I in Europe. Students continued to take college courses while training for the army. Unlike the Reserve Officers' Training Corps (ROTC), SATC students were required to live and take all meals on campus and adhered to a strict military schedule of study and training. They also required a pass to go off campus on weekends. Following the end of World War I, the SATC program was disbanded in December 1918, and White did not serve with the active armed forces.\nIn 1921, White graduated from Cornell University with a Bachelor of Arts degree. At Cornell, he obtained the nickname \"Andy\", where tradition confers that moniker on any male student whose surname is White after Cornell co-founder Andrew Dickson White. He worked as editor of \"The Cornell Daily Sun\" with classmate Allison Danzig, who later became a sportswriter for \"The New York Times\". As a Cornell University student, White was a member of Aleph Samach, Quill and Dagger, and Phi Gamma Delta fraternity.\nCareer.\nAfter graduating from Cornell, White went to work for the United Press, later United Press International, and the American Legion News Service in 1921 and 1922. From September 1922 to June 1923, he was a cub reporter for \"The Seattle Times\". On one occasion, when White was stuck writing a story, a \"Times\" editor said, \"Just say the words.\" \nWhite was fired from the \"Times\" and later wrote for the rival \"Seattle Post-Intelligencer\" before a stint in Alaska on a fireboat. He then worked for almost two years with the Frank Seaman advertising agency as a production assistant and copywriter before returning to New York City in 1924. \nIn 1925, after \"The New Yorker\" was founded, White began submitting manuscripts to the magazine. Katharine Angell, the literary editor, recommended to editor-in-chief and founder Harold Ross that White be hired as a staff writer. However, it took months to convince White to attend a meeting at the office and additional weeks to convince him to work on the premises. He eventually agreed to work in the office on Thursdays.\nWhite published his first article for \"The New Yorker\" in 1925, then joined the staff in 1927, and continued to write for the magazine for nearly six decades. Best recognized for his essays and unsigned \"Notes and Comment\" pieces, he gradually became the magazine's most important contributor. From the beginning to the end of his career at \"The New Yorker,\" he frequently provided what the magazine calls \"Newsbreaks\", which were short, witty comments on oddly worded printed items from many sources, under various categories, such as \"Block That Metaphor.\" He also was a columnist for \"Harper's Magazine\" from 1938 to 1943.\nIn 1929, White coauthored with James Thurber on Is Sex Necessary? In 1949, White published \"Here Is New York\", a short book based on an article he had been commissioned to write for \"Holiday\". Editor Ted Patrick approached White about writing the essay, telling him it would be fun. \"Writing is never 'fun'\", White replied. That article reflects the writer's appreciation of a city that provides its residents with both \"the gift of loneliness and the gift of privacy.\" It concludes with a dark note touching on the forces that could destroy the city that he loved. This prescient \"love letter\" to the city was re-published in 1999 on his centennial with an introduction by his stepson, Roger Angell.\nIn 1959, White edited and updated \"The Elements of Style\". This handbook of grammatical and stylistic guidance for writers of American English was first written and published in 1918 by William Strunk Jr., one of White's professors at Cornell. White's reworking of the book was extremely well received, and later editions followed in 1972, 1979, and 1999. Maira Kalman illustrated an edition in 2005. That same year, Nico Muhly, a New York City composer, premiered a short opera based on the book. The volume is a standard tool for students and writers and remains required reading in many composition classes. The complete history of \"The Elements of Style \"is detailed in Mark Garvey's \"Stylized: A Slightly Obsessive History of Strunk &amp; White's The Elements of Style\".\nIn 1978, White was awarded a special Pulitzer Prize, citing \"his letters, essays and the full body of his work\". He also received the Presidential Medal of Freedom in 1963 and honorary memberships in a variety of literary societies throughout the United States. The 1973 Oscar-nominated Canadian animated short \"The Family That Dwelt Apart\" was narrated by White and was based on his short story of the same name.\nChildren's books.\nIn the late 1930s, White turned his hand to children's fiction on behalf of a niece, Janice Hart White. His first children's book, \"Stuart Little\", was published in 1945, and \"Charlotte's Web\" followed in 1952. \"Stuart Little\" initially received a lukewarm welcome from the literary community. However, both books went on to receive high acclaim, and \"Charlotte's Web\" won a Newbery Honor from the American Library Association, though it lost out on winning the Newbery Medal to \"Secret of the Andes\" by Ann Nolan Clark.\nWhite received the Laura Ingalls Wilder Medal from the U.S. professional children's librarians in 1970. It recognized his \"substantial and lasting contributions to children's literature.\" That year, he was also the U.S. nominee and eventual runner-up for the biennial Hans Christian Andersen Award, as he was again in 1976. Also, in 1970, White's third children's novel was published, \"The Trumpet of the Swan\". In 1973 it won the Sequoyah Award from Oklahoma and the William Allen White Award from Kansas, both selected by students voting for their favorite book of the year. In 2012, the \"School Library Journal\" sponsored a survey of readers, which identified \"Charlotte's Web\" as the best children's novel (\"fictional title for readers 8\u201312\" years old). The librarian who conducted it said, \"It is impossible to conduct a poll of this sort and expect [White's novel] to be anywhere but #1.\"\nPersonal life.\nWhite was shy around women, claiming he had \"too small a heart, too large a pen\". But in 1929, after an affair that led to Katharine Angell's divorce, she and White were married. They had a son, Joel White, a naval architect and boat builder, who later owned Brooklin Boat Yard in Brooklin, Maine. Katharine's son from her first marriage, Roger Angell, spent decades as a fiction editor for \"The New Yorker\" and was well known as the magazine's baseball writer.\nIn her foreword to \"Charlotte's Web\", Kate DiCamillo quotes White as saying, \"All that I hope to say in books, all that I ever hope to say, is that I love the world.\" White also loved animals, farms and farming implements, seasons, and weather formats.\nJames Thurber described White as a quiet man who disliked publicity and who, during his time at \"The New Yorker\", would slip out of his office via the fire escape to a nearby branch of Schrafft's to avoid visitors he didn't know: \nLater in life, White developed Alzheimer's disease. He died on October 1, 1985, at his farm home in North Brooklin, Maine. He is buried in the Brooklin Cemetery beside Katharine, who died in 1977.\nLegacy.\nThe E. B. White Read Aloud Award is given by The Association of Booksellers for Children (ABC) to honor books that its membership feel embodies the universal read-aloud standards that E.B. White's works created.\nThe Division of Rare and Manuscript Collections at Cornell University Library holds the E.B. White Collection, an archive of manuscripts, letters, photographs, cassette tapes regarding E. B. White, including over 25,000 letters sent to him. For example, when Late Night show host Conan O'Brien reminisced about the return letter he received from E. B. White after writing him a letter at the age of 16, Cornell's Olin Library found that letter for him. During the 2025 Palisades Fire, O'Brien recalled that when he was told to evacuate, his wife asked what to grab, and he replied, \"Just grab the E.B. White letter off the wall.\""}
{"id": "9752", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=9752", "title": "Evangelist (Latter Day Saints)", "text": "In the Latter Day Saint movement, an evangelist is an ordained office of the ministry. In some denominations of the movement, an evangelist is referred to as a patriarch. However, the latter term was deprecated by the Community of Christ after the church began ordaining women to the priesthood. Other denominations, such as The Church of Jesus Christ (Bickertonite), have an evangelist position independent of the original \"patriarch\" office instituted movement founder Joseph Smith.\nEarly Latter Day Saint movement.\nThe first use of the term \"evangelist\" in Latter Day Saint theology were mainly consistent with how the term is used by Protestants and Catholics.\nIn 1833, Joseph Smith introduced the new office of patriarch, to which he ordained his father. The elder Smith was given the \"keys of the patriarchal Priesthood over the kingdom of God on earth\", the same power said to be held by the Biblical patriarchs, which included the power to give blessings upon one's posterity. The elder Smith, however, was also called to give patriarchal blessings to the fatherless within the church, and the church as a whole, a calling he passed onto his eldest surviving son Hyrum Smith prior to his death. Hyrum himself was killed in 1844 along with Joseph, resulting in a succession crisis that broke the Latter Day Saint movement into multiple denominations.\nIt is not known who first identified the term \"evangelist\" with the office of patriarch. However, in an 1835 church publication, W. W. Phelps stated,\nIn 1839, Joseph Smith equated an evangelist with the office of patriarch, stating that \"an Evangelist is a Patriarch\".\nThe necessity of an evangelist in the church organization has been reinforced repeatedly, based on the passage in Ephesians 4:11, which states, \"And he gave some, apostles; and some, prophets; and some, evangelists; and some, pastors and teachers\". In 1834, while writing what he called the \"principles of salvation\", prominent early Latter Day Saint Oliver Cowdery stated that:\nJoseph Smith echoed Cowdery's statement in 1842, in a letter to a Chicago newspaper editor outlining the church's basic beliefs. Smith said that his religion \"believe[s] in the same organization that existed in the primitive church, viz: apostles, prophets, pastors, teachers, evangelists\".\nCommunity of Christ.\nIn the Community of Christ, which was formerly known as the Reorganized Church of Jesus Christ of Latter Day Saints (RLDS Church), an evangelist is an office in the Melchizedec Order of the priesthood.\nAn evangelist-patriarch's primary responsibility was to provide special blessings to members of the church; these blessings were considered one of the eight sacraments in the RLDS Church. The local evangelist-patriarchs of the church were governed by an individual with church-wide authority known as the Presiding Patriarch.\nIn 1984, when the first women began to be ordained to the office of evangelist-patriarch, the RLDS Church changed the title of the evangelist-patriarchs to simply \"evangelist\". Similarly, it changed the title of the Presiding Patriarch to the \"Presiding Evangelist\". To be an evangelist, a person must also be a high priest of the Melchizedec Order of the priesthood.\nThe primary duty of an evangelist in the Community of Christ remains the giving of sacramental \"evangelist's blessings\"; it is for this reason that evangelists are often referred to as \"ministers of blessing\". Ideally, an evangelist is free from administrative responsibilities in the church in order to allow them to be fully responsive to the Holy Spirit. The blessings\u2014which are given by the laying on of hands\u2014provide counsel and advice and confer spiritual blessings upon the recipient(s). Not only individuals, but also couples, families, households, groups and congregations may receive an evangelist's blessing. Any person, including nonmembers, eight years of age or older can receive a blessing, although the blessing is rarely offered for someone who has not reached adolescence. A recipient may receive multiple evangelist's blessings in their life. Evangelist's blessings may or may not be recorded. If it is recorded in written form, a copy is stored in the church archives at Independence, Missouri.\nAll evangelists belong to the Order of Evangelists, which is led by the Presiding Evangelist (currently Jane M. Gardner, since 2016).\nThe Church of Jesus Christ (Bickertonite).\nIn The Church of Jesus Christ (Bickertonite), the prescribed duties of an evangelist are to preach the gospel of Jesus Christ to every nation, kindred, language, and people. An evangelist is part of the Quorum of Seventy Evangelists.\nQuorum of Seventy Evangelists.\nThe Quorum of Seventy Evangelists is responsible for management of the International Missionary Programs of the church and assists Regions of the church with their individual Domestic Missionary Programs. The Quorum of Seventy oversees the activities of its Missionary Operating Committees to ensure the fulfilling of Christ's commandment to take the gospel to the entire world.\nIn 2007, the officers of the Quorum of Seventy Evangelists were:\nThe Church of Jesus Christ of Latter-day Saints.\nIn the Church of Jesus Christ of Latter-day Saints (LDS Church), an evangelist is considered to be an office of the Melchizedek priesthood. However, the term \"evangelist\" is rarely used for this position; instead, the church has retained the term \"patriarch\", the term most commonly used by Joseph Smith.\nThe most prominent reference to the term \"evangelist\" in the LDS Church's literature is found in its \"Articles of Faith\", derived from the Wentworth letter\u2014a statement by Smith in 1842 to a Chicago newspaper editor\u2014that the church believes in \"the same organization that existed in the primitive church\", including \"evangelists\". Smith taught that \"an Evangelist is an Patriarch\"."}
{"id": "9753", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=9753", "title": "Eukaryotic cell", "text": ""}
{"id": "9754", "revid": "1014179039", "url": "https://en.wikipedia.org/wiki?curid=9754", "title": "Elegiac couplets", "text": ""}
{"id": "9755", "revid": "34452882", "url": "https://en.wikipedia.org/wiki?curid=9755", "title": "Elegiac couplet", "text": "The elegiac couplet or elegaic distich is a poetic form used by Greek lyric poets for a variety of themes usually of smaller scale than the epic. Roman poets, particularly Catullus, Propertius, Tibullus, and Ovid, adopted the same form in Latin many years later. As with the English heroic couplet, each pair of lines usually makes sense on its own, while forming part of a larger work.\nEach couplet consists of a dactylic hexameter verse followed by a dactylic pentameter verse. The following is a graphic representation of its scansion:\n \u2013 uu | \u2013 uu | \u2013 uu | \u2013 uu | \u2013 uu | \u2013 x\n \u2013 uu | \u2013 uu | \u2013 || \u2013 uu | \u2013 uu | \u2013\n \u2013 is one long syllable, u one short syllable, uu is one long or two short syllables, and x is one long or one short syllable (anceps).\nThe form was felt by the ancients to contrast the rising action of the first verse with a falling quality in the second. The sentiment is summarized in a line from Ovid's \"Amores\" I.1.27 \u2014 \"Sex mihi surgat opus numeris, in quinque residat\" \u2014 \"Let my work rise in six steps, fall back in five.\" The effect is illustrated by Friedrich Schiller's couplet\ntranslated into English by Samuel Taylor Coleridge as:\nand by Alfred, Lord Tennyson, as:\nGreek origins.\nThe elegiac couplet is presumed to be the oldest Greek form of epodic poetry (a form where a later verse is sung in response or comment to a previous one). Scholars, who even in the past did not know who created it, theorize the form was originally used in Ionian dirges, with the name \"elegy\" derived from the Greek \"\u03b5, \u03bb\u03b5\u03b3\u03b5 \u03b5, \u03bb\u03b5\u03b3\u03b5\"\u2014\"Woe, cry woe, cry!\" Hence, the form was used initially for funeral songs, typically accompanied by an aulos, a double-reed wind instrument. Archilochus expanded use of the form to treat other themes, such as war, travel, and homespun philosophy. Between Archilochus and other imitators, the verse form became a common poetic vehicle for conveying any strong emotion.\nAt the end of the 7th century BCE, Mimnermus of Colophon struck on the innovation of using the verse for erotic poetry. He composed several elegies celebrating his love for the flute girl Nanno, and though fragmentary today, his poetry was clearly influential in the later Roman development of the form. Propertius, to cite one example, notes \u2014\"The verse of Mimnermus is stronger in love than Homer\".\nThe form continued to be popular throughout the Greek period and treated a number of different themes. Tyrtaeus composed elegies on a war theme, apparently for a Spartan audience. Theognis of Megara vented himself in couplets as an embittered aristocrat in a time of social change. Popular leaders were writers of elegies\u2014Solon the lawgiver of Athens composed on political and ethical subjects\u2014and even Plato and Aristotle dabbled with the meter.\nA famous example of an elegiac couplet is the epitaph composed by Simonides of Ceos which Herodotus says was inscribed on a stone to commemorate those who died at the battle of Thermopylae in 490 BC:\nCicero translates it as follows (\"Tusc. Disp.\" 1.42.101), also using an elegiac couplet: \nBy the Hellenistic period, the Library of Alexandria made elegy its favorite and most highly developed form. They preferred the briefer style associated with elegy in contrast to the lengthier epic forms, and made it the singular medium for short epigrams. The founder of this school was Philitas of Cos. He was eclipsed only by the school's most admired exponent, Callimachus; their learned character and intricate art would have a heavy influence on the Romans.\nRoman elegy.\nLike many Greek forms, elegy was adapted by the Romans for their own literature. The fragments of Ennius contain a few couplets, but it is the elegists of the mid-to-late first century BCE who are most commonly associated with the distinctive Roman form of the elegiac couplet. Catullus, the first of these, is an invaluable link between the Alexandrine school and the subsequent elegies of Tibullus, Propertius and Ovid. He shows a familiarity with the usual Alexandrine style of terse epigram and a wealth of mythological learning, as in his 66th poem, , a direct translation of Callimachus' \"Lock of Berenice\". His 85th poem is famous:\nTo read it correctly it is necessary to take account of the three elisions:\n \u2013 u u| \u2013 \u2013| \u2013 u u|\u2013 \u2013 | \u2013 u u| \u2013 x\n Od'et a|mo. Qua|r'id faci|am, for|tasse re|quiris?\n \u2013 uu | \u2013 uu| \u2013 || \u2013 u u | \u2013 u u|\u2013\n Nescio, | sed fie|ri || senti'et | excruci|or.\nCornelius Gallus, an important statesman of this period, was also regarded by the ancients as a great elegist, but, except for a few lines, his work has been lost.\nElegy in the Augustan Age.\nThe form reached its zenith with the collections of Tibullus and Propertius and several collections of Ovid (the \"Amores, Ars Amatoria, Heroides, Tristia\", and \"Epistulae ex Ponto\"). The vogue of elegy during this time is seen in the so-called 3rd and 4th books of Tibullus. Many poems in these books were clearly not written by Tibullus but by others, perhaps part of a circle under Tibullus' patron Messalla. Notable in this collection are the poems of Sulpicia, thought to be the only surviving work by a Classical Latin female poet. The six elegiac poems of Lygdamus in the collection are thought by some to be an anonymous early work by Ovid, though other scholars attribute them to an imitator of Ovid who may have lived in a much later period.\nThrough these poets\u2014and in comparison with the earlier Catullus\u2014it is possible to trace specific characteristics and evolutionary patterns in the Roman form of the verse:\nPost-Augustan writers.\nAlthough no classical poet wrote collections of love elegies after Ovid, the verse retained its popularity as a vehicle for popular occasional poetry. Elegiac verses appear, for example, in Petronius' \"Satyricon\", and Martial's Epigrams uses it for many witty stand-alone couplets and for longer pieces. The trend continues through the remainder of the empire; short elegies appear in Apuleius's story of Cupid and Psyche and in the minor writings of Ausonius.\nMedieval elegy.\nAfter the fall of the empire, one writer who produced elegiac verse was Maximianus. Various Christian writers also adopted the form; Venantius Fortunatus wrote some of his hymns in the meter, while later Alcuin and the Venerable Bede dabbled in the verse. The form also remained popular among the educated classes for gravestone epitaphs; many such epitaphs can be found in European cathedrals.\n\"De tribus puellis\" is an example of a Latin \"fabliau\", a genre of comedy which employed elegiac couplets in imitation of Ovid. The medieval theorist John of Garland wrote that \"all comedy is elegy, but the reverse is not true.\" Medieval Latin had a developed comedic genre known as elegiac comedy. Sometimes narrative, sometimes dramatic, it deviated from ancient practice because, as Ian Thompson writes, \"no ancient drama would ever have been written in elegiacs.\"\nRenaissance and modern period.\nWith the Renaissance, more skilled writers interested in the revival of Roman culture attempted to recapture the spirit of the Augustan writers. The Dutch Latinist Johannes Secundus, for example, included Catullus-inspired love elegies in his \"Liber Basiorum\", while the English poet John Milton wrote several lengthy elegies throughout his career. This trend continued down through the Recent Latin writers, whose close study of their Augustan counterparts reflects their general attempts to apply the cultural and literary forms of the ancient world to contemporary themes."}
{"id": "9756", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=9756", "title": "Exabyte", "text": ""}
{"id": "9757", "revid": "10044298", "url": "https://en.wikipedia.org/wiki?curid=9757", "title": "Eon (geology)", "text": ""}
{"id": "9758", "revid": "48931982", "url": "https://en.wikipedia.org/wiki?curid=9758", "title": "Era", "text": "An era is a span of time defined for the purposes of chronology or historiography, as in the regnal eras in the history of a given monarchy, a calendar era used for a given calendar, or the geological eras defined for the history of Earth.\nComparable terms are Epoch, age, period, saeculum, aeon (Greek \"aion\") and Sanskrit yuga.\nEtymology.\nThe word has been in use in English since 1615, and is derived from Late Latin \"aera\" \"an era or epoch from which time is reckoned,\" probably identical to Latin \"\u00e6ra\" \"counters used for calculation,\" plural of \"\u00e6s\" \"brass, money\".\nThe Latin word use in chronology seems to have begun in 5th century Visigothic Spain, where it appears in the \"History\" of Isidore of Seville, and in later texts. The Spanish era is calculated from 38 BC, Before Christ, perhaps because of a tax (cfr. indiction) levied in that year, or due to a miscalculation of the Battle of Actium, which occurred in 31 BC.\nLike epoch, \"era\" in English originally meant \"the starting point of an age\"; the meaning \"system of chronological notation\" is c. 1646; that of \"historical period\" is 1741.\nUse in chronology.\nIn chronology, an \"era\" is the highest level for the organization of the measurement of time. A \"calendar era\" indicates a span of many years which are numbered beginning at a specific reference date (epoch), which often marks the origin of a political state or cosmology, dynasty, ruler, the birth of a leader, or another significant historical or mythological event; it is generally called after its focus accordingly as in \"Victorian era\".\nGeological era.\nIn large-scale natural science, there is need for another time perspective, independent from human activity, and indeed spanning a far longer period (mainly prehistoric), where \"geologic era\" refers to well-defined time spans.\nThe next-larger division of geologic time is the eon. The Phanerozoic Eon, for example, is subdivided into eras. There are currently three eras defined in the Phanerozoic; the following table lists them from youngest to oldest (BP is an abbreviation for \"before present\").\nThe older Proterozoic and Archean eons are also divided into eras.\nCosmological era.\nFor periods in the history of the universe, the term \"epoch\" is typically preferred, but \"era\" is used e.g. of the \"Stelliferous Era\".\nCalendar eras.\nCalendar eras count the years since a particular date (epoch), often one with religious significance. \"Anno mundi\" (year of the world) refers to a group of calendar eras based on a calculation of the age of the world, assuming it was created as described in the Book of Genesis. In Jewish religious contexts one of the versions is still used, and many Eastern Orthodox religious calendars used another version until 1728. Hebrew year 5772 AM began at sunset on 28 September 2011 and ended on 16 September 2012. In the Western church, \"Anno Domini\" (\"AD\" also written \"CE\"), counting the years since the birth of Jesus on traditional calculations, was always dominant.\nThe Islamic calendar, which also has variants, counts years from the Hijra or emigration of the Islamic prophet Muhammad from Mecca to Medina, which occurred in 622 AD. The Islamic year is some days shorter than 365; January 2012 fell in 1433 AH (\"After Hijra\").\nFor a time ranging from 1872 to the Second World War, the Japanese used the imperial year system (\"k\u014dki\"), counting from the year when the legendary Emperor Jimmu founded Japan, which occurred in 660 BC.\nMany Buddhist calendars count from the death of the Buddha, which according to the most commonly used calculations was in 545\u2013543 BCE or 483 BCE. Dates are given as \"BE\" for \"Buddhist Era\"; 2000 AD was 2543 BE in the Thai solar calendar.\nOther calendar eras of the past counted from political events, such as the Seleucid era and the Ancient Roman \"ab urbe condita\" (\"AUC\"), counting from the foundation of the city.\nRegnal eras.\nThe word era also denotes the units used under a different, more arbitrary system where time is not represented as an endless continuum with a single reference year, but each unit starts counting from one again as if time starts again. The use of regnal years is a rather impractical system, and a challenge for historians if a single piece of the historical chronology is missing, and often reflects the preponderance in public life of an absolute ruler in many ancient cultures. Such traditions sometimes outlive the political power of the throne, and may even be based on mythological events or rulers who may not have existed (for example Rome numbering from the rule of Romulus and Remus). In a manner of speaking the use of the supposed date of the birth of Christ as a base year is a form of an era.\nIn East Asia, each emperor's reign may be subdivided into several reign periods, each being treated as a new era. The name of each was a motto or slogan chosen by the emperor. Different East Asian countries utilized slightly different systems, notably:\nA similar practice survived in the United Kingdom until quite recently, but only for formal official writings: in daily life the ordinary year A.D. has been used for a long time, but Acts of Parliament were dated according to the years of the reign of the current monarch, so that \"61 &amp; 62 Vict c. 37\" refers to the Local Government (Ireland) Act 1898 passed in the session of Parliament in the 61st/62nd year of the reign of Queen Victoria.\nHistoriography.\n\"Era\" can be used to refer to well-defined periods in historiography, such as the Roman era, Elizabethan era, Victorian era, etc.\nUse of the term for more recent periods or topical history might include Soviet era, and \"musical eras\" in the history of modern popular music, such as the \"big band era\", \"disco era\", etc."}
{"id": "9760", "revid": "15534247", "url": "https://en.wikipedia.org/wiki?curid=9760", "title": "Eschatology", "text": "Eschatology (; ) concerns expectations of the end of present age, human history, or the world itself. The end of the world or end times is predicted by several world religions (both Abrahamic and non-Abrahamic), which teach that negative world events will reach a climax. Belief that the end of the world is imminent is known as apocalypticism, and over time has been held both by members of mainstream religions and by doomsday cults. In the context of mysticism, the term refers metaphorically to the end of ordinary reality and to reunion with the divine. Many religions treat eschatology as a future event prophesied in sacred texts or in folklore, while other religions may have concepts of renewal or transformation after significant events. The explicit description of a new earth is primarily found in Christian teachings (this description can be found in Chapter 21 of the Book of Revelation).\nThe Abrahamic religions maintain a linear cosmology, with end-time scenarios containing themes of transformation and redemption. In Judaism, the term \"end of days\" makes reference to the Messianic Age and includes an in-gathering of the exiled Jewish diaspora, the coming of the Messiah, the resurrection of the righteous, and the world to come. Christianity depicts the end time as a period of tribulation that precedes the second coming of Christ, who will face the rise of the Antichrist along with his power structure and false prophets, and usher in the Kingdom of God. In later traditions of Islam, separate hadiths detail the Day of Judgment is preceded by the appearance of the Mas\u012b\u1e25 ad-Dajj\u0101l, and followed by the descending of \u02bf\u012as\u0101 (Jesus), which shall triumph over the false Messiah or Antichrist; his defeat will lead to a sequence of events that will end with the sun rising from the west and the beginning of the Qiy\u0101mah (Judgment Day).\nDharmic religions tend to have more cyclical worldviews, with end-time eschatologies characterized by decay, redemption, and rebirth (though some believe transitions between cycles are relatively uneventful). In Hinduism, the end time occurs when Kalki, the final incarnation of Vishnu, descends atop a white horse and brings an end to the current \"Kali Yuga\", completing a cycle that starts again with the regeneration of the world. In Buddhism, the Buddha predicted his teachings would be forgotten after 5,000 years, followed by turmoil. It says a \"bodhisattva\" named Maitreya will appear and rediscover the teachings of the \"Buddha Dharma\", and that the ultimate destruction of the world will then come through seven suns.\nSince the development of the concept of deep time in the 18th century and the calculation of the estimated age of planet Earth, scientific discourse about end times has considered the ultimate fate of the universe. Theories have included the Big Rip, Big Crunch, Big Bounce, and Big Freeze (heat death). Social and scientific commentators also worry about global catastrophic risks and scenarios that could result in human extinction.\nEtymology.\nThe word \"eschatology\" arises from the Ancient Greek term (\"\u00e9schatos\"), meaning \"last\", and \"-logy\", meaning \"the study of\", and first appeared in English around 1844. The \"Oxford English Dictionary\" defines eschatology as \"the part of theology concerned with death, judgment, and the final destiny of the soul and of humankind\".\nLinear cosmology.\nJudaism.\nThe main tenets of modern Jewish eschatology, in no particular order, include:\nJudaism usually refers to the end times as the \"end of days\" (\"a\u1e25arit ha-yamim\", \u05d0\u05d7\u05e8\u05d9\u05ea \u05d4\u05d9\u05de\u05d9\u05dd), a phrase that appears several times in the Tanakh. The end times are addressed in the Book of Daniel and in numerous other prophetic passages in the Hebrew scriptures, and also in the Talmud, particularly Tractate Avodah Zarah.\nThe idea of a Messianic Age, an era of global peace and knowledge of the Creator, has a prominent place in Jewish thought, and is incorporated as part of the end of days. A well-known passage from the Book of Isaiah describes this future condition of the world: \"They shall beat their swords into plowshares and their spears into pruning hooks; nation will not lift sword against nation and they will no longer study warfare\" (Isaiah 2:4, see also Micah 4:3). Maimonides (1135\u20131204) further describes the Messianic Era in the Mishneh Torah: \"And at that time there will be no hunger or war, no jealousy or rivalry. For the good will be plentiful, and all delicacies available as dust. The entire occupation of the world will be only to know God;... the people Israel will be of great wisdom; they will perceive the esoteric truths and comprehend their Creator's wisdom as is the capacity of man. As it is written (Isaiah 11:9): 'For the earth shall be filled with the knowledge of God, as the waters cover the sea.'\"\nKabbalah.\nIn Kabbalah, the Zohar maintains that the seven days of the week, based on the seven days of creation, correspond to the seven millennia of creation. The seventh day of the week, the Shabbat day of rest, corresponds to the seventh millennium, the age of universal rest, or the Messianic Era. The seventh millennium begins with the year 6000 AM, and is the latest time the Messiah can come. A number of early and late Jewish scholars have written in support of this, including the Ramban, Isaac Abarbanel, Abraham Ibn Ezra, Rabbeinu Bachya, the Vilna Gaon, the Lubavitcher Rebbe, the Ramchal, Aryeh Kaplan and Rebbetzin Esther Jungreis.\nZoroastrianism.\nFrashokereti is the Zoroastrian doctrine of a final renovation of the universe when evil will be destroyed, and everything else will then be in perfect unity with God (Ahura Mazda). The doctrinal premises are:\nZoroastrian eschatology is considered one of the oldest in recorded history. The birth of its founder, Zoroaster, is unknown, with scholarly dates ranging from 500 BCE to 1,500 BCE. Pliny the Elder even suggests there were two Zoroasters. However, with beliefs paralleling and possibly predating the framework of the major Abrahamic faiths, a fully developed concept of the end of the world was not established in Zoroastrianism until 500 BCE. The Bahman Yasht describes:\nAt the end of thy tenth hundredth winter, the sun is more unseen and more spotted; the year, month, and day are shorter; and the earth is more barren; and the crop will not yield the seed. And men become more deceitful and more given to vile practices. They will have no gratitude. Honorable wealth will proceed to those of perverted faith. And a dark cloud makes the whole sky night, and it will rain more noxious creatures than water.\nA battle between the righteous and wicked will be followed by the Frashokereti. On earth, the Saoshyant will arrive as the final savior of mankind, and bring about the resurrection of the dead. The \"yazata\"s Airyaman and Atar will melt the metal in the hills and mountains, which will flow as lava across the earth and all mankind, both the living and resurrected, will be required to wade through it. \"Ashavan\" will pass through the molten river as if it were warm milk, but the sinful will burn. It will then flow down to hell, where it will annihilate Angra Mainyu and the last vestiges of wickedness.\nThe righteous will partake of the \"parahaoma\", which will confer immortality upon them. Humanity will become like the Amesha Spentas, living without food, hunger, thirst, weapons or injury. Bodies will become so light as to cast no shadow. All humanity will speak a single language, and belong to a single nation with no borders. All will share a single purpose and goal, joining with Ahura Mazda for a perpetual and divine exaltation.\nGnosticism.\nThe Gnostic codex On the Origin of the World (possibly dating from near the end of the third century AD) states that during what is called the consummation of the age, the Sun and Moon will become dark as the stars change their ordinary course. Kings will make war with each other, and thunder will cause the world to be shaken. The corrupt Archons will mourn. The sea will be troubled by fighting of the kings who became drunk from the flaming sword. Finally, great thunder will come from Sophia, the woman in the firmament above the forces of Chaos. She will cast the corrupt gods into the abyss where they will fight each other until only their chief Yaldabaoth remains and destroys himself. Next the heavens of the Archons will collapse on each other before the Earth sinks into the abyss. Light will cover the darkness and eliminate it then form into something greater than anything that ever existed before. The source of the darkness will dissolve, and the deficiency will be taken from its root. Those who were not perfected in the unconceived one will receive glories in their realms and kingdoms of the immortals, but those who were will enter a kingless realm. All will be judged according to their deeds and gnosis.\nChristianity.\nChristian eschatology is the study concerned with the ultimate destiny of the individual soul and of the entire created order, based primarily upon biblical texts within the Old and New Testaments.\nChristian eschatological research looks to study and discuss matters such as the nature of the divine and the divine nature of Jesus Christ, death and the afterlife, Heaven and Hell, the Second Coming of Jesus, the resurrection of the dead, the rapture, the Tribulation, millennialism, the end of the world, the Last Judgment, and the New Heaven and New Earth in the world to come.\nEschatological passages occur in many places in the Bible, in both the Old and the New Testaments. In the Old Testament, apocalyptic eschatology can be found notably in Isaiah 24\u201327, Isaiah 56\u201366, Joel, Zechariah 9\u201314 as well as in the closing chapters of Daniel, and in Ezekiel. In the New Testament, applicable passages include Matthew 24, Mark 13, the parable of \"The Sheep and the Goats\" and the Book of Revelation\u2014Revelation often occupies a central place in Christian eschatology.\nThe Second Coming of Christ is the central event in Christian eschatology within the broader context of the fullness of the Kingdom of God. Most Christians believe that death and suffering will continue to exist until Christ's return. There are, however, various views concerning the order and significance of other eschatological events.\nThe Book of Revelation stands at the core of much of Christian eschatology. The study of Revelation is usually divided into four interpretative methodologies or hermeneutics:\nDate.\nFirst-century Christians believed Jesus would return during their lifetime. When the converts of Paul in Thessalonica were persecuted by the Roman Empire, they believed the end of days to be imminent. Most of the scholars participating in the third quest hold that Jesus was an eschatological prophet who believed the \"Kingdom of God\" was coming within his own lifetime or within the lifetime of his contemporaries. This view, generally known as \"consistent eschatology,\" was influential during the early to the mid\u2014twentieth century and continues to be influential today in proposed portraits of the Historical Jesus. However, C. H. Dodd and others have insisted on a \"realized eschatology\" that says Jesus' own ministry fulfilled prophetic hopes. Many conservative scholars have adopted the paradoxical position the Kingdom of God passages describes a kingdom that is both \"present\" and \"still to come\" claiming Pauline eschatology as support. R. T. France and N. T. Wright among others have taken Jesus' apocalyptic statements of an imminent end, historically, as referring to the fall of Jerusalem and the destruction of the Temple in 70 AD. A number of interpretations of the term \"Kingdom of God\" have thus appeared in its eschatological context, e.g., apocalyptic, realized or Inaugurated eschatologies, yet no consensus has emerged among scholars.\nWhile some who believe in the literal interpretation of the Bible insist the prediction of dates or times is futile, others believe Jesus foretold signs of the end of days. The precise time, however, will come like a \"thief in the night\" (). They may also refer to in which Jesus is quoted as saying:\nGreat Tribulation.\nIn the New Testament, Jesus refers to this period preceding the end times as the \"Great Tribulation\" (), \"Affliction\" (), and \"days of vengeance\" ().\nThe Book of Matthew describes the devastation:\nThe resulting chaos will affect pregnancies, newborns, and a scourge will spread throughout the flesh, save for the elect. The vivid imagery of this section is repeated closely in .\nThe Gospel of Luke describes a complete unraveling of the social fabric, with widespread calamity and war:\nIn the Book of Revelation, the \"great tribulation\" (Rev. 7:14b) refers to a time of affliction upon God's people.\nCatholicism.\nThe Profession of Faith addresses Catholic beliefs concerning the last days. Catholicism adheres to the amillennial school of thought, promoted by Augustine of Hippo in his work \"The City of God\".\nProtestantism.\nContemporary use of the term \"End Times\" has evolved from literal belief in Christian millennialism. In this tradition, Biblical apocalypse is believed to be imminent, with various current events as omens of impending Armageddon. These beliefs have been put forward by the Adventist movement (Millerites) and dispensational premillennialists. In 1918 a group of eight, well-known preachers produced the London Manifesto, warning of an imminent second coming of Christ shortly after the 1917 liberation of Jerusalem by the British.\nMillennialists and Amillennialists.\nProtestants are divided between Millennialists and Amillennialists. Millennialists concentrate on the issue of whether the true believers will see the Great Tribulation or be removed from it by what is referred to as a Pre-Tribulation rapture.\nAmillennialists believe the end times encompass the time from Christ's ascension to the last day, and maintain that the mention of the \"thousand years\" in the Book of Revelation is meant to be taken metaphorically (i.e., not literally), a view which continues to cause divisions within Protestant Christianity.\nThere is a range of eschatological belief in Protestant Christianity. Christian premillennialists who believe the end times are occurring now, are usually specific about timelines that climax in the end of the world. For some, Israel, the European Union, or the United Nations are seen as major players whose roles were foretold in scripture. Within dispensational premillennialist writing, there is the belief that Christians will be summoned to Heaven by Christ at the rapture, occurring before a Great Tribulation prophesied in Matthew 24\u201325; Mark 13 and Luke 21. The Tribulation is described in the Book of Revelation.\n\"End times\" may also refer to the passing of an age or long period in the relationship between man and God. Adherents to this view cite the Second Epistle to Timothy and draw analogies to the late twentieth and early twenty-first centuries.\nPost-Exilic Hebrew books of prophecy such as Daniel and Ezekiel are given new interpretations in this Christian tradition, while apocalyptic forecasts appear in the Judeo-Christian Sibylline Oracles which include the Book of Revelation ascribed to John, the apocryphal Apocalypse of Peter, and the Second Book of Esdras.\nAdventists and Millerites.\nReligious movements which expect that the second coming of Christ will be a cataclysmic event are generally called adventism. These have arisen throughout the Christian era, but were particularly common after the Protestant Reformation. Emanuel Swedenborg considered the second coming to be symbolic, and to have occurred in 1757. Along with others, he developed a religious system around the second coming of Christ, disclosed by new prophecy or special revelation not described in the Bible. The Millerites are diverse religious groups which similarly rely upon a special gift of interpretation for predicting the second coming.\nThe difference between the 19th-century Millerite and adventist movements and contemporary prophecy is that William Miller and his followers, based on biblical interpretation, predicted the time of the Second Coming to have occurred in 1844. Contemporary writing of end time has suggested the timetable will be triggered by future wars and moral catastrophe, and that this time of tribulation is close at hand.\nSeventh-day Adventists believe biblical prophecy to foretell an end time scenario in which the United States works in conjunction with the Catholic Church to mandate worship on a day other than the true Sabbath, Saturday, as prescribed in the Ten Commandments (Exodus 20:8\u201311). This will bring about a situation where one must choose for or against the Bible as the will of God.\nPreterists.\nAnother view of the \"end times\" is preterism. It distinguishes \"the time of the end\" from \"the end of time\". Preterists believe the term \"last days\" (or \"Time of the End\") refers to, neither the last days of the Earth, nor the last days of humankind, but the end of the Old Covenant between God and Israel; which, according to preterism, took place when the Temple in Jerusalem was destroyed in 70 CE.\nPreterists believe that prophecies\u2014such as the Second Coming, the desecration of the Jewish Temple, the destruction of Jerusalem, the rise of the Antichrist, the Great Tribulation, the advent of The Day of the Lord, and a Final Judgment\u2014had been fulfilled when the Romans sacked Jerusalem and completely destroyed its Temple.\nProponents of \"full preterism\" do not believe in a coming resurrection of the dead. They place this event (as well as the Second Coming) in the year 70. Advocates of partial preterism do believe in a coming resurrection. Full preterists contend that partial preterists are merely \"futurists\", since they believe the Second Coming, the Resurrection, the Rapture, and the Judgment are yet to come.\nMany preterists believe first-century Christians experienced the Rapture to rejoin the Christ.\nAccording with Preterism's interpretation of end times, many \"time passages\" in the New Testament foretell a Second Coming of Christ, with last days to take place within the lifetimes of his disciples: Matt. 10:23, Matt. 16:28, Matt. 24:34, Matt. 26:64, Rom. 13:11\u201312, 1 Cor. 7:29\u201331, 1 Cor. 10:11, Phil. 4:5, James 5:8\u20139, 1 Pet. 4:7, 1 Jn. 2:18.\nDispensationalists.\nDispensationalism is an evangelical futurist Biblical interpretation that foresees a series of dispensations, or periods, in which God relates to human beings under different Biblical covenants. The belief system is primarily rooted in the writings of John Nelson Darby and is premillennial in content. The reestablishment of Israel in 1948 provided a major impetus to the dispensationalist belief system. The wars of Israel after 1948 with its Arab neighbors provided further support, according to John F. Walvoord. After the Six-Day War in 1967, and the Yom Kippur War in 1973, it seemed plausible to many Fundamentalist Christians in the 1970s that Middle East turmoil may well be leading up to the fulfillment of various Bible prophecies and to the Battle of Armageddon.\nMembers of the dispensationalist movement such as Hal Lindsey, J. Dwight Pentecost, John Walvoord, all of whom have Dallas Theological Seminary backgrounds, and some other writers, claimed further that the European Economic Community, which preceded the European Union, would become a United States of Europe, which would in turn become a Revived Roman Empire ruled by the Antichrist. The Revived Roman Empire also figured into the New Testament writers' vision of the future. The fact that in the early 1970s, there were (erroneously thought to be) seven nations in the European Economic Community was held to be significant; this aligned the Community with a seven-headed beast mentioned in Revelation. This specific prophecy has required revision, but the idea of a Revived Roman Empire remains.\nDispensationalism, in contrast to the Millerite Adventist movement, had its beginning in the 19th century, when John Nelson Darby, founder of the Plymouth Brethren religious denomination, incorporated into his system of Biblical interpretation a system of organizing Biblical time into a number of discrete dispensations, each of which marks a separate covenant with God. Darby's beliefs were widely publicized in Cyrus I. Scofield's \"Scofield Reference Bible\", an annotated Bible that became popular in the United States.\nSince the majority of the Biblical prophets were writing at a time when the Temple in Jerusalem was still functioning, they wrote as if it would still be standing during the prophesied events. According to preterism, this was a fulfillment of the prophecies. However, according to Futurists, their destruction in AD 70 put the prophetic timetable on hold. Many such believers therefore anticipated the return of Jews to Israel and the reconstruction of the Temple before the Second Coming could occur.\nPosttribulation premillennialism.\nA view of the Second Coming of Christ as held by posttribulational premillennialists holds that the Church of Christ will have to undergo great persecution by being present during the great tribulation.\nSpecific prophetic movements.\nIn 1843, William Miller made the first of several predictions that the world would end in only a few months. As his predictions did not come true (referred to as the Great Disappointment), followers of Miller went on to found separate groups, the most successful of which is the Seventh-day Adventist Church.\nMembers of the Bah\u00e1\u02bc\u00ed Faith believe Miller's interpretation of signs and dates of the coming of Jesus were, for the most part, correct. They believe the fulfillment of biblical prophecies of the coming of Christ came through a forerunner of their own religion, the B\u00e1b. According to the B\u00e1b's words, 4 April 1844 was \"the first day that the Spirit descended\" into his heart. His subsequent declaration to Mull\u00e1 Husayn-i Bushru'i that he was the \"Promised One\"\u2014an event now commemorated by Bah\u00e1\u02bc\u00eds as a major holy day\u2014took place on 23 May 1844. It was in October of that year that the B\u00e1b embarked on a pilgrimage to Mecca, where he openly declared his claims to the Sharif of Mecca. The first news coverage of these events in the West was in 1845 by \"The Times\", followed by others in 1850 in the United States. The first Bah\u00e1\u02bc\u00ed to come to America was in 1892. Several Bah\u00e1\u02bc\u00ed books and pamphlets make mention of the Millerites, the prophecies used by Miller and the Great Disappointment, most notably William Sears's \"Thief in the Night\".\nRestorationism (Christian primitivism).\nEnd times theology is also significant to restorationist Christian religions, which consider themselves distinct from both Catholicism and Protestantism.\nJehovah's Witnesses.\nThe eschatology of Jehovah's Witnesses is central to their religious beliefs. They believe Jesus Christ has been ruling in heaven as king since 1914 (a date they believe was prophesied in the Bible) and that after that time a period of cleansing occurred, resulting in God's selection of the Bible Students associated with Charles Taze Russell as his people in 1919. They also believe that the destruction of those who reject the Bible's message and thus willfully refuse to obey God will shortly take place at Armageddon, ensuring that the beginning of the new earthly society will be composed of willing subjects of that kingdom.\nThe religion's doctrines surrounding 1914 are the legacy of a series of emphatic claims regarding the years 1799, 1874, 1878, 1914, 1918 and 1925 made in the Watch Tower Society's publications between 1879 and 1924. Claims about the significance of those years, including the presence of Jesus Christ, the beginning of the \"last days\", the destruction of worldly governments and the earthly resurrection of Jewish patriarchs, were successively abandoned. In 1922 the society's principal magazine, \"The Watchtower\", described its chronology as \"no stronger than its weakest link\", but also claimed the chronological relationships to be \"of divine origin and divinely corroborated... in a class by itself, absolutely and unqualifiedly correct\" and \"indisputable facts\", and repudiation of Russell's teachings was described as \"equivalent to a repudiation of the Lord\".\nThe Watch Tower Society has acknowledged its early leaders promoted \"incomplete, even inaccurate concepts\". The Governing Body of Jehovah's Witnesses says that, unlike Old Testament prophets, its interpretations of the Bible are not inspired or infallible. It says that Bible prophecies can be fully understood only after their fulfillment, citing examples of biblical figures who did not understand the meaning of prophecies they received. Watch Tower Society literature often cites Proverbs 4:18, \"The path of the righteous ones is like the bright light that is getting lighter and lighter until the day is firmly established\" (NWT) to support their view that there would be an increase in knowledge during \"the time of the end\", and that this increase in knowledge needs adjustments. Watch Tower Society publications also say that unfulfilled expectations are partly due to eagerness for God's Kingdom and that they do not call their core beliefs into question.\nThe Church of Jesus Christ of Latter-day Saints.\nMembers of the Church of Jesus Christ of Latter-day Saints (LDS Church) believe there will be a Second Coming of Jesus to the earth at some time in the future. The LDS Church and its leaders do not make any predictions of the date of the Second Coming.\nAccording to church doctrine, the true gospel will be taught in all parts of the world prior to the Second Coming. They also believe there will be increasing war, earthquakes, hurricanes, and man-made disasters prior to the Second Coming. Disasters of all kind will happen before Christ comes. Upon the return of Jesus Christ, all people will be resurrected, the righteous in a first resurrection and the unrighteous in a second, later resurrection. Christ shall reign for a period of 1000 years, after which the Final Judgment will occur.\nRealized eschatology.\nRealized eschatology is a Christian eschatological theory that holds that the eschatological passages in the New Testament do not refer to the future, but instead refer to the ministry of Jesus and his lasting legacy.\nIslam.\nMuslims believe there are three periods before the Day of Judgment with some debate as to whether the periods could overlap.\nSunni.\nSunnis believe the dead will then stand in a grand assembly, awaiting a scroll detailing their righteous deeds, sinful acts and ultimate judgment. Muhammad will be the first to be resurrected. Punishments will include \"adhab\", or severe pain and embarrassment, and \"khizy\" or shame. There will also be a punishment of the grave between death and the resurrection. Several Sunni scholars explain some of the signs metaphorically.\nThe signs of the coming end time are divided into major and minor signs:\nFollowing the second period, the third is said to be marked by the ten major signs known as \"alamatu's-sa'ah al- kubra\" (The major signs of the end). They are as follows:\nShia.\nMany of the signs shown above are shared by both Sunni and Shia beliefs, with some exceptions, e.g. Imam Al-Mahdi defeating Al-Masih ad-Dajjal.\nConcepts and terminology in Shia eschatology include Mi'ad, the Occultation, Al-Yamani, and Sufyani. In Twelver Shia narrations about the last days, the literature largely revolves around Muhammad al-Mahdi, who is considered by many beliefs to be the true twelfth appointed successor to Muhammad. Muhammad al-Mahdi will help mankind against the deception by the \"Dajjal\" who will try to get people in to a new world religion which is called \"the great deception\".\nAhmadiyya.\nAhmadiyya is considered distinct from mainstream Islam. In its writing, the present age has been witness to the evil of man and wrath of God, with war and natural disaster. Ghulam Ahmad is seen as the promised Messiah and the Mahdi, fulfilling Islamic and Biblical prophecies, as well as scriptures of other religions such as Hinduism. His teaching will establish spiritual reform and establish an age of peace. This will continue for a thousand years, and will unify mankind under one faith.\nAhmadis believe that despite harsh and strong opposition and discrimination they will eventually be triumphant and their message vindicated both by Muslims and non-Muslims alike. Ahmadis also incorporate the eschatological views from other religions into their doctrine and believe Mirza Ghulam Ahmed falls into this sequence.\nBah\u00e1\u02bc\u00ed Faith.\nIn the Bah\u00e1\u02bc\u00ed Faith, creation has neither a beginning nor an end; Bah\u00e1\u02bc\u00eds regard the eschatologies of other religions as symbolic. In Bah\u00e1\u02bc\u00ed belief, human time is marked by a series of progressive revelations in which successive messengers or prophets come from God. The coming of each of these messengers is seen as the day of judgment to the adherents of the previous religion, who may choose to accept the new messenger and enter the \"heaven\" of belief, or denounce the new messenger and enter the \"hell\" of denial. In this view, the terms \"heaven\" and \"hell\" become symbolic terms for a person's spiritual progress and their nearness to or distance from God. In Bah\u00e1\u02bc\u00ed belief, Bah\u00e1'u'll\u00e1h (1817\u20131892), the founder of the Bah\u00e1\u02bc\u00ed Faith, was the Second Coming of Christ and also the fulfilment of previous eschatological expectations of Islam and other major religions.\nThe inception of the Bah\u00e1\u02bc\u00ed Faith coincides with Great Disappointment of the Millerite prophecy in 1844.\n\u02bbAbdu'l-Bah\u00e1 taught that Armageddon would begin in 1914, but without a clear indication of its end date. Bah\u00e1\u02bc\u00eds believe that the mass martyrdom anticipated during the \"End Times\" had already passed within the historical context of the Bah\u00e1\u02bc\u00ed Faith. Bah\u00e1\u02bc\u00eds expect their faith to be eventually embraced by the masses of the world, ushering in a golden age.\nRastafari.\nRastafari have a unique interpretation of end times, based on the Old Testament and the Book of Revelation. They believe Ethiopian Emperor Haile Selassie I to be God incarnate, the \"King of kings\" and \"Lord of lords\" mentioned in Revelation 5:5. They saw the crowning of Selassie as the second coming, and the Second Italo-Ethiopian War as fulfillment of Revelation. There is also the expectation that Selassie will return for a day of judgment and bring home the \"lost children of Israel\", which in Rastafari refers to those taken from Africa through the slave trade. There will then be an era of peace and harmony at Mount Zion in Africa.\nCyclic cosmology.\nHinduism.\nThe Vaishnavite tradition links contemporary Hindu eschatology to the figure of Kalki, the tenth and last avatar of Vishnu. Many Hindus believe that before the age draws to a close, Kalki will reincarnate as Shiva and simultaneously dissolve and regenerate the universe. Shaivites hold the view that Shiva is incessantly destroying and creating the world.\nIn Hindu eschatology, time is cyclic and consists of kalpas. Each lasts 4.1\u20138.2 billion years, which is a period of one full day and night for Brahma, who will be alive for 311 trillion, 40 billion years. Within a \"kalpa\" there are periods of creation, preservation and decline. After this larger cycle, all of creation will contract to a singularity and then again will expand from that single point, as the ages continue in a religious fractal pattern.\nWithin the current kalpa, there are four epochs that encompass the cycle. They progress from a beginning of complete purity to a descent into total corruption. The last of the four ages is Kali Yuga (which most Hindus believe is the current time), characterized by quarrel, hypocrisy, impiety, violence and decay. The four pillars of dharma will be reduced to one, with truth being all that remains. As written in the Gita:\n&lt;poem&gt;\"Yad\u0101 yad\u0101 hi dharmasya gl\u0101nirbhavati Bh\u0101rata\"\n\"Abhyutth\u0101nam adharmasya tad\u0101tm\u0101nam s\u1e5bj\u0101myaham\"\nO descendant of Bharata, whenever there is a decline of religion and an increase in irreligion, at that time I manifest My eternally perfect form in this mundane world.&lt;/poem&gt;\nAt this time of chaos, the final avatar, Kalki, endowed with eight superhuman faculties will appear on a white horse. Kalki will amass an army to \"establish righteousness upon the earth\" and leave \"the minds of the people as pure as crystal.\"\nAt the completion of Kali Yuga, the next Yuga Cycle will begin with a new Satya Yuga, in which all will once again be righteous with the reestablishment of dharma. This, in turn, will be followed by epochs of Treta Yuga, Dvapara Yuga and again another Kali Yuga. This cycle will then repeat until the larger cycle of existence under Brahma returns to the singularity, and a new universe is born.\nThe cycle of birth, growth, decay, and renewal at the individual level finds its echo in the cosmic order, yet is affected by vagueries of divine intervention in Vaishnavite belief.\nBuddhism.\nThere is no classic account of beginning or end\nin Buddhism; Masao Abe attributes this to the absence of God.\nHistory is embedded in the continuing process of samsara or the \"beginningless and endless cycles of birth-death-rebirth\". Buddhists believe there is an end to things but it is not final because they are bound to be born again. However, the writers of Mahayana Buddhist scriptures establish a specific end-time account in Buddhist tradition: this describes the return of Maitreya Buddha, who would bring about an end to the world. This constitutes one of the two major branches of Buddhist eschatology, with the other being the Sermon of the Seven Suns. End time in Buddhism could also involve a cultural eschatology covering \"final things\", which include the idea that Sakyamuni Buddha's dharma will also come to an end.\nMaitreya.\nThe Buddha described his teachings disappearing five thousand years from when he preached them, corresponding approximately to the year 4300 since he was born in 623 BCE. At this time, knowledge of dharma will be lost as well. The last of his relics will be gathered in Bodh Gaya and cremated. There will be a new era in which the next Buddha Maitreya will appear, but it will be preceded by the degeneration of human society. This will be a period of greed, lust, poverty, ill will, violence, murder, impiety, physical weakness, sexual depravity and societal collapse, and even the Buddha himself will be forgotten.\nThis will be followed by the coming of Maitreya when the teachings of dharma are forgotten. Maitreya was the first Bodhisattva around whom a cult developed, in approximately the third century CE.\nThe earliest known mention of Maitreya occurs in the Cakkavatti, or Sihanada Sutta in Digha Nikaya 26 of the Pali Canon. In it, Gautama Buddha predicted his teachings of dharma would be forgotten after 5,000 years.\nThe text then foretells the birth of Maitreya Buddha in the city of Ketumat\u012b in present-day Benares, whose king will be the Cakkavatt\u012b Sankha. Sankha will live in the former palace of King Mah\u0101panad\u0101, and will become a renunciate who follows Maitreya.\nIn Mahayana Buddhism, Maitreya will attain \"bodhi\" in seven days, the minimum period, by virtue of his many lifetimes of preparation. Once Buddha, he will rule over the Ketumati Pure Land, an earthly paradise sometimes associated with the Indian city of Varanasi or Benares in present-day Uttar Pradesh. In Mahayana Buddhism, the Buddha presides over a land of purity. For example, Amitabha presides over Sukhavati, more popularly known as the \"Western Paradise\".\nA notable teaching he will rediscover is that of the ten non-virtuous deeds\u2014killing, stealing, sexual misconduct, lying, divisive speech, abusive speech, idle speech, covetousness, harmful intent and wrong views. The ten virtuous deeds will replace them with the abandonment of each of these practices. Edward Conze in his \"Buddhist Scriptures\" (1959) gives an account of Maitreya:\nMaitreya currently resides in Tushita, but will come to Jambudvipa when needed most as successor to the historic \u015a\u0101kyamuni Buddha. Maitreya will achieve complete enlightenment during his lifetime, and following this reawakening he will bring back the timeless teaching of dharma to this plane and rediscover enlightenment. The Arya Maitreya Mandala, founded in 1933 by Lama Anagarika Govinda, is based on the idea of Maitreya.\nMaitreya eschatology forms the central canon of the White Lotus Society, a religious and political movement which emerged in Yuan China. It later branched into the Chinese underground criminal organization known as the Triads, which exist today as an international underground criminal network. \nNote that no description of Maitreya occurs in any other sutta in the canon, casting doubt as to the authenticity of the scripture. In addition, sermons of the Buddha normally are in response to a question, or in a specific context, but this sutta has a beginning and an ending, and its content is quite different from the others. This has led some to conclude that the whole sutta is apocryphal, or tampered with.\nSermon of the Seven Suns.\nIn his \"Sermon of the Seven Suns\" in the Pali Canon, the Buddha describes the ultimate fate of the Earth in an apocalypse characterized by the consequent appearance of seven suns in the sky, each causing progressive ruin until the planet is destroyed:\nThe canon goes on to describe the progressive destruction of each sun. The third sun will dry the Ganges River and other rivers, whilst the fourth will cause the lakes to evaporate; the fifth will dry the oceans. Later:\nThe sermon completes with the Earth immersed into an extensive holocaust. The Pali Canon does not indicate when this will happen relative to Maitreya.\nNorse mythology.\nNorse mythology depicts the end of days as \"Ragnar\u00f6k\", an Old Norse term translatable as \"twilight of the gods\". It will be heralded by a devastation known as Fimbulvetr which will seize Midgard in cold and darkness. The sun and moon will disappear from the sky, and poison will fill the air. The dead will rise from the ground and there will be widespread despair.\nThen there will be a battle between\u2014on the one hand\u2014the Gods with the \u00c6sir, Vanir and Einherjar, led by Odin, and\u2014on the other hand\u2014forces of Chaos, including the fire giants and j\u00f6tunn, led by Loki. In the fighting Odin will be swallowed whole by his old nemesis Fenrir. The god Freyr fights Surtr but loses. V\u00ed\u00f0arr, son of Odin, will then avenge his father by ripping Fenrir's jaws apart and stabbing the wolf in the heart with his spear. The serpent J\u00f6rmungandr will open its gaping maw and be met in combat by Thor. Thor, also a son of Odin, will defeat the serpent, only to take nine steps afterwards before collapsing in his own death.\nAfter this people will flee their homes as the sun blackens and the earth sinks into the sea. The stars will vanish, steam will rise, and flames will touch the heavens. This conflict will result in the deaths of most of the major Gods and forces of Chaos. Finally, Surtr will fling fire across the nine worlds. The ocean will then completely submerge Midgard.\nAfter the cataclysm, the world will resurface new and fertile, and the surviving Gods will meet. Baldr, another son of Odin, will be reborn in the new world, according to V\u00f6lusp\u00e1. The two human survivors, L\u00edf and L\u00edf\u00ferasir, will then repopulate this new earth.\nEgyptian mythology.\nEgyptian texts typically treat the dissolution of the world as a possibility to be avoided, and for that reason they do not often describe it in detail. However, many texts allude to the idea that the world, after countless cycles of renewal, is destined to end. This end is described in a passage in the \"Coffin Texts\" and a more explicit one in the \"Book of the Dead\", in which Atum says that he will one day dissolve the ordered world and return to his primeval, inert state within the waters of chaos. All things other than the creator will cease to exist, except Osiris, who will survive along with him. Details about this eschathological prospect are left unclear, including the fate of the dead who are associated with Osiris. Yet with the creator god and the god of renewal together in the waters that gave rise to the orderly world, there is the potential for a new creation to arise in the same manner as the old.\nNo end times.\nTaoism.\nThe Taoist faith is not concerned with what came before or after life, knowing only their own being in the Tao. The philosophy is that people come and go, just like mountains, trees and stars, but Tao will go on for time immemorial.\nAnalogies in science and philosophy.\nResearchers in futures studies and transhumanists investigate how the accelerating rate of scientific progress may lead to a \"technological singularity\" in the future that would profoundly and unpredictably change the course of human history, and result in \"Homo sapiens\" no longer being the dominant life form on Earth.\nOccasionally the term \"physical eschatology\" is applied to the long-term predictions of astrophysics about the future of Earth and ultimate fate of the universe. In approximately 6 billion years, the Sun will turn into a red giant. Life on Earth will become impossible due to a rise in temperature long before the planet is possibly actually swallowed up by the Sun or left charred. Later, the Sun will become a white dwarf."}
{"id": "9762", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=9762", "title": "Ecumenical council", "text": "An ecumenical council, also called general council, is a meeting of bishops and other church authorities to consider and rule on questions of Christian doctrine, administration, discipline, and other matters in which those entitled to vote are convoked from the whole world (\"oikoumene\") and which secures the approbation of the whole Church.\nThe word \"ecumenical\" derives from the Late Latin \"oecumenicus\" \"general, universal\", from Greek \"oikoumenikos\" \"from the whole world\", from \"he oikoumene ge\" \"the inhabited world\" (as known to the ancient Greeks); the Greeks and their neighbors, considered as developed human society (as opposed to barbarian lands); in later use \"the Roman world\" and in the Christian sense in ecclesiastical Greek, from \"oikoumenos\", present passive participle of \"oikein\" (\"inhabit\"), from \"oikos\" (\"house, habitation\"). The first seven ecumenical councils, recognised by both the eastern and western denominations comprising Chalcedonian Christianity, were convoked by Roman Emperors, who also enforced the decisions of those councils within the state church of the Roman Empire.\nStarting with the third ecumenical council, noteworthy schisms led to non-participation by some members of what had previously been considered a single Christian Church. Thus, some parts of Christianity did not attend later councils, or attended but did not accept the results. Bishops belonging to what became known as the Eastern Orthodox Church accept seven ecumenical councils, as described below. Bishops belonging to what became known as the Church of the East participated in the first two councils. Bishops belonging to what became known as Oriental Orthodoxy participated in the first four councils, but rejected the decisions of the fourth and did not attend any subsequent ecumenical councils.\nAcceptance of councils as ecumenical and authoritative varies between different Christian denominations. Disputes over Christological and other questions have led certain branches to reject some councils that others accept.\nAcceptance of councils by denomination.\nThe Church of the East (accused by others of adhering to Nestorianism) accepts as ecumenical the first two councils. Oriental Orthodox Churches accept the first three.\nBoth the Catholic Church and Eastern Orthodox Church recognize as ecumenical the first seven councils, held from the 4th to the 9th centuries. While some Eastern Orthodox accept one later council as ecumenical (which was later repudiated by the Catholic Church), the Catholic Church continues to hold general councils of the bishops in full communion with the Pope, reckoning them as ecumenical. In all, the Catholic Church recognizes twenty-one councils as ecumenical.\nThe first four ecumenical councils are recognized by some Lutheran Churches, Anglican Communion and Reformed Churches\u2014though they are \"considered subordinate to Scripture\". The Lutheran World Federation recognizes the first seven Ecumenical Councils as \"exercises of apostolic authority\" and recognizes their decisions as authoritative; while member churches are not required to accept all theological statements produced by the Federation, but only to subscribe to the most basic Lutheran historical confessional documents, most do follow this recommendation.\nInfallibility of ecumenical councils.\nThe doctrine of the \"infallibility of ecumenical councils\" states that solemn definitions of ecumenical councils, which concern faith or morals, and to which the whole Church must adhere, are infallible. Such decrees are often labeled as 'Canons' and they often have an attached anathema, a penalty of excommunication, against those who refuse to believe the teaching. The doctrine does not claim that every aspect of every ecumenical council is dogmatic, but that every aspect of an ecumenical council is free of errors or impeccable.\nBoth the Catholic and the Eastern Orthodox churches uphold versions of this doctrine. However, the Catholic Church holds that solemn definitions of ecumenical councils meet the conditions of infallibility only when approved by the Pope, while the Eastern Orthodox Church holds that an ecumenical council is itself infallible when pronouncing on a specific matter.\nProtestant churches would generally view ecumenical councils as fallible human institutions that have no more than a derived authority to the extent that they correctly expound Scripture (as most would generally consider occurred with the first four councils in regard to their dogmatic decisions).\nCouncil documents.\nChurch councils were, from the beginning, bureaucratic exercises. Written documents were circulated, speeches made and responded to, votes taken, and final documents published and distributed. A large part of what is known about the beliefs of heresies comes from the documents quoted in councils in order to be refuted, or indeed only from the deductions based on the refutations.\nMost councils dealt not only with doctrinal but also with disciplinary matters, which were decided in \"canons\" (\"laws\"). Study of the canons of church councils is the foundation of the development of canon law, especially the reconciling of seemingly contradictory canons or the determination of priority between them. Canons consist of doctrinal statements and disciplinary measures\u2014most Church councils and local synods dealt with immediate disciplinary concerns as well as major difficulties of doctrine. Eastern Orthodoxy typically views the purely doctrinal canons as dogmatic and applicable to the entire church at all times, while the disciplinary canons apply to a particular time and place and may or may not be applicable in other situations.\nCircumstances of the first ecumenical councils.\nOf the seven councils recognised in whole or in part by both the Catholic and the Eastern Orthodox Church as ecumenical, all were called by a Roman emperor. The emperor gave them legal status within the entire Roman Empire. All were held in the eastern part of the Roman Empire. The bishop of Rome (self-styled as \"pope\" since the end of the fourth century) did not attend, although he sent legates to some of them.\nChurch councils were traditional and the ecumenical councils were a continuation of earlier councils (also known as synods) held in the Empire before Christianity was made legal. These include the Council of Jerusalem (c. 50), the Council of Rome (155), the Second Council of Rome (193), the Council of Ephesus (193), the Council of Carthage (251), the Council of Iconium (258), the Council of Antioch (264), the Councils of Arabia (246\u2013247), the Council of Elvira (306), the Council of Carthage (311), the Synod of Neo-Caesarea (c. 314), the Council of Ancyra (314) and the Council of Arles (314).\nThe first seven councils recognised in both East and West as ecumenical and several others to which such recognition is refused were called by the Byzantine emperors. In the first millennium, various theological and political differences such as Nestorianism or Dyophysitism caused parts of the Church to separate after councils such as those of Ephesus and Chalcedon, but councils recognised as ecumenical continued to be held.\nThe Council of Hieria of 754, held at the imperial palace of that name close to Chalcedon in Anatolia, was summoned by Byzantine Emperor Constantine V and was attended by 338 bishops, who regarded it as the seventh ecumenical council. The Second Council of Nicaea, which annulled that of Hieria, was itself annulled at the synod held in 815 in Constantinople under Emperor Leo V. This synod, presided over by Patriarch Theodotus I of Constantinople, declared the Council of Hieria to be the seventh ecumenical council, but, although the Council of Hieria was called by an emperor and confirmed by another, and although it was held in the East, it later ceased to be considered ecumenical.\nSimilarly, the Second Council of Ephesus of 449, also held in Anatolia, was called by the Byzantine Emperor Theodosius II and, though annulled by the Council of Chalcedon, was confirmed by Emperor Basiliscus, who annulled the Council of Chalcedon. This too ceased to be considered an ecumenical council.\nCatholic views on those circumstances.\nThe Catholic Church does not consider the validity of an ecumenical council's teaching to be in any way dependent on where it is held or on the granting or withholding of prior authorization or legal status by any state, in line with the attitude of the 5th-century bishops who \"saw the definition of the church's faith and canons as supremely their affair, with or without the leave of the Emperor\" and who \"needed no one to remind them that Synodical process pre-dated the Christianisation of the royal court by several centuries\".\nThe Catholic Church recognizes as ecumenical various councils held later than the First Council of Ephesus (after which churches out of communion with the Holy See because of the Nestorian Schism did not participate), later than the Council of Chalcedon (after which there was no participation by churches that rejected Dyophysitism), later than the Second Council of Nicaea (after which there was no participation by the Eastern Orthodox Church), and later than the Fifth Council of the Lateran (after which groups that adhered to Protestantism did not participate).\nOf the twenty-one ecumenical councils recognised by the Catholic Church, some gained recognition as ecumenical only later. Thus the Eastern First Council of Constantinople became ecumenical only when its decrees were accepted in the West also.\nList of ecumenical councils.\nFirst seven ecumenical councils.\nIn the history of Christianity, the first seven ecumenical councils, from the First Council of Nicaea (325) to the Second Council of Nicaea (787), represent an attempt to reach an orthodox consensus and to unify Christendom.\nAll of the original seven ecumenical councils as recognized in whole or in part were called by an emperor of the Eastern Roman Empire and all were held in the Eastern Roman Empire, a recognition denied to other councils similarly called by an Eastern Roman emperor and held in his territory, in particular the Council of Serdica (343), the Second Council of Ephesus (449) and the Council of Hieria (754), which saw themselves as ecumenical or were intended as such.\nFurther councils recognised as ecumenical in the Catholic Church.\nAs late as the 11th century, seven councils were recognised as ecumenical in the Catholic Church. Then, in the time of Pope Gregory VII (1073\u20131085), canonists who in the Investiture Controversy quoted the prohibition in canon 22 of the Council of Constantinople of 869\u2013870 against laymen influencing the appointment of prelates elevated this council to the rank of ecumenical council. Only in the 16th century was recognition as ecumenical granted by Catholic scholars to the Councils of the Lateran, of Lyon and those that followed. The following is a list of further councils generally recognised as ecumenical by Catholic theologians:\nFurther councils recognised as ecumenical by some Eastern Orthodox.\nEastern Orthodox catechisms teach that there are seven ecumenical councils and there are feast days for seven ecumenical councils. Nonetheless, some Eastern Orthodox consider events like the Council of Constantinople of 879\u2013880, that of Constantinople in 1341\u20131351 and that of Jerusalem in 1672 to be ecumenical:\nIt is unlikely that formal ecumenical recognition will be granted to these councils, despite the acknowledged orthodoxy of their decisions, so that seven are universally recognized among the Eastern Orthodox as ecumenical.\nThe 2016 Pan-Orthodox Council was sometimes referred to as a potential \"Eighth Ecumenical Council\" following debates on several issues facing Eastern Orthodoxy, however not all autocephalous churches were represented. \nAcceptance of the councils.\nAlthough some Protestants reject the concept of an ecumenical council establishing doctrine for the entire Christian faith, Catholics, Lutherans, Anglicans, Methodists, Eastern Orthodox and Oriental Orthodox all accept the authority of ecumenical councils in principle. Where they differ is in which councils they accept and what the conditions are for a council to be considered \"ecumenical\". The relationship of the Papacy to the validity of ecumenical councils is a ground of controversy between Catholicism and the Eastern Orthodox churches. The Catholic Church holds that recognition by the Pope is an essential element in qualifying a council as ecumenical; Eastern Orthodox view approval by the Bishop of Rome (the Pope) as being roughly equivalent to that of other patriarchs.\nSome have held that a council is ecumenical only when all five patriarchs of the Pentarchy are represented at it. Others reject this theory in part because there were no patriarchs of Constantinople and Jerusalem at the time of the first ecumenical council.\nCatholic Church.\nBoth the Catholic and Eastern Orthodox churches recognize seven councils in the early centuries of the church, but Catholics also recognize fourteen councils in later times called or confirmed by the Pope. At the urging of German King Sigismund, who was to become Holy Roman Emperor in 1433, the Council of Constance was convoked in 1414 by Antipope John XXIII, one of three claimants to the papal throne, and was reconvened in 1415 by the Roman Pope Gregory XII. The Council of Florence is an example of a council accepted as ecumenical in spite of being rejected by the East, as the Councils of Ephesus and Chalcedon are accepted in spite of being rejected respectively by the Church of the East and Oriental Orthodoxy.\nThe Catholic Church teaches that an ecumenical council is a gathering of the College of Bishops (of which the Bishop of Rome is an essential part) to exercise in a solemn manner its supreme and full power over the whole Church. It holds that \"there never is an ecumenical council which is not confirmed or at least recognized as such by Peter's successor\". Its present canon law requires that an ecumenical council be convoked and presided over, either personally or through a delegate, by the Pope, who is also to decide the agenda; but the church makes no claim that all past ecumenical councils observed these present rules, declaring only that the Pope's confirmation or at least recognition has always been required, and saying that the version of the Nicene Creed adopted at the First Council of Constantinople (381) was accepted by the Church of Rome only seventy years later, in 451.\nEastern Orthodox Church.\nThe Eastern Orthodox Church accepts seven ecumenical councils, with the disputed Council in Trullo\u2014rejected by Catholics\u2014being incorporated into, and considered as a continuation of, the Third Council of Constantinople.\nTo be considered ecumenical, Orthodox accept a council that meets the condition that it was accepted by the whole church. That it was called together legally is also an important factor. A case in point is the Third Ecumenical Council, where two groups met as duly called for by the emperor, each claiming to be the legitimate council. The Emperor had called for bishops to assemble in the city of Ephesus. Theodosius did not attend but sent his representative Candidian to preside. However, Cyril managed to open the council over Candidian's insistent demands that the bishops disperse until the delegation from Syria could arrive. Cyril was able to completely control the proceedings, completely neutralizing Candidian, who favored Cyril's antagonist, Nestorius. When the pro-Nestorius Antiochene delegation finally arrived, they decided to convene their own council, over which Candidian presided. The proceedings of both councils were reported to the emperor, who decided ultimately to depose Cyril, Memnon and Nestorius. Nonetheless, the Orthodox accept Cyril's group as being the legitimate council because it maintained the same teaching that the church has always taught.\nParaphrasing a rule by St Vincent of L\u00e9rins, Hasler states\nOrthodox believe that councils could over-rule or even depose popes. At the Sixth Ecumenical Council, Pope Honorius and Patriarch Sergius were declared heretics. The council anathematized them and declared them tools of the devil and cast them out of the church.\nIt is their position that, since the Seventh Ecumenical Council, there has been no synod or council of the same scope. Local meetings of hierarchs have been called \"pan-Orthodox\", but these have invariably been simply meetings of local hierarchs of whatever Eastern Orthodox jurisdictions are party to a specific local matter. From this point of view, there has been no fully \"pan-Orthodox\" (Ecumenical) council since 787. The use of the term \"pan-Orthodox\" is confusing to those not within Eastern Orthodoxy, and it leads to mistaken impressions that these are \"ersatz\" ecumenical councils rather than purely local councils to which nearby Orthodox hierarchs, regardless of jurisdiction, are invited.\nOthers, including 20th-century theologians Metropolitan Hierotheos (Vlachos) of Naupactus, Fr. John S. Romanides, and Fr. George Metallinos (all of whom refer repeatedly to the \"Eighth and Ninth Ecumenical Councils\"), Fr. George Dragas, and the 1848 Encyclical of the Eastern Patriarchs (which refers explicitly to the \"Eighth Ecumenical Council\" and was signed by the patriarchs of Constantinople, Jerusalem, Antioch, and Alexandria as well as the Holy Synods of the first three), regard other synods beyond the Seventh Ecumenical Council as being ecumenical.\nFrom the Eastern Orthodox perspective, a council is accepted as being ecumenical if it is accepted by the Eastern Orthodox church at large\u2014clergy, monks and assembly of believers. Teachings from councils that purport to be ecumenical, but which lack this acceptance by the church at large, are, therefore, not considered ecumenical.\nOriental Orthodoxy.\nOriental Orthodoxy accepts three ecumenical councils, the First Council of Nicaea, the First Council of Constantinople, and the Council of Ephesus. The formulation of the Chalcedonian Creed caused a schism in the Alexandrian and Syriac churches. Reconciliatory efforts between Oriental Orthodox with the Eastern Orthodox and the Catholic Church in the mid- and late 20th century have led to common Christological declarations. The Oriental and Eastern Churches have also been working toward reconciliation as a consequence of the ecumenical movement.\nThe Oriental Orthodox hold that the Dyophysite formula of two natures formulated at the Council of Chalcedon is inferior to the Miaphysite formula of \"One Incarnate Nature of God the Word\" (Byzantine Greek: \"Mia physis tou theou logou sarkousomene\") and that the proceedings of Chalcedon themselves were motivated by imperial politics. The Alexandrian Church, the main Oriental Orthodox body, also felt unfairly underrepresented at the council following the deposition of their Pope, Dioscorus of Alexandria at the council.\nChurch of the East.\nThe Church of the East accepts two ecumenical councils, the First Council of Nicaea and the First Council of Constantinople, as well as a series of their own national councils, starting with the Council of Seleucia-Ctesiphon in 410 AD. It was the formulation of Mary as the Theotokos which caused a schism with the Church of the East, now divided between the Assyrian Church of the East and the Ancient Church of the East, while the Chaldean Catholic Church entered into full communion with Rome in the 16th century. Meetings between Pope John Paul II and the Assyrian Patriarch Mar Dinkha IV led to a common Christological declaration on 11 November 1994 that \"the humanity to which the Blessed Virgin Mary gave birth always was that of the Son of God himself\". Both sides recognised the legitimacy and rightness, as expressions of the same faith, of the Assyrian Church's liturgical invocation of Mary as \"the Mother of Christ our God and Saviour\" and the Catholic Church's use of \"the Mother of God\" and also as \"the Mother of Christ\".\nProtestantism.\nLutheran Churches.\nThe Lutheran World Federation, in ecumenical dialogues with the Ecumenical Patriarch of Constantinople, has affirmed all of the first seven councils as ecumenical and authoritative. It teaches:\nAnglican Communion.\nArticle XXI of the Thirty-nine Articles of Religion of Anglicanism teaches: \"General Councils ... when they be gathered together, forasmuch as they be an assembly of men, whereof all be not governed with the Spirit and word of God, they may err and sometime have erred, even in things pertaining to God. Wherefore things ordained by them as necessary to salvation have neither strength nor authority, unless it may be declared that they be taken out of Holy Scripture.\"\nThe 19th Canon of 1571 asserted the authority of the Councils in this manner: \"Let preachers take care that they never teach anything ... except what is agreeable to the doctrine of the Old and New Testament, and what the Catholic Fathers and ancient Bishops have collected from the same doctrine.\" This remains the Church of England's teaching on the subject. A modern version of this appeal to catholic consensus is found in the Canon Law of the Church of England and also in the liturgy published in \"Common Worship\":\nThe 1559 Act of Supremacy made a distinction between the decisions of the first four ecumenical councils, which were to be used as sufficient proof that something was heresy, as opposed to those of later councils, which could only be used to that purpose if \"the same was declared heresy by the express and plain words of the ... canonical Scriptures\". As such, the Anglican tradition accepts the first four ecumenical councils, though they \"considered subordinate to Scripture\".\nWhile the Councils are part of the \"historic formularies\" of Anglican tradition, it is difficult to locate an explicit reference in Anglicanism to the unconditional acceptance of all Seven Ecumenical Councils. There is little evidence of dogmatic or canonical acceptance beyond the statements of individual Anglican theologians and bishops. Anglican cleric of Anglo-Catholic churchmanship Bishop Chandler Holder Jones, SSC, explains:\nHe quotes William Tighe, Associate Professor of History at Muhlenberg College in Allentown, Pennsylvania, (another member of the Anglo-Catholic wing of Anglicanism):\nMethodist Churches.\nMethodist theologian Charles W. Brockwell Jr wrote that the first \"four ecumenical councils produced and clarified the Niceno-Constantinopolitan Symbol (Nicene Creed), the most important document in Christian history after the Bible itself.\"\nThe Manual of the Church of the Nazarene, part of the Wesleyan-Holiness movement within Methodism, states \"Our denomination receives the creeds of the first five Christian centuries as expressions of its own faith,\" including the Christological doctrines formulated during the first four Ecumenical Councils.\nOther Protestant denominations.\nSome, including some fundamentalist Christians, condemn the ecumenical councils for other reasons. Independency or congregationalist polity among Protestants may involve the rejection of any governmental structure or binding authority above local congregations; conformity to the decisions of these councils is therefore considered purely voluntary and the councils are to be considered binding only insofar as those doctrines are derived from the Scriptures. Many of these churches reject the idea that anyone other than the authors of Scripture can directly lead other Christians by original divine authority; after the New Testament, they assert, the doors of revelation were closed and councils can only give advice or guidance, but have no authority. They consider new doctrines not derived from the sealed canon of Scripture to be both impossible and unnecessary whether proposed by church councils or by more recent prophets. Catholic and Orthodox objections to this position point to the fact that the Canon of Scripture itself was fixed by these councils. They conclude that this would lead to a logical inconsistency of a non-authoritative body fixing a supposedly authoritative source.\nNontrinitarian groups.\nEcumenical councils are not recognised by nontrinitarian churches such as the Church of Jesus Christ of Latter-day Saints (and other denominations within the Latter Day Saint movement), Christadelphians, Jehovah's Witnesses, Church of God (Seventh-Day), their descendants and Unitarians. They view the ecumenical councils as misguided human attempts to establish doctrine, and as attempts to define dogmas by debate rather than by revelation."}
{"id": "9763", "revid": "42021989", "url": "https://en.wikipedia.org/wiki?curid=9763", "title": "Exoplanet", "text": "An exoplanet or extrasolar planet is a planet outside the Solar System. The first possible evidence of an exoplanet was noted in 1917 but was not then recognized as such. The first confirmed detection of an exoplanet was in 1992 around a pulsar, and the first detection around a main-sequence star was in 1995. A different planet, first detected in 1988, was confirmed in 2003. In collaboration with ground-based and other space-based observatories the James Webb Space Telescope (JWST) is expected to give more insight into exoplanet traits, such as their composition, environmental conditions, and potential for life.\nThere are many methods of detecting exoplanets. Transit photometry and Doppler spectroscopy have found the most, but these methods suffer from a clear observational bias favoring the detection of planets near the star; thus, 85% of the exoplanets detected are inside the tidal locking zone. In several cases, multiple planets have been observed around a star. About 1 in 5 Sun-like stars are estimated to have an \"Earth-sized\" planet in the habitable zone. Assuming there are 200 billion stars in the Milky Way, it can be hypothesized that there are 11 billion potentially habitable Earth-sized planets in the Milky Way, rising to 40 billion if planets orbiting the numerous red dwarfs are included.\nThe least massive exoplanet known is Draugr (also known as PSR B1257+12 A or PSR B1257+12 b), which is about twice the mass of the Moon. The most massive exoplanet listed on the NASA Exoplanet Archive is HR 2562 b, about 30 times the mass of Jupiter. However, according to some definitions of a planet (based on the nuclear fusion of deuterium), it is too massive to be a planet and might be a brown dwarf. Known orbital times for exoplanets vary from less than an hour (for those closest to their star) to thousands of years. Some exoplanets are so far away from the star that it is difficult to tell whether they are gravitationally bound to it.\nAlmost all planets detected so far are within the Milky Way. However, there is evidence that extragalactic planets, exoplanets located in other galaxies, may exist. The nearest exoplanets are located 4.2 light-years (1.3 parsecs) from Earth and orbit Proxima Centauri, the closest star to the Sun.\nThe discovery of exoplanets has intensified interest in the search for extraterrestrial life. There is special interest in planets that orbit in a star's habitable zone (sometimes called \"goldilocks zone\"), where it is possible for liquid water, a prerequisite for life as we know it, to exist on the surface. However, the study of planetary habitability also considers a wide range of other factors in determining the suitability of a planet for hosting life.\nRogue planets are those that are not in planetary systems. Such objects are generally considered in a separate category from planets, especially if they are gas giants, often counted as sub-brown dwarfs. The rogue planets in the Milky Way possibly number in the billions or more.\nDefinition.\nIAU.\nThe official definition of the term \"planet\" used by the International Astronomical Union (IAU) only covers the Solar System and thus does not apply to exoplanets. The IAU Working Group on Extrasolar Planets issued a position statement containing a working definition of \"planet\" in 2001 and which was modified in 2003. An \"exoplanet\" was defined by the following criteria:\nThis working definition was amended by the IAU's Commission F2: Exoplanets and the Solar System in August 2018. The official working definition of an \"exoplanet\" is now as follows:\nAlternatives.\nThe IAU's working definition is not always used. One alternate suggestion is that planets should be distinguished from brown dwarfs on the basis of their formation. It is widely thought that giant planets form through core accretion, which may sometimes produce planets with masses above the deuterium fusion threshold; massive planets of that sort may have already been observed. Brown dwarfs form like stars from the direct gravitational collapse of clouds of gas, and this formation mechanism also produces objects that are below the limit and can be as low as . Objects in this mass range that orbit their stars with wide separations of hundreds or thousands of astronomical units (AU) and have large star/object mass ratios likely formed as brown dwarfs; their atmospheres would likely have a composition more similar to their host star than accretion-formed planets, which would contain increased abundances of heavier elements. Most directly imaged planets as of April 2014 are massive and have wide orbits so probably represent the low-mass end of a brown dwarf formation. One study suggests that objects above formed through gravitational instability and should not be thought of as planets.\nAlso, the 13-Jupiter-mass cutoff does not have a precise physical significance. Deuterium fusion can occur in some objects with a mass below that cutoff. The amount of deuterium fused depends to some extent on the composition of the object. As of 2011, the Extrasolar Planets Encyclopaedia included objects up to 25 Jupiter masses, saying, \"The fact that there is no special feature around in the observed mass spectrum reinforces the choice to forget this mass limit\". As of 2016, this limit was increased to 60 Jupiter masses based on a study of mass\u2013density relationships. The Exoplanet Data Explorer includes objects up to 24 Jupiter masses with the advisory: \"The 13 Jupiter-mass distinction by the IAU Working Group is physically unmotivated for planets with rocky cores, and observationally problematic due to the sin i ambiguity.\" The NASA Exoplanet Archive includes objects with a mass (or minimum mass) equal to or less than 30 Jupiter masses. Another criterion for separating planets and brown dwarfs, rather than deuterium fusion, formation process or location, is whether the core pressure is dominated by Coulomb pressure or electron degeneracy pressure with the dividing line at around 5 Jupiter masses.\nNomenclature.\n&lt;section begin=nomenclature /&gt;\nThe convention for naming exoplanets is an extension of the system used for designating multiple-star systems as adopted by the International Astronomical Union (IAU). For exoplanets orbiting a single star, the IAU designation is formed by taking the designated or proper name of its parent star, and adding a lower case letter. Letters are given in order of each planet's discovery around the parent star, so that the first planet discovered in a system is designated \"b\" (the parent star is considered \"a\") and later planets are given subsequent letters. If several planets in the same system are discovered at the same time, the closest one to the star gets the next letter, followed by the other planets in order of orbital size. A provisional IAU-sanctioned standard exists to accommodate the designation of circumbinary planets. A limited number of exoplanets have IAU-sanctioned proper names. Other naming systems exist.&lt;section end=nomenclature /&gt;\nHistory of detection.\nFor centuries scientists, philosophers, and science fiction writers suspected that extrasolar planets existed, but there was no way of knowing whether they were real in fact, how common they were, or how similar they might be to the planets of the Solar System. Various detection claims made in the nineteenth century were rejected by astronomers.\nThe first evidence of a possible exoplanet, orbiting Van Maanen 2, was noted in 1917, but was not recognized as such. The astronomer Walter Sydney Adams, who later became director of the Mount Wilson Observatory, produced a spectrum of the star using Mount Wilson's 60-inch telescope. He interpreted the spectrum to be of an F-type main-sequence star, but it is now thought that such a spectrum could be caused by the residue of a nearby exoplanet that had been pulverized by the gravity of the star, the resulting dust then falling onto the star.\nThe first suspected scientific detection of an exoplanet occurred in 1988. Shortly afterwards, the first confirmation of detection came in 1992 when Aleksander Wolszczan announced the discovery of several terrestrial-mass planets orbiting the pulsar PSR B1257+12. The first confirmation of an exoplanet orbiting a main-sequence star was made in 1995, when a giant planet was found in a four-day orbit around the nearby star 51 Pegasi. Some exoplanets have been imaged directly by telescopes, but the vast majority have been detected through indirect methods, such as the transit method and the radial-velocity method. In February 2018, researchers using the Chandra X-ray Observatory, combined with a planet detection technique called microlensing, found evidence of planets in a distant galaxy, stating, \"Some of these exoplanets are as (relatively) small as the moon, while others are as massive as Jupiter. Unlike Earth, most of the exoplanets are not tightly bound to stars, so they're actually wandering through space or loosely orbiting between stars. We can estimate that the number of planets in this [faraway] galaxy is more than a trillion.\"\nEarly speculations.\nIn the sixteenth century, the Italian philosopher Giordano Bruno, an early supporter of the Copernican theory that Earth and other planets orbit the Sun (heliocentrism), put forward the view that fixed stars are similar to the Sun and are likewise accompanied by planets.\nIn the eighteenth century, the same possibility was mentioned by Isaac Newton in the \"General Scholium\" that concludes his \"Principia\". Making a comparison to the Sun's planets, he wrote \"And if the fixed stars are the centres of similar systems, they will all be constructed according to a similar design and subject to the dominion of \"One\".\"\nIn 1938, D.Belorizky demonstrated that it was realistic to search for exo-Jupiters by using transit photometry.\nIn 1952, more than 40 years before the first hot Jupiter was discovered, Otto Struve wrote that there is no compelling reason that planets could not be much closer to their parent star than is the case in the Solar System, and proposed that Doppler spectroscopy and the transit method could detect super-Jupiters in short orbits.\nDiscredited claims.\nClaims of exoplanet detections have been made since the nineteenth century. Some of the earliest involve the binary star 70 Ophiuchi. In 1855, William Stephen Jacob at the East India Company's Madras Observatory reported that orbital anomalies made it \"highly probable\" that there was a \"planetary body\" in this system. In the 1890s, Thomas J. J. See of the University of Chicago and the United States Naval Observatory stated that the orbital anomalies proved the existence of a dark body in the 70\u00a0Ophiuchi system with a 36-year period around one of the stars. However, Forest Ray Moulton published a paper proving that a three-body system with those orbital parameters would be highly unstable.\nDuring the 1950s and 1960s, Peter van de Kamp of Swarthmore College made another prominent series of detection claims, this time for planets orbiting Barnard's Star. Astronomers now generally regard all early reports of detection as erroneous.\nIn 1991, Andrew Lyne, M. Bailes and S. L. Shemar claimed to have discovered a pulsar planet in orbit around PSR 1829-10, using pulsar timing variations. The claim briefly received intense attention, but Lyne and his team soon retracted it.\nConfirmed discoveries.\nAs of , a total of confirmed exoplanets are listed in the NASA Exoplanet Archive, including a few that were confirmations of controversial claims from the late 1980s. The first published discovery to receive subsequent confirmation was made in 1988 by the Canadian astronomers Bruce Campbell, G. A. H. Walker, and Stephenson Yang of the University of Victoria and the University of British Columbia. Although they were cautious about claiming a planetary detection, their radial-velocity observations suggested that a planet orbits the star Gamma Cephei. Partly because the observations were at the very limits of instrumental capabilities at the time, astronomers remained skeptical for several years about this and other similar observations. It was thought some of the apparent planets might instead have been brown dwarfs, objects intermediate in mass between planets and stars. In 1990, additional observations were published that supported the existence of the planet orbiting Gamma Cephei, but subsequent work in 1992 again raised serious doubts. Finally, in 2003, improved techniques allowed the planet's existence to be confirmed.\nOn 9 January 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. Follow-up observations solidified these results, and confirmation of a third planet in 1994 revived the topic in the popular press. These pulsar planets are thought to have formed from the unusual remnants of the supernova that produced the pulsar, in a second round of planet formation, or else to be the remaining rocky cores of gas giants that somehow survived the supernova and then decayed into their current orbits. As pulsars are aggressive stars, it was considered unlikely at the time that a planet may be able to be formed in their orbit.\nIn the early 1990s, a group of astronomers led by Donald Backer, who were studying what they thought was a binary pulsar (PSR B1620\u221226 b), determined that a third object was needed to explain the observed Doppler shifts. Within a few years, the gravitational effects of the planet on the orbit of the pulsar and white dwarf had been measured, giving an estimate of the mass of the third object that was too small for it to be a star. The conclusion that the third object was a planet was announced by Stephen Thorsett and his collaborators in 1993.\nOn 6 October 1995, Michel Mayor and Didier Queloz of the University of Geneva announced the first definitive detection of an exoplanet orbiting a main-sequence star, nearby G-type star 51 Pegasi. This discovery, made at the Observatoire de Haute-Provence, ushered in the modern era of exoplanetary discovery, and was recognized by a share of the 2019 Nobel Prize in Physics. Technological advances, most notably in high-resolution spectroscopy, led to the rapid detection of many new exoplanets: astronomers could detect exoplanets indirectly by measuring their gravitational influence on the motion of their host stars. More extrasolar planets were later detected by observing the variation in a star's apparent luminosity as an orbiting planet transited in front of it.\nInitially, the most known exoplanets were massive planets that orbited very close to their parent stars. Astronomers were surprised by these \"hot Jupiters\", because theories of planetary formation had indicated that giant planets should only form at large distances from stars. But eventually more planets of other sorts were found, and it is now clear that hot Jupiters make up the minority of exoplanets. In 1999, Upsilon Andromedae became the first main-sequence star known to have multiple planets. Kepler-16 contains the first discovered planet that orbits a binary main-sequence star system.\nOn 26 February 2014, NASA announced the discovery of 715 newly verified exoplanets around 305 stars by the \"Kepler\" Space Telescope. These exoplanets were checked using a statistical technique called \"verification by multiplicity\". Before these results, most confirmed planets were gas giants comparable in size to Jupiter or larger because they were more easily detected, but the \"Kepler\" planets are mostly between the size of Neptune and the size of Earth.\nOn 23 July 2015, NASA announced Kepler-452b, a near-Earth-size planet orbiting the habitable zone of a G2-type star.\nOn 6 September 2018, NASA discovered an exoplanet about 145 light years away from Earth in the constellation Virgo. This exoplanet, Wolf 503b, is twice the size of Earth and was discovered orbiting a type of star known as an \"Orange Dwarf\". Wolf 503b completes one orbit in as few as six days because it is very close to the star. Wolf 503b is the only exoplanet that large that can be found near the so-called small planet radius gap. The gap, sometimes called the Fulton gap, is the observation that it is unusual to find exoplanets with sizes between 1.5 and 2 times the radius of the Earth.\nIn January 2020, scientists announced the discovery of TOI 700 d, the first Earth-sized planet in the habitable zone detected by TESS.\nCandidate discoveries.\nAs of January 2020, NASA's \"Kepler\" and TESS missions had identified 4374 planetary candidates yet to be confirmed, several of them being nearly Earth-sized and located in the habitable zone, some around Sun-like stars.\nIn September 2020, astronomers reported evidence, for the first time, of an extragalactic planet, M51-ULS-1b, detected by eclipsing a bright X-ray source (XRS), in the Whirlpool Galaxy (M51a).\nDetection methods.\nDirect imaging.\nPlanets are extremely faint compared to their parent stars. For example, a Sun-like star is about a billion times brighter than the reflected light from any exoplanet orbiting it. It is difficult to detect such a faint light source, and furthermore, the parent star causes a glare that tends to wash it out. It is necessary to block the light from the parent star to reduce the glare while leaving the light from the planet detectable; doing so is a major technical challenge which requires extreme optothermal stability. All exoplanets that have been directly imaged are both large (more massive than Jupiter) and widely separated from their parent stars.\nSpecially designed direct-imaging instruments such as Gemini Planet Imager, VLT-SPHERE, and SCExAO will image dozens of gas giants, but the vast majority of known extrasolar planets have only been detected through indirect methods.\nFormation and evolution.\nPlanets may form within a few to tens (or more) of millions of years of their star forming.\nThe planets of the Solar System can only be observed in their current state, but observations of different planetary systems of varying ages allows us to observe planets at different stages of evolution. Available observations range from young proto-planetary disks where planets are still forming to planetary systems of over 10 Gyr old. When planets form in a gaseous protoplanetary disk, they accrete hydrogen/helium envelopes. These envelopes cool and contract over time and, depending on the mass of the planet, some or all of the hydrogen/helium is eventually lost to space. This means that even terrestrial planets may start off with large radii if they form early enough. An example is Kepler-51b which has only about twice the mass of Earth but is almost the size of Saturn, which is a hundred times the mass of Earth. Kepler-51b is quite young at a few hundred million years old.\nPlanet-hosting stars.\nThere is at least one planet on average per star. About 1 in 5 Sun-like stars have an \"Earth-sized\" planet in the habitable zone.\nMost known exoplanets orbit stars roughly similar to the Sun, i.e. main-sequence stars of spectral categories F, G, or K. Lower-mass stars (red dwarfs, of spectral category M) are less likely to have planets massive enough to be detected by the radial-velocity method. Despite this, several tens of planets around red dwarfs have been discovered by the Kepler space telescope, which uses the transit method to detect smaller planets.\nUsing data from Kepler, a correlation has been found between the metallicity of a star and the probability that the star hosts a giant planet, similar to the size of Jupiter. Stars with higher metallicity are more likely to have planets, especially giant planets, than stars with lower metallicity.\nSome planets orbit one member of a binary star system, and several circumbinary planets have been discovered which orbit both members of a binary star. A few planets in triple star systems are known and one in the quadruple system Kepler-64.\nGeneral features.\nColor and brightness.\nThe apparent brightness (apparent magnitude) of a planet depends on how far away the observer is, how reflective the planet is (albedo), and how much light the planet receives from its star, which depends on how far the planet is from the star and how bright the star is. So, a planet with a low albedo that is close to its star can appear brighter than a planet with a high albedo that is far from the star.\nIn 2013, the color of an exoplanet was determined for the first time. The best-fit albedo measurements of HD 189733b suggest that it is deep dark blue. Later that same year, the colors of several other exoplanets were determined, including GJ 504 b which visually has a magenta color, and Kappa Andromedae b, which if seen up close would appear reddish in color. Helium planets are expected to be white or grey in appearance.\nThe darkest known planet in terms of geometric albedo is TrES-2b, a hot Jupiter that reflects less than 1% of the light from its star, making it less reflective than coal or black acrylic paint. Hot Jupiters are expected to be quite dark due to sodium and potassium in their atmospheres, but it is not known why TrES-2b is so dark\u2014it could be due to an unknown chemical compound.\nFor gas giants, geometric albedo generally decreases with increasing metallicity or atmospheric temperature unless there are clouds to modify this effect. Increased cloud-column depth increases the albedo at optical wavelengths, but decreases it at some infrared wavelengths. Optical albedo increases with age, because older planets have higher cloud-column depths. Optical albedo decreases with increasing mass, because higher-mass giant planets have higher surface gravities, which produces lower cloud-column depths. Also, elliptical orbits can cause major fluctuations in atmospheric composition, which can have a significant effect.\nThere is more thermal emission than reflection at some near-infrared wavelengths for massive and/or young gas giants. So, although optical brightness is fully phase-dependent, this is not always the case in the near infrared.\nTemperatures of gas giants reduce over time and with distance from their stars. Lowering the temperature increases optical albedo even without clouds. At a sufficiently low temperature, water clouds form, which further increase optical albedo. At even lower temperatures, ammonia clouds form, resulting in the highest albedos at most optical and near-infrared wavelengths.\nMagnetic field.\nIn 2014, a magnetic field around HD 209458 b was inferred from the way hydrogen was evaporating from the planet. It is the first (indirect) detection of a magnetic field on an exoplanet. The magnetic field is estimated to be about one-tenth as strong as Jupiter's.\nThe magnetic fields of exoplanets are thought to be detectable by their auroral radio emissions with sensitive low-frequency radio telescopes such as LOFAR, although they have yet to be found. The radio emissions could measure the rotation rate of the interior of an exoplanet, and may yield a more accurate way to measure exoplanet rotation than by examining the motion of clouds. However, the most sensitive radio search for auroral emissions, thus far, from nine exoplanets with Arecibo also did not result in any discoveries.\nEarth's magnetic field results from its flowing liquid metallic core, but on massive super-Earths with high pressure, different compounds may form which do not match those created under terrestrial conditions. Compounds may form with greater viscosities and high melting temperatures, which could prevent the interiors from separating into different layers and so result in undifferentiated coreless mantles. Forms of magnesium oxide such as MgSi3O12 could be a liquid metal at the pressures and temperatures found in super-Earths and could generate a magnetic field in the mantles of super-Earths.\nHot Jupiters have been observed to have a larger radius than expected. This could be caused by the interaction between the stellar wind and the planet's magnetosphere creating an electric current through the planet that heats it up (Joule heating) causing it to expand. The more magnetically active a star is, the greater the stellar wind and the larger the electric current leading to more heating and expansion of the planet. This theory matches the observation that stellar activity is correlated with inflated planetary radii.\nIn August 2018, scientists announced the transformation of gaseous deuterium into a liquid metallic hydrogen form. This may help researchers better understand giant gas planets, such as Jupiter, Saturn and related exoplanets, since such planets are thought to contain a lot of liquid metallic hydrogen, which may be responsible for their observed powerful magnetic fields.\nAlthough scientists previously announced that the magnetic fields of close-in exoplanets may cause increased stellar flares and starspots on their host stars, in 2019 this claim was demonstrated to be false in the HD 189733 system. The failure to detect \"star-planet interactions\" in the well-studied HD 189733 system calls other related claims of the effect into question. A later search for radio emissions from eight exoplanets that orbit within 0.1 astronomical units of their host stars, conducted by the Arecibo radio telescope also failed to find signs of these magnetic star-planet interactions.\nIn 2019, the strength of the surface magnetic fields of 4 hot Jupiters were estimated and ranged between 20 and 120 gauss compared to Jupiter's surface magnetic field of 4.3 gauss.\nPlate tectonics.\nIn 2007, two independent teams of researchers came to opposing conclusions about the likelihood of plate tectonics on larger super-Earths with one team saying that plate tectonics would be episodic or stagnant and the other team saying that plate tectonics is very likely on super-Earths even if the planet is dry.\nIf super-Earths have more than 80 times as much water as Earth, then they become ocean planets with all land completely submerged. However, if there is less water than this limit, then the deep water cycle will move enough water between the oceans and mantle to allow continents to exist.\nVolcanism.\nLarge surface temperature variations on 55 Cancri e have been attributed to possible volcanic activity releasing large clouds of dust which blanket the planet and block thermal emissions.\nRings.\nThe star V1400 Centauri was long believed to have been occulted by an object (either a planet or brown dwarf) that is circled by a ring system much larger than Saturn's rings. Follow-up observations found the supposed ring system could instead be a circumplanetary disk.\nThere is strong evidence of a ring system around HIP 41378 f, given the planet's measured radius is too large for its mass, the radius measurement might have been affected by a ring system around the planet.\nThe rings of the Solar System's gas giants are aligned with their planet's equator. However, for exoplanets that orbit close to their star, tidal forces from the star would lead to the outermost rings of a planet being aligned with the planet's orbital plane around the star. A planet's innermost rings would still be aligned with the planet's equator so that if the planet has a tilted rotational axis, then the different alignments between the inner and outer rings would create a warped ring system.\nMoons.\nThere is evidence that moons around other planets, commonly referred to exomoons, may exist. None has been confirmed so far.\nIn 2012 a candidate exomoon was detected around WASP-12b via periodic light variations in the planet's light curve. Subsequent observations found this object might actually be a trojan planet.\nIn December 2013, a candidate exomoon was detected in the microlensing event MOA-2011-BLG-262, it was believed to be either a exomoon around a Jupiter-sized free-floating planet or a Neptune-mass planet around a red dwarf, but follow-up observations confirmed the latter scenario. \nOn 3 October 2018, evidence suggesting a large exomoon orbiting Kepler-1625b was reported, and in 2021 evidence of an exomoon around Kepler-1708b was also reported. Their existence, however, remain doubtful, but follow-up observations may confirm these exomoons.\nThe detection of sodium in hot Jupiters such as WASP-76b, HD 189733 b or WASP-49b is likely due to a Io-like exomoon around these planets.\nAtmospheres.\nAtmospheres have been detected around several exoplanets. The first to be observed was HD 209458 b in 2001.\nAs of February 2014, more than fifty transiting and five directly imaged exoplanet atmospheres have been observed, resulting in detection of molecular spectral features; observation of day\u2013night temperature gradients; and constraints on vertical atmospheric structure. Also, an atmosphere has been detected on the non-transiting hot Jupiter Tau Bo\u00f6tis b.\nIn May 2017, glints of light from Earth, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere. The technology used to determine this may be useful in studying the atmospheres of distant worlds, including those of exoplanets.\nComet-like tails.\nKepler-1520b is a small rocky planet, very close to its star, that is evaporating and leaving a trailing tail of cloud and dust like a comet. The dust could be ash erupting from volcanos and escaping due to the small planet's low surface-gravity, or it could be from metals that are vaporized by the high temperatures of being so close to the star with the metal vapor then condensing into dust.\nIn June 2015, scientists reported that the atmosphere of GJ 436 b was evaporating, resulting in a giant cloud around the planet and, due to radiation from the host star, a long trailing tail long.\nInsolation pattern.\nTidally locked planets in a 1:1 spin-orbit resonance would have their star always shining directly overhead on one spot, which would be hot with the opposite hemisphere receiving no light and being freezing cold. Such a planet could resemble an eyeball, with the hotspot being the pupil. Planets with an eccentric orbit could be locked in other resonances. 3:2 and 5:2 resonances would result in a double-eyeball pattern with hotspots in both eastern and western hemispheres. Planets with both an eccentric orbit and a tilted axis of rotation would have more complicated insolation patterns.\nSurface.\nSurface composition.\nSurface features can be distinguished from atmospheric features by comparing emission and reflection spectroscopy with transmission spectroscopy. Mid-infrared spectroscopy of exoplanets may detect rocky surfaces, and near-infrared may identify magma oceans or high-temperature lavas, hydrated silicate surfaces and water ice, giving an unambiguous method to distinguish between rocky and gaseous exoplanets.\nSurface temperature.\nMeasuring the intensity of the light it receives from its parent star can estimate the temperature of an exoplanet. For example, the planet OGLE-2005-BLG-390Lb is estimated to have a surface temperature of roughly \u2212220\u00a0\u00b0C (50 K). However, such estimates may be substantially in error because they depend on the planet's usually unknown albedo, and because factors such as the greenhouse effect may introduce unknown complications. A few planets have had their temperature measured by observing the variation in infrared radiation as the planet moves around in its orbit and is eclipsed by its parent star. For example, the planet HD 189733b has been estimated to have an average temperature of 1,205 K (932\u00a0\u00b0C) on its dayside and 973 K (700\u00a0\u00b0C) on its nightside.\nHabitability.\nAs more planets are discovered, the field of exoplanetology continues to grow into a deeper study of extrasolar worlds, and will ultimately tackle the prospect of life on planets beyond the Solar System. At cosmic distances, life can only be detected if it is developed at a planetary scale and strongly modified the planetary environment, in such a way that the modifications cannot be explained by classical physico-chemical processes (out of equilibrium processes). For example, molecular oxygen () in the atmosphere of Earth is a result of photosynthesis by living plants and many kinds of microorganisms, so it can be used as an indication of life on exoplanets, although small amounts of oxygen could also be produced by non-biological means. Furthermore, a potentially habitable planet must orbit a stable star at a distance within which planetary-mass objects with sufficient atmospheric pressure can support liquid water at their surfaces.\nHabitable zone.\nThe habitable zone around a star is the region where the temperature is just right to allow liquid water to exist on the surface of a planet; that is, not too close to the star for the water to evaporate and not too far away from the star for the water to freeze. The heat produced by stars varies depending on the size and age of the star, so that the habitable zone can be at different distances for different stars. Also, the atmospheric conditions on the planet influence the planet's ability to retain heat so that the location of the habitable zone is also specific to each type of planet: desert planets (also known as dry planets), with very little water, will have less water vapor in the atmosphere than Earth and so have a reduced greenhouse effect, meaning that a desert planet could maintain oases of water closer to its star than Earth is to the Sun. The lack of water also means there is less ice to reflect heat into space, so the outer edge of desert-planet habitable zones is further out. Rocky planets with a thick hydrogen atmosphere could maintain surface water much further out than the Earth\u2013Sun distance. Planets with larger mass have wider habitable zones because gravity reduces the water cloud column depth which reduces the greenhouse effect of water vapor, thus moving the inner edge of the habitable zone closer to the star.\nPlanetary rotation rate is one of the major factors determining the circulation of the atmosphere and hence the pattern of clouds: slowly rotating planets create thick clouds that reflect more and so can be habitable much closer to their star. Earth with its current atmosphere would be habitable in Venus's orbit, if it had Venus's slow rotation. If Venus lost its water ocean due to a runaway greenhouse effect, it is likely to have had a higher rotation rate in the past. Alternatively, Venus never had an ocean because water vapor was lost to space during its formation and could have had its slow rotation throughout its history.\nTidally locked planets (a.k.a. \"eyeball\" planets) can be habitable closer to their star than previously thought due to the effect of clouds: at high stellar flux, strong convection produces thick water clouds near the substellar point that greatly increase the planetary albedo and reduce surface temperatures.\nPlanets in the habitable zones of stars with low metallicity are more habitable for complex life on land than high metallicity stars because the stellar spectrum of high metallicity stars is less likely to cause the formation of ozone thus enabling more ultraviolet rays to reach the planet's surface.\nHabitable zones have usually been defined in terms of surface temperature, however over half of Earth's biomass is from subsurface microbes, and the temperature increases with depth, so the subsurface can be conducive for microbial life when the surface is frozen and if this is considered, the habitable zone extends much further from the star, even rogue planets could have liquid water at sufficient depths underground. In an earlier era of the universe the temperature of the cosmic microwave background would have allowed any rocky planets that existed to have liquid water on their surface regardless of their distance from a star. Jupiter-like planets might not be habitable, but they could have habitable moons.\nIce ages and snowball states.\nThe outer edge of the habitable zone is where planets are completely frozen, but planets well inside the habitable zone can periodically become frozen. If orbital fluctuations or other causes produce cooling, then this creates more ice, but ice reflects sunlight causing even more cooling, creating a feedback loop until the planet is completely or nearly completely frozen. When the surface is frozen, this stops carbon dioxide weathering, resulting in a build-up of carbon dioxide in the atmosphere from volcanic emissions. This creates a greenhouse effect which thaws the planet again. Planets with a large axial tilt are less likely to enter snowball states and can retain liquid water further from their star. Large fluctuations of axial tilt can have even more of a warming effect than a fixed large tilt. Paradoxically, planets orbiting cooler stars, such as red dwarfs, are less likely to enter snowball states because the infrared radiation emitted by cooler stars is mostly at wavelengths that are absorbed by ice which heats it up.\nTidal heating.\nIf a planet has an eccentric orbit, then tidal heating can provide another source of energy besides stellar radiation. This means that eccentric planets in the radiative habitable zone can be too hot for liquid water. Tides also circularize orbits over time, so there could be planets in the habitable zone with circular orbits that have no water because they used to have eccentric orbits. Eccentric planets further out than the habitable zone would still have frozen surfaces, but the tidal heating could create a subsurface ocean similar to Europa's. In some planetary systems, such as in the Upsilon Andromedae system, the eccentricity of orbits is maintained or even periodically varied by perturbations from other planets in the system. Tidal heating can cause outgassing from the mantle, contributing to the formation and replenishment of an atmosphere.\nPotentially habitable planets.\nA review in 2015 identified exoplanets Kepler-62f, Kepler-186f and Kepler-442b as the best candidates for being potentially habitable. These are at a distance of 1200, 490 and 1,120 light-years away, respectively. Of these, Kepler-186f is in similar size to Earth with its 1.2-Earth-radius measure, and it is located towards the outer edge of the habitable zone around its red dwarf star.\nWhen looking at the nearest terrestrial exoplanet candidates, Proxima Centauri b is about 4.2 light-years away. Its equilibrium temperature is estimated to be .\nPlanetary system.\nExoplanets are often members of planetary systems of multiple planets around a star. The planets interact with each other gravitationally and sometimes form resonant systems where the orbital periods of the planets are in integer ratios. The Kepler-223 system contains four planets in an 8:6:4:3 orbital resonance.\nSome hot Jupiters orbit their stars in the opposite direction to their stars' rotation. One proposed explanation is that hot Jupiters tend to form in dense clusters, where perturbations are more common and gravitational capture of planets by neighboring stars is possible."}
{"id": "9764", "revid": "18916437", "url": "https://en.wikipedia.org/wiki?curid=9764", "title": "Emma Goldman", "text": "Emma Goldman (June 27, 1869 \u2013 May 14, 1940) was a Lithuanian-born anarchist revolutionary, political activist, and writer. She played a pivotal role in the development of anarchist political philosophy in North America and Europe in the first half of the 20th century.\nBorn in Kaunas, Lithuania (then within the Russian Empire), to an Orthodox Lithuanian Jewish family, Goldman immigrated to the United States in 1885. Attracted to anarchism after the Chicago Haymarket affair, Goldman became a writer and a renowned lecturer on anarchist philosophy, women's rights, and social issues, attracting crowds of thousands. She and anarchist writer Alexander Berkman, her lover and lifelong friend, planned to assassinate industrialist and financier Henry Clay Frick as an act of propaganda of the deed. Frick survived the attempt on his life in 1892, and Berkman was sentenced to 22 years in prison. Goldman was imprisoned several times in the years that followed, for \"inciting to riot\" and illegally distributing information about birth control. In 1906, Goldman founded the anarchist journal \"Mother Earth\".\nIn 1917, Goldman and Berkman were sentenced to two years in jail for conspiring to \"induce persons not to register\" for the newly instated draft. After their release from prison, they were arrested\u2014along with 248 others\u2014in the so-called Palmer Raids during the First Red Scare and deported to Russia in December 1919. Initially supportive of that country's October Revolution that brought the Bolsheviks to power, Goldman changed her opinion in the wake of the Kronstadt rebellion; she denounced the Soviet Union for its violent repression of independent voices. She left the Soviet Union and in 1923 published a book about her experiences, \"My Disillusionment in Russia\". While living in England, Canada, and France, she wrote an autobiography called \"Living My Life\". It was published in two volumes, in 1931 and 1935. After the outbreak of the Spanish Civil War, Goldman traveled to Spain to support the anarchist revolution there. She died in Toronto, Ontario, Canada, in 1940, aged 70.\nDuring her life, Goldman was lionized as a freethinking \"rebel woman\" by admirers, and denounced by detractors as an advocate of politically motivated murder and violent revolution. Her writing and lectures spanned a wide variety of issues, including prisons, atheism, freedom of speech, militarism, capitalism, marriage, free love, and homosexuality. Although she distanced herself from first-wave feminism and its efforts toward women's suffrage, she developed new ways of incorporating gender politics into anarchism. After decades of obscurity, Goldman gained iconic status in the 1970s by a revival of interest in her life, when feminist and anarchist scholars rekindled popular interest.\nBiography.\nFamily.\nEmma Goldman was born into an Orthodox Jewish family in Kaunas in Lithuania, then within the Russian Empire. Goldman's mother Taube Bienowitch had been married before to a man with whom she had two daughters\u2014Helena in 1860 and Lena in 1862. When her first husband died of tuberculosis, Taube was devastated. Goldman later wrote: \"Whatever love she had had died with the young man to whom she had been married at the age of fifteen.\"\nTaube's second marriage was arranged by her family and, as Goldman puts it, \"mismated from the first\". Her second husband, Abraham Goldman, invested Taube's inheritance in a business that quickly failed. The ensuing hardship, combined with the emotional distance between husband and wife, made the household a tense place for the children. When Taube became pregnant, Abraham hoped desperately for a son; a daughter, he believed, would be one more sign of failure. They eventually had three sons, but their first child was Emma.\nEmma Goldman was born on June 27, 1869. Her father used violence to punish his children, beating them when they disobeyed him. He used a whip on Emma, the most rebellious of them. Her mother provided scarce comfort, rarely calling on Abraham to tone down his beatings. Goldman later speculated that her father's furious temper was at least partly a result of sexual frustration.\nGoldman's relationships with her elder half-sisters, Helena and Lena, were a study in contrasts. Helena, the oldest, provided the comfort the children lacked from their mother and filled Goldman's childhood with \"whatever joy it had\". Lena, however, was distant and uncharitable. The three sisters were joined by brothers Louis (who died at the age of six), Herman (born in 1872), and Moishe (born in 1879).\nAdolescence.\nWhen Emma Goldman was a young girl, the Goldman family moved to the village of Papil\u0117, where her father ran an inn. While her sisters worked, she became friends with a servant named Petrushka, who excited her \"first erotic sensations\". Later in Papil\u0117 she witnessed a peasant being whipped with a knout in the street. This event traumatized her and contributed to her lifelong distaste for violent authority.\nAt the age of seven, Goldman moved with her family to the Prussian city of K\u00f6nigsberg (then part of the German Empire), and she was enrolled in a \"Realschule\". One teacher punished disobedient students\u2014targeting Goldman in particular\u2014by beating their hands with a ruler. Another teacher tried to molest his female students and was fired when Goldman fought back. She found a sympathetic mentor in her German-language teacher, who loaned her books and took her to an opera. A passionate student, Goldman passed the exam for admission into a gymnasium, but her religion teacher refused to provide a certificate of good behavior and she was unable to attend.\nThe family moved to the Russian capital of Saint Petersburg, where her father opened one unsuccessful store after another. Their poverty forced the children to work, and Goldman took an assortment of jobs, including one in a corset shop. As a teenager Goldman begged her father to allow her to return to school, but instead he threw her French book into the fire and shouted: \"Girls do not have to learn much! All a Jewish daughter needs to know is how to prepare gefilte fish, cut noodles fine, and give the man plenty of children.\"\nGoldman pursued an independent education on her own. She studied the political turmoil around her, particularly the Nihilists responsible for assassinating Alexander II of Russia. The ensuing turmoil intrigued Goldman, although she did not fully understand it at the time. When she read Nikolai Chernyshevsky's novel, \"What Is to Be Done?\" (1863), she found a role model in the protagonist Vera, who adopts a Nihilist philosophy and escapes her repressive family to live freely and organize a sewing cooperative. The book enthralled Goldman and remained a source of inspiration throughout her life.\nHer father, meanwhile, continued to insist on a domestic future for her, and he tried to arrange for her to be married at the age of fifteen. They fought about the issue constantly; he complained that she was becoming a \"loose\" woman, and she insisted that she would marry for love alone. At the corset shop, she was forced to fend off unwelcome advances from Russian officers and other men. One man took her into a hotel room and committed what Goldman described as \"violent contact\"; two biographers call it rape. She was stunned by the experience, overcome by \"shock at the discovery that the contact between man and woman could be so brutal and painful.\" Goldman felt that the encounter forever soured her interactions with men.\nRochester, New York.\nIn 1885, her sister Helena made plans to move to New York in the United States to join her sister Lena and her husband. Goldman wanted to join her sister, but their father refused to allow it. Despite Helena's offer to pay for the trip, Abraham turned a deaf ear to their pleas. Desperate, Goldman threatened to throw herself into the Neva River if she could not go. Their father finally agreed. On December 29, 1885, Helena and Emma arrived at New York City's Castle Garden, the entry for immigrants.\nThey settled upstate, living in the Rochester home which Lena had made with her husband Samuel. Fleeing the rising antisemitism of Saint Petersburg, their parents and brothers joined them a year later. Goldman began working as a seamstress, sewing overcoats for more than ten hours a day, earning two and a half dollars a week. She asked for a raise and was denied; she quit and took work at a smaller shop nearby.\nAt her new job, Goldman met a fellow worker named Jacob Kershner, who shared her love for books, dancing, and traveling, as well as her frustration with the monotony of factory work. After four months, they married in February 1887. Once he moved in with Goldman's family, their relationship faltered. On their wedding night she discovered that he was impotent; they became emotionally and physically distant. Before long he became jealous and suspicious and threatened to commit suicide should she leave him. Meanwhile, Goldman was becoming more engaged with the political turmoil around her, particularly the aftermath of executions related to the 1886 Haymarket affair in Chicago and the anti-authoritarian political philosophy of anarchism.\nLess than a year after the wedding, the couple were divorced; Kershner begged Goldman to return and threatened to poison himself if she did not. They reunited, but after three months she left once again. Her parents considered her behavior \"loose\" and refused to allow Goldman into their home. Carrying her sewing machine in one hand and a bag with five dollars in the other, she left Rochester and headed southeast to New York City.\nMost and Berkman.\nOn her first day in New York City, Goldman met two men who would have a significant and enduring influence on the course of her life. At Sachs' Caf\u00e9, a gathering place for radicals, she was introduced to Alexander Berkman, an anarchist who invited her to a public speech that evening. They went to hear Johann Most, editor of a radical publication called \"Freiheit\" and an advocate of \"propaganda of the deed\"\u2014the use of violence to instigate change. She was impressed by his fiery oration, and Most took her under his wing, training her in methods of public speaking. He encouraged her vigorously, telling her that she was \"to take my place when I am gone.\" One of her first public talks in support of \"the Cause\" was in Rochester. After convincing Helena not to tell their parents of her speech, Goldman found her mind a blank once on stage. She later wrote, suddenly:\nExcited by the experience, Goldman refined her public persona during subsequent engagements. She quickly found herself arguing with Most over her independence. After a momentous speech in Cleveland, she felt as though she had become \"a parrot repeating Most's views\" and resolved to express herself on the stage. When she returned to New York, Most became furious and told her: \"Who is not with me is against me!\" She left \"Freiheit\" and joined another publication, \"Die Autonomie\".\nMeanwhile, Goldman had begun a friendship with Berkman, whom she affectionately called Sasha. Before long they became lovers and moved into a communal apartment with his cousin Modest \"Fedya\" Stein and Goldman's friend, Helen Minkin, on 42nd Street. Although their relationship had numerous difficulties, Goldman and Berkman would share a close bond for decades, united by their anarchist principles and commitment to personal equality.\nIn 1892, Goldman joined with Berkman and Stein in opening an ice cream shop in Worcester, Massachusetts. After a few months of operating the shop, Goldman and Berkman were diverted to participate in the Homestead Strike near Pittsburgh.\nHomestead plot.\nBerkman and Goldman came together through the Homestead Strike. In June 1892, a steel plant in Homestead, Pennsylvania, owned by Andrew Carnegie became the focus of national attention when talks between the Carnegie Steel Company and the Amalgamated Association of Iron and Steel Workers (AA) broke down. The factory's manager was Henry Clay Frick, a fierce opponent of the union. When a final round of talks failed at the end of June, management closed the plant and locked out the workers, who immediately went on strike. Strikebreakers were brought in and the company hired Pinkerton guards to protect them. On July 6, a fight broke out between 300 Pinkerton guards and a crowd of armed union workers. During the twelve-hour gunfight, seven guards and nine strikers were killed.\nWhen a majority of the nation's newspapers expressed support of the strikers, Goldman and Berkman resolved to assassinate Frick, an action they expected would inspire the workers to revolt against the capitalist system. Berkman chose to carry out the assassination and ordered Goldman to stay behind in order to explain his motives after he went to jail. He would be in charge of \"the deed\"; she of the associated propaganda. Berkman set off for Pittsburgh on his way to Homestead, where he planned to shoot Frick.\nGoldman, meanwhile, decided to help fund the scheme through prostitution. Remembering the character of Sonya in Fyodor Dostoevsky's novel \"Crime and Punishment\" (1866), she mused: \"She had become a prostitute in order to support her little brothers and sisters...Sensitive Sonya could sell her body; why not I?\" Once on the street, Goldman caught the eye of a man who took her into a saloon, bought her a beer, gave her ten dollars, informed her she did not have \"the knack,\" and told her to quit the business. She was \"too astounded for speech\". She wrote to Helena, claiming illness, and asked her for fifteen dollars.\nOn July 23, Berkman gained access to Frick's office while carrying a concealed handgun; he shot Frick three times, and stabbed him in the leg. A group of workers\u2014far from joining in his \"attentat\"\u2014beat Berkman unconscious, and he was carried away by the police. Berkman was convicted of attempted murder and sentenced to 22 years in prison. Goldman suffered during his long absence.\nConvinced Goldman was involved in the plot, police raided her apartment. Although they found no evidence, they pressured her landlord into evicting her. Furthermore, the \"attentat\" had failed to rouse the masses: workers and anarchists alike condemned Berkman's action. Johann Most, their former mentor, lashed out at Berkman and the assassination attempt. Furious at these attacks, Goldman brought a toy horsewhip to a public lecture and demanded, onstage, that Most explain his betrayal. He dismissed her, whereupon she struck him with the whip, broke it on her knee, and hurled the pieces at him. She later regretted her assault, confiding to a friend: \"At the age of twenty-three, one does not reason.\"\n\"Inciting to riot\".\nWhen the Panic of 1893 struck in the following year, the United States suffered one of its worst economic crises. By year's end, the unemployment rate was higher than 20%, and \"hunger demonstrations\" sometimes gave way to riots. Goldman began speaking to crowds of frustrated men and women in New York City. On August 21, she spoke to a crowd of nearly 3,000 people in Union Square, where she encouraged unemployed workers to take immediate action. Her exact words are unclear: undercover agents insist she ordered the crowd to \"take everything\u00a0...\u00a0by force\". But Goldman later recounted this message: \"Well then, demonstrate before the palaces of the rich; demand work. If they do not give you work, demand bread. If they deny you both, take bread.\" Later in court, Detective-Sergeant Charles Jacobs offered yet another version of her speech.\nA week later, Goldman was arrested in Philadelphia and returned to New York City for trial, charged with \"inciting to riot\". During the train ride, Jacobs offered to drop the charges against her if she would inform on other radicals in the area. She responded by throwing a glass of ice water in his face. As she awaited trial, Goldman was visited by Nellie Bly, a reporter for the \"New York World.\" She spent two hours talking to Goldman and wrote a positive article about the woman she described as a \"modern Joan of Arc.\"\nDespite this positive publicity, the jury was persuaded by Jacobs' testimony and frightened by Goldman's politics. The assistant district attorney questioned Goldman about her anarchism, as well as her atheism; the judge spoke of her as \"a dangerous woman\". She was sentenced to one year in the Blackwell's Island Penitentiary. Once inside, she suffered an attack of rheumatism and was sent to the infirmary. There, she befriended a visiting doctor and received informal training in nursing, eventually being placed in charge of a 16-bed women's ward in the infirmary. She also read dozens of books, including works by the American activist-writers Ralph Waldo Emerson and Henry David Thoreau; novelist Nathaniel Hawthorne; poet Walt Whitman, and philosopher John Stuart Mill. When Goldman was released after ten months, a raucous crowd of nearly 3,000 people greeted her at the Thalia Theater in New York City. She soon became swamped with requests for interviews and lectures.\nTo make money, Goldman decided to continue the medical studies she had started in prison, but her preferred fields of specialization\u2014midwifery and massage\u2014were unavailable to nursing students in the US. She sailed to Europe, lecturing in London, Glasgow, and Edinburgh. She met with renowned anarchists such as Errico Malatesta, Louise Michel, and Peter Kropotkin. In Vienna, she received two diplomas for midwifery and put them immediately to use back in the US.\nAlternating between lectures and midwifery, Goldman conducted the first cross-country tour by an anarchist speaker. In November 1899, she returned to Europe to speak, where she met the Czech anarchist Hippolyte Havel in London. They went together to France and helped organize the 1900 International Anarchist Congress on the outskirts of Paris. Afterward, Havel immigrated to the United States, traveling with Goldman to Chicago. They shared a residence there with friends of Goldman.\nMcKinley assassination.\nOn September 6, 1901, Leon Czolgosz, an unemployed factory worker and anarchist, shot US President William McKinley twice during a public speaking event in Buffalo, New York. McKinley was hit in the breastbone and stomach, and died eight days later. Czolgosz was arrested, and interrogated around the clock. During interrogation he claimed to be an anarchist and said he had been inspired to act after attending a speech by Goldman. The authorities used this as a pretext to charge Goldman with planning McKinley's assassination. They tracked her to the residence in Chicago she shared with Havel, as well as with Mary and Abe Isaak, an anarchist couple and their family. Goldman was arrested, along with Isaak, Havel, and ten other anarchists.\nEarlier, Czolgosz had tried but failed to become friends with Goldman and her companions. During a talk in Cleveland, Czolgosz had approached Goldman and asked her advice on which books he should read. In July 1901, he had appeared at the Isaak house, asking a series of unusual questions. They assumed he was an infiltrator, like a number of police agents sent to spy on radical groups. They had remained distant from him, and Abe Isaak sent a notice to associates warning of \"another spy\".\nAlthough Czolgosz repeatedly denied Goldman's involvement, the police held her in close custody, subjecting her to what she called the \"third degree\" (intense interrogation by police). She explained her housemates' distrust of Czolgosz, and the police finally recognized that she had not had any significant contact with the attacker. No evidence was found linking Goldman to the attack, and she was released after two weeks of detention. Before McKinley died, Goldman offered to provide nursing care, referring to him as \"merely a human being\". Czolgosz, despite considerable evidence of mental illness, was convicted of murder and executed.\nThroughout her detention and after her release, Goldman steadfastly refused to condemn Czolgosz's actions, standing virtually alone in doing so. Friends and supporters\u2014including Berkman\u2014urged her to quit his cause. But Goldman defended Czolgosz as a \"supersensitive being\" and chastised other anarchists for abandoning him. She was vilified in the press as the \"high priestess of anarchy\", while many newspapers declared the anarchist movement responsible for the murder. In the wake of these events, socialism gained support over anarchism among US radicals. McKinley's successor, Theodore Roosevelt, declared his intent to crack down \"not only against anarchists, but against all active and passive sympathizers with anarchists\".\n\"Mother Earth\" and Berkman's release.\nAfter Czolgosz was executed, Goldman withdrew from society and, from 1903 to 1913, lived at 208\u2013210 East 13th Street, New York City. Scorned by her fellow anarchists, vilified by the press, and separated from her love, Berkman, she retreated into anonymity and nursing. \"It was bitter and hard to face life anew,\" she wrote later.\nUsing the name E. G. Smith, she left public life and took on a series of private nursing jobs while suffering from severe depression. The US Congress' passage of the Anarchist Exclusion Act (1903) stirred a new wave of oppositional activism, pulling Goldman back into the movement. A coalition of people and organizations across the left end of the political spectrum opposed the law on grounds that it violated freedom of speech, and she had the nation's ear once again.\nAfter an English anarchist named John Turner was arrested under the Anarchist Exclusion Act and threatened with deportation, Goldman joined forces with the Free Speech League to champion his cause. The league enlisted the aid of noted attorneys Clarence Darrow and Edgar Lee Masters, who took Turner's case to the US Supreme Court. Although Turner and the League lost, Goldman considered it a victory of propaganda. She had returned to anarchist activism, but it was taking its toll on her. \"I never felt so weighed down,\" she wrote to Berkman. \"I fear I am forever doomed to remain public property and to have my life worn out through the care for the lives of others.\"\nIn 1906, Goldman decided to start a publication, \"a place of expression for the young idealists in arts and letters\". \"Mother Earth\" was staffed by a cadre of radical activists, including Hippolyte Havel, Max Baginski, and Leonard Abbott. In addition to publishing original works by its editors and anarchists around the world, \"Mother Earth\" reprinted selections from a variety of writers. These included the French philosopher Pierre-Joseph Proudhon, Russian anarchist Peter Kropotkin, German philosopher Friedrich Nietzsche, and British writer Mary Wollstonecraft. Goldman wrote frequently about anarchism, politics, labor issues, atheism, sexuality, and feminism, and was the first editor of the magazine.\nOn May 18 of the same year, Alexander Berkman was released from prison. Carrying a bouquet of roses, Goldman met him on the train platform and found herself \"seized by terror and pity\" as she beheld his gaunt, pale form. Neither was able to speak; they returned to her home in silence. For weeks, he struggled to readjust to life on the outside: An abortive speaking tour ended in failure, and in Cleveland he purchased a revolver with the intent of killing himself. Upon returning to New York, he learned that Goldman had been arrested with a group of activists meeting to reflect on Czolgosz. Invigorated anew by this violation of freedom of assembly, he declared, \"My resurrection has come!\" and set about securing their release.\nBerkman took the helm of \"Mother Earth\" in 1907, while Goldman toured the country to raise funds to keep it operating. Editing the magazine was a revitalizing experience for Berkman. But his relationship with Goldman faltered, and he had an affair with a 15-year-old anarchist named Becky Edelsohn. Goldman was pained by his rejection of her but considered it a consequence of his prison experience. Later that year she served as a delegate from the US to the International Anarchist Congress of Amsterdam. Anarchists and syndicalists from around the world gathered to sort out the tension between the two ideologies, but no decisive agreement was reached. Goldman returned to the US and continued speaking to large audiences.\nReitman, essays, and birth control.\nFor the next ten years, Goldman traveled around the country nonstop, delivering lectures and agitating for anarchism. The coalitions formed in opposition to the Anarchist Exclusion Act had given her an appreciation for reaching out to those of other political positions. When the US Justice Department sent spies to observe, they reported the meetings as \"packed\". Writers, journalists, artists, judges, and workers from across the spectrum spoke of her \"magnetic power\", her \"convincing presence\", her \"force, eloquence, and fire\".\nIn the spring of 1908, Goldman met and fell in love with Ben Reitman, the so-called \"Hobo doctor\". Having grown up in Chicago's Tenderloin District, Reitman spent several years as a drifter before earning a medical degree from the College of Physicians and Surgeons of Chicago. As a doctor, he treated people suffering from poverty and illness, particularly venereal diseases. He and Goldman began an affair. They shared a commitment to free love and Reitman took a variety of lovers, but Goldman did not. She tried to reconcile her feelings of jealousy with a belief in freedom of the heart but found it difficult.\nTwo years later, Goldman began feeling frustrated with lecture audiences. She yearned to \"reach the few who really want to learn, rather than the many who come to be amused\". She collected a series of speeches and items she had written for \"Mother Earth\" and published a book titled \"Anarchism and Other Essays.\" Covering a wide variety of topics, Goldman tried to represent \"the mental and soul struggles of twenty-one years\".\nWhen Margaret Sanger, an advocate of access to contraception, coined the term \"birth control\" and disseminated information about various methods in the June 1914 issue of her magazine \"The Woman Rebel,\" she received aggressive support from Goldman. The latter had already been active in efforts to increase birth control access for several years. In 1916, Goldman was arrested for giving lessons in public on how to use contraceptives. Sanger, too, was arrested under the Comstock Law, which prohibited the dissemination of \"obscene, lewd, or lascivious articles\", which authorities defined as including information relating to birth control.\nAlthough they later split from Sanger over charges of insufficient support, Goldman and Reitman distributed copies of Sanger's pamphlet \"Family Limitation\" (along with a similar essay of Reitman's). In 1915 Goldman conducted a nationwide speaking tour, in part to raise awareness about contraception options. Although the nation's attitude toward the topic seemed to be liberalizing, Goldman was arrested on February 11, 1916, as she was about to give another public lecture. Goldman was charged with violating the Comstock Law. Refusing to pay a $100 fine, she spent two weeks in a prison workhouse, which she saw as an \"opportunity\" to reconnect with those rejected by society.\nWorld War I.\nAlthough President Woodrow Wilson was re-elected in 1916 under the slogan \"He kept us out of the war\", at the start of his second term, he announced that Germany's continued deployment of unrestricted submarine warfare was sufficient cause for the US to enter the Great War. Shortly afterward, Congress passed the Selective Service Act of 1917, which required all males aged 21\u201330 to register for military conscription. Goldman saw the decision as an exercise in militarist aggression, driven by capitalism. She declared in \"Mother Earth\" her intent to resist conscription, and to oppose US involvement in the war.\nTo this end, she and Berkman organized the No Conscription League of New York, which proclaimed: \"We oppose conscription because we are internationalists, antimilitarists, and opposed to all wars waged by capitalistic governments.\" The group became a vanguard for anti-draft activism, and chapters began to appear in other cities. When police began raiding the group's public events to find young men who had not registered for the draft, Goldman and others focused their efforts on distributing pamphlets and other writings. In the midst of the nation's patriotic fervor, many elements of the political left refused to support the League's efforts. The Women's Peace Party, for example, ceased its opposition to the war once the US entered it. The Socialist Party of America took an official stance against US involvement but supported Wilson in most of his activities.\nOn June 15, 1917, Goldman and Berkman were arrested during a raid of their offices, in which authorities seized \"a wagon load of anarchist records and propaganda\". \"The New York Times\" reported that Goldman asked to change into a more appropriate outfit, and emerged in a gown of \"royal purple\". The pair were charged with conspiracy to \"induce persons not to register\" under the newly enacted Espionage Act, and were held on US$25,000 bail each. Defending herself and Berkman during their trial, Goldman invoked the First Amendment, asking how the government could claim to fight for democracy abroad while suppressing free speech at home:\nWe say that if America has entered the war to make the world safe for democracy, she must first make democracy safe in America. How else is the world to take America seriously, when democracy at home is daily being outraged, free speech suppressed, peaceable assemblies broken up by overbearing and brutal gangsters in uniform; when free press is curtailed and every independent opinion gagged? Verily, poor as we are in democracy, how can we give of it to the world? \nThe jury found Goldman and Berkman guilty. Judge Julius Marshuetz Mayer imposed the maximum sentence: two years' imprisonment, a $10,000 fine each, and the possibility of deportation after their release from prison. As she was transported to Missouri State Penitentiary, Goldman wrote to a friend: \"Two years imprisonment for having made an uncompromising stand for one's ideal. Why that is a small price.\"\nIn prison, she was assigned to work as a seamstress, under the eye of a \"miserable gutter-snipe of a 21-year-old boy paid to get results\". She met the socialist Kate Richards O'Hare, who had also been imprisoned under the Espionage Act. Although they differed on political strategy\u2014O'Hare believed in voting to achieve state power\u2014the two women came together to agitate for better conditions among prisoners. Goldman also met and became friends with Gabriella Segata Antolini, an anarchist and follower of Luigi Galleani. Antolini had been arrested transporting a satchel filled with dynamite on a Chicago-bound train. She had refused to cooperate with authorities and was sent to prison for 14 months. Working together to make life better for the other inmates, the three women became known as \"The Trinity\". Goldman was released on September 27, 1919.\nDeportation.\nGoldman and Berkman were released from prison during the United States' Red Scare of 1919\u201320, when public anxiety about wartime pro-German activities had expanded into a pervasive fear of Bolshevism and the prospect of an imminent radical revolution. It was a time of social unrest due to union organizing strikes and actions by activist immigrants. Attorney General Alexander Mitchell Palmer and J. Edgar Hoover, head of the US Department of Justice's General Intelligence Division (now the FBI), were intent on using the Anarchist Exclusion Act and its 1918 expansion to deport any non-citizens they could identify as advocates of anarchy or revolution. \"Emma Goldman and Alexander Berkman,\" Hoover wrote while they were in prison, \"are, beyond doubt, two of the most dangerous anarchists in this country and return to the community will result in undue harm.\"\nAt her deportation hearing on October 27, 1919, Goldman refused to answer questions about her beliefs, on the grounds that her American citizenship invalidated any attempt to deport her under the Anarchist Exclusion Act, which could be enforced only against non-citizens of the US. She presented a written statement instead: \"Today so-called aliens are deported. Tomorrow native Americans will be banished. Already some patrioteers are suggesting that native American sons to whom democracy is a sacred ideal should be exiled.\" Louis Post at the Department of Labor, which had ultimate authority over deportation decisions, determined that the revocation of her husband Kershner's American citizenship in 1908 after his conviction had revoked hers as well. After initially promising a court fight, Goldman decided not to appeal his ruling.\nThe Labor Department included Goldman and Berkman among 249 aliens it deported \"en masse,\" mostly people with only vague associations with radical groups, who had been swept up in government raids in November. \"Buford\", a ship the press nicknamed the \"Soviet Ark\", sailed from the Army's New York Port of Embarkation on December 21. Some 58 enlisted men and four officers provided security on the journey, and pistols were distributed to the crew. Most of the press approved enthusiastically. The Cleveland \"Plain Dealer\" wrote: \"It is hoped and expected that other vessels, larger, more commodious, carrying similar cargoes, will follow in her wake.\" The ship landed her charges in Hanko, Finland, on Saturday, January 17, 1920. Upon arrival in Finland, authorities there conducted the deportees to the Russian frontier under a flag of truce.\nRussia.\nGoldman initially viewed the Bolshevik revolution in a positive light. She wrote in \"Mother Earth\" that despite its dependence on Communist government, it represented \"the most fundamental, far-reaching and all-embracing principles of human freedom and of economic well-being\". By the time she neared Europe, she expressed fears about what was to come. She was worried about the ongoing Russian Civil War and the possibility of being seized by anti-Bolshevik forces. The state, anti-capitalist though it was, also posed a threat. \"I could never in my life work within the confines of the State,\" she wrote to her niece, \"Bolshevist or otherwise.\"\nShe quickly discovered that her fears were justified. Days after returning to Petrograd (Saint Petersburg), she was shocked to hear a party official refer to free speech as a \"bourgeois superstition\". As she and Berkman traveled around the country, they found repression, mismanagement, and corruption instead of the equality and worker empowerment they had dreamed of. Those who questioned the government were demonized as counter-revolutionaries, and workers labored under severe conditions. They met with Vladimir Lenin, who assured them that government suppression of press liberties was justified. He told them: \"There can be no free speech in a revolutionary period.\" Berkman was more willing to forgive the government's actions in the name of \"historical necessity\", but he eventually joined Goldman in opposing the Soviet state's authority.\nIn March 1921, strikes erupted in Petrograd when workers took to the streets demanding better food rations and more union autonomy. Goldman and Berkman felt a responsibility to support the strikers, stating: \"To remain silent now is impossible, even criminal.\" The unrest spread to the port town of Kronstadt, where the government ordered a military response to suppress striking soldiers and sailors. In the Kronstadt rebellion, approximately 1,000 rebelling sailors and soldiers were killed and two thousand more were arrested; many were later executed. In the wake of these events, Goldman and Berkman decided there was no future in the country for them. \"More and more\", she wrote, \"we have come to the conclusion that we can do nothing here. And as we can not keep up a life of inactivity much longer we have decided to leave.\"\nIn December 1921, they left the country and went to the Latvian capital city of Riga. The US commissioner in that city wired officials in Washington DC, who began requesting information from other governments about the couple's activities. After a short trip to Stockholm, they moved to Berlin for several years; during this time Goldman agreed to write a series of articles about her time in Russia for Joseph Pulitzer's newspaper, the \"New York World.\" These were later collected and published in book form as \"My Disillusionment in Russia\" (1923) and \"My Further Disillusionment in Russia\" (1924). The publishers added these titles to attract attention; Goldman protested, albeit in vain.\nEngland, Canada, and France.\nGoldman found it difficult to acclimate to the German leftist community in Berlin. Communists despised her outspokenness about Soviet repression; liberals derided her radicalism. While Berkman remained in Berlin helping Russian exiles, Goldman moved to London in September 1924. Upon her arrival, the novelist Rebecca West arranged a reception dinner for her, attended by philosopher Bertrand Russell, novelist H. G. Wells, and more than 200 other guests. When she spoke of her dissatisfaction with the Soviet government, the audience was shocked. Some left the gathering; others berated her for prematurely criticizing the Communist experiment. Later, in a letter, Russell declined to support her efforts at systemic change in the Soviet Union and ridiculed her anarchist idealism.\nIn 1925, the spectre of deportation loomed again, but James Colton, a Scottish anarchist Goldman had first met in Glasgow whilst on a speaking tour in 1895, had offered to marry her and provide British citizenship. Although they were only distant acquaintances, she accepted and they were married on June 27, 1925, Goldman's 58th birthday. Her new status gave her peace of mind and allowed her to travel to France and Canada. The pair sporadically exchanged correspondence until Colton's death in 1936. Life in London was stressful for Goldman; she wrote to Berkman: \"I am awfully tired and so lonely and heartsick. It is a dreadful feeling to come back here from lectures and find not a kindred soul, no one who cares whether one is dead or alive.\" She worked on analytical studies of drama, expanding on the work she had published in 1914. But the audiences were \"awful,\" and she never finished her second book on the subject.\nGoldman traveled to Canada in 1927, just in time to receive news of the impending executions of Italian anarchists Nicola Sacco and Bartolomeo Vanzetti in Boston. Angered by the many irregularities of the case, she saw it as another travesty of justice in the US. She longed to join the mass demonstrations in Boston; memories of the Haymarket affair overwhelmed her, compounded by her isolation. \"Then,\" she wrote, \"I had my life before me to take up the cause for those killed. Now I have nothing.\"\nIn 1928, she began writing her autobiography, with the support of a group of American admirers, including journalist H. L. Mencken, poet Edna St. Vincent Millay, novelist Theodore Dreiser and art collector Peggy Guggenheim, who raised $4,000 for her. She secured a cottage in the French coastal city of Saint-Tropez and spent two years recounting her life. Berkman offered sharply critical feedback, which she eventually incorporated at the price of a strain on their relationship. Goldman intended the book, \"Living My Life,\" as a single volume for a price the working class could afford (she urged no more than $5.00); her publisher Alfred A. Knopf released it as two volumes sold together for $7.50. Goldman was furious, but unable to force a change. Due in large part to the Great Depression, sales were sluggish despite keen interest from libraries around the US. Critical reviews were generally enthusiastic; \"The New York Times\", \"The New Yorker\", and \"Saturday Review of Literature\" all listed it as one of the year's top non-fiction books.\nIn 1933, Goldman received permission to lecture in the United States under the condition that she speak only about drama and her autobiography\u2014but not current political events. She returned to New York on February 2, 1934, to generally positive press coverage\u2014except from Communist publications. Soon she was surrounded by admirers and friends, besieged with invitations to talks and interviews. Her visa expired in May, and she went to Toronto in order to file another request to visit the US. This second attempt was denied. She stayed in Canada, writing articles for US publications.\nIn February and March 1936, Berkman underwent a pair of prostate gland operations. Recuperating in Nice and cared for by his companion, Emmy Eckstein, he missed Goldman's sixty-seventh birthday in Saint-Tropez in June. She wrote in sadness, but he never read the letter; she received a call in the middle of the night that Berkman was in great distress. She left for Nice immediately but when she arrived that morning, Goldman found that he had shot himself and was in a nearly comatose paralysis. He died later that evening.\nSpanish Civil War.\nIn July 1936, the Spanish Civil War started after an attempted \"coup d'\u00e9tat\" by parts of the Spanish Army against the government of the Second Spanish Republic. At the same time, the Spanish anarchists, fighting against the Nationalist forces, started an anarchist revolution. Goldman was invited to Barcelona and in an instant, as she wrote to her niece, \"the crushing weight that was pressing down on my heart since Sasha's death left me as by magic\". She was welcomed by the Confederaci\u00f3n Nacional del Trabajo (CNT) and Federaci\u00f3n Anarquista Ib\u00e9rica (FAI) organizations, and for the first time in her life lived in a community run by and for anarchists, according to true anarchist principles. \"In all my life\", she wrote later, \"I have not met with such warm hospitality, comradeship and solidarity.\" After touring a series of collectives in the province of Huesca, she told a group of workers: \"Your revolution will destroy forever [the notion] that anarchism stands for chaos.\" She began editing the weekly \"CNT-FAI Information Bulletin\" and responded to English-language mail.\nGoldman began to worry about the future of Spain's anarchism when the CNT-FAI joined a coalition government in 1937\u2014against the core anarchist principle of abstaining from state structures\u2014and, more distressingly, made repeated concessions to Communist forces in the name of uniting against fascism. In November 1936, she wrote that cooperating with Communists in Spain was \"a denial of our comrades in Stalin's concentration camps\". The USSR, meanwhile, refused to send weapons to anarchist forces, and disinformation campaigns were being waged against the anarchists across Europe and the US. Her faith in the movement unshaken, Goldman returned to London as an official representative of the CNT-FAI.\nDelivering lectures and giving interviews, Goldman enthusiastically supported the Spanish anarcho-syndicalists. She wrote regularly for \"Spain and the World\", a biweekly newspaper focusing on the civil war. In May 1937, Communist-led forces attacked anarchist strongholds and broke up agrarian collectives. Newspapers in England and elsewhere accepted the timeline of events offered by the Second Spanish Republic at face value. British journalist George Orwell, present for the crackdown, wrote: \"[T]he accounts of the Barcelona riots in May\u00a0...\u00a0beat everything I have ever seen for lying.\"\nGoldman returned to Spain in September, but the CNT-FAI appeared to her like people \"in a burning house\". Worse, anarchists and other radicals around the world refused to support their cause. The Nationalist forces declared victory in Spain just before she returned to London. Frustrated by England's repressive atmosphere\u2014which she called \"more fascist than the fascists\"\u2014she returned to Canada in 1939. Her service to the anarchist cause in Spain was not forgotten. On her seventieth birthday, the former Secretary-General of the CNT, Mariano R. V\u00e1zquez, sent a message to her from Paris, praising her for her contributions and naming her as \"our spiritual mother\". She called it \"the most beautiful tribute I have ever received\".\nFinal years.\nAs the events preceding World War II began to unfold in Europe, Goldman reiterated her opposition to wars waged by governments. \"[M]uch as I loathe Hitler, Mussolini, Stalin and Franco\", she wrote to a friend, \"I would not support a war against them and for the democracies which, in the last analysis, are only Fascist in disguise.\" She felt that Britain and France had missed their opportunity to oppose fascism, and that the coming war would only result in \"a new form of madness in the world\".\nDeath.\nOn Saturday, February 17, 1940, Goldman suffered a debilitating stroke. She became paralyzed on her right side, and although her hearing was unaffected, she could not speak. As one friend described it: \"Just to think that here was Emma, the greatest orator in America, unable to utter one word.\" For three months she improved slightly, receiving visitors and on one occasion gesturing to her address book to signal that a friend might find friendly contacts during a trip to Mexico. She suffered another stroke on May 8 and she died six days later in Toronto, aged 70.\nThe US Immigration and Naturalization Service allowed her body to be brought back to the United States. She was buried in German Waldheim Cemetery (now named Forest Home Cemetery) in Forest Park, Illinois, a western suburb of Chicago, near the graves of those executed after the Haymarket affair. The bas relief on her grave marker was created by sculptor Jo Davidson, and the stone includes the quote \"Liberty will not descend to a people, a people must raise themselves to liberty\".\nPhilosophy.\nGoldman spoke and wrote extensively on a wide variety of issues. While she rejected orthodoxy and fundamentalist thinking, she was an important contributor to several fields of modern political philosophy. She was influenced by many diverse thinkers and writers, including Mikhail Bakunin, Henry David Thoreau, Peter Kropotkin, Ralph Waldo Emerson, Nikolai Chernyshevsky, and Mary Wollstonecraft. Another philosopher who influenced Goldman was Friedrich Nietzsche. In her autobiography, she wrote: \"Nietzsche was not a social theorist, but a poet, a rebel, and innovator. His aristocracy was neither of birth nor of purse; it was the spirit. In that respect Nietzsche was an anarchist, and all true anarchists were aristocrats.\"\nAnarchism.\nAnarchism was central to Goldman's view of the world, and she is widely considered one of the most important figures in the history of anarchism and libertarian socialism. First drawn to it during the persecution of anarchists after the 1886 Haymarket affair, she wrote and spoke regularly on behalf of anarchism. In the title essay of her book \"Anarchism and Other Essays\", she wrote:\nAnarchism, then, really stands for the liberation of the human mind from the dominion of religion; the liberation of the human body from the dominion of property; liberation from the shackles and restraint of government. Anarchism stands for a social order based on the free grouping of individuals for the purpose of producing real social wealth; an order that will guarantee to every human being free access to the earth and full enjoyment of the necessities of life, according to individual desires, tastes, and inclinations.\nGoldman's anarchism was intensely personal. She believed it was necessary for anarchist thinkers to live their beliefs, demonstrating their convictions with every action and word. \"I don't care if a man's theory for tomorrow is correct,\" she once wrote. \"I care if his spirit of today is correct.\" Anarchism and free association were to her logical responses to the confines of government control and capitalism. \"It seems to me that \"these\" are the new forms of life,\" she wrote, \"and that they will take the place of the old, not by preaching or voting, but by living them.\" At the same time, she believed that the movement on behalf of human liberty must be staffed by liberated humans. While dancing among fellow anarchists one evening, she was chided by an associate for her carefree demeanor. In her autobiography, Goldman wrote:\nI told him to mind his own business, I was tired of having the Cause constantly thrown in my face. I did not believe that a Cause which stood for a beautiful ideal, for anarchism, for release and freedom from conventions and prejudice, should demand denial of life and joy. I insisted that our Cause could not expect me to behave as a nun and that the movement should not be turned into a cloister. If it meant that, I did not want it. \"I want freedom, the right to self-expression, everybody's right to beautiful, radiant things.\"\nTactical uses of violence.\nIn her political youth, Goldman held targeted violence to be a legitimate means of revolutionary struggle. At that time, she believed that the use of violence, while distasteful, could be justified in relation to the social benefits it might accrue. She advocated propaganda of the deed\u2014\"attentat\", or violence carried out to encourage the masses to revolt. She supported her partner Alexander Berkman's attempt to kill industrialist Henry Clay Frick, and even begged him to allow her to participate. She believed that Frick's actions during the Homestead strike were reprehensible and that his murder would produce a positive result for working people. She later wrote in her autobiography, \"Yes, the end in this case justified the means.\" While she never gave explicit approval of Leon Czolgosz's assassination of US President William McKinley, she defended his ideals and believed actions like his were a natural consequence of repressive institutions. As she wrote in \"The Psychology of Political Violence\" that \"the accumulated forces in our social and economic life, culminating in an act of violence, are similar to the terrors of the atmosphere, manifested in storm and lightning.\"\nHer experiences in Russia led her to qualify her earlier belief that revolutionary ends might justify violent means. In the afterword to \"My Disillusionment in Russia\", she wrote: \"There is no greater fallacy than the belief that aims and purposes are one thing, while methods and tactics are another. ... The means employed become, through individual habit and social practice, part and parcel of the final purpose ... .\" In the same chapter, Goldman affirmed that \"Revolution is indeed a violent process,\" and noted that violence was the \"tragic inevitability of revolutionary upheavals\". Some misinterpreted her comments on the Bolshevik terror as a rejection of all militant force, but Goldman corrected this in the preface to the first US edition of \"My Disillusionment in Russia\":\nThe argument that destruction and terror are part of revolution I do not dispute. I know that in the past every great political and social change necessitated violence. ... Black slavery might still be a legalized institution in the United States but for the militant spirit of the John Browns. I have never denied that violence is inevitable, nor do I gainsay it now. Yet it is one thing to employ violence in combat, as a means of defense. It is quite another thing to make a principle of terrorism, to institutionalize it, to assign it the most vital place in the social struggle. Such terrorism begets counter-revolution and in turn itself becomes counter-revolutionary.\nGoldman saw the militarization of Soviet society not as a result of armed resistance per se, but of the statist vision of the Bolsheviks, writing that \"an insignificant minority bent on creating an absolute State is necessarily driven to oppression and terrorism.\"\nCapitalism and labor.\nGoldman believed that the economic system of capitalism was incompatible with human liberty. \"The only demand that property recognizes,\" she wrote in \"Anarchism and Other Essays\", \"is its own gluttonous appetite for greater wealth, because wealth means power; the power to subdue, to crush, to exploit, the power to enslave, to outrage, to degrade.\" She also argued that capitalism dehumanized workers, \"turning the producer into a mere particle of a machine, with less will and decision than his master of steel and iron.\" Originally opposed to anything less than complete revolution, Goldman was challenged during one talk by an elderly worker in the front row. In her autobiography, she wrote:\nHe said that he understood my impatience with such small demands as a few hours less a day, or a few dollars more a week... But what were men of his age to do? They were not likely to live to see the ultimate overthrow of the capitalist system. Were they also to forgo the release of perhaps two hours a day from the hated work? That was all they could hope to see realized in their lifetime.\nState.\nGoldman viewed the state as essentially and inevitably a tool of control and domination. As a result of her anti-state views, Goldman believed that voting was useless at best and dangerous at worst. Voting, she wrote, provided an illusion of participation while masking the true structures of decision-making. Instead, Goldman advocated targeted resistance in the form of strikes, protests, and \"direct action against the invasive, meddlesome authority of our moral code\". She maintained an anti-voting position even when many anarcho-syndicalists in 1930s Spain voted for the formation of a liberal republic. Goldman wrote that any power anarchists wielded as a voting bloc should instead be used to strike across the country.\nGoldman disagreed with the movement for women's suffrage, which demanded the right of women to vote. In her essay \"Woman Suffrage\", she ridicules the idea that women's involvement would infuse the democratic state with a more just orientation: \"As if women have not sold their votes, as if women politicians cannot be bought!\" She agreed with the suffragists' assertion that women are equal to men but disagreed that their participation alone would make the state more just. \"To assume, therefore, that she would succeed in purifying something which is not susceptible of purification, is to credit her with supernatural powers.\" Goldman was also critical of Zionism, which she saw as another failed experiment in state control.\nGoldman was a passionate critic of the prison system, critiquing both the treatment of prisoners and the social causes of crime. Goldman viewed crime as a natural outgrowth of an unjust economic system, and in her essay \"Prisons: A Social Crime and Failure\", she quoted liberally from the 19th-century authors Fyodor Dostoevsky and Oscar Wilde on prisons, and wrote:\nYear after year the gates of prison hells return to the world an emaciated, deformed, will-less, shipwrecked crew of humanity, with the Cain mark on their foreheads, their hopes crushed, all their natural inclinations thwarted. With nothing but hunger and inhumanity to greet them, these victims soon sink back into crime as the only possibility of existence.\nGoldman was a committed war resister and was particularly opposed to the draft, viewing it as one of the worst of the state's forms of coercion, and was one of the founders of the No-Conscription League for which she was ultimately arrested and imprisoned in 1917 before being deported in 1919.\nGoldman was routinely surveilled, arrested, and imprisoned for her speech and organizing activities in support of workers and various strikes, access to birth control, and in opposition to World War I. As a result, she became active in the early 20th century free speech movement, seeing freedom of expression as a fundamental necessity for achieving social change. Her outspoken championship of her ideals, in the face of persistent arrests, inspired Roger Baldwin, one of the founders of the American Civil Liberties Union. Goldman's and Reitman's experiences with vigilantism in the San Diego free speech fight in 1912 is an example of their persistence in the fight for free speech despite risking their safety.\nFeminism and sexuality.\nAlthough she was hostile to the suffragist goals of first-wave feminism, Goldman advocated passionately for the rights of women, and is today heralded as a founder of anarcha-feminism, which challenges patriarchy as a hierarchy to be resisted alongside state power and class divisions. In 1897, she wrote: \"I demand the independence of woman, her right to support herself; to live for herself; to love whomever she pleases, or as many as she pleases. I demand freedom for both sexes, freedom of action, freedom in love and freedom in motherhood.\"\nA nurse by training, Goldman was an early advocate for educating women concerning contraception. Like many feminists of her time, she saw abortion as a tragic consequence of social conditions, and birth control as a positive alternative. Goldman was also an advocate of free love, and a strong critic of marriage. She saw early feminists as confined in their scope and bounded by social forces of Puritanism and capitalism. She wrote: \"We are in need of unhampered growth out of old traditions and habits. The movement for women's emancipation has so far made but the first step in that direction.\"\nGoldman was an outspoken critic of prejudice against homosexual and genderqueer people. Her belief that social liberation should extend to gay men and lesbians was virtually unheard of at the time, even among anarchists. As German sexologist Magnus Hirschfeld wrote, \"she was the first and only woman, indeed the first and only American, to take up the defense of homosexual love before the general public.\" In numerous speeches and letters, she defended the right of gay men and lesbians to love as they pleased and condemned the fear and stigma associated with homosexuality. As Goldman wrote in a letter to Hirschfeld, \"It is a tragedy, I feel, that people of a different sexual type are caught in a world which shows so little understanding for homosexuals and is so crassly indifferent to the various gradations and variations of gender and their great significance in life.\"\nAtheism.\nA committed atheist, Goldman viewed religion as another instrument of control and domination. Her essay \"The Philosophy of Atheism\" quoted Bakunin at length on the subject and added:\nConsciously or unconsciously, most theists see in gods and devils, heaven and hell, reward and punishment, a whip to lash the people into obedience, meekness and contentment... The philosophy of Atheism expresses the expansion and growth of the human mind. The philosophy of theism, if we can call it a philosophy, is static and fixed.\nIn essays like \"The Hypocrisy of Puritanism\" and a speech entitled \"The Failure of Christianity\", Goldman made more than a few enemies among religious communities by attacking their moralistic attitudes and efforts to control human behavior. She blamed Christianity for \"the perpetuation of a slave society\", arguing that it dictated individuals' actions on Earth and offered poor people a false promise of a plentiful future in heaven.\nLegacy.\nGoldman was well known during her life, described as\u2014among other things\u2014\"the most dangerous woman in America\". After her death and through the middle part of the 20th century, her fame faded. Scholars and historians of anarchism viewed her as a great speaker and activist but did not regard her as a philosophical or theoretical thinker on par with, for example, Kropotkin.\nIn 1970, Dover Press reissued Goldman's biography, \"Living My Life\", and in 1972, feminist writer Alix Kates Shulman issued a collection of Goldman's writing and speeches, \"Red Emma Speaks\". These works brought Goldman's life and writings to a larger audience, and she was in particular lionized by the women's movement of the late 20th century. In 1973, Shulman was asked by a printer friend for a quotation by Goldman for use on a T-shirt. She sent him the selection from \"Living My Life\" about \"the right to self-expression, everybody's right to beautiful, radiant things\", recounting that she had been admonished \"that it did not behoove an agitator to dance\". The printer created a statement based on these sentiments that has become one of the most famous quotations attributed to Goldman even though she probably never said or wrote it as such: \"If I can't dance I don't want to be in your revolution.\" Variations of this saying have appeared on thousands of T-shirts, buttons, posters, bumper stickers, coffee mugs, hats, and other items.\nThe women's movement of the 1970s that \"rediscovered\" Goldman was accompanied by a resurgent anarchist movement, beginning in the late 1960s, which also reinvigorated scholarly attention to earlier anarchists. The growth of feminism also initiated some reevaluation of Goldman's philosophical work, with scholars pointing out the significance of Goldman's contributions to anarchist thought in her time. Goldman's belief in the value of aesthetics, for example, can be seen in the later influences of anarchism and the arts. Similarly, Goldman is now given credit for significantly influencing and broadening the scope of activism on issues of sexual liberty, reproductive rights, and freedom of expression.\nGoldman has been depicted in numerous works of fiction over the years, including Warren Beatty's 1981 film \"Reds\", in which she was portrayed by Maureen Stapleton, who won an Academy Award for her performance. Goldman has also been a character in two Broadway musicals, \"Ragtime\" and \"Assassins\". Plays depicting Goldman's life include: Howard Zinn's play, \"Emma\"; Martin Duberman's \"Mother Earth\"; Jessica Litwak's \"Emma Goldman: Love, Anarchy, and Other Affairs\" (about Goldman's relationship with Berkman and her arrest in connection with McKinley's assassination); Lynn Rogoff's \"Love Ben, Love Emma\" (about Goldman's relationship with Reitman); Carol Bolt's \"Red Emma\"; and Alexis Roblan's \"Red Emma and the Mad Monk\". Ethel Mannin's 1941 novel \"Red Rose\" is also based on Goldman's Life.\nGoldman has been honored by a number of organizations named in her memory. The Emma Goldman Clinic, a women's health center located in Iowa City, Iowa, selected Goldman as a namesake \"in recognition of her challenging spirit.\" Red Emma's Bookstore Coffeehouse, an infoshop in Baltimore, Maryland adopted her name out of their belief \"in the ideas and ideals that she fought for her entire life: free speech, sexual and racial equality and independence, the right to organize in our jobs and in our own lives, ideas and ideals that we continue to fight for, even today\".\nWorks.\nGoldman was a prolific writer, penning countless pamphlets and articles on a diverse range of subjects. She authored six books, including an autobiography, \"Living My Life\", and a biography of fellow anarchist Voltairine de Cleyre.\nExternal links.\nDigital collections\nPhysical collections"}
{"id": "9765", "revid": "1934512", "url": "https://en.wikipedia.org/wiki?curid=9765", "title": "Equuleus", "text": "Equuleus is a faint constellation located just north of the celestial equator. Its name is Latin for \"little horse\", a foal. It was one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and remains one of the 88 modern constellations. It is the second smallest of the modern constellations (after Crux), spanning only 72 square degrees. It is also very faint, having no stars brighter than the fourth magnitude.\nNotable features.\nStars.\nThe brightest star in Equuleus is \u03b1 Equulei, traditionally called Kitalpha, a yellow star magnitude 3.9, 186 light-years from Earth. Its traditional name means \"the section of the horse\".\nThere are few variable stars in Equuleus. Only around 25 are known, most of which are faint. \u03b3 Equulei is an \u03b12 CVn variable star, ranging between magnitudes 4.58 and 4.77 over a period of around 12\u00bd minutes. It is a white star 115 light-years from Earth, and has an optical companion of magnitude 6.1, 6 Equulei. It is divisible in binoculars. 6 Equulei is an astrometric binary system itself, with an apparent magnitude of 6.07. R Equulei is a Mira variable that ranges between magnitudes 8.0 and 15.7 over nearly 261 days. It has a spectral type of M3e-M4e and has an average B-V colour index of +1.41.\nEquuleus contains some double stars of interest. \u03b3 Equulei consists of a primary star with a magnitude around 4.7 (slightly variable) and a secondary star of magnitude 11.6, separated by 2 arcseconds. \u03b5 Equulei is a triple star also designated 1 Equulei. The system, 197 light-years away, has a primary of magnitude 5.4 that is itself a binary star; its components are of magnitude 6.0 and 6.3 and have a period of 101 years. The secondary is of magnitude 7.4 and is visible in small telescopes. The components of the primary are becoming closer together and will not be divisible in amateur telescopes beginning in 2015. \u03b4 Equulei is a binary star with an orbital period of 5.7 years, which at one time was the shortest known orbital period for an optical binary. The two components of the system are never more than 0.35 arcseconds apart.\nDeep-sky objects.\nDue to its small size and its distance from the plane of the Milky Way, Equuleus is rather devoid of deep sky objects. Some very faint galaxies in the NGC catalog between magnitudes 13 and 15 include NGC 7015, NGC 7040, and NGC 7046. NGC 7045 is a triple star that was mistaken as a nebula by its discoverer, John Herschel. Other faint galaxies in the IC Catalog include IC 1360, IC 1361, IC 1364, IC 1367, IC 1375, and IC 5083. IC 1365 is a group of galaxies. The magnitudes of these objects vary from 14.5 to 15.5, making them hard to see in even the largest of amateur telescopes.\nMythology.\nIn Greek mythology, one myth associates Equuleus with the foal Celeris (meaning \"swiftness\" or \"speed\"), who was the offspring or brother of the winged horse Pegasus. Celeris was given to Castor by Mercury. Other myths say that Equuleus is the horse struck from Poseidon's trident, during the contest between him and Athena when deciding which would be the superior. Because this section of stars rises before Pegasus, it is often called Equus Primus, or the First Horse. Equuleus is also linked to the story of Philyra and Saturn.\nCreated by Hipparchus and included by Ptolemy, it abuts Pegasus; unlike the larger horse, it is depicted as a horse's head alone.\nEquivalents.\nIn Chinese astronomy, the stars that correspond to Equuleus are located within the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\")."}
{"id": "9766", "revid": "408438", "url": "https://en.wikipedia.org/wiki?curid=9766", "title": "Eridanus", "text": "Eridanus can refer to:"}
{"id": "9767", "revid": "1455149", "url": "https://en.wikipedia.org/wiki?curid=9767", "title": "Eucharist", "text": "The Eucharist ( ; from , ), also called Holy Communion, the Blessed Sacrament or the Lord's Supper, is a Christian rite, considered a sacrament in most churches and an ordinance in others. Christians believe that the rite was instituted by Jesus at the Last Supper, the night before his crucifixion, giving his disciples bread and wine. Passages in the New Testament state that he commanded them to \"do this in memory of me\" while referring to the bread as \"my body\" and the cup of wine as \"the blood of my covenant, which is poured out for many\". According to the synoptic Gospels, this was at a Passover meal.\nThe elements of the Eucharist, bread, either leavened or unleavened, and wine (non-alcoholic grape juice in some Protestant traditions, such as Methodism), are consecrated on an altar or a communion table and consumed thereafter. The consecrated elements are the end product of the Eucharistic Prayer. Christians generally recognize a special presence of Christ in this rite, though they differ about exactly how, where, and when Christ is present.\nThe Catholic Church states that the Eucharist is the body and blood of Christ under the species of bread and wine. It maintains that by the consecration, the substances of the bread and wine actually become the substances of the body and blood of Jesus Christ (transubstantiation) while the form and appearances of the bread and wine remain unaltered (e.g. colour, taste, feel, and smell). The Eastern Orthodox and Oriental Orthodox churches agree that an objective change occurs of the bread and wine into the body and blood of Christ. Lutherans believe the true body and blood of Christ are really present \"in, with, and under\" the forms of the bread and wine, known as the sacramental union. Reformed Christians believe in a real spiritual presence of Christ in the Eucharist. Anglican eucharistic theologies universally affirm the real presence of Christ in the Eucharist, though Evangelical Anglicans believe that this is a spiritual presence, while Anglo-Catholics hold to a corporeal presence. Others, such as the Plymouth Brethren, hold the Lord's Supper to be purely a memorial. As a result of these different understandings, \"the Eucharist has been a central issue in the discussions and deliberations of the ecumenical movement.\"\nTerminology.\nEucharist.\nThe New Testament was originally written in the Greek language and the Greek noun (), meaning \"thanksgiving\", appears a few times in it, while the related Greek verb is found several times in New Testament accounts of the Last Supper, including the earliest such account:\nThe term (thanksgiving) is that by which the rite is referred to in the \"Didache\" (a late 1st or early 2nd century document), by Ignatius of Antioch (who died between 98 and 117) and by Justin Martyr (\"First Apology\" written between 155 and 157). Today, \"the Eucharist\" is the name still used by Eastern Orthodox, Oriental Orthodox, Catholics, Anglicans, Presbyterians, and Lutherans. Other Protestant denominations rarely use this term, preferring \"Communion\", \"the Lord's Supper\", \"Remembrance\", or \"the Breaking of Bread\". Latter-day Saints call it \"the Sacrament\".\nLord's Supper.\nIn the First Epistle to the Corinthians Paul uses the term \"Lord's Supper\", in Greek (), in the early 50s of the 1st century:\nSo Paul's use of the term \"Lord's Supper\" in reference to the Corinthian banquet is powerful and interesting; but to be an actual name for the Christian meal, rather than a meaningful phrase connected with an ephemeral rhetorical contrast, it would have to have some history, previous or subsequent. Nevertheless, given its existence in the biblical text, \"Lord's Supper\" came into use after the Protestant Reformation and remains the predominant term among Evangelicals, such as Baptists and Pentecostals. They also refer to the observance as an ordinance rather than a sacrament.\nCommunion.\nUse of the term \"Communion\" (or \"Holy Communion\") to refer to the Eucharistic rite began by some groups originating in the Protestant Reformation. Others, such as the Catholic Church, do not formally use this term for the rite, but instead mean by it the act of partaking of the consecrated elements; they speak of receiving Holy Communion at Mass or outside of it, they also use the term First Communion when one receives the Eucharist for the first time. The term \"Communion\" is derived from Latin (\"sharing in common\"), translated from the Greek () in 1 Corinthians 10:16:\nOther terms.\nBreaking of bread.\nThe phrase (, 'breaking of the bread'; in later liturgical Greek also ) appears in various related forms five times in the New Testament in contexts which, according to some, may refer to the celebration of the Eucharist, in either closer or symbolically more distant reference to the Last Supper. This term is used by the Plymouth Brethren.\nSacrament or Blessed Sacrament.\nThe \"Blessed Sacrament\", the \"Sacrament of the Altar\", and other variations, are common terms used by Catholics, Lutherans and some Anglicans (Anglo-Catholics) for the consecrated elements, particularly when reserved in a tabernacle. In the Church of Jesus Christ of Latter-day Saints the term \"The Sacrament\" is used of the rite.\nMass.\nThe term \"Mass\" is used in the Catholic Church, the Lutheran churches (especially the Churches of Sweden, Norway and Finland), and by some Anglicans. It derives from the Latin word , a dismissal: or \"go, it is sent\", the very last phrase of the service. That Latin word has come to imply \"mission\" as well because the congregation is sent out to serve Christ.\nAt least in the Catholic Church, the Mass is a long rite in two parts: the Liturgy of the Word and the Liturgy of the Eucharist. The former consists of readings from the Bible and a homily, or sermon, given by a priest or deacon. The latter, which follows seamlessly, includes the \"Offering\" of the bread and wine at the altar, their consecration by the priest through prayer, and their reception by the congregation in Holy Communion. Among the many other terms used in the Catholic Church are \"Holy Mass\", \"the Memorial of the Passion, Death and Resurrection of the Lord\", the \"Holy Sacrifice of the Mass\", and the \"Holy Mysteries\".\nDivine Liturgy and Divine Service.\nThe term Divine Liturgy () is used in Byzantine Rite traditions, whether in the Eastern Orthodox Church or among the Eastern Catholic Churches. These also speak of \"the Divine Mysteries\", especially in reference to the consecrated elements, which they also call \"the Holy Gifts\".\nThe term Divine Service () has often been used to refer to Christian worship more generally and is still used in Lutheran churches, in addition to the terms \"Eucharist\", \"Mass\" and \"Holy Communion\". Historically this refers (like the term \"worship\" itself) to service of God, although more recently it has been associated with the idea that God is serving the congregants in the liturgy.\nOther Eastern rites.\nSome Eastern rites have yet more names for the Eucharist. Holy Qurbana is common in Syriac Christianity and \"Badarak\" in the Armenian Rite; in the Alexandrian Rite, the term \"prosphora\" (from the Greek ) is common in Coptic Christianity and \"Keddase\" in Ethiopian and Eritrean Christianity.\nHistory.\nBiblical basis.\nThe Last Supper appears in all three synoptic Gospels: Matthew, Mark, and Luke. It also is found in the First Epistle to the Corinthians, which suggests how early Christians celebrated what Paul the Apostle called the Lord's Supper. Although the Gospel of John does not reference the Last Supper explicitly, some argue that it contains theological allusions to the early Christian celebration of the Eucharist, especially in the chapter 6 Bread of Life Discourse but also in other passages.\nGospels.\nThe synoptic Gospels, Mark 14:22\u201325, Matthew 26:26\u201329 and Luke 22:13\u201320 depict Jesus as presiding over the Last Supper prior to his crucifixion. The versions in Matthew and Mark are almost identical, but the Gospel of Luke presents a textual difference, in that a few manuscripts omit the second half of verse 19 and all of verse 20 (\"given for you [\u2026] poured out for you\"), which are found in the vast majority of ancient witnesses to the text. If the shorter text is the original one, then Luke's account is independent of both that of Paul and that of Matthew/Mark. If the majority longer text comes from the author of the third gospel, then this version is very similar to that of Paul in 1 Corinthians, being somewhat fuller in its description of the early part of the Supper, particularly in making specific mention of a cup being blessed before the bread was broken.\nIn the one prayer given to posterity by Jesus, the Lord's Prayer, the word epiousion\u2014which is otherwise unknown in Classical Greek literature\u2014was interpreted by some early Christian writers as meaning \"super-substantial\", and hence a possible reference to the Eucharist as the Bread of Life.\nIn the Gospel of John, however, the account of the Last Supper does not mention Jesus taking bread and \"the cup\" and speaking of them as his body and blood; instead, it recounts other events: his humble act of washing the disciples' feet, the prophecy of the betrayal, which set in motion the events that would lead to the cross, and his long discourse in response to some questions posed by his followers, in which he went on to speak of the importance of the unity of the disciples with him, with each other, and with God. Some would find in this unity and in the washing of the feet the deeper meaning of the Communion bread in the other three Gospels. In John 6:26\u201365, a long discourse is attributed to Jesus that deals with the subject of the living bread; John 6:51\u201359 also contains echoes of Eucharistic language.\nFirst Epistle to the Corinthians.\n1 Corinthians 11:23\u201325 gives the earliest recorded description of Jesus' Last Supper: \"The Lord Jesus on the night when he was betrayed took bread, and when he had given thanks, he broke it and said, 'This is my body, which is for you. Do this in remembrance of me.'\" The Greek word used in the passage for 'remembrance' is (), which itself has a much richer theological history than the English word \"remember\".\nThe expression \"The Lord's Supper\", derived from Paul's usage in 1 Corinthians 11:17\u201334, may have originally referred to the Agape feast (or love feast), the shared communal meal with which the Eucharist was originally associated. The Agape feast is mentioned in Jude 12 but \"The Lord's Supper\" is now commonly used in reference to a celebration involving no food other than the sacramental bread and wine.\nEarly Christian sources.\nThe \"Didache\" (Greek: , \"teaching\") is an Early Church treatise that includes instructions for baptism and the Eucharist. Most scholars date it to the late 1st century, and distinguish in it two separate Eucharistic traditions, the earlier tradition in chapter 10 and the later one preceding it in chapter 9. The Eucharist is mentioned again in chapter 14.\nIgnatius of Antioch (born , died between 98 and 117), one of the Apostolic Fathers, mentions the Eucharist as \"the flesh of our Saviour Jesus Christ\":\nJustin Martyr (born , died ) mentions in this regard:\nPaschasius Radbertus (785\u2013865) was a Carolingian theologian, and the abbot of Corbie, whose best-known and influential work is an exposition on the nature of the Eucharist written around 831, entitled . In it, Paschasius agrees with St Ambrose in affirming that the Eucharist contains the true, historical body of Jesus Christ. According to Paschasius, God is truth itself, and therefore, his words and actions must be true. Christ's proclamation at the Last Supper that the bread and wine were his body and blood must be taken literally, since God is truth. He thus believes that the transubstantiation of the bread and wine offered in the Eucharist really occurs. Only if the Eucharist is the actual body and blood of Christ can a Christian know it is salvific.\nJews and the Eucharist.\nThe concept of the Jews both destroying and partaking in some perverted version of the Eucharist has been a vessel to promote anti-Judaism and anti-Jewish ideology and violence. In medieval times, Jews were often depicted stabbing or in some other way physically harming communion wafers. These characterizations drew parallels to the idea that the Jews killed Christ; murdering this transubstantiation or \"host\" was thought of as a repetition of the event. Jewish people's eagerness to destroy hosts were also a variation of blood libel charges, with Jews being accused of murdering bodies of Christ, whether they be communion wafers or Christian children. The blood libel charges and the concept of Eucharist are also related in the belief that blood is efficacious, meaning it has some sort of divine power.\nEucharistic theology.\nMost Christians, even those who deny that there is any real change in the elements used, recognize a special presence of Christ in this rite. However, Christians differ about exactly how, where and how long Christ is present in it. Catholicism, Eastern Orthodoxy, Oriental Orthodoxy, and the Church of the East teach that the reality (the \"substance\") of the elements of bread and wine is wholly changed into the body and blood of Jesus Christ, while the appearances (the \"species\") remain. Transubstantiation (\"change of the substance\") is the term used by Catholics to denote is changed, not to explain the change occurs, since the Catholic Church teaches that \"the signs of bread and wine become, \"in a way surpassing understanding\", the Body and Blood of Christ\". The Orthodox use various terms such as transelementation, but no explanation is official as they prefer to leave it a mystery.\nLutherans believe Christ to be \"truly and substantially present\" with the bread and wine that are seen in the Eucharist, in a manner referred to as the sacramental union. They attribute the real presence of Jesus' living body to his word spoken in the Eucharist, and not to the faith of those receiving it. They also believe that \"forgiveness of sins, life, and salvation\" are given through the words of Christ in the Eucharist to those who believe his words (\"given and shed for you\").\nReformed Christians also believe Christ to be present in the Eucharist, but describe this presence as a spiritual presence, not a physical one. Anglicans adhere to a range of views depending on churchmanship although the teaching in the Anglican Thirty-Nine Articles also holds that the body of Christ is received by the faithful only in a heavenly and spiritual manner, a doctrine also taught in the Methodist Articles of Religion.\nChristians adhering to the theology of Memorialism, such as the Anabaptist Churches, do not believe in the concept of the real presence, believing that the Eucharist is only a ceremonial remembrance or memorial of the death of Christ.\nThe \"Baptism, Eucharist and Ministry\" document of the World Council of Churches, attempting to present the common understanding of the Eucharist on the part of the generality of Christians, describes it as \"essentially the sacrament of the gift which God makes to us in Christ through the power of the Holy Spirit\", \"Thanksgiving to the Father\", \"Anamnesis or Memorial of Christ\", \"the sacrament of the unique sacrifice of Christ, who ever lives to make intercession for us\", \"the sacrament of the body and blood of Christ, the sacrament of his real presence\", \"Invocation of the Spirit\", \"Communion of the Faithful\", and \"Meal of the Kingdom\".\nRitual and liturgy.\nMany Christian denominations classify the Eucharist as a sacrament. Some Protestants (though not all) prefer to instead call it an \"ordinance\", viewing it not as a specific channel of divine grace but as an expression of faith and of obedience to Christ.\nCatholic Church.\nIn the Catholic Church the Eucharist is considered as a sacrament, according to the church the Eucharist is \"the source and summit of the Christian life\". \"The other sacraments, and indeed all ecclesiastical ministries and works of the apostolate, are bound up with the Eucharist and are oriented toward it. For in the blessed Eucharist is contained the whole spiritual good of the Church, namely Christ himself, our Pasch.\" (\"Pasch\" is a word that sometimes means Easter, sometimes Passover.)\nAs a sacrifice.\nIn the Eucharist the same sacrifice that Jesus made only once on the cross is believed to be made present at every Mass. According to Compendium of the Catechism of the Catholic Church, \"The Eucharist is the very sacrifice of the Body and Blood of the Lord Jesus which he instituted to perpetuate the sacrifice of the cross throughout the ages until his return in glory.\"\n\"When the Church celebrates the Eucharist, she commemorates Christ's Passover, and it is made present the sacrifice Christ offered once for all on the cross remains ever present. [...] The Eucharist is thus a sacrifice because it re-presents (makes present) the same and only sacrifice offered once for all on the cross\"\nThe sacrifice of Christ and the sacrifice of the Eucharist are considered as one single sacrifice: \"The victim is one and the same: the same now offers through the ministry of priests, who then offered himself on the cross; only the manner of offering is different.\" In the holy sacrifice of the Mass, \"it is Christ himself, the eternal high priest of the New Covenant who, acting through the ministry of the priests, offers the Eucharistic sacrifice. And it is the same Christ, really present under the species of bread and wine, who is the offering of the Eucharistic sacrifice.\"\nAs a real presence.\nAccording to the Catholic Church Jesus Christ is present in the Eucharist in a true, real and substantial way, with his body, blood, soul and divinity. By the consecration, the substances of the bread and wine actually become the substances of the body and blood of Christ (transubstantiation) while the appearances or \"species\" of the bread and wine remain unaltered (e.g. colour, taste, feel, and smell). This change is brought about in the eucharistic prayer through the efficacy of the word of Christ and by the action of the Holy Spirit. The Eucharistic presence of Christ begins at the moment of the consecration and endures as long as the Eucharistic species subsist, that is, until the Eucharist is digested, physically destroyed, or decays by some natural process (at which point, theologian Thomas Aquinas argued, the substance of the bread and wine cannot return).\nThe Fourth Council of the Lateran in 1215 spoke of the bread and wine as \"transubstantiated\" into the body and blood of Christ: \"His body and blood are truly contained in the sacrament of the altar under the forms of bread and wine, the bread and wine having been transubstantiated, by God's power, into his body and blood\". In 1551, the Council of Trent definitively declared: \"Because Christ our Redeemer said that it was truly his body that he was offering under the species of bread, it has always been the conviction of the Church of God, and this holy Council now declares again that by the consecration of the bread and wine there takes place a change of the whole substance of the bread into the substance of the body of Christ and of the whole substance of the wine into the substance of his blood. This change the holy Catholic Church has fittingly and properly called transubstantiation.\"\nThe church holds that the body and blood of Jesus can no longer be truly separated. Where one is, the other must be. Therefore, although the priest (or extraordinary minister of Holy Communion) says \"The Body of Christ\" when administering the Host and \"The Blood of Christ\" when presenting the chalice, the communicant who receives either one receives Christ, whole and entire. \"Christ is present whole and entire in each of the species and whole and entire in each of their parts, in such a way that the breaking of the bread does not divide Christ.\"\nThe Catholic Church sees as the main basis for this belief the words of Jesus himself at his Last Supper: the synoptic Gospels and Paul's recount that Jesus at the time of taking the bread and the cup said: \"This is my body [\u2026] this is my blood.\" The Catholic understanding of these words, from the Patristic authors onward, has emphasized their roots in the covenantal history of the Old Testament. The interpretation of Christ's words against this Old Testament background coheres with and supports belief in the Real presence of Christ in the Eucharist.\nReception and devotions.\nAccording to the Catholic Church doctrine receiving the Eucharist in a state of mortal sin is a sacrilege and only those who are in a state of grace, that is, without any mortal sin, can receive it. Based on 1 Corinthians 11:27\u201329, it affirms the following: \"Anyone who is aware of having committed a mortal sin must not receive Holy Communion, even if he experiences deep contrition, without having first received sacramental absolution, unless he has a grave reason for receiving Communion and there is no possibility of going to confession.\"\nSince the Eucharist is the body and blood of Christ, \"the worship due to the sacrament of the Eucharist, whether during the celebration of the Mass or outside it, is the worship of , that is, the adoration given to God alone.\"\" The Blessed Sacrament can be exposed (displayed) on an altar in a monstrance. Rites involving the exposure of the Blessed Sacrament include Benediction and eucharistic adoration. According to Catholic theology, the host, after the Rite of Consecration, is no longer bread, but is the Body, Blood, Soul, and Divinity of Christ. Catholics believe that Jesus is the sacrificial Lamb of God prefigured in the Old Testament Passover. The flesh of that Passover sacrificial lamb was to be consumed by the family members. Any left overs were to be burned before daybreak so that none of the Passover Lamb's flesh remained. Only by marking the doorposts and lintel of one's home with the Blood of the Lamb were the members of the household saved from death. The consumption of the Lamb was not to save them but rather to give them energy for the journey of escape (Exodus = escape from slavery in Egypt) as was also true for the unleavened bread () As the Passover was the Old Covenant, so the Eucharist became the New Covenant. (, , , and )\nEastern Orthodoxy.\nWithin Eastern Christianity, the Eucharistic service is called the \"Divine Liturgy\" (Byzantine Rite) or similar names in other rites. It comprises two main divisions: the first is the \"Liturgy of the Catechumens\" which consists of introductory litanies, antiphons and scripture readings, culminating in a reading from one of the Gospels and, often, a homily; the second is the \"Liturgy of the Faithful\" in which the Eucharist is offered, consecrated, and received as Holy Communion. Within the latter, the actual Eucharistic prayer is called the \"anaphora\", (literally \"offering\" or \"carrying up\", from the Greek ). In the Rite of Constantinople, two different anaphoras are currently used: one is attributed to John Chrysostom, the other to Basil the Great. In the Oriental Orthodox Church, a variety of anaphoras are used, but all are similar in structure to those of the Constantinopolitan Rite, in which the Anaphora of Saint John Chrysostom is used most days of the year; Saint Basil's is offered on the Sundays of Great Lent, the eves of Christmas and Theophany, Holy Thursday, Holy Saturday, and upon his feast day (1 January). At the conclusion of the Anaphora the bread and wine are held to be the body and blood of Christ. Unlike the Latin Church, the Byzantine Rite uses leavened bread, with the leaven symbolizing the presence of the Holy Spirit. The Greek Orthodox Church utilizes leavened bread in their celebration.\nIn Eastern theology, one idea of consecration as a process has been suggested. This understands the change in the elements to be accomplished at the epiclesis (\"invocation\") by which the Holy Spirit is invoked and the consecration of the bread and wine as the genuine body and blood of Christ is specifically requested, but since the anaphora as a whole is considered a unitary (albeit lengthy) prayer, no one moment within it can readily be singled out.\nProtestantism.\nAnabaptists.\nAnabaptist denominations, such as the Mennonites and German Baptist Brethren Churches like the Church of the Brethren churches and congregations have the Agape feast, footwashing, as well as the serving of the bread and wine in the celebration of the Lovefeast. In the more modern groups, Communion is only the serving of the Lord's Supper. In the communion meal, the members of the Mennonite churches renew their covenant with God and with each other.\nMoravian/Hussite.\nThe Moravian Church adheres to a view known as the \"sacramental presence\", teaching that in the sacrament of Holy Communion:\nNicolaus Zinzendorf, a bishop of the Moravian Church, stated that Holy Communion is the \"most intimate of all connection with the person of the Saviour.\"\nThe Order of Service for the observance of the Lord's Supper includes a salutation, hymns, the right hand of fellowship, prayer, consecration of the elements, distribution of the elements, partaking of the elements, and a benediction. Moravian Christians traditionally practice footwashing before partaking in the Lord's Supper, although in certain Moravian congregations, this rite is observed chiefly on Maundy Thursday.\nAnglican.\nAnglican theology on the matter of the Eucharist is nuanced. The Eucharist is neither wholly a matter of transubstantiation nor simply devotional and memorialist in orientation. The Anglican churches do not adhere to the belief that the Lord's Supper is merely a devotional reflection on Christ's death. For some Anglicans, Christ is spiritually present in the fullness of his person in the Eucharist.\nThe Church of England itself has repeatedly refused to make official any definition of \"the presence of Christ\". Church authorities prefer to leave it a mystery while proclaiming the consecrated bread and wine to be \"spiritual food\" of \"Christ's Most Precious Body and Blood\"; the bread and wine are an \"outward sign of an inner grace\". The words of administration at communion allow for real presence or for a real but spiritual presence (Calvinist receptionism and virtualism). This concept was congenial to most Anglicans well into the 19th century. From the 1840s, the Tractarians reintroduced the idea of \"the real presence\" to suggest a corporeal presence, which could be done since the language of the BCP rite referred to the body and blood of Christ without details as well as referring to these as spiritual food at other places in the text. Both are found in the Latin and other rites, but in the former, a definite interpretation as corporeal is applied.\nBoth receptionism and virtualism assert the real presence. The former places emphasis on the recipient and the latter states \"the presence\" is confected by the power of the Holy Spirit but not in Christ's natural body. His presence is objective and does not depend on its existence from the faith of the recipient. The liturgy petitions that elements \"be\" rather than \"become\" the body and blood of Christ leaving aside any theory of a change in the natural elements: bread and wine are the outer reality and \"the presence\" is the inner invisible except as perceived in faith.\nIn 1789, the Episcopal Church in the United States restored explicit language that the Eucharist is an oblation (sacrifice) to God. Subsequent revisions of the \"Book of Common Prayer\" by member churches of the Anglican Communion have done likewise (the Church of England did so in the proposed 1928 prayer book).\nThe so-called \"Black Rubric\" in the 1552 prayer book, which allowed kneeling when receiving Holy Communion was omitted in the 1559 edition at Queen Elizabeth I's insistence. It was reinstated in the 1662 prayer book, modified to deny any corporal presence of Christ's natural flesh and blood, which are in Heaven and not here. \nBaptists.\nThe bread and \"fruit of the vine\" indicated in Matthew, Mark and Luke as the elements of the Lord's Supper are interpreted by many Baptists as unleavened bread (although leavened bread is often used) and, in line with the historical stance of some Baptist groups (since the mid-19th century) against partaking of alcoholic beverages, grape juice, which they commonly refer to simply as \"the Cup\". The unleavened bread also underscores the symbolic belief attributed to Christ's breaking the bread and saying that it was his body. A soda cracker is often used.\nSome Baptists consider the Communion to be primarily an act of remembrance of Christ's atonement, and a time of renewal of personal commitment (memorialism) such as Free Will Baptists, while others, such as Particular Baptists affirm the Reformed doctrine of a pneumatic presence, which is expressed in the Second London Baptist Confession, specifically in Chapter 30, Articles 3 and 7. This view is prevalent among Southern Baptists, those in the Founders movement (a Calvinistic movement among some Independent Baptists),and several individuals in other Baptist associations.\nCommunion practices and frequency vary among congregations. A typical practice is to have small cups of juice and plates of broken bread distributed to the seated congregation. In other congregations, communicants may proceed to the altar to receive the elements, then return to their seats. A widely accepted practice is for all to receive and hold the elements until everyone is served, then consume the bread and cup in unison. Usually, music is performed and Scripture such as the precise verses of Jesus speaking at the Last Supper is read during the receiving of the elements.\nSome Baptist churches are closed-Communionists (even requiring full membership in the local church congregation before partaking), with others being partially or fully open-Communionists. It is rare to find a Baptist church where the Lord's Supper is observed every Sunday; most observe monthly or quarterly, with some holding Communion only during a designated Communion service or following a worship service. Adults and children in attendance who have not made a profession of faith in Christ are expected to not participate.\nLutheran.\nLutherans believe that the body and blood of Christ are \"truly and substantially present in, with, and under the forms\" of the consecrated bread and wine (the elements), so that communicants eat and drink the body and blood of Christ himself as well as the bread and wine in the Eucharistic sacrament. The Lutheran doctrine of the Real Presence is more accurately and formally known as the \"sacramental union\". Others have erroneously called this consubstantiation, a Lollardist doctrine, though this term is specifically rejected by Lutheran churches and theologians since it creates confusion about the actual doctrine and subjects the doctrine to the control of a non-biblical philosophical concept in the same manner as, in their view, does the term \"transubstantiation\".\nWhile an official movement exists in Lutheran congregations to celebrate Eucharist weekly, using formal rites very similar to the Catholic and \"high\" Anglican services, it was historically common for congregations to celebrate monthly or even quarterly. Even in congregations where Eucharist is offered weekly, there is not a requirement that every church service be a Eucharistic service, nor that all members of a congregation must receive it weekly.\nOpen Brethren and Exclusive Brethren.\nAmong Open assemblies, also termed Plymouth Brethren, the Eucharist is more commonly called the Breaking of Bread or the Lord's Supper. They believe it is only a symbolic reenactment of the Last Supper and a memorial \"to remind believers of his body given and his blood shed for their salvation\". and is central to the worship of both individual and assembly. In principle, the service is open to all baptized Christians, but an individual's eligibility to participate depends on the views of each particular assembly. The service takes the form of non-liturgical, open worship with all male participants allowed to pray audibly and select hymns or readings. The breaking of bread itself typically consists of one leavened loaf, which is prayed over and broken by a participant in the meeting and then shared around. The wine is poured from a single container into one or several vessels, and these are again shared around.\nThe Exclusive Brethren follow a similar practice to the Open Brethren. They also call the Eucharist the Breaking of Bread or the Lord's Supper.\nReformed (Continental Reformed, Presbyterian and Congregationalist).\nIn the Reformed tradition (which includes the Continental Reformed Churches, the Presbyterian Churches, and the Congregationalist Churches), the Eucharist is variously administered. The Calvinist view of the Sacrament sees a real presence of Christ in the supper which differs both from the objective ontological presence of the Catholic view, and from the real absence of Christ and the mental recollection of the memorialism of the Zwinglians and their successors.\nThe bread and wine become the means by which the believer has real communion with Christ in his death and Christ's body and blood are present to the faith of the believer as really as the bread and wine are present to their senses but this presence is \"spiritual\", that is the work of the Holy Spirit. There is no standard frequency; John Calvin desired weekly communion, but the city council only approved monthly, and monthly celebration has become the most common practice in Reformed churches today.\nMany, on the other hand, follow John Knox in celebration of the Lord's supper on a quarterly basis, to give proper time for reflection and inward consideration of one's own state and sin. Recently, Presbyterian and Reformed Churches have been considering whether to restore more frequent communion, including weekly communion in more churches, considering that infrequent communion was derived from a memorialist view of the Lord's Supper, rather than Calvin's view of the sacrament as a means of grace. Some churches use bread without any raising agent (whether yeast or another leaven.) in view of the use of unleavened bread at Jewish Passover meals, while others use any bread available.\nThe Presbyterian Church (USA), for instance, prescribes \"bread common to the culture\". Harking back to the regulative principle of worship, the Reformed tradition had long eschewed coming forward to receive communion, preferring to have the elements distributed throughout the congregation by the presbyters (elders) more in the style of a shared meal. Over the last half a century it is much more common in Presbyterian churches to have Holy Communion monthly or on a weekly basis. It is also becoming common to receive the elements by intinction (receiving a piece of consecrated bread or wafer, dipping it in the blessed wine, and consuming it). Wine and grape juice are both used, depending on the congregation. Most Reformed churches practice \"open communion\", i.e., all believers who are united to a church of like faith and practice, and who are not living in sin, would be allowed to join in the Sacrament.\nMethodist.\nThe British \"Catechism for the use of the people called Methodists\" states that, \"[in the Eucharist] Jesus Christ is present with his worshipping people and gives himself to them as their Lord and Saviour\". Methodist theology of this sacrament is reflected in one of the fathers of the movement, Charles Wesley, who wrote a Eucharistic hymn with the following stanza:\n&lt;poem&gt;\nWe need not now go up to Heaven,\nTo bring the long sought Saviour down;\nThou art to all already given,\nThou dost e'en now Thy banquet crown:\nTo every faithful soul appear,\nAnd show Thy real presence here!\n&lt;/poem&gt;\nReflecting Wesleyan covenant theology, Methodists also believe that the Lord's Supper is a sign and seal of the covenant of grace.\nIn many Methodist denominations, non-alcoholic wine (grape juice) is used, so as to include those who do not take alcohol for any reason, as well as a commitment to the Church's historical support of temperance. Variations of the Eucharistic Prayer are provided for various occasions, including communion of the sick and brief forms for occasions that call for greater brevity. Though the ritual is standardized, there is great variation amongst Methodist churches, from typically high-church to low-church, in the enactment and style of celebration. Methodist clergy are not required to be vested when celebrating the Eucharist.\nJohn Wesley, a founder of Methodism, said that it was the duty of Christians to receive the sacrament as often as possible. Methodists in the United States are encouraged to celebrate the Eucharist every Sunday, though it is typically celebrated on the first Sunday of each month, while a few go as long as celebrating quarterly (a tradition dating back to the days of circuit riders that served multiple churches). Communicants may receive standing, kneeling, or while seated. Gaining more wide acceptance is the practice of receiving by intinction (receiving a piece of consecrated bread or wafer, dipping it in the blessed wine, and consuming it). The most common alternative to intinction is for the communicants to receive the consecrated juice using small, individual, specially made glass or plastic cups known as communion cups. The United Methodist Church practices open communion (which it describes as an \"open table\"), inviting \"all who intend a Christian life, together with their children\" to receive the eucharistic elements. \"The Doctrines and Discipline of the Methodist Church\" specifies, on days during which Holy Communion is celebrated, that \"Upon entering the church let the communicants bow in prayer and in the spirit of prayer and meditation approach the Blessed Sacrament.\"\nNondenominational Christians.\nMany non-denominational Christians, including the Churches of Christ, receive communion every Sunday. Others, including Evangelical churches such as the Church of God and Calvary Chapel, typically receive communion on a monthly or periodic basis. Many non-denominational Christians hold to the Biblical autonomy of local churches and have no universal requirement among congregations.\nSome Churches of Christ, among others, use grape juice and unleavened wafers or unleavened bread and practice open communion.\nSyriac Christianity.\nEdessan Rite (Church of the East).\nHoly Qurbana or Qurbana Qaddisha, the \"Holy Offering\" or \"Holy Sacrifice\", refers to the Eucharist as celebrated according to the East Syriac Christianity. The main Anaphora of the East Syrian tradition is the Holy Qurbana of Addai and Mari.\nSyro-Antiochene Rite (West Syriac).\nHoly Qurobo or Qurobo Qadisho refers to the Eucharist as celebrated in the West Syrian traditions of Syriac Christianity, while that of the West Syrian tradition is the Liturgy of Saint James.\nBoth are extremely old, going back at least to the third century, and are the oldest extant liturgies continually in use.\nRestorationism.\nIrvingian.\nIn the Irvingian Churches, Holy Communion, along with Holy Baptism and Holy Sealing, is one of the three sacraments. It is the focus of the Divine Service in the liturgies of Irvingism.\nEdward Irving, who founded the Irvingian Churches, such as the New Apostolic Church, taught the real presence of Christ in the Eucharist, emphasizing \"the \"humiliated\" humanity of Christ in the Lord's Supper.\" Additionally, the Irvingian Churches affirm the \"real presence of the sacrifice of Jesus Christ in Holy Communion\":\nIn the Irvingian tradition of Restorationist Christianity, consubstantiation is taught as the explanation of how the real presence is effected in the liturgy.\nSeventh-day Adventists.\nIn the Seventh-day Adventist Church the Holy Communion service customarily is celebrated once per quarter. The service includes the ordinance of footwashing and the Lord's Supper. Unleavened bread and unfermented (non-alcoholic) grape juice is used. Open communion is practised: all who have committed their lives to the Saviour may participate. The communion service must be conducted by an ordained pastor, minister or church elder.\nJehovah's Witnesses.\nJehovah's Witnesses commemorate Jesus' death annually on the evening that corresponds to the Passover, Nisan 14, according to the ancient Jewish calendar. They generally refer to the observance as \"the Lord's Evening Meal\" or the \"Memorial of Christ's Death\". They believe the event is the only annual religious observance commanded for Christians in the Bible.\nOf those who attend the Memorial, a small minority worldwide partake of the wine and unleavened bread. Jehovah's Witnesses believe that only 144,000 people will go to heaven, to serve as under-priests and co-rulers with Christ the King in God's Kingdom. They are referred to as the \"anointed\" class. They believe that the baptized \"other sheep\" also benefit from the ransom sacrifice, and are respectful observers and viewers of the Lord's Supper, but they hope to obtain everlasting life in Paradise restored on earth.\nThe Memorial, held after sundown, includes a sermon on the meaning and importance of the celebration and gathering, and includes the circulation of unadulterated red wine and unleavened bread (matzo). Jehovah's Witnesses believe that the bread represents Jesus' perfect body which he gave on behalf of mankind, and that the wine represents his perfect blood which he shed to redeem fallen man from inherited sin and death. The wine and the bread (sometimes referred to as \"emblems\") are viewed as symbolic and commemorative; the Witnesses do not believe in transubstantiation or consubstantiation.\nLatter-day Saints.\nIn the Church of Jesus Christ of Latter-day Saints, the \"Holy Sacrament of the Lord's Supper\", more simply referred to as the Sacrament, is administered every Sunday (except General Conference or other special Sunday meeting) in each Latter-Day Saint Ward or branch worldwide at the beginning of Sacrament meeting. The Sacrament, which consists of both ordinary bread and water (rather than wine or grape juice), is prepared by priesthood holders prior to the beginning of the meeting. At the beginning of the Sacrament, priests say specific prayers to bless the bread and water. The Sacrament is passed row-by-row to the congregation by priesthood holders (typically deacons).\nThe prayer recited for the bread and the water is found in the Book of Mormon and Doctrine and Covenants. The prayer contains the above essentials given by Jesus: \"Always remember him, and keep his commandments [\u2026] that they may always have his Spirit to be with them.\" (Moroni, 4:3.)\nNon-observing denominations.\nSalvation Army.\nWhile the Salvation Army does not reject the Eucharistic practices of other churches or deny that their members truly receive grace through this sacrament, it does not practice the sacraments of Communion or Baptism. This is because they believe that these are unnecessary for the living of a Christian life, and because in the opinion of Salvation Army founders William and Catherine Booth, the sacrament placed too much stress on outward ritual and too little on inward spiritual conversion.\nQuakers.\nEmphasizing the inward spiritual experience of their adherents over any outward ritual, Quakers (members of the Religious Society of Friends) generally do not baptize or observe Communion.\nChristian Scientists.\nAlthough the early Church of Christ, Scientist observed Communion, founder Mary Baker Eddy eventually discouraged the physical ritual as she believed it distracted from the true spiritual nature of the sacrament. As such, Christian Scientists do not observe physical communion with bread and wine, but spiritual communion at two special Sunday services each year by \"uniting together with Christ in silent prayer and on bended knee\".\nShakers.\nThe United Society of Believers (commonly known as Shakers) do not take communion, instead viewing every meal as a Eucharistic feast.\nPractice and customs.\nOpen and closed communion.\nChristian denominations differ in their understanding of whether they may celebrate the Eucharist with those with whom they are not in full communion. The apologist Justin Martyr () wrote of the Eucharist \"of which no one is allowed to partake but the man who believes that we teach are true, and who has been washed with the washing that is for the remission of sins and unto regeneration, and who is so living as Christ has enjoined.\" This was continued in the practice of dismissing the catechumens (those still undergoing instruction and not yet baptized) before the sacramental part of the liturgy, a custom which has left traces in the expression \"Mass of the Catechumens\" and in the Byzantine Rite exclamation by the deacon or priest, \"The doors! The doors!\", just before recitation of the Creed.\nChurches such as the Catholic and the Eastern Orthodox Churches practice closed communion under normal circumstances. However, the Catholic Church allows administration of the Eucharist, at their spontaneous request, to properly disposed members of the eastern churches (Eastern Orthodox, Oriental Orthodox and Church of the East) not in full communion with it and of other churches that the Holy See judges to be sacramentally in the same position as these churches; and in grave and pressing need, such as danger of death, it allows the Eucharist to be administered also to individuals who do not belong to these churches but who share the Catholic Church's faith in the reality of the Eucharist and have no access to a minister of their own community. Some Protestant communities exclude non-members from Communion.\nThe Evangelical Lutheran Church in America (ELCA) practices open communion, provided those who receive are baptized, but the Lutheran Church\u2013Missouri Synod and the Wisconsin Evangelical Lutheran Synod (WELS) practice closed communion, excluding non-members and requiring communicants to have been given catechetical instruction. The Evangelical Lutheran Church in Canada, the Evangelical Church in Germany, the Church of Sweden, and many other Lutheran churches outside of the U.S. also practice open communion.\nSome use the term \"close communion\" for restriction to members of the same denomination, and \"closed communion\" for restriction to members of the local congregation alone.\nMost Protestant communities including Congregational churches, the Church of the Nazarene, the Assemblies of God, Methodists, most Presbyterians and Baptists, Anglicans, and Churches of Christ and other non-denominational churches practice various forms of open communion. Some churches do not limit it to only members of the congregation, but to any people in attendance (regardless of Christian affiliation) who consider themselves to be Christian. Others require that the communicant be a baptized person, or a member of a church of that denomination or a denomination of \"like faith and practice\". Some Progressive Christian congregations offer communion to any individual who wishes to commemorate the life and teachings of Christ, regardless of religious affiliation.\nMost Latter-Day Saint churches practice closed communion; one notable exception is the Community of Christ, the second-largest denomination in this movement. While The Church of Jesus Christ of Latter-day Saints (the largest of the LDS denominations) technically practice a closed communion, their official direction to local Church leaders (in Handbook 2, section 20.4.1, last paragraph) is as follows: \"Although the sacrament is for Church members, the bishopric should not announce that it will be passed to members only, and nothing should be done to prevent nonmembers from partaking of it.\"\nIn the Malankara Orthodox Syrian Church the Eucharist is only given to those who have come prepared to receive the life-giving body and blood. Therefore, in a manner to worthily receive, believers fast the night before the liturgy, from around 6pm or the conclusion of evening prayer, and remain fasting until they receive Holy Qurbana the next morning. Additionally, members who plan to receive the holy communion have to follow a strict guide of prescribed prayers from the Shehimo, or the book of common prayers, for the week.\nPreparation.\nCatholic.\nThe Catholic Church requires its members to receive the sacrament of Penance or Reconciliation before taking Communion if they are aware of having committed a mortal sin and to prepare by fasting, prayer, and other works of piety.\nEastern Orthodox.\nTraditionally, the Eastern Orthodox church has required its members to have observed all church-appointed fasts (most weeks, this will be at least Wednesday and Friday) for the week prior to partaking of communion, and to fast from all food and water from midnight the night before. In addition, Orthodox Christians are to have made a recent confession to their priest (the frequency varying with one's particular priest), and they must be at peace with all others, meaning that they hold no grudges or anger against anyone. In addition, one is expected to attend Vespers or the All-Night Vigil, if offered, on the night before receiving communion. Furthermore, various pre-communion prayers have been composed, which many (but not all) Orthodox churches require or at least strongly encourage members to say privately before coming to the Eucharist. However, all this will typically vary from priest to priest and jurisdiction to jurisdiction, but abstaining from food and water for several hours beforehand is a fairly universal rule.\nProtestant confessions.\nMany Protestant congregations generally reserve a period of time for self-examination and private, silent confession just before partaking in the Lord's Supper.\nAdoration.\nEucharistic adoration is a practice in the Latin Church, Anglo-Catholic and some Lutheran traditions, in which the Blessed Sacrament is exposed to and adored by the faithful. When this exposure and adoration is constant (twenty-four hours a day), it is called \"Perpetual Adoration\". In a parish, this is usually done by volunteer parishioners; in a monastery or convent, it is done by the resident monks or nuns. In the \"Exposition of the Blessed Sacrament\", the Eucharist is displayed in a monstrance, typically placed on an altar, at times with a light focused on it, or with candles flanking it.\nHealth issues.\nGluten.\nThe gluten in wheat bread is dangerous to people with celiac disease and other gluten-related disorders, such as non-celiac gluten sensitivity and wheat allergy. For the Catholic Church, this issue was addressed in the 24 July 2003 letter of the Congregation for the Doctrine of the Faith, which summarized and clarified earlier declarations. The Catholic Church believes that the matter for the Eucharist must be wheaten bread and fermented wine from grapes: it holds that, if the gluten has been entirely removed, the result is not true wheaten bread. For celiacs, but not generally, it allows low-gluten bread. It also permits Holy Communion to be received under the form of either bread or wine alone, except by a priest who is celebrating Mass without other priests or as principal celebrant. Many Protestant churches offer communicants gluten-free alternatives to wheaten bread, usually in the form of a rice-based or other gluten-free wafer.\nAlcohol.\nThe Catholic Church believes that grape juice that has not begun even minimally to ferment cannot be accepted as wine, which it sees as essential for celebration of the Eucharist. For non-alcoholics, but not generally, it allows the use of mustum (grape juice in which fermentation has begun but has been suspended without altering the nature of the juice), and it holds that \"since Christ is sacramentally present under each of the species, communion under the species of bread alone makes it possible to receive all the fruit of Eucharistic grace. For pastoral reasons, this manner of receiving communion has been legitimately established as the most common form in the Latin rite.\"\nAs already indicated, the one exception is in the case of a priest celebrating Mass without other priests or as principal celebrant. The water that in the Roman Rite is prescribed to be mixed with the wine must be only a relatively small quantity. The practice of the Coptic Church is that the mixture should be two parts wine to one part water.\nSome Protestant churches allow communion in a non-alcoholic form, either normatively or as a pastoral exception. Since the invention of the necessary technology, grape juice which has been pasteurized to stop the fermentation process the juice naturally undergoes and de-alcoholized wine from which most of the alcohol has been removed (between 0.5% and 2% remains) are commonly used, and more rarely water may be offered. Exclusive use of unfermented grape juice is common in Baptist churches, the United Methodist Church, Seventh-day Adventists, Christian Churches/Churches of Christ, Churches of Christ, Church of God (Anderson, Indiana), some Lutherans, Assemblies of God, Pentecostals, Evangelicals, the Christian Missionary Alliance, and other American independent Protestant churches. \nFor members of the Church of Jesus Christ of Latter-day Saints, water is exclusively used in place of wine. From the church\u2019s General Handbook, section 18.9, \u201dDuring this ordinance, they partake of the bread and water to remember the Savior\u2019s sacrifice of His flesh and blood and to renew their sacred covenants\u2026\u201d \nTransmission of diseases.\nRisk of infectious disease transmission related to use of a common communion cup exists but it is low. No case of transmission of an infectious disease related to a common communion cup has ever been documented. Experimental studies have demonstrated that infectious diseases can be transmitted. The most likely diseases to be transmitted would be common viral illnesses such as the common cold. A study of 681 individuals found that taking communion up to daily from a common cup did not increase the risk of infection beyond that of those who did not attend services at all.\nIn influenza epidemics, some churches suspend the giving wine at communion, for fear of spreading the disease. This is in full accord with Catholic Church belief that communion under the form of bread alone makes it possible to receive all the fruit of Eucharistic grace. However, the same measure has also been taken by churches that normally insist on the importance of receiving communion under both forms. This was done in 2009 by the Church of England.\nSome fear contagion through the handling involved in distributing the hosts to the communicants, even if they are placed on the hand rather than on the tongue. Accordingly, some churches use mechanical wafer dispensers or \"pillow packs\" (communion wafers with wine inside them). While these methods of distributing communion are not generally accepted in Catholic parishes, one parish provides a mechanical dispenser to allow those intending to commune to place in a bowl, without touching them by hand, the hosts for use in the celebration."}
{"id": "9770", "revid": "82432", "url": "https://en.wikipedia.org/wiki?curid=9770", "title": "Eclipse", "text": "An eclipse is an astronomical event which occurs when an astronomical object or spacecraft is temporarily obscured, by passing into the shadow of another body or by having another body pass between it and the viewer. This alignment of three celestial objects is known as a \"syzygy\". An eclipse is the result of either an \"occultation\" (completely hidden) or a \"transit\" (partially hidden). A \"deep eclipse\" (or \"deep occultation\") is when a small astronomical object is behind a bigger one.\nThe term \"eclipse\" is most often used to describe either a solar eclipse, when the Moon's shadow crosses the Earth's surface, or a lunar eclipse, when the Moon moves into the Earth's shadow. However, it can also refer to such events beyond the Earth\u2013Moon system: for example, a planet moving into the shadow cast by one of its moons, a moon passing into the shadow cast by its host planet, or a moon passing into the shadow of another moon. A binary star system can also produce eclipses if the plane of the orbit of its constituent stars intersects the observer's position.\nFor the special cases of solar and lunar eclipses, these only happen during an \"eclipse season\", the two times of each year when the plane of the Earth's orbit around the Sun crosses with the plane of the Moon's orbit around the Earth and the line defined by the intersecting planes points near the Sun. The type of solar eclipse that happens during each season (whether total, annular, hybrid, or partial) depends on apparent sizes of the Sun and Moon. If the orbit of the Earth around the Sun and the Moon's orbit around the Earth were both in the same plane with each other, then eclipses would happen every month. There would be a lunar eclipse at every full moon, and a solar eclipse at every new moon. It is because of the non-planar differences that eclipses are not a common event. If both orbits were perfectly circular, then each eclipse would be the same type every month.\nLunar eclipses can be viewed from the entire nightside half of the Earth. But solar eclipses, particularly total eclipses occurring at any one particular point on the Earth's surface, are very rare events that can be many decades apart.\nEtymology.\nThe term is derived from the ancient Greek noun ('), which means 'the abandonment', 'the downfall', or 'the darkening of a heavenly body', which is derived from the verb (') which means 'to abandon', 'to darken', or 'to cease to exist', a combination of prefix ('), from preposition ('), 'out', and of verb (\"\"), 'to be absent'.\nUmbra, penumbra and antumbra.\nFor any two objects in space, a line can be extended from the first through the second. The latter object will block some amount of light being emitted by the former, creating a region of shadow around the axis of the line. Typically these objects are moving with respect to each other and their surroundings, so the resulting shadow will sweep through a region of space, only passing through any particular location in the region for a fixed interval of time. As viewed from such a location, this shadowing event is known as an eclipse.\nTypically the cross-section of the objects involved in an astronomical eclipse is roughly disk-shaped. The region of an object's shadow during an eclipse is divided into three parts:\nA total eclipse occurs when the observer is within the umbra, an annular eclipse when the observer is within the antumbra, and a partial eclipse when the observer is within the penumbra. During a lunar eclipse only the umbra and penumbra are applicable, because the antumbra of the Sun-Earth system lies far beyond the Moon. Analogously, Earth's apparent diameter from the viewpoint of the Moon is nearly four times that of the Sun and thus cannot produce an annular eclipse. The same terms may be used analogously in describing other eclipses, e.g., the antumbra of Deimos crossing Mars, or Phobos entering Mars's penumbra.\nThe \"first contact\" occurs when the eclipsing object's disc first starts to impinge on the light source; \"second contact\" is when the disc moves completely within the light source; \"third contact\" when it starts to move out of the light; and \"fourth\" or \"last contact\" when it finally leaves the light source's disc entirely.\nFor spherical bodies, when the occulting object is smaller than the star, the length (\"L\") of the umbra's cone-shaped shadow is given by:\nwhere \"Rs\" is the radius of the star, \"Ro\" is the occulting object's radius, and \"r\" is the distance from the star to the occulting object. For Earth, on average \"L\" is equal to 1.384\u00a0km, which is much larger than the Moon's semimajor axis of 3.844\u00a0km. Hence the umbral cone of the Earth can completely envelop the Moon during a lunar eclipse. If the occulting object has an atmosphere, however, some of the luminosity of the star can be refracted into the volume of the umbra. This occurs, for example, during an eclipse of the Moon by the Earth\u2014producing a faint, ruddy illumination of the Moon even at totality.\nOn Earth, the shadow cast during an eclipse moves very approximately at 1\u00a0km per sec. This depends on the location of the shadow on the Earth and the angle in which it is moving.\nEclipse cycles.\nAn eclipse cycle takes place when eclipses in a series are separated by a certain interval of time. This happens when the orbital motions of the bodies form repeating harmonic patterns. A particular instance is the saros, which results in a repetition of a solar or lunar eclipse every 6,585.3\u00a0days, or a little over 18 years. Because this is not a whole number of days, successive eclipses will be visible from different parts of the world. In one saros period there are 239.0 anomalistic periods, 241.0 sidereal periods, 242.0 nodical periods, and 223.0 synodic periods. Although the orbit of the Moon does not give exact integers, the numbers of orbit cycles are close enough to integers to give strong similarity for eclipses spaced at 18.03 yr intervals.\nEarth\u2013Moon system.\nAn eclipse involving the Sun, Earth, and Moon can occur only when they are nearly in a straight line, allowing one to be hidden behind another, viewed from the third. Because the orbital plane of the Moon is tilted with respect to the orbital plane of the Earth (the ecliptic), eclipses can occur only when the Moon is close to the intersection of these two planes (the nodes). The Sun, Earth and nodes are aligned twice a year (during an eclipse season), and eclipses can occur during a period of about two months around these times. There can be from four to seven eclipses in a calendar year, which repeat according to various eclipse cycles, such as a saros.\nBetween 1901 and 2100 there are the maximum of seven eclipses in:\nExcluding penumbral lunar eclipses, there are a maximum of seven eclipses in:\nSolar eclipse.\nAs observed from the Earth, a solar eclipse occurs when the Moon passes in front of the Sun. The type of solar eclipse event depends on the distance of the Moon from the Earth during the event. A total solar eclipse occurs when the Earth intersects the umbra portion of the Moon's shadow. When the umbra does not reach the surface of the Earth, the Sun is only partially occulted, resulting in an annular eclipse. Partial solar eclipses occur when the viewer is inside the penumbra.\nThe eclipse magnitude is the fraction of the Sun's diameter that is covered by the Moon. For a total eclipse, this value is always greater than or equal to one. In both annular and total eclipses, the eclipse magnitude is the ratio of the angular sizes of the Moon to the Sun.\nSolar eclipses are relatively brief events that can only be viewed in totality along a relatively narrow track. Under the most favorable circumstances, a total solar eclipse can last for 7\u00a0minutes, 31\u00a0seconds, and can be viewed along a track that is up to 250\u00a0km wide. However, the region where a partial eclipse can be observed is much larger. The Moon's umbra will advance eastward at a rate of 1,700\u00a0km/h, until it no longer intersects the Earth's surface.\nDuring a solar eclipse, the Moon can sometimes perfectly cover the Sun because its apparent size is nearly the same as the Sun's when viewed from the Earth. A total solar eclipse is in fact an occultation while an annular solar eclipse is a transit.\nWhen observed at points in space other than from the Earth's surface, the Sun can be eclipsed by bodies other than the Moon. Two examples include when the crew of Apollo 12 observed the in 1969 and when the \"Cassini\" probe observed in 2006.\nLunar eclipse.\nLunar eclipses occur when the Moon passes through the Earth's shadow. This happens only during a full moon, when the Moon is on the far side of the Earth from the Sun. Unlike a solar eclipse, an eclipse of the Moon can be observed from nearly an entire hemisphere. For this reason it is much more common to observe a lunar eclipse from a given location. A lunar eclipse lasts longer, taking several hours to complete, with totality itself usually averaging anywhere from about 30 minutes to over an hour.\nThere are three types of lunar eclipses: penumbral, when the Moon crosses only the Earth's penumbra; partial, when the Moon crosses partially into the Earth's umbra; and total, when the Moon crosses entirely into the Earth's umbra. Total lunar eclipses pass through all three phases. Even during a total lunar eclipse, however, the Moon is not completely dark. Sunlight refracted through the Earth's atmosphere enters the umbra and provides a faint illumination. Much as in a sunset, the atmosphere tends to more strongly scatter light with shorter wavelengths, so the illumination of the Moon by refracted light has a red hue, thus the phrase 'Blood Moon' is often found in descriptions of such lunar events as far back as eclipses are recorded.\nHistorical record.\nRecords of solar eclipses have been kept since ancient times. Eclipse dates can be used for chronological dating of historical records. A Syrian clay tablet, in the Ugaritic language, records a solar eclipse which occurred on March 5, 1223, B.C., while Paul Griffin argues that a stone in Ireland records an eclipse on November 30, 3340 B.C. Positing classical-era astronomers' use of Babylonian eclipse records mostly from the 13th century BC provides a feasible and mathematically consistent explanation for the Greek finding all three lunar mean motions (synodic, anomalistic, draconitic) to a precision of about one part in a million or better. Chinese historical records of solar eclipses date back over 3,000 years and have been used to measure changes in the Earth's rate of spin.\nThe first person to give scientific explanation on eclipses was Anaxagoras [c500BC - 428BC]. Anaxagoras stated that the Moon shines by reflected light from the Sun.\nIn 5th century AD, solar and lunar eclipses were scientifically explained by Aryabhata, in his treatise \"Aryabhatiya.\" Aryabhata states that the Moon and planets shine by reflected sunlight and explains eclipses in terms of shadows cast by and falling on Earth. Aryabhata provides the computation and the size of the eclipsed part during an eclipse. Indian computations were very accurate that 18th-century French scientist Guillaume Le Gentil, during a visit to Pondicherry, India, found the Indian computations of the duration of the lunar eclipse of 30 August 1765 to be short by only 41 seconds, whereas Le Gentil's charts were long by 68 seconds.\nBy the 1600s, European astronomers were publishing books with diagrams explaining how lunar and solar eclipses occurred. In order to disseminate this information to a broader audience and decrease fear of the consequences of eclipses, booksellers printed broadsides explaining the event either using the science or via astrology.\nEclipses in mythology and religion.\nThe American author Gene Weingarten described the tension between belief and eclipses thus: \"I am a devout atheist but can't explain why the moon is exactly the right size, and gets positioned so precisely between the Earth and the sun, that total solar eclipses are perfect. It bothers me.\"\nThe Graeco-Roman historian Cassius Dio, writing between AD 211\u2013229, relates the anecdote that Emperor Claudius considered it necessary to prevent disturbance among the Roman population by publishing a prediction for a solar eclipse which would fall on his birthday anniversary [1 August in the year AD 45]. In this context, Cassius Dio provides a detailed explanation of solar and lunar eclipses.\nTypically in mythology, eclipses were understood to be one variation or another of a spiritual battle between the sun and evil forces or spirits of darkness. More specifically, in Norse mythology, it is believed that there is a wolf by the name of Fenrir that is in constant pursuit of the Sun, and eclipses are thought to occur when the wolf successfully devours the divine Sun. Other Norse tribes believed that there are two wolves by the names of Sk\u00f6ll and Hati that are in pursuit of the Sun and the Moon, known by the names of Sol and Mani, and these tribes believed that an eclipse occurs when one of the wolves successfully eats either the Sun or the Moon.\nIn most types of mythologies and certain religions, eclipses were seen as a sign that the gods were angry and that danger was soon to come, so people often altered their actions in an effort to dissuade the gods from unleashing their wrath. In the Hindu religion, for example, people often sing religious hymns for protection from the evil spirits of the eclipse, and many people of the Hindu religion refuse to eat during an eclipse to avoid the effects of the evil spirits. Hindu people living in India will also wash off in the Ganges River, which is believed to be spiritually cleansing, directly following an eclipse to clean themselves of the evil spirits. In early Judaism and Christianity, eclipses were viewed as signs from God, and some eclipses were seen as a display of God's greatness or even signs of cycles of life and death. However, more ominous eclipses such as a blood moon were believed to be a divine sign that God would soon destroy their enemies.\nOther planets and dwarf planets.\nGas giants.\nThe gas giant planets have many moons and thus frequently display eclipses. The most striking involve Jupiter, which has four large moons and a low axial tilt, making eclipses more frequent as these bodies pass through the shadow of the larger planet. Transits occur with equal frequency. It is common to see the larger moons casting circular shadows upon Jupiter's cloudtops.\nThe eclipses of the Galilean moons by Jupiter became accurately predictable once their orbital elements were known. During the 1670s, it was discovered that these events were occurring about 17 minutes later than expected when Jupiter was on the far side of the Sun. Ole R\u00f8mer deduced that the delay was caused by the time needed for light to travel from Jupiter to the Earth. This was used to produce the first estimate of the speed of light.\nThe timing of the Jovian satellite eclipses was also used to calculate an observer's longitude upon the Earth. By knowing the expected time when an eclipse would be observed at a standard longitude (such as Greenwich), the time difference could be computed by accurately observing the local time of the eclipse. The time difference gives the longitude of the observer because every hour of difference corresponded to 15\u00b0 around the Earth's equator. This technique was used, for example, by Giovanni D. Cassini in 1679 to re-map France.\nOn the other three gas giants (Saturn, Uranus and Neptune) eclipses only occur at certain periods during the planet's orbit, due to their higher inclination between the orbits of the moon and the orbital plane of the planet. The moon Titan, for example, has an orbital plane tilted about 1.6\u00b0 to Saturn's equatorial plane. But Saturn has an axial tilt of nearly 27\u00b0. The orbital plane of Titan only crosses the line of sight to the Sun at two points along Saturn's orbit. As the orbital period of Saturn is 29.7\u00a0years, an eclipse is only possible about every 15 years.\nMars.\nOn Mars, only partial solar eclipses (transits) are possible, because neither of its moons is large enough, at their respective orbital radii, to cover the Sun's disc as seen from the surface of the planet. Eclipses of the moons by Mars are not only possible, but commonplace, with hundreds occurring each Earth year. There are also rare occasions when Deimos is eclipsed by Phobos. Martian eclipses have been photographed from both the surface of Mars and from orbit.\nPluto.\nPluto, with its proportionately largest moon Charon, is also the site of many eclipses. A series of such mutual eclipses occurred between 1985 and 1990. These daily events led to the first accurate measurements of the physical parameters of both objects.\nMercury and Venus.\nEclipses are impossible on Mercury and Venus, which have no moons. However, as seen from the Earth, both have been observed to transit across the face of the Sun. Transits of Venus occur in pairs separated by an interval of eight years, but each pair of events happen less than once a century. According to NASA, the next pair of Venus transits will occur on December 10, 2117, and December 8, 2125. Transits of Mercury are much more common, occurring 13 times each century, on average.\nEclipsing binaries.\nA binary star system consists of two stars that orbit around their common centre of mass. The movements of both stars lie on a common orbital plane in space. When this plane is very closely aligned with the location of an observer, the stars can be seen to pass in front of each other. The result is a type of extrinsic variable star system called an eclipsing binary.\nThe maximum luminosity of an eclipsing binary system is equal to the sum of the luminosity contributions from the individual stars. When one star passes in front of the other, the luminosity of the system is seen to decrease. The luminosity returns to normal once the two stars are no longer in alignment.\nThe first eclipsing binary star system to be discovered was Algol, a star system in the constellation Perseus. Normally this star system has a visual magnitude of 2.1. However, every 2.867 days the magnitude decreases to 3.4 for more than nine hours. This is caused by the passage of the dimmer member of the pair in front of the brighter star. The concept that an eclipsing body caused these luminosity variations was introduced by John Goodricke in 1783.\nTypes.\nSun \u2013 Moon \u2013 Earth: Solar eclipse | annular eclipse | hybrid eclipse | partial eclipse\nSun \u2013 Earth \u2013 Moon: Lunar eclipse | penumbral eclipse | partial lunar eclipse | central lunar eclipse\nSun \u2013 Phobos \u2013 Mars: Transit of Phobos from Mars | Solar eclipses on Mars\nSun \u2013 Deimos \u2013 Mars: Transit of Deimos from Mars | Solar eclipses on Mars\nOther types: Solar eclipses on Jupiter | Solar eclipses on Saturn | Solar eclipses on Uranus | Solar eclipses on Neptune | Solar eclipses on Pluto"}
{"id": "9771", "revid": "2790592", "url": "https://en.wikipedia.org/wiki?curid=9771", "title": "Ed (software)", "text": " (pronounced as distinct letters, ) is a line editor for Unix and Unix-like operating systems. It was one of the first parts of the Unix operating system that was developed, in August 1969. It remains part of the POSIX and Open Group standards for Unix-based operating systems, alongside the more sophisticated full-screen editor vi.\nHistory and influence.\nThe ed text editor was one of the first three key elements of the Unix operating system\u2014assembler, editor, and shell\u2014developed by Ken Thompson in August 1969 on a PDP-7 at AT&amp;T Bell Labs. Many features of ed came from the qed text editor developed at Thompson's alma mater University of California, Berkeley. Thompson was very familiar with qed, and had reimplemented it on the CTSS and Multics systems. Thompson's versions of qed were notable as the first to implement regular expressions. Regular expressions are also implemented in ed, though their implementation is considerably less general than that in qed.\nDennis M. Ritchie produced what Doug McIlroy later described as the \"definitive\" ed, and aspects of ed went on to influence ex, which in turn spawned vi. The non-interactive Unix command grep was inspired by a common special use of qed and later ed, where the command codice_1 performs a global regular expression search and prints the lines containing matches. The Unix stream editor, sed implemented many of the scripting features of qed that were not supported by ed on Unix.\nFeatures.\nFeatures of ed include:\nKnown for its terseness, ed, compatible with teletype terminals like Teletype Model 33, gives almost no visual feedback, and has been called (by Peter H. Salus) \"the most user-hostile editor ever created\", even when compared to the contemporary (and notoriously complex) TECO. For example, the message that ed will produce in case of error, \"and\" when it wants to make sure the user wishes to quit without saving, is \"?\". It does not report the current filename or line number, or even display the results of a change to the text, unless requested. Older versions (c. 1981) did not even ask for confirmation when a quit command was issued without the user saving changes. This terseness was appropriate in the early versions of Unix, when consoles were teletypes, modems were slow, and memory was precious. As computer technology improved and these constraints were loosened, editors with more visual feedback became the norm.\nIn current practice, ed is rarely used interactively, but does find use in some shell scripts. For interactive use, ed was subsumed by the sam, vi and Emacs editors in the 1980s. ed can be found on virtually every version of Unix and Linux available, and as such is useful for people who have to work with multiple versions of Unix. On Unix-based operating systems, some utilities like SQL*Plus run ed as the editor if the EDITOR and VISUAL environment variables are not defined. If something goes wrong, ed is sometimes the only editor available. This is often the only time when it is used interactively.\nThe version of ed provided by GNU has a few switches to enhance the feedback. Using provides a simple prompt and enables more useful feedback messages. The switch is defined in POSIX since XPG2 (1987).\nThe ed commands are often imitated in other line-based editors. For example, EDLIN in early MS-DOS versions and 32-bit versions of Windows NT has a somewhat similar syntax, and text editors in many MUDs (LPMud and descendants, for example) use ed-like syntax. These editors, however, are typically more limited in function.\nExample.\nHere is an example transcript of an ed session. For clarity, commands and text typed by the user are in normal face, and output from ed is emphasized.\n a\n This is line number two.\n 2i&lt;br&gt;\n ,l\n ed is the standard Unix text editor.$\n This is line number two.$\n w text.txt\n 63\n ,l\n ed is the standard Unix text editor.$\n This is line number three.$\n w text.txt\n 65\n q\nThe end result is a simple text file codice_2 containing the following text:\n ed is the standard Unix text editor.&lt;br&gt;\n This is line number three.\nStarted with an empty file, the codice_3 command appends text (all ed commands are single letters). The command puts ed in \"insert mode\", inserting the characters that follow and is terminated by a single dot on a line. The two lines that are entered before the dot end up in the file buffer. The codice_4 command also goes into insert mode, and will insert the entered text (a single empty line in our case) before line two. All commands may be prefixed by a line number to operate on that line.\nIn the line codice_5, the lowercase L stands for the list command. The command is prefixed by a range, in this case codice_6 which is a shortcut for codice_7. A range is two line numbers separated by a comma (codice_8 means the last line). In return, ed lists all lines, from first to last. These lines are ended with dollar signs, so that white space at the end of lines is clearly visible.\nOnce the empty line is inserted in line 2, the line which reads \"This is line number two.\" is now actually the third line. This error is corrected with , a substitution command. The codice_9 will apply it to the correct line; following the command is the text to be replaced, and then the replacement. Listing all lines with codice_5 the line is shown now to be correct.\ncodice_11 writes the buffer to the file codice_2 making ed respond with \"65\", the number of characters written to the file. codice_13 will end an ed session.\nCultural references.\nThe GNU Project has numerous jokes around ed hosted on its website. In addition, the glibc documentation notes an error code called with its description (errorstr) merely a single question mark, noting \"the experienced user will know what is wrong.\""}
{"id": "9772", "revid": "3641347", "url": "https://en.wikipedia.org/wiki?curid=9772", "title": "Edlin", "text": "Edlin is a line editor, and the only text editor provided with early versions of IBM PC DOS, MS-DOS and OS/2. Although superseded in MS-DOS 5.0 and later by the full-screen MS-DOS Editor, and by Notepad in Microsoft Windows, it continues to be included in the 32-bit versions of current Microsoft operating systems.\nHistory.\nEdlin was created by Tim Paterson in two weeks in 1980, for Seattle Computer Products's 86-DOS (QDOS) based on the CP/M context editor \"ED\", itself distantly inspired by the Unix \"ed\" line editor.\nMicrosoft acquired 86-DOS and, after some further development, sold it as MS-DOS, so Edlin was included in v1.0\u2013v5.0 of MS-DOS. From MS-DOS 6 onwards, the only editor included was the new full-screen MS-DOS Editor. \nWindows 95, 98 and ME ran on top of an embedded version of DOS, which reports itself as MS-DOS 7. As a successor to MS-DOS 6, this did not include Edlin. \nHowever, Edlin is included in the 32-bit versions of Windows NT and its derivatives\u2014up to and including Windows 10\u2014because the NTVDM's DOS support in those operating systems is based on MS-DOS version 5.0. However, unlike most other external DOS commands, it has not been transformed into a native Win32 program. It also does not support long filenames, which were not added to MS-DOS and Windows until long after Edlin was written.\nThe FreeDOS version was developed by Gregory Pietsch.\nUsage.\nThere are only a few commands. The short list can be found by entering a ? at the edlin prompt.\nWhen a file is open, typing L lists the contents (e.g., codice_1 lists lines 1 through 6). Each line is displayed with a line number in front of it.\n *1,6L\n 1: Edlin: The only text editor in early versions of DOS.\n 2:\n 3: Back in the day, I remember seeing web pages\n 4: branded with a logo at the bottom:\n 5: \"This page created in edlin.\"\n 6: The things that some people put themselves through. ;-)\nThe currently selected line has a *. To replace the contents of any line, the line number is entered and any text entered replaces the original. While editing a line pressing Ctrl-C cancels any changes. The * marker remains on that line.\nEntering I (optionally preceded with a line number) inserts one or more lines before the * line or the line given. When finished entering lines, Ctrl-C returns to the edlin command prompt.\n *6I\n 6:*(...or similar)\n 7:*^C \n *7D\n *L\n 1: Edlin: The only text editor in early versions of DOS.\n 2:\n 3: Back in the day, I remember seeing web pages\n 4: branded with a logo at the bottom:\n 5: \"This page created in edlin.\"\n 6: (...or similar)\nScripts.\nEdlin may be used as a non-interactive file editor in scripts by redirecting a series of edlin commands.\n edlin &lt; script\nFreeDOS Edlin.\nA GPL-licensed clone of Edlin that includes long filename support is available for download as part of the FreeDOS project. This runs on operating systems such as Linux or Unix as well as MS-DOS."}
{"id": "9773", "revid": "122189", "url": "https://en.wikipedia.org/wiki?curid=9773", "title": "EBCDIC", "text": "Extended Binary Coded Decimal Interchange Code (EBCDIC; ) is an eight-bit character encoding used mainly on IBM mainframe and IBM midrange computer operating systems. It descended from the code used with punched cards and the corresponding six-bit binary-coded decimal code used with most of IBM's computer peripherals of the late 1950s and early 1960s. It is supported by various non-IBM platforms, such as Fujitsu-Siemens' BS2000/OSD, OS-IV, MSP, and MSP-EX, the SDS Sigma series, Unisys VS/9, Unisys MCP and ICL VME.\nHistory.\nEBCDIC was devised in 1963 and 1964 by IBM and was announced with the release of the IBM System/360 line of mainframe computers. It is an eight-bit character encoding, developed separately from the seven-bit ASCII encoding scheme. It was created to extend the existing Binary-Coded Decimal (BCD) Interchange Code, or BCDIC, which itself was devised as an efficient means of encoding the two \"zone\" and \"number\" punches on punched cards into six bits. The distinct encoding of 's' and 'S' (using position 2 instead of 1) was maintained from punched cards where it was desirable not to have hole punches too close to each other to ensure the integrity of the physical card.\nWhile IBM was a chief proponent of the ASCII standardization committee, the company did not have time to prepare ASCII peripherals (such as card punch machines) to ship with its System/360 computers, so the company settled on EBCDIC. The System/360 became wildly successful, together with clones such as RCA Spectra 70, ICL System 4, and Fujitsu FACOM, thus so did EBCDIC.\nAll IBM's mainframe operating systems, and its IBM i operating system for midrange computers, use EBCDIC as their inherent encoding (with toleration for ASCII, for example, ISPF in z/OS can browse and edit both EBCDIC and ASCII encoded files). Software can translate to and from encodings, and modern mainframes (such as IBM Z) include processor instructions, at the hardware level, to accelerate translation between character sets. Modern z/OS compilers for the C and C++ languages on IBM Z mainframes, and earlier OS/390 C and C++ compilers on IBM System/390 mainframes, support a POSIX-compatible execution environment that makes use of ASCII by default.\nNot all operating systems running on IBM hardware use EBCDIC; IBM AIX, Linux on IBM Z, and Linux on Power all use ASCII, as do all operating systems that run on the IBM Personal Computer and its successors.\nCompatibility with ASCII.\nThere were numerous difficulties to writing software that would work in both ASCII and EBCDIC.\nCode page layout.\nThere are hundreds of EBCDIC code pages based on the original EBCDIC character encoding; there are a variety of EBCDIC code pages intended for use in different parts of the world, including code pages for non-Latin scripts such as Chinese, Japanese (e.g., EBCDIC 930, JEF, and KEIS), Korean, and Greek (EBCDIC 875). There is also a huge number of variations with the letters swapped around for no discernible reason.\nThe table below shows the \"invariant subset\" of EBCDIC, which are characters that \"should\" have the same assignments on all EBCDIC code pages that use the Latin alphabet. (This includes most of the ISO/IEC 646 invariant repertoire, except the exclamation mark.) It also shows (in gray) missing ASCII and EBCDIC punctuation, located where they are in Code Page 37 (one of the code page variants of EBCDIC). The blank cells are filled with region-specific characters in the variants, but the characters in gray are often swapped around or replaced as well. Like ASCII, the invariant subset works only for languages using the ISO basic Latin alphabet, such as English (excluding loanwords and some uncommon orthographic variations) and Dutch (if the \"\u0133\" and \"\u0132\" ligatures are written as two characters).\nDefinitions of non-ASCII EBCDIC controls.\nFollowing are the definitions of EBCDIC control characters which either do not map onto the ASCII control characters, or have additional uses. When mapped to Unicode, these are mostly mapped to C1 control character codepoints in a manner specified by IBM's Character Data Representation Architecture (CDRA).\nAlthough the default mapping of New Line (NL) corresponds to the ISO/IEC 6429 Next Line (NEL) character (the behaviour of which is also specified, but not required, in Unicode Annex 14), most of these C1-mapped controls match neither those in the ISO/IEC 6429 C1 set, nor those in other registered C1 control sets such as ISO 6630. Although this effectively makes the non-ASCII EBCDIC controls a unique C1 control set, they are not among the C1 control sets registered in the ISO-IR registry, meaning that they do not have an assigned control set designation sequence (as specified by ISO/IEC 2022, and optionally permitted in ISO/IEC 10646 (Unicode)).\nBesides U+0085 (Next Line), the Unicode Standard does not prescribe an interpretation of C1 control characters, leaving their interpretation to higher level protocols (it suggests, but does not require, their ISO/IEC 6429 interpretations in the absence of use for other purposes), so this mapping is permissible in, but not specified by, Unicode.\nCode pages with Latin-1 character sets.\nThe following code pages have the full Latin-1 character set (ISO/IEC 8859-1). The first column gives the original code page number. The second column gives the number of the code page updated with the euro sign (\u20ac) replacing the universal currency sign (\u00a4) (or in the case of EBCDIC 924, with the set changed to match ISO 8859-15)\nDifferent countries have different code pages because these code pages originated as code pages with country-specific character repertoires, and were later expanded to contain the entire ISO 8859-1 repertoire, meaning that a given ISO 8859-1 character may have different code point values in different code pages. They are known as Country Extended Code Pages (CECPs).\nCriticism and humor.\nOpen-source software advocate and software developer Eric S. Raymond writes in his \"Jargon File\" that EBCDIC was loathed by hackers, by which he meant members of a subculture of enthusiastic programmers. The Jargon File 4.4.7 gives the following definition:\nEBCDIC design was also the source of many jokes. One such joke, found in the Unix fortune file of 4.3BSD Reno (1990) went:\nReferences to the EBCDIC character set are made in the 1979 computer game series \"Zork\". In the \"Machine Room\" in \"Zork II\", EBCDIC is used to imply an incomprehensible language:\nIn 2021, it became public that a Belgian bank was still using EBCDIC internally in 2019. A customer insisted that the correct spelling of his surname included an umlaut, which the bank omitted, and the customer filed a complaint citing the guarantee in the General Data Protection Regulation of the right to timely \"rectification of inaccurate personal data.\" The bank's argument included the fact that their system used EBCDIC, as well as that it did not support letters with diacritics (or lower case, for that matter). The appeals court ruled in favor of the customer."}
{"id": "9775", "revid": "49129766", "url": "https://en.wikipedia.org/wiki?curid=9775", "title": "Endoplasmic reticulum", "text": "The endoplasmic reticulum (ER) is a part of a transportation system of the eukaryotic cell, and has many other important functions such as protein folding. The word endoplasmic means \u201cwithin the cytoplasm,\u201d and reticulum is Latin for \u201clittle net\u201d. It is a type of organelle made up of two subunits \u2013 rough endoplasmic reticulum (RER), and smooth endoplasmic reticulum (SER). The endoplasmic reticulum is found in most eukaryotic cells and forms an interconnected network of flattened, membrane-enclosed sacs known as cisternae (in the RER), and tubular structures in the SER. The membranes of the ER are continuous with the outer nuclear membrane. The endoplasmic reticulum is not found in red blood cells, or spermatozoa.\nThe two types of ER share many of the same proteins and engage in certain common activities such as the synthesis of certain lipids and cholesterol. Different types of cells contain different ratios of the two types of ER depending on the activities of the cell. RER is found mainly toward the nucleus of the cell and SER towards the cell membrane or plasma membrane of cell.\nThe outer (cytosolic) face of the RER is studded with ribosomes that are the sites of protein synthesis. The RER is especially prominent in cells such as hepatocytes. The SER lacks ribosomes and functions in lipid synthesis but not metabolism, the production of steroid hormones, and detoxification. The SER is especially abundant in mammalian liver and gonad cells.\nThe ER was observed by light microscopy by Garnier in 1897, who coined the term \"ergastoplasm\". The lacy membranes of the endoplasmic reticulum were first seen by electron microscopy in 1945 by Keith R. Porter, Albert Claude, and Ernest F. Fullam.\nStructure.\nThe general structure of the endoplasmic reticulum is a network of membranes called cisternae. These sac-like structures are held together by the cytoskeleton. The phospholipid membrane encloses the cisternal space (or lumen), which is continuous with the perinuclear space but separate from the cytosol. The functions of the endoplasmic reticulum can be summarized as the synthesis and export of proteins and membrane lipids, but varies between ER and cell type and cell function. The quantity of both rough and smooth endoplasmic reticulum in a cell can slowly interchange from one type to the other, depending on the changing metabolic activities of the cell. Transformation can include embedding of new proteins in membrane as well as structural changes. Changes in protein content may occur without noticeable structural changes.\nRough endoplasmic reticulum.\nThe surface of the rough endoplasmic reticulum (often abbreviated \"RER\" or \"rough ER\"; also called \"granular endoplasmic reticulum\") is studded with protein-manufacturing ribosomes giving it a \"rough\" appearance (hence its name). The binding site of the ribosome on the rough endoplasmic reticulum is the translocon. However, the ribosomes are not a stable part of this organelle's structure as they are constantly being bound and released from the membrane. A ribosome only binds to the RER once a specific protein-nucleic acid complex forms in the cytosol. This special complex forms when a free ribosome begins translating the mRNA of a protein destined for the secretory pathway. The first 5\u201330 amino acids polymerized encode a signal peptide, a molecular message that is recognized and bound by a signal recognition particle (SRP). Translation pauses and the ribosome complex binds to the RER translocon where translation continues with the nascent (new) protein forming into the RER lumen and/or membrane. The protein is processed in the ER lumen by an enzyme (a signal peptidase), which removes the signal peptide. Ribosomes at this point may be released back into the cytosol; however, non-translating ribosomes are also known to stay associated with translocons.\nThe membrane of the rough endoplasmic reticulum is in the form of large double-membrane sheets that are located near, and continuous with, the outer layer of the nuclear envelope. The double membrane sheets are stacked and connected through several right- or left-handed helical ramps, the \"Terasaki ramps\", giving rise to a structure resembling a parking garage. Although there is no continuous membrane between the endoplasmic reticulum and the Golgi apparatus, membrane-bound transport vesicles shuttle proteins between these two compartments. Vesicles are surrounded by coating proteins called COPI and COPII. COPII targets vesicles to the Golgi apparatus and COPI marks them to be brought back to the rough endoplasmic reticulum. The rough endoplasmic reticulum works in concert with the Golgi complex to target new proteins to their proper destinations. The second method of transport out of the endoplasmic reticulum involves areas called membrane contact sites, where the membranes of the endoplasmic reticulum and other organelles are held closely together, allowing the transfer of lipids and other small molecules.\nThe rough endoplasmic reticulum is key in multiple functions:\nSmooth endoplasmic reticulum.\nIn most cells the smooth endoplasmic reticulum (abbreviated SER) is scarce. Instead there are areas where the ER is partly smooth and partly rough, this area is called the transitional ER. The transitional ER gets its name because it contains ER exit sites. These are areas where the transport vesicles which contain lipids and proteins made in the ER, detach from the ER and start moving to the Golgi apparatus. Specialized cells can have a lot of smooth endoplasmic reticulum and in these cells the smooth ER has many functions. It synthesizes lipids, phospholipids, and steroids. Cells which secrete these products, such as those in the testes, ovaries, and sebaceous glands have an abundance of smooth endoplasmic reticulum. It also carries out the metabolism of carbohydrates, detoxification of natural metabolism products and of alcohol and drugs, attachment of receptors on cell membrane proteins, and steroid metabolism. In muscle cells, it regulates calcium ion concentration. Smooth endoplasmic reticulum is found in a variety of cell types (both animal and plant), and it serves different functions in each. The smooth endoplasmic reticulum also contains the enzyme glucose-6-phosphatase, which converts glucose-6-phosphate to glucose, a step in gluconeogenesis. It is connected to the nuclear envelope and consists of tubules that are located near the cell periphery. These tubes sometimes branch forming a network that is reticular in appearance. In some cells, there are dilated areas like the sacs of rough endoplasmic reticulum. The network of smooth endoplasmic reticulum allows for an increased surface area to be devoted to the action or storage of key enzymes and the products of these enzymes.\nSarcoplasmic reticulum.\nThe sarcoplasmic reticulum (SR), from the Greek \u03c3\u03ac\u03c1\u03be \"sarx\" (\"flesh\"), is smooth ER found in muscle cells. The only structural difference between this organelle and the smooth endoplasmic reticulum is the composition of proteins they have, both bound to their membranes and drifting within the confines of their lumens. This fundamental difference is indicative of their functions: The endoplasmic reticulum synthesizes molecules, while the sarcoplasmic reticulum stores calcium ions and pumps them out into the sarcoplasm when the muscle fiber is stimulated. After their release from the sarcoplasmic reticulum, calcium ions interact with contractile proteins that utilize ATP to shorten the muscle fiber. The sarcoplasmic reticulum plays a major role in excitation-contraction coupling.\nFunctions.\nThe endoplasmic reticulum serves many general functions, including the folding of protein molecules in sacs called cisternae and the transport of synthesized proteins in vesicles to the Golgi apparatus. Rough endoplasmic reticulum is also involved in protein synthesis. Correct folding of newly made proteins is made possible by several endoplasmic reticulum chaperone proteins, including protein disulfide isomerase (PDI), ERp29, the Hsp70 family member BiP/Grp78, calnexin, calreticulin, and the peptidylprolyl isomerase family. Only properly folded proteins are transported from the rough ER to the Golgi apparatus \u2013 unfolded proteins cause an unfolded protein response as a stress response in the ER. Disturbances in redox regulation, calcium regulation, glucose deprivation, and viral infection or the over-expression of proteins can lead to endoplasmic reticulum stress response (ER stress), a state in which the folding of proteins slows, leading to an increase in unfolded proteins. This stress is emerging as a potential cause of damage in hypoxia/ischemia, insulin resistance, and other disorders.\nProtein transport.\nSecretory proteins, mostly glycoproteins, are moved across the endoplasmic reticulum membrane. Proteins that are transported by the endoplasmic reticulum throughout the cell are marked with an address tag called a signal sequence. The N-terminus (one end) of a polypeptide chain (i.e., a protein) contains a few amino acids that work as an address tag, which are removed when the polypeptide reaches its destination. Nascent peptides reach the ER via the translocon, a membrane-embedded multiprotein complex. Proteins that are destined for places outside the endoplasmic reticulum are packed into transport vesicles and moved along the cytoskeleton toward their destination. In human fibroblasts, the ER is always co-distributed with microtubules and the depolymerisation of the latter cause its co-aggregation with mitochondria, which are also associated with the ER.\nThe endoplasmic reticulum is also part of a protein sorting pathway. It is, in essence, the transportation system of the eukaryotic cell. The majority of its resident proteins are retained within it through a retention motif. This motif is composed of four amino acids at the end of the protein sequence. The most common retention sequences are KDEL for lumen-located proteins and KKXX for transmembrane proteins. However, variations of KDEL and KKXX do occur, and other sequences can also give rise to endoplasmic reticulum retention. It is not known whether such variation can lead to sub-ER localizations. There are three KDEL (1, 2 and 3) receptors in mammalian cells, and they have a very high degree of sequence identity. The functional differences between these receptors remain to be established.\nBioenergetics regulation of ER ATP supply by a CaATiER mechanism.\nThe endoplasmic reticulum does not harbor an ATP-regeneration machinery, and therefore requires ATP import from mitochondria. The imported ATP is vital for the ER to carry out its house keeping cellular functions, such as for protein folding and trafficking.\nThe ER ATP transporter, SLC35B1/AXER, was recently cloned and characterized, and the mitochondria supply ATP to the ER through a \"Ca2+-antagonized transport into the ER\" (\"CaATiER\") mechanism. The \"CaATiER\" mechanism shows sensitivity to cytosolic Ca2+ ranging from high nM to low \u03bcM range, with the Ca2+-sensing element yet to be identified and validated.\nClinical significance.\nIncreased and supraphysiological ER stress in pancreatic \u03b2 cells disrupts normal insulin secretion, leading to hyperinsulinemia and consequently peripheral insulin resistance associated with obesity in humans. Human clinical trials also suggested a causal link between obesity-induced increase in insulin secretion and peripheral insulin resistance.\nAbnormalities in XBP1 lead to a heightened endoplasmic reticulum stress response and subsequently causes a higher susceptibility for inflammatory processes that may even contribute to Alzheimer's disease. In the colon, XBP1 anomalies have been linked to the inflammatory bowel diseases including Crohn's disease.\nThe unfolded protein response (UPR) is a cellular stress response related to the endoplasmic reticulum. The UPR is activated in response to an accumulation of unfolded or misfolded proteins in the lumen of the endoplasmic reticulum. The UPR functions to restore normal function of the cell by halting protein translation, degrading misfolded proteins, and activating the signaling pathways that lead to increasing the production of molecular chaperones involved in protein folding. Sustained overactivation of the UPR has been implicated in prion diseases as well as several other neurodegenerative diseases and the inhibition of the UPR could become a treatment for those diseases."}
{"id": "9776", "revid": "48790087", "url": "https://en.wikipedia.org/wiki?curid=9776", "title": "Enemy (disambiguation)", "text": "An enemy is an individual or group that is seen as forcefully adverse or threatening.\nEnemy or The Enemy may also refer to:"}
{"id": "9778", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=9778", "title": "Executive Order 9066", "text": "Executive Order 9066 was a United States presidential executive order signed and issued during World War II by United States president Franklin D. Roosevelt on February 19, 1942. \"This order authorized the forced removal of all persons deemed a threat to national security from the West Coast to \"relocation centers\" further inland\u2014resulting in the incarceration of Japanese Americans.\" Two-thirds of the 125,000 people displaced were U.S. citizens.\nNotably, far more Americans of Asian descent were forcibly interned than Americans of European descent, both in total and as a share of their relative populations. German and Italian Americans who were sent to internment camps during the war were sent under the provisions of Presidential Proclamation 2526 and the Alien Enemy Act, part of the Alien and Sedition Act of 1798.\nTranscript of Executive Order 9066.\nThe text of Executive Order 9066 was as follows:\nBackground to the Order.\nOriginating from a proclamation that was signed on the day of the Pearl Harbor attack, December 7, 1941, Executive Order 9066 was enacted by President Franklin Delano Roosevelt to strictly regulate the actions of Japanese Americans in the United States. At this point, Japanese Americans were not allowed to apply for citizenship in the United States, despite having lived in the United States for generations. This proclamation declared all Japanese American adults as the \"alien enemy,\" resulting in strict travel bans and mass xenophobia toward Asian Americans. Tensions rose in the United States, ultimately causing President Roosevelt to sign Executive Order 9066 on February 19, 1942.\nThe Order was consistent with Roosevelt's long-time racial views toward Japanese Americans. During the 1920s, for example, he had written articles in the \"Macon Telegraph\" opposing white-Japanese intermarriage for fostering \"the mingling of Asiatic blood with European or American blood\" and praising California's ban on land ownership by the first-generation Japanese. In 1936, while president he privately wrote that, in regard to contacts between Japanese sailors and the local Japanese American population in the event of war, \u201cevery Japanese citizen or non-citizen on the Island of Oahu who meets these Japanese ships or has any connection with their officers or men should be secretly but definitely identified and his or her name placed on a special list of those who would be the first to be placed in a concentration camp.\" In addition, during the crucial period after Pearl Harbor the president had failed to speak out for the rights of Japanese Americans despite the urgings of advisors such as John Franklin Carter. During the same period, Roosevelt rejected the recommendations of Attorney General Francis Biddle and other top advisors, who opposed the incarceration of Japanese Americans.\nExclusion under the Order.\nThe text of Roosevelt's order did not use the terms \"Japanese\" or \"Japanese Americans,\" instead giving officials broad power to exclude \"any or all persons\" from a designated area. (The lack of a specific mention of Japanese or Japanese Americans also characterized Public Law 77-503, which Roosevelt signed on March 21, 1942, to enforce the order.) Nevertheless, EO 9066 was intended to be applied almost solely to persons of Japanese descent. Notably, in a 1943 letter, Attorney General Francis Biddle reminded Roosevelt that \"You signed the original Executive Order permitting the exclusions so the Army could handle the Japs. It was never intended to apply to Italians and Germans.\"\nPublic Law 77-50 was approved (after only an hour of discussion in the Senate and thirty minutes in the House) in order to provide for the enforcement of the executive order. Authored by War Department official Karl Bendetsen\u2014who would later be promoted to Director of the Wartime Civilian Control Administration and oversee the incarceration of Japanese Americans\u2014the law made violations of military orders a misdemeanor punishable by up to $5,000 in fines and one year in prison.\nUsing a broad interpretation of EO 9066, Lieutenant General John L. DeWitt issued orders declaring certain areas of the western United States as zones of exclusion under the Executive Order. In contrast to EO 9066, the text of these orders specified \"all people of Japanese ancestry.\" As a result, approximately 112,000 men, women, and children of Japanese ancestry were evicted from the West Coast of the continental United States and held in American relocation camps and other confinement sites across the country.\nRoosevelt hoped to establish concentration camps for Japanese Americans in Hawaii even after he signed Executive Order 9066. On February 26, 1942, he informed Secretary of the Navy Knox that he had \"long felt most of the Japanese should be removed from Oahu to one of the other islands.\" Nevertheless, the tremendous cost, including the diversion of ships from the front lines, as well as the quiet resistance of the local military commander General Delos Emmons, made this proposal impractical and Japanese Americans in Hawaii were never incarcerated. Although the Japanese-American population in Hawaii was nearly 40% of the population of the territory and Hawaii would have been first in line for a Japanese attack, only a few thousand people were detained there. This fact supported the government's eventual conclusion that the mass removal of ethnic Japanese from the West Coast was motivated by reasons other than \"military necessity.\"\nJapanese Americans and other Asians in the U.S. had suffered for decades from prejudice and racially motivated fears. Racially discriminatory laws prevented Asian Americans from owning land, voting, testifying against whites in court, and set up other restrictions. Additionally, the FBI, Office of Naval Intelligence and Military Intelligence Division had been conducting surveillance on Japanese-American communities in Hawaii and the continental U.S. from the early 1930s. In early 1941, President Roosevelt secretly commissioned a study to assess the possibility that Japanese Americans would pose a threat to U.S. security. The report, submitted one month before the Japanese bombing of Pearl Harbor, found that, \"There will be no armed uprising of Japanese\" in the United States. \"For the most part,\" the Munson Report said, \"the local Japanese are loyal to the United States or, at worst, hope that by remaining quiet they can avoid concentration camps or irresponsible mobs.\" A second investigation started in 1940, written by Naval Intelligence officer Kenneth Ringle and submitted in January 1942, likewise found no evidence of fifth column activity and urged against mass incarceration. Both were ignored by military and political leaders.\nOver two-thirds of the people of Japanese ethnicity who were incarcerated were American citizens. Many of the rest had lived in the country between 20 and 40 years. Most Japanese Americans, particularly the first generation born in the United States (the \"Nisei\"), identified as loyal to the United States of America. No Japanese-American citizen or Japanese national residing in the United States was ever found guilty of sabotage or espionage.\nThere were 10 of these internment camps across the country called \u201crelocation centers\u201d. There were two in Arkansas, two in Arizona, two in California, one in Idaho, one in Utah, one in Wyoming, and one in Colorado.\nWorld War II camps under the Order.\nSecretary of War Henry L. Stimson was responsible for assisting relocated people with transport, food, shelter, and other accommodations and delegated Colonel Karl Bendetsen to administer the removal of West Coast Japanese. Over the spring of 1942, General John L. DeWitt issued Western Defense Command orders for Japanese Americans to present themselves for removal. The \"evacuees\" were taken first to temporary assembly centers, requisitioned fairgrounds and horse racing tracks where living quarters were often converted livestock stalls. As construction on the more permanent and isolated War Relocation Authority camps was completed, the population was transferred by truck or train. These accommodations consisted of tar paper-walled frame buildings in parts of the country with bitter winters and often hot summers. The camps were guarded by armed soldiers and fenced with barbed wire (security measures not shown in published photographs of the camps). Camps held up to 18,000 people, and were small cities, with medical care, food, and education provided by the government. Adults were offered \"camp jobs\" with wages of $12 to $19 per month, and many camp services such as medical care and education were provided by the camp inmates themselves.\nNot only was there limited room for living but, \u201cLiving in cramped barracks with minimal privacy and inadequate facilities. The camp's location in Utah's desert meant extreme temperatures and harsh weather, making daily life even more challenging.\u201d Based on the evidence listed, it is proven that these camps held poor living conditions for those relocated. On top of that children had to undergo education in these barracks as well as buildings for religion, all of these conditions add to the unpleasant way of life.\nTermination, apology, and redress.\nIn 1943 and 1944, Roosevelt did not release those incarcerated in the camps despite the urgings of Attorney General Francis Biddle, Secretary of Interior Harold L. Ickes. Ickes blamed the president's failure to act on his need to win California in a potentially close election. In December 1944, Roosevelt suspended the Executive Order after the Supreme Court decision \"Ex parte Endo\". Detainees were released, often to resettlement facilities and temporary housing, and the camps were shut down by 1946.\nOn February 19, 1976, President Gerald Ford signed a proclamation formally terminating Executive Order 9066 and apologizing for the internment, stated: \"We now know what we should have known then\u2014not only was that evacuation wrong but Japanese Americans were and are loyal Americans. On the battlefield and at home the names of Japanese Americans have been and continue to be written in history for the sacrifices and the contributions they have made to the well-being and to the security of this, our common Nation.\"\nIn 1980, President Jimmy Carter signed legislation to create the Commission on Wartime Relocation and Internment of Civilians (CWRIC). The CWRIC was appointed to conduct an official governmental study of Executive Order 9066, related wartime orders, and their effects on Japanese Americans in the West and Alaska Natives in the Pribilof Islands.\nIn December 1982, the CWRIC issued its findings in \"Personal Justice Denied\", concluding that the incarceration of Japanese Americans had not been justified by military necessity. The report determined that the decision to incarcerate was based on \"race prejudice, war hysteria, and a failure of political leadership\". The Commission recommended legislative remedies consisting of an official Government apology and redress payments of $20,000 to each of the survivors; a public education fund was set up to help ensure that this would not happen again ().\nOn August 10, 1988, the Civil Liberties Act of 1988, based on the CWRIC recommendations, was signed into law by Ronald Reagan. On November 21, 1989, George H. W. Bush signed an appropriation bill authorizing payments to be paid out between 1990 and 1998. In 1990, surviving internees began to receive individual redress payments and a letter of apology. This bill applied to the Japanese Americans and to members of the Aleut people inhabiting the strategic Aleutian islands in Alaska who had also been relocated.\nLife after the camps.\nIn the years after the war, the interned Japanese Americans had to rebuild their lives after having suffered heavy personal losses. United States citizens and long-time residents who had been incarcerated lost their personal liberties. Many also lost their homes, businesses, property, and savings. Individuals born in Japan were not allowed to become naturalized US citizens until after passage of the Immigration and Nationality Act of 1952, which canceled the Immigration Act of 1924 and reinstated the legality of immigration from Japan into the US.\nMany Japanese Americans hoped they would be going back to their homes, but soon realized that all of their possessions that they could carry with them were seized by the government. In place of their homes, the Federal government provided trailers in some areas for returning Japanese Americans. The populous Asian American community prior to the incarceration drastically decreased as many felt there was no life to go back to, choosing to start over somewhere else. With the residual effects of being incarcerated without committing a crime, the Japanese American community experienced strong trauma and continuing racism from their fellow Americans. Though they did receive redress of $20,000 per surviving incarcerate, many Japanese Americans feared increased Xenophobia and a minimizing of the trauma that the Japanese community endured during the WWII incarceration. Managing the wrongs committed to their community, Japanese Americans slowly managed to overcome their community's criminalization and incarceration and came to recognize February 19, the day President Roosevelt signed Executive Order 9066, as a National Day of Remembrance for Americans to reflect on the events that took place.\nCourt challenges.\nKorematsu v. United States.\nAfter the signing of Executive Order 9066 in February 1942, all Japanese Americans were required to be removed from their homes and moved into military camps as a matter of national security. Fred Korematsu, 23 at the time, was someone who elected not to comply, unlike his parents who left their home and flower nursery behind. Instead, Korematsu had plastic surgery to alter the appearance of his eyes and changed his name to Clyde Sarah, claiming Spanish and Hawaiian heritage. Six months later, on May 30, Korematsu was arrested for violating the order, leading to a trial in a San Francisco Federal Court. His case was presented by the American Civil Liberties Union, which attempted to challenge whether this order was constitutional or not. After losing the case, Korematsu appealed the decision all the way to the Supreme Court, where in a 6\u20133 decision, the order remained for reason of \"military necessity.\"\nHirabayashi v. United States.\nIncluded in FDR's order was a curfew starting at 8pm and ended at 6 am for all those of Japanese descent. University of Washington student, Gordon Hirabayashi, refused to abide by the order in an act of civil disobedience, resulting in his arrest. Similar to Korematsu's case, it was appealed and up to the Supreme Court. It was held by the Supreme Court in a unanimous decision that his arrest was constitutional on the basis of military necessity. He was sentenced six months in prison as a result of his civil disobedience.\nYasui v. United States.\nEarning his JD in 1939 from the University of Oregon, Minoru Yasui was the first Japanese American attorney admitted to the state of Oregon's bar. He began working as a consulate in Chicago for the Japanese government, but resigned shortly after the attack on Pearl Harbor. Returning to Oregon, where he was born, he tried to join the US Army but was denied. He was arrested in December 1941 for violating the military curfew, leading to his arrest and freezing of his assets. Looking to test the constitutionality of the curfew, Yasui turned himself into the police station as 11pm, five hours past the curfew. Yasui was found guilty of violating this curfew and was fined $5000 for not being a US citizen, despite being born in Oregon. He served a one-year prison sentence. Yasui appealed his case up to the Supreme Court, where it was held that the curfew was constitutional based on military necessity.\nReopening and justice.\nIn 1983, Peter Irons and Aiko Herzig-Yoshinaga discovered crucial evidence that allowed for them to petition to reopen the Korematsu case. The evidence was a copy of Lieutenant Commander K.D. Ringle's original report by the US Navy, which had not been destroyed. The report was in response to the question of Japanese loyalty to the US. It was stated in the report that Japanese Americans did not truly pose a threat to the US government, showing that the passage of Executive Order 9066 was entirely based on the false pretense that Japanese Americans were \"enemy aliens.\" This new found evidence was a document that failed to be destroyed by the US government in which included government intelligence agencies citing that Japanese Americans posed no military threat. The cases of Korematsu, Hirabayashi, and Yasui were reopened and overturned on the basis of government misconduct on November 10, 1983. In 2010, the state of California passed a bill that would name January 30 Fred Korematsu Day, making this the first day to be named after an Asian American. Korematsu v. United States was officially overturned in 2018, with Justice Sonia Sotomayor, describing the case as \"gravely wrong the day it was decided.\"\nLegacy.\nFebruary 19, the anniversary of the signing of Executive Order 9066, is now the Day of Remembrance, an annual commemoration of the unjust incarceration of the Japanese-American community. In 2017, the Smithsonian launched an exhibit about these events with artwork by Roger Shimomura. It provides context and interprets the treatment of Japanese Americans during World War II. In February 2022, for the 80th anniversary of the signing of the order, supporters lobbied to pass the Amache National Historic Site Act historical designation for the Granada War Relocation Center in Colorado."}
{"id": "9779", "revid": "11885793", "url": "https://en.wikipedia.org/wiki?curid=9779", "title": "Edvard Munch", "text": "Edvard Munch ( ; ; 12 December 1863 \u2013 23 January 1944) was a Norwegian painter. His 1893 work \"The Scream\" has become one of Western art's most acclaimed images.\nHis childhood was overshadowed by illness, bereavement and the dread of inheriting a mental condition that ran in the family. Studying at the Royal School of Art and Design in Kristiania (today's Oslo), Munch began to live a bohemian life under the influence of the nihilist Hans J\u00e6ger, who urged him to paint his own emotional and psychological state ('soul painting'); from this emerged his distinctive style.\nTravel brought new influences and outlets. In Paris, he learned much from Paul Gauguin, Vincent van Gogh and Henri de Toulouse-Lautrec, especially their use of color. In Berlin, he met the Swedish dramatist August Strindberg, whom he painted, as he embarked on a major series of paintings he would later call \"The Frieze of Life\", depicting a series of deeply-felt themes such as love, anxiety, jealousy and betrayal, steeped in atmosphere.\n\"The Scream\" was conceived in Kristiania. According to Munch, he was out walking at sunset, when he 'heard the enormous, infinite scream of nature'. The painting's agonized face is widely identified with the \"angst\" of the modern person. Between 1893 and 1910, he made two painted versions and two in pastels, as well as a number of prints. One of the pastels would eventually command the fourth highest nominal price paid for a painting at auction.\nAs his fame and wealth grew, his emotional state remained insecure. He briefly considered marriage, but could not commit himself. A mental breakdown in 1908 forced him to give up heavy drinking, and he was cheered by his increasing acceptance by the people of Kristiania and exposure in the city's museums. His later years were spent working in peace and privacy. Although his works were banned in Nazi-occupied Europe, most of them survived World War II, securing him a legacy.\nLife.\nChildhood.\nEdvard Munch was born in a farmhouse in the village of \u00c5dalsbruk in L\u00f8ten, Norway, to Laura Catherine Bj\u00f8lstad and Christian Munch, the son of a priest. Christian was a doctor and medical officer who married Laura, a woman half his age, in 1861. Edvard had an elder sister, Johanne Sophie, and three younger siblings: Peter Andreas, Laura Catherine, and Inger Marie. Laura was artistically talented and may have encouraged Edvard and Sophie. Edvard was related to the painter Jacob Munch and the historian Peter Andreas Munch.\nThe family moved to Oslo (then called Christiania and renamed Kristiania in 1877) in 1864 when Christian Munch was appointed medical officer at Akershus Fortress. In 1868 Edvard's mother died of tuberculosis, probably aggravated by the exhaustion of five consecutive pregnancies in seven years, imposed on her by her religious husband. Munch's favourite sister, Johanne Sophie, also died of tuberculosis, at the age of 15, in 1877. After their mother's death, the Munch siblings were raised by their father and by their aunt Karen. Often ill for much of the winters and kept out of school, Edvard would draw to keep himself occupied. He was tutored by his school mates and his aunt. Christian Munch also instructed his son in history and literature, and entertained the children with vivid ghost-stories and the tales of the American writer Edgar Allan Poe.\nAs Edvard remembered it, Christian's positive behavior towards his children was overshadowed by his morbid pietism. Munch wrote, \"My father was temperamentally nervous and obsessively religious\u2014to the point of psychoneurosis. From him I inherited the seeds of madness. The angels of fear, sorrow, and death stood by my side since the day I was born.\" Christian reprimanded his children by telling them that their mother was looking down from heaven and grieving over their misbehavior. The oppressive religious milieu, Edvard's poor health, and the vivid ghost stories helped inspire his macabre visions and nightmares; he felt that death was constantly approaching. One of Munch's younger sisters, Laura, was diagnosed with mental illness at an early age. Of the five siblings, only Andreas married, but he died a few months after the wedding. Munch would later write, \"I inherited two of mankind's most frightful enemies\u2014the heritage of consumption and insanity.\"\nChristian Munch's military pay was very low, and his attempts to develop a private side practice failed, keeping his family in genteel but perennial poverty. They moved frequently from one cheap flat to another. Munch's early drawings and watercolors depicted these interiors, and the individual objects, such as medicine bottles and drawing implements, plus some landscapes. By his teens, art dominated Munch's interests. At 13, Munch had his first exposure to other artists at the newly formed Art Association, where he admired the work of the Norwegian landscape school. He returned to copy the paintings, and soon he began to paint in oils.\nMental health.\nDue in part to the mental health struggles and incarceration in an institution of his sister, Laura Catherine, and in part to then-prevailing beliefs in hereditary insanity, Edvard Munch often expressed his fear that he would become insane. Critics of his art also accused him of insanity, deploying this term in a purely abusive sense. When his painting \"The Sick Child\" was first displayed in Oslo in 1886, Gustav Wentzel and other young Realists encircled Munch and accused him of being a \"madman;\" another critic Johan Scharffenberg stated that because Munch derived from an \"insane family\" his art was also \"insane.\" He is claimed by some to have had borderline personality disorder, a mental health disorder characterized by fear of abandonment, chronic feelings of emptiness, impulsive behavior, and various other symptoms. Munch also displayed alcoholism, a trait often associated with impulsivity in BPD.\nStudies and influences.\nIn 1879, Munch enrolled in a technical college to study engineering, where he excelled in physics, chemistry and mathematics. He learned scaled and perspective drawing, but frequent illnesses interrupted his studies. The following year, much to his father's disappointment, Munch left the college determined to become a painter. His father viewed art as an \"unholy trade\", and his neighbors reacted bitterly and sent him anonymous letters. In contrast to his father's rabid pietism, Munch adopted an undogmatic stance towards art. He wrote his goal in his diary: \"In my art I attempt to explain life and its meaning to myself.\"\nIn 1881, Munch enrolled at the Royal School of Art and Design of Kristiania, one of whose founders was his distant relative Jacob Munch. His teachers were the sculptor Julius Middelthun and the naturalistic painter Christian Krohg. That year, Munch demonstrated his quick absorption of his figure training at the academy in his first portraits, including one of his father and his first self-portrait. In 1883, Munch took part in his first public exhibition and shared a studio with other students. His full-length portrait of Karl Jensen-Hjell, a notorious bohemian-about-town, earned a critic's dismissive response: \"It is impressionism carried to the extreme. It is a travesty of art.\" Munch's nude paintings from this period survive only in sketches, except for \"Standing Nude\" (1887). They may have been confiscated by his father.\nImpressionism inspired Munch from a young age. During these early years, he experimented with many styles, including Naturalism and Impressionism. Some early works are reminiscent of Manet. Many of these attempts brought him unfavorable criticism from the press and garnered him constant rebukes by his father, who nonetheless provided him with small sums for living expenses. At one point, however, Munch's father, perhaps swayed by the negative opinion of Munch's cousin Edvard Diriks (an established, traditional painter), destroyed at least one painting (likely a nude) and refused to advance any more money for art supplies.\nMunch also received his father's ire for his relationship with Hans J\u00e6ger, the local nihilist who lived by the code \"a passion to destroy is also a creative passion\" and who advocated suicide as the ultimate way to freedom. Munch came under his malevolent, anti-establishment spell. \"My ideas developed under the influence of the bohemians or rather under Hans J\u00e6ger. Many people have mistakenly claimed that my ideas were formed under the influence of Strindberg and the Germans ... but that is wrong. They had already been formed by then.\" At that time, contrary to many of the other bohemians, Munch was still respectful of women, as well as reserved and well-mannered, but he began to give in to the binge drinking and brawling of his circle. He was unsettled by the sexual revolution going on at the time and by the independent women around him. He later turned cynical concerning sexual matters, expressed not only in his behavior and his art, but in his writings as well, an example being a long poem called \"The City of Free Love\".\nAfter numerous experiments, Munch concluded that the Impressionist idiom did not allow sufficient expression. He found it superficial and too akin to scientific experimentation. He felt a need to go deeper and explore situations brimming with emotional content and expressive energy. Under J\u00e6ger's commandment that Munch should \"write his life\", meaning that Munch should explore his own emotional and psychological state, the young artist began a period of reflection and self-examination, recording his thoughts in his \"soul's diary\". This deeper perspective helped move him to a new view of his art. He wrote that his painting \"The Sick Child\" (1886), based on his sister's death, was his first \"soul painting\", his first break from Impressionism. The painting received a negative response from critics and from his family, and caused another \"violent outburst of moral indignation\" from the community.\nOnly his friend Christian Krohg defended him:\nHe paints, or rather regards, things in a way that is different from that of other artists. He sees only the essential, and that, naturally, is all he paints. For this reason Munch's pictures are as a rule \"not complete\", as people are so delighted to discover for themselves. Oh, yes, they are complete. His complete handiwork. Art is complete once the artist has really said everything that was on his mind, and this is precisely the advantage Munch has over painters of the other generation, that he really knows how to show us what he has felt, and what has gripped him, and to this he subordinates everything else.\nMunch continued to employ a variety of brushstroke techniques and color palettes throughout the 1880s and early 1890s, as he struggled to define his style. His idiom continued to veer between naturalistic, as seen in \"Portrait of Hans J\u00e6ger\", and impressionistic, as in \"Rue Lafayette\". His \"Inger on the Beach\" (1889), which caused another storm of confusion and controversy, hints at the simplified forms, heavy outlines, sharp contrasts, and emotional content of his mature style to come. He began to carefully calculate his compositions to create tension and emotion. While stylistically influenced by the Post-Impressionists, what evolved was a subject matter which was symbolist in content, depicting a state of mind rather than an external reality. In 1889, Munch presented his first one-man show of nearly all his works to date. The recognition it received led to a two-year state scholarship to study in Paris under French painter L\u00e9on Bonnat.\nMunch seems to have been an early critic of photography as an art form, and remarked that it \"will never compete with the brush and the palette, until such time as photographs can be taken in Heaven or Hell!\"\nMunch's younger sister Laura was the subject of his 1899 interior \"Melancholy: Laura\". Amanda O'Neill says of the work, \"In this heated claustrophobic scene Munch not only portrays Laura's tragedy, but his own dread of the madness he might have inherited.\"\nParis.\nMunch arrived in Paris during the festivities of the Exposition Universelle (1889) and roomed with two fellow Norwegian artists. His picture \"Morning\" (1884) was displayed at the Norwegian pavilion. He spent his mornings at Bonnat's busy studio (which included female models) and afternoons at the exhibition, galleries, and museums (where students were expected to make copies as a way of learning technique and observation). Munch recorded little enthusiasm for Bonnat's drawing lessons\u2014\"It tires and bores me\u2014it's numbing\"\u2014but enjoyed the master's commentary during museum trips.\nMunch was enthralled by the vast display of modern European art, including the works of three artists who would prove influential: Paul Gauguin, Vincent van Gogh, and Henri de Toulouse-Lautrec\u2014all notable for how they used color to convey emotion. Munch was particularly inspired by Gauguin's \"reaction against realism\" and his credo that \"art was human work and not an imitation of Nature\", a belief earlier stated by Whistler. As one of his Berlin friends said later of Munch, \"he need not make his way to Tahiti to see and experience the primitive in human nature. He carries his own Tahiti within him.\" Influenced by Gauguin, as well as the etchings of German artist Max Klinger, Munch experimented with prints as a medium to create graphic versions of his works. In 1896 he created his first woodcuts\u2014a medium that proved ideal to Munch's symbolic imagery. Together with his contemporary Nikolai Astrup, Munch is considered an innovator of the woodcut medium in Norway.\nIn December 1889 his father died, leaving Munch's family destitute. He returned home and arranged a large loan from a wealthy Norwegian collector when wealthy relatives failed to help, and assumed financial responsibility for his family from then on. Christian's death depressed him and he was plagued by suicidal thoughts: \"I live with the dead\u2014my mother, my sister, my grandfather, my father...Kill yourself and then it's over. Why live?\" Munch's paintings of the following year included sketchy tavern scenes and a series of bright cityscapes in which he experimented with the pointillist style of Georges Seurat.\nBerlin.\nBy 1892, Munch had formulated his own characteristic, and original, synthetist style, as seen in \"Melancholy\" (1891), in which color is the symbol-laden element. Considered by the artist and journalist Christian Krohg as the first symbolist painting by a Norwegian artist, \"Melancholy\" was exhibited in 1891 at the Autumn Exhibition in Oslo. In 1892, Adelsteen Normann, on behalf of the Union of Berlin Artists, invited Munch to exhibit at its November exhibition, the society's first one-man exhibition. However, his paintings evoked bitter controversy (dubbed \"The Munch Affair\"), and after one week the exhibition closed. Munch was pleased with the \"great commotion\", and wrote in a letter: \"Never have I had such an amusing time\u2014it's incredible that something as innocent as painting should have created such a stir.\"\nIn Berlin, Munch became involved in an international circle of writers, artists and critics, including the Swedish dramatist and leading intellectual August Strindberg, whom he painted in 1892. He also met Danish writer and painter Holger Drachmann, whom he painted in 1898. Drachmann was 17 years Munch's senior and a drinking companion at Zum schwarzen Ferkel (At the Black Piglet) in 1893\u201394. In 1894 Drachmann wrote of Munch: \"He struggles hard. Good luck with your struggles, lonely Norwegian.\"\nDuring his four years in Berlin, Munch sketched out most of the ideas that would be comprised in his major work, \"The Frieze of Life\", first designed for book illustration but later expressed in paintings. He sold little, but made some income from charging entrance fees to view his controversial paintings. Munch began allowing the appearance of drips in his paintings, as first subtly seen in the painted version of \"At the Deathbed\" (1895). This effect resulted from the use of highly diluted paint and the deliberate inclusion of drips. Initially, this effect was visible at the edges of his work, but later, the drips became more central, as seen in \"By the Deathbed\" (1915). The effect of running paint was later adopted by many artists.\nHis other paintings, including casino scenes, show a simplification of form and detail which marked his early mature style. Munch also began to favor a shallow pictorial space and a minimal backdrop for his frontal figures. Since poses were chosen to produce the most convincing images of states of mind and psychological conditions, as in \"Ashes\", the figures impart a monumental, static quality. Munch's figures appear to play roles on a theatre stage (\"Death in the Sick-Room\"), whose pantomime of fixed postures signify various emotions; since each character embodies a single psychological dimension, as in \"The Scream\", Munch's men and women began to appear more symbolic than realistic. He wrote, \"No longer should interiors be painted, people reading and women knitting: there would be living people, breathing and feeling, suffering and loving.\"\n\"The Scream\".\n\"The Scream\" exists in four versions: two pastels (1893 and 1895) and two paintings (1893 and 1910). There are also several lithographs of \"The Scream\" (1895 and later).\nThe 1895 pastel sold at auction on 2 May 2012 for US$119,922,500, including commission. It is the most colorful of the versions and is distinctive for the downward-looking stance of one of its background figures. It is also the only version not held by a Norwegian museum.\nThe 1893 version was stolen from the National Gallery in Oslo in 1994 and was recovered. The 1910 painting was stolen in 2004 from the Munch Museum in Oslo, but recovered in 2006 with limited damage.\n\"The Scream\" is Munch's most famous work, and one of the most recognizable paintings in all art. It has been widely interpreted as representing the universal anxiety of modern man. Painted with broad bands of garish color and highly simplified forms, and employing a high viewpoint, it reduces the agonized figure to a garbed skull in the throes of an emotional crisis.\nWith this painting, Munch met his stated goal of \"the study of the soul, that is to say the study of my own self\". Munch wrote of how the painting came to be: \"I was walking down the road with two friends when the sun set; suddenly, the sky turned as red as blood. I stopped and leaned against the fence, feeling unspeakably tired. Tongues of fire and blood stretched over the bluish black fjord. My friends went on walking, while I lagged behind, shivering with fear. Then I heard the enormous, infinite scream of nature.\" He later described the personal anguish behind the painting, \"for several years I was almost mad... You know my picture, 'The Scream?' I was stretched to the limit\u2014nature was screaming in my blood... After that I gave up hope ever of being able to love again.\"\nIn 2003, comparing the painting with other great works, art historian Martha Tedeschi wrote:\n\"Whistler's Mother\", Wood's \"American Gothic\", Leonardo da Vinci's \"Mona Lisa\" and Edvard Munch's \"The Scream\" have all achieved something that most paintings\u2014regardless of their art historical importance, beauty, or monetary value\u2014have not: they communicate a specific meaning almost immediately to almost every viewer. These few works have successfully made the transition from the elite realm of the museum visitor to the enormous venue of popular culture.\n\"Frieze of Life \u2013 A Poem about Life, Love and Death\".\nIn December 1893, Unter den Linden in Berlin was the location of an exhibition of Munch's work, showing, among other pieces, six paintings entitled \"Study for a Series: Love.\" This began a cycle he later called the \"Frieze of Life \u2013 A Poem about Life, Love and Death\". \"Frieze of Life\" motifs, such as \"The Storm\" and \"Moonlight\", are steeped in atmosphere. Other motifs illuminate the nocturnal side of love, such as \"Rose and Amelie\" and \"Love and Pain\". In \"Death in the Sickroom\", the subject is the death of his sister Sophie, which he re-worked in many future variations. The dramatic focus of the painting, portraying his entire family, is dispersed in the separate and disconnected figures of sorrow. In 1894, he enlarged the spectrum of motifs by adding \"Anxiety\", \"Ashes\", \"Madonna\" and \"Women in Three Stages\" (from innocence to old age).\nAround the start of the 20th century, Munch worked to finish the \"Frieze\". He painted a number of pictures, several of them in bigger format and to some extent featuring the Art Nouveau aesthetics of the time. He made a wooden frame with carved reliefs for the large painting \"Metabolism\" (1898), initially called \"Adam and Eve\". This work reveals Munch's pre-occupation with the \"fall of man\" and his pessimistic philosophy of love. Motifs such as \"The Empty Cross\" and \"Golgotha\" (both ) reflect a metaphysical orientation, and also reflect Munch's pietistic upbringing. The entire \"Frieze\" was shown for the first time at the secessionist exhibition in Berlin in 1902.\n\"The Frieze of Life\" themes recur throughout Munch's work but he especially focused on them in the mid-1890s. In sketches, paintings, pastels and prints, he tapped the depths of his feelings to examine his major motifs: the stages of life, the femme fatale, the hopelessness of love, anxiety, infidelity, jealousy, sexual humiliation, and separation in life and death. These themes are expressed in paintings such as \"The Sick Child\" (1885), \"Love and Pain\" (retitled \"Vampire\"; 1893\u201394), \"Ashes\" (1894), and \"The Bridge\". The latter shows limp figures with featureless or hidden faces, over which loom the threatening shapes of heavy trees and brooding houses. Munch portrayed women either as frail, innocent sufferers (see \"Puberty\" and \"Love and Pain\") or as the cause of great longing, jealousy and despair (see \"Separation\", \"Jealousy\", and \"Ashes\").\nMunch often uses shadows and rings of color around his figures to emphasize an aura of fear, menace, anxiety, or sexual intensity. These paintings have been interpreted as reflections of the artist's sexual anxieties, though it could also be argued that they represent his turbulent relationship with love itself and his general pessimism regarding human existence. Many of these sketches and paintings were done in several versions, such as \"Madonna\", \"Hands\" and \"Puberty\", and also transcribed as wood-block prints and lithographs. Munch hated to part with his paintings because he thought of his work as a single body of expression. So to capitalize on his production and make some income, he turned to graphic arts to reproduce many of his paintings, including those in this series. Munch admitted to the personal goals of his work but he also offered his art to a wider purpose, \"My art is really a voluntary confession and an attempt to explain to myself my relationship with life\u2014it is, therefore, actually a sort of egoism, but I am constantly hoping that through this I can help others achieve clarity.\"\nWhile attracting strongly negative reactions, in the 1890s Munch began to receive some understanding of his artistic goals, as one critic wrote, \"With ruthless contempt for form, clarity, elegance, wholeness, and realism, he paints with intuitive strength of talent the most subtle visions of the soul.\" One of his great supporters in Berlin was Walther Rathenau, later the German foreign minister, who strongly contributed to his success.\nLandscapes and Nature.\nDespite over half of his painted works being landscapes, Munch is rarely seen as a landscape artist. However, Munch had a fixation on several elements of nature that resulted in recurrent motifs throughout his work. The shoreline and the forest are both significant settings of Munch's work. A focus on Munch's use of nature to convey emotion is the topic of \"Edvard Munch: Trembling Earth\" at the Clark Art Institute.\nParis, Berlin and Kristiania.\nIn 1896, Munch moved to Paris, where he focused on graphic representations of his \"Frieze of Life\" themes. He further developed his woodcut and lithographic technique. Munch's \"Self-Portrait with Skeleton Arm\" (1895) is done with an etching needle-and-ink method also used by Paul Klee. Munch also produced multi-colored versions of \"The Sick Child\", concerning tuberculosis, which sold well, as well as several nudes and multiple versions of \"Kiss\" (1892). In May 1896, Siegfried Bing held an exhibition of Munch's work inside Bing's Maison de l'Art Nouveau. The exhibition displayed 60 works, including \"The Kiss, The Scream, Madonna, The Sick Child, The Death Chamber, and The Day After.\" Bing's exhibition helped to introduce Munch to a French audience. Still, many of the Parisian critics still considered Munch's work \"violent and brutal\" even if his exhibitions received serious attention and good attendance. His financial situation improved considerably and, in 1897, Munch bought himself a summer house facing the fjords of Kristiania, a small fisherman's cabin built in the late 18th century, in the small town of \u00c5sg\u00e5rdstrand in Norway. He dubbed this home the \"Happy House\" and returned here almost every summer for the next 20 years. It was this place he missed when he was abroad and when he felt depressed and exhausted. \"To walk in \u00c5sg\u00e5rdstrand is like walking among my paintings\u2014I get so inspired to paint when I am here\".\nIn 1897 Munch returned to Kristiania, where he also received grudging acceptance\u2014one critic wrote, \"A fair number of these pictures have been exhibited before. In my opinion these improve on acquaintance.\" In 1899, Munch began an intimate relationship with Tulla Larsen, a \"liberated\" upper-class woman. They traveled to Italy together and upon returning, Munch began another fertile period in his art, which included landscapes and his final painting in \"The Frieze of Life\" series, \"The Dance of Life\" (1899). Larsen was eager for marriage, but Munch was not. His drinking and poor health reinforced his fears, as he wrote in the third person: \"Ever since he was a child he had hated marriage. His sick and nervous home had given him the feeling that he had no right to get married.\" Munch almost gave in to Tulla, but fled from her in 1900, also turning away from her considerable fortune, and moved to Berlin. His \"Girls on the Jetty\", created in 18 different versions, demonstrated the theme of feminine youth without negative connotations. In 1902, he displayed his works thematically at the hall of the Berlin Secession, producing \"a symphonic effect\u2014it made a great stir\u2014a lot of antagonism\u2014and a lot of approval.\" The Berlin critics were beginning to appreciate Munch's work even though the public still found his work alien and strange.\nThe good press coverage gained Munch the attention of influential patrons Albert Kollman and Max Linde. He described the turn of events in his diary, \"After 20 years of struggle and misery forces of good finally come to my aid in Germany\u2014and a bright door opens up for me.\" However, despite this positive change, Munch's self-destructive and erratic behavior led him first to a violent quarrel with another artist, then to an accidental shooting in the presence of Tulla Larsen, who had returned for a brief reconciliation, which injured two of his fingers. Munch later sawed a self-portrait depicting him and Larsen in half as a consequence of the shooting and subsequent events. She finally left him and married a younger colleague of Munch. Munch took this as a betrayal, and he dwelled on the humiliation for some time to come, channeling some of the bitterness into new paintings. His paintings \"Still Life (The Murderess)\" and \"The Death of Marat I\", done in 1906\u201307, clearly reference the shooting incident and the emotional after-effects.\nIn 1903\u201304, Munch exhibited in Paris where the coming Fauvists, famous for their boldly false colors, likely saw his works and might have found inspiration in them. When the Fauves held their own exhibit in 1906, Munch was invited and displayed his works with theirs. After studying the sculpture of Rodin, Munch may have experimented with plasticine as an aid to design, but he produced little sculpture. During this time, Munch received many commissions for portraits and prints which improved his usually precarious financial condition. In 1906, he painted the screen for an Ibsen play in the small Kammerspiele Theatre located in Berlin's Deutsches Theater, in which the \"Frieze of Life\" was hung. The theatre's director Max Reinhardt later sold it; it is now in the Berlin Nationalgalerie. After an earlier period of landscapes, in 1907 he turned his attention again to human figures and situations.\nBreakdown and recovery.\nIn the autumn of 1908, Munch's anxiety, compounded by excessive drinking and brawling, had become acute. As he later wrote, \"My condition was verging on madness\u2014it was touch and go.\" Subject to hallucinations and feelings of persecution, he entered the clinic of Daniel Jacobson. The therapy Munch received for the next eight months included diet and \"electrification\" (a treatment then fashionable for nervous conditions, not to be confused with electroconvulsive therapy). Munch's stay in hospital stabilized his personality, and after returning to Norway in 1909, his work became more colorful and less pessimistic. Further brightening his mood, the general public of Kristiania finally warmed to his work, and museums began to purchase his paintings. He was made a Knight of the Royal Order of St. Olav \"for services in art\". His first American exhibit was in 1912 in New York.\nAs part of his recovery, Jacobson advised Munch to only socialize with good friends and avoid drinking in public. Munch followed this advice and in the process produced several full-length portraits of high quality of friends and patrons\u2014honest portrayals devoid of flattery. He also created landscapes and scenes of people at work and play, using a new optimistic style\u2014broad, loose brushstrokes of vibrant color with frequent use of white space and rare use of black\u2014with only occasional references to his morbid themes. With more income Munch was able to buy several properties giving him new vistas for his art and he was finally able to provide for his family.\nThe outbreak of World War I found Munch with divided loyalties, as he stated, \"All my friends are German but it is France I love.\" In the 1930s, his German patrons, many Jewish, lost their fortunes and some their lives during the rise of the Nazi movement. Munch found Norwegian printers to substitute for the Germans who had been printing his graphic work. Given his poor health history, during 1918 Munch felt himself lucky to have survived a bout of the Spanish flu, the worldwide pandemic of that year.\nLater years.\nMunch spent most of his last two decades in solitude at his nearly self-sufficient estate in Ekely, at Sk\u00f8yen, Oslo. Many of his late paintings celebrate farm life, including several in which he used his work horse \"Rousseau\" as a model. Without any effort, Munch attracted a steady stream of female models, whom he painted as the subjects of numerous nude paintings. He likely had sexual relationships with some of them. Munch occasionally left his home to paint murals on commission, including those done for the Freia chocolate factory.\nTo the end of his life, Munch continued to paint unsparing self-portraits, adding to his self-searching cycle of his life and his unflinching series of takes on his emotional and physical states. In the 1930s and 1940s, the Nazis labeled Munch's work \"degenerate art\" (along with that of Picasso, Klee, Matisse, Gauguin and many other modern artists) and removed his 82 works from German museums. Adolf Hitler announced in 1937, \"For all we care, those pre-historic Stone Age culture barbarians and art-stutterers can return to the caves of their ancestors and there can apply their primitive international scratching.\"\nIn 1940, the Germans invaded Norway and the Nazi party took over the government. Munch was 76 years old. With nearly an entire collection of his art in the second floor of his house, Munch lived in fear of a Nazi confiscation. Seventy-one of the paintings previously taken by the Nazis had been returned to Norway through purchase by collectors (the other 11 were never recovered), including \"The Scream\" and \"The Sick Child\", and they too were hidden from the Nazis.\nMunch died in his house at Ekely near Oslo on 23 January 1944, about a month after his 80th birthday. His Nazi-orchestrated funeral suggested to Norwegians that he was a Nazi sympathizer, a kind of appropriation of the independent artist. The city of Oslo bought the Ekely estate from Munch's heirs in 1946; his house was demolished in May 1960.\nLegacy.\nWhen Munch died, his remaining works were bequeathed to the city of Oslo, which built the Munch Museum at T\u00f8yen (it opened in 1963). The museum holds a collection of approximately 1,100 paintings, 4,500 drawings, and 18,000 prints, the broadest collection of his works in the world. The Munch Museum serves as Munch's official estate; it has been active in responding to copyright infringements as well as clearing copyright for the work, such as the appearance of Munch's \"The Scream\" in a 2006 M&amp;M's advertising campaign. The U.S. copyright representative for the Munch Museum and the Estate of Edvard Munch is the Artists Rights Society.\nMunch's art was highly personalized and he did little teaching. His \"private\" symbolism was far more personal than that of other Symbolist painters such as Gustave Moreau and James Ensor. Munch was still highly influential, particularly with the German Expressionists, who followed his philosophy, \"I do not believe in the art which is not the compulsive result of Man's urge to open his heart.\" Many of his paintings, including \"The Scream\", have universal appeal in addition to their highly personal meaning.\nMunch's works are now represented in numerous major museums and galleries in Norway and abroad. His cabin, \"the Happy House\", was given to the municipality of \u00c5sg\u00e5rdstrand in 1944; it serves as a small Munch Museum. The inventory has been maintained exactly as he left it.\nOne version of \"The Scream\" was stolen from the National Gallery in 1994. In 2004, another version of \"The Scream\", along with one of \"Madonna\", was stolen from the Munch Museum in a daring daylight robbery. These were all eventually recovered, but the paintings stolen in the 2004 robbery were extensively damaged. They have been meticulously restored and are on display again. Three Munch works were stolen from the Hotel Refsnes Gods in 2005; they were shortly recovered, although one of the works was damaged during the robbery.\nIn October 2006, the color woodcut \"Two people. The lonely\" (\"To mennesker. De ensomme\") set a new record for his prints when it was sold at an auction in Oslo for 8.1\u00a0million kroner (US$1.27\u00a0million ). It also set a record for the highest price paid in auction in Norway. On 3 November 2008, the painting \"Vampire\" set a new record for his paintings when it was sold for US$38,162,000 () at Sotheby's New York.\nMunch's image appeared on the Norwegian 1,000-kroner note (Series VII; valid from 2001 to 2020), along with pictures inspired by his artwork.\nIn February 2012, a major Munch exhibition, \"Edvard Munch. The Modern Eye\", opened at the Schirn Kunsthalle Frankfurt; the exhibition was opened by Mette-Marit, Crown Princess of Norway.\nIn May 2012, \"The Scream\" sold for US$119.9\u00a0million (), and is the second most expensive artwork ever sold at an open auction. (It was surpassed in November 2013 by \"Three Studies of Lucian Freud\", which sold for US$142.4\u00a0million).\nIn 2013, four of Munch's paintings were depicted in a series of stamps by the Norwegian postal service, to commemorate in 2014 the 150th anniversary of his birth.\nOn 14 November 2016 a version of Munch's \"The Girls on the Bridge\" sold for US$54.5\u00a0million () at Sotheby's, New York, making it the second highest price achieved for one of his paintings.\nIn April 2019 the British Museum hosted the exhibition, \"Edvard Munch: Love and Angst\", comprising 83 artworks and including a rare original print of \"The Scream\".\nIn May 2022 the Courtauld Gallery hosted the exhibition, \"Edvard Munch. Masterpieces from Bergen\", showcasing 18 paintings from Norwegian industrialist Rasmus Meyer's collection.\nIn June 2023 the Clark Art Institute hosted the exhibition \"Edvard Munch: Trembling Earth\". It was the first exhibit in the United States to focus on how Munch used nature to convey deeper meaning in his painting. \"Trembling Earth\" featured more than 75 works, many from the Munchmuseet's collection, and over 40 paintings and prints from rarely seen private collections.\nIn September 2023, the Berlinische Galerie Museum for Modern Art hosted an exhibition \"Edvard Munch. Magic of the North\" in collaboration with the Munch Museum Oslo. The exhibition included around 80 works by Edvard Munch, supplemented by works by other artists who shaped the idea of the north and the modern art scene on the Spree in Berlin at the end of the 19th century.\nIn November 2023, the Museum Barberini in Potsdam also hosted an exhibition \"Edvard Munch: Trembling Earth\" in collaboration with the Munch Museum Oslo. The exhibition overlapped the Berlinische Galerie exhibition by eight weeks; both exhibitions were under the joint patronage of German President Frank-Walter Steinmeier and His Majesty King Harald V of Norway. The exhibition included more than 110 loans from other institutions.\nUniversity Aula.\nIn 1911 the final competition for the decoration of the large walls of the University of Oslo Aula (assembly hall) was held between Munch and Emanuel Vigeland. The episode is known as the \"Aula controversy\". In 1914 Munch was finally commissioned to decorate the Aula and the work was completed in 1916. This major work in Norwegian monumental painting includes 11 paintings covering . \"The Sun\", \"History\" and \"Alma Mater\" are the key works in this sequence. Munch declared: \"I wanted the decorations to form a complete and independent world of ideas, and I wanted their visual expression to be both distinctively Norwegian and universally human\". In 2014 it was suggested that the Aula paintings have a value of at least 500\u00a0million kroner.\nLooted art controversies.\nIn 2007, Munch's \"Summer Night at the Beach\" was returned to the granddaughter of Alma Mahler, who was forced to flee the Nazis with her Jewish husband in March 1938, after Hitler's annexation of Austria. In 2008 the Basel Fine Arts Museum rejected a claim for Munch's \"Madonna, a\" lithograph of a nude in black, red and blue\",\" from the heirs of the Jewish collector Curt Glaser. In 2012 Berlin's Kupferstichkabinett restituted three drawings by Munch to the heirs of Curt Glaser, a Jewish collector forced into exile by the Nazis. In 2012, a claim for \"The Scream\" from the heirs of Hugo Simon was rejected as it went to auction. In 2023 Munch's \"Dance on the Beach\" was the object of an accord between the Glaser heirs and the heirs of Thomas Olsen, a Norwegian shipowner and Munch's neighbour and collector."}
{"id": "9781", "revid": "91088", "url": "https://en.wikipedia.org/wiki?curid=9781", "title": "Extended Industry Standard Architecture", "text": "The Extended Industry Standard Architecture (frequently known by the acronym EISA and pronounced \"eee-suh\") is a bus standard for IBM PC compatible computers. It was announced in September 1988 by a consortium of PC clone vendors (the Gang of Nine) as an alternative to IBM's proprietary Micro Channel architecture (MCA) in its PS/2 series.\nIn comparison with the AT bus, which the Gang of Nine retroactively renamed to the ISA bus to avoid infringing IBM's trademark on its PC/AT computer, EISA is extended to 32 bits and allows more than one CPU to share the bus. The bus mastering support is also enhanced to provide access to 4\u00a0GB of memory. Unlike MCA, EISA can accept older ISA cards \u2014 the lines and slots for EISA are a superset of ISA.\nEISA was much favoured by manufacturers due to the proprietary nature of MCA, and even IBM produced some machines supporting it. It was somewhat expensive to implement (though not as much as MCA), so it never became particularly popular in desktop PCs. However, it was reasonably successful in the server market, as it was better suited to bandwidth-intensive tasks such as disk access and networking. Most EISA cards produced were either SCSI or network cards. EISA was also available on some non-IBM-compatible machines such as the DEC AlphaServer, , SGI Indigo2 and MIPS Magnum.\nBy the time there was a strong market need for a bus of these speeds and capabilities for desktop computers, the VESA Local Bus and later PCI filled this niche, and EISA vanished into obscurity.\nHistory.\nThe original IBM PC included five 8-bit slots, running at the system clock speed of 4.77\u00a0MHz. The PC/AT, introduced in 1984, had three 8-bit slots and five 16-bit slots, all running at the system clock speed of 6\u00a0MHz in the earlier models and 8\u00a0MHz in the last version of the computer. The 16-bit slots were a superset of the 8-bit configuration, so \"most\" 8-bit cards were able to plug into a 16-bit slot (some cards used a \"skirt\" design that physically interfered with the extended portion of the slot) and continue to run in 8-bit mode. One of the key reasons for the success of the IBM PC (and the PC clones that followed it) was the active ecosystem of third-party expansion cards available for the machines. IBM was restricted from patenting the bus and widely published the bus specifications.\nAs the PC-clone industry continued to build momentum in the mid- to late-1980s, several problems with the bus began to be apparent. First, because the \"AT slot\" (as it was known at the time) was not managed by any central standards group, there was nothing to prevent a manufacturer from \"pushing\" the standard. One of the most common issues was that as PC clones became more common, PC manufacturers began increasing the processor speed to maintain a competitive advantage. Unfortunately, because the ISA bus was originally locked to the processor clock, this meant that some 286 machines had ISA buses that ran at 10, 12, or even 16\u00a0MHz. In fact, the first systems to clock the ISA bus at 8\u00a0MHz were the turbo Intel 8088 clones that clocked the processors at 8\u00a0MHz. This caused many issues with incompatibility, where a true IBM-compatible third-party card (designed for an 8\u00a0MHz or 4.77\u00a0MHz bus) might not work reliably or at all in a higher-clocked system. Most PC makers eventually decoupled the bus clock from the system clock, but there was still no standards body to \"police\" the industry.\nAs companies like Dell modified the AT bus design, Phoenix Technologies in 1986 proposed a 32-bit extension to the AT bus in 1986, but leading clone vendor Compaq refused to cooperate. The AT architecture was so well entrenched that no single clone manufacturer had the leverage to create a standardized alternative, and there was no compelling reason for them to cooperate on a new standard. Because of this, when the first 386-based system (the Compaq Deskpro 386) was sold in 1986, it still supported 16-bit slots. Other 386 PCs followed suit, and the AT (later ISA) bus remained a part of most systems even into the late 1990s.\nMeanwhile, IBM began to worry that it was losing control of the industry it had created. In 1987, IBM released the PS/2 line of computers, most of which included the MCA bus. MCA included numerous enhancements over the 16-bit AT bus, including bus mastering, burst mode, software-configurable resources, and 32-bit capabilities. However, in an effort to reassert its dominant role, IBM patented the bus and placed stringent licensing and royalty policies on its use. A few manufacturers did produce licensed MCA machines (most notably, NCR), but overall the industry balked at IBM's restrictions.\nSteve Gibson proposed that clone makers adopt NuBus. Even while stating that the AT bus was sufficient for customers, a group of companies led by Compaq (the \"Gang of Nine\") developed a new bus instead. This new bus was named the Extended (or Enhanced) Industry Standard Architecture, or \"EISA\", while the older AT bus had already been renamed Industry Standard Architecture, or \"ISA\". This provided virtually all of the technical advantages of MCA, while remaining compatible with existing 8-bit and 16-bit cards, and (most enticing to system and card makers) minimal licensing cost.\nThe EISA bus slot is a two-level staggered pin system, with the upper part of the slot corresponding to the standard ISA bus pin layout. The additional features of the EISA bus are implemented on the lower part of the slot connector, using thin traces inserted into the insulating gap of the upper / ISA card card edge connector. Additionally, the lower part of the bus has five keying notches, so an ISA card with unusually long traces cannot accidentally extend down into the lower part of the slot.\nIntel introduced its first EISA chipset (and also their first chipset in the modern sense of the word) as the 82350 in September 1989. Intel introduced a lower-cost variant as the 82350DT, announced in April 1991; it began shipping in June of that year.\nThe first EISA computer announced was the HP Vectra 486 in October 1989. The first EISA computers to hit the market were the Compaq Deskpro 486 and the SystemPro. The SystemPro, being one of the first PC-style systems designed as a network server, was built from the ground up to take full advantage of the EISA bus. It included such features as multiprocessing, hardware RAID, and bus-mastering network cards.\nOne of the benefits to come out of the EISA standard was a final codification of the standard to which ISA slots and cards should be held (in particular, clock speed was fixed at an industry standard of 8.33\u00a0MHz). Thus, even systems that didn't use the EISA bus gained the advantage of having the ISA standardized, which contributed to its longevity.\nThe Gang of Nine.\nThe \"Gang of Nine\" was the informal name given to the consortium of personal computer manufacturing companies, led by Compaq, that together created the EISA bus. The nine companies together had more than 33% market share for all PCs in 1987, compared to IBM's 27%. The Gang of Nine had an even larger share of the market for 80386-based computers, with 43% compared to IBM's 16%. Compaq was among the first clone makers after the IBM PC's debut in 1981, and had 28% of the 80386 market; rival members generally acknowledged its leadership, with one stating in 1989 that within the Gang of Nine \"when you have 10 people sit down before a table to write a letter to the president, someone has to write the letter. Compaq is sitting down at the typewriter\". The members were:\nTechnical data.\nAlthough the MCA bus had a slight performance advantage over EISA (bus speed of 10\u00a0MHz, compared to 8.33\u00a0MHz), EISA contained almost all of the technological benefits that MCA boasted, including bus mastering, burst mode, software-configurable resources, and 32-bit data/address buses. These brought EISA nearly to par with MCA from a performance standpoint, and EISA easily defeated MCA in industry support.\nEISA replaced the tedious jumper configuration common with ISA cards with software-based configuration. Every EISA system shipped with an EISA configuration utility; this was usually a slightly customized version of the standard utilities written by the EISA chipset makers. The user would boot into this utility, either from floppy disk or on a dedicated hard-drive partition. The utility software would detect all EISA cards in the system and could configure any hardware resources (interrupts, memory ports, etc.) on any EISA card (each EISA card would include a disk with information that described the available options on the card) or on the EISA system motherboard. The user could also enter information about ISA cards in the system, allowing the utility to automatically reconfigure EISA cards to avoid resource conflicts.\nSimilarly, Windows 95, with its Plug-and-Play capability, was not able to change the configuration of EISA cards, but it could detect the cards, read their configuration, and reconfigure Plug-and-Play hardware to avoid resource conflicts. Windows 95 would also automatically attempt to install appropriate drivers for detected EISA cards.\nIndustry acceptance.\nEISA's success was far from guaranteed. IBM had lost market share because of slow PS/2 sales and customers' reluctance to use MCA. It debuted the AT bus-based PS/2 Model 30 286 in Manhattan at the same time as the EISA announcement also in the city, 17 months after tellilng customers that the AT bus was obsolete. Some customers wished that a 32-bit bus had been available years earlier, however, and now thought that IBM's rivals should adopt MCA, for which almost 400 expansion cards were available by EISA's introduction. Dell was a notable clone maker that did not join the Gang of Nine. Many manufacturers, including those in the Gang of Nine, researched the possibility of using MCA. For example, Compaq actually produced prototype DeskPro systems using the bus. However, these were never put into production, and when it was clear that MCA had lost, Compaq allowed its MCA license to expire (the license actually cost relatively little; the primary costs associated with MCA, and at which the industry revolted, were royalties to be paid per system shipped).\nOlivetti included EISA in its Olivetti NetStrada 7000 (CONDOR) product which embraced multiple bus architectures, its Adaptec RAID Controller occupied an EISA slot that could be accessed by up to 4 of its Pentium Pro 200 CPUs concurrently. \nOn the other hand, when it became clear to IBM that Micro Channel was dying, IBM actually licensed EISA for use in a few server systems. "}
{"id": "9782", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9782", "title": "EISA", "text": ""}
{"id": "9788", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9788", "title": "Electromagnetic spectroscopy", "text": ""}
{"id": "9789", "revid": "1271757233", "url": "https://en.wikipedia.org/wiki?curid=9789", "title": "Earthdawn", "text": "Earthdawn is a fantasy role-playing game, originally produced by FASA in 1993. In 1999 it was licensed to Living Room Games, which produced the \"Second Edition\". It was licensed to RedBrick in 2003, who released the Classic Edition in 2005 and the game's Third Edition in 2009 (the latter through Mongoose Publishing's Flaming Cobra imprint). The license is now held by FASA Games, Inc. (from FASA), who have released the Fourth Edition, with updated mechanics and an advanced metaplot timeline. Vagrant Workshop released the \"Age of Legend\" edition in 2016 using alternative rules-lite mechanics.\nThe game is similar to fantasy games like \"Dungeons &amp; Dragons\", but draws more inspiration from games like \"RuneQuest\". The rules of the game are tightly bound to the underlying magical metaphysics, with the goal of creating a rich, logical fantasy world. Like many role-playing games from the nineties, \"Earthdawn\" focuses much of its detail on its setting, a province called Barsaive. It was also originally written as a prequel to \"Shadowrun\", mirroring its setting of returning magic with one where magic has just recently dropped from its peak. However, after \"Shadowrun\" was licensed out to a different publisher, the ties between the two were deliberately severed.\nHistory.\nStarting in 1993, FASA released over 20 gaming supplements describing this universe; however, it closed down production of \"Earthdawn\" in January 1999. During that time several novels and short-story anthologies set in the \"Earthdawn\" universe were also released. In late 1999, FASA granted Living Room Games a licensing agreement to produce new material for the game.\nThe \"Second Edition\" did not alter the setting, though it did update the timeline to include events that took place in Barsaive. There were a few changes to the rules in the \"Second Edition\"; some classes were slightly different or altered abilities from the original. The changes were meant to allow for more rounded characters and better balance of play. Living Room Games last published in 2005 and they no longer have a license with FASA to publish Earthdawn material.\nIn 2003 a second license was granted to RedBrick, who developed their own edition based on the FASA products, in addition to releasing the original FASA books in PDF form. The \"Earthdawn Classic Player's Compendium\" and \"Earthdawn Classic Gamemaster's Compendium\" are essentially an alternative Second Edition, but without a version designation (since the material is compatible anyway). Each book has 524 pages and summarizes much of what FASA published\u2014not only the game mechanics, but also the setting, narrations, and stories. For example, each Discipline has its own chapter, describing it from the point of view of different adepts. Likewise, Barsaive gets a complete treatment, and the chapters contain a lot of log entries and stories in addition to the setting descriptions; the same applies to Horrors and Dragons. Errata was incorporated into the text, correcting previous edition errors and providing rules clarifications.\nWhile RedBrick tried to remain faithful to FASA's vision and visual style, they revised almost everything and introduced new material to fill the gaps. RedBrick began publishing new Earthdawn novels in 2007. In 2009, RedBrick announced the Third Edition of the game. To gain a larger audience for this edition, RedBrick published the book through Mongoose Publishing's Flaming Cobra imprint. The first two books were released in July 2009. In 2012, RedBrick ceased publishing and announced the transfer of the Earthdawn license to FASA Games, Inc.\nIn 2014, FASA Games announced the forthcoming publication of Earthdawn Fourth Edition and launched a successful Kickstarter to support the project. Fourth Edition is described as a reworking of the game mechanics, with redundancies eliminated, and a simpler success level system. The game world is advanced five years, past the end of the Barsaive-Thera War, in order to clear dangling threads in the metaplot and open the game world to new stories. The first Fourth Edition title\u2014the Player's Guide\u2014was released in early 2015. In 2014 FASA Corporation also gave permission for Impact Miniatures to return the original Heartbreaker Hobbies &amp; Games Official Earthdawn Miniatures range to production. In order to fund this, Impact Miniatures launched a successful Kickstarter project.\nIn 2016, Vagrant Workshop released the \"Age of Legend\" edition using a permutation of the rules-lite mechanics of the \"Freeform Universal\" RPG system. With its rules-lite mechanics the \"Age of Legend\" edition is marketed as being \"ideal for one-shots, convention games, and introductory games \u2014 even for kids!\"\nSetting.\nIn Barsaive, magic, like many things in nature, goes through cycles. As the magic level rises, it allows alien creatures called Horrors to cross from their distant, otherworldly dimension into our own. The Horrors come in an almost infinite variety\u2014from simple eating machines that devour all they encounter, to incredibly intelligent and cunning foes that feed off the negative emotions they inspire in their prey.\nIn the distant past of \"Earthdawn\"s setting, an elf scholar discovered that the time of the Horrors was approaching, and founded the Eternal Library in order to discover a way to defeat them \u2014 or at the very least, survive them. The community that grew up around the library developed wards and protections against the Horrors, which they traded to other lands and eventually became the powerful Theran Empire, an extremely magically advanced civilization and the main antagonist of the \"Earthdawn\" setting.\nThe peoples of the world built kaers, underground towns and cities, which they sealed with the Theran wards to wait out the time of the Horrors, which was called the Scourge. Theran wizards and politicians warned many of the outlying nations around Thera of the coming of the Horrors, offering the protection of the kaers to those who would pledge their loyalty to the Empire. Most of these nations agreed at first though some became unwilling to fulfill their end of the bargain after the end of the Scourge, wanting to have nothing to do with the bureaucratic nation run on political conflict and powered by slavery. After four hundred years of hiding, the Scourge ended, and the people emerged to a world changed by the Horrors. The player characters explore this new world, discovering lost secrets of the past, and fighting Horrors that remain.\nThe primary setting of Earthdawn is Barsaive, a former province of the Theran Empire. Barsaive is a region of city-states, independent from the Therans since the dwarven Kingdom of Throal led a rebellion against their former overlords. The Theran presence in Barsaive has been limited to a small part of south-western Barsaive, located around the magical fortress of Sky Point and the city of Vivane.\nThe setting of Earthdawn is the same world as \"Shadowrun\" (i.e. a fictionalized version of Earth), but takes place millennia earlier. The map of Barsaive and its neighboring regions established that most of the game takes place where Ukraine and Russia are in our world. However, the topography other than coastlines and major rivers is quite different, and the only apparent reference to the real world besides the map may be the Blood Wood, known as \"Wyrm Wood\" before the Scourge and similar in location and extent to the Chernobyl (Ukrainian for \"wormwood\") zone of alienation. Note should be made that game world links between \"Earthdawn\" and \"Shadowrun\" were deliberately broken by the publisher when the \"Shadowrun\" property was licensed out, in order to avoid the necessity for coordination between publishing companies. FASA has announced since then, that there are no plans to return \"Shadowrun\" to in-house publication, nor to restore the links between the game worlds.\nThree Earthdawn supplements cover territories outside Barsaive. \"The Theran Empire\" book (First Edition) covers the Theran Empire and its provinces (which roughly correspond to the territories of the Roman Empire, plus colonies in America and India). \"Cathay: The Five Kingdoms\" (Third Edition) covers the lands of Cathay (Far East).\"Vasgothia\" (Fourth Edition) covers the Theran Province in more detail than originally presented in First Edition (Germany). \nRaces.\nKnown as Namegivers, the setting of \"Earthdawn\" features several fantasy races for characters and NPCs:\nGame mechanics.\n\"Earthdawn\" stands out from other tabletop RPGs with a unique approach to skill tests. Players wanting to perform an action determine their level or \"step\" for the skill, talent, or ability to be used. This step can then be looked up in a list of dice to be thrown; it is the next-highest integer of the average roll of the dice(s) in question. For example, two six-sided dice will on average yield a result of 7, thus the step number 8 means that 2d6 will be rolled. The consequence is that each such dice roll has a 50% chance of yielding a result at least as high as the corresponding step number.\nThe result of each die is added (dice which reach their maximum value are thrown again, adding each maximum to the tally, along with the final result below maximum) and compared to a value decided by the game master/storyteller according to the difficulty of the task. This approach means it's always technically possible to succeed with a low step number, yet leaves room for failure on high step numbers. This will sometimes make combat last longer than in other games. As per the above, the difficulty value where the odds of success are perfectly even is identical to the step number.\nThe dice in steps 3 through 13 form the basis of an 11-Step cycle. To form Steps 14\u201324, add 1d20. To form Steps 25\u201335, further add 1d10 + 1d8. For higher cycles, continue alternating between the addition of 1d20 and 1d10 + 1d8. Step 2 is rolled as Step 3, but you subtract 1 from the result. This is notated as \"1d4 \u2013 1\". Step 1 is 1d4 \u2013 2.\nThe 3rd edition changes this by removing d4s and d20s from the system. Steps 6 through 12 (as listed above) form the basis of a 7-Step cycle. To add 7 Steps from then on, simply add 1d12.\nThe 4th edition changes this by making Steps 8 through 18 form the basis of an 11-Step cycle. To form Steps 19\u201329, add 1d20. To form Steps 30\u201341, add 2d20, and so on.\nThe \"Age of Legend\" edition departs from the Step System mechanics of previous Earthdawn editions and instead uses a permutation of the rules-lite mechanics of the \"Freeform Universal\" RPG system by Nathan Russell. In the \"Age of Legend\" permutation a six-sided die (\"d6\") is used with \"\"but...\" and \"and...\" situational modifiers added to four of the six die faces, and conditionally up to six additional Fudge dice of two differing colors which can alter the initial result of the main d6 die. (Alternatively, the \"Age of Legend\" edition can be played with just seven standard d6 dice, ideally of three differing colors.) Dice rolls in the \"Age of Legend\" edition answer closed yes\u2013no questions, with the default question being \"Do you get what you want?\" subsequent to a character's attempt to elicit a desired outcome.\nReception.\nStewart Wieck reviewed \"Earthdawn\" in \"White Wolf\" #37 (July/Aug., 1993), rating it a 3 out of 5 and stated that \"Earthdawn\" is a solid game, but the 'innovations' seem like unnecessary complications. The world is fun, but not fresh. This is not the fantasy game to leave your current campaign for unless you want to bank on the ever-fulfilled FASA promise - an extensive line of support material, much of which will be very good and will undoubtedly add a lot to the game.\"\nChris W. McCubbin reviewed \"Earthdawn\" in \"Pyramid\" #3 (Sept./Oct., 1993), and stated that \"Although it never becomes bogged down in cliches and avoids outmoded concepts, \"Earthdawn\" is, at heart, a very traditional heroic fantasy RPG.\"\nIn the February 1994 edition of \"Dragon\" (Issue 202), Rick Swan liked the high production values \"highlighted by striking illustrations and FASA\u2019s usual state-of-the-art graphics\", and found that \"Thanks to clear writing and sensible organization... it's an easy read.\" But Swan also found the game setting insubstantial compared to others. \"Despite workable rules and a clever setting, \"Earthdawn\" is more frosting than cake, with little of substance to distinguish it from the competition.\" Nevertheless, he found himself drawn to the game. \"In a greasy pizza, let\u2019s-not-take-this-too-seriously kind of way, \"Earthdawn\" holds its own.\"\nIn a 1996 reader poll conducted by \"Arcane\" magazine to determine the 50 most popular roleplaying games of all time, \"Earthdawn\" was ranked 24th. Editor Paul Pettengale commented: \"Very good indeed. \"Earthdawn\" combined traditional fantasy with \"Call of Cthulhu\"-style horror and a detailed background to create an evocative and interesting setting. Combined with a clear, well-designed rules system and an impressive range of supporting supplements and adventures, this is an excellent fantasy game. It's also of special interest to fans of \"Shadowrun\", because it describes the past of the same gameworld.\"\nIn 1999 \"Pyramid\" magazine named \"Earthdawn\" as one of \"The Millennium's Most Underrated Games\". Editor Scott Haring noted (referring to the FASA edition) that \"\"Earthdawn\" had an original, inventive magic system (no mean trick given the hundreds of fantasy RPGs that came before), and a game world that gave you the classic \"monsters and dungeons\" sort of RPG experience, but made sense doing it.\"\nIn Issue 12 of the Australian game magazine \"Australian Realms\", Malcolm Adler thought the rules would satisfy both new and experienced players: \"The rules are written in a simple enough form and with plenty of examples so that a new gamer should not get lost. For more experienced gamers there is enough depth in the system to keep the average player happy.\" Adler liked the ability of gamemasters to go in new directions, saying, \"One of the biggest positives on Earthdawn's side is the continual encouragement to do with it what you will.\" Adler concluded, \"My opinion is that the game is going to be big. I suspect the second biggest RPG in the market is about to arrive. Consequently you owe it to yourself to check it out when it becomes available in August. Give it a good look over and then make your own judgement.\"\nIn his 2023 book \"Monsters, Aliens, and Holes in the Ground\", RPG historian Stu Horvath noted, \"In a fantasy world, one of the most difficult tasks is conveying that sense of the fantastic. The design of \"Earthdawn\", through its careful presentation in both art and text, gives players the necessary details to bring to life a world of wonders as easily as they might conjure a game set in the real world. Once there, players can go forth and forge their own legends.\""}
