{"id": "5626", "revid": "36878010", "url": "https://en.wikipedia.org/wiki?curid=5626", "title": "Cognitive science", "text": "Cognitive science is the interdisciplinary, scientific study of the mind and its processes. It examines the nature, the tasks, and the functions of cognition (in a broad sense). Mental faculties of concern to cognitive scientists include perception, memory, attention, reasoning, language, and emotion; to understand these faculties, cognitive scientists borrow from fields such as psychology, economics, artificial intelligence, neuroscience, linguistics, and anthropology. The typical analysis of cognitive science spans many levels of organization, from learning and decision-making to logic and planning; from neural circuitry to modular brain organization. One of the fundamental concepts of cognitive science is that \"thinking can best be understood in terms of representational structures in the mind and computational procedures that operate on those structures.\"\nHistory.\nThe cognitive sciences began as an intellectual movement in the 1950s, called the cognitive revolution. Cognitive science has a prehistory traceable back to ancient Greek philosophical texts (see Plato's \"Meno\" and Aristotle's ); Modern philosophers such as Descartes, David Hume, Immanuel Kant, Benedict de Spinoza, Nicolas Malebranche, Pierre Cabanis, Leibniz and John Locke, rejected scholasticism while mostly having never read Aristotle, and they were working with an entirely different set of tools and core concepts than those of the cognitive scientist.\nThe modern culture of cognitive science can be traced back to the early cyberneticists in the 1930s and 1940s, such as Warren McCulloch and Walter Pitts, who sought to understand the organizing principles of the mind. McCulloch and Pitts developed the first variants of what are now known as artificial neural networks, models of computation inspired by the structure of biological neural networks.\nAnother precursor was the early development of the theory of computation and the digital computer in the 1940s and 1950s. Kurt G\u00f6del, Alonzo Church, Alan Turing, and John von Neumann were instrumental in these developments. The modern computer, or Von Neumann machine, would play a central role in cognitive science, both as a metaphor for the mind, and as a tool for investigation.\nThe first instance of cognitive science experiments being done at an academic institution took place at MIT Sloan School of Management, established by J.C.R. Licklider working within the psychology department and conducting experiments using computer memory as models for human cognition. In 1959, Noam Chomsky published a scathing review of B. F. Skinner's book \"Verbal Behavior\". At the time, Skinner's behaviorist paradigm dominated the field of psychology within the United States. Most psychologists focused on functional relations between stimulus and response, without positing internal representations. Chomsky argued that in order to explain language, we needed a theory like generative grammar, which not only attributed internal representations but characterized their underlying order.\nThe term \"cognitive science\" was coined by Christopher Longuet-Higgins in his 1973 commentary on the Lighthill report, which concerned the then-current state of artificial intelligence research. In the same decade, the journal \"Cognitive Science\" and the Cognitive Science Society were founded. The founding meeting of the Cognitive Science Society was held at the University of California, San Diego in 1979, which resulted in cognitive science becoming an internationally visible enterprise. In 1972, Hampshire College started the first undergraduate education program in Cognitive Science, led by Neil Stillings. In 1982, with assistance from Professor Stillings, Vassar College became the first institution in the world to grant an undergraduate degree in Cognitive Science. In 1986, the first Cognitive Science Department in the world was founded at the University of California, San Diego.\nIn the 1970s and early 1980s, as access to computers increased, artificial intelligence research expanded. Researchers such as Marvin Minsky would write computer programs in languages such as LISP to attempt to formally characterize the steps that human beings went through, for instance, in making decisions and solving problems, in the hope of better understanding human thought, and also in the hope of creating artificial minds. This approach is known as \"symbolic AI\".\nEventually the limits of the symbolic AI research program became apparent. For instance, it seemed to be unrealistic to comprehensively list human knowledge in a form usable by a symbolic computer program. The late 80s and 90s saw the rise of neural networks and connectionism as a research paradigm. Under this point of view, often attributed to James McClelland and David Rumelhart, the mind could be characterized as a set of complex associations, represented as a layered network. Critics argue that there are some phenomena which are better captured by symbolic models, and that connectionist models are often so complex as to have little explanatory power. Recently symbolic and connectionist models have been combined, making it possible to take advantage of both forms of explanation. While both connectionism and symbolic approaches have proven useful for testing various hypotheses and exploring approaches to understanding aspects of cognition and lower level brain functions, neither are biologically realistic and therefore, both suffer from a lack of neuroscientific plausibility. Connectionism has proven useful for exploring computationally how cognition emerges in development and occurs in the human brain, and has provided alternatives to strictly domain-specific / domain general approaches. For example, scientists such as Jeff Elman, Liz Bates, and Annette Karmiloff-Smith have posited that networks in the brain emerge from the dynamic interaction between them and environmental input.\nRecent developments in quantum computation, including the ability to run quantum circuits on quantum computers such as IBM Quantum Platform, has accelerated work using elements from quantum mechanics in cognitive models.\nPrinciples.\nLevels of analysis.\nA central tenet of cognitive science is that a complete understanding of the mind/brain cannot be attained by studying only a single level. An example would be the problem of remembering a phone number and recalling it later. One approach to understanding this process would be to study behavior through direct observation, or naturalistic observation. A person could be presented with a phone number and be asked to recall it after some delay of time; then the accuracy of the response could be measured. Another approach to measure cognitive ability would be to study the firings of individual neurons while a person is trying to remember the phone number. Neither of these experiments on its own would fully explain how the process of remembering a phone number works. Even if the technology to map out every neuron in the brain in real-time were available and it were known when each neuron fired it would still be impossible to know how a particular firing of neurons translates into the observed behavior. Thus an understanding of how these two levels relate to each other is imperative. Francisco Varela, in \"The Embodied Mind: Cognitive Science and Human Experience\", argues that \"the new sciences of the mind need to enlarge their horizon to encompass both lived human experience and the possibilities for transformation inherent in human experience\". On the classic cognitivist view, this can be provided by a functional level account of the process. Studying a particular phenomenon from multiple levels creates a better understanding of the processes that occur in the brain to give rise to a particular behavior.\nMarr gave a famous description of three levels of analysis:\nInterdisciplinary nature.\nCognitive science is an interdisciplinary field with contributors from various fields, including psychology, neuroscience, linguistics, philosophy of mind, computer science, anthropology and biology. Cognitive scientists work collectively in hope of understanding the mind and its interactions with the surrounding world much like other sciences do. The field regards itself as compatible with the physical sciences and uses the scientific method as well as simulation or modeling, often comparing the output of models with aspects of human cognition. Similarly to the field of psychology, there is some doubt whether there is a unified cognitive science, which have led some researchers to prefer 'cognitive sciences' in plural.\nMany, but not all, who consider themselves cognitive scientists hold a functionalist view of the mind\u2014the view that mental states and processes should be explained by their function \u2013 what they do. According to the multiple realizability account of functionalism, even non-human systems such as robots and computers can be ascribed as having cognition.\n\"Cognitive\" science: the term.\nThe term \"cognitive\" in \"cognitive science\" is used for \"any kind of mental operation or structure that can be studied in precise terms\" (Lakoff and Johnson, 1999). This conceptualization is very broad, and should not be confused with how \"cognitive\" is used in some traditions of analytic philosophy, where \"cognitive\" has to do only with formal rules and truth-conditional semantics.\nThe earliest entries for the word \"cognitive\" in the OED take it to mean roughly \"pertaining to the action or process of knowing\". The first entry, from 1586, shows the word was at one time used in the context of discussions of Platonic theories of knowledge. Most in cognitive science, however, presumably do not believe their field is the study of anything as certain as the knowledge sought by Plato.\nScope.\nCognitive science is a large field, and covers a wide array of topics on cognition. However, it should be recognized that cognitive science has not always been equally concerned with every topic that might bear relevance to the nature and operation of minds. Classical cognitivists have largely de-emphasized or avoided social and cultural factors, embodiment, emotion, consciousness, animal cognition, and comparative and evolutionary psychologies. However, with the decline of behaviorism, internal states such as affects and emotions, as well as awareness and covert attention became approachable again. For example, situated and embodied cognition theories take into account the current state of the environment as well as the role of the body in cognition. With the newfound emphasis on information processing, observable behavior was no longer the hallmark of psychological theory, but the modeling or recording of mental states.\nBelow are some of the main topics that cognitive science is concerned with; see List of cognitive science topics for a more exhaustive list. \nArtificial intelligence.\nArtificial intelligence (AI) involves the study of cognitive phenomena in machines. One of the practical goals of AI is to implement aspects of human intelligence in computers. Computers are also widely used as a tool with which to study cognitive phenomena. Computational modeling uses simulations to study how human intelligence may be structured. (See .)\nThere is some debate in the field as to whether the mind is best viewed as a huge array of small but individually feeble elements (i.e. neurons), or as a collection of higher-level structures such as symbols, schemes, plans, and rules. The former view uses connectionism to study the mind, whereas the latter emphasizes symbolic artificial intelligence. One way to view the issue is whether it is possible to accurately simulate a human brain on a computer without accurately simulating the neurons that make up the human brain.\nAttention.\nAttention is the selection of important information. The human mind is bombarded with millions of stimuli and it must have a way of deciding which of this information to process. Attention is sometimes seen as a spotlight, meaning one can only shine the light on a particular set of information. Experiments that support this metaphor include the dichotic listening task (Cherry, 1957) and studies of inattentional blindness (Mack and Rock, 1998). In the dichotic listening task, subjects are bombarded with two different messages, one in each ear, and told to focus on only one of the messages. At the end of the experiment, when asked about the content of the unattended message, subjects cannot report it. \nThe psychological construct of Attention is sometimes confused with the concept of Intentionality due to some degree of semantic ambiguity in their definitions. At the beginning of experimental research on Attention, Wilhelm Wundt defined this term as \"that psychical process, which is operative in the clear perception of the narrow region of the content of consciousness.\" His experiments showed the limits of Attention in space and time, which were 3-6 letters during an exposition of 1/10 s. Because this notion develops within the framework of the original meaning during a hundred years of research, the definition of Attention would reflect the sense when it accounts for the main features initially attributed to this term \u2013 it is a process of controlling thought that continues over time. While Intentionality is the power of minds to be about something, Attention is the concentration of awareness on some phenomenon during a period of time, which is necessary to elevate the clear perception of the narrow region of the content of consciousness and which is feasible to control this focus in mind. \nThe significance of knowledge about the scope of attention for studying cognition is that it defines the intellectual functions of cognition such as apprehension, judgment, reasoning, and working memory. The development of attention scope increases the set of faculties responsible for the mind relies on how it perceives, remembers, considers, and evaluates in making decisions. The ground of this statement is that the more details (associated with an event) the mind may grasp for their comparison, association, and categorization, the closer apprehension, judgment, and reasoning of the event are in accord with reality. According to Latvian professor Sandra Mihailova and professor Igor Val Danilov, the more elements of the phenomenon (or phenomena ) the mind can keep in the scope of attention simultaneously, the more significant number of reasonable combinations within that event it can achieve, enhancing the probability of better understanding features and particularity of the phenomenon (phenomena). For example, three items in the focal point of consciousness yield six possible combinations (3 factorial) and four items \u2013 24 (4 factorial) combinations. The number of reasonable combinations becomes significant in the case of a focal point with six items with 720 possible combinations (6 factorial).\nBodily processes related to cognition.\nEmbodied cognition approaches to cognitive science emphasize the role of body and environment in cognition. This includes both neural and extra-neural bodily processes, and factors that range from affective and emotional processes, to posture, motor control, proprioception, and kinaesthesis, to autonomic processes that involve heartbeat and respiration, to the role of the enteric gut microbiome. It also includes accounts of how the body engages with or is coupled to social and physical environments. 4E (embodied, embedded, extended and enactive) cognition includes a broad range of views about brain-body-environment interaction, from causal embeddedness to stronger claims about how the mind extends to include tools and instruments, as well as the role of social interactions, action-oriented processes, and affordances. 4E theories range from those closer to classic cognitivism (so-called \"weak\" embodied cognition) to stronger extended and enactive versions that are sometimes referred to as radical embodied cognitive science.\nKnowledge and processing of language.\nThe ability to learn and understand language is an extremely complex process. Language is acquired within the first few years of life, and all humans under normal circumstances are able to acquire language proficiently. A major driving force in the theoretical linguistic field is discovering the nature that language must have in the abstract in order to be learned in such a fashion. Some of the driving research questions in studying how the brain itself processes language include: (1) To what extent is linguistic knowledge innate or learned?, (2) Why is it more difficult for adults to acquire a second-language than it is for infants to acquire their first-language?, and (3) How are humans able to understand novel sentences?\nThe study of language processing ranges from the investigation of the sound patterns of speech to the meaning of words and whole sentences. Linguistics often divides language processing into orthography, phonetics, phonology, morphology, syntax, semantics, and pragmatics. Many aspects of language can be studied from each of these components and from their interaction.\nThe study of language processing in \"cognitive science\" is closely tied to the field of linguistics. Linguistics was traditionally studied as a part of the humanities, including studies of history, art and literature. In the last fifty years or so, more and more researchers have studied knowledge and use of language as a cognitive phenomenon, the main problems being how knowledge of language can be acquired and used, and what precisely it consists of. Linguists have found that, while humans form sentences in ways apparently governed by very complex systems, they are remarkably unaware of the rules that govern their own speech. Thus linguists must resort to indirect methods to determine what those rules might be, if indeed rules as such exist. In any event, if speech is indeed governed by rules, they appear to be opaque to any conscious consideration.\nLearning and development.\nLearning and development are the processes by which we acquire knowledge and information over time. Infants are born with little or no knowledge (depending on how knowledge is defined), yet they rapidly acquire the ability to use language, walk, and recognize people and objects. Research in learning and development aims to explain the mechanisms by which these processes might take place.\nA major question in the study of cognitive development is the extent to which certain abilities are innate or learned. This is often framed in terms of the nature and nurture debate. The nativist view emphasizes that certain features are innate to an organism and are determined by its genetic endowment. The empiricist view, on the other hand, emphasizes that certain abilities are learned from the environment. Although clearly both genetic and environmental input is needed for a child to develop normally, considerable debate remains about \"how\" genetic information might guide cognitive development. In the area of language acquisition, for example, some (such as Steven Pinker) have argued that specific information containing universal grammatical rules must be contained in the genes, whereas others (such as Jeffrey Elman and colleagues in Rethinking Innateness) have argued that Pinker's claims are biologically unrealistic. They argue that genes determine the architecture of a learning system, but that specific \"facts\" about how grammar works can only be learned as a result of experience.\nMemory.\nMemory allows us to store information for later retrieval. Memory is often thought of as consisting of both a long-term and short-term store. Long-term memory allows us to store information over prolonged periods (days, weeks, years). We do not yet know the practical limit of long-term memory capacity. Short-term memory allows us to store information over short time scales (seconds or minutes).\nMemory is also often grouped into declarative and procedural forms. Declarative memory\u2014grouped into subsets of semantic and episodic forms of memory\u2014refers to our memory for facts and specific knowledge, specific meanings, and specific experiences (e.g. \"Are apples food?\", or \"What did I eat for breakfast four days ago?\"). Procedural memory allows us to remember actions and motor sequences (e.g. how to ride a bicycle) and is often dubbed implicit knowledge or memory .\nCognitive scientists study memory just as psychologists do, but tend to focus more on how memory bears on cognitive processes, and the interrelationship between cognition and memory. One example of this could be, what mental processes does a person go through to retrieve a long-lost memory? Or, what differentiates between the cognitive process of recognition (seeing hints of something before remembering it, or memory in context) and recall (retrieving a memory, as in \"fill-in-the-blank\")?\nPerception and action.\nPerception is the ability to take in information via the senses, and process it in some way. Vision and hearing are two dominant senses that allow us to perceive the environment. Some questions in the study of visual perception, for example, include: (1) How are we able to recognize objects?, (2) Why do we perceive a continuous visual environment, even though we only see small bits of it at any one time? One tool for studying visual perception is by looking at how people process optical illusions. The image on the right of a Necker cube is an example of a bistable percept, that is, the cube can be interpreted as being oriented in two different directions.\nThe study of haptic (tactile), olfactory, and gustatory stimuli also fall into the domain of perception.\nAction is taken to refer to the output of a system. In humans, this is accomplished through motor responses. Spatial planning and movement, speech production, and complex motor movements are all aspects of action.\nConsciousness.\nConsciousness is the awareness of experiences within oneself. \nThis helps the mind with having the ability to experience or feel a sense of self.\nResearch methods.\nMany different methodologies are used to study cognitive science. As the field is highly interdisciplinary, research often cuts across multiple areas of study, drawing on research methods from psychology, neuroscience, computer science and systems theory.\nBehavioral experiments.\nIn order to have a description of what constitutes intelligent behavior, one must study behavior itself. This type of research is closely tied to that in cognitive psychology and psychophysics. By measuring behavioral responses to different stimuli, one can understand something about how those stimuli are processed. Lewandowski &amp; Strohmetz (2009) reviewed a collection of innovative uses of behavioral measurement in psychology including behavioral traces, behavioral observations, and behavioral choice. Behavioral traces are pieces of evidence that indicate behavior occurred, but the actor is not present (e.g., litter in a parking lot or readings on an electric meter). Behavioral observations involve the direct witnessing of the actor engaging in the behavior (e.g., watching how close a person sits next to another person). Behavioral choices are when a person selects between two or more options (e.g., voting behavior, choice of a punishment for another participant).\nBrain imaging.\nBrain imaging involves analyzing activity within the brain while performing various tasks. This allows us to link behavior and brain function to help understand how information is processed. Different types of imaging techniques vary in their temporal (time-based) and spatial (location-based) resolution. Brain imaging is often used in cognitive neuroscience.\nComputational modeling.\nComputational models require a mathematically and logically formal representation of a problem. Computer models are used in the simulation and experimental verification of different specific and general properties of intelligence. Computational modeling can help us understand the functional organization of a particular cognitive phenomenon.\nApproaches to cognitive modeling can be categorized as: (1) symbolic, on abstract mental functions of an intelligent mind by means of symbols; (2) subsymbolic, on the neural and associative properties of the human brain; and (3) across the symbolic\u2013subsymbolic border, including hybrid.\nAll the above approaches tend either to be generalized to the form of integrated computational models of a synthetic/abstract intelligence (i.e. cognitive architecture) in order to be applied to the explanation and improvement of individual and social/organizational decision-making and reasoning or to focus on single simulative programs (or microtheories/\"middle-range\" theories) modelling specific cognitive faculties (e.g. vision, language, categorization etc.).\nNeurobiological methods.\nResearch methods borrowed directly from neuroscience and neuropsychology can also help us to understand aspects of intelligence. These methods allow us to understand how intelligent behavior is implemented in a physical system.\nKey findings.\nCognitive science has given rise to models of human cognitive bias and risk perception, and has been influential in the development of behavioral finance, part of economics. It has also given rise to a new theory of the philosophy of mathematics (related to denotational mathematics), and many theories of artificial intelligence, persuasion and coercion. It has made its presence known in the philosophy of language and epistemology as well as constituting a substantial wing of modern linguistics. Fields of cognitive science have been influential in understanding the brain's particular functional systems (and functional deficits) ranging from speech production to auditory processing and visual perception. It has made progress in understanding how damage to particular areas of the brain affect cognition, and it has helped to uncover the root causes and results of specific dysfunction, such as dyslexia, anopsia, and hemispatial neglect.\nNotable researchers.\nSome of the more recognized names in cognitive science are usually either the most controversial or the most cited. Within philosophy, some familiar names include Daniel Dennett, who writes from a computational systems perspective, John Searle, known for his controversial Chinese room argument, and Jerry Fodor, who advocates functionalism.\nOthers include David Chalmers, who advocates Dualism and is also known for articulating the hard problem of consciousness, and Douglas Hofstadter, famous for writing \"G\u00f6del, Escher, Bach\", which questions the nature of words and thought.\nIn the realm of linguistics, Noam Chomsky and George Lakoff have been influential (both have also become notable as political commentators). In artificial intelligence, Marvin Minsky, Herbert A. Simon, and Allen Newell are prominent.\nPopular names in the discipline of psychology include George A. Miller, James McClelland, Philip Johnson-Laird, Lawrence Barsalou, Vittorio Guidano, Howard Gardner and Steven Pinker. Anthropologists Dan Sperber, Edwin Hutchins, Bradd Shore, James Wertsch and Scott Atran, have been involved in collaborative projects with cognitive and social psychologists, political scientists and evolutionary biologists in attempts to develop general theories of culture formation, religion, and political association.\nComputational theories (with models and simulations) have also been developed, by David Rumelhart, James McClelland and Philip Johnson-Laird.\nEpistemics.\nEpistemics is a term coined in 1969 by the University of Edinburgh with the foundation of its School of Epistemics. Epistemics is to be distinguished from epistemology in that epistemology is the philosophical theory of knowledge, whereas epistemics signifies the scientific study of knowledge.\nChristopher Longuet-Higgins has defined it as \"the construction of formal models of the processes (perceptual, intellectual, and linguistic) by which knowledge and understanding are achieved and communicated.\"\nIn his 1978 essay \"Epistemics: The Regulative Theory of Cognition\", Alvin I. Goldman claims to have coined the term \"epistemics\" to describe a reorientation of epistemology. Goldman maintains that his epistemics is continuous with traditional epistemology and the new term is only to avoid opposition. Epistemics, in Goldman's version, differs only slightly from traditional epistemology in its alliance with the psychology of cognition; epistemics stresses the detailed study of mental processes and information-processing mechanisms that lead to knowledge or beliefs.\nIn the mid-1980s, the School of Epistemics was renamed as The Centre for Cognitive Science (CCS). In 1998, CCS was incorporated into the University of Edinburgh's School of Informatics.\nBinding problem in cognitive science.\nOne of the core aims of cognitive science is to achieve an integrated theory of cognition. This requires integrative mechanisms explaining how the information processing that occurs simultaneously in spatially segregated (sub-)cortical areas in the brain is coordinated and bound together to give rise to coherent perceptual and symbolic representations. One approach is to solve this \"Binding problem\" (that is, the problem of dynamically representing conjunctions of informational elements, from the most basic perceptual representations (\"feature binding\") to the most complex cognitive representations, like symbol structures (\"variable binding\")), by means of integrative synchronization mechanisms. In other words, one of the coordinating mechanisms appears to be the temporal (phase) synchronization of neural activity based on dynamical self-organizing processes in neural networks, described by the Binding-by-synchrony (BBS) Hypothesis from neurophysiology. Connectionist cognitive neuroarchitectures have been developed that use integrative synchronization mechanisms to solve this binding problem in perceptual cognition and in language cognition. In perceptual cognition the problem is to explain how elementary object properties and object relations, like the object color or the object form, can be dynamically bound together or can be integrated to a representation of this perceptual object by means of a synchronization mechanism (\"feature binding\", \"feature linking\"). In language cognition the problem is to explain how semantic concepts and syntactic roles can be dynamically bound together or can be integrated to complex cognitive representations like systematic and compositional symbol structures and propositions by means of a synchronization mechanism (\"variable binding\") (see also the \"Symbolism vs. connectionism debate\" in connectionism).\nHowever, despite significant advances in understanding the integrated theory of cognition (specifically the Binding problem), the debate on this issue of beginning cognition is still in progress. From the different perspectives noted above, this problem can be reduced to the issue of how organisms at the simple reflexes stage of development overcome the threshold of the environmental chaos of sensory stimuli: electromagnetic waves, chemical interactions, and pressure fluctuations. The so-called Primary Data Entry (PDE) thesis poses doubts about the ability of such an organism to overcome this cue threshold on its own. In terms of mathematical tools, the PDE thesis underlines the insuperable high threshold of the cacophony of environmental stimuli (the stimuli noise) for young organisms at the onset of life. It argues that the temporal (phase) synchronization of neural activity based on dynamical self-organizing processes in neural networks, any dynamical bound together or integration to a representation of the perceptual object by means of a synchronization mechanism can not help organisms in distinguishing relevant cue (informative stimulus) for overcome this noise threshold."}
{"id": "5628", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=5628", "title": "Compilers", "text": ""}
{"id": "5630", "revid": "45684569", "url": "https://en.wikipedia.org/wiki?curid=5630", "title": "Copula (linguistics)", "text": "In linguistics, a copula /\u2018k\u0252pj\u0259l\u0259/ (: copulas or copulae; abbreviated ) is a word or phrase that links the subject of a sentence to a subject complement, such as the word \"is\" in the sentence \"The sky is blue\" or the phrase \"was not being\" in the sentence \"It was not being cooperative.\" The word \"copula\" derives from the Latin noun for a \"link\" or \"tie\" that connects two different things.\nA copula is often a verb or a verb-like word, though this is not universally the case. A verb that is a copula is sometimes called a copulative or copular verb. In English primary education grammar courses, a copula is often called a linking verb. In other languages, copulas show more resemblances to pronouns, as in Classical Chinese and Guarani, or may take the form of suffixes attached to a noun, as in Korean, Beja, and Inuit languages.\nMost languages have one main copula (in English, the verb \"to be\"), although some (like Spanish, Portuguese and Thai) have more than one, while others have none. While the term \"copula\" is generally used to refer to such principal verbs, it may also be used for a wider group of verbs with similar potential functions (like \"become\", \"get\", \"feel\" and \"seem\" in English); alternatively, these might be distinguished as \"semi-copulas\" or \"pseudo-copulas\".\nGrammatical function.\nThe principal use of a copula is to link the subject of a clause to a subject complement. A copular verb is often considered to be part of the predicate, the remainder being called a predicative expression. A simple clause containing a copula is illustrated below:\nThe book is on the table.\nIn that sentence, the noun phrase \"the book\" is the subject, the verb \"is\" serves as the copula, and the prepositional phrase \"on the table\" is the predicative expression. In some theories of grammar, the whole expression \"is on the table\" may be called a predicate or a verb phrase.\nThe predicative expression accompanying the copula, also known as the complement of the copula, may take any of several possible forms: it may be a noun or noun phrase, an adjective or adjective phrase, a prepositional phrase (as above), or an adverb or another adverbial phrase expressing time or location. Examples are given below, with the copula in bold and the predicative expression in italics:\nThe three components (subject, copula and predicative expression) do not necessarily appear in that order: their positioning depends on the rules for word order applicable to the language in question. In English (an SVO language), the ordering given above is the normal one, but certain variation is possible:\nIt is also possible, in certain circumstances, for one (or even two) of the three components to be absent:\nInverse copular constructions, in which the positions of the predicative expression and the subject are reversed, are found in various languages. They have been the subject of much theoretical analysis, particularly in regard to the difficulty of maintaining, in the case of such sentences, the usual division into a subject noun phrase and a predicate verb phrase.\nAnother issue is verb agreement when both subject and predicative expression are noun phrases (and differ in number or person): in English, the copula typically agrees with the syntactical subject even if it is not logically (i.e. semantically) the subject, as in \"the cause of the riot is\" (not \"are\") \"these pictures of the wall\". Compare Italian ; notice the use of the plural to agree with plural rather than with singular . In instances where an English syntactical subject comprises a prepositional object that is pluralized, however, the prepositional object agrees with the predicative expression, e.g. \"What kind \"of birds are\" those?\"\nThe definition and scope of the concept of a copula is not necessarily precise in any language. As noted above, though the concept of the copula in English is most strongly associated with the verb \"to be\", there are many other verbs that can be used in a copular sense as well.\nAnd more tenuously\nOther functions.\nA copular verb may also have other uses supplementary to or distinct from its uses as a copula. Some co-occurrences are common.\nAuxiliary verb.\nThe English verb \"to be\" is also used as an auxiliary verb, especially for expressing passive voice (together with the past participle) or expressing progressive aspect (together with the present participle):\nOther languages' copulas have additional uses as auxiliaries. For example, French can be used to express passive voice similarly to English \"be\"; both French and German are used to express the perfect forms of certain verbs:\nIn the same way, usage of English \"be\" in the present perfect, though archaic, is still commonly seen in old texts/translations:\nThe auxiliary functions of these verbs derived from their copular function, and could be interpreted as special cases of the copular function (with the verbal forms it precedes being considered adjectival).\nAnother auxiliary usage in English is to denote an obligatory action or expected occurrence: \"I am to serve you\". \"The manager is to resign\". This can be put also into past tense: \"We were to leave at 9\". For forms like \"if I was/were to come\", see English conditional sentences. (By certain criteria, the English copula \"be\" may always be considered an auxiliary verb; see Diagnostics for identifying auxiliary verbs in English.)\nExistential verb.\nThe English \"to be\" and its equivalents in certain other languages also have a non-copular use as an existential verb, meaning \"to exist\". This use is illustrated in the following sentences: \"I want only to be, and that is enough\"; \"I think therefore I am; To be or not to be, that is the question.\" In these cases, the verb itself expresses a predicate (that of existence), rather than linking to a predicative expression as it does when used as a copula. In ontology it is sometimes suggested that the \"is\" of existence is reducible to the \"is\" of property attribution or class membership; to be, Aristotle held, is to be \"something\". However, Abelard in his \"Dialectica\" made a \"reductio ad absurdum\" argument against the idea that the copula can express existence.\nSimilar examples can be found in many other languages; for example, the French and Latin equivalents of \"I think therefore I am\" are and , where and are the equivalents of English \"am\", normally used as copulas. However, other languages prefer a different verb for existential use, as in the Spanish version (where the verb is used rather than the copula or ).\nAnother type of existential usage is in clauses of the \"there is...\" or \"there are...\" type. Languages differ in the way they express such meanings; some of them use the copular verb, possibly with an expletive pronoun like the English \"there\", while other languages use different verbs and constructions, like the French (which uses parts of the verb , not the copula) or the Swedish (the passive voice of the verb for \"to find\"). For details, see existential clause.\nRelying on a unified theory of copular sentences, it has been proposed that the English \"there\"-sentences are subtypes of inverse copular constructions.\nMeanings.\nPredicates formed using a copula may express identity: that the two noun phrases (subject and complement) have the same referent or express an identical concept:\nThey may also express membership of a class or a subset relationship:\nSimilarly they may express some property, relation or position, permanent or temporary:\nEssence versus state.\nSome languages use different copulas, or different syntax, to denote a permanent, essential characteristic of something versus a temporary state. For examples, see the sections on the Romance languages, Slavic languages and Irish.\nForms.\nIn many languages the principal copula is a verb, like English \"(to) be\", German , Mixtec , Touareg \"emous\", etc. It may inflect for grammatical categories like tense, aspect and mood, like other verbs in the language. Being a very commonly used verb, it is likely that the copula has irregular inflected forms; in English, the verb \"be\" has a number of highly irregular (suppletive) forms and has more different inflected forms than any other English verb (\"am\", \"is\", \"are\", \"was\", \"were\", etc.; see English verbs for details).\nOther copulas show more resemblances to pronouns. That is the case for Classical Chinese and Guarani, for instance. In highly synthetic languages, copulas are often suffixes, attached to a noun, but they may still behave otherwise like ordinary verbs: in Inuit languages.\nIn some other languages, like Beja and Ket, the copula takes the form of suffixes that attach to a noun but are distinct from the person agreement markers used on predicative verbs. This phenomenon is known as \"nonverbal person agreement\" (or \"nonverbal subject agreement\"), and the relevant markers are always established as deriving from cliticized independent pronouns.\nZero copula.\nIn some languages, copula omission occurs within a particular grammatical context. For example, speakers of Bengali, Russian, Indonesian, Turkish, Hungarian, Arabic, Hebrew, Ge\u02bdez and Quechuan languages consistently drop the copula in present tense: Bengali: , Aami manush, 'I (am a) human'; Russian: , ; Indonesian: ; Turkish: ; Hungarian: ; Arabic: , ; Hebrew: , ; Ge\u02bdez: , / / ; Southern Quechua: . The usage is known generically as the zero copula. In other tenses (sometimes in forms other than third person singular), the copula usually reappears.\nSome languages drop the copula in poetic or aphoristic contexts. Examples in English include\nSuch poetic copula dropping is more pronounced in some languages other than English, like the Romance languages.\nIn informal speech of English, the copula may also be dropped in general sentences, as in \"She a nurse.\" It is a feature of African-American Vernacular English, but is also used by a variety of other English speakers. An example is the sentence \"I saw twelve men, each a soldier.\"\nExamples in specific languages.\nIn Ancient Greek, when an adjective precedes a noun with an article, the copula is understood: , \"the house is large\", can be written , \"large the house (is).\"\nIn Quechua (Southern Quechua used for the examples), zero copula is restricted to present tense in third person singular (): ; but: .\nIn M\u0101ori, the zero copula can be used in predicative expressions and with continuous verbs (many of which take a copulative verb in many Indo-European languages)\u00a0\u2014 , literally , ; , literally , ; , literally , , , literally , .\nAlternatively, in many cases, the particle can be used as a copulative (though not all instances of are used as thus, like all other M\u0101ori particles, has multiple purposes): ; ; .\nHowever, when expressing identity or class membership, must be used: ; ; .\nWhen expressing identity, can be placed on either object in the clause without changing the meaning ( is the same as ) but not on both ( would be equivalent to saying \"it is this, it is my book\" in English).\nIn Hungarian, zero copula is restricted to present tense in third person singular and plural: /\u00a0\u2014 / ; but: , , , . The copula also reappears for stating locations: , and for stating time: . However, the copula may be omitted in colloquial language: .\nHungarian uses copula for expressing location: , but it is omitted in the third person present tense for attribution or identity statements: ; ; (but , , ).\nIn Turkish, both the third person singular and the third person plural copulas are omittable. and both mean , and and both mean . Both of the sentences are acceptable and grammatically correct, but sentences with the copula are more formal.\nThe Turkish first person singular copula suffix is omitted when introducing oneself. is grammatically correct, but (same sentence with the copula) is not for an introduction (but is grammatically correct in other cases).\nFurther restrictions may apply before omission is permitted. For example, in the Irish language, , the present tense of the copula, may be omitted when the predicate is a noun. , the past/conditional, cannot be deleted. If the present copula is omitted, the pronoun (e.g., , , ) preceding the noun is omitted as well.\nCopula-like words.\nSometimes, the term \"copula\" is taken to include not only a language's equivalent(s) to the verb \"be\" but also other verbs or forms that serve to link a subject to a predicative expression (while adding semantic content of their own). For example, English verbs like \"become\", \"get\", \"feel\", \"look\", \"taste\", \"smell\", and \"seem\" can have this function, as in the following sentences (the predicative expression, the complement of the verb, is in italics):\nSome verbs have rarer, secondary uses as copular verbs, like the verb \"fall\" in sentences like \"The zebra fell victim to the lion.\"\nThese extra copulas are sometimes called \"semi-copulas\" or \"pseudo-copulas.\" For a list of common verbs of this type in English, see List of English copulae.\nIn particular languages.\nIndo-European.\nIn Indo-European languages, the words meaning \"to be\" are sometimes similar to each other. Due to the high frequency of their use, their inflection retains a considerable degree of similarity in some cases. Thus, for example, the English form \"is\" is a cognate of German , Latin , Persian and Russian , even though the Germanic, Italic, Iranian and Slavic language groups split at least 3000 years ago. The origins of the copulas of most Indo-European languages can be traced back to four Proto-Indo-European stems: (), (), and ().\nEnglish.\nThe English copular verb \"be\" has eight basic forms (\"be\", \"am\", \"is\", \"are\", \"being\", \"was\", \"were\", \"been\") and five negative forms (\"ain't\" (in some dialects), \"isn't\", \"aren't\", \"wasn't\", \"weren't\"). No other English verb has more than five forms. Additional archaic forms include \"art\", \"wast\", \"wert\", and occasionally \"beest\" (as a subjunctive). For more details see English verbs. For the etymology of the various forms, see Indo-European copula.\nThe main uses of the copula in English are described in the above sections. The possibility of copula omission is mentioned under .\nA particular construction found in English (particularly in speech) is the use of two successive copulas when only one appears necessary, as in \"My point is, is that...\". The acceptability of this construction is a disputed matter in English prescriptive grammar.\nThe simple English copula \"be\" may on occasion be substituted by other verbs with near identical meanings.\nPersian.\nIn Persian, the verb \"to be\" can take the form of either (cognate to English \"is\") or (cognate to \"be\").\nHindustani.\nIn Hindustani (Hindi and Urdu), the copula can be put into four grammatical aspects (simple, habitual, perfective, and progressive) and each of those four aspects can be put into five grammatical moods (indicative, presumptive, subjunctive, contrafactual, and imperative). Some example sentences using the simple aspect are shown below:\nBesides the verb , there are three other verbs which can also be used as the copula: , , and . The following table shows the conjugations of the copula in the five grammatical moods in the simple aspect. The transliteration scheme used is ISO 15919.\nRomance.\nCopulas in the Romance languages usually consist of two different verbs that can be translated as \"to be\", the main one from the Latin (via Vulgar Latin ; deriving from \"*es-\"), often referenced as (another of the Latin verb's principal parts) and a secondary one from (from \"*sta-\"), often referenced as . The resulting distinction in the modern forms is found in all the Iberian Romance languages, and to a lesser extent Italian, but not in French or Romanian. The difference is that the first usually refers to essential characteristics, while the second refers to states and situations, e.g., \"Bob is old\" versus \"Bob is well.\" A similar division is found in the non-Romance Basque language (viz. and ). (The English words just used, \"essential\" and \"state\", are also cognate with the Latin infinitives and . The word \"stay\" also comes from Latin , through Middle French , stem of Old French .) In Spanish and Portuguese, the high degree of verbal inflection, plus the existence of two copulas ( and ), means that there are 105 (Spanish) and 110 (Portuguese) separate forms to express the copula, compared to eight in English and one in Chinese.\nIn some cases, the verb itself changes the meaning of the adjective/sentence. The following examples are from Portuguese:\nSlavic.\nSome Slavic languages make a distinction between essence and state (similar to that discussed in the above section on the Romance languages), by putting a predicative expression denoting a state into the instrumental case, and essential characteristics are in the nominative. This can apply with other copula verbs as well: the verbs for \"become\" are normally used with the instrumental case.\nAs noted above under , Russian and other North Slavic languages generally or often omit the copula in the present tense.\nIrish.\nIn Irish and Scottish Gaelic, there are two copulas, and the syntax is also changed when one is distinguishing between states or situations and essential characteristics.\nDescribing the subject's state or situation typically uses the normal VSO ordering with the verb . The copula is used to state essential characteristics or equivalences.\nThe word is the copula (rhymes with the English word \"miss\").\nThe pronoun used with the copula is different from the normal pronoun. For a masculine singular noun, is used (for \"he\" or \"it\"), as opposed to the normal pronoun ; for a feminine singular noun, is used (for \"she\" or \"it\"), as opposed to normal pronoun ; for plural nouns, is used (for \"they\" or \"those\"), as opposed to the normal pronoun .\nTo describe being in a state, condition, place, or act, the verb \"to be\" is used: \nArabic dialects.\nNorth Levantine Arabic.\nThe North Levantine Arabic dialect, spoken in Syria and Lebanon, has a negative copula formed by and a suffixed pronoun.\nBantu languages.\nChichewa.\nIn Chichewa, a Bantu language spoken mainly in Malawi, a very similar distinction exists between permanent and temporary states as in Spanish and Portuguese, but only in the present tense. For a permanent state, in the 3rd person, the copula used in the present tense is (negative ):\nFor the 1st and 2nd persons the particle is combined with pronouns, e.g., :\nFor temporary states and location, the copula is the appropriate form of the defective verb :\nFor the 1st and 2nd persons the person is shown, as normally with Chichewa verbs, by the appropriate pronominal prefix:\nIn the past tenses, is used for both types of copula:\nIn the future, subjunctive, or conditional tenses, a form of the verb is used as a copula:\nMuylaq' Aymaran.\nUniquely, the existence of the copulative verbalizer suffix in the Southern Peruvian Aymaran language variety, Muylaq' Aymara, is evident only in the surfacing of a vowel that would otherwise have been deleted because of the presence of a following suffix, lexically prespecified to suppress it. As the copulative verbalizer has no independent phonetic structure, it is represented by the Greek letter \u028b in the examples used in this entry.\nAccordingly, unlike in most other Aymaran variants, whose copulative verbalizer is expressed with a vowel-lengthening component, -\":\", the presence of the copulative verbalizer in Muylaq' Aymara is often not apparent on the surface at all and is analyzed as existing only meta-linguistically. However, in a verb phrase like \"It is old\", the noun does not require the copulative verbalizer: .\nIt is now pertinent to make some observations about the distribution of the copulative verbalizer. The best place to start is with words in which its presence or absence is obvious. When the vowel-suppressing first person simple tense suffix attaches to a verb, the vowel of the immediately preceding suffix is suppressed (in the examples in this subsection, the subscript \"c\" appears prior to vowel-suppressing suffixes in the interlinear gloss to better distinguish instances of deletion that arise from the presence of a lexically pre-specified suffix from those that arise from other (e.g. phonotactic) motivations). Consider the verb , which is inflected for the first person simple tense and so, predictably, loses its final root vowel: .\nHowever, prior to the suffixation of the first person simple suffix to the same root nominalized with the agentive nominalizer , the word must be verbalized. The fact that the final vowel of below is not suppressed indicates the presence of an intervening segment, the copulative verbalizer: .\nIt is worthwhile to compare of the copulative verbalizer in Muylaq' Aymara as compared to La Paz Aymara, a variant which represents this suffix with vowel lengthening. Consider the near-identical sentences below, both translations of \"I have a small house\" in which the nominal root is verbalized with the copulative verbalizer, but the correspondence between the copulative verbalizer in these two variants is not always a strict one-to-one relation.\nGeorgian.\nAs in English, the verb \"to be\" () is irregular in Georgian (a Kartvelian language); different verb roots are employed in different tenses. The roots , , , and (past participle) are used in the present tense, future tense, past tense and the perfective tenses respectively. Examples:\nIn the last two examples (perfective and pluperfect), two roots are used in one verb compound. In the perfective tense, the root (which is the expected root for the perfective tense) is followed by the root , which is the root for the present tense. In the pluperfective tense, again, the root is followed by the past tense root . This formation is very similar to German (an Indo-European language), where the perfect and the pluperfect are expressed in the following way:\nHere, is the past participle of in German. In both examples, as in Georgian, this participle is used together with the present and the past forms of the verb in order to conjugate for the perfect and the pluperfect aspects.\nHaitian Creole.\nHaitian Creole, a French-based creole language, has three forms of the copula: , , and the zero copula, no word at all (the position of which will be indicated with \"\u00d8\", just for purposes of illustration).\nAlthough no textual record exists of Haitian-Creole at its earliest stages of development from French, is derived from French (written ), which is the normal French contraction of (that, written ) and the copula (is, written ) (a form of the verb ).\nThe derivation of is less obvious; but we can assume that the French source was (\"he/it is\", written ), which, in rapidly spoken French, is very commonly pronounced as (typically written ).\nThe use of a zero copula is unknown in French, and it is thought to be an innovation from the early days when Haitian-Creole was first developing as a Romance-based pidgin. Latin also sometimes used a zero copula.\nWhich of //\u00d8 is used in any given copula clause depends on complex syntactic factors that we can superficially summarize in the following four rules:\n1. Use \"\u00d8\" (i.e., no word at all) in declarative sentences where the complement is an adjective phrase, prepositional phrase, or adverb phrase:\n2. Use when the complement is a noun phrase. But, whereas other verbs come after any tense/mood/aspect particles (like to mark negation, or to explicitly mark past tense, or to mark progressive aspect), comes before any such particles:\n3. Use where French and English have a dummy \"it\" subject:\n4. Finally, use the other copula form in situations where the sentence's syntax leaves the copula at the end of a phrase:\nThe above is, however, only a simplified analysis.\nJapanese.\nThe Japanese copula (most often translated into English as an inflected form of \"to be\") is unique among verbs in Japanese. It is highly irregular, and in several ways behaves in ways other verbs do not; such as requiring a separate relativised form in some circumstances, and acting simply as a marker of formality/politeness with no predication force in some circumstances. In the most basic case, it behaves like a normal verb with irregular forms, which (like most copulas crosslinguistically) takes a non-case-marked complement instead of an object.\nAs with all verbs in Japanese, it is necessary to mark the speaker's implied social relationship to the addressee by the choice of verb form. The following two sentences differ only in the fact that the first is appropriate only between decently close friends or family, or said by someone of significantly higher social status than the listener, and the second is only appropriate outside of such circumstances.\nJapanese has two classes of words which correspond to adjectives in English, one of which requires a copula to become a predicate and one of which does not.\nHowever, the polite copula is used as a means to mark the self-predicating class of adjectives as grammatically formal, and thus the formal equivalent of is . In these situations, the copula is not serving as an actual predication device; it is only a means to supply formality marking.\nThe non-self-predicating class of adjectives is the one place in modern Japanese where a separate relativiser form appears; these require the form in order to modify nouns.\nEtymologically the copula is a reduced form of , which effectively means 'exists as'; in formal situations or its formal form can appear in place of or , and in certain situations other forms of may be appropriate (such as /). Nonstandard forms such as in Kansai and in much of the rest of western Japan (see map above) are due to various dialects reducing differently than the Kant\u014d-based standard form did.\nThe negative form of the copula is generally or its reduced form (or in formal situations, substitute for ). This includes the topic marker , due to negative copula sentences typically implying some kind of contrastive topic-like force on the complement. can occur in relative clauses, where information structure marking might be odd, but is also a general negative copula and would be sensible still in any situation might be used.\nMany sentences in Japanese are structurally a headless relative clause nominalised by (or its reduced form ) and then predicated with a copula; the structure is analogous to something like English \"it's that...\". This structure is used to indicate that the statement is intended to answer a question or explain confusion a listener may have had (though the question it answers may not have ever been overtly spoken). This has largely been incorporated into Japanese's sentence-final particle system, and is far more common than the equivalent English structure.\nSimilarly, has also been recruited into the sentence-final particle system, and is used to mark a sentence that the speaker should have been decently obvious to the listener, or to indicate that the speaker is surprised to find that the sentence is true. In this role it can cooccur with an actual predicative , but not with the positive ; is omitted in such sentences.\nKorean.\nFor sentences with predicate nominatives, the copula () is added to the predicate nominative (with no space in between).\nSome adjectives (usually colour adjectives) are nominalized and used with the copula ().\n1. Without the copula ():\n2. With the copula ():\nSome Korean adjectives are derived using the copula. Separating these articles and nominalizing the former part will often result in a sentence with a related, but different meaning. Using the separated sentence in a situation where the un-separated sentence is appropriate is usually acceptable as the listener can decide what the speaker is trying to say using the context.\nChinese.\nIn Chinese, both states and qualities are, in general, expressed with stative verbs (SV) with no need for a copula, e.g., in Chinese, \"to be tired\" ( ), \"to be hungry\" ( ), \"to be located at\" ( ), \"to be stupid\" ( ) and so forth. A sentence can consist simply of a pronoun and such a verb: for example, (). Usually, however, verbs expressing qualities are qualified by an adverb (meaning \"very\", \"not\", \"quite\", etc.); when not otherwise qualified, they are often preceded by , which in other contexts means \"very\", but in this use often has no particular meaning.\nOnly sentences with a noun as the complement (e.g., \"This is my sister\") use the copular verb \"to be\": . This is used frequently; for example, instead of having a verb meaning \"to be Chinese\", the usual expression is \"to be a Chinese person\" (; ; ). This is sometimes called an equative verb. Another possibility is for the complement to be just a noun modifier (ending in ), the noun being omitted: \nBefore the Han dynasty, the character served as a demonstrative pronoun meaning \"this\" (this usage survives in some idioms and .) Some linguists believe that developed into a copula because it often appeared, as a repetitive subject, after the subject of a sentence (in classical Chinese we can say, for example: \"George W. Bush, \"this\" president of the United States\" meaning \"George W. Bush \"is\" the president of the United States). The character appears to be formed as a compound of characters with the meanings of \"early\" and \"straight.\"\nAnother use of in modern Chinese is in combination with the modifier to mean \"yes\" or to show agreement. For example:\nQuestion: Response: , meaning \"Yes\", or , meaning \"No.\" \nYet another use of is in the \"sh\u00ec...(de)\" construction, which is used to emphasize a particular element of the sentence; see .\nIn Hokkien acts as the copula, and is the equivalent in Wu Chinese. Cantonese uses () instead of ; similarly, Hakka uses .\nSiouan languages.\nIn Siouan languages like Lakota, in principle almost all words\u2014according to their structure\u2014are verbs. So not only (transitive, intransitive and so-called \"stative\") verbs but even nouns often behave like verbs and do not need to have copulas.\nFor example, the word refers to a man, and the verb is expressed as . Yet there also is a copula that in most cases is used: .\nIn order to express the statement , one has to say . But, in order to express that that person is THE doctor (say, that had been phoned to help), one must use another copula :\nIn order to refer to space (e.g., Robert is in the house), various verbs are used, e.g., (lit., ) for humans, or for inanimate objects of a certain shape. \"Robert is in the house\" could be translated as , whereas \"There's one restaurant next to the gas station\" translates as \nConstructed languages.\nThe constructed language Lojban has two words that act similar to a copula in natural languages. The clause turns whatever follows it into a predicate that means to be (among) what it follows. For example, means \"to be Bob\", and means \"to be one of the three sisters\". Another one is , which is itself a predicate that means all its arguments are the same thing (equal). One word which is often confused for a copula in Lojban, but is not one, is . It merely indicates that the word which follows is the main predicate of the sentence. For example, means \"my friend is a musician\", but the word does not correspond to English \"is\"; instead, the word , which is a predicate, corresponds to the entire phrase \"is a musician\". The word is used to prevent , which would mean \"the friend-of-me type of musician\"."}
{"id": "5631", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=5631", "title": "Cheese/Gruyere", "text": ""}
{"id": "5632", "revid": "73292", "url": "https://en.wikipedia.org/wiki?curid=5632", "title": "Venezuelan Beaver cheese", "text": ""}
{"id": "5634", "revid": "548440", "url": "https://en.wikipedia.org/wiki?curid=5634", "title": "List of centuries and millennia", "text": ""}
{"id": "5635", "revid": "49107021", "url": "https://en.wikipedia.org/wiki?curid=5635", "title": "Christopher Columbus", "text": "Christopher Columbus (; between 25 August and 31 October 1451 \u2013 20 May 1506) was an Italian explorer and navigator from the Republic of Genoa who completed four Spanish-based voyages across the Atlantic Ocean sponsored by the Catholic Monarchs, opening the way for the widespread European exploration and colonization of the Americas. His expeditions were the first known European contact with the Caribbean and Central and South America.\nThe name \"Christopher Columbus\" is the anglicization of the Latin . Growing up on the coast of Liguria, he went to sea at a young age and traveled widely, as far north as the British Isles and as far south as what is now Ghana. He married Portuguese noblewoman Filipa Moniz Perestrelo, who bore a son, Diego, and was based in Lisbon for several years. He later took a Castilian mistress, Beatriz Enr\u00edquez de Arana, who bore a son, Ferdinand.\nLargely self-educated, Columbus was knowledgeable in geography, astronomy, and history. He developed a plan to seek a western sea passage to the East Indies, hoping to profit from the lucrative spice trade. After the Granada War, and Columbus's persistent lobbying in multiple kingdoms, the Catholic Monarchs, Queen Isabella I and King Ferdinand II, agreed to sponsor a journey west. Columbus left Castile in August 1492 with three ships and made landfall in the Americas on 12 October, ending the period of human habitation in the Americas now referred to as the pre-Columbian era. His landing place was an island in the Bahamas, known by its native inhabitants as Guanahani. He then visited the islands now known as Cuba and Hispaniola, establishing a colony in what is now Haiti. Columbus returned to Castile in early 1493, with captured natives. Word of his voyage soon spread throughout Europe.\nColumbus made three further voyages to the Americas, exploring the Lesser Antilles in 1493, Trinidad and the northern coast of South America in 1498, and the east coast of Central America in 1502. Many of the names given to geographical features by Columbus, particularly the names of islands, are still in use. He gave the name ('Indians') to the indigenous peoples he encountered. The extent to which he was aware that the Americas were a wholly separate landmass is uncertain; he never clearly renounced his belief he had reached the Far East. As a colonial governor, Columbus was accused by some of his contemporaries of significant brutality and removed from the post. Columbus's strained relationship with the Crown of Castile and its colonial administrators in America led to his arrest and removal from Hispaniola in 1500, and later to protracted litigation over the privileges he and his heirs claimed were owed to them by the Crown.\nColumbus's expeditions inaugurated a period of exploration, conquest, and colonization that lasted for centuries, thus bringing the Americas into the European sphere of influence. The transfer of plants, animals, precious metals, culture, human populations, technology, diseases, and ideas between the Old World and New World that followed his first voyage are known as the Columbian exchange, named after him. These events and the effects which persist to the present are often cited as the beginning of the modern era. Diseases introduced from the Old World contributed to the depopulation of Hispaniola's indigenous Ta\u00edno people, who were also subject to enslavement and other mistreatments by Columbus's government. Increased public awareness of these interactions has led to Columbus being less celebrated in Western culture, which has historically idealized him as a heroic discoverer. Numerous places have been named for him, as has Columbia, a personification commonly used to represent the United States.\nEarly life.\nColumbus's early life is obscure, but scholars believe he was born in the Republic of Genoa between 25 August and 31 October 1451. His father was Domenico Colombo, a wool weaver who worked in Genoa and Savona, and owned a cheese stand at which young Christopher worked. His mother was Susanna Fontanarossa. He had three brothers\u2014Bartholomew, Giovanni Pellegrino, and Giacomo (also called Diego)\u2014as well as a sister, Bianchinetta. Bartholomew ran a cartography workshop in Lisbon for at least part of his adulthood.\nHis native language is presumed to have been a Genoese dialect (Ligurian) as his first language, though Columbus probably never wrote in it. His name in 15th-century Genoese was \"Cristoffa Corombo\", in Italian, , and in Spanish .\nIn one of his writings, Columbus says he went to sea at 14. In 1470, the family moved to Savona, where Domenico took over a tavern. Some modern authors have argued that he was not from Genoa, but from the Aragon region of Spain or from Portugal. These competing hypotheses have been discounted by most scholars.\nIn 1473, Columbus began his apprenticeship as business agent for the wealthy Spinola, Centurione, and Di Negro families of Genoa. Later, he made a trip to the Greek island Chios in the Aegean Sea, then ruled by Genoa. In May 1476, he took part in an armed convoy sent by Genoa to carry valuable cargo to northern Europe. He probably visited Bristol, England, and Galway, Ireland, where he may have visited St. Nicholas' Collegiate Church. It has been speculated he went to Iceland in 1477, though many scholars doubt this. It is known that in the autumn of 1477, he sailed on a Portuguese ship from Galway to Lisbon, where he found his brother Bartholomew, and they continued trading for the Centurione family. Columbus based himself in Lisbon from 1477 to 1485. In 1478, the Centuriones sent Columbus on a sugar-buying trip to Madeira. He married Felipa Perestrello e Moniz, daughter of Bartolomeu Perestrello, a Portuguese nobleman of Lombard origin, who had been the donatary captain of Porto Santo.\nIn 1479 or 1480, Columbus's son Diego was born. Between 1482 and 1485, Columbus traded along the coasts of West Africa, reaching the Portuguese trading post of Elmina at the Guinea coast in present-day Ghana. Before 1484, Columbus returned to Porto Santo to find that his wife had died. He returned to Portugal to settle her estate and take Diego with him. He left Portugal for Castile in 1485, where he took a mistress in 1487, a 20-year-old orphan named Beatriz Enr\u00edquez de Arana. It is likely that Beatriz met Columbus when he was in C\u00f3rdoba, a gathering place for Genoese merchants and where the court of the Catholic Monarchs was located at intervals. Beatriz, unmarried at the time, gave birth to Columbus's second son, Fernando Columbus, in July 1488, named for the monarch of Aragon. Columbus recognized the boy as his offspring. Columbus entrusted his older, legitimate son Diego to take care of Beatriz and pay the pension set aside for her following his death, but Diego was negligent in his duties.\nColumbus learned Latin, Portuguese, and Castilian. He read widely about astronomy, geography, and history, including the works of Ptolemy, Pierre d'Ailly's ', the travels of Marco Polo and Sir John Mandeville, Pliny's \"Natural History\", and Pope Pius II's '. According to historian Edmund Morgan,\nColumbus was not a scholarly man. Yet he studied these books, made hundreds of marginal notations in them and came out with ideas about the world that were characteristically simple and strong and sometimes wrong\u00a0...\nQuest for Asia.\nBackground.\nUnder the Mongol Empire's hegemony over Asia and the \"Pax Mongolica\", Europeans had long enjoyed a safe land passage on the Silk Road to India, parts of East Asia, including China and Maritime Southeast Asia, which were sources of valuable goods. With the fall of Constantinople to the Ottoman Empire in 1453, the Silk Road was closed to Christian traders.\nIn 1474, the Florentine astronomer Paolo dal Pozzo Toscanelli suggested to King Afonso V of Portugal that sailing west across the Atlantic would be a quicker way to reach Asia than the route around Africa, but Afonso rejected his proposal. In the 1480s, Columbus and his brother proposed a plan to reach the East Indies by sailing west. Columbus supposedly wrote to Toscanelli in 1481 and received encouragement, along with a copy of a map the astronomer had sent Afonso implying that a westward route to Asia was possible. Columbus's plans were complicated by Bartolomeu Dias's rounding of the Cape of Good Hope in 1488, which suggested the Cape Route around Africa to Asia.\nColumbus had to wait until 1492 for King Ferdinand and Queen Isabella of Spain to support his voyage across the Atlantic to find gold, spices, a safer route to the East, and converts to Christianity.\nCarol Delaney and other commentators have argued that Columbus was a Christian millennialist and apocalypticist and that these beliefs motivated his quest for Asia in a variety of ways. Columbus often wrote about seeking gold in the log books of his voyages and writes about acquiring it \"in such quantity that the sovereigns... will undertake and prepare to go conquer the Holy Sepulcher\" in a fulfillment of Biblical prophecy. Columbus often wrote about converting all races to Christianity. Abbas Hamandi argues that Columbus was motivated by the hope of \"[delivering] Jerusalem from Muslim hands\" by \"using the resources of newly discovered lands\".\nGeographical considerations.\nDespite a popular misconception to the contrary, nearly all educated Westerners of Columbus's time knew that the Earth is spherical, a concept that had been understood since antiquity. The techniques of celestial navigation, which uses the position of the Sun and the stars in the sky, had long been in use by astronomers and were beginning to be implemented by mariners.\nHowever Columbus made several errors in calculating the size of the Earth, the distance the continent extended to the east, and therefore the distance to the west to reach his goal.\nFirst, as far back as the 3rd century\u00a0BC, Eratosthenes had correctly computed the circumference of the Earth by using simple geometry and studying the shadows cast by objects at two remote locations. In the 1st century\u00a0BC, Posidonius confirmed Eratosthenes's results by comparing stellar observations at two separate locations. These measurements were widely known among scholars, but Ptolemy's use of the smaller, old-fashioned units of distance led Columbus to underestimate the size of the Earth by about a third.\nSecond, three cosmographical parameters determined the bounds of Columbus's enterprise: the distance across the ocean between Europe and Asia, which depended on the extent of the oikumene, i.e., the Eurasian land-mass stretching east\u2013west between Spain and China; the circumference of the Earth; and the number of miles or leagues in a degree of longitude, which was possible to deduce from the theory of the relationship between the size of the surfaces of water and the land as held by the followers of Aristotle in medieval times.\nFrom Pierre d'Ailly's \"\" (1410), Columbus learned of Alfraganus's estimate that a degree of latitude (equal to approximately a degree of longitude along the equator) spanned 56.67\u00a0Arabic miles (equivalent to or 76.2\u00a0mi), but he did not realize that this was expressed in the Arabic mile (about ) rather than the shorter Roman mile (about 1,480\u00a0m) with which he was familiar. Columbus therefore estimated the size of the Earth to be about 75% of Eratosthenes's calculation.\nThird, most scholars of the time accepted Ptolemy's estimate that Eurasia spanned 180\u00b0 longitude, rather than the actual 130\u00b0 (to the Chinese mainland) or 150\u00b0 (to Japan at the latitude of Spain). Columbus believed an even higher estimate, leaving a smaller percentage for water. In d'Ailly's \"\", Columbus read Marinus of Tyre's estimate that the longitudinal span of Eurasia was 225\u00b0 at the latitude of Rhodes. Some historians, such as Samuel Eliot Morison, have suggested that he followed the statement in the apocryphal book 2 Esdras () that \"six parts [of the globe] are habitable and the seventh is covered with water.\" He was also aware of Marco Polo's claim that Japan (which he called \"Cipangu\") was some to the east of China (\"Cathay\"), and closer to the equator than it is. He was influenced by Toscanelli's idea that there were inhabited islands even farther to the east than Japan, including the mythical Antillia, which he thought might lie not much farther to the west than the Azores, and the distance westward from the Canary Islands to the Indies as only 68 degrees, equivalent to (a 58% error).\nBased on his sources, Columbus estimated a distance of from the Canary Islands west to Japan; the actual distance is . No ship in the 15th century could have carried enough food and fresh water for such a long voyage, and the dangers involved in navigating through the uncharted ocean would have been formidable. Most European navigators reasonably concluded that a westward voyage from Europe to Asia was unfeasible. The Catholic Monarchs, however, having completed the , an expensive war against the Moors in the Iberian Peninsula, were eager to obtain a competitive edge over other European countries in the quest for trade with the Indies. Columbus's project, though far-fetched, held the promise of such an advantage.\nNautical considerations.\nThough Columbus was wrong about the number of degrees of longitude that separated Europe from the Far East and about the distance that each degree represented, he did take advantage of the trade winds, which would prove to be the key to his successful navigation of the Atlantic Ocean. He planned to first sail to the Canary Islands before continuing west with the northeast trade wind. Part of the return to Spain would require traveling against the wind using an arduous sailing technique called beating, during which progress is made very slowly. To effectively make the return voyage, Columbus would need to follow the curving trade winds northeastward to the middle latitudes of the North Atlantic, where he would be able to catch the westerlies that blow eastward to the coast of Western Europe.\nThe navigational technique for travel in the Atlantic appears to have been exploited first by the Portuguese, who referred to it as the ('turn of the sea'). Through his marriage to his first wife, Felipa Perestrello, Columbus had access to the nautical charts and logs that had belonged to her deceased father, Bartolomeu Perestrello, who had served as a captain in the Portuguese navy under Prince Henry the Navigator. In the mapmaking shop where he worked with his brother Bartholomew, Columbus also had ample opportunity to hear the stories of old seamen about their voyages to the western seas, but his knowledge of the Atlantic wind patterns was still imperfect at the time of his first voyage. By sailing due west from the Canary Islands during hurricane season, skirting the so-called horse latitudes of the mid-Atlantic, he risked being becalmed and running into a tropical cyclone, both of which he avoided by chance.\nQuest for financial support for a voyage.\nBy about 1484, Columbus proposed his planned voyage to King John II of Portugal. The king submitted Columbus's proposal to his advisors, who rejected it, correctly, on the grounds that Columbus's estimate for a voyage of 2,400\u00a0nmi was only a quarter of what it should have been. In 1488, Columbus again appealed to the court of Portugal, and John II again granted him an audience. That meeting also proved unsuccessful, in part because not long afterwards Bartolomeu Dias returned to Portugal with news of his successful rounding of the southern tip of Africa (near the Cape of Good Hope).\nColumbus sought an audience with the monarchs Ferdinand II of Aragon and Isabella I of Castile, who had united several kingdoms in the Iberian Peninsula by marrying and now ruled together. On 1 May 1486, permission having been granted, Columbus presented his plans to Queen Isabella, who in turn referred it to a committee. The learned men of Spain, like their counterparts in Portugal, replied that Columbus had grossly underestimated the distance to Asia. They pronounced the idea impractical and advised the Catholic Monarchs to pass on the proposed venture. To keep Columbus from taking his ideas elsewhere, and perhaps to keep their options open, the sovereigns gave him an allowance, totaling about 14,000 for the year, or about the annual salary of a sailor. In May 1489, the queen sent him another 10,000 , and the same year the monarchs furnished him with a letter ordering all cities and towns under their dominion to provide him food and lodging at no cost.\nColumbus also dispatched his brother Bartholomew to the court of Henry VII of England to inquire whether the English Crown might sponsor his expedition, but he was captured by pirates en route, and only arrived in early 1491. By that time, Columbus had retreated to La R\u00e1bida Friary, where the Spanish Crown sent him 20,000 \"maravedis\" to buy new clothes and instructions to return to the Spanish court for renewed discussions.\nAgreement with the Spanish Crown.\nColumbus waited at King Ferdinand's camp until Ferdinand and Isabella conquered Granada, the last Muslim stronghold on the Iberian Peninsula, in January 1492. A council led by Isabella's confessor, Hernando de Talavera, found Columbus's proposal to reach the Indies implausible. Columbus had left for France when Ferdinand intervened, first sending Talavera and Bishop Diego Deza to appeal to the queen. Isabella was finally convinced by the king's clerk Luis de Sant\u00e1ngel, who argued that Columbus would take his ideas elsewhere, and offered to help arrange the funding. Isabella then sent a royal guard to fetch Columbus, who had traveled 2 leagues (over 10\u00a0km) toward C\u00f3rdoba.\nIn the April 1492 \"Capitulations of Santa Fe\", King Ferdinand and Queen Isabella promised Columbus that if he succeeded he would be given the rank of \"Admiral of the Ocean Sea\" and appointed Viceroy and Governor of all the new lands he might claim for Spain. He had the right to nominate three persons, from whom the sovereigns would choose one, for any office in the new lands. He would be entitled to one-tenth () of all the revenues from the new lands in perpetuity. He also would have the option of buying one-eighth interest in any commercial venture in the new lands, and receive one-eighth () of the profits.\nIn 1500, during his third voyage to the Americas, Columbus was arrested and dismissed from his posts. He and his sons, Diego and Fernando, then conducted a lengthy series of court cases against the Castilian Crown, known as the , alleging that the Crown had illegally reneged on its contractual obligations to Columbus and his heirs. The Columbus family had some success in their first litigation, as a judgment of 1511 confirmed Diego's position as viceroy but reduced his powers. Diego resumed litigation in 1512, which lasted until 1536, and further disputes initiated by heirs continued until 1790.\nVoyages.\nBetween 1492 and 1504, Columbus completed four round-trip voyages between Spain and the Americas, each voyage being sponsored by the Crown of Castile. On his first voyage he reached the Americas, initiating the European exploration and colonization of the continent, as well as the Columbian exchange. His role in history is thus important to the Age of Discovery, Western history, and human history writ large.\nIn Columbus's letter on the first voyage, published following his first return to Spain, he claimed that he had reached Asia, as previously described by Marco Polo and other Europeans. Over his subsequent voyages, Columbus refused to acknowledge that the lands he visited and claimed for Spain were not part of Asia, in the face of mounting evidence to the contrary. This might explain, in part, why the American continent was named after the Florentine explorer Amerigo Vespucci\u2014who received credit for recognizing it as a \"New World\"\u2014and not after Columbus.\nFirst voyage (1492\u20131493).\nOn the evening of 3 August 1492, Columbus departed from Palos de la Frontera with three ships. The largest was a carrack, the \"Santa Mar\u00eda\", owned and captained by Juan de la Cosa, and under Columbus's direct command. The other two were smaller caravels, the \"Pinta\" and the \"Ni\u00f1a\", piloted by the Pinz\u00f3n brothers. Columbus first sailed to the Canary Islands. There he restocked provisions and made repairs then departed from San Sebasti\u00e1n de La Gomera on 6 September, for what turned out to be a five-week voyage across the ocean.\nOn 7 October, the crew spotted \"[i]mmense flocks of birds\". On 11 October, Columbus changed the fleet's course to due west, and sailed through the night, believing land was soon to be found. At around 02:00 the following morning, a lookout on the \"Pinta\", Rodrigo de Triana, spotted land. The captain of the \"Pinta\", Mart\u00edn Alonso Pinz\u00f3n, verified the sight of land and alerted Columbus. Columbus later maintained that he had already seen a light on the land a few hours earlier, thereby claiming for himself the lifetime pension promised by Ferdinand and Isabella to the first person to sight land. Columbus called this island (in what is now the Bahamas) ('Holy Savior'); the Natives called it Guanahani. Christopher Columbus's journal entry of 12 October 1492 states:I saw some who had marks of wounds on their bodies and I made signs to them asking what they were; and they showed me how people from other islands nearby came there and tried to take them, and how they defended themselves; and I believed and believe that they come here from to take them captive. They should be good and intelligent servants, for I see that they say very quickly everything that is said to them; and I believe they would become Christians very easily, for it seemed to me that they had no religion. Our Lord pleasing, at the time of my departure I will take six of them from here to Your Highnesses in order that they may learn to speak.\nColumbus called the inhabitants of the lands that he visited ('Indians'). He initially encountered the Lucayan, Ta\u00edno, and Arawak peoples. Noting their gold ear ornaments, Columbus took some of the Arawaks prisoner and insisted that they guide him to the source of the gold. Columbus did not believe he needed to create a fortified outpost, writing, \"the people here are simple in war-like matters ... I could conquer the whole of them with fifty men, and govern them as I pleased.\" The Ta\u00ednos told Columbus that another indigenous tribe, the Caribs, were fierce warriors and cannibals, who made frequent raids on the Ta\u00ednos, often capturing their women, although this may have been a belief perpetuated by the Spaniards to justify enslaving them.\nColumbus also explored the northeast coast of Cuba, where he landed on 28 October. On the night of 26 November, Mart\u00edn Alonso Pinz\u00f3n took the \"Pinta\" on an unauthorized expedition in search of an island called \"Babeque\" or \"Baneque\", which the natives had told him was rich in gold. Columbus, for his part, continued to the northern coast of Hispaniola, where he landed on 6 December. There, the \"Santa Mar\u00eda\" ran aground on 25 December 1492 and had to be abandoned. The wreck was used as a target for cannon fire to impress the native peoples. Columbus was received by the native \"cacique\" Guacanagari, who gave him permission to leave some of his men behind. Columbus left 39 men, including the interpreter Luis de Torres, and founded the settlement of La Navidad, in present-day Haiti. Columbus took more natives prisoner and continued his exploration. He kept sailing along the northern coast of Hispaniola with a single ship until he encountered Pinz\u00f3n and the \"Pinta\" on 6 January.\nOn 13 January 1493, Columbus made his last stop of this voyage in the Americas, in the Bay of Rinc\u00f3n in northeast Hispaniola. There he encountered the Ciguayos, the only natives who offered violent resistance during this voyage. The Ciguayos refused to trade the amount of bows and arrows that Columbus desired; in the ensuing clash one Ciguayo was stabbed in the buttocks and another wounded with an arrow in his chest. Because of these events, Columbus called the inlet the ('Bay of Arrows').\nColumbus headed for Spain on the \"Ni\u00f1a\", but a storm separated him from the \"Pinta\", and forced the \"Ni\u00f1a\" to stop at the island of Santa Maria in the Azores. Half of his crew went ashore to say prayers of thanksgiving in a chapel for having survived the storm. But while praying, they were imprisoned by the governor of the island, ostensibly on suspicion of being pirates. After a two-day stand-off, the prisoners were released, and Columbus again set sail for Spain.\nAnother storm forced Columbus into the port at Lisbon. From there he went to north of Lisbon to meet King John II of Portugal, who told Columbus that he believed the voyage to be in violation of the 1479 Treaty of Alc\u00e1\u00e7ovas. After spending more than a week in Portugal, Columbus set sail for Spain. Returning to Palos on 15 March 1493, he was given a hero's welcome and soon afterward received by Isabella and Ferdinand in Barcelona. To them he presented kidnapped Ta\u00ednos and various plants and items he had collected.\nOne of the ten Natives taken on the return trip was a Lucayan Ta\u00edno from Guanahani thought to be 13\u201315 years of age, who Columbus adopted as his son upon their arrival in Spain; the boy, whose Lucayan name is unknown, received the name \"Diego\" at baptism. Initially, Diego had been recognized for his intelligence and rapid acquisition of Spanish customs, and would serve as a guide and interpreter on each of Columbus's subsequent voyages. By the second voyage's departure later in 1493, Diego was the only Native out of the ten taken to Europe who had not died or become seriously ill as the result of disease; while on this voyage, he played a vital role in the discovery of La Navidad. He subsequently married and had a son, also named Diego, who died of illness in 1506. Following Columbus's death, Diego spent the rest of his life confined to Santo Domingo, and does not reappear in the historical record following a smallpox epidemic that swept Hispaniola in 1519.\nColumbus's letter on the first voyage, probably dispatched to the Spanish court upon arrival in Lisbon, was instrumental in spreading the news throughout Europe about his voyage. Almost immediately after his arrival in Spain, printed versions began to appear, and word of his voyage spread rapidly. Most people initially believed that he had reached Asia. The Bulls of Donation, three papal bulls of Pope Alexander VI delivered in 1493, purported to grant overseas territories to Portugal and the Catholic Monarchs of Spain. They were replaced by the Treaty of Tordesillas of 1494.\nThe two earliest published copies of Columbus's letter on the first voyage aboard the \"Ni\u00f1a\" were donated in 2017 by the Jay I. Kislak Foundation to the University of Miami library in Coral Gables, Florida, where they are housed.\nSecond voyage (1493\u20131496).\nOn 24 September 1493, Columbus sailed from C\u00e1diz with 17 ships, and supplies to establish permanent colonies in the Americas. He sailed with nearly 1,500 men, including sailors, soldiers, priests, carpenters, stonemasons, metalworkers, and farmers. Among the expedition members were Alvarez Chanca, a physician who wrote a detailed account of the second voyage; Juan Ponce de Le\u00f3n, the first governor of Puerto Rico and Florida; the father of Bartolom\u00e9 de las Casas; Juan de la Cosa, a cartographer who is credited with making the first world map depicting the New World; and Columbus's youngest brother Diego. The fleet stopped at the Canary Islands to take on more supplies, and set sail again on 7 October, deliberately taking a more southerly course than on the first voyage.\nOn 3 November, they arrived in the Windward Islands; the first island they encountered was named Dominica by Columbus, but not finding a good harbor there, they anchored off a nearby smaller island, which he named , now a part of Guadeloupe and called Marie-Galante. Other islands named by Columbus on this voyage were Montserrat, Antigua, Saint Martin, the Virgin Islands, as well as many others.\nOn 17 November, Columbus first sighted the eastern coast of the island of Puerto Rico, known to its native Taino people as . His fleet sailed along the island's southern coast for a whole day, before making landfall on its northwestern coast at the Bay of A\u00f1asco, early on 19 November. Upon landing, Columbus christened the island \"San Juan Bautista\" after John the Baptist, and remained anchored there for two days from 20 to 21 November, filling the water casks of the ships in his fleet.\nOn 22 November, Columbus returned to Hispaniola to visit \"La Navidad\" in modern-day Haiti, where 39 Spaniards had been left during the first voyage. Columbus found the fort in ruins. He learned from Guacanagar\u00edx, the local tribe leader, that his men had quarreled over gold and taken women from the tribe, and that after some left for the territory of Caonabo, Caonabo came and burned the fort and killed the rest of the men there. \nColumbus then established a poorly located and short-lived settlement to the east, La Isabela, in the present-day Dominican Republic. By the end of 1494, disease and famine had killed two-thirds of the Spanish settlers there.\nFrom April to August 1494, Columbus explored Cuba and Jamaica, then returned to Hispaniola. Before leaving on this exploration to Cuba, Columbus had ordered a large amount of men, under Pedro Margarit, to \"journey the length and breadth of the island, enforcing Spanish control and bringing all the people under the Spanish yoke.\" These men, in his absence, raped women, took men captive to be servants, and stole from the indigenous people. A number of Spanish were killed in retaliation. By the time Columbus returned from exploring Cuba, the four primary leaders of the Arawak people in Hispaniola were gathering for war to try to drive the Spanish from the Island. Columbus assembled a large number of troops, and joined with his one native ally, chief [Guacanagarix], met for battle. The Spanish, even though they were largely outnumbered, won this battle, and over the next 9 months Columbus continued to wage war on the native Ta\u00edno on Hispaniola until they surrendered and agreed to pay tribute.\nColumbus implemented , a Spanish labor system that rewarded conquerors with the labor of conquered non-Christian people. It is also recorded that punishments to both Spaniards and natives included whippings and mutilation (cutting noses and ears).\nColumbus and the colonists enslaved many of the indigenous people, including children. Natives were beaten, raped, and tortured for the location of imagined gold. Thousands committed suicide rather than face the oppression.\nIn February 1495, Columbus rounded up about 1,500 Arawaks, some of whom had rebelled, in a great slave raid. About 500 of the strongest were shipped to Spain as slaves, with about two hundred of those dying en route.\nIn June 1495, the Spanish Crown sent ships and supplies to Hispaniola. In October, Florentine merchant Gianotto Berardi, who had won the contract to provision the fleet of Columbus's second voyage and to supply the colony on Hispaniola, received almost 40,000 worth of enslaved Indians. He renewed his effort to get supplies to Columbus, and was working to organize a fleet when he suddenly died in December. On 10 March 1496, having been away about 30 months, the fleet departed La Isabela. On 8 June the crew sighted land somewhere between Lisbon and Cape St. Vincent, and disembarked in C\u00e1diz on 11 June.\nThird voyage (1498\u20131500).\nOn 30 May 1498, Columbus left with six ships from Sanl\u00facar, Spain. The fleet called at Madeira and the Canary Islands, where it divided in two, with three ships heading for Hispaniola and the other three vessels, commanded by Columbus, sailing south to the Cape Verde Islands and then westward across the Atlantic. It is probable that this expedition was intended at least partly to confirm rumors of a large continent south of the Caribbean Sea, that is, South America.\nOn 31 July they sighted Trinidad, the most southerly of the Caribbean islands. On 5 August, Columbus sent several small boats ashore on the southern side of the Paria Peninsula in what is now Venezuela, near the mouth of the Orinoco river. This was the first recorded landing of Europeans on the mainland of South America, which Columbus realized must be a continent. The fleet then sailed to the islands of Chacachacare and Margarita, reaching the latter on 14 August, and sighted Tobago and Grenada from afar, according to some scholars.\nOn 19 August, Columbus returned to Hispaniola. There he found settlers in rebellion against his rule, and his unfulfilled promises of riches. Columbus had some of the Europeans tried for their disobedience; at least one rebel leader was hanged.\nIn October 1499, Columbus sent two ships to Spain, asking the Court of Spain to appoint a royal commissioner to help him govern. By this time, accusations of tyranny and incompetence on the part of Columbus had also reached the Court. The sovereigns sent Francisco de Bobadilla, a relative of Marquesa Beatriz de Bobadilla, a patron of Columbus and a close friend of Queen Isabella, to investigate the accusations of brutality made against the Admiral. Arriving in Santo Domingo while Columbus was away, Bobadilla was immediately met with complaints about all three Columbus brothers. He moved into Columbus's house and seized his property, took depositions from the Admiral's enemies, and declared himself governor.\nBobadilla reported to Spain that Columbus once punished a man found guilty of stealing corn by having his ears and nose cut off and then selling him into slavery. He claimed that Columbus regularly used torture and mutilation to govern Hispaniola. Testimony recorded in the report stated that Columbus congratulated his brother Bartholomew on \"defending the family\" when the latter ordered for a woman to be paraded naked through the streets and then had her tongue cut because she had \"spoken ill of the admiral and his brothers\". The document also describes how Columbus put down native unrest and revolt: he first ordered a brutal suppression of the uprising in which many natives were killed, and then paraded their dismembered bodies through the streets in an attempt to discourage further rebellion. Columbus vehemently denied the charges. The neutrality and accuracy of the accusations and investigations of Bobadilla toward Columbus and his brothers have been disputed by historians, given the anti-Italian sentiment of the Spaniards and Bobadilla's desire to take over Columbus's position.\nIn early October 1500, Columbus and Diego presented themselves to Bobadilla, and were put in chains aboard \"La Gorda\", the caravel on which Bobadilla had arrived at Santo Domingo. They were returned to Spain, and languished in jail for six weeks before King Ferdinand ordered their release. Not long after, the king and queen summoned the Columbus brothers to the Alhambra palace in Granada. The sovereigns expressed indignation at the actions of Bobadilla, who was then recalled and ordered to make restitutions of the property he had confiscated from Columbus. The royal couple heard the brothers' pleas; restored their freedom and wealth; and, after much persuasion, agreed to fund Columbus's fourth voyage. However, Nicol\u00e1s de Ovando was to replace Bobadilla and be the new governor of the West Indies.\nNew light was shed on the seizure of Columbus and his brother Bartholomew, the Adelantado, with the discovery by archivist Isabel Aguirre of an incomplete copy of the testimonies against them gathered by Francisco de Bobadilla at Santo Domingo in 1500. She found a manuscript copy of this (inquiry) \u200cin the Archive of Simancas, Spain, uncatalogued until she and Consuelo Varela published their book, \"\" (\"The fall of Christopher Col\u00f3n: the judgement of Bobadilla\") in 2006.\nFourth voyage (1502\u20131504).\nOn 9 May 1502, Columbus left C\u00e1diz with his flagship \"Santa Mar\u00eda\" and three other vessels. The ships were crewed by 140 men, including his brother Bartholomew as second in command and his son Fernando. He sailed to Asilah on the Moroccan coast to rescue Portuguese soldiers said to be besieged by the Moors. The siege had been lifted by the time they arrived, so the Spaniards stayed only a day and continued on to the Canary Islands.\nOn 15 June, the fleet arrived at Martinique, where it lingered for several days. A hurricane was forming, so Columbus continued westward, hoping to find shelter on Hispaniola. He arrived at Santo Domingo on 29 June, but was denied port, and the new governor Francisco de Bobadilla refused to listen to his warning that a hurricane was approaching. Instead, while Columbus's ships sheltered at the mouth of the Rio Jaina, the first Spanish treasure fleet sailed into the hurricane. Columbus's ships survived with only minor damage, while 20 of the 30 ships in the governor's fleet were lost along with 500 lives (including that of Francisco de Bobadilla). Although a few surviving ships managed to straggle back to Santo Domingo, \"\", the fragile ship carrying Columbus's personal belongings and his 4,000 pesos in gold was the sole vessel to reach Spain. The gold was his \"tenth\" () of the profits from Hispaniola, equal to 240,000 maravedis, guaranteed by the Catholic Monarchs in 1492.\nAfter a brief stop at Jamaica, Columbus sailed to Central America, arriving at the coast of Honduras on 30 July. Here Bartholomew found native merchants and a large canoe. On 14 August, Columbus landed on the continental mainland at Punta Caxinas, now Puerto Castilla, Honduras. He spent two months exploring the coasts of Honduras, Nicaragua, and Costa Rica, seeking a strait in the western Caribbean through which he could sail to the Indian Ocean. Sailing south along the Nicaraguan coast, he found a channel that led into Almirante Bay in Panama on 5 October.\nAs soon as his ships anchored in Almirante Bay, Columbus encountered Ng\u00e4be people in canoes who were wearing gold ornaments. In January 1503, he established a garrison at the mouth of the Bel\u00e9n River. Columbus left for Hispaniola on 16 April. On 10 May he sighted the Cayman Islands, naming them after the numerous sea turtles there. His ships sustained damage in a storm off the coast of Cuba. Unable to travel farther, on 25 June 1503 they were beached in Saint Ann Parish, Jamaica.\nFor six months Columbus and 230 of his men remained stranded on Jamaica. Diego M\u00e9ndez de Segura, who had shipped out as a personal secretary to Columbus, and a Spanish shipmate called Bartolom\u00e9 Flisco, along with six natives, paddled a canoe to get help from Hispaniola. The governor, Nicol\u00e1s de Ovando y C\u00e1ceres, detested Columbus and obstructed all efforts to rescue him and his men. In the meantime Columbus, in a desperate effort to induce the natives to continue provisioning him and his hungry men, won their favor by predicting a lunar eclipse for 29 February 1504, using Abraham Zacuto's astronomical charts. Despite the governor's obstruction, Christopher Columbus and his men were rescued on 28 June 1504, and arrived in Sanl\u00facar, Spain, on 7 November.\nLater life, illness, and death.\nColumbus had always claimed that the conversion of non-believers was one reason for his explorations, and he grew increasingly religious in his later years. Probably with the assistance of his son Diego and his friend the Carthusian monk Gaspar Gorricio, Columbus produced two books during his later years: a \"Book of Privileges\" (1502), detailing and documenting the rewards from the Spanish Crown to which he believed he and his heirs were entitled, and a \"Book of Prophecies\" (1505), in which passages from the Bible were used to place his achievements as an explorer in the context of Christian eschatology.\nIn his later years, Columbus demanded that the Crown of Castile give him his tenth of all the riches and trade goods yielded by the new lands, as stipulated in the Capitulations of Santa Fe. Because he had been relieved of his duties as governor, the Crown did not feel bound by that contract and his demands were rejected. After his death, his heirs sued the Crown for a part of the profits from trade with America, as well as other rewards. This led to a protracted series of legal disputes known as the ('Columbian lawsuits').\nDuring a violent storm on his first return voyage, Columbus, then 41, had suffered an attack of what was believed at the time to be gout. In subsequent years, he was plagued with what was thought to be influenza and other fevers, bleeding from the eyes, temporary blindness and prolonged attacks of gout. The attacks increased in duration and severity, sometimes leaving Columbus bedridden for months at a time, and culminated in his death 14 years later.\nBased on Columbus's lifestyle and the described symptoms, some modern commentators suspect that he suffered from reactive arthritis, rather than gout. Reactive arthritis is a joint inflammation caused by intestinal bacterial infections or after acquiring certain sexually transmitted diseases (primarily chlamydia or gonorrhea). In 2006, Frank C. Arnett, a medical doctor, and historian Charles Merrill, published their paper in \"The American Journal of the Medical Sciences\" proposing that Columbus had a form of reactive arthritis; Merrill made the case in that same paper that Columbus was the son of Catalans and his mother possibly a member of a prominent (converted Jew) family. \"It seems likely that [Columbus] acquired reactive arthritis from food poisoning on one of his ocean voyages because of poor sanitation and improper food preparation\", says Arnett, a rheumatologist and professor of internal medicine, pathology and laboratory medicine at the University of Texas Medical School at Houston.\nSome historians such as H. Micheal Tarver and Emily Slape, as well as medical doctors such as Arnett and Antonio Rodr\u00edguez Cuartero, believe that Columbus had such a form of reactive arthritis, but according to other authorities, this is \"speculative\", or \"very speculative\".\nAfter his arrival to Sanl\u00facar from his fourth voyage (and Queen Isabella's death), an ill Columbus settled in Seville in April 1505. He stubbornly continued to make pleas to the Crown to defend his own personal privileges and his family's. He moved to Segovia (where the court was at the time) on a mule by early 1506, and, on the occasion of the wedding of King Ferdinand with Germaine of Foix in Valladolid, Spain, in March 1506, Columbus moved to that city to persist with his demands. On 20 May 1506, aged 54, Columbus died in Valladolid.\nLocation of remains.\nColumbus's remains were first buried at the Chapel of Wonders at the Convent of St. Francis, Valladolid, but were then moved to the monastery of La Cartuja in Seville (southern Spain) by the will of his son Diego. They may have been exhumed in 1513 and interred at the Seville Cathedral. In about 1536, the remains of both Columbus and his son Diego were moved to a cathedral in Colonial Santo Domingo, in the present-day Dominican Republic; Columbus had requested to be buried on the island. By some accounts, in 1793, when France took over the entire island of Hispaniola, Columbus's remains were moved to Havana, Cuba. After Cuba became independent following the Spanish\u2013American War in 1898, at least some of these remains were moved back to the Seville Cathedral, where they were placed on an elaborate catafalque.\nIn June 2003, DNA samples were taken from the remains in Seville, as well as those of Columbus's brother Diego and younger son Fernando. Initial observations suggested that the bones did not appear to match Columbus's physique or age at death. DNA extraction proved difficult; only short fragments of mitochondrial DNA could be isolated. These matched corresponding DNA from Columbus's brother, supporting that the two men had the same mother. Such evidence, together with anthropologic and historic analyses, led the researchers to conclude that the remains belonged to Christopher Columbus.\nIn 1877, a priest discovered a lead box at Santo Domingo inscribed: \"Discoverer of America, First Admiral\". Inscriptions found the next year read \"Last of the remains of the first admiral, Sire Christopher Columbus, discoverer.\" The box contained bones of an arm and a leg, as well as a bullet. These remains were considered legitimate by physician and U.S. Assistant Secretary of State John Eugene Osborne, who suggested in 1913 that they travel through the Panama Canal as a part of its opening ceremony. These remains were kept at the Basilica Cathedral of Santa Mar\u00eda la Menor (in the Colonial City of Santo Domingo) before being moved to the Columbus Lighthouse (Santo Domingo Este, inaugurated in 1992). The authorities in Santo Domingo have never allowed these remains to be DNA-tested, so it is unconfirmed whether they are from Columbus's body as well.\nCommemoration.\nThe figure of Columbus was not ignored in the British colonies during the colonial era: Columbus became a unifying symbol early in the history of the colonies that became the United States when Puritan preachers began to use his life story as a model for a \"developing American spirit\". In the spring of 1692, Puritan preacher Cotton Mather described Columbus's voyage as one of three shaping events of the modern age, connecting Columbus's voyage and the Puritans' migration to North America, seeing them together as the key to a grand design.\nThe use of Columbus as a founding figure of New World nations spread rapidly after the American Revolution. This was out of a desire to develop a national history and founding myth with fewer ties to Britain. His name was the basis for the female national personification of the United States, Columbia, in use since the 1730s with reference to the original Thirteen Colonies, and also a historical name applied to the Americas and to the New World. Columbia, South Carolina and \"Columbia Rediviva\", the ship for which the Columbia River was named, are named for Columbus.\nColumbus's name was given to the newly born Republic of Colombia in the early 19th century, inspired by the political project of \"Colombeia\" developed by revolutionary Francisco de Miranda, which was put at the service of the emancipation of continental Hispanic America.\nTo commemorate the 400th anniversary of the landing of Columbus, the 1893 World's Fair in Chicago was named the World's Columbian Exposition. The U.S. Postal Service issued the first U.S. commemorative stamps, the Columbian Issue, depicting Columbus, Queen Isabella and others in various stages of his several voyages. A commemorative silver half dollar was also struck, which remains the only U.S. currency issued having a foreigner as its subject. The policies related to the celebration of the Spanish colonial empire as the vehicle of a nationalist project undertaken in Spain during the Restoration in the late 19th century took form with the commemoration of the 4th centenary on 12 October 1892 (in which the figure of Columbus was extolled by the Conservative government), eventually becoming the very same national day. Several monuments commemorating the \"discovery\" were erected in cities such as Palos, Barcelona, Granada, Madrid, Salamanca, Valladolid and Seville in the years around the 400th anniversary.\nFor the Columbus Quincentenary in 1992, a second Columbian issue was released jointly with Italy, Portugal, and Spain. Columbus was celebrated at Seville Expo '92, and Genoa Expo '92.\nThe Boal Mansion Museum, founded in 1951, contains a collection of materials concerning later descendants of Columbus and collateral branches of the family. It features a 16th-century chapel from a Spanish castle reputedly owned by Diego Col\u00f3n which became the residence of Columbus's descendants. The chapel interior was dismantled and moved from Spain in 1909 and re-erected on the Boal estate at Boalsburg, Pennsylvania. Inside it are numerous religious paintings and other objects including a reliquary with fragments of wood supposedly from the True Cross. The museum also holds a collection of documents mostly relating to Columbus descendants of the late 18th and early 19th centuries.\nIn many countries of the Americas, as well as Spain and Italy, Columbus Day celebrates the anniversary of Columbus's arrival in the Americas on 12 October 1492.\nLegacy.\nThe voyages of Columbus are considered a turning point in human history, marking the beginning of globalization and accompanying demographic, commercial, economic, social, and political changes.\nHis explorations resulted in permanent contact between the two hemispheres, and the term \"pre-Columbian\" is used to refer to the cultures of the Americas before the arrival of Columbus and his European successors. The ensuing Columbian exchange saw the massive exchange of animals, plants, fungi, diseases, technologies, mineral wealth and ideas.\nIn the first century after his endeavors, Columbus's figure largely languished in the backwaters of history, and his reputation was beset by his failures as a colonial administrator. His legacy was somewhat rescued from oblivion when he began to appear as a character in Italian and Spanish plays and poems from the late 16th century onward.\nColumbus was subsumed into the Western narrative of colonization and empire building, which invoked notions of \"translatio imperii\" and \"translatio studii\" to underline who was considered \"civilized\" and who was not.\nThe Americanization of the figure of Columbus began in the latter decades of the 18th century, after the revolutionary period of the United States, elevating the status of his reputation to a national myth, \"homo americanus\". His landing became a powerful icon as an \"image of American genesis\". \"The Discovery of America\" sculpture, depicting Columbus and a cowering Native maiden, was commissioned on 3 April 1837, when U.S. President Martin Van Buren sanctioned the engineering of Luigi Persico's design. This representation of Columbus's triumph and the Native's recoil is a demonstration of supposed white superiority over savage, naive Natives. As recorded during its unveiling in 1844, the sculpture extends to \"represent the meeting of the two races\", as Persico captures their first interaction, highlighting the \"moral and intellectual inferiority\" of Natives. Placed outside the U.S. Capitol building where it remained until its removal in the mid-20th century, the sculpture reflected the contemporary view of whites in the U.S. toward the Natives; they are labeled \"merciless Indian savages\" in the United States Declaration of Independence. In 1836, Pennsylvania senator and future U.S. President James Buchanan, who proposed the sculpture, described it as representing \"the great discoverer when he first bounded with ecstasy upon the shore, ail his toils past, presenting a hemisphere to the astonished world, with the name America inscribed upon it. Whilst he is thus standing upon the shore, a female savage, with awe and wonder depicted in her countenance, is gazing upon him.\"\nThe American Columbus myth was reconfigured later in the century when he was enlisted as an ethnic hero by immigrants to the United States who were not of Anglo-Saxon stock, such as Jewish, Italian, and Irish people, who claimed Columbus as a sort of ethnic founding father. Catholics unsuccessfully tried to promote him for canonization in the 19th century.\nFrom the 1990s onward, a narrative of Columbus being responsible for the genocide of indigenous peoples and environmental destruction began to compete with the then predominant discourse of Columbus as Christ-bearer, scientist, or father of America. This narrative features the negative effects of Columbus' conquests on native populations. Exposed to Old World diseases, the indigenous populations of the New World collapsed, and were largely replaced by Europeans and Africans, who brought with them new methods of farming, business, governance, and religious worship.\nOriginality of discovery of America.\nThough Christopher Columbus came to be considered the European discoverer of America in Western popular culture, his historical legacy is more nuanced. After settling Iceland, the Norse settled the uninhabited southern part of Greenland beginning in the 10th century. Norsemen are believed to have then set sail from Greenland and Iceland to become the first known Europeans to reach the North American mainland, nearly 500 years before Columbus reached the Caribbean. The 1960s discovery of a Norse settlement dating c.\u00a01000 at L'Anse aux Meadows, Newfoundland, partially corroborates accounts within the Icelandic sagas of Erik the Red's colonization of Greenland and his son Leif Erikson's subsequent exploration of a place he called Vinland.\nIn the 19th century, amid a revival of interest in Norse culture, Carl Christian Rafn and Benjamin Franklin DeCosta wrote works establishing that the Norse had preceded Columbus in colonizing the Americas. Following this, in 1874 Rasmus Bj\u00f8rn Anderson argued that Columbus must have known of the North American continent before he started his voyage of discovery. Most modern scholars doubt Columbus had knowledge of the Norse settlements in America, with his arrival to the continent being most likely an independent discovery.\nEuropeans devised explanations for the origins of the Native Americans and their geographical distribution with narratives that often served to reinforce their own preconceptions built on ancient intellectual foundations. In modern Latin America, the non-Native populations of some countries often demonstrate an ambiguous attitude toward the perspectives of indigenous peoples regarding the so-called \"discovery\" by Columbus and the era of colonialism that followed.\nIn his 1960 monograph, Mexican philosopher and historian Edmundo O'Gorman explicitly rejects the Columbus discovery myth, arguing that the idea that Columbus discovered America was a misleading legend fixed in the public mind through the works of American author Washington Irving during the 19th century. O'Gorman argues that to assert Columbus \"discovered America\" is to shape the facts concerning the events of 1492 to make them conform to an interpretation that arose many years later. For him, the Eurocentric view of the discovery of America sustains systems of domination in ways that favor Europeans. In a 1992 article for \"The UNESCO Courier\", F\u00e9lix Fern\u00e1ndez-Shaw argues that the word \"discovery\" prioritizes European explorers as the \"heroes\" of the contact between the Old and New World. He suggests that the word \"encounter\" is more appropriate, being a more universal term which includes Native Americans in the narrative.\nAmerica as a distinct land.\nHistorians have traditionally argued that Columbus remained convinced until his death that his journeys had been along the east coast of Asia as he originally intended (excluding arguments such as Anderson's). On his third voyage he briefly referred to South America as a \"hitherto unknown\" continent, while also rationalizing that it was the Earthly Paradise (Eden) located \"at the end of the Orient\". Columbus continued to claim in his later writings that he had reached Asia; in a 1502 letter to Pope Alexander VI, he asserts that Cuba is the east coast of Asia. On the other hand, in a document in the \"Book of Privileges\" (1502), Columbus refers to the New World as the \"Indias Occidentales\" ('West Indies'), which he says \"were unknown to all the world\".\nShape of the Earth.\nWashington Irving's 1828 biography of Columbus popularized the idea that Columbus had difficulty obtaining support for his plan because many Catholic theologians insisted that the Earth was flat, but this is a popular misconception which can be traced back to 17th-century Protestants campaigning against Catholicism. In fact, the spherical shape of the Earth had been known to scholars since antiquity, and was common knowledge among sailors, including Columbus. Coincidentally, the oldest surviving globe of the Earth, the Erdapfel, was made in 1492, just before Columbus's return to Europe from his first voyage. As such it contains no sign of the Americas and yet demonstrates the common belief in a spherical Earth.\nIn 1492, Columbus correctly measured Polaris's diurnal motion around true north as having a diameter of almost 7\u00b0. In 1498, while sailing west through the doldrums 8\u00b0 north in July and again in August sailing the trade winds 13\u00b0 north, Columbus reported seeing Polaris with a diurnal motion of 10\u00b0 in diameter. He accounted for the shift by concluding that Earth's figure is pear-shaped, with the 'stalk' portion (comparing this to a woman's breast) being nearest Heaven and upon which was centered the Earthly Paradise. Although Columbus's later readings were incorrect, 20th-century satellite data happens to indicate that the Earth has a slight pear shape.\nCriticism and defense.\nColumbus has been criticized both for his brutality and for initiating the depopulation of the indigenous peoples of the Caribbean, whether by imported diseases or intentional violence. According to scholars of Native American history, George Tinker and Mark Freedman, Columbus was responsible for creating a cycle of \"murder, violence, and slavery\" to maximize exploitation of the Caribbean islands' resources, and that Native deaths on the scale at which they occurred would not have been caused by new diseases alone. Further, they describe the proposition that disease and not genocide caused these deaths as \"American holocaust denial\". Historian Kris Lane disputes whether it is appropriate to use the term \"genocide\" when the atrocities were not Columbus's intent, but resulted from his decrees, family business goals, and negligence. Other scholars defend Columbus's actions or allege that the worst accusations against him are not based in fact while others claim that \"he has been blamed for events far beyond his own reach or knowledge\".\nAs a result of the protests and riots that followed the murder of George Floyd in 2020, many public monuments of Christopher Columbus have been removed.\nBrutality.\nSome historians have criticized Columbus for initiating the widespread colonization of the Americas and for abusing its native population. On St. Croix, Columbus's friend Michele da Cuneo\u2014according to his own account\u2014kept an indigenous woman he captured, whom Columbus \"gave to [him]\", then brutally raped her.\nAccording to some historians, the punishment for an indigenous person, aged 14 and older, failing to pay a hawk's bell, or \"cascabela\", worth of gold dust every six months (based on Bartolom\u00e9 de las Casas's account) was cutting off the hands of those without tokens, often leaving them to bleed to death. Other historians dispute such accounts. For example, a study of Spanish archival sources showed that the \"cascabela\" quotas were imposed by Guarionex, not Columbus, and that there is no mention, in the primary sources, of punishment by cutting off hands for failing to pay. Columbus had an economic interest in the enslavement of the Hispaniola natives and for that reason was not eager to baptize them, which attracted criticism from some churchmen. Consuelo Varela, a Spanish historian, stated that \"Columbus's government was characterized by a form of tyranny. Even those who loved him had to admit the atrocities that had taken place.\" Other historians have argued that some of the accounts of the brutality of Columbus and his brothers have been exaggerated as part of the Black Legend, a historical tendency towards anti-Spanish and anti-Catholic sentiment in historical sources dating as far back as the 16th century, which they speculate may continue to taint scholarship into the present day.\nAccording to historian Emily Berquist Soule, the immense Portuguese profits from the maritime trade in African slaves along the West African coast served as an inspiration for Columbus to create a counterpart of this apparatus in the New World using indigenous American slaves. Historian William J. Connell has argued that while Columbus \"brought the entrepreneurial form of slavery to the New World\", this \"was a phenomenon of the times\", further arguing that \"we have to be very careful about applying 20th-century understandings of morality to the morality of the 15th century.\" In a less popular defense of colonization, Spanish ambassador has argued, \"Normally we melded with the cultures in America, we stayed there, we spread our language and culture and religion.\"\nBritish historian Basil Davidson has dubbed Columbus the \"father of the slave trade\", citing the fact that the first license to ship enslaved Africans to the Caribbean was issued by the Catholic Monarchs in 1501 to the first royal governor of Hispaniola, Nicol\u00e1s de Ovando.\nDepopulation.\nAround the turn of the 21st century, estimates for the population of Hispaniola ranged between 250,000 and two million, but genetic analysis published in late 2020 suggests that smaller figures are more likely, perhaps as low as 10,000\u201350,000 for Hispaniola and Puerto Rico combined. Based on the previous figures of a few hundred thousand, some have estimated that a third or more of the natives in Haiti were dead within the first two years of Columbus's governorship. Contributors to depopulation included disease, warfare, and harsh enslavement. Indirect evidence suggests that some serious illness may have arrived with the 1,500 colonists who accompanied Columbus' second expedition in 1493. Charles C. Mann writes that \"It was as if the suffering these diseases had caused in Eurasia over the past millennia were concentrated into the span of decades.\" A third of the natives forced to work in gold and silver mines died every six months. Within three to six decades, the surviving Arawak population numbered only in the hundreds. The indigenous population of the Americas overall is thought to have been reduced by about 90% in the century after Columbus's arrival. Among indigenous peoples, Columbus is often viewed as a key agent of genocide. Samuel Eliot Morison, a Harvard University historian and author of a multivolume biography on Columbus, writes, \"The cruel policy initiated by Columbus and pursued by his successors resulted in complete genocide.\"\nAccording to Noble David Cook, \"There were too few Spaniards to have killed the millions who were reported to have died in the first century after Old and New World contact.\" He instead estimates that the death toll was caused by smallpox, which may have caused a pandemic only after the arrival of Hern\u00e1n Cort\u00e9s in 1519. According to some estimates, smallpox had an 80\u201390% fatality rate in Native American populations. The natives had no acquired immunity to these new diseases and suffered high fatalities. There is also evidence that they had poor diets and were overworked. Historian Andr\u00e9s Res\u00e9ndez of University of California, Davis, says the available evidence suggests \"slavery has emerged as major killer\" of the indigenous populations of the Caribbean between 1492 and 1550 more so than diseases such as smallpox, influenza and malaria. He says that indigenous populations did not experience a rebound like European populations did following the Black Death because unlike the latter, a large portion of the former were subjected to deadly forced labor in the mines.\nThe diseases that devastated the Native Americans came in multiple waves at different times, sometimes as much as centuries apart, which would mean that survivors of one disease may have been killed by others, preventing the population from recovering. Historian David Stannard describes the depopulation of the indigenous Americans as \"neither inadvertent nor inevitable\", saying it was the result of both disease and intentional genocide.\nNavigational expertise.\nBiographers and historians have a wide range of opinions about Columbus's expertise and experience navigating and captaining ships. One scholar lists some European works ranging from the 1890s to 1980s that support Columbus's experience and skill as among the best in Genoa, while listing some American works over a similar timeframe that portray the explorer as an untrained entrepreneur, having only minor crew or passenger experience prior to his noted journeys. According to Morison, Columbus's success in utilizing the trade winds might owe significantly to luck.\nPhysical appearance.\nContemporary descriptions of Columbus, including those by his son Fernando and Bartolom\u00e9 de las Casas, describe him as taller than average, with light skin (often sunburnt), blue or hazel eyes, high cheekbones and freckled face, an aquiline nose, and blond to reddish hair and beard (until about the age of 30, when it began to whiten). One Spanish commentator described his eyes using the word \"garzos\", now usually translated as \"light blue\", but it seems to have indicated light grey-green or hazel eyes to Columbus's contemporaries. The word \"rubios\" can mean \"blond\", \"fair\", or \"ruddy\". Although an abundance of artwork depicts Columbus, no authentic contemporary portrait is known.\nA well-known image of Columbus is by Sebastiano del Piombo, which has been reproduced in many textbooks. It agrees with descriptions of Columbus in that it shows a large man with auburn hair, but the painting dates from 1519 so cannot have been painted from life. Furthermore, the inscription identifying the subject as Columbus was probably added later, and the face shown differs from that of other images.\nSometime between 1531 and 1536, Alejo Fern\u00e1ndez painted an altarpiece, \"The Virgin of the Navigators\", that includes a depiction of Columbus. The painting was commissioned for a chapel in Seville's Casa de Contrataci\u00f3n (House of Trade) in the Alc\u00e1zar of Seville and remains there.\nAt the World's Columbian Exposition in 1893, 71 alleged portraits of Columbus were displayed; most of them did not match contemporary descriptions."}
{"id": "5636", "revid": "1269730400", "url": "https://en.wikipedia.org/wiki?curid=5636", "title": "Chemist", "text": "A chemist (from Greek \"ch\u0113m(\u00eda)\" alchemy; replacing \"chymist\" from Medieval Latin \"alchemist\") is a graduated scientist trained in the study of chemistry, or an officially enrolled student in the field. Chemists study the composition of matter and its properties. Chemists carefully describe the properties they study in terms of quantities, with detail on the level of molecules and their component atoms. Chemists carefully measure substance proportions, chemical reaction rates, and other chemical properties. In Commonwealth English, pharmacists are often called chemists.\nChemists use their knowledge to learn the composition and properties of unfamiliar substances, as well as to reproduce and synthesize large quantities of useful naturally occurring substances and create new artificial substances and useful processes. Chemists may specialize in any number of subdisciplines of chemistry. Materials scientists and metallurgists share much of the same education and skills with chemists. The work of chemists is often related to the work of chemical engineers, who are primarily concerned with the proper design, construction and evaluation of the most cost-effective large-scale chemical plants and work closely with industrial chemists on the development of new processes and methods for the commercial-scale manufacture of chemicals and related products.\nHistory of chemistry.\nThe roots of chemistry can be traced to the phenomenon of burning. Fire was a mystical force that transformed one substance into another and thus was of primary interest to mankind. It was fire that led to the discovery of iron and glasses. After gold was discovered and became a precious metal, many people were interested to find a method that could convert other substances into gold. This led to the protoscience called alchemy. The word \"chemist\" is derived from the Neo-Latin noun \"chimista\", an abbreviation of \"alchimista\" (alchemist). Alchemists discovered many chemical processes that led to the development of modern chemistry. \nChemistry as we know it today, was invented by Antoine Lavoisier with his law of conservation of mass in 1783. The discoveries of the chemical elements has a long history culminating in the creation of the periodic table by Dmitri Mendeleev. The Nobel Prize in Chemistry created in 1901 gives an excellent overview of chemical discovery since the start of the 20th century.\nAt the Washington Academy of Sciences during World War I, it was said that the side with the best chemists would win the war.\nEducation.\nFormal education.\nJobs for chemists generally require at least a bachelor's degree in chemistry, which takes four years. However, many positions, especially those in research, require a Master of Science or a Doctor of Philosophy (PhD.). Most undergraduate programs emphasize mathematics and physics as well as chemistry, partly because chemistry is also known as \"the central science\", thus chemists ought to have a well-rounded knowledge about science. At the Master's level and higher, students tend to specialize in a particular field. Fields of specialization include biochemistry, nuclear chemistry, organic chemistry, inorganic chemistry, polymer chemistry, analytical chemistry, physical chemistry, theoretical chemistry, quantum chemistry, environmental chemistry, and thermochemistry. Postdoctoral experience may be required for certain positions.\nWorkers whose work involves chemistry, but not at a complexity requiring an education with a chemistry degree, are commonly referred to as \"chemical technicians\". Such technicians commonly do such work as simpler, routine analyses for quality control or in clinical laboratories, having an associate degree. A chemical technologist has more education or experience than a chemical technician but less than a chemist, often having a bachelor's degree in a different field of science with also an associate degree in chemistry (or many credits related to chemistry) or having the same education as a chemical technician but more experience. There are also degrees specific to become a chemical technologist, which are somewhat distinct from those required when a student is interested in becoming a professional chemist. A Chemical technologist is more involved in the management and operation of the equipment and instrumentation necessary to perform chemical analyzes than a chemical technician. They are part of the team of a chemical laboratory in which the quality of the raw material, intermediate products and finished products is analyzed. They also perform functions in the areas of environmental quality control and the operational phase of a chemical plant.\nTraining.\nIn addition to all the training usually given to chemical technologists in their respective degree (or one given via an associate degree), a chemist is also trained to understand more details related to chemical phenomena so that the chemist can be capable of more planning on the steps to achieve a distinct goal via a chemistry-related endeavor. The higher the competency level achieved in the field of chemistry (as assessed via a combination of education, experience and personal achievements), the higher the responsibility given to that chemist and the more complicated the task might be. Chemistry, as a field, have so many applications that different tasks and objectives can be given to workers or scientists with these different levels of education or experience. The specific title of each job varies from position to position, depending on factors such as the kind of industry, the routine level of the task, the current needs of a particular enterprise, the size of the enterprise or hiring firm, the philosophy and management principles of the hiring firm, the visibility of the competency and individual achievements of the one seeking employment, economic factors such as recession or economic depression, among other factors, so this makes it difficult to categorize the exact roles of these chemistry-related workers as standard for that given level of education. Because of these factors affecting exact job titles with distinct responsibilities, some chemists might begin doing technician tasks while other chemists might begin doing more complicated tasks than those of a technician, such as tasks that also involve formal applied research, management, or supervision included within the responsibilities of that same job title. The level of supervision given to that chemist also varies in a similar manner, with factors similar to those that affect the tasks demanded for a particular chemist\nIt is important that those interested in a Chemistry degree understand the variety of roles available to them (on average), which vary depending on education and job experience. Those Chemists who hold a bachelor's degree are most commonly involved in positions related to either research assistance (working under the guidance of senior chemists in a research-oriented activity), or, alternatively, they may work on distinct (chemistry-related) aspects of a business, organization or enterprise including aspects that involve quality control, quality assurance, manufacturing, production, formulation, inspection, method validation, visitation for troubleshooting of chemistry-related instruments, regulatory affairs, \"on-demand\" technical services, chemical analysis for non-research purposes (e.g., as a legal request, for testing purposes, or for government or non-profit agencies); chemists may also work in environmental evaluation and assessment. Other jobs or roles may include sales and marketing of chemical products and chemistry-related instruments or technical writing. The more experience obtained, the more independence and leadership or management roles these chemists may perform in those organizations. Some chemists with relatively higher experience might change jobs or job position to become a manager of a chemistry-related enterprise, a supervisor, an entrepreneur or a chemistry consultant. Other chemists choose to combine their education and experience as a chemist with a distinct credential to provide different services (e.g., forensic chemists, chemistry-related software development, patent law specialists, environmental law firm staff, scientific news reporting staff, engineering design staff, etc.).\nIn comparison, chemists who have obtained a Master of Science (M.S.) in chemistry or in a very related discipline may find chemist roles that allow them to enjoy more independence, leadership and responsibility earlier in their careers with less years of experience than those with a bachelor's degree as highest degree. Sometimes, M.S. chemists receive more complex tasks duties in comparison with the roles and positions found by chemists with a bachelor's degree as their highest academic degree and with the same or close-to-same years of job experience. There are positions that are open only to those that at least have a degree related to chemistry at the master's level. Although good chemists without a Ph.D. degree but with relatively many years of experience may be allowed some applied research positions, the general rule is that Ph.D. chemists are preferred for research positions and are typically the preferred choice for the highest administrative positions on big enterprises involved in chemistry-related duties. Some positions, especially research oriented, will only allow those chemists who are Ph.D. holders. Jobs that involve intensive research and actively seek to lead the discovery of completely new chemical compounds under specifically assigned monetary funds and resources or jobs that seek to develop new scientific theories require a Ph.D. more often than not. Chemists with a Ph.D. as the highest academic degree are found typically on the research-and-development department of an enterprise and can also hold university positions as professors. Professors for research universities or for big universities usually have a Ph.D., and some research-oriented institutions might require post-doctoral training. Some smaller colleges (including some smaller four-year colleges or smaller non-research universities for undergraduates) as well as community colleges usually hire chemists with a M.S. as professors too (and rarely, some big universities who need part-time or temporary instructors, or temporary staff), but when the positions are scarce and the applicants are many, they might prefer Ph.D. holders instead.\nSkills.\nSkills that a chemist may need on the job include:\nEmployment.\nMost chemists begin their lives in research laboratories. Many chemists continue working at universities. Other chemists may start companies, teach at high schools or colleges, take samples outside (as environmental chemists), or work in medical examiner offices or police departments (as forensic chemists).\nSome software that chemists may find themselves using include:\nIncreasingly, chemists may also find themselves using artificial intelligence, such as for drug discovery.\nSubdisciplines.\nChemistry typically is divided into several major sub-disciplines. There are also several main cross-disciplinary and more specialized fields of chemistry. There is a great deal of overlap between different branches of chemistry, as well as with other scientific fields such as biology, medicine, physics, radiology, and several engineering disciplines.\nAll the above major areas of chemistry employ chemists. Other fields where chemical degrees are useful include astrochemistry (and cosmochemistry), atmospheric chemistry, chemical engineering, chemo-informatics, electrochemistry, environmental science, forensic science, geochemistry, green chemistry, history of chemistry, materials science, medical science, molecular biology, molecular genetics, nanotechnology, nuclear chemistry, oenology, organometallic chemistry, petrochemistry, pharmacology, photochemistry, phytochemistry, polymer chemistry, supramolecular chemistry and surface chemistry.\nProfessional societies.\nChemists may belong to professional societies specifically for professionals and researchers within the field of chemistry, such as the Royal Society of Chemistry in the United Kingdom, the American Chemical Society (ACS) in the United States, or the Institution of Chemists in India.\nEthics.\nThe \"Global Chemists' Code of Ethics\" suggests several ethical principles that all chemists should follow:\nThis code of ethics was codified in a 2016 conference held in Kuala Lumpur, Malaysia, run by the American Chemical Society. The points listed are inspired by the 2015 Hague Ethical Guidelines.\nHonors and awards.\nThe highest honor awarded to chemists is the Nobel Prize in Chemistry, awarded since 1901, by the Royal Swedish Academy of Sciences."}
{"id": "5637", "revid": "1273229945", "url": "https://en.wikipedia.org/wiki?curid=5637", "title": "Cypress Hill", "text": "Cypress Hill is an American hip hop group from South Gate, California, formed in 1988. They have sold over 20 million albums worldwide, and they have obtained multi-platinum and platinum certifications. The group has been critically acclaimed for their first five albums. They are considered to be among the main progenitors of West Coast hip hop and 1990s hip hop. All of the group members advocate for medical and recreational use of cannabis in the United States. In 2019, Cypress Hill became the first hip hop group to have a star on the Hollywood Walk of Fame.\nHistory.\nFormation (1988).\nSenen Reyes (also known as Sen Dog) and Ulpiano Sergio Reyes (also known as Mellow Man Ace) are brothers born in Pinar del R\u00edo, Cuba. In 1971, their family immigrated to the United States and initially lived in South Gate, California. In 1988, the two brothers teamed up with New York City native Lawrence Muggerud (also known as DJ Muggs, previously in a rap group named 7A3) and Louis Freese (also known as B-Real) to form a hip-hop group named DVX (Devastating Vocal Excellence). The band soon lost Mellow Man Ace to a solo career, and changed their name to Cypress Hill, after a street in South Gate.\nMainstream success with \"Cypress Hill\" and \"Black Sunday\", addition of Eric Bobo, and \"III: Temples of Boom\" (1989\u20131996).\nAfter recording a demo in 1989, Cypress Hill signed a record deal with Ruffhouse Records. Their self-titled first album was released in August 1991. The lead single was the double A-side \"The Phuncky Feel One\"/\"How I Could Just Kill a Man\" which received heavy airplay on urban and college radio, most notably peaking at No. 1 on \"Billboard\" Hot Rap Tracks chart and at No. 77 on the \"Billboard\" Hot 100. The other two singles released from the album were \"Hand on the Pump\" and \"Latin Lingo\", the latter of which combined English and Spanish lyrics, a trait that was continued throughout their career. The success of these singles led \"Cypress Hill\" to sell two million copies in the U.S. alone, and it peaked at No. 31 on the \"Billboard\" 200 and was certified double platinum by the RIAA. In 1992, Cypress Hill's first contribution to a soundtrack was the song \"Shoot 'Em Up\" for the film \"Juice\", and their songs were also featured in other major Hollywood films such as \"Lethal Weapon 3\" and \"White Men Can't Jump\". The group made their first appearance at Lollapalooza on the side stage in 1992. It was the festival's second year of touring, and featured a diverse lineup of acts such as Red Hot Chili Peppers, Ice Cube, Lush, Tool, Stone Temple Pilots, among others. The trio also supported the \"Cypress Hill\" album by touring with the Beastie Boys, who were touring behind their third album \"Check Your Head\".\n\"Black Sunday\", the group's second album, debuted at No. 1 on the \"Billboard\" 200 in 1993, recording the highest Soundscan for a rap group up until that time. \"Insane in the Brain\" became a crossover hit, peaking at No. 19 on the \"Billboard\" Hot 100, at No. 16 on the Dance Club Songs chart, and at No. 1 on the Hot Rap Tracks chart. \"Insane in the Brain\" also garnered the group their first Grammy nomination. \"Black Sunday\" went triple platinum in the U.S. and sold about 3.26\u00a0million copies. Cypress Hill headlined the Soul Assassins tour with House of Pain, Funkdoobiest and The Whooliganz as support, then performed on a college tour with Rage Against the Machine and Seven Year Bitch. Also in 1993, Cypress Hill had two tracks on the \"Judgment Night\" soundtrack, teaming up with Pearl Jam (without vocalist Eddie Vedder) on the track \"Real Thing\" and Sonic Youth on \"I Love You Mary Jane\". The soundtrack was notable for intentionally creating collaborations between the rap/hip-hop and rock/metal genres, and as a result the soundtrack peaked at No. 17 on the \"Billboard\" 200 and was certified gold by the RIAA. On October 2, 1993, Cypress Hill performed on the comedy show \"Saturday Night Live\", broadcast by NBC. Prior to their performances, studio executives, label representatives, and the group's own associates constantly asked the trio to not smoke marijuana on-stage. DJ Muggs became irritated due to the constant inquisitions, and he subsequently lit a joint during the group's second song. Up until that point, it was extremely uncommon to see marijuana usage on a live televised broadcast. The incident prompted NBC to ban the group from returning on the show, a distinction shared only by six other artists.\nThe group later played at Woodstock 94, officially making percussionist Eric Bobo a member of the group during the performance. Eric Bobo was known as the son of Willie Bobo and as a touring member of the Beastie Boys, who Cypress Hill previously toured with in 1992. That same year, \"Rolling Stone\" named the group as the Best Rap Group in their music awards voted by critics and readers. Cypress Hill then played at Lollapalooza for two successive years, topping the bill in 1995. They also appeared on the \"Homerpalooza\" episode of \"The Simpsons\". The group received their second Grammy nomination in 1995 for \"I Ain't Goin' Out Like That\".\nCypress Hill's third album \"\" was released in 1995, peaking at No. 3 on the \"Billboard\" 200 and at No. 3 on the Canadian Albums Chart. The album was certified platinum by the RIAA. \"Throw Your Set in the Air\" was the most successful single off the album, peaking at No. 45 on the \"Billboard\" Hot 100 and No. 11 on the Hot Rap Tracks chart. The single also earned Cypress Hill's third Grammy nomination. Shortly after the release of \"III: Temples of Boom\", Sen Dog became frustrated due to the rigorous touring schedule. Just prior to an overseas tour, he departed from the group unexpectedly. Cypress Hill continued their tours throughout 1995 and 1996, with Eric Bobo and also various guest vocalists covering Sen Dog's verses. Sen Dog later formed the rock band SX-10 to explore other musical genres. Later on in 1996, Cypress Hill appeared on the first Smokin' Grooves tour, featuring Ziggy Marley, the Fugees, Busta Rhymes, and A Tribe Called Quest. The group also released a nine track EP, \"Unreleased and Revamped\" with rare mixes.\nFocus on solo projects, \"IV\", crossover appeal with \"Skull &amp; Bones\", and \"Stoned Raiders\" (1997\u20132002).\nIn 1997, the members focused on their solo careers. DJ Muggs released \"Soul Assassins: Chapter 1\", with features from Dr. Dre, KRS-One, Wyclef Jean, and Mobb Deep. B-Real appeared with Busta Rhymes, Coolio, LL Cool J, and Method Man on \"Hit 'Em High\" from the multi-platinum \"Space Jam Soundtrack\". He also appeared with RBX, Nas, and KRS-One on \"East Coast Killer, West Coast Killer\" from Dr. Dre's \"Dr. Dre Presents the Aftermath\" album, and contributed to an album entitled \"The Psycho Realm\" with the group of the same name. Sen Dog also released the \"Get Wood\" sampler as part of SX-10 on the label Flip Records. In addition, Eric Bobo contributed drums to various rock bands on their albums, such as 311 and Soulfly.\nIn early 1998, Sen Dog returned to Cypress Hill. He cited his therapist and also his creative collaborations with the band SX-10 as catalysts for his rejoining. The quartet then embarked on the third annual Smokin' Grooves tour with Public Enemy, Wyclef Jean, Busta Rhymes, and Gang Starr. Cypress Hill released \"IV\" in October 1998 which went gold in the U.S. and peaked at No. 11 on the Billboard 200. The lead single off the album was \"Dr. Greenthumb\", as it peaked at No. 11 on the Hot Rap Tracks chart. It also peaked at No. 70 on the Billboard Hot 100, their last appearance on the chart to date. In 1999, Cypress Hill helped with the PC first-person shooter video game \"\". Three of the band's songs from the 1998 \"IV\" album were in the game; \"16 Men Till There's No Men Left\", \"Checkmate\", and \"Lightning Strikes\". The group also did voice work for some of the game's characters. Also in 1999, the band released a greatest hits album in Spanish, \"Los Grandes \u00c9xitos en Espa\u00f1ol\".\nIn 2000, Cypress Hill fused genres with their fifth album, \"Skull &amp; Bones\", which consisted of two discs. The first disc \"Skull\" was composed of rap tracks while \"Bones\" explored further the group's forays into rock. The album peaked at No. 5 on the Billboard 200 and at No. 3 on the Canadian Albums Chart, and the album was eventually certified platinum by the RIAA. The first two singles were \"(Rock) Superstar\" for rock radio and \"(Rap) Superstar\" for urban radio. Both singles received heavy airplay on both rock and urban radio, enabling Cypress Hill to crossover again. \"(Rock) Superstar\" peaked at No. 18 on the Modern Rock Tracks chart and \"(Rap) Superstar\" peaked at No. 43 on the Hot Rap Tracks chart.\nDue to the rock genre's prominent appearance on \"Skull &amp; Bones\", Cypress Hill employed the members of Sen Dog's band SX-10 as backing musicians for the live shows. Cypress Hill supported \"Skull &amp; Bones\" by initially playing a summer tour with Limp Bizkit and Cold called the Back 2 Basics Tour. The tour was controversial as it was sponsored by the file sharing service Napster. In addition, Napster enabled each show of the tour to be free to the fans, and no security guards were employed during the performances. After the tour's conclusion, the acts had not reported any disturbances. Towards the end of 2000, Cypress Hill and MxPx landed a slot opening for The Offspring on the Conspiracy of One Tour. The group also released \"Live at the Fillmore\", a concert disc recorded at San Francisco's The Fillmore in 2000. Cypress Hill continued their experimentation with rock on the \"Stoned Raiders\" album in 2001; however, its sales were a disappointment. The album peaked at No. 64 on the Billboard 200, the group's lowest position to that point. Also in 2001, the group made a cameo appearance as themselves in the film \"How High\". Cypress Hill then recorded the track \"Just Another Victim\" for WWF as a theme song for Tazz, borrowing elements from the 2000 single \"(Rock) Superstar\". The song would later be featured on the compilation \"WWF Forceable Entry\" in March 2002, which peaked at No. 3 on the Billboard 200 and was certified gold by the RIAA.\n\"Till Death Do Us Part\", DJ Muggs' hiatus, and extensive collaborations on \"Rise Up\" (2003\u20132012).\nCypress Hill released \"Till Death Do Us Part\" in March 2004 as it peaked at No. 21 on the Billboard 200. It featured appearances by Bob Marley's son Damian Marley, Prodigy of Mobb Deep, and producers The Alchemist and Fredwreck. The album represented a further departure from the group's signature sound. Reggae was a strong influence on its sound, especially on the lead single \"What's Your Number?\". The track featured Tim Armstrong of Rancid on guitar and backup vocals. It was based on the classic song \"The Guns of Brixton\" from The Clash's album \"London Calling\". \"What's Your Number?\" saw Cypress Hill crossover into the rock charts again, as the single peaked at No. 23 on the Modern Rock Tracks chart.\nAfterwards, DJ Muggs took a hiatus from the group to focus on other projects, such as Soul Assassins and his \"DJ Muggs vs.\" collaboration albums. In December 2005 another compilation album titled \"Greatest Hits From the Bong\" was released. It included nine hits from previous albums and two new tracks. In the summer of 2006, B-Real appeared on Snoop Dogg's single \"Vato\", which was produced by Pharrell Williams. The group's next album was tentatively scheduled for an early 2007 release, but it was pushed back numerous times. In 2007 Cypress Hill toured as a part of the Rock the Bells tour. They headlined with Public Enemy, Wu-Tang Clan, Nas, and a reunited Rage Against the Machine.\nOn July 25, 2008, Cypress Hill performed at a benefit concert at the House of Blues Chicago, where a majority of the proceeds went to the Chicago Alliance to End Homelessness. In August 2009, a new song by Cypress Hill titled \"Get 'Em Up\" was made available on iTunes. The song was also featured in the \"Madden NFL 2010\" video game. It was the first sampling of the group's then-upcoming album.\nCypress Hill's eighth studio album \"Rise Up\" featured contributions from Everlast, Tom Morello, Daron Malakian, Pitbull, Marc Anthony, and Mike Shinoda. Previously, the vast majority of the group's albums were produced by DJ Muggs; however, \"Rise Up\" instead featured a large array of guest features and producers, with DJ Muggs only appearing on two tracks. The album was released on Priority Records/EMI Entertainment, as the group was signed to the label by new creative chairman Snoop Dogg. \"Rise Up\" was released on April 20, 2010, and it peaked at No. 19 on the Billboard 200. The single \"Rise Up\" was featured at WWE's pay-per-view \"Elimination Chamber\" as the official theme song for the event. It also appeared in the trailer for the movie \"The Green Hornet\". \"Rise Up\" managed to peak at No. 20 on both the Modern Rock Tracks and Mainstream Rock Tracks charts. \"Armada Latina\", which featured Pitbull and Marc Anthony, was Cypress Hill's last song to chart in the U.S. to date, peaking at No. 25 on the Hot Rap Tracks chart.\nCypress Hill commenced its Rise Up tour in Philadelphia on April 10, 2010. In one particular instance, the group was supposed to stop in Tucson, Arizona but canceled the show in protest of the recent immigration legislation. At the Rock en Seine festival in Paris on August 27, 2010, they had said in an interview that they would anticipate the outcome of the legislation before returning. Also in 2010, Cypress Hill performed at the Reading and Leeds Festivals on August 28 at Leeds and August 29 at Reading. On June 5, 2012, Cypress Hill and dubstep artist Rusko released a collaborative EP entitled \"Cypress X Rusko\". DJ Muggs, who was still on a hiatus, and Eric Bobo were absent on the release. Also in 2012, Cypress Hill collaborated with Deadmau5 on his sixth studio album \"Album Title Goes Here\", lending vocals on \"Failbait\".\n\"Elephants on Acid\", Hollywood Walk of Fame, and \"Back in Black\" (2013\u20132022).\nDuring the interval between Cypress Hill albums, the four members commenced work on various projects. B-Real formed the band Prophets of Rage alongside three members of Rage Against the Machine and two members of Public Enemy. He also released \"The Prescription\" EP under his Dr. Greenthumb persona. Sen Dog formed the band Powerflo alongside members of Fear Factory, downset., and Biohazard. DJ Muggs revived his Soul Assassins project as its main producer. Eric Bobo formed a duo named Ritmo Machine. He also contributed to an unreleased album by his father Willie Bobo.\nOn September 28, 2018, Cypress Hill released the album \"Elephants on Acid\", which saw the return of DJ Muggs as main composer and producer. It peaked at No. 120 on the Billboard 200 and at No. 6 on the Top Independent Albums chart. Overall, four different singles were released to promote the album. In April 2019 Cypress Hill received a star on the Hollywood Walk of Fame. Although various solo hip hop artists had received stars, Cypress Hill became the first collective hip hop group to receive a star. The entire lineup of B-Real, Sen Dog, Eric Bobo, and DJ Muggs had all attended the ceremony.\nIn January 2022, the group announced their 10th studio album entitled \"Back in Black\". In addition, Cypress Hill planned to support the album by joining Slipknot alongside Ho99o9 for the second half of the 2022 Knotfest Roadshow. They had previously invited Slipknot to join their Great Smoke-Out festival back in 2009. \"Back in Black\" was released on March 18, 2022. It was the group's first album to not feature DJ Muggs on any of the tracks, as producing duties were handled by Black Milk. \"Back in Black\" was the lowest charting album of the group's career, and the first to not reach the Billboard 200 chart; however, it peaked at No. 69 on the Top Current Album Sales chart.\nA documentary about the group, entitled \"Cypress Hill: Insane in the Brain\", was released on the Showtime service in April 2022. Estevan Oriol, Cypress Hill's former tour manager and close associate, directed the film. It had mainly chronicled the group's formation and their first decade of existence. In relation to the \"Cypress Hill: Insane in the Brain\" documentary, Cypress Hill digitally released the single \"Crossroads\" in September 2022. The single featured the return of DJ Muggs on production.\nFuture plans and tentative final album (2023\u2013present).\nIn an interview, Sen Dog claimed that the group will fully reunite with DJ Muggs for an 11th album; however, he stated that it will be the group's final album of their career.\nThe group performed at various festivals in 2023 such as the Festival d'\u00e9t\u00e9 de Qu\u00e9bec and in celebrating the 30th anniversary of their second studio album \"Black Sunday\", they also announced several standalone concerts in North America and Europe. They also performed alongside The Pharcyde and Souls of Mischief in May 2024. In March 2024, they announced three dates in Italy, Austria, and Germany for July.\nIn a callback to Cypress Hill's appearance in the \"Homerpalooza\" Simpsons episode in 1996 (which contained a skit of the group realizing they must have ordered the London Symphony Orchestra while high to perform with), it was announced that the group would actually perform with the London Symphony Orchestra at London's Royal Albert Hall in July 2024. The band was joined by long-time collaborator Christian Olde Wolbers on double bass.\nStyle.\nRapping.\nOne of the band's most striking aspects is B-Real's exaggeratedly high-pitched nasal vocals. In the book \"Check the Technique\", B-Real described his nasal style, saying his rapping voice is \"high and annoying...the nasal style I have was just something that I developed...my more natural style wasn't so pleasing to DJ Muggs and Sen Dog's ears\" and talking about the nasal style in the book \"How to Rap\", B-Real said \"you want to stand out from the others and just be distinct...when you got something that can separate you from everybody else, you gotta use it to your advantage.\" In the film \"Art of Rap\", B-Real credited the Beastie Boys as an influence when developing his rapping style. Sen Dog's voice is deeper, more violent, and often shouted alongside the rapping; his vocals are often emphasized by adding another background/choir voice to say them. Sen Dog's style is in contrast to B-Real's, who said \"Sen's voice is so strong\" and \"it all blends together\" when they are both on the same track.\nBoth B-Real and Sen Dog started writing lyrics in both Spanish and English. Initially, B-Real was inspired to start writing raps from watching Sen Dog and Mellow Man Ace writing their lyrics, and originally B-Real was going to just be the writer for the group rather than a rapper. Their lyrics are noted for bringing a \"cartoonish\" approach to violence by Peter Shapiro and Allmusic.\nProduction.\nThe sound and groove of their music, mostly produced by DJ Muggs, has spooky sounds and a stoned aesthetic; with its bass-heavy rhythms and odd sample loops (\"Insane in the Brain\" has a blues guitar pitched looped in its chorus), it carries a psychedelic value, which is lessened in their rock-oriented albums. The double album \"Skull &amp; Bones\" consists of a pure rap disc (\"Skull\") and a separate rock disc (\"Bones\"). In the live album \"Live at The Fillmore\", some of the old classics were played in a rock/metal version, with Eric Bobo playing the drums and Sen Dog's band SX-10 as the other instrumentalists. 2010's \"Rise Up\" was the most radically different album in regards to production. DJ Muggs had produced the majority of each prior Cypress Hill album, but he only appeared on \"Rise Up\" twice. The remaining songs were handled by various other guests. 2018's \"Elephants on Acid\" marked the return of DJ Muggs, and the album featured a more psychedelic and hip-hop approach.\nLegacy.\nCypress Hill are often credited for being one of the few Latin American hip hop groups to break through with their own stylistic impact on rap music, in addition to finding a crossover audience among the rock community. Cypress Hill have been cited as an influence by artists such as Eminem, Baby Bash, Paul Wall, Post Malone, Luniz, and Fat Joe. Cypress Hill have also been cited as a strong influence on nu metal bands such as Deftones, Limp Bizkit, System of a Down, Linkin Park, Rage Against the Machine and Korn. Famously, the bassline during the outro of Korn's 1994 single \"Blind\" was a direct tribute to Cypress Hill's 1993 track \"Lick a Shot\".\nMembers.\nCurrent\nCurrent touring\nFormer\nFormer touring\nAwards and nominations.\nBillboard Music Awards\nGrammy Awards\nMTV Video Music Awards\nHollywood Walk of Fame"}
{"id": "5638", "revid": "36986459", "url": "https://en.wikipedia.org/wiki?curid=5638", "title": "Combustion", "text": "Combustion, or burning, is a high-temperature exothermic redox chemical reaction between a fuel (the reductant) and an oxidant, usually atmospheric oxygen, that produces oxidized, often gaseous products, in a mixture termed as smoke. Combustion does not always result in fire, because a flame is only visible when substances undergoing combustion vaporize, but when it does, a flame is a characteristic indicator of the reaction. While activation energy must be supplied to initiate combustion (e.g., using a lit match to light a fire), the heat from a flame may provide enough energy to make the reaction self-sustaining. The study of combustion is known as combustion science.\nCombustion is often a complicated sequence of elementary radical reactions. Solid fuels, such as wood and coal, first undergo endothermic pyrolysis to produce gaseous fuels whose combustion then supplies the heat required to produce more of them. Combustion is often hot enough that incandescent light in the form of either glowing or a flame is produced. A simple example can be seen in the combustion of hydrogen and oxygen into water vapor, a reaction which is commonly used to fuel rocket engines. This reaction releases 242kJ/mol of heat and reduces the enthalpy accordingly (at constant temperature and pressure):\nUncatalyzed combustion in air requires relatively high temperatures. Complete combustion is stoichiometric concerning the fuel, where there is no remaining fuel, and ideally, no residual oxidant. Thermodynamically, the chemical equilibrium of combustion in air is overwhelmingly on the side of the products. However, complete combustion is almost impossible to achieve, since the chemical equilibrium is not necessarily reached, or may contain unburnt products such as carbon monoxide, hydrogen and even carbon (soot or ash). Thus, the produced smoke is usually toxic and contains unburned or partially oxidized products. Any combustion at high temperatures in atmospheric air, which is 78 percent nitrogen, will also create small amounts of several nitrogen oxides, commonly referred to as NOx, since the combustion of nitrogen is thermodynamically favored at high, but not low temperatures. Since burning is rarely clean, fuel gas cleaning or catalytic converters may be required by law.\nFires occur naturally, ignited by lightning strikes or by volcanic products. Combustion (fire) was the first controlled chemical reaction discovered by humans, in the form of campfires and bonfires, and continues to be the main method to produce energy for humanity. Usually, the fuel is carbon, hydrocarbons, or more complicated mixtures such as wood that contain partially oxidized hydrocarbons. The thermal energy produced from the combustion of either fossil fuels such as coal or oil, or from renewable fuels such as firewood, is harvested for diverse uses such as cooking, production of electricity or industrial or domestic heating. Combustion is also currently the only reaction used to power rockets. Combustion is also used to destroy (incinerate) waste, both nonhazardous and hazardous.\nOxidants for combustion have high oxidation potential and include atmospheric or pure oxygen, chlorine, fluorine, chlorine trifluoride, nitrous oxide and nitric acid. For instance, hydrogen burns in chlorine to form hydrogen chloride with the liberation of heat and light characteristic of combustion. Although usually not catalyzed, combustion can be catalyzed by platinum or vanadium, as in the contact process.\nTypes.\nComplete and incomplete.\nComplete.\nIn complete combustion, the reactant burns in oxygen and produces a limited number of products. When a hydrocarbon burns in oxygen, the reaction will primarily yield carbon dioxide and water. When elements are burned, the products are primarily the most common oxides. Carbon will yield carbon dioxide, sulfur will yield sulfur dioxide, and iron will yield iron(III) oxide. Nitrogen is not considered to be a combustible substance when oxygen is the oxidant. Still, small amounts of various nitrogen oxides (commonly designated species) form when the air is the oxidative.\nCombustion is not necessarily favorable to the maximum degree of oxidation, and it can be temperature-dependent. For example, sulfur trioxide is not produced quantitatively by the combustion of sulfur. species appear in significant amounts above about , and more is produced at higher temperatures. The amount of is also a function of oxygen excess.\nIn most industrial applications and in fires, air is the source of oxygen (). In the air, each mole of oxygen is mixed with approximately of nitrogen. Nitrogen does not take part in combustion, but at high temperatures, some nitrogen will be converted to (mostly , with much smaller amounts of ). On the other hand, when there is insufficient oxygen to combust the fuel completely, some fuel carbon is converted to carbon monoxide, and some of the hydrogens remain unreacted. A complete set of equations for the combustion of a hydrocarbon in the air, therefore, requires an additional calculation for the distribution of oxygen between the carbon and hydrogen in the fuel.\nThe amount of air required for complete combustion is known as the \"theoretical air\" or \"stoichiometric air\". The amount of air above this value actually needed for optimal combustion is known as the \"excess air\", and can vary from 5% for a natural gas boiler, to 40% for anthracite coal, to 300% for a gas turbine.\nIncomplete.\nIncomplete combustion will occur when there is not enough oxygen to allow the fuel to react completely to produce carbon dioxide and water. It also happens when the combustion is quenched by a heat sink, such as a solid surface or flame trap. As is the case with complete combustion, water is produced by incomplete combustion; however, carbon and carbon monoxide are produced instead of carbon dioxide.\nFor most fuels, such as diesel oil, coal, or wood, pyrolysis occurs before combustion. In incomplete combustion, products of pyrolysis remain unburnt and contaminate the smoke with noxious particulate matter and gases. Partially oxidized compounds are also a concern; partial oxidation of ethanol can produce harmful acetaldehyde, and carbon can produce toxic carbon monoxide.\nThe designs of combustion devices can improve the quality of combustion, such as burners and internal combustion engines. Further improvements are achievable by catalytic after-burning devices (such as catalytic converters) or by the simple partial return of the exhaust gases into the combustion process. Such devices are required by environmental legislation for cars in most countries. They may be necessary to enable large combustion devices, such as thermal power stations, to reach legal emission standards.\nThe degree of combustion can be measured and analyzed with test equipment. HVAC contractors, firefighters and engineers use combustion analyzers to test the efficiency of a burner during the combustion process. Also, the efficiency of an internal combustion engine can be measured in this way, and some U.S. states and local municipalities use combustion analysis to define and rate the efficiency of vehicles on the road today.\nCarbon monoxide is one of the products from incomplete combustion. The formation of carbon monoxide produces less heat than formation of carbon dioxide so complete combustion is greatly preferred especially as carbon monoxide is a poisonous gas. When breathed, carbon monoxide takes the place of oxygen and combines with some of the hemoglobin in the blood, rendering it unable to transport oxygen.\nProblems associated with incomplete combustion.\nEnvironmental problems.\nThese oxides combine with water and oxygen in the atmosphere, creating nitric acid and sulfuric acids, which return to Earth's surface as acid deposition, or \"acid rain.\" Acid deposition harms aquatic organisms and kills trees. Due to its formation of certain nutrients that are less available to plants such as calcium and phosphorus, it reduces the productivity of the ecosystem and farms. An additional problem associated with nitrogen oxides is that they, along with hydrocarbon pollutants, contribute to the formation of ground level ozone, a major component of smog.\nHuman health problems.\nBreathing carbon monoxide causes headache, dizziness, vomiting, and nausea. If carbon monoxide levels are high enough, humans become unconscious or die. Exposure to moderate and high levels of carbon monoxide over long periods is positively correlated with the risk of heart disease. People who survive severe carbon monoxide poisoning may suffer long-term health problems. Carbon monoxide from the air is absorbed in the lungs which then binds with hemoglobin in human's red blood cells. This reduces the capacity of red blood cells that carry oxygen throughout the body.\nSmoldering.\nSmoldering is the slow, low-temperature, flameless form of combustion, sustained by the heat evolved when oxygen directly attacks the surface of a condensed-phase fuel. It is a typically incomplete combustion reaction. Solid materials that can sustain a smoldering reaction include coal, cellulose, wood, cotton, tobacco, peat, duff, humus, synthetic foams, charring polymers (including polyurethane foam) and dust. Common examples of smoldering phenomena are the initiation of residential fires on upholstered furniture by weak heat sources (e.g., a cigarette, a short-circuited wire) and the persistent combustion of biomass behind the flaming fronts of wildfires.\nSpontaneous.\nSpontaneous combustion is a type of combustion that occurs by self-heating (increase in temperature due to exothermic internal reactions), followed by thermal runaway (self-heating which rapidly accelerates to high temperatures) and finally, ignition.\nFor example, phosphorus self-ignites at room temperature without the application of heat. Organic materials undergoing bacterial composting can generate enough heat to reach the point of combustion.\nTurbulent.\nCombustion resulting in a turbulent flame is the most used for industrial applications (e.g. gas turbines, gasoline engines, etc.) because the turbulence helps the mixing process between the fuel and oxidizer.\nMicro-gravity.\nThe term 'micro' gravity refers to a gravitational state that is 'low' (i.e., 'micro' in the sense of 'small' and not necessarily a millionth of Earth's normal gravity) such that the influence of buoyancy on physical processes may be considered small relative to other flow processes that would be present at normal gravity. In such an environment, the thermal and flow transport dynamics can behave quite differently than in normal gravity conditions (e.g., a candle's flame takes the shape of a sphere.). Microgravity combustion research contributes to the understanding of a wide variety of aspects that are relevant to both the environment of a spacecraft (e.g., fire dynamics relevant to crew safety on the International Space Station) and terrestrial (Earth-based) conditions (e.g., droplet combustion dynamics to assist developing new fuel blends for improved combustion, materials fabrication processes, thermal management of electronic systems, multiphase flow boiling dynamics, and many others).\nMicro-combustion.\nCombustion processes that happen in very small volumes are considered micro-combustion. The high surface-to-volume ratio increases specific heat loss. Quenching distance plays a vital role in stabilizing the flame in such combustion chambers.\nChemical equations.\nStoichiometric combustion of a hydrocarbon in oxygen.\nGenerally, the chemical equation for stoichiometric combustion of a hydrocarbon in oxygen is:\nFor example, the stoichiometric combustion of methane in oxygen is:\nStoichiometric combustion of a hydrocarbon in air.\nIf the stoichiometric combustion takes place using air as the oxygen source, the nitrogen present in the air (Atmosphere of Earth) can be added to the equation (although it does not react) to show the stoichiometric composition of the fuel in air and the composition of the resultant flue gas. Treating all non-oxygen components in air as nitrogen gives a 'nitrogen' to oxygen ratio of 3.77, i.e. (100% \u2212 %) / % where % is 20.95% vol:\nwhere formula_3.\nFor example, the stoichiometric combustion of methane in air is:\nThe stoichiometric composition of methane in air is 1 / (1 + 2 + 7.54) = 9.49% vol.\nThe stoichiometric combustion reaction for CHO in air:\nThe stoichiometric combustion reaction for CHOS:\nThe stoichiometric combustion reaction for CHONS:\nThe stoichiometric combustion reaction for CHOF:\nTrace combustion products.\nVarious other substances begin to appear in significant amounts in combustion products when the flame temperature is above about . When excess air is used, nitrogen may oxidize to and, to a much lesser extent, to . forms by disproportionation of , and and form by disproportionation of .\nFor example, when of propane is burned with of air (120% of the stoichiometric amount), the combustion products contain 3.3% . At , the equilibrium combustion products contain 0.03% and 0.002% . At , the combustion products contain 0.17% , 0.05% , 0.01% , and 0.004% .\nDiesel engines are run with an excess of oxygen to combust small particles that tend to form with only a stoichiometric amount of oxygen, necessarily producing nitrogen oxide emissions. Both the United States and European Union enforce limits to vehicle nitrogen oxide emissions, which necessitate the use of special catalytic converters or treatment of the exhaust with urea (see Diesel exhaust fluid).\nIncomplete combustion of a hydrocarbon in oxygen.\nThe incomplete (partial) combustion of a hydrocarbon with oxygen produces a gas mixture containing mainly , , , and . Such gas mixtures are commonly prepared for use as protective atmospheres for the heat-treatment of metals and for gas carburizing. The general reaction equation for incomplete combustion of one mole of a hydrocarbon in oxygen is:\nWhen \"z\" falls below roughly 50% of the stoichiometric value, can become an important combustion product; when \"z\" falls below roughly 35% of the stoichiometric value, elemental carbon may become stable.\nThe products of incomplete combustion can be calculated with the aid of a material balance, together with the assumption that the combustion products reach equilibrium. For example, in the combustion of one mole of propane () with four moles of , seven moles of combustion gas are formed, and \"z\" is 80% of the stoichiometric value. The three elemental balance equations are:\nThese three equations are insufficient in themselves to calculate the combustion gas composition.\nHowever, at the equilibrium position, the water-gas shift reaction gives another equation:\nFor example, at the value of \"K\" is 0.728. Solving, the combustion gas consists of 42.4% , 29.0% , 14.7% , and 13.9% . Carbon becomes a stable phase at and pressure when z is less than 30% of the stoichiometric value, at which point the combustion products contain more than 98% and and about 0.5% .\nSubstances or materials which undergo combustion are called fuels. The most common examples are natural gas, propane, kerosene, diesel, petrol, charcoal, coal, wood, etc.\nLiquid fuels.\nCombustion of a liquid fuel in an oxidizing atmosphere actually happens in the gas phase. It is the vapor that burns, not the liquid. Therefore, a liquid will normally catch fire only above a certain temperature: its flash point. The flash point of liquid fuel is the lowest temperature at which it can form an ignitable mix with air. It is the minimum temperature at which there is enough evaporated fuel in the air to start combustion.\nGaseous fuels.\nCombustion of gaseous fuels may occur through one of four distinctive types of burning: diffusion flame, premixed flame, autoignitive reaction front, or as a detonation. The type of burning that actually occurs depends on the degree to which the fuel and oxidizer are mixed prior to heating: for example, a diffusion flame is formed if the fuel and oxidizer are separated initially, whereas a premixed flame is formed otherwise. Similarly, the type of burning also depends on the pressure: a detonation, for example, is an autoignitive reaction front coupled to a strong shock wave giving it its characteristic high-pressure peak and high detonation velocity.\nSolid fuels.\nThe act of combustion consists of three relatively distinct but overlapping phases:\nCombustion management.\nEfficient process heating requires recovery of the largest possible part of a fuel's heat of combustion into the material being processed. There are many avenues of loss in the operation of a heating process. Typically, the dominant loss is sensible heat leaving with the offgas (i.e., the flue gas). The temperature and quantity of offgas indicates its heat content (enthalpy), so keeping its quantity low minimizes heat loss.\nIn a perfect furnace, the combustion air flow would be matched to the fuel flow to give each fuel molecule the exact amount of oxygen needed to cause complete combustion. However, in the real world, combustion does not proceed in a perfect manner. Unburned fuel (usually and ) discharged from the system represents a heating value loss (as well as a safety hazard). Since combustibles are undesirable in the offgas, while the presence of unreacted oxygen there presents minimal safety and environmental concerns, the first principle of combustion management is to provide more oxygen than is theoretically needed to ensure that all the fuel burns. For methane () combustion, for example, slightly more than two molecules of oxygen are required.\nThe second principle of combustion management, however, is to not use too much oxygen. The correct amount of oxygen requires three types of measurement: first, active control of air and fuel flow; second, offgas oxygen measurement; and third, measurement of offgas combustibles. For each heating process, there exists an optimum condition of minimal offgas heat loss with acceptable levels of combustibles concentration. Minimizing excess oxygen pays an additional benefit: for a given offgas temperature, the NOx level is lowest when excess oxygen is kept lowest.\nAdherence to these two principles is furthered by making material and heat balances on the combustion process. The material balance directly relates the air/fuel ratio to the percentage of in the combustion gas. The heat balance relates the heat available for the charge to the overall net heat produced by fuel combustion. Additional material and heat balances can be made to quantify the thermal advantage from preheating the combustion air, or enriching it in oxygen.\nReaction mechanism.\nCombustion in oxygen is a chain reaction in which many distinct radical intermediates participate. The high energy required for initiation is explained by the unusual structure of the dioxygen molecule. The lowest-energy configuration of the dioxygen molecule is a stable, relatively unreactive diradical in a triplet spin state. Bonding can be described with three bonding electron pairs and two antibonding electrons, with spins aligned, such that the molecule has nonzero total angular momentum. Most fuels, on the other hand, are in a singlet state, with paired spins and zero total angular momentum. Interaction between the two is quantum mechanically a \"forbidden transition\", i.e. possible with a very low probability. To initiate combustion, energy is required to force dioxygen into a spin-paired state, or singlet oxygen. This intermediate is extremely reactive. The energy is supplied as heat, and the reaction then produces additional heat, which allows it to continue.\nCombustion of hydrocarbons is thought to be initiated by hydrogen atom abstraction (not proton abstraction) from the fuel to oxygen, to give a hydroperoxide radical (HOO). This reacts further to give hydroperoxides, which break up to give hydroxyl radicals. There are a great variety of these processes that produce fuel radicals and oxidizing radicals. Oxidizing species include singlet oxygen, hydroxyl, monatomic oxygen, and hydroperoxyl. Such intermediates are short-lived and cannot be isolated. However, non-radical intermediates are stable and are produced in incomplete combustion. An example is acetaldehyde produced in the combustion of ethanol. An intermediate in the combustion of carbon and hydrocarbons, carbon monoxide, is of special importance because it is a poisonous gas, but also economically useful for the production of syngas.\nSolid and heavy liquid fuels also undergo a great number of pyrolysis reactions that give more easily oxidized, gaseous fuels. These reactions are endothermic and require constant energy input from the ongoing combustion reactions. A lack of oxygen or other improperly designed conditions result in these noxious and carcinogenic pyrolysis products being emitted as thick, black smoke.\nThe rate of combustion is the amount of a material that undergoes combustion over a period of time. It can be expressed in grams per second (g/s) or kilograms per second (kg/s).\nDetailed descriptions of combustion processes, from the chemical kinetics perspective, require the formulation of large and intricate webs of elementary reactions. For instance, combustion of hydrocarbon fuels typically involve hundreds of chemical species reacting according to thousands of reactions.\nThe inclusion of such mechanisms within computational flow solvers still represents a pretty challenging task mainly in two aspects. First, the number of degrees of freedom (proportional to the number of chemical species) can be dramatically large; second, the source term due to reactions introduces a disparate number of time scales which makes the whole dynamical system stiff. As a result, the direct numerical simulation of turbulent reactive flows with heavy fuels soon becomes intractable even for modern supercomputers.\nTherefore, a plethora of methodologies have been devised for reducing the complexity of combustion mechanisms without resorting to high detail levels. Examples are provided by:\nKinetic modelling.\nThe kinetic modelling may be explored for insight into the reaction mechanisms of thermal decomposition in the combustion of different materials by using for instance Thermogravimetric analysis.\nTemperature.\nAssuming perfect combustion conditions, such as complete combustion under adiabatic conditions (i.e., no heat loss or gain), the adiabatic combustion temperature can be determined. The formula that yields this temperature is based on the first law of thermodynamics and takes note of the fact that the heat of combustion is used entirely for heating the fuel, the combustion air or oxygen, and the combustion product gases (commonly referred to as the \"flue gas\").\nIn the case of fossil fuels burnt in air, the combustion temperature depends on all of the following:\nThe adiabatic combustion temperature (also known as the \"adiabatic flame temperature\") increases for higher heating values and inlet air and fuel temperatures and for stoichiometric air ratios approaching one.\nMost commonly, the adiabatic combustion temperatures for coals are around (for inlet air and fuel at ambient temperatures and for formula_14), around for oil and for natural gas.\nIn industrial fired heaters, power station steam generators, and large gas-fired turbines, the more common way of expressing the usage of more than the stoichiometric combustion air is \"percent excess combustion air\". For example, excess combustion air of 15 percent means that 15 percent more than the required stoichiometric air is being used.\nInstabilities.\nCombustion instabilities are typically violent pressure oscillations in a combustion chamber. These pressure oscillations can be as high as 180dB, and long-term exposure to these cyclic pressure and thermal loads reduces the life of engine components. In rockets, such as the F1 used in the Saturn V program, instabilities led to massive damage to the combustion chamber and surrounding components. This problem was solved by re-designing the fuel injector. In liquid jet engines, the droplet size and distribution can be used to attenuate the instabilities. Combustion instabilities are a major concern in ground-based gas turbine engines because of emissions. The tendency is to run lean, an equivalence ratio less than 1, to reduce the combustion temperature and thus reduce the emissions; however, running the combustion lean makes it very susceptible to combustion instability.\nThe Rayleigh Criterion is the basis for analysis of thermoacoustic combustion instability and is evaluated using the Rayleigh Index over one cycle of instability\nformula_15\nwhere q' is the heat release rate perturbation and p' is the pressure fluctuation.\nWhen the heat release oscillations are in phase with the pressure oscillations, the Rayleigh Index is positive and the magnitude of the thermoacoustic instability is maximised. On the other hand, if the Rayleigh Index is negative, then thermoacoustic damping occurs. The Rayleigh Criterion implies that thermoacoustic instability can be optimally controlled by having heat release oscillations 180 degrees out of phase with pressure oscillations at the same frequency. This minimizes the Rayleigh Index.\nSee also.\nRelated concepts\nMachines and equipment\nScientific and engineering societies\nOther"}
{"id": "5639", "revid": "1271595342", "url": "https://en.wikipedia.org/wiki?curid=5639", "title": "Cyrillic script", "text": "The Cyrillic script ( ), Slavonic script or simply Slavic script is a writing system used for various languages across Eurasia. It is the designated national script in various Slavic, Turkic, Mongolic, Uralic, Caucasian and Iranic-speaking countries in Southeastern Europe, Eastern Europe, the Caucasus, Central Asia, North Asia, and East Asia, and used by many other minority languages.&lt;br&gt;\n, around 250\u00a0million people in Eurasia use Cyrillic as the official script for their national languages, with Russia accounting for about half of them. With the accession of Bulgaria to the European Union on 1 January 2007, Cyrillic became the third official script of the European Union, following the Latin and Greek alphabets.\nThe Early Cyrillic alphabet was developed during the 9th century AD at the Preslav Literary School in the First Bulgarian Empire during the reign of Tsar Simeon I the Great, probably by the disciples of the two Byzantine brothers Cyril and Methodius, who had previously created the Glagolitic script. Among them were Clement of Ohrid, Naum of Preslav, Constantine of Preslav, Joan Ekzarh, Chernorizets Hrabar, Angelar, Sava and other scholars. The script is named in honor of Saint Cyril.\nEtymology.\nSince the script was conceived and popularised by the followers of Cyril and Methodius in Bulgaria, rather than by Cyril and Methodius themselves, its name denotes homage rather than authorship.\nHistory.\nThe Cyrillic script was created during the First Bulgarian Empire. Modern scholars believe that the Early Cyrillic alphabet was created at the Preslav Literary School, the most important early literary and cultural center of the First Bulgarian Empire and of all Slavs:\nUnlike the Churchmen in Ohrid, Preslav scholars were much more dependent upon Greek models and quickly abandoned the Glagolitic scripts in favor of an adaptation of the Greek uncial to the needs of Slavic, which is now known as the Cyrillic alphabet.\nA number of prominent Bulgarian writers and scholars worked at the school, including Naum of Preslav until 893; Constantine of Preslav; Joan Ekzarh (also transcr. John the Exarch); and Chernorizets Hrabar, among others. The school was also a center of translation, mostly of Byzantine authors. The Cyrillic script is derived from the Greek uncial script letters, augmented by ligatures and consonants from the older Glagolitic alphabet for sounds not found in Greek. Glagolitic and Cyrillic were formalized by the Byzantine Saints Cyril and Methodius and their Bulgarian disciples, such as Saints Naum, Clement, Angelar, and Sava. They spread and taught Christianity in the whole of Bulgaria. Paul Cubberley posits that although Cyril may have codified and expanded Glagolitic, it was his students in the First Bulgarian Empire under Tsar Simeon the Great that developed Cyrillic from the Greek letters in the 890s as a more suitable script for church books.\nCyrillic spread among other Slavic peoples, as well as among non-Slavic Romanians. The earliest datable Cyrillic inscriptions have been found in the area of Preslav, in the medieval city itself and at nearby Patleina Monastery, both in present-day Shumen Province, as well as in the Ravna Monastery and in the Varna Monastery. The new script became the basis of alphabets used in various languages in Orthodox Church-dominated Eastern Europe, both Slavic and non-Slavic languages (such as Romanian, until the 1860s). For centuries, Cyrillic was also used by Catholic and Muslim Slavs.\nCyrillic and Glagolitic were used for the Church Slavonic language, especially the Old Church Slavonic variant. Hence expressions such as \"\u0418 is the tenth Cyrillic letter\" typically refer to the order of the Church Slavonic alphabet; not every Cyrillic alphabet uses every letter available in the script. The Cyrillic script came to dominate Glagolitic in the 12th century.\nThe literature produced in Old Church Slavonic soon spread north from Bulgaria and became the lingua franca of the Balkans and Eastern Europe.\nCyrillic in modern-day Bosnia, is an extinct and disputed variant of the Cyrillic alphabet that originated in medieval period.\nPaleographers consider the earliest features of script had likely begun to appear between the 10th or 11th century, with the Humac tablet to be the first such document using this type of script and is believed to date from this period. Was weak used continuously until the 18th century, with sporadic usage even taking place in the 20th century.\nWith the orthographic reform of Saint Evtimiy of Tarnovo and other prominent representatives of the Tarnovo Literary School of the 14th and 15th centuries, such as Gregory Tsamblak and Constantine of Kostenets, the school influenced Russian, Serbian, Wallachian and Moldavian medieval culture. This is known in Russia as the second South-Slavic influence.\nIn 170810, the Cyrillic script used in Russia was heavily reformed by Peter the Great, who had recently returned from his Grand Embassy in Western Europe. The new letterforms, called the Civil script, became closer to those of the Latin alphabet; several archaic letters were abolished and several new letters were introduced designed by Peter himself. Letters became distinguished between upper and lower case. West European typography culture was also adopted. The pre-reform letterforms, called '\u041f\u043e\u043b\u0443\u0443\u0441\u0442\u0430\u0432', were notably retained in Church Slavonic and are sometimes used in Russian even today, especially if one wants to give a text a 'Slavic' or 'archaic' feel.\nThe alphabet used for the modern Church Slavonic language in Eastern Orthodox and Eastern Catholic rites still resembles early Cyrillic. However, over the course of the following millennium, Cyrillic adapted to changes in spoken language, developed regional variations to suit the features of national languages, and was subjected to academic reform and political decrees. A notable example of such linguistic reform can be attributed to Vuk Stefanovi\u0107 Karad\u017ei\u0107, who updated the Serbian Cyrillic alphabet by removing certain graphemes no longer represented in the vernacular and introducing graphemes specific to Serbian (i.e. \u0409 \u040a \u0402 \u040b \u040f \u0408), distancing it from the Church Slavonic alphabet in use prior to the reform. Today, many languages in the Balkans, Eastern Europe, and northern Eurasia are written in Cyrillic alphabets.\nLetters.\nCyrillic script spread throughout the East Slavic and some South Slavic territories, being adopted for writing local languages, such as Old East Slavic. Its adaptation to local languages produced a number of Cyrillic alphabets, discussed below.\nMajuscule and minuscule.\nCapital and lowercase letters were not distinguished in old manuscripts.\nYeri () was originally a ligature of Yer and I ( + = ). Iotation was indicated by ligatures formed with the letter \u0406: (not an ancestor of modern Ya, \u042f, which is derived from ), , (ligature of and ), , . Sometimes different letters were used interchangeably, for example = = , as were typographical variants like = . There were also commonly used ligatures like = .\nNumbers.\nThe letters also had numeric values, based not on Cyrillic alphabetical order, but inherited from the letters' Greek ancestors.\nComputer support.\nComputer fonts for early Cyrillic alphabets are not routinely provided. Many of the letterforms differ from those of modern Cyrillic, varied a great deal between manuscripts, and changed over time. In accordance with Unicode policy, the standard does not include letterform variations or ligatures found in manuscript sources unless they can be shown to conform to the Unicode definition of a character: this aspect is the responsibility of the typeface designer.\nThe Unicode 5.1 standard, released on 4 April 2008, greatly improved computer support for the early Cyrillic and the modern Church Slavonic language. In Microsoft Windows, the Segoe UI user interface font is notable for having complete support for the archaic Cyrillic letters since Windows 8.\nCurrency signs.\nSome currency signs have derived from Cyrillic letters:\nLetterforms and type design.\nThe development of Cyrillic letter forms passed directly from the medieval stage to the late Baroque, without a Renaissance phase as in Western Europe. Late Medieval Cyrillic letters (categorized as vyaz' and still found on many icon inscriptions today) show a marked tendency to be very tall and narrow, with strokes often shared between adjacent letters.\nPeter the Great, Tsar of Russia, mandated the use of westernized letter forms () in the early 18th century. Over time, these were largely adopted in the other languages that use the script. Thus, unlike the majority of modern Greek typefaces that retained their own set of design principles for lower-case letters (such as the placement of serifs, the shapes of stroke ends, and stroke-thickness rules, although Greek capital letters do use Latin design principles), modern Cyrillic types are much the same as modern Latin types of the same typeface family. The development of some Cyrillic computer fonts from Latin ones has also contributed to a visual Latinization of Cyrillic type.\nLowercase forms.\nCyrillic uppercase and lowercase letter forms are not as differentiated as in Latin typography. Upright Cyrillic lowercase letters are essentially small capitals (with exceptions: Cyrillic , , , , , and adopted Latin lowercase shapes, lowercase is typically based on from Latin typefaces, lowercase , and are traditional handwritten forms), although a good-quality Cyrillic typeface will still include separate small-caps glyphs.\nCyrillic typefaces, as well as Latin ones, have roman and italic forms (practically all popular modern computer fonts include parallel sets of Latin and Cyrillic letters, where many glyphs, uppercase as well as lowercase, are shared by both). However, the native typeface terminology in most Slavic languages (for example, in Russian) does not use the words \"roman\" and \"italic\" in this sense. Instead, the nomenclature follows German naming patterns:\nItalic and cursive forms.\nSimilarly to Latin typefaces, italic and cursive forms of many Cyrillic letters (typically lowercase; uppercase only for handwritten or stylish types) are very different from their upright roman types. In certain cases, the correspondence between uppercase and lowercase glyphs does not coincide in Latin and Cyrillic types: for example, italic Cyrillic is the lowercase counterpart of not of .\nNote: in some typefaces or styles, , i.e. the lowercase italic Cyrillic , may look like Latin , and , i.e. lowercase italic Cyrillic , may look like small-capital italic .\nIn Standard Serbian, as well as in Macedonian, some italic and cursive letters are allowed to be different, to more closely resemble the handwritten letters. The regular (upright) shapes are generally standardized in small caps form.\nNotes: Depending on fonts available, the Serbian row may appear identical to the Russian row. Unicode approximations are used in the \"faux\" row to ensure it can be rendered properly across all systems.\nIn the Bulgarian alphabet, many lowercase letterforms may more closely resemble the cursive forms on the one hand and Latin glyphs on the other hand, e.g. by having an ascender or descender or by using rounded arcs instead of sharp corners. Sometimes, uppercase letters may have a different shape as well, e.g. more triangular, \u0414 and \u041b, like Greek delta \u0394 and lambda \u039b.\nNotes: Depending on fonts available, the Bulgarian row may appear identical to the Russian row. Unicode approximations are used in the \"faux\" row to ensure it can be rendered properly across all systems; in some cases, such as \u0436 with \"k\"-like ascender, no such approximation exists.\nAccessing variant forms.\nComputer fonts typically default to the Central/Eastern, Russian letterforms, and require the use of OpenType Layout (OTL) features to display the Western, Bulgarian or Southern, Serbian/Macedonian forms. Depending on the choices made by the (computer) font designer, they may either be automatically activated by the \"local variant\" codice_1 feature for text tagged with an appropriate language code, or the author needs to opt-in by activating a \"stylistic set\" codice_2 or \"character variant\" codice_3 feature. These solutions only enjoy partial support and may render with default glyphs in certain software configurations, and the reader may not see the same result as the author intended.\nCyrillic alphabets.\nAmong others, Cyrillic is the standard script for writing the following languages:\nSlavic languages:\nNon-Slavic languages of Russia:\nNon-Slavic languages in other countries: \nThe Cyrillic script has also been used for languages of Alaska, Slavic Europe (except for Western Slavic and some Southern Slavic), the Caucasus, the languages of Idel-Ural, Siberia, and the Russian Far East.\nThe first alphabet derived from Cyrillic was Abur, used for the Komi language. Other Cyrillic alphabets include the Molodtsov alphabet for the Komi language and various alphabets for Caucasian languages.\nUsage of Cyrillic versus other scripts.\nLatin script.\nA number of languages written in a Cyrillic alphabet have also been written in a Latin alphabet, such as Azerbaijani, Uzbek, Serbian, and Romanian (in the Moldavian SSR until 1989 and in the Danubian Principalities throughout the 19th century). After the disintegration of the Soviet Union in 1991, some of the former republics officially shifted from Cyrillic to Latin. The transition is complete in most of Moldova (except the breakaway region of Transnistria, where Moldovan Cyrillic is official), Turkmenistan, and Azerbaijan. Uzbekistan still uses both systems, and Kazakhstan has officially begun a transition from Cyrillic to Latin (scheduled to be complete by 2025). The Russian government has mandated that Cyrillic must be used for all public communications in all federal subjects of Russia, to promote closer ties across the federation. This act was controversial for speakers of many Slavic languages; for others, such as Chechen and Ingush speakers, the law had political ramifications. For example, the separatist Chechen government mandated a Latin script which is still used by many Chechens.\nStandard Serbian uses both the Cyrillic and Latin scripts. Cyrillic is nominally the official script of Serbia's administration according to the Serbian constitution; however, the law does not regulate scripts in standard language, or standard language itself by any means. In practice the scripts are equal, with Latin being used more often in a less official capacity.\nThe Zhuang alphabet, used between the 1950s and 1980s in portions of the People's Republic of China, used a mixture of Latin, phonetic, numeral-based, and Cyrillic letters. The non-Latin letters, including Cyrillic, were removed from the alphabet in 1982 and replaced with Latin letters that closely resembled the letters they replaced.\nRomanization.\nThere are various systems for romanization of Cyrillic text, including transliteration to convey Cyrillic spelling in Latin letters, and transcription to convey pronunciation.\nStandard Cyrillic-to-Latin transliteration systems include:\nSee also Romanization of Belarusian, Bulgarian, Kyrgyz, Russian, Macedonian and Ukrainian.\nCyrillization.\nRepresenting other writing systems with Cyrillic letters is called Cyrillization.\nComputer encoding.\nUnicode.\nAs of Unicode version , Cyrillic letters, including national and historical alphabets, are encoded across several blocks:\nThe characters in the range U+0400 to U+045F are essentially the characters from ISO 8859-5 moved upward by 864 positions. The characters in the range U+0460 to U+0489 are historic letters, not used now. The characters in the range U+048A to U+052F are additional letters for various languages that are written with Cyrillic script.\nUnicode as a general rule does not include accented Cyrillic letters. A few exceptions include:\nTo indicate stressed or long vowels, combining diacritical marks can be used after the respective letter (for example, : \u0435\u0301 \u0443\u0301 \u044d\u0301 etc.).\nSome languages, including Church Slavonic, are still not fully supported.\nUnicode 5.1, released on 4 April 2008, introduces major changes to the Cyrillic blocks. Revisions to the existing Cyrillic blocks, and the addition of Cyrillic Extended A (2DE0 ... 2DFF) and Cyrillic Extended B (A640 ... A69F), significantly improve support for the early Cyrillic alphabet, Abkhaz, Aleut, Chuvash, Kurdish, and Moksha.\nOther.\nOther character encoding systems for Cyrillic:\nKeyboard layouts.\nEach language has its own standard keyboard layout, adopted from traditional national typewriters. With the flexibility of computer input methods, there are also transliterating or phonetic/homophonic keyboard layouts made for typists who are more familiar with other layouts, like the common English QWERTY keyboard. When practical Cyrillic keyboard layouts are unavailable, computer users sometimes use transliteration (translit) or look-alike (volapuk encoding) to type in languages that are normally written with the Cyrillic alphabet. Potentially, these proxy versions could be transformed programmatically into Cyrillic at a later date."}
{"id": "5641", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=5641", "title": "Consonant", "text": "In articulatory phonetics, a consonant is a speech sound that is articulated with complete or partial closure of the vocal tract, except for the h sound, which is pronounced without any stricture in the vocal tract. Examples are and [b], pronounced with the lips; and [d], pronounced with the front of the tongue; and [g], pronounced with the back of the tongue; , pronounced throughout the vocal tract; , [v], and , pronounced by forcing air through a narrow channel (fricatives); and and , which have air flowing through the nose (nasals). Most consonants are pulmonic, using air pressure from the lungs to generate a sound. Very few natural languages are non-pulmonic, making use of ejectives, implosives, and clicks. Contrasting with consonants are vowels.\nSince the number of speech sounds in the world's languages is much greater than the number of letters in any one alphabet, linguists have devised systems such as the International Phonetic Alphabet (IPA) to assign a unique and unambiguous symbol to each attested consonant. The English alphabet has fewer consonant letters than the English language has consonant sounds, so digraphs like , , , and are used to extend the alphabet, though some letters and digraphs represent more than one consonant. For example, the sound spelled in \"this\" is a different consonant from the sound in \"thin\". (In the IPA, these are and , respectively.)\nEtymology.\nThe word \"consonant\" comes from Latin oblique stem , from 'sounding-together', a calque of Greek (plural , ).\nDionysius Thrax calls consonants ( 'sounded with') because in Greek they can only be pronounced with a vowel. He divides them into two subcategories: ( 'half-sounded'), which are the continuants, and ( 'unsounded'), which correspond to plosives.\nThis description does not apply to some languages, such as the Salishan languages, in which plosives may occur without vowels (see Nuxalk), and the modern concept of \"consonant\" does not require co-occurrence with a vowel.\nConsonant \"sounds\" and consonant \"letters\".\nThe word \"consonant\" may be used ambiguously for both speech sounds and the letters of the alphabet used to write them. In English, these letters are B, C, D, F, G, J, K, L, M, N, P, Q, S, T, V, X, Z and often H, R, W, Y.\nIn English orthography, the letters H, R, W, Y and the digraph GH are used for both consonants and vowels. For instance, the letter Y stands for the consonant/semi-vowel in yoke\", the vowel in \"myth\", the vowel in \"funny, the diphthong in \"sky, and forms several digraphs for other diphthongs, such as \"say, boy, key. Similarly, R commonly indicates or modifies a vowel in non-rhotic accents.\nThis article is concerned with consonant sounds, however they are written.\nConsonants versus vowels.\nConsonants and vowels correspond to distinct parts of a syllable: The most sonorous part of the syllable (that is, the part that is easiest to sing), called the \"syllabic peak\" or \"nucleus,\" is typically a vowel, while the less sonorous margins (called the \"onset\" and \"coda\") are typically consonants. Such syllables may be abbreviated CV, V, and CVC, where C stands for consonant and V stands for vowel. This can be argued to be the only pattern found in most of the world's languages, and perhaps the primary pattern in all of them. However, the distinction between consonant and vowel is not always clear cut: there are syllabic consonants and non-syllabic vowels in many of the world's languages.\nOne blurry area is in segments variously called \"semivowels\", \"semiconsonants\", or \"glides\". On one side, there are vowel-like segments that are not in themselves syllabic, but form diphthongs as part of the syllable nucleus, as the \"i\" in English \"boil\" . On the other, there are approximants that behave like consonants in forming onsets, but are articulated very much like vowels, as the \"y\" in English \"yes\" . Some phonologists model these as both being the underlying vowel , so that the English word \"bit\" would phonemically be , \"beet\" would be , and \"yield\" would be phonemically . Likewise, \"foot\" would be , \"food\" would be , \"wood\" would be , and \"wooed\" would be . However, there is a (perhaps allophonic) difference in articulation between these segments, with the in \"yes\" and \"yield\" and the of \"wooed\" having more constriction and a more definite place of articulation than the in \"boil\" or \"bit\" or the of \"foot\".\nThe other problematic area is that of syllabic consonants, segments articulated as consonants but occupying the nucleus of a syllable. This may be the case for words such as \"church\" in rhotic dialects of English, although phoneticians differ in whether they consider this to be a syllabic consonant, , or a rhotic vowel, : Some distinguish an approximant that corresponds to a vowel , for \"rural\" as or ; others see these as a single phoneme, .\nOther languages use fricative and often trilled segments as syllabic nuclei, as in Czech and several languages in Democratic Republic of the Congo, and China, including Mandarin Chinese. In Mandarin, they are historically allophones of , and spelled that way in Pinyin. Ladefoged and Maddieson call these \"fricative vowels\" and say that \"they can usually be thought of as syllabic fricatives that are allophones of vowels\". That is, phonetically they are consonants, but phonemically they behave as vowels.\nMany Slavic languages allow the trill and the lateral as syllabic nuclei (see Words without vowels). In languages like Nuxalk, it is difficult to know what the nucleus of a syllable is, or if all syllables even have nuclei. If the concept of 'syllable' applies in Nuxalk, there are syllabic consonants in words like (?) 'seal fat'. Miyako in Japan is similar, with 'to build' and 'to pull'.\nEach spoken consonant can be distinguished by several phonetic \"features\":\nAll English consonants can be classified by a combination of these features, such as \"voiceless alveolar stop\" . In this case, the airstream mechanism is omitted.\nSome pairs of consonants like \"p::b\", \"t::d\" are sometimes called fortis and lenis, but this is a phonological rather than phonetic distinction.\nConsonants are scheduled by their features in a number of IPA charts:\nExamples.\nThe recently extinct Ubykh language had only 2 or 3 vowels but 84 consonants; the Taa language has 87 consonants under one analysis, 164 under another, plus some 30 vowels and tone. The types of consonants used in various languages are by no means universal. For instance, nearly all Australian languages lack fricatives; a large percentage of the world's languages lack voiced stops such as , , as phonemes, though they may appear phonetically. Most languages, however, do include one or more fricatives, with being the most common, and a liquid consonant or two, with the most common. The approximant is also widespread, and virtually all languages have one or more nasals, though a very few, such as the Central dialect of Rotokas, lack even these. This last language has the smallest number of consonants in the world, with just six.\nMost common.\nIn rhotic American English, the consonants spoken most frequently are . ( is less common in non-rhotic accents.)\nThe most frequent consonant in many other languages is .\nThe most universal consonants around the world (that is, the ones appearing in nearly all languages) are the three voiceless stops , , , and the two nasals , . However, even these common five are not completely universal. Several languages in the vicinity of the Sahara Desert, including Arabic, lack . Several languages of North America, such as Mohawk, lack both of the labials and . The Wichita language of Oklahoma and some West African languages, such as Ijo, lack the consonant on a phonemic level, but do use it phonetically, as an allophone of another consonant (of in the case of Ijo, and of in Wichita). A few languages on Bougainville Island and around Puget Sound, such as Makah, lack both of the nasals and altogether, except in special speech registers such as baby-talk. The 'click language' N\u01c1ng lacks , and colloquial Samoan lacks both alveolars, and . Despite the 80-odd consonants of Ubykh, it lacks the plain velar in native words, as do the related Adyghe and Kabardian languages. But with a few striking exceptions, such as Xavante and Tahitian\u2014which have no dorsal consonants whatsoever\u2014nearly all other languages have at least one velar consonant: most of the few languages that do not have a simple (that is, a sound that is generally pronounced ) have a consonant that is very similar. For instance, an areal feature of the Pacific Northwest coast is that historical *k has become palatalized in many languages, so that Saanich for example has and but no plain ; similarly, historical *k in the Northwest Caucasian languages became palatalized to in extinct Ubykh and to in most Circassian dialects."}
{"id": "5642", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=5642", "title": "Costume jewelry", "text": "Costume or fashion jewelry includes a range of decorative items worn for personal adornment that are manufactured as less expensive ornamentation to complement a particular fashionable outfit or garment as opposed to \"real\" (fine) jewelry, which is more costly and which may be regarded primarily as collectibles, keepsakes, or investments. From the outset, costume jewelry \u2014 also known as fashion jewelry \u2014 paralleled the styles of its more precious fine counterparts.\nTerminology.\nIt is also known as artificial jewellery, imitation jewellery, imitated jewelry, trinkets, fashion jewelry, junk jewelry, fake jewelry, or fallalery.\nEtymology.\nThe term costume jewelry dates back to the early 20th century. It reflects the use of the word \"costume\" to refer to what is now called an \"outfit\".\nComponents.\nOriginally, costume or fashion jewelry was made of inexpensive simulated gemstones, such as rhinestones or lucite, set in pewter, silver, nickel, or brass. During the depression years, rhinestones were even down-graded by some manufacturers to meet the cost of production.\nDuring the World War II era, sterling silver was often incorporated into costume jewelry designs primarily because:\nThis resulted in a number of years during which sterling silver costume jewelry was produced and some can still be found in today's vintage jewelry marketplace.\nModern costume jewelry incorporates a wide range of materials. High-end crystals, cubic zirconia simulated diamonds, and some semi-precious stones are used in place of precious stones. Metals include gold- or silver-plated brass, and sometimes vermeil or sterling silver. Lower-priced jewelry may still use gold plating over pewter, nickel, or other metals; items made in countries outside the United States may contain lead. Some pieces incorporate plastic, acrylic, leather, or wood.\nHistorical expression.\nCostume jewelry can be characterized by the period in history in which it was made.\nArt Deco period (1920\u20131930s).\nThe Art Deco movement was an attempt to combine the harshness of mass production with the sensitivity of art and design. The movement died with the onset of the Great Depression and the outbreak of World War II.\nAccording to Schiffer, some of the characteristics of the costume jewelry in the Art Deco period were:\nRetro period (1935 to 1950).\nIn the Retro period, designers struggled with the art versus mass production dilemma. Natural materials merged with plastics. The retro period primarily included American-made jewelry, which had a distinctly American look. With the war in Europe, many European jewelry firms were forced to shut down. Many European designers emigrated to the U.S. since the economy was recovering.\nAccording to Schiffer, some of the characteristics of costume jewelry in the Retro period were:\nArt Modern period (1945 to 1960).\nIn the Art Modern period following World War II, jewelry designs became more traditional and understated. The big, bold styles of the Retro period went out of style and were replaced by the more tailored styles of the 1950s and 1960s.\nAccording to Schiffer, some of the characteristics of costume jewelry in the Art Modern period were:\nWith the advent of the Mod period came \"Body Jewelry\". Carl Schimel of Kim Craftsmen Jewelry was at the forefront of this style. While Kim Craftsmen closed in the early 1990s, many collectors still forage for their items at antique shows and flea markets.\nGeneral history.\nCostume jewelry has been part of the culture for almost 300 years. During the 18th century, jewelers began making pieces with inexpensive glass. In the 19th century, costume jewelry made of semi-precious material came into the market. Jewels made of semi-precious material were more affordable, and this affordability gave common people the chance to own costume jewelry.\nBut the real golden era for costume jewelry began in the middle of the 20th century. The new middle class wanted beautiful, but affordable jewelry. The demand for jewelry of this type coincided with the machine age and the Industrial Revolution. The revolution made the production of carefully executed replicas of admired heirloom pieces possible.\nAs the class structure in America changed, so did measures of real wealth. Women in all social stations, even the working-class woman, could own a small piece of costume jewelry. The average town and countrywoman could acquire and wear a considerable amount of this mass-produced jewelry that was both affordable and stylish.\nCostume jewelry was also made popular by various designers in the mid-20th century. Some of the most remembered names in costume jewelry include both the high and low priced brands: Crown Trifari, Dior, Chanel, Miriam Haskell, Sherman, Monet, Napier, Corocraft, Coventry, and Kim Craftsmen.\nA significant factor in the popularization of costume jewelry was Hollywood movies. The leading female stars of the 1940s and 1950s often wore and then endorsed the pieces produced by a range of designers. If you admired a necklace worn by Bette Davis in \"The Private Lives of Elizabeth and Essex\", you could buy a copy from Joseff of Hollywood, who made the original. Stars such as Vivien Leigh, Elizabeth Taylor, and Jane Russell appeared in adverts for the pieces and the availability of the collections in shops such as Woolworth made it possible for ordinary women to own and wear such jewelry.\nCoco Chanel greatly popularized the use of faux jewelry in her years as a fashion designer, bringing costume jewelry to life with gold and faux pearls. Chanel\u2019s designs drew from a variety of historical styles, including Byzantine and Renaissance influences, often featuring crosses and intricate metalwork. Her collaboration with glassmakers, such as the Gripoix family, introduced richly colored glass beads and simulated gemstones, which added depth to her creations without the high cost of traditional precious stones. \nKenneth Jay Lane has since the 1960s been known for creating unique pieces for Jackie Onassis, Elizabeth Taylor, Diana Vreeland, and Audrey Hepburn. He is probably best known for his three-strand faux pearl necklace worn by Barbara Bush to her husband's inaugural ball. Other celebrated names who wore Lane\u2019s creations include Jackie Kennedy, Babe Paley, the Duchess of Windsor, and Nancy Reagan. \nElsa Schiaparelli brought surrealist influences into costume jewelry design, collaborating with artists such as Salvador Dal\u00ed.\nIn many instances, high-end fashion jewelry has achieved a \"collectible\" status and increased value over time. Today, there is a substantial secondary market for vintage fashion jewelry. The main collecting market is for 'signed pieces', that is pieces that have the maker's mark, usually stamped on the reverse. Amongst the most sought after are Miriam Haskell, Sherman, Coro, Butler and Wilson, Crown Trifari, and Sphinx. However, there is also demand for good quality 'unsigned' pieces, especially if they are of an unusual design.\nBusiness and industry.\nCostume jewelry is considered a discrete category of fashion accessory and displays many characteristics of a self-contained industry. Costume jewelry manufacturers are located throughout the world, with a particular concentration in parts of China and India, where entire citywide and region-wide economies are dominated by the trade of these goods. There has been considerable controversy in the United States and elsewhere about the lack of regulations in the manufacture of such jewelry\u2014these range from human rights issues surrounding the treatment of labor, to the use of manufacturing processes in which small, but potentially harmful, amounts of toxic metals are added during production. In 2010, the Associated Press released the story that toxic levels of the metal cadmium were found in children's jewelry. An Associated Press investigation found some pieces contained more than 80 percent of cadmium. The wider issues surrounding imports, exports, trade laws, and globalization also apply to the costume jewelry trade.\nAs part of the supply chain, wholesalers in the United States and other nations purchase costume jewelry from manufacturers and typically import or export it to wholesale distributors and suppliers who deal directly with retailers. Wholesale costume jewelry merchants will traditionally seek out new suppliers at trade shows. As the Internet has become increasingly important in global trade, the trade-show model has changed. Retailers can now select from a large number of wholesalers with sites on the World Wide Web. The wholesalers purchase from international suppliers who are also available on the Web from different parts of the world like Chinese, Korean, Indonesian, Thai, and Indian jewelry companies, with their wide range of products in bulk quantities. Some of these sites also market directly to consumers who can purchase costume jewelry at greatly reduced prices. Some of these websites categorize fashion jewelry separately, while others use this term in place of costume jewelry. The trend of jewelry-making at home by hobbyists for personal enjoyment or for sale on sites like Etsy has resulted in the common practice of buying wholesale costume jewelry in bulk and using it for parts.\nThere is a rise in demand for artificial or imitation jewelry by 85% due to the increase in gold prices, according to a 2011 report."}
{"id": "5643", "revid": "6209078", "url": "https://en.wikipedia.org/wiki?curid=5643", "title": "Channel Islands", "text": "The Channel Islands are an archipelago in the English Channel, off the French coast of Normandy. They are divided into two Crown Dependencies: the Bailiwick of Jersey, which is the largest of the islands; and the Bailiwick of Guernsey, consisting of Guernsey, Alderney, Sark, Herm and some smaller islands. Historically, they are the remnants of the Duchy of Normandy. Although they are not part of the United Kingdom, the UK is responsible for the defence and international relations of the islands as it is for the other Crown Dependency, the Isle of Man, and the British Overseas Territories. The Crown Dependencies are neither members of the Commonwealth of Nations, nor part of the European Union. They have a total population of about , and the bailiwicks' capitals, Saint Helier and Saint Peter Port, have populations of 33,500 and 18,207 respectively.\n\"Channel Islands\" is a geographical term, not a political unit. The two bailiwicks have been administered separately since the late 13th century. Each has its own independent laws, elections, and representative bodies (although in modern times, politicians from the islands' legislatures are in regular contact). Any institution common to both is the exception rather than the rule.\nThe Bailiwick of Guernsey is divided into three jurisdictions \u2013 Guernsey, Alderney and Sark \u2013 each with its own legislature. Although there are a few pan-island institutions (such as the Channel Islands Brussels Office, the Director of Civil Aviation and the Channel Islands Financial Ombudsman, which are actually joint ventures between the bailiwicks), these tend to be established structurally as equal projects between Guernsey and Jersey. Otherwise, entities whose names imply membership of both Guernsey and Jersey might in fact be from one bailiwick only. For instance, The International Stock Exchange is in Saint Peter Port and therefore is in Guernsey.\nThe term \"Channel Islands\" began to be used around 1830, possibly first by the Royal Navy as a collective name for the islands. The term refers only to the archipelago to the west of the Cotentin Peninsula. Other populated islands located in the English Channel, and close to the coast of Britain, such as the Isle of Wight, Hayling Island and Portsea Island, are not regarded as \"Channel Islands\".\nGeography.\nThe two major islands are Jersey and Guernsey. They make up 99% of the population and 92% of the area.\nNames.\nThe names of the larger islands in the archipelago in general have the \"-ey\" suffix, whilst those of the smaller ones have the \"-hou\" suffix. These are believed to be from the Old Norse \"ey\" (island) and \"holmr\" (islet).\nThe Chausey Islands.\nThe Chausey Islands south of Jersey are not generally included in the geographical definition of the Channel Islands but are occasionally described in English as 'French Channel Islands' in view of their French jurisdiction. They were historically linked to the Duchy of Normandy, but they are part of the French territory along with continental Normandy, and not part of the British Isles or of the Channel Islands in a political sense. They are an incorporated part of the commune of Granville (Manche). While they are popular with visitors from France, Channel Islanders can only visit them by private or charter boats as there are no direct transport links from the other islands.\nIn official Jersey Standard French, the Channel Islands are called '\u00celes de la Manche', while in France, the term '\u00celes Anglo-normandes' (Anglo-Norman Isles) is used to refer to the British 'Channel Islands' in contrast to other islands in the Channel. Chausey is referred to as an '\u00cele normande' (as opposed to \"Anglo-normande\"). '\u00celes Normandes' and 'Archipel Normand' have also, historically, been used in Channel Island French to refer to the islands as a whole.\nWaters.\nThe very large tidal variation provides an environmentally rich inter-tidal zone around the islands, and some islands such as Burhou, the \u00c9cr\u00e9hous, and the Minquiers have been designated Ramsar sites.\nThe waters around the islands include the following:\nHighest point.\nThe highest point in the islands is Les Platons in Jersey at 143 metres (469\u00a0ft) above sea level. The lowest point is the English Channel (sea level).\nHistory.\nPrehistory.\nThe earliest evidence of human occupation of the Channel Islands has been dated to 250,000 years ago when they were attached to the landmass of continental Europe. The islands became detached by rising sea levels in the Mesolithic period. The numerous dolmens and other archaeological sites extant and recorded in history demonstrate the existence of a population large enough and organised enough to undertake constructions of considerable size and sophistication, such as the burial mound at La Hougue Bie in Jersey or the statue menhirs of Guernsey.\nFrom the Iron Age.\nHoards of Armorican coins have been excavated, providing evidence of trade and contact in the Iron Age period. Evidence for Roman settlement is sparse, although evidently the islands were visited by Roman officials and traders. The Roman name for the Channel Islands was \"I. Lenuri\" (Lenur Islands) and is included in the Peutinger Table. The traditional Latin names used for the islands (Caesarea for Jersey, Sarnia for Guernsey, Riduna for Alderney) derive (possibly mistakenly) from the Antonine Itinerary. Gallo-Roman culture was adopted to an unknown extent in the islands.\nIn the sixth century, Christian missionaries visited the islands. Samson of Dol, Helier, Marculf and Magloire are among saints associated with the islands. In the sixth century, they were already included in the diocese of Coutances where they remained until the Reformation.\nThere were probably some Celtic Britons who settled on the Islands in the 5th and 6th centuries AD (the indigenous Celts of Great Britain, and the ancestors of the modern Welsh, Cornish, and Bretons) who had emigrated from Great Britain in the face of invading Anglo-Saxons. But there were not enough of them to leave any trace, and the islands continued to be ruled by the king of the Franks and its church remained part of the diocese of Coutances.\nFrom the beginning of the ninth century, Norse raiders appeared on the coasts. Norse settlement eventually succeeded initial attacks, and it is from this period that many place names of Norse origin appear, including the modern names of the islands.\nFrom the Duchy of Normandy.\nIn 933, the islands were granted to William I Longsword by Raoul, the King of Western Francia, and annexed to the Duchy of Normandy. In 1066, William II of Normandy invaded and conquered England, becoming William I of England, also known as William the Conqueror. In the period 1204\u20131214, King John lost the Angevin lands in northern France, including mainland Normandy, to King Philip II of France, but managed to retain control of the Channel Islands. In 1259, his successor, Henry III of England, by the Treaty of Paris, officially surrendered his claim and title to the Duchy of Normandy, while retaining the Channel Islands, as peer of France and feudal vassal of the King of France. Since then, the Channel Islands have been governed as two separate bailiwicks and were never absorbed into the Kingdom of England nor its successor kingdoms of Great Britain or the United Kingdom. During the Hundred Years' War, the Channel Islands were part of the French territory recognizing the claims of the English kings to the French throne.\nThe islands were invaded by the French in 1338, who held some territory until 1345. Edward III of England granted a Charter in July 1341 to Jersey, Guernsey, Sark and Alderney, confirming their customs and laws to secure allegiance to the English Crown. Owain Lawgoch, a mercenary leader of a Free Company in the service of the French Crown, attacked Jersey and Guernsey in 1372, and in 1373 Bertrand du Guesclin besieged Mont Orgueil. The young King Richard II of England reconfirmed in 1378 the Charter rights granted by his grandfather, followed in 1394 with a second Charter granting, because of great loyalty shown to the Crown, exemption forever, from English tolls, customs and duties. Jersey was occupied by the French in 1461 as part of an exchange for helping the Lancastrians fight against the Yorkists during The War of the Roses. It was retaken by the Yorkists in 1468. In 1483 a Papal bull decreed that the islands would be neutral during time of war. This privilege of neutrality enabled islanders to trade with both France and England and was respected until 1689 when it was abolished by Order in Council following the Glorious Revolution in Great Britain.\nVarious attempts to transfer the islands from the diocese of Coutances (to Nantes (1400), Salisbury (1496), and Winchester (1499)) had little effect until an Order in Council of 1569 brought the islands formally into the diocese of Winchester. Control by the bishop of Winchester was ineffectual as the islands had turned overwhelmingly Calvinist and the episcopacy was not restored until 1620 in Jersey and 1663 in Guernsey.\nAfter the loss of Calais in 1558, the Channel Islands were the last remaining English holdings in France and the only French territory that was controlled by the English kings as Kings of France. This situation lasted until the English kings dropped their title and claims to the French throne in 1801, confirming the Channel Islands in a situation of a crown dependency under the sovereignty of neither Great Britain nor France but of the British crown directly.\nSark in the 16th century was uninhabited until colonised from Jersey in the 1560s. The grant of seigneurship from Elizabeth I of England in 1565 forms the basis of Sark's constitution today.\nFrom the 17th century.\nDuring the Wars of the Three Kingdoms, Jersey held out strongly for the Royalist cause, providing refuge for Charles, Prince of Wales in 1646 and 1649\u20131650, while the more strongly Presbyterian Guernsey more generally favoured the parliamentary cause (although Castle Cornet was held by Royalists and did not surrender until October 1651).\nThe islands acquired commercial and political interests in the North American colonies. Islanders became involved with the Newfoundland fisheries in the 17th century. In recognition for all the help given to him during his exile in Jersey in the 1640s, Charles II gave George Carteret, Bailiff and governor, a large grant of land in the American colonies, which he promptly named New Jersey, now part of the United States of America. Sir Edmund Andros, bailiff of Guernsey, was an early colonial governor in North America, and head of the short-lived Dominion of New England.\nIn the late 18th century, the islands were dubbed \"the French Isles\". Wealthy French \u00e9migr\u00e9s fleeing the French Revolution sought residency in the islands. Many of the town domiciles existing today were built in that time. In Saint Peter Port, a large part of the harbour had been built by 1865.\n20th century.\nWorld War II.\nThe islands were occupied by the German Army during World War II.\nThe British Government demilitarised the islands in June 1940, and the lieutenant-governors were withdrawn on 21 June, leaving the insular administrations to continue government as best they could under impending military occupation.\nBefore German troops landed, between 30 June and 4 July 1940, evacuation took place. Many young men had already left to join the Allied armed forces, as volunteers. 6,600 out of 50,000 left Jersey while 17,000 out of 42,000 left Guernsey. Thousands of children were evacuated with their schools to England and Scotland.\nThe population of Sark largely remained where they were; but in Alderney, all but six people left. In Alderney, the occupying Germans built four prison camps which housed approximately 6,000 people, of whom over 700 died. Due to the destruction of documents, it is impossible to state how many forced workers died in the other islands. Some have claimed that Alderney had the only Nazi concentration camps on British soil. Others have pointed out that, technically, Alderney was not British soil.\nThe Royal Navy blockaded the islands from time to time, particularly following the Invasion of Normandy in June 1944. There was considerable hunger and privation during the five years of German occupation, particularly in the final months when the population was close to starvation. Intense negotiations resulted in some humanitarian aid being sent via the Red Cross, leading to the arrival of Red Cross parcels in the supply ship SS \"Vega\" in December 1944.\nThe German occupation of 1940\u201345 was harsh: over 2,000 islanders were deported by the Germans, and some Jews were sent to concentration camps; partisan resistance and retribution, accusations of collaboration, and slave labour also occurred. Many Spaniards, initially refugees from the Spanish Civil War, were brought to the islands to build fortifications. Later, Russians and Central Europeans continued the work. Many land mines were laid, with 65,718 land mines laid in Jersey alone.\nThere was no resistance movement in the Channel Islands on the scale of that in mainland France. This has been ascribed to a range of factors including the physical separation of the islands, the density of troops (up to one German for every two Islanders), the small size of the islands precluding any hiding places for resistance groups, and the absence of the Gestapo from the occupying forces. Moreover, much of the population of military age had already joined the British Army.\nThe end of the occupation came after VE-Day on 8 May 1945, with Jersey and Guernsey being liberated on 9 May. The German garrison in Alderney was left until 16 May, and it was one of the last of the Nazi German remnants to surrender. The first evacuees returned on the first sailing from Great Britain on 23 June, but the people of Alderney were unable to start returning until December 1945. Many of the evacuees who returned home had difficulty reconnecting with their families after five years of separation.\nAfter 1945.\nFollowing the liberation of 1945, reconstruction led to a transformation of the economies of the islands, attracting immigration and developing tourism. The legislatures were reformed and non-party governments embarked on social programmes, aided by the incomes from offshore finance, which grew rapidly from the 1960s. The islands decided not to join the European Economic Community when the UK joined. Since the 1990s, declining profitability of agriculture and tourism has challenged the governments of the islands.\nGovernance.\nThe Channel Islands fall into two separate self-governing bailiwicks, the Bailiwick of Guernsey and the Bailiwick of Jersey. Each of these is a British Crown Dependency, and neither is a part of the United Kingdom. They have been parts of the Duchy of Normandy since the 10th century, and Queen Elizabeth II was often referred to by her traditional and conventional title of Duke of Normandy. However, pursuant to the Treaty of Paris (1259), she governed in her right as The Queen (the \"Crown in right of Jersey\", and the \"Crown in right of the \"r\u00e9publique\" of the Bailiwick of Guernsey\"), and not as the Duke. This notwithstanding, it is a matter of local pride for monarchists to treat the situation otherwise: the Loyal toast at formal dinners was to 'The Queen, our Duke', rather than to 'Her Majesty, The Queen' as in the UK. The Queen died in 2022 and her son Charles III became the King.\nA bailiwick is a territory administered by a bailiff. Although the words derive from a common root ('bail' = 'to give charge of') there is a vast difference between the meanings of the word 'bailiff' in Great Britain and in the Channel Islands; a bailiff in Britain is a court-appointed private debt-collector authorised to collect judgment debts, in the Channel Islands, the Bailiff in each bailiwick is the civil head, presiding officer of the States, and also head of the judiciary, and thus the most important citizen in the bailiwick.\nIn the early 21st century, the existence of governmental offices such as the bailiffs' with multiple roles straddling the different branches of government came under increased scrutiny for their apparent contravention of the doctrine of separation of powers\u2014most notably in the Guernsey case of \"McGonnell -v- United Kingdom\" (2000) 30 EHRR 289. That case, following final judgement at the European Court of Human Rights, became part of the impetus for much recent constitutional change, particularly the Constitutional Reform Act 2005 (2005 c.4) in the UK, including the separation of the roles of the Lord Chancellor, the abolition of the House of Lords' judicial role, and its replacement by the UK Supreme Court. The islands' bailiffs, however, still retain their historic roles.\nThe systems of government in the islands date from Norman times, which accounts for the names of the legislatures, the States, derived from the Norman '\u00c9tats' or 'estates' (i.e. the Crown, the Church, and the people). The States have evolved over the centuries into democratic parliaments.\nThe UK Parliament has power to legislate for the islands, but Acts of Parliament do not extend to the islands automatically. Usually, an Act gives power to extend its application to the islands by an Order in Council, after consultation. For the most part the islands legislate for themselves. Each island has its own primary legislature, known as the States of Guernsey and the States of Jersey, with Chief Pleas in Sark and the States of Alderney. The Channel Islands are not represented in the UK Parliament. Laws passed by the States are given royal assent by the King-in-Council, to whom the islands' governments are responsible.\nThe islands have never been part of the European Union, and thus were not a party to the 2016 referendum on the EU membership, but were part of the Customs Territory of the European Community by virtue of Protocol Three to the Treaty on European Union. In September 2010, a Channel Islands Brussels Office was set up jointly by the two Bailiwicks to develop the Channel Islands' influence with the EU, to advise the Channel Islands' governments on European matters, and to promote economic links with the EU.\nBoth bailiwicks are members of the British\u2013Irish Council, and J\u00e8rriais and Guern\u00e9siais are recognised regional languages of the islands.\nThe legal courts are separate; separate courts of appeal have been in place since 1961. Among the legal heritage from Norman law is the Clameur de haro. The basis of the legal systems of both Bailiwicks is Norman customary law (Coutume) rather than the English Common Law, although elements of the latter have become established over time.\nIslanders are full British citizens, but were not classed as European citizens unless by descent from a UK national. Any British citizen who applies for a passport in Jersey or Guernsey receives a passport bearing the words \"British Islands, Bailiwick of Jersey\" or \"British Islands, Bailiwick of Guernsey\". Under the provisions of Protocol Three, Channel Islanders who do not have a close connection with the UK (no parent or grandparent from the UK, and have never been resident in the UK for a five-year period) did not automatically benefit from the EU provisions on free movement within the EU, and their passports received an endorsement to that effect. This affected only a minority of islanders.\nUnder the UK Interpretation Act 1978, the Channel Islands are deemed to be part of the British Islands, not to be confused with the British Isles. For the purposes of the British Nationality Act 1981, the \"British Islands\" include the United Kingdom (Great Britain and Northern Ireland), the Channel Islands and the Isle of Man, taken together, unless the context otherwise requires.\nEconomy.\nTourism is still important. However, Jersey and Guernsey have, since the 1960s, become major offshore financial centres. Historically Guernsey's horticultural and greenhouse activities have been more significant than in Jersey, and Guernsey has maintained light industry as a higher proportion of its economy than Jersey. In Jersey, potatoes are an important export crop, shipped mostly to the UK.\nJersey is heavily reliant on financial services, with 39.4% of Gross Value Added (GVA) in 2018 contributed by the sector. Rental income comes second at 15.1% with other business activities at 11.2%. Tourism 4.5% with agriculture contributing just 1.2% and manufacturing even lower at 1.1%. GVA has fluctuated between \u00a34.5 and \u00a35 billion for 20 years.\nJersey has had a steadily rising population, increasing from below 90,000 in 2000 to over 105,000 in 2018 which combined with a flat GVA has resulted in GVA per head of population falling from \u00a357,000 to \u00a344,000 per person. \nIn 2018, Guernsey had a GDP of \u00a33.2 billion and with a stable population of around 66,000 has had a steadily rising GDP, and a GVA per head of population which in 2018 surpassed \u00a352,000.\nBoth bailiwicks issue their own banknotes and coins, which circulate freely in all the islands alongside UK coinage and Bank of England and Scottish banknotes.\nTransport and communications.\nPost.\nSince 1969, Jersey and Guernsey have operated postal administrations independently of the UK's Royal Mail, with their own postage stamps, which can be used for postage only in their respective Bailiwicks. UK stamps are no longer valid, but mail to the islands, and to the Isle of Man, is charged at UK inland rates. It was not until the early 1990s that the islands joined the UK's postcode system, Jersey postcodes using the initials JE and Guernsey GY.\nTransport.\nRoad.\nEach of the three largest islands has a distinct vehicle registration scheme:\nIn Sark, where most motor traffic is prohibited, the few vehicles \u2013\u00a0nearly all tractors\u00a0\u2013 do not display plates. Bicycles display tax discs.\nSea.\nIn the 1960s, names used for the cross-Channel ferries plying the mail route between the islands and Weymouth, Dorset, were taken from the popular Latin names for the islands: (Jersey), (Guernsey) and (Alderney). Fifty years later, the ferry route between the Channel Islands and the UK is operated by Condor Ferries from both St Helier, Jersey and St Peter Port, Guernsey, using high-speed catamaran fast craft to Poole in the UK. A regular passenger ferry service on the Commodore Clipper goes from both Channel Island ports to Portsmouth daily, and carries both passengers and freight.\nFerry services to Normandy are operated by , and services between Jersey and Saint-Malo are operated by and Condor Ferries. The Isle of Sark Shipping Company operates small ferries to Sark. Normandy Trader operates an ex military tank landing craft for transporting freight between the islands and France.\nOn 20 August 2013, , which had operated a \"lift-on lift-off\" container service for 80 years between the Port of Southampton and the Port of Jersey, ceased trading. Senator Alan Maclean, a Jersey politician, had previously tried to save the 90-odd jobs furnished by the company to no avail. On 20 September, it was announced that Channel Island Lines would continue this service, and would purchase the MV \"Huelin Dispatch\" from Associated British Ports who in turn had purchased them from the receiver in the bankruptcy. The new operator was to be funded by Rockayne Limited, a closely held association of Jersey businesspeople.\nAir.\nThere are three airports in the Channel Islands: Alderney Airport, Guernsey Airport and Jersey Airport. They are directly connected to each other by services operated by Blue Islands and Aurigny.\nRail.\nHistorically, there have been railway networks on Jersey, Guernsey, and Alderney, but all of the lines on Jersey and Guernsey have been closed and dismantled. Today there are three working railways in the Channel Islands, of which the Alderney Railway is the only one providing a regular timetabled passenger service. The other two are a gauge miniature railway, also on Alderney, and the heritage steam railway operated on Jersey as part of the Pallot Heritage Steam Museum.\nMedia.\nThe Channel Islands are served by a number of local radio services \u2013 BBC Radio Jersey and BBC Radio Guernsey, Channel 103 and Island FM \u2013 as well as regional television news opt-outs from BBC Channel Islands and ITV Channel Television.\nOn 1 August 2021, DAB+ digital radio became available for the first time, introducing new stations like the local Bailiwick Radio and Soleil Radio, and UK-wide services like Capital, Heart, and Times Radio.\nThere are two broadcast transmitters serving Jersey \u2013 at Fr\u00e9mont Point and Les Platons \u2013 as well as one at Les Touillets in Guernsey and a relay in Alderney.\nThere are several local newspapers including the Guernsey Press and the Jersey Evening Post and magazines.\nTelephone.\nJersey always operated its own telephone services independently of Britain's national system, Guernsey established its own telephone service in 1968. Both islands still form part of the British telephone numbering plan, but Ofcom on the mainlines does not have responsibility for telecommunications regulatory and licensing issues on the islands. It is responsible for wireless telegraphy licensing throughout the islands, and by agreement, for broadcasting regulation in the two large islands only. Submarine cables connect the various islands and provide connectivity with England and France.\nInternet.\nModern broadband speeds are available on all of the islands, including full-fibre (FTTH) in Jersey (offering speeds of up to 1\u00a0Gbit/s on all broadband connections) and VDSL and some business and homes with fibre connectivity in Guernsey. Providers include Sure and JT.\nThe two Bailiwicks each have their own internet domain, .GG (Guernsey, Alderney, Sark) and .JE (Jersey), which are managed by channelisles.net.\nCulture.\nThe Norman language predominated in the islands until the nineteenth century, when increasing influence from English-speaking settlers and easier transport links led to Anglicisation. There are four main dialects/languages of Norman in the islands, Auregnais (Alderney, extinct in late twentieth century), Dg\u00e8rn\u00e9siais (Guernsey), J\u00e8rriais (Jersey) and Sercquiais (Sark, an offshoot of J\u00e8rriais).\nVictor Hugo spent many years in exile, first in Jersey and then in Guernsey, where he finished \"Les Mis\u00e9rables\". Guernsey is the setting of Hugo's later novel \"Les Travailleurs de la Mer\" (\"Toilers of the Sea\"). A \"Guernsey-man\" also makes an appearance in chapter 91 of Herman Melville's \"Moby-Dick\".\nThe annual \"Muratti\", the inter-island football match, is considered the sporting event of the year, although, due to broadcast coverage, it no longer attracts the crowds of spectators, travelling between the islands, that it did during the twentieth century.\nCricket is popular in the Channel Islands. The Jersey cricket team and the Guernsey cricket team are both associate members of the International Cricket Council. The teams have played each other in the inter-insular match since 1957. In 2001 and 2002, the Channel Islands entered a team into the MCCA Knockout Trophy, the one-day tournament of the minor counties of English and Welsh cricket.\nChannel Island sportsmen and women compete in the Commonwealth Games for their respective islands and the islands have also been enthusiastic supporters of the Island Games. Shooting is a popular sport, in which islanders have won Commonwealth medals.\nGuernsey's traditional colour for sporting and other purposes is green and Jersey's is red.\nThe main islanders have traditional animal nicknames:\nReligion.\nChristianity was brought to the islands around the sixth century; according to tradition, Jersey was evangelised by St Helier, Guernsey by St Samson of Dol, and the smaller islands were occupied at various times by monastic communities representing strands of Celtic Christianity. At the Reformation, the previously Catholic islands converted to Calvinism under the influence of an influx of French-language pamphlets published in Geneva. Anglicanism was imposed in the seventeenth century, but the Nonconformist local tendency returned with a strong adoption of Methodism. In the late twentieth century, a strong Catholic presence re-emerged with the arrival of numerous Portuguese workers (both from mainland Portugal and the island of Madeira). Their numbers have been reinforced by recent migrants from Poland and elsewhere in Eastern Europe. Today, Evangelical churches have been established. Services are held in a number of languages.\nAccording to 2015 statistics, 39% of the population was non-religious.\nOther islands in the English Channel.\nA number of islands in the English Channel are part of France. Among these are Br\u00e9hat, \u00cele de Batz, Chausey, Tatihou and the \u00celes Saint-Marcouf.\nThe Isle of Wight, which is part of England, lies just off the coast of Great Britain, between the Channel and the Solent.\nHayling and Portsea islands, both being near or part of Portsmouth, are also part of England (and thus part of the United Kingdom)."}
{"id": "5644", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=5644", "title": "Comedy film", "text": "The comedy film is a film genre that emphasizes humor. These films are designed to amuse audiences and make them laugh. Films in this genre typically have a happy ending, with dark comedy being an exception to this rule. Comedy is one of the oldest genres in film, and it is derived from classical comedy in theatre. Some of the earliest silent films were slapstick comedies, which often relied on visual depictions, such as sight gags and pratfalls, so they could be enjoyed without requiring sound. To provide drama and excitement to silent movies, live music was played in sync with the action on the screen, on pianos, organs, and other instruments. When sound films became more prevalent during the 1920s, comedy films grew in popularity, as laughter could result from both burlesque situations but also from humorous dialogue.\nComedy, compared with other film genres, places more focus on individual star actors, with many former stand-up comics transitioning to the film industry due to their popularity.\nIn \"The Screenwriters Taxonomy\" (2017), Eric R. Williams contends that film genres are fundamentally based upon a film's atmosphere, character, and story, and therefore, the labels \"drama\" and \"comedy\" are too broad to be considered a genre. Instead, his taxonomy argues that comedy is a type of film that contains at least a dozen different sub-types. A number of hybrid genres have emerged, such as action comedy and romantic comedy.\nHistory.\nSilent film era.\nThe first comedy film was \"L'Arroseur Arros\u00e9\" (1895), directed and produced by film pioneer Louis Lumi\u00e8re. Less than a minute long, it shows a boy playing a prank on a gardener. The most notable comedy actors of the silent film era (1895\u20131927) were Charlie Chaplin, Harold Lloyd, and Buster Keaton, though they were able to make the transition into \"talkies\" after the 1920s.\nSocial commentary in comedy.\nFilm-makers in the 1960s skillfully employed the use of comedy film to make social statements by building their narratives around sensitive cultural, political or social issues. Such films include Dr Strangelove, or How I Learned to Love the Bomb, Guess Who's Coming to Dinner? and The Graduate. \nCamp and bawdy comedy.\nIn America, the sexual revolution drove an appetite for comedies that celebrated and parodied changing social morals, including Bob &amp; Carol &amp; Ted &amp; Alice and Fanny Hill. In Britain, a camp sensibility lay behind the successful Carry On films, while in America subversive independent film-maker John Waters made camp films for college audiences with his drag queen friends that eventually found a mainstream audience. The success of the American television show Saturday Night Live drove decades of cinema with racier content allowed on television drawing on the program's stars and characters, with bigger successes including Wayne's World, Mean Girls, Ghostbusters and Animal House.\nPresent era.\nParody and joke-based films continue to find audiences.\nReception.\nWhile comedic films are among the most popular with audiences at the box office, there is an 'historical bias against a close and serious consideration of comedy' when it comes to critical reception and conferring of awards, such as at the Academy Awards. Film writer Cailian Savage observes \"Comedies have won Oscars, although they\u2019ve usually been comedy-dramas, involved very depressing scenes, or appealed to stone-hearted drama lovers in some other way, such as \"Shakespeare in Love\".\"\nHybrid sub-genres.\nAccording to Williams' taxonomy, all film descriptions should contain their type (comedy or drama) combined with one (or more) sub-genres. This combination does not create a separate genre, but rather, provides a better understanding of the film."}
{"id": "5645", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=5645", "title": "Cult film", "text": " \nA cult film or cult movie, also commonly referred to as a cult classic, is a film that has acquired a cult following. Cult films are known for their dedicated, passionate fanbase, which forms an elaborate subculture, members of which engage in repeated viewings, dialogue-quoting, and audience participation. Inclusive definitions allow for major studio productions, especially box-office bombs, while exclusive definitions focus more on obscure, transgressive films shunned by the mainstream. The difficulty in defining the term and subjectivity of what qualifies as a cult film mirror classificatory disputes about art. The term \"cult film\" itself was first used in the 1970s to describe the culture that surrounded underground films and midnight movies, though \"cult\" was in common use in film analysis for decades prior to that.\nCult films trace their origin back to controversial and suppressed films kept alive by dedicated fans. In some cases, reclaimed or rediscovered films have acquired cult followings decades after their original release, occasionally for their camp value. Other cult films have since become well-respected or reassessed as classics; there is debate as to whether these popular and accepted films are still cult films. After failing at the cinema, some cult films have become regular fixtures on cable television or profitable sellers on home video. Others have inspired their own film festivals. Cult films can both appeal to specific subcultures and form their own subcultures. Other media that reference cult films can easily identify which demographics they desire to attract and offer savvy fans an opportunity to demonstrate their knowledge.\nCult films frequently break cultural taboos, and many feature excessive displays of violence, gore, sexuality, profanity, or combinations thereof. This can lead to controversy, censorship, and outright bans; less transgressive films may attract similar amounts of controversy when critics call them frivolous or incompetent. Films that fail to attract requisite amounts of controversy may face resistance when labeled as cult films. Mainstream films and big budget blockbusters have attracted cult followings similar to more underground and lesser known films; fans of these films often emphasize the films' niche appeal and reject the more popular aspects. Fans who like the films for the wrong reasons, such as perceived elements that represent mainstream appeal and marketing, will often be ostracized or ridiculed. Likewise, fans who stray from accepted subcultural scripts may experience similar rejection.\nSince the late 1970s, cult films have become increasingly popular. Films that once would have been limited to obscure cult followings are now capable of breaking into the mainstream, and showings of cult films have proved to be a profitable business venture. Overly broad usage of the term has resulted in controversy, as purists state it has become a meaningless descriptor applied to any film that is the slightest bit weird or unconventional; others accuse Hollywood studios of trying to artificially create cult films or use the term as a marketing tactic. Modern films are frequently stated to be an \"instant cult classic\", occasionally before they are released. Some films have acquired massive, quick cult followings, owing to advertisements and posts made by fans spreading virally through social media. Easy access to cult films via video on demand and peer-to-peer file sharing has led some critics to pronounce the death of cult films.\nDefinition.\nA cult film is any film that has a cult following, although the term is not easily defined and can be applied to a wide variety of films. Some definitions exclude films that have been released by major studios or have big budgets, that try specifically to become cult films, or become accepted by mainstream audiences and critics. Cult films are defined by audience reaction as much as by their content. This may take the form of elaborate and ritualized audience participation, film festivals, or cosplay. Over time, the definition has become more vague and inclusive as it drifts away from earlier, stricter views. Increasing use of the term by mainstream publications has resulted in controversy, as cinephiles argue that the term has become meaningless or \"elastic, a catchall for anything slightly maverick or strange\". Academic Mark Shiel has criticized the term itself as being a weak concept, reliant on subjectivity; different groups can interpret films in their own terms. According to feminist scholar Joanne Hollows, this subjectivity causes films with large female cult followings to be perceived as too mainstream and not transgressive enough to qualify as a cult film. Academic Mike Chopra\u2011Gant says that cult films become decontextualized when studied as a group, and Shiel criticizes this recontextualization as cultural commodification.\nIn 2008, \"Cineaste\" asked a range of academics for their definition of a cult film. Several people defined cult films primarily in terms of their opposition to mainstream films and conformism, explicitly requiring a transgressive element, though others disputed the transgressive potential, given the demographic appeal to conventional moviegoers and mainstreaming of cult films. Jeffrey Andrew Weinstock instead called them mainstream films with transgressive elements. Most definitions also required a strong community aspect, such as obsessed fans or ritualistic behavior. Citing misuse of the term, Mikel J. Koven took a self-described hard-line stance that rejected definitions that use any other criteria. Matt Hills instead stressed the need for an open-ended definition rooted in structuration, where the film and the audience reaction are interrelated and neither is prioritized. Ernest Mathijs focused on the accidental nature of cult followings, arguing that cult film fans consider themselves too savvy to be marketed to, while Jonathan Rosenbaum rejected the continued existence of cult films and called the term a marketing buzzword. Mathijs suggests that cult films help to understand ambiguity and incompleteness in life given the difficulty in even defining the term. That cult films can have opposing qualities\u00a0\u2013 such as good and bad, failure and success, innovative and retro\u00a0\u2013 helps to illustrate that art is subjective and never self-evident. This ambiguity leads critics of postmodernism to accuse cult films of being beyond criticism, as the emphasis is now on personal interpretation rather than critical analysis or metanarratives. These inherent dichotomies can lead audiences to be split between ironic and earnest fans.\nWriting in \"Defining Cult Movies\", Jancovich et al. quote academic Jeffrey Sconce, who defines cult films in terms of paracinema, marginal films that exist outside critical and cultural acceptance: everything from exploitation to beach party musicals to softcore pornography. However, they reject cult films as having a single unifying feature; instead, they state that cult films are united in their \"subcultural ideology\" and opposition to mainstream tastes, itself a vague and undefinable term. Cult followings themselves can range from adoration to contempt, and they have little in common except for their celebration of nonconformity\u00a0\u2013 even the bad films ridiculed by fans are artistically nonconformist, albeit unintentionally. At the same time, they state that bourgeois, masculine tastes are frequently reinforced, which makes cult films more of an internal conflict within the bourgeoisie, rather than a rebellion against it. This results in an anti-academic bias despite the use of formal methodologies, such as defamiliarization. This contradiction exists in many subcultures, especially those dependent on defining themselves in terms of opposition to the mainstream. This nonconformity is eventually co-opted by the dominant forces, such as Hollywood, and marketed to the mainstream. Academic Xavier Mendik proposes that films can become cult by virtue of their genre or content, especially if it is transgressive. Due to their rejection of mainstream appeal, Mendik says cult films can be more creative and political; times of relative political instability produce more interesting films.\nGeneral overview.\nCult films have existed since the early days of cinema. Film critic Harry Allan Potamkin traces them back to 1910s France and the reception of Pearl White, William S. Hart, and Charlie Chaplin, which he described as \"a dissent from the popular ritual\". \"Nosferatu\" (1922) was an unauthorized adaptation of Bram Stoker's \"Dracula\". Stoker's widow sued the production company and drove it to bankruptcy. All known copies of the film were destroyed, and \"Nosferatu\" become an early cult film, kept alive by a cult following that circulated illegal bootlegs. Academic Chuck Kleinhans identifies the Marx Brothers as making other early cult films. On their original release, some highly regarded classics from the Golden Age of Hollywood were panned by critics and audiences, relegated to cult status. \"The Night of the Hunter\" (1955) was a cult film for years, quoted often and championed by fans, before it was reassessed as an important and influential classic. During this time, American exploitation films and imported European art films were marketed similarly. Although critics Pauline Kael and Arthur Knight argued against arbitrary divisions into high and low culture, American films settled into rigid genres; European art films continued to push the boundaries of simple definitions, and these exploitative art films and artistic exploitation films would go on to influence American cult films. Much like later cult films, these early exploitation films encouraged audience participation, influenced by live theater and vaudeville.\nModern cult films grew from 1960s counterculture and underground films, popular among those who rejected mainstream Hollywood films. These underground film festivals led to the creation of midnight movies, which attracted cult followings. The term \"cult film\" itself was an outgrowth of this movement and was first used in the 1970s, though \"cult\" had been in use for decades in film analysis with both positive and negative connotations. These films were more concerned with cultural significance than the social justice sought by earlier avant-garde films. Midnight movies became more popular and mainstream by the 1970s, peaking with the release of \"The Rocky Horror Picture Show\" (1975), which finally found its audience several years after its release. Eventually, the rise of home video would marginalize midnight movies once again, after which many directors joined the burgeoning independent film scene or went back underground. Home video would give a second life to box-office flops, as positive word-of-mouth or excessive replay on cable television led these films to develop an appreciative audience, as well as obsessive replay and study. For example, \"The Beastmaster\" (1982), despite its failure at the box office, became one of the most played movies on American cable television and developed into a cult film. Home video and television broadcasts of cult films were initially greeted with hostility. Joanne Hollows states that they were seen as turning cult films mainstream\u00a0\u2013 in effect, feminizing them by opening them to distracted, passive audiences.\nReleases from major studios\u00a0, such as \"The Big Lebowski\" (1998), which was distributed by Universal Studios\u00a0, can become cult films when they fail at the box office and develop a cult following through reissues, such as midnight movies, festivals, and home video. Hollywood films, due to their nature, are more likely to attract this kind of attention, which leads to a mainstreaming effect of cult culture. With major studios behind them, even financially unsuccessful films can be re-released multiple times, which plays into a trend to capture audiences through repetitious reissues. The constant use of profanity and drugs in otherwise mainstream, Hollywood films, such as \"The Big Lebowski\", can alienate critics and audiences yet lead to a large cult following among more open-minded demographics not often associated with cult films, such as Wall Street bankers and professional soldiers. Thus, even comparatively mainstream films can satisfy the traditional demands of a cult film, perceived by fans as transgressive, niche, and uncommercial. Discussing his reputation for making cult films, Bollywood director Anurag Kashyap said, \"I didn't set out to make cult films. I wanted to make box-office hits.\" Writing in \"Cult Cinema\", academics Ernest Mathijs and Jamie Sexton state that this acceptance of mainstream culture and commercialism is not out of character, as cult audiences have a more complex relationship to these concepts: they are more opposed to mainstream values and excessive commercialism than they are anything else.\nIn a global context, popularity can vary widely by territory, especially with regard to limited releases. \"Mad Max\" (1979) was an international hit\u00a0, except in America where it became an obscure cult favorite, ignored by critics and available for years only in a dubbed version though it earned over $100M internationally. Foreign cinema can put a different spin on popular genres, such as Japanese horror, which was initially a cult favorite in America. Asian imports to the West are often marketed as exotic cult films and of interchangeable national identity, which academic Chi-Yun Shin criticizes as reductive. Foreign influence can affect fan response, especially on genres tied to a national identity; when they become more global in scope, questions of authenticity may arise. Filmmakers and films ignored in their own country can become the objects of cult adoration in another, producing perplexed reactions in their native country. Cult films can also establish an early viability for more mainstream films, both for filmmakers and national cinema. The early cult horror films of Peter Jackson were so strongly associated with his homeland that they affected the international reputation of New Zealand and its cinema. As more artistic films emerged, New Zealand was perceived as a legitimate competitor to Hollywood, which mirrored Jackson's career trajectory. \"Heavenly Creatures\" (1994) acquired its own cult following, became a part of New Zealand's national identity, and paved the way for big-budget, Hollywood-style epics, such as Jackson's \"The Lord of the Rings\" trilogy.\nMathijs states that cult films and fandom frequently involve nontraditional elements of time and time management. Fans will often watch films obsessively, an activity that is viewed by the mainstream as wasting time yet can be seen as resisting the commodification of leisure time. They may also watch films idiosyncratically: sped up, slowed down, frequently paused, or at odd hours. Cult films themselves subvert traditional views of time\u00a0\u2013 time travel, non-linear narratives, and ambiguous establishments of time are all popular. Mathijs also identifies specific cult film viewing habits, such as viewing horror films on Halloween, sentimental melodrama on Christmas, and romantic films on Valentine's Day. These films are often viewed as marathons where fans can gorge themselves on their favorites. Mathijs states that cult films broadcast on Christmas have a nostalgic factor. These films, ritually watched every season, give a sense of community and shared nostalgia to viewers. New films often have trouble making inroads against the institutions of \"It's a Wonderful Life\" (1946) and \"Miracle on 34th Street\" (1947). These films provide mild criticism of consumerism while encouraging family values. Halloween, on the other hand, allows for flaunting society's taboos and testing one's fears. Horror films have appropriated the holiday, and many horror films debut on Halloween. Mathijs criticizes the over-cultified, commercialized nature of Halloween and horror films, which, he states feed into each other so much that Halloween has turned into an image or product with no real community. Mathijs states that Halloween horror conventions can provide the missing community aspect.\nDespite their oppositional nature, cult films can produce celebrities. Like cult films themselves, authenticity is an important aspect of their popularity. Actors can become typecast as they become strongly associated with such iconic roles. Tim Curry, despite his acknowledged range as an actor, found casting difficult after he achieved fame in \"The Rocky Horror Picture Show\". Even when discussing unrelated projects, interviewers frequently bring up the role, which causes him to tire of discussing it. Mary Woronov, known for her transgressive roles in cult films, eventually transitioned to mainstream films. She was expected to recreate the transgressive elements of her cult films within the confines of mainstream cinema. Instead of the complex gender deconstructions of her Andy Warhol films, she became typecast as a lesbian or domineering woman. Sylvia Kristel, after starring in \"Emmanuelle\" (1974), found herself highly associated with the film and the sexual liberation of the 1970s. Caught between the transgressive elements of her cult film and the mainstream appeal of soft-core pornography, she was unable to work in anything but exploitation films and \"Emmanuelle\" sequels. Despite her immense popularity and cult following, she would rate only a footnote in most histories of European cinema if she was even mentioned. Similarly, Chlo\u00eb Sevigny has struggled with her reputation as a cult independent film star famous for her daring roles in transgressive films. Cult films can also trap directors. Leonard Kastle, who directed \"The Honeymoon Killers\" (1969), never directed another film again. Despite his cult following, which included Fran\u00e7ois Truffaut, he was unable to find financing for any of his other screenplays. Qualities that bring cult films to prominence\u00a0\u2013 such as an uncompromising, unorthodox vision\u00a0\u2013 caused Alejandro Jodorowsky to languish in obscurity for years.\nTransgression and censorship.\nTransgressive films as a distinct artistic movement began in the 1970s. Unconcerned with genre distinctions, they drew inspiration equally from the nonconformity of European art cinema and experimental film, the gritty subject matter of Italian neorealism, and the shocking images of 1960s exploitation. Some used hardcore pornography and horror, occasionally at the same time. In the 1980s, filmmaker Nick Zedd identified this movement as the Cinema of Transgression and later wrote a manifesto. Popular in midnight showings, they were mainly limited to large urban areas, which led academic Joan Hawkins to label them as \"downtown culture\". These films acquired a legendary reputation as they were discussed and debated in alternative weeklies, such as \"The Village Voice\". Home video would finally allow general audiences to see them, which gave many people their first taste of underground film. Ernest Mathijs says that cult films often disrupt viewer expectations, such as giving characters transgressive motivations or focusing attention on elements outside the film. Cult films can also transgress national stereotypes and genre conventions, such as \"Battle Royale\" (2000), which broke many rules of teenage slasher films. The reverse\u00a0\u2013 when films based on cult properties lose their transgressive edge\u00a0\u2013 can result in derision and rejection by fans. Audience participation itself can be transgressive, such as breaking long-standing taboos against talking during films and throwing things at the screen.\nAccording to Mathijs, critical reception is important to a film's perception as cult, through topicality and controversy. Topicality, which can be regional (such as objection to government funding of the film) or critical (such as philosophical objections to the themes), enables attention and a contextual response. Cultural topics make the film relevant and can lead to controversy, such as a moral panic, which provides opposition. Cultural values transgressed in the film, such as sexual promiscuity, can be attacked by proxy, through attacks on the film. These concerns can vary from culture to culture, and they need not be at all similar. However, Mathijs says the film must invoke metacommentary for it to be more than simply culturally important. While referencing previous arguments, critics may attack its choice of genre or its very right to exist. By taking stances on these varied issues, critics assure their own relevance while helping to elevate the film to cult status. Perceived racist and reductive remarks by critics can rally fans and raise the profile of cult films, an example of which would be Rex Reed's comments about Korean culture in his review of \"Oldboy\" (2003). Critics can also polarize audiences and lead debates, such as how Joe Bob Briggs and Roger Ebert dueled over \"I Spit On Your Grave\" (1978). Briggs would later contribute a commentary track to the DVD release in which he describes it as a feminist film. Films which do not attract enough controversy may be ridiculed and rejected when suggested as cult films.\nAcademic Peter Hutchings, noting the many definitions of a cult film that require transgressive elements, states that cult films are known in part for their excesses. Both subject matter and its depiction are portrayed in extreme ways that break taboos of good taste and aesthetic norms. Violence, gore, sexual perversity, and even the music can be pushed to stylistic excess far beyond that allowed by mainstream cinema. Film censorship can make these films obscure and make it difficult to find common criteria used to define cult films. Despite this, these films remain well-known and prized among collectors. Fans will occasionally express frustration with dismissive critics and conventional analysis, which they believe marginalizes and misinterprets paracinema. In marketing these films, young men are predominantly targeted. Horror films in particular can draw fans who seek the most extreme films. Audiences can also ironically latch on to offensive themes, such as misogyny, using these films as catharsis for the things that they hate most in life. Exploitative, transgressive elements can be pushed to excessive extremes for both humor and satire. Frank Henenlotter faced censorship and ridicule, but he found acceptance among audiences receptive to themes that Hollywood was reluctant to touch, such as violence, drug addiction, and misogyny. Lloyd Kaufman sees his films' political statements as more populist and authentic than the hypocrisy of mainstream films and celebrities. Despite featuring an abundance of fake blood, vomit, and diarrhea, Kaufman's films have attracted positive attention from critics and academics. Excess can also exist in films that highlight the excesses of 1980s fashion and commercialism.\nFilms that are influenced by unpopular styles or genres can become cult films. Director Jean Rollin worked within \"cin\u00e9ma fantastique\", an unpopular genre in modern France. Influenced by American films and early French fantasists, he drifted between art, exploitation, and pornography. His films were reviled by critics, but he retained a cult following drawn by the nudity and eroticism. Similarly, Jess Franco chafed under fascist censorship in Spain but became influential in Spain's horror boom of the 1960s. These transgressive films that straddle the line between art and horror may have overlapping cult followings, each with their own interpretation and reasons for appreciating it. The films that followed Jess Franco were unique in their rejection of mainstream art. Popular among fans of European horror for their subversiveness and obscurity, these later Spanish films allowed political dissidents to criticize the fascist regime within the cloak of exploitation and horror. Unlike most exploitation directors, they were not trying to establish a reputation. They were already established in the art-house world and intentionally chose to work within paracinema as a reaction against the New Spanish Cinema, an artistic revival supported by the fascists. As late as the 1980s, critics still cited Pedro Almod\u00f3var's anti-macho iconoclasm as a rebellion against fascist mores, as he grew from countercultural rebel to mainstream respectability. Transgressive elements that limit a director's appeal in one country can be celebrated or highlighted in another. Takashi Miike has been marketed in the West as a shocking and avant-garde filmmaker despite his many family-friendly comedies, which have not been imported.\nThe transgressive nature of cult films can lead to their censorship. During the 1970s and early 1980s, a wave of explicit, graphic exploitation films caused controversy. Called \"video nasties\" within the UK, they ignited calls for censorship and stricter laws on home video releases, which were largely unregulated. Consequently, the British Board of Film Classification banned many popular cult films due to issues of sex, violence, and incitement to crime. Released during the cannibal boom, \"Cannibal Holocaust\" (1980) was banned in dozens of countries and caused the director to be briefly jailed over fears that it was a real snuff film. Although opposed to censorship, director Ruggero Deodato would later agree with cuts made by the BBFC that removed unsimulated animal killings, which limited the film's distribution. Frequently banned films may introduce questions of authenticity as fans question whether they have seen a truly uncensored cut. Cult films have been falsely claimed to have been banned to increase their transgressive reputation and explain their lack of mainstream penetration. Marketing campaigns have also used such claims to raise interest among curious audiences. Home video has allowed cult film fans to import rare or banned films, finally giving them a chance to complete their collection with imports and bootlegs. Cult films previously banned are sometimes released with much fanfare, and the fans assumed to be already familiar with the controversy. Personal responsibility is often highlighted, and a strong anti-censorship message may be present. Previously lost scenes cut by studios can be re-added and restore a director's original vision, which draws similar fanfare and acclaim from fans. Imports are sometimes censored to remove elements that would be controversial, such as references to Islamic spirituality in Indonesian cult films.\nAcademics have written of how transgressive themes in cult films can be regressive. David Church and Chuck Kleinhans describe an uncritical celebration of transgressive themes in cult films, including misogyny and racism. Church has also criticized gendered descriptions of transgressive content that celebrate masculinity. Joanne Hollows further identifies a gendered component to the celebration of transgressive themes in cult films, where male terms are used to describe films outside the mainstream while female terms are used to describe mainstream, conformist cinema. Jacinda Read's expansion states that cult films, despite their potential for empowerment of the marginalized, are more often used by politically incorrect males. Knowledgeable about feminism and multiculturalism, they seek a refuge from the academic acceptance of these progressive ideals. Their playful and ironic acceptance of regressive lad culture invites, and even dares, condemnation from academics and the uncool. Thus, cult films become a tool to reinforce mainstream values through transgressive content; Rebecca Feasy states that cultural hierarchies can also be reaffirmed through mockery of films perceived to be lacking masculinity. However, the sexploitation films of Doris Wishman took a feminist approach which avoids and subverts the male gaze and traditional goal-oriented methods. Wishman's subject matter, though exploitative and transgressive, was always framed in terms of female empowerment and the feminine spectator. Her use of common cult film motifs\u00a0\u2013 female nudity and ambiguous gender\u00a0\u2013 were repurposed to comment on feminist topics. Similarly, the films of Russ Meyer were a complicated combination of transgressive, mainstream, progressive, and regressive elements. They attracted both acclaim and denouncement from critics and progressives. Transgressive films imported from cultures that are recognizably different yet still relatable can be used to progressively examine issues in another culture.\nSubcultural appeal and fandom.\nCult films can be used to help define or create groups as a form of subcultural capital; knowledge of cult films proves that one is \"authentic\" or \"non-mainstream\". They can be used to provoke an outraged response from the mainstream, which further defines the subculture, as only members could possibly tolerate such deviant entertainment. More accessible films have less subcultural capital; among extremists, banned films will have the most. By referencing cult films, media can identify desired demographics, strengthen bonds with specific subcultures, and stand out among those who understand the intertextuality. Popular films from previous eras may be reclaimed by genre fans long after they have been forgotten by the original audiences. This can be done for authenticity, such as horror fans who seek out now-obscure titles from the 1950s instead of the modern, well-known remakes. Authenticity may also drive fans to deny genre categorization to films perceived as too mainstream or accessible. Authenticity in performance and expertise can drive fan acclaim. Authenticity can also drive fans to decry the mainstream in the form of hostile critics and censors. Especially when promoted by enthusiastic and knowledgeable programmers, choice of venue can be an important part of expressing individuality. Besides creating new communities, cult films can link formerly disparate groups, such as fans and critics. As these groups intermix, they can influence each other, though this may be resisted by older fans, unfamiliar with these new references. In extreme cases, cult films can lead to the creation of religions, such as Dudeism. For their avoidance of mainstream culture and audiences, enjoyment of irony, and celebration of obscure subcultures, academic Martin Roberts compares cult film fans to hipsters.\nA film can become the object of a cult following within a particular region or culture if it has unusual significance. For example, Norman Wisdom's films, friendly to Marxist interpretation, amassed a cult following in Albania, as they were among the few Western films allowed by the country's Communist rulers. \"The Wizard of Oz\" (1939) and its star, Judy Garland, hold special significance to American and British gay culture, although it is a widely viewed and historically important film in greater American culture. Similarly, James Dean and his brief film career have become icons of alienated youth. Cult films can have such niche appeal that they are only popular within certain subcultures, such as \"Reefer Madness\" (1936) and \"Hemp for Victory\" (1942) among the stoner subculture. Beach party musicals, popular among American surfers, failed to find an equivalent audience when imported to the United Kingdom. When films target subcultures like this, they may seem unintelligible without the proper cultural capital. Films which appeal to teenagers may offer subcultural identities that are easily recognized and differentiate various subcultural groups. Films which appeal to stereotypical male activities, such as sports, can easily gain strong male cult followings. Sports metaphors are often used in the marketing of cult films to males, such as emphasizing the \"extreme\" nature of the film, which increases the appeal to youth subcultures fond of extreme sports.\nMatt Hills' concept of the \"cult blockbuster\" involves cult followings inside larger, mainstream films. Although these are big budget, mainstream films, they still attract cult followings. The cult fans differentiate themselves from ordinary fans in several ways: longstanding devotion to the film, distinctive interpretations, and fan works. Hills identifies three different cult followings for \"The Lord of the Rings\", each with their own fandom separate from the mainstream. Academic Emma Pett identifies \"Back to the Future\" (1985) as another example of a cult blockbuster. Although the film was an instant hit when released, it has also developed a nostalgic cult following over the years. The hammy acting by Christopher Lloyd and quotable dialogue have drawn a cult following, as they mimic traditional cult films. Blockbuster science fiction films that include philosophical subtexts, such as \"The Matrix\", allow cult film fans to enjoy them on a higher level than the mainstream. \"Star Wars\", with its large cult following in geek subculture, has been cited as both a cult blockbuster and a cult film. Although a mainstream epic, \"Star Wars\" has provided its fans with a spirituality and culture outside of the mainstream.\nFans, in response to the popularity of these blockbusters, will claim elements for themselves while rejecting others. For example, in the \"Star Wars\" film series, mainstream criticism of Jar Jar Binks focused on racial stereotyping; although cult film fans will use that to bolster their arguments, he is rejected because he represents mainstream appeal and marketing. Also, instead of valuing textual rarity, fans of cult blockbusters will value repeat viewings. They may also engage in behaviors more traditional for fans of cult television and other serial media, as cult blockbusters are often franchised, preconceived as a film series, or both. To reduce mainstream accessibility, a film series can be self-reflexive and full of in-jokes that only longtime fans can understand. Mainstream critics may ridicule commercially successful directors of cult blockbusters, such as James Cameron, Michael Bay, and Luc Besson, whose films have been called simplistic. This critical backlash may serve to embellish the filmmakers' reception as cult auteurs. In the same way, critics may ridicule fans of cult blockbusters as immature or shallow.\nCult films can create their own subculture. \"Rocky Horror\", originally made to exploit the popularity of glam subculture, became what academic Gina Marchetti called a \"sub-subculture\", a variant that outlived its parent subculture. Although often described as primarily composed of obsessed fans, cult film fandom can include many newer, less experienced members. Familiar with the film's reputation and having watched clips on YouTube, these fans may take the next step and enter the film's fandom. If they are the majority, they may alter or ignore long-standing traditions, such as audience participation rituals; rituals which lack perceived authenticity may be criticized, but accepted rituals bring subcultural capital to veteran fans who introduce them to the newer members. Fans who flaunt their knowledge receive negative reactions. Newer fans may cite the film itself as their reason for attending a showing, but longtime fans often cite the community. Organized fandoms may spread and become popular as a way of introducing new people to the film, as well as theatrical screenings being privileged by the media and fandom itself. Fandom can also be used as a process of legitimation. Fans of cult films, as in media fandom, are frequently producers instead of mere consumers. Unconcerned with traditional views on intellectual property, these fan works are often unsanctioned, transformative, and ignore fictional canon.\nLike cult films themselves, magazines and websites dedicated to cult films revel in their self-conscious offensiveness. They maintain a sense of exclusivity by offending mainstream audiences with misogyny, gore, and racism. Obsessive trivia can be used to bore mainstream audiences while building up subcultural capital. Specialist stores on the fringes of society (or websites which prominently partner with hardcore pornographic sites) can be used to reinforce the outsider nature of cult film fandom, especially when they use erotic or gory imagery. By assuming a preexisting knowledge of trivia, non-fans can be excluded. Previous articles and controversies can also be alluded to without explanation. Casual readers and non-fans will thus be left out of discussions and debates, as they lack enough information to meaningfully contribute. When fans like a cult film for the wrong reasons, such as casting or characters aimed at mainstream appeal, they may be ridiculed. Thus, fandom can keep the mainstream at bay while defining themselves in terms of the \"Other\", a philosophical construct divergent from social norms. Commercial aspects of fandom (such as magazines or books) can also be defined in terms of \"otherness\" and thus valid to consume: consumers purchasing independent or niche publications are discerning consumers, but the mainstream is denigrated. Irony or self-deprecating humor can also be used. In online communities, different subcultures attracted to transgressive films can clash over values and criteria for subcultural capital. Even within subcultures, fans who break subcultural scripts, such as denying the affectivity of a disturbing film, will be ridiculed for their lack of authenticity.\nTypes.\n\"So bad it's good\".\nThe critic Michael Medved characterized examples of the \"so bad it's good\" class of low-budget cult film through books such as \"The Golden Turkey Awards.\" These films include financially fruitless and critically scorned films that have become inadvertent comedies to film buffs, such as \"Plan 9 from Outer Space\" (1957), \"Mommie Dearest\" (1981), \"The Room\" (2003), and the Ugandan action comedy film \"Who Killed Captain Alex?\" (2010). Similarly, Paul Verhoeven's \"Showgirls\" (1995) bombed in theaters but developed a cult following on video. Catching on, Metro-Goldwyn-Mayer capitalized on the film's ironic appeal and marketed it as a cult film. Sometimes, fans will impose their own interpretation of films which have attracted derision, such as reinterpreting an earnest melodrama as a comedy. Jacob deNobel of the \"Carroll County Times\" states that films can be perceived as nonsensical or inept when audiences misunderstand avant-garde filmmaking or misinterpret parody. Films such as \"Rocky Horror\" can be misinterpreted as \"weird for weirdness' sake\" by people unfamiliar with the cult films that they parody. deNobel ultimately rejects the use of the label \"so bad it's good\" as mean-spirited and often misapplied. Alamo Drafthouse programmer Zack Carlson has further said that any film which succeeds in entertaining an audience is good, regardless of irony. In francophone culture, \"so bad it's good\" films, known as , have given rise to a subculture with dedicated websites such as \"Nanarland\", film festivals and viewings in theaters, as well as various books analyzing the phenomenon. The rise of the Internet and on-demand films has led critics to question whether \"so bad it's good\" films have a future now that people have such diverse options in both availability and catalog, though fans eager to experience the worst films ever made can lead to lucrative showings for local theaters and merchandisers.\nCamp and guilty pleasures.\nChuck Kleinhans states that the difference between a guilty pleasure and a cult film can be as simple as the number of fans; David Church raises the question of how many people it takes to form a cult following, especially now that home video makes fans difficult to count. As these cult films become more popular, they can bring varied responses from fans that depend on different interpretations, such as camp, irony, genuine affection, or combinations thereof. Earnest fans, who recognize and accept the film's faults, can make minor celebrities of the film's cast, though the benefits are not always clear. Cult film stars known for their camp can inject subtle parody or signal when films should not be taken seriously. Campy actors can also provide comic book supervillains for serious, artistic-minded films. This can draw fan acclaim and obsession more readily than subtle, method-inspired acting. Mark Chalon Smith of the \"Los Angeles Times\" says technical faults may be forgiven if a film makes up for them in other areas, such as camp or transgressive content. Smith states that the early films of John Waters are amateurish and less influential than claimed, but Waters' outrageous vision cements his place in cult cinema. Films such as \"Myra Breckinridge\" (1970) and \"Beyond the Valley of the Dolls\" (1970) can experience critical reappraisal later, once their camp excess and avant-garde filmmaking are better accepted, and films that are initially dismissed as frivolous are often reassessed as campy. Films that intentionally try to appeal to fans of camp may end up alienating them, as the films become perceived as trying too hard or not authentic.\nNostalgia.\nAccording to academic Brigid Cherry, nostalgia \"is a strong element of certain kinds of cult appeal.\" When Veoh added many cult films to their site, they cited nostalgia as a factor for their popularity. Academic I.\u00a0Q. Hunter describes cult films as \"New Hollywood \"in extremis\"\" and a form of nostalgia for that period. Ernest Mathijs instead states that cult films use nostalgia as a form of resistance against progress and capitalistic ideas of a time-based economy. By virtue of the time travel plot, \"Back to the Future\" permits nostalgia for both the 1950s and 1980s. Many members of its nostalgic cult following are too young to have been alive during those periods, which Emma Pett interprets as fondness for retro aesthetics, nostalgia for when they saw the film rather than when it was released, and looking to the past to find a better time period. Similarly, films directed by John Hughes have taken hold in midnight movie venues, trading off of nostalgia for the 1980s and an ironic appreciation for their optimism. Mathijs and Sexton describe \"Grease\" (1978) as a film nostalgic about an imagined past that has acquired a nostalgic cult following. Other cult films, such as \"Streets of Fire\" (1984), create a new fictional world based on nostalgic views of the past. In martial arts movies, there is the movie \"Bloodsport\" (1988) with Jean-Claude Van Damme as well as \"Road House\" (1989) with Patrick Swayze. Cult films may also subvert nostalgia, such as \"The Big Lebowski\", which introduces many nostalgic elements and then reveals them as fake and hollow. \"Scott Pilgrim vs. the World\" (2010) is another example, containing extensive nostalgia for the music and video gaming culture of the 2000s. Nathan Lee of the \"New York Sun\" identifies the retro aesthetic and nostalgic pastiche in films such as \"Donnie Darko\" as factors in its popularity among midnight movie crowds.\nMidnight movies.\nAuthor Tomas Crowder-Taraborrelli describes midnight movies as a reaction against the political and cultural conservatism in America, and Joan Hawkins identifies the movement as running the gamut from anarchist to libertarian, united in their anti-establishment attitude and punk aesthetic. These films are resistant to simple categorization and are defined by the fanaticism and ritualistic behaviors of their audiences. Midnight movies require a night life and an audience willing to invest themselves actively. Hawkins states that these films took a rather bleak point of view due to the living conditions of the artists and the economic prospects of the 1970s. Like the surrealists and dadaists, they not only satirically attacked society but also the very structure of film\u00a0\u2013 a counter-cinema that deconstructs narrative and traditional processes. In the late 1980s and 1990s, midnight movies transitioned from underground showings to home video viewings; eventually, a desire for community brought a resurgence, and \"The Big Lebowski\" kick-started a new generation. Demographics shifted, and more hip and mainstream audiences were drawn to them. Although studios expressed skepticism, large audiences were drawn to box-office flops, such as \"The Warriors\" (1979) gang movie from Walter Hill, \"Office Space\" (1999) and \"Donnie Darko\" (2001). Modern midnight movies retain their popularity and have been strongly diverging from mainstream films shown at midnight. Mainstream cinemas, eager to disassociate themselves from negative associations and increase profits, have begun abandoning midnight screenings. Although classic midnight movies have dropped off in popularity, they still bring reliable crowds.\nArt and exploitation.\nAlthough seemingly at odds with each other, art and exploitation films are frequently treated as equal and interchangeable in cult fandom, listed alongside each other and described in similar terms: their ability to provoke a response. The most exploitative aspects of art films are thus played up and their academic recognition ignored. This flattening of culture follows the popularity of post-structuralism, which rejects a hierarchy of artistic merit and equates exploitation and art. Mathijs and Sexton state that although cult films are not synonymous with exploitation, as is occasionally assumed, this is a key component; they write that exploitation, which exists on the fringes of the mainstream and deals with taboo subjects, is well-suited for cult followings. Academic David Andrews writes that cult softcore films are \"the most masculinized, youth-oriented, populist, and openly pornographic softcore area.\" The sexploitation films of Russ Meyer were among the first to abandon all hypocritical pretenses of morality and were technically proficient enough to gain a cult following. His persistent vision saw him received as an auteur worthy of academic study; director John Waters attributes this to Meyer's ability to create complicated, sexually charged films without resorting to explicit sex. Myrna Oliver described Doris Wishman's exploitation films as \"crass, coarse, and camp\u00a0... perfect fodder for a cult following.\" \"Sick films\", the most disturbing and graphically transgressive films, have their own distinct cult following; these films transcend their roots in exploitation, horror, and art films. In 1960s and 1970s America, exploitation and art films shared audiences and marketing, especially in New York City's grindhouse cinemas.\nB and genre films.\nMathijs and Sexton state that genre is an important part of cult films; cult films will often mix, mock, or exaggerate the tropes associated with traditional genres. Science fiction, fantasy, and horror are known for their large and dedicated cult followings; as science fiction films become more popular, fans emphasize non-mainstream and less commercial aspects of it. B films, which are often conflated with exploitation, are as important to cult films as exploitation. Teodor Reljic of \"Malta Today\" states that cult B films are a realistic goal for Malta's burgeoning film industry. Genre films, B films that strictly adhere to genre limitations, can appeal to cult film fans: given their transgressive excesses, horror films are likely to become to cult films; films like \"Galaxy Quest\" (1999) highlight the importance of cult followings and fandom to science fiction; and authentic martial arts skills in Hong Kong action films can drive them to become cult favorites. Cult musicals can range from the traditional, such as \"Singin' in the Rain\" (1952), which appeal to cult audiences through nostalgia, camp, and spectacle, to the more non-traditional, such as \"Cry-Baby\" (1990), which parodies musicals, and \"Rocky Horror\", which uses a rock soundtrack. Romantic fairy tale \"The Princess Bride\" (1987) failed to attract audiences in its original release, as the studio did not know how to market it. The freedom and excitement associated with cars can be an important part of drawing cult film fans to genre films, and they can signify action and danger with more ambiguity than a gun. \"Ad Week\" writes that cult B films, when released on home video, market themselves and need only enough advertising to raise curiosity or nostalgia.\nAnimation.\nAnimation can provide wide open vistas for stories. The French film \"Fantastic Planet\" (1973) explored ideas beyond the limits of traditional, live-action science fiction films. Ralph Bakshi's career has been marked with controversy: \"Fritz the Cat\" (1972), the first animated film to be rated \"X\" by the MPAA, provoked outrage for its racial caricatures and graphic depictions of sex, and \"Coonskin\" (1975) was decried as racist. Bakshi recalls that older animators had tired of \"kid stuff\" and desired edgier work, whereas younger animators hated his work for \"destroying the Disney images\". Eventually, his work would be reassessed and cult followings, which include Quentin Tarantino and Robert Rodriguez, developed around several of his films. \"Heavy Metal\" (1981) faced similar denunciations from critics. Donald Liebenson of the \"Los Angeles Times\" cites the violence and sexual imagery as alienating critics, who did not know what to make of the film. It would go on to become a popular midnight movie and frequently bootlegged by fans, as licensing issues kept it from being released on video for many years.\nPhil Hoad of \"The Guardian\" identifies \"Akira\" (1988) as introducing violent, adult Japanese animation (known as anime) to the West and paving the way for later works. Anime, according to academic Brian Ruh, is not a cult genre, but the lack of individual fandoms inside anime fandom itself lends itself to a bleeding over of cult attention and can help spread works internationally. Anime, which is frequently presented as a series (with movies either rising from existing series, or spinning off series based on the film), provides its fans with alternative fictional canons and points of view that can drive fan activity. The \"Ghost in the Shell\" films, for example, provided Japanese fans with enough bonus material and spinoffs that it encouraged cult tendencies. Markets that did not support the sale of these materials saw less cult activity. The claymation film \"\" (1995), which made only $57,100 at the box office against its $2.8 million budget but sold a million copies on VHS alone, was subsequently released on DVD and remastered in high definition for Blu-ray due to its strong cult following. Like many cult films, RiffTrax made their own humorous audio commentary for \"Gumby: The Movie\" in 2021.\nNonfiction.\nSensationalistic documentaries called mondo films replicate the most shocking and transgressive elements of exploitation films. They are usually modeled after \"sick films\" and cover similar subject matter. In \"The Cult Film Reader\", academics Mathijs and Mendik write that these documentaries often present non-Western societies as \"stereotypically mysterious, seductive, immoral, deceptive, barbaric or savage\". Though they can be interpreted as racist, Mathijs and Mendik state that they also \"exhibit a liberal attitude towards the breaking of cultural taboos\". Mondo films like \"Faces of Death\" mix real and fake footage freely, and they gain their cult following through the outrage and debate over authenticity that results. Like \"so bad it's good\" cult films, old propaganda and government hygiene films may be enjoyed ironically by more modern audiences for the camp value of the outdated themes and outlandish claims made about perceived social threats, such as drug use. Academic Barry K. Grant states that Frank Capra's \"Why We Fight\" World War II propaganda films are explicitly not cult, because they are \"slickly made and have proven their ability to persuade an audience.\" The sponsored film \"Mr. B Natural\" became a cult hit when it was broadcast on the satirical television show \"Mystery Science Theater 3000\"; cast member Trace Beaulieu cited these educational shorts as his favorite to mock on the show. Mark Jancovich states that cult audiences are drawn to these films because of their \"very banality or incoherence of their political positions\", unlike traditional cult films, which achieve popularity through auteurist radicalism.\nMainstream popularity.\nMark Shiel explains the rising popularity of cult films as an attempt by cinephiles and scholars to escape the oppressive conformity and mainstream appeal of even independent film, as well as a lack of condescension in both critics and the films; Academic Donna de Ville says it is a chance to subvert the dominance of academics and cinephiles. According to Xavier Mendik, \"academics have been really interested in cult movies for quite a while now.\" Mendik has sought to bring together academic interest and fandom through Cine-Excess, a film festival. I. Q. Hunter states that \"it's much easier to be a cultist now, but it is also rather more inconsequential.\" Citing the mainstream availability of \"Cannibal Holocaust\", Jeffrey Sconce rejects definitions of cult films based on controversy and excess, as they've now become meaningless. Cult films have influenced such diverse industries as cosmetics, music videos, and fashion. Cult films have shown up in less expected places; as a sign of his popularity, a bronze statue of Ed Wood has been proposed in his hometown, and \"L'Osservatore Romano\", the official newspaper of the Holy See, has courted controversy for its endorsement of cult films and pop culture. When cities attempt to renovate neighborhoods, fans have called attempts to demolish iconic settings from cult films \"cultural vandalism\". Cult films can also drive tourism, even when it is unwanted. From Latin America, Alejandro Jodorowsky's film \"El Topo\" (1970) has attracted attention of rock musicians such as John Lennon, Mick Jagger, and Bob Dylan.\nAs far back as the 1970s, \"Attack of the Killer Tomatoes\" (1978) was designed specifically to be a cult film, and \"The Rocky Horror Picture Show\" was produced by 20th Century Fox, a major Hollywood studio. Over its decades-long release, \"Rocky Horror\" became the seventh highest grossing R-rated film when adjusted for inflation; journalist Matt Singer has questioned whether \"Rocky Horror\"s popularity invalidates its cult status. Founded in 1974, Troma Entertainment, an independent studio, would become known for both its cult following and cult films. In the 1980s, Danny Peary's \"Cult Movies\" (1981) would influence director Edgar Wright and film critic Scott Tobias of \"The A.V. Club\". The rise of home video would have a mainstreaming effect on cult films and cultish behavior, though some collectors would be unlikely to self-identify as cult film fans. Film critic Joe Bob Briggs began reviewing drive-in theater and cult films, though he faced much criticism as an early advocate of exploitation and cult films. Briggs highlights the mainstreaming of cult films by pointing out the respectful obituaries that cult directors have received from formerly hostile publications and acceptance of politically incorrect films at mainstream film festivals. This acceptance is not universal, though, and some critics have resisted this mainstreaming of paracinema. Beginning in the 1990s, director Quentin Tarantino would have the greatest success in turning cult films mainstream. Tarantino later used his fame to champion obscure cult films that had influenced him and set up the short-lived Rolling Thunder Pictures, which distributed several of his favorite cult films. Tarantino's clout led Phil Hoad of \"The Guardian\" to call Tarantino the world's most influential director.\nAs major Hollywood studios and audiences both become savvy to cult films, productions once limited to cult appeal have instead become popular hits, and cult directors have become hot properties known for more mainstream and accessible films. Remarking on the popular trend of remaking cult films, Claude Brodesser-Akner of \"New York\" magazine states that Hollywood studios have been superstitiously hoping to recreate past successes rather than trading on nostalgia. Their popularity would bring some critics to proclaim the death of cult films now that they have finally become successful and mainstream, are too slick to attract a proper cult following, lack context, or are too easily found online. In response, David Church says that cult film fans have retreated to more obscure and difficult to find films, often using illegal distribution methods, which preserves the outlaw status of cult films. Virtual spaces, such as online forums and fan sites, replace the traditional fanzines and newsletters. Cult film fans consider themselves collectors, rather than consumers, as they associate consumers with mainstream, Hollywood audiences. This collecting can take the place of fetishization of a single film. Addressing concerns that DVDs have revoked the cult status of films like \"Rocky Horror\", academic Mikel J. Koven states that small scale screenings with friends and family can replace midnight showings. Koven also identifies television shows, such as \"Twin Peaks\", as retaining more traditional cult activities inside popular culture. David Lynch himself has not ruled out another television series, as studios have become reluctant to take chances on non-mainstream ideas. Despite this, the Alamo Drafthouse has capitalized on cult films and the surrounding culture through inspiration drawn from \"Rocky Horror\" and retro promotional gimmickry. They sell out their shows regularly and have acquired a cult following of their own.\nAcademic Bob Batchelor, writing in \"Cult Pop Culture\", states that the internet has democratized cult culture and destroyed the line between cult and mainstream. Fans of even the most obscure films can communicate online with each other in vibrant communities. Although known for their big-budget blockbusters, Steven Spielberg and George Lucas have criticized the current Hollywood system of gambling everything on the opening weekend of these productions. Geoffrey Macnab of \"The Independent\" instead suggests that Hollywood look to capitalize on cult films, which have exploded in popularity on the internet. The rise of social media has been a boon to cult films. Sites such as Twitter have displaced traditional venues for fandom and courted controversy from cultural critics who are unamused by campy cult films. After a clip from one of his films went viral, director-producer Roger Corman made a distribution deal with YouTube. Found footage which had originally been distributed as cult VHS collections eventually went viral on YouTube, which opened them to new generations of fans. Films such as \"\" (2008) and \"The Room\" (2003) gained quick, massive popularity, as prominent members of social networking sites discussed them. Their rise as \"instant cult classics\" bypasses the years of obscurity that most cult films labor under. In response, critics have described the use of viral marketing as astroturfing and an attempt to manufacture cult films.\nI. Q. Hunter identifies a prefabricated cult film style which includes \"deliberately, insulting bad films\", \"slick exercises in dysfunction and alienation\", and mainstream films \"that sell themselves as worth obsessing over\". Writing for NPR, Scott Tobias states that Don Coscarelli, whose previous films effortlessly attracted cult followings, has drifted into this realm. Tobias criticizes Coscarelli as trying too hard to appeal to cult audiences and sacrificing internal consistency for calculated quirkiness. Influenced by the successful online hype of \"The Blair Witch Project\" (1999), other films have attempted to draw online cult fandom with the use of prefabricated cult appeal. \"Snakes on a Plane\" (2006) is an example that attracted massive attention from curious fans. Uniquely, its cult following preceded the film's release and included speculative parodies of what fans imagined the film might be. This reached the point of convergence culture when fan speculation began to impact on the film's production. Although it was proclaimed a cult film and major game-changer before it was released, it failed to win either mainstream audiences or maintain its cult following. In retrospect, critic Spencer Kornhaber would call it a serendipitous novelty and a footnote to a \"more naive era of the Internet\". However, it became influential in both marketing and titling. This trend of \"instant cult classics\" which are hailed yet fail to attain a lasting following is described by Matt Singer, who states that the phrase is an oxymoron.\nCult films are often approached in terms of auteur theory, which states that the director's creative vision drives a film. This has fallen out of favor in academia, creating a disconnect between cult film fans and critics. Matt Hills states that auteur theory can help to create cult films; fans that see a film as continuing a director's creative vision are likely to accept it as cult. According to academic Greg Taylor, auteur theory also helped to popularize cult films when middlebrow audiences found an accessible way to approach avant-garde film criticism. Auteur theory provided an alternative culture for cult film fans while carrying the weight of scholarship. By requiring repeated viewings and extensive knowledge of details, auteur theory naturally appealed to cult film fans. Taylor further states that this was instrumental in allowing cult films to break through to the mainstream. Academic Joe Tompkins states that this auteurism is often highlighted when mainstream success occurs. This may take the place of\u00a0\u2013 and even ignore\u00a0\u2013 political readings of the director. Cult films and directors may be celebrated for their transgressive content, daring, and independence, but Tompkins argues that mainstream recognition requires they be palatable to corporate interests who stand to gain much from the mainstreaming of cult film culture. While critics may champion revolutionary aspects of filmmaking and political interpretation, Hollywood studios and other corporate interests will instead highlight only the aspects that they wish to legitimize in their own films, such as sensational exploitation. Someone like George A. Romero, whose films are both transgressive and subversive, will have the transgressive aspects highlighted while the subversive aspects are ignored."}
{"id": "5646", "revid": "20248368", "url": "https://en.wikipedia.org/wiki?curid=5646", "title": "Constantinople", "text": "Constantinople (see other names) was a historical city located on the Bosporus that served as the capital of the Roman, Byzantine, Latin, and Ottoman empires between its consecration in 330 until 1930, when it was renamed to Istanbul. Initially as New Rome, Constantinople was founded in 324 during the reign of Constantine the Great on the site of the existing settlement of Byzantium, and shortly thereafter in 330 became the capital of the Roman Empire. Following the collapse of the Western Roman Empire in the late 5th century, Constantinople remained the capital of the Eastern Roman Empire (also known as the Byzantine Empire; 330\u20131204 and 1261\u20131453), the Latin Empire (1204\u20131261), and the Ottoman Empire (1453\u20131922). Following the Turkish War of Independence, the Turkish capital then moved to Ankara. Officially renamed Istanbul in 1930, the city is today the largest city in Europe, straddling the Bosporus strait and lying in both Europe and Asia, and the financial center of Turkey.\nIn 324, following the reunification of the Eastern and Western Roman Empires, the ancient city of Byzantium was selected to serve as the new capital of the Roman Empire, and the city was renamed Nova Roma, or 'New Rome', by Emperor Constantine the Great. On 11 May 330, it was renamed Constantinople and dedicated to Constantine. Constantinople is generally considered to be the center and the \"cradle of Orthodox Christian civilization\". From the mid-5th century to the early 13th century, Constantinople was the largest and wealthiest city in Europe. The city became famous for its architectural masterpieces, such as Hagia Sophia, the cathedral of the Eastern Orthodox Church, which served as the seat of the Ecumenical Patriarchate; the sacred Imperial Palace, where the emperors lived; the Hippodrome; the Golden Gate of the Land Walls; and opulent aristocratic palaces. The University of Constantinople was founded in the 5th century and contained artistic and literary treasures before it was sacked in 1204 and 1453, including its vast Imperial Library which contained the remnants of the Library of Alexandria and had 100,000 volumes. The city was the home of the Ecumenical Patriarch of Constantinople and guardian of Christendom's holiest relics, such as the Crown of Thorns and the True Cross.\nConstantinople was famous for its massive and complex fortifications, which ranked among the most sophisticated defensive architectures of antiquity. The Theodosian Walls consisted of a double wall lying about to the west of the first wall and a moat with palisades in front. Constantinople's location between the Golden Horn and the Sea of Marmara reduced the land area that needed defensive walls. The city was built intentionally to rival Rome, and it was claimed that several elevations within its walls matched Rome's 'seven hills'. The impenetrable defenses enclosed magnificent palaces, domes, and towers, the result of prosperity Constantinople achieved as the gateway between two continents (Europe and Asia) and two seas (the Mediterranean and the Black Sea). Although besieged on numerous occasions by various armies, the defenses of Constantinople proved impenetrable for nearly nine hundred years.\nIn 1204, however, the armies of the Fourth Crusade took and devastated the city, and for several decades, its inhabitants resided under Latin occupation in a dwindling and depopulated city. In 1261, the Byzantine Emperor Michael VIII Palaiologos liberated the city, and after the restoration under the Palaiologos dynasty, it enjoyed a partial recovery. With the advent of the Ottoman Empire in 1299, the Byzantine Empire began to lose territories, and the city began to lose population. By the early 15th century, the Byzantine Empire was reduced to just Constantinople and its environs, along with Morea in Greece, making it an enclave inside the Ottoman Empire. The city was finally besieged and conquered by the Ottoman Empire in 1453, remaining under its control until the early 20th century, after which it was renamed Istanbul under the Empire's successor state, Turkey.\nNames.\nBefore Constantinople.\nAccording to Pliny the Elder in his \"Natural History\", the first known name of a settlement on the site of Constantinople was \"Lygos\", a settlement likely of Thracian origin founded between the 13th and 11th centuries BC. The site, according to the founding myth of the city, was abandoned by the time Greek settlers from the city-state of Megara founded \"Byzantium\" (, \"Byz\u00e1ntion\") in around 657\u00a0BC, across from the town of Chalcedon on the Asiatic side of the Bosphorus.\nThe origins of the name of \"Byzantion\", more commonly known by the later Latin \"Byzantium\", are not entirely clear, though some suggest it is of Thracian origin. The founding myth of the city has it told that the settlement was named after the leader of the Megarian colonists, Byzas. The later Byzantines of Constantinople themselves would maintain that the city was named in honor of two men, Byzas and Antes, though this was more likely just a play on the word Byzantion.\nThe city was briefly renamed \"Augusta Antonina\" in the early 3rd century AD by the Emperor Septimius Severus (193\u2013211), who razed the city to the ground in 196 for supporting a rival contender in the civil war and had it rebuilt in honor of his son Marcus Aurelius Antoninus (who succeeded him as Emperor), popularly known as Caracalla. The name appears to have been quickly forgotten and abandoned, and the city reverted to Byzantium/Byzantion after either the assassination of Caracalla in 217 or, at the latest, the fall of the Severan dynasty in 235.\nNames of Constantinople.\nByzantium took on the name of Constantinople (Greek: \u039a\u03c9\u03bd\u03c3\u03c4\u03b1\u03bd\u03c4\u03b9\u03bd\u03bf\u03cd\u03c0\u03bf\u03bb\u03b9\u03c2, romanized: \"K\u014dnstantinoupolis;\" \"city of Constantine\") after its refoundation under Roman emperor Constantine I, who transferred the capital of the Roman Empire to Byzantium in 330 and designated his new capital officially as \"Nova Roma\" () 'New Rome'. During this time, the city was also called 'Second Rome', 'Eastern Rome', and \"Roma Constantinopolitana\" (Latin for 'Constantinopolitan Rome'). As the city became the sole remaining capital of the Roman Empire after the fall of the West, and its wealth, population, and influence grew, the city also came to have a multitude of nicknames.\nAs the largest and wealthiest city in Europe during the 4th\u201313th centuries and a center of culture and education of the Mediterranean basin, Constantinople came to be known by prestigious titles such as \"Basileuousa\" (Queen of Cities) and \"Megalopolis\" (the Great City) and was, in colloquial speech, commonly referred to as just \"Polis\" () 'the City' by Constantinopolitans and provincial Byzantines alike.\nIn the language of other peoples, Constantinople was referred to just as reverently. The medieval Vikings, who had contacts with the empire through their expansion in eastern Europe (Varangians), used the Old Norse name \"Miklagar\u00f0r\" (from \"mikill\" 'big' and \"gar\u00f0r\" 'city'), and later \"Miklagard\" and \"Miklagarth\". In Arabic, the city was sometimes called \"R\u016bmiyyat al-Kubra\" (Great City of the Romans) and in Persian as \"Takht-e Rum\" (Throne of the Romans).\nIn East and South Slavic languages, including in Kievan Rus', Constantinople has been referred to as \"Tsargrad\" (\"\u0426\u0430\u0440\u044c\u0433\u0440\u0430\u0434\") or \"Carigrad\", 'City of the Caesar (Emperor)', from the Slavonic words \"tsar\" ('Caesar' or 'King') and \"grad\" ('city'). This was presumably a calque on a Greek phrase such as (\"Vasileos Polis\"), 'the city of the emperor [king]'.\nIn Persian the city was also called \"Asitane\" (the Threshold of the State), and in Armenian, it was called \"Gosdantnubolis\" (City of Constantine).\nModern names of the city.\nThe modern Turkish name for the city, \"\u0130stanbul\", derives from the Greek phrase \"eis tin Polin\" (), meaning '(in)to the city'. This name was used in colloquial speech in Turkish alongside \"Kostantiniyye\", the more formal adaptation of the original \"Constantinople\", during the period of Ottoman rule, while western languages mostly continued to refer to the city as Constantinople until the early 20th century. In 1928, the Turkish alphabet was changed from Arabic script to Latin script. After that, as part of the Turkification movement, Turkey started to urge other countries to use Turkish names for Turkish cities, instead of other transliterations to Latin script that had been used in Ottoman times and the city came to be known as Istanbul and its variations in most world languages.\nThe name \"Constantinople\" is still used by members of the Eastern Orthodox Church in the title of one of their most important leaders, the Orthodox patriarch based in the city, referred to as \"His Most Divine All-Holiness the Archbishop of Constantinople New Rome and Ecumenical Patriarch\". In Greece today, the city is still called \"Konstantino\u00fapoli(s)\" () or simply just \"the City\" ().\nHistory.\nFoundation of Byzantium.\nConstantinople was founded by the Roman emperor Constantine I (272\u2013337) in 324 on the site of an already-existing city, Byzantium, which was settled in the early days of Greek colonial expansion, in around 657 BC, by colonists of the city-state of Megara. This is the first major settlement that would develop on the site of later Constantinople, but the first known settlement was that of \"Lygos\", referred to in Pliny's Natural Histories. Apart from this, little is known about this initial settlement. The site, according to the founding myth of the city, was abandoned by the time Greek settlers from the city-state of Megara founded Byzantium () in around 657\u00a0 BC, across from the town of Chalcedon on the Asiatic side of the Bosphorus.\nHesychius of Miletus wrote that some \"claim that people from Megara, who derived their descent from Nisos, sailed to this place under their leader Byzas, and invent the fable that his name was attached to the city\". Some versions of the founding myth say Byzas was the son of a local nymph, while others say he was conceived by one of Zeus' daughters and Poseidon. Hesychius also gives alternate versions of the city's founding legend, which he attributed to old poets and writers:\n&lt;poem&gt;It is said that the first Argives, after having received this prophecy from Pythia,\n Blessed are those who will inhabit that holy city,\n a narrow strip of the Thracian shore at the mouth of the Pontos,\n where two pups drink of the gray sea,\n where fish and stag graze on the same pasture,\nset up their dwellings at the place where the rivers Kydaros and Barbyses have their estuaries, one flowing from the north, the other from the west, and merging with the sea at the altar of the nymph called Semestre\"&lt;/poem&gt;\nThe city maintained independence as a city-state until it was annexed by Darius I in 512\u00a0BC into the Persian Empire, who saw the site as the optimal location to construct a pontoon bridge crossing into Europe as Byzantium was situated at the narrowest point in the Bosphorus strait. Persian rule lasted until 478\u00a0BC when as part of the Greek counterattack to the Second Persian invasion of Greece, a Greek army led by the Spartan general Pausanias captured the city which remained an independent, yet subordinate, city under the Athenians, and later to the Spartans after 411\u00a0BC. A farsighted treaty with the emergent power of Rome in which stipulated tribute in exchange for independent status allowed it to enter Roman rule unscathed. This treaty would pay dividends retrospectively as Byzantium would maintain this independent status, and prosper under peace and stability in the Pax Romana, for nearly three centuries until the late 2nd century AD.\nByzantium was never a major influential city-state like Athens, Corinth or Sparta, but the city enjoyed relative peace and steady growth as a prosperous trading city because of its fortunate location. The site lay astride the land route from Europe to Asia and the seaway from the Black Sea to the Mediterranean, and had in the Golden Horn an excellent and spacious harbor. Already then, in Greek and early Roman times, Byzantium was famous for the strategic geographic position that made it difficult to besiege and capture, and its position at the crossroads of the Asiatic-European trade route over land and as the gateway between the Mediterranean and Black Seas made it too valuable a settlement to abandon, as Emperor Septimius Severus later realized when he razed the city to the ground for supporting Pescennius Niger's claimancy. It was a move greatly criticized by the contemporary consul and historian Cassius Dio who said that Severus had destroyed \"a strong Roman outpost and a base of operations against the barbarians from Pontus and Asia\". He would later rebuild Byzantium towards the end of his reign, in which it would be briefly renamed \"Augusta Antonina\", fortifying it with a new city wall in his name, the Severan Wall.\n324\u2013337: The refoundation as Constantinople.\nConstantine had altogether more colourful plans. Having restored the unity of the Empire, and, being in the course of major governmental reforms as well as of sponsoring the consolidation of the Christian church, he was well aware that Rome was an unsatisfactory capital. Rome was too far from the frontiers, and hence from the armies and the imperial courts, and it offered an undesirable playground for disaffected politicians. Yet it had been the capital of the state for over a thousand years, and it might have seemed unthinkable to suggest that the capital be moved to a different location. Nevertheless, Constantine identified the site of Byzantium as the right place: a place where an emperor could sit, readily defended, with easy access to the Danube or the Euphrates frontiers, his court supplied from the rich gardens and sophisticated workshops of Roman Asia, his treasuries filled by the wealthiest provinces of the Empire.\nConstantinople was built over six years, and consecrated on 11 May 330. Constantine divided the expanded city, like Rome, into 14 regions, and ornamented it with public works worthy of an imperial metropolis. Yet, at first, Constantine's new Rome did not have all the dignities of old Rome. It possessed a proconsul, rather than an urban prefect. It had no praetors, tribunes, or quaestors. Although it did have senators, they held the title \"clarus\", not \"clarissimus\", like those of Rome. It also lacked the panoply of other administrative offices regulating the food supply, police, statues, temples, sewers, aqueducts, or other public works. The new programme of building was carried out in great haste: columns, marbles, doors, and tiles were taken wholesale from the temples of the empire and moved to the new city. In similar fashion, many of the greatest works of Greek and Roman art were soon to be seen in its squares and streets. The emperor stimulated private building by promising householders gifts of land from the imperial estates in Asiana and Pontica and on 18 May 332 he announced that, as in Rome, free distributions of food would be made to the citizens. At the time, the amount is said to have been 80,000 rations a day, doled out from 117 distribution points around the city.\nConstantine laid out a new square at the centre of old Byzantium, naming it the Augustaeum. The new senate-house (or Curia) was housed in a basilica on the east side. On the south side of the great square was erected the Great Palace of the Emperor with its imposing entrance, the Chalke, and its ceremonial suite known as the Palace of Daphne. Nearby was the vast Hippodrome for chariot-races, seating over 80,000 spectators, and the famed Baths of Zeuxippus. At the western entrance to the Augustaeum was the Milion, a vaulted monument from which distances were measured across the Eastern Roman Empire.\nFrom the Augustaeum led a great street, the Mese, lined with colonnades. As it descended the First Hill of the city and climbed the Second Hill, it passed on the left the Praetorium or law-court. Then it passed through the oval Forum of Constantine where there was a second Senate-house and a high column with a statue of Constantine himself in the guise of Helios, crowned with a halo of seven rays and looking toward the rising sun. From there, the Mese passed on and through the Forum Tauri and then the Forum Bovis, and finally up the Seventh Hill (or Xerolophus) and through to the Golden Gate in the Constantinian Wall. After the construction of the Theodosian Walls in the early 5th century, it was extended to the new Golden Gate, reaching a total length of seven Roman miles. After the construction of the Theodosian Walls, Constantinople consisted of an area approximately the size of Old Rome within the Aurelian walls, or some 1,400 ha.\n337\u2013529: Constantinople during the Barbarian Invasions and the fall of the West.\nThe importance of Constantinople increased, but it was gradual. From the death of Constantine in 337 to the accession of Theodosius I, emperors had been resident only in the years 337\u2013338, 347\u2013351, 358\u2013361, 368\u2013369. Its status as a capital was recognized by the appointment of the first known Urban Prefect of the City Honoratus, who held office from 11 December 359 until 361. The urban prefects had concurrent jurisdiction over three provinces each in the adjacent dioceses of Thrace (in which the city was located), Pontus and Asia comparable to the 100-mile extraordinary jurisdiction of the prefect of Rome. The emperor Valens, who hated the city and spent only one year there, nevertheless built the Palace of Hebdomon on the shore of the Propontis near the Golden Gate, probably for use when reviewing troops. All the emperors up to Zeno and Basiliscus were crowned and acclaimed at the Hebdomon. Theodosius I founded the Church of John the Baptist to house the skull of the saint (today preserved at the Topkap\u0131 Palace), put up a memorial pillar to himself in the Forum of Taurus, and turned the ruined temple of Aphrodite into a coach house for the Praetorian Prefect; Arcadius built a new forum named after himself on the Mese, near the walls of Constantine.\nAfter the shock of the Battle of Adrianople in 378, in which Valens and the flower of the Roman armies were destroyed by the Visigoths within a few days' march, the city looked to its defences, and in 413\u2013414 Theodosius II built the 18-metre (60-foot)-tall triple-wall fortifications, which were not to be breached until the coming of gunpowder. Theodosius also founded a University near the Forum of Taurus, on 27 February 425.\nUldin, a prince of the Huns, appeared on the Danube about this time and advanced into Thrace, but he was deserted by many of his followers, who joined with the Romans in driving their king back north of the river. Subsequent to this, new walls were built to defend the city and the fleet on the Danube improved.\nAfter the barbarians overran the Western Roman Empire, Constantinople became the indisputable capital city of the Roman Empire. Emperors were no longer peripatetic between various court capitals and palaces. They remained in their palace in the Great City and sent generals to command their armies. The wealth of the eastern Mediterranean and western Asia flowed into Constantinople.\n527\u2013565: Constantinople in the Age of Justinian.\nThe emperor Justinian I (527\u2013565) was known for his successes in war, for his legal reforms and for his public works. It was from Constantinople that his expedition for the reconquest of the former Diocese of Africa set sail on or about 21 June 533. Before their departure, the ship of the commander Belisarius was anchored in front of the Imperial palace, and the Patriarch offered prayers for the success of the enterprise. After the victory, in 534, the Temple treasure of Jerusalem, looted by the Romans in AD\u00a070 and taken to Carthage by the Vandals after their sack of Rome in 455, was brought to Constantinople and deposited for a time, perhaps in the Church of St Polyeuctus, before being returned to Jerusalem in either the Church of the Resurrection or the New Church.\nChariot-racing had been important in Rome for centuries. In Constantinople, the hippodrome became over time increasingly a place of political significance. It was where (as a shadow of the popular elections of old Rome) the people by acclamation showed their approval of a new emperor, and also where they openly criticized the government, or clamoured for the removal of unpopular ministers. It played a crucial role during the riots and in times of political unrest. The Hippodrome provided a space for a crowd to be responded to positively or where the acclamations of a crowd were subverted, resorting to the riots that would ensue in coming years. In the time of Justinian, public order in Constantinople became a critical political issue.\nThroughout the late Roman and early Byzantine periods, Christianity was resolving fundamental questions of identity, and the dispute between the orthodox and the monophysites became the cause of serious disorder, expressed through allegiance to the chariot-racing parties of the Blues and the Greens. The partisans of the Blues and the Greens were said to affect untrimmed facial hair, head hair shaved at the front and grown long at the back, and wide-sleeved tunics tight at the wrist; and to form gangs to engage in night-time muggings and street violence. At last these disorders took the form of a major rebellion of 532, known as the \"Nika\" riots (from the battle-cry of \"Conquer!\" of those involved). The Nika Riots began in the Hippodrome and finished there with the onslaught of over 30,000 people according to Procopius, those in the blue and green factions, innocent and guilty. This came full circle on the relationship within the Hippodrome between the power and the people during the time of Justinian.\nFires started by the Nika rioters consumed the Theodosian basilica of Hagia Sophia (Holy Wisdom), the city's cathedral, which lay to the north of the Augustaeum and had itself replaced the Constantinian basilica founded by Constantius II to replace the first Byzantine cathedral, Hagia Irene (Holy Peace). Justinian commissioned Anthemius of Tralles and Isidore of Miletus to replace it with a new and incomparable Hagia Sophia. This was the great cathedral of the city, whose dome was said to be held aloft by God alone, and which was directly connected to the palace so that the imperial family could attend services without passing through the streets. \"The architectural form of the building was meant to reflect Justinian programmatic harmony: the circular dome (a symbol of secular authority in classical Roman architecture) would be harmoniously combined with the rectangular form (typical for Christian and pre-Christian temples).\" The dedication took place on 26 December 537 in the presence of the emperor, who was later reported to have exclaimed, \"O Solomon, I have outdone thee!\" Hagia Sophia was served by 600 people including 80 priests, and cost 20,000 pounds of gold to build.\nJustinian also had Anthemius and Isidore demolish and replace the original Church of the Holy Apostles and Hagia Irene built by Constantine with new churches under the same dedication. The Justinianic Church of the Holy Apostles was designed in the form of an equal-armed cross with five domes, and ornamented with beautiful mosaics. This church was to remain the burial place of the emperors from Constantine himself until the 11th century. When the city fell to the Turks in 1453, the church was demolished to make room for the tomb of Mehmet II the Conqueror. Justinian was also concerned with other aspects of the city's built environment, legislating against the abuse of laws prohibiting building within of the sea front, in order to protect the view.\nDuring Justinian I's reign, the city's population reached about 500,000 people. However, the social fabric of Constantinople was also damaged by the onset of the Plague of Justinian between 541 and 542 AD, It killed perhaps 40% of the city's inhabitants. Lasting two months, the plague is noted to have caused widespread civil disruption, including the inability of the population to bury the dead and attend relatives funerals.\nSurvival, 565\u2013717: Constantinople during the Byzantine Dark Ages.\nIn the early 7th century, the Avars and later the Bulgars overwhelmed much of the Balkans, threatening Constantinople with attack from the west. Simultaneously, the Persian Sassanids overwhelmed the Prefecture of the East and penetrated deep into Anatolia. Heraclius, son of the exarch of Africa, set sail for the city and assumed the throne. He found the military situation so dire that he is said to have contemplated withdrawing the imperial capital to Carthage, but relented after the people of Constantinople begged him to stay. The citizens lost their right to free grain in 618 when Heraclius realized that the city could no longer be supplied from Egypt as a result of the Persian wars: the population fell substantially as a result.\nWhile the city withstood a siege by the Sassanids and Avars in 626, Heraclius campaigned deep into Persian territory and briefly restored the \"status quo\" in 628, when the Persians surrendered all their conquests. However, further sieges followed the Arab conquests, first from 674 to 678 and then in 717 to 718. The Theodosian Walls kept the city impenetrable from the land, while a newly discovered incendiary substance known as Greek fire allowed the Byzantine navy to destroy the Arab fleets and keep the city supplied. In the second siege, the second ruler of Bulgaria, Khan Tervel, rendered decisive help. He was called \"Saviour of Europe\".\n717\u20131025: Constantinople during the Macedonian Renaissance.\nIn the 730s Leo III carried out extensive repairs of the Theodosian walls, which had been damaged by frequent and violent attacks; this work was financed by a special tax on all the subjects of the Empire.\nTheodora, widow of the Emperor Theophilus (died 842), acted as regent during the minority of her son Michael III, who was said to have been introduced to dissolute habits by her brother Bardas. When Michael assumed power in 856, he became known for excessive drunkenness, appeared in the hippodrome as a charioteer and burlesqued the religious processions of the clergy. He removed Theodora from the Great Palace to the Carian Palace and later to the monastery of Gastria, but, after the death of Bardas, she was released to live in the palace of St Mamas; she also had a rural residence at the Anthemian Palace, where Michael was assassinated in 867.\nIn 860, an attack was made on the city by a new principality set up a few years earlier at Kiev by Askold and Dir, two Varangian chiefs: Two hundred small vessels passed through the Bosporus and plundered the monasteries and other properties on the suburban Princes' Islands. Oryphas, the admiral of the Byzantine fleet, alerted the emperor Michael, who promptly put the invaders to flight; but the suddenness and savagery of the onslaught made a deep impression on the citizens.\nIn 980, the emperor Basil II received an unusual gift from Prince Vladimir of Kiev: 6,000 Varangian warriors, which Basil formed into a new bodyguard known as the Varangian Guard. They were known for their ferocity, honour, and loyalty. It is said that, in 1038, they were dispersed in winter quarters in the Thracesian Theme when one of their number attempted to violate a countrywoman, but in the struggle she seized his sword and killed him; instead of taking revenge, however, his comrades applauded her conduct, compensated her with all his possessions, and exposed his body without burial as if he had committed suicide. However, following the death of an Emperor, they became known also for plunder in the Imperial palaces. Later in the 11th century the Varangian Guard became dominated by Anglo-Saxons who preferred this way of life to subjugation by the new Norman kings of England.\nThe \"Book of the Eparch\", which dates to the 10th century, gives a detailed picture of the city's commercial life and its organization at that time. The corporations in which the tradesmen of Constantinople were organised were supervised by the Eparch, who regulated such matters as production, prices, import, and export. Each guild had its own monopoly, and tradesmen might not belong to more than one. It is an impressive testament to the strength of tradition how little these arrangements had changed since the office, then known by the Latin version of its title, had been set up in 330 to mirror the urban prefecture of Rome.\nIn the 9th and 10th centuries, Constantinople had a population of between 500,000 and 800,000.\nIconoclast controversy in Constantinople.\nIn the 8th and 9th centuries, the iconoclast movement caused serious political unrest throughout the Empire. The emperor Leo III issued a decree in 726 against images, and ordered the destruction of a statue of Christ over one of the doors of the Chalke, an act that was fiercely resisted by the citizens. Constantine V convoked a church council in 754, which condemned the worship of images, after which many treasures were broken, burned, or painted over with depictions of trees, birds or animals: One source refers to the church of the Holy Virgin at Blachernae as having been transformed into a \"fruit store and aviary\". Following the death of her husband Leo IV in 780, the empress Irene restored the veneration of images through the agency of the Second Council of Nicaea in 787.\nThe iconoclast controversy returned in the early 9th century, only to be resolved once more in 843 during the regency of Empress Theodora, who restored the icons. These controversies contributed to the deterioration of relations between the Western and the Eastern Churches.\n1025\u20131081: Constantinople after Basil II.\nIn the late 11th century catastrophe struck with the unexpected and calamitous defeat of the imperial armies at the Battle of Manzikert in Armenia in 1071. The Emperor Romanus Diogenes was captured. The peace terms demanded by Alp Arslan, sultan of the Seljuk Turks, were not excessive, and Romanus accepted them. On his release, however, Romanus found that enemies had placed their own candidate on the throne in his absence; he surrendered to them and suffered death by torture, and the new ruler, Michael VII Ducas, refused to honour the treaty. In response, the Turks began to move into Anatolia in 1073. The collapse of the old defensive system meant that they met no opposition, and the empire's resources were distracted and squandered in a series of civil wars. Thousands of Turkoman tribesmen crossed the unguarded frontier and moved into Anatolia. By 1080, a huge area had been lost to the Empire, and the Turks were within striking distance of Constantinople.\n1081\u20131185: Constantinople under the Komneni.\nUnder the Komnenian dynasty (1081\u20131185), Byzantium staged a remarkable recovery. In 1090\u201391, the nomadic Pechenegs reached the walls of Constantinople, where Emperor Alexius I with the aid of the Kipchaks annihilated their army. In response to a call for aid from Alexius, the First Crusade assembled at Constantinople in 1096, but declining to put itself under Byzantine command set out for Jerusalem on its own account. John II built the monastery of the Pantocrator (Almighty) with a hospital for the poor of 50 beds.\nWith the restoration of firm central government, the empire became fabulously wealthy. The population was rising (estimates for Constantinople in the 12th century vary from some 100,000 to 500,000), and towns and cities across the realm flourished. Meanwhile, the volume of money in circulation dramatically increased. This was reflected in Constantinople by the construction of the Blachernae palace, the creation of brilliant new works of art, and general prosperity at this time: an increase in trade, made possible by the growth of the Italian city-states, may have helped the growth of the economy. It is certain that the Venetians and others were active traders in Constantinople, making a living out of shipping goods between the Crusader Kingdoms of Outremer and the West, while also trading extensively with Byzantium and Egypt. The Venetians had factories on the north side of the Golden Horn, and large numbers of westerners were present in the city throughout the 12th century. Toward the end of Manuel I Komnenos's reign, the number of foreigners in the city reached about 60,000\u201380,000 people out of a total population of about 400,000 people. In 1171, Constantinople also contained a small community of 2,500 Jews. In 1182, most Latin (Western European) inhabitants of Constantinople were massacred.\nIn artistic terms, the 12th century was a very productive period. There was a revival in the mosaic art, for example: Mosaics became more realistic and vivid, with an increased emphasis on depicting three-dimensional forms. There was an increased demand for art, with more people having access to the necessary wealth to commission and pay for such work.\n1185\u20131261: Constantinople during the Imperial Exile.\nOn 25 July 1197, Constantinople was struck by a severe fire which burned the Latin Quarter and the area around the Gate of the Droungarios () on the Golden Horn. Nevertheless, the destruction wrought by the 1197 fire paled in comparison with that brought by the Crusaders. In the course of a plot between Philip of Swabia, Boniface of Montferrat and the Doge of Venice, the Fourth Crusade was, despite papal excommunication, diverted in 1203 against Constantinople, ostensibly promoting the claims of Alexios IV Angelos brother-in-law of Philip, son of the deposed emperor Isaac II Angelos. The reigning emperor Alexios III Angelos had made no preparation. The Crusaders occupied Galata, broke the defensive chain protecting the Golden Horn, and entered the harbour, where on 27 July they breached the sea walls: Alexios III fled. But the new Alexios IV Angelos found the Treasury inadequate, and was unable to make good the rewards he had promised to his western allies. Tension between the citizens and the Latin soldiers increased. In January 1204, the \"protovestiarius\" Alexios Murzuphlos provoked a riot, it is presumed, to intimidate Alexios IV, but whose only result was the destruction of the great statue of Athena Promachos, the work of Phidias, which stood in the principal forum facing west.\nIn February 1204, the people rose again: Alexios IV was imprisoned and executed, and Murzuphlos took the purple as Alexios V Doukas. He made some attempt to repair the walls and organise the citizenry, but there had been no opportunity to bring in troops from the provinces and the guards were demoralised by the revolution. An attack by the Crusaders on 6 April failed, but a second from the Golden Horn on 12 April succeeded, and the invaders poured in. Alexios V fled. The Senate met in Hagia Sophia and offered the crown to Theodore Lascaris, who had married into the Angelos dynasty, but it was too late. He came out with the Patriarch to the Golden Milestone before the Great Palace and addressed the Varangian Guard. Then the two of them slipped away with many of the nobility and embarked for Asia. By the next day the Doge and the leading Franks were installed in the Great Palace, and the city was given over to pillage for three days.\nSir Steven Runciman, historian of the Crusades, wrote that the sack of Constantinople is \"unparalleled in history\".\nFor the next half-century, Constantinople was the seat of the Latin Empire. Under the rulers of the Latin Empire, the city declined, both in population and the condition of its buildings. Alice-Mary Talbot cites an estimated population for Constantinople of 400,000 inhabitants; after the destruction wrought by the Crusaders on the city, about one third were homeless, and numerous courtiers, nobility, and higher clergy, followed various leading personages into exile. \"As a result Constantinople became seriously depopulated,\" Talbot concludes.\nThe Latins took over at least 20 churches and 13 monasteries, most prominently the Hagia Sophia, which became the cathedral of the Latin Patriarch of Constantinople. It is to these that E.H. Swift attributed the construction of a series of flying buttresses to shore up the walls of the church, which had been weakened over the centuries by earthquake tremors. However, this act of maintenance is an exception: for the most part, the Latin occupiers were too few to maintain all of the buildings, either secular and sacred, and many became targets for vandalism or dismantling. Bronze and lead were removed from the roofs of abandoned buildings and melted down and sold to provide money to the chronically under-funded Empire for defense and to support the court; Deno John Geanokoplos writes that \"it may well be that a division is suggested here: Latin laymen stripped secular buildings, ecclesiastics, the churches.\" Buildings were not the only targets of officials looking to raise funds for the impoverished Latin Empire: the monumental sculptures which adorned the Hippodrome and fora of the city were pulled down and melted for coinage. \"Among the masterpieces destroyed, writes Talbot, \"were a Herakles attributed to the fourth-century B.C. sculptor Lysippos, and monumental figures of Hera, Paris, and Helen.\"\nThe Nicaean emperor John III Vatatzes reportedly saved several churches from being dismantled for their valuable building materials; by sending money to the Latins \"to buy them off\" (\"exonesamenos\"), he prevented the destruction of several churches. According to Talbot, these included the churches of Blachernae, Rouphinianai, and St. Michael at Anaplous. He also granted funds for the restoration of the Church of the Holy Apostles, which had been seriously damaged in an earthquake.\nThe Byzantine nobility scattered, many going to Nicaea, where Theodore Lascaris set up an imperial court, or to Epirus, where Theodore Angelus did the same; others fled to Trebizond, where one of the Comneni had already with Georgian support established an independent seat of empire. Nicaea and Epirus both vied for the imperial title, and tried to recover Constantinople. In 1261, Constantinople was captured from its last Latin ruler, Baldwin II, by the forces of the Nicaean emperor Michael VIII Palaiologos under the command of Caesar Alexios Strategopoulos.\n1261\u20131453: Palaiologan Era and the Fall of Constantinople.\nAlthough Constantinople was retaken by Michael VIII Palaiologos, the Empire had lost many of its key economic resources, and struggled to survive. The palace of Blachernae in the north-west of the city became the main Imperial residence, with the old Great Palace on the shores of the Bosporus going into decline. When Michael VIII captured the city, its population was 35,000 people, but, by the end of his reign, he had succeeded in increasing the population to about 70,000 people. The Emperor achieved this by summoning former residents who had fled the city when the crusaders captured it, and by relocating Greeks from the recently reconquered Peloponnese to the capital. Military defeats, civil wars, earthquakes and natural disasters were joined by the Black Death, which in 1347 spread to Constantinople, exacerbated the people's sense that they were doomed by God.\nCastilian traveler and writer Ruy Gonz\u00e1lez de Clavijo, who saw Constantinople in 1403, wrote that the area within the city walls included small neighborhoods separated by orchards and fields. The ruins of palaces and churches could be seen everywhere. The aqueducts and the most densely inhabited neighborhoods were along the coast of the Marmara Sea and Golden Horn. Only the coastal areas, in particular the commercial areas facing the Golden Horn, had a dense population. Although the Genoese colony in Galata was small, it was overcrowded and had magnificent mansions.\nBy May 1453, the city no longer possessed the treasure troves of Aladdin that the Ottoman troops longingly imagined as they stared up at the walls. Gennadios Scholarios, Patriarch of Constantinople from 1454 to 1464, was saying that the capital of the Empire, that was once the \"city of wisdom\", became \"the city of ruins\".\nWhen the Ottoman Turks captured the city (1453) it contained approximately 50,000 people. Tedaldi of Florence estimated the population at 30,000 to 36,000, while in Chronica Vicentina, the Italian Andrei di Arnaldo estimated it at 50,000. The plague epidemic of 1435 must have caused the population to drop.\nThe population decline also had a huge impact upon the Constantinople's defense capabilities. At the end of March 1453, emperor Constantine XI ordered a census of districts to record how many able-bodied men were in the city and whatever weapons each possessed for defense. George Sphrantzes, the faithful chancellor of the last emperor, recorded that \"in spite of the great size of our city, our defenders amounted to 4,773 Greeks, as well as just 200 foreigners\". In addition there were volunteers from outside, the \"Genoese, Venetians and those who came secretly from Galata to help the defense\", who numbered \"hardly as many as three thousand\", amounting to something under 8,000 men in total to defend a perimeter wall of twelve miles.\nConstantinople was conquered by the Ottoman Empire on 29 May 1453. Mehmed II intended to complete his father's mission and conquer Constantinople for the Ottomans. In 1452 he reached peace treaties with Hungary and Venice. He also began the construction of the Bo\u011fazkesen (later called the Rumelihisar\u0131), a fortress at the narrowest point of the Bosphorus Strait, in order to restrict passage between the Black and Mediterranean seas. Mehmed then tasked the Hungarian gunsmith Urban with both arming Rumelihisar\u0131 and building cannon powerful enough to bring down the walls of Constantinople. By March 1453 Urban's cannon had been transported from the Ottoman capital of Edirne to the outskirts of Constantinople. In April, having quickly seized Byzantine coastal settlements along the Black Sea and Sea of Marmara, Ottoman troops in Rumelia and Anatolia assembled outside the Byzantine capital. Their fleet moved from Gallipoli to nearby Diplokionion, and the sultan himself set out to meet his army.\nThe Ottomans were commanded by 21-year-old Ottoman Sultan Mehmed II. The conquest of Constantinople followed a seven-week siege which had begun on 6 April 1453. The Empire fell on 29 May 1453.\nThe number of people captured by the Ottomans after the fall of the city was around 33,000. The small number of people left in the city indicates that there could not have been many residents there. The primary concern of Mehmed II in the early years of his reign was the construction and settlement of the city. However, since an insufficient number of Muslims accepted his invitation, the settlement of 30 abandoned neighborhoods with the inhabitants of formerly conquered areas became necessary.\n1453\u20131930: Ottoman and Republican Kostantiniyye.\nThe Christian Orthodox city of Constantinople was now under Ottoman control. As tradition followed for the region, Ottoman soldiers had three days to pillage the city. When Mehmed II on the second day entered Constantinople through the Gate of Charisius (today known as Edirnekap\u0131 or Adrianople Gate), it is said that first thing he did was ride his horse to Hagia Sophia, which was not in good shape even though it was avoided in the pillage by strict orders. Displeased by the pillaging, Mehmed II ordered it to end, for it will be the capital of his empire. He then ordered that an imam meet him in Hagia Sophia in order to chant the adhan thus transforming the Orthodox cathedral into a Muslim mosque, solidifying Islamic rule in Constantinople.\nMehmed's main concern with Constantinople had to do with consolidating control over the city and rebuilding its defenses. After 45,000 captives were marched from the city, building projects were commenced immediately after the conquest, which included the repair of the walls, construction of the citadel, and building a new palace. Mehmed issued orders across his empire that Muslims, Christians, and Jews should resettle the city, with Christians and Jews required to pay \"jizya\" and Muslims pay Zakat; he demanded that five thousand households needed to be transferred to Constantinople by September. From all over the Islamic empire, prisoners of war and deported people were sent to the city: these people were called \"S\u00fcrg\u00fcn\" in Turkish (). Two centuries later, Ottoman traveler Evliya \u00c7elebi gave a list of groups introduced into the city with their respective origins. Even today, many quarters of Istanbul, such as Aksaray, \u00c7ar\u015famba, bear the names of the places of origin of their inhabitants. However, many people escaped again from the city, and there were several outbreaks of plague, so that in 1459 Mehmed allowed the deported Greeks to come back to the city.\nCulture.\nConstantinople was the largest and richest urban center in the Eastern Mediterranean Sea during the late Eastern Roman Empire, mostly as a result of its strategic position commanding the trade routes between the Aegean Sea and the Black Sea. It would remain the capital of the eastern, Greek-speaking empire for over a thousand years and in some ways is the nexus of Byzantine art production. At its peak, roughly corresponding to the Middle Ages, it was one of the richest and largest cities in Europe. It exerted a powerful cultural pull and dominated much of the economic life in the Mediterranean. Visitors and merchants were especially struck by the beautiful monasteries and churches of the city, in particular the Hagia Sophia, or the Church of Holy Wisdom. According to Russian 14th-century traveler Stephen of Novgorod: \"There is much that amazes one there, which the human mind cannot express\".\nIt was especially important for preserving in its libraries manuscripts of Greek and Latin authors throughout a period when instability and disorder caused their mass-destruction in western Europe and north Africa: On the city's fall, thousands of these were brought by refugees to Italy, and played a key part in stimulating the Renaissance, and the transition to the modern world. The cumulative influence of the city on the west, over the many centuries of its existence, is incalculable. In terms of technology, art and culture, as well as sheer size, Constantinople was without parallel anywhere in Europe for a thousand years. Many languages were spoken in Constantinople. A 16th century Chinese geographical treatise specifically recorded that there were translators living in the city, indicating it was multilingual, multicultural, and cosmopolitan. \nWomen in literature.\nConstantinople was home to the first known Western Armenian journal published and edited by a woman (Elpis Kesaratsian). Entering circulation in 1862, \"Kit'arr\" or \"Guitar\" stayed in print for only seven months. Female writers who openly expressed their desires were viewed as immodest, but this changed slowly as journals began to publish more \"women's sections\". In the 1880s, Matteos Mamurian invited Srpouhi Dussap to submit essays for \"Arevelian Mamal\". According to Zaruhi Galemkearian's autobiography, she was told to write about women's place in the family and home after she published two volumes of poetry in the 1890s. By 1900, several Armenian journals had started to include works by female contributors including the Constantinople-based \"Tsaghik\".\nMarkets.\nEven before Constantinople was founded, the markets of Byzantion were mentioned first by Xenophon and then by Theopompus who wrote that Byzantians \"spent their time at the market and the harbour\". In Justinian's age the \"Mese\" street running across the city from east to west was a daily market. Procopius claimed \"more than 500 prostitutes\" did business along the market street. Ibn Batutta who traveled to the city in 1325 wrote of the bazaars \"Astanbul\" in which the \"majority of the artisans and salespeople in them are women\".\nArchitecture and coinage.\nThe Byzantine Empire used Roman and Greek architectural models and styles to create its own unique type of architecture. The influence of Byzantine architecture and art can be seen in the copies taken from it throughout Europe. Particular examples include St Mark's Basilica in Venice, the basilicas of Ravenna, and many churches throughout the Slavic East. Also, alone in Europe until the 13th-century Italian florin, the Empire continued to produce sound gold coinage, the solidus of Diocletian becoming the bezant prized throughout the Middle Ages. Its city walls were much imitated (for example, see Caernarfon Castle) and its urban infrastructure was moreover a marvel throughout the Middle Ages, keeping alive the art, skill and technical expertise of the Roman Empire. In the Ottoman period Islamic architecture and symbolism were used. \nGreat bathhouses were built in Byzantine centers such as Constantinople and Antioch.\nReligion.\nConstantine's foundation gave prestige to the Bishop of Constantinople, who eventually came to be known as the Ecumenical Patriarch, and made it a prime center of Christianity alongside Rome. This contributed to cultural and theological differences between Eastern and Western Christianity eventually leading to the Great Schism that divided Western Catholicism from Eastern Orthodoxy from 1054 onwards. Constantinople is also of great religious importance to Islam, as the conquest of Constantinople is one of the signs of the End time in Islam.\nEducation.\nThere were many institutions in ancient Constantinople such as the Imperial University of Constantinople, sometimes known as the University of the Palace Hall of Magnaura (), an Eastern Roman educational institution that could trace its corporate origins to 425 AD, when the emperor Theodosius II founded the Pandidacterium ().\nMedia.\nFilm.\nThe first film shown in Constantinople (and the Ottoman Empire) was, \"L'Arriv\u00e9e d'un train en gare de La Ciotat\", by the Lumi\u00e8re Brothers in 1896.\nThe first film made in Constantinople (and the Ottoman Empire) was, \"Ayastefanos'taki Rus Abidesinin Y\u0131k\u0131l\u0131\u015f\u0131,\" by Fuat Uzk\u0131nay in 1914.\nNewspaper.\nIn the past the Bulgarian newspapers in the late Ottoman period were \"Makedoniya\", \"Napred\u016dk\", and \"Pravo\".\nBetween 1908 (after the Young Turk Revolution) and 1914 (start of World War I) the \"\"Kurdistan\" Newspaper\" was published in Constantinople by Mikdad Midhad Bedir Khan, before that it was published in exile in Cairo, Egypt.\nInternational status.\nThe city acted as a defence for the eastern provinces of the old Roman Empire against the barbarian invasions of the 5th century. The 18-meter-tall walls built by Theodosius II were, in essence, impregnable to the barbarians coming from south of the Danube river, who found easier targets to the west rather than the richer provinces to the east in Asia. From the 5th century, the city was also protected by the Anastasian Wall, a 60-kilometer chain of walls across the Thracian peninsula. Many scholars argue that these sophisticated fortifications allowed the east to develop relatively unmolested while Ancient Rome and the west collapsed.\nConstantinople's fame was such that it was described even in contemporary Chinese histories, the \"Old\" and \"New Book of Tang\", which mentioned its massive walls and gates as well as a purported clepsydra mounted with a golden statue of a man. The Chinese histories even related how the city had been besieged in the 7th century by Mu'awiya I and how he exacted tribute in a peace settlement."}
{"id": "5647", "revid": "33049997", "url": "https://en.wikipedia.org/wiki?curid=5647", "title": "Columbus", "text": "Columbus is a Latinized version of the Italian surname \"Colombo\". It most commonly refers to:\nColumbus may also refer to:"}
{"id": "5648", "revid": "12845131", "url": "https://en.wikipedia.org/wiki?curid=5648", "title": "Cornwall", "text": "Cornwall (; ; ; or ) is a ceremonial county in South West England. It is recognised by Cornish and Celtic political groups as one of the Celtic nations, and is the homeland of the Cornish people. The county is bordered by the Atlantic Ocean to the north and west, Devon to the east, and the English Channel to the south. The largest urban area in the county is a conurbation that includes the former mining towns of Redruth and Camborne, and the county town is the city of Truro.\nThe county is rural, with an area of and population of 568,210. Outside of the Redruth-Camborne conurbation the largest settlements are Falmouth, Penzance, Newquay, St Austell, and Truro. For local government purposes most of Cornwall is a unitary authority area, with the Isles of Scilly having a unique local authority. The Cornish nationalist movement disputes the constitutional status of Cornwall and seeks greater autonomy within the United Kingdom.\nCornwall is the westernmost part of the South West Peninsula, and the southernmost county within the United Kingdom. Its coastline is characterised by steep cliffs and, to the south, several rias, including those at the mouths of the rivers Fal and Fowey. It includes the southernmost point on Great Britain, Lizard Point, and forms a large part of the Cornwall National Landscape. The national landscape also includes Bodmin Moor, an upland outcrop of the Cornubian batholith granite formation. The county contains many short rivers; the longest is the Tamar, which forms the border with Devon.\nCornwall had a minor Roman presence, and later formed part of the Brittonic kingdom of Dumnonia. From the 7th century, the Britons in the South West increasingly came into conflict with the expanding Anglo-Saxon kingdom of Wessex, eventually being pushed west of the Tamar; by the Norman Conquest Cornwall was administered as part of England, though it retained its own culture. The remainder of the Middle Ages and Early Modern Period were relatively settled, with Cornwall developing its tin mining industry and becoming a duchy in 1337. During the Industrial Revolution, the tin and copper mines were expanded and then declined, with china clay extraction becoming a major industry. Railways were built, leading to a growth of tourism in the 20th century. The Cornish language became extinct as a living community language at the end of the 18th century, but is now being revived.\nName.\nThe modern English name \"Cornwall\" is a compound of two terms coming from two different language groups:\nIn the Cornish language, Cornwall is \"Kernow\" which stems from the same Proto-Celtic root.\nHistory.\nPrehistory, Roman and post-Roman periods.\nHumans reoccupied Britain after the last Ice Age. The area now known as Cornwall was first inhabited in the Palaeolithic and Mesolithic periods. It continued to be occupied by Neolithic and then by Bronze Age people.\nCornwall in the Late Bronze Age formed part of a maritime trading-networked culture which researchers have dubbed the Atlantic Bronze Age system, and which extended over most of the areas of present-day Ireland, England, Wales, France, Spain, and Portugal.\nDuring the British Iron Age, Cornwall, like all of Britain (modern England, Scotland, Wales, and the Isle of Man), was inhabited by a Celtic-speaking people known as the Britons with distinctive cultural relations to neighbouring Brittany. The Common Brittonic spoken at this time eventually developed into several distinct tongues, including Cornish, Welsh, Breton, Cumbric and Pictish.\nThe first written account of Cornwall comes from the 1st-century BC Sicilian Greek historian Diodorus Siculus, supposedly quoting or paraphrasing the 4th-century BCE geographer Pytheas, who had sailed to Britain:\nThe identity of these merchants is unknown. It has been theorized that they were Phoenicians, but there is no evidence for this. Professor Timothy Champion, discussing Diodorus Siculus's comments on the tin trade, states that \"Diodorus never actually says that the Phoenicians sailed to Cornwall. In fact, he says quite the opposite: the production of Cornish tin was in the hands of the natives of Cornwall, and its transport to the Mediterranean was organized by local merchants, by sea and then overland through France, passing through areas well outside Phoenician control.\" Isotopic evidence suggests that tin ingots found off the coast of Haifa, Israel, may have been from Cornwall. Tin, required for the production of bronze, was a relatively rare and precious commodity in the Bronze Age \u2013 hence the interest shown in Devon and Cornwall's tin resources. (For further discussion of tin mining see the section on the economy below.)\nIn the first four centuries AD, during the time of Roman dominance in Britain, Cornwall was rather remote from the main centres of Romanization \u2013 the nearest being Isca Dumnoniorum, modern-day Exeter. However, the Roman road system extended into Cornwall with four significant Roman sites based on forts: Tregear near Nanstallon was discovered in the early 1970s, two others were found at Restormel Castle, Lostwithiel in 2007, and a third fort near Calstock was also discovered early in 2007. In addition, a Roman-style villa was found at Magor Farm, Illogan in 1935. Ptolemy's \"Geographike Hyphegesis\" mentions four towns controlled by the Dumnonii, three of which may have been in Cornwall. However, after 410 AD, Cornwall appears to have reverted to rule by Romano-Celtic chieftains of the Cornovii tribe as part of the Brittonic kingdom of Dumnonia (which also included present-day Devonshire and the Scilly Isles), including the territory of one Marcus Cunomorus, with at least one significant power base at Tintagel in the early 6th century.\nKing Mark of Cornwall is a semi-historical figure known from Welsh literature, from the Matter of Britain, and, in particular, from the later Norman-Breton medieval romance of Tristan and Yseult, where he appears as a close relative of King Arthur, himself usually considered to be born of the Cornish people in folklore traditions derived from Geoffrey of Monmouth's 12th-century \"Historia Regum Britanniae\".\nArchaeology supports ecclesiastical, literary and legendary evidence for some relative economic stability and close cultural ties between the sub-Roman Westcountry, South Wales, Brittany, the Channel Islands, and Ireland through the fifth and sixth centuries. In Cornwall, the arrival of Celtic saints such as Nectan, Paul Aurelian, Petroc, Piran, Samson and numerous others reinforced the preexisting Roman Christianity.\nConflict with Wessex.\nThe Battle of Deorham in 577 saw the separation of Dumnonia (and therefore Cornwall) from Wales, following which the Dumnonii often came into conflict with the expanding English kingdom of Wessex. Centwine of Wessex \"drove the Britons as far as the sea\" in 682, and by 690 St Bonifice, then a Saxon boy, was attending an abbey in Exeter, which was in turn ruled by a Saxon abbot. The Carmen Rhythmicum written by Aldhelm contains the earliest literary reference to Cornwall as distinct from Devon. Religious tensions between the Dumnonians (who celebrated celtic Christian traditions) and Wessex (who were Roman Catholic) are described in Aldhelm's letter to King Geraint. The \"Annales Cambriae\" report that in AD 722 the Britons of Cornwall won a battle at \"Hehil\". It seems likely that the enemy the Cornish fought was a West Saxon force, as evidenced by the naming of King Ine of Wessex and his kinsman Nonna in reference to an earlier Battle of Llongborth in 710.\nThe \"Anglo-Saxon Chronicle\" stated in 815 (adjusted date) \"and in this year king Ecgbryht raided in Cornwall from east to west.\" this has been interpreted to mean a raid from the Tamar to Land's End, and the end of Cornish independence. However, the \"Anglo-Saxon Chronicle\" states that in 825 (adjusted date) a battle took place between the Wealas (Cornish) and the Defnas (men of Devon) at Gafulforda. The Cornish giving battle here, and the later battle at Hingston Down, casts doubt on any claims of control Wessex had at this stage.\nIn 838, the Cornish and their Danish allies were defeated by Egbert in the Battle of Hingston Down at Hengestesdune. In 875, the last recorded king of Cornwall, Dumgarth, is said to have drowned. Around the 880s, Anglo-Saxons from Wessex had established modest land holdings in the north eastern part of Cornwall; notably Alfred the Great who had acquired a few estates. William of Malmesbury, writing around 1120, says that King Athelstan of England (924\u2013939) fixed the boundary between English and Cornish people at the east bank of the River Tamar. While elements of William's story, like the burning of Exeter, have been cast in doubt by recent writers Athelstan did re-establish a separate Cornish Bishop and relations between Wessex and the Cornish elite improved from the time of his rule.\nEventually King Edgar was able to issue charters the width of Cornwall, and frequently sent emissaries or visited personally as seen by his appearances in the Bodmin Manumissions.\nBreton\u2013Norman period.\nOne interpretation of the Domesday Book is that by this time the native Cornish landowning class had been almost completely dispossessed and replaced by English landowners, particularly Harold Godwinson himself. However, the Bodmin manumissions show that two leading Cornish figures nominally had Saxon names, but these were both glossed with native Cornish names. In 1068, Brian of Brittany may have been created Earl of Cornwall, and naming evidence cited by medievalist Edith Ditmas suggests that many other post-Conquest landowners in Cornwall were Breton allies of the Normans, the Bretons being descended from Britons who had fled to what is today Brittany during the early years of the Anglo-Saxon conquest. She also proposed this period for the early composition of the Tristan and Iseult cycle by poets such as B\u00e9roul from a pre-existing shared Brittonic oral tradition.\nSoon after the Norman conquest most of the land was transferred to the new Breton\u2013Norman aristocracy, with the lion's share going to Robert, Count of Mortain, half-brother of King William and the largest landholder in England after the king with his stronghold at Trematon Castle near the mouth of the Tamar.\nLater medieval administration and society.\nSubsequently, however, Norman absentee landlords became replaced by a new Cornish-Norman ruling class including scholars such as Richard Rufus of Cornwall. These families eventually became the new rulers of Cornwall, typically speaking Norman French, Breton-Cornish, Latin, and eventually English, with many becoming involved in the operation of the Stannary Parliament system, the Earldom and eventually the Duchy of Cornwall. The Cornish language continued to be spoken and acquired a number of characteristics establishing its identity as a separate language from Breton.\nStannary parliaments.\nThe stannary parliaments and stannary courts were legislative and legal institutions in Cornwall and in Devon (in the Dartmoor area). The stannary courts administered equity for the region's tin-miners and tin mining interests, and they were also courts of record for the towns dependent on the mines. The separate and powerful government institutions available to the tin miners reflected the enormous importance of the tin industry to the English economy during the Middle Ages. Special laws for tin miners pre-date written legal codes in Britain, and ancient traditions exempted everyone connected with tin mining in Cornwall and Devon from any jurisdiction other than the stannary courts in all but the most exceptional circumstances.\nPiracy and smuggling.\nCornish piracy was active during the Elizabethan era on the west coast of Britain. Cornwall is well known for its wreckers who preyed on ships passing Cornwall's rocky coastline. During the 17th and 18th centuries Cornwall was a major smuggling area.\nHeraldry.\nIn later times, Cornwall was known to the Anglo-Saxons as \"West Wales\" to distinguish it from \"North Wales\" (the modern nation of Wales). The name appears in the \"Anglo-Saxon Chronicle\" in 891 as \"On Corn walum\". In the Domesday Book it was referred to as \"Cornualia\" and in c. 1198 as \"Cornwal\". Other names for the county include a latinisation of the name as \"Cornubia\" (first appears in a mid-9th-century deed purporting to be a copy of one dating from c. 705), and as \"Cornugallia\" in 1086.\nPhysical geography.\nCornwall forms the tip of the south-west peninsula of the island of Great Britain, and is therefore exposed to the full force of the prevailing winds that blow in from the Atlantic Ocean. The coastline is composed mainly of resistant rocks that give rise in many places to tall cliffs. Cornwall has a border with only one other county, Devon, which is formed almost entirely by the River Tamar, and the remainder (to the north) by the Marsland Valley.\nCoastal areas.\nThe north and south coasts have different characteristics. The north coast on the Celtic Sea, part of the Atlantic Ocean, is more exposed and therefore has a wilder nature. The \"High Cliff\", between Boscastle and St Gennys, is the highest sheer-drop cliff in Cornwall at . Beaches, which form an important part of the tourist industry, include Bude, Polzeath, Watergate Bay, Perranporth, Porthtowan, Fistral Beach, Newquay, St Agnes, St Ives, and on the south coast Gyllyngvase beach in Falmouth and the large beach at Praa Sands further to the south-west. There are two river estuaries on the north coast: Hayle Estuary and the estuary of the River Camel, which provides Padstow and Rock with a safe harbour. The seaside town of Newlyn is a popular holiday destination, as it is one of the last remaining traditional Cornish fishing ports, with views reaching over Mount's Bay.\nThe south coast, dubbed the \"Cornish Riviera\", is more sheltered and there are several broad estuaries offering safe anchorages, such as at Falmouth and Fowey. Beaches on the south coast usually consist of coarser sand and shingle, interspersed with rocky sections of wave-cut platform. Also on the south coast, the picturesque fishing village of Polperro, at the mouth of the Pol River, and the fishing port of Looe on the River Looe are both popular with tourists.\nInland areas.\nThe interior of the county consists of a roughly east\u2013west spine of infertile and exposed upland, with a series of granite intrusions, such as Bodmin Moor, which contains the highest land within Cornwall. From east to west, and with approximately descending altitude, these are Bodmin Moor, Hensbarrow north of St Austell, Carnmenellis to the south of Camborne, and the Penwith or Land's End peninsula. These intrusions are the central part of the granite outcrops that form the exposed parts of the Cornubian batholith of south-west Britain, which also includes Dartmoor to the east in Devon and the Isles of Scilly to the west, the latter now being partially submerged.\nThe intrusion of the granite into the surrounding sedimentary rocks gave rise to extensive metamorphism and mineralisation, and this led to Cornwall being one of the most important mining areas in Europe until the early 20th century. It is thought tin was mined here as early as the Bronze Age, and copper, lead, zinc and silver have all been mined in Cornwall. Alteration of the granite also gave rise to extensive deposits of China Clay, especially in the area to the north of St Austell, and the extraction of this remains an important industry.\nThe uplands are surrounded by more fertile, mainly pastoral farmland. Near the south coast, deep wooded valleys provide sheltered conditions for flora that like shade and a moist, mild climate. These areas lie mainly on Devonian sandstone and slate. The north east of Cornwall lies on Carboniferous rocks known as the Culm Measures. In places these have been subjected to severe folding, as can be seen on the north coast near Crackington Haven and in several other locations.\nLizard Peninsula.\nThe geology of the Lizard peninsula is unusual, in that it is mainland Britain's only example of an ophiolite, a section of oceanic crust now found on land. Much of the peninsula consists of the dark green and red Precambrian serpentinite, which forms spectacular cliffs, notably at Kynance Cove, and carved and polished serpentine ornaments are sold in local gift shops. This ultramafic rock also forms a very infertile soil which covers the flat and marshy heaths of the interior of the peninsula. This is home to rare plants, such as the Cornish Heath, which has been adopted as the county flower.\nSettlements and transport.\nCornwall's only city, and the home of the council headquarters, is Truro. Nearby Falmouth is notable as a port. St Just in Penwith is the westernmost town in England, though the same claim has been made for Penzance, which is larger. St Ives and Padstow are today small vessel ports with a major tourism and leisure sector in their economies. Newquay on the north coast is another major urban settlement which is known for its beaches and is a popular surfing destination, as is Bude further north, but Newquay is now also becoming important for its aviation-related industries. Camborne is the county's largest town and more populous than the county town Truro. Together with the neighbouring town of Redruth, it forms the largest urban area in Cornwall, and both towns were significant as centres of the global tin mining industry in the 19th century; nearby copper mines were also very productive during that period. St Austell is also larger than Truro and was the centre of the china clay industry in Cornwall. Until four new parishes were created for the St Austell area on 1 April 2009 St Austell was the largest settlement in Cornwall.\nCornwall borders the county of Devon at the River Tamar. Major roads between Cornwall and the rest of Great Britain are the A38 which crosses the Tamar at Plymouth via the Tamar Bridge and the town of Saltash, the A39 road (Atlantic Highway) from Barnstaple, passing through North Cornwall to end in Falmouth, and the A30 which connects Cornwall to the M5 motorway at Exeter, crosses the border south of Launceston, crosses Bodmin Moor and connects Bodmin, Truro, Redruth, Camborne, Hayle and Penzance. Torpoint Ferry links Plymouth with Torpoint on the opposite side of the Hamoaze. A rail bridge, the Royal Albert Bridge built by Isambard Kingdom Brunel (1859), provides the other main land transport link. The city of Plymouth, a large urban centre in south west Devon, is an important location for services such as hospitals, department stores, road and rail transport, and cultural venues, particularly for people living in east Cornwall.\nCardiff and Swansea, across the Bristol Channel, have at some times in the past been connected to Cornwall by ferry, but these do not operate now.\nThe Isles of Scilly are served by ferry (from Penzance) and by aeroplane, having its own airport: St Mary's Airport. There are regular flights between St Mary's and Land's End Airport, near St Just, and Newquay Airport; during the summer season, a service is also provided between St Mary's and Exeter Airport, in Devon.\nEcology.\nFlora and fauna.\nCornwall has varied habitats including terrestrial and marine ecosystems. One noted species in decline locally is the Reindeer lichen, which species has been made a priority for protection under the national UK Biodiversity Action Plan.\nBotanists divide Cornwall and Scilly into two vice-counties: West (1) and East (2). The standard flora is by F. H. Davey \"Flora of Cornwall\" (1909). Davey was assisted by A. O. Hume and he thanks Hume, his companion on excursions in Cornwall and Devon, and for help in the compilation of that Flora, publication of which was financed by him.\nClimate.\nCornwall has a temperate Oceanic climate (K\u00f6ppen climate classification: \"Cfb\"), with mild winters and cool summers. Cornwall has the mildest and one of the sunniest climates of the United Kingdom, as a result of its oceanic setting and the influence of the Gulf Stream. The average annual temperature in Cornwall ranges from on the Isles of Scilly to in the central uplands. Winters are among the warmest in the country due to the moderating effects of the warm ocean currents, and frost and snow are very rare at the coast and are also rare in the central upland areas. Summers are, however, not as warm as in other parts of southern England. The surrounding sea and its southwesterly position mean that Cornwall's weather can be relatively changeable.\nCornwall is one of the sunniest areas in the UK. It has more than 1,541 hours of sunshine per year, with the highest average of 7.6 hours of sunshine per day in July. The moist, mild air coming from the southwest brings higher amounts of rainfall than in eastern Great Britain, at per year. However, this is not as much as in more northern areas of the west coast. The Isles of Scilly, for example, where there are on average fewer than two days of air frost per year, is the only area in the UK to be in the Hardiness zone 10. The islands have, on average, less than one day of air temperature exceeding 30\u00a0\u00b0C per year and are in the AHS Heat Zone 1. Extreme temperatures in Cornwall are particularly rare; however, extreme weather in the form of storms and floods is common. Due to climate change Cornwall faces more heatwaves and severe droughts, faster coastal erosion, stronger storms and higher wind speeds as well as the possibility of more high-impact flooding.\nCulture.\nLanguage.\nCornish language.\n \nCornish, a member of the Brythonic branch of the Celtic language family, died out as a first language in the late 18th century. In the 20th and 21st centuries, it has been revived by a small number of speakers. It is closely related to the other Brythonic languages (Breton and Welsh), and less so to the Goidelic languages. Cornish has no legal status in the UK.\nThere has been a revival of the language by academics and optimistic enthusiasts since the mid-19th century that gained momentum from the publication in 1904 of Henry Jenner's \"Handbook of the Cornish Language\". It is a social networking community language rather than a social community group language. Cornwall Council encourages and facilitates language classes within the county, in schools and within the wider community.\nIn 2002, Cornish was named as a UK regional language in the European Charter for Regional or Minority Languages. As a result, in 2005 its promoters received limited government funding. Several words originating in Cornish are used in the mining terminology of English, such as costean, gossan, gunnies, kibbal, kieve and vug.\nEnglish dialect.\nThe Cornish language and culture influenced the emergence of particular pronunciations and grammar not used elsewhere in England. The Cornish dialect is spoken to varying degrees; however, someone speaking in broad Cornish may be practically unintelligible to one not accustomed to it. Cornish dialect has generally declined, as in most places it is now little more than a regional accent and grammatical differences have been eroded over time. Marked differences in vocabulary and usage still exist between the eastern and western parts of Cornwall.\nFlag.\nSaint Piran's Flag is the national flag and ancient banner of Cornwall, and an emblem of the Cornish people. The banner of Saint Piran is a white cross on a black background (in terms of heraldry 'sable, a cross argent'). According to legend Saint Piran adopted these colours from seeing the white tin in the black coals and ashes during his discovery of tin. The Cornish flag is an exact reverse of the former Breton black cross national flag and is known by the same name \"Kroaz Du\".\nArts and media.\nSince the 19th century, Cornwall, with its unspoilt maritime scenery and strong light, has sustained a vibrant visual art scene of international renown. Artistic activity within Cornwall was initially centred on the art-colony of Newlyn, most active at the turn of the 20th century. This Newlyn School is associated with the names of Stanhope Forbes, Elizabeth Forbes, Norman Garstin and Lamorna Birch. Modernist writers such as D. H. Lawrence and Virginia Woolf lived in Cornwall between the wars, and Ben Nicholson, the painter, having visited in the 1920s came to live in St Ives with his then wife, the sculptor Barbara Hepworth, at the outbreak of the Second World War. They were later joined by the Russian emigrant Naum Gabo, and other artists. These included Peter Lanyon, Terry Frost, Patrick Heron, Bryan Wynter and Roger Hilton. St Ives also houses the Leach Pottery, where Bernard Leach, and his followers championed Japanese inspired studio pottery. Much of this modernist work can be seen in Tate St Ives. The Newlyn Society and Penwith Society of Arts continue to be active, and contemporary visual art is documented in a dedicated online journal.\nLocal television programmes are provided by BBC South West &amp; ITV West Country. Radio programmes are produced by BBC Radio Cornwall in Truro for the entire county, Heart West, Source FM for the Falmouth and Penryn areas, Coast FM for west Cornwall, Radio St Austell Bay for the St Austell area, NCB Radio for north Cornwall &amp; Pirate FM.\nMusic.\nCornwall has a folk music tradition that has survived into the present and is well known for its unusual folk survivals such as Mummers Plays, the Furry Dance in Helston played by the famous Helston Town Band, and Obby Oss in Padstow.\nNewlyn is home to a food and music festival that hosts live music, cooking demonstrations, and displays of locally caught fish.\nAs in other former mining districts of Britain, male voice choirs and brass bands, such as \"Brass on the Grass\" concerts during the summer at Constantine, are still very popular in Cornwall. Cornwall also has around 40 brass bands, including the six-times National Champions of Great Britain, Camborne Youth Band, and the bands of Lanner and St Dennis.\nCornish players are regular participants in inter-Celtic festivals, and Cornwall itself has several inter-Celtic festivals such as Perranporth's Lowender Peran folk festival.\nContemporary musician Richard D. James (also known as Aphex Twin) grew up in Cornwall, as did Luke Vibert and Alex Parks, winner of Fame Academy 2003. Roger Taylor, the drummer from the band Queen was also raised in the county, and currently lives not far from Falmouth. The American singer-songwriter Tori Amos now resides predominantly in North Cornwall not far from Bude with her family. The lutenist, composer and festival director Ben Salfield lives in Truro. Mick Fleetwood of Fleetwood Mac was born in Redruth.\nLiterature.\nCornwall's rich heritage and dramatic landscape have inspired numerous writers.\nFiction.\nSir Arthur Quiller-Couch, author of many novels and works of literary criticism, lived in Fowey: his novels are mainly set in Cornwall. Daphne du Maurier lived at Menabilly near Fowey and many of her novels had Cornish settings: \"The Loving Spirit\", \"Jamaica Inn\", \"Rebecca\", \"Frenchman's Creek\", \"The King's General\" (partially), \"My Cousin Rachel\", \"The House on the Strand\" and \"Rule Britannia\". She is also noted for writing \"Vanishing Cornwall\". Cornwall provided the inspiration for \"The Birds\", one of her terrifying series of short stories, made famous as a film by Alfred Hitchcock. \nConan Doyle's \"The Adventure of the Devil's Foot\" featuring Sherlock Holmes is set in Cornwall. Winston Graham's series \"Poldark\", Kate Tremayne's Adam Loveday series, Susan Cooper's novels \"Over Sea, Under Stone\" and \"Greenwitch\", and Mary Wesley's \"The Camomile Lawn\" are all set in Cornwall. Writing under the pseudonym of Alexander Kent, Douglas Reeman sets parts of his Richard Bolitho and Adam Bolitho series in the Cornwall of the late 18th and the early 19th centuries, particularly in Falmouth. Gilbert K. Chesterton placed the action of many of his stories there.\nMedieval Cornwall is the setting of the trilogy by Monica Furlong, \"Wise Child\", \"Juniper\" and \"Colman\", as well as part of Charles Kingsley's \"Hereward the Wake\".\nHammond Innes's novel, \"The Killer Mine\"; Charles de Lint's novel \"The Little Country\"; and Chapters 24\u201325 of J. K. Rowling's \"Harry Potter and the Deathly Hallows\" take place in Cornwall (Shell Cottage, on the beach outside the fictional village of Tinworth).\nDavid Cornwell, who wrote espionage novels under the name John le Carr\u00e9, lived and worked in Cornwall. Nobel Prize-winning novelist William Golding was born in St Columb Minor in 1911, and returned to live near Truro from 1985 until his death in 1993. D. H. Lawrence spent a short time living in Cornwall. Rosamunde Pilcher grew up in Cornwall, and several of her books take place there.\nSt. Michael's Mount in Cornwall (under the fictional name of Mount Polbearne) is the setting of the Little Beach Street Bakery series by Jenny Colgan, who spent holidays in Cornwall as a child. The book series includes \"Little Beach Street Bakery\" (2014), \"Summer at Little Beach Street Bakery\" (2015), \"Christmas at Little Beach Street Bakery\" (2016), and \"Sunrise by the Sea\" (2021).\nIn the \"Paddington Bear\" novels by Michael Bond the title character is said to have landed at an unspecified port in Cornwall having travelled in a lifeboat aboard a cargo ship from darkest Peru. From here he travels to London on a train and eventually arrives at Paddington Station.\nEnid Blyton's 1953 novel \"Five Go Down to the Sea\" (the twelfth book in \"The Famous Five\" series) is set in Cornwall, near the fictional coastal village of Tremannon.\nPoetry.\nThe late Poet Laureate Sir John Betjeman was famously fond of Cornwall and it featured prominently in his poetry. He is buried in the churchyard at St Enodoc's Church, Trebetherick.\nCharles Causley, the poet, was born in Launceston and is perhaps the best known of Cornish poets. Jack Clemo and the scholar A. L. Rowse were also notable Cornishmen known for their poetry; The Rev. R. S. Hawker of Morwenstow wrote some poetry which was very popular in the Victorian period. The Scottish poet W. S. Graham lived in West Cornwall from 1944 until his death in 1986.\nThe poet Laurence Binyon wrote \"For the Fallen\" (first published in 1914) while sitting on the cliffs between Pentire Point and The Rumps and a stone plaque was erected in 2001 to commemorate the fact. The plaque bears the inscription \"FOR THE FALLEN / Composed on these cliffs, 1914\". The plaque also bears below this the fourth stanza (sometimes referred to as \"The Ode\") of the poem:\nOther literary works.\nCornwall produced a substantial number of passion plays such as the Ordinalia during the Middle Ages. Many are still extant, and provide valuable information about the Cornish language. See also Cornish literature\nColin Wilson, a prolific writer who is best known for his debut work \"The Outsider\" (1956) and for \"The Mind Parasites\" (1967), lived in Gorran Haven, a small village on the southern Cornish coast. The writer D. M. Thomas was born in Redruth but lived and worked in Australia and the United States before returning to his native Cornwall. He has written novels, poetry, and other works, including translations from Russian.\nThomas Hardy's drama \"The Queen of Cornwall\" (1923) is a version of the Tristan story; the second act of Richard Wagner's opera \"Tristan und Isolde\" takes place in Cornwall, as do Gilbert and Sullivan's operettas \"The Pirates of Penzance\" and \"Ruddigore\".\nClara Vyvyan was the author of various books about many aspects of Cornish life such as \"Our Cornwall\". She once wrote: \"The Loneliness of Cornwall is a loneliness unchanged by the presence of men, its freedoms a freedom inexpressible by description or epitaph. Your cannot say Cornwall is this or that. Your cannot describe it in a word or visualise it in a second. You may know the country from east to west and sea to sea, but if you close your eyes and think about it no clear-cut image rises before you. In this quality of changefulness have we possibly surprised the secret of Cornwall's wild spirit\u2014in this intimacy the essence of its charm? Cornwall!\".\nA level of \"\", a game dealing with Arthurian Legend, takes place in Cornwall at a museum above King Arthur's tomb. The adventure game \"The Lost Crown\" is set in the fictional town of Saxton, which uses the Cornish settlements of Polperro, Talland and Looe as its model.\nThe fairy tale Jack the Giant Killer takes place in Cornwall.\n\"The Mousehole Cat\", a children's book written by Antonia Barber and illustrated by Nicola Bayley, is set in the Cornish village Mousehole and based on the legend of Tom Bawcock and the continuing tradition of Tom Bawcock's Eve.\nSports.\nThe main sports played in Cornwall are rugby, football and cricket. Athletes from Truro have done well in Olympic and Commonwealth Games fencing, winning several medals. Surfing is popular, particularly with tourists, thousands of whom take to the water throughout the summer months. Some towns and villages have bowling clubs, and a wide variety of British sports are played throughout Cornwall. Cornwall is also one of the few places in England where shinty is played; the English Shinty Association is based in Penryn.\nThe Cornwall County Cricket Club plays as one of the minor counties of English cricket.\nTruro, and all of the towns and some villages have football clubs belonging to the Cornwall County Football Association, and some clubs have teams competing higher within the English football league pyramid. Of these, the highest ranked \u2014 by two flights \u2014 is Truro City F.C., who will be playing in the National League South in the 2023\u201324 season. Other notable Cornish teams include Mousehole A.F.C., Helston Athletic F.C., and Falmouth Town F.C.\nRugby football.\nViewed as an \"important identifier of ethnic affiliation\", rugby union has become a sport strongly tied to notions of Cornishness. and since the 20th century, rugby union has emerged as one of the most popular spectator and team sports in Cornwall (perhaps the most popular), with professional Cornish rugby footballers being described as a \"formidable force\", \"naturally independent, both in thought and deed, yet paradoxically staunch English patriots whose top players have represented England with pride and passion\".\nIn 1985, sports journalist Alan Gibson made a direct connection between the love of rugby in Cornwall and the ancient parish games of hurling and wrestling that existed for centuries before rugby officially began. Among Cornwall's native sports are a distinctive form of Celtic wrestling related to Breton wrestling, and Cornish hurling, a kind of mediaeval football played with a silver ball (distinct from Irish Hurling). Cornish Wrestling is Cornwall's oldest sport and as Cornwall's native tradition it has travelled the world to places like Victoria, Australia and Grass Valley, California following the miners and gold rushes. Cornish hurling now takes place at St. Columb Major, St Ives, and less frequently at Bodmin.\nIn rugby league, Cornwall R.L.F.C., founded in 2021, will represent the county in the professional league system. The semi-pro club will start in the third tier RFL League 1. At an amateur level, the county is represented by Cornish Rebels.\nSurfing and watersports.\nDue to its long coastline, various maritime sports are popular in Cornwall, notably sailing and surfing. International events in both are held in Cornwall. Cornwall hosted the Inter-Celtic Watersports Festival in 2006. Surfing in particular is very popular, as locations such as Bude and Newquay offer some of the best surf in the UK. Pilot gig rowing has been popular for many years and the World championships takes place annually on the Isles of Scilly. On 2 September 2007, 300 surfers at Polzeath beach set a new world record for the highest number of surfers riding the same wave as part of the Global Surf Challenge and part of a project called Earthwave to raise awareness about global warming.\nFencing.\nAs its population is comparatively small, and largely rural, Cornwall's contribution to British national sport in the United Kingdom has been limited; the county's greatest successes have come in fencing. In 2014, half of the men's GB team fenced for Truro Fencing Club, and 3 Truro fencers appeared at the 2012 Olympics.\nCuisine.\nCornwall has a strong culinary heritage. Surrounded on three sides by the sea amid fertile fishing grounds, Cornwall naturally has fresh seafood readily available; Newlyn is the largest fishing port in the UK by value of fish landed, and is known for its wide range of restaurants. Television chef Rick Stein has long operated a fish restaurant in Padstow for this reason, and Jamie Oliver chose to open his second restaurant, Fifteen, in Watergate Bay near Newquay. \"MasterChef\" host and founder of Smiths of Smithfield, John Torode, in 2007 purchased Seiners in Perranporth. One famous local fish dish is Stargazy pie, a fish-based pie in which the heads of the fish stick through the piecrust, as though \"star-gazing\". The pie is cooked as part of traditional celebrations for Tom Bawcock's Eve, but is not generally eaten at any other time.\nCornwall is perhaps best known though for its pasties, a savoury dish made with pastry. Today's pasties usually contain a filling of beef steak, onion, potato and swede with salt and white pepper, but historically pasties had a variety of different fillings. \"Turmut, 'tates and mate\" (i.e. \"Turnip, potatoes and meat\", turnip being the Cornish and Scottish term for swede, itself an abbreviation of 'Swedish Turnip', the British term for rutabaga) describes a filling once very common. For instance, the licky pasty contained mostly leeks, and the herb pasty contained watercress, parsley, and shallots. Pasties are often locally referred to as \"oggies\". Historically, pasties were also often made with sweet fillings such as jam, apple and blackberry, plums or cherries.\nThe wet climate and relatively poor soil of Cornwall make it unsuitable for growing many arable crops. However, it is ideal for growing the rich grass required for dairying, leading to the production of Cornwall's other famous export, clotted cream. This forms the basis for many local specialities including Cornish fudge and Cornish ice cream. Cornish clotted cream has Protected Geographical Status under EU law, and cannot be made anywhere else. Its principal manufacturer is A. E. Rodda &amp; Son of Scorrier.\nLocal cakes and desserts include Saffron cake, Cornish heavy (\"hevva\") cake, Cornish fairings biscuits, figgy 'obbin, Cream tea and whortleberry pie.\nThere are also many types of beers brewed in Cornwall\u2014those produced by Sharp's Brewery, Skinner's Brewery, Keltek Brewery and St Austell Brewery are the best known\u2014including stouts, ales and other beer types. There is some small scale production of wine, mead and cider.\nPolitics and administration.\nCornish national identity.\n Cornwall is recognised by Cornish and Celtic political groups as one of six Celtic nations, alongside Brittany, Ireland, the Isle of Man, Scotland and Wales. (The Isle of Man Government and the Welsh Government also recognise Asturias and Galicia.) Cornwall is represented, as one of the Celtic nations, at the \"Festival Interceltique de Lorient\", an annual celebration of Celtic culture held in Brittany.\nCornwall Council consider Cornwall's unique cultural heritage and distinctiveness to be one of the area's major assets. They see Cornwall's language, landscape, Celtic identity, political history, patterns of settlement, maritime tradition, industrial heritage, and non-conformist tradition, to be among the features making up its \"distinctive\" culture. However, it is uncertain exactly how many of the people living in Cornwall consider themselves to be Cornish; results from different surveys (including the national census) have varied. In the 2001 census, 7 per cent of people in Cornwall identified themselves as Cornish, rather than British or English. However, activists have argued that this underestimated the true number as there was no explicit \"Cornish\" option included in the official census form. Subsequent surveys have suggested that as many as 44 per cent identify as Cornish. Many people in Cornwall say that this issue would be resolved if a Cornish option became available on the census. The question and content recommendations for the 2011 census provided an explanation of the process of selecting an ethnic identity which is relevant to the understanding of the often quoted figure of 37,000 who claimed Cornish identity. The 2021 census found that 17% of people in Cornwall identified as being Cornish (89,000), with 14% of people in Cornwall identifying as Cornish-only (80,000). Again there was no tick-box provided, and \"Cornish\" had to be written-in as \"Other\".\nOn 24 April 2014 it was announced that Cornish people have been granted minority status under the European Framework Convention for the Protection of National Minorities.\nLocal politics.\nThe ceremonial county of Cornwall is made up of two local government districts; mainland Cornwall, governed by Cornwall Council, and the Isles of Scilly. Cornwall Council, formerly \"Cornwall County Council\" until 2009, is a unitary authority based at Lys Kernow in Truro. The Isles of Scilly are governed by the \"sui generis\" Council of the Isles of Scilly based in Hugh Town, and have been administered by their own unitary authority since 1890. They are grouped with Cornwall for other administrative purposes, such as the National Health Service and Devon and Cornwall Police. The county's Crown Court is based at the Courts of Justice in Truro. Magistrates' Courts are found in Truro (but at a different location to the Crown Court) and at Bodmin.\nCornwall County Council was established in 1889 under the Local Government Act 1888, and the Local Government Act 1972 reorganised the county's second tier of administration with the formation of six district councils: Caradon, Carrick, Kerrier, North Cornwall, Penwith, and Restormel. In 2009, structural changes to local government in England resulted in the abolition of the six district councils and turned Cornwall Council into a unitary authority. While projected to streamline services, cut red tape and save around \u00a317\u00a0million a year, the reorganisation was met with wide opposition, with a poll in 2008 showing 89% disapproval from Cornish residents.\nThe first elections for the unitary authority were held on 4 June 2009. At the most recent council election in 2021, the Conservative Party won 47 of the 87 seats. Also elected were 16 independent councillors, 13 Liberal Democrats, five from the Labour Party, five from Mebyon Kernow and one Green Party representative. Before the creation of the unitary council, the former county council had 82 seats, the majority of which were held by the Liberal Democrats, elected at the 2005 county council elections. The six former districts had a total of 249 council seats, and the groups with greatest numbers of councillors were Liberal Democrats, Conservatives and Independents.\nParliament and national politics.\nUntil 1832, Cornwall was represented by 44 Members of Parliament (MPs) in the House of Commons\u2014more than any other county\u2014reflecting the importance of tin mining to the Crown. Most of the increase in numbers of MPs came between 1529 and 1584 after which there was no change until the Reform Act 1832, which enacted widespread changes to the country's electoral system and reduced Cornwall's number of MPs to 14. This was reduced further in subsequent boundary commission reviews to better reflect Cornwall's population. The county is currently divided into six county constituencies.\nThe Liberal Party and its successor, the Liberal Democrats, have traditionally been popular in Cornwall; the Liberals won every Cornish seat in 1906 and January 1910, and again in 1929 despite the party finishing third nationally. The Liberal Democrats won every seat in the county in 2005, but lost seats to the Conservatives in 2010 before being wiped out in 2015. The Conservatives won all six Cornish seats in 2015, 2017 and 2019. Following expectation of a Conservative defeat at the 2024 general election, Cornwall was considered a three-party battleground. The Conservatives lost all six seats and the county is currently represented by four Labour and two Liberal Democrat MPs.\nAlthough Cornwall does not have a designated government department, in 2007 while Leader of the Opposition David Cameron created a Shadow Secretary of State for Cornwall. The position was not made into a formal UK Cabinet position when Cameron entered government following the 2010 United Kingdom general election\n! rowspan=2 colspan=2 style=text-align:left; | Party\n! colspan=5 | Votes (%)\n! 2010\n! 2015\n! 2017\n! 2019\n! 2024\n! colspan=\"2\" style=\"text-align:left;\" | Total\n! 280,881\n! 294,828\n! 314,709\n! 322,079\n! 294,228\nDevolution movement.\nCornish nationalists have organised into two political parties: Mebyon Kernow, formed in 1951, and the Cornish Nationalist Party. In addition to the political parties, there are various interest groups such as the Revived Cornish Stannary Parliament and the Celtic League. The Cornish Constitutional Convention was formed in 2000 as a cross-party organisation including representatives from the private, public and voluntary sectors to campaign for the creation of a Cornish Assembly, along the lines of the National Assembly for Wales, Northern Ireland Assembly and the Scottish Parliament. Between 5 March 2000 and December 2001, the campaign collected the signatures of 41,650 Cornish residents endorsing the call for a devolved assembly, along with 8,896 signatories from outside Cornwall. The resulting petition was presented to the Prime Minister, Tony Blair.\nEconomy.\nCornwall is one of the poorest parts of the United Kingdom in terms of per capita GDP and average household incomes. At the same time, parts of the county, especially on the coast, have high house prices, driven up by demand from relatively wealthy retired people and second-home owners. The GVA per head was 65% of the UK average for 2004. The GDP per head for Cornwall and the Isles of Scilly was 79.2% of the EU-27 average for 2004, the UK per head average was 123.0%. In 2011, the latest available figures, Cornwall's (including the Isles of Scilly) measure of wealth was 64% of the European average per capita.\nHistorically mining of tin (and later also of copper) was important in the Cornish economy. The first reference to this appears to be by Pytheas: \"see above\". Julius Caesar was the last classical writer to mention the tin trade, which appears to have declined during the Roman occupation. The tin trade revived in the Middle Ages and its importance to the Kings of England resulted in certain privileges being granted to the tinners; the Cornish rebellion of 1497 is attributed to grievances of the tin miners. In the mid-19th century, however, the tin trade again fell into decline. Other primary sector industries that have declined since the 1960s include china clay production, fishing and farming.\nToday, the Cornish economy depends heavily on its tourist industry, which makes up around a quarter of the economy. The official measures of deprivation and poverty at district and 'sub-ward' level show that there is great variation in poverty and prosperity in Cornwall with some areas among the poorest in England and others among the top half in prosperity. For example, the ranking of 32,482 sub-wards in England in the index of multiple deprivation (2006) ranged from 819th (part of Penzance East) to 30,899th (part of Saltash Burraton in Caradon), where the lower number represents the greater deprivation.\nCornwall was one of two UK areas designated as 'less developed regions' by the European Union, which, prior to Brexit, meant the area qualified for EU Cohesion Policy grants. It was granted Objective 1 status by the European Commission for 2000 to 2006, followed by further rounds of funding known as 'Convergence Funding' from 2007 to 2013 and 'Growth Programme' for 2014 to 2020.\nTourism.\nCornwall has a tourism-based seasonal economy which is estimated to contribute up to 24% of Cornwall's gross domestic product. In 2011 tourism brought \u00a31.85\u00a0billion into the Cornish economy. Cornwall's unique culture, spectacular landscape and mild climate make it a popular tourist destination, despite being somewhat distant from the United Kingdom's main centres of population. Surrounded on three sides by the English Channel and Celtic Sea, Cornwall has many miles of beaches and cliffs; the South West Coast Path follows a complete circuit of both coasts. Other tourist attractions include moorland, country gardens, museums, historic and prehistoric sites, and wooded valleys. Five million tourists visit Cornwall each year, mostly drawn from within the UK. Visitors to Cornwall are served by the airport at Newquay, whilst private jets, charters and helicopters are also served by Perranporth airfield; nightsleeper and daily rail services run between Cornwall, London and other regions of the UK.\nNewquay and Porthtowan are popular destinations for surfers. In recent years, the Eden Project near St Austell has been a major financial success, drawing one in eight of Cornwall's visitors in 2004.\nIn the summer of 2018, due to the recognition of its beaches and weather through social media and the marketing of travel companies, Cornwall received about 20 per cent more visitors than the usual 4.5\u00a0million figure. The sudden rise and demand of tourism in Cornwall caused multiple traffic and safety issues in coastal areas.\nIn October 2021, Cornwall was longlisted for the UK City of Culture 2025, but failed to make the March 2022 shortlist.\nFishing.\nOther industries include fishing, although this has been significantly re-structured by EU fishing policies ( the Southwest Handline Fishermen's Association has started to revive the fishing industry).\nAgriculture.\nAgriculture, once an important part of the Cornish economy, has declined significantly relative to other industries. However, there is still a strong dairy industry, with products such as Cornish clotted cream.\nMining.\nMining of tin and copper was also an industry, but today the derelict mine workings survive only as a World Heritage Site. However, the Camborne School of Mines, which was relocated to Penryn in 2004, is still a world centre of excellence in the field of mining and applied geology and the grant of World Heritage status has attracted funding for conservation and heritage tourism. China clay extraction has also been an important industry in the St Austell area, but this sector has been in decline, and this, coupled with increased mechanisation, has led to a decrease in employment in this sector, although the industry still employs around 2,133 people in Cornwall, and generates over \u00a380\u00a0million to the local economy.\nIn March 2016, a Canadian company, Strongbow Exploration, had acquired, from administration, a 100% interest in the South Crofty tin mine and the associated mineral rights in Cornwall with the aim of reopening the mine and bringing it back to full production. Work is currently ongoing to build a water filtration plant in order to dewater the mine.\nInternet.\nCornwall is the landing point for twenty-two of the world's fastest high-speed undersea and transatlantic fibre optic cables, making Cornwall an important hub within Europe's Internet infrastructure. The Superfast Cornwall project completed in 2015, and saw 95% of Cornish houses and businesses connected to a fibre-based broadband network, with over 90% of properties able to connect with speeds above 24\u00a0Mbit/s.\nAerospace.\nThe county's newest industry is aviation: Newquay Airport is the home of a growing business park with Enterprise Zone status, known as Aerohub. Also a space launch facility, Spaceport Cornwall, has been established at Newquay, in partnership with Goonhilly satellite tracking station near Helston in south Cornwall.\nDemographics.\nCornwall's population was 537,400 in the 2011 census, with a population density of 144 people per square kilometre, ranking it 40th and 41st, respectively, among the 47 counties of England. Cornwall's population was 95.7% White British and has a relatively high rate of population growth. At 11.2% in the 1980s and 5.3% in the 1990s, it had the fifth-highest population growth rate of the counties of England. The natural change has been a small population decline, and the population increase is due to inward migration into Cornwall. According to the 1991 census, the population was 469,800.\nCornwall has a relatively high retired population, with 22.9% of pensionable age, compared with 20.3% for the United Kingdom as a whole. This may be due partly to Cornwall's rural and coastal geography increasing its popularity as a retirement location, and partly to outward migration of younger residents to more economically diverse areas.\nEducation.\nOver 10,000 students attend Cornwall's two universities, Falmouth University and the University of Exeter (including Camborne School of Mines). Falmouth University is a specialist public university for the creative industries and arts, while the University Of Exeter has two campuses in Cornwall, Truro and Penryn, the latter shared with Falmouth. Penryn campus is home to educational departments such as the rapidly growing Centre for Ecology and Conservation (CEC), the Environment and Sustainability Institute (ESI), and the Institute of Cornish Studies.\nCornwall has a comprehensive education system, with 31 state and eight independent secondary schools. There are three further education colleges: Truro and Penwith College, Cornwall College and Callywith College which opened in September 2017. The Isles of Scilly only has one school, while the former Restormel district has the highest school population, and school year sizes are around 200, with none above 270. Before the introduction of comprehensive schools there were a number of grammar schools and secondary modern schools, e.g. the schools that later became Sir James Smith's School and Wadebridge School. There are also primary schools in many villages and towns: e.g. St Mabyn Church of England Primary School."}
{"id": "5649", "revid": "8729451", "url": "https://en.wikipedia.org/wiki?curid=5649", "title": "Constitutional monarchy", "text": "Constitutional monarchy, also known as limited monarchy, parliamentary monarchy or democratic monarchy, is a form of monarchy in which the monarch exercises their authority in accordance with a constitution and is not alone in making decisions. Constitutional monarchies differ from absolute monarchies (in which a monarch is the only decision-maker) in that they are bound to exercise powers and authorities within limits prescribed by an established legal framework. A constitutional monarch in a parliamentary democracy is a hereditary symbolic head of state (who may be an emperor, king or queen, prince or grand duke) who mainly performs representative and civic roles but does not exercise executive or policy-making power. \nConstitutional monarchies range from countries such as Liechtenstein, Monaco, Morocco, Jordan, Kuwait, Bahrain and Bhutan, where the constitution grants substantial discretionary powers to the sovereign, to countries such as the United Kingdom and other Commonwealth realms, the Netherlands, Spain, Belgium, Denmark, Norway, Sweden, Lesotho, Malaysia, Thailand, Cambodia, and Japan, where the monarch retains significantly less, if any, personal discretion in the exercise of their authority. On the surface level, this distinction may be hard to establish, with numerous liberal democracies restraining monarchic power in practice rather than written law, e.g., the constitution of the United Kingdom, which affords the monarch substantial, if limited, legislative and executive powers.\n\"Constitutional monarchy\" may refer to a system in which the monarch acts as a non-party political ceremonial head of state under the constitution, whether codified or uncodified. While most monarchs may hold formal authority and the government may legally operate in the monarch's name, in the form typical in Europe the monarch no longer personally sets public policy or chooses political leaders. Political scientist Vernon Bogdanor, paraphrasing Thomas Macaulay, has defined a constitutional monarch as \"A sovereign who reigns but does not rule\".\nIn addition to acting as a visible symbol of national unity, a constitutional monarch may hold formal powers such as dissolving parliament or giving royal assent to legislation. However, such powers generally may only be exercised strictly in accordance with either written constitutional principles or unwritten constitutional conventions, rather than any personal political preferences of the sovereign. \nIn \"The English Constitution\", British political theorist Walter Bagehot identified three main political rights which a constitutional monarch may freely exercise: the right to be consulted, the right to encourage, and the right to warn. Many constitutional monarchies still retain significant authorities or political influence, however, such as through certain reserve powers, and may also play an important political role.\nThe Commonwealth realms share the same person as hereditary monarchy under the Westminster system of constitutional governance. Two constitutional monarchies\u00a0\u2013 Malaysia and Cambodia\u00a0\u2013 are elective monarchies, in which the ruler is periodically selected by a small electoral college.\nThe concept of semi-constitutional monarch identifies constitutional monarchies where the monarch retains substantial powers, on a par with a president in a presidential or semi-presidential system. As a result, constitutional monarchies where the monarch has a largely ceremonial role may also be referred to as \"parliamentary monarchies\" to differentiate them from semi-constitutional monarchies. Strongly limited constitutional monarchies, such as those of the United Kingdom and Australia, have been referred to as crowned republics by writers H. G. Wells and Glenn Patmore.\nHistory.\nThe oldest constitutional monarchy dating back to ancient times was that of the Hittites. They were an ancient Anatolian people that lived during the Bronze Age whose king had to share his authority with an assembly, called the \"Panku\", which was the equivalent to a modern-day deliberative assembly or a legislature. Members of the \"Panku\" came from scattered noble families who worked as representatives of their subjects in an adjutant or subaltern federal-type landscape.\nAccording to Herodotus, Demonax created a constitutional monarchy for King Battus III the Lame, of Cyrene, when Cyrenaica had become an unstable state, in about 548 BC.\nConstitutional and absolute monarchy.\nEngland, Scotland and the United Kingdom.\nIn the Kingdom of England, the Glorious Revolution of 1688 furthered the constitutional monarchy, restricted by laws such as the Bill of Rights 1689 and the Act of Settlement 1701, although the first form of constitution was enacted with Magna Carta of 1215. At the same time, in Scotland, the Convention of Estates enacted the Claim of Right Act 1689, which placed similar limits on the Scottish monarchy.\nQueen Anne was the last monarch to veto an Act of Parliament when, on 11 March 1708, she blocked the Scottish Militia Bill. However Hanoverian monarchs continued to selectively dictate government policies. For instance King George III constantly blocked Catholic Emancipation, eventually precipitating the resignation of William Pitt the Younger as prime minister in 1801. The sovereign's influence on the choice of prime minister gradually declined over this period. King William IV was the last monarch to dismiss a prime minister, when in 1834 he removed Lord Melbourne as a result of Melbourne's choice of Lord John Russell as Leader of the House of Commons. Queen Victoria was the last monarch to exercise real personal power, but this diminished over the course of her reign. In 1839, she became the last sovereign to keep a prime minister in power against the will of Parliament when the Bedchamber crisis resulted in the retention of Lord Melbourne's administration. By the end of her reign, however, she could do nothing to block the unacceptable (to her) premierships of William Gladstone, although she still exercised power in appointments to the Cabinet. For example, in 1886 she vetoed Gladstone's choice of Hugh Childers as War Secretary in favour of Sir Henry Campbell-Bannerman.\nToday, the role of the British monarch is by convention effectively ceremonial. The British Parliament and the Government \u2013 chiefly in the office of Prime Minister of the United Kingdom \u2013 exercise their powers under \"royal (or Crown) prerogative\": on behalf of the monarch and through powers still formally possessed by the monarch.\nNo person may accept significant public office without swearing an oath of allegiance to the King. With few exceptions, the monarch is bound by constitutional convention to act on the advice of the government.\nContinental Europe.\nPoland developed the first constitution for a monarchy in continental Europe, with the Constitution of 3 May 1791; it was the second single-document constitution in the world just after the first republican Constitution of the United States. Constitutional monarchy also occurred briefly in the early years of the French Revolution, but much more widely afterwards. Napoleon Bonaparte is considered the first monarch proclaiming himself as an embodiment of the nation, rather than as a divinely appointed ruler; this interpretation of monarchy is germane to continental constitutional monarchies. German philosopher Georg Wilhelm Friedrich Hegel, in his work \"Elements of the Philosophy of Right\" (1820), gave the concept a philosophical justification that concurred with evolving contemporary political theory and the Protestant Christian view of natural law. Hegel's forecast of a constitutional monarch with very limited powers whose function is to embody the national character and provide constitutional continuity in times of emergency was reflected in the development of constitutional monarchies in Europe and Japan.\nExecutive monarchy versus ceremonial monarchy.\nThere exist at least two different types of constitutional monarchies in the modern world \u2013 executive and ceremonial. In executive monarchies (also called \"semi-constitutional monarchies\"), the monarch wields significant (though not absolute) power. The monarchy under this system of government is a powerful political (and social) institution. By contrast, in ceremonial monarchies, the monarch holds little or no actual power or direct political influence, though they frequently still have a great deal of social and cultural influence.\nCeremonial and executive monarchy should not be confused with democratic and non-democratic monarchical systems. For example, in Liechtenstein and Monaco, the ruling monarchs wield significant executive power. However, while they are theoretically very powerful within their small states, they are \"not\" absolute monarchs and have very limited \"de facto\" power compared to the Islamic monarchs, which is why their countries are generally considered to be liberal democracies and not undemocratic. For instance, when Hereditary Prince Alois of Liechtenstein threatened to veto a possible approval of a referendum to legalize abortion in 2011, it came as a surprise because the prince had not vetoed any law for over 30 years (in the end, this was moot, as the proposal was not approved).\nModern constitutional monarchy.\nAs originally conceived, a constitutional monarch was head of the executive branch and quite a powerful figure even though their power was limited by the constitution and the elected parliament. Some of the framers of the U.S. Constitution may have envisioned the president as an elected constitutional monarch, as the term was then understood, following Montesquieu's account of the separation of powers.\nThe present-day concept of a constitutional monarchy developed in the United Kingdom, where they democratically elected parliaments, and their leader, the prime minister, exercise power, with the monarchs having ceded power and remaining as a titular position. In many cases, the monarchs, while still at the very top of the political and social hierarchy, were given the status of \"servants of the people\" to reflect the new, egalitarian position. In the course of France's July Monarchy, Louis-Philippe I was styled \"King of the French\" rather than \"King of France\".\nFollowing the unification of Germany, Otto von Bismarck rejected the British model. In the constitutional monarchy established under the Constitution of the German Empire which Bismarck inspired, the Kaiser retained considerable actual executive power, while the Imperial Chancellor needed no parliamentary vote of confidence and ruled solely by the imperial mandate. However, this model of constitutional monarchy was discredited and abolished following Germany's defeat in the First World War. Later, Fascist Italy could also be considered a constitutional monarchy, in that there was a king as the titular head of state while actual power was held by Benito Mussolini under a constitution. This eventually discredited the Italian monarchy and led to its abolition in 1946. After the Second World War, surviving European monarchies almost invariably adopted some variant of the constitutional monarchy model originally developed in Britain.\nNowadays a parliamentary democracy that is a constitutional monarchy is considered to differ from one that is a republic only in detail rather than in substance. In both cases, the titular head of statemonarch or presidentserves the traditional role of embodying and representing the nation, while the government is carried on by a cabinet composed predominantly of elected Members of Parliament.\nHowever, three important factors distinguish monarchies such as the United Kingdom from systems where greater power might otherwise rest with Parliament. These are:\nOther privileges may be nominal or ceremonial (e.g., where the executive, judiciary, police or armed forces act on the authority of or owe allegiance to the Crown).\nToday slightly more than a quarter of constitutional monarchies are Western European countries, including the United Kingdom, Spain, the Netherlands, Belgium, Norway, Denmark, Luxembourg, Monaco, Liechtenstein and Sweden. However, the two most populous constitutional monarchies in the world are in Asia: Japan and Thailand. In these countries, the prime minister holds the day-to-day powers of governance, while the monarch retains residual (but not always insignificant) powers. The powers of the monarch differ between countries. In Denmark and in Belgium, for example, the monarch formally appoints a representative to preside over the creation of a coalition government following a parliamentary election, while in Norway the King chairs special meetings of the cabinet.\nIn nearly all cases, the monarch is still the nominal chief executive, but is bound by convention to act on the advice of the Cabinet. However, a few monarchies (most notably Japan and Sweden) have amended their constitutions so that the monarch is no longer the nominal chief executive.\nThere are fifteen constitutional monarchies under King Charles III, which are known as Commonwealth realms. Unlike some of their continental European counterparts, the Monarch and his Governors-General in the Commonwealth realms hold significant \"reserve\" or \"prerogative\" powers, to be wielded in times of extreme emergency or constitutional crises, usually to uphold parliamentary government. For example, during the 1975 Australian constitutional crisis, the Governor-General dismissed the Australian Prime Minister Gough Whitlam. The Australian Senate had threatened to block the Government's budget by refusing to pass the necessary appropriation bills. On 11 November 1975, Whitlam intended to call a half-Senate election to try to break the deadlock. When he sought the Governor-General's approval of the election, the Governor-General instead dismissed him as Prime Minister. Shortly after that, he installed leader of the opposition Malcolm Fraser in his place. Acting quickly before all parliamentarians became aware of the government change, Fraser and his allies secured passage of the appropriation bills, and the Governor-General dissolved Parliament for a double dissolution election. Fraser and his government were returned with a massive majority. This led to much speculation among Whitlam's supporters as to whether this use of the Governor-General's reserve powers was appropriate, and whether Australia should become a republic. Among supporters of constitutional monarchy, however, the event confirmed the monarchy's value as a source of checks and balances against elected politicians who might seek powers in excess of those conferred by the constitution, and ultimately as a safeguard against dictatorship.\nIn Thailand's constitutional monarchy, the monarch is recognized as the Head of State, Head of the Armed Forces, Upholder of the Buddhist Religion, and Defender of the Faith. The immediate former King, Bhumibol Adulyadej, was the longest-reigning monarch in the world and in all of Thailand's history, before passing away on 13 October 2016. Bhumibol reigned through several political changes in the Thai government. He played an influential role in each incident, often acting as mediator between disputing political opponents. (See Bhumibol's role in Thai Politics.) Among the powers retained by the Thai monarch under the constitution, l\u00e8se majest\u00e9 protects the image of the monarch and enables him to play a role in politics. It carries strict criminal penalties for violators. Generally, the Thai people were reverent of Bhumibol. Much of his social influence arose from this reverence and from the socioeconomic improvement efforts undertaken by the royal family.\nIn the United Kingdom, a frequent debate centres on when it is appropriate for a British monarch to act. When a monarch does act, political controversy can often ensue, partially because the neutrality of the crown is seen to be compromised in favour of a partisan goal, while some political scientists champion the idea of an \"interventionist monarch\" as a check against possible illegal action by politicians. For instance, the monarch of the United Kingdom can theoretically exercise an absolute veto over legislation by withholding royal assent. However, no monarch has done so since 1708, and it is widely believed that this and many of the monarch's other political powers are lapsed powers.\nList of current constitutional monarchies.\nThere are currently 43 monarchies worldwide."}
{"id": "5650", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=5650", "title": "Comets", "text": ""}
{"id": "5652", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=5652", "title": "Computer networking", "text": ""}
{"id": "5653", "revid": "16526057", "url": "https://en.wikipedia.org/wiki?curid=5653", "title": "Clarke's three laws", "text": "British science fiction writer Arthur C. Clarke formulated three adages that are known as Clarke's three laws, of which the third law is the best known and most widely cited. They are part of his ideas in his extensive writings about the future.\nThe laws.\nThe laws are:\nOrigins.\nOne account stated that Clarke's laws were developed after the editor of his works in French started numbering the author's assertions. All three laws appear in Clarke's essay \"Hazards of Prophecy: The Failure of Imagination\", first published in \"Profiles of the Future\" (1962); however, they were not all published at the same time. Clarke's first law was proposed in the 1962 edition of the essay, as \"Clarke's Law\" in \"Profiles of the Future\".\nThe second law is offered as a simple observation in the same essay but its status as Clarke's second law was conferred by others. It was initially a derivative of the first law and formally became Clarke's second law where the author proposed the third law in the 1973 revision of \"Profiles of the Future\", which included an acknowledgement. It was also here that Clarke wrote about the third law in these words: \"As three laws were good enough for Newton, I have modestly decided to stop there\".\nThe third law is the best known and most widely cited. It was published in a 1968 letter to \"Science\" magazine and eventually added to the 1973 revision of the \"Hazards of Prophecy\" essay. In 1952, Isaac Asimov in his book \"Foundation and Empire\" (part 1.1 \"Search for Magicians\") wrote down a similar phrase \"...\u00a0an uninformed public tends to confuse scholarship with magicians\u00a0...\" It also echoes a statement in a 1942 story by Leigh Brackett: \"Witchcraft to the ignorant, ...\u00a0simple science to the learned\". Even earlier examples of this sentiment may be found in the short story \"The Hound of Death\" (1933) by Agatha Christie: \"The supernatural is only the nature of which the laws are not yet understood\"; and in \"Wild Talents\" (1932) by Charles Fort: \"...\u00a0a performance that may someday be considered understandable, but that, in these primitive times, so transcends what is said to be the known that it is what I mean by magic\". Virginia Woolf's 1928 novel \"\" explicitly compares advanced technology to magic:\nClarke gave an example of the third law when he said that while he \"would have believed anyone who told him back in 1962 that there would one day exist a book-sized object capable of holding the content of an entire library, he would never have accepted that the same device could find a page or word in a second and then convert it into any typeface and size from Albertus Extra Bold to Zurich Calligraphic\", referring to his memory of \"seeing and hearing Linotype machines which slowly converted 'molten lead into front pages that required two men to lift them.\nVariants of the third law.\nThe third law has inspired many snowclones and other variations:\nCorollaries.\nIsaac Asimov's Corollary to Clarke's First Law: \"When, however, the lay public rallies round an idea that is denounced by distinguished but elderly scientists and supports that idea with great fervour and emotion \u2013 the distinguished but elderly scientists are then, after all, probably right.\"A contrapositive of the third law is \"Any technology distinguishable from magic is insufficiently advanced.\" (Gehm's corollary)"}
{"id": "5654", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=5654", "title": "Caspar David Friedrich", "text": "Caspar David Friedrich (; 5 September 1774 \u2013 7 May 1840) was a German Romantic landscape painter, generally considered the most important German artist of his generation, whose often symbolic, and anti-classical work, conveys a subjective, emotional response to the natural world. Friedrich's paintings often set contemplative human figures silhouetted against night skies, morning mists, barren trees or Gothic ruins. Art historian Christopher John Murray described their presence, in diminished perspective, amid expansive landscapes, as reducing the figures to a scale that directs \"the viewer's gaze towards their metaphysical dimension\".\nFriedrich was born in the town of Greifswald on the Baltic Sea in what was at the time Swedish Pomerania. He studied in Copenhagen 1794-1798, before settling in Dresden. He came of age during a period when, across Europe, a growing disillusionment with materialistic society was giving rise to a new appreciation of spirituality. This shift in ideals was often expressed through a reevaluation of the natural world, as artists such as Friedrich, J. M. W. Turner and John Constable sought to depict nature as a \"divine creation, to be set against the artifice of human civilization\".\nFriedrich's work brought him renown early in his career. Contemporaries such as the French sculptor David d'Angers spoke of him as having discovered \"the tragedy of landscape\". His work nevertheless fell from favour during his later years, and he died in obscurity. As Germany moved towards modernisation in the late 19th century, a new sense of urgency characterised its art, and Friedrich's contemplative depictions of stillness came to be seen as products of a bygone age.\nThe early 20th century brought a renewed appreciation of his art, beginning in 1906 with an exhibition of thirty-two of his paintings in Berlin. His work influenced Expressionist artists and later Surrealists and Existentialists. The rise of Nazism in the early 1930s saw a resurgence in Friedrich's popularity, but this was followed by a sharp decline as his paintings were, by association with the Nazi movement, seen as promoting German nationalism.\nIn the late 1970s Friedrich regained his reputation as an icon of the German Romantic movement and a painter of international importance. His work has been brought together in a major exhibition in Germany in 2024 under the title \"Infinitive Landscapes\", which refers to the philosopher Friedrich Schleiermacher, who was important to Friedrich and whose mathematics of infinity found its way into Friedrich's geometrically constructed paintings as hyperbolas and the golden ratio.\nIn 2025, the Metropolitan Museum of Art in New York will also show a 75 piece exhibition on Caspar David Friedrich under the title \"Caspar David Friedrich: The Soul of Nature.\"\nLife.\nEarly years and family.\nCaspar David Friedrich was born on 5 September 1774, in Greifswald, Swedish Pomerania, on the Baltic coast of Germany. The sixth of ten children, he was raised in the strict Lutheran creed of his father Adolf Gottlieb Friedrich, a candle-maker and soap boiler. Records of the family's financial circumstances are contradictory; while some sources indicate the children were privately tutored, others record that they were raised in relative poverty. He became familiar with death from an early age. His mother, Sophie, died in 1781 when he was seven. A year later, his sister Elisabeth died, and a second sister, Maria, succumbed to typhus in 1791. Arguably the greatest tragedy of his childhood happened in 1787 when his brother Johann Christoffer died: at the age of thirteen, Caspar David witnessed his younger brother fall through the ice of a frozen lake, and drown. Some accounts suggest that Johann Christoffer perished while trying to rescue Caspar David, who was also in danger on the ice.\nFriedrich began his formal study of art in 1790 as a private student of artist Johann Gottfried Quistorp at the University of Greifswald in his home city, at which the art department is now named \"Caspar-David-Friedrich-Institut\" in his honour. Quistorp took his students on outdoor drawing excursions; as a result, Friedrich was encouraged to sketch from life at an early age. Through Quistorp, Friedrich met and was subsequently influenced by the theologian Ludwig Gotthard Kosegarten, who taught that nature was a revelation of God. Quistorp introduced Friedrich to the work of the German 17th-century artist Adam Elsheimer, whose works often included religious subjects dominated by landscape, and nocturnal subjects. During this period he also studied literature and aesthetics with Swedish professor Thomas Thorild. Four years later Friedrich entered the prestigious Academy of Copenhagen, where he began his education by making copies of casts from antique sculptures before proceeding to drawing from life.\nLiving in Copenhagen afforded the young painter access to the Royal Picture Gallery's collection of 17th-century Dutch landscape painting. At the academy he studied under teachers such as Christian August Lorentzen and the landscape painter Jens Juel. These artists were inspired by the \"Sturm und Drang\" movement and represented a midpoint between the dramatic intensity and expressive manner of the budding Romantic aesthetic and the waning neo-classical ideal. Mood was paramount, and influence was drawn from such sources as the Icelandic legend of Edda, the poems of Ossian and Norse mythology.\nMove to Dresden.\nFriedrich settled permanently in Dresden in 1798. During this early period, he experimented in printmaking with etchings and designs for woodcuts which his furniture-maker brother cut. By 1804 he had produced 18 etchings and four woodcuts; they were apparently made in small numbers and only distributed to friends. Despite these forays into other media, he gravitated toward working primarily with ink, watercolour and sepias. With the exception of a few early pieces, such as \"\" (1797), he did not work extensively with oils until his reputation was more established.\nLandscapes were his preferred subject, inspired by frequent trips, beginning in 1801, to the Baltic coast, Bohemia, the Krkono\u0161e and the Harz Mountains. Mostly based on the landscapes of northern Germany, his paintings depict woods, hills, harbors, morning mists and other light effects based on a close observation of nature. These works were modeled on sketches and studies of scenic spots, such as the cliffs on R\u00fcgen, the surroundings of Dresden and the river Elbe. He executed his studies almost exclusively in pencil, even providing topographical information, yet the subtle atmospheric effects characteristic of Friedrich's mid-period paintings were rendered from memory. These effects took their strength from the depiction of light, and of the illumination of sun and moon on clouds and water: optical phenomena peculiar to the Baltic coast that had never before been painted with such an emphasis.\nHis reputation as an artist was established when he won a prize in 1805 at the Weimar competition organised by Johann Wolfgang von Goethe. At the time, the Weimar competition tended to draw mediocre and now-forgotten artists presenting derivative mixtures of neo-classical and pseudo-Greek styles. The poor quality of the entries began to prove damaging to Goethe's reputation, so when Friedrich entered two sepia drawings\u2014\"Procession at Dawn\" and \"Fisher-Folk by the Sea\"\u2014the poet responded enthusiastically and wrote, \"We must praise the artist's resourcefulness in this picture fairly. The drawing is well done, the procession is ingenious and appropriate\u00a0... his treatment combines a great deal of firmness, diligence and neatness\u00a0... the ingenious watercolour\u00a0... is also worthy of praise.\"\nFriedrich completed the first of his major paintings in 1808, at the age of 34. \"Cross in the Mountains\", today known as the \"Tetschen Altar\", is an altarpiece panel said to have been commissioned for a family chapel in Tetschen, Bohemia. The panel depicts a cross in profile at the top of a mountain, alone, and surrounded by pine trees.\nAlthough the altarpiece was generally coldly received, it was Friedrich's first painting to receive wide publicity. The artist's friends publicly defended the work, while art critic Basilius von Ramdohr published a long article challenging Friedrich's use of landscape in a religious context. He rejected the idea that landscape painting could convey explicit meaning, writing that it would be \"a veritable presumption, if landscape painting were to sneak into the church and creep onto the altar\". Friedrich responded with a programme describing his intentions in 1809, comparing the rays of the evening sun to the light of the Holy Father. This statement marked the only time Friedrich recorded a detailed interpretation of his own work, and the painting was among the few commissions the artist ever received.\nFollowing the purchase of two of his paintings by the Prussian Crown Prince, Friedrich was elected a member of the Berlin Academy in 1810. Yet in 1816, he sought to distance himself from Prussian authority and applied that June for Saxon citizenship. The move was not expected; the Saxon government was pro-French, while Friedrich's paintings were seen as generally patriotic and distinctly anti-French. Nevertheless, with the aid of his Dresden-based friend Graf Vitzthum von Eckst\u00e4dt, Friedrich attained citizenship, and in 1818, membership in the Saxon Academy with a yearly dividend of 150 thalers. Although he had hoped to receive a full professorship, it was never awarded him as, according to the German Library of Information, \"it was felt that his painting was too personal, his point of view too individual to serve as a fruitful example to students.\" Politics too may have played a role in stalling his career: Friedrich's decidedly Germanic subjects and costuming frequently clashed with the era's prevailing pro-French attitudes.\nMarriage.\nOn 21 January 1818, Friedrich married , the twenty-five-year-old daughter of a dyer from Dresden. The couple had three children, with their first, Emma, arriving in 1820. , their third child, was named after Swedish King Gustavus Adolphus, and became a notable painter in his own right.\nPhysiologist and painter Carl Gustav Carus notes in his biographical essays that marriage did not impact significantly on either Friedrich's life or personality, yet his canvasses from this period, including \"Chalk Cliffs on R\u00fcgen\"\u2014painted after his honeymoon\u2014display a new sense of levity, while his palette is brighter and less austere. Human figures appear with increasing frequency in the paintings of this period, which Siegel interprets as a reflection that \"the importance of human life, particularly his family, now occupies his thoughts more and more, and his friends, his wife, and his townspeople appear as frequent subjects in his art.\"\nAround this time, he found support from two sources in Russia. In 1820, the Grand Duke Nikolai Pavlovich, at the behest of his wife Alexandra Feodorovna, visited Friedrich's studio and returned to Saint Petersburg with a number of his paintings, an exchange that began a patronage that continued for many years. Not long thereafter, the poet Vasily Zhukovsky, tutor to the Grand Duke's son (later Tsar Alexander II), met Friedrich in 1821 and found in him a kindred spirit. For decades Zhukovsky helped Friedrich both by purchasing his work himself and by recommending his art to the royal family; his assistance toward the end of Friedrich's career proved invaluable to the ailing and impoverished artist. Zhukovsky remarked that his friend's paintings \"please us by their precision, each of them awakening a memory in our mind.\"\nFriedrich was acquainted with Philipp Otto Runge, another leading German painter of the Romantic period. He was also a friend of Georg Friedrich Kersting, and painted him at work in his unadorned studio, and of the Norwegian painter Johan Christian Clausen Dahl (1788\u20131857). Dahl was close to Friedrich during the artist's final years, and he expressed dismay that to the art-buying public, Friedrich's pictures were only \"curiosities\". While the poet Zhukovsky appreciated Friedrich's psychological themes, Dahl praised the descriptive quality of Friedrich's landscapes, commenting that \"artists and connoisseurs saw in Friedrich's art only a kind of mystic, because they themselves were only looking out for the mystic\u00a0... They did not see Friedrich's faithful and conscientious study of nature in everything he represented\".\nLater life.\nFriedrich's reputation steadily declined over the final fifteen years of his life. As the ideals of early Romanticism passed from fashion, he came to be viewed as an eccentric and melancholy character, out of touch with the times. Gradually his patrons fell away. By 1820, he was living as a recluse and was described by friends as the \"most solitary of the solitary\". Towards the end of his life he lived in relative poverty. He became isolated and spent long periods of the day and night walking alone through woods and fields, often beginning his strolls before sunrise.\nHe suffered his first stroke in June 1835, which left him with minor limb paralysis and greatly reduced his ability to paint. As a result, he was unable to work in oil; instead he was limited to watercolour, sepia and reworking older compositions. Although his vision remained strong, he had lost the full strength of his hand. Yet he was able to produce a final 'black painting', \"Seashore by Moonlight\" (1835\u20131836), described by Vaughan as the \"darkest of all his shorelines, in which richness of tonality compensates for the lack of his former finesse\". Symbols of death appeared in his work from this period. Soon after his stroke, the Russian royal family purchased a number of his earlier works, and the proceeds allowed him to travel to Teplitz\u2014in today's Czech Republic\u2014to recover.\nDuring the mid-1830s, Friedrich began a series of portraits and he returned to observing himself in nature. As the art historian William Vaughan observed, however, \"He can see himself as a man greatly changed. He is no longer the upright, supportive figure that appeared in \"Two Men Contemplating the Moon\" in 1819. He is old and stiff\u00a0... he moves with a stoop\". By 1838, he was capable of working in a small format only. He and his family were living in poverty and grew increasingly dependent for support on the charity of friends.\nDeath.\nFriedrich died in Dresden on 7 May 1840, and was buried in Dresden's Trinitatis-Friedhof (Trinity Cemetery) east of the city centre (the entrance to which he had painted some 15 years earlier). His simple flat gravestone lies north-west of the central roundel within the main avenue. His wife Caroline died impoverished seven years later, in 1847. \nBy this time his reputation and fame had waned, and his passing was little noticed within the artistic community. His artwork had certainly been acknowledged during his lifetime, but not widely. While the close study of landscape and an emphasis on the spiritual elements of nature were commonplace in contemporary art, his interpretations were highly original and personal. By 1838, his work no longer sold or received attention from critics; the Romantic movement had moved away from the early idealism that the artist had helped found.\nCarl Gustav Carus later wrote a series of articles which paid tribute to Friedrich's transformation of the conventions of landscape painting. However, Carus' articles placed Friedrich firmly in his time, and did not place the artist within a continuing tradition. Only one of his paintings had been reproduced as a print, and that was produced in very few copies.\nThemes.\nLandscape and the sublime.\nThe visualisation and portrayal of landscape in an entirely new manner was Friedrich's key innovation. He sought not just to explore the blissful enjoyment of a beautiful view, as in the classic conception, but rather to examine an instant of sublimity, a reunion with the spiritual self through the contemplation of nature. Friedrich was instrumental in transforming landscape in art from a backdrop subordinated to human drama to a self-contained emotive subject. Friedrich's paintings commonly employed the \"R\u00fcckenfigur\"\u2014a person seen from behind, contemplating the view. The viewer is encouraged to place himself in the position of the \"R\u00fcckenfigur\", by which means he experiences the sublime potential of nature, understanding that the scene is as perceived and idealised by a human.\nFriedrich created the idea of a landscape full of romantic feeling\u2014\"die romantische Stimmungslandschaft\". His art details a wide range of geographical features, such as rock coasts, forests and mountain scenes, and often used landscape to express religious themes. During his time, most of the best-known paintings were viewed as expressions of a religious mysticism. He wrote: \"The artist should paint not only what he sees before him, but also what he sees within him. If, however, he sees nothing within him, then he should also refrain from painting that which he sees before him. Otherwise, his pictures will be like those folding screens behind which one expects to find only the sick or the dead.\" Expansive skies, storms, mist, forests, ruins and crosses bearing witness to the presence of God are frequent elements in Friedrich's landscapes. Though death finds symbolic expression in boats that move away from shore\u2014a Charon-like motif\u2014and in the poplar tree, it is referenced more directly in paintings like \"The Abbey in the Oakwood\" (1808\u20131810), in which monks carry a coffin past an open grave, toward a cross, and through the portal of a church in ruins.\nHe was one of the first artists to portray winter landscapes in which the land is rendered as stark and dead. Friedrich's winter scenes are solemn and still\u2014according to the art historian Hermann Beenken, Friedrich painted winter scenes in which \"no man has yet set his foot. The theme of nearly all the older winter pictures had been less winter itself than life in winter. In the 16th and 17th centuries, it was thought impossible to leave out such motifs as the crowd of skaters, the wanderer\u00a0... It was Friedrich who first felt the wholly detached and distinctive features of a natural life. Instead of many tones, he sought the one; and so, in his landscape, he subordinated the composite chord into one single basic note\".\nBare oak trees and tree stumps, such as those in \"\" (), \"Man and Woman Contemplating the Moon\" (), and \"Willow Bush under a Setting Sun\" (), are recurring elements of his paintings, and usually symbolise death. Countering the sense of despair are Friedrich's symbols for redemption: the cross and the clearing sky promise eternal life, and the slender moon suggests hope and the growing closeness of Christ. In his paintings of the sea, anchors often appear on the shore, also indicating a spiritual hope. In \"The Abbey in the Oakwood\", the movement of the monks away from the open grave and toward the cross and the horizon imparts Friedrich's message that the final destination of man's life lies beyond the grave.\nWith dawn and dusk constituting prominent themes of his landscapes, Friedrich's own later years were characterised by a growing pessimism. His work becomes darker, revealing a fearsome monumentality. \"The Wreck of the Hope\"\u2014also known as \"The Polar Sea\" or \"The Sea of Ice\" (1823\u20131824)\u2014perhaps best summarises Friedrich's ideas and aims at this point, though in such a radical way that the painting was not well received. Completed in 1824, it depicted a grim subject, a shipwreck in the Arctic Ocean; \"the image he produced, with its grinding slabs of travertine-colored floe ice chewing up a wooden ship, goes beyond documentary into allegory: the frail bark of human aspiration crushed by the world's immense and glacial indifference.\"\nFriedrich's written commentary on aesthetics was limited to a collection of aphorisms set down in 1830, in which he explained the need for the artist to match natural observation with an introspective scrutiny of his own personality. His best-known remark advises the artist to \"close your bodily eye so that you may see your picture first with the spiritual eye. Then bring to the light of day that which you have seen in the darkness so that it may react upon others from the outside inwards.\"\nLoneliness and death.\nBoth Friedrich's life and art have at times been perceived by some to have been marked with an overwhelming sense of loneliness. Art historians and some of his contemporaries attribute such interpretations to the losses suffered during his youth to the bleak outlook of his adulthood, while Friedrich's pale and withdrawn appearance helped reinforce the popular notion of the \"taciturn man from the North\".\nFriedrich suffered depressive episodes in 1799, 1803\u20131805, c. 1813, in 1816 and between 1824 and 1826. There are noticeable thematic shifts in the works he produced during these episodes, which see the emergence of such motifs and symbols as vultures, owls, graveyards and ruins. From 1826 these motifs became a permanent feature of his output, while his use of colour became more dark and muted. Carus wrote in 1829 that Friedrich \"is surrounded by a thick, gloomy cloud of spiritual uncertainty\", though the noted art historian and curator Hubertus Gassner disagrees with such notions, seeing in Friedrich's work a positive and life-affirming subtext inspired by Freemasonry and religion.\nGermanic folklore.\nReflecting Friedrich's patriotism and resentment during the 1813 French occupation of the dominion of Pomerania, motifs from German folklore became increasingly prominent in his work. An anti-French German nationalist, Friedrich used motifs from his native landscape to celebrate Germanic culture, customs and mythology. He was impressed by the anti-Napoleonic poetry of Ernst Moritz Arndt and Theodor K\u00f6rner, and the patriotic literature of Adam M\u00fcller and Heinrich von Kleist. Moved by the deaths of three friends killed in battle against France, as well as by Kleist's 1808 drama \"Die Hermannsschlacht\", Friedrich undertook a number of paintings in which he intended to convey political symbols solely by means of the landscape\u2014a first in the history of art.\nIn ' (1812), a dilapidated monument inscribed \"Arminius\" invokes the Germanic chieftain, a symbol of nationalism, while the four tombs of fallen heroes are slightly ajar, freeing their spirits for eternity. Two French soldiers appear as small figures before a cave, lower and deep in a grotto surrounded by rock, as if farther from heaven. A second political painting, ' (c. 1813), depicts a lost French soldier dwarfed by a dense forest, while on a tree stump a raven is perched\u2014a prophet of doom, symbolizing the anticipated defeat of France.\nLegacy.\nInfluence.\nAlongside other Romantic painters, Friedrich helped position landscape painting as a major genre within Western art. Of his contemporaries, Friedrich's style most influenced the painting of Johan Christian Dahl (1788\u20131857). Among later generations, Arnold B\u00f6cklin (1827\u20131901) was strongly influenced by his work, and the substantial presence of Friedrich's works in Russian collections influenced many Russian painters, in particular Arkhip Kuindzhi (c. 1842\u20131910) and Ivan Shishkin (1832\u20131898). Friedrich's spirituality anticipated American painters such as Albert Pinkham Ryder (1847\u20131917), Ralph Blakelock (1847\u20131919), the painters of the Hudson River School and the New England Luminists.\nAt the turn of the 20th century, Friedrich was rediscovered by the Norwegian art historian Andreas Aubert (1851\u20131913), whose writing initiated modern Friedrich scholarship, and by the Symbolist painters, who valued his visionary and allegorical landscapes. The Norwegian Symbolist Edvard Munch (1863\u20131944) would have seen Friedrich's work during a visit to Berlin in the 1880s. Munch's 1899 print \"The Lonely Ones\" echoes Friedrich's \"R\u00fcckenfigur (back figure)\", although in Munch's work the focus has shifted away from the broad landscape and toward the sense of dislocation between the two melancholy figures in the foreground.\nFriedrich's modern revival gained momentum in 1906, when thirty-two of his works were featured in an exhibition in Berlin of Romantic-era art. His landscapes exercised a strong influence on the work of German artist Max Ernst (1891\u20131976), and as a result other Surrealists came to view Friedrich as a precursor to their movement. In 1934, the Belgian painter Ren\u00e9 Magritte (1898\u20131967) paid tribute in his work \"The Human Condition\", which directly echoes motifs from Friedrich's art in its questioning of perception and the role of the viewer.\nA few years later, the Surrealist journal \"Minotaure\" included Friedrich in a 1939 article by the critic Marie Landsberger, thereby exposing his work to a far wider circle of artists. The influence of \"The Wreck of Hope\" (or \"The Sea of Ice\") is evident in the 1940\u201341 painting \"Totes Meer\" by Paul Nash (1889\u20131946), a fervent admirer of Ernst. Friedrich's work has been cited as an inspiration by other major 20th-century artists, including Mark Rothko (1903\u20131970), Gerhard Richter (b. 1932), Gotthard Graubner and Anselm Kiefer (b. 1945). Friedrich's Romantic paintings have also been singled out by writer Samuel Beckett (1906\u201389), who, standing before \"Man and Woman Contemplating the Moon\", said \"This was the source of \"Waiting for Godot\", you know.\"\nIn his 1961 article \"The Abstract Sublime\", originally published in \"ARTnews\", the art historian Robert Rosenblum drew comparisons between the Romantic landscape paintings of both Friedrich and Turner with the Abstract Expressionist paintings of Mark Rothko. Rosenblum specifically describes Friedrich's 1809 painting \"The Monk by the Sea\", Turner's \"The Evening Star\" and Rothko's 1954 \"Light, Earth and Blue\" as revealing affinities of vision and feeling. According to Rosenblum, \"Rothko, like Friedrich and Turner, places us on the threshold of those shapeless infinities discussed by the aestheticians of the Sublime. The tiny monk in the Friedrich and the fisher in the Turner establish a poignant contrast between the infinite vastness of a pantheistic God and the infinite smallness of His creatures. In the abstract language of Rothko, such literal detail\u2014a bridge of empathy between the real spectator and the presentation of a transcendental landscape\u2014is no longer necessary; we ourselves are the monk before the sea, standing silently and contemplatively before these huge and soundless pictures as if we were looking at a sunset or a moonlit night.\"\nCritical opinion.\nUntil 1890, and especially after his friends had died, Friedrich's work lay in near-oblivion for decades. Yet, by 1890, the symbolism in his work began to ring true with the artistic mood of the day, especially in central Europe. However, despite a renewed interest and an acknowledgment of his originality, his lack of regard for \"painterly effect\" and thinly rendered surfaces jarred with the theories of the time.\nDuring the 1930s, Friedrich's work was used in the promotion of Nazi ideology, which attempted to fit the Romantic artist within the nationalistic \"Blut und Boden\". It took decades for Friedrich's reputation to recover from this association with Nazism. His reliance on symbolism and the fact that his work fell outside the narrow definitions of modernism contributed to his fall from favour. In 1949, art historian Kenneth Clark wrote that Friedrich \"worked in the frigid technique of his time, which could hardly inspire a school of modern painting\", and suggested that the artist was trying to express in painting what is best left to poetry. Clark's dismissal of Friedrich reflected the damage the artist's reputation sustained during the late 1930s.\nFriedrich's reputation suffered further damage when his imagery was adopted by a number of Hollywood directors, including Walt Disney, built on the work of such German cinema masters as Fritz Lang and F. W. Murnau, within the horror and fantasy genres. His rehabilitation was slow, but enhanced through the writings of such critics and scholars as Werner Hofmann, Helmut B\u00f6rsch-Supan and Sigrid Hinz, who successfully rebutted the political associations ascribed to his work, developed a \"catalogue raisonn\u00e9\", and placed Friedrich within a purely art-historical context.\nBy the 1970s, he was again being exhibited in major international galleries and found favour with a new generation of critics and art historians. Today, his international reputation is well established. He is a national icon in his native Germany, and highly regarded by art historians and connoisseurs across the Western World. He is generally viewed as a figure of great psychological complexity, and according to Vaughan, \"a believer who struggled with doubt, a celebrator of beauty haunted by darkness. In the end, he transcends interpretation, reaching across cultures through the compelling appeal of his imagery. He has truly emerged as a butterfly\u2014hopefully one that will never again disappear from our sight\".\nWork.\nFriedrich was a prolific artist who produced more than 500 attributed works. In line with the Romantic ideals of his time, he intended his paintings to function as pure aesthetic statements, so he was cautious that the titles given to his work were not overly descriptive or evocative. It is likely that some of today's more literal titles, such as \"The Stages of Life\", were not given by the artist himself, but were instead adopted during one of the revivals of interest in Friedrich. Complications arise when dating Friedrich's work, in part because he often did not directly name or date his canvases. He kept a carefully detailed notebook on his output, however, which has been used by scholars to tie paintings to their completion dates."}
{"id": "5655", "revid": "46907991", "url": "https://en.wikipedia.org/wiki?curid=5655", "title": "Courtney Love", "text": "Courtney Michelle Love (n\u00e9e Harrison; born July 9, 1964) is an American singer, guitarist, songwriter, and actress. A figure in the alternative and grunge scenes of the 1990s, her career has spanned four decades. She rose to prominence as the lead vocalist and rhythm guitarist of the alternative rock band Hole, which she formed in 1989. Love has drawn public attention for her uninhibited live performances and confrontational lyrics, as well as her highly publicized personal life following her marriage to Nirvana frontman Kurt Cobain. In 2020, \"NME\" named her one of the most influential singers in alternative culture of the last 30 years.\nLove had an itinerant childhood, but was primarily raised in Portland, Oregon, where she played in a series of short-lived bands and was active in the local punk scene. After briefly being in a juvenile hall, she spent a year living in Dublin and Liverpool before returning to the United States and pursuing an acting career. She appeared in supporting roles in the Alex Cox films \"Sid and Nancy\" (1986) and \"Straight to Hell\" (1987) before forming the band Hole in Los Angeles with guitarist Eric Erlandson. The group received critical acclaim from underground rock press for their 1991 debut album \"Pretty on the Inside\", produced by Kim Gordon, while their second release, \"Live Through This\" (1994), was met with critical accolades and multi-platinum sales. In 1995, Love returned to acting, earning a Golden Globe Award nomination for her performance as Althea Leasure in Milo\u0161 Forman's \"The People vs. Larry Flynt\" (1996), which established her as a mainstream actress. The following year, Hole's third album, \"Celebrity Skin\" (1998), was nominated for three Grammy Awards.\nLove continued to work as an actress into the early 2000s, appearing in big-budget pictures such as \"Man on the Moon\" (1999) and \"Trapped\" (2002), before releasing her first solo album, \"America's Sweetheart\", in 2004. The subsequent several years were marred with publicity surrounding Love's legal troubles and drug relapse, which resulted in a mandatory lockdown rehabilitation sentence in 2005 while she was writing a second solo album. That project became \"Nobody's Daughter\", released in 2010 as a Hole album but without the former Hole lineup. Between 2014 and 2015, Love released two solo singles and returned to acting in the network series \"Sons of Anarchy\" and \"Empire\". In 2020, she confirmed she was writing new music. Love has also been active as a writer; she co-created and co-wrote three volumes of a manga, \"Princess Ai\", between 2004 and 2006, and wrote a memoir, \"\" (2006).\nLife and career.\n1964\u20131982: Childhood and education.\nCourtney Michelle Harrison was born July 9, 1964, at Saint Francis Memorial Hospital in San Francisco, the first child of psychotherapist Linda Carroll (n\u00e9e Risi; born 1944) and Hank Harrison (1941\u20132022), a publisher and road manager for the Grateful Dead. Her parents met at a party held for Dizzy Gillespie in 1963, and the two married in Reno, Nevada after Carroll discovered she was pregnant. Carroll, who was adopted at birth, is the biological daughter of novelist Paula Fox. Love's matrilineal great-grandmother was Elsie Fox (n\u00e9e de Sola), a Cuban writer who co-wrote the film \"The Last Train from Madrid\" with Love's great-grandfather, Paul Hervey Fox, cousin of writer Faith Baldwin and actor Douglas Fairbanks. Phil Lesh, the founding bassist of the Grateful Dead, was Love's godfather. According to Love, she was named after Courtney Farrell, the protagonist of Pamela Moore's 1956 novel \"Chocolates for Breakfast\". Love is of mixed Cuban, English, German, Irish, Ashkenazi Jewish, and Welsh ancestry. Through her mother's subsequent marriages, Love has two younger half-sisters, three younger half-brothers (one of whom died in infancy), and one adopted brother.\nLove spent her early years in Haight-Ashbury, San Francisco, until her parents divorced in 1970. In a custody hearing, her mother, as well as one of her father's girlfriends, testified that Hank had dosed Courtney with LSD when she was a toddler. Carroll also alleged that Hank threatened to abduct his daughter and flee with her to a foreign country. Though Hank denied these allegations, his custody was revoked. In 1970, Carroll relocated with Love to the rural community of Marcola, Oregon where they lived along the Mohawk River while Carroll completed her psychology degree at the University of Oregon. There, Carroll remarried to schoolteacher Frank Rodr\u00edguez, who legally adopted Love. Though Love was baptized a Roman Catholic, her mother maintained an unorthodox home; according to Love, \"There were hairy, wangly-ass hippies running around naked [doing] Gestalt therapy\", and her mother raised her in a gender-free household with \"no dresses, no patent leather shoes, no canopy beds, nothing\". Love attended a Montessori school in Eugene, Oregon, where she struggled academically and socially. She has said that she began seeing psychiatrists at \"like, [age] three. Observational therapy. TM for tots. You name it, I've been there.\" At age nine, a psychologist noted that she exhibited signs of autism, among them tactile defensiveness. Love commented in 1995: \"When I talk about being introverted, I was diagnosed autistic. At an early age, I would not speak. Then I simply bloomed.\"\nIn 1972, Love's mother divorced Rodr\u00edguez, remarried to sportswriter David Menely, and moved the family to Nelson, New Zealand. Love was enrolled at Nelson College for Girls, but soon expelled for misbehavior. In 1973, Carroll sent Love back to Portland, Oregon, to be raised by her former stepfather and other family friends. At age 14, Love was arrested for shoplifting from a Portland department store and remanded at Hillcrest Correctional Facility, a juvenile hall in Salem, Oregon. While at Hillcrest, she became acquainted with records by Patti Smith, the Runaways, and the Pretenders, who later inspired her to start a band. She was intermittently placed in foster care throughout late 1979 until becoming legally emancipated in 1980, after which she remained staunchly estranged from her mother. Shortly after her emancipation, Love spent two months in Japan working as a topless dancer, but was deported after her passport was confiscated. She returned to Portland and began working at the strip club Mary's Club, adopting the surname Love to conceal her identity; she later adopted Love as her surname. She worked odd jobs, including as a DJ at a gay disco. Love said she lacked social skills, and learned them while frequenting gay clubs and spending time with drag queens. During this period, she enrolled at Portland State University, studying English and philosophy. She later commented that, had she not found a passion for music, she would have sought a career working with children.\nIn 1981, Love was granted a small trust fund that had been left by her maternal grandparents, which she used to travel to Dublin, Ireland, where her biological father was living. She audited courses at Trinity College, studying theology for two semesters. She later received honorary patronage from Trinity's University Philosophical Society in 2010. While in Dublin, Love met musician Julian Cope of the Teardrop Explodes at one of the band's concerts. Cope took a liking to Love and offered to let her stay at his Liverpool home in his absence. She traveled to London, where she was met by her friend and future bandmate, Robin Barbur, from Portland. Recalling Cope's offer, Love and Barbur moved into Cope's home with him and several other artists, including Pete de Freitas of Echo &amp; the Bunnymen. De Freitas was initially hesitant to allow the girls to stay, but acquiesced as they were \"alarmingly young and obviously had nowhere else to go\". Love recalled: \"They kind of took me in. I was sort of a mascot; I would get them coffee or tea during rehearsals.\" Cope writes of Love frequently in his 1994 autobiography, \"Head-On\", in which he refers to her as \"the adolescent\".\nIn July 1982, Love returned to the United States. In late 1982, she attended a Faith No More concert in San Francisco and convinced the members to let her join as a singer. The group recorded material with Love as a vocalist, but fired her; according to keyboardist Roddy Bottum, who remained Love's friend in the years after, the band wanted a \"male energy\". Love returned to working abroad as an erotic dancer, briefly in Taiwan, and then at a taxi dance hall in Hong Kong. By Love's account, she first used heroin while working at the Hong Kong dance hall, having mistaken it for cocaine. While still inebriated from the drug, Love was pursued by a wealthy male client who requested that she return with him to the Philippines, and gave her money to purchase new clothes. She used the money to purchase an airfare back to the United States.\n1983\u20131987: Early music projects and film.\nAt age 19, through her then-boyfriend's mother, film costume designer Bernadene Mann, Love took a job at Paramount Studios cleaning out the wardrobe department of vintage pieces that had suffered dry rot or other damage. During this time, Love became interested in vintage fashion. She subsequently returned to Portland, where she formed short-lived musical projects with her friends Ursula Wehr and Robin Barbur (namely Sugar Babylon, later known as Sugar Babydoll). Love briefly fronted Faith no More for their first TV appearance in 1984: she sang with a Siouxsie Sioux-style vocal. After meeting Kat Bjelland at the Satyricon nightclub in 1984, the two formed the group the Pagan Babies. Love asked Bjelland to start the band with her as a guitarist, and the two moved to San Francisco in June 1985, where they recruited bassist Jennifer Finch and drummer Janis Tanaka. According to Bjelland, \"[Courtney] didn't play an instrument at the time\" aside from keyboards, so Bjelland would transcribe Love's musical ideas on guitar for her. The group played several house shows and recorded one 4-track demo before disbanding in late 1985. After Pagan Babies, Love moved to Minneapolis, where Bjelland had formed the group Babes in Toyland, and briefly worked as a concert promoter before returning to California. Drummer Lori Barbero recalled Love's time in Minneapolis: \nDeciding to shift her focus to acting, Love enrolled at the San Francisco Art Institute and studied film under experimental director George Kuchar, featuring in one of his short films, \"Club Vatican\". She also took experimental theater courses in Oakland taught by Whoopi Goldberg. In 1985, Love submitted an audition tape for the role of Nancy Spungen in the Sid Vicious biopic \"Sid and Nancy\" (1986) and was given a minor supporting role by director Alex Cox. After filming \"Sid and Nancy\" in New York City, she worked at a peep show in Times Square and squatted at the ABC No Rio social center and Pyramid Club in the East Village. That year, Cox cast her in a leading role in his film \"Straight to Hell\" (1987), a Spaghetti Western starring Joe Strummer, Dennis Hopper, and Grace Jones, shot in Spain in 1986. The film was poorly reviewed by critics, but it caught the attention of Andy Warhol, who featured Love in an episode of \"Andy Warhol's Fifteen Minutes\". She also had a part in the 1988 Ramones music video for \"I Wanna Be Sedated\", appearing as a bride among dozens of party guests.\nDispleased by the \"celebutante\" fame she had attained, Love abandoned her acting career in 1988 and resumed work as a stripper in Oregon, where she was recognized by customers at a bar in the small town of McMinnville. This prompted Love to go into isolation and relocate to Anchorage, Alaska, where she lived for three months to \"gather her thoughts\", supporting herself by working at a strip club frequented by local fishermen. \"I decided to move to Alaska because I needed to get my shit together and learn how to work\", she said in retrospect. \"So I went on this sort of vision quest. I got rid of all my earthly possessions. I had my bad little strip clothes and some big sweaters, and I moved into a trailer with a bunch of other strippers.\"\n1988\u20131991: Beginnings of Hole.\nAt the end of 1988, Love taught herself to play guitar and relocated to Los Angeles, where she placed an ad in a local music zine: \"I want to start a band. My influences are Big Black, Sonic Youth, and Fleetwood Mac.\" By 1989, Love had recruited guitarist Eric Erlandson; bassist Lisa Roberts, her neighbor; and drummer Caroline Rue, whom she met at a Gwar concert. Love named the band Hole after a line from Euripides' \"Medea\" (\"There is a hole that pierces right through me\") and a conversation in which her mother told her that she could not live her life \"with a hole running through her\". On July 23, 1989, Love married Leaving Trains vocalist James Moreland in Las Vegas; the marriage was annulled the same year. She later said that Moreland was a transvestite and that they had married \"as a joke\". After forming Hole, Love and Erlandson had a romantic relationship that lasted over a year.\nIn Hole's formative stages, Love continued to work at strip clubs in Hollywood (including Jumbo's Clown Room and the Seventh Veil), saving money to purchase backline equipment and a touring van, while rehearsing at a Hollywood studio loaned to her by the Red Hot Chili Peppers. Hole played their first show in November 1989 at Raji's, a rock club in central Hollywood. Their debut single, \"Retard Girl\", was issued in April 1990 through the Long Beach indie label Sympathy for the Record Industry and was played by Rodney Bingenheimer on local rock station KROQ. Hole appeared on the cover of \"Flipside\", a Los Angeles-based punk fanzine. In early 1991, they released their second single, \"Dicknail\", through Sub Pop Records.\nWith no wave, noise rock, and grindcore bands being major influences on Love, Hole's first studio album, \"Pretty on the Inside\", captured an abrasive sound and contained disturbing, graphic lyrics, described by \"Q\" as \"confrontational [and] genuinely uninhibited\". The record was released in September 1991 on Caroline Records, produced by Kim Gordon of Sonic Youth with assistant production from Gumball's Don Fleming; Love and Gordon had met when Hole opened for Sonic Youth during their promotional tour for \"Goo\" at the Whisky a Go Go in November 1990. In early 1991, Love sent Gordon a personal letter asking her to produce the record for the band, to which she agreed.\n\"Pretty on the Inside\" received generally positive critical reception from indie and punk rock critics and was named one of the 20 best albums of the year by \"Spin\". It gained a following in the United Kingdom, charting at 59 on the UK Albums Chart, and its lead single, \"Teenage Whore\", entered the UK Indie Chart at number one. The album's feminist slant led many to tag the band as part of the riot grrrl movement, a movement with which Love did not associate. The band toured in support of the record, headlining with Mudhoney in Europe; in the United States, they opened for the Smashing Pumpkins, and performed at CBGB in New York City.\nDuring the tour, Love briefly dated Smashing Pumpkins frontman Billy Corgan and then the Nirvana frontman Kurt Cobain. The journalist Michael Azerrad states that Love and Cobain met in 1989 at the Satyricon nightclub in Portland, Oregon. However, the Cobain biographer Charles Cross gives the date as February 12, 1990; Cross said that Cobain playfully wrestled Love to the floor after she said that he looked like Dave Pirner of Soul Asylum. According to Love, she met Cobain at a Dharma Bums show in Portland, while Love's bandmate Eric Erlandson said that he and Love were introduced to Cobain in a parking lot after a concert at the Hollywood Palladium on May 17, 1991. In late 1991, Love and Cobain became re-acquainted through Jennifer Finch, one of Love's friends and former bandmates. Love and Cobain were a couple by 1992.\n1992\u20131995: Marriage to Kurt Cobain, \"Live Through This\" and breakthrough.\nShortly after completing the tour for \"Pretty on the Inside\", Love married Cobain on Waikiki Beach on February 24, 1992. She wore a satin and lace dress once owned by actress Frances Farmer, and Cobain wore plaid pajamas. During Love's pregnancy, Hole recorded a cover of \"Over the Edge\" for a Wipers tribute album, and recorded their fourth single, \"Beautiful Son\", which was released in April 1993. On August 18, 1992 the couple's only child, a daughter, Frances Bean Cobain, was born in Los Angeles. They relocated to Carnation, Washington, and then Seattle.\nLove's first major media exposure came in a September 1992 profile with Cobain for \"Vanity Fair\" by Lynn Hirschberg, entitled \"Strange Love\". Cobain had become a major public figure following the surprise success of Nirvana's album \"Nevermind\". Love was urged by her manager to participate in the cover story. During the prior year, Love and Cobain had developed a heroin addiction; the profile portrayed them in an unflattering light, and suggested that Love had been addicted to heroin during her pregnancy. The Los Angeles Department of Children and Family Services investigated, and custody of Frances was temporarily awarded to Love's sister Jaimee. Love said she was misquoted by Hirschberg, and that she had immediately quit heroin during her first trimester once she discovered she was pregnant. Love later said the article had serious implications for her marriage and Cobain's mental state, suggesting it was a factor in his suicide two years later.\nOn September 8, 1993, Love and Cobain made their only public performance together at the Rock Against Rape benefit in Hollywood, performing two acoustic duets of \"Pennyroyal Tea\" and \"Where Did You Sleep Last Night\". Love also performed electric versions of two new Hole songs, \"Doll Parts\" and \"Miss World\", both written for their upcoming second album. In October 1993, Hole recorded their second album, \"Live Through This\", in Atlanta. The album featured a new lineup with bassist Kristen Pfaff and drummer Patty Schemel.\nIn April 1994, Cobain killed himself in the Seattle home he shared with Love, who was in rehab in Los Angeles at the time. In the following months, Love was rarely seen in public, staying at her home with friends and family. Cobain's remains were cremated and his ashes divided into portions by Love, who kept some in a teddy bear and some in an urn. In June, she traveled to the Namgyal Buddhist Monastery in Ithaca, New York and had Cobain's ashes ceremonially blessed by Buddhist monks. Another portion was mixed into clay and made into memorial sculptures.\n\"Live Through This\" was released one week after Cobain's death, on Geffen's subsidiary label DGC. On June 16, Pfaff died of a heroin overdose in Seattle. For Hole's impending tour, Love recruited the Canadian bassist Melissa Auf der Maur. Hole's performance on August 26, 1994, at the Reading Festival\u2014Love's first public performance following Cobain's death\u2014was described by MTV as \"by turns macabre, frightening and inspirational\". John Peel wrote in \"The Guardian\" that Love's disheveled appearance \"would have drawn whistles of astonishment in Bedlam\", and that her performance \"verged on the heroic\u00a0... Love steered her band through a set which dared you to pity either her recent history or that of the band\u00a0... The band teetered on the edge of chaos, generating a tension which I cannot remember having felt before from any stage.\"\n\"Live Through This\" was certified platinum in April 1995 and received numerous accolades. The success combined with Cobain's suicide produced publicity for Love, and she was featured on Barbara Walters' \"10 Most Fascinating People\" in 1995. Her erratic onstage behavior and various legal troubles during Hole's tour compounded the media coverage of her. Hole performed a series of riotous concerts over the following year, with Love frequently appearing hysterical onstage, flashing crowds, stage diving, and getting into fights with audience members. One journalist reported that at the band's show in Boston in December 1994: \"Love interrupted the music and talked about her deceased husband Kurt Cobain, and also broke out into Tourette syndrome-like rants. The music was great, but the raving was vulgar and offensive, and prompted some of the audience to shout back at her.\"\nIn January 1995, Love was arrested in Melbourne for disrupting a Qantas flight after getting into an argument with a stewardess. On July 4, 1995, at the Lollapalooza Festival in George, Washington, Love threw a lit cigarette at musician Kathleen Hanna before punching her in the face, alleging that she had made a joke about her daughter. She pleaded guilty to an assault charge and was sentenced to anger management classes. In November 1995, two male teenagers sued Love for allegedly punching them during a Hole concert in Orlando, Florida in March 1995. The judge dismissed the case on grounds that the teens \"weren't exposed to any greater amount of violence than could reasonably be expected at an alternative rock concert\". Love later said she had little memory of 1994 and 1995, as she had been using large quantities of heroin and Rohypnol at the time.\n1996\u20132002: Acting success and \"Celebrity Skin\".\nAfter Hole's world tour concluded in 1996, Love made a return to acting, first in small roles in the Jean-Michel Basquiat biopic \"Basquiat\" and the drama \"Feeling Minnesota\" (1996), and then a starring role as Larry Flynt's wife Althea in Milo\u0161 Forman's critically acclaimed 1996 film \"The People vs. Larry Flynt\". Love went through rehabilitation and quit using heroin at the insistence of Forman; she was ordered to take multiple urine tests under the supervision of Columbia Pictures while filming, and passed all of them. Despite Columbia Pictures' initial reluctance to hire Love due to her troubled past, her performance received acclaim, earning a Golden Globe nomination for Best Actress, and a New York Film Critics Circle Award for Best Supporting Actress. Critic Roger Ebert called her work in the film \"quite a performance; Love proves she is not a rock star pretending to act, but a true actress.\" She won several other awards from various film critic associations for the film. During this time, Love maintained what the media noted as a more decorous public image, and she appeared in ad campaigns for Versace and in a \"Vogue Italia\" spread. Following the release of \"The People vs. Larry Flynt\", she dated her co-star Edward Norton, with whom she remained until 1999.\nIn late 1997, Hole released the compilations \"My Body, the Hand Grenade\" and \"The First Session\", both of which featured previously recorded material. Love attracted media attention in May 1998 after punching journalist Belissa Cohen at a party; the suit was settled out of court for an undisclosed sum. In September 1998, Hole released their third studio album, \"Celebrity Skin\", which featured a stark power pop sound that contrasted with their earlier punk influences. Love divulged her ambition of making an album where \"art meets commerce\u00a0... there are no compromises made, it has commercial appeal, and it sticks to [our] original vision.\" She said she was influenced by Neil Young, Fleetwood Mac, and My Bloody Valentine when writing the album. Smashing Pumpkins frontman Billy Corgan co-wrote several songs. \"Celebrity Skin\" was well received by critics; \"Rolling Stone\" called it \"accessible, fiery and intimate\u2014often at the same time\u00a0... a basic guitar record that's anything but basic.\" \"Celebrity Skin\" went multi-platinum, and topped \"Best of Year\" lists at \"Spin\" and \"The Village Voice\". It garnered Hole's only number-one single on the Modern Rock Tracks chart with \"Celebrity Skin\". Hole promoted the album through MTV performances and at the 1998 Billboard Music Awards, and were nominated for three Grammy Awards at the 41st Grammy Awards ceremony.\nBefore the release of \"Celebrity Skin\", Love and Fender designed a low-priced Squier brand guitar, the Vista Venus. The instrument featured a shape inspired by Mercury, a little-known independent guitar manufacturer, Stratocaster, and Rickenbacker's solid body guitars. It had a single-coil and a humbucker pickup and was available in 6-string and 12-string versions. In an early 1999 interview, Love said about the Venus: \"I wanted a guitar that sounded really warm and pop, but which required just one box to go dirty\u00a0... And something that could also be your first band guitar. I didn't want it all teched out. I wanted it real simple, with just one pickup switch.\"\nHole toured with Marilyn Manson on the Beautiful Monsters Tour in 1999, but dropped out after nine performances; Love and Manson disagreed over production costs, and Hole was forced to open for Manson under an agreement with Interscope Records. Hole resumed touring with Imperial Teen. Love later said Hole also abandoned the tour due to Manson and Korn's (whom they also toured with in Australia) sexualized treatment of teenage female audience members. Love told interviewers at 99X.FM in Atlanta: \"What I really don't like\u2014there are certain girls that like us, or like me, who are really messed up\u00a0... they're very young, and they do not need to be taken and raped, or filmed having enema contests\u00a0... [they were] going out into the audience and picking up fourteen and fifteen-year-old girls who obviously cut themselves, and then [I had] to see them in the morning\u00a0... it's just uncool.\"\nIn 1999, Love was awarded an Orville H. Gibson award for Best Female Rock Guitarist. During this time, she starred opposite Jim Carrey as his partner Lynne Margulies in the Andy Kaufman biopic \"Man on the Moon\" (1999), followed by a role as William S. Burroughs's wife Joan Vollmer in \"Beat\" (2000) alongside Kiefer Sutherland. Love was cast as the lead in John Carpenter's sci-fi horror film \"Ghosts of Mars\", but backed out after injuring her foot. She sued the ex-wife of her then-boyfriend, James Barber, whom Love alleged had caused the injury by running over her foot with her Volvo. The following year, she returned to film opposite Lili Taylor in \"Julie Johnson\" (2001), in which she played a woman who has a lesbian relationship; Love won an Outstanding Actress award at L.A.'s Outfest. She was then cast in the thriller \"Trapped\" (2002), alongside Kevin Bacon and Charlize Theron. The film was a box-office flop.\nIn the interim, Hole had become dormant. In March 2001, Love began a \"punk rock femme supergroup\", Bastard, enlisting Schemel, Veruca Salt co-frontwoman Louise Post, and bassist Gina Crosley. Post recalled: \"[Love] was like, 'Listen, you guys: I've been in my Malibu, manicure, movie-star world for two years, alright? I wanna make a record. And let's leave all that grunge shit behind us, eh? We were being so improvisational, and singing together, and with a trust developing between us. It was the shit.\" The group recorded a demo tape, but by September 2001, Post and Crosley had left, with Post citing \"unhealthy and unprofessional working conditions\". In May 2002, Hole announced their breakup amid continuing litigation with Universal Music Group over their record contract.\nIn 1997, Love and former Nirvana members Krist Novoselic and Dave Grohl formed a limited liability company, Nirvana LLC, to manage Nirvana's business dealings. In June 2001, Love filed a lawsuit to dissolve it, blocking the release of unreleased Nirvana material and delaying the release of the Nirvana compilation \"With the Lights Out\". Grohl and Novoselic sued Love, calling her \"irrational, mercurial, self-centered, unmanageable, inconsistent and unpredictable\". She responded with a letter stating that \"Kurt Cobain was Nirvana\" and that she and his family were the \"rightful heirs\" to the Nirvana legacy.\n2003\u20132008: Solo work and legal troubles.\nIn February 2003, Love was arrested at Heathrow Airport for disrupting a flight and was banned from Virgin Airlines. In October, she was arrested in Los Angeles after breaking several windows of her producer and then-boyfriend James Barber's home and was charged with being under the influence of a controlled substance; the ordeal resulted in her temporarily losing custody of her daughter.\nAfter the breakup of Hole, Love began composing material with songwriter Linda Perry, and in July 2003 signed a contract with Virgin Records. She began recording her debut solo album, \"America's Sweetheart\", in France shortly after. Virgin Records released \"America's Sweetheart\" in February 2004; it received mixed reviews. Charles Aaron of \"Spin\" called it a \"jaw-dropping act of artistic will and a fiery, proper follow-up to 1994's \"Live Through This\"\" and awarded it eight out of ten, while Amy Phillips of \"The Village Voice\" wrote: \"[Love is] willing to act out the dream of every teenage brat who ever wanted to have a glamorous, high-profile hissyfit, and she turns those egocentric nervous breakdowns into art. Sure, the art becomes less compelling when you've been pulling the same stunts for a decade. But, honestly, is there anybody out there who fucks up better?\" The album sold fewer than 100,000 copies. Love later expressed regret over the record, blaming her drug problems at the time. Shortly after it was released, she told Kurt Loder on \"TRL\": \"I cannot exist as a solo artist. It's a joke.\"\nOn March 17, 2004, Love appeared on the \"Late Show with David Letterman\" to promote \"America's Sweetheart\". Her appearance drew media coverage when she lifted her shirt multiple times, flashed Letterman, and stood on his desk. The \"New York Times\" wrote: \"The episode was not altogether surprising for Ms. Love, 39, whose most public moments have veered from extreme pathos\u2014like the time she read the suicide note of her famous husband, Kurt Cobain, on MTV\u2014to angry feminism to catfights to incoherent ranting.\" Hours later, in the early morning of March 18, Love was arrested in Manhattan for allegedly striking a fan with a microphone stand during a small concert in the East Village. She was released within hours and performed a scheduled concert the following evening at the Bowery Ballroom. Four days later, she called in multiple times to \"The Howard Stern Show\", claiming in broadcast conversations with Stern that the incident had not occurred, and that actress Natasha Lyonne, who was at the concert, was told by the alleged victim that he had been paid $10,000 to file a false claim leading to Love's arrest.\nOn July 9, 2004, her 40th birthday, Love was arrested for failing to make a court appearance for the March 2004 charges, and taken to Bellevue Hospital, allegedly incoherent, where she was placed on a 72-hour watch. According to police, she was believed to be a potential danger to herself, but deemed mentally sound and released to a rehab facility two days later. Amidst public criticism and press coverage, comedian Margaret Cho published an opinion piece, \"Courtney Deserves Better from Feminists\", arguing that negative associations of Love with her drug and personal problems (including from feminists) overshadowed her music and wellbeing. Love pleaded guilty in October 2004 to disorderly conduct over the incident in East Village.\nLove's appearance as a roaster on the \"Comedy Central Roast\" of Pamela Anderson in August 2005, in which she appeared intoxicated and disheveled, attracted further media attention. One review said that Love \"acted as if she belonged in an institution\". Six days after the broadcast, Love was sentenced to a 28-day lockdown rehab program for being under the influence of a controlled substance, violating her probation. To avoid jail time, she accepted an additional 180-day rehab sentence in September 2005. In November 2005, after completing the program, Love was discharged from the rehab center under the provision that she complete further outpatient rehab. In subsequent interviews, Love said she had been addicted to substances including prescription drugs, cocaine, and crack cocaine. She said she had been sober since completing rehabilitation in 2007, and cited her Soka Gakkai Buddhist practice (which she began in 1988) as integral to her sobriety.\nIn the midst of her legal troubles, Love had endeavors in writing and publishing. She co-wrote a semi-autobiographical manga, \"Princess Ai\" (Japanese: \u30d7\u30ea\u30f3\u30bb\u30b9\u00b7\u30a2\u30a4\u7269\u8a9e), with Stu Levy, illustrated by Misaho Kujiradou and Ai Yazawa; it was released in three volumes in the United States and Japan between 2004 and 2006. In 2006, Love published a memoir, \"\", and began recording her second solo album, \"How Dirty Girls Get Clean\", collaborating again with Perry and Billy Corgan. Love had written several songs, including an anti-cocaine song titled \"Loser Dust\", during her time in rehab in 2005. She told \"Billboard\": \"My hand-eye coordination was so bad [after the drug use], I didn't even know chords anymore. It was like my fingers were frozen. And I wasn't allowed to make noise [in rehab]\u00a0... I never thought I would work again.\" Tracks and demos for the album leaked online in 2006, and a documentary, \"The Return of Courtney Love\", detailing the making of the album, aired on the British television network More4 in the fall of that year. A rough acoustic version of \"Never Go Hungry Again\", recorded during an interview for \"The Times\" in November, was also released. Incomplete audio clips of the song \"Samantha\", originating from an interview with NPR, were distributed on the internet in 2007.\n2009\u20132012: Hole revival and visual art.\nIn March 2009, fashion designer Dawn Simorangkir brought a libel suit against Love concerning a defamatory post Love made on her Twitter account, which was eventually settled for $450,000. Several months later, in June 2009, \"NME\" published an article detailing Love's plan to reunite Hole and release a new album, \"Nobody's Daughter\". In response, former Hole guitarist Eric Erlandson stated in \"Spin\" magazine that contractually no reunion could take place without his involvement; therefore \"Nobody's Daughter\" would remain Love's solo record, as opposed to a \"Hole\" record. Love responded to Erlandson's comments in a Twitter post, claiming \"he's out of his mind, Hole is my band, my name, and my Trademark\". \"Nobody's Daughter\" was released worldwide as a Hole album on April 27, 2010. For the new line-up, Love recruited guitarist Micko Larkin, Shawn Dailey (bass guitar), and Stu Fisher (drums, percussion). \"Nobody's Daughter\" featured material written and recorded for Love's unfinished solo album, \"How Dirty Girls Get Clean\", including \"Pacific Coast Highway\", \"Letter to God\", \"Samantha\", and \"Never Go Hungry\", although they were re-produced in the studio with Larkin and engineer Michael Beinhorn. The album's subject matter was largely centered on Love's tumultuous life between 2003 and 2007, and featured a polished folk rock sound, and more acoustic guitar work than previous Hole albums.\nThe first single from \"Nobody's Daughter\" was \"Skinny Little Bitch\", released to promote the album in March 2010. The album received mixed reviews. Robert Sheffield of \"Rolling Stone\" gave the album three out of five, saying Love \"worked hard on these songs, instead of just babbling a bunch of druggy bullshit and assuming people would buy it, the way she did on her 2004 flop, \"America's Sweetheart\"\". Sal Cinquemani of \"Slant Magazine\" also gave the album three out of five: \"It's Marianne Faithfull's substance-ravaged voice that comes to mind most often while listening to songs like 'Honey' and 'For Once in Your Life'. The latter track is, in fact, one of Love's most raw and vulnerable vocal performances to date\u00a0... the song offers a rare glimpse into the mind of a woman who, for the last 15 years, has been as famous for being a rock star as she's been for being a victim.\" Love and the band toured internationally from 2010 into late 2012 promoting the record, with their pre-release shows in London and at South by Southwest receiving critical acclaim. In 2011, Love participated in \"Hit So Hard\", a documentary chronicling bandmate Schemel's time in Hole.\nIn May 2012, Love debuted an art collection at Fred Torres Collaborations in New York titled \"And She's Not Even Pretty\", which contained over 40 drawings and paintings by Love composed in ink, colored pencil, pastels, and watercolors. Later in the year, she collaborated with Michael Stipe on the track \"Rio Grande\" for Johnny Depp's sea shanty album \"\", and in 2013, co-wrote and contributed vocals on \"Rat A Tat\" from Fall Out Boy's album \"Save Rock and Roll\", also appearing in the song's music video.\n2013\u20132015: Return to acting; libel lawsuits.\nAfter dropping the Hole name and performing as a solo artist in late 2012, Love appeared in spring 2013 advertisements for Yves Saint Laurent alongside Kim Gordon and Ariel Pink. Love completed a solo tour of North America in mid-2013, which was purported to be in promotion of an upcoming solo album; however, it was ultimately dubbed a \"greatest hits\" tour, and featured songs from Love's and Hole's back catalogue. Love told \"Billboard\" at the time that she had recorded eight songs in the studio.\nLove was subject of a second landmark libel lawsuit brought against her in January 2014 by her former attorney Rhonda Holmes, who accused Love of online defamation, seeking $8 million in damages. It was the first case of alleged Twitter-based libel in U.S. history to make it to trial. The jury, however, found in Love's favor. A subsequent defamation lawsuit filed by fashion designer Simorangkir in February 2014, however, resulted in Love being ordered to pay a further $350,000 in recompense.\nOn April 22, 2014, Love debuted the song \"You Know My Name\" on BBC Radio 6 to promote her tour of the United Kingdom. It was released as a double A-side single with the song \"Wedding Day\" on May 4, 2014, on her own label Cherry Forever Records via Kobalt Label Services. The tracks were produced by Michael Beinhorn, and feature Tommy Lee on drums. In an interview with the BBC, Love revealed that she and former Hole guitarist Eric Erlandson had reconciled, and had been rehearsing new material together, along with former bassist Melissa Auf der Maur and drummer Patty Schemel, though she did not confirm a reunion of the band. On May 1, 2014, in an interview with \"Pitchfork\", Love commented further on the possibility of Hole reuniting, saying:\n\"I'm not going to commit to it happening, because we want an element of surprise. There's a lot of \"i\"s to be dotted and \"t\"s to be crossed.\"\nLove was cast in several television series in supporting parts throughout 2014, including the FX series \"Sons of Anarchy\", \"Revenge\", and Lee Daniels' network series \"Empire\" in a recurring guest role as Elle Dallas. The track \"Walk Out on Me\", featuring Love, was included on the \"\" album, which debuted at number 1 on the Billboard 200. Alexis Petridis of \"The Guardian\" praised the track, saying: \"The idea of Courtney Love singing a ballad with a group of gospel singers seems faintly terrifying\u00a0... The reality is brilliant. Love's voice fits the careworn lyrics, effortlessly summoning the kind of ravaged darkness that Lana Del Rey nearly ruptures herself trying to conjure up.\"\nIn January 2015, Love starred in a New York City stage production, \"Kansas City Choir Boy\", a \"pop opera\" conceived by and co-starring Todd Almond. Charles Isherwood of \"The New York Times\" praised her performance, noting a \"soft-edged and bewitching\" stage presence, and wrote: \"Her voice, never the most supple or rangy of instruments, retains the singular sound that made her an electrifying front woman for the band Hole: a single sustained noted can seem to simultaneously contain a plea, a wound and a threat.\" The show toured later in the year, with performances in Boston and Los Angeles. In April 2015, the journalist Anthony Bozza sued Love, alleging a contractual violation regarding his co-writing of her memoir. Love performed as the opening act for Lana Del Rey on her Endless Summer Tour for eight West Coast shows in May and June 2015. During her tenure, Love debuted the single \"Miss Narcissist\", released on Wavves' independent label Ghost Ramp. She was also cast in a supporting role in James Franco's film \"The Long Home\", based on the novel by William Gay, her first film role in over ten years; as of 2022, it remains unreleased.\n2016\u2013present: Fashion and forthcoming music.\nIn January 2016, Love released a clothing line in collaboration with Sophia Amoruso, \"Love, Courtney\", featuring 18 pieces reflecting her personal style. In November 2016, she began filming the pilot for \"A Midsummer's Nightmare\", a Shakespeare anthology series adapted for Lifetime. She starred as Kitty Menendez in \"\", a biopic television film based on the lives of Lyle and Erik Menendez, which premiered on Lifetime in June 2017.\nIn 2017, Love accompanied the museum director Nicholas Cullinan to the GQ Men of the Year awards at the Tate Modern, calling him her \"soulmate\" and her \"family for life\".\nIn October 2017, shortly after the Harvey Weinstein scandal made news, a 2005 video of Love warning young actresses about Weinstein went viral. In the footage, while on the red carpet for the \"Comedy Central Roast of Pamela Anderson\", Love was asked by Natasha Leggero if she had any advice for \"a young girl moving to Hollywood\"; she responded, \"If Harvey Weinstein invites you to a private party in the Four Seasons [hotel], don't go.\" She later tweeted, \"Although I wasn't one of his victims, I was eternally banned by [Creative Artists Agency] for speaking out.\"\nIn the same year, Love was cast in Justin Kelly's biopic \"JT LeRoy\", portraying a film producer opposite Laura Dern. In March 2018, she appeared in the music video for Marilyn Manson's \"Tattooed in Reverse\", and in April she appeared as a guest judge on \"RuPaul's Drag Race\". In December, Love was awarded a restraining order against Sam Lutfi, who had acted as her manager for the previous six years, alleging verbal abuse and harassment. Her daughter, Frances, and sister, Jaimee, were also awarded restraining orders against Lutfi. In January 2019, a Los Angeles County judge extended the three-year order to five years, citing Lutfi's tendency to \"prey upon people\".\nOn August 18, 2019, Love performed a solo set at the Yola D\u00eda festival in Los Angeles, which also featured performances by Cat Power and Lykke Li. On September 9, Love garnered press attention when she publicly criticized Joss Sackler, an heiress to the Sackler family OxyContin fortune, after she allegedly offered Love $100,000 to attend her fashion show during New York Fashion Week. In the same statement, Love indicated that she had relapsed into opioid addiction in 2018, stating that she had recently celebrated a year of sobriety. In October 2019, Love relocated from Los Angeles to London.\nOn November 21, 2019, Love recorded the song \"Mother\", written and produced by Lawrence Rothman, as part of the soundtrack for the horror film \"The Turning\" (2020). In January 2020, she received the Icon Award at the \"NME\" Awards; \"NME\" described her as \"one of the most influential singers in alternative culture of the last 30 years\". The following month, she confirmed she was writing a new record which she described as \"really sad\u00a0... [I'm] writing in minor chords, and that appeals to my sadness.\" In March 2021, Love said she had been hospitalized with acute anemia in August 2020, which had nearly killed her and reduced her weight to ; she made a full recovery.\nIn August 2022, Love revealed the completion of her memoir, \"The Girl with the Most Cake\", after a nearly ten-year period of writing.\nLove is featured as a guest vocalist on the track \"Song to the Siren\" by rapper 070 Shake, from her studio album \"Petrichor\", which was released on November 15, 2024.\nArtistry.\nInfluences.\nLove has been candid about her diverse musical influences, the earliest being Patti Smith, the Runaways, and the Pretenders, artists she discovered while in juvenile hall as a young teenager. As a child, her first exposure to music was records that her parents received each month through Columbia Record Club. The first record Love owned was Leonard Cohen's \"Songs of Leonard Cohen\" (1967), which she obtained from her mother: \"He was so lyric-conscious and morbid, and I was a pretty morbid kid\", she recalled. As a teenager, she named Flipper, Kate Bush, Soft Cell, Joni Mitchell, Laura Nyro, Lou Reed, and Dead Kennedys among her favorite artists. While in Dublin at age fifteen, Love attended a Virgin Prunes concert, an event she credited as being a pivotal influence: \"I had never seen so much sex, snarl, poetry, evil, restraint, grace, filth, raw power and the very essence of rock and roll\", she recalled. \"[I had seen] U2 [who] gave me lashes of love and inspiration, and a few nights later the Virgin Prunes fuckedmeup.\" Decades later, in 2009, Love introduced the band's frontman Gavin Friday at a Carnegie Hall event, and performed a song with him.\nThough often associated with punk music, Love has noted that her most significant musical influences have been post-punk and new wave artists. Commenting in 2021, Love said: Over the years, Love has also named several other new wave and post-punk bands as influences, including the Smiths, Siouxsie and the Banshees, Television, and Bauhaus.\nLove's diverse genre interests were illustrated in a 1991 interview with \"Flipside\", in which she stated: \"There's a part of me that wants to have a grindcore band and another that wants to have a Raspberries-type pop band.\" Discussing the abrasive sound of Hole's debut album, she said she felt she had to \"catch up with all my hip peers who'd gone all indie on me, and who made fun of me for liking R.E.M. and The Smiths.\" She has also embraced the influence of experimental artists and punk rock groups, including Sonic Youth, Swans, Big Black, Diamanda Gal\u00e1s, the Germs, and the Stooges. While writing \"Celebrity Skin\", she drew influence from Neil Young and My Bloody Valentine. She has also cited her contemporary PJ Harvey as an influence, saying: \"The one rock star that makes me know I'm shit is Polly Harvey. I'm nothing next to the purity that she experiences.\"\nLiterature and poetry have often been a major influence on her songwriting; Love said she had \"always wanted to be a poet, but there was no money in it.\" She has named the works of T. S. Eliot and Charles Baudelaire as influential, and referenced works by Dante Rossetti, William Shakespeare, Rudyard Kipling, and Anne Sexton in her lyrics.\nMusical style and lyrics.\nMusically, Love's work with Hole and her solo efforts have been characterized as alternative rock; Hole's early material, however, was described by critics as being stylistically closer to grindcore and aggressive punk rock. \"Spin\"s October 1991 review of Hole's first album noted Love's layering of harsh and abrasive riffs buried more sophisticated musical arrangements. In 1998, she stated that Hole had \"always been a pop band. We always had a subtext of pop. I always talked about it, if you go back\u00a0... what'll sound like some weird Sonic Youth tuning back then to you was sounding like the Raspberries to me, in my demented pop framework.\"\nLove's lyrics are composed from a female's point of view, and her lyrics have been described as \"literate and mordant\" and noted by scholars for \"articulating a third-wave feminist consciousness.\" Simon Reynolds, in reviewing Hole's debut album, noted: \"Ms. Love's songs explore the full spectrum of female emotions, from vulnerability to rage. The songs are fueled by adolescent traumas, feelings of disgust about the body, passionate friendships with women and the desire to escape domesticity. Her lyrical style could be described as emotional nudism.\" Journalist and critic Kim France, in critiquing Love's lyrics, referred to her as a \"dark genius\" and likened her work to that of Anne Sexton.\nLove has remarked that lyrics have always been the most important component of songwriting for her: \"The important thing for me\u00a0... is it has to look good on the page. I mean, you can love Led Zeppelin and not love their lyrics\u00a0... but I made a big effort in my career to have what's on the page mean something.\" Common themes present in Love's lyrics during her early career included body image, rape, suicide, conformity, pregnancy, prostitution, and death. In a 1991 interview with Everett True, she said: \"I try to place [beautiful imagery] next to fucked up imagery, because that's how I view things\u00a0... I sometimes feel that no one's taken the time to write about certain things in rock, that there's a certain female point of view that's never been given space.\"\nCritics have noted that Love's later musical work is more lyrically introspective. \"Celebrity Skin\" and \"America's Sweetheart\" are lyrically centered on celebrity life, Hollywood, and drug addiction, while continuing Love's interest in vanity and body image. \"Nobody's Daughter\" was lyrically reflective of Love's past relationships and her struggle for sobriety, with the majority of its lyrics written while she was in rehab in 2006.\nPerformance.\nLove has a contralto vocal range. According to Love, she never wanted to be a singer, but rather aspired to be a skilled guitarist: \"I'm such a lazy bastard though that I never did that\", she said. \"I was always the only person with the nerve to sing, and so I got stuck with it.\" She has been regularly noted by critics for her husky vocals as well as her \"banshee [-like]\" screaming abilities. Her vocals have been compared to those of Johnny Rotten, and David Fricke of \"Rolling Stone\" described them as \"lung-busting\" and \"a corrosive, lunatic wail\". Upon the release of Hole's 2010 album, \"Nobody's Daughter\", Amanda Petrusich of \"Pitchfork\" compared Love's raspy, unpolished vocals to those of Bob Dylan. In 2023, \"Rolling Stone\" ranked Love at number 130 on its list of the 200 Greatest Singers of All Time.\nShe has played a variety of Fender guitars throughout her career, including a Jaguar and a vintage 1965 Jazzmaster; the latter was purchased by the Hard Rock Cafe and is on display in New York City. Between 1989 and 1991, Love primarily played a Rickenbacker 425 because she \"preferred the 3/4 neck\", but she destroyed the guitar onstage at a 1991 concert opening for the Smashing Pumpkins. In the mid-1990s, she often played a guitar made by Mercury, an obscure company that manufactured custom guitars, as well as a Univox Hi-Flier. Fender's Vista Venus, designed by Love in 1998, was partially inspired by Rickenbacker guitars as well as her Mercury. During tours after the release of \"Nobody's Daughter\" (post-2010), Love has played a Rickenbacker 360 onstage. Her setup has included Fender tube gear, Matchless, Ampeg, Silvertone and a solid-state 1976 Randall Commander.\nLove has referred to herself as \"a shit guitar player\", further commenting in a 2014 interview: \"I can still write a song, but [the guitar playing] sounds like shit\u00a0... I used to be a good rhythm player but I am no longer dependable.\" Throughout her career, she has also garnered a reputation for unpredictable live shows. In the 1990s, her performances with Hole were characterized by confrontational behavior, with Love stage diving, smashing guitars or throwing them into the audience, wandering into the crowd at the end of sets, and engaging in sometimes incoherent rants. Critics and journalists have noted Love for her comical, often stream-of-consciousness-like stage banter. Music journalist Robert Hilburn wrote in 1993 that, \"rather than simply scripted patter, Love's comments between songs [have] the natural feel of someone who is sharing her immediate feelings.\" In a review of a live performance published in 2010, it was noted that Love's onstage \"one-liners [were] worthy of the Comedy Store.\"\nPhilanthropy.\nIn 1993, Love and husband Kurt Cobain performed an acoustic set together at the Rock Against Rape benefit in Los Angeles, which raised awareness and provided resources for victims of sexual abuse. In 2000, Love publicly advocated for reform of the record industry in a personal letter published by \"Salon\". In the letter, Love said: \"It's not piracy when kids swap music over the Internet using Napster or Gnutella or Freenet or iMesh or beaming their CDs into a My.MP3.com or MyPlay.com music locker. It's piracy when those guys that run those companies make side deals with the cartel lawyers and label heads so that they can be 'the label's friend', and not the artists'.\" In a subsequent interview with Carrie Fisher, she said that she was interested in starting a union for recording artists, and also discussed race relations in the music industry, advocating for record companies to \"put money back into the black community [whom] white people have been stealing from for years.\"\nLove has been a long-standing supporter of LGBT causes. She has frequently collaborated with Los Angeles Gay and Lesbian Center, taking part in the center's \"An Evening with Women\" events. The proceeds of the event help provide food and shelter for homeless youth; services for seniors; legal assistance; domestic violence services; health and mental health services, and cultural arts programs. Love participated with Linda Perry for the event in 2012, and performed alongside Aimee Mann and comedian Wanda Sykes. Speaking on her collaboration on the event, Love said: \"Seven thousand kids in Los Angeles a year go out on the street, and forty percent of those kids are gay, lesbian, or transgender. They come out to their parents, and become homeless\u00a0... for whatever reason, I don't really know why, but gay men have a lot of foundations\u2014I've played many of them\u2014but the lesbian side of it doesn't have as much money and/or donors, so we're excited that this has grown to cover women and women's affairs.\"\nShe has also contributed to AIDS organizations, partaking in benefits for amfAR and the RED Campaign. In May 2011, she donated six of her husband Cobain's personal vinyl records for auction at Mariska Hargitay's Joyful Heart Foundation event for victims of child abuse, rape, and domestic violence. She has also supported the Sophie Lancaster Foundation.\nLegacy.\nLove has had an impact on female-fronted alternative acts and performers. She has been cited as influential on young female instrumentalists in particular, having once infamously proclaimed: \"I want every girl in the world to pick up a guitar and start screaming\u00a0... I strap on that motherfucking guitar and you cannot fuck with me. That's my feeling.\" In \"The Electric Guitar: A History of an American Icon\", it is noted: \nWith over 3 million records sold in the United States alone, Hole became one of the most successful rock bands of all time fronted by a woman. VH1 ranked Love 69 in their list of \"The 100 Greatest Women in Music History\" in 2012. In 2015, the \"Phoenix New Times\" declared Love the number one greatest female rock star of all time, writing: \"To build a perfect rock star, there are several crucial ingredients: musical talent, physical attractiveness, tumultuous relationships, substance abuse, and public meltdowns, just to name a few. These days, Love seems to have rebounded from her epic tailspin and has leveled out in a slightly more normal manner, but there's no doubt that her life to date is the type of story people wouldn't believe in a novel or a movie.\"\nAmong the alternative musicians who have cited Love as an influence are Scout Niblett; Brody Dalle of The Distillers; Dee Dee Penny of Dum Dum Girls; Florence Welch; Annie Hardy of Giant Drag; and Nine Black Alps. Contemporary female pop artists Lana Del Rey, Avril Lavigne, Tove Lo, and Sky Ferreira have also cited Love as an influence. Love has frequently been recognized as the most high-profile contributor of feminist music during the 1990s, and for \"subverting [the] mainstream expectations of how a woman should look, act, and sound.\" According to music journalist Maria Raha, \"Hole was the highest-profile female-fronted band of the '90s to openly and directly sing about feminism.\" Patti Smith, a major influence of Love's, also praised her, saying: \"I hate genderizing things\u00a0... [but] when I heard Hole, I was amazed to hear a girl sing like that. Janis Joplin was her own thing; she was into Big Mama Thornton and Bessie Smith. But what Courtney Love does, I'd never heard a girl do that.\"\nShe has also been a gay icon since the mid-1990s, and has jokingly referred to her fanbase as consisting of \"females, gay guys, and a few advanced, evolved heterosexual men.\" Love's aesthetic image, particularly in the early 1990s, also became influential and was dubbed \"kinderwhore\" by critics and media. The subversive fashion mainly consisted of vintage babydoll dresses accompanied by smeared makeup and red lipstick. MTV reporter Kurt Loder described Love as looking like \"a debauched rag doll\" onstage. Love later said she had been influenced by the fashion of Chrissy Amphlett of the Divinyls. Interviewed in 1994, Love commented \"I would like to think\u2013in my heart of hearts\u2013that I'm changing some psychosexual aspects of rock music. Not that I'm so desirable. I didn't do the kinder-whore thing because I thought I was so hot. When I see the look used to make one more appealing, it pisses me off. When I started, it was a \"What Ever Happened to Baby Jane?\" thing. My angle was irony.\""}
{"id": "5657", "revid": "140154", "url": "https://en.wikipedia.org/wiki?curid=5657", "title": "Cow (disambiguation)", "text": "Cow most commonly refers to adult female cattle, and colloquially used to refer to cattle in general. \nCow, cows or COW may also refer to:"}
{"id": "5658", "revid": "45627014", "url": "https://en.wikipedia.org/wiki?curid=5658", "title": "Human cannibalism", "text": "Human cannibalism is the act or practice of humans eating the flesh or internal organs of other human beings. A person who practices cannibalism is called a cannibal. The meaning of \"cannibalism\" has been extended into zoology to describe animals consuming parts of individuals of the same species as food.\nAnatomically modern humans, Neanderthals, and \"Homo antecessor\" are known to have practised cannibalism to some extent in the Pleistocene. Cannibalism was occasionally practised in Egypt during ancient and Roman times, as well as later during severe famines. The Island Caribs of the Lesser Antilles, whose name is the origin of the word \"cannibal\", acquired a long-standing reputation as eaters of human flesh, reconfirmed when their legends were recorded in the 17th century. Some controversy exists over the accuracy of these legends and the prevalence of actual cannibalism in the culture. Depicting indigenous peoples as cannibals was a common fantasy and rationale for European colonialism and 'civilising missions'.\nCannibalism has been well documented in much of the world, including Fiji (once nicknamed the \"Cannibal Isles\"), the Amazon Basin, the Congo, and the M\u0101ori people of New Zealand. Cannibalism was also practised in New Guinea and in parts of the Solomon Islands, and human flesh was sold at markets in some parts of Melanesia and of the Congo Basin. A form of cannibalism popular in early modern Europe was the consumption of body parts or blood for medical purposes. Reaching its height during the 17th century, this practice continued in some cases into the second half of the 19th century.\nCannibalism has occasionally been practised as a last resort by people suffering from famine. Well-known examples include the ill-fated Donner Party (1846\u20131847), the Holodomor (1932\u20131933), and the crash of Uruguayan Air Force Flight 571 (1972), after which the survivors ate the bodies of the dead. Additionally, there are cases of people engaging in cannibalism for sexual pleasure, such as Albert Fish, Issei Sagawa, Jeffrey Dahmer, and Armin Meiwes. Cannibalism has been both practised and fiercely condemned in several recent wars, especially in Liberia and the Democratic Republic of the Congo. It was still practised in Papua New Guinea as of 2012, for cultural reasons.\nCannibalism has been said to test the bounds of cultural relativism because it challenges anthropologists \"to define what is or is not beyond the pale of acceptable human behavior\". A few scholars argue that no firm evidence exists that cannibalism has ever been a socially acceptable practice anywhere in the world, but such views have been largely rejected as irreconcilable with the actual evidence.\nEtymology.\nThe word \"cannibal\" is derived from Spanish \"can\u00edbal\" or \"car\u00edbal\", originally used as a name variant for the Kalinago (Island Caribs), a people from the West Indies said to have eaten human flesh. The older term \"anthropophagy\", meaning \"eating humans\", is also used for human cannibalism.\nReasons and types.\nCannibalism has been practised under a variety of circumstances and for various motives. To adequately express this diversity, Shirley Lindenbaum suggests that \"it might be better to talk about 'cannibalisms in the plural.\nInstitutionalized, survival, and pathological cannibalism.\nOne major distinction is whether cannibal acts are accepted by the culture in which they occur (\"institutionalized cannibalism\"), or whether they are merely practised under starvation conditions to ensure one's immediate survival (\"survival cannibalism\"), or by isolated individuals considered criminal and often pathological by society at large (\"cannibalism as psychopathology\" or as \"aberrant behavior\").\nInstitutionalized cannibalism, sometimes also called \"learned cannibalism\", is the consumption of human body parts as \"an institutionalized practice\" generally accepted in the culture where it occurs.\nBy contrast, survival cannibalism means \"the consumption of others under conditions of starvation such as shipwreck, military siege, and famine, in which persons normally averse to the idea are driven [to it] by the will to live\". Also known as \"famine cannibalism\", such forms of cannibalism resorted to only in situations of extreme necessity have occurred in many cultures where cannibalism is otherwise clearly rejected. The survivors of the shipwrecks of the \"Essex\" and \"M\u00e9duse\" in the 19th century are said to have engaged in cannibalism, as did the members of Franklin's lost expedition and the Donner Party.\nSuch cases often involve only \"necro-cannibalism\" (eating the corpse of someone already dead) as opposed to \"homicidal cannibalism\" (killing someone for food). In modern English law, the latter is always considered a crime, even in the most trying circumstances. The case of \"R v Dudley and Stephens\", in which two men were found guilty of murder for killing and eating a cabin boy while adrift at sea in a lifeboat, set the precedent that necessity is no defence to a charge of murder. This decision outlawed and effectively ended the practice of shipwrecked sailors drawing lots in order to determine who would be killed and eaten to prevent the others from starving, a time-honoured practice formerly known as a \"custom of the sea\".\nIn other cases, cannibalism is an expression of a psychopathology or mental disorder, condemned by the society in which it occurs and \"considered to be an indicator of [a] severe personality disorder or psychosis\". Well-known cases include Albert Fish, Issei Sagawa, and Armin Meiwes. Fantasies of cannibalism, whether acted out or not, are not specifically mentioned in manuals of mental disorders such as the \"DSM\", presumably because at least serious cases (that lead to murder) are very rare.\nExo-, endo-, and autocannibalism.\nWithin institutionalized cannibalism, \"exocannibalism\" is often distinguished from \"endocannibalism\". Endocannibalism refers to the consumption of a person from the same community. Often it is a part of a funerary ceremony, similar to burial or cremation in other cultures. The consumption of the recently deceased in such rites can be considered \"an act of affection\" and a major part of the grieving process. It has also been explained as a way of guiding the souls of the dead into the bodies of living descendants.\nIn contrast, exocannibalism is the consumption of a person from outside the community. It is frequently \"an act of aggression, often in the context of warfare\", where the flesh of killed or captured enemies may be eaten to celebrate one's victory over them.\nSome scholars explain both types of cannibalism as due to a belief that eating a person's flesh or internal organs will endow the cannibal with some of the positive characteristics of the deceased. However, several authors investigating exocannibalism in New Zealand, New Guinea, and the Congo Basin observe that such beliefs were absent in these regions.\nA further type, different from both exo- and endocannibalism, is \"autocannibalism\" (also called \"autophagy\" or \"self-cannibalism\"), \"the act of eating parts of oneself\". It does not ever seem to have been an institutionalized practice, but occasionally occurs as pathological behaviour, or due to other reasons such as curiosity. Also on record are instances of forced autocannibalism committed as acts of aggression, where individuals are forced to eat parts of their own bodies as a form of torture.\nExocannibalism is thus often associated with the consumption of enemies as an act of aggression, a practice also known as \"war cannibalism\". Endocannibalism is often associated with the consumption of deceased relatives in funerary rites driven by a practice known as \"funerary\" or \"mortuary cannibalism\".\nAdditional motives.\n\"Medicinal cannibalism\" (also called \"medical cannibalism\") means \"the ingestion of human tissue\u00a0... as a supposed medicine or tonic\". In contrast to other forms of cannibalism, which Europeans generally frowned upon, the \"medicinal ingestion\" of various \"human body parts was widely practiced throughout Europe from the sixteenth to the eighteenth centuries\", with early records of the practice going back to the first century CE. It was also frequently practised in China.\n\"Sacrificial cannibalism\" refers the consumption of the flesh of victims of human sacrifice, for example among the Aztecs. Human and animal remains excavated in Knossos, Crete, have been interpreted as evidence of a ritual in which children and sheep were sacrificed and eaten together during the Bronze Age. According to Ancient Roman reports, the Celts in Britain practised sacrificial cannibalism, and archaeological evidence backing these claims has by now been found.\n\"Infanticidal cannibalism\" or \"cannibalistic infanticide\" refers to cases where newborns or infants are killed because they are \"considered unwanted or unfit to live\" and then \"consumed by the mother, father, both parents or close relatives\".\nInfanticide followed by cannibalism was practised in various regions, but is particularly well documented among Aboriginal Australians. Among animals, such behaviour is called \"filial cannibalism\", and it is common in many species, especially among fish.\n\"Human predation\" is the hunting of people from unrelated and possibly hostile groups in order to eat them. In parts of the Southern New Guinea lowland rain forests, hunting people \"was an opportunistic extension of seasonal foraging or pillaging strategies\", with human bodies just as welcome as those of animals as sources of protein, according to the anthropologist Bruce M. Knauft. As populations living near coasts and rivers were usually better nourished and hence often physically larger and stronger than those living inland, they \"raided inland 'bush' peoples with impunity and often with little fear of retaliation\". Cases of human predation are also on record for the neighbouring Bismarck Archipelago and for Australia. In the Congo Basin, there lived groups such as the Bankutu who hunted humans for food even when game was plentiful.\nThe term \"innocent cannibalism\" has been used for cases of people eating human flesh without knowing what they are eating. It is a subject of myths, such as the myth of Thyestes who unknowingly ate the flesh of his own sons. There are also actual cases on record, for example from the Congo Basin, where cannibalism had been quite widespread and where even in the 1950s travellers were sometimes served a meat dish, learning only afterwards that the meat had been of human origin.\nGastronomic and functionalist explanations.\nThe term \"gastronomic cannibalism\" has been suggested for cases where human flesh is eaten to \"provide a supplement to the regular thus essentially for its nutritional or, in an alternative definition, for cases where it is \"eaten without ceremony (other than culinary), in the same manner as the flesh of any other animal\". While the term has been criticized as being too vague to clearly identify a specific type of cannibalism, various records indicate that nutritional or culinary concerns could indeed play a role in such acts even outside of periods of starvation. Referring to the Congo Basin, where many of the eaten were butchered slaves rather than enemies killed in war, the anthropologist Emil Torday notes that \"the most common [reason for cannibalism] was simply gastronomic: the natives loved 'the flesh that speaks' [as human flesh was commonly called] and paid for it\". The historian Key Ray Chong observes that, throughout Chinese history, \"learned cannibalism was often practiced\u00a0... for culinary appreciation\".\nIn his popular book \"Guns, Germs and Steel\", Jared Diamond suggests that \"protein starvation is probably also the ultimate reason why cannibalism was widespread in traditional New Guinea highland societies\", and both in New Zealand and Fiji, cannibals explained their acts as due to a lack of animal meat. In Liberia, a former cannibal argued that it would have been wasteful to let the flesh of killed enemies spoil, and eaters of human flesh in New Guinea and the neighbouring Bismarck Archipelago expressed the same sentiment.\nIn many cases, human flesh was also described as particularly delicious, especially when it came from women, children, or both. Such statements are on record for various regions and peoples, including the Aztecs, today's Liberia and Nigeria, the Fang people in west-central Africa, the Congo Basin, China up to the 14th century, Sumatra, Borneo, Australia, New Guinea, New Zealand, Vanuatu, and Fiji.\nSome Europeans and Americans who ate human flesh accidentally, out of curiosity, or to comply with local customs likewise tended to describe it as very good.\nThere is a debate among anthropologists on how important functionalist reasons are for the understanding of institutionalized cannibalism. Diamond is not alone in suggesting \"that the consumption of human flesh was of nutritional benefit for some populations in New Guinea\" and the same case has been made for other \"tropical peoples\u00a0... exploiting a diverse range of animal foods\", including human flesh. The materialist anthropologist Marvin Harris argued that a \"shortage of animal protein\" was also the underlying reason for Aztec cannibalism. The cultural anthropologist Marshall Sahlins, on the other hand, rejected such explanations as overly simplistic, stressing that cannibal customs must be regarded as \"complex phenomen[a]\" with \"myriad attributes\" which can only be understood if one considers \"symbolism, ritual, and cosmology\" in addition to their \"practical function\".\nIn pre-modern medicine, an explanation given by the now-discredited theory of humorism for cannibalism was that it was caused by a black acrimonious humor, which, being lodged in the linings of the ventricles of the heart, produced a voracity for human flesh. On the other hand, the French philosopher Michel de Montaigne understood war cannibalism as a way of expressing vengeance and hatred towards one's enemies and celebrating one's victory over them, thus giving an interpretation that is close to modern explanations. He also pointed out that some acts of Europeans in his own time could be considered as equally barbarous, making his essay \"Of Cannibals\" () a precursor to later ideas of cultural relativism.\nBody parts and culinary practices.\nNutritional value of the human body.\nArchaeologist James Cole investigated the nutritional value of the human body and found it to be similar to that of animals of similar size.\nHe notes that, according to ethnographic and archaeological records, nearly all edible parts of humans were sometimes eaten \u2013 not only skeletal muscle tissue (\"flesh\" or \"meat\" in a narrow sense), but also \"lungs, liver, brain, heart, nervous tissue, bone marrow, genitalia and skin\", as well as kidneys. For a typical adult man, the combined nutritional value of all these edible parts is about 126,000 kilocalories (kcal). The nutritional value of women and younger individuals is lower because of their lower body weight \u2013 for example, around 86% of a male adult for an adult woman and 30% for a boy aged around 5 or 6.\nAs the daily energy need of an adult man is about 2,400 kilocalories, a dead male body could thus have fed a group of 25 men for a bit more than two days, provided they ate nothing but the human flesh alone \u2013 longer if it was part of a mixed diet. The nutritional value of the human body is thus not insubstantial, though Cole notes that for prehistoric hunters, large megafauna such as mammoths, rhinoceros, and bisons would have been an even better deal as long as they were available and could be caught, because of their much higher body weight.\nHearts and livers.\nCases of people eating human livers and hearts, especially of enemies, have been reported from across the world. After the Battle of Uhud (625), Hind bint Utba ate (or at least attempted to) the liver of Hamza ibn Abd al-Muttalib, an uncle of Muhammad. At that time, the liver was considered \"the seat of life\".\nFrench Catholics ate livers and hearts of Huguenots at the St. Bartholomew's Day massacre in 1572, in some cases also offering them for sale.\nIn China, medical cannibalism was practised over centuries. People voluntarily cut their own body parts, including parts of their livers, and boiled them to cure ailing relatives. Children were sometimes killed because eating their boiled hearts was considered a good way of extending one's life. Emperor Wuzong of Tang supposedly ordered provincial officials to send him \"the hearts and livers of fifteen-year-old boys and girls\" when he had become seriously ill, hoping in vain that this folk \"medicine\" would cure him. Later, private individuals sometimes followed his example, paying soldiers who kidnapped preteen children for their kitchen.\nWhen \"human flesh and organs were sold openly at the marketplace\" during the Taiping Rebellion in 1850\u20131864, human hearts became a popular dish, according to some who afterwards freely admitted having consumed them.\nAccording to a missionary's report from the brutal suppression of the Dungan Revolt of 1895\u20131896 in northwestern China, \"thousands of men, women and children were ruthlessly massacred by the imperial soldiers\" and \"many a meal of human hearts and livers was partaken of by soldiers\", supposedly out of a belief that this would give them \"the courage their enemies had displayed\".\nIn World War II, Japanese soldiers ate the livers of killed Americans in the Chichijima incident.\nMany Japanese soldiers who died during the occupation of Jolo Island in the Philippines had their livers eaten by local Moro fighters, according to Japanese soldier Fujioka Akiyoshi.\nDuring the Cultural Revolution (1966\u20131976), hundreds of incidents of cannibalism occurred, mostly motivated by hatred against supposed \"class enemies\", but sometimes also by health concerns. In a case recorded by the local authorities, a school teacher in Mengshan County \"heard that consuming a 'beauty's heart' could cure disease\". He then chose a 13- or 14-year-old student of his and publicly denounced her as a member of the enemy faction, which was enough to get her killed by an angry mob. After the others had left, he \"cut open the girl's chest\u00a0..., dug out her heart, and took it home to enjoy\".\nIn a further case that took place in Wuxuan County, likewise in the Guangxi region, three brothers were beaten to death as supposed enemies; afterwards their livers were cut out, baked, and consumed \"as medicine\".\nAccording to the Chinese writer Zheng Yi, who researched these events, \"the consumption of human liver was mentioned at least fifty or sixty times\" in just a small number of archival documents. He talked with a man who had eaten human liver and told him that \"barbecued liver is delicious\".\nDuring a massacre of the Madurese minority in the Indonesian part of Borneo in 1999, reporter Richard Lloyd Parry met a young cannibal who had just participated in a \"human barbecue\" and told him without hesitation: \"It tastes just like chicken. Especially the liver \u2013 just the same as chicken.\" In 2013, during the Syrian civil war, Syrian rebel Abu Sakkar was filmed eating parts of the lung or liver of a government soldier while declaring that \"We will eat your hearts and your livers you soldiers of Bashar the dog\".\nBreasts, palms, and soles.\nVarious accounts from around the world mention women's breasts as a\nfavourite body part. Also frequently mentioned are the palms of the hands and sometimes the soles of the feet, regardless of the victim's gender.\nJerome, in his treatise \"Against Jovinianus\", claimed that the British Attacotti were cannibals who\nregarded the buttocks of men and the breasts of women as delicacies.\nDuring the Mongol invasion of Europe in the 13th century and their subsequent rule over China during the Yuan dynasty (1271\u20131368), some Mongol fighters practised cannibalism and both European and Chinese observers record a preference for women's breasts, which were considered \"delicacies\" and, if there were many corpses, sometimes the only part of a female body that was eaten (of men, only the thighs were said to be eaten in such circumstances).\nAfter meeting a group of cannibals in West Africa in the 14th century, the Moroccan explorer Ibn Battuta recorded that, according to their preferences, \"the tastiest part of women's flesh is the palms and the breast.\"\nCenturies later, the anthropologist wrote that, in southern Nigeria, \"the parts in greatest favour are the palms of the hands, the fingers and toes, and, of a woman, the breast.\"\nRegarding the north of the country, his colleague Charles Kingsley Meek added: \"Among all the cannibal tribes the palms of the hands and the soles of the feet were considered the tit-bits of the body.\"\nAmong the Apambia, a cannibalistic clan of the Azande people in Central Africa, palms and soles were considered the best parts of the human body, while their favourite dish was prepared with \"fat from a woman's breast\", according to the missionary and ethnographer F. Gero.\nSimilar preferences are on record throughout Melanesia. According to the anthropologists Bernard Deacon and Camilla Wedgwood, women were \"specially fattened for eating\" in Vanuatu, \"the breasts being the great delicacy\". A missionary confirmed that \"a body of a female usually formed the principal part of the repast\" at feasts for chiefs and warriors.\nThe ethnologist writes: \"Apart from the breasts of women and the genitals of men, palms of hands and soles of feet were the most coveted morsels.\" He knew a chief on Ambae, one of the islands of Vanuatu, who, \"according to fairly reliably sources\", dined on a young girl's breasts every few days.\nWhen visiting the Solomon Islands in the 1980s, anthropologist Michael Krieger met a former cannibal who told him that women's breasts had been considered the best part of the human body because they were so fatty, with fat being a rare and sought delicacy.\nThey were also considered among the best parts in New Guinea and the Bismarck Archipelago.\nModes of preparation.\nBased on theoretical considerations, the structuralist anthropologist Claude L\u00e9vi-Strauss suggested that human flesh was most typically boiled, with roasting also used to prepare the bodies of enemies and other outsiders in exocannibalism, but rarely in funerary endocannibalism (when eating deceased relatives).\nBut an analysis of 60 sufficiently detailed and credible descriptions of institutionalized cannibalism by anthropologist Paul Shankman failed to confirm this hypothesis. Shankman found that roasting and boiling together accounted for only about half of the cases, with roasting being slightly more common. In contrast to L\u00e9vi-Strauss's predictions, boiling was more often used in exocannibalism, while roasting was about equally common for both.\nShankman observed that various other \"ways of preparing people\" were repeatedly employed as well; in one third of all cases, two or more modes were used together (e.g. some bodies or body parts were boiled or baked, while others were roasted). Human flesh was baked in steam on preheated rocks or in earth ovens (a technique widely used in the Pacific), smoked (which allowed to preserve it for later consumption), or eaten raw. While these modes were used in both exo- and endocannibalism, another method that was only used in the latter and only in the Americas was to burn the bones or bodies of deceased relatives and then to consume the bone ash.\nAfter analysing numerous accounts from China, Key Ray Chong similarly concludes that \"a variety of methods for cooking human flesh\" were used in this country. Most popular were \"broiling, roasting, boiling and steaming\", followed by \"pickling in salt, wine, sauce and the like\". Human flesh was also often \"cooked into soup\" or stewed in cauldrons. Eating human flesh raw was the \"least popular\" method, but a few cases are on record too. Chong notes that human flesh was typically cooked in the same way as \"ordinary foodstuffs for daily consumption\" \u2013 no principal distinction from the treatment of animal meat is detectable, and nearly any mode of preparation used for animals could also be used for people.\nWhole-body roasting and baking.\nThough human corpses, like those of animals, were usually cut into pieces for further processing, reports of people being roasted or baked whole are on record throughout the world.\nAt the archaeological site of Herxheim, Germany, more than a thousand people were killed and eaten about 7000 years ago, and the evidence indicates that many of them were spit-roasted whole over open fires.\nDuring severe famines in China and Egypt during the 12th and early 13th centuries, there was a black-market trade in corpses of little children that were roasted or boiled whole.\nIn China, human-flesh sellers advertised such corpses as good for being boiled or steamed whole, \"including their bones\", and praised their particular tenderness.\nIn Cairo, Egypt, the Arab physician Abd al-Latif al-Baghdadi repeatedly saw \"little children, roasted or boiled\", offered for sale in baskets on street corners during a heavy famine that started in 1200 CE.\nOlder children and possibly adults were sometimes prepared in the same way.\nOnce he saw \"a child nearing the age of puberty, who had been found roasted\"; two young people confessed to having killed and cooked the child.\nAnother time, remains were found of a person who had apparently been roasted and served whole, the legs tied like those of \"a sheep trussed for cooking\".\nOnly the skeleton was found, still undivided and in the trussed position, but \"with all the flesh stripped off for food\".\nIn some cases children were roasted and offered for sale by their own parents; other victims were street children, who had become very numerous and were often kidnapped and cooked by people looking for food or extra income.\nThe victims were so numerous that sometimes \"two or three children, even more, would be found in a single cooking pot.\"\nAl-Latif notes that, while initially people were shocked by such acts, they \"eventually\u00a0... grew accustomed, and some conceived such a taste for these detestable meats that they made them their ordinary provender\u00a0... The horror people had felt at first vanished entirely\".\nAfter the end of the Mongol-led Yuan dynasty (1271\u20131368), a Chinese writer criticized in his recollections of the period that some Mongol soldiers ate human flesh because of its taste rather than (as had also occurred in other times) merely in cases of necessity. He added that they enjoyed torturing their victims (often children or women, whose flesh was preferred over that of men) by roasting them alive, in \"large jars whose outside touched the fire [or] on an iron grate\".\nOther victims were placed \"inside a double bag\u00a0... which was put into a large pot\" and so boiled alive.\nWhile not mentioning live roasting or boiling, European authors also complained about cannibalism and cruelty during the Mongol invasion of Europe, and a drawing in the \"Chronica Majora\" (compiled by Matthew Paris) shows Mongol fighters spit-roasting a human victim.\n, who accompanied Christopher Columbus during his second voyage, afterwards stated \"that he saw there with his own eyes several Indians skewered on spits being roasted over burning coals as a treat for the gluttonous.\"\nJean de L\u00e9ry, who lived for several months among the Tupinamb\u00e1 in Brazil, writes that several of his companions reported \"that they had seen not only a number of men and women cut in pieces and grilled on the \"boucans\", but also little unweaned children roasted whole\" after a successful attack on an enemy village.\nAccording to German ethnologist Leo Frobenius, children captured by Songye slave raiders in the Central African Kasa\u00ef region that were too young to be sold with a profit were instead \"skewered on long spears like rats and roasted over a quickly kindled large fire\" for consumption by the raiders.\nIn the Solomon Islands in the 1870s, a British captain saw a \"dead body, dressed and cooked whole\" offered for sale in a canoe. A settler treated the scene as \"an every-day occurrence\" and told him \"that he had seen as many as twenty bodies lying on the beach, dressed and cooked\". Decades later, a missionary reported that whole bodies were still offered \"up and down the coast in canoes for sale\" after battles, since human flesh was eaten \"for pleasure\".\nIn Fiji, whole human bodies cooked in earth ovens were served in carefully pre-arranged postures, according to anthropologist Lorimer Fison and several other sources:\nWithin this archipelago, it was especially the Gau Islanders who \"were famous for cooking bodies whole\".\nIn New Caledonia, a missionary named Ta'unga from the Cook Islands repeatedly saw how whole human bodies were cooked in earth ovens: \"They tie the hands together and bundle them up together with the intestines. The legs are bent up and bound with hibiscus bark. When it is completed they lay the body out flat on its back in the earth oven, then when it is baked ready they cut it up and eat it.\" Ta'unga commented: \"One curious thing is that when a man is alive he has a human appearance, but after he is baked he looks more like a dog, as the lips are shriveled back and his teeth are bared.\"\nAmong the M\u0101ori in New Zealand, children captured in war campaigns were sometimes spit-roasted whole (after slitting open their bellies to remove the intestines), as various sources report. Enslaved children, including teenagers, could meet the same fate, and whole babies were sometimes served at the tables of chiefs.\nIn the Marquesas Islands, captives (preferably women) killed for consumption \"were spitted on long poles that entered between their legs and emerged from their mouths\" and then roasted whole. Similar customs had a long history: In Nuku Hiva, the largest of these islands, archaeologists found the partially consumed \"remains of a young child\" that had been roasted whole in an oven during the 14th century or earlier.\nMedical aspects.\nA well-known case of mortuary cannibalism is that of the Fore tribe in New Guinea, which resulted in the spread of the prion disease kuru. Although the Fore's mortuary cannibalism was well-documented, the practice had ceased before the cause of the disease was recognized. However, some scholars argue that although post-mortem dismemberment was the practice during funeral rites, cannibalism was not. Marvin Harris theorizes that it happened during a famine period coincident with the arrival of Europeans and was rationalized as a religious rite.\nIn 2003, a publication in \"Science\" received a large amount of press attention when it suggested that early humans may have practised extensive cannibalism. According to this research, genetic markers commonly found in modern humans worldwide suggest that today many people carry a gene that evolved as protection against the brain diseases that can be spread by consuming human brain tissue. A 2006 reanalysis of the data questioned this hypothesis, because it claimed to have found a data collection bias, which led to an erroneous conclusion. This claimed bias came from incidents of cannibalism used in the analysis not being due to local cultures, but having been carried out by explorers, stranded seafarers or escaped convicts. The original authors published a subsequent paper in 2008 defending their conclusions.\nMyths, legends and folklore.\nCannibalism features in the folklore and legends of many cultures and is most often attributed to evil characters or as extreme retribution for some wrongdoing. Examples include the witch in \"Hansel and Gretel\", Lamia of Greek mythology, the witch Baba Yaga of Slavic folklore, and the Yama-uba in Japanese folklore.\nA number of stories in Greek mythology involve cannibalism, in particular the eating of close family members, e.g., the stories of Thyestes, Tereus and especially Cronus, who became Saturn in the Roman pantheon. The story of Tantalus is another example, though here a family member is prepared for consumption by others.\nThe wendigo is a creature appearing in the legends of the Algonquian people. It is thought of variously as a malevolent cannibalistic spirit that could possess humans or a monster that humans could physically transform into. Those who indulged in cannibalism were at particular risk, and the legend appears to have reinforced this practice as taboo. The Zuni people tell the story of the \u00c1tahsaia \u2013 a giant who cannibalizes his fellow demons and seeks out human flesh.\nThe wechuge is a demonic cannibalistic creature that seeks out human flesh appearing in the mythology of the Athabaskan people. It is said to be half monster and half human-like; however, it has many shapes and forms.\nIn literature and popular culture.\nCannibalism is depicted in literary and other imaginative works across history. Homer's \"Odyssey\", \"Beowulf\", Shakespeare's \"Titus Andronicus\", Daniel Defoe's \"Robinson Crusoe\", Herman Melville's \"Moby-Dick\", and Gustave Flaubert's \"Salammbo\" are prominent examples. It also features in several classic Chinese novels, such as \"Romance of the Three Kingdoms\" and \"Water Margin\".\nOne of the most famous satirical essays in the English language concerns cannibalism. \"A Modest Proposal for Preventing the Children of Poor People from Being a Burthen to Their Parents or Country, and for Making Them Beneficial to the Publick,\" commonly referred to as \"A Modest Proposal\", is a Juvenalian satire published by Anglo-Irish writer and clergyman Jonathan Swift in 1729. It suggests that poor people in Ireland could ease their economic troubles by selling their young children as food to the elite, and describes in detail the various advantages this would ostensibly have. Among other satirical works depicting cannibalism are Mark Twain's short story \"Cannibalism in the Cars\" (1868) and Mo Yan's novel \"The Republic of Wine\" (1992).\nCannibalism is also a recurring theme in popular culture, especially within the horror genre, with cannibal films being a notable subgenre. One of the best known fictional serial killers is a cannibal: Hannibal Lecter, created by Thomas Harris. Survival cannibalism is a topic of films such as \"Society of the Snow\" (2023) and TV series such as \"Yellowjackets\" (2021\u2013). Other works mention cannibalism in post-apocalyptic settings, among them Cormac McCarthy's novel \"The Road\" (2006) and its 2009 film adaptation. People who consume human flesh without knowing it are depicted in various films, among them the science fiction classic \"Soylent Green\" (1973) and the horror comedy \"The Rocky Horror Picture Show\" (1975).\nScepticism.\nWilliam Arens, author of \"The Man-Eating Myth: Anthropology and Anthropophagy\", questions the credibility of reports of cannibalism and argues that the description by one group of people of another people as cannibals is a consistent and demonstrable ideological and rhetorical device to establish perceived cultural superiority. Arens bases his thesis on a detailed analysis of various \"classic\" cases of cannibalism reported by explorers, missionaries, and anthropologists. He claims that all of them were steeped in racism, unsubstantiated, or based on second-hand or hearsay evidence. Though widely discussed, Arens's book generally failed to convince the academic community. Claude L\u00e9vi-Strauss observes that, in spite of his \"brilliant but superficial book ... [n]o serious ethnologist disputes the reality of cannibalism\". Shirley Lindenbaum notes that, while after \"Arens['s] ... provocative suggestion ... many anthropologists ... reevaluated their data\", the outcome was an improved and \"more nuanced\" understanding of where, why and under which circumstances cannibalism took place rather than a confirmation of his claims: \"Anthropologists working in the Americas, Africa, and Melanesia now acknowledge that institutionalized cannibalism occurred in some places at some times. Archaeologists and evolutionary biologists are taking cannibalism seriously.\"\nLindenbaum and others point out that Arens displays a \"strong ethnocentrism\". His refusal to admit that institutionalized cannibalism ever existed seems to be motivated by the implied idea \"that cannibalism is the worst thing of all\" \u2013 worse than any other behaviour people engaged in, and therefore uniquely suited to vilifying others. Kajsa Ekholm Friedman calls this \"a remarkable opinion in a culture [the European/American one] that has been capable of the most extreme cruelty and destructive behavior, both at home and in other parts of the world.\"\nShe observes that, contrary to European values and expectations, \"in many parts of the Congo region there was no negative evaluation of cannibalism. On the contrary, people expressed their strong appreciation of this very special meat and could not understand the hysterical reactions from the white man's side.\" And why indeed, she goes on to ask, should they have had the same negative reactions to cannibalism as Arens and his contemporaries? Implicitly he assumes that everybody throughout human history must have shared the strong taboo placed by his own culture on cannibalism, but he never attempts to explain why this should be so, and \"neither logic nor historical evidence justifies\" this viewpoint, as Christian Siefkes commented.\nSome have argued that it is the taboo against cannibalism, rather than its practice, that needs to be explained. Hubert Murray, the Lieutenant-Governor of Papua in the early 20th century, admitted that \"I have never been able to give a convincing answer to a native who says to me, 'Why should I not eat human flesh? After observing that the Orokaiva people in New Guinea explained their cannibal customs as due to \"a simple desire for good food\", the Australian anthropologist F. E. Williams commented: \"Anthropologically speaking the fact that we ourselves should persist in a superstitious, or at least sentimental, prejudice against human flesh is more puzzling than the fact that the Orokaiva, a born hunter, should see fit to enjoy perfectly good meat when he gets it.\"\nAccusations of cannibalism could be used to characterize indigenous peoples as \"uncivilized\", \"primitive\", or even \"inhuman.\" While this means that the reliability of reports of cannibal practices must be carefully evaluated especially if their wording suggests such a context, many actual accounts do not fit this pattern. The earliest firsthand account of cannibal customs in the Caribbean comes from Diego \u00c1lvarez Chanca, who accompanied Christopher Columbus on his second voyage. His description of the customs of the Caribs of Guadeloupe includes their cannibalism (men killed or captured in war were eaten, while captured boys were \"castrated [and used as] servants until they gr[e]w up, when they [were] slaughtered\" for consumption), but he nevertheless notes \"that these people are more civilized than the other islanders\" (who did not practice cannibalism). Nor was he an exception. Among the earliest reports of cannibalism in the Caribbean and the Americas, there are some (like those of Amerigo Vespucci) that seem to mostly consist of hearsay and \"gross exaggerations\", but others (by Chanca, Columbus himself, and other early travellers) show \"genuine interest and respect for the natives\" and include \"numerous cases of sincere praise\".\nReports of cannibalism from other continents follow similar patterns. Condescending remarks can be found, but many Europeans who described cannibal customs in Central Africa wrote about those who practised them in quite positive terms, calling them \"splendid\" and \"the finest people\" and not rarely, like Chanca, actually considering them as \"far in advance of\" and \"intellectually and morally superior\" to the non-cannibals around them. Writing from Melanesia, the missionary George Brown explicitly rejects the European prejudice of picturing cannibals as \"particularly ferocious and repulsive\", noting instead that many cannibals he met were \"no more ferocious than\" others and \"indeed ... very nice people\".\nReports or assertions of cannibal practices could nevertheless be used to promote the use of military force as a means of \"civilizing\" and \"pacifying\" the \"savages\". During the Spanish conquest of the Aztec Empire and its earlier conquests in the Caribbean there were widespread reports of cannibalism, and cannibals became exempted from Queen Isabella's prohibition on enslaving the indigenous. Another example of the sensationalism of cannibalism and its connection to imperialism occurred during Japan's 1874 expedition to Taiwan. As Robert Eskildsen describes, Japan's popular media \"exaggerated the aborigines' violent nature\", in some cases by wrongly accusing them of cannibalism.\n\"This Horrid Practice: The Myth and Reality of Traditional Maori Cannibalism\" (2008) by New Zealand historian Paul Moon received a hostile reception by some M\u0101ori, who felt the book tarnished their whole people. However, the factual accuracy of the book was not seriously disputed and even critics such as Margaret Mutu grant that cannibalism was \"definitely\" practised and that it was \"part of our [M\u0101ori] culture.\"\nHistory.\nThere is archaeological evidence that cannibalism has been practised for at least hundreds of thousands of years by early \"Homo sapiens\" and archaic hominins.\nAmong modern humans, cannibalism has been practised by various groups. An incomplete list of cases where it is documented to have occurred in institutionalized form includes prehistoric and early modern Europe, South America, Mesoamerica, Iroquoian peoples in North America, parts of Western and Central Africa, China and Sumatra, among pre-contact Aboriginal Australians, among M\u0101ori in New Zealand, on some other Polynesian islands as well as in New Guinea, the Solomon Islands, and Fiji. Evidence of cannibalism has also been found in ruins associated with the Ancestral Puebloans, at Cowboy Wash in the Southwestern United States.\nAfter World War I, institutionalized cannibalism has become very rare, but cases were still reported during times of famine. Occasional cannibal acts committed by individual criminals also are documented throughout the 20th and 21st centuries."}
{"id": "5659", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=5659", "title": "Chemical element", "text": "A chemical element is a chemical substance whose atoms all have the same number of protons. The number of protons is called the atomic number of that element. For example, oxygen has an atomic number of 8, meaning each oxygen atom has 8 protons in its nucleus. Atoms of the same element can have different numbers of neutrons in their nuclei, known as isotopes of the element. Two or more atoms can combine to form molecules. Some elements are formed from molecules of identical atoms, e. g. atoms of hydrogen (H) form diatomic molecules (H2). Chemical compounds are substances made of atoms of different elements; they can have molecular or non-molecular structure. Mixtures are materials containing different chemical substances; that means (in case of molecular substances) that they contain different types of molecules. Atoms of one element can be transformed into atoms of a different element in nuclear reactions, which change an atom's atomic number.\nHistorically, the term \"chemical element\" meant a substance that cannot be broken down into constituent substances by chemical reactions, and for most practical purposes this definition still has validity. There was some controversy in the 1920s over whether isotopes deserved to be recognized as separate elements if they could be separated by chemical means.\nThe term \"(chemical) element\" is used in two different but closely related meanings: it can mean a chemical substance consisting of a single kind of atoms, or it can mean that kind of atoms as a component of various chemical substances. For example, molecules of water (H2O) contain atoms of hydrogen (H) and oxygen (O), so water can be said as a compound consisting of the elements hydrogen (H) and oxygen (O) even though it does not contain the chemical substances (di)hydrogen (H2) and (di)oxygen (O2), as H2O molecules are different from H2 and O2 molecules. For the meaning \"chemical substance consisting of a single kind of atoms\", the terms \"elementary substance\" and \"simple substance\" have been suggested, but they have not gained much acceptance in English chemical literature, whereas in some other languages their equivalent is widely used. For example, the French chemical terminology distinguishes (kind of atoms) and (chemical substance consisting of a single kind of atoms); the Russian chemical terminology distinguishes and .\nAlmost all baryonic matter in the universe is composed of elements (among rare exceptions are neutron stars). When different elements undergo chemical reactions, atoms are rearranged into new compounds held together by chemical bonds. Only a few elements, such as silver and gold, are found uncombined as relatively pure native element minerals. Nearly all other naturally occurring elements occur in the Earth as compounds or mixtures. Air is mostly a mixture of molecular nitrogen and oxygen, though it does contain compounds including carbon dioxide and water, as well as atomic argon, a noble gas which is chemically inert and therefore does not undergo chemical reactions.\nThe history of the discovery and use of elements began with early human societies that discovered native minerals like carbon, sulfur, copper and gold (though the modern concept of an element was not yet understood). Attempts to classify materials such as these resulted in the concepts of classical elements, alchemy, and similar theories throughout history. Much of the modern understanding of elements developed from the work of Dmitri Mendeleev, a Russian chemist who published the first recognizable periodic table in 1869. This table organizes the elements by increasing atomic number into rows (\"periods\") in which the columns (\"groups\") share recurring (\"periodic\") physical and chemical properties. The periodic table summarizes various properties of the elements, allowing chemists to derive relationships between them and to make predictions about elements not yet discovered, and potential new compounds.\nBy November 2016, the International Union of Pure and Applied Chemistry (IUPAC) had recognized a total of 118 elements. The first 94 occur naturally on Earth, and the remaining 24 are synthetic elements produced in nuclear reactions. Save for unstable radioactive elements (radioelements) which decay quickly, nearly all elements are available industrially in varying amounts. The discovery and synthesis of further new elements is an ongoing area of scientific study.\nDescription.\nThe lightest elements are hydrogen and helium, both created by Big Bang nucleosynthesis in the first 20 minutes of the universe in a ratio of around 3:1 by mass (or 12:1 by number of atoms), along with tiny traces of the next two elements, lithium and beryllium. Almost all other elements found in nature were made by various natural methods of nucleosynthesis. On Earth, small amounts of new atoms are naturally produced in nucleogenic reactions, or in cosmogenic processes, such as cosmic ray spallation. New atoms are also naturally produced on Earth as radiogenic daughter isotopes of ongoing radioactive decay processes such as alpha decay, beta decay, spontaneous fission, cluster decay, and other rarer modes of decay.\nOf the 94 naturally occurring elements, those with atomic numbers 1 through 82 each have at least one stable isotope (except for technetium, element 43 and promethium, element 61, which have no stable isotopes). Isotopes considered stable are those for which no radioactive decay has yet been observed. Elements with atomic numbers 83 through 94 are unstable to the point that radioactive decay of all isotopes can be detected. Some of these elements, notably bismuth (atomic number 83), thorium (atomic number 90), and uranium (atomic number 92), have one or more isotopes with half-lives long enough to survive as remnants of the explosive stellar nucleosynthesis that produced the heavy metals before the formation of our Solar System. At over 1.9 years, over a billion times longer than the estimated age of the universe, bismuth-209 has the longest known alpha decay half-life of any isotope, and is almost always considered on par with the 80 stable elements. The heaviest elements (those beyond plutonium, element 94) undergo radioactive decay with half-lives so short that they are not found in nature and must be synthesized.\nThere are now 118 known elements. In this context, \"known\" means observed well enough, even from just a few decay products, to have been differentiated from other elements. Most recently, the synthesis of element 118 (since named oganesson) was reported in October 2006, and the synthesis of element 117 (tennessine) was reported in April 2010. Of these 118 elements, 94 occur naturally on Earth. Six of these occur in extreme trace quantities: technetium, atomic number 43; promethium, number 61; astatine, number 85; francium, number 87; neptunium, number 93; and plutonium, number 94. These 94 elements have been detected in the universe at large, in the spectra of stars and also supernovae, where short-lived radioactive elements are newly being made. The first 94 elements have been detected directly on Earth as primordial nuclides present from the formation of the Solar System, or as naturally occurring fission or transmutation products of uranium and thorium.\nThe remaining 24 heavier elements, not found today either on Earth or in astronomical spectra, have been produced artificially: all are radioactive, with short half-lives; if any of these elements were present at the formation of Earth, they are certain to have completely decayed, and if present in novae, are in quantities too small to have been noted. Technetium was the first purportedly non-naturally occurring element synthesized, in 1937, though trace amounts of technetium have since been found in nature (and also the element may have been discovered naturally in 1925). This pattern of artificial production and later natural discovery has been repeated with several other radioactive naturally occurring rare elements.\nList of the elements are available by name, atomic number, density, melting point, boiling point and chemical symbol, as well as ionization energy. The nuclides of stable and radioactive elements are also available as a list of nuclides, sorted by length of half-life for those that are unstable. One of the most convenient, and certainly the most traditional presentation of the elements, is in the form of the periodic table, which groups together elements with similar chemical properties (and usually also similar electronic structures).\nAtomic number.\nThe atomic number of an element is equal to the number of protons in each atom, and defines the element. For example, all carbon atoms contain 6 protons in their atomic nucleus; so the atomic number of carbon is 6. Carbon atoms may have different numbers of neutrons; atoms of the same element having different numbers of neutrons are known as isotopes of the element.\nThe number of protons in the nucleus also determines its electric charge, which in turn determines the number of electrons of the atom in its non-ionized state. The electrons are placed into atomic orbitals that determine the atom's chemical properties. The number of neutrons in a nucleus usually has very little effect on an element's chemical properties; except for hydrogen (for which the kinetic isotope effect is significant). Thus, all carbon isotopes have nearly identical chemical properties because they all have six electrons, even though they may have 6 to 8 neutrons. That is why atomic number, rather than mass number or atomic weight, is considered the identifying characteristic of an element.\nThe symbol for atomic number is \"Z\".\nIsotopes.\nIsotopes are atoms of the same element (that is, with the same number of protons in their nucleus), but having \"different\" numbers of neutrons. Thus, for example, there are three main isotopes of carbon. All carbon atoms have 6 protons, but they can have either 6, 7, or 8 neutrons. Since the mass numbers of these are 12, 13 and 14 respectively, said three isotopes are known as carbon-12, carbon-13, and carbon-14 (C, C, and C). Natural carbon is a mixture of C (about 98.9%), C (about 1.1%) and about 1 atom per trillion of C.\nMost (54 of 94) naturally occurring elements have more than one stable isotope. Except for the isotopes of hydrogen (which differ greatly from each other in relative mass\u2014enough to cause chemical effects), the isotopes of a given element are chemically nearly indistinguishable.\nAll elements have radioactive isotopes (radioisotopes); most of these radioisotopes do not occur naturally. Radioisotopes typically decay into other elements via alpha decay, beta decay, or inverse beta decay; some isotopes of the heaviest elements also undergo spontaneous fission. Isotopes that are not radioactive, are termed \"stable\" isotopes. All known stable isotopes occur naturally (see primordial nuclide). The many radioisotopes that are not found in nature have been characterized after being artificially produced. Certain elements have no stable isotopes and are composed \"only\" of radioisotopes: specifically the elements without any stable isotopes are technetium (atomic number 43), promethium (atomic number 61), and all observed elements with atomic number greater than 82.\nOf the 80 elements with at least one stable isotope, 26 have only one stable isotope. The mean number of stable isotopes for the 80 stable elements is 3.1 stable isotopes per element. The largest number of stable isotopes for a single element is 10 (for tin, element 50).\nIsotopic mass and atomic mass.\nThe mass number of an element, \"A\", is the number of nucleons (protons and neutrons) in the atomic nucleus. Different isotopes of a given element are distinguished by their mass number, which is written as a superscript on the left hand side of the chemical symbol (e.g., U). The mass number is always an integer and has units of \"nucleons\". Thus, magnesium-24 (24 is the mass number) is an atom with 24 nucleons (12 protons and 12 neutrons).\nWhereas the mass number simply counts the total number of neutrons and protons and is thus an integer, the atomic mass of a particular isotope (or \"nuclide\") of the element is the mass of a single atom of that isotope, and is typically expressed in daltons (symbol: Da), or universal atomic mass units (symbol: u). Its relative atomic mass is a dimensionless number equal to the atomic mass divided by the atomic mass constant, which equals 1\u00a0Da. In general, the mass number of a given nuclide differs in value slightly from its relative atomic mass, since the mass of each proton and neutron is not exactly 1\u00a0Da; since the electrons contribute a lesser share to the atomic mass as neutron number exceeds proton number; and because of the nuclear binding energy and electron binding energy. For example, the atomic mass of chlorine-35 to five significant digits is 34.969\u00a0Da and that of chlorine-37 is 36.966\u00a0Da. However, the relative atomic mass of each isotope is quite close to its mass number (always within 1%). The only isotope whose atomic mass is exactly a natural number is C, which has a mass of 12\u00a0Da; because the dalton is defined as 1/12 of the mass of a free neutral carbon-12 atom in the ground state.\nThe standard atomic weight (commonly called \"atomic weight\") of an element is the \"average\" of the atomic masses of all the chemical element's isotopes as found in a particular environment, weighted by isotopic abundance, relative to the atomic mass unit. This number may be a fraction that is \"not\" close to a whole number. For example, the relative atomic mass of chlorine is 35.453\u00a0u, which differs greatly from a whole number as it is an average of about 76% chlorine-35 and 24% chlorine-37. Whenever a relative atomic mass value differs by more than ~1% from a whole number, it is due to this averaging effect, as significant amounts of more than one isotope are naturally present in a sample of that element.\nChemically pure and isotopically pure.\nChemists and nuclear scientists have different definitions of a \"pure element\". In chemistry, a pure element means a substance whose atoms all (or in practice almost all) have the same atomic number, or number of protons. Nuclear scientists, however, define a pure element as one that consists of only one isotope.\nFor example, a copper wire is 99.99% chemically pure if 99.99% of its atoms are copper, with 29 protons each. However it is not isotopically pure since ordinary copper consists of two stable isotopes, 69% Cu and 31% Cu, with different numbers of neutrons. However, pure gold would be both chemically and isotopically pure, since ordinary gold consists only of one isotope, Au.\nAllotropes.\nAtoms of chemically pure elements may bond to each other chemically in more than one way, allowing the pure element to exist in multiple chemical structures (spatial arrangements of atoms), known as allotropes, which differ in their properties. For example, carbon can be found as diamond, which has a tetrahedral structure around each carbon atom; graphite, which has layers of carbon atoms with a hexagonal structure stacked on top of each other; graphene, which is a single layer of graphite that is very strong; fullerenes, which have nearly spherical shapes; and carbon nanotubes, which are tubes with a hexagonal structure (even these may differ from each other in electrical properties). The ability of an element to exist in one of many structural forms is known as 'allotropy'.\nThe reference state of an element is defined by convention, usually as the thermodynamically most stable allotrope and physical state at a pressure of 1 bar and a given temperature (typically at 298.15K). However, for phosphorus, the reference state is white phosphorus even though it is not the most stable allotrope, and the reference state for carbon is graphite, because the structure of graphite is more stable than that of the other allotropes. In thermochemistry, an element is defined to have an enthalpy of formation of zero in its reference state. \nProperties.\nSeveral kinds of descriptive categorizations can be applied broadly to the elements, including consideration of their general physical and chemical properties, their states of matter under familiar conditions, their melting and boiling points, their densities, their crystal structures as solids, and their origins.\nGeneral properties.\nSeveral terms are commonly used to characterize the general physical and chemical properties of the chemical elements. A first distinction is between metals, which readily conduct electricity, nonmetals, which do not, and a small group, (the \"metalloids\"), having intermediate properties and often behaving as semiconductors.\nA more refined classification is often shown in colored presentations of the periodic table. This system restricts the terms \"metal\" and \"nonmetal\" to only certain of the more broadly defined metals and nonmetals, adding additional terms for certain sets of the more broadly viewed metals and nonmetals. The version of this classification used in the periodic tables presented here includes: actinides, alkali metals, alkaline earth metals, halogens, lanthanides, transition metals, post-transition metals, metalloids, reactive nonmetals, and noble gases. In this system, the alkali metals, alkaline earth metals, and transition metals, as well as the lanthanides and the actinides, are special groups of the metals viewed in a broader sense. Similarly, the reactive nonmetals and the noble gases are nonmetals viewed in the broader sense. In some presentations, the halogens are not distinguished, with astatine identified as a metalloid and the others identified as nonmetals.\nStates of matter.\nAnother commonly used basic distinction among the elements is their state of matter (phase), whether solid, liquid, or gas, at standard temperature and pressure (STP). Most elements are solids at STP, while several are gases. Only bromine and mercury are liquid at 0 degrees Celsius (32 degrees Fahrenheit) and 1 atmosphere pressure; caesium and gallium are solid at that temperature, but melt at 28.4\u00b0C (83.2\u00b0F) and 29.8\u00b0C (85.6\u00b0F), respectively.\nMelting and boiling points.\nMelting and boiling points, typically expressed in degrees Celsius at a pressure of one atmosphere, are commonly used in characterizing the various elements. While known for most elements, either or both of these measurements is still undetermined for some of the radioactive elements available in only tiny quantities. Since helium remains a liquid even at absolute zero at atmospheric pressure, it has only a boiling point, and not a melting point, in conventional presentations.\nDensities.\nThe density at selected standard temperature and pressure (STP) is often used in characterizing the elements. Density is often expressed in grams per cubic centimetre (g/cm). Since several elements are gases at commonly encountered temperatures, their densities are usually stated for their gaseous forms; when liquefied or solidified, the gaseous elements have densities similar to those of the other elements.\nWhen an element has allotropes with different densities, one representative allotrope is typically selected in summary presentations, while densities for each allotrope can be stated where more detail is provided. For example, the three familiar allotropes of carbon (amorphous carbon, graphite, and diamond) have densities of 1.8\u20132.1, 2.267, and 3.515\u00a0g/cm, respectively.\nCrystal structures.\nThe elements studied to date as solid samples have eight kinds of crystal structures: cubic, body-centered cubic, face-centered cubic, hexagonal, monoclinic, orthorhombic, rhombohedral, and tetragonal. For some of the synthetically produced transuranic elements, available samples have been too small to determine crystal structures.\nOccurrence and origin on Earth.\nChemical elements may also be categorized by their origin on Earth, with the first 94 considered naturally occurring, while those with atomic numbers beyond 94 have only been produced artificially via human-made nuclear reactions.\nOf the 94 naturally occurring elements, 83 are considered primordial and either stable or weakly radioactive. The longest-lived isotopes of the remaining 11 elements have half lives too short for them to have been present at the beginning of the Solar System, and are therefore considered transient elements. Of these 11 transient elements, five (polonium, radon, radium, actinium, and protactinium) are relatively common decay products of thorium and uranium. The remaining six transient elements (technetium, promethium, astatine, francium, neptunium, and plutonium) occur only rarely, as products of rare decay modes or nuclear reaction processes involving uranium or other heavy elements.\nElements with atomic numbers 1 through 82, except 43 (technetium) and 61 (promethium), each have at least one isotope for which no radioactive decay has been observed. Observationally stable isotopes of some elements (such as tungsten and lead), however, are predicted to be slightly radioactive with very long half-lives: for example, the half-lives predicted for the observationally stable lead isotopes range from 10 to 10 years. Elements with atomic numbers 43, 61, and 83 through 94 are unstable enough that their radioactive decay can be detected. Three of these elements, bismuth (element 83), thorium (90), and uranium (92) have one or more isotopes with half-lives long enough to survive as remnants of the explosive stellar nucleosynthesis that produced the heavy elements before the formation of the Solar System. For example, at over 1.9 years, over a billion times longer than the estimated age of the universe, bismuth-209 has the longest known alpha decay half-life of any isotope. The last 24 elements (those beyond plutonium, element 94) undergo radioactive decay with short half-lives and cannot be produced as daughters of longer-lived elements, and thus are not known to occur in nature at all.\nPeriodic table.\nThe properties of the elements are often summarized using the periodic table, which powerfully and elegantly organizes the elements by increasing atomic number into rows (\"periods\") in which the columns (\"groups\") share recurring (\"periodic\") physical and chemical properties. The table contains 118 confirmed elements as of 2021.\nAlthough earlier precursors to this presentation exist, its invention is generally credited to Russian chemist Dmitri Mendeleev in 1869, who intended the table to illustrate recurring trends in the properties of the elements. The layout of the table has been refined and extended over time as new elements have been discovered and new theoretical models have been developed to explain chemical behavior.\nUse of the periodic table is now ubiquitous in chemistry, providing an extremely useful framework to classify, systematize and compare all the many different forms of chemical behavior. The table has also found wide application in physics, geology, biology, materials science, engineering, agriculture, medicine, nutrition, environmental health, and astronomy. Its principles are especially important in chemical engineering.\nNomenclature and symbols.\nThe various chemical elements are formally identified by their unique atomic numbers, their accepted names, and their chemical symbols.\nAtomic numbers.\nThe known elements have atomic numbers from 1 to 118, conventionally presented as Arabic numerals. Since the elements can be uniquely sequenced by atomic number, conventionally from lowest to highest (as in a periodic table), sets of elements are sometimes specified by such notation as \"through\", \"beyond\", or \"from ... through\", as in \"through iron\", \"beyond uranium\", or \"from lanthanum through lutetium\". The terms \"light\" and \"heavy\" are sometimes also used informally to indicate relative atomic numbers (not densities), as in \"lighter than carbon\" or \"heavier than lead\", though the atomic masses of the elements (their atomic weights or atomic masses) do not always increase monotonically with their atomic numbers.\nElement names.\nThe naming of various substances now known as elements precedes the atomic theory of matter, as names were given locally by various cultures to various minerals, metals, compounds, alloys, mixtures, and other materials, though at the time it was not known which chemicals were elements and which compounds. As they were identified as elements, the existing names for anciently known elements (e.g., gold, mercury, iron) were kept in most countries. National differences emerged over the element names either for convenience, linguistic niceties, or nationalism. For example, German speakers use \"Wasserstoff\" (water substance) for \"hydrogen\", \"Sauerstoff\" (acid substance) for \"oxygen\" and \"Stickstoff\" (smothering substance) for \"nitrogen\"; English and some other languages use \"sodium\" for \"natrium\", and \"potassium\" for \"kalium\"; and the French, Italians, Greeks, Portuguese and Poles prefer \"azote/azot/azoto\" (from roots meaning \"no life\") for \"nitrogen\".\nFor purposes of international communication and trade, the official names of the chemical elements both ancient and more recently recognized are decided by the International Union of Pure and Applied Chemistry (IUPAC), which has decided on a sort of international English language, drawing on traditional English names even when an element's chemical symbol is based on a Latin or other traditional word, for example adopting \"gold\" rather than \"aurum\" as the name for the 79th element (Au). IUPAC prefers the British spellings \"aluminium\" and \"caesium\" over the U.S. spellings \"aluminum\" and \"cesium\", and the U.S. \"sulfur\" over British \"sulphur\". However, elements that are practical to sell in bulk in many countries often still have locally used national names, and countries whose national language does not use the Latin alphabet are likely to use the IUPAC element names.\nAccording to IUPAC, element names are not proper nouns; therefore, the full name of an element is not capitalized in English, even if derived from a proper noun, as in californium and einsteinium. Isotope names are also uncapitalized if written out, \"e.g.,\" carbon-12 or uranium-235. Chemical element \"symbols\" (such as Cf for californium and Es for einsteinium), are always capitalized (see below).\nIn the second half of the 20th century, physics laboratories became able to produce elements with half-lives too short for an appreciable amount of them to exist at any time. These are also named by IUPAC, which generally adopts the name chosen by the discoverer. This practice can lead to the controversial question of which research group actually discovered an element, a question that delayed the naming of elements with atomic number of 104 and higher for a considerable amount of time. (See element naming controversy).\nPrecursors of such controversies involved the nationalistic namings of elements in the late 19th century. For example, \"lutetium\" was named in reference to Paris, France. The Germans were reluctant to relinquish naming rights to the French, often calling it \"cassiopeium\". Similarly, the British discoverer of \"niobium\" originally named it \"columbium\", in reference to the New World. It was used extensively as such by American publications before the international standardization (in 1950).\nChemical symbols.\nSpecific elements.\nBefore chemistry became a science, alchemists designed arcane symbols for both metals and common compounds. These were however used as abbreviations in diagrams or procedures; there was no concept of atoms combining to form molecules. With his advances in the atomic theory of matter, John Dalton devised his own simpler symbols, based on circles, to depict molecules.\nThe current system of chemical notation was invented by J\u00f6ns Jacob Berzelius in 1814. In this system, chemical symbols are not mere abbreviations\u2014though each consists of letters of the Latin alphabet. They are intended as universal symbols for people of all languages and alphabets.\nSince Latin was the common language of science at Berzelius' time, his symbols were abbreviations based on the Latin names of elements (they may be Classical Latin names of elements known since antiquity or Neo-Latin coinages for later elements). The symbols are not followed by a period (full stop) as with abbreviations. In most cases, Latin names of elements as used by Berzelius have the same roots as the modern English name. For example, hydrogen has the symbol \"H\" from Neo-Latin , which has the same Greek roots as English \"hydrogen\". However, in eleven cases Latin (as used by Berzelius) and English names of elements have different roots. Eight of them are the seven metals of antiquity and a metalloid also known since antiquity: \"Fe\" (Latin ) for iron, \"Hg\" (Latin ) for mercury, \"Sn\" (Latin ) for tin, \"Au\" (Latin ) for gold, \"Ag\" (Latin ) for silver, \"Pb\" (Latin ) for lead, \"Cu\" (Latin ) for copper, and \"Sb\" (Latin ) for antimony. The three other mismatches between Neo-Latin (as used by Berzelius) and English names are \"Na\" (Neo-Latin ) for sodium, \"K\" (Neo-Latin ) for potassium, and \"W\" (Neo-Latin ) for tungsten. These mismatches came from different suggestings of naming the elements in the Modern era. Initially Berzelius had suggested \"So\" and \"Po\" for sodium and potassium, but he changed the symbols to \"Na\" and \"K\" later in the same year.\nElements discovered after 1814 were also assigned unique chemical symbols, based on the name of the element. The use of Latin as the universal language of science was fading, but chemical names of newly discovered elements came to be borrowed from language to language with little or no modifications. Symbols of elements discovered after 1814 match their names in English, French (ignoring the acute accent on ), and German (though German often allows alternate spellings with or instead of : e.g., the name of calcium may be spelled or in German, but its symbol is always \"Ca\"). Other languages sometimes modify element name spellings: Spanish (ytterbium), Italian (hafnium), Swedish (moscovium); but those modifications do not affect chemical symbols: Yb, Hf, Mc.\nChemical symbols are understood internationally when element names might require translation. There have been some differences in the past. For example, Germans in the past have used \"J\" (for the name ) for iodine, but now use \"I\" and .\nThe first letter of a chemical symbol is always capitalized, as in the preceding examples, and the subsequent letters, if any, are always lower case. Thus, the symbols for californium and einsteinium are Cf and Es.\nGeneral chemical symbols.\nThere are also symbols in chemical equations for groups of elements, for example in comparative formulas. These are often a single capital letter, and the letters are reserved and not used for names of specific elements. For example, \"X\" indicates a variable group (usually a halogen) in a class of compounds, while \"R\" is a radical, meaning a compound structure such as a hydrocarbon chain. The letter \"Q\" is reserved for \"heat\" in a chemical reaction. \"Y\" is also often used as a general chemical symbol, though it is also the symbol of yttrium. \"Z\" is also often used as a general variable group. \"E\" is used in organic chemistry to denote an electron-withdrawing group or an electrophile; similarly \"Nu\" denotes a nucleophile. \"L\" is used to represent a general ligand in inorganic and organometallic chemistry. \"M\" is also often used in place of a general metal.\nAt least two other, two-letter generic chemical symbols are also in informal use, \"Ln\" for any lanthanide and \"An\" for any actinide. \"Rg\" was formerly used for any rare gas element, but the group of rare gases has now been renamed noble gases and \"Rg\" now refers to roentgenium.\nIsotope symbols.\nIsotopes of an element are distinguished by mass number (total protons and neutrons), with this number combined with the element's symbol. IUPAC prefers that isotope symbols be written in superscript notation when practical, for example C and U. However, other notations, such as carbon-12 and uranium-235, or C-12 and U-235, are also used.\nAs a special case, the three naturally occurring isotopes of hydrogen are often specified as H for H (protium), D for H (deuterium), and T for H (tritium). This convention is easier to use in chemical equations, replacing the need to write out the mass number each time. Thus, the formula for heavy water may be written DO instead of HO.\nOrigin of the elements.\nOnly about 4% of the total mass of the universe is made of atoms or ions, and thus represented by elements. This fraction is about 15% of the total matter, with the remainder of the matter (85%) being dark matter. The nature of dark matter is unknown, but it is not composed of atoms of elements because it contains no protons, neutrons, or electrons. (The remaining non-matter part of the mass of the universe is composed of the even less well understood dark energy).\nThe 94 naturally occurring elements were produced by at least four classes of astrophysical process. Most of the hydrogen, helium and a very small quantity of lithium were produced in the first few minutes of the Big Bang. This Big Bang nucleosynthesis happened only once; the other processes are ongoing. Nuclear fusion inside stars produces elements through stellar nucleosynthesis, including all elements from carbon to iron in atomic number. Elements higher in atomic number than iron, including heavy elements like uranium and plutonium, are produced by various forms of explosive nucleosynthesis in supernovae and neutron star mergers. The light elements lithium, beryllium and boron are produced mostly through cosmic ray spallation (fragmentation induced by cosmic rays) of carbon, nitrogen, and oxygen.\nIn the early phases of the Big Bang, nucleosynthesis of hydrogen resulted in the production of hydrogen-1 (protium, H) and helium-4 (He), as well as a smaller amount of deuterium (H) and tiny amounts (on the order of 10) of lithium and beryllium. Even smaller amounts of boron may have been produced in the Big Bang, since it has been observed in some very old stars, while carbon has not. No elements heavier than boron were produced in the Big Bang. As a result, the primordial abundance of atoms (or ions) consisted of ~75% H, 25% He, and 0.01% deuterium, with only tiny traces of lithium, beryllium, and perhaps boron. Subsequent enrichment of galactic halos occurred due to stellar nucleosynthesis and supernova nucleosynthesis. However, the element abundance in intergalactic space can still closely resemble primordial conditions, unless it has been enriched by some means.\nOn Earth (and elsewhere), trace amounts of various elements continue to be produced from other elements as products of nuclear transmutation processes. These include some produced by cosmic rays or other nuclear reactions (see cosmogenic and nucleogenic nuclides), and others produced as decay products of long-lived primordial nuclides. For example, trace (but detectable) amounts of carbon-14 (C) are continually produced in the air by cosmic rays impacting nitrogen atoms, and argon-40 (Ar) is continually produced by the decay of primordially occurring but unstable potassium-40 (K). Also, three primordially occurring but radioactive actinides, thorium, uranium, and plutonium, decay through a series of recurrently produced but unstable elements such as radium and radon, which are transiently present in any sample of containing these metals. Three other radioactive elements, technetium, promethium, and neptunium, occur only incidentally in natural materials, produced as individual atoms by nuclear fission of the nuclei of various heavy elements or in other rare nuclear processes.\nBesides the 94 naturally occurring elements, several artificial elements have been produced by nuclear physics technology. By 2016, these experiments had produced all elements up to atomic number 118.\nAbundance.\nThe following graph (note log scale) shows the abundance of elements in our Solar System. The table shows the 12 most common elements in our galaxy (estimated spectroscopically), as measured in parts per million by mass. Nearby galaxies that have evolved along similar lines have a corresponding enrichment of elements heavier than hydrogen and helium. The more distant galaxies are being viewed as they appeared in the past, so their abundances of elements appear closer to the primordial mixture. As physical laws and processes appear common throughout the visible universe, however, scientists expect that these galaxies evolved elements in similar abundance.\nThe abundance of elements in the Solar System is in keeping with their origin from nucleosynthesis in the Big Bang and a number of progenitor supernova stars. Very abundant hydrogen and helium are products of the Big Bang, but the next three elements are rare since they had little time to form in the Big Bang and are not made in stars (they are, however, produced in small quantities by the breakup of heavier elements in interstellar dust, as a result of impact by cosmic rays). Beginning with carbon, elements are produced in stars by buildup from alpha particles (helium nuclei), resulting in an alternatingly larger abundance of elements with even atomic numbers (these are also more stable). In general, such elements up to iron are made in large stars in the process of becoming supernovas. Iron-56 is particularly common, since it is the most stable nuclide that can easily be made from alpha particles (being a product of decay of radioactive nickel-56, ultimately made from 14 helium nuclei). Elements heavier than iron are made in energy-absorbing processes in large stars, and their abundance in the universe (and on Earth) generally decreases with their atomic number.\nThe abundance of the chemical elements on Earth varies from air to crust to ocean, and in various types of life. The abundance of elements in Earth's crust differs from that in the Solar System (as seen in the Sun and massive planets like Jupiter) mainly in selective loss of the very lightest elements (hydrogen and helium) and also volatile neon, carbon (as hydrocarbons), nitrogen and sulfur, as a result of solar heating in the early formation of the Solar System. Oxygen, the most abundant Earth element by mass, is retained on Earth by combination with silicon. Aluminium at 8% by mass is more common in the Earth's crust than in the universe and solar system, but the composition of the far more bulky mantle, which has magnesium and iron in place of aluminium (which occurs there only at 2% of mass) more closely mirrors the elemental composition of the solar system, save for the noted loss of volatile elements to space, and loss of iron which has migrated to the Earth's core.\nThe composition of the human body, by contrast, more closely follows the composition of seawater\u2014save that the human body has additional stores of carbon and nitrogen necessary to form the proteins and nucleic acids, together with phosphorus in the nucleic acids and energy transfer molecule adenosine triphosphate (ATP) that occurs in the cells of all living organisms. Certain kinds of organisms require particular additional elements, for example the magnesium in chlorophyll in green plants, the calcium in mollusc shells, or the iron in the hemoglobin in vertebrates' red blood cells.\nHistory.\nEvolving definitions.\nThe concept of an \"element\" as an indivisible substance has developed through three major historical phases: Classical definitions (such as those of the ancient Greeks), chemical definitions, and atomic definitions.\nClassical definitions.\nAncient philosophy posited a set of classical elements to explain observed patterns in nature. These \"elements\" originally referred to \"earth\", \"water\", \"air\" and \"fire\" rather than the chemical elements of modern science.\nThe term 'elements' (\"stoicheia\") was first used by Greek philosopher Plato around 360\u00a0BCE in his dialogue Timaeus, which includes a discussion of the composition of inorganic and organic bodies and is a speculative treatise on chemistry. Plato believed the elements introduced a century earlier by Empedocles were composed of small polyhedral forms: tetrahedron (fire), octahedron (air), icosahedron (water), and cube (earth).\nAristotle, , also used the term \"stoicheia\" and added a fifth element, aether, which formed the heavens. Aristotle defined an element as:\nChemical definitions.\nRobert Boyle.\nIn 1661, in \"The Sceptical Chymist\", Robert Boyle proposed his theory of corpuscularism which favoured the analysis of matter as constituted of irreducible units of matter (atoms); and, choosing to side with neither Aristotle's view of the four elements nor Paracelsus' view of three fundamental elements, left open the question of the number of elements. Boyle argued against a pre-determined number of elements\u2014directly against Paracelsus' three principles (sulfur, mercury, and salt), indirectly against the \"Aristotelian\" elements (earth, water, air, and fire), for Boyle felt that the arguments against the former were at least as valid against the latter.\nThen Boyle stated his view in four propositions. In the first and second, he suggests that matter consists of particles, but that these particles may be difficult to separate. Boyle used the concept of \"corpuscles\"\u2014or \"atomes\", as he also called them\u2014to explain how a limited number of elements could combine into a vast number of compounds.\nBoyle explained that gold reacts with \"aqua regia,\" and mercury with nitric acid, sulfuric acid, and sulfur to produce various \"compounds\", and that they could be recovered from those compounds, just as would be expected of elements. Yet, Boyle did not consider gold, mercury, or lead elements, but rather\u2014together with wine\u2014\"perfectly mixt bodies\". \nEven though Boyle is primarily regarded as the first modern chemist, \"The Sceptical Chymist\" still contains old ideas about the elements, alien to a contemporary viewpoint. Sulfur, for example, is not only the familiar yellow non-metal but also an inflammable \"spirit\".\nIsaac Watts.\nIn 1724, in his book \"Logick\", the English minister and logician Isaac Watts enumerated the elements then recognized by chemists. Watts' list of elements included two of Paracelsus' \"principles\" (sulfur and salt) and two classical elements (earth and water) as well as \"spirit\". Watts did, however, note a lack of consensus among chemists.\nAntoine Lavoisier, J\u00f6ns Jacob Berzelius, and Dmitri Mendeleev.\nThe first modern list of elements was given in Antoine Lavoisier's 1789 \"Elements of Chemistry\", which contained 33 elements, including light and caloric. By 1818, J\u00f6ns Jacob Berzelius had determined atomic weights for 45 of the 49 then-accepted elements. Dmitri Mendeleev had 63 elements in his 1869 periodic table.\nFrom Boyle until the early 20th century, an element was defined as a pure substance that cannot be decomposed into any simpler substance and cannot be transformed into other elements by chemical processes. Elements at the time were generally distinguished by their atomic weights, a property measurable with fair accuracy by available analytical techniques.\nAtomic definitions.\nThe 1913 discovery by English physicist Henry Moseley that the nuclear charge is the physical basis for the atomic number, further refined when the nature of protons and neutrons became appreciated, eventually led to the current definition of an element based on atomic number (number of protons). The use of atomic numbers, rather than atomic weights, to distinguish elements has greater predictive value (since these numbers are integers) and also resolves some ambiguities in the chemistry-based view due to varying properties of isotopes and allotropes within the same element. Currently, IUPAC defines an element to exist if it has isotopes with a lifetime longer than the 10 seconds it takes the nucleus to form an electronic cloud.\nBy 1914, eighty-seven elements were known, all naturally occurring (see Discovery of chemical elements). The remaining naturally occurring elements were discovered or isolated in subsequent decades, and various additional elements have also been produced synthetically, with much of that work pioneered by Glenn T. Seaborg. In 1955, element 101 was discovered and named mendelevium in honor of D. I. Mendeleev, the first to arrange the elements periodically.\nDiscovery and recognition of various elements.\nTen materials familiar to various prehistoric cultures are now known to be elements: Carbon, copper, gold, iron, lead, mercury, silver, sulfur, tin, and zinc. Three additional materials now accepted as elements, arsenic, antimony, and bismuth, were recognized as distinct substances before 1500 AD. Phosphorus, cobalt, and platinum were isolated before 1750.\nMost of the remaining naturally occurring elements were identified and characterized by 1900, including:\nElements isolated or produced since 1900 include:\nRecently discovered elements.\nThe first transuranium element (element with an atomic number greater than 92) discovered was neptunium in 1940. Since 1999, the IUPAC/IUPAP Joint Working Party has considered claims for the discovery of new elements. As of January 2016, all 118 elements have been confirmed by IUPAC as being discovered. The discovery of element 112 was acknowledged in 2009, and the name \"copernicium\" and the chemical symbol \"Cn\" were suggested for it. The name and symbol were officially endorsed by IUPAC on 19 February 2010. The heaviest element that is believed to have been synthesized to date is element 118, oganesson, on 9 October 2006, by the Flerov Laboratory of Nuclear Reactions in Dubna, Russia. Tennessine, element 117 was the latest element claimed to be discovered, in 2009. On 28 November 2016, scientists at the IUPAC officially recognized the names for the four newest elements, with atomic numbers 113, 115, 117, and 118.\nList of the 118 known chemical elements.\nThe following sortable table shows the 118 known elements."}
{"id": "5661", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=5661", "title": "Centime", "text": "Centime (from ) is French for \"cent\", and is used in English as the name of the fraction currency in several Francophone countries (including Switzerland, Algeria, Belgium, Morocco and France).\nIn France, the usage of \"centime\" goes back to the introduction of the decimal monetary system under Napoleon. This system aimed at replacing non-decimal fractions of older coins. A five-centime coin was known as a \"sou\", i.e. a solidus or shilling.\nIn Francophone Canada of a Canadian dollar is officially known as a \"cent\" (pronounced /s\u025bnt/) in both English and French. However, in practice, the form of \"cenne\" (pronounced /s\u025bn/) has completely replaced the official \"cent\". Spoken and written use of the official form \"cent\" in Francophone Canada is exceptionally uncommon.\nIn the Canadian French vernacular \"sou\", \"sou noir\" ( means \"black\" in French), \"cenne\", and \"cenne noire\" are all widely known, used, and accepted monikers when referring to either of a Canadian dollar or the 1\u00a2 coin (colloquially known as a \"penny\" in North American English).\nSubdivision of euro: cent or centime?\nIn the European community, \"cent\" is the official name for one hundredth of a euro. However, in French-speaking countries, the word \"centime \"is the preferred term. The Superior Council of the French language of Belgium recommended in 2001 the use of \"centime\", since \"cent\" is also the French word for \"hundred\". An analogous decision was published in the \"Journal officiel\" in France (2 December 1997).\nIn Morocco, dirhams are divided into 100 \"centime\"s and one may find prices in the country quoted in \"centime\"s rather than in dirhams. Sometimes \"centime\"s are known as francs or, in former Spanish areas, pesetas.\nUsage.\nA centime is one-hundredth of the following basic monetary units:"}
{"id": "5662", "revid": "248739", "url": "https://en.wikipedia.org/wiki?curid=5662", "title": "Calendar year", "text": "A calendar year begins on the New Year's Day of the given calendar system and ends on the day before the following New Year's Day, and thus consists of a whole number of days.\nThe Gregorian calendar year, which is in use as civil calendar in most of the world, begins on January 1 and ends on December 31. It has a length of 365 days in an ordinary year but, in order to reconcile the calendar year with the astronomical cycle, it has 366 days in a leap year. With 97 leap years every 400 years, the Gregorian calendar year has an average length of 365.2425 days.\nOther formula-based calendars can have lengths which are further out of step with the solar cycle: for example, the Julian calendar has an average length of 365.25 days, and the Hebrew calendar has an average length of 365.2468 days. The Lunar Hijri calendar (\"Islamic calendar\") is a lunar calendar consisting of 12 lunar months in a year of 354 or 355 days. The astronomer's mean tropical year, which is averaged over equinoxes and solstices, is currently 365.24219 days, slightly shorter than the average length of the calendar year in most calendars.\nA year can also be measured by starting on any other named day of the calendar, and ending on the day before this named day in the following year. This may be termed a \"year's time\", but is not a \"calendar year\".\nQuarter year.\nThe calendar year can be divided into four quarters, often abbreviated as Q1, Q2, Q3, and Q4. Since they are three months each, they are also called trimesters. In the Gregorian calendar:\nIn some domains, weeks are preferred over months for scheduling and reporting, so they use quarters of exactly 13 weeks each, often following ISO week date conventions. One in five to six years has a 53rd week which is usually appended to the last quarter. It is then 98 days instead of 91 days long, which complicates comparisons.\nIn the Chinese calendar, the quarters are traditionally associated with the 4 seasons of the year:\nQuadrimester.\nThe calendar year can also be divided into quadrimesters (from French \"quadrimestre\"), lasting for four months each. They can also be called the early, middle, or late parts of the year. In the Gregorian calendar:\nSemester.\nThe calendar year can also be divided into semesters, lasting six months each and often being abbreviated as S1 and S2. In the Gregorian calendar:"}
{"id": "5663", "revid": "24465790", "url": "https://en.wikipedia.org/wiki?curid=5663", "title": "CFA franc", "text": "The CFA franc (, ) is the name of two currencies used by 210 million people (as of 2023) in fourteen African countries: the West African CFA franc (where \"CFA\" stands for , i.e. \"African Financial Community\" in English), used in eight West African countries, and the Central African CFA franc (where \"CFA\" stands for , i.e. \"Financial Cooperation in Central Africa\" in English), used in six Central African countries. The ISO currency codes are XAF for the Central African CFA franc and XOF for the West African CFA franc. Although the two currencies are commonly called the CFA franc and (currently) have the same value, they are not interchangeable. It is therefore not a common monetary zone but two juxtaposed zones.\nBoth CFA francs have a fixed exchange rate (peg) to the euro guaranteed by France: \u20ac1 = F.CFA\u00a0655.957 exactly. To ensure this convertibility guarantee, member countries were required to deposit half of their foreign exchange reserves with the French Treasury, but this requirement was dropped in 2019 (effective in 2021) for the West African CFA franc. This requirement remains unchanged for the Central African CFA franc, which wasn't reformed in 2019 (the reform concerned only the West African CFA franc). The currency has been criticized for restricting the sovereignty of the African member states, effectively putting their monetary policy in the hands of the European Central Bank. Others argue that the CFA \"helps stabilize the national currencies of Franc Zone member-countries and greatly facilitates the flow of exports and imports between France and the member-countries\".\nOn 22 December 2019, it was announced that the West African currency would be reformed and replaced by an independent currency to be called Eco. In May 2020, the French National Assembly agreed to end the French engagement in the West African CFA franc, including the foreign reserve deposit requirements, thereby facilitating the transition to the Eco. Despite initial plans for a monetary union by late 2020, setbacks including the COVID-19 pandemic, global geopolitical uncertainties, and failure to meet criteria resulted in a postponement until 2027.\nUsage.\nCFA francs are used in fourteen countries: twelve nations formerly ruled by France in West and Central Africa (excluding Guinea and Mauritania, which withdrew), plus Guinea-Bissau (a former Portuguese colony), and Equatorial Guinea (a former Spanish colony). These fourteen countries have a combined population of 210.4\u00a0million people (as of 2023), and a combined GDP of US$313.7\u00a0billion (as of 2023).\nName.\nBetween 1945 and 1958, CFA stood for (\"French colonies of Africa\"); then for (\"French Community of Africa\") between 1958 (establishment of the French Fifth Republic) and the independence of these African countries at the beginning of the 1960s. Since independence, CFA is taken to mean (African Financial Community) or \"Coop\u00e9ration financi\u00e8re en Afrique centrale\" (see Institutions below).\nHistory.\nCreation.\nThe CFA franc was created on 26 December 1945, along with the CFP franc. The reason for their creation was the weakness of the French franc immediately after World War II. When France ratified the Bretton Woods Agreement in December 1945, the French franc was devalued in order to set a fixed exchange rate with the US dollar. New currencies were created in the French colonies to spare them the strong devaluation, thereby making it easier for them to import goods from France (and simultaneously making it harder for them to export goods to France). French officials presented the decision as an act of generosity. Ren\u00e9 Pleven, the French Minister of Finance, was quoted as saying:\nExchange rate.\nThe CFA franc was created with a fixed exchange rate versus the French franc. This exchange rate was changed only twice, in 1948 and in 1994 (besides nominal adaptation to the new French franc in 1960 and the Euro in 1999).\nExchange rate:\nThe 1960 and 1999 events merely reflect changes of currency in use in France: the actual relative value of the CFA franc versus the French franc/euro only changed in 1948 and 1994.\nChanges in countries using the franc.\nOver time, the number of countries and territories using the CFA franc has changed as some countries began introducing their own separate currencies. A couple of nations in West Africa have also chosen to adopt the CFA franc since its introduction, despite the fact that they had never been French colonies.\nEuropean Monetary Union.\nIn 1998, in anticipation of Economic and Monetary Union of the European Union, the Council of the European Union addressed the monetary agreements France had with the CFA Zone and Comoros and ruled that:\nCriticism in France.\nThe yellow vest movement in France includes in its brochure the demand for the end of the CFA franc in Central and West Africa.The yellow vest movement, perceives the CFA franc as a tool of French imperialism and a catch-all on African economies.\nCriticism and replacement in West Africa.\nThe currency has been criticized for making national monetary policy for the developing countries of French West Africa all but impossible, since the CFA's value is pegged to the euro (whose monetary policy is set by the European Central Bank). Others disagree and argue that the CFA \"helps stabilize the national currencies of Franc Zone member-countries and greatly facilitates the flow of exports and imports between France and the member-countries\". The European Union's 2008 assessment of the CFA's link to the euro noted that \"benefits from economic integration within each of the two monetary unions of the CFA franc zone, and even more so between them, remained remarkably low\" but that \"the peg to the French franc and, since 1999, to the euro as exchange rate anchor is usually found to have had favourable effects in the region in terms of macroeconomic stability\".\nCritics point out that the currency is controlled by the French treasury, and in turn African countries channel more money to France than they receive in aid and have no sovereignty over their monetary policies. In January 2019, Italian ministers accused France of impoverishing Africa through the CFA franc, and criticism continued from various African organizations. On 21 December 2019, President Alassane Ouattara of the Ivory Coast and President Emmanuel Macron of France announced an initiative to replace the West African CFA Franc with the Eco. Subsequently, a reform of the West African CFA franc was initiated. In May 2020, the French National Assembly agreed to end the French engagement in the West African CFA franc. The countries using the currency will no longer have to deposit half of their foreign exchange reserves with the French Treasury.\nThe broader Economic Community of West African States (ECOWAS), which includes the members of UEMOA, plans to introduce its own common currency for its member states by 2027, for which they have also formally adopted the name Eco.\nDebate on ending the Central African CFA.\nOn April 25, 2023, the subject of the CFA franc was discussed at the ministerial meeting of the Economic and Monetary Community of Central Africa (CEMAC) and France. The French perceive the guarantee provided to the CFA franc, and the assurance of its convertibility, as a pillar of economic stability for the region. France remains \u201copen\u201d and \u201cavailable\u201d to CEMAC proposals to reform monetary cooperation in Central Africa, as has happened in West Africa.\nInstitutions.\nThere are two different currencies called the CFA franc: the West African CFA franc (ISO 4217 currency code XOF), and the Central Africa CFA franc (ISO 4217 currency code XAF). They are distinguished in French by the meaning of the abbreviation CFA. These two CFA francs have the same exchange rate with the euro (1 euro = 655.957 XOF = 655.957 XAF), and they are both guaranteed by the French treasury (), but the two currencies are only legal tender in their respective member countries.\nWest African.\nThe West African CFA franc (XOF) is known in French as the , where CFA stands for ('Financial Community of Africa') or (\"African Financial Community\"). It is issued by the BCEAO (, i.e., \"Central Bank of the West African States\"), located in Dakar, Senegal, for the eight countries of the UEMOA (, i.e., \"West African Economic and Monetary Union\"):\nThese eight countries have a combined population of 147.6\u00a0million people (as of 2023), and a combined GDP of US$199.4\u00a0billion (as of 2023).\nCentral Africa.\nThe Central Africa CFA franc (XAF) is known in French as the , where CFA stands for (\"Financial Cooperation in Central Africa\"). It is issued by the BEAC (, i.e., \"Bank of the Central African States\"), located in Yaound\u00e9, Cameroon, for the six countries of the CEMAC (, i.e., \"Economic and Monetary Community of Central Africa\"):\nThese six countries have a combined population of 62.8\u00a0million people (as of 2023), and a combined GDP of US$114.3\u00a0billion (as of 2023).\nIn 1975, Central African CFA banknotes were issued with an obverse unique to each participating country, and common reverse, in a fashion similar to euro coins.\nEquatorial Guinea, the only former Spanish colony in the zone, adopted the CFA in 1984."}
{"id": "5664", "revid": "47988270", "url": "https://en.wikipedia.org/wiki?curid=5664", "title": "Consciousness", "text": "Consciousness, at its simplest, is awareness of internal and external existence. However, its nature has led to millennia of analyses, explanations, and debate by philosophers, scientists, and theologians. Opinions differ about what exactly needs to be studied or even considered consciousness. In some explanations, it is synonymous with the mind, and at other times, an aspect of it. In the past, it was one's \"inner life\", the world of introspection, of private thought, imagination, and volition. Today, it often includes any kind of cognition, experience, feeling, or perception. It may be awareness, awareness of awareness, metacognition, or self-awareness, either continuously changing or not. The disparate range of research, notions, and speculations raises a curiosity about whether the right questions are being asked.\nExamples of the range of descriptions, definitions or explanations are: ordered distinction between self and environment, simple wakefulness, one's sense of selfhood or soul explored by \"looking within\"; being a metaphorical \"stream\" of contents, or being a mental state, mental event, or mental process of the brain.\nEtymology.\nThe words \"conscious\" and \"consciousness\" in the English language date to the 17th century, and the first recorded use of \"conscious\" as a simple adjective was applied figuratively to inanimate objects (\"the conscious Groves\", 1643). It derived from the Latin \"conscius\" (\"con-\" \"together\" and \"scio\" \"to know\") which meant \"knowing with\" or \"having joint or common knowledge with another\", especially as in sharing a secret. Thomas Hobbes in \"Leviathan\" (1651) wrote: \"Where two, or more men, know of one and the same fact, they are said to be Conscious of it one to another\". There were also many occurrences in Latin writings of the phrase \"conscius sibi\", which translates literally as \"knowing with oneself\", or in other words \"sharing knowledge with oneself about something\". This phrase has the figurative sense of \"knowing that one knows\", which is something like the modern English word \"conscious\", but it was rendered into English as \"conscious to oneself\" or \"conscious unto oneself\". For example, Archbishop Ussher wrote in 1613 of \"being so conscious unto myself of my great weakness\".\nThe Latin ', literally 'knowledge-with', first appears in Roman juridical texts by writers such as Cicero. It means a kind of shared knowledge with moral value, specifically what a witness knows of someone else's deeds. Although Ren\u00e9 Descartes (1596\u20131650), writing in Latin, is generally taken to be the first philosopher to use \"conscientia\" in a way less like the traditional meaning and more like the way modern English speakers would use \"conscience\", his meaning is nowhere defined. In \"Search after Truth\" (', Amsterdam 1701) he wrote the word with a gloss: \"conscienti\u00e2, vel interno testimonio\" (translatable as \"conscience, or internal testimony\"). It might mean the knowledge of the value of one's own thoughts.\nThe origin of the modern concept of consciousness is often attributed to John Locke who defined the word in his \"Essay Concerning Human Understanding\", published in 1690, as \"the perception of what passes in a man's own mind\". The essay strongly influenced 18th-century British philosophy, and Locke's definition appeared in Samuel Johnson's celebrated \"Dictionary\" (1755).\nThe French term \"conscience\" is defined roughly like English \"consciousness\" in the 1753 volume of Diderot and d'Alembert's Encyclop\u00e9die as \"the opinion or internal feeling that we ourselves have from what we do\".\nProblem of definition.\nScholars are divided as to whether Aristotle had a concept of consciousness. He does not use any single word or terminology that is clearly similar to the phenomenon or concept defined by John Locke. Victor Caston contends that Aristotle did have a concept more clearly similar to perception.\nModern dictionary definitions of the word \"consciousness\" evolved over several centuries and reflect a range of seemingly related meanings, with some differences that have been controversial, such as the distinction between \"inward awareness\" and \"perception\" of the physical world, or the distinction between \"conscious\" and \"unconscious\", or the notion of a \"mental entity\" or \"mental activity\" that is not physical.\nThe common-usage definitions of \"consciousness\" in \"Webster's Third New International Dictionary\" (1966) are as follows:\nThe \"Cambridge English Dictionary\" defines consciousness as \"the state of understanding and realizing something\".\nThe \"Oxford Living Dictionary\" defines consciousness as \"[t]he state of being aware of and responsive to one's surroundings\", \"[a] person's awareness or perception of something\", and \"[t]he fact of awareness by the mind of itself and the world\".\nPhilosophers have attempted to clarify technical distinctions by using a jargon of their own. The corresponding entry in the \"Routledge Encyclopedia of Philosophy\" (1998) reads:\nTraditional metaphors for mind.\nDuring the early 19th century, the emerging field of geology inspired a popular metaphor that the mind likewise had hidden layers \"which recorded the past of the individual\". By 1875, most psychologists believed that \"consciousness was but a small part of mental life\", and this idea underlies the goal of Freudian therapy, to expose the of the mind.\nOther metaphors from various sciences inspired other analyses of the mind, for example: Johann Friedrich Herbart described ideas as being attracted and repulsed like magnets; John Stuart Mill developed the idea of \"mental chemistry\" and \"mental compounds\", and Edward B. Titchener sought the \"structure\" of the mind by analyzing its \"elements\". The abstract idea of \"states of consciousness\" mirrored the concept of states of matter.\nIn 1892, William James noted that the \"ambiguous word 'content' has been recently invented instead of 'object'\" and that the metaphor of mind as a seemed to minimize the dualistic problem of how \"states of consciousness can \" things, or objects; by 1899 psychologists were busily studying the \"contents of conscious experience by introspection and experiment\". Another popular metaphor was James's doctrine of the stream of consciousness, with continuity, fringes, and transitions.\nJames discussed the difficulties of describing and studying psychological phenomena, recognizing that commonly-used terminology was a necessary and acceptable starting point towards more precise, scientifically justified language. Prime examples were phrases like \"inner experience\" and \"personal consciousness\":\nFrom introspection to awareness.\nPrior to the 20th century, philosophers treated the phenomenon of consciousness as the \"inner world [of] one's own mind\", and introspection was the mind \"attending to\" itself, an activity seemingly distinct from that of perceiving the 'outer world' and its physical phenomena. In 1892 William James noted the distinction along with doubts about the inward character of the mind:\nBy the 1960s, for many philosophers and psychologists who talked about consciousness, the word no longer meant the 'inner world' but an indefinite, large category called \"awareness\", as in the following example:\nMany philosophers and scientists have been unhappy about the difficulty of producing a definition that does not involve circularity or fuzziness. In The \"Macmillan Dictionary of Psychology\" (1989 edition), Stuart Sutherland emphasized external awareness, and expressed a skeptical attitude more than a definition:\nUsing 'awareness', however, as a definition or synonym of consciousness is not a simple matter:\nInfluence on research.\nMany philosophers have argued that consciousness is a unitary concept that is understood by the majority of people despite the difficulty philosophers have had defining it. Max Velmans proposed that the \"everyday understanding of consciousness\" uncontroversially \"refers to experience itself rather than any particular thing that we observe or experience\" and he added that consciousness \"is [therefore] exemplified by the things that we observe or experience\", whether thoughts, feelings, or perceptions. Velmans noted however, as of 2009, that there was a deep level of \"confusion and internal division\" among experts about the phenomenon of consciousness, because researchers lacked \"a sufficiently well-specified use of the term...to agree that they are investigating the same thing\". He argued additionally that \"pre-existing theoretical commitments\" to competing explanations of consciousness might be a source of bias.\nWithin the \"modern consciousness studies\" community the technical phrase 'phenomenal consciousness' is a common synonym for all forms of awareness, or simply 'experience', without differentiating between inner and outer, or between higher and lower types. With advances in brain research, \"the presence or absence of \"experienced phenomena\"\" of any kind underlies the work of those neuroscientists who seek \"to analyze the precise relation of conscious phenomenology to its associated information processing\" in the brain. This neuroscientific goal is to find the \"neural correlates of consciousness\" (NCC). One criticism of this goal is that it begins with a theoretical commitment to the neurological origin of all \"experienced phenomena\" whether inner or outer. Also, the fact that the easiest 'content of consciousness' to be so analyzed is \"the experienced three-dimensional world (the phenomenal world) beyond the body surface\" invites another criticism, that most consciousness research since the 1990s, perhaps because of bias, has focused on processes of external perception.\nFrom a history of psychology perspective, Julian Jaynes rejected popular but \"superficial views of consciousness\" especially those which equate it with \"that vaguest of terms, experience\". In 1976 he insisted that if not for introspection, which for decades had been ignored or taken for granted rather than explained, there could be no \"conception of what consciousness is\" and in 1990, he reaffirmed the traditional idea of the phenomenon called 'consciousness', writing that \"its denotative definition is, as it was for Ren\u00e9 Descartes, John Locke, and David Hume, what is introspectable\". Jaynes saw consciousness as an important but small part of human mentality, and he asserted: \"there can be no progress in the science of consciousness until\u00a0... what is introspectable [is] sharply distinguished\" from the processes of cognition such as perception, reactive awareness and attention, and automatic forms of learning, problem-solving, and decision-making.\nThe cognitive science point of view\u2014with an inter-disciplinary perspective involving fields such as psychology, linguistics and anthropology\u2014requires no agreed definition of \"consciousness\" but studies the interaction of many processes besides perception. For some researchers, consciousness is linked to some kind of \"selfhood\", for example to certain pragmatic issues such as the feeling of agency and the effects of regret and action on experience of one's own body or social identity. Similarly Daniel Kahneman, who focused on systematic errors in perception, memory and decision-making, has differentiated between two kinds of mental processes, or cognitive \"systems\": the \"fast\" activities that are primary, automatic and \"cannot be turned off\", and the \"slow\", deliberate, effortful activities of a secondary system \"often associated with the subjective experience of agency, choice, and concentration\". Kahneman's two systems have been described as \"roughly corresponding to unconscious and conscious processes\". The two systems can interact, for example in sharing the control of attention. While System 1 can be impulsive, \"System 2 is in charge of self-control\", and \"When we think of ourselves, we identify with System 2, the conscious, reasoning self that has beliefs, makes choices, and decides what to think about and what to do\".\nSome have argued that we should eliminate the concept from our understanding of the mind, a position known as consciousness semanticism.\nIn medicine, a \"level of consciousness\" terminology is used to describe a patient's arousal and responsiveness, which can be seen as a continuum of states ranging from full alertness and comprehension, through disorientation, delirium, loss of meaningful communication, and finally loss of movement in response to painful stimuli. Issues of practical concern include how the level of consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat conditions in which consciousness is impaired or disrupted. The degree or level of consciousness is measured by standardized behavior observation scales such as the Glasgow Coma Scale.\nPhilosophy of mind.\nWhile historically philosophers have defended various views on consciousness, surveys indicate that physicalism is now the dominant position among contemporary philosophers of mind. For an overview of the field, approaches often include both historical perspectives (e.g., Descartes, Locke, Kant) and organization by key issues in contemporary debates. An alternative is to focus primarily on current philosophical stances and empirical findings.\nCoherence of the concept.\nPhilosophers differ from non-philosophers in their intuitions about what consciousness is. While most people have a strong intuition for the existence of what they refer to as consciousness, skeptics argue that this intuition is too narrow, either because the concept of consciousness is embedded in our intuitions, or because we all are illusions. Gilbert Ryle, for example, argued that traditional understanding of consciousness depends on a Cartesian dualist outlook that improperly distinguishes between mind and body, or between mind and world. He proposed that we speak not of minds, bodies, and the world, but of entities, or identities, acting in the world. Thus, by speaking of \"consciousness\" we end up leading ourselves by thinking that there is any sort of thing as consciousness separated from behavioral and linguistic understandings.\nTypes.\nNed Block argued that discussions on consciousness often failed to properly distinguish \"phenomenal\" (P-consciousness) from \"access\" (A-consciousness), though these terms had been used before Block. P-consciousness, according to Block, is raw experience: it is moving, colored forms, sounds, sensations, emotions and feelings with our bodies and responses at the center. These experiences, considered independently of any impact on behavior, are called qualia. A-consciousness, on the other hand, is the phenomenon whereby information in our minds is accessible for verbal report, reasoning, and the control of behavior. So, when we perceive, information about what we perceive is access conscious; when we introspect, information about our thoughts is access conscious; when we remember, information about the past is access conscious, and so on. Although some philosophers, such as Daniel Dennett, have disputed the validity of this distinction, others have broadly accepted it. David Chalmers has argued that A-consciousness can in principle be understood in mechanistic terms, but that understanding P-consciousness is much more challenging: he calls this the hard problem of consciousness.\nSome philosophers believe that Block's two types of consciousness are not the end of the story. William Lycan, for example, argued in his book \"Consciousness and Experience\" that at least eight clearly distinct types of consciousness can be identified (organism consciousness; control consciousness; consciousness \"of\"; state/event consciousness; reportability; introspective consciousness; subjective consciousness; self-consciousness)\u2014and that even this list omits several more obscure forms.\nThere is also debate over whether or not A-consciousness and P-consciousness always coexist or if they can exist separately. Although P-consciousness without A-consciousness is more widely accepted, there have been some hypothetical examples of A without P. Block, for instance, suggests the case of a \"zombie\" that is computationally identical to a person but without any subjectivity. However, he remains somewhat skeptical concluding \"I don't know whether there are any actual cases of A-consciousness without P-consciousness, but I hope I have illustrated their conceptual possibility\".\nDistinguishing consciousness from its contents.\nSam Harris observes: \"At the level of your experience, you are not a body of cells, organelles, and atoms; you are consciousness and its ever-changing contents\". Seen in this way, consciousness is a subjectively experienced, ever-present field in which things (the contents of consciousness) come and go.\nChristopher Tricker argues that this field of consciousness is symbolized by the mythical bird that opens the Daoist classic the \"Zhuangzi.\" This bird's name is Of a Flock (\"peng\" \u9d6c), yet its back is countless thousands of miles across and its wings are like clouds arcing across the heavens. \"Like Of a Flock, whose wings arc across the heavens, the wings of your consciousness span to the horizon. At the same time, the wings of every other being's consciousness span to the horizon. You are of a flock, one bird among kin.\"\nMind\u2013body problem.\nMental processes (such as consciousness) and physical processes (such as brain events) seem to be correlated, however the specific nature of the connection is unknown.\nThe first influential philosopher to discuss this question specifically was Descartes, and the answer he gave is known as mind\u2013body dualism. Descartes proposed that consciousness resides within an immaterial domain he called \"res cogitans\" (the realm of thought), in contrast to the domain of material things, which he called \"res extensa\" (the realm of extension). He suggested that the interaction between these two domains occurs inside the brain, perhaps in a small midline structure called the pineal gland.\nAlthough it is widely accepted that Descartes explained the problem cogently, few later philosophers have been happy with his solution, and his ideas about the pineal gland have especially been ridiculed. However, no alternative solution has gained general acceptance. Proposed solutions can be divided broadly into two categories: dualist solutions that maintain Descartes's rigid distinction between the realm of consciousness and the realm of matter but give different answers for how the two realms relate to each other; and monist solutions that maintain that there is really only one realm of being, of which consciousness and matter are both aspects. Each of these categories itself contains numerous variants. The two main types of dualism are substance dualism (which holds that the mind is formed of a distinct type of substance not governed by the laws of physics), and property dualism (which holds that the laws of physics are universally valid but cannot be used to explain the mind). The three main types of monism are physicalism (which holds that the mind consists of matter organized in a particular way), idealism (which holds that only thought or experience truly exists, and matter is merely an illusion), and neutral monism (which holds that both mind and matter are aspects of a distinct essence that is itself identical to neither of them). There are also, however, a large number of idiosyncratic theories that cannot cleanly be assigned to any of these schools of thought.\nSince the dawn of Newtonian science with its vision of simple mechanical principles governing the entire universe, some philosophers have been tempted by the idea that consciousness could be explained in purely physical terms. The first influential writer to propose such an idea explicitly was Julien Offray de La Mettrie, in his book \"Man a Machine\" (\"L'homme machine\"). His arguments, however, were very abstract. The most influential modern physical theories of consciousness are based on psychology and neuroscience. Theories proposed by neuroscientists such as Gerald Edelman and Antonio Damasio, and by philosophers such as Daniel Dennett, seek to explain consciousness in terms of neural events occurring within the brain. Many other neuroscientists, such as Christof Koch, have explored the neural basis of consciousness without attempting to frame all-encompassing global theories. At the same time, computer scientists working in the field of artificial intelligence have pursued the goal of creating digital computer programs that can simulate or embody consciousness.\nA few theoretical physicists have argued that classical physics is intrinsically incapable of explaining the holistic aspects of consciousness, but that quantum theory may provide the missing ingredients. Several theorists have therefore proposed quantum mind (QM) theories of consciousness. Notable theories falling into this category include the holonomic brain theory of Karl Pribram and David Bohm, and the Orch-OR theory formulated by Stuart Hameroff and Roger Penrose. Some of these QM theories offer descriptions of phenomenal consciousness, as well as QM interpretations of access consciousness. None of the quantum mechanical theories have been confirmed by experiment. Recent publications by G. Guerreshi, J. Cia, S. Popescu, and H. Briegel could falsify proposals such as those of Hameroff, which rely on quantum entanglement in protein. At the present time many scientists and philosophers consider the arguments for an important role of quantum phenomena to be unconvincing. Empirical evidence is against the notion of quantum consciousness, an experiment about wave function collapse led by Catalina Curceanu in 2022 suggests that quantum consciousness, as suggested by Roger Penrose and Stuart Hameroff, is highly implausible.\nApart from the general question of the \"hard problem\" of consciousness (which is, roughly speaking, the question of how mental experience can arise from a physical basis), a more specialized question is how to square the subjective notion that we are in control of our decisions (at least in some small measure) with the customary view of causality that subsequent events are caused by prior events. The topic of free will is the philosophical and scientific examination of this conundrum.\nProblem of other minds.\nMany philosophers consider experience to be the essence of consciousness, and believe that experience can only fully be known from the inside, subjectively. The problem of other minds is a philosophical problem traditionally stated as the following epistemological question: Given that I can only observe the behavior of others, how can I know that others have minds? The problem of other minds is particularly acute for people who believe in the possibility of philosophical zombies, that is, people who think it is possible in principle to have an entity that is physically indistinguishable from a human being and behaves like a human being in every way but nevertheless lacks consciousness. Related issues have also been studied extensively by Greg Littmann of the University of Illinois, and by Colin Allen (a professor at the University of Pittsburgh) regarding the literature and research studying artificial intelligence in androids.\nThe most commonly given answer is that we attribute consciousness to other people because we see that they resemble us in appearance and behavior; we reason that if they look like us and act like us, they must be like us in other ways, including having experiences of the sort that we do. There are, however, a variety of problems with that explanation. For one thing, it seems to violate the principle of parsimony, by postulating an invisible entity that is not necessary to explain what we observe. Some philosophers, such as Daniel Dennett in a research paper titled \"The Unimagined Preposterousness of Zombies\", argue that people who give this explanation do not really understand what they are saying. More broadly, philosophers who do not accept the possibility of zombies generally believe that consciousness is reflected in behavior (including verbal behavior), and that we attribute consciousness on the basis of behavior. A more straightforward way of saying this is that we attribute experiences to people because of what they can \"do\", including the fact that they can tell us about their experiences.\nQualia.\nThe term \"qualia\" was introduced in philosophical literature by C. I. Lewis. The word is derived from Latin and means \"of what sort\". It is basically a quantity or property of something as perceived or experienced by an individual, like the scent of rose, the taste of wine, or the pain of a headache. They are difficult to articulate or describe. The philosopher and scientist Daniel Dennett describes them as \"the way things seem to us\", while philosopher and cognitive scientist David Chalmers expanded on qualia as the \"hard problem of consciousness\" in the 1990s. When qualia is experienced, activity is simulated in the brain, and these processes are called neural correlates of consciousness (NCCs). Many scientific studies have been done to attempt to link particular brain regions with emotions or experiences.\nSpecies which experience qualia are said to have sentience, which is central to the animal rights movement, because it includes the ability to experience pain and suffering.\nIdentity.\nAn unsolved problem in the philosophy of consciousness is how it relates to the nature of personal identity. This includes questions regarding whether someone is the \"same person\" from moment to moment. If that is the case, another question is what exactly the \"identity carrier\" is that makes a conscious being \"the same\" being from one moment to the next. The problem of determining personal identity also includes also includes questions such as Benj Hellie's vertiginous question, which can be summarized as \"Why am I me and not someone else?\". The philosophical problems regarding the nature of personal identity have been extensively discussed by Thomas Nagel in his book \"The View from Nowhere\".\nA common view of personal identity is that an individual has a continuous identity that persists from moment to moment, with an individual having a continuous identity consisting of a line segment stretching across time from birth to death. In the case of an afterlife as described in Abrahamic religions, one's personal identity is believed to stretch infinitely into the future, forming a ray or line. This notion of identity is similar to the form of dualism advocated by Ren\u00e9 Descartes. However, some philosophers argue that this common notion of personal identity is unfounded. Daniel Kolak has argued extensively against it in his book \"I am You\". Kolak refers to the aforementioned notion of personal identity being linear as \"Closed individualism\". Another view of personal identity according to Kolak is \"Empty individualism\", in which one's personal identity only exists for a single moment of time. However, Kolak advocates for a view of personal identity called Open individualism, in which all consciousness is in reality a single being and individual personal identity in reality does not exist at all. Another philosopher who has contested the notion of personal identity is Derek Parfit. In his book \"Reasons and Persons\", he describes a thought experiment known as the teletransportation paradox. In Buddhist philosophy, the concept of anatt\u0101 refers to the idea that the self is an illusion.\nOther philosophers have argued that Hellie's vertiginous question has a number of philosophical implications relating to the metaphysical nature of consciousness. Christian List argues that the vertiginous question and the existence of first-personal facts is evidence against physicalism, and evidence against other third-personal metaphysical pictures, including standard versions of dualism. List also argues that the vertiginous question implies a \"quadrilemma\" for theories of consciousness. He claims that at most three of the following metaphysical claims can be true: 'first-person realism', 'non-solipsism', 'non-fragmentation', and 'one world' \u2013 and at at least one of these four must be false. List has proposed a model he calls the \"many-worlds theory of consciousness\" in order to reconcile the subjective nature of consciousness without lapsing into solipsism. Vincent Conitzer argues that the nature of identity is connected to A series and B series theories of time, and that A-theory being true implies that the \"I\" is metaphysically distinguished from other perspectives. Giovanni Merlo has argued that the subjectivist view of mental phenomena goes a considerable way towards solving various long-standing philosophical puzzles related to various aspects of consciousness, such as the unity of consciousness, the contents of self-awareness, and the problems with transmitting information related to the contents of subjective experience. Other philosophical theories regarding the metaphysical nature of self are Caspar Hare's theories of perspectival realism, in which things within perceptual awareness have a defining intrinsic property that exists absolutely and not relative to anything, and egocentric presentism, in which the experiences of other individuals are not \"present\" in the way that one's current perspective is.\nScientific study.\nFor many decades, consciousness as a research topic was avoided by the majority of mainstream scientists, because of a general feeling that a phenomenon defined in subjective terms could not properly be studied using objective experimental methods. In 1975 George Mandler published an influential psychological study which distinguished between slow, serial, and limited conscious processes and fast, parallel and extensive unconscious ones. The Science and Religion Forum 1984 annual conference, \"'From Artificial Intelligence to Human Consciousness\"' identified the nature of consciousness as a matter for investigation; Donald Michie was a keynote speaker. Starting in the 1980s, an expanding community of neuroscientists and psychologists have associated themselves with a field called \"Consciousness Studies\", giving rise to a stream of experimental work published in books, journals such as \"Consciousness and Cognition\", \"Frontiers in Consciousness Research\", \"Psyche\", and the \"Journal of Consciousness Studies\", along with regular conferences organized by groups such as the Association for the Scientific Study of Consciousness and the Society for Consciousness Studies.\nModern medical and psychological investigations into consciousness are based on psychological experiments (including, for example, the investigation of priming effects using subliminal stimuli), and on case studies of alterations in consciousness produced by trauma, illness, or drugs. Broadly viewed, scientific approaches are based on two core concepts. The first identifies the content of consciousness with the experiences that are reported by human subjects; the second makes use of the concept of consciousness that has been developed by neurologists and other medical professionals who deal with patients whose behavior is impaired. In either case, the ultimate goals are to develop techniques for assessing consciousness objectively in humans as well as other animals, and to understand the neural and psychological mechanisms that underlie it.\nMeasurement via verbal report.\nExperimental research on consciousness presents special difficulties, due to the lack of a universally accepted operational definition. In the majority of experiments that are specifically about consciousness, the subjects are human, and the criterion used is verbal report: in other words, subjects are asked to describe their experiences, and their descriptions are treated as observations of the contents of consciousness.\nFor example, subjects who stare continuously at a Necker cube usually report that they experience it \"flipping\" between two 3D configurations, even though the stimulus itself remains the same. The objective is to understand the relationship between the conscious awareness of stimuli (as indicated by verbal report) and the effects the stimuli have on brain activity and behavior. In several paradigms, such as the technique of response priming, the behavior of subjects is clearly influenced by stimuli for which they report no awareness, and suitable experimental manipulations can lead to increasing priming effects despite decreasing prime identification (double dissociation).\nVerbal report is widely considered to be the most reliable indicator of consciousness, but it raises a number of issues. For one thing, if verbal reports are treated as observations, akin to observations in other branches of science, then the possibility arises that they may contain errors\u2014but it is difficult to make sense of the idea that subjects could be wrong about their own experiences, and even more difficult to see how such an error could be detected. Daniel Dennett has argued for an approach he calls heterophenomenology, which means treating verbal reports as stories that may or may not be true, but his ideas about how to do this have not been widely adopted. Another issue with verbal report as a criterion is that it restricts the field of study to humans who have language: this approach cannot be used to study consciousness in other species, pre-linguistic children, or people with types of brain damage that impair language. As a third issue, philosophers who dispute the validity of the Turing test may feel that it is possible, at least in principle, for verbal report to be dissociated from consciousness entirely: a philosophical zombie may give detailed verbal reports of awareness in the absence of any genuine awareness.\nAlthough verbal report is in practice the \"gold standard\" for ascribing consciousness, it is not the only possible criterion. In medicine, consciousness is assessed as a combination of verbal behavior, arousal, brain activity, and purposeful movement. The last three of these can be used as indicators of consciousness when verbal behavior is absent. The scientific literature regarding the neural bases of arousal and purposeful movement is very extensive. Their reliability as indicators of consciousness is disputed, however, due to numerous studies showing that alert human subjects can be induced to behave purposefully in a variety of ways in spite of reporting a complete lack of awareness. Studies related to the neuroscience of free will have also shown that the influence consciousness has on decision-making is not always straightforward.\nMirror test and contingency awareness.\nAnother approach applies specifically to the study of self-awareness, that is, the ability to distinguish oneself from others. In the 1970s Gordon Gallup developed an operational test for self-awareness, known as the mirror test. The test examines whether animals are able to differentiate between seeing themselves in a mirror versus seeing other animals. The classic example involves placing a spot of coloring on the skin or fur near the individual's forehead and seeing if they attempt to remove it or at least touch the spot, thus indicating that they recognize that the individual they are seeing in the mirror is themselves. Humans (older than 18 months) and other great apes, bottlenose dolphins, orcas, pigeons, European magpies and elephants have all been observed to pass this test. While some other animals like pigs have been shown to find food by looking into the mirror.\nContingency awareness is another such approach, which is basically the conscious understanding of one's actions and its effects on one's environment. It is recognized as a factor in self-recognition. The brain processes during contingency awareness and learning is believed to rely on an intact medial temporal lobe and age. A study done in 2020 involving transcranial direct current stimulation, Magnetic resonance imaging (MRI) and eyeblink classical conditioning supported the idea that the parietal cortex serves as a substrate for contingency awareness and that age-related disruption of this region is sufficient to impair awareness.\nNeural correlates.\nA major part of the scientific literature on consciousness consists of studies that examine the relationship between the experiences reported by subjects and the activity that simultaneously takes place in their brains\u2014that is, studies of the neural correlates of consciousness. The hope is to find that activity in a particular part of the brain, or a particular pattern of global brain activity, which will be strongly predictive of conscious awareness. Several brain imaging techniques, such as EEG and fMRI, have been used for physical measures of brain activity in these studies.\nAnother idea that has drawn attention for several decades is that consciousness is associated with high-frequency (gamma band) oscillations in brain activity. This idea arose from proposals in the 1980s, by Christof von der Malsburg and Wolf Singer, that gamma oscillations could solve the so-called binding problem, by linking information represented in different parts of the brain into a unified experience. Rodolfo Llin\u00e1s, for example, proposed that consciousness results from recurrent thalamo-cortical resonance where the specific thalamocortical systems (content) and the non-specific (centromedial thalamus) thalamocortical systems (context) interact in the gamma band frequency via synchronous oscillations.\nA number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex (V1) show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry). Furthermore, top-down feedback from higher to lower visual brain areas may be weaker or absent in the peripheral visual field, as suggested by some experimental data and theoretical arguments; nevertheless humans can perceive visual inputs in the peripheral visual field arising from bottom-up V1 neural activities. Meanwhile, bottom-up V1 activities for the central visual fields can be vetoed, and thus made invisible to perception, by the top-down feedback, when these bottom-up signals are inconsistent with the brain's internal model of the visual world.\nModulation of neural responses may correlate with phenomenal experiences. In contrast to the raw electrical responses that do not correlate with consciousness, the modulation of these responses by other stimuli correlates surprisingly well with an important aspect of consciousness: namely with the phenomenal experience of stimulus intensity (brightness, contrast). In the research group of Danko Nikoli\u0107 it has been shown that some of the changes in the subjectively perceived brightness correlated with the modulation of firing rates while others correlated with the modulation of neural synchrony. An fMRI investigation suggested that these findings were strictly limited to the primary visual areas. This indicates that, in the primary visual areas, changes in firing rates and synchrony can be considered as neural correlates of qualia\u2014at least for some type of qualia.\nIn 2013, the perturbational complexity index (PCI) was proposed, a measure of the algorithmic complexity of the electrophysiological response of the cortex to transcranial magnetic stimulation. This measure was shown to be higher in individuals that are awake, in REM sleep or in a locked-in state than in those who are in deep sleep or in a vegetative state, making it potentially useful as a quantitative assessment of consciousness states.\nAssuming that not only humans but even some non-mammalian species are conscious, a number of evolutionary approaches to the problem of neural correlates of consciousness open up. For example, assuming that birds are conscious\u2014a common assumption among neuroscientists and ethologists due to the extensive cognitive repertoire of birds\u2014there are comparative neuroanatomical ways to validate some of the principal, currently competing, mammalian consciousness\u2013brain theories. The rationale for such a comparative study is that the avian brain deviates structurally from the mammalian brain. So how similar are they? What homologs can be identified? The general conclusion from the study by Butler, et al. is that some of the major theories for the mammalian brain also appear to be valid for the avian brain. The structures assumed to be critical for consciousness in mammalian brains have homologous counterparts in avian brains. Thus the main portions of the theories of Crick and Koch, Edelman and Tononi, and Cotterill seem to be compatible with the assumption that birds are conscious. Edelman also differentiates between what he calls primary consciousness (which is a trait shared by humans and non-human animals) and higher-order consciousness as it appears in humans alone along with human language capacity. Certain aspects of the three theories, however, seem less easy to apply to the hypothesis of avian consciousness. For instance, the suggestion by Crick and Koch that layer 5 neurons of the mammalian brain have a special role, seems difficult to apply to the avian brain, since the avian homologs have a different morphology. Likewise, the theory of Eccles seems incompatible, since a structural homolog/analogue to the dendron has not been found in avian brains. The assumption of an avian consciousness also brings the reptilian brain into focus. The reason is the structural continuity between avian and reptilian brains, meaning that the phylogenetic origin of consciousness may be earlier than suggested by many leading neuroscientists.\nJoaquin Fuster of UCLA has advocated the position of the importance of the prefrontal cortex in humans, along with the areas of Wernicke and Broca, as being of particular importance to the development of human language capacities neuro-anatomically necessary for the emergence of higher-order consciousness in humans.\nA study in 2016 looked at lesions in specific areas of the brainstem that were associated with coma and vegetative states. A small region of the rostral dorsolateral pontine tegmentum in the brainstem was suggested to drive consciousness through functional connectivity with two cortical regions, the left ventral anterior insular cortex, and the pregenual anterior cingulate cortex. These three regions may work together as a triad to maintain consciousness.\nModels.\nA wide range of empirical theories of consciousness have been proposed. Adrian Doerig and colleagues list 13 notable theories, while Anil Seth and Tim Bayne list 22 notable theories.\nGlobal workspace theory.\nGlobal workspace theory (GWT) is a cognitive architecture and theory of consciousness proposed by the cognitive psychologist Bernard Baars in 1988. Baars explains the theory with the metaphor of a theater, with conscious processes represented by an illuminated stage. This theater integrates inputs from a variety of unconscious and otherwise autonomous networks in the brain and then broadcasts them to unconscious networks (represented in the metaphor by a broad, unlit \"audience\"). The theory has since been expanded upon by other scientists including cognitive neuroscientist Stanislas Dehaene and Lionel Naccache.\nIntegrated information theory.\nIntegrated information theory (IIT), pioneered by neuroscientist Giulio Tononi in 2004, postulates that consciousness resides in the information being processed and arises once the information reaches a certain level of complexity. Additionally, IIT is one of the only leading theories of consciousness that attempts to create a 1:1 mapping between conscious states and precise, formal mathematical descriptions of those mental states. Proponents of this model suggest that it may provide a physical grounding for consciousness in neurons, as they provide the mechanism by which information is integrated. This also relates to the \"hard problem of consciousness\" proposed by David Chalmers. The theory remains controversial, because of its lack of credibility.\nOrchestrated objective reduction.\nOrchestrated objective reduction (Orch-OR), or the quantum theory of mind, was proposed by scientists Roger Penrose and Stuart Hameroff, and states that consciousness originates at the quantum level inside neurons. The mechanism is held to be a quantum process called objective reduction that is orchestrated by cellular structures called microtubules, which form the cytoskeleton around which the brain is built. The duo proposed that these quantum processes accounted for creativity, innovation, and problem-solving abilities. Penrose published his views in the book \"The Emperor's New Mind\". In 2014, the discovery of quantum vibrations inside microtubules gave new life to the argument.\nAttention schema theory.\nIn 2011, Graziano and Kastner proposed the \"attention schema\" theory of awareness. In that theory, specific cortical areas, notably in the superior temporal sulcus and the temporo-parietal junction, are used to build the construct of awareness and attribute it to other people. The same cortical machinery is also used to attribute awareness to oneself. Damage to these cortical regions can lead to deficits in consciousness such as hemispatial neglect. In the attention schema theory, the value of explaining the feature of awareness and attributing it to a person is to gain a useful predictive model of that person's attentional processing. Attention is a style of information processing in which a brain focuses its resources on a limited set of interrelated signals. Awareness, in this theory, is a useful, simplified schema that represents attentional states. To be aware of X is explained by constructing a model of one's attentional focus on X.\nEntropic brain theory.\nThe entropic brain is a theory of conscious states informed by neuroimaging research with psychedelic drugs. The theory suggests that the brain in primary states such as rapid eye movement (REM) sleep, early psychosis and under the influence of psychedelic drugs, is in a disordered state; normal waking consciousness constrains some of this freedom and makes possible metacognitive functions such as internal self-administered reality testing and self-awareness. Criticism has included questioning whether the theory has been adequately tested.\nProjective consciousness model.\nIn 2017, work by David Rudrauf and colleagues, including Karl Friston, applied the active inference paradigm to consciousness, leading to the projective consciousness model (PCM), a model of how sensory data is integrated with priors in a process of projective transformation. The authors argue that, while their model identifies a key relationship between computation and phenomenology, it does not completely solve the hard problem of consciousness or completely close the explanatory gap.\nClaustrum being the conductor for consciousness.\nIn 2004, a proposal was made by molecular biologist Francis Crick (co-discoverer of the double helix), which stated that to bind together an individual's experience, a conductor of an orchestra is required. Together with neuroscientist Christof Koch, he proposed that this conductor would have to collate information rapidly from various regions of the brain. The duo reckoned that the claustrum was well suited for the task. However, Crick died while working on the idea.\nThe proposal is backed by a study done in 2014, where a team at the George Washington University induced unconsciousness in a 54-year-old woman suffering from intractable epilepsy by stimulating her claustrum. The woman underwent depth electrode implantation and electrical stimulation mapping. The electrode between the left claustrum and anterior-dorsal insula was the one which induced unconsciousness. Correlation for interactions affecting medial parietal and posterior frontal channels during stimulation increased significantly as well. Their findings suggested that the left claustrum or anterior insula is an important part of a network that subserves consciousness, and that disruption of consciousness is related to increased EEG signal synchrony within frontal-parietal networks. However, this remains an isolated, hence inconclusive study.\nBiological function and evolution.\nThe emergence of consciousness during biological evolution remains a topic of ongoing scientific inquiry. The survival value of consciousness is still a matter of exploration and understanding. While consciousness appears to play a crucial role in human cognition, decision-making, and self-awareness, its adaptive significance across different species remains a subject of debate.\nSome people question whether consciousness has any survival value. Some argue that consciousness is a by-product of evolution. Thomas Henry Huxley for example defends in an essay titled \"On the Hypothesis that Animals are Automata, and its History\" an epiphenomenalist theory of consciousness, according to which consciousness is a causally inert effect of neural activity\u2014\"as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery\". To this William James objects in his essay \"Are We Automata?\" by stating an evolutionary argument for mind-brain interaction implying that if the preservation and development of consciousness in the biological evolution is a result of natural selection, it is plausible that consciousness has not only been influenced by neural processes, but has had a survival value itself; and it could only have had this if it had been efficacious. Karl Popper develops a similar evolutionary argument in the book \"The Self and Its Brain\".\nOpinions are divided on when and how consciousness first arose. It has been argued that consciousness emerged (i) exclusively with the first humans, (ii) exclusively with the first mammals, (iii) independently in mammals and birds, or (iv) with the first reptiles. Other authors date the origins of consciousness to the first animals with nervous systems or early vertebrates in the Cambrian over 500 million years ago. Donald Griffin suggests in his book \"Animal Minds\" a gradual evolution of consciousness. Further exploration of the origins of consciousness, particularly in molluscs, has been done by Peter Godfrey Smith in his book \"Metazoa\".\nRegarding the primary function of conscious processing, a recurring idea in recent theories is that phenomenal states somehow integrate neural activities and information-processing that would otherwise be independent. This has been called the \"integration consensus\". Another example has been proposed by Gerald Edelman called dynamic core hypothesis which puts emphasis on reentrant connections that reciprocally link areas of the brain in a massively parallel manner. Edelman also stresses the importance of the evolutionary emergence of higher-order consciousness in humans from the historically older trait of primary consciousness which humans share with non-human animals (see \"Neural correlates\" section above). These theories of integrative function present solutions to two classic problems associated with consciousness: differentiation and unity. They show how our conscious experience can discriminate between a virtually unlimited number of different possible scenes and details (differentiation) because it integrates those details from our sensory systems, while the integrative nature of consciousness in this view easily explains how our experience can seem unified as one whole despite all of these individual parts. However, it remains unspecified which kinds of information are integrated in a conscious manner and which kinds can be integrated without consciousness. Nor is it explained what specific causal role conscious integration plays, nor why the same functionality cannot be achieved without consciousness. Not all kinds of information are capable of being disseminated consciously (e.g., neural activity related to vegetative functions, reflexes, unconscious motor programs, low-level perceptual analyzes, etc.), and many kinds of information can be disseminated and combined with other kinds without consciousness, as in intersensory interactions such as the ventriloquism effect. Hence it remains unclear why any of it is conscious. For a review of the differences between conscious and unconscious integrations, see the article of Ezequiel Morsella.\nAs noted earlier, even among writers who consider consciousness to be well-defined, there is widespread dispute about which animals other than humans can be said to possess it. Edelman has described this distinction as that of humans possessing higher-order consciousness while sharing the trait of primary consciousness with non-human animals (see previous paragraph). Thus, any examination of the evolution of consciousness is faced with great difficulties. Nevertheless, some writers have argued that consciousness can be viewed from the standpoint of evolutionary biology as an adaptation in the sense of a trait that increases fitness. In his article \"Evolution of consciousness\", John Eccles argued that special anatomical and physical properties of the mammalian cerebral cortex gave rise to consciousness (\"[a] psychon ... linked to [a] dendron through quantum physics\"). Bernard Baars proposed that once in place, this \"recursive\" circuitry may have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms. Peter Carruthers has put forth one such potential adaptive advantage gained by conscious creatures by suggesting that consciousness allows an individual to make distinctions between appearance and reality. This ability would enable a creature to recognize the likelihood that their perceptions are deceiving them (e.g. that water in the distance may be a mirage) and behave accordingly, and it could also facilitate the manipulation of others by recognizing how things appear to them for both cooperative and devious ends.\nOther philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes. No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a philosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between function \"F\" being performed by conscious organism \"O\" and non-conscious organism \"O*\", it is unclear what adaptive advantage consciousness could provide. As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was an exaptation arising as a consequence of other developments such as increases in brain size or cortical rearrangement. Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired. Several scholars including Pinker, Chomsky, Edelman, and Luria have indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness (see \"Neural correlates\" section above).\nAltered states.\nThere are some brain states in which consciousness seems to be absent, including dreamless sleep or coma. There are also a variety of circumstances that can change the relationship between the mind and the world in less drastic ways, producing what are known as altered states of consciousness. Some altered states occur naturally; others can be produced by drugs or brain damage. Altered states can be accompanied by changes in thinking, disturbances in the sense of time, feelings of loss of control, changes in emotional expression, alternations in body image and changes in meaning or significance.\nThe two most widely accepted altered states are sleep and dreaming. Although dream sleep and non-dream sleep appear very similar to an outside observer, each is associated with a distinct pattern of brain activity, metabolic activity, and eye movement; each is also associated with a distinct pattern of experience and cognition. During ordinary non-dream sleep, people who are awakened report only vague and sketchy thoughts, and their experiences do not cohere into a continuous narrative. During dream sleep, in contrast, people who are awakened report rich and detailed experiences in which events form a continuous progression, which may however be interrupted by bizarre or fantastic intrusions. Thought processes during the dream state frequently show a high level of irrationality. Both dream and non-dream states are associated with severe disruption of memory: it usually disappears in seconds during the non-dream state, and in minutes after awakening from a dream unless actively refreshed.\nResearch conducted on the effects of partial epileptic seizures on consciousness found that patients who have partial epileptic seizures experience altered states of consciousness. In partial epileptic seizures, consciousness is impaired or lost while some aspects of consciousness, often automated behaviors, remain intact. Studies found that when measuring the qualitative features during partial epileptic seizures, patients exhibited an increase in arousal and became absorbed in the experience of the seizure, followed by difficulty in focusing and shifting attention.\nA variety of psychoactive drugs, including alcohol, have notable effects on consciousness. These range from a simple dulling of awareness produced by sedatives, to increases in the intensity of sensory qualities produced by stimulants, cannabis, empathogens\u2013entactogens such as MDMA (\"Ecstasy\"), or most notably by the class of drugs known as psychedelics. LSD, mescaline, psilocybin, dimethyltryptamine, and others in this group can produce major distortions of perception, including hallucinations; some users even describe their drug-induced experiences as mystical or spiritual in quality. The brain mechanisms underlying these effects are not as well understood as those induced by use of alcohol, but there is substantial evidence that alterations in the brain system that uses the chemical neurotransmitter serotonin play an essential role.\nThere has been some research into physiological changes in yogis and people who practise various techniques of meditation. Some research with brain waves during meditation has reported differences between those corresponding to ordinary relaxation and those corresponding to meditation. It has been disputed, however, whether there is enough evidence to count these as physiologically distinct states of consciousness.\nThe most extensive study of the characteristics of altered states of consciousness was made by psychologist Charles Tart in the 1960s and 1970s. Tart analyzed a state of consciousness as made up of a number of component processes, including exteroception (sensing the external world); interoception (sensing the body); input-processing (seeing meaning); emotions; memory; time sense; sense of identity; evaluation and cognitive processing; motor output; and interaction with the environment. Each of these, in his view, could be altered in multiple ways by drugs or other manipulations. The components that Tart identified have not, however, been validated by empirical studies. Research in this area has not yet reached firm conclusions, but a recent questionnaire-based study identified eleven significant factors contributing to drug-induced states of consciousness: experience of unity; spiritual experience; blissful state; insightfulness; disembodiment; impaired control and cognition; anxiety; complex imagery; elementary imagery; audio-visual synesthesia; and changed meaning of percepts.\nMedical aspects.\nThe medical approach to consciousness is scientifically oriented. It derives from a need to treat people whose brain function has been impaired as a result of disease, brain damage, toxins, or drugs. In medicine, conceptual distinctions are considered useful to the degree that they can help to guide treatments. The medical approach focuses mostly on the amount of consciousness a person has: in medicine, consciousness is assessed as a \"level\" ranging from coma and brain death at the low end, to full alertness and purposeful responsiveness at the high end.\nConsciousness is of concern to patients and physicians, especially neurologists and anesthesiologists. Patients may have disorders of consciousness or may need to be anesthetized for a surgical procedure. Physicians may perform consciousness-related interventions such as instructing the patient to sleep, administering general anesthesia, or inducing medical coma. Also, bioethicists may be concerned with the ethical implications of consciousness in medical cases of patients such as the Karen Ann Quinlan case, while neuroscientists may study patients with impaired consciousness in hopes of gaining information about how the brain works.\nAssessment.\nIn medicine, consciousness is examined using a set of procedures known as neuropsychological assessment. There are two commonly used methods for assessing the level of consciousness of a patient: a simple procedure that requires minimal training, and a more complex procedure that requires substantial expertise. The simple procedure begins by asking whether the patient is able to move and react to physical stimuli. If so, the next question is whether the patient can respond in a meaningful way to questions and commands. If so, the patient is asked for name, current location, and current day and time. A patient who can answer all of these questions is said to be \"alert and oriented times four\" (sometimes denoted \"A&amp;Ox4\" on a medical chart), and is usually considered fully conscious.\nThe more complex procedure is known as a neurological examination, and is usually carried out by a neurologist in a hospital setting. A formal neurological examination runs through a precisely delineated series of tests, beginning with tests for basic sensorimotor reflexes, and culminating with tests for sophisticated use of language. The outcome may be summarized using the Glasgow Coma Scale, which yields a number in the range 3\u201315, with a score of 3 to 8 indicating coma, and 15 indicating full consciousness. The Glasgow Coma Scale has three subscales, measuring the best motor response (ranging from \"no motor response\" to \"obeys commands\"), the best eye response (ranging from \"no eye opening\" to \"eyes opening spontaneously\") and the best verbal response (ranging from \"no verbal response\" to \"fully oriented\"). There is also a simpler pediatric version of the scale, for children too young to be able to use language.\nIn 2013, an experimental procedure was developed to measure degrees of consciousness, the procedure involving stimulating the brain with a magnetic pulse, measuring resulting waves of electrical activity, and developing a consciousness score based on the complexity of the brain activity.\nDisorders.\nMedical conditions that inhibit consciousness are considered disorders of consciousness. This category generally includes minimally conscious state and persistent vegetative state, but sometimes also includes the less severe locked-in syndrome and more severe chronic coma. Differential diagnosis of these disorders is an active area of biomedical research. Finally, brain death results in possible irreversible disruption of consciousness. While other conditions may cause a moderate deterioration (e.g., dementia and delirium) or transient interruption (e.g., grand mal and petit mal seizures) of consciousness, they are not included in this category.\nMedical experts increasingly view anosognosia as a disorder of consciousness. \"Anosognosia\" is a Greek-derived term meaning \"unawareness of disease\". This is a condition in which patients are disabled in some way, most commonly as a result of a stroke, but either misunderstand the nature of the problem or deny that there is anything wrong with them. The most frequently occurring form is seen in people who have experienced a stroke damaging the parietal lobe in the right hemisphere of the brain, giving rise to a syndrome known as hemispatial neglect, characterized by an inability to direct action or attention toward objects located to the left with respect to their bodies. Patients with hemispatial neglect are often paralyzed on the left side of the body, but sometimes deny being unable to move. When questioned about the obvious problem, the patient may avoid giving a direct answer, or may give an explanation that does not make sense. Patients with hemispatial neglect may also fail to recognize paralyzed parts of their bodies: one frequently mentioned case is of a man who repeatedly tried to throw his own paralyzed right leg out of the bed he was lying in, and when asked what he was doing, complained that somebody had put a dead leg into the bed with him. An even more striking type of anosognosia is Anton\u2013Babinski syndrome, a rarely occurring condition in which patients become blind but claim to be able to see normally, and persist in this claim in spite of all evidence to the contrary.\nOutside human adults.\nIn children.\nOf the eight types of consciousness in the Lycan classification, some are detectable in utero and others develop years after birth. Psychologist and educator William Foulkes studied children's dreams and concluded that prior to the shift in cognitive maturation that humans experience during ages five to seven, children lack the Lockean consciousness that Lycan had labeled \"introspective consciousness\" and that Foulkes labels \"self-reflection\". In a 2020 paper, Katherine Nelson and Robyn Fivush use \"autobiographical consciousness\" to label essentially the same faculty, and agree with Foulkes on the timing of this faculty's acquisition. Nelson and Fivush contend that \"language is the tool by which humans create a new, uniquely human form of consciousness, namely, autobiographical consciousness\". Julian Jaynes had staked out these positions decades earlier. Citing the developmental steps that lead the infant to autobiographical consciousness, Nelson and Fivush point to the acquisition of \"theory of mind\", calling theory of mind \"necessary for autobiographical consciousness\" and defining it as \"understanding differences between one's own mind and others' minds in terms of beliefs, desires, emotions and thoughts\". They write, \"The hallmark of theory of mind, the understanding of false belief, occurs ... at five to six years of age\".\nIn animals.\nThe topic of animal consciousness is beset by a number of difficulties. It poses the problem of other minds in an especially severe form, because non-human animals, lacking the ability to express human language, cannot tell humans about their experiences. Also, it is difficult to reason objectively about the question, because a denial that an animal is conscious is often taken to imply that it does not feel, its life has no value, and that harming it is not morally wrong. Descartes, for example, has sometimes been blamed for mistreatment of animals due to the fact that he believed only humans have a non-physical mind. Most people have a strong intuition that some animals, such as cats and dogs, are conscious, while others, such as insects, are not; but the sources of this intuition are not obvious, and are often based on personal interactions with pets and other animals they have observed.\nPhilosophers who consider subjective experience the essence of consciousness also generally believe, as a correlate, that the existence and nature of animal consciousness can never rigorously be known. Thomas Nagel spelled out this point of view in an influential essay titled \"What Is it Like to Be a Bat?\". He said that an organism is conscious \"if and only if there is something that it is like to be that organism\u2014something it is like \"for\" the organism\"; and he argued that no matter how much we know about an animal's brain and behavior, we can never really put ourselves into the mind of the animal and experience its world in the way it does itself. Other thinkers, such as Douglas Hofstadter, dismiss this argument as incoherent. Several psychologists and ethologists have argued for the existence of animal consciousness by describing a range of behaviors that appear to show animals holding beliefs about things they cannot directly perceive\u2014Donald Griffin's 2001 book \"Animal Minds\" reviews a substantial portion of the evidence.\nOn July 7, 2012, eminent scientists from different branches of neuroscience gathered at the University of Cambridge to celebrate the Francis Crick Memorial Conference, which deals with consciousness in humans and pre-linguistic consciousness in nonhuman animals. After the conference, they signed in the presence of Stephen Hawking, the 'Cambridge Declaration on Consciousness', which summarizes the most important findings of the survey:\n\"We decided to reach a consensus and make a statement directed to the public that is not scientific. It's obvious to everyone in this room that animals have consciousness, but it is not obvious to the rest of the world. It is not obvious to the rest of the Western world or the Far East. It is not obvious to the society.\"\n\"Convergent evidence indicates that non-human animals ..., including all mammals and birds, and other creatures, ... have the necessary neural substrates of consciousness and the capacity to exhibit intentional behaviors.\"\nIn artificial intelligence.\nThe idea of an artifact made conscious is an ancient theme of mythology, appearing for example in the Greek myth of Pygmalion, who carved a statue that was magically brought to life, and in medieval Jewish stories of the Golem, a magically animated homunculus built of clay. However, the possibility of actually constructing a conscious machine was probably first discussed by Ada Lovelace, in a set of notes written in 1842 about the Analytical Engine invented by Charles Babbage, a precursor (never built) to modern electronic computers. Lovelace was essentially dismissive of the idea that a machine such as the Analytical Engine could think in a humanlike way. She wrote:\nOne of the most influential contributions to this question was an essay written in 1950 by pioneering computer scientist Alan Turing, titled \"Computing Machinery and Intelligence\". Turing disavowed any interest in terminology, saying that even \"Can machines think?\" is too loaded with spurious connotations to be meaningful; but he proposed to replace all such questions with a specific operational test, which has become known as the Turing test. To pass the test, a computer must be able to imitate a human well enough to fool interrogators. In his essay Turing discussed a variety of possible objections, and presented a counterargument to each of them. The Turing test is commonly cited in discussions of artificial intelligence as a proposed criterion for machine consciousness; it has provoked a great deal of philosophical debate. For example, Daniel Dennett and Douglas Hofstadter argue that anything capable of passing the Turing test is necessarily conscious, while David Chalmers argues that a philosophical zombie could pass the test, yet fail to be conscious. A third group of scholars have argued that with technological growth once machines begin to display any substantial signs of human-like behavior then the dichotomy (of human consciousness compared to human-like consciousness) becomes pass\u00e9 and issues of machine autonomy begin to prevail even as observed in its nascent form within contemporary industry and technology. J\u00fcrgen Schmidhuber argues that consciousness is the result of compression. As an agent sees representation of itself recurring in the environment, the compression of this representation can be called consciousness.\nIn a lively exchange over what has come to be referred to as \"the Chinese room argument\", John Searle sought to refute the claim of proponents of what he calls \"strong artificial intelligence (AI)\" that a computer program can be conscious, though he does agree with advocates of \"weak AI\" that computer programs can be formatted to \"simulate\" conscious states. His own view is that consciousness has subjective, first-person causal powers by being essentially intentional due to the way human brains function biologically; conscious persons can perform computations, but consciousness is not inherently computational the way computer programs are. To make a Turing machine that speaks Chinese, Searle imagines a room with one monolingual English speaker (Searle himself, in fact), a book that designates a combination of Chinese symbols to be output paired with Chinese symbol input, and boxes filled with Chinese symbols. In this case, the English speaker is acting as a computer and the rulebook as a program. Searle argues that with such a machine, he would be able to process the inputs to outputs perfectly without having any understanding of Chinese, nor having any idea what the questions and answers could possibly mean. If the experiment were done in English, since Searle knows English, he would be able to take questions and give answers without any algorithms for English questions, and he would be effectively aware of what was being said and the purposes it might serve. Searle would pass the Turing test of answering the questions in both languages, but he is only conscious of what he is doing when he speaks English. Another way of putting the argument is to say that computer programs can pass the Turing test for processing the syntax of a language, but that the syntax cannot lead to semantic meaning in the way strong AI advocates hoped.\nIn the literature concerning artificial intelligence, Searle's essay has been second only to Turing's in the volume of debate it has generated. Searle himself was vague about what extra ingredients it would take to make a machine conscious: all he proposed was that what was needed was \"causal powers\" of the sort that the brain has and that computers lack. But other thinkers sympathetic to his basic argument have suggested that the necessary (though perhaps still not sufficient) extra conditions may include the ability to pass not just the verbal version of the Turing test, but the robotic version, which requires grounding the robot's words in the robot's sensorimotor capacity to categorize and interact with the things in the world that its words are about, Turing-indistinguishably from a real person. Turing-scale robotics is an empirical branch of research on embodied cognition and situated cognition.\nIn 2014, Victor Argonov has suggested a non-Turing test for machine consciousness based on a machine's ability to produce philosophical judgments. He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures' consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that a machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine's intellect, not by absence of consciousness.\nStream of consciousness.\nWilliam James is usually credited with popularizing the idea that human consciousness flows like a stream, in his \"Principles of Psychology\" of 1890.\nAccording to James, the \"stream of thought\" is governed by five characteristics: \nA similar concept appears in Buddhist philosophy, expressed by the Sanskrit term \"Citta-sa\u1e43t\u0101na\", which is usually translated as mindstream or \"mental continuum\". Buddhist teachings describe that consciousness manifests moment to moment as sense impressions and mental phenomena that are continuously changing. The teachings list six triggers that can result in the generation of different mental events. These triggers are input from the five senses (seeing, hearing, smelling, tasting or touch sensations), or a thought (relating to the past, present or the future) that happen to arise in the mind. The mental events generated as a result of these triggers are: feelings, perceptions and intentions/behaviour. The moment-by-moment manifestation of the mind-stream is said to happen in every person all the time. It even happens in a scientist who analyzes various phenomena in the world, or analyzes the material body including the organ brain. The manifestation of the mindstream is also described as being influenced by physical laws, biological laws, psychological laws, volitional laws, and universal laws. The purpose of the Buddhist practice of mindfulness is to understand the inherent nature of the consciousness and its characteristics.\nNarrative form.\nIn the West, the primary impact of the idea has been on literature rather than science: \"stream of consciousness as a narrative mode\" means writing in a way that attempts to portray the moment-to-moment thoughts and experiences of a character. This technique perhaps had its beginnings in the monologues of Shakespeare's plays and reached its fullest development in the novels of James Joyce and Virginia Woolf, although it has also been used by many other noted writers.\nHere, for example, is a passage from Joyce's \"Ulysses\" about the thoughts of Molly Bloom:\nSpiritual approaches.\nThe Upanishads hold the oldest recorded map of consciousness, as explored by sages through meditation.\nThe Canadian psychiatrist Richard Maurice Bucke, author of the 1901 book \"Cosmic Consciousness: A Study in the Evolution of the Human Mind\", distinguished between three types of consciousness: 'Simple Consciousness', awareness of the body, possessed by many animals; 'Self Consciousness', awareness of being aware, possessed only by humans; and 'Cosmic Consciousness', awareness of the life and order of the universe, possessed only by humans who have attained \"intellectual enlightenment or illumination\".\nAnother thorough account of the spiritual approach is Ken Wilber's 1977 book \"The Spectrum of Consciousness\", a comparison of western and eastern ways of thinking about the mind. Wilber described consciousness as a spectrum with ordinary awareness at one end, and more profound types of awareness at higher levels.\nOther examples include the various levels of spiritual consciousness presented by Prem Saran Satsangi and Stuart Hameroff."}
{"id": "5665", "revid": "1271249238", "url": "https://en.wikipedia.org/wiki?curid=5665", "title": "Currency", "text": "A currency is a standardization of money in any form, in use or circulation as a medium of exchange, for example banknotes and coins. A more general definition is that a currency is a \"system of money\" in common use within a specific environment over time, especially for people in a nation state. Under this definition, the British Pound sterling (\u00a3), euros (\u20ac), Japanese yen (\u00a5), and U.S. dollars (US$) are examples of (government-issued) fiat currencies. Currencies may act as stores of value and be traded between nations in foreign exchange markets, which determine the relative values of the different currencies. Currencies in this sense are either chosen by users or decreed by governments, and each type has limited boundaries of acceptance; i.e., legal tender laws may require a particular unit of account for payments to government agencies.\nOther definitions of the term \"currency\" appear in the respective synonymous articles: banknote, coin, and money. This article uses the definition which focuses on the currency systems of countries.\nOne can classify currencies into three monetary systems: fiat money, commodity money, and representative money, depending on what guarantees a currency's value (the economy at large vs. the government's precious metal reserves). Some currencies function as legal tender in certain jurisdictions, or for specific purposes, such as payment to a government (taxes), or government agencies (fees, fines). Others simply get traded for their economic value.\nThe concept of a digital currency has arisen in recent years. Whether government-backed digital notes and coins (such as the digital renminbi in China, for example) will be successfully developed and implemented remains unknown. Digital currencies that are not issued by a government monetary authority, such as cryptocurrencies like Bitcoin, are different because their value is market-dependent and has no safety net. Various countries have expressed concern about the opportunities that cryptocurrencies create for illegal activities such as scams, ransomware (extortion), money laundering and terrorism. In 2014, the United States IRS advised that virtual currency is treated as property for federal income-tax purposes, and it provides examples of how long-standing tax principles applicable to transactions involving property apply to virtual currency.\nHistory.\nEarly currency.\nOriginally, currency was a form of receipt, representing grain stored in temple granaries in Sumer in ancient Mesopotamia and in Ancient Egypt.\nIn this first stage of currency, metals were used as symbols to represent value stored in the form of commodities. This formed the basis of trade in the Fertile Crescent for over 1500 years. However, the collapse of the Near Eastern trading system pointed to a flaw: in an era where there was no place that was safe to store value, the value of a circulating medium could only be as sound as the forces that defended that store. A trade could only reach as far as the credibility of that military. By the late Bronze Age, however, a series of treaties had established safe passage for merchants around the Eastern Mediterranean, spreading from Minoan Crete and Mycenae in the northwest to Elam and Bahrain in the southeast. It is not known what was used as a currency for these exchanges, but it is thought that oxhide-shaped ingots of copper, produced in Cyprus, may have functioned as a currency.\nIt is thought that the increase in piracy and raiding associated with the Bronze Age collapse, possibly produced by the Peoples of the Sea, brought the trading system of oxhide ingots to an end. It was only the recovery of Phoenician trade in the 10th and 9th centuries BC that led to a return to prosperity, and the appearance of real coinage, possibly first in Anatolia with Croesus of Lydia and subsequently with the Greeks and Persians. In Africa, many forms of value store have been used, including beads, ingots, ivory, various forms of weapons, livestock, the manilla currency, shell money, and ochre and other earth oxides. The manilla rings of West Africa were one of the currencies used from the 15th century onwards to sell slaves. African currency is still notable for its variety, and in many places, various forms of barter still apply.\nCoinage.\nThe prevalence of metal coins possibly led to the metal itself being the store of value: first copper, then both silver and gold, and at one point also bronze. Today other non-precious metals are used for coins. Metals were mined, weighed, and stamped into coins. This was to assure the individual accepting the coin that he was getting a certain known weight of precious metal. Coins could be counterfeited, but the existence of standard coins also created a new unit of account, which helped lead to banking. Archimedes' principle provided the next link: coins could now be easily tested for their fine weight of the metal, and thus the value of a coin could be determined, even if it had been shaved, debased or otherwise tampered with (see Numismatics).\nMost major economies using coinage had several tiers of coins of different values, made of copper, silver, and gold. Gold coins were the most valuable and were used for large purchases, payment of the military, and backing of state activities. Units of account were often defined as the value of a particular type of gold coin. Silver coins were used for midsized transactions, and sometimes also defined a unit of account, while coins of copper or silver, or some mixture of them (see debasement), might be used for everyday transactions. This system had been used in ancient India since the time of the Mahajanapadas. The exact ratios between the values of the three metals varied greatly between different eras and places; for example, the opening of silver mines in the Harz mountains of central Europe made silver relatively less valuable, as did the flood of New World silver after the Spanish conquests. However, the rarity of gold consistently made it more valuable than silver, and likewise silver was consistently worth more than copper.\nPaper money.\nIn premodern China, the need for lending and for a medium of exchange that was less physically cumbersome than large numbers of copper coins led to the introduction of paper money, i.e. banknotes. Their introduction was a gradual process that lasted from the late Tang dynasty (618\u2013907) into the Song dynasty (960\u20131279). It began as a means for merchants to exchange heavy coinage for receipts of deposit issued as promissory notes by wholesalers' shops. These notes were valid for temporary use in a small regional territory. In the 10th century, the Song dynasty government began to circulate these notes amongst the traders in its monopolized salt industry. The Song government granted several shops the right to issue banknotes, and in the early 12th century the government finally took over these shops to produce state-issued currency. Yet the banknotes issued were still only locally and temporarily valid: it was not until the mid 13th century that a standard and uniform government issue of paper money became an acceptable nationwide currency. The already widespread methods of woodblock printing and then Bi Sheng's movable type printing by the 11th century were the impetus for the mass production of paper money in premodern China.\nAt around the same time in the medieval Islamic world, a vigorous monetary economy was created during the 7th\u201312th centuries on the basis of the expanding levels of circulation of a stable high-value currency (the dinar). Innovations introduced by Muslim economists, traders and merchants include the earliest uses of credit, cheques, promissory notes, savings accounts, transaction accounts, loaning, trusts, exchange rates, the transfer of credit and debt, and banking institutions for loans and deposits.\nIn Europe, paper currency was first introduced on a regular basis in Sweden in 1661 (although Washington Irving records an earlier emergency use of it, by the Spanish in a siege during the Conquest of Granada). As Sweden was rich in copper, many copper coins were in circulation, but its relatively low value necessitated extraordinarily big coins, often weighing several kilograms.\nThe advantages of paper currency were numerous: it reduced the need to transport gold and silver, which was risky; it facilitated loans of gold or silver at interest, since the underlying specie (money in the form of gold or silver coins rather than notes) never left the possession of the lender until someone else redeemed the note; and it allowed a division of currency into credit- and specie-backed forms. It enabled the sale of investment in joint-stock companies and the redemption of those shares in a paper.\nBut there were also disadvantages. First, since a note has no intrinsic value, there was nothing to stop issuing authorities from printing more notes than they had specie to back them with. Second, because this increased the money supply, it increased inflationary pressures, a fact observed by David Hume in the 18th century. Thus paper money would often lead to an inflationary bubble, which could collapse if people began demanding hard money, causing the demand for paper notes to fall to zero. The printing of paper money was also associated with wars, and financing of wars, and therefore regarded as part of maintaining a standing army. For these reasons, paper currency was held in suspicion and hostility in Europe and America. It was also addictive since the speculative profits of trade and capital creation were quite large. Major nations established mints to print money and mint coins, and branches of their treasury to collect taxes and hold gold and silver stock.\nAt that time, both silver and gold were considered a legal tender and accepted by governments for taxes. However, the instability in the exchange rate between the two grew over the course of the 19th century, with the increases both in the supply of these metals, particularly silver, and in trade. The parallel use of both metals is called bimetallism, and the attempt to create a bimetallic standard where both gold and silver backed currency remained in circulation occupied the efforts of inflationists. Governments at this point could use currency as an instrument of policy, printing paper currency such as the United States greenback, to pay for military expenditures. They could also set the terms at which they would redeem notes for specie, by limiting the amount of purchase, or the minimum amount that could be redeemed.\nBy 1900, most of the industrializing nations were on some form of gold standard, with paper notes and silver coins constituting the circulating medium. Private banks and governments across the world followed Gresham's law: keeping the gold and silver they received but paying out in notes. This did not happen all around the world at the same time, but occurred sporadically, generally in times of war or financial crisis, beginning in the early 20th century and continuing across the world until the late 20th century, when the regime of floating fiat currencies came into force. One of the last countries to break away from the gold standard was the United States in 1971, an action which was known as the Nixon shock. No country has an enforceable gold standard or silver standard currency system.\nBanknote era.\nA banknote or a bill is a type of currency and it is commonly used as legal tender in many jurisdictions. Together with coins, banknotes make up the cash form of a currency. Banknotes were initially mostly paper, but Australia's Commonwealth Scientific and Industrial Research Organisation developed a polymer currency in the 1980s; it went into circulation on the nation's bicentenary in 1988. Polymer banknotes had already been introduced in the Isle of Man in 1983. polymer currency is used in over 20 countries (over 40 if counting commemorative issues), and dramatically increases the life span of banknotes and reduces counterfeiting.\nModern currencies.\nThe currency used is based on the concept of lex monetae; that a sovereign state decides which currency it shall use. (See Fiat currency.)\nCurrency codes and currency symbols.\nIn 1978 the International Organization for Standardization published a system of three-digit alphabetic codes (ISO 4217) to denote currencies. These codes are based on two initial letters allocated to a specific country and a final letter denoting a specific monetary unit of account.\nMany currencies use a currency symbol. These are not subject to international standards and are not unique: the dollar sign in particular has many uses.\nAlternative currencies.\nDistinct from centrally controlled government-issued currencies, private decentralized trust-reduced networks support alternative currencies (such as Bitcoin and Ethereum's ether, which are classified as cryptocurrency since transference transactions are assured through cryptographic signatures validated by all users. With few exceptions, these currencies are not asset backed. The U.S. Commodity Futures Trading Commission has declared Bitcoin (and, by extension, similar products) to be a commodity under the Commodity Exchange Act.\nThere are also branded currencies, for example 'obligation' based stores of value, such as quasi-regulated BarterCard, Loyalty Points (Credit Cards, Airlines) or Game-Credits (MMO games) that are based on reputation of commercial products.\nHistorically, pseudo-currencies have also included company scrip, a form of wages that could only be exchanged in company stores owned by the employers. Modern token money, such as the tokens operated by local exchange trading systems (LETS), is a form of barter rather than being a true currency.\nThe currency may be Internet-based and digital, for instance, Bitcoin is not tied to any specific country, or the IMF's SDR that is based on a basket of currencies (and assets held).\nPossession and sale of alternative forms of currencies is often outlawed by governments in order to preserve the legitimacy of the constitutional currency for the benefit of all citizens. For example, Article I, section 8, clause 5 of the United States Constitution delegates to Congress the power to coin money and to regulate the value thereof. This power was delegated to Congress in order to establish and preserve a uniform standard of value and to insure a singular monetary system for all purchases and debts in the United States, public and private. Along with the power to coin money, the United States Congress has the concurrent power to restrain the circulation of money which is not issued under its own authority in order to protect and preserve the constitutional currency. It is a violation of federal law for individuals, or organizations to create private coin or currency systems to compete with the official coinage and currency of the United States.\nControl and production.\nCommonly a central bank has the exclusive power to issue all forms of currency, including coins and banknotes (fiat money), and to restrain the circulation alternative currencies for its own area of circulation (a country or group of countries); it regulates the production of currency by banks (credit) through monetary policy.\nAn exchange rate is a price at which two currencies can be exchanged against each other. This is used for trade between the two currency zones. Exchange rates can be classified as either floating or fixed. In the former, day-to-day movements in exchange rates are determined by the market; in the latter, governments intervene in the market to buy or sell their currency to balance supply and demand at a static exchange rate.\nIn cases where a country has control of its own currency, that control is exercised either by a central bank or by a Ministry of Finance. The institution that has control of monetary policy is referred to as the monetary authority. Monetary authorities have varying degrees of autonomy from the governments that create them. A monetary authority is created and supported by its sponsoring government, so independence can be reduced by the legislative or executive authority that creates it.\nSeveral countries can use the same name for their own separate currencies (for example, a \"dollar\" in Australia, Canada, and the United States). By contrast, several countries can also use the same currency (for example, the euro or the CFA franc), or one country can declare the currency of another country to be legal tender. For example, Panama and El Salvador have declared US currency to be legal tender, and from 1791 to 1857, Spanish dollars were legal tender in the United States. At various times countries have either re-stamped foreign coins or used currency boards, issuing one note of currency for each note of a foreign government held, as Ecuador currently does.\nEach currency typically has a main currency unit (the dollar, for example, or the euro) and a fractional unit, often defined as of the main unit: 100 cents\u00a0= 1\u00a0dollar, 100 centimes\u00a0= 1\u00a0franc, 100 pence\u00a0= 1\u00a0pound, although units of or occasionally also occur. Some currencies do not have any smaller units at all, such as the Icelandic kr\u00f3na and the Japanese yen.\nMauritania and Madagascar are the only remaining countries that have theoretical fractional units not based on the decimal system; instead, the Mauritanian ouguiya is in theory divided into 5 khoums, while the Malagasy ariary is theoretically divided into 5 iraimbilanja. In these countries, words like \"dollar\" or \"pound\" \"were simply names for given weights of gold\". Due to inflation khoums and iraimbilanja have in practice fallen into disuse. (See non-decimal currencies for other historic currencies with non-decimal divisions.)\nCurrency convertibility.\nSubject to variation around the world, local currency can be converted to another currency or vice versa with or without central bank/government intervention. Such conversions take place in the foreign exchange market. Based on the above restrictions or free and readily conversion features, currencies are classified as:\nAccording to the three aspects of trade in goods and services, capital flows and national policies, the supply-demand relationship of different currencies determines the exchange ratio between currencies.\nTrade in goods and services\nThrough cost transfer, goods and services circulating in the country (such as hotels, tourism, catering, advertising, household services) will indirectly affect the trade cost of goods and services and the price of export trade. Therefore, services and goods involved in international trade are not the only reason affecting the exchange rate. The large number of international tourists and overseas students has resulted in the flow of services and goods at home and abroad. It also represents that the competitiveness of global goods and services directly affects the change of international exchange rates.\nCapital flows\nNational currencies will be traded on international markets for investment purposes. Investment opportunities in each country attract other countries into investment programs, so that these foreign currencies become the reserves of the central banks of each country. The exchange rate mechanism, in which currencies are quoted continuously between countries, is based on foreign exchange markets in which currencies are invested by individuals and traded or speculated by central banks and investment institutions. In addition, changes in interest rates, capital market fluctuations and changes in investment opportunities will affect the global capital inflows and outflows of countries around the world, and exchange rates will fluctuate accordingly.\nNational policies\nThe country's foreign trade, monetary and fiscal policies affect the exchange rate fluctuations. Foreign trade includes policies such as tariffs and import standards for commodity exports. The impact of monetary policy on the total amount and yield of money directly determines the changes in the international exchange rate. Fiscal policies, such as transfer payments, taxation ratios, and other factors, dominate the profitability of capital and economic development, and the ratio of national debt issuance to deficit determines the repayment capacity and credit rating of the country. Such policies determine the mechanism of linking domestic and foreign currencies and therefore have a significant impact on the generation of exchange rates.\nCurrency convertibility is closely linked to economic development and finance. There are strict conditions for countries to achieve currency convertibility, which is a good way for countries to improve their economies. The currencies of some countries or regions in the world are freely convertible, such as the US dollar, Australian dollar and Japanese yen. The requirements for currency convertibility can be roughly divided into four parts:\nWith a freely convertible currency, domestic firms will have to compete fiercely with their foreign counterparts. The development of competition among them will affect the implementation effect of currency convertibility. In addition, microeconomics is a prerequisite for macroeconomic conditions.\nSince currency convertibility is the cross-border flow of goods and capital, it will have an impact on the macro economy. This requires that the national economy be in a normal and orderly state, that is, there is no serious inflation and economic overheating. In addition, the government should use macro policies to make mature adjustments to deal with the impact of currency exchange on the economy.\nThe maintainability of international balance of payments is the main performance of reasonable economic structure. Currency convertibility not only causes difficulties in the sustainability of international balance of payments but also affects the government's direct control over international economic transactions. To eliminate the foreign exchange shortage, the government needs adequate international reserves.\nThe level of exchange rate is an important factor in maintaining exchange rate stability, both before and after currency convertibility. The exchange rate of freely convertible currency is too high or too low, which can easily trigger speculation and undermine the stability of macroeconomic and financial markets. Therefore, to maintain the level of exchange rate, a proper exchange rate regime is crucial.\nLocal currency.\nIn economics, a local currency is a currency not backed by a national government and intended to trade only in a small area. Advocates such as Jane Jacobs argue that this enables an economically depressed region to pull itself up, by giving the people living there a medium of exchange that they can use to exchange services and locally produced goods (in a broader sense, this is the original purpose of all money). Opponents of this concept argue that local currency creates a barrier that can interfere with economies of scale and comparative advantage and that in some cases they can serve as a means of tax evasion.\nLocal currencies can also come into being when there is economic turmoil involving the national currency. An example of this is the Argentinian economic crisis of 2002 in which IOUs issued by local governments quickly took on some of the characteristics of local currencies.\nOne of the best examples of a local currency is the original LETS currency, founded on Vancouver Island in the early 1980s. In 1982, the Canadian Central Bank's lending rates ran up to 14% which drove chartered bank lending rates as high as 19%. The resulting currency and credit scarcity left island residents with few options other than to create a local currency.\nList of major world payment currencies.\nThe following table are estimates of the 20 most frequently used currencies in world payments in December 2024 by SWIFT.\nSee also.\nRelated concepts\nAccounting units\nLists"}
{"id": "5666", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=5666", "title": "Central bank", "text": "A central bank, reserve bank, national bank, or monetary authority is an institution that manages the currency and monetary policy of a country or monetary union. In contrast to a commercial bank, a central bank possesses a monopoly on increasing the monetary base. Many central banks also have supervisory or regulatory powers to ensure the stability of commercial banks in their jurisdiction, to prevent bank runs, and in some cases also to enforce policies on financial consumer protection and against bank fraud, money laundering, or terrorism financing. Central banks play a crucial role in macroeconomic forecasting, which is essential for guiding monetary policy decisions, especially during times of economic turbulence.\nCentral banks in most developed nations are usually set up to be institutionally independent from political interference, even though governments typically have governance rights over them, legislative bodies exercise scrutiny, and central banks frequently do show responsiveness to politics.\nIssues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies (monetary and fiscal policy) of the state are a focus of contention and criticism by some policymakers, researchers and specialized business, economics and finance media.\nDefinition.\nThe notion of central banks as a separate category from other banks has emerged gradually, and only fully coalesced in the 20th century. In the aftermath of World War I, leading central bankers of the United Kingdom and the United States respectively, Montagu Norman and Benjamin Strong, agreed on a definition of central banks that was both positive and normative. Since that time, central banks have been generally distinguishable from other financial institutions, except under Communism in so-called single-tier banking systems such as Hungary's between 1950 and 1987, where the Hungarian National Bank operated alongside three other major state-owned banks. For earlier periods, what institutions do or do not count as central banks is often not univocal.\nCorrelatively, different scholars have held different views about the timeline of emergence of the first central banks. A widely held view in the second half of the 20th century has been that Stockholms Banco (est. 1657), as the original issuer of banknotes, counted as the oldest central bank, and that consequently its successor the Sveriges Riksbank was the oldest central bank in continuous operation, with the Bank of England as second-oldest and direct or indirect model for all subsequent central banks. That view has persisted in some early-21st-century publications. In more recent scholarship, however, the issuance of banknotes has often been viewed as just one of several techniques to provide central bank money, defined as financial money (in contrast to commodity money) of the highest quality. Under that definition, municipal banks of the late medieval and early modern periods, such as the Taula de canvi de Barcelona (est. 1401) or Bank of Amsterdam (est. 1609), issued central bank money and count as early central banks.\nNaming.\nThere is no universal terminology for the name of a central bank. Early central banks were often the only or principal formal financial institution in their jurisdiction, and were consequently often named \"bank of\" the relevant city's or country's name, e.g. the Bank of Amsterdam, Bank of Hamburg, Bank of England, or Wiener Stadtbank. Naming practices subsequently evolved as more central banks were established. The expression \"central bank\" itself only appeared in the early 19th century, but at that time it referred to the head office of a multi-branched bank, and was still used in that sense by Walter Bagehot in his seminal 1873 essay \"\". During that era, what is now known as a central bank was often referred to as a bank of issue (, ). The reference to central banking in the current sense only became widespread in the early 20th century.\nNames of individual central banks include, with references to the date when the bank acquired its current name: \nIn some cases, the local-language name is used in English-language practice, e.g. Sveriges Riksbank (est. 1668, current name in use since 1866), De Nederlandsche Bank (est. 1814), (est. 1957), or Bangko Sentral ng Pilipinas (est. 1993).\nSome commercial banks have names suggestive of central banks, even if they are not: examples are the State Bank of India and Central Bank of India, National Bank of Greece, Banco do Brasil, National Bank of Pakistan, Bank of China, Bank of Cyprus, or Bank of Ireland, as well as Deutsche Bank. Some but not all of these institutions had assumed central banking roles in the past.\nThe leading executive of a central bank is usually known as the Governor, President, or Chair.\nHistory.\nThe widespread adoption of central banking is a rather recent phenomenon. At the start of the 20th century, approximately two-thirds of sovereign states did not have a central bank. Waves of central bank adoption occurred in the interwar period and in the aftermath of World War II.\nIn the 20th century, central banks were often created with the intent to attract foreign capital, as bankers preferred to lend to countries with a central bank on the gold standard.\nBackground.\nThe use of money as a unit of account predates history. Government control of money is documented in the ancient Egyptian economy (2750\u20132150 BCE). The Egyptians measured the value of goods with a central unit called \"shat\". Like many other currencies, the shat was linked to gold. The value of a shat in terms of goods was defined by government administrations. Other cultures in Asia Minor later materialized their currencies in the form of gold and silver coins.\nThe mere issuance of paper currency or other types of financial money by a government is not the same as central banking. The difference is that government-issued financial money, as present e.g. in China during the Yuan dynasty in the form of paper currency, is typically not freely convertible and thus of inferior quality, occasionally leading to hyperinflation.\nFrom the 12th century, a network of professional banks emerged primarily in Southern Europe (including Southern France, with the Cahorsins). Banks could use book money to create deposits for their customers. Thus, they had the possibility to issue, lend and transfer money autonomously without direct control from political authorities.\nEarly municipal central banks.\nThe Taula de canvi de Barcelona, established in 1401, is the first example of municipal, mostly public banks which pioneered central banking on a limited scale. It was soon emulated by the Bank of Saint George in the Republic of Genoa, first established in 1407, and significantly later by the Banco del Giro in the Republic of Venice and by a network of institutions in Naples that later consolidated into Banco di Napoli. Notable municipal central banks were established in the early 17th century in leading northwestern European commercial centers, namely the Bank of Amsterdam in 1609 and the Hamburger Bank in 1619. These institutions offered a public infrastructure for cashless international payments. They aimed to increase the efficiency of international trade and to safeguard monetary stability. These municipal public banks thus fulfilled comparable functions to modern central banks.\nEarly national central banks.\nThe Swedish central bank, known since 1866 as Sveriges Riksbank, was founded in Stockholm in 1664 from the remains of the failed Stockholms Banco and answered to the Riksdag of the Estates, Sweden's early modern parliament. One role of the Swedish central bank was lending money to the government.\nThe establishment of the Bank of England was devised by Charles Montagu, 1st Earl of Halifax, following a 1691 proposal by William Paterson. A royal charter was granted on through the passage of the Tonnage Act. The bank was given exclusive possession of the government's balances, and was the only limited-liability corporation allowed to issue banknotes. The early modern Bank of England, however, did not have all the functions of a today's central banks, e.g. to regulate the value of the national currency, to finance the government, to be the sole authorized distributor of banknotes, or to function as a lender of last resort to banks suffering a liquidity crisis.\nIn the early 18th century, a major experiment in national central banking failed in France with John Law's Banque Royale in 1720\u20131721. Later in the century, France had other attempts with the Caisse d'Escompte first created in 1767, and King Charles III established the Bank of Spain in 1782. The Russian Assignation Bank, established in 1769 by Catherine the Great, was an outlier from the general pattern of early national central banks in that it was directly owned by the Imperial Russian government, rather than private individual shareholders. In the nascent United States, Alexander Hamilton, as Secretary of the Treasury in the 1790s, set up the First Bank of the United States despite heavy opposition from Jeffersonian Republicans.\nNational central banks since 1800.\nCentral banks were established in many European countries during the 19th century. Napoleon created the Banque de France in 1800, in order to stabilize and develop the French economy and to improve the financing of his wars. The Bank of France remained the most important Continental European central bank throughout the 19th century. The Bank of Finland was founded in 1812, soon after Finland had been taken over from Sweden by Russia to become a grand duchy. Simultaneously, a quasi-central banking role was played by a small group of powerful family-run banking networks, typified by the House of Rothschild, with branches in major cities across Europe, as well as Hottinguer in Switzerland and Oppenheim in Germany.\nThe theory of central banking, even though the name was not yet widely used, evolved in the 19th century. Henry Thornton, an opponent of the real bills doctrine, was a defender of the bullionist position and a significant figure in monetary theory. Thornton's process of monetary expansion anticipated the theories of Knut Wicksell regarding the \"cumulative process which restates the Quantity Theory in a theoretically coherent form\". As a response to a currency crisis in 1797, Thornton wrote in 1802 \"An Enquiry into the Nature and Effects of the Paper Credit of Great Britain\", in which he argued that the increase in paper credit did not cause the crisis. The book also gives a detailed account of the British monetary system as well as a detailed examination of the ways in which the Bank of England should act to counteract fluctuations in the value of the pound.\nIn the United Kingdom until the mid-nineteenth century, commercial banks were able to issue their own banknotes, and notes issued by provincial banking companies were commonly in circulation. Many consider the origins of the central bank to lie with the passage of the Bank Charter Act 1844. Under the 1844 Act, bullionism was institutionalized in Britain, creating a ratio between the gold reserves held by the Bank of England and the notes that the bank could issue. The Act also placed strict curbs on the issuance of notes by the country banks. The Bank of England took over a role of lender of last resort in the 1870s after criticism of its lacklustre response to the failure of Overend, Gurney and Company. The journalist Walter Bagehot wrote on the subject in \"\", in which he advocated for the bank to officially become a lender of last resort during a credit crunch, sometimes referred to as \"Bagehot's dictum\".\nThe 19th and early 20th centuries central banks in most of Europe and Japan developed under the international gold standard. Free banking or currency boards were common at the time. Problems with collapses of banks during downturns, however, led to wider support for central banks in those nations which did not as yet possess them, for example in Australia. In the United States, the role of a central bank had been ended in the so-called Bank War of the 1830s by President Andrew Jackson. In 1913, the U.S. created the Federal Reserve System through the passing of The Federal Reserve Act.\nFollowing World War I, the Economic and Financial Organization (EFO) of the League of Nations, influenced by the ideas of Montagu Norman and other leading policymakers and economists of the time, took an active role to promote the independence of central banks, a key component of the economic orthodoxy the EFO fostered at the Brussels Conference (1920). The EFO thus directed the creation of the Oesterreichische Nationalbank in Austria, Hungarian National Bank, Bank of Danzig, and Bank of Greece, as well as comprehensive reforms of the Bulgarian National Bank and Bank of Estonia. Similar ideas were emulated in other newly independent European countries, e.g. for the National Bank of Czechoslovakia.\nBrazil established a central bank in 1945, which was a precursor to the Central Bank of Brazil created twenty years later. After gaining independence, numerous African and Asian countries also established central banks or monetary unions. The Reserve Bank of India, which had been established during British colonial rule as a private company, was nationalized in 1949 following India's independence. By the early 21st century, most of the world's countries had a national central bank set up as a public sector institution, albeit with widely varying degrees of independence.\nColonial, extraterritorial and federal central banks.\nBefore the near-generalized adoption of the model of national public-sector central banks, a number of economies relied on a central bank that was effectively or legally run from outside their territory. The first colonial central banks, such as the Bank of Java (est. 1828 in Batavia), Banque de l'Alg\u00e9rie (est. 1851 in Algiers), or Hongkong and Shanghai Banking Corporation (est. 1865 in Hong Kong), operated from the colony itself. Following the generalization of the transcontinental use of the electrical telegraph using submarine communications cable, however, new colonial banks were typically headquartered in the colonial metropolis; prominent examples included the Paris-based Banque de l'Indochine (est. 1875), Banque de l'Afrique Occidentale (est. 1901), and Banque de Madagascar (est. 1925). The Banque de l'Alg\u00e9rie's head office was relocated from Algiers to Paris in 1900.\nIn some cases, independent countries which did not have a strong domestic base of capital accumulation and were critically reliant on foreign funding found advantage in granting a central banking role to banks that were effectively or even legally foreign. A seminal case was the Imperial Ottoman Bank established in 1863 as a French-British joint venture, and a particularly egregious one was the Paris-based National Bank of Haiti (est. 1881) which captured significant financial resources from the economically struggling albeit independent nation of Haiti. Other cases include the London-based Imperial Bank of Persia, established in 1885, and the Rome-based National Bank of Albania, established in 1925. The State Bank of Morocco was established in 1907 with international shareholding and headquarters functions distributed between Paris and Tangier, a half-decade before the country lost its independence. In other cases, there have been organized currency unions such as the Belgium\u2013Luxembourg Economic Union established in 1921, under which Luxembourg had no central bank, but that was managed by a national central bank (in that case the National Bank of Belgium) rather than a supranational one. The present-day Common Monetary Area of Southern Africa has comparable features.\nYet another pattern was set in countries where federated or otherwise sub-sovereign entities had wide policy autonomy that was echoed to varying degrees in the organization of the central bank itself. These included, for example, the Austro-Hungarian Bank from 1878 to 1918, the U.S. Federal Reserve in its first two decades, the Bank deutscher L\u00e4nder between 1948 and 1957, or the National Bank of Yugoslavia between 1972 and 1993. Conversely, some countries that are politically organized as federations, such as today's Canada, Mexico, or Switzerland, rely on a unitary central bank.\nSupranational central banks.\nIn the second half of the 20th century, the dismantling of colonial systems left some groups of countries using the same currency even though they had achieved national independence. In contrast to the unraveling of Austria-Hungary and the Ottoman Empire after World War I, some of these countries decided to keep using a common currency, thus forming a monetary union, and to entrust its management to a common central bank. Examples include the Eastern Caribbean Currency Authority, the Central Bank of West African States, and the Bank of Central African States.\nThe concept of supranational central banking took a globally significant dimension with the Economic and Monetary Union of the European Union and the establishment of the European Central Bank (ECB) in 1998. In 2014, the ECB took an additional role of banking supervision as part of the newly established policy of European banking union.\nCentral bank mandates.\nPrice stability.\nThe primary role of central banks is usually to maintain price stability, as defined as a specific level of inflation. Inflation is defined either as the devaluation of a currency or equivalently the rise of prices relative to a currency. Most central banks currently have an inflation target close to 2%.\nSince inflation lowers real wages, Keynesians view inflation as the solution to involuntary unemployment. However, \"unanticipated\" inflation leads to lender losses as the real interest rate will be lower than expected. Thus, Keynesian monetary policy aims for a steady rate of inflation.\nCentral banks as monetary authorities in representative states are intertwined through globalized financial markets. As a regulator of one of the most widespread currencies in the global economy, the US Federal Reserve plays an outsized role in the international monetary market. Being the main supplier and rate adjusted for US dollars, the Federal Reserve implements a set of requirements to control inflation and unemployment in the US.\nHigh employment.\nFrictional unemployment is the time period between jobs when a worker is searching for, or transitioning from one job to another. Unemployment beyond frictional unemployment is classified as unintended unemployment. For example, structural unemployment is a form of unintended unemployment resulting from a mismatch between demand in the labour market and the skills and locations of the workers seeking employment. Macroeconomic policy generally aims to reduce unintended unemployment.\nKeynes labeled any jobs that would be created by a rise in wage-goods (i.e., a decrease in real-wages) as involuntary unemployment:\nEconomic growth.\nEconomic growth can be enhanced by investment in capital, such as more or better machinery. A low interest rate implies that firms can borrow money to invest in their capital stock and pay less interest for it. Lowering the interest is therefore considered to encourage economic growth and is often used to alleviate times of low economic growth. On the other hand, raising the interest rate is often used in times of high economic growth as a contra-cyclical device to keep the economy from overheating and avoid market bubbles.\nFurther goals of monetary policy are stability of interest rates, of the financial market, and of the foreign exchange market.\nGoals frequently cannot be separated from each other and often conflict. Costs must therefore be carefully weighed before policy implementation.\nClimate change.\nIn the aftermath of the Paris agreement on climate change, a debate is now underway on whether central banks should also pursue environmental goals as part of their activities. In 2017, eight central banks formed the Network for Greening the Financial System (NGFS) to evaluate the way in which central banks can use their regulatory and monetary policy tools to support climate change mitigation. Today more than 70 central banks are part of the NGFS.\nIn January 2020, the European Central Bank has announced it will consider climate considerations when reviewing its monetary policy framework.\nProponents of \"green monetary policy\" are proposing that central banks include climate-related criteria in their collateral eligibility frameworks, when conducting asset purchases and also in their refinancing operations. But critics such as Jens Weidmann are arguing it is not central banks' role to conduct climate policy. China is among the most advanced central banks when it comes to green monetary policy. It has given green bonds preferential status to lower their yield and uses window policy to direct green lending.\nThe implications of potential stranded assets in the economy highlights one example of the embedded transition risk to climate change with potential cascade effects throughout the financial system. In response, four broad types of interventions including methodology development, investor encouragement, financial regulation and policy toolkits have been adopted by or suggested for central banks.\nAchieving the 2\u00b0C threshold revolve in part around the development of climate-aligned financial regulations. A significant challenge lies in the lack of awareness among corporations and investors, driven by poor information flow and insufficient disclosure. To address this issue, regulators and central banks are promoting transparency, integrated reporting, and exposure specifications, with the goal of promoting long-term, low-carbon emission goals, rather than short-term financial objectives. These regulations aim to assess risk comprehensively, identifying carbon-intensive assets and increasing their capital requirements. This should result in high-carbon assets becoming less attractive while favoring low-carbon assets, which have historically been perceived as high-risk, and low volatility investment vehicles.\nQuantitative easing is a potential measure that could be applied by Central banks to achieve a low-carbon transition. Although there is a historical bias toward high-carbon companies, included in Central banks portfolios due to their high credit ratings, innovative approaches to quantitative easing could invert this trend to favor low-carbon assets.\nConsidering the potential impact of central banks on climate change, it is important to consider the mandates of central banks. The mandate of a central bank can be narrow, meaning only a few objectives are given, limiting the ability of a central bank to include climate change in its policies. However, central bank mandates may not necessarily have to be modified to accommodate climate change-related activities. For example, the European Central Bank has incorporated carbon-emissions into its asset purchase criteria, despite its relatively narrow mandate that focuses on price stability.\nCentral bank operations.\nThe functions of a central bank may include:\nMonetary policy.\nCentral banks implement a country's chosen monetary policy.\nCurrency issuance.\nAt the most basic level, monetary policy involves establishing what form of currency the country may have, whether a fiat currency, gold-backed currency (disallowed for countries in the International Monetary Fund), currency board or a currency union. When a country has its own national currency, this involves the issue of some form of standardized currency, which is essentially a form of promissory note: \"money\" under certain circumstances. Historically, this was often a promise to exchange the money for precious metals in some fixed amount. Now, when many currencies are fiat money, the \"promise to pay\" consists of the promise to accept that currency to pay for taxes.\nA central bank may use another country's currency either directly in a currency union, or indirectly on a currency board. In the latter case, exemplified by the Bulgarian National Bank, Hong Kong and Latvia (until 2014), the local currency is backed at a fixed rate by the central bank's holdings of a foreign currency.\nSimilar to commercial banks, central banks hold assets (government bonds, foreign exchange, gold, and other financial assets) and incur liabilities (currency outstanding). Central banks create money by issuing banknotes and loaning them to the government in exchange for interest-bearing assets such as government bonds. When central banks decide to increase the money supply by an amount which is greater than the amount their national governments decide to borrow, the central banks may purchase private bonds or assets denominated in foreign currencies.\nThe European Central Bank remits its interest income to the central banks of the member countries of the European Union. The US Federal Reserve remits most of its profits to the U.S. Treasury. This income, derived from the power to issue currency, is referred to as seigniorage, and usually belongs to the national government. The state-sanctioned power to create currency is called the Right of Issuance. Throughout history, there have been disagreements over this power, since whoever controls the creation of currency controls the seigniorage income.\nThe expression \"monetary policy\" may also refer more narrowly to the interest-rate targets and other active measures undertaken by the monetary authority.\nMonetary policy instruments.\nThe primary monetary policy tool available to central banks is the administered interest rate paid on qualifying deposits held with them. Adjusting this rate up or down influences the rate commercial banks pay on their own customer deposits, which in turn influences the rate that commercial banks charge customers for loans.\nA central bank affects the monetary base through open market operations, if its country has a well developed market for its government bonds. This entails managing the quantity of money in circulation through the buying and selling of various financial instruments, such as treasury bills, repurchase agreements or \"repos\", company bonds, or foreign currencies, in exchange for money on deposit at the central bank. Those deposits are convertible to currency, so all of these purchases or sales result in more or less base currency entering or leaving market circulation.\nIf the central bank wishes to decrease interest rates, it reduces its administered rates (Bank Rate, the reverse repurchase agreement rate and the discount rate). This results in commercial banks bidding down the rate they pay customers on their deposits and, subsequently, loan rates are reduced commensurately. Cheaper credit can increase consumer spending or business investment, stimulating output growth. On the other hand, cheaper interest income can reduce spending, suppressing output. Additionally, when business loans are more affordable, companies can expand to keep up with consumer demand. They ultimately hire more workers, whose incomes increase, which in its turn also increases the demand. This method is usually enough to stimulate demand and drive economic growth to a higher rate. In other instances, monetary policy might instead entail the targeting of a specific exchange rate relative to some foreign currency or else relative to gold. For example, in the case of the United States, the Federal Reserve targets the federal funds rate, the rate at which member banks lend to one another overnight; however, the monetary policy of China (since 2014) is to target the exchange rate between the Chinese renminbi and a basket of foreign currencies.\nA third alternative is to change reserve requirements. The reserve requirement refers to the proportion of total liabilities that banks must keep on hand overnight, either in its vaults or at the central bank. Banks only maintain a small portion of their assets as cash available for immediate withdrawal; the rest is invested in illiquid assets like mortgages and loans. Lowering the reserve requirement frees up funds for banks to buy other profitable assets. However, even though this tool immediately increases liquidity, central banks rarely change the reserve requirement because doing so frequently adds uncertainty to banks' planning. Most modern central banks now have zero formal reserve requirement.\nUnconventional monetary policy.\nOther forms of monetary policy, particularly used when interest rates are at or near 0% and there are concerns about deflation or deflation is occurring, are referred to as unconventional monetary policy. These include credit easing, quantitative easing, forward guidance, and signalling. In credit easing, a central bank purchases private sector assets to improve liquidity and improve access to credit. Signaling can be used to lower market expectations for lower interest rates in the future. For example, during the credit crisis of 2008, the US Federal Reserve indicated rates would be low for an \"extended period\", and the Bank of Canada made a \"conditional commitment\" to keep rates at the lower bound of 25 basis points (0.25%) until the end of the second quarter of 2010.\nSome have envisaged the use of what Milton Friedman once called \"helicopter money\" whereby the central bank would make direct transfers to citizens in order to lift inflation up to the central bank's intended target. Such policy option could be particularly effective at the zero lower bound.\nCentral Bank Digital Currencies.\nSince 2017, prospect of implementing Central Bank Digital Currency (CBDC) has been in discussion. As of the end of 2018, at least 15 central banks were considering to implementing CBDC. Since 2014, the People's Bank of China has been working on a project for digital currency to make its own digital currency and electronic payment systems.\nBanking supervision and other activities.\nIn some countries a central bank, through its subsidiaries, controls and monitors the banking sector. In other countries banking supervision is carried out by a government department such as the UK Treasury, or by an independent government agency, for example, UK's Financial Conduct Authority. It examines the banks' balance sheets and behaviour and policies toward consumers. Apart from refinancing, it also provides banks with services such as transfer of funds, bank notes and coins or foreign currency. Thus it is often described as the \"bank of banks\".\nMany countries will monitor and control the banking sector through several different agencies and for different purposes. The Bank regulation in the United States for example is highly fragmented with 3 federal agencies, the Federal Deposit Insurance Corporation, the Federal Reserve Board, or Office of the Comptroller of the Currency and numerous others on the state and the private level. There is usually significant cooperation between the agencies. For example, money center banks, deposit-taking institutions, and other types of financial institutions may be subject to different (and occasionally overlapping) regulation. Some types of banking regulation may be delegated to other levels of government, such as state or provincial governments.\nAny cartel of banks is particularly closely watched and controlled. Most countries control bank mergers and are wary of concentration in this industry due to the danger of groupthink and runaway lending bubbles based on a single point of failure, the credit culture of the few large banks.\nPublic communication.\nCentral banks have increasingly engaged in public communication to ensure accountability, build trust, and manage inflation expectations. Various aspects of central bank communication are also analyzed, including textual content through text mining techniques, facial expressions during press conferences, vocal characteristics, and the clarity and readability of monetary policy announcements.\nCentral bank governance and independence.\nNumerous governments have opted to make central banks independent. The economic logic behind central bank independence is that when governments delegate monetary policy to an independent central bank (with an anti-inflationary purpose) and away from elected politicians, monetary policy will not reflect the interests of the politicians. When governments control monetary policy, politicians may be tempted to boost economic activity in advance of an election to the detriment of the long-term health of the economy and the country. As a consequence, financial markets may not consider future commitments to low inflation to be credible when monetary policy is in the hands of elected officials, which increases the risk of capital flight. An alternative to central bank independence is to have fixed exchange rate regimes.\nGovernments generally have some degree of influence over even \"independent\" central banks; the aim of independence is primarily to prevent short-term interference. In 1951, the became the first central bank to be given full independence, leading this form of central bank to be referred to as the \"Bundesbank model\", as opposed, for instance, to the New Zealand model, which has a goal (i.e. inflation target) set by the government.\nCentral bank independence is usually guaranteed by legislation and the institutional framework governing the bank's relationship with elected officials, particularly the minister of finance. Central bank legislation will enshrine specific procedures for selecting and appointing the head of the central bank. Often the minister of finance will appoint the governor in consultation with the central bank's board and its incumbent governor. In addition, the legislation will specify banks governor's term of appointment. The most independent central banks enjoy a fixed non-renewable term for the governor in order to eliminate pressure on the governor to please the government in the hope of being re-appointed for a second term. Generally, independent central banks enjoy both goal and instrument independence.\nDespite their independence, central banks are usually accountable at some level to government officials, either to the finance ministry or to parliament. For example, the Board of Governors of the U.S. Federal Reserve are nominated by the U.S. president and confirmed by the Senate, publishes verbatim transcripts, and balance sheets are audited by the Government Accountability Office.\nIn the 1990s there was a trend towards increasing the independence of central banks as a way of improving long-term economic performance. While a large volume of economic research has been done to define the relationship between central bank independence and economic performance, the results are ambiguous.\nThe literature on central bank independence has defined a cumulative and complementary number of aspects:\nThere is very strong consensus among economists that an independent central bank can run a more credible monetary policy, making market expectations more responsive to signals from the central bank. Both the Bank of England (1997) and the European Central Bank have been made independent and follow a set of published inflation targets so that markets know what to expect. Populism can reduce de facto central bank independence.\nInternational organizations such as the World Bank, the Bank for International Settlements (BIS) and the International Monetary Fund (IMF) strongly support central bank independence. This results, in part, from a belief in the intrinsic merits of increased independence. The support for independence from the international organizations also derives partly from the connection between increased independence for the central bank and increased transparency in the policy-making process. The IMF's Financial Services Action Plan (FSAP) review self-assessment, for example, includes a number of questions about central bank independence in the transparency section. An independent central bank will score higher in the review than one that is not independent.\nCentral bank independence indices.\nCentral bank independence indices allow a quantitative analysis of central bank independence for individual countries over time. One central bank independence index is the Garriga CBI, where a higher index indicates higher central bank independence, shown below for individual countries.\nStatistics.\nCollectively, central banks purchase less than 500 tonnes of gold each year, on average (out of an annual global production of 2,500\u20133,000 tonnes). In 2018, central banks collectively hold over 33,000 metric tons of the gold, about a fifth of all the gold ever mined, according to Bloomberg News.\nIn 2016, 75% of the world's central-bank assets were controlled by four centers in China, the United States, Japan and the eurozone. The central banks of Brazil, Switzerland, Saudi Arabia, the U.K., India and Russia, each account for an average of 2.5 percent. The remaining 107 central banks hold less than 13 percent. According to data compiled by Bloomberg News, the top 10 largest central banks owned $21.4\u00a0trillion in assets, a 10 percent increase from 2015."}
{"id": "5667", "revid": "17794675", "url": "https://en.wikipedia.org/wiki?curid=5667", "title": "Chlorine", "text": "Chlorine is a chemical element; it has symbol Cl and atomic number 17. The second-lightest of the halogens, it appears between fluorine and bromine in the periodic table and its properties are mostly intermediate between them. Chlorine is a yellow-green gas at room temperature. It is an extremely reactive element and a strong oxidising agent: among the elements, it has the highest electron affinity and the third-highest electronegativity on the revised Pauling scale, behind only oxygen and fluorine.\nChlorine played an important role in the experiments conducted by medieval alchemists, which commonly involved the heating of chloride salts like ammonium chloride (sal ammoniac) and sodium chloride (common salt), producing various chemical substances containing chlorine such as hydrogen chloride, mercury(II) chloride (corrosive sublimate), and . However, the nature of free chlorine gas as a separate substance was only recognised around 1630 by Jan Baptist van Helmont. Carl Wilhelm Scheele wrote a description of chlorine gas in 1774, supposing it to be an oxide of a new element. In 1809, chemists suggested that the gas might be a pure element, and this was confirmed by Sir Humphry Davy in 1810, who named it after the Ancient Greek (, \"pale green\") because of its colour.\nBecause of its great reactivity, all chlorine in the Earth's crust is in the form of ionic chloride compounds, which includes table salt. It is the second-most abundant halogen (after fluorine) and 20th most abundant element in Earth's crust. These crystal deposits are nevertheless dwarfed by the huge reserves of chloride in seawater.\nElemental chlorine is commercially produced from brine by electrolysis, predominantly in the chloralkali process. The high oxidising potential of elemental chlorine led to the development of commercial bleaches and disinfectants, and a reagent for many processes in the chemical industry. Chlorine is used in the manufacture of a wide range of consumer products, about two-thirds of them organic chemicals such as polyvinyl chloride (PVC), many intermediates for the production of plastics, and other end products which do not contain the element. As a common disinfectant, elemental chlorine and chlorine-generating compounds are used more directly in swimming pools to keep them sanitary. Elemental chlorine at high concentration is extremely dangerous, and poisonous to most living organisms. As a chemical warfare agent, chlorine was first used in World War\u00a0I as a poison gas weapon.\nIn the form of chloride ions, chlorine is necessary to all known species of life. Other types of chlorine compounds are rare in living organisms, and artificially produced chlorinated organics range from inert to toxic. In the upper atmosphere, chlorine-containing organic molecules such as chlorofluorocarbons have been implicated in ozone depletion. Small quantities of elemental chlorine are generated by oxidation of chloride ions in neutrophils as part of an immune system response against bacteria.\nHistory.\nThe most common compound of chlorine, sodium chloride, has been known since ancient times; archaeologists have found evidence that rock salt was used as early as 3000\u00a0BC and brine as early as 6000\u00a0BC.\nEarly discoveries.\nAround 900, the authors of the Arabic writings attributed to Jabir ibn Hayyan (Latin: Geber) and the Persian physician and alchemist Abu Bakr al-Razi ( 865\u2013925, Latin: Rhazes) were experimenting with sal ammoniac (ammonium chloride), which when it was distilled together with vitriol (hydrated sulfates of various metals) produced hydrogen chloride. However, it appears that in these early experiments with chloride salts, the gaseous products were discarded, and hydrogen chloride may have been produced many times before it was discovered that it can be put to chemical use. One of the first such uses was the synthesis of mercury(II) chloride (corrosive sublimate), whose production from the heating of mercury either with alum and ammonium chloride or with vitriol and sodium chloride was first described in the \"De aluminibus et salibus\" (\"On Alums and Salts\", an eleventh- or twelfth century Arabic text falsely attributed to Abu Bakr al-Razi and translated into Latin in the second half of the twelfth century by Gerard of Cremona, 1144\u20131187). Another important development was the discovery by pseudo-Geber (in the \"De inventione veritatis\", \"On the Discovery of Truth\", after c.\u00a01300) that by adding ammonium chloride to nitric acid, a strong solvent capable of dissolving gold (i.e., \"aqua regia\") could be produced. Although \"aqua regia\" is an unstable mixture that continually gives off fumes containing free chlorine gas, this chlorine gas appears to have been ignored until c.\u00a01630, when its nature as a separate gaseous substance was recognised by the Brabantian chemist and physician Jan Baptist van Helmont.\nIsolation.\nThe element was first studied in detail in 1774 by Swedish chemist Carl Wilhelm Scheele, and he is credited with the discovery. Scheele produced chlorine by reacting MnO2 (as the mineral pyrolusite) with HCl:\nScheele observed several of the properties of chlorine: the bleaching effect on litmus, the deadly effect on insects, the yellow-green colour, and the smell similar to aqua regia. He called it \"dephlogisticated muriatic acid air\" since it is a gas (then called \"airs\") and it came from hydrochloric acid (then known as \"muriatic acid\"). He failed to establish chlorine as an element.\nCommon chemical theory at that time held that an acid is a compound that contains oxygen (remnants of this survive in the German and Dutch names of oxygen: or \"\", both translating into English as \"acid substance\"), so a number of chemists, including Claude Berthollet, suggested that Scheele's \"dephlogisticated muriatic acid air\" must be a combination of oxygen and the yet undiscovered element, \"muriaticum\".\nIn 1809, Joseph Louis Gay-Lussac and Louis-Jacques Th\u00e9nard tried to decompose \"dephlogisticated muriatic acid air\" by reacting it with charcoal to release the free element \"muriaticum\" (and carbon dioxide). They did not succeed and published a report in which they considered the possibility that \"dephlogisticated muriatic acid air\" is an element, but were not convinced.\nIn 1810, Sir Humphry Davy tried the same experiment again, and concluded that the substance was an element, and not a compound. He announced his results to the Royal Society on 15 November that year. At that time, he named this new element \"chlorine\", from the Greek word \u03c7\u03bb\u03c9\u03c1\u03bf\u03c2 (\"chl\u014dros\", \"green-yellow\"), in reference to its colour. The name \"halogen\", meaning \"salt producer\", was originally used for chlorine in 1811 by Johann Salomo Christoph Schweigger. This term was later used as a generic term to describe all the elements in the chlorine family (fluorine, bromine, iodine), after a suggestion by J\u00f6ns Jakob Berzelius in 1826. In 1823, Michael Faraday liquefied chlorine for the first time, and demonstrated that what was then known as \"solid chlorine\" had a structure of chlorine hydrate (Cl2\u00b7H2O).\nLater uses.\nChlorine gas was first used by French chemist Claude Berthollet to bleach textiles in 1785. Modern bleaches resulted from further work by Berthollet, who first produced sodium hypochlorite in 1789 in his laboratory in the town of Javel (now part of Paris, France), by passing chlorine gas through a solution of sodium carbonate. The resulting liquid, known as \"\" (\"Javel water\"), was a weak solution of sodium hypochlorite. This process was not very efficient, and alternative production methods were sought. Scottish chemist and industrialist Charles Tennant first produced a solution of calcium hypochlorite (\"chlorinated lime\"), then solid calcium hypochlorite (bleaching powder). These compounds produced low levels of elemental chlorine and could be more efficiently transported than sodium hypochlorite, which remained as dilute solutions because when purified to eliminate water, it became a dangerously powerful and unstable oxidizer. Near the end of the nineteenth century, E. S. Smith patented a method of sodium hypochlorite production involving electrolysis of brine to produce sodium hydroxide and chlorine gas, which then mixed to form sodium hypochlorite. This is known as the chloralkali process, first introduced on an industrial scale in 1892, and now the source of most elemental chlorine and sodium hydroxide. In 1884 Chemischen Fabrik Griesheim of Germany developed another chloralkali process which entered commercial production in 1888.\nElemental chlorine solutions dissolved in chemically basic water (sodium and calcium hypochlorite) were first used as anti-putrefaction agents and disinfectants in the 1820s, in France, long before the establishment of the germ theory of disease. This practice was pioneered by Antoine-Germain Labarraque, who adapted Berthollet's \"Javel water\" bleach and other chlorine preparations. Elemental chlorine has since served a continuous function in topical antisepsis (wound irrigation solutions and the like) and public sanitation, particularly in swimming and drinking water.\nChlorine gas was first used as a weapon on April 22, 1915, at the Second Battle of Ypres by the German Army. The effect on the allies was devastating because the existing gas masks were difficult to deploy and had not been broadly distributed.\nProperties.\nChlorine is the second halogen, being a nonmetal in group 17 of the periodic table. Its properties are thus similar to fluorine, bromine, and iodine, and are largely intermediate between those of the first two. Chlorine has the electron configuration [Ne]3s23p5, with the seven electrons in the third and outermost shell acting as its valence electrons. Like all halogens, it is thus one electron short of a full octet, and is hence a strong oxidising agent, reacting with many elements in order to complete its outer shell. Corresponding to periodic trends, it is intermediate in electronegativity between fluorine and bromine (F: 3.98, Cl: 3.16, Br: 2.96, I: 2.66), and is less reactive than fluorine and more reactive than bromine. It is also a weaker oxidising agent than fluorine, but a stronger one than bromine. Conversely, the chloride ion is a weaker reducing agent than bromide, but a stronger one than fluoride. It is intermediate in atomic radius between fluorine and bromine, and this leads to many of its atomic properties similarly continuing the trend from iodine to bromine upward, such as first ionisation energy, electron affinity, enthalpy of dissociation of the X2 molecule (X = Cl, Br, I), ionic radius, and X\u2013X bond length. (Fluorine is anomalous due to its small size.)\nAll four stable halogens experience intermolecular van der Waals forces of attraction, and their strength increases together with the number of electrons among all homonuclear diatomic halogen molecules. Thus, the melting and boiling points of chlorine are intermediate between those of fluorine and bromine: chlorine melts at \u2212101.0\u00a0\u00b0C and boils at \u221234.0\u00a0\u00b0C. As a result of the increasing molecular weight of the halogens down the group, the density and heats of fusion and vaporisation of chlorine are again intermediate between those of bromine and fluorine, although all their heats of vaporisation are fairly low (leading to high volatility) thanks to their diatomic molecular structure. The halogens darken in colour as the group is descended: thus, while fluorine is a pale yellow gas, chlorine is distinctly yellow-green. This trend occurs because the wavelengths of visible light absorbed by the halogens increase down the group. Specifically, the colour of a halogen, such as chlorine, results from the electron transition between the highest occupied antibonding \"\u03c0g\" molecular orbital and the lowest vacant antibonding \"\u03c3u\" molecular orbital. The colour fades at low temperatures, so that solid chlorine at \u2212195\u00a0\u00b0C is almost colourless.\nLike solid bromine and iodine, solid chlorine crystallises in the orthorhombic crystal system, in a layered lattice of Cl2 molecules. The Cl\u2013Cl distance is 198\u00a0pm (close to the gaseous Cl\u2013Cl distance of 199\u00a0pm) and the Cl\u00b7\u00b7\u00b7Cl distance between molecules is 332\u00a0pm within a layer and 382\u00a0pm between layers (compare the van der Waals radius of chlorine, 180\u00a0pm). This structure means that chlorine is a very poor conductor of electricity, and indeed its conductivity is so low as to be practically unmeasurable.\nIsotopes.\nChlorine has two stable isotopes, 35Cl and 37Cl. These are its only two natural isotopes occurring in quantity, with 35Cl making up 76% of natural chlorine and 37Cl making up the remaining 24%. Both are synthesised in stars in the oxygen-burning and silicon-burning processes. Both have nuclear spin 3/2+ and thus may be used for nuclear magnetic resonance, although the spin magnitude being greater than 1/2 results in non-spherical nuclear charge distribution and thus resonance broadening as a result of a nonzero nuclear quadrupole moment and resultant quadrupolar relaxation. The other chlorine isotopes are all radioactive, with half-lives too short to occur in nature primordially. Of these, the most commonly used in the laboratory are 36Cl (\"t\"1/2 = 3.0\u00d7105\u00a0y) and 38Cl (\"t\"1/2 = 37.2\u00a0min), which may be produced from the neutron activation of natural chlorine.\nThe most stable chlorine radioisotope is 36Cl. The primary decay mode of isotopes lighter than 35Cl is electron capture to isotopes of sulfur; that of isotopes heavier than 37Cl is beta decay to isotopes of argon; and 36Cl may decay by either mode to stable 36S or 36Ar. 36Cl occurs in trace quantities in nature as a cosmogenic nuclide in a ratio of about (7\u201310)\u00a0\u00d7\u00a010\u221213 to 1 with stable chlorine isotopes: it is produced in the atmosphere by spallation of 36Ar by interactions with cosmic ray protons. In the top meter of the lithosphere, 36Cl is generated primarily by thermal neutron activation of 35Cl and spallation of 39K and 40Ca. In the subsurface environment, muon capture by 40Ca becomes more important as a way to generate 36Cl.\nChemistry and compounds.\nChlorine is intermediate in reactivity between fluorine and bromine, and is one of the most reactive elements. Chlorine is a weaker oxidising agent than fluorine but a stronger one than bromine or iodine. This can be seen from the standard electrode potentials of the X2/X\u2212 couples (F, +2.866\u00a0\u2009V; Cl, +1.395\u00a0V; Br, +1.087\u00a0\u2009V; I, +0.615\u00a0V; At, approximately +0.3\u00a0\u2009V). However, this trend is not shown in the bond energies because fluorine is singular due to its small size, low polarisability, and inability to show hypervalence. As another difference, chlorine has a significant chemistry in positive oxidation states while fluorine does not. Chlorination often leads to higher oxidation states than bromination or iodination but lower oxidation states than fluorination. Chlorine tends to react with compounds including M\u2013M, M\u2013H, or M\u2013C bonds to form M\u2013Cl bonds.\nGiven that E\u00b0(O2/H2O) = +1.229\u00a0V, which is less than +1.395\u00a0V, it would be expected that chlorine should be able to oxidise water to oxygen and hydrochloric acid. However, the kinetics of this reaction are unfavorable, and there is also a bubble overpotential effect to consider, so that electrolysis of aqueous chloride solutions evolves chlorine gas and not oxygen gas, a fact that is very useful for the industrial production of chlorine.\nHydrogen chloride.\nThe simplest chlorine compound is hydrogen chloride, HCl, a major chemical in industry as well as in the laboratory, both as a gas and dissolved in water as hydrochloric acid. It is often produced by burning hydrogen gas in chlorine gas, or as a byproduct of chlorinating hydrocarbons. Another approach is to treat sodium chloride with concentrated sulfuric acid to produce hydrochloric acid, also known as the \"salt-cake\" process:\nIn the laboratory, hydrogen chloride gas may be made by drying the acid with concentrated sulfuric acid. Deuterium chloride, DCl, may be produced by reacting benzoyl chloride with heavy water (D2O).\nAt room temperature, hydrogen chloride is a colourless gas, like all the hydrogen halides apart from hydrogen fluoride, since hydrogen cannot form strong hydrogen bonds to the larger electronegative chlorine atom; however, weak hydrogen bonding is present in solid crystalline hydrogen chloride at low temperatures, similar to the hydrogen fluoride structure, before disorder begins to prevail as the temperature is raised. Hydrochloric acid is a strong acid (p\"K\"a = \u22127) because the hydrogen-chlorine bonds are too weak to inhibit dissociation. The HCl/H2O system has many hydrates HCl\u00b7\"n\"H2O for \"n\" = 1, 2, 3, 4, and 6. Beyond a 1:1 mixture of HCl and H2O, the system separates completely into two separate liquid phases. Hydrochloric acid forms an azeotrope with boiling point 108.58\u00a0\u00b0C at 20.22\u00a0g HCl per 100\u00a0g solution; thus hydrochloric acid cannot be concentrated beyond this point by distillation.\nUnlike hydrogen fluoride, anhydrous liquid hydrogen chloride is difficult to work with as a solvent, because its boiling point is low, it has a small liquid range, its dielectric constant is low and it does not dissociate appreciably into H2Cl+ and ions \u2013 the latter, in any case, are much less stable than the bifluoride ions () due to the very weak hydrogen bonding between hydrogen and chlorine, though its salts with very large and weakly polarising cations such as Cs+ and (R = Me, Et, Bu\"n\") may still be isolated. Anhydrous hydrogen chloride is a poor solvent, only able to dissolve small molecular compounds such as nitrosyl chloride and phenol, or salts with very low lattice energies such as tetraalkylammonium halides. It readily protonates nucleophiles containing lone-pairs or \u03c0 bonds. Solvolysis, ligand replacement reactions, and oxidations are well-characterised in hydrogen chloride solution:\nOther binary chlorides.\nNearly all elements in the periodic table form binary chlorides. The exceptions are decidedly in the minority and stem in each case from one of three causes: extreme inertness and reluctance to participate in chemical reactions (the noble gases, with the exception of xenon in the highly unstable XeCl2 and XeCl4); extreme nuclear instability hampering chemical investigation before decay and transmutation (many of the heaviest elements beyond bismuth); and having an electronegativity higher than chlorine's (oxygen and fluorine) so that the resultant binary compounds are formally not chlorides but rather oxides or fluorides of chlorine. Even though nitrogen in NCl3 is bearing a negative charge, the compound is usually called nitrogen trichloride.\nChlorination of metals with Cl2 usually leads to a higher oxidation state than bromination with Br2 when multiple oxidation states are available, such as in MoCl5 and MoBr3. Chlorides can be made by reaction of an element or its oxide, hydroxide, or carbonate with hydrochloric acid, and then dehydrated by mildly high temperatures combined with either low pressure or anhydrous hydrogen chloride gas. These methods work best when the chloride product is stable to hydrolysis; otherwise, the possibilities include high-temperature oxidative chlorination of the element with chlorine or hydrogen chloride, high-temperature chlorination of a metal oxide or other halide by chlorine, a volatile metal chloride, carbon tetrachloride, or an organic chloride. For instance, zirconium dioxide reacts with chlorine at standard conditions to produce zirconium tetrachloride, and uranium trioxide reacts with hexachloropropene when heated under reflux to give uranium tetrachloride. The second example also involves a reduction in oxidation state, which can also be achieved by reducing a higher chloride using hydrogen or a metal as a reducing agent. This may also be achieved by thermal decomposition or disproportionation as follows:\nMost metal chlorides with the metal in low oxidation states (+1 to +3) are ionic. Nonmetals tend to form covalent molecular chlorides, as do metals in high oxidation states from +3 and above. Both ionic and covalent chlorides are known for metals in oxidation state +3 (e.g. scandium chloride is mostly ionic, but aluminium chloride is not). Silver chloride is very insoluble in water and is thus often used as a qualitative test for chlorine.\nPolychlorine compounds.\nAlthough dichlorine is a strong oxidising agent with a high first ionisation energy, it may be oxidised under extreme conditions to form the cation. This is very unstable and has only been characterised by its electronic band spectrum when produced in a low-pressure discharge tube. The yellow cation is more stable and may be produced as follows:\nThis reaction is conducted in the oxidising solvent arsenic pentafluoride. The trichloride anion, , has also been characterised; it is analogous to triiodide.\nChlorine fluorides.\nThe three fluorides of chlorine form a subset of the interhalogen compounds, all of which are diamagnetic. Some cationic and anionic derivatives are known, such as , , , and Cl2F+. Some pseudohalides of chlorine are also known, such as cyanogen chloride (ClCN, linear), chlorine cyanate (ClNCO), chlorine thiocyanate (ClSCN, unlike its oxygen counterpart), and chlorine azide (ClN3).\nChlorine monofluoride (ClF) is extremely thermally stable, and is sold commercially in 500-gram steel lecture bottles. It is a colourless gas that melts at \u2212155.6\u00a0\u00b0C and boils at \u2212100.1\u00a0\u00b0C. It may be produced by the reaction of its elements at 225\u00a0\u00b0C, though it must then be separated and purified from chlorine trifluoride and its reactants. Its properties are mostly intermediate between those of chlorine and fluorine. It will react with many metals and nonmetals from room temperature and above, fluorinating them and liberating chlorine. It will also act as a chlorofluorinating agent, adding chlorine and fluorine across a multiple bond or by oxidation: for example, it will attack carbon monoxide to form carbonyl chlorofluoride, COFCl. It will react analogously with hexafluoroacetone, (CF3)2CO, with a potassium fluoride catalyst to produce heptafluoroisopropyl hypochlorite, (CF3)2CFOCl; with nitriles RCN to produce RCF2NCl2; and with the sulfur oxides SO2 and SO3 to produce ClSO2F and ClOSO2F respectively. It will also react exothermically with compounds containing \u2013OH and \u2013NH groups, such as water:\nChlorine trifluoride (ClF3) is a volatile colourless molecular liquid which melts at \u221276.3\u00a0\u00b0C and boils at 11.8\u00a0\u2009\u00b0C. It may be formed by directly fluorinating gaseous chlorine or chlorine monofluoride at 200\u2013300\u00a0\u00b0C. One of the most reactive chemical compounds known, the list of elements it sets on fire is diverse, containing hydrogen, potassium, phosphorus, arsenic, antimony, sulfur, selenium, tellurium, bromine, iodine, and powdered molybdenum, tungsten, rhodium, iridium, and iron. It will also ignite water, along with many substances which in ordinary circumstances would be considered chemically inert such as asbestos, concrete, glass, and sand. When heated, it will even corrode noble metals as palladium, platinum, and gold, and even the noble gases xenon and radon do not escape fluorination. An impermeable fluoride layer is formed by sodium, magnesium, aluminium, zinc, tin, and silver, which may be removed by heating. Nickel, copper, and steel containers are usually used due to their great resistance to attack by chlorine trifluoride, stemming from the formation of an unreactive layer of metal fluoride. Its reaction with hydrazine to form hydrogen fluoride, nitrogen, and chlorine gases was used in experimental rocket engine, but has problems largely stemming from its extreme hypergolicity resulting in ignition without any measurable delay. Today, it is mostly used in nuclear fuel processing, to oxidise uranium to uranium hexafluoride for its enriching and to separate it from plutonium, as well as in the semiconductor industry, where it is used to clean chemical vapor deposition chambers. It can act as a fluoride ion donor or acceptor (Lewis base or acid), although it does not dissociate appreciably into and ions.\nChlorine pentafluoride (ClF5) is made on a large scale by direct fluorination of chlorine with excess fluorine gas at 350\u00a0\u00b0C and 250\u00a0atm, and on a small scale by reacting metal chlorides with fluorine gas at 100\u2013300\u00a0\u00b0C. It melts at \u2212103\u00a0\u00b0C and boils at \u221213.1\u00a0\u00b0C. It is a very strong fluorinating agent, although it is still not as effective as chlorine trifluoride. Only a few specific stoichiometric reactions have been characterised. Arsenic pentafluoride and antimony pentafluoride form ionic adducts of the form [ClF4]+[MF6]\u2212 (M = As, Sb) and water reacts vigorously as follows:\nThe product, chloryl fluoride, is one of the five known chlorine oxide fluorides. These range from the thermally unstable FClO to the chemically unreactive perchloryl fluoride (FClO3), the other three being FClO2, F3ClO, and F3ClO2. All five behave similarly to the chlorine fluorides, both structurally and chemically, and may act as Lewis acids or bases by gaining or losing fluoride ions respectively or as very strong oxidising and fluorinating agents.\nChlorine oxides.\nThe chlorine oxides are well-studied in spite of their instability (all of them are endothermic compounds). They are important because they are produced when chlorofluorocarbons undergo photolysis in the upper atmosphere and cause the destruction of the ozone layer. None of them can be made from directly reacting the elements.\nDichlorine monoxide (Cl2O) is a brownish-yellow gas (red-brown when solid or liquid) which may be obtained by reacting chlorine gas with yellow mercury(II) oxide. It is very soluble in water, in which it is in equilibrium with hypochlorous acid (HOCl), of which it is the anhydride. It is thus an effective bleach and is mostly used to make hypochlorites. It explodes on heating or sparking or in the presence of ammonia gas.\nChlorine dioxide (ClO2) was the first chlorine oxide to be discovered in 1811 by Humphry Davy. It is a yellow paramagnetic gas (deep-red as a solid or liquid), as expected from its having an odd number of electrons: it is stable towards dimerisation due to the delocalisation of the unpaired electron. It explodes above \u221240\u00a0\u00b0C as a liquid and under pressure as a gas and therefore must be made at low concentrations for wood-pulp bleaching and water treatment. It is usually prepared by reducing a chlorate as follows:\nIts production is thus intimately linked to the redox reactions of the chlorine oxoacids. It is a strong oxidising agent, reacting with sulfur, phosphorus, phosphorus halides, and potassium borohydride. It dissolves exothermically in water to form dark-green solutions that very slowly decompose in the dark. Crystalline clathrate hydrates ClO2\u00b7\"n\"H2O (\"n\" \u2248 6\u201310) separate out at low temperatures. However, in the presence of light, these solutions rapidly photodecompose to form a mixture of chloric and hydrochloric acids. Photolysis of individual ClO2 molecules result in the radicals ClO and ClOO, while at room temperature mostly chlorine, oxygen, and some ClO3 and Cl2O6 are produced. Cl2O3 is also produced when photolysing the solid at \u221278\u00a0\u00b0C: it is a dark brown solid that explodes below 0\u00a0\u00b0C. The ClO radical leads to the depletion of atmospheric ozone and is thus environmentally important as follows:\nChlorine perchlorate (ClOClO3) is a pale yellow liquid that is less stable than ClO2 and decomposes at room temperature to form chlorine, oxygen, and dichlorine hexoxide (Cl2O6). Chlorine perchlorate may also be considered a chlorine derivative of perchloric acid (HOClO3), similar to the thermally unstable chlorine derivatives of other oxoacids: examples include chlorine nitrate (ClONO2, vigorously reactive and explosive), and chlorine fluorosulfate (ClOSO2F, more stable but still moisture-sensitive and highly reactive). Dichlorine hexoxide is a dark-red liquid that freezes to form a solid which turns yellow at \u2212180\u2009\u00b0C: it is usually made by reaction of chlorine dioxide with oxygen. Despite attempts to rationalise it as the dimer of ClO3, it reacts more as though it were chloryl perchlorate, [ClO2]+[ClO4]\u2212, which has been confirmed to be the correct structure of the solid. It hydrolyses in water to give a mixture of chloric and perchloric acids: the analogous reaction with anhydrous hydrogen fluoride does not proceed to completion.\nDichlorine heptoxide (Cl2O7) is the anhydride of perchloric acid (HClO4) and can readily be obtained from it by dehydrating it with phosphoric acid at \u221210\u00a0\u00b0C and then distilling the product at \u221235\u00a0\u00b0C and 1\u00a0mmHg. It is a shock-sensitive, colourless oily liquid. It is the least reactive of the chlorine oxides, being the only one to not set organic materials on fire at room temperature. It may be dissolved in water to regenerate perchloric acid or in aqueous alkalis to regenerate perchlorates. However, it thermally decomposes explosively by breaking one of the central Cl\u2013O bonds, producing the radicals ClO3 and ClO4 which immediately decompose to the elements through intermediate oxides.\nChlorine oxoacids and oxyanions.\nChlorine forms four oxoacids: hypochlorous acid (HOCl), chlorous acid (HOClO), chloric acid (HOClO2), and perchloric acid (HOClO3). As can be seen from the redox potentials given in the adjacent table, chlorine is much more stable towards disproportionation in acidic solutions than in alkaline solutions:\nThe hypochlorite ions also disproportionate further to produce chloride and chlorate (3 ClO\u2212 2 Cl\u2212 + ) but this reaction is quite slow at temperatures below 70\u00a0\u00b0C in spite of the very favourable equilibrium constant of 1027. The chlorate ions may themselves disproportionate to form chloride and perchlorate (4 Cl\u2212 + 3 ) but this is still very slow even at 100\u00a0\u00b0C despite the very favourable equilibrium constant of 1020. The rates of reaction for the chlorine oxyanions increases as the oxidation state of chlorine decreases. The strengths of the chlorine oxyacids increase very quickly as the oxidation state of chlorine increases due to the increasing delocalisation of charge over more and more oxygen atoms in their conjugate bases.\nMost of the chlorine oxoacids may be produced by exploiting these disproportionation reactions. Hypochlorous acid (HOCl) is highly reactive and quite unstable; its salts are mostly used for their bleaching and sterilising abilities. They are very strong oxidising agents, transferring an oxygen atom to most inorganic species. Chlorous acid (HOClO) is even more unstable and cannot be isolated or concentrated without decomposition: it is known from the decomposition of aqueous chlorine dioxide. However, sodium chlorite is a stable salt and is useful for bleaching and stripping textiles, as an oxidising agent, and as a source of chlorine dioxide. Chloric acid (HOClO2) is a strong acid that is quite stable in cold water up to 30% concentration, but on warming gives chlorine and chlorine dioxide. Evaporation under reduced pressure allows it to be concentrated further to about 40%, but then it decomposes to perchloric acid, chlorine, oxygen, water, and chlorine dioxide. Its most important salt is sodium chlorate, mostly used to make chlorine dioxide to bleach paper pulp. The decomposition of chlorate to chloride and oxygen is a common way to produce oxygen in the laboratory on a small scale. Chloride and chlorate may comproportionate to form chlorine as follows:\nPerchlorates and perchloric acid (HOClO3) are the most stable oxo-compounds of chlorine, in keeping with the fact that chlorine compounds are most stable when the chlorine atom is in its lowest (\u22121) or highest (+7) possible oxidation states. Perchloric acid and aqueous perchlorates are vigorous and sometimes violent oxidising agents when heated, in stark contrast to their mostly inactive nature at room temperature due to the high activation energies for these reactions for kinetic reasons. Perchlorates are made by electrolytically oxidising sodium chlorate, and perchloric acid is made by reacting anhydrous sodium perchlorate or barium perchlorate with concentrated hydrochloric acid, filtering away the chloride precipitated and distilling the filtrate to concentrate it. Anhydrous perchloric acid is a colourless mobile liquid that is sensitive to shock that explodes on contact with most organic compounds, sets hydrogen iodide and thionyl chloride on fire and even oxidises silver and gold. Although it is a weak ligand, weaker than water, a few compounds involving coordinated are known. The Table below presents typical oxidation states for chlorine element as given in the secondary schools or colleges. There are more complex chemical compounds, the structure of which can only be explained using modern quantum chemical methods, for example, cluster technetium chloride [(CH3)4N]3[Tc6Cl14], in which 6 of the 14 chlorine atoms are formally divalent, and oxidation states are fractional. In addition, all the above chemical regularities are valid for \"normal\" or close to normal conditions, while at ultra-high pressures (for example, in the cores of large planets), chlorine can exhibit an oxidation state of -3, forming a Na3Cl compound with sodium, which does not fit into traditional concepts of chemistry.\nOrganochlorine compounds.\nLike the other carbon\u2013halogen bonds, the C\u2013Cl bond is a common functional group that forms part of core organic chemistry. Formally, compounds with this functional group may be considered organic derivatives of the chloride anion. Due to the difference of electronegativity between chlorine (3.16) and carbon (2.55), the carbon in a C\u2013Cl bond is electron-deficient and thus electrophilic. Chlorination modifies the physical properties of hydrocarbons in several ways: chlorocarbons are typically denser than water due to the higher atomic weight of chlorine versus hydrogen, and aliphatic organochlorides are alkylating agents because chloride is a leaving group.\nAlkanes and aryl alkanes may be chlorinated under free-radical conditions, with UV light. However, the extent of chlorination is difficult to control: the reaction is not regioselective and often results in a mixture of various isomers with different degrees of chlorination, though this may be permissible if the products are easily separated. Aryl chlorides may be prepared by the Friedel-Crafts halogenation, using chlorine and a Lewis acid catalyst. The haloform reaction, using chlorine and sodium hydroxide, is also able to generate alkyl halides from methyl ketones, and related compounds. Chlorine adds to the multiple bonds on alkenes and alkynes as well, giving di- or tetrachloro compounds. However, due to the expense and reactivity of chlorine, organochlorine compounds are more commonly produced by using hydrogen chloride, or with chlorinating agents such as phosphorus pentachloride (PCl5) or thionyl chloride (SOCl2). The last is very convenient in the laboratory because all side products are gaseous and do not have to be distilled out.\nMany organochlorine compounds have been isolated from natural sources ranging from bacteria to humans. Chlorinated organic compounds are found in nearly every class of biomolecules including alkaloids, terpenes, amino acids, flavonoids, steroids, and fatty acids. Organochlorides, including dioxins, are produced in the high temperature environment of forest fires, and dioxins have been found in the preserved ashes of lightning-ignited fires that predate synthetic dioxins. In addition, a variety of simple chlorinated hydrocarbons including dichloromethane, chloroform, and carbon tetrachloride have been isolated from marine algae. A majority of the chloromethane in the environment is produced naturally by biological decomposition, forest fires, and volcanoes.\nSome types of organochlorides, though not all, have significant toxicity to plants or animals, including humans. Dioxins, produced when organic matter is burned in the presence of chlorine, and some insecticides, such as DDT, are persistent organic pollutants which pose dangers when they are released into the environment. For example, DDT, which was widely used to control insects in the mid 20th century, also accumulates in food chains, and causes reproductive problems (e.g., eggshell thinning) in certain bird species. Due to the ready homolytic fission of the C\u2013Cl bond to create chlorine radicals in the upper atmosphere, chlorofluorocarbons have been phased out due to the harm they do to the ozone layer.\nOccurrence.\nChlorine is too reactive to occur as the free element in nature but is very abundant in the form of its chloride salts. It is the 20th most abundant element in Earth's crust and makes up 126\u00a0parts per million of it, through the large deposits of chloride minerals, especially sodium chloride, that have been evaporated from water bodies. All of these pale in comparison to the reserves of chloride ions in seawater: smaller amounts at higher concentrations occur in some inland seas and underground brine wells, such as the Great Salt Lake in Utah and the Dead Sea in Israel.\nSmall batches of chlorine gas are prepared in the laboratory by combining hydrochloric acid and manganese dioxide, but the need rarely arises due to its ready availability. In industry, elemental chlorine is usually produced by the electrolysis of sodium chloride dissolved in water. This method, the chloralkali process industrialized in 1892, now provides most industrial chlorine gas. Along with chlorine, the method yields hydrogen gas and sodium hydroxide, which is the most valuable product. The process proceeds according to the following chemical equation:\nProduction.\nChlorine is primarily produced by the chloralkali process, although non-chloralkali processes exist. Global 2022 production was estimated to be 97 million tonnes. The most visible use of chlorine is in water disinfection. 35-40 % of chlorine produced is used to make poly(vinyl chloride) through ethylene dichloride and vinyl chloride. The chlorine produced is available in cylinders from sizes ranging from 450\u00a0g to 70\u00a0kg, as well as drums (865\u00a0kg), tank wagons (15\u00a0tonnes on roads; 27\u201390\u00a0tonnes by rail), and barges (600\u20131200\u00a0tonnes).\nDue to the difficulty and hazards in transporting elemental chlorine, production is typically located near where it is consumed. As examples, vinyl chloride producers such as Westlake Chemical and Formosa Plastics have integrated chloralkali assets.\nChloralkali processes.\nThe electrolysis of chloride solutions all proceed according to the following equations:\nIn the conventional case where sodium chloride is electrolyzed, sodium hydroxide and chlorine are coproducts.\nIndustrially, there are three chloralkali processes:\nThe Castner\u2013Kellner process was the first method used at the end of the nineteenth century to produce chlorine on an industrial scale. Mercury (that is toxic) was used as an electrode to amalgamate the sodium product, preventing undesirable side reactions.\nIn diaphragm cell electrolysis, an asbestos (or polymer-fiber) diaphragm separates a cathode and an anode, preventing the chlorine forming at the anode from re-mixing with the sodium hydroxide and the hydrogen formed at the cathode. The salt solution (brine) is continuously fed to the anode compartment and flows through the diaphragm to the cathode compartment, where the caustic alkali is produced and the brine is partially depleted. Diaphragm methods produce dilute and slightly impure alkali, but they are not burdened with the problem of mercury disposal and they are more energy efficient.\nMembrane cell electrolysis employs permeable membrane as an ion exchanger. Saturated sodium (or potassium) chloride solution is passed through the anode compartment, leaving at a lower concentration. This method also produces very pure sodium (or potassium) hydroxide but has the disadvantage of requiring very pure brine at high concentrations.\nHowever, due to the lower energy requirements of the membrane process, new chlor-alkali installations are now almost exclusively employing the membrane process. Next to this, the use of large volumes of mercury is considered undesirable.\nAlso, older plants are converted into the membrane process.\nNon-chloralkali processes.\nIn the Deacon process, hydrogen chloride recovered from the production of organochlorine compounds is recovered as chlorine. The process relies on oxidation using oxygen:\nThe reaction requires a catalyst. As introduced by Deacon, early catalysts were based on copper. Commercial processes, such as the Mitsui MT-Chlorine Process, have switched to chromium and ruthenium-based catalysts.\nApplications.\nSodium chloride is the most common chlorine compound, and is the main source of chlorine for the demand by the chemical industry. About 15000 chlorine-containing compounds are commercially traded, including such diverse compounds as chlorinated methane, ethanes, vinyl chloride, polyvinyl chloride (PVC), aluminium trichloride for catalysis, the chlorides of magnesium, titanium, zirconium, and hafnium which are the precursors for producing the pure form of those elements.\nQuantitatively, of all elemental chlorine produced, about 63% is used in the manufacture of organic compounds, and 18% in the manufacture of inorganic chlorine compounds. About 15,000 chlorine compounds are used commercially. The remaining 19% of chlorine produced is used for bleaches and disinfection products. The most significant of organic compounds in terms of production volume are 1,2-dichloroethane and vinyl chloride, intermediates in the production of PVC. Other particularly important organochlorines are methyl chloride, methylene chloride, chloroform, vinylidene chloride, trichloroethylene, perchloroethylene, allyl chloride, epichlorohydrin, chlorobenzene, dichlorobenzenes, and trichlorobenzenes. The major inorganic compounds include HCl, Cl2O, HOCl, NaClO3, AlCl3, SiCl4, SnCl4, PCl3, PCl5, POCl3, AsCl3, SbCl3, SbCl5, BiCl3, and ZnCl2.\nSanitation, disinfection, and antisepsis.\nCombating putrefaction.\nIn France (as elsewhere), animal intestines were processed to make musical instrument strings, Goldbeater's skin and other products. This was done in \"gut factories\" (\"boyauderies\"), and it was an odiferous and unhealthy process. In or about 1820, the Soci\u00e9t\u00e9 d'encouragement pour l'industrie nationale offered a prize for the discovery of a method, chemical or mechanical, for separating the peritoneal membrane of animal intestines without putrefaction. The prize was won by Antoine-Germain Labarraque, a 44-year-old French chemist and pharmacist who had discovered that Berthollet's chlorinated bleaching solutions (\"Eau de Javel\") not only destroyed the smell of putrefaction of animal tissue decomposition, but also actually retarded the decomposition.\nLabarraque's research resulted in the use of chlorides and hypochlorites of lime (calcium hypochlorite) and of sodium (sodium hypochlorite) in the \"boyauderies.\" The same chemicals were found to be useful in the routine disinfection and deodorization of latrines, sewers, markets, abattoirs, anatomical theatres, and morgues. They were successful in hospitals, lazarets, prisons, infirmaries (both on land and at sea), magnaneries, stables, cattle-sheds, etc.; and they were beneficial during exhumations, embalming, outbreaks of epidemic disease, fever, and blackleg in cattle.\nDisinfection.\nLabarraque's chlorinated lime and soda solutions have been advocated since 1828 to prevent infection (called \"contagious infection\", presumed to be transmitted by \"miasmas\"), and to treat putrefaction of existing wounds, including septic wounds. In his 1828 work, Labarraque recommended that doctors breathe chlorine, wash their hands in chlorinated lime, and even sprinkle chlorinated lime about the patients' beds in cases of \"contagious infection\". In 1828, the contagion of infections was well known, even though the agency of the microbe was not discovered until more than half a century later.\nDuring the Paris cholera outbreak of 1832, large quantities of so-called \"chloride of lime\" were used to disinfect the capital. This was not simply modern calcium chloride, but chlorine gas dissolved in lime-water (dilute calcium hydroxide) to form calcium hypochlorite (chlorinated lime). Labarraque's discovery helped to remove the terrible stench of decay from hospitals and dissecting rooms, and by doing so, effectively deodorised the Latin Quarter of Paris. These \"putrid miasmas\" were thought by many to cause the spread of \"contagion\" and \"infection\" \u2013 both words used before the germ theory of infection. Chloride of lime was used for destroying odors and \"putrid matter\". One source claims chloride of lime was used by Dr. John Snow to disinfect water from the cholera-contaminated well that was feeding the Broad Street pump in 1854 London, though three other reputable sources that describe that famous cholera epidemic do not mention the incident. One reference makes it clear that chloride of lime was used to disinfect the offal and filth in the streets surrounding the Broad Street pump \u2013 a common practice in mid-nineteenth century England.\nSemmelweis and experiments with antisepsis.\nPerhaps the most famous application of Labarraque's chlorine and chemical base solutions was in 1847, when Ignaz Semmelweis used chlorine-water (chlorine dissolved in pure water, which was cheaper than chlorinated lime solutions) to disinfect the hands of Austrian doctors, which Semmelweis noticed still carried the stench of decomposition from the dissection rooms to the patient examination rooms. Long before the germ theory of disease, Semmelweis theorized that \"cadaveric particles\" were transmitting decay from fresh medical cadavers to living patients, and he used the well-known \"Labarraque's solutions\" as the only known method to remove the smell of decay and tissue decomposition (which he found that soap did not). The solutions proved to be far more effective antiseptics than soap (Semmelweis was also aware of their greater efficacy, but not the reason), and this resulted in Semmelweis's celebrated success in stopping the transmission of childbed fever (\"puerperal fever\") in the maternity wards of Vienna General Hospital in Austria in 1847.\nMuch later, during World War I in 1916, a standardized and diluted modification of Labarraque's solution containing hypochlorite (0.5%) and boric acid as an acidic stabilizer was developed by Henry Drysdale Dakin (who gave full credit to Labarraque's prior work in this area). Called Dakin's solution, the method of wound irrigation with chlorinated solutions allowed antiseptic treatment of a wide variety of open wounds, long before the modern antibiotic era. A modified version of this solution continues to be employed in wound irrigation in modern times, where it remains effective against bacteria that are resistant to multiple antibiotics (see Century Pharmaceuticals).\nPublic sanitation.\nThe first continuous application of chlorination to drinking U.S. water was installed in Jersey City, New Jersey, in 1908. By 1918, the US Department of Treasury called for all drinking water to be disinfected with chlorine. Chlorine is presently an important chemical for water purification (such as in water treatment plants), in disinfectants, and in bleach. Even small water supplies are now routinely chlorinated.\nChlorine is usually used (in the form of hypochlorous acid) to kill bacteria and other microbes in drinking water supplies and public swimming pools. In most private swimming pools, chlorine itself is not used, but rather sodium hypochlorite, formed from chlorine and sodium hydroxide, or solid tablets of chlorinated isocyanurates. The drawback of using chlorine in swimming pools is that the chlorine reacts with the amino acids in proteins in human hair and skin. Contrary to popular belief, the distinctive \"chlorine aroma\" associated with swimming pools is not the result of elemental chlorine itself, but of chloramine, a chemical compound produced by the reaction of free dissolved chlorine with amines in organic substances including those in urine and sweat. As a disinfectant in water, chlorine is more than three times as effective against \"Escherichia coli\" as bromine, and more than six times as effective as iodine. Increasingly, monochloramine itself is being directly added to drinking water for purposes of disinfection, a process known as chloramination.\nIt is often impractical to store and use poisonous chlorine gas for water treatment, so alternative methods of adding chlorine are used. These include hypochlorite solutions, which gradually release chlorine into the water, and compounds like sodium dichloro-s-triazinetrione (dihydrate or anhydrous), sometimes referred to as \"dichlor\", and trichloro-s-triazinetrione, sometimes referred to as \"trichlor\". These compounds are stable while solid and may be used in powdered, granular, or tablet form. When added in small amounts to pool water or industrial water systems, the chlorine atoms hydrolyze from the rest of the molecule, forming hypochlorous acid (HOCl), which acts as a general biocide, killing germs, microorganisms, algae, and so on.\nUse as a weapon.\nWorld War I.\nChlorine gas, also known as bertholite, was first used as a weapon in World War I by Germany on April 22, 1915, in the Second Battle of Ypres. As described by the soldiers, it had the distinctive smell of a mixture of pepper and pineapple. It also tasted metallic and stung the back of the throat and chest. Chlorine reacts with water in the mucosa of the lungs to form hydrochloric acid, destructive to living tissue and potentially lethal. Human respiratory systems can be protected from chlorine gas by gas masks with activated charcoal or other filters, which makes chlorine gas much less lethal than other chemical weapons. It was pioneered by a German scientist later to be a Nobel laureate, Fritz Haber of the Kaiser Wilhelm Institute in Berlin, in collaboration with the German chemical conglomerate IG Farben, which developed methods for discharging chlorine gas against an entrenched enemy. After its first use, both sides in the conflict used chlorine as a chemical weapon, but it was soon replaced by the more deadly phosgene and mustard gas.\nMiddle east.\nChlorine gas was also used during the Iraq War in Anbar Province in 2007, with insurgents packing truck bombs with mortar shells and chlorine tanks. The attacks killed two people from the explosives and sickened more than 350. Most of the deaths were caused by the force of the explosions rather than the effects of chlorine since the toxic gas is readily dispersed and diluted in the atmosphere by the blast. In some bombings, over a hundred civilians were hospitalized due to breathing difficulties. The Iraqi authorities tightened security for elemental chlorine, which is essential for providing safe drinking water to the population.\nOn 23 October 2014, it was reported that the Islamic State of Iraq and the Levant had used chlorine gas in the town of Duluiyah, Iraq. Laboratory analysis of clothing and soil samples confirmed the use of chlorine gas against Kurdish Peshmerga Forces in a vehicle-borne improvised explosive device attack on 23 January 2015 at the Highway 47 Kiske Junction near Mosul.\nAnother country in the middle east, Syria, has used chlorine as a chemical weapon delivered from barrel bombs and rockets. In 2016, the OPCW-UN Joint Investigative Mechanism concluded that the Syrian government used chlorine as a chemical weapon in three separate attacks. Later investigations from the OPCW's Investigation and Identification Team concluded that the Syrian Air Force was responsible for chlorine attacks in 2017 and 2018.\nBiological role.\nThe chloride anion is an essential nutrient for metabolism. Chlorine is needed for the production of hydrochloric acid in the stomach and in cellular pump functions. The main dietary source is table salt, or sodium chloride. Overly low or high concentrations of chloride in the blood are examples of electrolyte disturbances. Hypochloremia (having too little chloride) rarely occurs in the absence of other abnormalities. It is sometimes associated with hypoventilation. It can be associated with chronic respiratory acidosis. Hyperchloremia (having too much chloride) usually does not produce symptoms. When symptoms do occur, they tend to resemble those of hypernatremia (having too much sodium). Reduction in blood chloride leads to cerebral dehydration; symptoms are most often caused by rapid rehydration which results in cerebral edema. Hyperchloremia can affect oxygen transport.\nHazards.\nChlorine is a toxic gas that attacks the respiratory system, eyes, and skin. Because it is denser than air, it tends to accumulate at the bottom of poorly ventilated spaces. Chlorine gas is a strong oxidizer, which may react with flammable materials.\nChlorine is detectable with measuring devices in concentrations as low as 0.2 parts per million (ppm), and by smell at 3\u00a0ppm. Coughing and vomiting may occur at 30\u00a0ppm and lung damage at 60\u00a0ppm. About 1000\u00a0ppm can be fatal after a few deep breaths of the gas. The IDLH (immediately dangerous to life and health) concentration is 10\u00a0ppm. Breathing lower concentrations can aggravate the respiratory system and exposure to the gas can irritate the eyes. When chlorine is inhaled at concentrations greater than 30\u00a0ppm, it reacts with water within the lungs, producing hydrochloric acid (HCl) and hypochlorous acid (HOCl).\nWhen used at specified levels for water disinfection, the reaction of chlorine with water is not a major concern for human health. Other materials present in the water may generate disinfection by-products that are associated with negative effects on human health.\nIn the United States, the Occupational Safety and Health Administration (OSHA) has set the permissible exposure limit for elemental chlorine at 1\u00a0ppm, or 3\u00a0mg/m3. The National Institute for Occupational Safety and Health has designated a recommended exposure limit of 0.5\u00a0ppm over 15 minutes.\nIn the home, accidents occur when hypochlorite bleach solutions come into contact with certain acidic drain-cleaners to produce chlorine gas. Hypochlorite bleach (a popular laundry additive) combined with ammonia (another popular laundry additive) produces chloramines, another toxic group of chemicals.\nChlorine-induced cracking in structural materials.\nChlorine is widely used for purifying water, especially potable water supplies and water used in swimming pools. Several catastrophic collapses of swimming pool ceilings have occurred from chlorine-induced stress corrosion cracking of stainless steel suspension rods. Some polymers are also sensitive to attack, including acetal resin and polybutene. Both materials were used in hot and cold water domestic plumbing, and stress corrosion cracking caused widespread failures in the US in the 1980s and 1990s.\nChlorine-iron fire.\nThe element iron can combine with chlorine at high temperatures in a strong exothermic reaction, creating a \"chlorine-iron fire\". Chlorine-iron fires are a risk in chemical process plants, where much of the pipework that carries chlorine gas is made of steel."}
{"id": "5668", "revid": "41591971", "url": "https://en.wikipedia.org/wiki?curid=5668", "title": "Calcium", "text": "Calcium is a chemical element; it has symbol Ca and atomic number 20. As an alkaline earth metal, calcium is a reactive metal that forms a dark oxide-nitride layer when exposed to air. Its physical and chemical properties are most similar to its heavier homologues strontium and barium. It is the fifth most abundant element in Earth's crust, and the third most abundant metal, after iron and aluminium. The most common calcium compound on Earth is calcium carbonate, found in limestone and the fossilized remnants of early sea life; gypsum, anhydrite, fluorite, and apatite are also sources of calcium. The name derives from Latin \"calx\" \"lime\", which was obtained from heating limestone.\nSome calcium compounds were known to the ancients, though their chemistry was unknown until the seventeenth century. Pure calcium was isolated in 1808 via electrolysis of its oxide by Humphry Davy, who named the element. Calcium compounds are widely used in many industries: in foods and pharmaceuticals for calcium supplementation, in the paper industry as bleaches, as components in cement and electrical insulators, and in the manufacture of soaps. On the other hand, the metal in pure form has few applications due to its high reactivity; still, in small quantities it is often used as an alloying component in steelmaking, and sometimes, as a calcium\u2013lead alloy, in making automotive batteries.\nCalcium is the most abundant metal and the fifth-most abundant element in the human body. As electrolytes, calcium ions (Ca2+) play a vital role in the physiological and biochemical processes of organisms and cells: in signal transduction pathways where they act as a second messenger; in neurotransmitter release from neurons; in contraction of all muscle cell types; as cofactors in many enzymes; and in fertilization. Calcium ions outside cells are important for maintaining the potential difference across excitable cell membranes, protein synthesis, and bone formation.\nCharacteristics.\nClassification.\nCalcium is a very ductile silvery metal (sometimes described as pale yellow) whose properties are very similar to the heavier elements in its group, strontium, barium, and radium. A calcium atom has twenty electrons, with electron configuration [Ar]4s. Like the other elements placed in group 2 of the periodic table, calcium has two valence electrons in the outermost s-orbital, which are very easily lost in chemical reactions to form a dipositive ion with the stable electron configuration of a noble gas, in this case argon.\nHence, calcium is almost always divalent in its compounds, which are usually ionic. Hypothetical univalent salts of calcium would be stable with respect to their elements, but not to disproportionation to the divalent salts and calcium metal, because the enthalpy of formation of MX is much higher than those of the hypothetical MX. This occurs because of the much greater lattice energy afforded by the more highly charged Ca cation compared to the hypothetical Ca cation.\nCalcium, strontium, barium, and radium are always considered to be alkaline earth metals; the lighter beryllium and magnesium, also in group 2 of the periodic table, are often included as well. Nevertheless, beryllium and magnesium differ significantly from the other members of the group in their physical and chemical behaviour: they behave more like aluminium and zinc respectively and have some of the weaker metallic character of the post-transition metals, which is why the traditional definition of the term \"alkaline earth metal\" excludes them.\nPhysical properties.\nCalcium metal melts at 842\u00a0\u00b0C and boils at 1494\u00a0\u00b0C; these values are higher than those for magnesium and strontium, the neighbouring group 2 metals. It crystallises in the face-centered cubic arrangement like strontium and barium; above , it changes to a body-centered cubic. Its density of 1.526\u00a0g/cm3 (at 20\u00a0\u00b0C) is the lowest in its group.\nCalcium is harder than lead but can be cut with a knife with effort. While calcium is a poorer conductor of electricity than copper or aluminium by volume, it is a better conductor by mass than both due to its very low density. While calcium is infeasible as a conductor for most terrestrial applications as it reacts quickly with atmospheric oxygen, its use as such in space has been considered.\nChemical properties.\nThe chemistry of calcium is that of a typical heavy alkaline earth metal. For example, calcium spontaneously reacts with water more quickly than magnesium and less quickly than strontium to produce calcium hydroxide and hydrogen gas. It also reacts with the oxygen and nitrogen in air to form a mixture of calcium oxide and calcium nitride. When finely divided, it spontaneously burns in air to produce the nitride. Bulk calcium is less reactive: it quickly forms a hydration coating in moist air, but below 30% relative humidity it may be stored indefinitely at room temperature.\nBesides the simple oxide CaO, calcium peroxide, CaO, can be made by direct oxidation of calcium metal under a high pressure of oxygen, and there is some evidence for a yellow superoxide Ca(O).Calcium hydroxide, Ca(OH), is a strong base, though not as strong as the hydroxides of strontium, barium or the alkali metals. All four dihalides of calcium are known. Calcium carbonate (CaCO) and calcium sulfate (CaSO) are particularly abundant minerals. Like strontium and barium, as well as the alkali metals and the divalent lanthanides europium and ytterbium, calcium metal dissolves directly in liquid ammonia to give a dark blue solution.\nDue to the large size of the calcium ion (Ca), high coordination numbers are common, up to 24 in some intermetallic compounds such as CaZn. Calcium is readily complexed by oxygen chelates such as EDTA and polyphosphates, which are useful in analytic chemistry and removing calcium ions from hard water. In the absence of steric hindrance, smaller group 2 cations tend to form stronger complexes, but when large polydentate macrocycles are involved the trend is reversed.\nThough calcium is in the same group as magnesium and organomagnesium compounds are very widely used throughout chemistry, organocalcium compounds are not similarly widespread because they are more difficult to make and more reactive, though they have recently been investigated as possible catalysts. Organocalcium compounds tend to be more similar to organoytterbium compounds due to the similar ionic radii of Yb (102\u00a0pm) and Ca (100\u00a0pm).\nMost of these compounds can only be prepared at low temperatures; bulky ligands tend to favour stability. For example, calcium dicyclopentadienyl, Ca(CH), must be made by directly reacting calcium metal with mercurocene or cyclopentadiene itself; replacing the CH ligand with the bulkier C(CH) ligand on the other hand increases the compound's solubility, volatility, and kinetic stability.\nIsotopes.\nNatural calcium is a mixture of five stable isotopes (Ca, Ca, Ca, Ca, and Ca) and one isotope with a half-life so long that it is for all practical purposes stable (Ca, with a half-life of about 4.3\u00a0\u00d7\u00a010\u00a0years). Calcium is the first (lightest) element to have six naturally occurring isotopes.\nBy far the most common isotope of calcium in nature is Ca, which makes up 96.941% of all natural calcium. It is produced in the silicon-burning process from fusion of alpha particles and is the heaviest stable nuclide with equal proton and neutron numbers; its occurrence is also supplemented slowly by the decay of primordial K. Adding another alpha particle leads to unstable Ti, which decays via two successive electron captures to stable Ca; this makes up 2.806% of all natural calcium and is the second-most common isotope.\nThe other four natural isotopes, Ca, Ca, Ca, and Ca, are significantly rarer, each comprising less than 1% of all natural calcium. The four lighter isotopes are mainly products of the oxygen-burning and silicon-burning processes, leaving the two heavier ones to be produced via neutron capture processes. Ca is mostly produced in a \"hot\" s-process, as its formation requires a rather high neutron flux to allow short-lived Ca to capture a neutron. Ca is produced by electron capture in the r-process in type Ia supernovae, where high neutron excess and low enough entropy ensures its survival.\nCa and Ca are the first \"classically stable\" nuclides with a 6-neutron or 8-neutron excess respectively. Although extremely neutron-rich for such a light element, Ca is very stable because it is a doubly magic nucleus, having 20 protons and 28 neutrons arranged in closed shells. Its beta decay to Sc is very hindered because of the gross mismatch of nuclear spin: Ca has zero nuclear spin, being even\u2013even, while Sc has spin 6+, so the decay is forbidden by the conservation of angular momentum. While two excited states of Sc are available for decay as well, they are also forbidden due to their high spins. As a result, when Ca does decay, it does so by double beta decay to Ti instead, being the lightest nuclide known to undergo double beta decay.\nCa can also theoretically undergo double beta decay to Ti, but this has never been observed. The most common isotope Ca is also doubly magic and could undergo double electron capture to Ar, but this has likewise never been observed. Calcium is the only element with two primordial doubly magic isotopes. The experimental lower limits for the half-lives of Ca and Ca are 5.9\u00a0\u00d7\u00a010 years and 2.8\u00a0\u00d7\u00a010 years respectively.\nApart from the practically stable Ca, the longest lived radioisotope of calcium is Ca. It decays by electron capture to stable K with a half-life of about 10 years. Its existence in the early Solar System as an extinct radionuclide has been inferred from excesses of K: traces of Ca also still exist today, as it is a cosmogenic nuclide, continuously produced through neutron activation of natural Ca.\nMany other calcium radioisotopes are known, ranging from Ca to Ca. They are all much shorter-lived than Ca, the most stable being Ca (half-life 163 days) and Ca (half-life 4.54 days). Isotopes lighter than Ca usually undergo beta plus decay to isotopes of potassium, and those heavier than Ca usually undergo beta minus decay to isotopes of scandium, though near the nuclear drip lines, proton emission and neutron emission begin to be significant decay modes as well.\nLike other elements, a variety of processes alter the relative abundance of calcium isotopes. The best studied of these processes is the mass-dependent fractionation of calcium isotopes that accompanies the precipitation of calcium minerals such as calcite, aragonite and apatite from solution. Lighter isotopes are preferentially incorporated into these minerals, leaving the surrounding solution enriched in heavier isotopes at a magnitude of roughly 0.025% per atomic mass unit (amu) at room temperature. Mass-dependent differences in calcium isotope composition are conventionally expressed by the ratio of two isotopes (usually Ca/Ca) in a sample compared to the same ratio in a standard reference material. Ca/Ca varies by about 1\u20132\u2030 among organisms on Earth.\nHistory.\nCalcium compounds were known for millennia, though their chemical makeup was not understood until the 17th century. Lime as a building material and as plaster for statues was used as far back as around 7000\u00a0BC. The first dated lime kiln dates back to 2500\u00a0BC and was found in Khafajah, Mesopotamia.\nAbout the same time, dehydrated gypsum (CaSO\u00b72HO) was being used in the Great Pyramid of Giza. This material would later be used for the plaster in the tomb of Tutankhamun. The ancient Romans instead used lime mortars made by heating limestone (CaCO). The name \"calcium\" itself derives from the Latin word \"calx\" \"lime\".\nVitruvius noted that the lime that resulted was lighter than the original limestone, attributing this to the boiling of the water. In 1755, Joseph Black proved that this was due to the loss of carbon dioxide, which as a gas had not been recognized by the ancient Romans.\nIn 1789, Antoine Lavoisier suspected that lime might be an oxide of a fundamental chemical element. In his table of the elements, Lavoisier listed five \"salifiable earths\" (i.e., ores that could be made to react with acids to produce salts (\"salis\" = salt, in Latin): \"chaux\" (calcium oxide), \"magn\u00e9sie\" (magnesia, magnesium oxide), \"baryte\" (barium sulfate), \"alumine\" (alumina, aluminium oxide), and \"silice\" (silica, silicon dioxide)). About these \"elements\", Lavoisier reasoned: \nCalcium, along with its congeners magnesium, strontium, and barium, was first isolated by Humphry Davy in 1808. Following the work of J\u00f6ns Jakob Berzelius and Magnus Martin af Pontin on electrolysis, Davy isolated calcium and magnesium by putting a mixture of the respective metal oxides with mercury(II) oxide on a platinum plate which was used as the anode, the cathode being a platinum wire partially submerged into mercury. Electrolysis then gave calcium\u2013mercury and magnesium\u2013mercury amalgams, and distilling off the mercury gave the metal. However, pure calcium cannot be prepared in bulk by this method and a workable commercial process for its production was not found until over a century later.\nOccurrence and production.\nAt 3%, calcium is the fifth most abundant element in the Earth's crust, and the third most abundant metal behind aluminium and iron. It is also the fourth most abundant element in the lunar highlands. Sedimentary calcium carbonate deposits pervade the Earth's surface as fossilized remains of past marine life; they occur in two forms, the rhombohedral calcite (more common) and the orthorhombic aragonite (forming in more temperate seas). Minerals of the first type include limestone, dolomite, marble, chalk, and iceland spar; aragonite beds make up the Bahamas, the Florida Keys, and the Red Sea basins. Corals, sea shells, and pearls are mostly made up of calcium carbonate. Among the other important minerals of calcium are gypsum (CaSO4\u00b72H2O), anhydrite (CaSO4), fluorite (CaF2), and apatite ([Ca5(PO4)3X], X = OH, Cl, or F).gre\nThe major producers of calcium are China (about 10000 to 12000 tonnes per year), Russia (about 6000 to 8000 tonnes per year), and the United States (about 2000 to 4000 tonnes per year). Canada and France are also among the minor producers. In 2005, about 24000 tonnes of calcium were produced; about half of the world's extracted calcium is used by the United States, with about 80% of the output used each year.\nIn Russia and China, Davy's method of electrolysis is still used, but is instead applied to molten calcium chloride. Since calcium is less reactive than strontium or barium, the oxide\u2013nitride coating that results in air is stable and lathe machining and other standard metallurgical techniques are suitable for calcium. In the United States and Canada, calcium is instead produced by reducing lime with aluminium at high temperatures.\nGeochemical cycling.\nCalcium cycling provides a link between tectonics, climate, and the carbon cycle. In the simplest terms, mountain-building exposes calcium-bearing rocks such as basalt and granodiorite to chemical weathering and releases Ca2+ into surface water. These ions are transported to the ocean where they react with dissolved CO2 to form limestone (), which in turn settles to the sea floor where it is incorporated into new rocks. Dissolved CO2, along with carbonate and bicarbonate ions, are termed \"dissolved inorganic carbon\" (DIC).\nThe actual reaction is more complicated and involves the bicarbonate ion (HCO) that forms when CO2 reacts with water at seawater pH:\nAt seawater pH, most of the dissolved CO2 is immediately converted back into . The reaction results in a net transport of one molecule of CO2 from the ocean/atmosphere into the lithosphere. The result is that each Ca2+ ion released by chemical weathering ultimately removes one CO2 molecule from the surficial system (atmosphere, ocean, soils and living organisms), storing it in carbonate rocks where it is likely to stay for hundreds of millions of years. The weathering of calcium from rocks thus scrubs CO2 from the ocean and atmosphere, exerting a strong long-term effect on climate.\nApplications.\nThe largest use of metallic calcium is in steelmaking, due to its strong chemical affinity for oxygen and sulfur. Its oxides and sulfides, once formed, give liquid lime aluminate and sulfide inclusions in steel which float out; on treatment, these inclusions disperse throughout the steel and become small and spherical, improving castability, cleanliness and general mechanical properties. Calcium is also used in maintenance-free automotive batteries, in which the use of 0.1% calcium\u2013lead alloys instead of the usual antimony\u2013lead alloys leads to lower water loss and lower self-discharging.\nDue to the risk of expansion and cracking, aluminium is sometimes also incorporated into these alloys. These lead\u2013calcium alloys are also used in casting, replacing lead\u2013antimony alloys. Calcium is also used to strengthen aluminium alloys used for bearings, for the control of graphitic carbon in cast iron, and to remove bismuth impurities from lead. Calcium metal is found in some drain cleaners, where it functions to generate heat and calcium hydroxide that saponifies the fats and liquefies the proteins (for example, those in hair) that block drains.\nBesides metallurgy, the reactivity of calcium is exploited to remove nitrogen from high-purity argon gas and as a getter for oxygen and nitrogen. It is also used as a reducing agent in the production of chromium, zirconium, thorium, vanadium and uranium. It can also be used to store hydrogen gas, as it reacts with hydrogen to form solid calcium hydride, from which the hydrogen can easily be re-extracted.\nCalcium isotope fractionation during mineral formation has led to several applications of calcium isotopes. In particular, the 1997 observation by Skulan and DePaolo that calcium minerals are isotopically lighter than the solutions from which the minerals precipitate is the basis of analogous applications in medicine and in paleoceanography. In animals with skeletons mineralized with calcium, the calcium isotopic composition of soft tissues reflects the relative rate of formation and dissolution of skeletal mineral.\nIn humans, changes in the calcium isotopic composition of urine have been shown to be related to changes in bone mineral balance. When the rate of bone formation exceeds the rate of bone resorption, the 44Ca/40Ca ratio in soft tissue rises and vice versa. Because of this relationship, calcium isotopic measurements of urine or blood may be useful in the early detection of metabolic bone diseases like osteoporosis.\nA similar system exists in seawater, where 44Ca/40Ca tends to rise when the rate of removal of Ca2+ by mineral precipitation exceeds the input of new calcium into the ocean. In 1997, Skulan and DePaolo presented the first evidence of change in seawater 44Ca/40Ca over geologic time, along with a theoretical explanation of these changes. More recent papers have confirmed this observation, demonstrating that seawater Ca2+ concentration is not constant, and that the ocean is never in a \"steady state\" with respect to calcium input and output. This has important climatological implications, as the marine calcium cycle is closely tied to the carbon cycle.\nMany calcium compounds are used in food, as pharmaceuticals, and in medicine, among others. For example, calcium and phosphorus are supplemented in foods through the addition of calcium lactate, calcium diphosphate, and tricalcium phosphate. The last is also used as a polishing agent in toothpaste and in antacids. Calcium lactobionate is a white powder that is used as a suspending agent for pharmaceuticals. In baking, calcium phosphate is used as a leavening agent. Calcium sulfite is used as a bleach in papermaking and as a disinfectant, calcium silicate is used as a reinforcing agent in rubber, and calcium acetate is a component of liming rosin and is used to make metallic soaps and synthetic resins.\nCalcium is on the World Health Organization's List of Essential Medicines.\nFood sources.\nFoods rich in calcium include dairy products such as milk and yogurt, cheese, sardines, salmon, soy products, kale, and fortified breakfast cereals.\nBecause of concerns for long-term adverse side effects, including calcification of arteries and kidney stones, both the U.S. Institute of Medicine (IOM) and the European Food Safety Authority (EFSA) set Tolerable Upper Intake Levels (ULs) for combined dietary and supplemental calcium. From the IOM, people of ages 9\u201318 years are not to exceed 3\u00a0g/day combined intake; for ages 19\u201350, not to exceed 2.5\u00a0g/day; for ages 51 and older, not to exceed 2\u00a0g/day. EFSA set the UL for all adults at 2.5\u00a0g/day, but decided the information for children and adolescents was not sufficient to determine ULs.\nBiological and pathological role.\nFunction.\nCalcium is an essential element needed in large quantities. The Ca2+ ion acts as an electrolyte and is vital to the health of the muscular, circulatory, and digestive systems; is indispensable to the building of bone in the form of hydroxyapatite; and supports synthesis and function of blood cells. For example, it regulates the contraction of muscles, nerve conduction, and the clotting of blood. As a result, intra- and extracellular calcium levels are tightly regulated by the body. Calcium can play this role because the Ca2+ ion forms stable coordination complexes with many organic compounds, especially proteins; it also forms compounds with a wide range of solubilities, enabling the formation of the skeleton.\nBinding.\nCalcium ions may be complexed by proteins through binding the carboxyl groups of glutamic acid or aspartic acid residues; through interacting with phosphorylated serine, tyrosine, or threonine residues; or by being chelated by \u03b3-carboxylated amino acid residues. Trypsin, a digestive enzyme, uses the first method; osteocalcin, a bone matrix protein, uses the third.\nSome other bone matrix proteins such as osteopontin and bone sialoprotein use both the first and the second. Direct activation of enzymes by binding calcium is common; some other enzymes are activated by noncovalent association with direct calcium-binding enzymes. Calcium also binds to the phospholipid layer of the cell membrane, anchoring proteins associated with the cell surface.\nSolubility.\nAs an example of the wide range of solubility of calcium compounds, monocalcium phosphate is very soluble in water, 85% of extracellular calcium is as dicalcium phosphate with a solubility of 2.00\u00a0mM, and the hydroxyapatite of bones in an organic matrix is tricalcium phosphate with a solubility of 1000\u00a0\u03bcM.\nNutrition.\nCalcium is a common constituent of multivitamin dietary supplements, but the composition of calcium complexes in supplements may affect its bioavailability which varies by solubility of the salt involved: calcium citrate, malate, and lactate are highly bioavailable, while the oxalate is less. Other calcium preparations include calcium carbonate, calcium citrate malate, and calcium gluconate. The intestine absorbs about one-third of calcium eaten as the free ion, and plasma calcium level is then regulated by the kidneys.\nHormonal regulation of bone formation and serum levels.\nParathyroid hormone and vitamin D promote the formation of bone by allowing and enhancing the deposition of calcium ions there, allowing rapid bone turnover without affecting bone mass or mineral content. When plasma calcium levels fall, cell surface receptors are activated and the secretion of parathyroid hormone occurs; it then proceeds to stimulate the entry of calcium into the plasma pool by taking it from targeted kidney, gut, and bone cells, with the bone-forming action of parathyroid hormone being antagonized by calcitonin, whose secretion increases with increasing plasma calcium levels.\nAbnormal serum levels.\nExcess intake of calcium may cause hypercalcemia. However, because calcium is absorbed rather inefficiently by the intestines, high serum calcium is more likely caused by excessive secretion of parathyroid hormone (PTH) or possibly by excessive intake of vitamin D, both of which facilitate calcium absorption. All these conditions result in excess calcium salts being deposited in the heart, blood vessels, or kidneys. Symptoms include anorexia, nausea, vomiting, memory loss, confusion, muscle weakness, increased urination, dehydration, and metabolic bone disease.\nChronic hypercalcaemia typically leads to calcification of soft tissue and its serious consequences: for example, calcification can cause loss of elasticity of vascular walls and disruption of laminar blood flow\u2014and thence to plaque rupture and thrombosis. Conversely, inadequate calcium or vitamin D intakes may result in hypocalcemia, often caused also by inadequate secretion of parathyroid hormone or defective PTH receptors in cells. Symptoms include neuromuscular excitability, which potentially causes tetany and disruption of conductivity in cardiac tissue.\nBone disease.\nAs calcium is required for bone development, many bone diseases can be traced to the organic matrix or the hydroxyapatite in molecular structure or organization of bone. Osteoporosis is a reduction in mineral content of bone per unit volume, and can be treated by supplementation of calcium, vitamin D, and bisphosphonates. Inadequate amounts of calcium, vitamin D, or phosphates can lead to softening of bones, called osteomalacia.\nSafety.\nMetallic calcium.\nBecause calcium reacts exothermically with water and acids, calcium metal coming into contact with bodily moisture results in severe corrosive irritation. When swallowed, calcium metal has the same effect on the mouth, oesophagus, and stomach, and can be fatal. However, long-term exposure is not known to have distinct adverse effects."}
{"id": "5669", "revid": "34997143", "url": "https://en.wikipedia.org/wiki?curid=5669", "title": "Chromium", "text": " \nChromium is a chemical element; it has symbol Cr and atomic number 24. It is the first element in group 6. It is a steely-grey, lustrous, hard, and brittle transition metal.\nChromium is valued for its high corrosion resistance and hardness. A major development in steel production was the discovery that steel could be made highly resistant to corrosion and discoloration by adding metallic chromium to form stainless steel. Stainless steel and chrome plating (electroplating with chromium) together comprise 85% of the commercial use. Chromium is also greatly valued as a metal that is able to be highly polished while resisting tarnishing. Polished chromium reflects almost 70% of the visible spectrum, and almost 90% of infrared light. The name of the element is derived from the Greek word \u03c7\u03c1\u1ff6\u03bc\u03b1, \"chr\u014dma\", meaning color, because many chromium compounds are intensely colored.\nIndustrial production of chromium proceeds from chromite ore (mostly FeCr2O4) to produce ferrochromium, an iron-chromium alloy, by means of aluminothermic or silicothermic reactions. Ferrochromium is then used to produce alloys such as stainless steel. Pure chromium metal is produced by a different process: roasting and leaching of chromite to separate it from iron, followed by reduction with carbon and then aluminium.\nTrivalent chromium (Cr(III)) occurs naturally in many foods and is sold as a dietary supplement, although there is insufficient evidence that dietary chromium provides nutritional benefit to people. In 2014, the European Food Safety Authority concluded that research on dietary chromium did not justify it to be recognized as an essential nutrient.\nWhile chromium metal and Cr(III) ions are considered non-toxic, chromate and its derivatives, often called \"hexavalent chromium\", is toxic and carcinogenic. According to the European Chemicals Agency (ECHA), chromium trioxide that is used in industrial electroplating processes is a \"substance of very high concern\" (SVHC).\nPhysical properties.\nAtomic.\nGaseous chromium has a ground-state electron configuration of [Ar] 3d5 4s1. It is the first element in the periodic table whose configuration violates the Aufbau principle. Exceptions to the principle also occur later in the periodic table for elements such as copper, niobium and molybdenum.\nChromium is the first element in the 3d series where the 3d electrons start to sink into the core; they thus contribute less to metallic bonding, and hence the melting and boiling points and the enthalpy of atomisation of chromium are lower than those of the preceding element vanadium. Chromium(VI) is a strong oxidising agent in contrast to the molybdenum(VI) and tungsten(VI) oxides.\nBulk.\nChromium is the third hardest element after carbon (diamond) and boron. Its Mohs hardness is 8.5, which means that it can scratch samples of quartz and topaz, but can be scratched by corundum. Chromium is highly resistant to tarnishing, which makes it useful as a metal that preserves its outermost layer from corroding, unlike other metals such as copper, magnesium, and aluminium.\nChromium has a melting point of 1907\u00a0\u00b0C (3465\u00a0\u00b0F), which is relatively low compared to the majority of transition metals. However, it still has the second highest melting point out of all the period 4 elements, being topped by vanadium by 3\u00a0\u00b0C (5\u00a0\u00b0F) at 1910\u00a0\u00b0C (3470\u00a0\u00b0F). The boiling point of 2671\u00a0\u00b0C (4840\u00a0\u00b0F), however, is comparatively lower, having the fourth lowest boiling point out of the Period 4 transition metals alone behind copper, manganese and zinc. The electrical resistivity of chromium at 20\u00a0\u00b0C is 125 nanoohm-meters.\nChromium has a high specular reflection in comparison to other transition metals. In infrared, at 425\u00a0\u03bcm, chromium has a maximum reflectance of about 72%, reducing to a minimum of 62% at 750\u00a0\u03bcm before rising again to 90% at 4000\u00a0\u03bcm. When chromium is used in stainless steel alloys and polished, the specular reflection decreases with the inclusion of additional metals, yet is still high in comparison with other alloys. Between 40% and 60% of the visible spectrum is reflected from polished stainless steel. The explanation on why chromium displays such a high turnout of reflected photon waves in general, especially the 90% in infrared, can be attributed to chromium's magnetic properties. Chromium has unique magnetic properties; it is the only elemental solid that shows antiferromagnetic ordering at room temperature and below. Above 38\u00a0\u00b0C, its magnetic ordering becomes paramagnetic. The antiferromagnetic properties, which cause the chromium atoms to temporarily ionize and bond with themselves, are present because the body-centric cubic's magnetic properties are disproportionate to the lattice periodicity. This is due to the magnetic moments at the cube's corners and the unequal, but antiparallel, cube centers. From here, the frequency-dependent relative permittivity of chromium, deriving from Maxwell's equations and chromium's antiferromagnetism, leaves chromium with a high infrared and visible light reflectance.\nPassivation.\nChromium metal in air is passivated: it forms a thin, protective surface layer of chromium oxide with the corundum structure. Passivation can be enhanced by short contact with oxidizing acids like nitric acid. Passivated chromium is stable against acids. Passivation can be removed with a strong reducing agent that destroys the protective oxide layer on the metal. Chromium metal treated in this way readily dissolves in weak acids.\nThe surface chromia scale, is adherent to the metal. In contrast, iron forms a more porous oxide which is weak and flakes easily and exposes fresh metal to the air, causing continued rusting. At room temperature, the chromia scale is a few atomic layers thick, growing in thickness by outward diffusion of metal ions across the scale. Above 950 \u00b0C volatile chromium trioxide forms from the chromia scale, limiting the scale thickness and oxidation protection.\nChromium, unlike iron and nickel, does not suffer from hydrogen embrittlement. However, it does suffer from nitrogen embrittlement, reacting with nitrogen from air and forming brittle nitrides at the high temperatures necessary to work the metal parts.\nIsotopes.\nNaturally occurring chromium is composed of four stable isotopes; 50Cr, 52Cr, 53Cr and 54Cr, with 52Cr being the most abundant (83.789% natural abundance). 50Cr is observationally stable, as it is theoretically capable of decaying to 50Ti via double electron capture with a half-life of no less than 1.3 years. Twenty-five radioisotopes have been characterized, ranging from 42Cr to 70Cr; the most stable radioisotope is 51Cr with a half-life of 27.7 days. All of the remaining radioactive isotopes have half-lives that are less than 24 hours and the majority less than 1 minute. Chromium also has two metastable nuclear isomers. The primary decay mode before the most abundant stable isotope, 52Cr, is electron capture and the primary mode after is beta decay.\n53Cr is the radiogenic decay product of 53Mn (half-life 3.74\u00a0million years). Chromium isotopes are typically collocated (and compounded) with manganese isotopes. This circumstance is useful in isotope geology. Manganese-chromium isotope ratios reinforce the evidence from 26Al and 107Pd concerning the early history of the Solar System. Variations in 53Cr/52Cr and Mn/Cr ratios from several meteorites indicate an initial 53Mn/55Mn ratio that suggests Mn-Cr isotopic composition must result from in-situ decay of 53Mn in differentiated planetary bodies. Hence 53Cr provides additional evidence for nucleosynthetic processes immediately before coalescence of the Solar System. 53Cr has been posited as a proxy for atmospheric oxygen concentration.\nChemistry and compounds.\nChromium is a member of group 6, of the transition metals. The +3 and +6 states occur most commonly within chromium compounds, followed by +2; charges of +1, +4 and +5 for chromium are rare, but do nevertheless occasionally exist.\nCommon oxidation states.\nChromium(0).\nMany Cr(0) complexes are known. Bis(benzene)chromium and chromium hexacarbonyl are highlights in organochromium chemistry.\nChromium(II).\nChromium(II) compounds are uncommon, in part because they readily oxidize to chromium(III) derivatives in air. Water-stable chromium(II) chloride that can be made by reducing chromium(III) chloride with zinc. The resulting bright blue solution created from dissolving chromium(II) chloride is stable at neutral pH. Some other notable chromium(II) compounds include chromium(II) oxide , and chromium(II) sulfate . Many chromium(II) carboxylates are known. The red chromium(II) acetate (Cr2(O2CCH3)4) is somewhat famous. It features a Cr-Cr quadruple bond.\nChromium(III).\nA large number of chromium(III) compounds are known, such as chromium(III) nitrate, chromium(III) acetate, and chromium(III) oxide. Chromium(III) can be obtained by dissolving elemental chromium in acids like hydrochloric acid or sulfuric acid, but it can also be formed through the reduction of chromium(VI) by cytochrome c7. The ion has a similar radius (63\u00a0pm) to (radius 50\u00a0pm), and they can replace each other in some compounds, such as in chrome alum and alum.\nChromium(III) tends to form octahedral complexes. Commercially available chromium(III) chloride hydrate is the dark green complex [CrCl2(H2O)4]Cl. Closely related compounds are the pale green [CrCl(H2O)5]Cl2 and violet [Cr(H2O)6]Cl3. If anhydrous violet chromium(III) chloride is dissolved in water, the violet solution turns green after some time as the chloride in the inner coordination sphere is replaced by water. This kind of reaction is also observed with solutions of chrome alum and other water-soluble chromium(III) salts. A tetrahedral coordination of chromium(III) has been reported for the Cr-centered Keggin anion [\u03b1-CrW12O40]5\u2013.\nChromium(III) hydroxide (Cr(OH)3) is amphoteric, dissolving in acidic solutions to form [Cr(H2O)6]3+, and in basic solutions to form . It is dehydrated by heating to form the green chromium(III) oxide (Cr2O3), a stable oxide with a crystal structure identical to that of corundum.\nChromium(VI).\nChromium(VI) compounds are oxidants at low or neutral pH. Chromate anions () and dichromate (Cr2O72\u2212) anions are the principal ions at this oxidation state. They exist at an equilibrium, determined by pH:\nChromium(VI) oxyhalides are known also and include chromyl fluoride (CrO2F2) and chromyl chloride (). However, despite several erroneous claims, chromium hexafluoride (as well as all higher hexahalides) remains unknown, as of 2020.\nSodium chromate is produced industrially by the oxidative roasting of chromite ore with sodium carbonate. The change in equilibrium is visible by a change from yellow (chromate) to orange (dichromate), such as when an acid is added to a neutral solution of potassium chromate. At yet lower pH values, further condensation to more complex oxyanions of chromium is possible.\nBoth the chromate and dichromate anions are strong oxidizing reagents at low pH:\nThey are, however, only moderately oxidizing at high pH:\nChromium(VI) compounds in solution can be detected by adding an acidic hydrogen peroxide solution. The unstable dark blue chromium(VI) peroxide (CrO5) is formed, which can be stabilized as an ether adduct .\nChromic acid has the hypothetical formula . It is a vaguely described chemical, despite many well-defined chromates and dichromates being known. The dark red chromium(VI) oxide , the acid anhydride of chromic acid, is sold industrially as \"chromic acid\". It can be produced by mixing sulfuric acid with dichromate and is a strong oxidizing agent.\nOther oxidation states.\nCompounds of chromium(V) are rather rare; the oxidation state +5 is only realized in few compounds but are intermediates in many reactions involving oxidations by chromate. The only binary compound is the volatile chromium(V) fluoride (CrF5). This red solid has a melting point of 30\u00a0\u00b0C and a boiling point of 117\u00a0\u00b0C. It can be prepared by treating chromium metal with fluorine at 400\u00a0\u00b0C and 200 bar pressure. The peroxochromate(V) is another example of the +5 oxidation state. Potassium peroxochromate (K3[Cr(O2)4]) is made by reacting potassium chromate with hydrogen peroxide at low temperatures. This red brown compound is stable at room temperature but decomposes spontaneously at 150\u2013170\u00a0\u00b0C.\nCompounds of chromium(IV) are slightly more common than those of chromium(V). The tetrahalides, CrF4, CrCl4, and CrBr4, can be produced by treating the trihalides () with the corresponding halogen at elevated temperatures. Such compounds are susceptible to disproportionation reactions and are not stable in water. Organic compounds containing Cr(IV) state such as chromium tetra \"t\"-butoxide are also known.\nMost chromium(I) compounds are obtained solely by oxidation of electron-rich, octahedral chromium(0) complexes. Other chromium(I) complexes contain cyclopentadienyl ligands. As verified by X-ray diffraction, a Cr-Cr quintuple bond (length 183.51(4) pm) has also been described. Extremely bulky monodentate ligands stabilize this compound by shielding the quintuple bond from further reactions.\nOccurrence.\nChromium is the 21st most abundant element in Earth's crust with an average concentration of 100\u00a0ppm. Chromium compounds are found in the environment from the erosion of chromium-containing rocks, and can be redistributed by volcanic eruptions. Typical background concentrations of chromium in environmental media are: atmosphere &lt;10\u00a0ng/m3; soil &lt;500\u00a0mg/kg; vegetation &lt;0.5\u00a0mg/kg; freshwater &lt;10\u00a0\u03bcg/L; seawater &lt;1\u00a0\u03bcg/L; sediment &lt;80\u00a0mg/kg. Chromium is mined as chromite (FeCr2O4) ore.\nAbout two-fifths of the chromite ores and concentrates in the world are produced in South Africa, about a third in Kazakhstan, while India, Russia, and Turkey are also substantial producers. Untapped chromite deposits are plentiful, but geographically concentrated in Kazakhstan and southern Africa. Although rare, deposits of native chromium exist. The Udachnaya Pipe in Russia produces samples of the native metal. This mine is a kimberlite pipe, rich in diamonds, and the reducing environment helped produce both elemental chromium and diamonds.\nThe relation between Cr(III) and Cr(VI) strongly depends on pH and oxidative properties of the location. In most cases, Cr(III) is the dominating species, but in some areas, the ground water can contain up to 39\u00a0\u03bcg/L of total chromium, of which 30\u00a0\u03bcg/L is Cr(VI).\nHistory.\nEarly applications.\nThe ancient Chinese are credited with the first ever use of chromium to prevent rusting. Modern archaeologists discovered that bronze-tipped crossbow bolts at the tomb of Qin Shi Huang showed no sign of corrosion after more than 2,000 years, because they had been coated in chromium. In multiple Warring States period tombs, sharp \"jians\" and other weapons were also found to be coated with 10 to 15 micrometers of chromium oxide, which left them in pristine condition to this day. Chromium was not used anywhere else until the experiments of French pharmacist and chemist Louis Nicolas Vauquelin (1763\u20131829) in the late 1790s. \nChromium minerals as pigments came to the attention of the west in the eighteenth century. On 26\u00a0July 1761, Johann Gottlob Lehmann found an orange-red mineral in the Beryozovskoye mines in the Ural Mountains which he named \"Siberian red lead\". Though misidentified as a lead compound with selenium and iron components, the mineral was in fact crocoite with a formula of PbCrO4. In 1770, Peter Simon Pallas visited the same site as Lehmann and found a red lead mineral that was discovered to possess useful properties as a pigment in paints. After Pallas, the use of Siberian red lead as a paint pigment began to develop rapidly throughout the region. Crocoite would be the principal source of chromium in pigments until the discovery of chromite many years later.\nIn 1794, Louis Nicolas Vauquelin received samples of crocoite ore. He produced chromium trioxide (CrO3) by mixing crocoite with hydrochloric acid. In 1797, Vauquelin discovered that he could isolate metallic chromium by heating the oxide in a charcoal oven, for which he is credited as the one who truly discovered the element. Vauquelin was also able to detect traces of chromium in precious gemstones, such as ruby and emerald.\nDuring the nineteenth century, chromium was primarily used not only as a component of paints, but in tanning salts as well. For quite some time, the crocoite found in Russia was the main source for such tanning materials. In 1827, a larger chromite deposit was discovered near Baltimore, United States, which quickly met the demand for tanning salts much more adequately than the crocoite that had been used previously. This made the United States the largest producer of chromium products until the year 1848, when larger deposits of chromite were uncovered near the city of Bursa, Turkey. With the development of metallurgy and chemical industries in the Western world, the need for chromium increased.\nChromium is also famous for its reflective, metallic luster when polished. It is used as a protective and decorative coating on car parts, plumbing fixtures, furniture parts and many other items, usually applied by electroplating. Chromium was used for electroplating as early as 1848, but this use only became widespread with the development of an improved process in 1924.\nProduction.\nApproximately 28.8 million metric tons (Mt) of marketable chromite ore was produced in 2013, and converted into 7.5 Mt of ferrochromium. According to John F. Papp, writing for the USGS, \"Ferrochromium is the leading end use of chromite ore, [and] stainless steel is the leading end use of ferrochromium.\"\nThe largest producers of chromium ore in 2013 have been South Africa (48%), Kazakhstan (13%), Turkey (11%), and India (10%), with several other countries producing the rest of about 18% of the world production.\nThe two main products of chromium ore refining are ferrochromium and metallic chromium. For those products the ore smelter process differs considerably. For the production of ferrochromium, the chromite ore (FeCr2O4) is reduced in large scale in electric arc furnace or in smaller smelters with either aluminium or silicon in an aluminothermic reaction.\nFor the production of pure chromium, the iron must be separated from the chromium in a two step roasting and leaching process. The chromite ore is heated with a mixture of calcium carbonate and sodium carbonate in the presence of air. The chromium is oxidized to the hexavalent form, while the iron forms the stable Fe2O3. The subsequent leaching at higher elevated temperatures dissolves the chromates and leaves the insoluble iron oxide. The chromate is converted by sulfuric acid into the dichromate.\nThe dichromate is converted to the chromium(III) oxide by reduction with carbon and then reduced in an aluminothermic reaction to chromium.\nApplications.\nThe creation of metal alloys account for 85% of the available chromium's usage. The remainder of chromium is used in the chemical, refractory, and foundry industries.\nMetallurgy.\nThe strengthening effect of forming stable metal carbides at grain boundaries, and the strong increase in corrosion resistance made chromium an important alloying material for steel. High-speed tool steels contain 3\u20135% chromium. Stainless steel, the primary corrosion-resistant metal alloy, is formed when chromium is introduced to iron in concentrations above 11%. For stainless steel's formation, ferrochromium is added to the molten iron. Also, nickel-based alloys have increased strength due to the formation of discrete, stable, metal, carbide particles at the grain boundaries. For example, Inconel 718 contains 18.6% chromium. Because of the excellent high-temperature properties of these nickel superalloys, they are used in jet engines and gas turbines in lieu of common structural materials. ASTM B163 relies on chromium for condenser and heat-exchanger tubes, while castings with high strength at elevated temperatures that contain chromium are standardised with ASTM A567. AISI type 332 is used where high temperature would normally cause carburization, oxidation or corrosion. Incoloy 800 \"is capable of remaining stable and maintaining its austenitic structure even after long time exposures to high temperatures\". Nichrome is used as resistance wire for heating elements in things like toasters and space heaters. These uses make chromium a strategic material. Consequently, during World War II, U.S. road engineers were instructed to avoid chromium in yellow road paint, as it \"may become a critical material during the emergency\". The United States likewise considered chromium \"essential for the German war industry\" and made intense diplomatic efforts to keep it out of the hands of Nazi Germany.\nThe high hardness and corrosion resistance of unalloyed chromium makes it a reliable metal for surface coating; it is still the most popular metal for sheet coating, with its above-average durability, compared to other coating metals. A layer of chromium is deposited on pretreated metallic surfaces by electroplating techniques. There are two deposition methods: thin, and thick. Thin deposition involves a layer of chromium below 1\u00a0\u03bcm thickness deposited by chrome plating, and is used for decorative surfaces. Thicker chromium layers are deposited if wear-resistant surfaces are needed. Both methods use acidic chromate or dichromate solutions. To prevent the energy-consuming change in oxidation state, the use of chromium(III) sulfate is under development; for most applications of chromium, the previously established process is used.\nIn the chromate conversion coating process, the strong oxidative properties of chromates are used to deposit a protective oxide layer on metals like aluminium, zinc, and cadmium. This passivation and the self-healing properties of the chromate stored in the chromate conversion coating, which is able to migrate to local defects, are the benefits of this coating method. Because of environmental and health regulations on chromates, alternative coating methods are under development.\nChromic acid anodizing (or Type I anodizing) of aluminium is another electrochemical process that does not lead to the deposition of chromium, but uses chromic acid as an electrolyte in the solution. During anodization, an oxide layer is formed on the aluminium. The use of chromic acid, instead of the normally used sulfuric acid, leads to a slight difference of these oxide layers.\nThe high toxicity of Cr(VI) compounds, used in the established chromium electroplating process, and the strengthening of safety and environmental regulations demand a search for substitutes for chromium, or at least a change to less toxic chromium(III) compounds.\nPigment.\nThe mineral crocoite (which is also lead chromate PbCrO4) was used as a yellow pigment shortly after its discovery. After a synthesis method became available starting from the more abundant chromite, chrome yellow was, together with cadmium yellow, one of the most used yellow pigments. The pigment does not photodegrade, but it tends to darken due to the formation of chromium(III) oxide. It has a strong color, and was used for school buses in the United States and for the postal services (for example, the Deutsche Post) in Europe. The use of chrome yellow has since declined due to environmental and safety concerns and was replaced by organic pigments or other alternatives that are free from lead and chromium. Other pigments that are based around chromium are, for example, the deep shade of red pigment chrome red, which is simply lead chromate with lead(II) hydroxide (PbCrO4\u00b7Pb(OH)2). A very important chromate pigment, which was used widely in metal primer formulations, was zinc chromate, now replaced by zinc phosphate. A wash primer was formulated to replace the dangerous practice of pre-treating aluminium aircraft bodies with a phosphoric acid solution. This used zinc tetroxychromate dispersed in a solution of polyvinyl butyral. An 8% solution of phosphoric acid in solvent was added just before application. It was found that an easily oxidized alcohol was an essential ingredient. A thin layer of about 10\u201315\u00a0\u03bcm was applied, which turned from yellow to dark green when it was cured. There is still a question as to the correct mechanism. Chrome green is a mixture of Prussian blue and chrome yellow, while the chrome oxide green is chromium(III) oxide.\nChromium oxides are also used as a green pigment in the field of glassmaking and also as a glaze for ceramics. Green chromium oxide is extremely lightfast and as such is used in cladding coatings. It is also the main ingredient in infrared reflecting paints, used by the armed forces to paint vehicles and to give them the same infrared reflectance as green leaves.\nOther uses.\nChromium(III) ions present in corundum crystals (aluminium oxide) cause them to be colored red; when corundum appears as such, it is known as a ruby. If the corundum is lacking in chromium(III) ions, it is known as a sapphire. A red-colored artificial ruby may also be achieved by doping chromium(III) into artificial corundum crystals, thus making chromium a requirement for making synthetic rubies. Such a synthetic ruby crystal was the basis for the first laser, produced in 1960, which relied on stimulated emission of light from the chromium atoms in such a crystal. Ruby has a laser transition at 694.3 nanometers, in a deep red color.\nChromium(VI) salts are used for the preservation of wood. For example, chromated copper arsenate (CCA) is used in timber treatment to protect wood from decay fungi, wood-attacking insects, including termites, and marine borers. The formulations contain chromium based on the oxide CrO3 between 35.3% and 65.5%. In the United States, 65,300 metric tons of CCA solution were used in 1996.\nChromium(III) salts, especially chrome alum and chromium(III) sulfate, are used in the tanning of leather. The chromium(III) stabilizes the leather by cross linking the collagen fibers. Chromium tanned leather can contain 4\u20135% of chromium, which is tightly bound to the proteins. Although the form of chromium used for tanning is not the toxic hexavalent variety, there remains interest in management of chromium in the tanning industry. Recovery and reuse, direct/indirect recycling, and \"chrome-less\" or \"chrome-free\" tanning are practiced to better manage chromium usage.\nThe high heat resistivity and high melting point makes chromite and chromium(III) oxide a material for high temperature refractory applications, like blast furnaces, cement kilns, molds for the firing of bricks and as foundry sands for the casting of metals. In these applications, the refractory materials are made from mixtures of chromite and magnesite. The use is declining because of the environmental regulations due to the possibility of the formation of chromium(VI). \nSeveral chromium compounds are used as catalysts for processing hydrocarbons. For example, the Phillips catalyst, prepared from chromium oxides, is used for the production of about half the world's polyethylene. Fe-Cr mixed oxides are employed as high-temperature catalysts for the water gas shift reaction. Copper chromite is a useful hydrogenation catalyst.\nBiological role.\nThe possible nutritional value of chromium(III) is unproven. Although chromium is regarded as a trace element and dietary mineral, its suspected roles in the action of insulin \u2013 a hormone that mediates the metabolism and storage of carbohydrate, fat, and protein \u2013 have not been adequately established. The mechanism of its actions in the body is undefined, leaving in doubt whether chromium has a biological role in healthy people. \nIn contrast, hexavalent chromium (Cr(VI) or Cr6+) is highly toxic and mutagenic. Ingestion of chromium(VI) in water has been linked to stomach tumors, and it may also cause allergic contact dermatitis.\n\"Chromium deficiency\", involving a lack of Cr(III) in the body, or perhaps some complex of it, such as glucose tolerance factor, is not accepted as a medical condition, as it has no symptoms and healthy people do not require chromium supplementation. Some studies suggest that the biologically active form of chromium(III) is transported in the body via an oligopeptide called low-molecular-weight chromium-binding substance (chromodulin), which might play a role in the insulin signaling pathway.\nThe chromium content of common foods is generally low (1\u201313 micrograms per serving). The chromium content of food varies widely, due to differences in soil mineral content, growing season, plant cultivar, and contamination during processing. Chromium (and nickel) leach into food cooked in stainless steel, with the effect being largest when the cookware is new. Acidic foods that are cooked for many hours also exacerbate this effect.\nDietary recommendations.\nThere is disagreement on chromium's status as an essential nutrient. Governmental departments from Australia, New Zealand, India, and Japan consider chromium as essential, while the United States and European Food Safety Authority of the European Union do not.\nThe U.S. National Academy of Medicine (NAM) updated the Estimated Average Requirements (EARs) and the Recommended Dietary Allowances (RDAs) for chromium in 2001. For chromium, there was insufficient information to set EARs and RDAs, so its needs are described as estimates for Adequate Intake (AI). From a 2001 assessment, AI of chromium for women ages 14 through 50 is 25\u00a0\u03bcg/day, and the AI for women ages 50 and above is 20\u00a0\u03bcg/day. The AIs for women who are pregnant are 30\u00a0\u03bcg/day, and for women who are lactating, the set AI is 45\u00a0\u03bcg/day. The AI for men ages 14 through 50 is 35\u00a0\u03bcg/day, and the AI for men ages 50 and above is 30\u00a0\u03bcg/day. For children ages 1 through 13, the AI increases with age from 0.2\u00a0\u03bcg/day up to 25\u00a0\u03bcg/day. As for safety, the NAM sets Tolerable Upper Intake Levels (ULs) for vitamins and minerals when the evidence is sufficient. In the case of chromium, there is not yet enough information, hence no UL has been established. Collectively, the EARs, RDAs, AIs, and ULs are the parameters for the nutrition recommendation system known as Dietary Reference Intake (DRI). \nAustralia and New Zealand consider chromium to be an essential nutrient, with an AI of 35\u00a0\u03bcg/day for men, 25\u00a0\u03bcg/day for women, 30\u00a0\u03bcg/day for women who are pregnant, and 45\u00a0\u03bcg/day for women who are lactating. A UL has not been set due to the lack of sufficient data. India considers chromium to be an essential nutrient, with an adult recommended intake of 33\u00a0\u03bcg/day. Japan also considers chromium to be an essential nutrient, with an AI of 10\u00a0\u03bcg/day for adults, including women who are pregnant or lactating. A UL has not been set. \nThe EFSA does not consider chromium to be an essential nutrient.\nLabeling.\nFor U.S. food and dietary supplement labeling purposes, the amount of the substance in a serving is expressed as a percent of the Daily Value (%DV). For chromium labeling purposes, 100% of the Daily Value was 120\u00a0\u03bcg. As of 27\u00a0May 2016, the percentage of daily value was revised to 35\u00a0\u03bcg to bring the chromium intake into a consensus with the official Recommended Dietary Allowance. A table of the old and new adult daily values in the United States is provided at Reference Daily Intake.\nAfter evaluation of research on the potential nutritional value of chromium, the European Food Safety Authority concluded that there was no evidence of benefit by dietary chromium in healthy people, thereby declining to establish recommendations in Europe for dietary intake of chromium.\nFood sources.\nFood composition databases such as those maintained by the U.S. Department of Agriculture do not contain information on the chromium content of foods. A wide variety of animal and vegetable foods contain chromium. Content per serving is influenced by the chromium content of the soil in which the plants are grown, by foodstuffs fed to animals, and by processing methods, as chromium is leached into foods if processed or cooked in stainless steel equipment. One diet analysis study conducted in Mexico reported an average daily chromium intake of 30 micrograms. An estimated 31% of adults in the United States consume multi-vitamin/mineral dietary supplements, which often contain 25 to 60 micrograms of chromium.\nSupplementation.\nChromium is an ingredient in total parenteral nutrition (TPN), because deficiency can occur after months of intravenous feeding with chromium-free TPN. It is also added to nutritional products for preterm infants. Although the mechanism of action in biological roles for chromium is unclear, in the United States chromium-containing products are sold as non-prescription dietary supplements in amounts ranging from 50 to 1,000 \u03bcg. Lower amounts of chromium are also often incorporated into multi-vitamin/mineral supplements consumed by an estimated 31% of adults in the United States. Chemical compounds used in dietary supplements include chromium chloride, chromium citrate, chromium(III) picolinate, chromium(III) polynicotinate, and other chemical compositions. The benefit of supplements has not been proven.\nInitiation of research on glucose.\nThe notion of chromium as a potential regulator of glucose metabolism began in the 1950s when scientists performed a series of experiments controlling the diet of rats. The experimenters subjected the rats to a chromium deficient diet, and witnessed an inability to respond effectively to increased levels of blood glucose. A chromium-rich Brewer's yeast was provided in the diet, enabling the rats to effectively metabolize glucose, and so giving evidence that chromium may have a role in glucose management.\nApproved and disapproved health claims.\nIn 2005, the U.S. Food and Drug Administration had approved a qualified health claim for chromium picolinate with a requirement for specific label wording:\nIn other parts of the petition, the FDA rejected claims for chromium picolinate and cardiovascular disease, retinopathy or kidney disease caused by abnormally high blood sugar levels. As of March 2024, this ruling on chromium remains in effect.\nIn 2010, chromium(III) picolinate was approved by Health Canada to be used in dietary supplements. Approved labeling statements include: a factor in the maintenance of good health, provides support for healthy glucose metabolism, helps the body to metabolize carbohydrates and helps the body to metabolize fats. The European Food Safety Authority approved claims in 2010 that chromium contributed to normal macronutrient metabolism and maintenance of normal blood glucose concentration, but rejected claims for maintenance or achievement of a normal body weight, or reduction of tiredness or fatigue. \nHowever, in a 2014 reassessment of studies to determine whether a Dietary Reference Intake value could be established for chromium, EFSA stated:\nDiabetes.\nGiven the evidence for chromium deficiency causing problems with glucose management in the context of intravenous nutrition products formulated without chromium, research interest turned to whether chromium supplementation would benefit people who have type\u00a02 diabetes but are not chromium deficient. Looking at the results from four meta-analyses, one reported a statistically significant decrease in fasting plasma glucose levels and a non-significant trend in lower hemoglobin A1C. A second reported the same, a third reported significant decreases for both measures, while a fourth reported no benefit for either. A review published in 2016 listed 53 randomized clinical trials that were included in one or more of six meta-analyses. It concluded that whereas there may be modest decreases in fasting blood glucose and/or HbA1C that achieve statistical significance in some of these meta-analyses, few of the trials achieved decreases large enough to be expected to be relevant to clinical outcome.\nBody weight.\nTwo systematic reviews looked at chromium supplements as a mean of managing body weight in overweight and obese people. One, limited to chromium picolinate, a common supplement ingredient, reported a statistically significant \u22121.1\u00a0kg (2.4\u00a0lb) weight loss in trials longer than 12 weeks. The other included all chromium compounds and reported a statistically significant \u22120.50\u00a0kg (1.1\u00a0lb) weight change. Change in percent body fat did not reach statistical significance. Authors of both reviews considered the clinical relevance of this modest weight loss as uncertain/unreliable. The European Food Safety Authority reviewed the literature and concluded that there was insufficient evidence to support a claim.\nSports.\nChromium is promoted as a sports performance dietary supplement, based on the theory that it potentiates insulin activity, with anticipated results of increased muscle mass, and faster recovery of glycogen storage during post-exercise recovery. A review of clinical trials reported that chromium supplementation did not improve exercise performance or increase muscle strength. The International Olympic Committee reviewed dietary supplements for high-performance athletes in 2018 and concluded there was no need to increase chromium intake for athletes, nor support for claims of losing body fat.\nFresh-water fish.\nIrrigation water standards for chromium are 0.1\u00a0mg/L, but some rivers in Bangladesh are more than five times that amount. The standard for fish for human consumption is less than 1\u00a0mg/kg, but many tested samples were more than five times that amount. Chromium, especially hexavalent chromium, is highly toxic to fish because it is easily absorbed across the gills, readily enters blood circulation, crosses cell membranes and bioconcentrates up the food chain. In contrast, the toxicity of trivalent chromium is very low, attributed to poor membrane permeability and little biomagnification.\nAcute and chronic exposure to chromium(VI) affects fish behavior, physiology, reproduction and survival. Hyperactivity and erratic swimming have been reported in contaminated environments. Egg hatching and fingerling survival are affected. In adult fish there are reports of histopathological damage to liver, kidney, muscle, intestines, and gills. Mechanisms include mutagenic gene damage and disruptions of enzyme functions.\nThere is evidence that fish may not require chromium, but benefit from a measured amount in diet. In one study, juvenile fish gained weight on a zero chromium diet, but the addition of 500\u00a0\u03bcg of chromium in the form of chromium chloride or other supplement types, per kilogram of food (dry weight), increased weight gain. At 2,000\u00a0\u03bcg/kg the weight gain was no better than with the zero chromium diet, and there were increased DNA strand breaks.\nPrecautions.\nWater-insoluble chromium(III) compounds and chromium metal are not considered a health hazard, while the toxicity and carcinogenic properties of chromium(VI) have been known for a long time. Because of the specific transport mechanisms, only limited amounts of chromium(III) enter the cells. Acute oral toxicity ranges between 50 and 150\u00a0mg/kg. A 2008 review suggested that moderate uptake of chromium(III) through dietary supplements poses no genetic-toxic risk. In the US, the Occupational Safety and Health Administration (OSHA) has designated an air permissible exposure limit (PEL) in the workplace as a time-weighted average (TWA) of 1\u00a0mg/m3. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of 0.5\u00a0mg/m3, time-weighted average. The IDLH (immediately dangerous to life and health) value is 250\u00a0mg/m3.\nChromium(VI) toxicity.\nThe acute oral toxicity for chromium(VI) ranges between 1.5 and 3.3\u00a0mg/kg. In the body, chromium(VI) is reduced by several mechanisms to chromium(III) already in the blood before it enters the cells. The chromium(III) is excreted from the body, whereas the chromate ion is transferred into the cell by a transport mechanism, by which also sulfate and phosphate ions enter the cell. The acute toxicity of chromium(VI) is due to its strong oxidant properties. After it reaches the blood stream, it damages the kidneys, the liver and blood cells through oxidation reactions. Hemolysis, renal, and liver failure result. Aggressive dialysis can be therapeutic.\nThe carcinogenity of chromate dust has been known for a long time, and in 1890 the first publication described the elevated cancer risk of workers in a chromate dye company. Three mechanisms have been proposed to describe the genotoxicity of chromium(VI). The first mechanism includes highly reactive hydroxyl radicals and other reactive radicals which are by products of the reduction of chromium(VI) to chromium(III). The second process includes the direct binding of chromium(V), produced by reduction in the cell, and chromium(IV) compounds to the DNA. The last mechanism attributed the genotoxicity to the binding to the DNA of the end product of the chromium(III) reduction.\nChromium salts (chromates) are also the cause of allergic reactions in some people. Chromates are often used to manufacture, amongst other things, leather products, paints, cement, mortar and anti-corrosives. Contact with products containing chromates can lead to allergic contact dermatitis and irritant dermatitis, resulting in ulceration of the skin, sometimes referred to as \"chrome ulcers\". This condition is often found in workers that have been exposed to strong chromate solutions in electroplating, tanning and chrome-producing manufacturers.\nEnvironmental issues.\nBecause chromium compounds were used in dyes, paints, and leather tanning compounds, these compounds are often found in soil and groundwater at active and abandoned industrial sites, needing environmental cleanup and remediation. Primer paint containing hexavalent chromium is still widely used for aerospace and automobile refinishing applications.\nIn 2010, the Environmental Working Group studied the drinking water in 35 American cities in the first nationwide study. The study found measurable hexavalent chromium in the tap water of 31 of the cities sampled, with Norman, Oklahoma, at the top of list; 25 cities had levels that exceeded California's proposed limit.\nThe more toxic hexavalent chromium form can be reduced to the less soluble trivalent oxidation state in soils by organic matter, ferrous iron, sulfides, and other reducing agents, with the rates of such reduction being faster under more acidic conditions than under more alkaline ones. In contrast, trivalent chromium can be oxidized to hexavalent chromium in soils by manganese oxides, such as Mn(III) and Mn(IV) compounds. Since the solubility and toxicity of chromium (VI) are greater that those of chromium (III), the oxidation-reduction conversions between the two oxidation states have implications for movement and bioavailability of chromium in soils, groundwater, and plants."}
{"id": "5671", "revid": "1267859815", "url": "https://en.wikipedia.org/wiki?curid=5671", "title": "Cymbal", "text": "A cymbal is a common percussion instrument. Often used in pairs, cymbals consist of thin, normally round plates of various alloys. The majority of cymbals are of indefinite pitch, although small disc-shaped cymbals based on ancient designs sound a definite note (such as crotales). Cymbals are used in many ensembles ranging from the orchestra, percussion ensembles, jazz bands, heavy metal bands, and marching groups. Drum kits usually incorporate at least a crash, ride, or crash/ride, and a pair of hi-hat cymbals. A player of cymbals is known as a cymbalist.\nEtymology and names.\nThe word cymbal is derived from the Latin , which is the latinisation , which in turn derives .\nIn orchestral scores, cymbals may be indicated by the French ; German , , , or ; Italian or ; and Spanish . Many of these derive from the word for plates.\nHistory.\nCymbals have existed since ancient times. Representations of cymbals may be found in reliefs and paintings from Armenian Highlands (7th century BC), Larsa, Babylon, Assyria, ancient Egypt, ancient Greece, and ancient Rome. References to cymbals also appear throughout the Bible, through many Psalms and songs of praise to God. Cymbals may have been introduced to China from Central Asia in the 3rd or 4th century AD.\nIndia.\nIn India, cymbals have been in use since ancient times and are still used across almost all major temples and Buddhist sites. Gigantic aartis along the Ganges, which are revered by Hindus all over the world, are incomplete without large cymbals.\nCentral Asia and Iran.\nThe Shahnameh (circa 977 and 1010 CE) mentions the use of cymbals at least 14 times in its text, most in the context of creating a loud din in war, to frighten the enemy or to celebrate. The Persian word is \"sanj\" or \"senj\" (), but the Shahnameh does not claim these to be Persian in origin. Several times it calls then \"Indian cymbals.\" Other adjectives to describe them include \"golden\" and \"brass,\" and to play them is to \"clash\" them.\nA different form is called \"sanj angshati\" (), these are zill.\nAshura ceremony.\nBesides the original use in war, another use in Persian culture was the Ashura ceremony. \nOriginally in the ceremony, two pieces of stone were beaten on the sides of the mourner with special movements accompanied by a lamentation song. This has been replaced by beating \"Karbzani\" or \"Karebzani\" and playing \"sanj \"and ratchets. Cities where this has been performed include Lahijan and Aran of Kashan, as well as Semnan and Sabzevar.\nEtymology.\nAll theories about the etymology of the word Sanj, identify it as a Pahlavi word. By some accounts means \"weight\"; and it is possible that the original term was \"sanjk\u016bb\" meaning \u201dstriking weights\u201d [against each other]. By some accounts the word is reform version of \"Zang\" (bell), referring to its bell-shaped plate.\nTurkey.\nCymbals were employed by Turkish janissaries in the 14th century or earlier. By the 17th century, such cymbals were used in European music, and more commonly played in military bands and orchestras by the mid 18th century. Since the 19th century, some composers have called for larger roles for cymbals in musical works, and a variety of cymbal shapes, techniques, and hardware have been developed in response.\nAnatomy.\nThe anatomy of the cymbal plays a large part in the sound it creates. A hole is drilled in the center of the cymbal, which is used to either mount the cymbal on a stand or for tying straps through (for hand playing). The bell, dome, or cup is the raised section immediately surrounding the hole. The bell produces a higher \"pinging\" pitch than the rest of the cymbal. The bow is the rest of the surface surrounding the bell. The bow is sometimes described in two areas: the ride and crash area. The ride area is the thicker section closer to the bell while the crash area is the thinner tapering section near the edge. The edge or rim is the immediate circumference of the cymbal.\nCymbals are measured by their diameter either in inches or centimeters. The size of the cymbal affects its sound, larger cymbals usually being louder and having longer sustain. The weight describes how thick the cymbal is. Cymbal weights are important to the sound they produce and how they play. Heavier cymbals have a louder volume, more cut, and better stick articulation (when using drum sticks). Thin cymbals have a fuller sound, lower pitch, and faster response.\nThe profile of the cymbal is the vertical distance of the bow from the bottom of the bell to the cymbal edge (higher profile cymbals are more bowl-shaped). The profile affects the pitch of the cymbal: higher profile cymbals have higher pitch.\nTypes.\nOrchestral cymbals.\nCymbals offer a composer nearly endless amounts of color and effect. Their unique timbre allows them to project even against a full orchestra and through the heaviest of orchestrations and enhance articulation and nearly any dynamic. Cymbals have been utilized historically to suggest frenzy, fury or bacchanalian revels, as seen in the Venus music in Wagner's \"Tannh\u00e4user\", Grieg's \"Peer Gynt suite\", and Osmin's aria \"O wie will ich triumphieren\" from Mozart's \"Die Entf\u00fchrung aus dem Serail\".\nClash cymbals.\nOrchestral clash cymbals are traditionally used in pairs, each one having a strap set in the bell of the cymbal by which they are held. Such a pair is known as clash cymbals, crash cymbals, hand cymbals, or plates. Certain sounds can be obtained by rubbing their edges together in a sliding movement for a \"sizzle\", striking them against each other in what is called a \"crash\", tapping the edge of one against the body of the other in what is called a \"tap-crash\", scraping the edge of one from the inside of the bell to the edge for a \"scrape\" or \"zischen\", or shutting the cymbals together and choking the sound in what is called a \"hi-hat\" or \"crush\". A skilled percussionist can obtain an enormous dynamic range from such cymbals. For example, in Beethoven's Symphony No. 9, the percussionist is employed to first play cymbals pianissimo, adding a touch of colour rather than loud crash.\nCrash cymbals are usually damped by pressing them against the percussionist's body. A composer may write \"laissez vibrer\", or, \"let vibrate\" (usually abbreviated l.v.), \"secco\" (dry), or equivalent indications on the score; more usually, the percussionist must judge when to damp based on the written duration of a crash and the context in which it occurs. Crash cymbals have traditionally been accompanied by the bass drum playing an identical part. This combination, played loudly, is an effective way to accentuate a note since it contributes to both very low and very high-frequency ranges and provides a satisfying \"crash-bang-wallop\". In older music the composer sometimes provided one part for this pair of instruments, writing \"senza piatti\" or \"piatti soli\" () if only one is needed. This came from the common practice of having one percussionist play using one cymbal mounted to the shell of the bass drum. The percussionist would crash the cymbals with the left hand and use a mallet to strike the bass drum with the right. This method is nowadays often employed in pit orchestras and called for specifically by composers who desire a certain effect. Stravinsky calls for this in his ballet Petrushka, and Mahler calls for this in his Titan Symphony. The modern convention is for the instruments to have independent parts. However, in kit drumming, a cymbal crash is still most often accompanied by a simultaneous kick to the bass drum, which provides a musical effect and support to the crash.\nHi hats.\nCrash cymbals evolved into the low-sock and from this to the modern hi-hat. Even in a modern drum kit, they remain paired with the bass drum as the two instruments which are played with the player's feet. However, hi-hat cymbals tend to be heavy with little taper, more similar to a ride cymbal than to a clash cymbal as found in a drum kit, and perform a ride rather than a crash function.\nSuspended cymbal.\nAnother use of cymbals is the suspended cymbal. This instrument takes its name from the traditional method of suspending the cymbal by means of a leather strap or rope, thus allowing the cymbal to vibrate as freely as possible for maximum musical effect. Early jazz drumming pioneers borrowed this style of cymbal mounting during the early 1900s and later drummers further developed this instrument into the mounted horizontal or nearly horizontally mounted \"crash\" cymbals of a modern drum kit instead of a leather strap suspension system. Many modern drum kits use a mount with felt or otherwise dampening fabric to act as a barrier to hold the cymbals between metal clamps: thus forming the modern-day ride cymbal. Suspended cymbals can be played with yarn-, sponge-, or cord wrapped mallets. The first known instance of using a sponge-headed mallet on a cymbal is the final chord of Hector Berlioz' Symphonie Fantastique. Composers sometimes specifically request other types of mallets like felt mallets or timpani mallets for different attack and sustain qualities. Suspended cymbals can produce bright and slicing tones when forcefully struck, and give an eerie transparent \"windy\" sound when played quietly. A tremolo, or roll (played with two mallets alternately striking on opposing sides of the cymbal) can build in volume from almost inaudible to an overwhelming climax in a satisfyingly smooth manner (as in Humperdinck's Mother Goose Suite). The edge of a suspended cymbal may be hit with the shoulder of a drum stick to obtain a sound somewhat akin to that of clash cymbals. Other methods of playing include scraping a coin or triangle beater rapidly across the ridges on the top of the cymbal, giving a \"zing\" sound (as some percussionists do in the fourth movement of Dvo\u0159\u00e1k's Symphony No. 9). Other effects that can be used include drawing a bass bow across the edge of the cymbal for a sound like squealing car brakes.\nAncient cymbals.\nAncient, antique or tuned cymbals are much more rarely called for. Their timbre is entirely different, more like that of small hand-bells or of the notes of the keyed harmonica. They are not struck full against each other, but by one of their edges, and the note given in by them is higher in proportion as they are thicker and smaller. Berlioz's \"Romeo and Juliet\" calls for two pairs of cymbals, modeled on some old Pompeian instruments no larger than the hand (some are no larger than a large coin), and tuned to F and B flat. The modern instruments descended from this line are the crotales.\nList of cymbal types.\nCymbal types include:"}
{"id": "5672", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=5672", "title": "Cadmium", "text": "Cadmium is a chemical element; it has symbol Cd and atomic number 48. This soft, silvery-white metal is chemically similar to the two other stable metals in group 12, zinc and mercury. Like zinc, it demonstrates oxidation state +2 in most of its compounds, and like mercury, it has a lower melting point than the transition metals in groups 3 through 11. Cadmium and its congeners in group 12 are often not considered transition metals, in that they do not have partly filled \"d\" or \"f\" electron shells in the elemental or common oxidation states. The average concentration of cadmium in Earth's crust is between 0.1 and 0.5 parts per million (ppm). It was discovered in 1817 simultaneously by Stromeyer and Hermann, both in Germany, as an impurity in zinc carbonate.\nCadmium occurs as a minor component in most zinc ores and is a byproduct of zinc production. It was used for a long time in the 1900s as a corrosion-resistant plating on steel, and cadmium compounds are used as red, orange, and yellow pigments, to color glass, and to stabilize plastic. Cadmium's use is generally decreasing because it is toxic (it is specifically listed in the European Restriction of Hazardous Substances Directive) and nickel\u2013cadmium batteries have been replaced with nickel\u2013metal hydride and lithium-ion batteries. Due to it being a neutron poison, cadmium is also used as a component of control rods in nuclear fission reactors. One of its few new uses is in cadmium telluride solar panels.\nAlthough cadmium has no known biological function in higher organisms, a cadmium-dependent carbonic anhydrase has been found in marine diatoms.\nCharacteristics.\nPhysical properties.\nCadmium is a soft, malleable, ductile, silvery-white divalent metal. It is similar in many respects to zinc but forms complex compounds. Unlike most other metals, cadmium is resistant to corrosion and is used as a protective plate on other metals. As a bulk metal, cadmium is insoluble in water and is not flammable; however, in its powdered form it may burn and release toxic fumes.\nChemical properties.\nAlthough cadmium usually has an oxidation state of +2, it also exists in the +1 state. Cadmium and its congeners are not always considered transition metals, in that they do not have partly filled d or f electron shells in the elemental or common oxidation states. Cadmium burns in air to form brown amorphous cadmium oxide (CdO); the crystalline form of this compound is a dark red which changes color when heated, similar to zinc oxide. Hydrochloric acid, sulfuric acid, and nitric acid dissolve cadmium by forming cadmium chloride (CdCl2), cadmium sulfate (CdSO4), or cadmium nitrate (Cd(NO3)2). The oxidation state +1 can be produced by dissolving cadmium in a mixture of cadmium chloride and aluminium chloride, forming the Cd22+ cation, which is similar to the Hg22+ cation in mercury(I) chloride.\nThe structures of many cadmium complexes with nucleobases, amino acids, and vitamins have been determined.\nIsotopes.\nNaturally occurring cadmium is composed of eight isotopes. Two of them are radioactive, and three are expected to decay but have not measurably done so under laboratory conditions. The two natural radioactive isotopes are 113Cd (beta decay, half-life is ) and 116Cd (two-neutrino double beta decay, half-life is ). The other three are 106Cd, 108Cd (both double electron capture), and 114Cd (double beta decay); only lower limits on these half-lives have been determined. At least three isotopes\u00a0\u2013 110Cd, 111Cd, and 112Cd\u00a0\u2013 are stable. Among the isotopes that do not occur naturally, the most long-lived are 109Cd with a half-life of 462.6\u00a0days, and 115Cd with a half-life of 53.46\u00a0hours. All of the remaining radioactive isotopes have half-lives of less than 2.5\u00a0hours, and the majority have half-lives of less than 5\u00a0minutes. Cadmium has 8 known meta states, with the most stable being 113mCd (\"t\"1\u20442\u00a0= 14.1\u00a0years), 115mCd (\"t\"1\u20442\u00a0= 44.6\u00a0days), and 117mCd (\"t\"1\u20442\u00a0= 3.36\u00a0hours).\nThe known isotopes of cadmium range in atomic mass from 94.950\u00a0u (95Cd) to 131.946\u00a0u (132Cd). For isotopes lighter than 112\u00a0u, the primary decay mode is electron capture and the dominant decay product is element\u00a047 (silver). Heavier isotopes decay mostly through beta emission producing element\u00a049 (indium).\nOne isotope of cadmium, 113Cd, absorbs neutrons with high selectivity: With very high probability, neutrons with energy below the \"cadmium cut-off\" will be absorbed; those higher than the \"cut-off will be transmitted\". The cadmium cut-off is about 0.5\u00a0eV, and neutrons below that level are deemed slow neutrons, distinct from intermediate and fast neutrons.\nCadmium is created via the s-process in low- to medium-mass stars with masses of 0.6\u00a0to 10\u00a0solar masses, over thousands of years. In that process, a silver atom captures a neutron and then undergoes beta decay.\nHistory.\nCadmium (Latin \"cadmia\", Greek \"\u03ba\u03b1\u03b4\u03bc\u03b5\u03af\u03b1\" meaning \"calamine\", a cadmium-bearing mixture of minerals that was named after the Greek mythological character \u039a\u03ac\u03b4\u03bc\u03bf\u03c2, Cadmus, the founder of Thebes) was discovered in contaminated zinc compounds sold in pharmacies in Germany in 1817 by Friedrich Stromeyer. Karl Samuel Leberecht Hermann simultaneously investigated the discoloration in zinc oxide and found an impurity, first suspected to be arsenic, because of the yellow precipitate with hydrogen sulfide. Additionally Stromeyer discovered that one supplier sold zinc carbonate instead of zinc oxide. Stromeyer found the new element as an impurity in zinc carbonate (calamine), and, for 100 years, Germany remained the only important producer of the metal. The metal was named after the Latin word for calamine, because it was found in this zinc ore. Stromeyer noted that some impure samples of calamine changed color when heated but pure calamine did not. He was persistent in studying these results and eventually isolated cadmium metal by roasting and reducing the sulfide. The potential for cadmium yellow as pigment was recognized in the 1840s, but the lack of cadmium limited this application.\nEven though cadmium and its compounds are toxic in certain forms and concentrations, the British Pharmaceutical Codex from 1907 states that cadmium iodide was used as a medication to treat \"enlarged joints, scrofulous glands, and chilblains\".\nIn 1907, the International Astronomical Union defined the international \u00e5ngstr\u00f6m in terms of a red cadmium spectral line (1 wavelength = 6438.46963\u00a0\u00c5). This was adopted by the 7th General Conference on Weights and Measures in 1927. In 1960, the definitions of both the metre and \u00e5ngstr\u00f6m were changed to use krypton.\nAfter the industrial scale production of cadmium started in the 1930s and 1940s, the major application of cadmium was the coating of iron and steel to prevent corrosion; in 1944, 62% and in 1956, 59% of the cadmium in the United States was used for plating. In 1956, 24% of the cadmium in the United States was used for a second application in red, orange and yellow pigments from sulfides and selenides of cadmium.\nThe stabilizing effect of cadmium chemicals like the carboxylates cadmium laurate and cadmium stearate on PVC led to an increased use of those compounds in the 1970s and 1980s. The demand for cadmium in pigments, coatings, stabilizers, and alloys declined as a result of environmental and health regulations in the 1980s and 1990s; in 2006, only 7% of total cadmium consumption was used for plating, and only 10% was used for pigments.\nAt the same time, these decreases in consumption were compensated by a growing demand for cadmium for nickel\u2013cadmium batteries, which accounted for 81% of the cadmium consumption in the United States in 2006.\nOccurrence.\nCadmium makes up about 0.1\u00a0ppm of Earth's crust and is the 65th most abundant element. It is much rarer than zinc, which makes up about 65\u00a0ppm. No significant deposits of cadmium-containing ores are known. The only cadmium mineral of importance, greenockite (CdS), is nearly always associated with sphalerite (ZnS). This association is caused by geochemical similarity between zinc and cadmium, with no geological process likely to separate them. Thus, cadmium is produced mainly as a byproduct of mining, smelting, and refining sulfidic ores of zinc, and, to a lesser degree, lead and copper. Small amounts of cadmium, about 10% of consumption, are produced from secondary sources, mainly from dust generated by recycling iron and steel scrap. Production in the United States began in 1907, but wide use began after World War I.\nMetallic cadmium can be found in the Vilyuy River basin in Siberia.\nRocks mined for phosphate fertilizers contain varying amounts of cadmium, resulting in a cadmium concentration of as much as 300\u00a0mg/kg in the fertilizers and a high cadmium content in agricultural soils. Coal can contain significant amounts of cadmium, which ends up mostly in coal fly ash.\nCadmium in soil can be absorbed by crops such as rice and cocoa. In 2002, the Chinese ministry of agriculture measured that 28% of rice it sampled had excess lead and 10% had excess cadmium above limits defined by law. \"Consumer Reports\" tested 28 brands of dark chocolate sold in the United States in 2022, and found cadmium in all of them, with 13 exceeding the California Maximum Allowable Dose level.\nSome plants such as willow trees and poplars have been found to clean both lead and cadmium from soil.\nTypical background concentrations of cadmium do not exceed 5\u00a0ng/m3 in the atmosphere; 2\u00a0mg/kg in soil; 1\u00a0\u03bcg/L in freshwater and 50\u00a0ng/L in seawater. Concentrations of cadmium above 10 \u03bcg/L may be stable in water having low total solute concentrations and \"p\" H and can be difficult to remove by conventional water treatment processes.\nProduction.\nCadmium is a common impurity in zinc ores, and it is most often isolated during the production of zinc. Some zinc ores concentrates from zinc sulfate ores contain up to 1.4% of cadmium. In the 1970s, the output of cadmium was per ton of zinc. Zinc sulfide ores are roasted in the presence of oxygen, converting the zinc sulfide to the oxide. Zinc metal is produced either by smelting the oxide with carbon or by electrolysis in sulfuric acid. Cadmium is isolated from the zinc metal by vacuum distillation if the zinc is smelted, or cadmium sulfate is precipitated from the electrolysis solution.\nThe British Geological Survey reports that in 2001, China was the top producer of cadmium with almost one-sixth of the world's production, closely followed by South Korea and Japan.\nApplications.\nCadmium is a common component of electric batteries, pigments, coatings, and electroplating.\nBatteries.\nIn 2009, 86% of cadmium was used in batteries, predominantly in rechargeable nickel\u2013cadmium batteries. Nickel\u2013cadmium cells have a nominal cell potential of 1.2\u00a0V. The cell consists of a positive nickel hydroxide electrode and a negative cadmium electrode plate separated by an alkaline electrolyte (potassium hydroxide). The European Union put a limit on cadmium in electronics in 2004 of 0.01%, with some exceptions, and in 2006 reduced the limit on cadmium content to 0.002%. Another type of battery based on cadmium is the silver\u2013cadmium battery.\nElectroplating.\nCadmium electroplating, consuming 6% of the global production, is used in the aircraft industry to reduce corrosion of steel components. This coating is passivated by chromate salts. A limitation of cadmium plating is hydrogen embrittlement of high-strength steels from the electroplating process. Therefore, steel parts heat-treated to tensile strength above 1300 MPa (200 ksi) should be coated by an alternative method (such as special low-embrittlement cadmium electroplating processes or physical vapor deposition).\nTitanium embrittlement from cadmium-plated tool residues resulted in banishment of those tools (and the implementation of routine tool testing to detect cadmium contamination) in the A-12/SR-71, U-2, and subsequent aircraft programs that use titanium.\nNuclear technology.\nCadmium is used in the control rods of nuclear reactors, acting as a very effective neutron poison to control neutron flux in nuclear fission. When cadmium rods are inserted in the core of a nuclear reactor, cadmium absorbs neutrons, preventing them from creating additional fission events, thus controlling the amount of reactivity. The pressurized water reactor designed by Westinghouse Electric Company uses an alloy consisting of 80% silver, 15% indium, and 5% cadmium.\nTelevisions.\nQLED TVs have been starting to include cadmium in construction. Some companies have been looking to reduce the environmental impact of human exposure and pollution of the material in televisions during production.\nAnticancer drugs.\nComplexes based on cadmium and other heavy metals have potential for the treatment of cancer, but their use is often limited due to toxic side effects.\nCompounds.\nCadmium oxide was used in black and white television phosphors and in the blue and green phosphors of color television cathode ray tubes. Cadmium sulfide (CdS) is used as a photoconductive surface coating for photocopier drums.\nVarious cadmium salts are used in paint pigments, with CdS as a yellow pigment being the most common. Cadmium selenide is a red pigment, commonly called \"cadmium red\". To painters who work with the pigment, cadmium provides the most brilliant and durable yellows, oranges, and reds\u00a0\u2013 so much so that during production, these colors are significantly toned down before they are ground with oils and binders or blended into watercolors, gouaches, acrylics, and other paint and pigment formulations. Because these pigments are potentially toxic, users should use a barrier cream on the hands to prevent absorption through the skin even though the amount of cadmium absorbed into the body through the skin is reported to be less than 1%.\nIn PVC, cadmium was used as heat, light, and weathering stabilizers. Currently, cadmium stabilizers have been completely replaced with barium-zinc, calcium-zinc and organo-tin stabilizers. Cadmium is used in many kinds of solder and bearing alloys, because it has a low coefficient of friction and fatigue resistance. It is also found in some of the lowest-melting alloys, such as Wood's metal.\nSemiconductors.\nCadmium is an element in some semiconductor materials. Cadmium sulfide, cadmium selenide, and cadmium telluride are used in some photodetectors and solar cells. HgCdTe detectors are sensitive to mid-infrared light and used in some motion detectors.\nLaboratory uses.\nHelium\u2013cadmium lasers are a common source of blue or ultraviolet laser light. Lasers at wavelengths of 325, 354 and 442\u00a0nm are made using this gain medium; some models can switch between these wavelengths. They are notably used in fluorescence microscopy as well as various laboratory uses requiring laser light at these wavelengths.\nCadmium selenide quantum dots emit bright luminescence under UV excitation (He\u2013Cd laser, for example). The color of this luminescence can be green, yellow or red depending on the particle size. Colloidal solutions of those particles are used for imaging of biological tissues and solutions with a fluorescence microscope.\nIn molecular biology, cadmium is used to block voltage-dependent calcium channels from fluxing calcium ions, as well as in hypoxia research to stimulate proteasome-dependent degradation of Hif-1\u03b1.\nCadmium-selective sensors based on the fluorophore BODIPY have been developed for imaging and sensing of cadmium in cells. One powerful method for monitoring cadmium in aqueous environments involves electrochemistry. By employing a self-assembled monolayer one can obtain a cadmium selective electrode with a ppt-level sensitivity.\nBiological role.\nCadmium has no known function in higher organisms and is considered toxic. Cadmium is considered an environmental pollutant hazardous to living organisms. A cadmium-dependent carbonic anhydrase has been found in some marine diatoms, which live in environments with low zinc concentrations.\nCadmium is preferentially absorbed in the kidneys of humans. Up to about 30\u00a0mg of cadmium is commonly inhaled throughout human childhood and adolescence.\nCadmium is under research for its potential toxicity to increase the risk of cancer, cardiovascular disease, and osteoporosis.\nEnvironmental impact.\nThe biogeochemistry of cadmium and its release to the environment is under research.\nSafety.\nIndividuals and organizations have been reviewing cadmium's bioinorganic aspects for its toxicity. The most dangerous form of occupational exposure to cadmium is inhalation of fine dust and fumes, or ingestion of highly soluble cadmium compounds. Inhalation of cadmium fumes can result initially in metal fume fever, but may progress to chemical pneumonitis, pulmonary edema, and death.\nCadmium is also an environmental hazard. Human exposure is primarily from fossil fuel combustion, phosphate fertilizers, natural sources, iron and steel production, cement production and related activities, nonferrous metals production, and municipal solid waste incineration. Other sources of cadmium include bread, root crops, and vegetables.\nThere have been a few instances of general population poisoning as the result of long-term exposure to cadmium in contaminated food and water. Research into an estrogen mimicry that may induce breast cancer is ongoing, . In the decades leading up to World War II, mining operations contaminated the Jinz\u016b River in Japan with cadmium and traces of other toxic metals. As a consequence, cadmium accumulated in the rice crops along the riverbanks downstream of the mines. Some members of the local agricultural communities consumed the contaminated rice and developed itai-itai disease and renal abnormalities, including proteinuria and glucosuria. The victims of this poisoning were almost exclusively post-menopausal women with low iron and low body stores of other minerals. Similar general population cadmium exposures in other parts of the world have not resulted in the same health problems because the populations maintained sufficient iron and other mineral levels. Thus, although cadmium is a major factor in the itai-itai disease in Japan, most researchers have concluded that it was one of several factors.\nCadmium is one of ten substances banned by the European Union's Restriction of Hazardous Substances (RoHS) directive, which regulates hazardous substances in electrical and electronic equipment, but allows for certain exemptions and exclusions from the scope of the law.\nThe International Agency for Research on Cancer has classified cadmium and cadmium compounds as carcinogenic to humans. Although occupational exposure to cadmium is linked to lung and prostate cancer, there is still uncertainty about the carcinogenicity of cadmium in low environmental exposure. Recent data from epidemiological studies suggest that intake of cadmium through diet is associated with a higher risk of endometrial, breast, and prostate cancer as well as with osteoporosis in humans. A recent study has demonstrated that endometrial tissue is characterized by higher levels of cadmium in current and former smoking females.\nCadmium exposure is associated with a large number of illnesses including kidney disease, early atherosclerosis, hypertension, and cardiovascular diseases. Although studies show a significant correlation between cadmium exposure and occurrence of disease in human populations, a molecular mechanism has not yet been identified. One hypothesis holds that cadmium is an endocrine disruptor and some experimental studies have shown that it can interact with different hormonal signaling pathways. For example, cadmium can bind to the estrogen receptor alpha, and affect signal transduction along the estrogen and MAPK signaling pathways at low doses.\nThe tobacco plant absorbs and accumulates heavy metals such as cadmium from the surrounding soil into its leaves. Following tobacco smoke inhalation, these are readily absorbed into the body of users. Tobacco smoking is the most important single source of cadmium exposure in the general population. An estimated 10% of the cadmium content of a cigarette is inhaled through smoking. Absorption of cadmium through the lungs is more effective than through the gut. As much as 50% of the cadmium inhaled in cigarette smoke may be absorbed.\nOn average, cadmium concentrations in the blood of smokers is 4\u00a0to 5 times greater than non-smokers and in the kidney, 2\u20133 times greater than in non-smokers. Despite the high cadmium content in cigarette smoke, there seems to be little exposure to cadmium from passive smoking.\nIn a non-smoking population, food is the greatest source of exposure. High quantities of cadmium can be found in crustaceans, mollusks, offal, frog legs, cocoa solids, bitter and semi-bitter chocolate, seaweed, fungi and algae products. However, grains, vegetables, and starchy roots and tubers are consumed in much greater quantity in the U.S., and are the source of the greatest dietary exposure there. Most plants bio-accumulate metal toxins such as cadmium and when composted to form organic fertilizers, yield a product that often can contain high amounts (e.g., over 0.5\u00a0mg) of metal toxins for every kilogram of fertilizer. Fertilizers made from animal dung (e.g., cow dung) or urban waste can contain similar amounts of cadmium. The cadmium added to the soil from fertilizers (rock phosphates or organic fertilizers) become bio-available and toxic only if the soil pH is low (i.e., acidic soils). In the European Union, an analysis of almost 22,000 topsoil samples with LUCAS survey concluded that 5.5% of samples have concentrations higher than 1\u00a0mg kg\u22121.\nZinc, copper, calcium, and iron ions, and selenium with vitamin C are used to treat cadmium intoxication, although it is not easily reversed.\nRegulations.\nBecause of the adverse effects of cadmium on the environment and human health, the supply and use of cadmium is restricted in Europe under the REACH Regulation.\nThe EFSA Panel on Contaminants in the Food Chain specifies that 2.5 \u03bcg/kg body weight is a tolerable weekly intake for humans. The Joint FAO/WHO Expert Committee on Food Additives has declared 7 \u03bcg/kg body weight to be the provisional tolerable weekly intake level. The state of California requires a food label to carry a warning about potential exposure to cadmium on products such as cocoa powder. The European Commission has put in place the EU regulation (2019/1009) on fertilizing products (EU, 2019), adopted in June 2019 and fully applicable as of July 2022. It sets a Cd limit value in phosphate fertilizers to 60\u00a0mg kg\u22121 of P2O5.\nThe U.S. Occupational Safety and Health Administration (OSHA) has set the permissible exposure limit (PEL) for cadmium at a time-weighted average (TWA) of 0.005 ppm. The National Institute for Occupational Safety and Health (NIOSH) has not set a recommended exposure limit (REL) and has designated cadmium as a known human carcinogen. The IDLH (immediately dangerous to life and health) level for cadmium is 9\u00a0mg/m3.\nIn addition to mercury, the presence of cadmium in some batteries has led to the requirement of proper disposal (or recycling) of batteries.\nProduct recalls.\nIn May 2006, a sale of the seats from Arsenal F.C.'s old stadium, Highbury in London, England was cancelled when the seats were discovered to contain trace amounts of cadmium. Reports of high levels of cadmium use in children's jewelry in 2010 led to a US Consumer Product Safety Commission investigation. The U.S. CPSC issued specific recall notices for cadmium content in jewelry sold by Claire's and Wal-Mart stores.\nIn June 2010, McDonald's voluntarily recalled more than 12\u00a0million promotional \"Shrek Forever After 3D\" Collectible Drinking Glasses because of the cadmium levels in paint pigments on the glassware. The glasses were manufactured by Arc International, of Millville, New Jersey, USA."}
{"id": "5675", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=5675", "title": "Curium", "text": "Curium is a synthetic chemical element; it has symbol Cm and atomic number 96. This transuranic actinide element was named after eminent scientists Marie and Pierre Curie, both known for their research on radioactivity. Curium was first intentionally made by the team of Glenn T. Seaborg, Ralph A. James, and Albert Ghiorso in 1944, using the cyclotron at Berkeley. They bombarded the newly discovered element plutonium (the isotope 239Pu) with alpha particles. This was then sent to the Metallurgical Laboratory at University of Chicago where a tiny sample of curium was eventually separated and identified. The discovery was kept secret until after the end of World War II. The news was released to the public in November 1947. Most curium is produced by bombarding uranium or plutonium with neutrons in nuclear reactors \u2013 one tonne of spent nuclear fuel contains ~20 grams of curium. \nCurium is a hard, dense, silvery metal with a high melting and boiling point for an actinide. It is paramagnetic at ambient conditions, but becomes antiferromagnetic upon cooling, and other magnetic transitions are also seen in many curium compounds. In compounds, curium usually has valence +3 and sometimes +4; the +3 valence is predominant in solutions. Curium readily oxidizes, and its oxides are a dominant form of this element. It forms strongly fluorescent complexes with various organic compounds. If it gets into the human body, curium accumulates in bones, lungs, and liver, where it promotes cancer.\nAll known isotopes of curium are radioactive and have small critical mass for a nuclear chain reaction. The most stable isotope, 247Cm, has a half-life of 15.6\u00a0million years; the longest-lived curium isotopes predominantly emit alpha particles. Radioisotope thermoelectric generators can use the heat from this process, but this is hindered by the rarity and high cost of curium. Curium is used in making heavier actinides and the 238Pu radionuclide for power sources in artificial cardiac pacemakers and RTGs for spacecraft. It served as the \u03b1-source in the alpha particle X-ray spectrometers of several space probes, including the \"Sojourner\", \"Spirit\", \"Opportunity\", and \"Curiosity\" Mars rovers and the Philae lander on comet 67P/Churyumov\u2013Gerasimenko, to analyze the composition and structure of the surface.\nHistory.\nThough curium had likely been produced in previous nuclear experiments as well as the natural nuclear fission reactor at Oklo, Gabon, it was first intentionally synthesized, isolated and identified in 1944, at University of California, Berkeley, by Glenn T. Seaborg, Ralph A. James, and Albert Ghiorso. In their experiments, they used a cyclotron.\nCurium was chemically identified at the Metallurgical Laboratory (now Argonne National Laboratory), University of Chicago. It was the third transuranium element to be discovered even though it is the fourth in the series \u2013 the lighter element americium was still unknown.\nThe sample was prepared as follows: first plutonium nitrate solution was coated on a platinum foil of ~0.5\u00a0cm2 area, the solution was evaporated and the residue was converted into plutonium(IV) oxide (PuO2) by annealing. Following cyclotron irradiation of the oxide, the coating was dissolved with nitric acid and then precipitated as the hydroxide using concentrated aqueous ammonia solution. The residue was dissolved in perchloric acid, and further separation was done by ion exchange to yield a certain isotope of curium. The separation of curium and americium was so painstaking that the Berkeley group initially called those elements \"pandemonium\" (from Greek for \"all demons\" or \"hell\") and \"delirium\" (from Latin for \"madness\").\nCurium-242 was made in July\u2013August 1944 by bombarding 239Pu with \u03b1-particles to produce curium with the release of a neutron:\nCurium-242 was unambiguously identified by the characteristic energy of the \u03b1-particles emitted during the decay:\nThe half-life of this alpha decay was first measured as 5 months (150 days) and then corrected to 162.8 days.\nAnother isotope 240Cm was produced in a similar reaction in March 1945:\nThe \u03b1-decay half-life of 240Cm was determined as 26.8 days and later revised to 30.4 days.\nThe discovery of curium and americium in 1944 was closely related to the Manhattan Project, so the results were confidential and declassified only in 1945. Seaborg leaked the synthesis of the elements 95 and 96 on the U.S. radio show for children, the \"Quiz Kids\", five days before the official presentation at an American Chemical Society meeting on November 11, 1945, when one listener asked if any new transuranic element beside plutonium and neptunium had been discovered during the war. The discovery of curium (242Cm and 240Cm), its production, and its compounds was later patented listing only Seaborg as the inventor.\nThe element was named after Marie Curie and her husband Pierre Curie, who are known for discovering radium and for their work in radioactivity. It followed the example of gadolinium, a lanthanide element above curium in the periodic table, which was named after the explorer of rare-earth elements Johan Gadolin:\nThe first curium samples were barely visible, and were identified by their radioactivity. Louis Werner and Isadore Perlman made the first substantial sample of 30\u00a0\u03bcg curium-242 hydroxide at University of California, Berkeley in 1947 by bombarding americium-241 with neutrons. Macroscopic amounts of curium(III) fluoride were obtained in 1950 by W. W. T. Crane, J. C. Wallmann and B. B. Cunningham. Its magnetic susceptibility was very close to that of GdF3 providing the first experimental evidence for the +3 valence of curium in its compounds. Curium metal was produced only in 1951 by reduction of CmF3 with barium.\nCharacteristics.\nPhysical.\nA synthetic, radioactive element, curium is a hard, dense metal with a silvery-white appearance and physical and chemical properties resembling gadolinium. Its melting point of 1344\u00a0\u00b0C is significantly higher than that of the previous elements neptunium (637\u00a0\u00b0C), plutonium (639\u00a0\u00b0C) and americium (1176\u00a0\u00b0C). In comparison, gadolinium melts at 1312\u00a0\u00b0C. Curium boils at 3556\u00a0\u00b0C. With a density of 13.52\u00a0g/cm3, curium is lighter than neptunium (20.45\u00a0g/cm3) and plutonium (19.8\u00a0g/cm3), but heavier than most other metals. Of two crystalline forms of curium, \u03b1-Cm is more stable at ambient conditions. It has a hexagonal symmetry, space group P63/mmc, lattice parameters \"a\"\u00a0=\u00a0365\u00a0pm and \"c\"\u00a0=\u00a01182\u00a0pm, and four formula units per unit cell. The crystal consists of double-hexagonal close packing with the layer sequence ABAC and so is isotypic with \u03b1-lanthanum. At pressure &gt;23\u00a0GPa, at room temperature, \u03b1-Cm becomes \u03b2-Cm, which has face-centered cubic symmetry, space group Fmm and lattice constant \"a\"\u00a0=\u00a0493\u00a0pm. On further compression to 43\u00a0GPa, curium becomes an orthorhombic \u03b3-Cm structure similar to \u03b1-uranium, with no further transitions observed up to 52\u00a0GPa. These three curium phases are also called Cm I, II and III.\nCurium has peculiar magnetic properties. Its neighbor element americium shows no deviation from Curie-Weiss paramagnetism in the entire temperature range, but \u03b1-Cm transforms to an antiferromagnetic state upon cooling to 65\u201352\u00a0K, and \u03b2-Cm exhibits a ferrimagnetic transition at ~205\u00a0K. Curium pnictides show ferromagnetic transitions upon cooling: 244CmN and 244CmAs at 109\u00a0K, 248CmP at 73\u00a0K and 248CmSb at 162\u00a0K. The lanthanide analog of curium, gadolinium, and its pnictides, also show magnetic transitions upon cooling, but the transition character is somewhat different: Gd and GdN become ferromagnetic, and GdP, GdAs and GdSb show antiferromagnetic ordering.\nIn accordance with magnetic data, electrical resistivity of curium increases with temperature \u2013 about twice between 4 and 60\u00a0K \u2013 and then is nearly constant up to room temperature. There is a significant increase in resistivity over time (~) due to self-damage of the crystal lattice by alpha decay. This makes uncertain the true resistivity of curium (~). Curium's resistivity is similar to that of gadolinium, and the actinides plutonium and neptunium, but significantly higher than that of americium, uranium, polonium and thorium.\nUnder ultraviolet illumination, curium(III) ions show strong and stable yellow-orange fluorescence with a maximum in the range of 590\u2013640\u00a0nm depending on their environment. The fluorescence originates from the transitions from the first excited state 6D7/2 and the ground state 8S7/2. Analysis of this fluorescence allows monitoring interactions between Cm(III) ions in organic and inorganic complexes.\nChemical.\nCurium ion in solution almost always has a +3 oxidation state, the most stable oxidation state for curium. A +4 oxidation state is seen mainly in a few solid phases, such as CmO2 and CmF4. Aqueous curium(IV) is only known in the presence of strong oxidizers such as potassium persulfate, and is easily reduced to curium(III) by radiolysis and even by water itself. Chemical behavior of curium is different from the actinides thorium and uranium, and is similar to americium and many lanthanides. In aqueous solution, the Cm3+ ion is colorless to pale green; Cm4+ ion is pale yellow. The optical absorption of Cm3+ ion contains three sharp peaks at 375.4, 381.2 and 396.5\u00a0nm and their strength can be directly converted into the concentration of the ions. The +6 oxidation state has only been reported once in solution in 1978, as the curyl ion (): this was prepared from beta decay of americium-242 in the americium(V) ion . Failure to get Cm(VI) from oxidation of Cm(III) and Cm(IV) may be due to the high Cm4+/Cm3+ ionization potential and the instability of Cm(V).\nCurium ions are hard Lewis acids and thus form most stable complexes with hard bases. The bonding is mostly ionic, with a small covalent component. Curium in its complexes commonly exhibits a 9-fold coordination environment, with a tricapped trigonal prismatic molecular geometry.\nIsotopes.\nAbout 19 radioisotopes and 7 nuclear isomers, 233Cm to 251Cm, are known; none are stable. The longest half-lives are 15.6 million years (247Cm) and 348,000 years (248Cm). Other long-lived ones are 245Cm (8500 years), 250Cm (8300 years) and 246Cm (4760 years). Curium-250 is unusual: it mostly (~86%) decays by spontaneous fission. The most commonly used isotopes are 242Cm and 244Cm with the half-lives 162.8 days and 18.11 years, respectively.\nAll isotopes ranging from 242Cm to 248Cm, as well as 250Cm, undergo a self-sustaining nuclear chain reaction and thus in principle can be a nuclear fuel in a reactor. As in most transuranic elements, nuclear fission cross section is especially high for the odd-mass curium isotopes 243Cm, 245Cm and 247Cm. These can be used in thermal-neutron reactors, whereas a mixture of curium isotopes is only suitable for fast breeder reactors since the even-mass isotopes are not fissile in a thermal reactor and accumulate as burn-up increases. The mixed-oxide (MOX) fuel, which is to be used in power reactors, should contain little or no curium because neutron activation of 248Cm will create californium. Californium is a strong neutron emitter, and would pollute the back end of the fuel cycle and increase the dose to reactor personnel. Hence, if minor actinides are to be used as fuel in a thermal neutron reactor, the curium should be excluded from the fuel or placed in special fuel rods where it is the only actinide present.\nThe adjacent table lists the critical masses for curium isotopes for a sphere, without moderator or reflector. With a metal reflector (30\u00a0cm of steel), the critical masses of the odd isotopes are about 3\u20134\u00a0kg. When using water (thickness ~20\u201330\u00a0cm) as the reflector, the critical mass can be as small as 59\u00a0grams for 245Cm, 155\u00a0grams for 243Cm and 1550\u00a0grams for 247Cm. There is significant uncertainty in these critical mass values. While it is usually on the order of 20%, the values for 242Cm and 246Cm were listed as large as 371\u00a0kg and 70.1\u00a0kg, respectively, by some research groups.\nCurium is not currently used as nuclear fuel due to its low availability and high price. 245Cm and 247Cm have very small critical mass and so could be used in tactical nuclear weapons, but none are known to have been made. Curium-243 is not suitable for such, due to its short half-life and strong \u03b1 emission, which would cause excessive heat. Curium-247 would be highly suitable due to its long half-life, which is 647 times longer than plutonium-239 (used in many existing nuclear weapons).\nOccurrence.\nThe longest-lived isotope, 247Cm, has half-life 15.6\u00a0million years; so any primordial curium, that is, present on Earth when it formed, should have decayed by now. Its past presence as an extinct radionuclide is detectable as an excess of its primordial, long-lived daughter 235U. Traces of 242Cm may occur naturally in uranium minerals due to neutron capture and beta decay (238U \u2192 239Pu \u2192 240Pu \u2192 241Am \u2192 242Cm), though the quantities would be tiny and this has not been confirmed: even with \"extremely generous\" estimates for neutron absorption possibilities, the quantity of 242Cm present in 1\u00a0\u00d7\u00a0108\u00a0kg of 18% uranium pitchblende would not even be one atom. Traces of 247Cm are also probably brought to Earth in cosmic rays, but this also has not been confirmed. There is also the possibility of 244Cm being produced as the double beta decay daughter of natural 244Pu.\nCurium is made artificially in small amounts for research purposes. It also occurs as one of the waste products in spent nuclear fuel. Curium is present in nature in some areas used for nuclear weapons testing. Analysis of the debris at the test site of the United States' first thermonuclear weapon, Ivy Mike (1 November 1952, Enewetak Atoll), besides einsteinium, fermium, plutonium and americium also revealed isotopes of berkelium, californium and curium, in particular 245Cm, 246Cm and smaller quantities of 247Cm, 248Cm and 249Cm.\nAtmospheric curium compounds are poorly soluble in common solvents and mostly adhere to soil particles. Soil analysis revealed about 4,000 times higher concentration of curium at the sandy soil particles than in water present in the soil pores. An even higher ratio of about 18,000 was measured in loam soils.\nThe transuranium elements from americium to fermium, including curium, occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\nCurium, and other non-primordial actinides, have also been suspected to exist in the spectrum of Przybylski's Star.\nSynthesis.\nIsotope preparation.\nCurium is made in small amounts in nuclear reactors, and by now only kilograms of 242Cm and 244Cm have been accumulated, and grams or even milligrams for heavier isotopes. Hence the high price of curium, which has been quoted at 160\u2013185 USD per milligram, with a more recent estimate at US$2,000/g for 242Cm and US$170/g for 244Cm. In nuclear reactors, curium is formed from 238U in a series of nuclear reactions. In the first chain, 238U captures a neutron and converts into 239U, which via \u03b2\u2212 decay transforms into 239Np and 239Pu.\nFurther neutron capture followed by \u03b2\u2212-decay gives americium (241Am) which further becomes 242Cm:\nFor research purposes, curium is obtained by irradiating not uranium but plutonium, which is available in large amounts from spent nuclear fuel. A much higher neutron flux is used for the irradiation that results in a different reaction chain and formation of 244Cm:\nCurium-244 alpha decays to 240Pu, but it also absorbs neutrons, hence a small amount of heavier curium isotopes. Of those, 247Cm and 248Cm are popular in scientific research due to their long half-lives. But the production rate of 247Cm in thermal neutron reactors is low because it is prone to fission due to thermal neutrons. Synthesis of 250Cm by neutron capture is unlikely due to the short half-life of the intermediate 249Cm (64 min), which \u03b2\u2212 decays to the berkelium isotope 249Bk.\nThe above cascade of (n,\u03b3) reactions gives a mix of different curium isotopes. Their post-synthesis separation is cumbersome, so a selective synthesis is desired. Curium-248 is favored for research purposes due to its long half-life. The most efficient way to prepare this isotope is by \u03b1-decay of the californium isotope 252Cf, which is available in relatively large amounts due to its long half-life (2.65 years). About 35\u201350\u00a0mg of 248Cm is produced thus, per year. The associated reaction produces 248Cm with isotopic purity of 97%.\nAnother isotope, 245Cm, can be obtained for research, from \u03b1-decay of 249Cf; the latter isotope is produced in small amounts from \u03b2\u2212-decay of 249Bk.\nMetal preparation.\nMost synthesis routines yield a mix of actinide isotopes as oxides, from which a given isotope of curium needs to be separated. An example procedure could be to dissolve spent reactor fuel (e.g. MOX fuel) in nitric acid, and remove the bulk of the uranium and plutonium using a PUREX (Plutonium \u2013 URanium EXtraction) type extraction with tributyl phosphate in a hydrocarbon. The lanthanides and the remaining actinides are then separated from the aqueous residue (raffinate) by a diamide-based extraction to give, after stripping, a mixture of trivalent actinides and lanthanides. A curium compound is then selectively extracted using multi-step chromatographic and centrifugation techniques with an appropriate reagent. \"Bis\"-triazinyl bipyridine complex has been recently proposed as such reagent which is highly selective to curium. Separation of curium from the very chemically similar americium can also be done by treating a slurry of their hydroxides in aqueous sodium bicarbonate with ozone at elevated temperature. Both americium and curium are present in solutions mostly in the +3 valence state; americium oxidizes to soluble Am(IV) complexes, but curium stays unchanged and so can be isolated by repeated centrifugation.\nMetallic curium is obtained by reduction of its compounds. Initially, curium(III) fluoride was used for this purpose. The reaction was done in an environment free of water and oxygen, in an apparatus made of tantalum and tungsten, using elemental barium or lithium as reducing agents.\nAnother possibility is reduction of curium(IV) oxide using a magnesium-zinc alloy in a melt of magnesium chloride and magnesium fluoride.\nCompounds and reactions.\nOxides.\nCurium readily reacts with oxygen forming mostly Cm2O3 and CmO2 oxides, but the divalent oxide CmO is also known. Black CmO2 can be obtained by burning curium oxalate (), nitrate (), or hydroxide in pure oxygen. Upon heating to 600\u2013650\u00a0\u00b0C in vacuum (about 0.01\u00a0Pa), it transforms into the whitish Cm2O3:\nOr, Cm2O3 can be obtained by reducing CmO2 with molecular hydrogen:\nAlso, a number of ternary oxides of the type M(II)CmO3 are known, where M stands for a divalent metal, such as barium.\nThermal oxidation of trace quantities of curium hydride (CmH2\u20133) has been reported to give a volatile form of CmO2 and the volatile trioxide CmO3, one of two known examples of the very rare +6 state for curium. Another observed species was reported to behave similar to a supposed plutonium tetroxide and was tentatively characterized as CmO4, with curium in the extremely rare +8 state; but new experiments seem to indicate that CmO4 does not exist, and have cast doubt on the existence of PuO4 as well.\nHalides.\nThe colorless curium(III) fluoride (CmF3) can be made by adding fluoride ions into curium(III)-containing solutions. The brown tetravalent curium(IV) fluoride (CmF4) on the other hand is only obtained by reacting curium(III) fluoride with molecular fluorine:\nA series of ternary fluorides are known of the form A7Cm6F31 (A = alkali metal).\nThe colorless curium(III) chloride (CmCl3) is made by reacting curium hydroxide (Cm(OH)3) with anhydrous hydrogen chloride gas. It can be further turned into other halides such as curium(III) bromide (colorless to light green) and curium(III) iodide (colorless), by reacting it with the ammonia salt of the corresponding halide at temperatures of ~400\u2013450\u00a0\u00b0C:\nOr, one can heat curium oxide to ~600\u00b0C with the corresponding acid (such as hydrobromic for curium bromide). Vapor phase hydrolysis of curium(III) chloride gives curium oxychloride:\nChalcogenides and pnictides.\nSulfides, selenides and tellurides of curium have been obtained by treating curium with gaseous sulfur, selenium or tellurium in vacuum at elevated temperature. Curium pnictides of the type CmX are known for nitrogen, phosphorus, arsenic and antimony. They can be prepared by reacting either curium(III) hydride (CmH3) or metallic curium with these elements at elevated temperature.\nOrganocurium compounds and biological aspects.\nOrganometallic complexes analogous to uranocene are known also for other actinides, such as thorium, protactinium, neptunium, plutonium and americium. Molecular orbital theory predicts a stable \"curocene\" complex (\u03b78-C8H8)2Cm, but it has not been reported experimentally yet.\nFormation of the complexes of the type (BTP = 2,6-di(1,2,4-triazin-3-yl)pyridine), in solutions containing n-C3H7-BTP and Cm3+ ions has been confirmed by EXAFS. Some of these BTP-type complexes selectively interact with curium and thus are useful for separating it from lanthanides and another actinides. Dissolved Cm3+ ions bind with many organic compounds, such as hydroxamic acid, urea, fluorescein and adenosine triphosphate. Many of these compounds are related to biological activity of various microorganisms. The resulting complexes show strong yellow-orange emission under UV light excitation, which is convenient not only for their detection, but also for studying interactions between the Cm3+ ion and the ligands via changes in the half-life (of the order ~0.1 ms) and spectrum of the fluorescence.\nThere are a few reports on biosorption of Cm3+ by bacteria and archaea, and in the laboratory both americium and curium were found to support the growth of methylotrophs.\nApplications.\nRadionuclides.\nCurium is one of the most radioactive isolable elements. Its two most common isotopes 242Cm and 244Cm are strong alpha emitters (energy 6\u00a0MeV); they have fairly short half-lives, 162.8 days and 18.1 years, and give as much as 120\u00a0W/g and 3\u00a0W/g of heat, respectively. Therefore, curium can be used in its common oxide form in radioisotope thermoelectric generators like those in spacecraft. This application has been studied for the 244Cm isotope, while 242Cm was abandoned due to its prohibitive price, around 2000\u00a0USD/g. 243Cm with a ~30-year half-life and good energy yield of ~1.6\u00a0W/g could be a suitable fuel, but it gives significant amounts of harmful gamma and beta rays from radioactive decay products. As an \u03b1-emitter, 244Cm needs much less radiation shielding, but it has a high spontaneous fission rate, and thus a lot of neutron and gamma radiation. Compared to a competing thermoelectric generator isotope such as 238Pu, 244Cm emits 500 times more neutrons, and its higher gamma emission requires a shield that is 20 times thicker\u2014 of lead for a 1\u00a0kW source, compared to for 238Pu. Therefore, this use of curium is currently considered impractical.\nA more promising use of 242Cm is for making 238Pu, a better radioisotope for thermoelectric generators such as in heart pacemakers. The alternate routes to 238Pu use the (n,\u03b3) reaction of 237Np, or deuteron bombardment of uranium, though both reactions always produce 236Pu as an undesired by-product since the latter decays to 232U with strong gamma emission. Curium is a common starting material for making higher transuranic and superheavy elements. Thus, bombarding 248Cm with neon (22Ne), magnesium (26Mg), or calcium (48Ca) yields isotopes of seaborgium (265Sg), hassium (269Hs and 270Hs), and livermorium (292Lv, 293Lv, and possibly 294Lv). Californium was discovered when a microgram-sized target of curium-242 was irradiated with 35\u00a0MeV alpha particles using the cyclotron at Berkeley:\nOnly about 5,000 atoms of californium were produced in this experiment.\nThe odd-mass curium isotopes 243Cm, 245Cm, and 247Cm are all highly fissile and can release additional energy in a thermal spectrum nuclear reactor. All curium isotopes are fissionable in fast-neutron reactors. This is one of the motives for minor actinide separation and transmutation in the nuclear fuel cycle, helping to reduce the long-term radiotoxicity of used, or spent nuclear fuel.\nX-ray spectrometer.\nThe most practical application of 244Cm\u2014though rather limited in total volume\u2014is as \u03b1-particle source in alpha particle X-ray spectrometers (APXS). These instruments were installed on the Sojourner, Mars, Mars 96, Mars Exploration Rovers and Philae comet lander, as well as the Mars Science Laboratory to analyze the composition and structure of the rocks on the surface of planet Mars. APXS was also used in the Surveyor 5\u20137 moon probes but with a 242Cm source.\nAn elaborate APXS setup has a sensor head containing six curium sources with a total decay rate of several tens of millicuries (roughly one gigabecquerel). The sources are collimated on a sample, and the energy spectra of the alpha particles and protons scattered from the sample are analyzed (proton analysis is done only in some spectrometers). These spectra contain quantitative information on all major elements in the sample except for hydrogen, helium and lithium.\nSafety.\nDue to its radioactivity, curium and its compounds must be handled in appropriate labs under special arrangements. While curium itself mostly emits \u03b1-particles which are absorbed by thin layers of common materials, some of its decay products emit significant fractions of beta and gamma rays, which require a more elaborate protection. If consumed, curium is excreted within a few days and only 0.05% is absorbed in the blood. From there, ~45% goes to the liver, 45% to the bones, and the remaining 10% is excreted. In bone, curium accumulates on the inside of the interfaces to the bone marrow and does not significantly redistribute with time; its radiation destroys bone marrow and thus stops red blood cell creation. The biological half-life of curium is about 20 years in the liver and 50 years in the bones. Curium is absorbed in the body much more strongly via inhalation, and the allowed total dose of 244Cm in soluble form is 0.3\u00a0\u03bcCi. Intravenous injection of 242Cm- and 244Cm-containing solutions to rats increased the incidence of bone tumor, and inhalation promoted lung and liver cancer.\nCurium isotopes are inevitably present in spent nuclear fuel (about 20 g/tonne). The isotopes 245Cm\u2013248Cm have decay times of thousands of years and must be removed to neutralize the fuel for disposal. Such a procedure involves several steps, where curium is first separated and then converted by neutron bombardment in special reactors to short-lived nuclides. This procedure, nuclear transmutation, while well documented for other elements, is still being developed for curium."}
{"id": "5676", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=5676", "title": "Californium", "text": "Californium is a synthetic chemical element; it has symbol Cf and atomic number 98. It was first synthesized in 1950 at Lawrence Berkeley National Laboratory (then the University of California Radiation Laboratory) by bombarding curium with alpha particles (helium-4 ions). It is an actinide element, the sixth transuranium element to be synthesized, and has the second-highest atomic mass of all elements that have been produced in amounts large enough to see with the naked eye (after einsteinium). It was named after the university and the U.S. state of California.\nTwo crystalline forms exist at normal pressure: one above and one below . A third form exists at high pressure. Californium slowly tarnishes in air at room temperature. Californium compounds are dominated by the +3 oxidation state. The most stable of californium's twenty known isotopes is californium-251, with a half-life of 898 years. This short half-life means the element is not found in significant quantities in the Earth's crust. Cf, with a half-life of about 2.645 years, is the most common isotope used and is produced at Oak Ridge National Laboratory (ORNL) in the United States and Research Institute of Atomic Reactors in Russia.\nCalifornium is one of the few transuranium elements with practical uses. Most of these applications exploit the fact that certain isotopes of californium emit neutrons. For example, californium can be used to help start up nuclear reactors, and it is used as a source of neutrons when studying materials using neutron diffraction and neutron spectroscopy. It can also be used in nuclear synthesis of higher mass elements; oganesson (element 118) was synthesized by bombarding californium-249 atoms with calcium-48 ions. Users of californium must take into account radiological concerns and the element's ability to disrupt the formation of red blood cells by bioaccumulating in skeletal tissue.\nCharacteristics.\nPhysical properties.\nCalifornium is a silvery-white actinide metal with a melting point of and an estimated boiling point of . The pure metal is malleable and is easily cut with a knife. Californium metal starts to vaporize above when exposed to a vacuum. Below californium metal is either ferromagnetic or ferrimagnetic (it acts like a magnet), between 48 and 66\u00a0K it is antiferromagnetic (an intermediate state), and above it is paramagnetic (external magnetic fields can make it magnetic). It forms alloys with lanthanide metals but little is known about the resulting materials.\nThe element has two crystalline forms at standard atmospheric pressure: a double-hexagonal close-packed form dubbed alpha (\u03b1) and a face-centered cubic form designated beta (\u03b2). The \u03b1 form exists below 600\u2013800\u00a0\u00b0C with a density of 15.10\u00a0g/cm3 and the \u03b2 form exists above 600\u2013800\u00a0\u00b0C with a density of 8.74\u00a0g/cm. At 48\u00a0GPa of pressure the \u03b2 form changes into an orthorhombic crystal system due to delocalization of the atom's 5f electrons, which frees them to bond.\nThe bulk modulus of a material is a measure of its resistance to uniform pressure. Californium's bulk modulus is , which is similar to trivalent lanthanide metals but smaller than more familiar metals, such as aluminium (70\u00a0GPa).\nChemical properties and compounds.\nCalifornium exhibits oxidation states of 4, 3, or 2. It typically forms eight or nine bonds to surrounding atoms or ions. Its chemical properties are predicted to be similar to other primarily 3+ valence actinide elements and the element dysprosium, which is the lanthanide above californium in the periodic table. Compounds in the +4 oxidation state are strong oxidizing agents and those in the +2 state are strong reducing agents.\nThe element slowly tarnishes in air at room temperature, with the rate increasing when moisture is added. Californium reacts when heated with hydrogen, nitrogen, or a chalcogen (oxygen family element); reactions with dry hydrogen and aqueous mineral acids are rapid. \nCalifornium is only water-soluble as the californium(III) cation. Attempts to reduce or oxidize the +3 ion in solution have failed. The element forms a water-soluble chloride, nitrate, perchlorate, and sulfate and is precipitated as a fluoride, oxalate, or hydroxide. Californium is the heaviest actinide to exhibit covalent properties, as is observed in the californium borate.\nIsotopes.\nTwenty isotopes of californium are known (mass number ranging from 237 to 256); the most stable are Cf with half-life 898 years, Cf with half-life 351 years, Cf at 13.08 years, and Cf at 2.645 years. All other isotopes have half-life shorter than a year, and most of these have half-lives less than 20 minutes.\nCf is formed by beta decay of berkelium-249, and most other californium isotopes are made by subjecting berkelium to intense neutron radiation in a nuclear reactor. Though californium-251 has the longest half-life, its production yield is only 10% due to its tendency to collect neutrons (high neutron capture) and its tendency to interact with other particles (high neutron cross section).\nCf is a very strong neutron emitter, which makes it extremely radioactive and harmful. Cf, 96.9% of the time, alpha decays to curium-248; the other 3.1% of decays are spontaneous fission. One microgram (\u03bcg) of Cf emits 2.3\u00a0million neutrons per second, an average of 3.7 neutrons per spontaneous fission. Most other isotopes of californium, alpha decay to curium (atomic number 96).\nHistory.\nCalifornium was first made at University of California Radiation Laboratory, Berkeley, by physics researchers Stanley Gerald Thompson, Kenneth Street Jr., Albert Ghiorso, and Glenn T. Seaborg, about February 9, 1950. It was the sixth transuranium element to be discovered; the team announced its discovery on March 17, 1950.\nTo produce californium, a microgram-size target of curium-242 () was bombarded with 35\u00a0MeV alpha particles () in the cyclotron at Berkeley, which produced californium-245 () plus one free neutron ().\nTo identify and separate out the element, ion exchange and adsorsion methods were undertaken. Only about 5,000 atoms of californium were produced in this experiment, and these atoms had a half-life of 44\u00a0minutes.\nThe discoverers named the new element after the university and the state. This was a break from the convention used for elements 95 to 97, which drew inspiration from how the elements directly above them in the periodic table were named. However, the element directly above element 98 in the periodic table, dysprosium, has a name that means \"hard to get at\", so the researchers decided to set aside the informal naming convention. They added that \"the best we can do is to point out [that] ... searchers a century ago found it difficult to get to California\".\nWeighable amounts of californium were first produced by the irradiation of plutonium targets at Materials Testing Reactor at National Reactor Testing Station, eastern Idaho; these findings were reported in 1954. The high spontaneous fission rate of californium-252 was observed in these samples. The first experiment with californium in concentrated form occurred in 1958. The isotopes Cf to Cf were isolated that same year from a sample of plutonium-239 that had been irradiated with neutrons in a nuclear reactor for five years. Two years later, in 1960, Burris Cunningham and James Wallman of Lawrence Radiation Laboratory of the University of California created the first californium compounds\u2014californium trichloride, californium(III) oxychloride, and californium oxide\u2014by treating californium with steam and hydrochloric acid.\nThe High Flux Isotope Reactor (HFIR) at ORNL in Oak Ridge, Tennessee, started producing small batches of californium in the 1960s. By 1995, HFIR nominally produced of californium annually. Plutonium supplied by the United Kingdom to the United States under the 1958 US\u2013UK Mutual Defence Agreement was used for making californium.\nThe Atomic Energy Commission sold Cf to industrial and academic customers in the early 1970s for $10/microgram, and an average of of Cf were shipped each year from 1970 to 1990. Californium metal was first prepared in 1974 by Haire and Baybarz, who reduced californium(III) oxide with lanthanum metal to obtain microgram amounts of sub-micrometer thick films.\nOccurrence.\nTraces of californium can be found near facilities that use the element in mineral prospecting and in medical treatments. The element is fairly insoluble in water, but it adheres well to ordinary soil; and concentrations of it in the soil can be 500 times higher than in the water surrounding the soil particles.\nNuclear fallout from atmospheric nuclear weapons testing prior to 1980 contributed a small amount of californium to the environment. Californium-249, -252, -253, and -254 have been observed in the radioactive dust collected from the air after a nuclear explosion. Californium is not a major radionuclide at United States Department of Energy legacy sites since it was not produced in large quantities.\nCalifornium was once believed to be produced in supernovas, as their decay matches the 60-day half-life of Cf. However, subsequent studies failed to demonstrate any californium spectra, and supernova light curves are now thought to follow the decay of nickel-56.\nThe transuranic elements americium to fermium, including californium, occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\nSpectral lines of californium, along with those of several other non-primordial elements, were detected in Przybylski's Star in 2008.\nProduction.\nCalifornium is produced in nuclear reactors and particle accelerators. Californium-250 is made by bombarding berkelium-249 (Bk) with neutrons, forming berkelium-250 (Bk) via neutron capture (n,\u03b3) which, in turn, quickly beta decays (\u03b2) to californium-250 (Cf) in the following reaction:\nBombardment of Cf with neutrons produces Cf and Cf.\nProlonged irradiation of americium, curium, and plutonium with neutrons produces milligram amounts of Cf and microgram amounts of Cf. As of 2006, curium isotopes 244 to 248 are irradiated by neutrons in special reactors to produce mainly californium-252 with lesser amounts of isotopes 249 to 255.\nMicrogram quantities of Cf are available for commercial use through the U.S. Nuclear Regulatory Commission. Only two sites produce Cf: Oak Ridge National Laboratory in the U.S., and the Research Institute of Atomic Reactors in Dimitrovgrad, Russia. As of 2003, the two sites produce 0.25 grams and 0.025 grams of Cf per year, respectively.\nThree californium isotopes with significant half-lives are produced, requiring a total of 15 neutron captures by uranium-238 without nuclear fission or alpha decay occurring during the process. Cf is at the end of a production chain that starts with uranium-238, and includes several isotopes of plutonium, americium, curium, and berkelium, and the californium isotopes 249 to 253 (see diagram).\nApplications.\nCalifornium-252 has a number of specialized uses as a strong neutron emitter; it produces 139\u00a0million neutrons per microgram per minute. This property makes it useful as a startup neutron source for some nuclear reactors and as a portable (non-reactor based) neutron source for neutron activation analysis to detect trace amounts of elements in samples. Neutrons from californium are used as a treatment of certain cervical and brain cancers where other radiation therapy is ineffective. It has been used in educational applications since 1969 when Georgia Institute of Technology got a loan of 119\u00a0\u03bcg of Cf from the Savannah River Site. It is also used with online elemental coal analyzers and bulk material analyzers in the coal and cement industries.\nNeutron penetration into materials makes californium useful in detection instruments such as fuel rod scanners; neutron radiography of aircraft and weapons components to detect corrosion, bad welds, cracks and trapped moisture; and in portable metal detectors. Neutron moisture gauges use Cf to find water and petroleum layers in oil wells, as a portable neutron source for gold and silver prospecting for on-the-spot analysis, and to detect ground water movement. The main uses of Cf in 1982 were, reactor start-up (48.3%), fuel rod scanning (25.3%), and activation analysis (19.4%). By 1994, most Cf was used in neutron radiography (77.4%), with fuel rod scanning (12.1%) and reactor start-up (6.9%) as important but secondary uses. In 2021, fast neutrons from Cf were used for wireless data transmission.\nCf has a very small calculated critical mass of about , high lethality, and a relatively short period of toxic environmental irradiation. The low critical mass of californium led to some exaggerated claims about possible uses for the element.\nIn October 2006, researchers announced that three atoms of oganesson (element 118) had been identified at Joint Institute for Nuclear Research in Dubna, Russia, from bombarding Cf with calcium-48, making it the heaviest element ever made. The target contained about 10\u00a0mg of Cf deposited on a titanium foil of 32\u00a0cm area. Californium has also been used to produce other transuranic elements; for example, lawrencium was first synthesized in 1961 by bombarding californium with boron nuclei.\nPrecautions.\nCalifornium that bioaccumulates in skeletal tissue releases radiation that disrupts the body's ability to form red blood cells. The element plays no natural biological role in any organism due to its intense radioactivity and low concentration in the environment.\nCalifornium can enter the body from ingesting contaminated food or drinks or by breathing air with suspended particles of the element. Once in the body, only 0.05% of the californium will reach the bloodstream. About 65% of that californium will be deposited in the skeleton, 25% in the liver, and the rest in other organs, or excreted, mainly in urine. Half of the californium deposited in the skeleton and liver are gone in 50 and 20 years, respectively. Californium in the skeleton adheres to bone surfaces before slowly migrating throughout the bone.\nThe element is most dangerous if taken into the body. In addition, californium-249 and californium-251 can cause tissue damage externally, through gamma ray emission. Ionizing radiation emitted by californium on bone and in the liver can cause cancer."}
{"id": "5677", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=5677", "title": "Cerebral Spinal Fluid", "text": ""}
{"id": "5679", "revid": "40943757", "url": "https://en.wikipedia.org/wiki?curid=5679", "title": "Christian Social Union in Bavaria", "text": " \nThe Christian Social Union in Bavaria (German: , CSU) is a Christian democratic and conservative political party in Germany. Having a regionalist identity, the CSU operates only in Bavaria while its larger counterpart, the Christian Democratic Union (CDU), operates in the other fifteen states of Germany. It differs from the CDU by being somewhat more conservative in social matters, following Catholic social teaching. The CSU is considered the \"de facto\" successor of the Weimar-era Catholic Bavarian People's Party.\nAt the federal level, the CSU forms a common faction in the Bundestag with the CDU which is frequently referred to as the Union Faction (\"die Unionsfraktion\") or simply CDU/CSU. The CSU has had 43 seats in the Bundestag since the 2021 federal election, making it currently the second smallest of the eight parties represented. The CSU is a member of the European People's Party and the International Democracy Union.\nParty leader Markus S\u00f6der serves as Minister-President of Bavaria, a position that CSU representatives have held from 1946 to 1954 and again since 1957. From 1962 to 2008 and from 2013 to 2018, the CSU had the absolute majority in the Bavarian Landtag.\nHistory.\nFranz Josef Strau\u00df (1915\u20131988) had left behind the strongest legacy as a leader of the party, having led the party from 1961 until his death in 1988. His political career in the federal cabinet was unique in that he had served in four ministerial posts in the years between 1953 and 1969. From 1978 until his death in 1988, Strau\u00df served as the Minister-President of Bavaria. Strau\u00df was the first leader of the CSU to be a candidate for the German chancellery in 1980. In the 1980 federal election, Strau\u00df ran against the incumbent Helmut Schmidt of the Social Democratic Party of Germany (SPD) but lost thereafter as the SPD and the Free Democratic Party (FDP) managed to secure an absolute majority together, forming a social-liberal coalition.\nThe CSU has led the Bavarian state government since it came into existence in 1946, save from 1954 to 1957 when the SPD formed a state government in coalition with the Bavaria Party and the state branches of the GB/BHE and FDP.\nInitially, the separatist Bavaria Party (BP) successfully competed for the same electorate as the CSU, as both parties saw and presented themselves as successors to the BVP. The CSU was ultimately able to win this power struggle for itself. Among other things, the BP was involved in the \"casino affair\" under dubious circumstances by the CSU at the end of the 1950s and lost considerable prestige and votes. In the 1966 state election, the BP finally left the state parliament.\nBefore the 2008 elections in Bavaria, the CSU perennially achieved absolute majorities at the state level by itself. This level of dominance is unique among Germany's 16 states. Edmund Stoiber took over the CSU leadership in 1999. He ran for Chancellor of Germany in 2002, but his preferred CDU/CSU\u2013FDP coalition lost against the SPD candidate Gerhard Schr\u00f6der's SPD\u2013Green alliance.\nIn the 2003 Bavarian state election, the CSU won 60.7% of the vote and 124 of 180 seats in the state parliament. This was the first time any party had won a two-thirds majority in a German state parliament. \"The Economist\" later suggested that this exceptional result was due to a backlash against Schr\u00f6der's government in Berlin. The CSU's popularity declined in subsequent years. Stoiber stepped down from the posts of Minister-President and CSU chairman in September 2007. A year later, the CSU lost its majority in the 2008 Bavarian state election, with its vote share dropping from 60.7% to 43.4%. The CSU remained in power by forming a coalition with the FDP. In the 2009 general election, the CSU received only 42.5% of the vote in Bavaria in the 2009 election, which by then constituted its weakest showing in the party's history.\nThe CSU made gains in the 2013 Bavarian state election and the 2013 federal election, which were held a week apart in September 2013. The CSU regained their majority in the Bavarian Landtag and remained in government in Berlin. They had three ministers in the Fourth Merkel cabinet, namely Horst Seehofer (Minister of the Interior, Building and Community), Andreas Scheuer (Minister of Transport and Digital Infrastructure) and Gerd M\u00fcller (Minister for Economic Cooperation and Development).\nThe 2018 Bavarian state election yielded the worst result for the CSU in the state elections (top candidate Markus S\u00f6der) since 1950 with 37.2% of votes, a decline of over ten percentage points compared to the last result in 2013. After that, the CSU had to form a new coalition government with the minor partner Free Voters of Bavaria.\nThe 2021 German federal election saw the worst election result ever for the Union. The CSU also had a weak showing with 5.2% of votes nationally and 31.7% of the total in Bavaria.\nRelationship with the CDU.\nThe CSU is the sister party of the Christian Democratic Union (CDU). Together, they are called the Union. The CSU operates only within Bavaria, and the CDU operates in all states other than Bavaria. While virtually independent, at the federal level the parties form a common CDU/CSU faction. No Chancellor has ever come from the CSU, although Strau\u00df and Edmund Stoiber were CDU/CSU candidates for Chancellor in the 1980 federal election and the 2002 federal election, respectively, which were both won by the Social Democratic Party of Germany (SPD). Below the federal level, the parties are entirely independent.\nSince its formation, the CSU has been more conservative than the CDU. CSU and the state of Bavaria decided not to sign the \"Grundgesetz\" of the Federal Republic of Germany as they could not agree with the division of Germany into two states after World War II. Although Bavaria like all German states has a separate police and justice system (distinctive and non-federal), the CSU has actively participated in all political affairs of the German Parliament, the German government, the German Bundesrat, the parliamentary elections of the German President, the European Parliament and meetings with Mikhail Gorbachev in Russia.\nLike the CDU, the CSU is pro-European, although some Eurosceptic tendencies were shown in the past.\nLeaders.\nMinisters-president.\nThe CSU has contributed eleven of the twelve Ministers-President of Bavaria since 1945, with only Wilhelm Hoegner (1945\u20131946, 1954\u20131957) of the SPD also holding the office."}
{"id": "5680", "revid": "13560851", "url": "https://en.wikipedia.org/wiki?curid=5680", "title": "CEO", "text": ""}
{"id": "5681", "revid": "27556023", "url": "https://en.wikipedia.org/wiki?curid=5681", "title": "Corporate title", "text": "Corporate titles or business titles are given to corporate officers to show what duties and responsibilities they have in the organization. Such titles are used by publicly and privately held for-profit corporations, cooperatives, non-profit organizations, educational institutions, partnerships, and sole proprietorships that also confer corporate titles.\nVariations.\nThere are considerable variations in the composition and responsibilities of corporate titles.\nWithin the corporate office or corporate center of a corporation, some corporations have a chairman and chief executive officer (CEO) as the top-ranking executive, while the number two is the president and chief operating officer (COO); other corporations have a president and CEO but no official deputy. Typically, senior managers are \"higher\" than vice presidents, although many times a senior officer may also hold a vice president title, such as executive vice president and chief financial officer (CFO). The board of directors is technically not part of management itself, although its chairman may be considered part of the corporate office if he or she is an executive chairman.\nA corporation often consists of different businesses, whose senior executives report directly to the CEO or COO, but that depends on the form of the business. If organized as a division then the top manager is often known as an executive vice president (EVP). If that business is a subsidiary which has considerably more independence, then the title might be chairman and CEO.\nIn many countries, particularly in Europe and Asia, there is a separate executive board for day-to-day business and supervisory board (elected by shareholders) for control purposes. In these countries, the CEO presides over the executive board and the chairman presides over the supervisory board, and these two roles will always be held by different people. This ensures a distinction between management by the executive board and governance by the supervisory board. This seemingly allows for clear lines of authority. There is a strong parallel here with the structure of government, which tends to separate the political cabinet from the management civil service.\nIn the United States and other countries that follow a single-board corporate structure, the board of directors (elected by the shareholders) is often equivalent to the European or Asian supervisory board, while the functions of the executive board may be vested either in the board of directors or in a separate committee, which may be called an operating committee (J.P. Morgan Chase), management committee (Goldman Sachs), executive committee (Lehman Brothers), executive council (Hewlett-Packard), or executive board (HeiG) composed of the division/subsidiary heads and senior officers that report directly to the CEO.\nUnited States.\nState laws in the United States traditionally required certain positions to be created within every corporation, such as president, secretary and treasurer. Today, the approach under the \"Model Business Corporation Act\", which is employed in many states, is to grant corporations discretion in determining which titles to have, with the only mandated organ being the board of directors.\nSome states that do not employ the MBCA continue to require that certain offices be established. Under the law of Delaware, where most large US corporations are established, stock certificates must be signed by two officers with titles specified by law (e.g. a president and secretary or a president and treasurer). Every corporation incorporated in California must have a chairman of the board or a president (or both), as well as a secretary and a chief financial officer.\nLimited liability company (LLC)-structured companies are generally run directly by their members, but the members can agree to appoint officers such as a CEO or to appoint \"managers\" to operate the company.\nAmerican companies are generally led by a CEO. In some companies, the CEO also has the title of \"president\". In other companies, a president is a different person, and the primary duties of the two positions are defined in the company's bylaws (or the laws of the governing legal jurisdiction). Many companies also have a CFO, a COO and other senior positions such as chief legal officer (CLO), chief strategy officer (CSO), chief marketing officer (CMO), etc. that report to the president and CEO. The next level, which are not executive positions, is middle management and may be called \"vice presidents\", \"directors\" or \"managers\", depending on the size and required managerial depth of the company.\nUnited Kingdom.\nIn British English, the title of managing director is broadly synonymous with that of chief executive officer. Managing directors do not have any particular authority under the \"Companies Act\" in the UK, but do have implied authority based on the general understanding of what their position entails, as well as any authority expressly delegated by the board of directors.\nJapan and South Korea.\nIn Japan, corporate titles are roughly standardized across companies and organizations; although there is variation from company to company, corporate titles within a company are always consistent, and the large companies in Japan generally follow the same outline. These titles are the formal titles that are used on business cards. Korean corporate titles are similar to those of Japan.\nLegally, Japanese and Korean companies are only required to have a board of directors with at least one representative director. In Japanese, a company director is called a \"torishimariyaku\" (\u53d6\u7de0\u5f79) and a representative director is called a \"daihy\u014d torishimariyaku\" (\u4ee3\u8868\u53d6\u7de0\u5f79). The equivalent Korean titles are \"isa\" (\uc774\uc0ac, \u7406\u4e8b) and \"daepyo-isa\" (\ub300\ud45c\uc774\uc0ac, \u4ee3\u8868\u7406\u4e8b). These titles are often combined with lower titles, e.g. \"senmu torishimariyaku\" or \"j\u014dmu torishimariyaku\" for Japanese executives who are also board members. Most Japanese companies also have statutory auditors, who operate alongside the board of directors in supervisory roles.\nUnder the commercial code in Japan, \"Jugy\u014din\" (\u5f93\u696d\u54e1) meaning the \"employee\", is different from \"Kaishain\" (\u4f1a\u793e\u54e1), meaning the \"stockholders\".\nThe typical structure of executive titles in large companies includes the following:\nThe top management group, comprising \"jomu\"/\"sangmu\" and above, is often referred to collectively as \"cadre\" or \"senior management\" (\u5e79\u90e8 or \u91cd\u5f79; \"kambu\" or \"juyaku\" in Japanese; \"ganbu\" or \"jungy\u014fk\" in Korean).\nSome Japanese and Korean companies have also adopted American-style titles, but these are not yet widespread and their usage varies. For example, although there is a Korean translation for \"chief operating officer\" (\"\ucd5c\uace0\uc6b4\uc601\ucc45\uc784\uc790, choego uny\u014fng chaegimja\"), not companies have yet adopted it with the exception of a few multi-nationals such as Samsung and CJ (a spin-off from Samsung), while the CFO title is often used alongside other titles such as \"bu-sajang\" (SEVP) or \"J\u014fnmu\" (EVP).\nSince the late 1990s, many Japanese companies have introduced the title of \"shikk\u014d yakuin\" (\u57f7\u884c\u5f79\u54e1) or 'officer', seeking to emulate the separation of directors and officers found in American companies. In 2002, the statutory title of \"shikk\u014d yaku\" (\u57f7\u884c\u5f79) was introduced for use in companies that introduced a three-committee structure in their board of directors. The titles are frequently given to \"buch\u014d\" and higher-level personnel. Although the two titles are very similar in intent and usage, there are several legal distinctions: \"shikk\u014d yaku\" make their own decisions in the course of performing work delegated to them by the board of directors, and are considered managers of the company rather than employees, with a legal status similar to that of directors. \"Shikk\u014d yakuin\" are considered employees of the company that follow the decisions of the board of directors, although in some cases directors may have the \"shikk\u014d yakuin\" title as well.\nSenior management.\nThe highest-level executives in senior management usually have titles beginning with \"chief\" and ending with \"officer\", forming what is often called the \"C-suite\", or \"CxO\", where \"x\" is a variable that could be any functional area (not to be confused with CXO). The traditional three such officers are CEO, COO, and CFO. Depending on the management structure, titles may exist instead of, or be blended/overlapped with, other traditional executive titles, such as \"president\", various designations of \"vice presidents\" (e.g. VP of marketing), and \"general managers\" or \"directors\" of various divisions (such as director of marketing); the latter may or may not imply membership of the \"board of directors\".\nCertain other prominent positions have emerged, some of which are sector-specific. For example, chief audit executive (CAE), chief procurement officer (CPO) and chief risk officer (CRO) positions are often found in many types of financial services companies. Technology companies of all sorts now tend to have a chief technology officer (CTO) to manage technology development. A chief information officer (CIO) oversees information technology (IT) matters, either in companies that specialize in IT or in any kind of company that relies on it for supporting infrastructure.\nMany companies now also have a chief marketing officer (CMO), particularly mature companies in competitive sectors, where brand management is a high priority. A chief value officer (CVO) is introduced in companies where business processes and organizational entities are focused on the creation and maximization of value. Approximately 50% of the S&amp;P 500 companies have created a chief strategy officer (CSO) in their top management team to lead strategic planning and manage inorganic growth, which provides a long range perspective versus the tactical view of the COO or CFO. This function often replaces a COO on the C-Suite team, in cases where the company wants to focus on growth rather than efficiency and cost containment. A chief administrative officer (CAO) may be found in many large complex organizations that have various departments or divisions. Additionally, many companies now call their top diversity leadership position the chief diversity officer (CDO). However, this and many other nontraditional and lower-ranking titles are not universally recognized as corporate officers, and they tend to be specific to particular organizational cultures or the preferences of employees.\nSpecific corporate officer positions.\nChairman of the board \u2013 presiding officer of the corporate board of directors. The chairman influences the board of directors, which in turn elects and removes the officers of a corporation and oversees the human, financial, environmental and technical operations of a corporation."}
{"id": "5683", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=5683", "title": "Computer expo", "text": ""}
