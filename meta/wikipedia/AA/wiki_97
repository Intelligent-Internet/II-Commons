{"id": "10799", "revid": "5229428", "url": "https://en.wikipedia.org/wiki?curid=10799", "title": "Film theory", "text": "Film theory is a set of scholarly approaches within the academic discipline of film or cinema studies that began in the 1920s by questioning the formal essential attributes of motion pictures; and that now provides conceptual frameworks for understanding film's relationship to reality, the other arts, individual viewers, and society at large. Film theory is not to be confused with general film criticism, or film history, though these three disciplines interrelate.\nAlthough some branches of film theory are derived from linguistics and literary theory, it also originated and overlaps with the philosophy of film.\nHistory.\nEarly theory, before 1945.\nFrench philosopher Henri Bergson's \"Matter and Memory\" (1896) anticipated the development of film theory during the birth of cinema in the early twentieth century. Bergson commented on the need for new ways of thinking about movement, and coined the terms \"the movement-image\" and \"the time-image\". However, in his 1906 essay \"L'illusion cin\u00e9matographique\" (in \"L'\u00e9volution cr\u00e9atrice\"; English: \"The cinematic illusion\") he rejects film as an example of what he had in mind. Nonetheless, decades later, in \"Cin\u00e9ma I and \" (1983\u20131985), the philosopher Gilles Deleuze took \"Matter and Memory\" as the basis of his philosophy of film and revisited Bergson's concepts, combining them with the semiotics of Charles Sanders Peirce. Early film theory arose in the silent era and was mostly concerned with defining the crucial elements of the medium. Ricciotto Canudo was an early Italian film theoretician who saw cinema as \"\"plastic art in motion\", and gave cinema the label \"the Sixth Art\", later changed to \"the Seventh Art\"\".\nIn 1915, Vachel Lindsay wrote a book on film, followed a year later by Hugo M\u00fcnsterberg. Lindsay argued that films could be classified into three categories: \"action films\", \"intimate films\", as well as \"films of splendour\". According to him, the action film was \"sculpture-in-motion\", while the intimate film was \"painting-in-motion\", and splendour film \"architecture-in-motion\". He also argued against the contemporary notion of calling films \"photoplays\" and seen as filmed versions of theatre, instead seeing film with \"camera-born\" opportunities. He also described cinema as \"hieroglyphic\" in the sense of containing symbols in its images. He believed this visuality gave film the potential for universal accessibility. M\u00fcnsterberg in turn noted the analogies between cinematic techniques and certain mental processes. For example, he compared the close-up to the mind paying attention. The flashback, in turn, was similar to remembering. This was later followed by the \"formalism\" of Rudolf Arnheim, who studied how techniques influenced film as art.\nAmong early French theorists, Germaine Dulac brought the concept of \"impressionism\" to film by describing cinema that explored the malleability of the border between internal experience and external reality, for example through superimposition. \"Surrealism\" also had an influence on early French film culture. The term \"photog\u00e9nie\" was important to both, having been brought to use by Louis Delluc in 1919 and becoming widespread in its usage to capture the unique power of cinema. Jean Epstein noted how filming gives a \"personality\" or a \"spirit\" to objects while also being able to reveal \"the untrue, the unreal, the 'surreal'\". This was similar to defamiliarization used by avant-garde artists to recreate the world. He saw the close-up as the essence of \"photog\u00e9nie\". B\u00e9la Bal\u00e1zs also praised the close-up for similar reasons. Arnheim also believed defamiliarization to be a critical element of film.\nAfter the Russian Revolution, a chaotic situation in the country also created a sense of excitement at new possibilities. This gave rise to montage theory in the work of Dziga Vertov and Sergei Eisenstein. After the establishment of the Moscow Film School, Lev Kuleshov set up a workshop to study the formal structure of film, focusing on editing as \"the essence of cinematography\". This produced findings on the Kuleshov effect. Editing was also associated with the foundational Marxist concept of dialectical materialism. To this end, Eisenstein claimed that \"montage is conflict\". Eisenstein's theories were focused on montage having the ability create meaning transcending the sum of its parts with a \"thematic effect\" in a way that ideograms turned graphics into abstract symbols. Multiple scenes could work to produce themes (\"tonal montage\"), while multiple themes could create even higher levels of meaning (\"intellectual montage\"). Vertov in turn focused on developing Kino-Pravda, \"film truth,\" and the Kino-Eye, which he claimed showed a deeper truth than could be seen with the naked eye.\nLater theory, after 1945.\nIn the years after World War II, the French film critic and theorist Andr\u00e9 Bazin argued that film's essence lay in its ability to mechanically reproduce reality, not in its difference from reality. This had followed the rise of \"poetic realism\" in French cinema in the 1930s. He believed that the purpose of art is to preserve reality, even famously claiming that \"The photographic image is the object itself\". Based on this, he advocated for the use of long takes and deep focus, to reveal the \"structural depth\" of reality and finding meaning objectively in images. This was soon followed by the rise of Italian neorealism. Siegfried Kracauer was also notable for arguing that realism is the most important function of cinema.\nThe Auteur theory derived from the approach of critic and filmmaker Alexandre Astruc, among others, and was originally developed in articles in \"Cahiers du Cin\u00e9ma\", a film journal that had been co-founded by Bazin. Fran\u00e7ois Truffaut issued auteurism's manifestos in two \"Cahiers\" essays: \"Une certaine tendance du cin\u00e9ma fran\u00e7ais\" (January 1954) and \"Ali Baba et la 'Politique des auteurs'\" (February 1955). His approach was brought to American criticism by Andrew Sarris in 1962. The auteur theory was based on films depicting the directors' own worldviews and impressions of the subject matter, by varying lighting, camerawork, staging, editing, and so on. Georges Sadoul deemed a film's putative \"author\" potentially even an actor, but a film indeed collaborative. Aljean Harmetz cited major control even by film executives. David Kipen's view of screenwriter as indeed main author is termed \"Schreiber theory\".\nIn the 1960s and 1970s, film theory took up residence in academia importing concepts from established disciplines like psychoanalysis, gender studies, anthropology, literary theory, semiotics and linguisticsas advanced by scholars such as Christian Metz. However, not until the late 1980s or early 1990s did film theory \"per se\" achieve much prominence in American universities by displacing the prevailing humanistic, auteur theory that had dominated cinema studies and which had been focused on the practical elements of film writing, production, editing and criticism. American scholar David Bordwell has spoken against many prominent developments in film theory since the 1970s. He uses the derogatory term \"SLAB theory\" to refer to film studies based on the ideas of Ferdinand de Saussure, Jacques Lacan, Louis Althusser, and Roland Barthes. Instead, Bordwell promotes what he describes as \"neoformalism\" (a revival of formalist film theory).\nDuring the 1990s the digital revolution in image technologies has influenced film theory in various ways. There has been a refocus onto celluloid film's ability to capture an \"indexical\" image of a moment in time by theorists like Mary Ann Doane, Philip Rosen and Laura Mulvey who was informed by psychoanalysis. From a psychoanalytical perspective, after the Lacanian notion of \"the Real\", Slavoj \u017di\u017eek offered new aspects of \"the gaze\" extensively used in contemporary film analysis. From the 1990s onward the Matrixial theory of artist and psychoanalyst Bracha L. Ettinger revolutionized feminist film theory. Her concept The Matrixial Gaze, that has established a feminine gaze and has articulated its differences from the phallic gaze and its relation to feminine as well as maternal specificities and potentialities of \"coemergence\", offering a critique of Sigmund Freud's and Jacques Lacan's psychoanalysis, is extensively used in analysis of films by female authors, like Chantal Akerman, as well as by male authors, like Pedro Almodovar. The matrixial gaze offers the female the position of a subject, not of an object, of the gaze, while deconstructing the structure of the subject itself, and offers border-time, border-space and a possibility for compassion and witnessing. Ettinger's notions articulate the links between aesthetics, ethics and trauma. There has also been a historical revisiting of early cinema screenings, practices and spectatorship modes by writers Tom Gunning, Miriam Hansen and Yuri Tsivian.\nIn \"Critical Cinema: Beyond the Theory of Practice\" (2011), Clive Meyer suggests that 'cinema is a different experience to watching a film at home or in an art gallery', and argues for film theorists to re-engage the specificity of philosophical concepts for cinema as a medium distinct from others."}
{"id": "10800", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=10800", "title": "List of film techniques", "text": ""}
{"id": "10802", "revid": "45584915", "url": "https://en.wikipedia.org/wiki?curid=10802", "title": "Film noir", "text": "Film noir (; ) is a cinematic term used primarily to describe stylized Hollywood crime dramas, particularly those that emphasize cynical attitudes and motivations. The 1940s and 1950s are generally regarded as the \"classic period\" of American film noir. Film noir of this era is associated with a low-key, black-and-white visual style that has roots in German expressionist cinematography. Many of the prototypical stories and attitudes expressed in classic noir derive from the hardboiled school of crime fiction that emerged in the United States during the Great Depression, known as noir fiction. \nThe term \"film noir\", French for \"black film\" (literal) or \"dark film\" (closer meaning), was first applied to Hollywood films by French critic Nino Frank in 1946, but was unrecognized by most American film industry professionals of that era. Frank is believed to have been inspired by the French literary publishing imprint S\u00e9rie noire, founded in 1945.\nCinema historians and critics defined the category retrospectively. Before the notion was widely adopted in the 1970s, many of the classic films noir were referred to as \"melodramas\". Whether film noir qualifies as a distinct genre or whether it should be considered a filmmaking style is a matter of ongoing and heavy debate among film scholars.\nFilm noir encompasses a range of plots; common archetypical protagonists include a private investigator (\"The Big Sleep\"), a plainclothes police officer (\"The Big Heat\"), an aging boxer (\"The Set-Up\"), a hapless grifter (\"Night and the City\"), a law-abiding citizen lured into a life of crime (\"Gun Crazy\"), a femme fatale (\"Gilda\") or simply a victim of circumstance (\"D.O.A.\"). Although film noir was originally associated with American productions, the term has been used to describe films from around the world. Many films released from the 1960s onward share attributes with films noir of the classical period, and often treat its conventions self-referentially. Latter-day works are typically referred to as neo-noir. The clich\u00e9s of film noir have inspired parody since the mid-1940s.\nDefinition.\nThe question of what defines film noir and what sort of category it is, provokes continuing debate. \"We'd be oversimplifying things in calling film noir oneiric, strange, erotic, ambivalent, and cruel\u00a0...\"\u2014this set of attributes constitutes the first of many attempts to define film noir made by French critics and \u00c9tienne Chaumeton in their 1955 book \"Panorama du film noir am\u00e9ricain 1941\u20131953\" (\"A Panorama of American Film Noir\"), the original and seminal extended treatment of the subject.\n They emphasize that not every noir film embodies all five attributes in equal measure\u2014one might be more dreamlike; another, particularly brutal. The authors' caveats and repeated efforts at alternative definition have been echoed in subsequent scholarship, but in the words of cinema historian Mark Bould, film noir remains an \"elusive phenomenon.\"\nThough film noir is often identified with a visual style that emphasizes low-key lighting and unbalanced compositions, films commonly identified as noir evidence a variety of visual approaches, including ones that fit comfortably within the Hollywood mainstream. Film noir similarly embraces a variety of genres, from the gangster film to the police procedural to the gothic romance to the social problem picture\u2014any example of which from the 1940s and 1950s, now seen as noir's classical era, was likely to be described as a melodrama at the time.\nWhile many critics refer to film noir as a genre itself, others argue that it can be no such thing. Foster Hirsch defines a genre as determined by \"conventions of narrative structure, characterization, theme, and visual design.\" Hirsch, as one who has taken the position that film noir is a genre, argues that these elements are present \"in abundance.\" Hirsch notes that there are unifying features of tone, visual style and narrative sufficient to classify noir as a distinct genre.\nOthers argue that film noir is not a genre. It is often associated with an urban setting, but many classic noirs take place in small towns, suburbia, rural areas, or on the open road; setting is not a determinant, as with the Western. Similarly, while the private eye and the femme fatale are stock character types conventionally identified with noir, the majority of films in the genre feature neither. Nor does film noir rely on anything as evident as the monstrous or supernatural elements of the horror film, the speculative leaps of the science fiction film, or the song-and-dance routines of the musical.\nAn analogous case is that of the screwball comedy, widely accepted by film historians as constituting a \"genre\": screwball is defined not by a fundamental attribute, but by a general disposition and a group of elements, some\u2014but rarely and perhaps never all\u2014of which are found in each of the genre's films. Because of the diversity of noir (much greater than that of the screwball comedy), certain scholars in the field, such as film historian Thomas Schatz, treat it as not a genre but a \"style\".\n Alain Silver, the most widely published American critic specializing in film noir studies, refers to film noir as a \"cycle\" and a \"phenomenon\", even as he argues that it has\u2014like certain genres\u2014a consistent set of visual and thematic codes. Screenwriter Eric R. Williams labels both film noir and screwball comedy a \"pathway\" in his screenwriters taxonomy; explaining that a pathway has two parts: 1) the way the audience connects with the protagonist and 2) the trajectory the audience expects the story to follow. Other critics treat film noir as a \"mood,\" a \"series\", or simply a chosen set of films they regard as belonging to the noir \"canon.\" There is no consensus on the matter.\nBackground.\nCinematic sources.\nThe aesthetics of film noir were influenced by German Expressionism, an artistic movement of the 1910s and 1920s that involved theater, music, photography, painting, sculpture and architecture, as well as cinema. The opportunities offered by the booming Hollywood film industry and then the threat of Nazism led to the emigration of many film artists working in Germany who had been involved in the Expressionist movement or studied with its practitioners. \"M\" (1931), shot only a few years before director Fritz Lang's departure from Germany, is among the first crime films of the sound era to join a characteristically noirish visual style with a noir-type plot, in which the protagonist is a criminal (as are his most successful pursuers). Directors such as Lang, Jacques Tourneur, Robert Siodmak and Michael Curtiz brought a dramatically shadowed lighting style and a psychologically expressive approach to visual composition (\"mise-en-sc\u00e8ne\") with them to Hollywood, where they made some of the most famous classic noirs.\nBy 1931, Curtiz had already been in Hollywood for half a decade, making as many as six films a year. Movies of his such as \"20,000 Years in Sing Sing\" (1932) and \"Private Detective 62\" (1933) are among the early Hollywood sound films arguably classifiable as noir\u2014scholar Marc Vernet offers the latter as evidence that dating the initiation of film noir to 1940 or any other year is \"arbitrary\". Expressionism-orientated filmmakers had free stylistic rein in Universal horror pictures such as \"Dracula\" (1931), \"The Mummy\" (1932)\u2014the former photographed and the latter directed by the Berlin-trained Karl Freund\u2014and \"The Black Cat\" (1934), directed by Austrian \u00e9migr\u00e9 Edgar G. Ulmer. The Universal horror film that comes closest to noir, in story and sensibility, is \"The Invisible Man\" (1933), directed by Englishman James Whale and photographed by American Arthur Edeson. Edeson later photographed \"The Maltese Falcon\" (1941), widely regarded as the first major film noir of the classic era.\nJosef von Sternberg was directing in Hollywood during the same period. Films of his such as \"Shanghai Express\" (1932) and \"The Devil Is a Woman\" (1935), with their hothouse eroticism and baroque visual style anticipated central elements of classic noir. The commercial and critical success of Sternberg's silent \"Underworld\" (1927) was largely responsible for spurring a trend of Hollywood gangster films. Successful films in that genre such as \"Little Caesar\" (1931), \"The Public Enemy\" (1931) and \"Scarface\" (1932) demonstrated that there was an audience for crime dramas with morally reprehensible protagonists. An important, possibly influential, cinematic antecedent to classic noir was 1930s French poetic realism, with its romantic, fatalistic attitude and celebration of doomed heroes. The movement's sensibility is mirrored in the Warner Bros. drama \"I Am a Fugitive from a Chain Gang\" (1932), a forerunner of noir. Among films not considered noir, perhaps none had a greater effect on the development of the genre than \"Citizen Kane\" (1941), directed by Orson Welles. Its visual intricacy and complex, voiceover narrative structure are echoed in dozens of classic films noir.\nItalian neorealism of the 1940s, with its emphasis on quasi-documentary authenticity, was an acknowledged influence on trends that emerged in American noir. \"The Lost Weekend\" (1945), directed by Billy Wilder, another Vienna-born, Berlin-trained American auteur, tells the story of an alcoholic in a manner evocative of neorealism. It also exemplifies the problem of classification: one of the first American films to be described as a film noir, it has largely disappeared from considerations of the field. Director Jules Dassin of \"The Naked City\" (1948) pointed to the neorealists as inspiring his use of location photography with non-professional extras. This semidocumentary approach characterized a substantial number of noirs in the late 1940s and early 1950s. Along with neorealism, the style had an American precedent cited by Dassin, in director Henry Hathaway's \"The House on 92nd Street\" (1945), which demonstrated the parallel influence of the cinematic newsreel.\nLiterary sources.\nThe primary literary influence on film noir was the hardboiled school of American detective and crime fiction, led in its early years by such writers as Dashiell Hammett (whose first novel, \"Red Harvest\", was published in 1929) and James M. Cain (whose \"The Postman Always Rings Twice\" appeared five years later), and popularized in pulp magazines such as \"Black Mask\". The classic film noirs \"The Maltese Falcon\" (1941) and \"The Glass Key\" (1942) were based on novels by Hammett; Cain's novels provided the basis for \"Double Indemnity\" (1944), \"Mildred Pierce\" (1945), \"The Postman Always Rings Twice\" (1946), and \"Slightly Scarlet\" (1956; adapted from \"Love's Lovely Counterfeit\"). A decade before the classic era, a story by Hammett was the source for the gangster melodrama \"City Streets\" (1931), directed by Rouben Mamoulian and photographed by Lee Garmes, who worked regularly with Sternberg. Released the month before Lang's \"M\", \"City Streets\" has a claim to being the first major film noir; both its style and story had many noir characteristics.\nRaymond Chandler, who debuted as a novelist with \"The Big Sleep\" in 1939, soon became the most famous author of the hardboiled school. Not only were Chandler's novels turned into major noirs\u2014\"Murder, My Sweet\" (1944; adapted from \"Farewell, My Lovely\"), \"The Big Sleep\" (1946), and \"Lady in the Lake\" (1947)\u2014he was an important screenwriter in the genre as well, producing the scripts for \"Double Indemnity\", \"The Blue Dahlia\" (1946), and \"Strangers on a Train\" (1951). Where Chandler, like Hammett, centered most of his novels and stories on the character of the private eye, Cain featured less heroic protagonists and focused more on psychological exposition than on crime solving; the Cain approach has come to be identified with a subset of the hardboiled genre dubbed \"noir fiction\". For much of the 1940s, one of the most prolific and successful authors of this often downbeat brand of suspense tale was Cornell Woolrich (sometimes under the pseudonym George Hopley or William Irish). No writer's published work provided the basis for more noir films of the classic period than Woolrich's: thirteen in all, including \"Black Angel\" (1946), \"Deadline at Dawn\" (1946), and \"Fear in the Night\" (1947).\nAnother crucial literary source for film noir was W. R. Burnett, whose first novel to be published was \"Little Caesar\", in 1929. It was turned into a hit for Warner Bros. in 1931; the following year, Burnett was hired to write dialogue for \"Scarface\", while \"The Beast of the City\" (1932) was adapted from one of his stories. At least one important reference work identifies the latter as a film noir despite its early date. Burnett's characteristic narrative approach fell somewhere between that of the quintessential hardboiled writers and their noir fiction compatriots\u2014his protagonists were often heroic in their own way, which happened to be that of the gangster. During the classic era, his work, either as author or screenwriter, was the basis for seven films now widely regarded as noir, including three of the most famous: \"High Sierra\" (1941), \"This Gun for Hire\" (1942), and \"The Asphalt Jungle\" (1950).\nClassic period.\nOverview.\nThe 1940s and 1950s are generally regarded as the classic period of American film noir. While \"City Streets\" and other pre-WWII crime melodramas such as \"Fury\" (1936) and \"You Only Live Once\" (1937), both directed by Fritz Lang, are categorized as full-fledged noir in Alain Silver and Elizabeth Ward's film noir encyclopedia, other critics tend to describe them as \"proto-noir\" or in similar terms.\nThe film now most commonly cited as the first \"true\" film noir is \"Stranger on the Third Floor\" (1940), directed by Latvian-born, Soviet-trained Boris Ingster. Hungarian \u00e9migr\u00e9 Peter Lorre\u2014who had starred in Lang's \"M\"\u2014was top-billed, although he did not play the primary lead. (He later played secondary roles in several other formative American noirs.) Although modestly budgeted, at the high end of the B movie scale, \"Stranger on the Third Floor\" still lost its studio, RKO, US$56,000 (), almost a third of its total cost. \"Variety\" magazine found Ingster's work: \"...too studied and when original, lacks the flare to hold attention. It's a film too arty for average audiences, and too humdrum for others.\" \"Stranger on the Third Floor\" was not recognized as the beginning of a trend, let alone a new genre, for many decades.\nMost film noirs of the classic period were similarly low- and modestly-budgeted features without major stars\u2014B movies either literally or in spirit. In this production context, writers, directors, cinematographers, and other craftsmen were relatively free from typical big-picture constraints. There was more visual experimentation than in Hollywood filmmaking as a whole: the Expressionism now closely associated with noir and the semi-documentary style that later emerged represent two very different tendencies. Narrative structures sometimes involved convoluted flashbacks uncommon in non-noir commercial productions. In terms of content, enforcement of the Production Code ensured that no film character could literally get away with murder or be seen sharing a bed with anyone but a spouse; within those bounds, however, many films now identified as noir feature plot elements and dialogue that were very risqu\u00e9 for the time.\nThematically, films noir were most exceptional for the relative frequency with which they centered on portrayals of women of questionable virtue\u2014a focus that had become rare in Hollywood films after the mid-1930s and the end of the pre-Code era. The signal film in this vein was \"Double Indemnity\", directed by Billy Wilder; setting the mold was Barbara Stanwyck's femme fatale, Phyllis Dietrichson\u2014an apparent nod to Marlene Dietrich, who had built her extraordinary career playing such characters for Sternberg. An A-level feature, the film's commercial success and seven Oscar nominations made it probably the most influential of the early noirs. A slew of now-renowned noir \"bad girls\" followed, such as those played by Rita Hayworth in \"Gilda\" (1946), Lana Turner in \"The Postman Always Rings Twice\" (1946), Ava Gardner in \"The Killers\" (1946), and Jane Greer in \"Out of the Past\" (1947). The iconic noir counterpart to the femme fatale, the private eye, came to the fore in films such as \"The Maltese Falcon\" (1941), with Humphrey Bogart as Sam Spade, and \"Murder, My Sweet\" (1944), with Dick Powell as Philip Marlowe.\nThe prevalence of the private eye as a lead character declined in film noir of the 1950s, a period during which several critics describe the form as becoming more focused on extreme psychologies and more exaggerated in general. A prime example is \"Kiss Me Deadly\" (1955); based on a novel by Mickey Spillane, the best-selling of all the hardboiled authors, here the protagonist is a private eye, Mike Hammer. As described by Paul Schrader, \"Robert Aldrich's teasing direction carries \"noir\" to its sleaziest and most perversely erotic. Hammer overturns the underworld in search of the 'great whatsit' [which] turns out to be\u2014joke of jokes\u2014an exploding atomic bomb.\" Orson Welles's baroquely styled \"Touch of Evil\" (1958) is frequently cited as the last noir of the classic period. Some scholars believe film noir never really ended, but continued to transform even as the characteristic noir visual style began to seem dated and changing production conditions led Hollywood in different directions\u2014in this view, post-1950s films in the noir tradition are seen as part of a continuity with classic noir. A majority of critics, however, regard comparable films made outside the classic era to be something other than genuine film noir. They regard true film noir as belonging to a temporally and geographically limited cycle or period, treating subsequent films that evoke the classics as fundamentally different due to general shifts in filmmaking style and latter-day awareness of noir as a historical source for allusion. These later films are often called neo-noir.\nDirectors and the business of noir.\nWhile the inceptive noir, \"Stranger on the Third Floor\", was a B picture directed by a virtual unknown, many of the films noir still remembered were A-list productions by well-known film makers. Debuting as a director with \"The Maltese Falcon\" (1941), John Huston followed with \"Key Largo\" (1948) and \"The Asphalt Jungle\" (1950). Opinion is divided on the noir status of several Alfred Hitchcock thrillers from the era; at least four qualify by consensus: \"Shadow of a Doubt\" (1943), \"Notorious\" (1946), \"Strangers on a Train\" (1951) and \"The Wrong Man\" (1956), Otto Preminger's success with \"Laura\" (1944) made his name and helped demonstrate noir's adaptability to a high-gloss 20th Century-Fox presentation. Among Hollywood's most celebrated directors of the era, arguably none worked more often in a noir mode than Preminger; his other noirs include \"Fallen Angel\" (1945), \"Whirlpool\" (1949), \"Where the Sidewalk Ends\" (1950) (all for Fox) and \"Angel Face\" (1952). A half-decade after \"Double Indemnity\" and \"The Lost Weekend\", Billy Wilder made \"Sunset Boulevard\" (1950) and \"Ace in the Hole\" (1951), noirs that were not so much crime dramas as satires on Hollywood and the news media respectively. \"In a Lonely Place\" (1950) was Nicholas Ray's breakthrough; his other noirs include his debut, \"They Live by Night\" (1948) and \"On Dangerous Ground\" (1952), noted for their unusually sympathetic treatment of characters alienated from the social mainstream.\nOrson Welles had notorious problems with financing but his three film noirs were well-budgeted: \"The Lady from Shanghai\" (1947) received top-level, \"prestige\" backing, while \"The Stranger\" (1946), his most conventional film, and \"Touch of Evil\" (1958), an unmistakably personal work, were funded at levels lower but still commensurate with headlining releases. Like \"The Stranger\", Fritz Lang's \"The Woman in the Window\" (1944) was a production of the independent International Pictures. Lang's follow-up, \"Scarlet Street\" (1945), was one of the few classic noirs to be officially censored: filled with erotic innuendo, it was temporarily banned in Milwaukee, Atlanta and New York State. \"Scarlet Street\" was a semi-independent, cosponsored by Universal and Lang's Diana Productions, of which the film's co-star, Joan Bennett, was the second biggest shareholder. Lang, Bennett and her husband, the Universal veteran and Diana production head Walter Wanger, made \"Secret Beyond the Door\" (1948) in similar fashion.\nBefore leaving the United States while subject to the Hollywood blacklist, Jules Dassin made two classic noirs that also straddled the major/independent line: \"Brute Force\" (1947) and the influential documentary-style \"The Naked City\" (1948) were developed by producer Mark Hellinger, who had an \"inside/outside\" contract with Universal similar to Wanger's. Years earlier, working at Warner Bros., Hellinger had produced three films for Raoul Walsh, the proto-noirs \"They Drive by Night\" (1940), \"Manpower\" (1941) and \"High Sierra\" (1941), now regarded as a seminal work in noir's development. Walsh had no great name during his half-century as a director but his noirs \"The Man I Love\" (1947), \"White Heat\" (1949) and \"The Enforcer\" (1951) had A-list stars and are seen as important examples of the cycle. Other directors associated with top-of-the-bill Hollywood films noir include Edward Dmytryk (\"Murder, My Sweet\" (1944), \"Crossfire\" (1947))\u2014the first important noir director to fall prey to the industry blacklist\u2014as well as Henry Hathaway (\"The Dark Corner\" (1946), \"Kiss of Death\" (1947)) and John Farrow (\"The Big Clock\" (1948), \"Night Has a Thousand Eyes\" (1948)).\nMost of the Hollywood films considered to be classic noirs fall into the category of the B movie. Some were Bs in the most precise sense, produced to run on the bottom of double bills by a low-budget unit of one of the major studios or by one of the smaller Poverty Row outfits, from the relatively well-off Monogram to shakier ventures such as Producers Releasing Corporation (PRC). Jacques Tourneur had made over thirty Hollywood Bs (a few now highly regarded, most forgotten) before directing the A-level \"Out of the Past\", described by scholar Robert Ottoson as \"the \"ne plus ultra\" of forties film noir\". Movies with budgets a step up the ladder, known as \"intermediates\" by the industry, might be treated as A or B pictures depending on the circumstances. Monogram created Allied Artists in the late 1940s to focus on this sort of production. Robert Wise (\"Born to Kill\" [1947], \"The Set-Up\" [1949]) and Anthony Mann (\"T-Men\" [1947] and \"Raw Deal\" [1948]) each made a series of impressive intermediates, many of them noirs, before graduating to steady work on big-budget productions. Mann did some of his most celebrated work with cinematographer John Alton, a specialist in what James Naremore called \"hypnotic moments of light-in-darkness\". \"He Walked by Night\" (1948), shot by Alton though credited solely to Alfred Werker, directed in large part by Mann, demonstrates their technical mastery and exemplifies the late 1940s trend of \"police procedural\" crime dramas. It was released, like other Mann-Alton noirs, by the small Eagle-Lion company; it was the inspiration for the \"Dragnet\" series, which debuted on radio in 1949 and television in 1951.\nSeveral directors associated with noir built well-respected oeuvres largely at the B-movie/intermediate level. Samuel Fuller's brutal, visually energetic films such as \"Pickup on South Street\" (1953) and \"Underworld U.S.A.\" (1961) earned him a unique reputation; his advocates praise him as \"primitive\" and \"barbarous\". Joseph H. Lewis directed noirs as diverse as \"Gun Crazy\" (1950) and \"The Big Combo\" (1955). The former\u2014whose screenplay was written by the blacklisted Dalton Trumbo, disguised by a front\u2014features a bank hold-up sequence shown in an unbroken take of over three minutes that was influential. \"The Big Combo\" was shot by John Alton and took the shadowy noir style to its outer limits. The most distinctive films of Phil Karlson (\"The Phenix City Story\" [1955] and \"The Brothers Rico\" [1957]) tell stories of vice organized on a monstrous scale. The work of other directors in this tier of the industry, such as Felix E. Feist (\"The Devil Thumbs a Ride\" [1947], \"Tomorrow Is Another Day\" [1951]), has become obscure. Edgar G. Ulmer spent most of his Hollywood career working at B studios and once in a while on projects that achieved intermediate status; for the most part, on unmistakable Bs. In 1945, while at PRC, he directed a noir cult classic, \"Detour\". Ulmer's other noirs include \"Strange Illusion\" (1945), also for PRC; \"Ruthless\" (1948), for Eagle-Lion, which had acquired PRC the previous year and \"Murder Is My Beat\" (1955), for Allied Artists.\nA number of low- and modestly-budgeted noirs were made by independent, often actor-owned, companies contracting with larger studios for distribution. Serving as producer, writer, director and top-billed performer, Hugo Haas made films like \"Pickup\" (1951), \"The Other Woman\" (1954) and Jacques Tourneur, \"The Fearmakers (1958)\". It was in this way that accomplished noir actress Ida Lupino established herself as the sole female director in Hollywood during the late 1940s and much of the 1950s. She does not appear in the best-known film she directed, \"The Hitch-Hiker\" (1953), developed by her company, The Filmakers, with support and distribution by RKO. It is one of the seven classic film noirs produced largely outside of the major studios that have been chosen for the United States National Film Registry. Of the others, one was a small-studio release: \"Detour\". Four were independent productions distributed by United Artists, the \"studio without a studio\": \"Gun Crazy\"; \"Kiss Me Deadly\"; \"D.O.A.\" (1950), directed by Rudolph Mat\u00e9 and \"Sweet Smell of Success\" (1957), directed by Alexander Mackendrick. One was an independent distributed by MGM, the industry leader: \"Force of Evil\" (1948), directed by Abraham Polonsky and starring John Garfield, both of whom were blacklisted in the 1950s. Independent production usually meant restricted circumstances but \"Sweet Smell of Success\", despite the plans of the production team, was clearly not made on the cheap, though like many other cherished A-budget noirs, it might be said to have a B-movie soul.\nPerhaps no director better displayed that spirit than the German-born Robert Siodmak, who had already made a score of films before his 1940 arrival in Hollywood. Working mostly on A features, he made eight films now regarded as classic-era noir (a figure matched only by Lang and Mann). In addition to \"The Killers\", Burt Lancaster's debut and a Hellinger/Universal co-production, Siodmak's other important contributions to the genre include 1944's \"Phantom Lady\" (a top-of-the-line B and Woolrich adaptation), the ironically titled \"Christmas Holiday\" (1944), and \"Cry of the City\" (1948). \"Criss Cross\" (1949), with Lancaster again the lead, exemplifies how Siodmak brought the virtues of the B-movie to the A noir. In addition to the relatively looser constraints on character and message at lower budgets, the nature of B production lent itself to the noir style for economic reasons: dim lighting saved on electricity and helped cloak cheap sets (mist and smoke also served the cause). Night shooting was often compelled by hurried production schedules. Plots with obscure motivations and intriguingly elliptical transitions were sometimes the consequence of hastily written scripts. There was not always enough time or money to shoot every scene. In \"Criss Cross\", Siodmak achieved these effects, wrapping them around Yvonne De Carlo, who played the most understandable of femme fatales; Dan Duryea, in one of his many charismatic villain roles; and Lancaster as an ordinary laborer turned armed robber, doomed by a romantic obsession.\nOutside the United States.\nSome critics regard classic film noir as a cycle exclusive to the United States; Alain Silver and Elizabeth Ward, for example, argue, \"With the Western, film noir shares the distinction of being an indigenous American form\u00a0... a wholly American film style.\" However, although the term \"film noir\" was originally coined to describe Hollywood movies, it was an international phenomenon. Even before the beginning of the generally accepted classic period, there were films made far from Hollywood that can be seen in retrospect as films noir, for example, the French productions \"P\u00e9p\u00e9 le Moko\" (1937), directed by Julien Duvivier, and \"Le Jour se l\u00e8ve\" (1939), directed by Marcel Carn\u00e9. In addition, Mexico experienced a vibrant film noir period from roughly 1946 to 1952, which was around the same time film noir was blossoming in the United States.\nDuring the classic period, there were many films produced in Europe, particularly in France, that share elements of style, theme, and sensibility with American films noir and may themselves be included in the genre's canon. In certain cases, the interrelationship with Hollywood noir is obvious: American-born director Jules Dassin moved to France in the early 1950s as a result of the Hollywood blacklist, and made one of the most famous French film noirs, \"Rififi\" (1955). Other well-known French films often classified as noir include \"Quai des Orf\u00e8vres\" (1947) and \"Les Diaboliques\" (1955), both directed by Henri-Georges Clouzot. \"Casque d'Or\" (1952), \"Touchez pas au grisbi\" (1954), and \"Le Trou\" (1960) directed by Jacques Becker; and \"Ascenseur pour l'\u00e9chafaud\" (1958), directed by Louis Malle. French director Jean-Pierre Melville is widely recognized for his tragic, minimalist films noir\u2014\"Bob le flambeur\" (1955), from the classic period, was followed by \"Le Doulos\" (1962), \"Le deuxi\u00e8me souffle\" 1966), \"Le Samoura\u00ef\" (1967), and \"Le Cercle rouge\" (1970). In the 1960s, Greek films noir \"\"The Secret of the Red Mantle\" and \"The Fear\"\" allowed audience for an anti-ableist reading which challenged stereotypes of disability. .\nScholar Andrew Spicer argues that British film noir evidences a greater debt to French poetic realism than to the expressionistic American mode of noir. Examples of British noir (sometimes described as \"Brit noir\") from the classic period include \"Brighton Rock\" (1947), directed by John Boulting; \"They Made Me a Fugitive\" (1947), directed by Alberto Cavalcanti; \"The Small Back Room\" (1948), directed by Michael Powell and Emeric Pressburger; \"The October Man\" (1947), directed by Roy Ward Baker; and \"Cast a Dark Shadow\" (1955), directed by Lewis Gilbert. Terence Fisher directed several low-budget thrillers in a noir mode for Hammer Film Productions, including \"The Last Page\" (a.k.a. \"Man Bait\"; 1952), \"Stolen Face\" (1952), and \"Murder by Proxy\" (a.k.a. \"Blackout\"; 1954). Before leaving for France, Jules Dassin had been obliged by political pressure to shoot his last English-language film of the classic noir period in Great Britain: \"Night and the City\" (1950). Though it was conceived in the United States and was not only directed by an American but also stars two American actors\u2014Richard Widmark and Gene Tierney\u2014it is technically a UK production, financed by 20th Century-Fox's British subsidiary. The most famous of classic British noirs is director Carol Reed's \"The Third Man\" (1949), from a screenplay by Graham Greene. Set in Vienna immediately after World War II, it also stars two American actors, Joseph Cotten and Orson Welles, who had appeared together in \"Citizen Kane\".\nElsewhere, Italian director Luchino Visconti adapted Cain's \"The Postman Always Rings Twice\" as \"Ossessione\" (1943), regarded both as one of the great noirs and a seminal film in the development of neorealism. (This was not even the first screen version of Cain's novel, having been preceded by the French \"Le Dernier Tournant\" in 1939.) In Japan, the celebrated Akira Kurosawa directed several films recognizable as films noir, including \"Drunken Angel\" (1948), \"Stray Dog\" (1949), \"The Bad Sleep Well\" (1960), and \"High and Low\" (1963). Spanish author Mercedes Formica's novel \"La ciudad perdida\" (The Lost City) was adapted into film in 1960.\nAmong the first major neo-noir films\u2014the term often applied to films that consciously refer back to the classic noir tradition\u2014was the French \"Tirez sur le pianiste\" (1960), directed by Fran\u00e7ois Truffaut from a novel by one of the gloomiest of American noir fiction writers, David Goodis. Noir crime films and melodramas have been produced in many countries in the post-classic area. Some of these are quintessentially self-aware neo-noirs\u2014for example, \"Il Conformista\" (1969; Italy), \"Der Amerikanische Freund\" (1977; Germany), \"The Element of Crime\" (1984; Denmark), and \"El Aura\" (2005; Argentina). Others simply share narrative elements and a version of the hardboiled sensibility associated with classic noir, such as \"Castle of Sand\" (1974; Japan), \"Insomnia\" (1997; Norway), \"Croupier\" (1998; UK), and \"Blind Shaft\" (2003; China).\nNeo-noir and echoes of the classic mode.\nThe neo-noir film genre developed mid-way into the Cold War. This cinematological trend reflected much of the cynicism and the possibility of nuclear annihilation of the era. This new genre introduced innovations that were not available to earlier noir films. The violence was also more potent.\n1960s and 1970s.\nWhile it is hard to draw a line between some of the noir films of the early 1960s such as \"Blast of Silence\" (1961) and \"Cape Fear\" (1962) and the noirs of the late 1950s, new trends emerged in the post-classic era. \"The Manchurian Candidate\" (1962), directed by John Frankenheimer, \"Shock Corridor\" (1963), directed by Samuel Fuller, and \"Brainstorm\" (1965), directed by experienced noir character actor William Conrad, all treat the theme of mental dispossession within stylistic and tonal frameworks derived from classic film noir. \"The Manchurian Candidate\" examined the situation of American prisoners of war (POWs) during the Korean War. Incidents that occurred during the war as well as those post-war functioned as an inspiration for a \"Cold War Noir\" subgenre. The television series \"The Fugitive\" (1963\u201367) brought classic noir themes and mood to the small screen for an extended run.\nIn a different vein, films began to appear that self-consciously acknowledged the conventions of classic film noir as historical archetypes to be revived, rejected, or reimagined. These efforts typify what came to be known as neo-noir. Though several late classic noirs, \"Kiss Me Deadly\" (1955) in particular, were deeply self-knowing and post-traditional in conception, none tipped its hand so evidently as to be remarked on by American critics at the time. The first major film to overtly work this angle was French director Jean-Luc Godard's \"\u00c0 bout de souffle\" (\"Breathless\"; 1960), which pays its literal respects to Bogart and his crime films while brandishing a bold new style for a new day. In the United States, Arthur Penn (1965's \"Mickey One\", drawing inspiration from Truffaut's \"Tirez sur le pianiste\" and other French New Wave films), John Boorman (1967's \"Point Blank\", similarly caught up, though in the \"Nouvelle vague\"'s deeper waters), and Alan J. Pakula (1971's \"Klute\") directed films that knowingly related themselves to the original films noir, inviting audiences in on the game.\nA manifest affiliation with noir traditions\u2014which, by its nature, allows different sorts of commentary on them to be inferred\u2014can also provide the basis for explicit critiques of those traditions. In 1973, director Robert Altman flipped off noir piety with \"The Long Goodbye\". Based on the novel by Raymond Chandler, it features one of Bogart's most famous characters, but in iconoclastic fashion: Philip Marlowe, the prototypical hardboiled detective, is replayed as a hapless misfit, almost laughably out of touch with contemporary mores and morality. Where Altman's subversion of the film noir mythos was so irreverent as to outrage some contemporary critics, around the same time Woody Allen was paying affectionate, at points idolatrous homage to the classic mode with \"Play It Again, Sam\" (1972). The \"blaxploitation\" film \"Shaft\" (1971), wherein Richard Roundtree plays the titular African-American private eye, John Shaft, takes conventions from classic noir.\nThe most acclaimed of the neo-noirs of the era was director Roman Polanski's 1974 \"Chinatown\". Written by Robert Towne, it is set in 1930s Los Angeles, an accustomed noir locale nudged back some few years in a way that makes the pivotal loss of innocence in the story even crueler. Where Polanski and Towne raised noir to a black apogee by turning rearward, director Martin Scorsese and screenwriter Paul Schrader brought the noir attitude crashing into the present day with \"Taxi Driver\" (1976), a crackling, bloody-minded gloss on bicentennial America. In 1978, Walter Hill wrote and directed \"The Driver\", a chase film as might have been imagined by Jean-Pierre Melville in an especially abstract mood.\nHill was already a central figure in 1970s noir of a more straightforward manner, having written the script for director Sam Peckinpah's \"The Getaway\" (1972), adapting a novel by pulp master Jim Thompson, as well as for two tough private eye films: an original screenplay for \"Hickey &amp; Boggs\" (1972) and an adaptation of a novel by Ross Macdonald, the leading literary descendant of Hammett and Chandler, for \"The Drowning Pool\" (1975). Some of the strongest 1970s noirs, in fact, were unwinking remakes of the classics, \"neo\" mostly by default: the heartbreaking \"Thieves Like Us\" (1974), directed by Altman from the same source as Ray's \"They Live by Night\", and \"Farewell, My Lovely\" (1975), the Chandler tale made classically as \"Murder, My Sweet\", remade here with Robert Mitchum in his last notable noir role. Detective series, prevalent on American television during the period, updated the hardboiled tradition in different ways, but the show conjuring the most noir tone was a horror crossover touched with shaggy, \"Long Goodbye\"-style humor: \"\" (1974\u201375), featuring a Chicago newspaper reporter investigating strange, usually supernatural occurrences.\n1980s and 1990s.\nThe turn of the decade brought Scorsese's black-and-white \"Raging Bull\" (1980, cowritten by Schrader). An acknowledged masterpiecein 2007 the American Film Institute ranked it as the greatest American film of the 1980s and the fourth greatest of all timeit tells the story of a boxer's moral self-destruction that recalls in both theme and visual ambiance noir dramas such as \"Body and Soul\" (1947) and \"Champion\" (1949). From 1981, \"Body Heat\", written and directed by Lawrence Kasdan, invokes a different set of classic noir elements, this time in a humid, erotically charged Florida setting. Its success confirmed the commercial viability of neo-noir at a time when the major Hollywood studios were becoming increasingly risk averse. The mainstreaming of neo-noir is evident in such films as \"Black Widow\" (1987), \"Shattered\" (1991), and \"Final Analysis\" (1992). Few neo-noirs have made more money or more wittily updated the tradition of the noir double entendre than \"Basic Instinct\" (1992), directed by Paul Verhoeven and written by Joe Eszterhas. The film also demonstrates how neo-noir's polychrome palette can reproduce many of the expressionistic effects of classic black-and-white noir.\nLike \"Chinatown\", its more complex predecessor, Curtis Hanson's Oscar-winning \"L.A. Confidential\" (1997), based on the James Ellroy novel, demonstrates the opposite tendency\u2014the deliberately retro film noir; its tale of corrupt cops and femmes fatale is seemingly lifted straight from a film of 1953, the year in which it is set. Director David Fincher followed the immensely successful neo-noir \"Seven\" (1995) with a film that developed into a cult favorite after its original, disappointing release: \"Fight Club\" (1999), a \"sui generis\" mix of noir aesthetic, perverse comedy, speculative content, and satiric intent.\nWorking generally with much smaller budgets, brothers Joel and Ethan Coen have created one of the most extensive oeuvres influenced by classic noir, with films such as \"Blood Simple\" (1984) and \"Fargo\" (1996), the latter considered by some a supreme work in the neo-noir mode. The Coens cross noir with other generic traditions in the gangster drama \"Miller's Crossing\" (1990)\u2014loosely based on the Dashiell Hammett novels \"Red Harvest\" and \"The Glass Key\"\u2014and the comedy \"The Big Lebowski\" (1998), a tribute to Chandler and an homage to Altman's version of \"The Long Goodbye\". The characteristic work of David Lynch combines film noir tropes with scenarios driven by disturbed characters such as the sociopathic criminal played by Dennis Hopper in \"Blue Velvet\" (1986) and the delusionary protagonist of \"Lost Highway\" (1997). The \"Twin Peaks\" cycle, both the TV series (1990\u201391) and a film, \"\" (1992), puts a detective plot through a succession of bizarre spasms. David Cronenberg also mixes surrealism and noir in \"Naked Lunch\" (1991), inspired by William S. Burroughs' novel.\nPerhaps no American neo-noirs better reflect the classic noir B movie spirit than those of director-writer Quentin Tarantino. Neo-noirs of his such as \"Reservoir Dogs\" (1992) and \"Pulp Fiction\" (1994) display a relentlessly self-reflexive, sometimes tongue-in-cheek sensibility, similar to the work of the New Wave directors and the Coens. Other films from the era readily identifiable as neo-noir (some retro, some more au courant) include director John Dahl's \"Kill Me Again\" (1989), \"Red Rock West\" (1992), and \"The Last Seduction\" (1993); four adaptations of novels by Jim Thompson\u2014\"The Kill-Off\" (1989), \"After Dark, My Sweet\" (1990), \"The Grifters\" (1990), and the remake of \"The Getaway\" (1994); and many more, including adaptations of the work of other major noir fiction writers: \"The Hot Spot\" (1990), from \"Hell Hath No Fury\", by Charles Williams; \"Miami Blues\" (1990), from the novel by Charles Willeford; and \"Out of Sight\" (1998), from the novel by Elmore Leonard. Several films by director-writer David Mamet involve noir elements: \"House of Games\" (1987), \"Homicide\" (1991), \"The Spanish Prisoner\" (1997), and \"Heist\" (2001). On television, \"Moonlighting\" (1985\u201389) paid homage to classic noir while demonstrating an unusual appreciation of the sense of humor often found in the original cycle. Between 1983 and 1989, Mickey Spillane's hardboiled private eye Mike Hammer was played with wry gusto by Stacy Keach in a series and several stand-alone television films (an unsuccessful revival followed in 1997\u201398). The British miniseries \"The Singing Detective\" (1986), written by Dennis Potter, tells the story of a mystery writer named Philip Marlow; widely considered one of the finest neo-noirs in any medium, some critics rank it among the greatest television productions of all time.\nNeon-noir.\nAmong big-budget auteurs, Michael Mann has worked frequently in a neo-noir mode, with such films as \"Thief\" (1981) and \"Heat\" (1995) and the TV series \"Miami Vice\" (1984\u201389) and \"Crime Story\" (1986\u201388). Mann's output exemplifies a primary strain of neo-noir, or as it is affectionately called, \"neon noir\", in which classic themes and tropes are revisited in a contemporary setting with an up-to-date visual style and rock- or hip hop-based musical soundtrack.\nNeo-noir film borrows from and reflects many of the characteristics of the film noir: the presence of crime and violence, complex characters and plot-lines, mystery, and moral ambivalence, all of which come into play in the neon-noir sub-genre. But more than just exhibiting the superficial traits of the genre, neon-noir emphasizes the socio-critique of film noir, recalling the specific socio-cultural dimensions of the interwar years when noirs first became prominent; a time of global existential crisis, depression and the mass movement of the rural population to cities. Long shots or montages of cityscapes, often portrayed as dark and menacing, are suggestive of what Dueck referred to as a \u2018bleak societal perspective\u2019, providing a critique on global capitalism and consumerism. Other characteristics include the use of highly stylized lighting techniques such chiaroscuro, and neon signs and brightly lit buildings that provide a sense of alienation and entrapment.\nAccentuating the use of artificial and neon lighting in the films-noir of the '40s and '50s, neon-noir films accentuate this aesthetic with electrifying color and manipulated light in order to highlight their socio-cultural critiques and their references to contemporary and pop culture. In doing so, neon-noir films present the themes of urban decay, consumerist decadence and capitalism, existentialism, sexuality, and issues of race and violence in the contemporary culture, not only in America, but the globalized world at large.\nNeon-noirs seek to bring the contemporary noir, somewhat diluted under the umbrella of neo-noir, back to the exploration of culture: class, race, gender, patriarchy, and capitalism. Neon-noirs present an existential exploration of society in a hyper-technological and globalized world. Illustrating society as decadent and consumerist, and identity as confused and anxious, neon-noirs reposition the contemporary noir in the setting of urban decay, often featuring scenes set in underground city haunts: brothels, nightclubs, casinos, strip bars, pawnshops, laundromats.\nNeon-noirs were popularized in the '70s and '80s by films such as \"Taxi Driver\" (1976), \"Blade Runner\" (1982), and films from David Lynch, such as \"Blue Velvet\" (1986) and later, \"Lost Highway\" (1997). Other titles from this era included Brian De Palma's \"Blow Out\" (1981) and the Coen Brothers' debut \"Blood Simple\" (1984). More currently, films such as Harmony Korine\u2019s highly provocative \"Spring Breakers\" (2012), and Danny Boyle\u2019s \"Trance\" (2013) have been especially noted for their neon-infused rendering of film noir; while \"Trance\" was celebrated for \u2018shak(ing) the ingredients (of the noir) like colored sand in a jar\u2019, \"Spring Breakers\" notoriously produced a slew of criticism referring to its \u2018fever-dream\u2019 aesthetic and \u2018neon-caked explosion of excess\u2019 (Kohn).\nNeon-noir can be seen as a response to the over-use of the term neo-noir. While the term neo-noir functions to bring noir into the contemporary landscape, it has often been criticized for its dilution of the noir genre. Author Robert Arnett commented on its \"amorphous\" reach: \"any film featuring a detective or crime qualifies\". The neon-noir, more specifically, seeks to revive noir sensibilities in a more targeted manner of reference, focalizing socio-cultural commentary and a hyper-stylized aesthetic.\n2000s and 2010s.\nThe Coen brothers make reference to the noir tradition again with \"The Man Who Wasn't There\" (2001); a black-and-white crime melodrama set in 1949; it features a scene apparently staged to mirror one from \"Out of the Past\". Lynch's \"Mulholland Drive\" (2001) continued in his characteristic vein, making the classic noir setting of Los Angeles the venue for a noir-inflected psychological jigsaw puzzle. British-born director Christopher Nolan's black-and-white debut, \"Following\" (1998), was an overt homage to classic noir. During the new century's first decade, he was one of the leading Hollywood directors of neo-noir with the acclaimed \"Memento\" (2000) and the remake of \"Insomnia\" (2002).\nDirector Sean Penn's \"The Pledge\" (2001), though adapted from a very self-reflexive novel by Friedrich D\u00fcrrenmatt, plays noir comparatively straight, to devastating effect. Screenwriter David Ayer updated the classic noir bad-cop tale, typified by \"Shield for Murder\" (1954) and \"Rogue Cop\" (1954), with his scripts for \"Training Day\" (2001) and, adapting a story by James Ellroy, \"Dark Blue\" (2002); he later wrote and directed the even darker \"Harsh Times\" (2006). Michael Mann's \"Collateral\" (2004) features a performance by Tom Cruise as an assassin in the lineage of \"Le Samoura\u00ef\". The torments of \"The Machinist\" (2004), directed by Brad Anderson, evoke both \"Fight Club\" and \"Memento\". In 2005, Shane Black directed \"Kiss Kiss Bang Bang\", basing his screenplay in part on a crime novel by Brett Halliday, who published his first stories back in the 1920s. The film plays with an awareness not only of classic noir but also of neo-noir reflexivity itself.\nWith ultra-violent films such as \"Sympathy for Mr. Vengeance\" (2002) and \"Thirst\" (2009), Park Chan-wook of South Korea has been the most prominent director outside of the United States to work regularly in a noir mode in the new millennium. The most commercially successful neo-noir of this period has been \"Sin City\" (2005), directed by Robert Rodriguez in extravagantly stylized black and white with splashes of color. The film is based on a series of comic books created by Frank Miller (credited as the film's codirector), which are in turn openly indebted to the works of Spillane and other pulp mystery authors. Similarly, graphic novels provide the basis for \"Road to Perdition\" (2002), directed by Sam Mendes, and \"A History of Violence\" (2005), directed by David Cronenberg; the latter was voted best film of the year in the annual \"Village Voice\" poll. Writer-director Rian Johnson's \"Brick\" (2005), featuring present-day high schoolers speaking a version of 1930s hardboiled argot, won the Special Jury Prize for Originality of Vision at the Sundance Film Festival. The television series \"Veronica Mars\" (2004\u201307, 2019) and the movie \"Veronica Mars\" (2014) also brought a youth-oriented twist to film noir. Examples of this sort of generic crossover have been dubbed \"teen noir\".\nNeo-noir films released in the 2010s include Kim Jee-woon\u2019s \"I Saw the Devil\" (2010), Fred Cavaye\u2019s \"Point Blank\" (2010), Na Hong-jin\u2019s \"The Yellow Sea\" (2010), Nicolas Winding Refn\u2019s \"Drive\" (2011), Claire Denis' \"Bastards\" (2013) and Dan Gilroy's \"Nightcrawler\" (2014).\n2020s.\nThe Science Channel broadcast the 2021 science documentary series \"Killers of the Cosmos\" in a format it describes as \"space noir.\" In the series, actor Aidan Gillen in animated form serves as the host of the series while portraying a private investigator who takes on \"cases\" in which he \"hunts down\" lethal threats to humanity posed by the cosmos. The animated sequences combine the characteristics of film noir with those of a pulp fiction graphic novel set in the mid-20th century, and they link conventional live-action documentary segments in which experts describe the potentially deadly phenomena.\nScience fiction noir.\nIn the post-classic era, a significant trend in noir crossovers has involved science fiction. In Jean-Luc Godard's \"Alphaville\" (1965), Lemmy Caution is the name of the old-school private eye in the city of tomorrow. \"The Groundstar Conspiracy\" (1972) centers on another implacable investigator and an amnesiac named Welles. \"Soylent Green\" (1973), the first major American example, portrays a dystopian, near-future world via a noir detection plot; starring Charlton Heston (the lead in \"Touch of Evil\"), it also features classic noir standbys Joseph Cotten, Edward G. Robinson, and Whit Bissell. The film was directed by Richard Fleischer, who two decades before had directed several strong B noirs, including \"Armored Car Robbery\" (1950) and \"The Narrow Margin\" (1952).\nThe cynical and stylized perspective of classic film noir had a formative effect on the cyberpunk genre of science fiction that emerged in the early 1980s; the film most directly influential on cyberpunk was \"Blade Runner\" (1982), directed by Ridley Scott, which pays evocative homage to the classic noir mode (Scott subsequently directed the poignant 1987 noir crime melodrama \"Someone to Watch Over Me\"). Scholar Jamaluddin Bin Aziz has observed how \"the shadow of Philip Marlowe lingers on\" in such other \"future noir\" films as \"12 Monkeys\" (1995), \"Dark City\" (1998) and \"Minority Report\" (2002). Fincher's feature debut was \"Alien 3\" (1992), which evoked the classic noir jail film \"Brute Force\".\nDavid Cronenberg's \"Crash\" (1996), an adaptation of the speculative novel by J. G. Ballard, has been described as a \"film noir in bruise tones\". The hero is the target of investigation in \"Gattaca\" (1997), which fuses film noir motifs with a scenario indebted to \"Brave New World\". \"The Thirteenth Floor\" (1999), like \"Blade Runner\", is an explicit homage to classic noir, in this case involving speculations about virtual reality. Science fiction, noir, and anime are brought together in the Japanese films of 90s \"Ghost in the Shell\" (1995) and \"\" (2004), both directed by Mamoru Oshii. \"The Animatrix\" (2003), based on and set within the world of \"The Matrix\" film trilogy, contains an anime short film in classic noir style titled \"A Detective Story\". Anime television series with science fiction noir themes include \"Noir\" (2001) and \"Cowboy Bebop\" (1998).\nThe 2015 film \"Ex Machina\" puts an understated film noir spin on the Frankenstein mythos, with the sentient android Ava as a potential \"femme fatale\", her creator Nathan embodying the abusive husband or father trope, and her would-be rescuer Caleb as a \"clueless drifter\" enthralled by Ava.\nRural/outback noir.\nA sub-genre of noir fiction has been named \"rural noir\" in the US; and sometimes \"outback noir\" in Australia. Many rural noir novels have been adapted for film and TV series in both countries, such as \"Ozark\", \"No Country for Old Men\", and \"Big Sky\" in the US, and \"Troppo\", \"The Dry\" (and its sequel \"\"), \"Scrublands\", and \"High Country\" (2024) in Australia.\nIn Australia, outback noir increasingly includes issues relating to Indigenous Australians, such as the dispossession of land from Aboriginal peoples and racism. Filmmaker Ivan Sen is known for his exploration of such themes in his \"Mystery Road\" TV series and film of the same name with its prequel \"Goldstone\", and his more recent award-winning film \"Limbo\" (2023).\nParodies.\nFilm noir has been parodied many times in many manners. In 1945, Danny Kaye starred in what appears to be the first intentional film noir parody, \"Wonder Man\". That same year, Deanna Durbin was the singing lead in the comedic noir \"Lady on a Train\", which makes fun of Woolrich-brand wistful miserablism. Bob Hope inaugurated the private-eye noir parody with \"My Favorite Brunette\" (1947), playing a baby-photographer who is mistaken for an ironfisted detective. In 1947 as well, The Bowery Boys appeared in \"Hard Boiled Mahoney\", which had a similar mistaken-identity plot; they spoofed the genre once more in \"Private Eyes\" (1953). Two RKO productions starring Robert Mitchum take film noir over the border into self-parody: \"The Big Steal\" (1949), directed by Don Siegel, and \"His Kind of Woman\" (1951). The \"Girl Hunt\" ballet in Vincente Minnelli's \"The Band Wagon\" (1953) is a ten-minute distillation of\u2014and play on\u2014noir in dance. \"The Cheap Detective\" (1978), starring Peter Falk, is a broad spoof of several films, including the Bogart classics \"The Maltese Falcon\" and \"Casablanca\". Carl Reiner's black-and-white \"Dead Men Don't Wear Plaid\" (1982) appropriates clips of classic noirs for a farcical pastiche, while his \"Fatal Instinct\" (1993) sends up noir classic (\"Double Indemnity\") and neo-noir (\"Basic Instinct\"). Robert Zemeckis's \"Who Framed Roger Rabbit\" (1988) develops a noir plot set in 1940s Los Angeles around a host of cartoon characters.\nNoir parodies come in darker tones as well. \"Murder by Contract\" (1958), directed by Irving Lerner, is a deadpan joke on noir, with a denouement as bleak as any of the films it kids. An ultra-low-budget Columbia Pictures production, it may qualify as the first intentional example of what is now called a neo-noir film; it was likely a source of inspiration for both Melville's \"Le Samoura\u00ef\" and Scorsese's \"Taxi Driver\". Belying its parodic strain, \"The Long Goodbye\"s final act is seriously grave. \"Taxi Driver\" caustically deconstructs the \"dark\" crime film, taking it to an absurd extreme and then offering a conclusion that manages to mock every possible anticipated ending\u2014triumphant, tragic, artfully ambivalent\u2014while being each, all at once. Flirting with splatter status even more brazenly, the Coens' \"Blood Simple\" is both an exacting pastiche and a gross exaggeration of classic noir. Adapted by director Robinson Devor from a novel by Charles Willeford, \"The Woman Chaser\" (1999) sends up not just the noir mode but the entire Hollywood filmmaking process, with each shot seemingly staged as the visual equivalent of an acerbic Marlowe wisecrack.\nIn other media, the television series \"Sledge Hammer!\" (1986\u201388) lampoons noir, along with such topics as capital punishment, gun fetishism, and Dirty Harry. \"Sesame Street\" (1969\u2013curr.) occasionally casts Kermit the Frog as a private eye; the sketches refer to some of the typical motifs of noir films, in particular the voiceover. Garrison Keillor's radio program \"A Prairie Home Companion\" features the recurring character Guy Noir, a hardboiled detective whose adventures always wander into farce (Guy also appears in the Altman-directed film based on Keillor's show). Firesign Theatre's Nick Danger has trodden the same not-so-mean streets, both on radio and in comedy albums. Cartoons such as \"Garfield's Babes and Bullets\" (1989) and comic strip characters such as Tracer Bullet of \"Calvin and Hobbes\" have parodied both film noir and the kindred hardboiled tradition\u2014one of the sources from which film noir sprang and which it now overshadows. \"It's Always Sunny in Philadelphia\" parodied the noir genre in its season 14 episode \"The Janitor Always Mops Twice.\"\nIdentifying characteristics.\nIn their original 1955 canon of film noir, Raymond Borde and Etienne Chaumeton identified twenty-two Hollywood films released between 1941 and 1952 as core examples; they listed another fifty-nine American films from the period as significantly related to the field of noir. A half-century later, film historians and critics had come to agree on a canon of approximately three hundred films from 1940 to 1958. There remain, however, many differences of opinion over whether other films of the era, among them a number of well-known ones, qualify as films noir or not. For instance, \"The Night of the Hunter\" (1955), starring Robert Mitchum in an acclaimed performance, is treated as a film noir by some critics, but not by others. Some critics include \"Suspicion\" (1941), directed by Alfred Hitchcock, in their catalogues of noir; others ignore it. Concerning films made either before or after the classic period, or outside of the United States at any time, consensus is even rarer.\nTo support their categorization of certain films as noirs and their rejection of others, many critics refer to a set of elements they see as marking examples of the mode. The question of what constitutes the set of noir's identifying characteristics is a fundamental source of controversy. For instance, critics tend to define the model film noir as having a tragic or bleak conclusion, but many acknowledged classics of the genre have clearly happy endings (e.g., \"Stranger on the Third Floor,\" \"The Big Sleep\", \"Dark Passage\", and \"The Dark Corner\"), while the tone of many other noir denouements is ambivalent. Some critics perceive classic noir's hallmark as a distinctive visual style. Others, observing that there is actually considerable stylistic variety among noirs, instead emphasize plot and character type. Still others focus on mood and attitude. No survey of classic noir's identifying characteristics can therefore be considered definitive. In the 1990s and 2000s, critics have increasingly turned their attention to that diverse field of films called neo-noir; once again, there is even less consensus about the defining attributes of such films made outside the classic period. Roger Ebert offered \"A Guide to Film Noir\", writing that \"Film noir is...\nVisual style.\nThe low-key lighting schemes of many classic films noir are associated with stark light/dark contrasts and dramatic shadow patterning\u2014a style known as chiaroscuro (a term adopted from Renaissance painting). The shadows of Venetian blinds or banister rods, cast upon an actor, a wall, or an entire set, are an iconic visual in noir and had already become a clich\u00e9 well before the neo-noir era. Characters' faces may be partially or wholly obscured by darkness\u2014a relative rarity in conventional Hollywood filmmaking. While black-and-white cinematography is considered by many to be one of the essential attributes of classic noir, the color films \"Leave Her to Heaven\" (1945) and \"Niagara\" (1953) are routinely included in noir filmographies, while \"Slightly Scarlet\" (1956), \"Party Girl\" (1958), and \"Vertigo\" (1958) are classified as noir by varying numbers of critics.\nFilm noir is also known for its use of low-angle, wide-angle, and skewed, or Dutch angle shots. Other devices of disorientation relatively common in film noir include shots of people reflected in one or more mirrors, shots through curved or frosted glass or other distorting objects (such as during the strangulation scene in \"Strangers on a Train\"), and special effects sequences of a sometimes bizarre nature. Night-for-night shooting, as opposed to the Hollywood norm of day-for-night, was often employed. From the mid-1940s forward, location shooting became increasingly frequent in noir.\nIn an analysis of the visual approach of \"Kiss Me Deadly\", a late and self-consciously stylized example of classic noir, critic Alain Silver describes how cinematographic choices emphasize the story's themes and mood. In one scene, the characters, seen through a \"confusion of angular shapes\", thus appear \"caught in a tangible vortex or enclosed in a trap.\" Silver makes a case for how \"side light is used\u00a0... to reflect character ambivalence\", while shots of characters in which they are lit from below \"conform to a convention of visual expression which associates shadows cast upward of the face with the unnatural and ominous\".\nStructure and narrational devices.\nFilms noir tend to have unusually convoluted story lines, frequently involving flashbacks and other editing techniques that disrupt and sometimes obscure the narrative sequence. Framing the entire primary narrative as a flashback is also a standard device. Voiceover narration, sometimes used as a structuring device, came to be seen as a noir hallmark; while classic noir is generally associated with first-person narration (i.e., by the protagonist), Stephen Neale notes that third-person narration is common among noirs of the semidocumentary style. Neo-noirs as varied as \"The Element of Crime\" (surrealist), \"After Dark, My Sweet\" (retro), and \"Kiss Kiss Bang Bang\" (meta) have employed the flashback/voiceover combination.\nBold experiments in cinematic storytelling were sometimes attempted during the classic era: \"Lady in the Lake\", for example, is shot entirely from the point of view of protagonist Philip Marlowe; the face of star (and director) Robert Montgomery is seen only in mirrors. \"The Chase\" (1946) takes oneirism and fatalism as the basis for its fantastical narrative system, redolent of certain horror stories, but with little precedent in the context of a putatively realistic genre. In their different ways, both \"Sunset Boulevard\" and \"D.O.A.\" are tales told by dead men. Latter-day noir has been in the forefront of structural experimentation in popular cinema, as exemplified by such films as \"Pulp Fiction\", \"Fight Club\", and \"Memento\".\nPlots, characters, and settings.\nCrime, usually murder, is an element of almost all films noir; in addition to standard-issue greed, jealousy is frequently the criminal motivation. A crime investigation\u2014by a private eye, a police detective (sometimes acting alone), or a concerned amateur\u2014is the most prevalent, but far from dominant, basic plot. In other common plots the protagonists are implicated in heists or con games, or in murderous conspiracies often involving adulterous affairs. False suspicions and accusations of crime are frequent plot elements, as are betrayals and double-crosses. According to J. David Slocum, \"protagonists assume the literal identities of dead men in nearly fifteen percent of all noir.\" Amnesia is fairly epidemic\u2014\"noir's version of the common cold\", in the words of film historian Lee Server.\nFilms noir tend to revolve around heroes who are more flawed and morally questionable than the norm, often fall guys of one sort or another. The characteristic protagonists of noir are described by many critics as \"alienated\"; in the words of Silver and Ward, \"filled with existential bitterness\". Certain archetypal characters appear in many film noirs\u2014hardboiled detectives, femme fatales, corrupt policemen, jealous husbands, intrepid claims adjusters, and down-and-out writers. Among characters of every stripe, cigarette smoking is rampant. From historical commentators to neo-noir pictures to pop culture ephemera, the private eye and the femme fatale have been adopted as the quintessential film noir figures, though they do not appear in most films now regarded as classic noir. Of the twenty-six National Film Registry noirs, in only four does the star play a private eye: \"The Maltese Falcon\", \"The Big Sleep\", \"Out of the Past\", and \"Kiss Me Deadly\". Just four others readily qualify as detective stories: \"Laura\", \"The Killers\", \"The Naked City\", and \"Touch of Evil\". There is usually an element of drug or alcohol use, particularly as part of the detective's method to solving the crime, as an example the character of Mike Hammer in the 1955 film \"Kiss Me Deadly\" who walks into a bar saying \"Give me a double bourbon, and leave the bottle\". Chaumeton and Borde have argued that film noir grew out of the \"literature of drugs and alcohol\".\nFilm noir is often associated with an urban setting, and a few cities\u2014Los Angeles, San Francisco, New York, and Chicago, in particular\u2014are the location of many of the classic films. In the eyes of many critics, the city is presented in noir as a \"labyrinth\" or \"maze\". Bars, lounges, nightclubs, and gambling dens are frequently the scene of action. The climaxes of a substantial number of film noirs take place in visually complex, often industrial settings, such as refineries, factories, trainyards, power plants\u2014most famously the explosive conclusion of \"White Heat\", set at a chemical plant. In the popular (and, frequently enough, critical) imagination, in noir it is always night and it always raining.\nA substantial trend within latter-day noir\u2014dubbed \"film soleil\" by critic D. K. Holm\u2014heads in precisely the opposite direction, with tales of deception, seduction, and corruption exploiting bright, sun-baked settings, stereotypically the desert or open water, to searing effect. Significant predecessors from the classic and early post-classic eras include \"The Lady from Shanghai\"; the Robert Ryan vehicle \"Inferno\" (1953); the French adaptation of Patricia Highsmith's \"The Talented Mr. Ripley\", \"Plein soleil\" (\"Purple Noon\" in the United States, more accurately rendered elsewhere as \"Blazing Sun\" or \"Full Sun\"; 1960); and director Don Siegel's version of \"The Killers\" (1964). The tendency was at its peak during the late 1980s and 1990s, with films such as \"Dead Calm\" (1989), \"After Dark, My Sweet\" (1990), \"The Hot Spot\" (1990), \"Delusion\" (1991), \"Red Rock West\" (1993) and the television series \"Miami Vice\".\nWorldview, morality, and tone.\nFilm noir is often described as essentially pessimistic. The noir stories that are regarded as most characteristic tell of people trapped in unwanted situations (which, in general, they did not cause but are responsible for exacerbating), striving against random, uncaring fate, and are frequently doomed. The films are seen as depicting a world that is inherently corrupt. Classic film noir has been associated by many critics with the American social landscape of the era\u2014in particular, with a sense of heightened anxiety and alienation that is said to have followed World War II. In author Nicholas Christopher's opinion, \"it is as if the war, and the social eruptions in its aftermath, unleashed demons that had been bottled up in the national psyche.\" Films noir, especially those of the 1950s and the height of the Red Scare, are often said to reflect cultural paranoia; \"Kiss Me Deadly\" is the noir most frequently marshaled as evidence for this claim.\nFilm noir is often said to be defined by \"moral ambiguity\", yet the Production Code obliged almost all classic noirs to see that steadfast virtue was ultimately rewarded and vice, in the absence of shame and redemption, severely punished (however dramatically incredible the final rendering of mandatory justice might be). A substantial number of latter-day noirs flout such conventions: vice emerges triumphant in films as varied as the grim \"Chinatown\" and the ribald \"Hot Spot\".\nThe tone of film noir is generally regarded as downbeat; some critics experience it as darker still\u2014\"overwhelmingly black\", according to Robert Ottoson. Influential critic (and filmmaker) Paul Schrader wrote in a seminal 1972 essay that \"\"film noir\" is defined by tone\", a tone he seems to perceive as \"hopeless\". In describing the adaptation of \"Double Indemnity,\" noir analyst Foster Hirsch describes the \"requisite hopeless tone\" achieved by the filmmakers, which appears to characterize his view of noir as a whole. On the other hand, definitive film noirs such as \"The Big Sleep\", \"The Lady from Shanghai\", \"Scarlet Street\" and \"Double Indemnity\" itself are famed for their hardboiled repartee, often imbued with sexual innuendo and self-reflexive humor.\nMusic.\nThe music of film noir was typically orchestral, per the Hollywood norm, but often with added dissonance. Many of the prime composers, like the directors and cameramen, were European \u00e9migr\u00e9s, e.g., Max Steiner (\"The Big Sleep\", \"Mildred Pierce\"), Mikl\u00f3s R\u00f3zsa (\"Double Indemnity\", \"The Killers\", \"Criss Cross\"), and Franz Waxman (\"Fury\", \"Sunset Boulevard\", \"Night and the City\"). \"Double Indemnity\" is a seminal score, initially disliked by Paramount's music director for its harshness but strongly endorsed by director Billy Wilder and studio chief Buddy DeSylva. There is a widespread popular impression that \"sleazy\" jazz saxophone and pizzicato bass constitute the sound of noir, but those characteristics arose much later, as in the late-1950s music of Henry Mancini for \"Touch of Evil\" and television's \"Peter Gunn\". Bernard Herrmann's score for \"Taxi Driver\" makes heavy use of saxophone."}
{"id": "10803", "revid": "1264107897", "url": "https://en.wikipedia.org/wiki?curid=10803", "title": "Finno-Ugric languages", "text": "Finno-Ugric () is a traditional linguistic grouping of all languages in the Uralic language family except for the Samoyedic languages. Its once commonly accepted status as a subfamily of Uralic is based on criteria formulated in the 19th century and is criticized by some contemporary linguists such as Tapani Salminen and Ante Aikio. The three most spoken Uralic languages, Hungarian, Finnish, and Estonian, are all included in Finno-Ugric.\nThe term \"Finno-Ugric\", which originally referred to the entire family, is sometimes used as a synonym for the term \"Uralic\", which includes the Samoyedic languages, as commonly happens when a language family is expanded with further discoveries. Before the 20th century, the language family might be referred to as \"Finnish\", \"Ugric\", \"Finno-Hungarian\" or with a variety of other names. The name \"Finno-Ugric\" came into general use in the late 19th or early 20th century.\nStatus.\nThe validity of Finno-Ugric as a phylogenic grouping is currently disputed, with some linguists maintaining that the Finno-Permic languages are as distinct from the Ugric languages as they are from the Samoyedic languages spoken in Siberia, or even that none of the Finno-Ugric, Finno-Permic, or Ugric branches has been established. Received opinion is that the easternmost (and last discovered) Samoyed had separated first and the branching into Ugric and Finno-Permic took place later, but this reconstruction does not have strong support in the linguistic data.\nOrigins.\nAttempts at reconstructing a Proto-Finno-Ugric proto-language, a common ancestor of all Uralic languages except for the Samoyedic languages, are largely indistinguishable from Proto-Uralic, suggesting that Finno-Ugric might not be a historical grouping but a geographical one, with Samoyedic being distinct by lexical borrowing rather than actually being historically divergent. It has been proposed that the area in which Proto-Finno-Ugric was spoken reached between the Baltic Sea and the Ural Mountains.\nTraditionally, the main set of evidence for the genetic proposal of Proto-Finno-Ugric has come from vocabulary. A large amount of vocabulary (e.g. the numerals \"one\", \"three\", \"four\" and \"six\"; the body-part terms \"hand\", \"head\") is only reconstructed up to the Proto-Finno-Ugric level, and only words with a Samoyedic equivalent have been reconstructed for Proto-Uralic. That methodology has been criticised, as no coherent explanation other than inheritance has been presented for the origin of most of the Finno-Ugric vocabulary (though a small number has been explained as old loanwords from Proto-Indo-European or its immediate successors).\nThe Samoyedic group has undergone a longer period of independent development, and its divergent vocabulary could be caused by mechanisms of replacement such as language contact. (The Finno-Ugric group is usually dated to approximately 4,000 years ago, the Samoyedic a little over 2,000.) Proponents of the traditional binary division note, however, that the invocation of extensive contact influence on vocabulary is at odds with the grammatical conservatism of Samoyedic.\nThe consonant \"*\u0161\" (voiceless postalveolar fricative, ) has not been conclusively shown to occur in the traditional Proto-Uralic lexicon, but it is attested in some of the Proto-Finno-Ugric material. Another feature attested in the Finno-Ugric vocabulary is that \"*i\" now behaves as a neutral vowel with respect to front-back vowel harmony, and thus there are roots such as \"*niwa-\" \"to remove the hair from hides\".\nRegular sound changes proposed for this stage are few and remain open to interpretation. Sammallahti (1988) proposes five, following Janhunen's (1981) reconstruction of Proto-Finno-Permic:\nSammallahti (1988) further reconstructs sound changes \"*oo\", \"*ee\" \u2192 \"*a\", \"*\u00e4\" (merging with original \"*a\", \"*\u00e4\") for the development from Proto-Finno-Ugric to Proto-Ugric. Similar sound laws are required for other languages as well. Thus, the origin and raising of long vowels may actually belong at a later stage, and the development of these words from Proto-Uralic to Proto-Ugric can be summarized as simple loss of \"*x\" (if it existed in the first place at all; vowel length only surfaces consistently in the Baltic-Finnic languages.) The proposed raising of \"*o\" has been alternatively interpreted instead as a lowering \"*u\" \u2192 \"*o\" in Samoyedic (PU *\"lumi\" \u2192 \"*lom\u0259\" \u2192 Proto-Samoyedic \"*jom\").\nJanhunen (2007, 2009) notes a number of derivational innovations in Finno-Ugric, including \"*\u0144oma\" \"hare\" \u2192 \"*\u0144oma-la\", (vs. Samoyedic \"*\u0144om\u00e5\"), \"*pexli\" \"side\" \u2192 \"*peel-ka\" \u2192 \"*pelka\" \"thumb\", though involving Proto-Uralic derivational elements.\nStructural features.\nThe Finno-Ugric group is not typologically distinct from Uralic as a whole: the most widespread structural features among the group all extend to the Samoyedic languages as well.\nClassification models.\nModern linguistic research has shown that \"Volgaic languages\" is a geographical classification rather than a linguistic one, because the Mordvinic languages are more closely related to the Finno-Samic languages than the Mari languages.\nThe relation of the Finno-Permic and the Ugric groups is adjudged remote by some scholars. On the other hand, with a projected time depth of only 3,000 to 4,000 years, the traditionally accepted Finno-Ugric grouping would be far younger than many major families such as Indo-European or Semitic, and would be about the same age as, for instance, the Eastern subfamily of Nilotic. But the grouping is far from transparent or securely established. The absence of early records is a major obstacle. As for the Finno-Ugric \"Urheimat\", most of what has been said about it is speculation.\nSome linguists criticizing the Finno-Ugric genetic proposal, especially Angela Marcantonio, also question the validity of the entire Uralic family, instead proposing a Ural\u2013Altaic hypothesis, within which they believe Finno-Permic may be as distant from Ugric as from Turkic. However, this approach has been rejected by nearly all other specialists in Uralic linguistics.\nCommon vocabulary.\nLoanwords.\nOne argument in favor of the Finno-Ugric grouping has come from loanwords. Several loans from the Indo-European languages are present in most or all of the Finno-Ugric languages, while being absent from Samoyedic.\nAccording to H\u00e4kkinen (1983) the alleged Proto-Finno-Ugric loanwords are disproportionally well-represented in Hungarian and the Permic languages, and disproportionally poorly represented in the Ob-Ugric languages; hence it is possible that such words have been acquired by the languages only after the initial dissolution of the Uralic family into individual dialects, and that the scarcity of loanwords in Samoyedic results from its peripheric location.\nNumbers.\nThe number systems among the Finno-Ugric languages are particularly distinct from the Samoyedic languages: only the numerals \"2\", \"5\", and \"7\" have cognates in Samoyedic, while also the numerals, \"1\", \"3\", \"4\", \"6\", \"10\" are shared by all or most Finno-Ugric languages.\nBelow are the numbers 1 to 10 in several Finno-Ugric languages. Forms in \"italic\" do not descend from the reconstructed forms.\nThe number '2' descends in Ugric from a front-vocalic variant *kekt\u00e4.\nThe numbers '9' and '8' in Finnic through Mari are considered to be derived from the numbers '1' and '2' as '10\u20131' and '10\u20132'. One reconstruction is *\"yk+teksa\" and *\"kak+teksa\", respectively, where *\"teksa\" cf. \"deka\" is an Indo-European loan; the difference between /t/ and /d/ is not phonemic, unlike in Indo-European. Another analysis is *\"ykt-e-ksa\", *\"kakt-e-ksa\", with *\"e\" being the negative verb.\nFinno-Ugric Swadesh lists.\n100-word Swadesh lists for certain Finno-Ugric languages can be compared and contrasted at the Rosetta Project website:\nFinnish, Estonian, Hungarian, and Erzya.\nSpeakers.\nThe four largest ethnic groups that speak Finno-Ugric languages are the Hungarians (14.5 million), Finns (6.5 million), Estonians (1.1 million), and Mordvins (0.85 million). Majorities of three (the Hungarians, Finns, and Estonians) inhabit their respective nation states in Europe, i.e. Hungary, Finland, and Estonia, while a large minority of Mordvins inhabit the federal Mordovian Republic within Russia (Russian Federation).\nThe indigenous area of the S\u00e1mi people is known as S\u00e1pmi and it consists of the northern parts of the Fennoscandian Peninsula. Some other peoples that speak Finno-Ugric languages have been assigned formerly autonomous republics within Russia. These are the Karelians (Republic of Karelia), Komi (Komi Republic), Udmurts (Udmurt Republic) and Mari (Mari El Republic). The Khanty-Mansi Autonomous Okrug was set up for the Khanty and Mansi of Russia. A once-autonomous Komi-Permyak Okrug was set up for a region of high Komi habitation outside the Komi Republic.\nSome of the ethnicities speaking Finno-Ugric languages are:\nInternational Finno-Ugric societies.\nIn the Finno-Ugric countries of Finland, Estonia and Hungary that find themselves surrounded by speakers of unrelated tongues, language origins and language history have long been relevant to national identity. In 1992, the 1st \"World Congress of Finno-Ugric Peoples\" was organized in Syktyvkar in the Komi Republic in Russia, the 2nd World Congress in 1996 in Budapest in Hungary, the 3rd Congress in 2000 in Helsinki in Finland, the 4th Congress in 2004 in Tallinn in Estonia, the 5th Congress in 2008 in Khanty-Mansiysk in Russia, the 6th Congress in 2012 in Si\u00f3fok in Hungary, the 7th Congress in 2016 in Lahti in Finland, and the 8th Congress in 2021 in Tartu in Estonia. The members of the Finno-Ugric Peoples' Consultative Committee include: the Erzyas, Estonians, Finns, Hungarians, Ingrian Finns, Ingrians, Karelians, Khants, Komis, Mansis, Maris, Mokshas, Nenetses, Permian Komis, Saamis, Tver Karelians, Udmurts, Vepsians; Observers: Livonians, Setos.\nIn 2007, the 1st \"Festival of the Finno-Ugric Peoples\" was hosted by President Vladimir Putin of Russia, and visited by Finnish President, Tarja Halonen, and Hungarian Prime Minister, Ferenc Gyurcs\u00e1ny.\nThe International Finno-Ugric Students' Conference (IFUSCO) is organised annually by students of Finno-Ugric languages to bring together people from all over the world who are interested in the languages and cultures. The first conference was held in 1984 in G\u00f6ttingen in Germany. IFUSCO features presentations and workshops on topics such as linguistics, ethnography, history and more.\nThe International Congress for Finno-Ugric Studies is the largest scientific meeting of scientists studying the culture and languages of Finno-Ugric peoples, held every five years. The first congress was organized in 1960 in Budapest, the last congress took place in 2022 in Vienna, the next congress is planned to be held in Tartu, Estonia in 2025.\nPopulation genetics.\nThe linguistic reconstruction of the Finno-Ugric language family has led to the postulation that the ancient Proto-Finno-Ugric people were ethnically related, and that even the modern Finno-Ugric-speaking peoples are ethnically related. Such hypotheses are based on the assumption that heredity can be traced through linguistic relatedness, although it must be kept in mind that language shift and ethnic admixture, a relatively frequent and common occurrence both in recorded history and most likely also in prehistory, confuses the picture and there is no straightforward relationship, if at all, between linguistic and genetic affiliation. Still, the premise that the speakers of the ancient proto-language were ethnically homogeneous is generally accepted.\nModern genetic studies have shown that the Y-chromosome haplogroup N3, and sometimes N2, is almost specific though certainly not restricted to Uralic- or Finno-Ugric-speaking populations, especially as high frequency or primary paternal haplogroup. These haplogroups branched from haplogroup N, which probably spread north, then west and east from Northern China about 12,000\u201314,000 years before present from father haplogroup NO (haplogroup O being the most common Y-chromosome haplogroup in Southeast Asia).\nA study of the Finno-Ugric-speaking peoples of northern Eurasia (i.e., excluding the Hungarians), carried out between 2002 and 2008 in the Department of Forensic Medicine at the University of Helsinki, showed that the Finno-Ugric-speaking populations do not retain genetic evidence of a common founder. Most possess an amalgamation of West and East Eurasian gene pools that may have been present in central Asia, with subsequent genetic drift and recurrent founder effects among speakers of various branches of Finno-Ugric. Not all branches show evidence of a single founder effect. North Eurasian Finno-Ugric-speaking populations were found to be genetically a heterogeneous group showing lower haplotype diversities compared to more southern populations. North Eurasian Finno-Ugric-speaking populations possess unique genetic features due to complex genetic changes shaped by molecular and population genetics and adaptation to the areas of Boreal and Arctic North Eurasia."}
{"id": "10804", "revid": "1104775252", "url": "https://en.wikipedia.org/wiki?curid=10804", "title": "Finnish", "text": "Finnish may refer to:"}
{"id": "10808", "revid": "1271712461", "url": "https://en.wikipedia.org/wiki?curid=10808", "title": "Freestyle music", "text": "Freestyle, or Latin freestyle (initially called Latin hip hop) is a form of electronic dance music that emerged in the New York metropolitan area, Philadelphia, and Miami, primarily among Black Americans, Hispanic Americans, and Italian Americans. \nAn important precursor to freestyle is 1982's \"Planet Rock\" by Afrika Bambaataa &amp; Soul Sonic Force. Shannon's 1983 hit \"Let the Music Play\" is often considered the first freestyle song and the first major song recorded by a Latin American artist is \"Please Don't Go\" by Nayobe from 1984. From there, freestyle gained a large presence in American clubs, especially in New York and Miami. Radio airplay followed in the mid-1980s.\nPerformers such as Expos\u00e9, Lisa Lisa and Cult Jam, Stevie B and Sweet Sensation gained mainstream chart success with the genre in the late 1980s and early 1990s, but its popularity largely faded by the end of the decade. Both classic and newer freestyle output remain popular as a niche genre in Brazil (where it is an influence on \"funk carioca\"), Germany and Canada.\nHistory.\n1982\u20131987: Origin.\nFreestyle music developed in the early 1980s, primarily simultaneously in the Hispanic (mainly Puerto Rican/Afro-Latin) communities of Upper Manhattan and The Bronx and in the Italian-American communities in Brooklyn, the Bronx, other boroughs of New York City, New Jersey, Westchester County and Long Island. It initially was a fusion of synthetic instrumentation and syncopated percussion of 1980s electro, as favored by fans of breakdancing. Sampling, as found in synth-pop music and hip-hop, was incorporated. Key influences include Afrika Bambaataa &amp; Soul Sonic Force's \"Planet Rock\" (1982) and Shannon's \"Let the Music Play\" (1983), the latter was a top-ten \"Billboard\" Hot 100 hit. \nIn 1984, a Latin presence was established when the first song recorded in the genre by a Latin American artist, \"Please Don't Go\", by newcomer Nayobe (a singer from Brooklyn and of Afro-Cuban descent) was recorded and released. The song became a success, reaching No. 23 on the \"Billboard\" Hot Dance Music/Club Play chart. In 1985, a Spanish version of the song was released with the title \"No Te Vayas\". By 1987, freestyle began getting more airplay on American pop radio stations. Songs such as \"Come Go with Me\" by Expos\u00e9, \"Show Me\" by the Cover Girls, \"Fascinated\" by Company B, \"Silent Morning\" by Noel, and \"Catch Me (I'm Falling)\" by Pretty Poison, brought freestyle into the mainstream. House music, based partly on disco rhythms, was by 1992 challenging the relatively upbeat, syncopated freestyle sound. Pitchfork considers the Miami Mix of ABC's single \"When Smokey Sings\" to be proto-freestyle, despite that version being released in 1987. \nMany early or popular freestyle artists and DJs were of Hispanic or Italian descent, including Jellybean, Tony Torres, Raul Soto, Roman Ricardo, Mickey Garcia (who is of both Italian and Puerto Rican descent), Lil Suzy, and Nocera, which was one reason for the style's popularity among Hispanic Americans and Italian Americans in the New York City area and Philadelphia.\n1988: Pop crossover.\nFreestyle's Top 40 Radio airplay started to really take off by 1987, and it began to disappear from the airwaves in the early 1990s as radio stations moved to Top 40-only formats. Artists such as George Lamond, Expos\u00e9, Sweet Sensation, and Stevie B were still heard on mainstream radio, but other notable freestyle artists did not fare as well. Carlos Berrios and Platinum producer Frankie Cutlass used a freestyle production on \"Temptation\" by Corina and \"Together Forever\" by Lisette Melendez. The songs were released in 1991, almost simultaneously, and caused a resurgence in the style when they were embraced by Top 40 radio. \"Temptation\" reached the number 6 spot on the \"Billboard\" Hot 100 Chart. These hits were followed by the success of Lisa Lisa and Cult Jam, who had been one of the earliest freestyle acts. Their records were produced by Full Force, who had also worked with UTFO and James Brown.\nSeveral primarily freestyle artists released ballads during the 1980s and early 1990s that crossed over to the pop charts and charted higher than their previous work. These include \"Seasons Change\" by Expos\u00e9, \"Thinking of You\" by Sa-Fire, \"One More Try\" by Timmy T, \"Because I Love You (The Postman Song)\" by Stevie B, and \"If Wishes Came True\" by Sweet Sensation. Brenda K. Starr reached the Hot 100 with her ballad \"I Still Believe\". Freestyle shortly thereafter gave way to mainstream pop artists such as MC Hammer, Paula Abdul, Bobby Brown, New Kids on the Block, and Milli Vanilli (with some artists utilizing elements of freestyle beginning in the 1980s) using hip hop beats and electro samples in a mainstream form with slicker production and MTV-friendly videos. These artists were successful on crossover stations as well as R&amp;B stations, and freestyle was replaced as an underground genre by newer styles such as new jack swing, trance and Eurodance. Despite this, some freestyle acts managed to garner hits well into the 1990s, with acts such as Cynthia and Rockell scoring minor hits on the \"Billboard\" Hot 100 as late as 1998. As this new music style took over many big cities in America, the labels that signed these artists such as Columbia, Warner Bros, and other labels did not know how to market these artists originally. Instead of pushing this style of music as a solidified sound, the labels separated the cities. This caused the Miami sound of freestyle music to be more popularized through the radio compared to NYC's sound at the time. The labels who pushed out low quality tracks ended up hurting themselves, instead of making the track a quality piece of music. This is part of the reason freestyle music never reached its full potential.\nPost-freestyle era.\nFreestyle remained a largely underground genre with a sizable following in New York, but has recently seen a comeback in the cities where the music originally experienced its greatest success. New York City impresario Steve Sylvester and producer Sal Abbatiello of Fever Records launched Stevie Sly's Freestyle Party show at the Manhattan live music venue, Coda on April 1, 2004. The show featured Judy Torres, Cynthia, and the Cover Girls and was attended by several celebrity guests. The Coda show was successful, and was followed by a summer 2006 Madison Square Garden concert that showcased freestyle's most successful performers. New freestyle releases are popular with enthusiasts and newcomers alike. Miami rapper Pitbull collaborated with Miami freestyle artist Stevie B to create an updated version of Stevie B's hit, \"Spring Love\".\nCurrently, freestyle music continues to have a thriving fanbase in certain parts of the country, with New York City Italian-American DJs such as Bad Boy Joe and Louie DeVito helping to maintain an active freestyle scene in the NYC metro area. In cities like New York, Miami, and Los Angeles, recent concerts by freestyle artists have been extremely successful, with many events selling out.\nInfluence on other genres.\nNYC hard house.\nAs Latin freestyle in the late 1980s and early 1990s gradually became superseded with house music, dance-pop, and regular hip hop on one front and Spanish-language pop music with marginal Latin freestyle influences on another, \"harder strain\" of house music originating in New York City was known to incorporate elements of Latin freestyle and the old school hip hop sound. Principal architects of the genre were Todd Terry (early instances include \"Alright Alright,\" and \"Dum Dum Cry\") and Nitro Deluxe. Deluxe's \"This Brutal House,\" fusing Latin percussion and the New York electro sound of Man Parrish with brash house music, proved to have an impact on the United Kingdom's club music scene, presaging the early 1990s British rave scene.\nTerminology.\nThe genre was recognized as a subgenre of hip-hop in the mid-1980s. It was dominated by \"hard\" electro beats of the type used primarily at the time in hip-hop music. Freestyle was more appreciated in larger cities.\nFreestyle scenes.\nNew York.\n\"Let the Music Play\" by Shannon, is often named as the genre's first hit, and its sound, called \"The Shannon Sound\", as the foundation of the genre, although also known as the beginnings of the electro genre which then gave birth to techno. Afrika Bambaataa's \"Planet Rock\" was arguably the first freestyle song produced. \"Let the Music Play\" eventually became freestyle's biggest hit, and still receives frequent airplay. Its producers Chris Barbosa and Mark Liggett changed and redefined the electro funk sound with the addition of Latin-American rhythms and a syncopated drum-machine sound.\nIn March 2013, Radio City Music Hall hosted a freestyle concert. Top freestyle artists included in the line-up were TKA, Safire, Judy Torres, Cynthia, Cover Girls, Lisa Lisa, Shannon, Noel, and Lisette Melendez. Originally scheduled as a one-night event, a second night was added shortly after the first night was sold out in a matter of days.\nMiami.\nRadio stations nationwide began to play hits by artists like TKA, Sweet Sensation, Expos\u00e9, and Sa-Fire on the same playlists as Michael Jackson and Madonna. \"(You Are My) All and All\" by Joyce Sims became the first freestyle record to cross over into the R&amp;B market, and was one of the first to reach the European market. Radio station WPOW/Power 96 was noted for exposing freestyle to South Florida in the mid-'80s through the early '90s, as well as mixing in some local Miami bass into its playlist.\n'Pretty Tony' Butler produced several hits on Miami's Jam-Packed Records, including Debbie Deb's \"When I Hear Music\" and \"Lookout Weekend\", and Trinere's \"I'll Be All You'll Ever Need\" and \"They're Playing Our Song\". Company B, Stevie B, Paris by Air, Linear, Will to Power and Expos\u00e9's later hits defined Miami freestyle. Tolga Katas is credited as one of the first persons to create a hit record entirely on a computer, and produced Stevie B's \"Party Your Body\", \"In My Eyes\" and \"Dreamin' of Love\". Katas' record label Futura Records was an incubator for artists such as Linear, who achieved international success after a move from Futura to Atlantic Records.\nPhiladelphia.\nThe groundbreaking \"Nightime\" by Pretty Poison featuring red headed diva Jade Starling in 1984 initially put Philadelphia on the freestyle map. Their follow-up \"Catch Me I'm Falling\" was a worldwide hit and brought freestyle to American Bandstand, Soul Train, Solid Gold and the Arsenio Hall Show. \"Catch Me I'm Falling\" broke on the street during the summer of 1987 and was the #1 single at WCAU (98 Hot Hits) and #2 at WUSL (Power 99) during the first two weeks of July. Virgin Records was quick to sign Pretty Poison helping to usher in the avalanche of other major label signings from the expanding freestyle scene.\nSeveral freestyle acts followed on the heels of Pretty Poison emerging from the metropolitan Philadelphia, PA area in the early 1990s, benefiting from both the clubs and the overnight success of then-Dance friendly Rhythmic Top 40 WIOQ. Artists such as T.P.E. (The Philadelphia Experiment) enjoyed regional success.\nCalifornia.\nFreestyle had a notable following in California, especially Los Angeles, the Central Valley, San Francisco Bay, and San Diego. California's large Latino community enjoyed the sounds of America's East Coast club scene, and a number of California artists became popular with East Coast freestyle enthusiasts. In Northern California, primarily San Francisco and San Jose, they leaned toward a similar rhythm dance to hi-NRG, so most of the Californian freestyle emerged from the southern regions of the Bay Area and Los Angeles.\nTimmy T, Bernadette, Caleb-B, SF Spanish Fly, Angelina, One Voice, M:G, Stephanie Fastro and The S Factor were from the Bay Area, and from San Diego were Gustavo Campain, Alex Campain, Jose (Jojo) Santos, Robert Romo of the group Internal Affairs, F. Felix, Leticia and Frankie J.\nThe Filipino American community in California also embraced freestyle music during the late 1980s and early 1990s. Jaya was one of the first Filipino-American freestyle singers, reaching number 44 in 1990 with \"If You Leave Me Now\". Later Filipino-American freestyle artists include Jocelyn Enriquez, Buffy, Korell, Damien Bautista, One Voice, Kuya, Sharyn Maceren, and others.\nCanada.\nFreestyle's popularity spread outward from the Greater Toronto Area's Italian, Hispanic/Latino and Greek populations in the late 1980s and early 1990s. It was showcased alongside house music in various Toronto nightclubs, but by the mid-1990s was replaced almost entirely by house music.\nLil' Suzy released several 12-inch singles and performed live on the Canadian live dance music television program \"Electric Circus\". Montreal singer Nancy Martinez's 1986 single \"For Tonight\" would become the first Canadian freestyle single to reach the top 40 on the \"Billboard\" Hot 100 chart, while the Montreal girl group reached the Canadian chart with \"Ole Ole\" in 2000.\nElsewhere in the world.\nPerformers and producers associated with the style also came from around the world, including Turkish-American Murat Konar (the writer and singer of Information Society's \"Running\"), Paul Lekakis from Greece, Asian artist Leonard (Leon Youngboy) who released the song \"Youngboys\", and British musicians including Freeez, Paul Hardcastle, Samantha Fox (whose singles \"Naughty Girls (Need Love Too)\", \"Love House\" and \"I Wanna Have Some Fun\" were all top 10 chart hits), and even Robin Gibb of the Bee Gees, who also adopted the freestyle sound in his 1984 album \"Secret Agent\", having worked with producer Chris Barbosa. Several British new wave and synth-pop bands also teamed up with freestyle producers or were influenced by the genre, and released freestyle songs or remixes. These include Duran Duran whose song \"Notorious\" was remixed by the Latin Rascals, and whose album \"Big Thing\" contained several freestyle inspired songs such as \"All She Wants Is\"; New Order who teamed up with Arthur Baker, producing and co-writing the track \"Confusion\"; Erasure and the Der Deutsche mixes of their song \"Blue Savannah\"; and the Pet Shop Boys, whose song \"Domino Dancing\" was produced by Miami-based freestyle producer Lewis Martine\u00e9. Australian act I'm Talking utilized freestyle elements into their singles \"Trust Me\" and \"Do You Wanna Be?\", both becoming top ten hits in their native Australia."}
{"id": "10810", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=10810", "title": "Fantasy (psychology)", "text": "In psychology, fantasy is a broad range of mental experiences, mediated by the faculty of imagination in the human brain, and marked by an expression of certain desires through vivid mental imagery. Fantasies are generally associated with scenarios that are impossible or unlikely to happen.\nConscious fantasy.\nIn everyday life, individuals often find their thoughts \"pursue a series of fantasies concerning things they wish they could do or wish they had done ... fantasies of control or of sovereign choice ... daydreams.\"\nGeorge Eman Vaillant in his study of defence mechanisms took as a central example of \"an immature defence ... \"fantasy\" \u2014 living in a 'Walter Mitty' dream world where you imagine you are successful and popular, instead of making real efforts to make friends and succeed at a job.\"\nOther researchers and theorists find that fantasy has beneficial elements\u00a0\u2014 providing \"small regressions and compensatory wish fulfilments which are recuperative in effect.\" Research by Deirdre Barrett reports that people differ radically in the vividness, as well as frequency of fantasy, and that those who have the most elaborately developed fantasy life are often the people who make productive use of their imaginations in art, literature, or by being especially creative and innovative in more traditional professions.\nFreud and fantasy.\nAccording to Sigmund Freud, a fantasy is constructed around multiple, often repressed wishes, and employs disguise to mask and mark the very defensive processes by which desire is enacted. The subject's desire to maintain distance from the repressed wish and simultaneously experience it opens up a type of third person syntax allowing for multiple entry into the fantasy. Therefore, in fantasy, vision is multiplied\u2014it becomes possible to see from more than one position at the same time, to see oneself and to see oneself seeing oneself, to divide vision and dislocate subjectivity. This radical omission of the \"I\" position creates space for all those processes that depend upon such a center, including not only identification but also the field and organization of vision itself.\nFor Freud, sexuality is linked from the very beginning to an object of fantasy. However, \"the object to be rediscovered is not the lost object, but its substitute by displacement; the lost object is the object of self-preservation, of hunger, and the object one seeks to re-find in sexuality is an object displaced in relation to that first object.\" This initial scene of fantasy is created out of the frustrated infants' deflection away from the instinctual need for milk and nourishment towards a phantasmization of the mothers' breast, which is in close proximity to the instinctual need. Now bodily pleasure is derived from the sucking of the mother's breast itself. The mouth that was the original source of nourishment is now the mouth that takes pleasure in its own sucking. This substitution of the breast for milk and the breast for a phantasmic scene represents a further level of mediation which is increasingly psychic. The child cannot experience the pleasure of milk without the psychic re-inscription of the scene in the mind. \"The finding of an object is in fact a re-finding of it.\" It is in the movement and constant restaging away from the instinct that desire is constituted and mobilized.\nFreud and daydreams.\nA similarly positive view of fantasy was taken by Sigmund Freud who considered fantasy () a defence mechanism. He considered that men and women \"cannot subsist on the scanty satisfaction which they can extort from reality. 'We simply cannot do without auxiliary constructions,' as Theodor Fontane once said ... [without] dwelling on imaginary wish fulfillments.\" As childhood adaptation to the reality principle developed, so too \"one species of thought activity was split off; it was kept free from reality-testing and remained subordinated to the pleasure principle alone. This activity is \"fantasying\" ... continued as \"day-dreaming\".\" He compared such phantasising to the way a \"nature reserve preserves its original state where everything ... including what is useless and even what is noxious, can grow and proliferate there as it pleases.\"\nDaydreams for Freud were thus a valuable resource. \"These day-dreams are cathected with a large amount of interest; they are carefully cherished by the subject and usually concealed with a great deal of sensitivity ... such phantasies may be unconscious just as well as conscious.\" He considered these fantasies to include a great deal of the true constitutional essence of a personality, and that the energetic man \"is one who succeeds by his efforts in turning his wishful phantasies into reality,\" whereas the artist \"can transform his phantasies into artistic creations instead of into symptoms ... the doom of neurosis.\"\nKlein and unconscious fantasy.\nMelanie Klein extended Freud's concept of fantasy to cover the developing child's relationship to a world of internal objects. In her thought, this kind of \"play activity inside the person is known as 'unconscious fantasy'. And these phantasies are often very violent and aggressive. They are different from ordinary day-dreams or 'fantasies'.\"\nThe term \"fantasy\" became a central issue with the development of the Kleinian group as a distinctive strand within the British Psycho-Analytical Society, and was at the heart of the so-called controversial discussions of the wartime years. \"A paper by Susan Isaacs (1952) on 'The nature and function of Phantasy' ... has been generally accepted by the Klein group in London as a fundamental statement of their position.\" As a defining feature, \"Kleinian psychoanalysts regard the unconscious as made up of phantasies of relations with objects. These are thought of as primary and innate, and as the mental representations of instincts ... the psychological equivalents in the mind of defence mechanisms.\"\nIsaacs considered that \"unconscious phantasies exert a continuous influence throughout life, both in normal and neurotic people, the difference lying in the specific character of the dominant phantasies.\" Most schools of psychoanalytic thought would now accept that both in analysis and life, we perceive reality through a veil of unconscious fantasy. Isaacs however claimed that \"Freud's 'hallucinatory wish-fulfilment' and his 'introjection' and 'projection' are the basis of the fantasy life,\" and how far unconscious fantasy was a genuine development of Freud's ideas, how far it represented the formation of a new psychoanalytic paradigm, is perhaps the key question of the controversial discussions.\nLacan, fantasy, and desire.\nLacan engaged from early on with \"the phantasies revealed by Melanie Klein ... the \"imago\" of the mother ... this shadow of the \"bad internal objects\"\" \u2014 with the Imaginary. Increasingly, however, it was Freud's idea of fantasy as a kind of \"screen-memory, representing something of more importance with which it was in some way connected\" that was for him of greater importance. Lacan came to believe that \"the phantasy is never anything more than the screen that conceals something quite primary, something determinate in the function of repetition.\"\nPhantasies thus both link to and block off the individual's unconscious, his kernel or real core: \"subject and real are to be situated on either side of the split, in the resistance of the phantasy\", which thus comes close to the centre of the individual's personality and its splits and conflicts. \"The subject situates himself as determined by the phantasy ... whether in the dream or in any of the more or less well-developed forms of day-dreaming;\" and as a rule \"a subject's fantasies are close variations on a single theme ... the 'fundamental fantasy' ... minimizing the variations in meaning which might otherwise cause a problem for desire.\"\nThe goal of therapy thus became \"\"la travers\u00e9e du fantasme\", the crossing over, traversal, or traversing of the fundamental fantasy.\" For Lacan, \"The traversing of fantasy involves the subject's assumption of a new position with respect to the Other as language and the Other as desire ... a utopian moment beyond neurosis.\" The question he was left with was \"What, then, does he who has passed through the experience ... who has traversed the radical phantasy ... become?.\"\nThe \"fantasy principle\".\nThe postmodern intersubjectivity of the 21st century has seen a new interest in fantasy as a form of interpersonal communication. Here, we are told, \"We need to go beyond the pleasure principle, the reality principle, and repetition compulsion to ... the \"fantasy principle\" - not, as Freud did, reduce fantasies to wishes ... [but consider] all other imaginable emotions\" and thus envisage emotional fantasies as a possible means of moving beyond stereotypes to more nuanced forms of personal and social relating.\nSuch a perspective \"sees emotions as central to developing fantasies about each other that are not determined by collective 'typifications'.\"\nNarcissistic personality disorder.\nTwo characteristics of someone with narcissistic personality disorder are:\nSchizophrenia.\nFantasy is a common symptom in individuals with schizophrenia; they depict specific patterns of high-neurological activities in their brains' default mode network, which possibly constitute the biomarker of these fantasies."}
{"id": "10812", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=10812", "title": "Fantasy/authors", "text": ""}
{"id": "10814", "revid": "6289403", "url": "https://en.wikipedia.org/wiki?curid=10814", "title": "Surnames by country", "text": "Surname conventions and laws vary around the world. This article gives an overview of surnames around the world.\nSpanish-speaking countries.\nArgentina.\nIn Argentina, normally only one family name, the father's paternal family name, is used and registered, as in English-speaking countries. However, it is possible to use both the paternal and maternal name. For example, if \"Ana Laura Melachenko\" and \"Emanuel Dar\u00edo Guerrero\" had a daughter named \"Adabel Anah\u00ed\", her full name could be \"Adabel Anah\u00ed Guerrero Melachenko\". Women, however, do not change their family names upon marriage and continue to use their birth family names instead of their husband's family names. However, women have traditionally, and some still choose to use the old Spanish custom of adjoining \"de\" and her husband's surname to her own name. For example, if Paula Segovia marries Felipe Cossia, she might keep her birth name or become \"Paula Segovia de Cossia\" or \"Paula Cossia\".\nThere are some province offices where a married woman can use only her birth name, and some others where she has to use the complete name, for legal purposes. The Argentine Civilian Code states both uses are correct, but police offices and passports are issued with the complete name. Today most women prefer to maintain their birth name given that \"de\" can be interpreted as meaning they belong to their husbands.\nWhen Eva Duarte married Juan Domingo Per\u00f3n, she could be addressed as Eva Duarte de Per\u00f3n, but the preferred style was Eva Per\u00f3n, or the familiar and affectionate \"Evita\" (little Eva).\nCombined names come from old traditional families and are considered one last name, but are rare. Although Argentina is a Spanish-speaking country, it is also composed of other varied European influences, such as Italian, French, Russian, German, etc.\nChildren typically use their fathers' last names only. Some state offices have started to use both last names, in the traditional father then mother order, to reduce the risk of a person being mistaken for others using the same name combinations, e.g. if Eva Duarte and Juan Per\u00f3n had a child named Juan, he might be misidentified if he were called \"Juan Per\u00f3n\", but not if he was known as Juan Per\u00f3n Duarte.\nIn early 2008, some new legislation is under consideration that will place the mother's last name ahead the father's last name, as it is done in Portuguese-speaking countries and only optionally in Spain, despite Argentina being a Spanish-speaking country.\nChile.\nIn Chile, marriage has no effect at all on either of the spouses' names, so people keep their birth names for all their life, no matter how many times marital status, theirs or that of their parents, may change. However, in some upper-class circles or in older couples, even though considered to be old-fashioned, it is still customary for a wife to use her husband's name as reference, as in \"Do\u00f1a Mar\u00eda In\u00e9s de Ram\u00edrez\" (literally Lady Mar\u00eda In\u00e9s (wife) of Ram\u00edrez).\nChildren will always bear the surname of the father followed by that of the mother, but if there is no known father and the mother is single, the children can bear either both of her mother's surnames or the mother's first surname followed by any of the surnames of the mother's parents or grandparents, or the child may bear the mother's first surname twice in a row.\nFrench-speaking countries.\nFrance \nBelgium \nCanadian \nGerman-speaking countries.\nThere are about 1,000,000 different family names in German. German family names most often derive from given names, geographical names, occupational designations, bodily attributes or even traits of character. Hyphenations notwithstanding, they mostly consist of a single word; in those rare cases where the family name is linked to the given names by particles such as \"von\" or \"zu\", they usually indicate noble ancestry. Not all noble families used these names (see Riedesel), while some farm families, particularly in Westphalia, used the particle \"von\" or \"zu\" followed by their farm or former farm's name as a family name (see \"Meyer zu Erpen\").\nFamily names in German-speaking countries are usually positioned last, after all given names. There are exceptions, however: in parts of Austria and Bavaria and the Alemannic-speaking areas, the family name is regularly put in front of the first given name. Also in many \u2013 especially rural \u2013 parts of Germany, to emphasize family affiliation there is often an inversion in colloquial use, in which the family name becomes a possessive: \"R\u00fcters Erich\", for example, would be Erich of the R\u00fcter family.\nIn Germany today, upon marriage, both partners can choose to keep their birth name or choose either partner's name as the common name. In the latter case the partner whose name was not chosen can keep their birth name hyphenated to the new name (e.g. \"Schmidt\" and \"Meyer\" choose to marry under the name \"Meyer\". The former \"Schmidt\" can choose to be called \"Meyer\", \"Schmidt-Meyer\" or \"Meyer-Schmidt\"), but any children will only get the single common name. In the case that both partners keep their birth name they must decide on one of the two family names for all their future children. (German name)\nChanging one's family name for reasons other than marriage, divorce or adoption is possible only if the application is approved by the responsible government agency. In Germany, permission will usually be granted if:\nOtherwise, name changes will normally not be granted.\nDutch-speaking countries.\nThe Netherlands and Belgium (Flanders)\nNordic countries.\nIn the Nordic countries, family names often, but certainly not always, originate from a patronymic. In Denmark and Norway, the corresponding ending is \"-sen\", as in \"Karlsen\". Names ending with \"dotter/datter\" (daughter), such as \"Olofsdotter\", are rare but occurring, and only apply to women. Today, the patronymic names are passed on similarly to family names in other Western countries, and a person's father does not have to be called Karl if he or she has the surname Karlsson. However, in 2006 Denmark reinstated patronymic and matronymic surnames as an option. Thus, parents Karl Larsen and Anna Hansen can name a son Karlsen or Annasen and a daughter Karlsdotter or Annasdotter.\nBefore the 19th century there was the same system in Scandinavia as in Iceland today. Noble families, however, as a rule adopted a family name, which could refer to a presumed or real forefather or to the family's coat of arms. In many surviving family noble names, such as \"Silfversparre\" (\"silver chevron\"; in modern spelling, \"Silver-\") or \"Stiernhielm\" (\"star-helmet\"; in modernized spelling, \"stj\u00e4rnhj\u00e4lm\"), the spelling is obsolete, but since it applies to a name, remains unchanged. (Some names from relatively modern times also use archaic or otherwise aberrant spelling as a stylistic trait; e.g. \"-quist\" instead of standard \"-kvist\" \"twig\" or \"-gr\u00e9n\" instead of standard \"-gren\", \"branch\".)\nLater on, people from the Scandinavian middle classes, particularly artisans and town dwellers, adopted names in a similar fashion to that of the nobility. Family names joining two elements from nature such as the Swedish \"Bergman\" (\"mountain man\"), \"Holmberg\" (\"island mountain\"), \"Lindgren\" (\"linden branch\"), \"Sandstr\u00f6m\" (\"sand stream\") and \"\u00c5kerlund\" (\"field meadow\") were quite frequent and remain common today. The same is true for similar Norwegian and Danish names.\nAnother common practice was to adopt one's place of origin as a middle or surname.\nEven more important a driver of change was the need, for administrative purposes, to develop a system under which each individual had a \"stable\" name from birth to death. In the old days, people would be known by their name, patronymic and the farm they lived at. This last element would change if a person got a new job, bought a new farm, or otherwise came to live somewhere else. (This is part of the origin, in this part of the world, of the custom of women changing their names upon marriage. Originally it indicated, basically, a change of address, and from older times, there are numerous examples of men doing the same thing). The many patronymic names may derive from the fact that people who moved from the country to the cities, also gave up the name of the farm they came from. As a worker, you passed by your father's name, and this name passed on to the next generation as a family name. Einar Gerhardsen, the Norwegian prime minister, used a true patronym, as his father was named Gerhard Olsen (Gerhard, the son of Ola). Gerhardsen passed his own patronym on to his children as a family name. This has been common in many working-class families. The tradition of keeping the farm name as a family name got stronger during the first half of the 20th century in Norway.\nThese names often indicated the place of residence of the family. For this reason, Denmark and Norway have a very high incidence of last names derived from those of farms, many signified by the suffixes like \"-b\u00f8\", \"-rud\", \"-heim/-um\", \"-land\" or \"-set\" (these being examples from Norway). In Denmark, the most common suffix is \"-gaard\" \u2014 the modern spelling is \"g\u00e5rd\" in Danish and can be either \"g\u00e5rd\" or \"gard\" in Norwegian, but as in Sweden, archaic spelling persists in surnames. The most well-known example of this kind of surname is probably \"Kierkegaard\" (combined by the words \"kirke/kierke\" (= church) and \"gaard\" (= farm) meaning \"the farm located by the Church\". It is, however, a common misunderstanding that the name relates to its direct translation: churchyard/cemetery), but many others could be cited. It should also be noted that, since the names in question are derived from the original owners' domiciles, the possession of this kind of name is no longer an indicator of affinity with others who bear it.\nIn many cases, names were taken from the nature around them. In Norway, for instance, there is an abundance of surnames based on coastal geography, with suffixes like \"-strand\", \"-\u00f8y\", \"-holm\", \"-vik\", \"-fjord\" or \"-nes\". Like the names derived from farms, most of these family names reflected the family's place of residence at the time the family name was \"fixed\", however. A family name such as Swedish \"Dahlgren\" is derived from \"dahl\" meaning valley and \"gren\" meaning branch; or similarly \"Upvall\" meaning \"upper-valley\"; It depends on the country, language, and dialect.\nSweden.\nIn Scandinavia family names often, but certainly not always, originate from a patronymic. Later on, people from the Scandinavian middle classes, particularly artisans and town dwellers, adopted surnames in a similar fashion to that of the gentry. Family names joining two elements from nature such as the Swedish \"Bergman\" (\"mountain man\"), \"Holmberg\" (\"island mountain\"), \"Lindgren\" (\"linden branch\"), \"Sandstr\u00f6m\" (\"sand stream\") and \"\u00c5kerlund\" (\"field grove\") were quite frequent and remain common today.\nFinland.\nFinland including Karelia and Estonia was the eastern part of The Kingdom of Sweden from its unification around 1100\u20131200 AD until the year 1809 when Finland was conquered by Russia. During the Russian revolution 1917, Finland proclaimed the republic Finland and Sweden and many European countries rapidly acknowledged the new nation Finland. Finland has mainly Finnish (increasing) and Swedish (decreasing) surnames and first names. There are two predominant surname traditions among the \"Finnish\" in Finland: the West Finnish and the East Finnish. The surname traditions of \"Swedish-speaking\" farmers, fishermen and craftsmen resembles the West Finnish tradition, while smaller populations of \"Sami\" and \"Romani people\" have traditions of their own. Finland was exposed to a very small immigration from Russia, so Russian names barely exists.\nUntil the mid-20th century, Finland was a predominantly agrarian society, and the names of West Finns were based on their association with a particular area, farm, or homestead, e.g. \"Jaakko Jussila\" (\"Jaakko from the farm of Jussi\"). On the other hand, the East Finnish surname tradition dates back to at least the 13th century. There, the Savonians pursued slash-and-burn agriculture which necessitated moving several times during a person's lifetime. This in turn required the families to have surnames, which were in wide use among the common folk as early as the 13th century. By the mid-16th century, the East Finnish surnames had become hereditary. Typically, the oldest East Finnish surnames were formed from the first names of the patriarchs of the families, e.g. \"Ik\u00e4valko\", \"Termonen\", \"Pentik\u00e4inen\". In the 16th, 17th, and 18th centuries, new names were most often formed by adding the name of the former or current place of living (e.g. \"Puumalainen\" &lt; Puumala). In the East Finnish tradition, the women carried the family name of their fathers in female form (e.g. \"Puumalatar\" &lt; \"Puumalainen\"). By the 19th century, this practice fell into disuse due to the influence of the West-European surname tradition.\nIn Western Finland, agrarian names dominated, and the last name of the person was usually given according to the farm or holding they lived on. In 1921, surnames became compulsory for all Finns. At this point, the agrarian names were usually adopted as surnames. A typical feature of such names is the addition of prefixes \"Ala-\" (Sub-) or \"Yl\u00e4-\" (Up-), giving the location of the holding along a waterway in relation of the main holding. (e.g. \"Yli-Ojanper\u00e4\", \"Ala-Verronen\"). The Swedish speaking farmers along the coast of \u00d6sterbotten usually used two surnames \u2013 one which pointed out the father's name (e.g. \"Eriksson\", \"Andersson\", \"Johansson\") and one which related to the farm or the land their family or bigger family owned or had some connection to (e.g. \"Holm\", \"Fant\", \"Westerg\u00e5rd\", \"Kloo\"). So a full name could be \"Johan Karlsson Kvist\", for his daughter \"Elvira Johansdotter Kvist\", and when she married a man with the Ahlskog farm, Elvira kept the first surname Johansdotter but changed the second surname to her husbands (e.g. \"Elvira Johansdotter Ahlskog\"). During the 20th century they started to drop the -son surname while they kept the second. So in Western Finland the Swedish speaking had names like \"Johan Varg\", \"Karl Viskas\", \"Sebastian Byskata\" and \"Elin Loo\", while the Swedes in Sweden at the other side of the Baltic Sea kept surnames ending with \"-son\" (e.g. \"Johan Eriksson\", \"Thor Andersson\", \"Anna-Karin Johansson\").\nA third tradition of surnames was introduced in south Finland by the Swedish-speaking upper and middle classes, which used typical German and Swedish surnames. By custom, all Finnish-speaking persons who were able to get a position of some status in urban or learned society, discarded their Finnish name, adopting a Swedish, German or (in the case of clergy) Latin surname. In the case of enlisted soldiers, the new name was given regardless of the wishes of the individual.\nIn the late 19th and early 20th century, the overall modernization process, and especially the political movement of fennicization, caused a movement for adoption of Finnish surnames. At that time, many persons with a Swedish or otherwise foreign surname changed their family name to a Finnish one. The features of nature with endings \"-o/\u00f6\", \"-nen\" (\"Meri\u00f6\" &lt; \"Meri\" \"sea\", \"Nieminen\" &lt; \"Niemi\" \"point\") are typical of the names of this era, as well as more or less direct translations of Swedish names (\"Paasivirta\" &lt; \"H\u00e4llstr\u00f6m\").\nIn 21st-century Finland, the use of surnames follows the German model. Every person is legally obligated to have a first and last name. At most, three first names are allowed. The Finnish married couple may adopt the name of either spouse, or either spouse (or both spouses) may decide to use a double name. The parents may choose either surname or the double surname for their children, but all siblings must share the same surname. All persons have the right to change their surname once without any specific reason. A surname that is un-Finnish, contrary to the usages of the Swedish or Finnish languages, or is in use by any person residing in Finland cannot be accepted as the new name, unless valid family reasons or religious or national customs give a reason for waiving this requirement. However, persons may change their surname to any surname that has ever been used by their ancestors if they can prove such claim. Some immigrants have had difficulty naming their children, as they must choose from an approved list based on the family's household language.\nIn the Finnish language, both the root of the surname and the first name can be modified by consonant gradation regularly when inflected to a case.\nIceland.\nIn Iceland, most people have no family name; a person's last name is most commonly a patronymic, i.e. derived from the father's first name. For example, when a man called \"Karl\" has a daughter called \"Anna\" and a son called \"Magn\u00fas\", their full names will typically be \"Anna Karlsd\u00f3ttir\" (\"Karl's daughter\") and \"Magn\u00fas Karlsson\" (\"Karl's son\"). The name is not changed upon marriage.\nSlavic world.\nSlavic countries are noted for having masculine and feminine versions for many (but not all) of their names. In most countries the use of a feminine form is obligatory in official documents as well as in other communication, except for foreigners. In some countries only the male form figures in official use (Bosnia and Herzegovina, Croatia, Montenegro, Serbia, Slovenia), but in communication (speech, print) a feminine form is often used.\nIn Slovenia the last name of a female is the same as the male form in official use (identification documents, letters). In speech and descriptive writing (literature, newspapers) a female form of the last name is regularly used.\nIf the name has no suffix, it may or may not have a feminine version. Sometimes it has the ending changed (such as the addition of \"-a\"). In the Czech Republic and Slovakia, suffixless names, such as those of German origin, are feminized by adding \"-ov\u00e1\" (for example, \"Schusterov\u00e1\").\nBulgaria.\nBulgarian names usually consist of three components \u2013 given name, patronymic (based on father's name), family name.\nGiven names have many variations, but the most common names have Christian/Greek (e.g. Maria, Ivan, Christo, Peter, Pavel), Slavic (Ognyan, Miroslav, Tihomir) or Protobulgarian (Krum, Asparukh) (pre-Christian) origin.\nFather's names normally consist of the father's first name and the \"-ov\" (male) or \"-ova\" (female) or \"-ovi\" (plural) suffix.\nFamily names usually also end with the \"-ov\", \"-ev\" (male) or \"-ova\", \"-eva\" (female) or \"-ovi\", \"-evi\" (plural) suffix.\nIn many cases (depending on the name root) the suffixes can be also \"-ski\" (male and plural) or \"-ska\" (female); \"-ovski\", \"-evski\" (male and plural) or \"-ovska\", \"-evska\" (female); \"-in\" (male) or \"-ina\" (female) or \"-ini\" (plural); etc.\nThe meaning of the suffixes is similar to the English word \"of\", expressing membership in/belonging to a family.\nFor example, the family name Ivanova means a person belonging to the Ivanovi family.\nA father's name Petrov means son of Peter.\nRegarding the different meaning of the suffixes, \"-ov\", \"-ev\"/\"-ova\", \"-eva\" are used for expressing relationship to the father and \"-in\"/\"-ina\" for relationship to the mother (often for orphans whose father is dead).\nCzech Republic and Slovakia.\nNames of Czech people consist of given name (\"k\u0159estn\u00ed jm\u00e9no\") and surname (\"p\u0159\u00edjmen\u00ed\"). Usage of the second or middle name is not common. Feminine names are usually derived from masculine ones by a suffix \"-ov\u00e1\" (\"Nov\u00e1kov\u00e1\") or \"-\u00e1\" for names being originally adjectives (\"Vesel\u00e1\"), sometimes with a little change of original name's ending (\"Sedl\u00e1\u010dkov\u00e1\" from \"Sedl\u00e1\u010dek\" or \"Svobodov\u00e1\" from \"Svoboda\"). Women usually change their family names when they get married. The family names are usually nouns (\"Svoboda\", \"Kr\u00e1l\", \"R\u016f\u017ei\u010dka\", \"Dvo\u0159\u00e1k\", \"Bene\u0161\"), adjectives (\"Novotn\u00fd\", \"\u010cern\u00fd\", \"Vesel\u00fd\") or past participles of verbs (\"Posp\u00ed\u0161il\"). There are also a couple of names with more complicated origin which are actually complete sentences (\"Sko\u010ddopole\", \"Hrejsemnou\" or \"V\u00edt\u00e1mv\u00e1s\"). The most common Czech family name is \"Nov\u00e1k\" / \"Nov\u00e1kov\u00e1\".\nIn addition, many Czechs and some Slovaks have German surnames due to mixing between the ethnic groups over the past thousand years. Deriving women's names from German and other foreign names is often problematic since foreign names do not suit Czech language rules, although most commonly \"-ov\u00e1\" is simply added (\"Schmidtov\u00e1\"; umlauts are often, but not always, dropped, e.g. \"M\u00fcllerov\u00e1\"), or the German name is respelled with Czech spelling (\"\u0160mitov\u00e1\"). Hungarian names, which can be found fairly commonly among Slovaks, can also be either left unchanged (Hungarian \"Nagy\", fem. \"Nagyov\u00e1\") or respelled according to Czech/Slovak orthography (masc. \"Na\u010f\", fem. \"Na\u010fov\u00e1\").\nPoland.\nIn Poland and most of the former Polish\u2013Lithuanian Commonwealth, surnames first appeared during the late Middle Ages. They initially denoted the differences between various people living in the same town or village and bearing the same name. The conventions were similar to those of English surnames, using occupations, patronymic descent, geographic origins, or personal characteristics. Thus, early surnames indicating occupation include \"Karczmarz\" (\"innkeeper\"), \"Kowal\" (\"blacksmith\"), \"Z\u0142otnik\" (\"gold smith\") and \"Bednarczyk\" (\"young cooper\"), while those indicating patronymic descent include \"Szczepaniak\" (\"Son of \"Szczepan\"), \"J\u00f3zefowicz\" (\"Son of \"J\u00f3zef\"), and \"Ka\u017amirkiewicz\" (\"Son of \"Kazimierz\"\"). Similarly, early surnames like \"Mazur\" (\"the one from Mazury\") indicated geographic origin, while ones like \"Nowak\" (\"the new one\"), \"Bia\u0142y\" (\"the pale one\"), and \"Wielgus\" (\"the big one\") indicated personal characteristics.\nIn the early 16th century, (the Polish Renaissance), toponymic names became common, especially among the nobility. Initially, the surnames were in a form of \"[first name] \"z\" (\"de\", \"of\") [location]\". Later, most surnames were changed to adjective forms, e.g. \"Jakub Wi\u015blicki\" (\"James of Wi\u015blica\") and \"Zbigniew Ole\u015bnicki\" (\"\"Zbigniew\" of Ole\u015bnica\"), with masculine suffixes \"-ski\", \"-cki\", \"-dzki\" and \"-icz\" or respective feminine suffixes \"-ska\", \"-cka\", \"-dzka\" and \"-icz\" on the east of Polish\u2013Lithuanian Commonwealth. Names formed this way are adjectives grammatically, and therefore change their form depending on sex; for example, \"Jan Kowalski\" and \"Maria Kowalska\" collectively use the plural \"Kowalscy\".\nNames with masculine suffixes \"-ski\", \"-cki\", and \"-dzki\", and corresponding feminine suffixes \"-ska\", \"-cka\", and \"-dzka\" became associated with noble origin. Many people from lower classes successively changed their surnames to fit this pattern. This produced many \"Kowalski\"s, \"Bednarski\"s, \"Kaczmarski\"s and so on.\nA separate class of surnames derive from the names of noble clans. These are used either as separate names or the first part of a double-barrelled name. Thus, persons named \"Jan Nieczuja\" and \"Krzysztof Nieczuja-Machocki\" might be related. Similarly, after World War I and World War II, many members of Polish underground organizations adopted their war-time pseudonyms as the first part of their surnames. \"Edward Rydz\" thus became Marshal of Poland \"Edward \u015amig\u0142y-Rydz\" and \"Zdzis\u0142aw Jeziora\u0144ski\" became \"Jan Nowak-Jeziora\u0144ski\".\nRussia.\nA full Russian name consists of personal (given) name, patronymic, and family name (surname).\nMost Russian family names originated from patronymics, that is, father's name usually formed by adding the adjective suffix \"-ov(a)\" or \"-ev(a)\". Contemporary patronymics, however, have a substantive suffix \"-ich\" for masculine and the adjective suffix \"-na\" for feminine.\nFor example, the proverbial triad of most common Russian surnames follows:\nFeminine forms of these surnames have the ending \"-a\":\nSuch a pattern of name formation is not unique to Russia or even to the Eastern and Southern Slavs in general; quite common are also names derived from professions, places of origin, and personal characteristics, with various suffixes (e.g. \"-in(a)\" and \"-sky (-skaya)\").\nProfessions:\nPlaces of origin:\nPersonal characteristics:\nA considerable number of \"artificial\" names exists, for example, those given to seminary graduates; such names were based on Great Feasts of the Orthodox Church or Christian virtues.\nGreat Orthodox Feasts:\nChristian virtues:\nMany freed serfs were given surnames after those of their former owners. For example, a serf of the Demidov family might be named \"Demidovsky\", which translates roughly as \"belonging to Demidov\" or \"one of Demidov's bunch\".\nGrammatically, Russian family names follow the same rules as other nouns or adjectives (names ending with \"-oy\", \"-aya\" are grammatically adjectives), with exceptions: some names do not change in different cases and have the same form in both genders (for example, \"Sedykh\", \"Lata\").\nUkraine and Belarus.\nUkrainian and Belarusian names evolved from the same Old East Slavic and Ruthenian language (western Rus') origins. Ukrainian and Belarusian names share many characteristics with family names from other Slavic cultures. Most prominent are the shared root words and suffixes. For example, the root \"koval\" (blacksmith) compares to the Polish \"kowal\", and the root \"bab\" (woman) is shared with Polish, Slovakian, and Czech. The suffix \"-vych\" (son of) corresponds to the South Slavic \"-vic\", the Russian \"-vich\", and the Polish \"-wicz\", while \"-sky\", \"-ski\", and \"-ska\" are shared with both Polish and Russian, and \"-ak\" with Polish.\nHowever some suffixes are more uniquely characteristic to Ukrainian and Belarusian names, especially: \"-chuk\" (Western Ukraine), \"-enko\" (all other Ukraine) (both son of), \"-ko\" (little [masculine]), \"-ka\" (little [feminine]), \"-shyn\", and \"-uk\". See, for example, Mihalko, Ukrainian Presidents Leonid Kravchuk, and Viktor Yushchenko, Belarusian President Alexander Lukashenko, or former Soviet diplomat Andrei Gromyko. Such Ukrainian and Belarusian names can also be found in Russia, Poland, or even other Slavic countries (e.g. Croatian general Zvonimir \u010cervenko), but are due to importation by Ukrainian, Belarusian, or Rusyn ancestors.\nSouth Slavs.\nEndings in -i\u0107 and -i\u010d.\nSurnames of some South Slavic groups such as Serbs, Croats, Montenegrins, and Bosniaks traditionally end with the suffixes \"-i\u0107\" and \"-vi\u0107\" (often transliterated to English and other western languages as \"ic\", \"ich\", \"vic\" or \"vich\". The v is added in the case of a name to which \"-i\u0107\" is appended would otherwise end with a vowel, to avoid double vowels with the \"i\" in \"-i\u0107\".) These are a diminutive indicating descent i.e. \"son of\". In some cases the family name was derived from a profession (e.g. blacksmith \u2013 \"Kova\u010d\" \u2192 \"Kova\u010devi\u0107\").\nAn analogous ending is also common in Slovenia. As the Slovenian language does not have the softer consonant \"\u0107\", in Slovene words and names only \"\u010d\" is used. So that people from the former Yugoslavia need not change their names, in official documents \"\u0107\" is also allowed (as well as \"\u0110 / \u0111\"). Thus, one may have two surname variants, e.g.: Bo\u017ei\u010d, Tom\u0161i\u010d (Slovenian origin or assimilated) and Bo\u017ei\u0107, Tom\u0161i\u0107 (roots from the Serbo-Croat language continuum area). Slovene names ending in -i\u010d do not necessarily have a patrimonial origin.\nIn general family names in all of these countries follow this pattern with some family names being typically Serbian, some typically Croat and yet others being common throughout the whole linguistic region.\nChildren usually inherit their fathers' family name. In an older naming convention which was common in Serbia up until the mid-19th century, a person's name would consist of three distinct parts: the person's given name, the patronymic derived from the father's personal name, and the family name, as seen, for example, in the name of the language reformer Vuk Stefanovi\u0107 Karad\u017ei\u0107.\nOfficial family names do not have distinct male or female forms, except in North Macedonia, though a somewhat archaic unofficial form of adding suffixes to family names to form female form persists, with \"-eva\", implying \"daughter of\" or \"female descendant of\" or \"-ka\", implying \"wife of\" or \"married to\". In Slovenia the feminine form of a surname (\"-eva\" or \"-ova\") is regularly used in non-official communication (speech, print), but not for official IDs or other legal documents.\nBosniak Muslim names follow the same formation pattern but are usually derived from proper names of Islamic origin, often combining archaic Islamic or feudal Turkish titles i.e. Mulaomerovi\u0107, \u0160abanovi\u0107, Had\u017eihafizbegovi\u0107, etc. Also related to Islamic influence is the prefix \"Had\u017ei-\" found in some family names. Regardless of religion, this prefix was derived from the honorary title which a distinguished ancestor earned by making a pilgrimage to either Christian or Islamic holy places; Had\u017eibegi\u0107, being a Bosniak Muslim example, and Had\u017eianti\u0107 an Orthodox Christian one.\nIn Croatia where tribal affiliations persisted longer, Lika, Herzegovina etc., originally a family name, came to signify practically all people living in one area, clan land or holding of the nobles. The \u0160ubi\u0107 family owned land around the Zrin River in the Central Croatian region of Banovina. The surname became \u0160ubi\u0107 Zrinski, the most famous being Nikola \u0160ubi\u0107 Zrinski.\nIn Montenegro and Herzegovina, family names came to signify all people living within one clan or bratstvo. As there exists a strong tradition of inheriting personal names from grandparents to grandchildren, an additional patronymic usually using suffix \"-ov\" had to be introduced to make distinctions between two persons bearing the same personal name and the same family name and living within same area. A noted example is Marko Miljanov Popovi\u0107, i.e. Marko, son of Miljan, from Popovi\u0107 family.\nDue to discriminatory laws in the Austro-Hungarian Empire, some Serb families of Vojvodina discarded the suffix \"-i\u0107\" in an attempt to mask their ethnicity and avoid heavy taxation.\nThe prefix \"Pop-\" in Serbian names indicates descent from a priest, for example Gordana Pop Lazi\u0107, i.e. descendant of Pop Laza.\nSome Serbian family names include prefixes of Turkish origin, such as \"Uzun-\" meaning tall, or \"Kara-\", black. Such names were derived from nicknames of family ancestors. A famous example is Kara\u0111or\u0111evi\u0107, descendants of \u0110or\u0111e Petrovi\u0107, known as Kara\u0111or\u0111e or Black \u0110or\u0111e.\nEndings -ov and -ski.\nAmong the Bulgarians, another South Slavic people, the typical surname suffix is \"-ov\" (Ivanov, Kovachev), although other popular suffixes also exist.\nIn North Macedonia, the most popular suffix today is \"-ski\".\nSlovenia.\nSlovenes have a great variety of surnames, most of them differentiated according to region. Surnames ending in -i\u010d are by far less frequent than among Croats and Serbs. There are typically Slovenian surnames ending in -i\u010d, such as Bla\u017ei\u010d, Stani\u010d, Maru\u0161i\u010d. Many Slovenian surnames, especially in the Slovenian Littoral, end in -\u010di\u010d (Gregor\u010di\u010d, Kocijan\u010di\u010d, Miklav\u010di\u010d, etc.), which is uncommon for other South Slavic peoples (except the neighboring Croats, e.g. Kova\u010di\u0107, Jela\u010di\u0107, Kranj\u010di\u0107, etc.). On the other hand, surname endings in -ski and -ov are rare, they can denote a noble origin (especially for the -ski, if it completes a toponym) or a foreign (mostly Czech) origin. One of the most typical Slovene surname endings is -nik (Rupnik, Pu\u010dnik, Ple\u010dnik, Poga\u010dnik, Podobnik) and other used surname endings are -lin (Pavlin, Mehlin, Ahlin, Ferlin), -ar (Mlakar, Ravnikar, Smrekar Tisnikar) and -lj (Rugelj, Pucelj, Bagatelj, Bricelj). Many Slovenian surnames are linked to Medieval rural settlement patterns. Surnames like Novak (literally, \"the new one\") or Hribar (from \"hrib\", hill) were given to the peasants settled in newly established farms, usually in high mountains. Peasant families were also named according to the owner of the land which they cultivated: thus, the surname Kralj (King) or Cesar (Emperor) was given to those working on royal estates, \u0160kof (Bishop) or Vidmar to those working on ecclesiastical lands, etc. Many Slovenian surnames are named after animals (Medved \u2013 bear, Volk, Vovk or Vouk \u2013 wolf, Golob \u2013 pigeon, Strnad \u2013 yellowhammer, Orel \u2013 eagle, Lisjak \u2013 fox, or Zajec \u2013 rabbit, etc.) or plants P\u0161enica \u2013 wheat, Slak \u2013 bindweed, Hrast \u2013 oak, etc. Many are named after neighbouring peoples: Horvat, Hrovat, or Hrovatin (Croat), Furlan (Friulian), Nemec (German), Lah (Italian), Vogrin, Vogri\u010d or Vogrin\u010di\u010d (Hungarian), Vo\u0161njak (Bosnian), \u010ceh (Czech), Turk (Turk), or different Slovene regions: Kranjc, Kranjec or Krajnc (from Carniola), Kra\u0161evec (from the Karst Plateau), Koro\u0161ec (from Carinthia), Ko\u010devar or Ho\u010devar (from the Gottschee county).\nUse of feminine surnames in Slovenia.\nIn Slovenia last name of a female is the same as the male form in official use (identification documents, letters). In speech and descriptive writing (literature, newspapers) a female form of the last name is regularly used. Examples: Novak (m.) &amp; Novakova (f.), Kralj (m.) &amp; Kraljeva (f.), Mali (m.) &amp; Malijeva (f.). Usually surenames on -ova are used together with the title/gender: gospa Novakova (Mrs. Novakova), gospa Kraljeva (Mrs. Kraljeva), gospodi\u010dna Malijeva (Miss Malijeva, if unmarried), etc. or with the name. So we have Maja Novak on the ID card and Novakova Maja (extremely rarely Maja Novakova) in communication; Tja\u0161a Mali and Malijeva Tja\u0161a (rarely Tja\u0161a Malijeva); respectively. Diminutive forms of last names for females are also available: Novakovka, Kraljevka. As for pronunciation, in Slovenian there is some leeway regarding accentuation. Depending on the region or local usage, you may have either N\u00f3vak &amp; N\u00f3vakova or, more frequently, Nov\u00e1k &amp; Nov\u00e1kova. Accent marks are normally not used.\nArabic-speaking countries.\nThe given name is always followed by the father's first name, then the father's family surname.\nSome surnames have a prefix of \"ibn\"- (\"ould\"- in Mauritania) meaning \"son of\".\nThe surnames follow similar rules defining a relation to a clan, family, place etc.\nSome Arab countries have differences due to historic rule by the Ottoman Empire or due to being a different minority.\nA large number of Arabic last names start with \"Al-\" which means \"The\"\nArab States of the Persian Gulf:\nNames mainly consist of the person's name followed by the father's first name connected by the word \"ibn\" or \"bin\" (meaning \"son of\"). The last name either refers to the name of the tribe the person belongs to, or to the region, city, or town he/she originates from. In exceptional cases, members of the royal families or ancient tribes mainly, the title (usually H.M./H.E., Prince, or Sheikh) is included in the beginning as a prefix, and the first name can be followed by four names, his father, his grandfather, and great \u2013 grandfather, as a representation of the purity of blood and to show the pride one has for his ancestry.\nIn Arabic-speaking Levantine countries (Jordan, Lebanon, Palestine, Syria) it's common to have family names associated with a certain profession or craft, such as \"Al-Haddad\"/\"Haddad\" which means \"Blacksmith\" or \"Al-Najjar\"/\"Najjar\" which means \"Carpenter\".\nIndian Subcontinent.\nIndia.\nIn India, surnames are placed as last names or before first names, which often denote: village of origin, caste, clan, office of authority their ancestors held, or trades of their ancestors. The use of surnames is a relatively new convention, introduced during British colonisation. Typically, parts of northern India follow English-speaking Western naming conventions by having a given name followed by a surname. This is not necessarily the case in southern India, where people may adopt a surname out of necessity when migrating or travelling abroad.\nThe largest variety of surnames is found in the states of Maharashtra and Goa, which numbers more than the rest of India together. Here surnames are placed last, the order being: the given name, followed by the father's name, followed by the family name. The majority of surnames are derived from the place where the family lived, with the 'kar' (Marathi and Konkani) suffix, for example, Mumbaikar, Punekar, Aurangabadkar, Tendulkar, Parrikar, Mangeshkar, Mahendrakar. Another common variety found in Maharashtra and Goa are the ones ending in 'e'. These are usually more archaic than the 'Kar's and usually denote medieval clans or professions like Rane, Salunkhe, Gupte, Bhonsle, Ranadive, Rahane, Hazare, Apte, Satpute, Shinde, Sathe, Londhe, Salve, Kale, Gore, Godbole, etc.\nIn Andhra Pradesh and Telangana, surnames usually denote family names. It is easy to track family history and the caste they belonged to using a surname.\nIn Odisha and West Bengal, surnames denote the caste they belong. There are also several local surnames like Das, Patnaik, Mohanty, Jena etc.\nIn Kerala, surnames denote the caste they belong. There are also several local surnames like Nair, Menon, Panikkar etc.\nIt is a common in Kerala, Tamil Nadu, and some other parts of South India that the spouse adopts her husband's first name instead of his family or surname name after marriage.\nIn Rajasthan, the community name and sometimes the gotra or clan name are used as surnames. Usage of community name as surname include: Charan, Jat, Meena, Rajput, etc. Sometimes, the faith name (for example: Jain) can also be used as a surname.\nIndia is a country with numerous distinct cultural and linguistic groups. Thus, Indian surnames, where formalized, fall into seven general types.\nSurnames are based on:\nThe convention is to write the first name followed by middle names and surname. It is common to use the father's first name as the middle name or last name even though it is not universal. In some Indian states like Maharashtra, official documents list the family name first, followed by a comma and the given names.\nIn modern times, in urban areas at least, this practice is not universal and some wives either suffix their husband's surname or do not alter their surnames at all. In some rural areas, particularly in North India, wives may also take a new first name after their nuptials. Children inherit their surnames from their father.\nJains generally use Jain, Shah, Firodia, Singhal or Gupta as their last names. Sikhs generally use the words \"Singh\" (\"lion\") and \"Kaur\" (\"princess\") as surnames added to the otherwise unisex first names of men and women, respectively. It is also common to use a different surname after Singh in which case Singh or Kaur are used as middle names (Montek Singh Ahluwalia, Surinder Kaur Badal). The tenth Guru of Sikhism ordered (Hukamnama) that any man who considered himself a Sikh must use \"Singh\" in his name and any woman who considered herself a Sikh must use \"Kaur\" in her name. Other middle names or honorifics that are sometimes used as surnames include Kumar, Dev, Lal, and Chand.\nThe modern-day spellings of names originated when families translated their surnames to English, with no standardization across the country. Variations are regional, based on how the name was translated from the local language to English in the 18th, 19th and 20th centuries during British rule. Therefore, it is understood in the local traditions that Baranwal and Barnwal represent the same name derived from Uttar Pradesh and Punjab respectively. Similarly, Tagore derives from Bengal while Thakur is from Hindi-speaking areas. The officially recorded spellings tended to become the standard for that family. In the modern times, some states have attempted standardization, particularly where the surnames were corrupted because of the early British insistence of shortening them for convenience. Thus Bandopadhyay became Banerji, Mukhopadhay became Mukherji, Chattopadhyay became Chatterji, etc. This coupled with various other spelling variations created several surnames based on the original surnames. The West Bengal Government now insists on re-converting all the variations to their original form when the child is enrolled in school.\nSome parts of Sri Lanka, Thailand, Nepal, Myanmar, and Indonesia have similar patronymic customs to those of India.\nNepal.\nNepali surnames are divided into three origins; Indo-Aryan languages, Tibeto-Burman languages and indigenous origins. Surnames of Khas community contains toponyms as Ghimire, Dahal, Pokharel, Sapkota from respective villages, occupational names as (Adhikari, Bhandari, Karki, Thapa). Many Khas surnames includes suffix as -wal, -al as in Katwal, Silwal, Khanal, Khulal, Rijal. Kshatriya titles such as Bista, Kunwar, Rana, Rawal, Shah, Thakuri, Chand, were taken as surnames by various Kshetri and Thakuris. Khatri Kshetris share surnames with mainstream Pahari Bahuns. Other popular Chhetri surnames include Basnyat, Bogati, Budhathoki, Khadka, Mahat, Raut. Similarly, Brahmin surnames such as Acharya, Joshi, Pandit, Sharma, Upadhyay were taken by Pahari Bahuns. Bahuns bear distinct surnames as Kattel, and share surnames with mainstream Bahuns. Other Bahun surnames include Aryal, Bhattarai, Banskota, Chaulagain, Devkota, Dhakal, Gyawali, Koirala, Mainali, Pandey, Panta, Paudel, Regmi, Subedi, Lamsal, and Dhungel. Khas-Dalits surnames include Kami, Bishwakarma or B.K., Damai, Mijar, Pariyar, Sarki. Newar groups of multiethnic background bears both Indo-Aryan surnames (like Shrestha, Pradhan) and indigenous surnames like Maharjan, Dangol. Magars bear surnames derived from Khas peoples such as Baral, Budhathoki, Lamichhane, Thapa and indigenous origins as Gharti, Pun, Pulami. Other Himalayan Mongoloid castes bears Tibeto-Burmese surnames like Gurung, Tamang, Thakali, Sherpa. Various Kiranti ethnic group contains many Indo-Aryan surnames of Khas origin which were awarded by the government of Khas peoples. These surnames are Rai, Subba depending upon job and position hold by them. Terai community consists both Indo-Aryan and Indigenous origin surnames. Terai Brahmins bears surnames as Jha. Nepalese Muslims bears Islamic surnames such as Ali, Ansari, Begum, Khan, Mohammad, Pathan. Other common Terai surnames are Kayastha.\nPakistan.\nPakistani surnames are basically divided in three categories: Arab naming convention, tribal or caste names and ancestral names.\nFamily names indicating Arab ancestry, e.g. Shaikh, Siddiqui, Abbasi, Syed, Zaidi, Khawaja, Naqvi, Farooqi, Osmani, Alavi, Hassani, and Husseini.\nPeople claiming Afghan ancestry include those with family names like Durrani, Gardezi, Suri, Yousafzai, Afridi, Mullagori, Mohmand, Khattak, Wazir, Mehsud, Niazi.\nFamily names indicating Turkic heritage include Mughal, Baig or Beg, Pasha, Barlas, and Seljuki. Family names indicating Turkish/Kurd ancestry, Dogar.\nPeople claiming Indic ancestry include those with family names Barelwi, Lakhnavi, Delhvi, Godharvi, Bilgrami, and Rajput. A large number of Muslim Rajputs have retained their surnames such as Chauhan, Rathore, Parmar, and Janjua.\nPeople claiming Iranian ancestry include those with family names Agha, Bukhari, Firdausi, Ghazali, Gilani, Hamadani, Isfahani, Kashani, Kermani, Khorasani, Farooqui, Mir, Mirza, Montazeri, Nishapuri, Noorani, Kayani, Qizilbash, Saadi, Sabzvari, Shirazi, Sistani, Suhrawardi, Yazdani, Zahedi, and Zand.\nTribal names include Abro Afaqi, Afridi, Cheema, Khogyani (Khakwani), Amini, Ansari, Ashrafkhel, Awan, Bajwa, Baloch, Barakzai, Baranzai, Bhatti, Bhutto, Ranjha, Bijarani, Bizenjo, Brohi, Khetran, Bugti, Butt, Farooqui, Gabol, Ghaznavi, Ghilzai, Gichki, Gujjar, Jamali, Jamote, Janjua, Jatoi, Jutt Joyo, Junejo, Karmazkhel, Kayani, Khar, Khattak, Khuhro, Lakhani, Leghari, Lodhi, Magsi, Malik, Mandokhel, Mayo, Marwat, Mengal, Mughal, Palijo, Paracha, Panhwar, Phul, Popalzai, Qureshi &amp; qusmani, Rabbani, Raisani, Rakhshani, Sahi, Swati, Soomro, Sulaimankhel, Talpur, Talwar, Thebo, Yousafzai, and Zamani.\nIn Pakistan, the official paperwork format regarding personal identity is as follows:\nSo and so, son of so and so, of such and such tribe or clan and religion and resident of such and such place. For example, Amir Khan s/o Fakeer Khan, tribe Mughal Kayani or Chauhan Rajput, Follower of religion Islam, resident of Village Anywhere, Tehsil Anywhere, District.\nSinosphere.\nIn modern Chinese, Japanese, Korean, Taiwanese, and Vietnamese, the family name is placed before the given names, although this order may not be observed in translation. Generally speaking, Chinese, Korean, and Vietnamese names do not alter their order in English (Mao Zedong, Kim Jong-il, Ho Chi Minh) and Japanese names do (Kenzabur\u014d \u014ce). However, numerous exceptions exist, particularly for people born in English-speaking countries such as Yo-Yo Ma. This is sometimes systematized: in all Olympic events, the athletes of the People's Republic of China list their names in the Chinese ordering, while Chinese athletes representing other countries, such as the United States, use the Western ordering. (In Vietnam, the system is further complicated by the cultural tradition of addressing people by their given name, usually with an honorific. For example, Phan V\u0103n Kh\u1ea3i is \"properly\" addressed as Mr.\u2009Kh\u1ea3i, even though Phan is his family name.)\nChinese family names have many types of origins, some claiming dates as early as the legendary Yellow Emperor (2nd millennium BC):\nIn history, some changed their surnames due to a naming taboo (from Zhuang \u838a to Yan \u56b4 during the era of Liu Zhuang \u5289\u838a) or when the imperial surname was awarded by the Emperor (the imperial surname Li was often bestowed on senior officers during the Tang dynasty).\nIn modern times, some Chinese adopt an English name in addition to their native given names: e.g., adopted the English name Martin Lee. Particularly in Hong Kong and Singapore, the convention is to write both names together: Martin Lee Chu-ming. Owing to the confusion this can cause, a further convention is sometimes observed of capitalizing the surname: Martin L Chu-ming. Sometimes, however, the Chinese given name is forced into the Western system as a middle name (\"Martin Chu-ming Lee\"); less often, the English given name is forced into the Chinese system (\"Lee Chu-ming Martin\").\nIn Japan, the civil law forces a common surname for every married couple, unless in a case of international marriage. In most cases, women surrender their surnames upon marriage, and use the surnames of their husbands. However, a convention that a man uses his wife's family name if the wife is an only child is sometimes observed. A similar tradition called \"ru zhui\" (\u5165\u8d05) is common among Chinese when the bride's family is wealthy and has no son but wants the heir to pass on their assets under the same family name. The Chinese character \"zhui\" (\u8d05) carries a money radical (\u8c9d), which implies that this tradition was originally based on financial reasons. All their offspring carry the mother's family name. If the groom is the first born with an obligation to carry his own ancestor's name, a compromise may be reached in that the first male child carries the mother's family name while subsequent offspring carry the father's family name. The tradition is still in use in many Chinese communities outside mainland China, but largely disused in China because of social changes from communism. Due to the economic reform in the past decade, accumulation and inheritance of personal wealth made a comeback to the Chinese society. It is unknown if this financially motivated tradition would also come back to mainland China.\nIn Chinese, Korean, Vietnamese and Singaporean cultures, women keep their own surnames, while the family as a whole is referred to by the surnames of the husbands.\nIn Hong Kong, some women would be known to the public with the surnames of their husbands preceding their own surnames, such as Anson Chan Fang On Sang. Anson is an English given name, On Sang is the given name in Chinese, Chan is the surname of Anson's husband, and Fang is her own surname. A name change on legal documents is not necessary. In Hong Kong's English publications, her family names would have been presented in small cap letters to resolve ambiguity, e.g. Anson C F On Sang in full or simply Anson Chan in short form.\nIn Macau, some people have their names in Portuguese spelt with some Portuguese style, such as \"Carlos do Rosario Tchiang\".\nChinese women in Canada, especially Hongkongers in Toronto, would preserve their maiden names before the surnames of their husbands when written in English, for instance, Rosa Chan Leung, where Chan is the maiden name, and Leung is the surname of the husband.\nIn Chinese, Korean, and Vietnamese, surnames are predominantly monosyllabic (written with one character), though a small number of common disyllabic (or written with two characters) surnames exists (e.g. the Chinese name \"Ouyang\", the Korean name \"Jegal\" and the Vietnamese name \"Phan-Tran\").\nMany Chinese, Korean, and Vietnamese surnames are of the same origin, but simply pronounced differently and even transliterated differently overseas in Western nations. For example, the common Chinese surnames Chen, Chan, Chin, Cheng and Tan, the Korean surname Jin, as well as the Vietnamese surname Tr\u1ea7n are often all the same exact character \u9673. The common Korean surname Kim is also the common Chinese surname Jin, and written \u91d1. The common Mandarin surnames Lin or Lim (\u6797) is also one and the same as the common Cantonese or Vietnamese surname \"Lam\" and Korean family name Lim (written/pronounced as Im in South Korea). There are people with the surname of Hayashi (\u6797) in Japan too. The common Chinese surname \u674e, translated to English as Lee, is, in Chinese, the same character but transliterated as Li according to pinyin convention. Lee is also a common surname of Koreans, and the character is identical.\nVietnam.\n40% of all Vietnamese have the surname Nguyen. This may be because when a new dynasty took power in Vietnam it was custom to adopt that dynasty's surname. The last dynasty in Vietnam was the Nguyen dynasty, so as a result, many people have this surname.\nAfrica.\nBurundi and Rwanda.\nIn Burundi and Rwanda, most, if not all surnames have God in it, for example, Hakizimana (meaning God cures), Nshimirimana (I thank God) or Havyarimana/Habyarimana (God gives birth). But not all surnames end with the suffix -imana. Irakoze is one of these (technically meaning Thank God, though it is hard to translate it correctly in English or probably any other language). Surnames are often different among immediate family members, as parents frequently choose unique surnames for each child, and women keep their maiden names when married. Surnames are placed before given names and frequently written in capital letters, e.g. HAKIZIMANA Jacques.\nEast Africa.\nIn several Northeast Bantu languages such as Kamba, Taita and Kikuyu in Kenya the word \"wa\" (meaning \"of\") is inserted before the surname, for instance, Mugo wa Kibiru (Kikuyu) and Mekatilili wa Menza (Mijikenda).\nEthiopia and Eritrea.\nThe patronymic custom in most of the Horn of Africa gives children the father's first name as their surname. The family then gives the child its first name. Middle names are unknown. So, for example, a person's name might be \"Bereket Mekonen \". In this case, \"Bereket \" is the first name and \"Mekonen\" is the surname, and also the first name of the father.\nThe paternal grandfather's name is often used if there is a requirement to identify a person further, for example, in school registration. Also, different cultures and tribes use the father's or grandfather's given name as the family's name. For example, some Oromos use Warra Ali to mean families of Ali, where Ali, is either the householder, a father or grandfather.\nIn Ethiopia, the customs surrounding the bestowal and use of family names is as varied and complex as the cultures to be found there. There are so many cultures, nations or tribes, that currently there can be no one formula whereby to demonstrate a clear pattern of Ethiopian family names. In general, however, Ethiopians use their father's name as a surname in most instances where identification is necessary, sometimes employing both father's and grandfather's names together where exigency dictates.\nMany people in Eritrea have Italian surnames, but all of these are owned by Eritreans of Italian descent.\nLibya.\nLibya's names and surnames have a strong Islamic/Arab nature, with some Turkish influence from Ottoman Empire rule of nearly 400 years.\nAmazigh, Touareg and other minorities also have their own name/surname traditions.\nDue to its location as a trade route and the different cultures that had their impact on Libya throughout history, one can find names that could have originated in neighboring countries, including clan names from the Arabian Peninsula, and Turkish names derived from military rank or status (\"Basha\", \"Agha\").\nOther countries.\nAlbania.\nA full Albanian name consists of a given name (), patronymic () and family name (), for example \"Agron Mark Gjoni\". The patronymic is simply the given name of the individual's father, with no suffix added. The family name is typically a noun in the definite form or at the very least ends with a vowel or -j (an approximant close to -i). Many traditional last names end with -aj (previously -anj), which is more prevalent in certain regions of Albania and Kosovo. Family names are usually patrilineal, however, the mother's surname can be legally added if so wished by the parents.\nProper names in Albanian are fully declinable like any noun (e.g. \"Marinelda\", genitive case \"i/e Marineld\u00ebs\" \"of Marinelda\").\nArmenia.\nArmenian surnames almost always have the ending () transliterated into English as -yan or -ian (spelled -ean (\u0565\u0561\u0576) in Western Armenian and pre-Soviet Eastern Armenian, of Ancient Armenian or Iranian origin, presumably meaning \"son of\"), though names with that ending can also be found among Persians and a few other nationalities. Armenian surnames can derive from a geographic location, profession, noble rank, personal characteristic or personal name of an ancestor. Armenians in the diaspora sometimes adapt their surnames to help assimilation. In Russia, many have changed -yan to -ov (or -ova for women). In Turkey, many have changed the ending to -o\u011flu (also meaning \"son of\"). In English and French-speaking countries, many have shortened their name by removing the ending (for example Charles Aznavour). In ancient Armenia, many noble names ended with the locative -t'si (example, Khorenatsi) or -uni (Bagratuni). Several modern Armenian names also have a Turkish suffix which appears before -ian/-yan: -lian denotes a placename; -djian denotes a profession. Some Western Armenian names have a particle Der, while their Eastern counterparts have Ter. This particle indicates an ancestor who was a priest (Armenian priests can choose to marry or remain celibate, but married priests cannot become a bishop). Thus someone named Der Bedrosian (Western) or Ter Petrosian (Eastern) is a descendant of an Armenian priest. The convention is still in use today: the children of a priest named Hagop Sarkisian would be called Der Sarkisian. Other examples of Armenian surnames: Adonts, Sakunts, Vardanyants, Rshtuni.\nAzerbaijan.\nIt was common for Azerbaijani names to have 3 components: given name, father's name and family name. However, in recent years it is becoming increasingly popular to only have 2 components: first name and surname.\nWhile under Soviet rule, it was mandatory for Azerbaijanis to register their names, but most people did not have surnames. This was normally circumvented by taking the individual's father's name and adding a Russian suffixes such as \"-yev\"/\"-ov\" for men and \"-yeva/-ova\" for women (meaning \"born of\"). For example, from \"Ali\" we get \"Aliyev\" and \"Aliyeva\" and from \"Husein\" we get \"Huseinov\" and \"Huseinova\". However, as the Soviet era came to an end, many Azerbaijanis dropped these endings in an attempt to derussify. Some chose to replace these with traditional suffixes like \"-zade\" (Persian for \"born of\") and \"-li/-lu\" (Turkish for \"with\" or \"belonging to\"), \"-oglu/-oghlu\" (Turkish for \"son of\"). Some chose to drop the suffixes entirely.\nGeorgia.\nMost eastern Georgian surnames end with the suffix of \"-shvili\", (e.g. Kartveli'shvili) Georgian for \"child\" or \"offspring\". Western Georgian surnames most commonly have the suffix \"-dze\", (e.g. ) Georgian for \"son\". Megrelian surnames usually end in \"-ia\", \"-ua\" or \"-ava\". Other location-specific endings exist: In Svaneti \"-iani\", meaning \"belonging to\", or \"hailing from\", is common. In the eastern Georgian highlands common endings are \"uri\" and \"uli\". Some noble family names end in \"eli\", meaning \"of (someplace)\".\nIn Georgian, the surname is not normally used as the polite form of address; instead, the given name is used together with a title. For instance, Nikoloz Kartvelishvili is politely addressed as \"bat'ono Nikoloz\" \"My Lord. Nikoloz\".\nGreece and Cyprus.\nGreek surnames are most commonly patronymics. Occupation, characteristic, or ethnic background and location/origin-based surnames names also occur; they are sometimes supplemented by nicknames.\nCommonly, Greek male surnames end in -s, which is the common ending for Greek masculine proper nouns in the nominative case. Exceptionally, some end in -ou, indicating the genitive case of this proper noun for patronymic reasons.\nAlthough surnames are static today, dynamic and changing patronym usage survives in middle names in Greece where the genitive of the father's first name is commonly the middle name.\nBecause of their codification in the Modern Greek state, surnames have Katharevousa forms even though Katharevousa is no longer the official standard. Thus, the Ancient Greek name Eleutherios forms the Modern Greek proper name Lefteris, and former vernacular practice (prefixing the surname to the proper name) was to call John Eleutherios Leftero-giannis.\nModern practice is to call the same person Giannis Eleftheriou: the proper name is vernacular (and not Ioannis), but the surname is an archaic genitive. However, children are almost always baptised with the archaic form of the name so in official matters, the child will be referred to as Ioannis Eleftheriou and not Giannis Eleftheriou.\nFemale surnames are most often in the Katharevousa genitive case of a male name. This is an innovation of the Modern Greek state; Byzantine practice was to form a feminine counterpart of the male surname (e.g. masculine Palaiologos, Byzantine feminine Palaiologina, Modern feminine Palaiologou).\nIn the past, women would change their surname when married to that of their husband (again in the genitive case) signifying the transfer of \"dependence\" from the father to the husband. In earlier Modern Greek society, women were named with -aina as a feminine suffix on the husband's first name: \"Giorgaina\", \"Mrs George\", \"Wife of George\". Nowadays, a woman's legal surname does not change upon marriage, though she can use the husband's surname socially. Children usually receive the paternal surname, though in rare cases, if the bride and groom have agreed before the marriage, the children can receive the maternal surname.\nSome surnames are prefixed with Papa-, indicating ancestry from a priest, e.g. \"Papageorgiou\", the \"son of a priest named George\". Others, like Archi- and Mastro- signify \"boss\" and \"tradesman\" respectively.\nPrefixes such as Konto-, Makro-, and Chondro- describe body characteristics, such as \"short\", \"tall/long\" and \"fat\". \"Gero-\" and \"Palaio-\" signify \"old\" or \"wise\".\nOther prefixes include Hadji- (\u03a7\u03b1\u03bd\u03c4\u03b6\u03ae- or \u03a7\u03b1\u03bd\u03c4\u03b6\u03b9-) which was an honorific deriving from the Arabic Hadj or pilgrimage, and indicate that the person had made a pilgrimage (in the case of Christians, to Jerusalem) and Kara- which is attributed to the Turkish word for \"black\" deriving from the Ottoman Empire era. The Turkish suffix -oglou (derived from a patronym, \"-o\u011flu\" in Turkish) can also be found. Although they are of course more common among Greece's Muslim minority, they still can be found among the Christian majority, often Greeks or Karamanlides who were pressured to leave Turkey after the Turkish Republic was founded (since Turkish surnames only date to the founding of the Republic, when Atat\u00fcrk made them compulsory).\nArvanitic surnames also exist; an example is \"Tzanavaras\" or \"Tzavaras\", from the Arvanitic word \"\u00e7anavar\" or \"\u00e7avar\" meaning \"brave\" (\"pallikari\" in Greek).\nMost Greek patronymic suffixes are diminutives, which vary by region. The most common Hellenic patronymic suffixes are:\nOthers, less common, are:\nEither the surname or the given name may come first in different contexts; in newspapers and in informal uses, the order is \"given name + surname\", while in official documents and forums (tax forms, registrations, military service, school forms), the surname is often listed or said first.\nHungary.\nIn Hungarian, like Asian languages but unlike most other European ones (see French and German above for exceptions), the family name is placed before the given names. This usage does not apply to non-Hungarian names, for example \"Tony Blair\" will remain \"Tony Blair\" when written in Hungarian texts.\nNames of Hungarian individuals, however, appear in Western order in English writing.\nIndonesia.\nIndonesians comprise more than 600 ethnic groups. Not all of these groups traditionally have surnames, and in the populous Java surnames are not common at all \u2013 regardless of which one of the six officially recognized religions the name carrier profess. For instance, a Christian Javanese woman named \"Agnes Mega Rosalin\" has three forenames and no surname. \"Agnes\" is her Christian name, but \"Mega\" can be the first name she uses and the name which she is addressed with. \"Rosalin\" is only a middle name. Nonetheless, Indonesians are well aware of the custom of family names, which is known as \"marga\" or \"fam\", and such names have become a specific kind of identifier. People can tell what a person's heritage is by his or her family or clan name.\nJavanese people are the majority in Indonesia, and most do not have any surname. There are some individuals, especially the old generation, who have only one name, such as \"Suharto\" and \"Sukarno\". These are not only common with the Javanese but also with other Indonesian ethnic groups who do not have the tradition of surnames. If, however, they are Muslims, they might opt to follow Arabic naming customs, but Indonesian Muslims do not automatically follow Arabic name traditions.\nIn conjunction with migration to Europe or America, Indonesians without surnames often adopt a surname based on some family name or middle name. The forms for visa application many Western countries use, has a square for writing the last name which cannot be left unfilled by the applicant.\nMost Chinese Indonesians substituted their Chinese surnames with Indonesian-sounding surnames due to political pressure from 1965 to 1998 under Suharto's regime.\nIranian/Persian/Kazan.\nPersian last names may be:\nSuffixes include: -an (plural suffix), -i (\"of\"), -zad/-zadeh (\"born of\"), -pur (\"son of\"), -nejad (\"from the race of\"), -nia (\"descendant of\"), -mand (\"having or pertaining to\"), -vand (\"succeeding\"), -far (\"holder of\"), -doost (\"-phile\"), -khah (\"seeking of\"), -manesh (\"having the manner of\"), -ian/-yan, -gar and -chi (\"whose vocation pertains\").\nAn example is names of geographical locations plus \"-i\": Irani (\"Iranian\"), Gilani (\"of Gilan province\"), Tabrizi (\"of the city of Tabriz\").\nAnother example is last names that indicate relation to religious groups such as Zoroastrian (e.g. Goshtaspi, Namiranian, Azargoshasp), Jewish (e.g. Yaghubian [Jacobean], Hayyem [Life], Shaul [Saul]) or Muslim (e.g. Alavi, Islamnia, Montazeri)\nLast names are arbitrary; their holder need not to have any relation with their meaning.\nTraditionally in Iran, the wife does not take her husband's surname, although children take the surname of their father. Individual reactions notwithstanding, it is possible to call a married woman by her husband's surname. This is facilitated by the fact that English words \"Mrs.\", \"Miss\", \"Woman\", \"Lady\" and \"Wife (of)\" in a polite context are all translated into \"\u062e\u0627\u0646\u0645\" (Khaanom). Context, however, is important: \"\u062e\u0627\u0646\u0645 \u06af\u0644\u062f\u0648\u0633\u062a\" (Khaanom Goldust) may, for instance, refer to the daughter of Mr. Goldust instead of his wife.\nWhen most of Iranian surnames are used with a name, the name will be ended with a suffix _E or _ie (of) such as Hasan_e roshan (Hasan is name and roshan is surname) that means Hasan of Roshan or Mosa_ie saiidi (Muses of saiidi). The _e is not for surname and it is difficult to say it is a part of surname.\nItaly.\nItaly has around 350,000 surnames. Most of them derive from the following sources: patronym or ilk (e.g. \"Francesco di Marco\", \"Francis, son of Mark\" or \"Eduardo de Filippo\", \"Edward belonging to the family of Philip\"), occupation (e.g. \"Enzo Ferrari\", \"Heinz (of the) Blacksmiths\"), personal characteristic (e.g. nicknames or pet names like \"Dario Forte\", \"Darius the Strong\"), geographic origin (e.g. \"Elisabetta Romano\", \"Elisabeth from Rome\") and objects (e.g. \"Carlo Sacchi\", \"Charles Bags\"). The two most common Italian family names, \"Russo\" and \"Rossi\", mean the same thing, \"Red\", possibly referring to the hair color.\nBoth Western and Eastern orders are used for full names: the given name usually comes first, but the family name may come first in administrative settings; lists are usually indexed according to the last name.\nSince 1975, women have kept their own surname when married, but until recently (2000) they could have added the surname of the husband according to the civil code, although it was a very seldom-used practice. In recent years, the husband's surname cannot be used in any official situation. In some unofficial situations, sometimes both surnames are written (the proper first), sometimes separated by \"in\" (e.g. \"Giuseppina Mauri in Crivelli\") or, in case of widows, \"ved.\" (\"vedova\").\nLatvia.\nLatvian male surnames usually end in \"-s\", \"-\u0161\" or \"-is\" whereas the female versions of the same names end in \"-a\" or \"-e\" or \"s\" in both unmarried and married women.\nBefore the emancipation from serfdom (1817 in Courland, 1819 in Vidzeme, 1861 in Latgale) only noblemen, free craftsmen or people living in towns had surnames. Therefore, the oldest Latvian surnames originate from German or Low German, reflecting the dominance of German as an official language in Latvia till the 19th century. Examples: \"Meijers/Meijere\" (German: \"Meier\", farm administrator; akin to Mayor), \"Millers/Millere\" (German: \"M\u00fcller\", miller), \"\u0160mits/\u0160mite\" (German: \"Schmidt\", smith), \"\u0160ulcs/\u0160ulce, \u0160ulca\" (German: \"Schultz\" or \"Schulz\", constable), \"Ulmanis\" (German: \"Ullmann\", a person from Ulm), \"Godmanis\" (a God-man), \"P\u0113tersons\" (son of Peter). Some Latvian surnames, mainly from Latgale are of Polish or Belarusian origin by changing the final \"-ski/-cki\" to \"-skis/-ckis\", \"-czyk\" to \"-\u010diks\" or \"-vich/-wicz\" to \"-vi\u010ds\", such as \"Sokolovkis/Sokolovska\", \"Baldun\u010diks/Baldun\u010dika\" or \"Ratkevi\u010ds/Ratkevi\u010da\".\nMost Latvian peasants received their surnames in 1826 (in Vidzeme), in 1835 (in Courland), and in 1866 (in Latgale). Diminutives were the most common form of family names. Examples: \"Kalni\u0146\u0161/Kalni\u0146a\" (small hill), \"B\u0113rzi\u0146\u0161/B\u0113rzi\u0146a\" (small birch).\nNowadays many Latvians of Slavic descent have surnames of Russian, Belarusian, or Ukrainian origin, for example \"Volkovs/Volkova\" or \"Anto\u0146enko\".\nLithuania.\nLithuanian names follow the Baltic distinction between male and female suffixes of names, although the details are different. Male surnames usually end in \"-a\", \"-as\", \"-aitis\", \"-ys\", \"-ius\", or \"-us\", whereas the female versions change these suffixes to \"-ait\u0117, -yt\u0117, -i\u016bt\u0117\", and \"-ut\u0117\" respectively (if unmarried), \"-ien\u0117\" (if married), or \"-\u0117\" (not indicating the marital status). Some Lithuanians have names of Polish or another Slavic origin, which are made to conform to Lithuanian by changing the final \"-ski\" to \"-skas\", such as \"Sadauskas\", with the female version bein -\"skait\u0117\" (if unmarried), \"-skien\u0117\" (if married), or \"-sk\u0117\" (not indicating the marital status).\nMalta.\nDifferent cultures have their impact on the demographics of the Maltese islands, and this is evident in the various surnames Maltese citizens bear nowadays. There are very few \"Maltese\" surnames per se: the few that originate from Maltese places of origin include \"Chircop\" (Kirkop), \"Lia\" (Lija), \"Balzan\" (Balzan), \"Valletta\" (Valletta), and \"Sciberras\" (Xebb ir-Ras Hill, on which Valletta was built). The village of Munxar, Gozo is characterised by the majority of its population having one of two surnames, either \"Curmi\" or \"de Brincat\". In Gozo, the surnames \"Bajada\" and \"Farrugia\" are also common.\nSicilian and Italian surnames are common due to the close vicinity to Malta. Sicilians were the first to colonise the Maltese islands. Common examples include \"Azzopardi\", \"Bonello\", \"Cauchi\", \"Farrugia\", \"Gauci\", \"Rizzo\", \"Schembri\", \"Tabone\", \"Vassallo\", \"Vella\".\nCommon examples include \"Depuis\", \"Montfort\", \"Monsenuier\", \"Tafel\".\nEnglish surnames exist for a number of reasons, but mainly due to migration as well as Malta forming a part of the British Empire in the 19th century and most of the 20th. Common examples include \"Bone\", \"Harding\", \"Atkins\", \"Mattocks\", \"Smith\", \"Jones\", \"Woods\", \"Turner\", \"Littlejohn\".\nArabic surnames occur in part due to the early presence of the Arabs in Malta. Common examples include \"Sammut\", \"Camilleri\", \"Zammit\", and \"Xuereb\".\nCommon surnames of Spanish origin include \"Abela\", \"Galdes\", \"Herrera\", and \"Guzman\".\nSurnames from foreign countries from the Middle Ages include German,\nsuch as \"von Brockdorff\", \"Hyzler\", and \"Schranz\".\nMany of the earliest Maltese surnames are Sicilian Greek, e.g. \"Cilia\", \"Calleja\", \"Brincat\", \"Cauchi\". Much less common are recent surnames from Greece; examples include \"Dacoutros\", and \"Trakosopoulos\"\nThe original Jewish community of Malta and Gozo has left no trace of their presence on the islands since they were expelled in January 1493.\nIn line with the practice in other Christian, European states, women generally assume their husband's surname after legal marriage, and this is passed on to any children the couple may bear. Some women opt to retain their old name, for professional/personal reasons, or combine their surname with that of their husband.\nMongolia.\nMongolians do not use surnames in the way that most Westerners, Chinese or Japanese do. Since the socialist period, patronymics \u2013 then called \"ovog\", now called \"etsgiin ner\" \u2013 are used instead of a surname. If the father's name is unknown, a matronymic is used. The patro- or matronymic is written before the given name. Therefore, if a man with given name Tsakhia has a son, and gives the son the name Elbegdorj, the son's full name is Tsakhia Elbegdorj. Very frequently, the patronymic is given in genitive case, i.e. Tsakhiagiin Elbegdorj. However, the patronymic is rather insignificant in everyday use and usually just given as an initial \u2013 Ts. Elbegdorj. People are normally just referred to and addressed by their given name (Elbegdorj \"guai\" \u2013 Mr. Elbegdorj), and if two people share a common given name, they are usually just kept apart by their initials, not by the full patronymic.\nSince 2000, Mongolians have been officially using clan names \u2013 \"ovog\", the same word that had been used for the patronymics before \u2013 on their IDs. Many people chose the names of the ancient clans and tribes such Borjigin, Besud, Jalair, etc. Also many extended families chose the names of the native places of their ancestors. Some chose the names of their most ancient known ancestor. Some just decided to pass their own given names (or modifications of their given names) to their descendants as clan names. Some chose other attributes of their lives as surnames. G\u00fcrragchaa chose Sansar (Cosmos). Clan names precede the patronymics and given names, e.g. Besud Tsakhiagiin Elbegdorj. These clan names have a significance and are included in Mongolian passports.\nMyanmar (Burma).\nPeople from Myanmar or Burmese, have no family names. This, to some, is the only known Asian people having no family names at all. Some of those from Myanmar or Burma, who are familiar with European or American cultures, began to put to their younger generations with a family name \u2013 adopted from the notable ancestors. For example, Ms. Aung San Suu Kyi is the daughter of the late Father of Independence General Aung San; Hayma Ne Win, is the daughter of the famous actor Kawleikgyin Ne Win etc.\nPhilippines.\nUntil the middle of the 19th century, there was no standardization of surnames in the Philippines. There were native Filipinos without surnames, others whose surnames deliberately did not match that of their families, as well as those who took certain surnames simply because they had a certain prestige, usually ones related to the Roman Catholic religion, such as de los Santos (\"of the saints\") and de la Cruz (\"of the cross\"), or of local nobility such as of rajahs or \"datus\".\nOn 21 November 1849, the Spanish Governor-General of the Philippines, Narciso Claver\u00eda y Zald\u00faa, decreed an end to these arbitrary practices, the systematic distribution of surnames to Filipinos without prior surnames and the universal implementation of the Spanish naming system. This produced the \"Cat\u00e1logo alfab\u00e9tico de apellidos\" (\"Alphabetical Catalogue of Surnames\"), which listed permitted surnames with origins in Spanish, Filipino, and Hispanized Chinese words, names, and numbers. Thus, many Spanish-sounding Filipino surnames are not surnames common to the rest of the Spanish-speaking world. The book contained many words coming from Spanish and the Philippine languages such as Tagalog, as well as many Basque and Catalan surnames.\nThe colonial authorities implemented this decree because many Christianized Filipinos assumed religious names. There soon were too many people surnamed \"de los Santos\" (\"of the saints\"), \"de la Cruz\" (\"of the cross\"), \"del Rosario\" (\"of the Rosary\") etc., which made it difficult for the Spanish colonists to control the Filipino people, and most importantly, to collect taxes. These extremely common names were also banned by the decree unless the name has been used by a family for at least four generations. This Spanish naming custom also countered the native custom before the Spanish period, wherein siblings assumed different surnames. Claver\u00eda's decree was enforced to different degrees in different parts of the colony.\nBecause of this implementation of Spanish naming customs, of the arrangement \"given name + paternal surname + maternal surname\", in the Philippines, a Spanish surname does not necessarily denote Spanish ancestry.\nIn practice, the application of this decree varied from municipality to municipality. Most municipalities received surnames starting with only one initial letter; in others, this was not well enforced. For example, the majority of residents of the island of Banton in the province of Romblon have surnames starting with F such as \"Fabicon\", \"Fallarme\", \"Fadrilan\", and \"Ferran\". Other examples are most cities and towns in Albay, Catanduanes, Ilocos Sur and Marinduque, where the majority of their residents have surnames beginning with a particular letter.\nThus, although perhaps a majority of Filipinos have Spanish surnames, such a surname does not indicate Spanish ancestry. In addition, most Filipinos currently do not use Spanish accented letters in their Spanish derived names. The lack of accents in Filipino Spanish has been attributed to the lack of accents on the predominantly American typewriters after the United States gained control of the Philippines.\nThe vast majority of Filipinos follow a naming system in the American order (i.e. given name + middle name + surname), which is the reverse of the Spanish naming order (i.e. given name + paternal surname + maternal surname). Children take the mother's surname as their middle name, followed by their father's as their surname; for example, a son of Juan de la Cruz and his wife Mar\u00eda Agbayani may be David Agbayani de la Cruz. Women usually take the surnames of their husband upon marriage, and consequently lose their maiden middle names; so upon her marriage to David de la Cruz, the full name of Laura Yuchengco Macaraeg would become Laura Macaraeg de la Cruz. Their maiden last names automatically become their middle names upon marriage.\nThere are other sources for surnames. Many Filipinos also have Chinese-derived surnames, which in some cases could indicate Chinese ancestry. Many Hispanized Chinese numerals and other Hispanized Chinese words, however, were also among the surnames in the \"Cat\u00e1logo alfab\u00e9tico de apellidos\". For those whose surname may indicate Chinese ancestry, analysis of the surname may help to pinpoint when those ancestors arrived in the Philippines. A Hispanized Chinese surname such as Cojuangco suggests an 18th-century arrival while a Chinese surname such as Lim suggests a relatively recent immigration. Some Chinese surnames such as Tiu-Laurel are composed of the immigrant Chinese ancestor's surname as well as the name of that ancestor's godparent on receiving Christian baptism.\nIn the predominantly Muslim areas of the southern Philippines, adoption of surnames was influenced by Islamic religious terms. As a result, surnames among Filipino Muslims are largely Arabic-based, and include such surnames as Hassan and Haradji.\nThere are also Filipinos who, to this day, have no surnames at all, particularly if they come from indigenous cultural communities.\nNaming customs in the Philippines.\nPrior to the establishment of the Philippines as a US territory during the earlier part of the 20th century, Filipinos usually followed Iberian naming customs. However, upon the promulgation of the Family Code of 1987, Filipinos formalized adopting the American system of using their surnames.\nA common Filipino name will consist of the given name (mostly 2 given names are given), the initial letter of the mother's maiden name and finally the father's surname (i.e. Lucy Anne C. de Guzman). Also, women are allowed to retain their maiden name or use both her and her husband's surname as a double-barreled surname, separated by a dash. This is common in feminist circles or when the woman holds a prominent office (e.g. Gloria Macapagal Arroyo, Miriam Defensor Santiago). In more traditional circles, especially those who belong to the prominent families in the provinces, the custom of the woman being addressed as \"Mrs. Husband's Full Name\" is still common.\nFor widows, who chose to marry again, two norms are in existence. For those who were widowed before the Family Code, the full name of the woman remains while the surname of the deceased husband is attached. That is, Maria Andres, who was widowed by Ignacio Dimaculangan will have the name Maria Andres viuda de Dimaculangan. If she chooses to marry again, this name will still continue to exist while the surname of the new husband is attached. Thus, if Maria marries Rene de los Santos, her new name will be Maria Andres viuda de Dimaculangan de los Santos.\nHowever, a new norm is also in existence. The woman may choose to use her husband's surname to be one of her middle names. Thus, Maria Andres viuda de Dimaculangan de los Santos may also be called Maria A.D. de los Santos.\nChildren will however automatically inherit their father's surname if they are considered legitimate. If the child is born out of wedlock, the mother will automatically pass her surname to the child, unless the father gives a written acknowledgment of paternity. The father may also choose to give the child both his parents' surnames if he wishes (that is Gustavo Paredes, whose parents are Eulogio Paredes and Juliana Angeles, while having Maria Solis as a wife, may name his child Kevin S. Angeles-Paredes.\nIn some Tagalog regions, the norm of giving patronyms, or in some cases matronyms, is also accepted. These names are of course not official, since family names in the Philippines are inherited. It is not uncommon to refer to someone as Juan anak ni Pablo (John, the son of Paul) or Juan apo ni Teofilo (John, the grandson of Theophilus).\nRomania.\nIn Romania, like in most of Europe, it is customary for a child to take his father's family name, and a wife to take her husband's last name. However, this is not compulsory spouses and parents are allowed to choose other options too, as the law is flexible (see Art. 282, Art. 449 Art. 450. of the Civil Code of Romania).\nUntil the 19th century, the names were primarily of the form \"[given name] [father's name] [grandfather's name]\". The few exceptions are usually famous people or the nobility (boyars). The name reform introduced around 1850 had the names changed to a western style, most likely imported from France, consisting of a given name followed by a family name.\nAs such, the name is called \"prenume\" (French \"pr\u00e9nom\"), while the family name is called \"nume\" or, when otherwise ambiguous, \"nume de familie\" (\"family name\"). Although not mandatory, middle names are common.\nHistorically, when the family name reform was introduced in the mid-19th century, the default was to use a patronym, or a matronym when the father was dead or unknown. A common convention was to append the suffix \"-escu\" to the father's name, e.g. \"Anghelescu\" (\"\"Anghel's\" child\") and \"Petrescu\" (\"\"Petre's\" child\"). (The \"-escu\" seems to come from Latin \"-iscum\", thus being cognate with Italian \"-esco\" and French \"-esque\".) Another common convention was to append the suffix \"-eanu\" to the name of the place of origin, e.g. \"Munteanu\" (\"from the mountains\") and \"Moldoveanu\" (\"from \"Moldova\"\"). These uniquely Romanian suffixes strongly identify ancestral nationality.\nThere are also descriptive family names derived from occupations, nicknames, and events, e.g. \"Botezatu\" (\"baptised\"), \"Barbu\" (\"bushy bearded\"), \"Prodan\" (\"foster\"), \"B\u0103lan\" (\"blond\"), \"Fieraru\" (\"smith\"), \"Croitoru\" (\"tailor\"), \"P\u0103curaru\" (\"shepherd\").\nRomanian family names remain the same regardless of the sex of the person.\nAlthough given names appear before family names in most Romanian contexts, official documents invert the order, ostensibly for filing purposes. Correspondingly, Romanians occasionally introduce themselves with their family names first, e.g. a student signing a test paper in school.\nRomanians bearing names of non-Romanian origin often adopt Romanianised versions of their ancestral surnames. For example, \"Jurovschi\" for Polish \"\u017burowski\", or Popovici for Serbian Popovi\u0107 (\"son of a priest\"), which preserves the original pronunciation of the surname through transliteration. In some cases, these changes were mandated by the state.\nTurkey.\nIn Turkey, following the Surname Law imposed in 1934 in the context of Atat\u00fcrk's Reforms, every family living in Turkey was given a family name. The surname was generally selected by the elderly people of the family and could be any Turkish word (or a permitted word for families belonging to official minority groups).\nSome of the most common family names in Turkey are \"Y\u0131lmaz\" ('undaunted'), \"Do\u011fan\" ('falcon'), \"\u015eahin\" ('hawk'), \"Y\u0131ld\u0131r\u0131m\" ('thunderbolt'), \"\u015eim\u015fek\" ('lightning'), \"\u00d6zt\u00fcrk\" ('purely Turkish').\nPatronymic surnames do not necessarily refer to ancestry, or in most cases cannot be traced back historically. The most usual Turkish patronymic suffix is \"\u2013o\u011flu\"; \"\u2013ov(a)\", \"\u2013yev(a)\" and \"\u2013zade\" also occur in the surnames of Azeri or other Turkic descendants.\nOfficial minorities like Armenians, Greeks, and Jews have surnames in their own mother languages.\nThe Armenian families living in Turkey usually have Armenian surnames and generally have the suffix \"\u2013yan\", \"\u2013ian\", or, using Turkish spelling, \"-can\". Greek descendants usually have Greek surnames which might have Greek suffixes like \"\u2013ou\", \"\u2013aki(s)\", \"\u2013poulos/poulou\", \"\u2013idis/idou\", \"\u2013iadis/iadou\" or prefixes like \"papa\u2013\".\nThe Sephardic Jews who were expelled from Spain and settled in Turkey in 1492 have both Jewish/Hebrew surnames, and Spanish surnames, usually indicating their native regions, cities or villages back in Spain, like \"De Leon\" or \"Toledano\"."}
{"id": "10815", "revid": "1256836860", "url": "https://en.wikipedia.org/wiki?curid=10815", "title": "Franc", "text": "The franc is any of various units of currency. One franc is typically divided into 100 centimes. The name is said to derive from the Latin inscription \"francorum rex\" (King of the Franks) used on early French coins and until the 18th century, or from the French \"franc\", meaning \"frank\" (and \"free\" in certain contexts, such as \"coup franc\", \"free kick\").\nThe countries that use francs today include Switzerland, Liechtenstein, and most of Francophone Africa. The Swiss franc is a major world currency today due to the prominence of Swiss financial institutions.\nBefore the introduction of the euro in 1999, francs were also used in France, Belgium and Luxembourg, while Andorra and Monaco accepted the French franc as legal tender (Mon\u00e9gasque franc). The franc was also used in French colonies including Algeria and Cambodia. The franc is sometimes Italianised or Hispanicised as the \"franco\", for instance in Luccan franco.\nOrigins.\nThe franc was originally a French gold coin of 3.87\u00a0g minted in 1360 on the occasion of the release of King John II (\"the Good\"), held by the English since his capture at the Battle of Poitiers four years earlier. It was equivalent to one \"livre tournois\" (Tours pound).\nFrench franc.\nThe French franc was originally a gold coin issued in France from 1360 until 1380, then a silver coin issued between 1575 and 1641. The franc finally became the national currency from 1795 until 1999 (franc coins and notes were legal tender until 2002). Though abolished as a legal coin by King Louis XIII in 1641 in favor of the gold louis and silver \u00e9cu, the term franc continued to be used in common parlance for the livre tournois. The franc was also minted for many of the former French colonies, such as Morocco, Algeria, French West Africa, and others. Today, after independence, many of these countries continue to use the franc as their standard denomination.\nThe value of the French franc was locked to the euro at 1 euro = 6.55957 FRF on 31 December 1998, and after the introduction of the euro notes and coins, ceased to be legal tender after 28 February 2002, although they were still exchangeable at banks until 19 February 2012.\nCFA and CFP francs.\nFourteen African countries use the franc CFA (in west Africa, \"Communaut\u00e9 financi\u00e8re africaine\"; in equatorial Africa, \"Coop\u00e9ration financi\u00e8re en Afrique centrale\"), originally (1945) worth 1.7 French francs and then from 1948, 2 francs (from 1960: 0.02 new franc) but after January 1994 worth only 0.01 French franc. Therefore, from January 1999, 1 CFA franc is equivalent to \u20ac0.00152449.\nA separate (franc CFP) circulates in France's Pacific territories, worth \u20ac0.0084 (formerly 0.055 French franc).\nComorian franc.\nIn 1981, the Comoros established an arrangement with the French government similar to that of the CFA franc. Originally, 50 Comorian francs were worth 1 French franc. In January 1994, the rate was changed to 75 Comorian francs to the French franc. Since 1999, the currency has been pegged to the euro.\nBelgian franc and Luxembourg franc.\nThe conquest of most of western Europe by Revolutionary and Napoleonic France led to the franc's wide circulation. Following independence from the Kingdom of the Netherlands, the new Kingdom of Belgium in 1832 adopted its own Belgian franc, equivalent to the French one, followed by Luxembourg adopting the Luxembourgish franc in 1848 and Switzerland in 1850. Newly unified Italy adopted the lira on a similar basis in 1862.\nIn 1865, France, Belgium, Switzerland and Italy created the Latin Monetary Union (to be joined by Spain and Greece in 1868): each would possess a national currency unit (franc, lira, peseta, drachma) worth 4.5\u00a0g of silver or of gold (fine), all freely exchangeable at a rate of 1:1. In the 1870s the gold value was made the fixed standard, a situation which was to continue until 1914.\nIn 1926, Belgium as well as France experienced depreciation and an abrupt collapse of confidence, leading to the introduction of a new gold currency for international transactions, the \"belga\" of 5 francs, and the country's withdrawal from the monetary union, which ceased to exist at the end of the year. The 1921 monetary union of Belgium and Luxembourg survived and formed the basis for full economic union in 1932.\nLike the French franc, the Belgian and Luxembourg francs ceased to exist on 1 January 1999, when they became fixed at 1\u00a0EUR = 40.3399\u00a0BEF/LUF, thus a Belgian or Luxembourg franc was worth \u20ac0.024789. Old franc coins and notes lost their legal tender status on 28 February 2002.\nOne Luxembourg franc was equal to one Belgian franc. Belgian francs were legal tender inside Luxembourg, and Luxembourg francs were legal tender in the whole of Belgium. (In reality, Luxembourg francs were only accepted as means of payment by shops and businesses in the Belgian province of Luxembourg adjacent to the independent Grand Duchy of Luxembourg, this for historical reasons.)\nThe equivalent name of the Belgian franc in Dutch and German, Belgium's other official languages, was . As mentioned before, in Luxembourg the franc was called (plural ) in Luxembourgish.\nSwiss franc and Liechtenstein franc.\nThe Swiss franc (ISO code: CHF or 756; ; ), which appreciated significantly against the new European currency from April to September 2000, remains one of the world's strongest currencies, worth just over one euro. The Swiss franc is used in Switzerland and in Liechtenstein. Liechtenstein retains the ability to mint its own currency, the Liechtenstein franc, which it does from time to time for commemorative or emergency purposes.\nThe name of the country \"Swiss Confederation\" is found on some of the coins in Latin (\"Confoederatio Helvetica\"), as Switzerland has four official languages, all of which are used on the notes. The denomination is abbreviated \"Fr.\" on the coins which is the abbreviation in all four languages.\nSaar franc.\nThe Saar franc, linked at par to the French franc, was introduced in the Saar Protectorate in 1948. On 1 January 1957, the territory joined the Federal Republic of Germany, nevertheless, in its new member state of Saarland, the Saar franc continued to be the currency until 6 July 1959.\nThe name of the Saar franc in German, the main official language in the Protectorate, was \"Franken\". Coins displaying German inscriptions and the coat of arms of the Protectorate were circulated and used together with French francs. As banknotes, only French franc bills existed."}
{"id": "10816", "revid": "48823678", "url": "https://en.wikipedia.org/wiki?curid=10816", "title": "Francophone nations and territories", "text": ""}
{"id": "10819", "revid": "36878010", "url": "https://en.wikipedia.org/wiki?curid=10819", "title": "Federal Reserve", "text": "The Federal Reserve System (often shortened to the Federal Reserve, or simply the Fed) is the central banking system of the United States. It was created on December 23, 1913, with the enactment of the Federal Reserve Act, after a series of financial panics (particularly the panic of 1907) led to the desire for central control of the monetary system in order to alleviate financial crises. Over the years, events such as the Great Depression in the 1930s and the Great Recession during the 2000s have led to the expansion of the roles and responsibilities of the Federal Reserve System.\nCongress established three key objectives for monetary policy in the Federal Reserve Act: maximizing employment, stabilizing prices, and moderating long-term interest rates. The first two objectives are sometimes referred to as the Federal Reserve's dual mandate. Its duties have expanded over the years, and currently also include supervising and regulating banks, maintaining the stability of the financial system, and providing financial services to depository institutions, the U.S. government, and foreign official institutions. The Fed also conducts research into the economy and provides numerous publications, such as the Beige Book and the FRED database.\nThe Federal Reserve System is composed of several layers. It is governed by the presidentially-appointed board of governors or Federal Reserve Board (FRB). Twelve regional Federal Reserve Banks, located in cities throughout the nation, regulate and oversee privately owned commercial banks. Nationally chartered commercial banks are required to hold stock in, and can elect some board members of, the Federal Reserve Bank of their region.\nThe Federal Open Market Committee (FOMC) sets monetary policy by adjusting the target for the federal funds rate, which generally influences market interest rates and, in turn, US economic activity via the monetary transmission mechanism. The FOMC consists of all seven members of the board of governors and the twelve regional Federal Reserve Bank presidents, though only five bank presidents vote at a time\u2014the president of the New York Fed and four others who rotate through one-year voting terms. There are also various advisory councils. It has a structure unique among central banks, and is also unusual in that the United States Department of the Treasury, an entity outside of the central bank, prints the currency used.\nThe federal government sets the salaries of the board's seven governors, and it receives all the system's annual profits after dividends on member banks' capital investments are paid, and an account surplus is maintained. In 2015, the Federal Reserve earned a net income of $100.2 billion and transferred $97.7 billion to the U.S. Treasury, and 2020 earnings were approximately $88.6 billion with remittances to the U.S. Treasury of $86.9 billion. Although an instrument of the U.S. government, the Federal Reserve System considers itself \"an independent central bank because its monetary policy decisions do not have to be approved by the president or by anyone else in the executive or legislative branches of government, it does not receive funding appropriated by Congress, and the terms of the members of the board of governors span multiple presidential and congressional terms.\" The Federal Reserve has been criticized by some for its approach to managing inflation, perceived lack of transparency, and its role in economic downturns.\nPurpose.\nThe primary declared motivation for creating the Federal Reserve System was to address banking panics. Other purposes are stated in the Federal Reserve Act, such as \"to furnish an elastic currency, to afford means of rediscounting commercial paper, to establish a more effective supervision of banking in the United States, and for other purposes\". Before the founding of the Federal Reserve System, the United States underwent several financial crises. A particularly severe crisis in 1907 led Congress to enact the Federal Reserve Act in 1913. Today the Federal Reserve System has responsibilities in addition to stabilizing the financial system.\nCurrent functions of the Federal Reserve System include:\nAddressing the problem of bank panics.\nBanking institutions in the United States are required to hold reservesamounts of currency and deposits in other banksequal to only a fraction of the amount of the bank's deposit liabilities owed to customers. This practice is called fractional-reserve banking. As a result, banks usually invest the majority of the funds received from depositors. On rare occasions, too many of the bank's customers will withdraw their savings and the bank will need help from another institution to continue operating; this is called a bank run. Bank runs can lead to a multitude of social and economic problems. The Federal Reserve System was designed as an attempt to prevent or minimize the occurrence of bank runs, and possibly act as a lender of last resort when a bank run does occur. Many economists, following Nobel laureate Milton Friedman, believe that the Federal Reserve inappropriately refused to lend money to small banks during the bank runs of 1929; Friedman argued that this contributed to the Great Depression.\nCheck clearing system.\nBecause some banks refused to clear checks from certain other banks during times of economic uncertainty, a check-clearing system was created in the Federal Reserve System. It is briefly described in \"The Federal Reserve SystemPurposes and Functions\" as follows:\nLender of last resort.\nIn the United States, the Federal Reserve serves as the lender of last resort to those institutions that cannot obtain credit elsewhere and the collapse of which would have serious implications for the economy. It took over this role from the private sector \"clearing houses\" which operated during the ; whether public or private, the availability of liquidity was intended to prevent bank runs.\nFluctuations.\nThrough its discount window and credit operations, Reserve Banks provide liquidity to banks to meet short-term needs stemming from seasonal fluctuations in deposits or unexpected withdrawals. Longer-term liquidity may also be provided in exceptional circumstances. The rate the Fed charges banks for these loans is called the discount rate (officially the primary credit rate).\nBy making these loans, the Fed serves as a buffer against unexpected day-to-day fluctuations in reserve demand and supply. This contributes to the effective functioning of the banking system, alleviates pressure in the reserves market and reduces the extent of unexpected movements in the interest rates. For example, on September 16, 2008, the Federal Reserve Board authorized an $85\u00a0billion loan to stave off the bankruptcy of international insurance giant American International Group (AIG).\nCentral bank.\nIn its role as the central bank of the United States, the Fed serves as a banker's bank and as the government's bank. As the banker's bank, it helps to assure the safety and efficiency of the payments system. As the government's bank or fiscal agent, the Fed processes a variety of financial transactions involving trillions of dollars. Just as an individual might keep an account at a bank, the U.S. Treasury keeps a checking account with the Federal Reserve, through which incoming federal tax deposits and outgoing government payments are handled. As part of this service relationship, the Fed sells and redeems U.S. government securities such as savings bonds and Treasury bills, notes and bonds. It also issues the nation's coin and paper currency. The U.S. Treasury, through its Bureau of the Mint and Bureau of Engraving and Printing, actually produces the nation's cash supply and, in effect, sells the paper currency to the Federal Reserve Banks at manufacturing cost, and the coins at face value. The Federal Reserve Banks then distribute it to other financial institutions in various ways. During the Fiscal Year 2020, the Bureau of Engraving and Printing delivered 57.95\u00a0billion notes at an average cost of 7.4 cents per note.\nFederal funds.\nFederal funds are the reserve balances (also called Federal Reserve Deposits) that private banks keep at their local Federal Reserve Bank. These balances are the namesake reserves of the Federal Reserve System. The purpose of keeping funds at a Federal Reserve Bank is to have a mechanism for private banks to lend funds to one another. This market for funds plays an important role in the Federal Reserve System as it is the basis for its monetary policy work. Monetary policy is put into effect partly by influencing how much interest the private banks charge each other for the lending of these funds.\nFederal reserve accounts contain federal reserve credit, which can be converted into federal reserve notes. Private banks maintain their bank reserves in federal reserve accounts.\nBank regulation.\nThe Federal Reserve regulates private banks. The system was designed out of a compromise between the competing philosophies of privatization and government regulation. In 2006 Donald L. Kohn, vice chairman of the board of governors, summarized the history of this compromise:\nThe balance between private interests and government can also be seen in the structure of the system. Private banks elect members of the board of directors at their regional Federal Reserve Bank while the members of the board of governors are selected by the president of the United States and confirmed by the Senate.\nGovernment regulation and supervision.\nThe Federal Banking Agency Audit Act, enacted in 1978 as Public Law 95-320 and 31 U.S.C. section 714 establish that the board of governors of the Federal Reserve System and the Federal Reserve banks may be audited by the Government Accountability Office (GAO).\nThe GAO has authority to audit check-processing, currency storage and shipments, and some regulatory and bank examination functions\u2013though there are restrictions to what the GAO may audit. Under the Federal Banking Agency Audit Act, 31 U.S.C. section 714(b), audits of the Federal Reserve Board and Federal Reserve banks do not include (1) transactions for or with a foreign central bank or government or non-private international financing organization; (2) deliberations, decisions, or actions on monetary policy matters; (3) transactions made under the direction of the Federal Open Market Committee; or (4) a part of a discussion or communication among or between members of the board of governors and officers and employees of the Federal Reserve System related to items (1), (2), or (3). See Federal Reserve System Audits: Restrictions on GAO's Access (GAO/T-GGD-94-44), statement of Charles A. Bowsher.\nThe board of governors in the Federal Reserve System has a number of supervisory and regulatory responsibilities in the U.S. banking system, but not complete responsibility. A general description of the types of regulation and supervision involved in the U.S. banking system is given by the Federal Reserve:\nRegulatory and oversight responsibilities.\nThe board of directors of each Federal Reserve Bank District also has regulatory and supervisory responsibilities. If the board of directors of a district bank has judged that a member bank is performing or behaving poorly, it will report this to the board of governors. This policy is described in law:\nNational payments system.\nThe Federal Reserve plays a role in the U.S. payments system. The twelve Federal Reserve Banks provide banking services to depository institutions and to the federal government. For depository institutions, they maintain accounts and provide various payment services, including collecting checks, electronically transferring funds, and distributing and receiving currency and coin. For the federal government, the Reserve Banks act as fiscal agents, paying Treasury checks; processing electronic payments; and issuing, transferring, and redeeming U.S. government securities.\nIn the Depository Institutions Deregulation and Monetary Control Act of 1980, Congress reaffirmed that the Federal Reserve should promote an efficient nationwide payments system. The act subjects all depository institutions, not just member commercial banks, to reserve requirements and grants them equal access to Reserve Bank payment services.\nThe Federal Reserve plays a role in the nation's retail and wholesale payments systems by providing financial services to depository institutions. Retail payments are generally for relatively small-dollar amounts and often involve a depository institution's retail clientsindividuals and smaller businesses. The Reserve Banks' retail services include distributing currency and coin, collecting checks, electronically transferring funds through FedACH (the Federal Reserve's automated clearing house system), and beginning in 2023, facilitating instant payments using the FedNow service. By contrast, wholesale payments are generally for large-dollar amounts and often involve a depository institution's large corporate customers or counterparties, including other financial institutions. The Reserve Banks' wholesale services include electronically transferring funds through the Fedwire Funds Service and transferring securities issued by the U.S. government, its agencies, and certain other entities through the Fedwire Securities Service.\nStructure.\nThe Federal Reserve System has a \"unique structure that is both public and private\" and is described as \"independent within the government\" rather than \"independent of government\". The System does not require public funding, and derives its authority and purpose from the Federal Reserve Act, which was passed by Congress in 1913 and is subject to Congressional modification or repeal. The four main components of the Federal Reserve System are (1) the board of governors, (2) the Federal Open Market Committee, (3) the twelve regional Federal Reserve Banks, and (4) the member banks throughout the country.\nBoard of governors.\nThe seven-member board of governors is a large federal agency that functions in business oversight by examining national banks. It is charged with the overseeing of the 12 District Reserve Banks and setting national monetary policy. It also supervises and regulates the U.S. banking system in general.\nGovernors are appointed by the president of the United States and confirmed by the Senate for staggered 14-year terms. One term begins every two years, on February 1 of even-numbered years, and members serving a full term cannot be renominated for a second term. \"[U]pon the expiration of their terms of office, members of the Board shall continue to serve until their successors are appointed and have qualified.\" The law provides for the removal of a member of the board by the president \"for cause\". The board is required to make an annual report of operations to the Speaker of the U.S. House of Representatives.\nThe chair and vice chair of the board of governors are appointed by the president from among the sitting governors. They both serve a four-year term and they can be renominated as many times as the president chooses, until their terms on the board of governors expire.\nList of members of the board of governors.\nThe current members of the board of governors are:\nNominations, confirmations and resignations.\nIn late December 2011, President Barack Obama nominated Jeremy C. Stein, a Harvard University finance professor and a Democrat, and Jerome Powell, formerly of Dillon Read, Bankers Trust and The Carlyle Group and a Republican. Both candidates also have Treasury Department experience in the Obama and George H. W. Bush administrations respectively.\n\"Obama administration officials [had] regrouped to identify Fed candidates after Peter Diamond, a Nobel Prize-winning economist, withdrew his nomination to the board in June [2011] in the face of Republican opposition. Richard Clarida, a potential nominee who was a Treasury official under George W. Bush, pulled out of consideration in August [2011]\", one account of the December nominations noted. The two other Obama nominees in 2011, Janet Yellen and Sarah Bloom Raskin, were confirmed in September. One of the vacancies was created in 2011 with the resignation of Kevin Warsh, who took office in 2006 to fill the unexpired term ending January 31, 2018, and resigned his position effective March 31, 2011. In March 2012, U.S. Senator David Vitter (R, LA) said he would oppose Obama's Stein and Powell nominations, dampening near-term hopes for approval. However, Senate leaders reached a deal, paving the way for affirmative votes on the two nominees in May 2012 and bringing the board to full strength for the first time since 2006 with Duke's service after term end. Later, on January 6, 2014, the United States Senate confirmed Yellen's nomination to be chair of the Federal Reserve Board of Governors; she was the first woman to hold the position. Subsequently, President Obama nominated Stanley Fischer to replace Yellen as the vice-chair.\nIn April 2014, Stein announced he was leaving to return to Harvard on May 28 with four years remaining on his term. At the time of the announcement, the FOMC \"already is down three members as it awaits the Senate confirmation of ... Fischer and Lael Brainard, and as [President] Obama has yet to name a replacement for ... Duke. ... Powell is still serving as he awaits his confirmation for a second term.\"\nAllan R. Landon, former president and CEO of the Bank of Hawaii, was nominated in early 2015 by President Obama to the board.\nIn July 2015, President Obama nominated University of Michigan economist Kathryn M. Dominguez to fill the second vacancy on the board. The Senate had not yet acted on Landon's confirmation by the time of the second nomination.\nDaniel Tarullo submitted his resignation from the board on February 10, 2017, effective on or around April 5, 2017.\nFederal Open Market Committee.\nThe Federal Open Market Committee (FOMC) consists of 12 members, seven from the board of governors and 5 of the regional Federal Reserve Bank presidents. The FOMC oversees and sets policy on open market operations, the principal tool of national monetary policy. These operations affect the amount of Federal Reserve balances available to depository institutions, thereby influencing overall monetary and credit conditions. The FOMC also directs operations undertaken by the Federal Reserve in foreign exchange markets. The FOMC must reach consensus on all decisions. The president of the Federal Reserve Bank of New York is a permanent member of the FOMC; the presidents of the other banks rotate membership at two- and three-year intervals. All Regional Reserve Bank presidents contribute to the committee's assessment of the economy and of policy options, but only the five presidents who are then members of the FOMC vote on policy decisions. The FOMC determines its own internal organization and, by tradition, elects the chair of the board of governors as its chair and the president of the Federal Reserve Bank of New York as its vice chair. Formal meetings typically are held eight times each year in Washington, D.C. Nonvoting Reserve Bank presidents also participate in Committee deliberations and discussion. The FOMC generally meets eight times a year in telephone consultations and other meetings are held when needed.\nThere is very strong consensus among economists against politicising the FOMC.\nFederal Advisory Council.\nThe Federal Advisory Council, composed of twelve representatives of the banking industry, advises the board on all matters within its jurisdiction.\nFederal Reserve Banks.\nThere are 12 Federal Reserve Banks, each of which is responsible for member banks located in its district. They are located in Boston, New York, Philadelphia, Cleveland, Richmond, Atlanta, Chicago, St. Louis, Minneapolis, Kansas City, Dallas, and San Francisco. The size of each district was set based upon the population distribution of the United States when the Federal Reserve Act was passed.\nThe charter and organization of each bank is established by law and cannot be altered by the member banks. Member banks do, however, elect six of the nine members of the Federal Reserve Banks' boards of directors.\nEach regional bank has a president, who is the chief executive officer of their bank. Each president is nominated by their bank's board of directors, but the nomination is contingent upon approval by the board of governors. Presidents serve five-year terms and may be reappointed.\nEach regional bank's board has nine members. Members are of three classes: A, B, and C. There are three board members in each class. Class A members are chosen by the regional Bank's shareholders, and are intended to represent member banks' interests. Member banks are divided into three categories: large, medium, and small. Each category elects one of the three class A board members. Class B board members are also nominated by the region's member banks, but class B board members are supposed to represent the interests of the public. Lastly, class C board members are appointed by the board of governors, and are also intended to represent the interests of the public.\nLegal status of regional Federal Reserve Banks.\nThe Federal Reserve Banks have an intermediate legal status, with some features of private corporations and some features of public federal agencies. The United States has an interest in the Federal Reserve Banks as tax-exempt federally created instrumentalities whose profits belong to the federal government, but this interest is not proprietary. In \"Lewis v. United States\", the United States Court of Appeals for the Ninth Circuit stated that: \"The Reserve Banks are not federal instrumentalities for purposes of the FTCA [the Federal Tort Claims Act], but are independent, privately owned and locally controlled corporations.\" The opinion went on to say, however, that: \"The Reserve Banks have properly been held to be federal instrumentalities for some purposes.\" Another relevant decision is \"Scott v. Federal Reserve Bank of Kansas City\", in which the distinction is made between Federal Reserve Banks, which are federally created instrumentalities, and the board of governors, which is a federal agency.\nRegarding the structural relationship between the twelve Federal Reserve banks and the various commercial (member) banks, political science professor Michael D. Reagan has written:\nMember banks.\nA member bank is a private institution and owns stock in its regional Federal Reserve Bank. All nationally chartered banks hold stock in one of the Federal Reserve Banks. State chartered banks may choose to be members (and hold stock in their regional Federal Reserve bank) upon meeting certain standards.\nThe amount of stock a member bank must own is equal to 3% of its combined capital and surplus. However, holding stock in a Federal Reserve bank is not like owning stock in a publicly traded company. These stocks cannot be sold or traded, and member banks do not control the Federal Reserve Bank as a result of owning this stock. From their Regional Bank, member banks with $10\u00a0billion or less in assets receive a dividend of 6%, while member banks with more than $10\u00a0billion in assets receive the lesser of 6% or the current 10-year Treasury auction rate. The remainder of the regional Federal Reserve Banks' profits is given over to the United States Treasury Department. In 2015, the Federal Reserve Banks made a profit of $100.2\u00a0billion and distributed $2.5\u00a0billion in dividends to member banks as well as returning $97.7\u00a0billion to the U.S. Treasury.\nAbout 38% of U.S. banks are members of their regional Federal Reserve Bank.\nAccountability.\nAn external auditor selected by the audit committee of the Federal Reserve System regularly audits the Board of Governors and the Federal Reserve Banks. The GAO will audit some activities of the Board of Governors. These audits do not cover \"most of the Fed's monetary policy actions or decisions, including discount window lending (direct loans to financial institutions), open-market operations and any other transactions made under the direction of the Federal Open Market Committee\" ...[nor may the GAO audit] \"dealings with foreign governments and other central banks.\"\nThe annual and quarterly financial statements prepared by the Federal Reserve System conform to a basis of accounting that is set by the Federal Reserve Board and does not conform to Generally Accepted Accounting Principles (GAAP) or government Cost Accounting Standards (CAS). The financial reporting standards are defined in the Financial Accounting Manual for the Federal Reserve Banks. The cost accounting standards are defined in the Planning and Control System Manual. , the Federal Reserve Board has been publishing unaudited financial reports for the Federal Reserve banks every quarter.\nOn November 7, 2008, Bloomberg L.P. brought a lawsuit against the board of governors of the Federal Reserve System to force the board to reveal the identities of firms for which it provided guarantees during the financial crisis of 2007\u20132008. Bloomberg, L.P. won at the trial court and the Fed's appeals were rejected at both the United States Court of Appeals for the Second Circuit and the U.S. Supreme Court. The data was released on March 31, 2011.\nMonetary policy.\nThe term \"monetary policy\" refers to the actions undertaken by a central bank, such as the Federal Reserve, to influence economic activity (the overall demand for goods and services) to help promote national economic goals. The Federal Reserve Act of 1913 gave the Federal Reserve authority to set monetary policy in the United States. The Fed's mandate for monetary policy is commonly known as the dual mandate of promoting maximum employment and stable prices, the latter being interpreted as a stable inflation rate of 2 percent per year on average. The Fed's monetary policy influences economic activity by influencing the general level of interest rates in the economy, which again via the monetary transmission mechanism affects households' and firms' demand for goods and services and in turn employment and inflation.\nInterbank lending.\nThe Federal Reserve sets monetary policy by influencing the federal funds rate, which is the rate of interbank lending of reserve balances. The rate that banks charge each other for these loans is determined in the interbank market, and the Federal Reserve influences this rate through the \"tools\" of monetary policy described in the \"Tools\" section below. The federal funds rate is a short-term interest rate that the FOMC focuses on, which affects the longer-term interest rates throughout the economy. The Federal Reserve explained the implementation of its monetary policy in 2021:\nChanges in the target for the federal funds rate affect overall financial conditions through various channels, including subsequent changes in the market interest rates that commercial banks and other lenders charge on short-term and longer-term loans, and changes in asset prices and in currency exchange rates, which again affects private consumption, investment and net export. By easening or tightening the stance of monetary policy, i.e. lowering or raising its target for the federal funds rate, the Fed can either spur or restrain growth in the overall US demand for goods and services.\nTools.\nThere are four main tools of monetary policy that the Federal Reserve uses to implement its monetary policy:\nFederal funds rate.\nThe Federal Reserve System implements monetary policy largely by targeting the federal funds rate. This is the interest rate that banks charge each other for overnight loans of federal funds, which are the reserves held by banks at the Fed. This rate is actually determined by the market and is not explicitly mandated by the Fed. The Fed therefore tries to align the effective federal funds rate with the targeted rate, mainly by adjusting its IORB rate. The Federal Reserve System usually adjusts the federal funds rate target by 0.25% or 0.50% at a time.\nInterest on reserve balances.\nThe interest on reserve balances (IORB) is the interest that the Fed pays on funds held by commercial banks in their reserve balance accounts at the individual Federal Reserve System banks. It is an administrated interest rate (i.e. set directly by the Fed as opposed to a market interest rate which is determined by the forces of supply and demand). As banks are unlikely to lend their reserves in the FFR market for less than they get paid by the Fed, the IORB guides the effective FFR and is used as the primary tool of the Fed's monetary policy.\nOpen market operations.\nOpen market operations are done through the sale and purchase of United States Treasury securities, or \"Treasurys\". The Federal Reserve buys Treasurys both directly and via primary dealers, which have accounts at depository institutions.\nThe Federal Reserve's objective for open market operations has varied over the years. During the 1980s, the focus gradually shifted toward attaining a specified level of the federal funds rate (the rate that banks charge each other for overnight loans of federal funds, which are the reserves held by banks at the Fed), a process that was largely complete by the end of the decade.\nUntil the 2007\u20132008 financial crisis, the Fed used open market operations as its primary tool to adjust the supply of reserve balances in order to keep the federal funds rate around the Fed's target. This regime is also known as a limited reserves regime. After the financial crisis, the Federal Reserve has adopted a so-called ample reserves regime where open market operations leading to modest changes in the supply of reserves are no longer effective in influencing the FFR. Instead the Fed uses its administered rates, in particular the IORB rate, to influence the FFR. However, open market operations are still an important maintenance tool in the overall framework of the conduct of monetary policy as they are used for ensuring that reserves remain ample.\nRepurchase agreements.\nTo smooth temporary or cyclical changes in the money supply, the desk engages in repurchase agreements (repos) with its primary dealers. Repos are essentially secured, short-term lending by the Fed. On the day of the transaction, the Fed deposits money in a primary dealer's reserve account, and receives the promised securities as collateral. When the transaction matures, the process unwinds: the Fed returns the collateral and charges the primary dealer's reserve account for the principal and accrued interest. The term of the repo (the time between settlement and maturity) can vary from 1 day (called an overnight repo) to 65 days.\nDiscount window and discount rate.\nThe Federal Reserve System also directly sets the discount rate, which is the interest rate for \"discount window lending\", overnight loans that member banks borrow directly from the Fed. This rate is generally set at a rate close to 100 basis points above the target federal funds rate. The idea is to encourage banks to seek alternative funding before using the \"discount rate\" option. The equivalent operation by the European Central Bank is referred to as the \"marginal lending facility\".\nBoth the discount rate and the federal funds rate influence the prime rate, which is usually about 3 percentage points higher than the federal funds rate.\nTerm Deposit facility.\nThe Term Deposit facility is a program through which the Federal Reserve Banks offer interest-bearing term deposits to eligible institutions. It is intended to facilitate the implementation of monetary policy by providing a tool by which the Federal Reserve can manage the aggregate quantity of reserve balances held by depository institutions. Funds placed in term deposits are removed from the accounts of participating institutions for the life of the term deposit and thus drain reserve balances from the banking system. The program was announced December 9, 2009, and approved April 30, 2010, with an effective date of June 4, 2010. Fed Chair Ben S. Bernanke, testifying before the House Committee on Financial Services, stated that the Term Deposit Facility would be used to reverse the expansion of credit during the Great Recession, by drawing funds out of the money markets into the Federal Reserve Banks. It would therefore result in increased market interest rates, acting as a brake on economic activity and inflation. The Federal Reserve authorized up to five \"small-value offerings\" in 2010 as a pilot program. After three of the offering auctions were successfully completed, it was announced that small-value auctions would continue on an ongoing basis.\nQuantitative easing (QE) policy.\nA little-used tool of the Federal Reserve is the quantitative easing policy. Under that policy, the Federal Reserve buys back corporate bonds and mortgage backed securities held by banks or other financial institutions. This in effect puts money back into the financial institutions and allows them to make loans and conduct normal business.\nThe bursting of the United States housing bubble prompted the Fed to buy mortgage-backed securities for the first time in November 2008. Over six weeks, a total of $1.25\u00a0trillion were purchased in order to stabilize the housing market, about one-fifth of all U.S. government-backed mortgages.\nExpired policy tools.\nReserve requirements.\nAn instrument of monetary policy adjustment historically employed by the Federal Reserve System was the fractional reserve requirement, also known as the required reserve ratio. The required reserve ratio set the balance that the Federal Reserve System required a depository institution to hold in the Federal Reserve Banks. The required reserve ratio was set by the board of governors of the Federal Reserve System. The reserve requirements have changed over time and some history of these changes is published by the Federal Reserve.\nAs a response to the financial crisis of 2008, the Federal Reserve started making interest payments on depository institutions' required and excess reserve balances. The payment of interest on excess reserves gave the central bank greater opportunity to address credit market conditions while maintaining the federal funds rate close to the target rate set by the FOMC. The reserve requirement did not play a significant role in the post-2008 interest-on-excess-reserves regime, and in March 2020, the reserve ratio was set to zero for all banks, which meant that no bank was required to hold any reserves, and hence the reserve requirement effectively ceased to exist.\nTemporary policy tools during the financial crisis.\nIn order to address problems related to the subprime mortgage crisis and United States housing bubble, several new tools were created. The first new tool, called the Term auction facility, was added on December 12, 2007. It was announced as a temporary tool, but remained in place for a prolonged period of time. Creation of the second new tool, called the Term Securities Lending Facility, was announced on March 11, 2008. The main difference between these two facilities was that the Term auction Facility was used to inject cash into the banking system whereas the Term securities Lending Facility was used to inject treasury securities into the banking system. Creation of the third tool, called the Primary Dealer Credit Facility (PDCF), was announced on March 16, 2008. The PDCF was a fundamental change in Federal Reserve policy because it enabled the Fed to lend directly to primary dealers, which was previously against Fed policy. The differences between these three facilities was described by the Federal Reserve:\nSome measures taken by the Federal Reserve to address the financial crisis had not been used since the Great Depression.\nTerm auction facility.\nThe Term auction Facility was a program in which the Federal Reserve auctioned term funds to depository institutions. The creation of this facility was announced by the Federal Reserve on December 12, 2007, and was done in conjunction with the Bank of Canada, the Bank of England, the European Central Bank, and the Swiss National Bank to address elevated pressures in short-term funding markets. The reason it was created was that banks were not lending funds to one another and banks in need of funds were refusing to go to the discount window. Banks were not lending money to each other because there was a fear that the loans would not be paid back. Banks refused to go to the discount window because it was usually associated with the stigma of bank failure. Under the Term auction Facility, the identity of the banks in need of funds was protected in order to avoid the stigma of bank failure. Foreign exchange swap lines with the European Central Bank and Swiss National Bank were opened so the banks in Europe could have access to U.S. dollars. The final Term Auction Facility auction was carried out on March 8, 2010.\nTerm securities lending facility.\nThe Term securities Lending Facility was a 28-day facility that offered Treasury general collateral to the Federal Reserve Bank of New York's primary dealers in exchange for other program-eligible collateral. It was intended to promote liquidity in the financing markets for Treasury and other collateral and thus to foster the functioning of financial markets more generally. Like the Term auction Facility, the TSLF was done in conjunction with the Bank of Canada, the Bank of England, the European Central Bank, and the Swiss National Bank. The resource allowed dealers to switch debt that was less liquid for U.S. government securities that were easily tradable. The currency swap lines with the European Central Bank and Swiss National Bank were increased. The TSLF was closed on February 1, 2010.\nPrimary dealer credit facility.\nThe Primary Dealer Credit Facility (PDCF) was an overnight loan facility that provided funding to primary dealers in exchange for a specified range of eligible collateral and was intended to foster the functioning of financial markets more generally. It ceased extending credit on March 31, 2021.\nAsset Backed Commercial Paper Money Market Mutual Fund Liquidity Facility.\nThe Asset Backed Commercial Paper Money Market Mutual Fund Liquidity Facility (ABCPMMMFLF) was also called the AMLF. The Facility began operations on September 22, 2008, and was closed on February 1, 2010.\nAll U.S. depository institutions, bank holding companies (parent companies or U.S. broker-dealer affiliates), or U.S. branches and agencies of foreign banks were eligible to borrow under this facility pursuant to the discretion of the FRBB.\nCollateral eligible for pledge under the Facility was required to meet the following criteria:\nCommercial Paper Funding Facility.\nOn October 7, 2008, the Federal Reserve further expanded the collateral it would loan against to include commercial paper using the Commercial Paper Funding Facility (CPFF). The action made the Fed a crucial source of credit for non-financial businesses in addition to commercial banks and investment firms. Fed officials said they would buy as much of the debt as necessary to get the market functioning again. They refused to say how much that might be, but they noted that around $1.3\u00a0trillion worth of commercial paper would qualify. There was $1.61\u00a0trillion in outstanding commercial paper, seasonally adjusted, on the market , according to the most recent data from the Fed. That was down from $1.70\u00a0trillion in the previous week. Since the summer of 2007, the market had shrunk from more than $2.2\u00a0trillion. This program lent out a total $738\u00a0billion before it was closed. Forty-five out of 81 of the companies participating in this program were foreign firms. Research shows that Troubled Asset Relief Program (TARP) recipients were twice as likely to participate in the program than other commercial paper issuers who did not take advantage of the TARP bailout. The Fed incurred no losses from the CPFF.\nHistory.\nCentral banking in the United States, 1791\u20131913.\nThe first attempt at a national currency was during the American Revolutionary War. In 1775, the Continental Congress, as well as the states, began issuing paper currency, calling the bills \"Continentals\". The Continentals were backed only by future tax revenue, and were used to help finance the Revolutionary War. Overprinting, as well as British counterfeiting, caused the value of the Continental to diminish quickly. This experience with paper money led the United States to strip the power to issue Bills of Credit (paper money) from a draft of the new Constitution on August 16, 1787, as well as banning such issuance by the various states, and limiting the states' ability to make anything but gold or silver coin legal tender on August 28.\nIn 1791, the government granted the First Bank of the United States a charter to operate as the U.S. central bank until 1811. The First Bank of the United States came to an end under President Madison when Congress refused to renew its charter. The Second Bank of the United States was established in 1816, and lost its authority to be the central bank of the U.S. twenty years later under President Jackson when its charter expired. Both banks were based upon the Bank of England. Ultimately, a third national bank, known as the Federal Reserve, was established in 1913 and still exists to this day.\nFirst Central Bank, 1791 and Second Central Bank, 1816.\nThe first U.S. institution with central banking responsibilities was the First Bank of the United States, chartered by Congress and signed into law by President George Washington on February 25, 1791, at the urging of Alexander Hamilton. This was done despite strong opposition from Thomas Jefferson and James Madison, among numerous others. The charter was for twenty years and expired in 1811 under President Madison, when Congress refused to renew it.\nIn 1816, however, Madison revived it in the form of the Second Bank of the United States. Years later, early renewal of the bank's charter became the primary issue in the reelection of President Andrew Jackson. After Jackson, who was opposed to the central bank, was reelected, he pulled the government's funds out of the bank. Jackson was the only President to completely pay off the national debt but his efforts to close the bank contributed to the Panic of 1837. The bank's charter was not renewed in 1836, and it would fully dissolve after several years as a private corporation.\nFrom 1837 to 1862, in the Free Banking Era there was no formal central bank.\nFrom 1846 to 1921, an Independent Treasury System ruled.\nFrom 1863 to 1913, a system of national banks was instituted by the 1863 National Banking Act during which series of bank panics, in 1873, 1893, and 1907 occurred.\nCreation of Third Central Bank, 1907\u20131913.\nThe main motivation for the third central banking system came from the Panic of 1907, which caused a renewed desire among legislators, economists, and bankers for an overhaul of the monetary system. During the last quarter of the 19th century and the beginning of the 20th century, the United States economy went through a series of financial panics. According to many economists, the previous national banking system had two main weaknesses: an inelastic currency and a lack of liquidity. In 1908, Congress enacted the Aldrich\u2013Vreeland Act, which provided for an emergency currency and established the National Monetary Commission to study banking and currency reform. The National Monetary Commission returned with recommendations which were repeatedly rejected by Congress. A revision crafted during a secret meeting on Jekyll Island by Senator Aldrich and representatives of the nation's top finance and industrial groups later became the basis of the Federal Reserve Act. The House voted on December 22, 1913, with 298 voting yes to 60 voting no. The Senate voted 43\u201325 on December 23, 1913. President Woodrow Wilson signed the bill later that day.\nFederal Reserve Act, 1913.\nThe head of the bipartisan National Monetary Commission was financial expert and Senate Republican leader Nelson Aldrich. Aldrich set up two commissions \u2013 one to study the American monetary system in depth and the other, headed by Aldrich himself, to study the European central banking systems and report on them.\nIn early November 1910, Aldrich met with five well known members of the New York banking community to devise a central banking bill. Paul Warburg, an attendee of the meeting and longtime advocate of central banking in the U.S., later wrote that Aldrich was \"bewildered at all that he had absorbed abroad and he was faced with the difficult task of writing a highly technical bill while being harassed by the daily grind of his parliamentary duties\". After ten days of deliberation, the bill, which would later be referred to as the \"Aldrich Plan\", was agreed upon. It had several key components, including a central bank with a Washington-based headquarters and fifteen branches located throughout the U.S. in geographically strategic locations, and a uniform elastic currency based on gold and commercial paper. Aldrich believed a central banking system with no political involvement was best, but was convinced by Warburg that a plan with no public control was not politically feasible. The compromise involved representation of the public sector on the board of directors.\nAldrich's bill met much opposition from politicians. Critics charged Aldrich of being biased due to his close ties to wealthy bankers such as J. P. Morgan and John D. Rockefeller Jr., Aldrich's son-in-law. Most Republicans favored the Aldrich Plan, but it lacked enough support in Congress to pass because rural and western states viewed it as favoring the \"eastern establishment\". In contrast, progressive Democrats favored a reserve system owned and operated by the government; they believed that public ownership of the central bank would end Wall Street's control of the American currency supply. Conservative Democrats fought for a privately owned, yet decentralized, reserve system, which would still be free of Wall Street's control.\nThe original Aldrich Plan was dealt a fatal blow in 1912, when Democrats won the White House and Congress. Nonetheless, President Woodrow Wilson believed that the Aldrich plan would suffice with a few modifications. The plan became the basis for the Federal Reserve Act, which was proposed by Senator Robert Owen in May 1913. The primary difference between the two bills was the transfer of control of the board of directors (called the Federal Open Market Committee in the Federal Reserve Act) to the government. The bill passed Congress on December 23, 1913, on a mostly partisan basis, with most Democrats voting \"yea\" and most Republicans voting \"nay\".\nFederal Reserve era, 1913\u2013present.\nKey laws affecting the Federal Reserve have been:\nMeasurement of economic variables.\nThe Federal Reserve records and publishes large amounts of data. A few websites where data is published are at the board of governors' Economic Data and Research page, the board of governors' statistical releases and historical data page, and at the St. Louis Fed's FRED (Federal Reserve Economic Data) page. The Federal Open Market Committee (FOMC) examines many economic indicators prior to determining monetary policy.\nSome criticism involves economic data compiled by the Fed. The Fed sponsors much of the monetary economics research in the U.S., and Lawrence H. White objects that this makes it less likely for researchers to publish findings challenging the status quo.\nNet worth of households and nonprofit organizations.\nThe net worth of households and nonprofit organizations in the United States is published by the Federal Reserve in a report titled \"Flow of Funds\". At the end of the third quarter of fiscal year 2012, this value was $64.8\u00a0trillion. At the end of the first quarter of fiscal year 2014, this value was $95.5\u00a0trillion.\nMoney supply.\nThe most common measures are named M0 (narrowest), M1, M2, and M3. In the United States they are defined by the Federal Reserve as follows:\nThe Federal Reserve stopped publishing M3 statistics in March 2006, saying that the data cost a lot to collect but did not provide significantly useful information. The other three money supply measures continue to be provided in detail.\nPersonal consumption expenditures price index.\nThe Personal consumption expenditures price index, also referred to as simply the PCE price index, is used as one measure of the value of money. It is a United States-wide indicator of the average increase in prices for all domestic personal consumption. Using a variety of data including United States Consumer Price Index and U.S. Producer Price Index prices, it is derived from the largest component of the gross domestic product in the BEA's National Income and Product Accounts, personal consumption expenditures.\nOne of the Fed's main roles is to maintain price stability, which means that the Fed's ability to keep a low inflation rate is a long-term measure of their success. Although the Fed is not required to maintain inflation within a specific range, their long run target for the growth of the PCE price index is between 1.5 and 2 percent. There has been debate among policy makers as to whether the Federal Reserve should have a specific inflation targeting policy.\nInflation and the economy.\nMost mainstream economists favor a low, steady rate of inflation. Chief economist, and advisor to the Federal Reserve, the Congressional Budget Office and the Council of Economic Advisers, Diane C. Swonk observed, in 2022, that \"From the Fed's perspective, you have to remember inflation is kind of like cancer. If you don't deal with it now with something that may be painful, you could have something that metastasized and becomes much more chronic later on.\"\nLow (as opposed to zero or negative) inflation may reduce the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduce the risk that a liquidity trap prevents monetary policy from stabilizing the economy. The task of keeping the rate of inflation low and stable is usually given to monetary authorities.\nUnemployment rate.\nOne of the stated goals of monetary policy is maximum employment. The unemployment rate statistics are collected by the Bureau of Labor Statistics, and like the PCE price index are used as a barometer of the nation's economic health.\nBudget.\nThe Federal Reserve is self-funded. Over 90percent of Fed revenues come from open market operations, specifically the interest on the portfolio of Treasury securities as well as \"capital gains/losses\" that may arise from the buying/selling of the securities and their derivatives as part of Open Market Operations. The balance of revenues come from sales of financial services (check and electronic payment processing) and discount window loans. The board of governors (Federal Reserve Board) creates a budget report once per year for Congress. There are two reports with budget information. The one that lists the complete balance statements with income and expenses, as well as the net profit or loss, is the large report simply titled, \"Annual Report\". It also includes data about employment throughout the system. The other report, which explains in more detail the expenses of the different aspects of the whole system, is called \"Annual Report: Budget Review\". These detailed comprehensive reports can be found at the board of governors' website under the section \"Reports to Congress\"\nRemittance payments to the Treasury.\nThe Federal Reserve has been remitting interest that it has been receiving back to the United States Treasury. Most of the assets the Fed holds are U.S. Treasury bonds and mortgage-backed securities that it has been purchasing as part of quantitative easing since the 2007\u20132008 financial crisis. In 2022 the Fed started quantitative tightening (QT) and selling these assets and taking a loss on them in the secondary bond market. As a result, the nearly $100billion that it was remitting annually to the Treasury, is expected to be discontinued during QT.\nIn 2023, the Federal Reserve reported a net negative income of $114.3 billion. This triggered the creation of a deferred asset liability on the Federal Reserve balance sheet booked as \"Interest on Federal Reserve notes due to U.S. Treasury\" totaling $133.3 billion. The deferred asset is the amount of net excess revenues the Federal Reserve must realize before remittances can continue. It does not have any impact on the ability of the Federal Reserve to conduct monetary policy or meet its obligations. The Federal Reserve has estimated the deferred asset will last until mid-2027.\nBalance sheet.\nOne of the keys to understanding the Federal Reserve is the Federal Reserve balance sheet (or balance statement). In accordance with Section 11 of the Federal Reserve Act, the board of governors of the Federal Reserve System publishes once each week the \"Consolidated Statement of Condition of All Federal Reserve Banks\" showing the condition of each Federal Reserve bank and a consolidated statement for all Federal Reserve banks. The board of governors requires that excess earnings of the Reserve Banks be transferred to the Treasury as interest on Federal Reserve notes.\nThe Federal Reserve releases its balance sheet every Thursday. Below is the balance sheet (in billions of dollars):\nIn addition, the balance sheet also indicates which assets are held as collateral against Federal Reserve Notes.\nAs of August 2024, the Fed's total assets on balance sheet are $7.139 trillion.\nCriticism.\nThe Federal Reserve System has faced various criticisms since its inception in 1913. Criticisms include lack of transparency and claims that it is ineffective."}
{"id": "10821", "revid": "11331109", "url": "https://en.wikipedia.org/wiki?curid=10821", "title": "Francium", "text": "Francium is a chemical element; it has symbol Fr and atomic number 87. It is extremely radioactive; its most stable isotope, francium-223 (originally called \"actinium\u00a0K\" after the natural decay chain in which it appears), has a half-life of only 22\u00a0minutes. It is the second-most electropositive element, behind only caesium, and is the second rarest naturally occurring element (after astatine). Francium's isotopes decay quickly into astatine, radium, and radon. The electronic structure of a francium atom is [Rn] 7s1; thus, the element is classed as an alkali metal.\nAs a consequence of its extreme instability, bulk francium has never been seen. Because of the general appearance of the other elements in its periodic table column, it is presumed that francium would appear as a highly reactive metal if enough could be collected together to be viewed as a bulk solid or liquid. Obtaining such a sample is highly improbable since the extreme heat of decay resulting from its short half-life would immediately vaporize any viewable quantity of the element.\nFrancium was discovered by Marguerite Perey in France (from which the element takes its name) on January 7, 1939. Before its discovery, francium was referred to as \"eka-caesium\" or \"ekacaesium\" because of its conjectured existence below caesium in the periodic table. It was the last element first discovered in nature, rather than by synthesis. Outside the laboratory, francium is extremely rare, with trace amounts found in uranium ores, where the isotope francium-223 (in the family of uranium-235) continually forms and decays. As little as exists at any given time throughout the Earth's crust; aside from francium-223 and francium-221, its other isotopes are entirely synthetic. The largest amount produced in the laboratory was a cluster of more than 300,000 atoms.\nCharacteristics.\nFrancium is one of the most unstable of the naturally occurring elements: its longest-lived isotope, francium-223, has a half-life of only 22\u00a0minutes. The only comparable element is astatine, whose most stable natural isotope, astatine-219 (the alpha daughter of francium-223), has a half-life of 56\u00a0seconds, although synthetic astatine-210 is much longer-lived with a half-life of 8.1\u00a0hours. All isotopes of francium decay into astatine, radium, or radon. Francium-223 also has a shorter half-life than the longest-lived isotope of each synthetic element up to and including element 105, dubnium.\nFrancium is an alkali metal whose chemical properties mostly resemble those of caesium. A heavy element with a single valence electron, it has the highest equivalent weight of any element. Liquid francium\u2014if created\u2014should have a surface tension of 0.05092\u00a0N/m at its melting point. Francium's melting point was estimated to be around ; a value of is also often encountered. The melting point is uncertain because of the element's extreme rarity and radioactivity; a different extrapolation based on Dmitri Mendeleev's method gave . A calculation based on the melting temperatures of binary ionic crystals gives . The estimated boiling point of is also uncertain; the estimates and , as well as the extrapolation from Mendeleev's method of , have also been suggested. The density of francium is expected to be around 2.48\u00a0g/cm3 (Mendeleev's method extrapolates 2.4\u00a0g/cm3).\nLinus Pauling estimated the electronegativity of francium at 0.7 on the Pauling scale, the same as caesium; the value for caesium has since been refined to 0.79, but there are no experimental data to allow a refinement of the value for francium. Francium has a slightly higher ionization energy than caesium, 392.811(4)\u00a0kJ/mol as opposed to 375.7041(2)\u00a0kJ/mol for caesium, as would be expected from relativistic effects, and this would imply that caesium is the less electronegative of the two. Francium should also have a higher electron affinity than caesium and the Fr\u2212 ion should be more polarizable than the Cs\u2212 ion.\nCompounds.\nAs a result of francium's instability, its salts are only known to a small extent. Francium coprecipitates with several caesium salts, such as caesium perchlorate, which results in small amounts of francium perchlorate. This coprecipitation can be used to isolate francium, by adapting the radiocaesium coprecipitation method of Lawrence E. Glendenin and C. M. Nelson. It will additionally coprecipitate with many other caesium salts, including the iodate, the picrate, the tartrate (also rubidium tartrate), the chloroplatinate, and the silicotungstate. It also coprecipitates with silicotungstic acid, and with perchloric acid, without another alkali metal as a carrier, which leads to other methods of separation.\nFrancium perchlorate.\nFrancium perchlorate is produced by the reaction of francium chloride and sodium perchlorate. The francium perchlorate coprecipitates with caesium perchlorate. This coprecipitation can be used to isolate francium, by adapting the radiocaesium coprecipitation method of Lawrence E. Glendenin and C. M. Nelson. However, this method is unreliable in separating thallium, which also coprecipitates with caesium. Francium perchlorate's entropy is expected to be 42.7\u00a0e.u (178.7 J mol\u22121 K\u22121).\nFrancium halides.\nFrancium halides are all soluble in water and are expected to be white solids. They are expected to be produced by the reaction of the corresponding halogens. For example, francium chloride would be produced by the reaction of francium and chlorine. Francium chloride has been studied as a pathway to separate francium from other elements, by using the high vapour pressure of the compound, although francium fluoride would have a higher vapour pressure.\nOther compounds.\nFrancium nitrate, sulfate, hydroxide, carbonate, acetate, and oxalate, are all soluble in water, while the iodate, picrate, tartrate, chloroplatinate, and silicotungstate are insoluble. The insolubility of these compounds are used to extract francium from other radioactive products, such as zirconium, niobium, molybdenum, tin, antimony, the method mentioned in the section above. Francium oxide is believed to disproportionate to the peroxide and francium metal. The CsFr molecule is predicted to have francium at the negative end of the dipole, unlike all known heterodiatomic alkali metal molecules. Francium superoxide (FrO2) is expected to have a more covalent character than its lighter congeners; this is attributed to the 6p electrons in francium being more involved in the francium\u2013oxygen bonding. The relativistic destabilisation of the 6p3/2 spinor may make francium compounds in oxidation states higher than +1 possible, such as [FrVF6]\u2212; but this has not been experimentally confirmed.\nIsotopes.\nThere are 37 known isotopes of francium ranging in atomic mass from 197 to 233. Francium has seven metastable nuclear isomers. Francium-223 and francium-221 are the only isotopes that occur in nature, with the former being far more common.\nFrancium-223 is the most stable isotope, with a half-life of 21.8\u00a0minutes, and it is highly unlikely that an isotope of francium with a longer half-life will ever be discovered or synthesized. Francium-223 is a fifth product of the uranium-235 decay series as a daughter isotope of actinium-227; thorium-227 is the more common daughter. Francium-223 then decays into radium-223 by beta decay (1.149\u00a0MeV decay energy), with a minor (0.006%) alpha decay path to astatine-219 (5.4\u00a0MeV decay energy).\nFrancium-221 has a half-life of 4.8\u00a0minutes. It is the ninth product of the neptunium decay series as a daughter isotope of actinium-225. Francium-221 then decays into astatine-217 by alpha decay (6.457\u00a0MeV decay energy). Although all primordial 237Np is extinct, the neptunium decay series continues to exist naturally in tiny traces due to (n,2n) knockout reactions in natural 238U. Francium-222, with a half-life of 14\u00a0minutes, may be produced as a result of the beta decay of natural radon-222; this process has nonetheless not yet been observed, and it is unknown whether this process is energetically possible.\nThe least stable ground state isotope is francium-215, with a half-life of 90\u00a0ns: it undergoes a 9.54\u00a0MeV alpha decay to astatine-211.\nApplications.\nDue to its instability and rarity, there are no commercial applications for francium. It has been used for research purposes in the fields of chemistry\nand of atomic structure. Its use as a potential diagnostic aid for various cancers has also been explored, but this application has been deemed impractical.\nFrancium's ability to be synthesized, trapped, and cooled, along with its relatively simple atomic structure, has made it the subject of specialized spectroscopy experiments. These experiments have led to more specific information regarding energy levels and the coupling constants between subatomic particles. Studies on the light emitted by laser-trapped francium-210 ions have provided accurate data on transitions between atomic energy levels which are fairly similar to those predicted by quantum theory. Francium is a prospective candidate for searching for CP violation.\nHistory.\nAs early as 1870, chemists thought that there should be an alkali metal beyond caesium, with an atomic number of 87. It was then referred to by the provisional name \"eka-caesium\".\nErroneous and incomplete discoveries.\nIn 1914, Stefan Meyer, Viktor F. Hess, and Friedrich Paneth (working in Vienna) made measurements of alpha radiation from various substances, including 227Ac. They observed the possibility of a minor alpha branch of this nuclide, though follow-up work could not be done due to the outbreak of World War I. Their observations were not precise and sure enough for them to announce the discovery of element 87, though it is likely that they did indeed observe the decay of 227Ac to 223Fr.\nSoviet chemist Dmitry Dobroserdov was the first scientist to claim to have found eka-caesium, or francium. In 1925, he observed weak radioactivity in a sample of potassium, another alkali metal, and incorrectly concluded that eka-caesium was contaminating the sample (the radioactivity from the sample was from the naturally occurring potassium radioisotope, potassium-40). He then published a thesis on his predictions of the properties of eka-caesium, in which he named the element \"russium\" after his home country. Shortly thereafter, Dobroserdov began to focus on his teaching career at the Polytechnic Institute of Odesa, and he did not pursue the element further.\nThe following year, English chemists Gerald J. F. Druce and Frederick H. Loring analyzed X-ray photographs of manganese(II) sulfate. They observed spectral lines which they presumed to be of eka-caesium. They announced their discovery of element 87 and proposed the name \"alkalinium\", as it would be the heaviest alkali metal.\nIn 1930, Fred Allison of the Alabama Polytechnic Institute claimed to have discovered element 87 (in addition to 85) when analyzing pollucite and lepidolite using his magneto-optical machine. Allison requested that it be named \"virginium\" after his home state of Virginia, along with the symbols Vi and Vm. In 1934, H.G. MacPherson of UC Berkeley disproved the effectiveness of Allison's device and the validity of his discovery.\nIn 1936, Romanian physicist Horia Hulubei and his French colleague Yvette Cauchois also analyzed pollucite, this time using their high-resolution X-ray apparatus. They observed several weak emission lines, which they presumed to be those of element 87. Hulubei and Cauchois reported their discovery and proposed the name \"moldavium\", along with the symbol Ml, after Moldavia, the Romanian province where Hulubei was born. In 1937, Hulubei's work was criticized by American physicist F. H. Hirsh Jr., who rejected Hulubei's research methods. Hirsh was certain that eka-caesium would not be found in nature, and that Hulubei had instead observed mercury or bismuth X-ray lines. Hulubei insisted that his X-ray apparatus and methods were too accurate to make such a mistake. Because of this, Jean Baptiste Perrin, Nobel Prize winner and Hulubei's mentor, endorsed moldavium as the true eka-caesium over Marguerite Perey's recently discovered francium. Perey took pains to be accurate and detailed in her criticism of Hulubei's work, and finally she was credited as the sole discoverer of element 87. All other previous purported discoveries of element 87 were ruled out due to francium's very limited half-life.\nPerey's analysis.\nEka-caesium was discovered on January 7, 1939, by Marguerite Perey of the Curie Institute in Paris, when she purified a sample of actinium-227 which had been reported to have a decay energy of 220\u00a0keV. Perey noticed decay particles with an energy level below 80\u00a0keV. Perey thought this decay activity might have been caused by a previously unidentified decay product, one which was separated during purification, but emerged again out of the pure actinium-227. Various tests eliminated the possibility of the unknown element being thorium, radium, lead, bismuth, or thallium. The new product exhibited chemical properties of an alkali metal (such as coprecipitating with caesium salts), which led Perey to believe that it was element 87, produced by the alpha decay of actinium-227. Perey then attempted to determine the proportion of beta decay to alpha decay in actinium-227. Her first test put the alpha branching at 0.6%, a figure which she later revised to 1%.\nPerey named the new isotope \"actinium-K\" (it is now referred to as francium-223) and in 1946, she proposed the name \"catium\" (Cm) for her newly discovered element, as she believed it to be the most electropositive cation of the elements. Ir\u00e8ne Joliot-Curie, one of Perey's supervisors, opposed the name due to its connotation of \"cat\" rather than \"cation\"; furthermore, the symbol coincided with that which had since been assigned to curium. Perey then suggested \"francium\", after France. This name was officially adopted by the International Union of Pure and Applied Chemistry (IUPAC) in 1949, becoming the second element after gallium to be named after France. It was assigned the symbol Fa, but it was revised to the current Fr shortly thereafter. Francium was the last element discovered in nature, rather than synthesized, following hafnium and rhenium. Further research into francium's structure was carried out by, among others, Sylvain Lieberman and his team at CERN in the 1970s and 1980s.\nOccurrence.\n223Fr is the result of the alpha decay of 227Ac and can be found in trace amounts in uranium minerals. In a given sample of uranium, there is estimated to be only one francium atom for every 1 \u00d7 1018 uranium atoms. Only about of francium is present naturally in the earth's crust.\nProduction.\nFrancium can be synthesized by a fusion reaction when a gold-197 target is bombarded with a beam of oxygen-18 atoms from a linear accelerator in a process originally developed at the physics department of the State University of New York at Stony Brook in 1995. Depending on the energy of the oxygen beam, the reaction can yield francium isotopes with masses of 209, 210, and 211.\nThe francium atoms leave the gold target as ions, which are neutralized by collision with yttrium and then isolated in a magneto-optical trap (MOT) in a gaseous unconsolidated state. Although the atoms only remain in the trap for about 30 seconds before escaping or undergoing nuclear decay, the process supplies a continual stream of fresh atoms. The result is a steady state containing a fairly constant number of atoms for a much longer time. The original apparatus could trap up to a few thousand atoms, while a later improved design could trap over 300,000 at a time. Sensitive measurements of the light emitted and absorbed by the trapped atoms provided the first experimental results on various transitions between atomic energy levels in francium. Initial measurements show very good agreement between experimental values and calculations based on quantum theory. The research project using this production method relocated to TRIUMF in 2012, where over 106 francium atoms have been held at a time, including large amounts of 209Fr in addition to 207Fr and 221Fr.\nOther synthesis methods include bombarding radium with neutrons, and bombarding thorium with protons, deuterons, or helium ions.\n223Fr can also be isolated from samples of its parent 227Ac, the francium being milked via elution with NH4Cl\u2013CrO3 from an actinium-containing cation exchanger and purified by passing the solution through a silicon dioxide compound loaded with barium sulfate.\nIn 1996, the Stony Brook group trapped 3000 atoms in their MOT, which was enough for a video camera to capture the light given off by the atoms as they fluoresce. Francium has not been synthesized in amounts large enough to weigh."}
{"id": "10822", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=10822", "title": "Fermium", "text": "Fermium is a synthetic chemical element; it has symbol Fm and atomic number 100. It is an actinide and the heaviest element that can be formed by neutron bombardment of lighter elements, and hence the last element that can be prepared in macroscopic quantities, although pure fermium metal has not been prepared yet. A total of 20 isotopes are known, with 257Fm being the longest-lived with a half-life of 100.5 days.\nFermium was discovered in the debris of the first hydrogen bomb explosion in 1952, and named after Enrico Fermi, one of the pioneers of nuclear physics. Its chemistry is typical for the late actinides, with a preponderance of the +3 oxidation state but also an accessible +2 oxidation state. Owing to the small amounts of produced fermium and all of its isotopes having relatively short half-lives, there are currently no uses for it outside basic scientific research.\nDiscovery.\nFermium was first discovered in the fallout from the 'Ivy Mike' nuclear test (1\u00a0November 1952), the first successful test of a hydrogen bomb. Initial examination of the debris from the explosion had shown the production of a new isotope of plutonium, : this could only have formed by the absorption of six neutrons by a uranium-238 nucleus followed by two \u03b2\u2212\u00a0decays. At the time, the absorption of neutrons by a heavy nucleus was thought to be a rare process, but the identification of raised the possibility that still more neutrons could have been absorbed by the uranium nuclei, leading to new elements.\nElement\u00a099 (einsteinium) was quickly discovered on filter papers which had been flown through clouds from the explosion (the same sampling technique that had been used to discover ). It was then identified in December 1952 by Albert Ghiorso and co-workers at the University of California at Berkeley. They discovered the isotope 253Es (half-life 20.5 days) that was made by the capture of 15 neutrons by uranium-238 nuclei \u2013 which then underwent seven successive beta decays:\nSome 238U atoms, however, could capture another amount of neutrons (most likely, 16 or 17).\nThe discovery of fermium (\"Z\"\u00a0=\u00a0100) required more material, as the yield was expected to be at least an order of magnitude lower than that of element\u00a099, and so contaminated coral from the Enewetak atoll (where the test had taken place) was shipped to the University of California Radiation Laboratory in Berkeley, California, for processing and analysis. About two months after the test, a new component was isolated emitting high-energy \u03b1-particles (7.1\u00a0MeV) with a half-life of about a day. With such a short half-life, it could only arise from the \u03b2\u2212\u00a0decay of an isotope of einsteinium, and so had to be an isotope of the new element\u00a0100: it was quickly identified as 255Fm ().\nThe discovery of the new elements, and the new data on neutron capture, was initially kept secret on the orders of the U.S.\u00a0military until 1955 due to Cold War tensions. Nevertheless, the Berkeley team was able to prepare elements 99 and 100 by civilian means, through the neutron bombardment of plutonium-239, and published this work in 1954 with the disclaimer that it was not the first studies that had been carried out on the elements. The \"Ivy Mike\" studies were declassified and published in 1955.\nThe Berkeley team had been worried that another group might discover lighter isotopes of element\u00a0100 through ion-bombardment techniques before they could publish their classified research, and this proved to be the case. A group at the Nobel Institute for Physics in Stockholm independently discovered the element, producing an isotope later confirmed to be 250Fm (\"t\"1/2\u00a0= 30\u00a0minutes) by bombarding a target with oxygen-16 ions, and published their work in May 1954. Nevertheless, the priority of the Berkeley team was generally recognized, and with it the prerogative to name the new element in honour of Enrico Fermi, the developer of the first artificial self-sustained nuclear reactor. Fermi was still alive when the name was proposed, but had died by the time it became official.\nIsotopes.\nThere are 20 isotopes of fermium listed in N\u00a02016, with atomic weights of 241 to 260, of which Fm is the longest-lived with a half-life of 100.5\u00a0days. Fm has a half-life of 3 days, while Fm of 5.3\u00a0h, Fm of 25.4\u00a0h, Fm of 3.2\u00a0h, Fm of 20.1\u00a0h, and Fm of 2.6\u00a0hours. All the remaining ones have half-lives ranging from 30 minutes to less than a millisecond.\nThe neutron capture product of fermium-257, Fm, undergoes spontaneous fission with a half-life of just 370(14)\u00a0microseconds; Fm and Fm also undergo spontaneous fission (\"t\"1/2\u00a0= 1.5(3)\u00a0s and 4\u00a0ms respectively). This means that neutron capture cannot be used to create nuclides with a mass number greater than 257, unless carried out in a nuclear explosion. As Fm alpha decays to Cf, and no known fermium isotopes undergo beta minus decay to the next element, mendelevium, fermium is also the last element that can be synthesized by neutron-capture. Because of this impediment in forming heavier isotopes, these short-lived isotopes Fm constitute the \"fermium gap.\" \nOccurrence.\nProduction.\nFermium is produced by the bombardment of lighter actinides with neutrons in a nuclear reactor. Fermium-257 is the heaviest isotope that is obtained via neutron capture, and can only be produced in picogram quantities. The major source is the 85\u00a0MW High Flux Isotope Reactor (HFIR) at the Oak Ridge National Laboratory in Tennessee, USA, which is dedicated to the production of transcurium (\"Z\"\u00a0&gt;\u00a096) elements. Lower mass fermium isotopes are available in greater quantities, though these isotopes (254Fm and 255Fm) are comparatively short-lived. In a \"typical processing campaign\" at Oak Ridge, tens of grams of curium are irradiated to produce decigram quantities of californium, milligram quantities of berkelium and einsteinium, and picogram quantities of fermium. However, nanogram quantities of fermium can be prepared for specific experiments. The quantities of fermium produced in 20\u2013200\u00a0kiloton thermonuclear explosions is believed to be of the order of milligrams, although it is mixed in with a huge quantity of debris; 4.0\u00a0picograms of 257Fm was recovered from 10\u00a0kilograms of debris from the \"Hutch\" test (16\u00a0July 1969). The Hutch experiment produced an estimated total of 250 micrograms of 257Fm.\nAfter production, the fermium must be separated from other actinides and from lanthanide fission products. This is usually achieved by ion-exchange chromatography, with the standard process using a cation exchanger such as Dowex\u00a050 or T eluted with a solution of ammonium \u03b1-hydroxyisobutyrate. Smaller cations form more stable complexes with the \u03b1-hydroxyisobutyrate anion, and so are preferentially eluted from the column. A rapid fractional crystallization method has also been described.\nAlthough the most stable isotope of fermium is 257Fm, with a half-life of 100.5\u00a0days, most studies are conducted on 255Fm (\"t\"1/2\u00a0= 20.07(7)\u00a0hours), since this isotope can be easily isolated as required as the decay product of 255Es (\"t\"1/2\u00a0= 39.8(12)\u00a0days).\nSynthesis in nuclear explosions.\nThe analysis of the debris at the 10-megaton \"Ivy Mike\" nuclear test was a part of long-term project, one of the goals of which was studying the efficiency of production of transuranium elements in high-power nuclear explosions. The motivation for these experiments was as follows: synthesis of such elements from uranium requires multiple neutron capture. The probability of such events increases with the neutron flux, and nuclear explosions are the most powerful neutron sources, providing densities on the order 10 neutrons/cm within a microsecond, i.e. about 10 neutrons/(cm\u00b7s). For comparison, the flux of the HFIR reactor is 5 neutrons/(cm\u00b7s). A dedicated laboratory was set up right at Enewetak Atoll for preliminary analysis of debris, as some isotopes could have decayed by the time the debris samples reached the U.S. The laboratory was receiving samples for analysis, as soon as possible, from airplanes equipped with paper filters which flew over the atoll after the tests. Whereas it was hoped to discover new chemical elements heavier than fermium, those were not found after a series of megaton explosions conducted between 1954 and 1956 at the atoll.\nThe atmospheric results were supplemented by the underground test data accumulated in the 1960s at the Nevada Test Site, as it was hoped that powerful explosions conducted in confined space might result in improved yields and heavier isotopes. Apart from traditional uranium charges, combinations of uranium with americium and thorium have been tried, as well as a mixed plutonium-neptunium charge. They were less successful in terms of yield, which was attributed to stronger losses of heavy isotopes due to enhanced fission rates in heavy-element charges. Isolation of the products was found to be rather problematic, as the explosions were spreading debris through melting and vaporizing rocks under the great depth of 300\u2013600 meters, and drilling to such depth in order to extract the products was both slow and inefficient in terms of collected volumes.\nAmong the nine underground tests, which were carried between 1962 and 1969 and codenamed Anacostia (5.2 kilotons, 1962), Kennebec (&lt;5 kilotons, 1963), Par (38 kilotons, 1964), Barbel (&lt;20 kilotons, 1964), Tweed (&lt;20 kilotons, 1965), Cyclamen (13 kilotons, 1966), Kankakee (20-200 kilotons, 1966), Vulcan (25 kilotons, 1966) and Hutch (20-200 kilotons, 1969), the last one was most powerful and had the highest yield of transuranium elements. In the dependence on the atomic mass number, the yield showed a saw-tooth behavior with the lower values for odd isotopes, due to their higher fission rates. The major practical problem of the entire proposal, however, was collecting the radioactive debris dispersed by the powerful blast. Aircraft filters adsorbed only about 4 of the total amount and collection of tons of corals at Enewetak Atoll increased this fraction by only two orders of magnitude. Extraction of about 500 kilograms of underground rocks 60 days after the Hutch explosion recovered only about 10 of the total charge. The amount of transuranium elements in this 500-kg batch was only 30 times higher than in a 0.4\u00a0kg rock picked up 7 days after the test. This observation demonstrated the highly nonlinear dependence of the transuranium elements yield on the amount of retrieved radioactive rock. In order to accelerate sample collection after the explosion, shafts were drilled at the site not after but before the test, so that the explosion would expel radioactive material from the epicenter, through the shafts, to collecting volumes near the surface. This method was tried in the Anacostia and Kennebec tests and instantly provided hundreds of kilograms of material, but with actinide concentrations 3 times lower than in samples obtained after drilling; whereas such a method could have been efficient in scientific studies of short-lived isotopes, it could not improve the overall collection efficiency of the produced actinides.\nThough no new elements (apart from einsteinium and fermium) could be detected in the nuclear test debris, and the total yields of transuranium elements were disappointingly low, these tests did provide significantly higher amounts of rare heavy isotopes than previously available in laboratories. For example, 6 atoms of Fm could be recovered after the Hutch detonation. They were then used in the studies of thermal-neutron induced fission of Fm and in discovery of a new fermium isotope Fm. Also, the rare isotope Cm was synthesized in large quantities, which is very difficult to produce in nuclear reactors from its progenitor Cm; the half-life of Cm (64 minutes) is much too short for months-long reactor irradiations, but is very \"long\" on the explosion timescale.\nNatural occurrence.\nBecause of the short half-life of all known isotopes of fermium, any primordial fermium, that is fermium present on Earth during its formation, has decayed by now. Synthesis of fermium from naturally occurring uranium and thorium in the Earth's crust requires multiple neutron captures, which is extremely unlikely. Therefore, most fermium is produced on Earth in laboratories, high-power nuclear reactors, or in nuclear tests, and is present for only a few months afterward. The transuranic elements americium to fermium did occur naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\nChemistry.\nThe chemistry of fermium has only been studied in solution using tracer techniques, and no solid compounds have been prepared. Under normal conditions, fermium exists in solution as the Fm3+ ion, which has a hydration number of 16.9 and an acid dissociation constant of 1.6 (p\"K\"\u00a0= 3.8). Fm forms complexes with a wide variety of organic ligands with hard donor atoms such as oxygen, and these complexes are usually more stable than those of the preceding actinides. It also forms anionic complexes with ligands such as chloride or nitrate and, again, these complexes appear to be more stable than those formed by einsteinium or californium. It is believed that the bonding in the complexes of the later actinides is mostly ionic in character: the Fm ion is expected to be smaller than the preceding An ions because of the higher effective nuclear charge of fermium, and hence fermium would be expected to form shorter and stronger metal\u2013ligand bonds.\nFermium(III) can be fairly easily reduced to fermium(II), for example with samarium(II) chloride, with which fermium(II) coprecipitates. In the precipitate, the compound fermium(II) chloride (FmCl) was produced, though it was not purified or studied in isolation. The electrode potential has been estimated to be similar to that of the ytterbium(III)/(II) couple, or about \u22121.15\u00a0V with respect to the standard hydrogen electrode, a value which agrees with theoretical calculations. The Fm/Fm couple has an electrode potential of \u22122.37(10)\u00a0V based on polarographic measurements.\nToxicity.\nThough few people come in contact with fermium, the International Commission on Radiological Protection has set annual exposure limits for the two most stable isotopes. For fermium-253, the ingestion limit was set at 10 becquerels (1 Bq equals one decay per second), and the inhalation limit at 10 Bq; for fermium-257, at 10 Bq and 4,000 Bq respectively."}
{"id": "10823", "revid": "34515925", "url": "https://en.wikipedia.org/wiki?curid=10823", "title": "Fr\u00e9d\u00e9ric Chopin", "text": "Fr\u00e9d\u00e9ric Fran\u00e7ois Chopin (born Fryderyk Franciszek Chopin; 1 March 181017 October 1849) was a Polish composer and virtuoso pianist of the Romantic period, who wrote primarily for solo piano. He has maintained worldwide renown as a leading musician of his era, one whose \"poetic genius was based on a professional technique that was without equal in his generation\".\nChopin was born in \u017belazowa Wola and grew up in Warsaw, which in 1815 became part of Congress Poland. A child prodigy, he completed his musical education and composed his earlier works in Warsaw before leaving Poland at the age of 20, less than a month before the outbreak of the November 1830 Uprising. At 21, he settled in Paris. Thereafter he gave only 30 public performances, preferring the more intimate atmosphere of the salon. He supported himself by selling his compositions and by giving piano lessons, for which he was in high demand. Chopin formed a friendship with Franz Liszt and was admired by many of his musical contemporaries, including Robert Schumann. After a failed engagement to Maria Wodzi\u0144ska from 1836 to 1837, he maintained an often troubled relationship with the French writer Aurore Dupin (known by her pen name George Sand). A brief and unhappy visit to Mallorca with Sand in 1838\u201339 would prove one of his most productive periods of composition. In his final years, he was supported financially by his admirer Jane Stirling. For most of his life, Chopin was in poor health. He died in Paris in 1849 at the age of 39.\nAll of Chopin's compositions feature the piano. Most are for solo piano, though he also wrote two piano concertos, some chamber music, and 19 songs set to Polish lyrics. His piano pieces are technically demanding and expanded the limits of the instrument; his own performances were noted for their nuance and sensitivity. Chopin's major piano works include mazurkas, waltzes, nocturnes, polonaises, the instrumental \"ballade\" (which Chopin created as an instrumental genre), \u00e9tudes, impromptus, scherzi, preludes, and sonatas, some published only posthumously. Among the influences on his style of composition were Polish folk music, the classical tradition of Mozart and Schubert, and the atmosphere of the Paris salons, of which he was a frequent guest. His innovations in style, harmony, and musical form, and his association of music with nationalism, were influential throughout and after the late Romantic period.\nChopin's music, his status as one of music's earliest celebrities, his indirect association with political insurrection, his high-profile love life, and his early death have made him a leading symbol of the Romantic era. His works remain popular, and he has been the subject of numerous films and biographies of varying historical fidelity. Among his many memorials is the Fryderyk Chopin Institute, which was created by the Parliament of Poland to research and promote his life and works. It hosts the International Chopin Piano Competition, a prestigious competition devoted entirely to his works.\nLife.\nEarly life.\nChildhood.\nFr\u00e9d\u00e9ric Chopin was born in \u017belazowa Wola, 46 kilometres () west of Warsaw, in what was then the Duchy of Warsaw, a Polish state established by Napoleon. The parish baptismal record, which is dated 23 April 1810, gives his birthday as 22 February 1810, and cites his given names in the Latin form (in Polish, he was ). The composer and his family used the birthdate 1 March, which is now generally accepted as the correct date.\nHis father, Nicolas Chopin, was a Frenchman from Lorraine who had emigrated to Poland in 1787 at the age of sixteen. He married Justyna Krzy\u017canowska, a poor relative of the Skarbeks, one of the families for whom he worked. Chopin was baptised in the same church where his parents had married, in Broch\u00f3w. His eighteen-year-old godfather, for whom he was named, was Fryderyk Skarbek, a pupil of Nicolas Chopin. Chopin was the second child of Nicolas and Justyna and their only son; he had an elder sister, Ludwika, and two younger sisters, Izabela and Emilia, whose death at the age of 14 was probably from tuberculosis. Nicolas Chopin was devoted to his adopted homeland, and insisted on the use of the Polish language in the household.\nIn October 1810, six months after Chopin's birth, the family moved to Warsaw, where his father acquired a post teaching French at the Warsaw Lyceum, then housed in the Saxon Palace. Chopin lived with his family on the Palace grounds. His father played the flute and violin; his mother played the piano and gave lessons to boys in the boarding house that the Chopins kept. Chopin was of slight build, and even in early childhood was prone to illnesses.\nChopin may have had some piano instruction from his mother, but his first professional music tutor, from 1816 to 1821, was the Czech pianist Wojciech \u017bywny. His elder sister Ludwika also took lessons from \u017bywny, and occasionally played duets with her brother. It quickly became apparent that he was a child prodigy. By the age of seven he had begun giving public concerts, and in 1817 he composed two polonaises, in G minor and B-flat major. His next work, a polonaise in A-flat major of 1821, dedicated to \u017bywny, is his earliest surviving musical manuscript.\nIn 1817 the Saxon Palace was requisitioned by Warsaw's Russian governor for military use, and the Warsaw Lyceum was reestablished in the Kazimierz Palace (today the rectorate of Warsaw University). Chopin and his family moved to a building, which still survives, adjacent to the Kazimierz Palace. During this period, he was sometimes invited to the Belweder Palace as playmate to the son of the ruler of Russian Poland, Grand Duke Konstantin Pavlovich of Russia; he played the piano for Konstantin Pavlovich and composed a march for him. Julian Ursyn Niemcewicz, in his dramatic eclogue, \"\" (\"Our Discourses\", 1818), attested to \"little Chopin's\" popularity.\nEducation.\nFrom September 1823 to 1826, Chopin attended the Warsaw Lyceum, where he received organ lessons from the Czech musician Wilhelm W\u00fcrfel during his first year. In the autumn of 1826 he began a three-year course under the Silesian composer J\u00f3zef Elsner at the Warsaw Conservatory, studying music theory, figured bass, and composition. Throughout this period he continued to compose and to give recitals in concerts and salons in Warsaw. He was engaged by the inventors of the \"aeolomelodicon\" (a combination of piano and mechanical organ), and on this instrument in May 1825 he performed his own improvisation and part of a concerto by Moscheles. The success of this concert led to an invitation to give a recital on a similar instrument (the \"aeolopantaleon\") before Tsar Alexander I, who was visiting Warsaw; the Tsar presented him with a diamond ring. At a subsequent aeolopantaleon concert on 10 June 1825, Chopin performed his Rondo Op. 1. This was the first of his works to be commercially published and earned him his first mention in the foreign press, when the Leipzig praised his \"wealth of musical ideas\".\nFrom 1824 until 1828, Chopin spent his vacations away from Warsaw, at a number of locations. In 1824 and 1825, at Szafarnia, he was a guest of Dominik Dziewanowski, the father of a schoolmate. Here, for the first time, he encountered Polish rural folk music. His letters home from Szafarnia (to which he gave the title \"The Szafarnia Courier\"), written in a very modern and lively Polish, amused his family with their spoofing of the Warsaw newspapers and demonstrated the youngster's literary gift.\nIn 1827, soon after the death of Chopin's youngest sister Emilia, the family moved from the Warsaw University building, adjacent to the Kazimierz Palace, to lodgings just across the street from the university, in the south annex of the Krasi\u0144ski Palace on Krakowskie Przedmie\u015bcie, where Chopin lived until he left Warsaw in 1830. Here his parents continued running their boarding house for male students. Four boarders at his parents' apartments became Chopin's intimates: Tytus Woyciechowski, Jan Nepomucen Bia\u0142ob\u0142ocki, Jan Matuszy\u0144ski, and Julian Fontana. The latter two would become part of his Paris milieu.\nChopin was friendly with members of Warsaw's young artistic and intellectual world, including Fontana, J\u00f3zef Bohdan Zaleski, and Stefan Witwicki. Chopin's final Conservatory report (July 1829) read: \"Chopin F., third-year student, exceptional talent, musical genius.\" In 1829 the artist Ambro\u017cy Mieroszewski executed a set of portraits of Chopin family members, including the first known portrait of the composer.\nLetters from Chopin to Woyciechowski in the period 1829\u201330 (when Chopin was about twenty) contain apparent homoerotic references to dreams and to offered kisses.\nAccording to Adam Zamoyski, such expressions \"were, and to some extent still are, common currency in Polish and carry no greater implication than the 'love concluding letters today. \"The spirit of the times, pervaded by the Romantic movement in art and literature, favoured extreme expression of feeling\u00a0... Whilst the possibility cannot be ruled out entirely, it is unlikely that the two were ever lovers.\" Chopin's biographer Alan Walker considers that, insofar as such expressions could be perceived as homosexual in nature, they would not denote more than a passing phase in Chopin's life, or be the resultin Walker's wordsof a \"mental twist\". The musicologist Jeffrey Kallberg notes that concepts of sexual practice and identity were very different in Chopin's time, so modern interpretation is problematic. Other scholars argue that these are clear, or potential, demonstrations of homosexual impulses on Chopin's part.\nProbably in early 1829, Chopin met the singer Konstancja G\u0142adkowska and developed an intense affection for her, although it is not clear that he ever addressed her directly on the matter. In a letter to Woyciechowski of 3 October 1829 he refers to his \"ideal, whom I have served faithfully for six months, though without ever saying a word to her about my feelings; whom I dream of, who inspired the Adagio of my Concerto\". All of Chopin's biographers, following the lead of Frederick Niecks, agree that this \"ideal\" was G\u0142adkowska. After what would be Chopin's farewell concert in Warsaw in October 1830, which included the concerto, played by the composer, and G\u0142adkowska singing an aria by Gioachino Rossini, the two exchanged rings, and two weeks later she wrote in his album some affectionate lines bidding him farewell. After Chopin left Warsaw, he and G\u0142adkowska did not meet and apparently did not correspond.\nCareer.\nTravel and domestic success.\nIn September 1828, Chopin, while still a student, visited Berlin with a family friend, zoologist Feliks Jarocki, enjoying operas directed by Gaspare Spontini and attending concerts by Carl Friedrich Zelter, Felix Mendelssohn, and other celebrities. On an 1829 return trip to Berlin, he was a guest of Prince Antoni Radziwi\u0142\u0142, governor of the Grand Duchy of Posenhimself an accomplished composer and aspiring cellist. For the prince and his pianist daughter Wanda, he composed his Introduction and Polonaise brillante in C major for cello and piano, Op.\u00a03.\nBack in Warsaw that year, Chopin heard Niccol\u00f2 Paganini play the violin, and composed a set of variations, . It may have been this experience that encouraged him to commence writing his first \u00c9tudes (1829\u20131832), exploring the capacities of his own instrument. After completing his studies at the Warsaw Conservatory, he made his debut in Vienna. He gave two piano concerts and received many favourable reviewsin addition to some commenting (in Chopin's own words) that he was \"too delicate for those accustomed to the piano-bashing of local artists\". In the first of these concerts, he premiered his Variations on, Op.\u00a02 (variations on a duet from Mozart's opera \"Don Giovanni\") for piano and orchestra. He returned to Warsaw in September 1829, where he premiered his Piano Concerto No. 2 in F minor, Op.\u00a021 on 17 March 1830.\nChopin's successes as a composer and performer opened the door to western Europe for him, and on 2 November 1830, he set out, in the words of Zdzis\u0142aw Jachimecki, \"into the wide world, with no very clearly defined aim, forever\". With Woyciechowski, he headed for Austria again, intending to go on to Italy. Later that month, in Warsaw, the November 1830 Uprising broke out, and Woyciechowski returned to Poland to enlist. Chopin, now alone in Vienna, was nostalgic for his homeland, and wrote to a friend, \"I curse the moment of my departure.\" When in September 1831 he learned, while travelling from Vienna to Paris, that the uprising had been crushed, he expressed his anguish in the pages of his private journal: \"Oh God!\u00a0... You are there, and yet you do not take vengeance!\". The journal is now in the National Library of Poland. Jachimecki ascribes to these events the composer's maturing \"into an inspired national bard who intuited the past, present and future of his native Poland\".\nParis.\nWhen he left Warsaw on 2 November 1830, Chopin had intended to go to Italy, but violent unrest there made that a dangerous destination. His next choice was Paris; difficulties obtaining a visa from Russian authorities resulted in him obtaining transit permission from the French. In later years he would quote the passport's endorsement (\"In transit to London via Paris\"), joking that he was in the city \"only in passing\". Chopin arrived in Paris on 5 October 1831;\n he would never return to Poland, thus becoming one of many expatriates of the Polish Great Emigration. In France, he used the French versions of his given names, and after receiving French citizenship in 1835, he travelled on a French passport. Chopin remained close to his fellow Poles in exile as friends and confidants. He never felt fully comfortable speaking French or considered himself to be French, despite his father's French origins. He always saw himself as a Pole, Adam Zamoyski wrote.\nIn Paris, Chopin encountered artists and other distinguished figures and found many opportunities to exercise his talents and achieve celebrity. During his years in Paris, he was to become acquainted with, among many others, Hector Berlioz, Franz Liszt, Ferdinand Hiller, Heinrich Heine, Eug\u00e8ne Delacroix, Alfred de Vigny, and Friedrich Kalkbrenner, who introduced him to the piano manufacturer Camille Pleyel. This was the beginning of a long and close association between the composer and Pleyel's instruments. Chopin was also acquainted with the poet Adam Mickiewicz, principal of the Polish Literary Society, some of whose verses he set as songs. He also was more than once guest of Marquis Astolphe de Custine, one of his fervent admirers, playing his works in Custine's salon.\nTwo Polish friends in Paris were also to play important roles in Chopin's life there. A fellow student at the Warsaw Conservatory, Julian Fontana, had originally tried unsuccessfully to establish himself in England; Fontana was to become, in the words of the music historian Jim Samson, Chopin's \"general factotum and copyist\". Albert Grzyma\u0142a, who in Paris became a wealthy financier and society figure, often acted as Chopin's adviser and, in Zamoyski's words, \"gradually began to fill the role of elder brother in [his] life\".\nOn 7 December 1831, Chopin received the first major endorsement from an outstanding contemporary when Robert Schumann, reviewing the Op. 2 Variations in the (his first published article on music), declared: \"Hats off, gentlemen! A genius.\" On 25 February 1832 Chopin gave a debut Paris concert in the at 9 rue Cadet, which drew universal admiration. The critic Fran\u00e7ois-Joseph F\u00e9tis wrote in the : \"Here is a young man who\u00a0... taking no model, has found, if not a complete renewal of piano music,\u00a0... an abundance of original ideas of a kind to be found nowhere else\u00a0...\" After this concert, Chopin realised that his essentially intimate keyboard technique was not optimal for large concert spaces. Later that year he was introduced to the wealthy Rothschild banking family, whose patronage also opened doors for him to other private salons (social gatherings of the aristocracy and artistic and literary elite). By the end of 1832 Chopin had established himself among the Parisian musical elite and had earned the respect of his peers such as Hiller, Liszt, and Berlioz. He no longer depended financially upon his father, and in the winter of 1832, he began earning a handsome income from publishing his works and teaching piano to affluent students from all over Europe. This freed him from the strains of public concert-giving, which he disliked.\nChopin seldom performed publicly in Paris. In later years he generally gave a single annual concert at the Salle Pleyel, a venue that seated three hundred. He played more frequently at salons but preferred playing at his own Paris apartment for small groups of friends. The musicologist Arthur Hedley has observed that \"As a pianist Chopin was unique in acquiring a reputation of the highest order on the basis of a minimum of public appearancesfew more than thirty in the course of his lifetime.\" The list of musicians who took part in some of his concerts indicates the richness of Parisian artistic life during this period. Examples include a concert on 23 March 1833, in which Chopin, Liszt, and Hiller performed (on pianos) a concerto by J. S. Bach for three keyboards; and, on 3 March 1838, a concert in which Chopin, his pupil Adolphe Gutmann, Charles-Valentin Alkan, and Alkan's teacher Joseph Zimmermann performed Alkan's arrangement, for eight hands, of two movements from Beethoven's 7th symphony. Chopin was also involved in the composition of Liszt's \"Hexameron\"; he wrote the sixth (and final) variation on Bellini's theme. Chopin's music soon found success with publishers, and in 1833 he contracted with Maurice Schlesinger, who arranged for it to be published not only in France but, through his family connections, also in Germany and England.\nIn the spring of 1834, Chopin attended the Lower Rhenish Music Festival in Aix-la-Chapelle with Hiller, and it was there that Chopin met Felix Mendelssohn. After the festival, the three visited D\u00fcsseldorf, where Mendelssohn had been appointed musical director. They spent what Mendelssohn described as \"a very agreeable day\", playing and discussing music at his piano, and met Friedrich Wilhelm Schadow, director of the Academy of Art, and some of his eminent pupils such as Lessing, Bendemann, Hildebrandt and Sohn. In 1835 Chopin went to Carlsbad, where he spent time with his parents; it was the last time he would see them. On his way back to Paris, he met old friends from Warsaw, the Wodzi\u0144skis, their sons, and their daughters, amongst which Maria, whom he occasionally had given piano lessons in Poland. This meeting prompted him to stay for two weeks in Dresden, when he had previously intended to return to Paris via Leipzig. The sixteen-year-old girl's portrait of the composer has been considered, along with Delacroix's, as among the best likenesses of Chopin.\nIn October he finally reached Leipzig, where he met Schumann, Clara Wieck, and Mendelssohn, who organised for him a performance of his own oratorio \"St. Paul\", and who considered him \"a perfect musician\". In July 1836 Chopin travelled to Marienbad and Dresden to be with the Wodzi\u0144ski family, and in September he proposed to Maria, whose mother Countess Wodzi\u0144ska approved in principle. Chopin went on to Leipzig, where he presented Schumann with his G minor Ballade. At the end of 1836, he sent Maria an album in which his sister Ludwika had inscribed seven of his songs, and his 1835 Nocturne in C-sharp minor, Op. 27, No. 1. The anodyne thanks he received from Maria proved to be the last letter he was to have from her. Chopin placed the letters he had received from Maria and her mother into a large envelope, wrote on it the words \"My sorrow\" (), and to the end of his life retained in a desk drawer this keepsake of the second love of his life.\nFranz Liszt.\nAlthough it is not known exactly when Chopin first met Franz Liszt after arriving in Paris, on 12 December 1831 he mentioned in a letter to his friend Woyciechowski that \"I have met Rossini, Cherubini, Baillot, etc.also Kalkbrenner. You would not believe how curious I was about Herz, Liszt, Hiller, etc.\" Liszt was in attendance at Chopin's Parisian debut on 26 February 1832 at the Salle Pleyel, which led him to remark: \"The most vigorous applause seemed not to suffice to our enthusiasm in the presence of this talented musician, who revealed a new phase of poetic sentiment combined with such happy innovation in the form of his art.\"\nThe two became friends, and for many years lived close to each other in Paris, Chopin at 38 , and Liszt at the on the , a few blocks away. They performed together on seven occasions between 1833 and 1841. The first, on 2 April 1833, was at a benefit concert organised by Hector Berlioz for his bankrupt Shakespearean actress wife Harriet Smithson, during which they played George Onslow's \"Sonata in F minor\" for piano duet. Later joint appearances included a benefit concert for the Benevolent Association of Polish Ladies in Paris. Their last appearance together in public was for a charity concert conducted for the Beethoven Monument in Bonn, held at the Salle Pleyel and the Paris Conservatory on 25 and 26 April 1841.\nAlthough the two displayed great respect and admiration for each other, their friendship was uneasy and had some qualities of a love\u2013hate relationship. Harold C. Schonberg believes that Chopin displayed a \"tinge of jealousy and spite\" towards Liszt's virtuosity on the piano, and others have also argued that he had become enchanted with Liszt's theatricality, showmanship, and success. Liszt was the dedicatee of Chopin's Op. 10 , and his performance of them prompted the composer to write to Hiller, \"I should like to rob him of the way he plays my studies.\" However, Chopin expressed annoyance in 1843 when Liszt performed one of his nocturnes with the addition of numerous intricate embellishments, at which Chopin remarked that he should play the music as written or not play it at all, forcing an apology. Most biographers of Chopin state that after this the two had little to do with each other, although in his letters dated as late as 1848 he still referred to him as \"my friend Liszt\". Some commentators point to events in the two men's romantic lives which led to a rift between them; there are claims that Liszt had displayed jealousy of his mistress Marie d'Agoult's obsession with Chopin, while others believe that Chopin had become concerned about Liszt's growing relationship with George Sand.\nGeorge Sand.\nIn 1836, at a party hosted by Marie d'Agoult, Chopin met the French author George Sand (born [Amantine] Aurore [Lucile] Dupin). Short (under five feet, or 152\u00a0cm), dark, big-eyed and a cigar smoker, she initially repelled Chopin, who remarked, \"What an unattractive person \"la Sand\" is. Is she really a woman?\" However, by early 1837 Maria Wodzi\u0144ska's mother had made it clear to Chopin in correspondence that a marriage with her daughter was unlikely to proceed. It is thought that she was influenced by his poor health and possibly also by rumours about his associations with women such as d'Agoult and Sand. Chopin finally placed the letters from Maria and her mother in a package on which he wrote, in Polish, \"My Sorrow\". Sand, in a letter to Grzyma\u0142a of June 1838, admitted strong feelings for the composer and debated whether to abandon a current affair to begin a relationship with Chopin; she asked Grzyma\u0142a to assess Chopin's relationship with Maria Wodzi\u0144ska, without realising that the affair, at least from Maria's side, was over.\nIn June 1837, Chopin visited London incognito in the company of the piano manufacturer Camille Pleyel, where he played at a musical soir\u00e9e at the house of English piano maker James Broadwood. On his return to Paris his association with Sand began in earnest, and by July 1838 they had become lovers. Sand, who was six years older than the composer and had had a series of lovers, wrote at this time: \"I must say I was confused and amazed at the effect this little creature had on me\u00a0... I have still not recovered from my astonishment, and if I were a proud person I should be feeling humiliated at having been carried away\u00a0...\" The two spent a miserable winter on Majorca (8 November 1838 to 13 February 1839), where, together with Sand's two children, they had journeyed in the hope of improving Chopin's health and that of Sand's 15-year-old son Maurice, and also to escape the threats of Sand's former lover F\u00e9licien Mallefille. After discovering that the couple were not married, the deeply traditional Catholic people of Majorca became inhospitable, making accommodation difficult to find. This compelled the group to take lodgings in a former Carthusian monastery in Valldemossa, which gave little shelter from the cold winter weather.\nOn 3 December 1838, Chopin complained about his bad health and the incompetence of the doctors in Majorca, commenting: \"The three most celebrated doctors on the island have seen me\u00a0... The first said I was dead, the second that I am dying, and the third that I'm going to die\" He also had problems having his Pleyel piano sent to him, having to rely in the meantime on a piano made in Palma by Juan Bauza. The Pleyel piano finally arrived from Paris in December, just shortly before Chopin and Sand left the island. Chopin wrote to Pleyel in January 1839: \"I am sending you my Preludes [Op. 28]. I finished them on your little piano, which arrived in the best possible condition in spite of the sea, the bad weather and the Palma customs.\" Chopin was also able to undertake work while in Majorca on his Ballade No. 2, Op. 38; on two Polonaises, Op. 40; and on the Scherzo No. 3, Op. 39.\nAlthough this period had been productive, the bad weather had such a detrimental effect on Chopin's health that Sand determined to leave the island. To avoid further customs duties, Sand sold the piano to a local French couple, the Canuts. The group travelled first to Barcelona, then to Marseille, where they stayed for a few months while Chopin convalesced. While in Marseille, Chopin made a rare appearance at the organ during a requiem mass for the tenor Adolphe Nourrit on 24 April 1839, playing a transcription of Franz Schubert's (D. 939). George Sand gives a description of Chopin's playing in a letter of 28 April 1839:\nIn May 1839, they headed to Sand's estate at Nohant for the summer, where they spent most of the following summers until 1846. In autumn they returned to Paris, where Chopin's apartment at 5 rue Tronchet was close to Sand's rented accommodation on the rue Pigalle. He frequently visited Sand in the evenings, but both retained some independence. (In 1842 he and Sand moved to the Square d'Orl\u00e9ans, living in adjacent buildings.)\nOn 26 July 1840, Chopin and Sand were present at the dress rehearsal of Berlioz's , composed to commemorate the tenth anniversary of the July Revolution. Chopin was reportedly unimpressed with the composition. \nDuring the summers at Nohant, particularly in the years 1839\u20131843 (except 1840), Chopin found quiet, productive days during which he composed many works, including his Polonaise in A-flat major, Op. 53. Sand compellingly describes Chopin's creative process: an inspiration, its painstaking elaboration \u2013 sometimes amid tormented weeping and complaining, with hundreds of changes in concept \u2013 only to return finally to the initial idea.\nAmong the visitors to Nohant were Delacroix and the mezzo-soprano Pauline Viardot, whom Chopin had advised on piano technique and composition. Delacroix gives an account of staying at Nohant in a letter of 7 June 1842:\nDecline.\nFrom 1842 onwards, Chopin showed signs of serious illness. After a solo recital in Paris on 21 February 1842, he wrote to Grzyma\u0142a: \"I have to lie in bed all day long, my mouth and tonsils are aching so much.\" He was forced by illness to decline a written invitation from Alkan to participate in a repeat performance of the Beethoven 7th Symphony arrangement at \u00c9rard's on 1 March 1843. Late in 1844, Charles Hall\u00e9 visited Chopin and found him \"hardly able to move, bent like a half-opened penknife and evidently in great pain\", although his spirits returned when he started to play the piano for his visitor. Chopin's health continued to deteriorate, particularly from this time onwards. Modern research suggests that apart from any other illnesses, he may also have suffered from temporal lobe epilepsy.\nChopin's output as a composer throughout this period declined in quantity year by year. Whereas in 1841 he had written a dozen works, only six were written in 1842 and six shorter pieces in 1843. In 1844 he wrote only the Op. 58 sonata. 1845 saw the completion of three mazurkas (Op. 59). Although these works were more refined than many of his earlier compositions, Zamoyski concludes that \"his powers of concentration were failing and his inspiration was beset by anguish, both emotional and intellectual\". Chopin's relations with Sand were soured in 1846 by problems involving her daughter Solange and Solange's fianc\u00e9, the young fortune-hunting sculptor Auguste Cl\u00e9singer. The composer frequently took Solange's side in quarrels with her mother; he also faced jealousy from Sand's son Maurice. Moreover, Chopin was indifferent to Sand's radical political pursuits, including her enthusiasm for the February Revolution of 1848.\nAs the composer's illness progressed, Sand had become less of a lover and more of a nurse to Chopin, whom she called her \"third child\". In letters to third parties she vented her impatience, referring to him as a \"child\", a \"poor angel\", a \"sufferer\", and a \"beloved little corpse\". In 1847 Sand published her novel \"Lucrezia Floriani\", whose main charactersa rich actress and a prince in weak healthcould be interpreted as Sand and Chopin. In Chopin's presence, Sand read the manuscript aloud to Delacroix, who was both shocked and mystified by its implications, writing that \"Madame Sand was perfectly at ease and Chopin could hardly stop making admiring comments\". That year their relationship ended following an angry correspondence which, in Sand's words, made \"a strange conclusion to nine years of exclusive friendship\". Grzyma\u0142a, who had followed their romance from the beginning, commented, \"If [Chopin] had not had the misfortune of meeting G. S. [George Sand], who poisoned his whole being, he would have lived to be Cherubini's age.\" Chopin would die two years later at thirty-nine; the composer Luigi Cherubini had died in Paris in 1842 at the age of 81.\nTour of Great Britain.\nChopin's public popularity as a virtuoso began to wane, as did the number of his pupils, and this, together with the political strife and instability of the time, caused him to struggle financially. In February 1848, with the cellist Auguste Franchomme, he gave his last Paris concert, which included three movements of the Cello Sonata Op. 65.\nIn April, during the 1848 Revolution in Paris, he left for London, where he performed at several concerts and numerous receptions in great houses. This tour was suggested to him by his Scottish pupil Jane Stirling and her elder sister. Stirling also made all the logistical arrangements and provided much of the necessary funding.\nIn London, Chopin took lodgings at Dover Street, where the firm of Broadwood provided him with a grand piano. At his first engagement, on 15 May at Stafford House, the audience included Queen Victoria and Prince Albert. The Prince, who was himself a talented musician, moved close to the keyboard to view Chopin's technique. Broadwood also arranged concerts for him; among those attending were the author William Makepeace Thackeray and the singer Jenny Lind. Chopin was also sought after for piano lessons, for which he charged the high fee of one guinea per hour, and for private recitals for which the fee was 20 guineas. At a concert on 7 July he shared the platform with Viardot, who sang arrangements of some of his mazurkas to Spanish texts. A few days later, he performed for Thomas Carlyle and his wife Jane at their home in Chelsea. On 28 August he played at a concert in Manchester's Gentlemen's Concert Hall, sharing the stage with Marietta Alboni and Lorenzo Salvi.\nIn late summer he was invited by Jane Stirling to visit Scotland, where he stayed at Calder House near Edinburgh and at Johnstone Castle in Renfrewshire, both owned by members of Stirling's family. She clearly had a notion of going beyond mere friendship, and Chopin was obliged to make it clear to her that this could not be so. He wrote at this time to Grzyma\u0142a: \"My Scottish ladies are kind, but such bores\", and responding to a rumour about his involvement, answered that he was \"closer to the grave than the nuptial bed\". He gave a public concert in Glasgow on 27 September, and another in Edinburgh at the Hopetoun Rooms on Queen Street (now Erskine House) on 4 October. In late October 1848, while staying at 10 Warriston Crescent in Edinburgh with the Polish physician Adam \u0141yszczy\u0144ski, he wrote out his last will and testament\"a kind of disposition to be made of my stuff in the future, if I should drop dead somewhere\", he wrote to Grzyma\u0142a.\nChopin made his last public appearance on a concert platform at London's Guildhall on 16 November 1848, when, in a final patriotic gesture, he played for the benefit of Polish refugees. This gesture proved to be a mistake, as most of the participants were more interested in the dancing and refreshments than in Chopin's piano artistry, which drained him. By this time he was very seriously ill, weighing under 45\u00a0kg (99 lb), and his doctors were aware that his sickness was at a terminal stage.\nAt the end of November Chopin returned to Paris. He passed the winter in unremitting illness, but gave occasional lessons and was visited by friends, including Delacroix and Franchomme. Occasionally he played, or accompanied the singing of Delfina Potocka, for his friends. During the summer of 1849, his friends found him an apartment in Chaillot, out of the centre of the city, for which the rent was secretly subsidised by an admirer, Princess Yekaterina Dmitrievna Soutzos-Obreskova. He was visited here by Jenny Lind in June 1849.\nDeath and funeral.\nWith his health further deteriorating, Chopin desired to have a family member with him. In June 1849 his sister Ludwika came to Paris with her husband and daughter, and in September, he took an apartment at the H\u00f4tel Baudard de Saint-James on the Place Vend\u00f4me, with rent possibly supported by Jane Stirling. After 15 October, when his condition took a marked turn for the worse, only a handful of his closest friends remained with him. Viardot remarked sardonically, though, that \"all the grand Parisian ladies considered it to faint in his room\".\nSome of his friends provided music at his request; among them, Potocka sang and Franchomme played the cello. Chopin bequeathed his unfinished notes on a piano tuition method, , to Alkan for completion. On 17 October, after midnight, the physician leaned over him and asked whether he was suffering greatly. \"No longer\", he replied. He died a few minutes before 2 a.m. He was 39. Those present at the deathbed appear to have included his sister Ludwika, Fr. Aleksander Je\u0142owicki, Princess Marcelina Czartoryska, Sand's daughter Solange, and his close friend Thomas Albrecht. Later that morning, Solange's husband Cl\u00e9singer made Chopin's death mask and a cast of his left hand.\nThe funeral, held at the Church of the Madeleine in Paris, was delayed almost two weeks until 30 October. Entrance was restricted to ticket holders, as many people were expected to attend. Over 3,000 people arrived without invitations, from as far as London, Berlin and Vienna, and were excluded.\nMozart's Requiem was sung at the funeral; the soloists were the soprano Jeanne-Ana\u00efs Castellan, the mezzo-soprano Pauline Viardot, the tenor Alexis Dupont, and the bass Luigi Lablache; Chopin's Preludes No.\u00a04 in E minor and No.\u00a06 in B minor were also played. The organist was Alfred Lef\u00e9bure-W\u00e9ly. The funeral procession to P\u00e8re Lachaise Cemetery, which included Chopin's sister Ludwika, was led by the aged Prince Adam Czartoryski. The pallbearers included Delacroix, Franchomme, and Camille Pleyel. At the graveside, the \"Funeral March\" from Chopin's Piano Sonata No. 2 was played, in Reber's instrumentation.\nChopin's tombstone, featuring the muse of music, Euterpe, weeping over a broken lyre, was designed and sculpted by Cl\u00e9singer and installed on the anniversary of his death in 1850. The expenses of the monument, amounting to 4,500 francs, were covered by Jane Stirling, who also paid for the return of the composer's sister Ludwika to Warsaw. As requested by Chopin, Ludwika took his heart (which had been removed by his doctor Jean Cruveilhier and preserved in alcohol in a vase) back to Poland in 1850. She also took a collection of 200 letters from Sand to Chopin; after 1851 these were returned to Sand, who destroyed them.\nChopin's disease and the cause of his death have been topics of debate. His death certificate gave the cause as tuberculosis, and his physician, Cruveilhier, was then the leading French authority on this disease. Other possibilities advanced have included cystic fibrosis, cirrhosis, and alpha 1-antitrypsin deficiency. A visual examination of Chopin's preserved heart (the jar was not opened), conducted in 2014 and first published in the \"American Journal of Medicine\" in 2017, suggested that the likely cause of his death was a rare case of pericarditis caused by complications of chronic tuberculosis.\nMusic.\nOverview.\nOver 230 works of Chopin survive; some compositions from early childhood have been lost. All his known works involve the piano, and only a few range beyond solo piano music, as either piano concertos, songs or chamber music.\nChopin was educated in the tradition of Beethoven, Haydn, Mozart, and Clementi; he used Clementi's piano method with his students. He was also influenced by Hummel's development of virtuoso, yet Mozartian, piano technique. He cited Bach and Mozart as the two most important composers in shaping his musical outlook. Chopin's early works are in the style of the \"brilliant\" keyboard pieces of his era as exemplified by the works of Ignaz Moscheles, Friedrich Kalkbrenner, and others. Less direct in the earlier period are the influences of Polish folk music and of Italian opera. Much of what became his typical style of ornamentation (for example, his \"fioriture\") is taken from singing. His melodic lines were increasingly reminiscent of the modes and features of the music of his native country, such as drones.\nChopin took the new salon genre of the nocturne, invented by the Irish composer John Field, to a deeper level of sophistication. He was the first to write ballades and scherzi as individual concert pieces. He essentially established a new genre with his own set of free-standing preludes (Op.\u00a028, published 1839). He exploited the poetic potential of the concept of the concert \u00e9tude, already being developed in the 1820s and 1830s by Liszt, Clementi, and Moscheles, in his two sets of studies (Op.\u00a010 published in 1833, Op.\u00a025 in 1837).\nChopin also endowed popular dance forms with a greater range of melody and expression. Chopin's mazurkas, while originating in the traditional Polish dance (the \"mazurek\"), differed from the traditional variety in that they were written for the concert hall rather than the dance hall; as J. Barrie Jones puts it, \"it was Chopin who put the mazurka on the European musical map\". The series of seven polonaises published in his lifetime (another nine were published posthumously), beginning with the Op.\u00a026 pair (published 1836), set a new standard for music in the form. His waltzes were also written specifically for the salon recital rather than the ballroom and are frequently at rather faster tempos than their dance-floor equivalents.\nTitles, opus numbers and editions.\nSome of Chopin's well-known pieces have acquired descriptive titles, such as the \"Revolutionary\" \u00c9tude (Op.\u00a010,\u00a0No.\u00a012), and the \"Minute Waltz\" (Op.\u00a064,\u00a0No.\u00a01). However, except for his \"Funeral March\", the composer never named an instrumental work beyond genre and number, leaving all potential extramusical associations to the listener; the names by which many of his pieces are known were invented by others. There is no evidence to suggest that the \"Revolutionary\" \u00c9tude was written with the failed Polish uprising against Russia in mind; it merely appeared at that time. The \"Funeral March\", the third movement of his Sonata No. 2 (Op.\u00a035), the one case where he did give a title, was written before the rest of the sonata, but no specific event or death is known to have inspired it.\nThe last opus number that Chopin himself used was 65, allocated to the Cello Sonata in G minor. He expressed a deathbed wish that all his unpublished manuscripts be destroyed. At the request of the composer's mother and sisters, however, his musical executor Julian Fontana selected 23 unpublished piano pieces and grouped them into eight further opus numbers (Opp. 66\u201373), published in 1855. In 1857, 17 Polish songs that Chopin wrote at various stages of his life were collected and published as Op. 74, though their order within the opus did not reflect the order of composition.\nWorks published since 1857 have received alternative catalogue designations instead of opus numbers. The most up-to-date catalogue is maintained by the Fryderyk Chopin Institute at its Internet Chopin Information Centre. The older Kobyla\u0144ska Catalogue (usually represented by the initials 'KK'), named for its compiler, the Polish musicologist Krystyna Kobyla\u0144ska, is still considered an important scholarly reference. The most recent catalogue of posthumously published works is that of the National Edition of the Works of Fryderyk Chopin, represented by the initials 'WN'.\nChopin's original publishers included Maurice Schlesinger and Camille Pleyel. His works soon began to appear in popular 19th-century piano anthologies. The first collected edition was by Breitkopf &amp; H\u00e4rtel (1878\u20131902). Among modern scholarly editions of Chopin's works is the version named after Paderewski (although he died before the work had begun), published between 1949 and 1961. However, scholarly opinion has moved against this edition. The more recent Polish National Edition, edited by Jan Ekier and published between 1967 and 2010, is recommended to contestants of the Chopin Competition. Both editions contain detailed explanations and discussions regarding choices and sources.\nChopin published his music in France, England, and the German states (i.e. he worked with as many as three separate publishers for each piece or set of pieces) due to the copyright laws of the time. Thus there are often three different \"first editions\" of each work. Each edition is different from the others; Chopin edited them separately, and at times he did some revision to the music while editing it. Furthermore, Chopin provided his publishers with varying sources, including autographs, annotated proofsheets, and scribal copies. Only recently have these differences gained greater recognition.\nForm and harmony.\n Improvisation stands at the centre of Chopin's creative processes. However, this does not imply impulsive rambling: Nicholas Temperley writes that \"improvisation is designed for an audience, and its starting-point is that audience's expectations, which include the current conventions of musical form\". The works for piano and orchestra, including the two concertos, are held by Temperley to be \"merely vehicles for brilliant piano playing\u00a0... formally longwinded and extremely conservative\". After the piano concertos (which are both early, dating from 1830), Chopin made no attempts at large-scale multi-movement forms, save for his late sonatas for piano and cello; \"instead he achieved near-perfection in pieces of simple general design but subtle and complex cell-structure\". Rosen suggests that an important aspect of Chopin's individuality is his flexible handling of the four-bar phrase as a structural unit.\nJ. Barrie Jones suggests that \"amongst the works that Chopin intended for concert use, the four ballades and four scherzi stand supreme\", and adds that \"the Barcarolle Op.\u00a060 stands apart as an example of Chopin's rich harmonic palette coupled with an Italianate warmth of melody\". Temperley opines that these works, which contain \"immense variety of mood, thematic material and structural detail\", are based on an extended \"departure and return\" form; \"the more the middle section is extended, and the further it departs in key, mood and theme, from the opening idea, the more important and dramatic is the reprise when it at last comes\".\nChopin's mazurkas and waltzes are all in straightforward ternary or episodic form, sometimes with a coda. The mazurkas often show more folk features than many of his other works, sometimes including modal scales and harmonies and the use of drone basses. However, some also show unusual sophistication, for example, Op.\u00a063 No.\u00a03, which includes a canon at one beat's distance, a great rarity in music.\nChopin's polonaises show a marked advance on those of his Polish predecessors in the form (who included his teachers \u017bywny and Elsner). As with the traditional polonaise, Chopin's works are in triple time and typically display a martial rhythm in their melodies, accompaniments, and cadences. Unlike most of their precursors, they also require a formidable playing technique.\nHis nocturnes are more structured, and of greater emotional depth, than those of Field, whom Chopin met in 1832. Many of the Chopin nocturnes have middle sections marked by agitated expression (and often making very difficult demands on the performer), which heightens their dramatic character.\nChopin's \u00e9tudes are largely in straightforward ternary form. He used them to teach his own technique of piano playingfor instance playing double thirds (Op.\u00a025, No.\u00a06), playing in octaves (Op.\u00a025, No.\u00a010), and playing repeated notes (Op.\u00a010, No.\u00a0 7).\nThe preludes, many of which are very brief, were described by Schumann as \"the beginnings of studies\". Inspired by J. S. Bach's \"The Well-Tempered Clavier\", Chopin's preludes move up the circle of fifths (rather than Bach's chromatic scale sequence) to create a prelude in each major and minor tonality. The preludes were perhaps not intended to be played as a group, and may even have been used by him and later pianists as generic preludes to others of his pieces, or even to music by other composers. This is suggested by Kenneth Hamilton, who has noted a 1922 recording by Ferruccio Busoni in which the Prelude Op.\u00a028 No.\u00a07 is followed by the \u00c9tude Op.\u00a010 No.\u00a05.\nThe two mature Chopin piano sonatas (No.\u00a02, Op.\u00a035, written in 1839 and No.\u00a03, Op.\u00a058, written in 1844) are in four movements. In Op.\u00a035, Chopin combined within a formal large musical structure many elements of his virtuosic piano technique\"a kind of dialogue between the public pianism of the brilliant style and the German sonata principle\". This sonata has been considered as showing the influences of both Bach and Beethoven. The Prelude from Bach's Suite No. 6 in D major for cello (BWV 1012) is quoted; and there are references to the Sonata Opus 26 by Beethoven, which, like Chopin's Op. 35, has a funeral march as its slow movement. The last movement of Chopin's Op. 35, a brief (75-bar) perpetuum mobile in which the hands play in unmodified octave unison throughout, was found shocking and unmusical by contemporaries, including Schumann. The Op.\u00a058 sonata is closer to the German tradition, including many passages of complex counterpoint, \"worthy of Brahms\" according to Samson.\nChopin's harmonic innovations may have arisen partly from his keyboard improvisation technique. In his works, Temperley says, \"novel harmonic effects often result from the combination of ordinary appoggiaturas or passing notes with melodic figures of accompaniment\", and cadences are delayed by the use of chords outside the home key (neapolitan sixths and diminished sevenths) or by sudden shifts to remote keys. Chord progressions sometimes anticipate the shifting tonality of later composers such as Claude Debussy, as does Chopin's use of modal harmony.\nTechnique and performance style.\nIn 1841 L\u00e9on Escudier wrote of a recital given by Chopin that year, \"One may say that Chopin is the creator of a school of piano and a school of composition. In truth, nothing equals the lightness, the sweetness with which the composer preludes on the piano; moreover nothing may be compared to his works full of originality, distinction and grace.\" Chopin refused to conform to a standard method of playing and believed that there was no set technique for playing well. His style was based extensively on his use of a very independent finger technique. In his he wrote: \"Everything is a matter of knowing good fingering\u00a0... we need no less to use the rest of the hand, the wrist, the forearm and the upper arm.\" He further stated: \"One needs only to study a certain position of the hand in relation to the keys to obtain with ease the most beautiful quality of sound, to know how to play short notes and long notes, and [to attain] unlimited dexterity.\" The consequences of this approach to technique in Chopin's music include the frequent use of the entire range of the keyboard, passages in double octaves and other chord groupings, swiftly repeated notes, the use of grace notes, and the use of contrasting rhythms (four against three, for example) between the hands.\nJonathan Bellman writes that modern concert performance styleset in the \"conservatory\" tradition of late 19th- and 20th-century music schools, and suitable for large auditoria or recordingsmilitates against what is known of Chopin's more intimate performance technique. The composer himself said to a pupil that \"concerts are never real music, you have to give up the idea of hearing in them all the most beautiful things of art\". Contemporary accounts indicate that in performance, Chopin avoided rigid procedures sometimes incorrectly attributed to him, such as \"always crescendo to a high note\", but that he was concerned with expressive phrasing, rhythmic consistency and sensitive colouring. Berlioz wrote in 1853 that Chopin \"has created a kind of chromatic embroidery\u00a0... whose effect is so strange and piquant as to be impossible to describe\u00a0... virtually nobody but Chopin himself can play this music and give it this unusual turn\". Hiller wrote that \"What in the hands of others was elegant embellishment, in his hands became a colourful wreath of flowers.\"\nChopin's music is frequently played with \"rubato\", \"the practice in performance of disregarding strict time, 'robbing' some note-values for expressive effect\". There are differing opinions as to how much, and what type, of \"rubato\" is appropriate for his works. Charles Rosen comments that \"most of the written-out indications of rubato in Chopin are to be found in his mazurkas\u00a0... It is probable that Chopin used the older form of rubato so important to Mozart\u00a0... [where] the melody note in the right hand is delayed until after the note in the bass\u00a0... An allied form of this rubato is the arpeggiation of the chords thereby delaying the melody note; according to Chopin's pupil Karol Mikuli, Chopin was firmly opposed to this practice.\"\nChopin's pupil wrote:\nInstruments.\nWhen living in Warsaw, Chopin composed and played on an instrument built by the piano-maker Fryderyk Buchholtz. Later in Paris Chopin purchased a piano from Pleyel. He rated Pleyel's pianos as \"non plus ultra\" (\"nothing better\"). Franz Liszt befriended Chopin in Paris and described the sound of Chopin's Pleyel as being \"the marriage of crystal and water\". While in London in 1848, Chopin mentioned his pianos in his letters: \"I have a large drawing-room with three pianos, a Pleyel, a Broadwood and an Erard.\"\nPolish identity.\nWith his mazurkas and polonaises, Chopin has been credited with introducing to music a new sense of nationalism. Schumann, in his 1836 review of the piano concertos, highlighted the composer's strong feelings for his native Poland, writing:\nThe biography of Chopin published in 1863 under the name of Franz Liszt (but probably written by Carolyne zu Sayn-Wittgenstein) states that Chopin \"must be ranked among the first musicians\u00a0... individualizing in themselves the poetic sense of an entire nation\".\nSome modern commentators have argued against exaggerating Chopin's primacy as a \"nationalist\" or \"patriotic\" composer. George Golos refers to earlier \"nationalist\" composers in Central Europe, including Poland's Micha\u0142 Kleofas Ogi\u0144ski and Franciszek Lessel, who utilised polonaise and mazurka forms. Barbara Milewski suggests that Chopin's experience of Polish music came more from \"urbanised\" Warsaw versions than from folk music, and that attempts by Jachimecki and others to demonstrate genuine folk music in his works are without basis. Richard Taruskin impugns Schumann's attitude toward Chopin's works as patronising, and comments that Chopin \"felt his Polish patriotism deeply and sincerely\" but consciously modelled his works on the tradition of Bach, Beethoven, Schubert, and Field.\nA reconciliation of these views is suggested by William Atwood:\nReception and influence.\nJones comments that \"Chopin's unique position as a composer, despite the fact that virtually everything he wrote was for the piano, has rarely been questioned.\" He also notes that Chopin was fortunate to arrive in Paris in 1831\"the artistic environment, the publishers who were willing to print his music, the wealthy and aristocratic who paid what Chopin asked for their lessons\"and these factors, as well as his musical genius, also fuelled his contemporary and later reputation. While his illness and his love affairs conform to some of the stereotypes of romanticism, the rarity of his public recitals (as opposed to performances at fashionable Paris soir\u00e9es) led Arthur Hutchings to suggest that \"his lack of Byronic flamboyance [and] his aristocratic reclusiveness make him exceptional\" among his romantic contemporaries such as Liszt and Henri Herz.\nChopin's qualities as a pianist and composer were recognised by many of his fellow musicians. Schumann named a piece for him in his suite \"Carnaval\", and Chopin later dedicated his Ballade No. 2 in F major to Schumann. Elements of Chopin's music can be found in many of Liszt's later works. Liszt later transcribed for piano six of Chopin's Polish songs. A less fraught friendship was with Alkan, with whom he discussed elements of folk music, and who was deeply affected by Chopin's death.\nIn Paris, Chopin had a number of pupils, including Friedericke M\u00fcller, who left memoirs of his teaching and the prodigy Carl Filtsch, to whom both Chopin and Sand became dedicated, Chopin giving him three lessons a week; Filtsch was the only pupil to whom Chopin gave lessons in composition, and, exceptionally, he on several occasions shared a concert platform with him. Two of Chopin's long-standing pupils, Karol Mikuli and Georges Mathias, were themselves piano teachers and passed on details of his playing to their students, some of whom (such as Raoul Koczalski) were to make recordings of his music. Other pianists and composers influenced by Chopin's style include Louis Moreau Gottschalk, \u00c9douard Wolff, and Pierre Zimmermann. Debussy dedicated his own 1915 piano \u00c9tudes to the memory of Chopin; he frequently played Chopin's music during his studies at the Paris Conservatoire, and undertook the editing of Chopin's piano music for the publisher Jacques Durand.\nPolish composers of the following generation included virtuosi such as Moritz Moszkowski; but, in the opinion of J. Barrie Jones, his \"one worthy successor\" among his compatriots was Karol Szymanowski. Edvard Grieg, Anton\u00edn Dvo\u0159\u00e1k, Isaac Alb\u00e9niz, Pyotr Ilyich Tchaikovsky, and Sergei Rachmaninoff, among others, are regarded by critics as having been influenced by Chopin's use of national modes and idioms. Alexander Scriabin was devoted to the music of Chopin, and his early published works include nineteen mazurkas as well as numerous \u00e9tudes and preludes; his teacher Nikolai Zverev drilled him in Chopin's works to improve his virtuosity as a performer. In the 20th century, composers who paid homage to (or in some cases parodied) the music of Chopin included George Crumb, Leopold Godowsky, Bohuslav Martin\u016f, Darius Milhaud, Igor Stravinsky, and Heitor Villa-Lobos.\nChopin's music was used in the 1909 ballet \"Chopiniana\", choreographed by Michel Fokine and orchestrated by Alexander Glazunov. Sergei Diaghilev commissioned additional orchestrationsfrom Stravinsky, Anatoly Lyadov, Sergei Taneyev, and Nikolai Tcherepninfor later productions, which used the title . Other noted composers have created orchestrations for the ballet, including Benjamin Britten, Roy Douglas, Alexander Gretchaninov, Gordon Jacob, and Maurice Ravel, whose score is lost.\nMusicologist Erinn Knyt writes: \"In the nineteenth century Chopin and his music were commonly viewed as effeminate, androgynous, childish, sickly, and 'ethnically other. Music historian Jeffrey Kallberg says that in Chopin's time, \"listeners to the genre of the piano nocturne often couched their reactions in feminine imagery\", and he cites many examples of such reactions to Chopin's nocturnes. One reason for this may be \"demographic\"there were more female than male piano players, and playing such \"romantic\" pieces was seen by male critics as a female domestic pastime. Such genderization was not commonly applied to other genres among Chopin's works, such as the scherzo or the polonaise. The cultural historian Edward Said has cited the demonstrations by pianist and writer Charles Rosen, in the latter's book \"The Romantic Generation\", of Chopin's skills in \"planning, polyphony, and sheer harmonic creativity\", as effectively overthrowing any legend of Chopin \"as a swooning, 'inspired', small-scale salon composer\".\nChopin's music remains very popular and is regularly performed, recorded and broadcast worldwide. The world's oldest monographic music competition, the International Chopin Piano Competition, founded in 1927, is held every five years in Warsaw. The Fryderyk Chopin Institute lists over eighty societies worldwide devoted to the composer and his music. The Institute site also lists over 1500 performances of Chopin works on YouTube .\nRecordings.\nThe British Library notes that \"Chopin's works have been recorded by all the great pianists of the recording era.\" The earliest recording was an 1895 performance by Paul Pabst of the Nocturne in E major, Op. 62, No. 2. The British Library site makes available a number of historic recordings, including some by Alfred Cortot, Ignaz Friedman, Vladimir Horowitz, Benno Moiseiwitsch, Ignacy Jan Paderewski, Arthur Rubinstein, Xaver Scharwenka, Josef Hofmann, Vladimir de Pachmann, Moriz Rosenthal and many others. A select discography of recordings of Chopin works by pianists representing the various pedagogic traditions stemming from Chopin is given by James Methuen-Campbell in his work tracing the lineage and character of those traditions.\nNumerous recordings of Chopin's works are available. On the occasion of the composer's bicentenary, the critics of \"The New York Times\" recommended performances by the following contemporary pianists (among many others): Martha Argerich, Vladimir Ashkenazy, Emanuel Ax, Evgeny Kissin, Ivan Moravec, Murray Perahia, Maria Jo\u00e3o Pires, Maurizio Pollini, Alexandre Tharaud, Yundi, and Krystian Zimerman. The Warsaw Chopin Society organises the \"Grand prix du disque de F. Chopin\" for notable Chopin recordings, held every five years.\nIn literature, stage, film and television.\nChopin has figured extensively in Polish literature, both in serious critical studies and in fictional treatments. The earliest manifestation was probably an 1830 sonnet on Chopin by Leon Ulrich. French writers on Chopin (apart from Sand) have included Marcel Proust and Andr\u00e9 Gide, and he has also featured in works of Gottfried Benn and Boris Pasternak. There are numerous biographies of Chopin in English (see bibliography for some of these).\nPossibly the first venture into fictional treatments of Chopin's life was a fanciful operatic version of some of its events: \"Chopin\" (1901). The musicbased on Chopin's ownwas assembled by Giacomo Orefice, with a libretto by .\nChopin's life has been fictionalised in numerous films. As early as 1919, Chopin's relationships with three womenhis youth sweetheart Mariolka, then Polish singer Sonja Radkowska, and later George Sandwere portrayed in the German silent film \"Nocturno der Liebe\" (1919). The 1945 biographical film \"A Song to Remember\" earned Cornel Wilde an Academy Award nomination as Best Actor for his portrayal of the composer. Other film treatments have included (1928) by Henry Roussel, with Pierre Blanchar as Chopin; \"Impromptu\" (1991), starring Hugh Grant as Chopin; (1991); and \"\" (2002).\nChopin's life was covered in a 1999 BBC \"Omnibus\" documentary by Andr\u00e1s Schiff and Mischa Scorer, in a 2010 documentary realised by Angelo Bozzolini and Roberto Prosseda for Italian television, and in a BBC Four documentary \"ChopinThe Women Behind The Music\" (2010).\nExternal links.\nMusic scores"}
{"id": "10825", "revid": "1272922898", "url": "https://en.wikipedia.org/wiki?curid=10825", "title": "Free Democratic Party (Germany)", "text": "The Free Democratic Party (, FDP, ) is a liberal political party in Germany.\nThe FDP was founded in 1948 by members of former liberal political parties which existed in Germany before World War II, namely the German Democratic Party and the German People's Party. For most of the second half of the 20th century, particularly from 1961 to 1982, the FDP held the balance of power in the Bundestag. It has been a junior coalition partner to both the CDU/CSU (1949\u20131956, 1961\u20131966, 1982\u20131998 and 2009\u20132013) and Social Democratic Party (SPD) (1969\u20131982, 2021\u20132024). In the 2013 federal election, the FDP failed to win any directly elected seats in the Bundestag and came up short of the 5 percent threshold to qualify for list representation, being left without representation in the Bundestag for the first time in its history. In the 2017 federal election, the FDP regained its representation in the Bundestag, receiving 10.6% of the vote. From the 2021 federal election to the 2024 German government crisis, the FDP was part of governing Scholz cabinet in a \"traffic light coalition\" with the Social Democratic Party and the Greens.\nApart from a brief progressive and social liberal period in the 1970s (\"Freiburger Thesen\"), the FDP has traditionally been located in the centre-right of the political spectrum. Since the 1980s, the party, consistently with its ordoliberal tradition, has pushed economic liberalism and has aligned itself closely to the promotion of free markets and privatization. The FDP is a member of the Liberal International, the Alliance of Liberals and Democrats for Europe and Renew Europe.\nHistory.\nPredecessors.\nThe history of liberal parties in Germany dates back to 1861, when the German Progress Party (DFP) was founded, being the first political party in the modern sense in Germany. From the establishment of the National Liberal Party in 1867 until the demise of the Weimar Republic in 1933, the liberal-democratic camp was divided into a \"national-liberal\" and a \"left-liberal\" line of tradition. After 1918 the national-liberal strain was represented by the German People's Party (DVP), the left-liberal one by the German Democratic Party (DDP, which merged into the German State Party in 1930). Both parties played an important role in government during the Weimar Republic era, but successively lost votes during the rise of the Nazi Party beginning in the late-1920s. After the Nazi seizure of power, both liberal parties agreed to the Enabling Act of 1933 and subsequently dissolved themselves. During the 12 years of Hitler's rule, some former liberals collaborated with the Nazis (e.g. economy minister Hjalmar Schacht), while others resisted actively against Nazism, with some Liberal leaning members and former members of the military joining up with Henning von Tresckow (e.g. the Solf Circle).\nSoon after World War II, the Soviet Union pushed for the creation of licensed \"anti-fascist\" parties in its occupation zone in East Germany. In July 1945, former DDP politicians Wilhelm K\u00fclz, Eugen Schiffer and Waldemar Koch called for the establishment of a pan-German liberal party. Their Liberal-Democratic Party (LDP) was soon licensed by the Soviet Military Administration in Germany, under the condition that the new party joined the pro-Soviet \"Democratic Bloc\".\nIn September 1945, citizens in Hamburg\u2014including the anti-Nazi resistance circle \"Association Free Hamburg\"\u2014established the \"Party of Free Democrats\" (PFD) as a bourgeois left-wing party and the first liberal Party in the Western occupation zones. The German Democratic Party was revived in some states of the Western occupation zones (in the Southwestern states of W\u00fcrttemberg-Baden and W\u00fcrttemberg-Hohenzollern under the name of Democratic People's Party).\nMany former members of DDP and DVP however agreed to finally overcome the traditional split of German liberalism into a national-liberal and a left-liberal branch, aiming for the creation of a united liberal party. In October 1945 a liberal coalition party was founded in the state of Bremen under the name of Bremen Democratic People's Party. In January 1946, liberal state parties of the British occupation zone merged into the \"Free Democratic Party of the British Zone\" (FDP). A similar state party in Hesse, called the Liberal Democratic Party, was licensed by the U.S. military government in January 1946. In the state of Bavaria, a \"Free Democratic Party\" was founded in May 1946.\nIn the first post-war state elections in 1946, liberal parties performed well in W\u00fcrttemberg-Baden (16.8%), Bremen (18.3%), Hamburg (18.2%) and Greater Berlin (still undivided; 9.3%). The LDP was especially strong in the October 1946 state elections of the Soviet zone\u2014the last free parliamentary election in East Germany\u2014obtaining an average of 24.6% (highest in Saxony-Anhalt, 29.9%, and Thuringia, 28.5%), thwarting an absolute majority of the Socialist Unity Party of Germany (SED) that was favoured by the Soviet occupation power. This disappointment to the communists however led to a change of electoral laws in the Soviet zone, cutting the autonomy of non-socialist parties including the LDP and forcing it to join the SED-dominated National Front, making it a dependent \"bloc party\".\nThe Democratic Party of Germany (DPD) was established in Rothenburg ob der Tauber on 17 March 1947 as a pan-German party of liberals from all four occupation zones. Its leaders were Theodor Heuss (representing the DVP of W\u00fcrttemberg-Baden in the American zone) and Wilhelm K\u00fclz (representing the LDP of the Soviet zone). However, the project failed in January 1948 as a result of disputes over K\u00fclz's pro-Soviet direction.\nFounding of the party.\nThe Free Democratic Party was established on 11\u201312 December 1948 in Heppenheim, in Hesse, as an association of all 13 liberal state parties in the three Western zones of occupation. As such, the party included former members of the pre-1933 German People's Party (DVP) which represented the more conservative and national tradition of German liberalism and members from the social liberal German Democratic Party (DDP). The proposed name, Liberal Democratic Party, was rejected by the delegates, who voted 64 to 25 in favour of the name Free Democratic Party (FDP).\nThe party's first chairman was Theodor Heuss, a member of the Democratic People's Party in W\u00fcrttemberg-Baden; his deputy was Franz Bl\u00fccher of the FDP in the British Zone. The place for the party's foundation was chosen deliberately: the \"Heppenheim Assembly\" was held at the Hotel \"Halber Mond\" on 10 October 1847, a meeting of moderate liberals who were preparing for what would be, within a few months, the German revolutions of 1848\u20131849.\n1949\u20131969: reconstruction of Germany.\nIn the first elections to the Bundestag on 14 August 1949, the FDP won a vote share of 11.9 percent (with 12 direct mandates, particularly in Baden-W\u00fcrttemberg and Hesse), and thus obtained 52 of 402 seats. In September of the same year the FDP chairman Theodor Heuss was elected the first President of the Federal Republic of Germany. In his 1954 re-election, he received the best election result to date of a President with 871 of 1018 votes (85.6 percent) of the Federal Assembly. Adenauer was also elected on the proposal of the new German President with an extremely narrow majority as the first Chancellor. The FDP participated with the CDU/CSU and the national-conservative German Party (DP) in Adenauer's coalition cabinet; they had three ministers: Franz Bl\u00fccher (Vice-Chancellor), Thomas Dehler (justice), and Eberhard Wildermuth (housing).\nOn the most important economic, social and German national issues, the FDP agreed with their coalition partners, the CDU/CSU. However, the FDP offered to middle-class voters a secular party that refused the religious schools and accused the opposition parties of clericalization. The FDP said they were known also as a consistent representative of the market economy, while the CDU was then dominated nominally from the Ahlen Programme, which allowed a Third Way between capitalism and socialism. Ludwig Erhard, the \"father\" of the social market economy, had his followers in the early years of the Federal Republic in the CDU/CSU rather than in the FDP. The FDP won Hesse's 1950 state election with 31.8 percent, the best result in its history, through appealing to East Germans displaced by the war by including them on their ticket.\nUp to the 1950s, several of the FDP's regional organizations were to the right of the CDU/CSU, particularly the Hesse, Lower Saxony and North Rhine-Westphalia branches where Friedrich Middelhauve tried to foster a \u201eNational Rally\" as a third bloc next to Social Democrats and Christian Democrats. This was criticized by the social liberals around Theodor Heuss who distanced himself from the \"Nazi FDP\" branches. Under the influence of the party's right wing, the Free Democrats campaigned against West Germany's denazification provisions and courted even former office-holders of the Third Reich with nationalist values. At their party conference in Munich in 1951 they demanded the release of all \"so-called war criminals\" and welcomed the establishment of the \"Association of German soldiers\" of former Wehrmacht and SS members to advance the integration of the Nazi forces in democracy. The FDP members were seen as part of the \"extremist\" block along with the German Party in West Germany by the US intelligence officials. The 1953 Naumann Circle, named after Werner Naumann, consisted of a group of former Nazis who tried to infiltrate the party. After the British occupation authorities had arrested seven prominent members of the Naumann Circle, the FDP federal board installed a commission of inquiry, chaired by Thomas Dehler, which particularly sharply criticized the situation in the North Rhine-Westphalian FDP. In the following years, the right wing lost power, and the extreme right increasingly sought areas of activity outside the FDP. In the 1953 federal election, the FDP received 9.5 percent of the party votes, 10.8 percent of the primary vote (with 14 direct mandates, particularly in Hamburg, Lower Saxony, Hesse, W\u00fcrttemberg and Bavaria) and 48 of 487 seats.\nIn the second term of the Bundestag, the South German Liberal Democrats gained influence in the party controlling the party leadership between 1954 and 1960. Thomas Dehler, a representative of a more social-liberal course from Bavaria took over as party and parliamentary leader. The former Minister of Justice Dehler, who in 1933 suffered persecution by the Nazis, was known for his populist rhetorics and tried to emancipate the party from Adenauer's CDU/CSU. In the mid-1950s, there were some disagreements between Dehler and Adenauer over foreign policy issues, particularly the founding of the European Defence Community and the Saar statute. The FDP took an emphatically nationalist stance on both issues. In 1956, the infights between Dehler and Adenauer culminated in a government crisis: The FDP in North Rhine-Westphalia terminated their alliance with the Christian Democrats and formed a new state government with the Social Democratic Party of Germany and the German Center Party which led to a party split. 16 members of parliament, including former party leader Franz Bl\u00fccher and the four federal ministers from the FDP left their party and founded the short-lived Free People's Party (FVP). Whilst the FVP continued the government coalition with Adenauer's CDU/CSU and merged with the right-wing German Party (DP) in 1957, the FDP took it to the opposition for the first time in its history.\nOnly one of the smaller post-war parties, the FDP survived despite many problems. In the 1957 federal elections they still reached 7.7 percent of the vote and held 41 of 497 seats in the Bundestag. However, they still remained in opposition because the Union won an absolute majority. At the federal party meeting in Berlin at the end of January 1957, Thomas Dehler was replaced as party chairman by another liberal democrat from South Germany, Reinhold Maier, who was able to stabilize his party before he made way for Erich Mende from North Rhine-Westphalia in 1960. With Mende as party leader the FDP went into the 1961 federal election with the promise of ending Konrad Adenauer's leadership and gained 12.8 percent nationwide, the best result until then. After the election, however, the FDP again formed a coalition with Adenauer's CDU on the condition that he would retire as chancellor after two years. These events led to the FDP being nicknamed the (\"pushover party\"). In the 1962 Spiegel affair, the FDP temporarily withdrew their ministers from the federal government forcing Defence Minister Franz-Josef Strau\u00df to resign. In accordance with his agreement with the FDP, Adenauer resigned from his chancellorship in October 1963, making place for Ludwig Erhard who appointed FDP leader Erich Mende as Vice Chancellor and Minister of All-German Affairs. \nIn the 1965 federal elections the FDP gained 9.5 percent. The Free Democrats initially renewed their alliance with the CDU under Erhard but the coalition broke up in 1966 on the issue of tax increases. During the 1966-1969 Grand coalition the party led the opposition. Under their new chairman, Walter Scheel, there were signs of a change both in foreign policy and in party strategy: For the first time, the FDP opened up to a coalition with the SPD on a federal level, embracing foreign minister Willy Brandt's Ostpolitik. \n1969\u20131982: social changes and crises.\nThe 1969 West German federal election led to the first social-liberal coalition between Social Democrats and Free Democrats in German post-war history. Even though the Christian Democrats won the election, the Free Democrats rejected a new centre-right alliance and opted for a centre-left coalition under the new Chancellor Willy Brandt. With FDP leader Walter Scheel as Vice Chancellor and Foreign Minister, the liberals initiated a new controversial Ostpolitik effectively normalizing relations between capitalist-democratic West Germany and communist-led East Germany. Within the FDP, this policy was quite controversial, especially after the \"de facto\" recognition of the Oder-Neisse line by the 1970 Treaty of Warsaw.\nIn July 1970, right-wing members founded a \"non-partisan\" organization called the National-Liberal Action with the goal of breaking up the SPD/FDP coalition government. A little later, members of parliament Siegfried Zoglmann, Heinz Starke and former party leader Erich Mende left the party with Starke and Mende joining the CDU and Zoglmann founding a new splinter party called German Union \"(Deutsche Union)\". This led to the 1972 snap elections from which the SPD/FDP government emerged even stronger. In 1974, party leader Walter Scheel was the second Liberal to be elected Federal President after Theodor Heuss. He was succeeded by Interior Minister Hans-Dietrich Genscher as the new FDP leader and Foreign Minister who continued the centre-left coalition under new SPD Chancellor Helmut Schmidt. \nThe party's centre-left strategy was supported by a new party manifesto, the 1971 Freiburg Theses (\"Freiburger Thesen\") which set the party on a progressive and social liberal course. Among other things, the party committed itself to \"self-determination\", \"democratization of society\", a \"reform of capitalism\" and a form of ecoliberalism which prioritized \"environmental protection over profit and personal gains\". However, in 1977, the progressive liberal Freiburg Theses were supplemented and partially revised by the more economically liberal Kiel Theses (\"Kieler Thesen\"), effectively setting the party back on a classical liberal course. \nEven prior to the 1980 West German federal election, cooperation between Social Democrats and Free Democrats seemed to come to an end but the candidacy of CSU chairman Franz Josef Strauss for chancellor led both parties to once again renew their coalition government. \n1982\u20131998: Kohl government, economic transition and reunification.\nIn the fall of 1982, the FDP reneged on its coalition agreement with the SPD and instead threw its support behind the CDU/CSU. On 1 October, the FDP and CDU/CSU were able to oust Schmidt and replace him with CDU party chairman Helmut Kohl as the new Chancellor. The coalition change resulted in severe internal conflicts, and the FDP then lost about 20 percent of its 86,500 members, as reflected in the general election in 1983 by a drop from 10.6 percent to 7.0 percent. The members went mostly to the SPD, the Greens and newly formed splinter parties, such as the left-liberal party Liberal Democrats (LD). The exiting members included the former FDP General Secretary and later EU Commissioner G\u00fcnter Verheugen. \nAt the party convention in November 1982, the Schleswig-Holstein state chairman Uwe Ronneburger challenged Hans-Dietrich Genscher as party chairman. Ronneburger received 186 of the votes\u2014about 40 percent\u2014and was just narrowly defeated by Genscher who went on to act as party chairman as well as Vice Chancellor and Foreign Minister in the new Kohl government. In the following federal election campaigns during the 1980s and 1990s, the party sided with the CDU and CSU, the main conservative parties in Germany. \nin 1980, FDP members who did not agree with the politics of the left-leaning FDP youth organization Young Democrats founded the Young Liberals (JuLis). For a time JuLis and the Young Democrats operated side by side, until the JuLis became the sole official youth wing of the FDP in 1983. The Young Democrats split from the FDP and were left as a party-independent youth organization ultimately merging with a marxist youth group to form the \"Young Democrats/Young Left\" in 1992.\nDuring the \"Peaceful Revolution\" of 1989 in the GDR, a couple of new liberal parties emerged from the opposition, like the Free Democratic Party (East Germany) or the German Forum Party. Prior to the March 1990 Volkskammer elections they joined the established Liberal Democratic Party, who had previously acted as a pro-communist bloc party on the side of the SED, to form the Alliance of Free Democrats (BFD). In the Volkskammer election of March 1990 the Association of Free Democrats was heavily supported by the West German FDP and polled 5.28% of the votes. Most of the seats went to Liberal Democratic Party members, whose leader Rainer Ortleb became their parliamentary leader. It then participated in the last GDR government led by Lothar de Maizi\u00e8re. After the Liberal Democratic Party and another former bloc party, the National Democratic Party of Germany, merged into the new party \"Association of Free Democrats\" in late March, the several liberal parties all united with the West German FDP in August 1990 to form the first all-German party. The merger brought the Free Democrats a great, albeit short-lived, increase in membership and assets of DM 6.3 million in cash and property.\nAt the time of reunification, the FDP's objective was a special economic zone in the former East Germany, but the party could not prevail against the CDU/CSU. In the first all-German Bundestag elections, the centre-right Kohl coalition was confirmed, the FDP received 11.0 percent of the valid votes (79 seats) and won in Genscher's city of birth Halle (Saale) the first direct mandate since 1957. During the 1990s, the FDP won between 6.2 and 11 percent of the vote in Bundestag elections. \nIn the second half of the 1990s, however, the FDP had to contend with a series of electoral defeats at local and state level, which led to it falling out of twelve of the 16 state parliaments and the European Parliament between 1993 and 1995. The party was derisively referred to as the \u2018lady without an abdomen\u2019. At the same time, the party was shaken by new infights between the left and right wings. In 1996, Federal Minister of Justice Sabine Leutheusser-Schnarrenberger, a prominent representative of the party's social liberal wing, resigned in protest to the government's policy of expanding the state's right to interfere in citizens' private domain by means of acoustic observation \"(Gro\u00dfer Lauschangriff\", literally \"big eavesdropping attack\"). On the other hand, former Public Prosecutor General Alexander von Stahl tried to rebuild the party's national liberal wing in an ultimately failed attempt to bring the FDP onto a right-wing course modelled on J\u00f6rg Haider's FP\u00d6 in Austria.\nThese infights contributed to the CDU/CSU-FDP defeat in the 1998 German federal election which ended the 16-year centre-right coalition in Germany and the FDP's nearly three decade reign in government. For the first time since 1969 (apart from a brief period in 1982), the Free Democrats now found themselves in opposition and out of power on a federal level. \n2002 and 2005 federal elections.\nFollowing their electoral defeat, the party developed a strategy of equidistance to the CDU and SPD championed by North Rhine-Westfalia state party leader J\u00fcrgen M\u00f6llemann who led the party to a good result in the 2000 state elections. At their 2001 party conference in D\u00fcsseldorf, outgoing party leader Wolfgang Gerhardt was replaced by a 39 year old Guido Westerwelle who became the youngest FDP leader in history. The party conference also adopted a strategy developed by M\u00f6llemann which became known as \u2018Project 18\u2019. It aimed at winning new groups of voters through new forms of communication and presentation and at profiling the party as an independent force autonomous from SPD and CDU. The name referred to the electoral goal of tripling the party's share of the vote from 6% to 18%. While Westerwelle and M\u00f6llemann generated a lot of media attention, the party was once again embroiled in controversy on Westerwelle's perceived lack of seriousness in his election campaign (\"Spa\u00dfwahlkampf\") and on M\u00f6llemann's alleged right-wing populism. Many critics interpreted the use of the number 18 as a hidden right-wing extremist symbol (a code for the letters A and H, meaning Adolf Hitler) and an attempt to attract voters on the far right. In addition, M\u00f6llemann launched a leaflet campaign with harsh criticism of the Israeli government under Ariel Sharon and the German-Jewish journalist Michel Friedman, which critics interpreted as anti-Semitism. Amid controversy over a possible right-wing populist orientation associated with this, the FDP ultimately achieved 7.4% instead of the targeted 18 per cent in the 2002 German federal election.\nIn the 2005 general election the party won 9.8 percent of the vote and 61 federal deputies, an unpredicted improvement from prior opinion polls. It is believed that this was partly due to tactical voting by CDU and Christian Social Union of Bavaria (CSU) alliance supporters who hoped for stronger market-oriented economic reforms than the CDU/CSU alliance called for. However, because the CDU did worse than predicted, the FDP and the CDU/CSU alliance were unable to form a coalition government. At other times, for example after the 2002 federal election, a coalition between the FDP and CDU/CSU was impossible primarily because of the weak results of the FDP.\nThe CDU/CSU parties had achieved the third-worst performance in German postwar history with only 35.2 percent of the votes. Therefore, the FDP was unable to form a coalition with its preferred partners, the CDU/CSU parties. As a result, the party was considered as a potential member of two other political coalitions, following the election. One possibility was a partnership between the FDP, the Social Democratic Party of Germany (SPD) and the Alliance 90/The Greens, known as a \"traffic light coalition\", named after the colors of the three parties. This coalition was ruled out, because the FDP considered the Social Democrats and the Greens insufficiently committed to market-oriented economic reform. The other possibility was a CDU-FDP-Green coalition, known as a \"Jamaica coalition\" because of the colours of the three parties. This coalition wasn't concluded either, since the Greens ruled out participation in any coalition with the CDU/CSU. Instead, the CDU formed a Grand coalition with the SPD, and the FDP entered the opposition. FDP leader Guido Westerwelle became the unofficial leader of the opposition by virtue of the FDP's position as the largest opposition party in the Bundestag.\nIn the 2009 European election, the FDP received 11% of the national vote (2,888,084 votes in total) and returned 12 MEPs.\n2009\u20132013: Merkel II government.\nIn the September 2009 federal elections, the FDP increased its share of the vote by 4.8 percentage points to 14.6%, an all-time record. This percentage was enough to offset a decline in the CDU/CSU's vote compared to 2005, to create a CDU-FDP centre-right governing coalition in the Bundestag with a 53% majority of seats. On election night, party leader Westerwelle said his party would work to ensure that civil liberties were respected and that Germany got an \"equitable tax system and better education opportunities\".\nThe party also made gains in the two state elections held at the same time, acquiring sufficient seats for a CDU-FDP coalition in the northernmost state, Schleswig-Holstein, and gaining enough votes in left-leaning Brandenburg to clear the 5% hurdle to enter that state's parliament.\nHowever, after reaching its best ever election result in 2009, the FDP's support collapsed. The party's policy pledges were put on hold by Merkel as the Great Recession unfolded and with the onset of the European debt crisis in 2010. By the end of 2010, the party's support had dropped to as low as 5%. The FDP retained their seats in the state elections in North Rhine-Westphalia, which was held six months after the federal election, but out of the seven state elections that have been held since 2009, the FDP have lost all their seats in five of them due to failing to cross the 5% threshold.\nSupport for the party further eroded amid infighting and an internal rebellion over euro-area bailouts during the debt crisis.\nWesterwelle stepped down as party leader following the 2011 state elections, in which the party was wiped out in Saxony-Anhalt and Rhineland-Palatinate and lost half its seats in Baden-W\u00fcrttemberg. Westerwelle was replaced in May 2011 by Philipp R\u00f6sler. The change in leadership failed to revive the FDP's fortunes, however, and in the next series of state elections, the party lost all its seats in Bremen, Mecklenburg-Vorpommern, and Berlin. In Berlin, the party lost nearly 75% of the support they had had in the previous election.\nIn March 2012, the FDP lost all their state-level representation in the 2012 Saarland state election. However, this was offset by the Schleswig-Holstein state elections, when they achieved 8% of the vote, which was a severe loss of seats but still over the 5% threshold. In the snap elections in North Rhine-Westphalia a week later, the FDP not only crossed the electoral threshold, but also increased its share of the votes to 2 percentage points higher than in the previous state election. This was attributed to the local leadership of Christian Lindner.\n2013 federal election.\nThe FDP last won a directly elected seat in 1990, in Halle\u2014the only time it has won a directly elected seat since 1957. The party's inability to win directly elected seats came back to haunt it at the 2013 election, in which it came up just short of the 5% threshold. With no directly elected seats, the FDP was shut out of the Bundestag for the first time since 1949. After the previous chairman Philipp R\u00f6sler then resigned, Christian Lindner took over the leadership of the party.\n2014 European and state elections.\nIn the 2014 European parliament elections, the FDP received 3.4% of the national vote (986,253 votes in total) and returned 3 MEPs. In the 2014 Brandenburg state election the party experienced a 5.8% down-swing and lost all their representatives in the Brandenburg state parliament. In the 2014 Saxony state election, the party experienced a 5.2% down-swing, again losing all of its seats. In the 2014 Thuringian state election a similar phenomenon was repeated with the party falling below the 5% threshold following a 5.1% drop in popular vote.\n2015\u20132020.\nThe party managed to enter parliament in the 2015 Bremen state election with the party receiving 6.5% of the vote and gaining 6 seats. However, it failed to get into government as a coalition between the Social Democrats and the Greens was created. In the 2016 Mecklenburg-Vorpommern state election the party failed to get into parliament despite increasing its vote share by 0.3%. The party did manage to get into parliament in Baden-W\u00fcrttemberg, gaining 3% of the vote and a total of 12 seats. This represents a five-seat improvement over their previous results. In the 2016 Berlin state election the party gained 4.9% of the vote and 12 seats but still failed to get into government. A red-red-green coalition was instead formed relegating the FDP to the opposition. In the 2016 Rhineland-Palatinate state election, the party managed to enter parliament receiving 6.2% of the vote and 7 seats. It also managed to enter government under a traffic light coalition. In 2016 Saxony-Anhalt state election the party narrowly missed the 5% threshold, receiving 4.9% of the vote and therefore receiving zero seats despite a 1% swing in their favour.\nThe 2017 North Rhine-Westphalia state election was widely considered a test of the party's future as their chairman Christian Lindner was also leading the party in that state. The party experienced a 4% swing in its favour gaining 6 seats and entering into a coalition with the CDU with a bare majority. In the 2017 Saarland state election the party again failed to gain any seats despite a 1% swing in their favour. The party gained 3 seats and increased its vote share by 3.2% in the 2017 Schleswig-Holstein state election. This success was often credited to their state chairman Wolfgang Kubicki. They also managed to re-enter the government under a Jamaica coalition.\nIn the 2017 federal election the party scored 10.7% of votes and re-entered the Bundestag, winning 80 seats. After the election, a Jamaica coalition was considered between the CDU, Greens, and FDP. However, FDP chief Christian Lindner walked out of the coalition talks due to a disagreement over European migration policy, saying \"It is better not to govern than to govern badly.\" As a result, the CDU/CSU formed another grand coalition with the SPD.\nThe FDP won 5.4% and 5 seats in the 2019 European election.\nIn the October 2019 Thuringian state election, the FDP won seats in the Landtag of Thuringia for the first time since 2009. It exceeded the 5% threshold by just 5 votes. In February 2020, the FDP's Thomas Kemmerich was elected Minister-President of Thuringia by the Landtag with the likely support of the CDU and AfD, becoming the second member of the FDP to serve as head of government in a German state. This was also the first time a head of government had been elected with the support of AfD. Under intense pressure from state and federal politicians, Kemmerich resigned the following day, stating he would seek new elections. The next month, he was replaced by Bodo Ramelow of The Left; the FDP did not run a candidate in the second vote for Minister-President.\n2021\u2013present.\nIn 2021, the FDP returned to the Saxony-Anhalt state parliament after five years of absence. They had similar success in Baden-W\u00fcrttemberg and Mecklenburg-Vorpommern, but faced setbacks in Baden-W\u00fcrttemberg, Berlin and Rhineland-Palatinate.\nIn the September 2021 federal election, the CDU/CSU under Armin Laschet was defeated. The FDP saw both its vote share and number of seats grow, to 11.5% and 92 seats respectively. As a result, the SPD, Greens, and FDP entered talks to form an \"Ampelkoalition\" (traffic light coalition). In the agreement finalised on 24 November, the FDP held four federal ministries in the Scholz cabinet (Finance, Justice, Digital and Transport and Education and Research).\nThroughout 2022, the FDP saw poor approval in national opinion polls. In State Parliament elections they also performed poorly. In March, the FDP didn't win any seats in Saarland. In May they lost over half their seats in North Rhine-Westphalia and Schleswig-Holstein. In October, the FDP lost all 11 of their seats in Lower Saxony. It also lost all 12 seats in the 2023 Berlin repeat state election. \nIn the 2023 Bavarian state election, where Martin Hagen led the party, all 11 seats were lost. In the 2024 European Parliament elections, the FDP narrowly surpassed the 5% threshold, remaining on 5 seats and coming in sixth, behind the newly formed BSW. The FDP were similarly wiped out in the 2024 Thuringian state election, where Thomas Kemmerich lost his party's 5 seats. In the 2024 Saxony state election, the FDP achieved less than 1% of the vote.\nIn November 2024, Christian Lindner was fired as Minister of Finance. The FDP leaving the coalition meant the collapse of the traffic light government. Marco Buschmann and Bettina Stark-Watzinger also resigned from the cabinet. Justice minister Volker Wissing decided to resign from the FDP in order to stay in cabinet.\nIdeology and platform.\nThe FDP's political position has variously been described as centrist, centre-right, and right-wing. The FDP has been described as liberal, conservative-liberal, classical-liberal, and liberal-conservative. Other sources have described the party as fiscally conservative, libertarian or right-libertarian.\nThe FDP is a predominantly classical-liberal inspired party, both in the sense of supporting free market economic policies and in the sense of policies emphasizing the minimization of government interference in individual affairs. During election campaigning, the party has emphasised support for tax cuts, reductions in government spending and balanced budgets. The party has also been described by various media sources as neoliberal. Scholars of political science have historically identified the FDP as closer to the CDU/CSU bloc than to the Social Democratic Party of Germany (SPD) on economic issues but closer to the SPD and the Greens on issues such as civil liberties, education, defense, and foreign policy. The FDP has oriented itself towards a centrist position between the CDU and the SPD, however it is to the right of the CDU in its socioeconomics perspective, environmental and labour policies.\nThe party is a traditional supporter of ordoliberalism, having been influenced by the economic theories of Wilhelm R\u00f6pke and Alexander R\u00fcstow. Otto Graf Lambsdorff, who served as Federal Minister of Economics, is a historical FDP grandee who was a proponent of ordoliberalism. In 1971 during its federal social-liberal coalition with the SPD, the FDP published the Freiburger Thesis programme, heralding an ideological move towards reformism and social liberalism, and support for environmental protection. However, the party's 1977 Kiel Theses and 1985 Liberal Manifesto returned the FDP towards its traditional free-market, ordoliberal approach. Historical members of the party's social-liberal wing included Gerhart Baum and Werner Maihofer, a faction who remained organised as the Freiberg Circle. Alternatively to the liberal-orientated wings of the party are a conservative or national-conservative wing, influenced by the populist and nationalist developments of the Freedom Party of Austria and the New Right. The FDP's national-conservative wing has included individuals such as Rainer Zitelmann, Klaus Rainer R\u00f6hl, Alexander von Stahl, and J\u00fcrgen M\u00f6llemann, and was organised as the Liberal Offensive. M\u00f6llemann in the particular was noted for his role during the 2002 federal election in attempting to push the party in a right-wing populist direction, albeit to poor electoral results. \nDuring the 2017 federal election, the party called for Germany to adopt an immigration channel using a Canada-style points-based immigration system; spend up to 3% of GDP on defense and international security; phase out the solidarity surcharge tax (which was first levied in 1991 to pay for the costs of absorbing East Germany after German reunification); cut taxes by 30 billion euro (twice the amount of the tax cut proposed by the CDU); and improve road infrastructure by spending 2 billion euro annually for each of the next two decades, to be funded by selling government stakes in Deutsche Bahn, Deutsche Telekom, and Deutsche Post. The FDP also called for the improvement of Germany's digital infrastructure, the establishment of a Ministry of Digital Affairs, and greater investment in education. The party also supports allowing dual citizenship (in contrast to the CDU/CSU, which opposes it) but also supports requiring third-generation immigrants to select a single nationality.\nThe FDP supports the legalization of cannabis in Germany and opposes proposals to heighten Internet surveillance. The FDP supports same-sex marriage in Germany. The FDP supports legalisation of altruistic surrogacy.\nThe FDP has mixed views on European integration. In its 2009 campaign manifesto, the FDP pledged support for ratification of the Lisbon Treaty as well as EU reforms aimed at enhancing transparency and democratic responsiveness, reducing bureaucracy, establishing stringent curbs on the EU budget, and fully liberalizing the Single Market. At its January 2019 congress ahead of the 2019 European Parliament election, FDP's manifesto called for further EU reforms, including reducing the number of European Commissioners to 18 from the current 28, abolishing the European Economic and Social Committee, and ending the European Parliament's \"traveling circus\" between Brussels and Strasbourg. Vice chairwoman and Deputy Leader Nicola Beer stated: \"We want both more and less Europe.\"\nElectorate.\nIn 1940s and 1950s, the FDP was the only German party strongly in favour of market economy, while the CDU/CSU was still adhering to a \"third way\" between capitalism and socialism. Initially founded as a party uniting liberals and nationalists, the early FDP wanted former Nazis to be reintegrated into society and demanded a release of Nazi war criminals.\nThe party's membership has historically been largely male; in 1995, less than one-third of the party's members were women, and in the 1980s women made up less than one-tenth of the party's national executive committee. By the 1990s, the percentage of women on the FDP's national executive committee rose to 20%.\nThe party tends to draw its support from professionals and self-employed Germans. It lacks consistent support from a voting bloc, such as the trade union membership that supports the SPD or the church membership that supports the CDU/CSU, and thus has historically only garnered a small group of \"Stammw\u00e4hler\" (core voters) who consistently vote for the party.\nIn the 2021 elections, the FDP was the second-most popular party among voters under age 30; among this demographic, the Greens won 22% of the vote, the FDP 19%, the SPD 17%, the CDU/CSU 11%, Die Linke 8%, and the AfD 8%. According to Deutsche Welle in 2021, voters for both the FDP and the Greens are similar in being younger, politically centrist professionals living in cities, unlike left working-class voters and right Christian voters.\nEuropean representation.\nIn the European Parliament the Free Democratic Party sits in the Renew Europe group with five MEPs.\nIn the European Committee of the Regions, the Free Democratic Party sits in the Renew Europe CoR group, with one full member for the 2020\u20132025 mandate.\nElection results.\nFederal parliament (\"Bundestag\").\nBelow are charts of the results that the FDP has secured in each election to the federal Bundestag. Timelines showing the number of seats and percentage of party list votes won are on the right."}
{"id": "10826", "revid": "1271542996", "url": "https://en.wikipedia.org/wiki?curid=10826", "title": "Fax", "text": "Fax (short for facsimile), sometimes called telecopying or telefax (short for telefacsimile), is the telephonic transmission of scanned printed material (both text and images), normally to a telephone number connected to a printer or other output device. The original document is scanned with a fax machine (or a telecopier), which processes the contents (text or images) as a single fixed graphic image, converting it into a bitmap, and then transmitting it through the telephone system in the form of audio-frequency tones. The receiving fax machine interprets the tones and reconstructs the image, printing a paper copy. Early systems used direct conversions of image darkness to audio tone in a continuous or analog manner. Since the 1980s, most machines transmit an audio-encoded digital representation of the page, using data compression to transmit areas that are all-white or all-black, more quickly. \nInitially a niche product, fax machines became ubiquitous in offices in the 1980s and 1990s. However, they have largely been rendered obsolete by Internet-based technologies such as email and the World Wide Web, but are still used in some medical administration and law enforcement settings.\nHistory.\nWire transmission.\nScottish inventor Alexander Bain worked on chemical-mechanical fax-type devices and in 1846 Bain was able to reproduce graphic signs in laboratory experiments. He received British patent 9745 on May 27, 1843, for his \"Electric Printing Telegraph\". Frederick Bakewell made several improvements on Bain's design and demonstrated a telefax machine. The Pantelegraph was invented by the Italian physicist Giovanni Caselli. He introduced the first commercial telefax service between Paris and Lyon in 1865, some 11 years before the invention of the telephone.\nIn 1880, English inventor Shelford Bidwell constructed the \"scanning phototelegraph\" that was the first telefax machine to scan any two-dimensional original, not requiring manual plotting or drawing. An account of Henry Sutton's \"telephane\" was published in 1896. Around 1900, German physicist Arthur Korn invented the \"Bildtelegraph\", widespread in continental Europe especially following a widely noticed transmission of a wanted-person photograph from Paris to London in 1908, used until the wider distribution of the radiofax. Its main competitors were the \"B\u00e9linographe\" by \u00c9douard Belin first, then since the 1930s the \"Hellschreiber\", invented in 1929 by German inventor Rudolf Hell, a pioneer in mechanical image scanning and transmission.\nThe 1888 invention of the telautograph by Elisha Gray marked a further development in fax technology, allowing users to send signatures over long distances, thus allowing the verification of identification or ownership over long distances.\nOn May 19, 1924, scientists of the AT&amp;T Corporation \"by a new process of transmitting pictures by electricity\" sent 15 photographs by telephone from Cleveland to New York City, such photos being suitable for newspaper reproduction. Previously, photographs had been sent over the radio using this process.\nThe Western Union \"Deskfax\" fax machine, announced in 1948, was a compact machine that fit comfortably on a desktop, using special spark printer paper.\nWireless transmission.\nAs a designer for the Radio Corporation of America (RCA), in 1924, Richard H. Ranger invented the wireless photoradiogram, or transoceanic radio facsimile, the forerunner of today's \"fax\" machines. A photograph of President Calvin Coolidge sent from New York to London on November 29, 1924, became the first photo picture reproduced by transoceanic radio facsimile. Commercial use of Ranger's product began two years later. Also in 1924, Herbert E. Ives of AT&amp;T transmitted and reconstructed the first color facsimile, a natural-color photograph of silent film star Rudolph Valentino in period costume, using red, green and blue color separations.\nBeginning in the late 1930s, the Finch Facsimile system was used to transmit a \"radio newspaper\" to private homes via commercial AM radio stations and ordinary radio receivers equipped with Finch's printer, which used thermal paper. Sensing a new and potentially golden opportunity, competitors soon entered the field, but the printer and special paper were expensive luxuries, AM radio transmission was very slow and vulnerable to static, and the newspaper was too small. After more than ten years of repeated attempts by Finch and others to establish such a service as a viable business, the public, apparently quite content with its cheaper and much more substantial home-delivered daily newspapers, and with conventional spoken radio bulletins to provide any \"hot\" news, still showed only a passing curiosity about the new medium.\nBy the late 1940s, radiofax receivers were sufficiently miniaturized to be fitted beneath the dashboard of Western Union's \"Telecar\" telegram delivery vehicles.\nIn the 1960s, the United States Army transmitted the first photograph via satellite facsimile to Puerto Rico from the Deal Test Site using the Courier satellite.\nRadio fax is still in limited use today for transmitting weather charts and information to ships at sea. The closely related technology of slow-scan television is still used by amateur radio operators.\nTelephone transmission.\nIn 1964, Xerox Corporation introduced (and patented) what many consider to be the first commercialized version of the modern fax machine, under the name (LDX) or Long Distance Xerography. This model was superseded two years later with a unit that would set the standard for fax machines for years to come. Up until this point facsimile machines were very expensive and hard to operate. In 1966, Xerox released the Magnafax Telecopiers, a smaller, facsimile machine. This unit was far easier to operate and could be connected to any standard telephone line. This machine was capable of transmitting a letter-sized document in about six minutes. The first sub-minute, digital fax machine was developed by Dacom, which built on digital data compression technology originally developed at Lockheed for satellite communication.\nBy the late 1970s, many companies around the world (especially Japanese firms) had entered the fax market. Very shortly after this, a new wave of more compact, faster and efficient fax machines would hit the market. Xerox continued to refine the fax machine for years after their ground-breaking first machine. In later years it would be combined with copier equipment to create the hybrid machines we have today that copy, scan and fax. Some of the lesser known capabilities of the Xerox fax technologies included their Ethernet enabled Fax Services on their 8000 workstations in the early 1980s.\nPrior to the introduction of the ubiquitous fax machine, one of the first being the Exxon Qwip in the mid-1970s, facsimile machines worked by optical scanning of a document or drawing spinning on a drum. The reflected light, varying in intensity according to the light and dark areas of the document, was focused on a photocell so that the current in a circuit varied with the amount of light. This current was used to control a tone generator (a modulator), the current determining the frequency of the tone produced. This audio tone was then transmitted using an acoustic coupler (a speaker, in this case) attached to the microphone of a common telephone handset. At the receiving end, a handset's speaker was attached to an acoustic coupler (a microphone), and a demodulator converted the varying tone into a variable current that controlled the mechanical movement of a pen or pencil to reproduce the image on a blank sheet of paper on an identical drum rotating at the same rate.\nComputer facsimile interface.\nIn 1985, Hank Magnuski, founder of GammaLink, produced the first computer fax board, called GammaFax. Such boards could provide voice telephony via Analog Expansion Bus.\nIn the 21st century.\nAlthough businesses usually maintain some kind of fax capability, the technology has faced increasing competition from Internet-based alternatives. In some countries, such as Germany, because electronic signatures on contracts are not yet recognized by law, while faxed contracts with copies of signatures are, fax machines enjoy continuing support in business. In Japan, faxes are still used extensively as of September 2020 for cultural and They are available for sending to both domestic and international recipients from over 81% of all convenience stores nationwide. Convenience-store fax machines commonly print the slightly re-sized content of the sent fax in the electronic confirmation-slip, in A4 paper size. Use of fax machines for reporting cases during the COVID-19 pandemic has been criticised in Japan for introducing data errors and delays in reporting, slowing response efforts to contain the spread of infections and hindering the transition to remote work.\nIn many corporate environments, freestanding fax machines have been replaced by fax servers and other computerized systems capable of receiving and storing incoming faxes electronically, and then routing them to users on paper or via an email (which may be secured). Such systems have the advantage of reducing costs by eliminating unnecessary printouts and reducing the number of inbound analog phone lines needed by an office.\nThe once ubiquitous fax machine has also begun to disappear from the small office and home office environments. Remotely hosted fax-server services are widely available from VoIP and e-mail providers allowing users to send and receive faxes using their existing e-mail accounts without the need for any hardware or dedicated fax lines. Personal computers have also long been able to handle incoming and outgoing faxes using analog modems or ISDN, eliminating the need for a stand-alone fax machine. These solutions are often ideally suited for users who only very occasionally need to use fax services. In July 2017 the United Kingdom's National Health Service was said to be the world's largest purchaser of fax machines because the digital revolution has largely bypassed it. In June 2018 the Labour Party said that the NHS had at least 11,620 fax machines in operation and in December the Department of Health and Social Care said that no more fax machines could be bought from 2019 and that the existing ones must be replaced by secure email by March 31, 2020.\nLeeds Teaching Hospitals NHS Trust, generally viewed as digitally advanced in the NHS, was engaged in a process of removing its fax machines in early 2019. This involved quite a lot of e-fax solutions because of the need to communicate with pharmacies and nursing homes which may not have access to the NHS email system and may need something in their paper records.\nIn 2018 two-thirds of Canadian doctors reported that they primarily used fax machines to communicate with other doctors. Faxes are still seen as safer and more secure and electronic systems are often unable to communicate with each other.\nHospitals are the leading users for fax machines in the United States where some doctors prefer fax machines over emails, often due to concerns about accidentally violating HIPAA.\nCapabilities.\nThere are several indicators of fax capabilities: group, class, data transmission rate, and conformance with ITU-T (formerly CCITT) recommendations. Since the 1968 Carterfone decision, most fax machines have been designed to connect to standard PSTN lines and telephone numbers.\nGroup.\nAnalog.\nGroup 1 and 2 faxes are sent in the same manner as a frame of analog television, with each scanned line transmitted as a continuous analog signal. Horizontal resolution depended upon the quality of the scanner, transmission line, and the printer. Analog fax machines are obsolete and no longer manufactured. ITU-T Recommendations T.2 and T.3 were withdrawn as obsolete in July 1996.\nDigital.\nA major breakthrough in the development of the modern facsimile system was the result of digital technology, where the analog signal from scanners was digitized and then compressed, resulting in the ability to transmit high rates of data across standard phone lines. The first digital fax machine was the Dacom Rapidfax first sold in late 1960s, which incorporated digital data compression technology developed by Lockheed for transmission of images from satellites.\nGroup 3 and 4 faxes are digital formats and take advantage of digital compression methods to greatly reduce transmission times.\nFax Over IP (FoIP) can transmit and receive pre-digitized documents at near-realtime speeds using ITU-T recommendation T.38 to send digitised images over an IP network using JPEG compression. T.38 is designed to work with VoIP services and often supported by analog telephone adapters used by legacy fax machines that need to connect through a VoIP service. Scanned documents are limited to the amount of time the user takes to load the document in a scanner and for the device to process a digital file. The resolution can vary from as little as 150\u00a0DPI to 9600\u00a0DPI or more. This type of faxing is not related to the e-mail\u2013to\u2013fax service that still uses fax modems at least one way.\nClass.\nComputer modems are often designated by a particular fax class, which indicates how much processing is offloaded from the computer's CPU to the fax modem.\nData transmission rate.\nSeveral different telephone-line modulation techniques are used by fax machines. They are negotiated during the fax-modem handshake, and the fax devices will use the highest data rate that both fax devices support, usually a minimum of 14.4\u00a0kbit/s for Group\u00a03 fax.\n\"Super Group\u00a03\" faxes use V.34bis modulation that allows a data rate of up to 33.6\u00a0kbit/s.\nCompression.\nAs well as specifying the resolution (and allowable physical size) of the image being faxed, the ITU-T\u00a0T.4 recommendation specifies two compression methods for decreasing the amount of data that needs to be transmitted between the fax machines to transfer the image. The two methods defined in T.4 are:\nAn additional method is specified in T.6:\nLater, other compression techniques were added as options to ITU-T recommendation T.30, such as the more efficient JBIG (T.82, T.85) for bi-level content, and JPEG (T.81), T.43, MRC (T.44), and T.45 for grayscale, palette, and colour content. Fax machines can negotiate at the start of the T.30 session to use the best technique implemented on both sides.\nModified Huffman.\nModified Huffman (MH), specified in T.4 as the one-dimensional coding scheme, is a codebook-based run-length encoding scheme optimised to efficiently compress whitespace. As most faxes consist mostly of white space, this minimises the transmission time of most faxes. Each line scanned is compressed independently of its predecessor and successor.\nModified READ.\nModified READ, specified as an optional two-dimensional coding scheme in T.4, encodes the first scanned line using MH. The next line is compared to the first, the differences determined, and then the differences are encoded and transmitted. This is effective, as most lines differ little from their predecessor. This is not continued to the end of the fax transmission, but only for a limited number of lines until the process is reset, and a new \"first line\" encoded with MH is produced. This limited number of lines is to prevent errors propagating throughout the whole fax, as the standard does not provide for error correction. This is an optional facility, and some fax machines do not use MR in order to minimise the amount of computation required by the machine. The limited number of lines is 2 for \"Standard\"-resolution faxes, and 4 for \"Fine\"-resolution faxes.\nModified Modified READ.\nThe ITU-T T.6 recommendation adds a further compression type of Modified Modified READ (MMR), which simply allows a greater number of lines to be coded by MR than in T.4. This is because T.6 makes the assumption that the transmission is over a circuit with a low number of line errors, such as digital ISDN. In this case, the number of lines for which the differences are encoded is not limited.\nJBIG.\nIn 1999, ITU-T recommendation T.30 added JBIG (ITU-T T.82) as another lossless bi-level compression algorithm, or more precisely a \"fax profile\" subset of JBIG (ITU-T T.85). JBIG-compressed pages result in 20% to 50% faster transmission than MMR-compressed pages, and up to 30 times faster transmission if the page includes halftone images.\nJBIG performs adaptive compression, that is, both the encoder and decoder collect statistical information about the transmitted image from the pixels transmitted so far, in order to predict the probability for each next pixel being either black or white. For each new pixel, JBIG looks at ten nearby, previously transmitted pixels. It counts, how often in the past the next pixel has been black or white in the same neighborhood, and estimates from that the probability distribution of the next pixel. This is fed into an arithmetic coder, which adds only a small fraction of a bit to the output sequence if the more probable pixel is then encountered.\nThe ITU-T T.85 \"fax profile\" constrains some optional features of the full JBIG standard, such that codecs do not have to keep data about more than the last three pixel rows of an image in memory at any time. This allows the streaming of \"endless\" images, where the height of the image may not be known until the last row is transmitted.\nITU-T T.30 allows fax machines to negotiate one of two options of the T.85 \"fax profile\":\nMatsushita Whiteline Skip.\nA proprietary compression scheme employed on Panasonic fax machines is Matsushita Whiteline Skip (MWS). It can be overlaid on the other compression schemes, but is operative only when two Panasonic machines are communicating with one another. This system detects the blank scanned areas between lines of text, and then compresses several blank scan lines into the data space of a single character. (JBIG implements a similar technique called \"typical prediction\", if header flag TPBON is set to 1.)\nTypical characteristics.\nGroup 3 fax machines transfer one or a few printed or handwritten pages per minute in black-and-white (bitonal) at a resolution of 204\u00d798 (normal) or 204\u00d7196 (fine) dots per square inch. The transfer rate is 14.4\u00a0kbit/s or higher for modems and some fax machines, but fax machines support speeds beginning with 2400 bit/s and typically operate at 9600 bit/s. The transferred image formats are called ITU-T (formerly CCITT) fax group 3 or 4. Group 3 faxes have the suffix codice_1 and the MIME type codice_2.\nThe most basic fax mode transfers in black and white only. The original page is scanned in a resolution of 1728 pixels/line and 1145 lines/page (for A4). The resulting raw data is compressed using a modified Huffman code optimized for written text, achieving average compression factors of around 20. Typically a page needs 10\u00a0s for transmission, instead of about three minutes for the same uncompressed raw data of 1728\u00d71145 bits at a speed of 9600\u00a0bit/s. The compression method uses a Huffman codebook for run lengths of black and white runs in a single scanned line, and it can also use the fact that two adjacent scanlines are usually quite similar, saving bandwidth by encoding only the differences.\nFax classes denote the way fax programs interact with fax hardware. Available classes include Class 1, Class 2, Class 2.0 and 2.1, and Intel CAS. Many modems support at least class 1 and often either Class 2 or Class 2.0. Which is preferable to use depends on factors such as hardware, software, modem firmware, and expected use.\nPrinting process.\nFax machines from the 1970s to the 1990s often used direct thermal printers with rolls of thermal paper as their printing technology, but since the mid-1990s there has been a transition towards plain-paper faxes: thermal transfer printers, inkjet printers and laser printers.\nOne of the advantages of inkjet printing is that inkjets can affordably print in color; therefore, many of the inkjet-based fax machines claim to have color fax capability. There is a standard called ITU-T30e (formally ITU-T Recommendation T.30 Annex E ) for faxing in color; however, it is not widely supported, so many of the color fax machines can only fax in color to machines from the same manufacturer.\nStroke speed.\nStroke speed in facsimile systems is the rate at which a fixed line perpendicular to the direction of scanning is crossed in one direction by a scanning or recording spot. Stroke speed is usually expressed as a number of strokes per minute. When the fax system scans in both directions, the stroke speed is twice this number. In most conventional 20th century mechanical systems, the stroke speed is equivalent to drum speed.\nFax paper.\nAs a precaution, thermal fax paper is typically not accepted in archives or as documentary evidence in some courts of law unless photocopied. This is because the image-forming coating is eradicable and brittle, and it tends to detach from the medium after a long time in storage.\nFax tone.\nA CNG tone is an 1100\u00a0Hz tone transmitted by a fax machine when it calls another fax machine. Fax tones can cause complications when implementing fax over IP.\nInternet fax.\nOne popular alternative is to subscribe to an Internet fax service, allowing users to send and receive faxes from their personal computers using an existing email account. No software, fax server or fax machine is needed. Faxes are received as attached TIFF or PDF files, or in proprietary formats that require the use of the service provider's software. Faxes can be sent or retrieved from anywhere at any time that a user can get Internet access. Some services offer secure faxing to comply with stringent HIPAA and Gramm\u2013Leach\u2013Bliley Act requirements to keep medical information and financial information private and secure. Utilizing a fax service provider does not require paper, a dedicated fax line, or consumable resources.\nAnother alternative to a physical fax machine is to make use of computer software which allows people to send and receive faxes using their own computers, utilizing fax servers and unified messaging. A virtual (email) fax can be printed out and then signed and scanned back to computer before being emailed. Also the sender can attach a digital signature to the document file.\nWith the surging popularity of mobile phones, virtual fax machines can now be downloaded as applications for Android and iOS. These applications make use of the phone's internal camera to scan fax documents for upload or they can import from various cloud services."}
{"id": "10827", "revid": "45906155", "url": "https://en.wikipedia.org/wiki?curid=10827", "title": "Film crew", "text": "A film crew is a group of people, hired by a production company, for the purpose of producing a film or motion picture. The crew is distinguished from the cast, as the cast are understood to be the actors who appear in front of the camera or provide voices for characters in the film. The crew is also separate from the producers, as the producers are the ones who own a portion of either the film studio or the film's intellectual property rights. A film crew is divided into different departments, each of which specializes in a specific aspect of the production. Film crew positions have evolved over the years, spurred by technological change, but many traditional jobs date from the early 20th century and are common across jurisdictions and filmmaking cultures.\nMotion picture projects have three discrete stages: development, production, and distribution. Within the production stage there are also three clearly defined sequential phases (pre-production, principal photography, and post-production) and many film crew positions are associated with only one or two of the phases. Distinctions are also made between above-the-line personnel (such as the director, screenwriter, and producers) who begin their involvement during the project's development stage, and the below-the-line technical crew involved only with the production stage.\nDirector.\nA director is the person who directs the making of a film. The director most often has the highest authority on a film set. Generally, a director controls a film's artistic and dramatic aspects and visualizes the screenplay (or script) while guiding the technical crew and actors in the fulfillment of that vision. The director has a key role in choosing the cast members, production design, and the creative aspects of filmmaking. Under European Union law, the director is viewed as the author of the film.\nThe director gives direction to the cast and crew, and creates an overall vision through which a film eventually becomes realized or noticed. Directors need to be able to mediate differences in creative visions and stay within the boundaries of the film's budget. There are many pathways to becoming a film director. Some directors started as screenwriters, cinematographers, film editors, or actors. Other directors have attended a film school. Directors use different approaches. Some outline a general plotline and let the actors improvise dialogue, while others control every aspect, and demand that the actors and crew follow instructions precisely. Some directors also write their own screenplays or collaborate on screenplays with long-standing writing partners. Some directors edit or appear in their films, or compose the music score for their films.\nProduction.\nProduction is generally not considered a department as such, but rather as a series of functional groups. These include the film's producers and executive producers and production office staff such as the production manager, the production coordinator, and their assistants; the various assistant directors; the accounting staff and sometimes the locations manager and their assistants.\nDigital service.\nSince the turn of the 21st century, several additional professionals are now routinely listed in the production credits on most major motion pictures.\nCamera and lighting.\nGrip.\nGrips are trained lighting and rigging technicians. Their main responsibility is to work closely with the electrical department to put in the non-electrical components of lighting set-ups required for a shot, such as flags, overheads, and bounces. On the sound stage, they move and adjust major set pieces when something needs to be moved to get a camera into position. In addition to lifting heavy objects and setting rigging points for lights, they also report to the key grip. In the US and Canada, grips may belong to the International Alliance of Theatrical Stage Employees.\nArt department.\nThe art department in a major feature film can often number hundreds of people. Usually it is considered to include several sub-departments: the art department proper, with its art director, set designers and draftsmen; set decoration, under the set decorator; props, under the props master/mistress; construction, headed by the construction coordinator; scenic, headed by the key scenic artist; and special effects.\nArt (sets and graphic art).\nWithin the overall art department is a sub-department, also called the art department \u2013 which can be confusing. This consists of the people who design the sets and create the graphic art.\nCostume department.\nHair and make-up.\nSome actors or actresses have personal makeup artists or hair stylists.\nSpecial effects.\nThe special effects department oversees the mechanical effects (also called physical or practical effects) that create optical illusions during live-action shooting. It is not to be confused with the visual effects department, which adds photographic effects during filming to be altered later during video editing in the post-production process.\nPost-production.\nVisual effects.\nVisual effects commonly refers to post-production alterations of the film's images. The on set VFX crew works to prepare shots and plates for future visual effects. This may include adding tracking markers, taking and asking for reference plates and helping the director understand the limitations and ease of certain shots that will effect the future post production. A VFX crew can also work alongside the special effects department for any on-set optical effects that need physical representation during filming (on camera).\nPrevisualization.\nPrevisualization (also known as previs, previz, pre-rendering, preview, or wireframe windows) is the visualizing of complex scenes in a film before filming. It is also a concept in still photography. It is also used to describe techniques such as storyboarding, either in the form of charcoal sketches or in digital technology, in the planning and conceptualization of film scenes.\nAnimation.\nAnimation film crews have many of the same roles and departments as live-action films (including directing, production, editing, camera, sound, etc.), but nearly all on-set departments (lighting, electrical, grip, sets, props, costume, hair, makeup, special effects, and stunts) were traditionally replaced with a single animation department made up of various types of animators (character, effects, in-betweeners, cleanup, etc.). In traditional animation, the nature of the medium meant that everything was literally flattened into the drawn lines and solid colors that became the characters, making nearly all live-action positions irrelevant. Because animation has traditionally been so labor-intensive and thus expensive, animation films normally have a separate story department in which storyboard artists painstakingly develop scenes to make sure they make sense before they are actually animated.\nHowever, since the turn of the 21st century, modern 3D computer graphics and computer animation have made possible a level of rich detail never seen before. Many animated films now have specialized artists and animators who act as the virtual equivalent of lighting technicians, grips, costume designers, props masters, set decorators, set dressers, and cinematographers. They make artistic decisions strongly similar to those of their live-action counterparts, but implement them in a virtual space that exists only in software rather than on a physical set. There have been major breakthroughs in the simulation of hair since 2005, meaning that hairstylists have been called in since then to consult on a few animation projects."}
{"id": "10828", "revid": "39494265", "url": "https://en.wikipedia.org/wiki?curid=10828", "title": "Fear", "text": "Fear is an unpleasant emotion that arises in response to perceived dangers or threats. Fear causes physiological and psychological changes. It may produce behavioral reactions such as mounting an aggressive response or fleeing the threat, commonly known as the fight-or-flight response. Extreme cases of fear can trigger an immobilized freeze response. Fear in humans can occur in response to a present stimulus or anticipation of a future threat. Fear is involved in some mental disorders, particularly anxiety disorders.\nIn humans and other animals, fear is modulated by cognition and learning. Thus, fear is judged as rational and appropriate, or irrational and inappropriate. Irrational fears are phobias. Fear is closely related to the emotion anxiety, which occurs as the result of often future threats that are perceived to be uncontrollable or unavoidable. The fear response serves survival and has been preserved throughout evolution. Even simple invertebrates display an emotion \"akin to fear.\" Research suggests that fears are not solely dependent on their nature but also shaped by social relations and culture, which guide an individual's understanding of when and how to fear.\nPhysiological signs.\nMany physiological changes in the body are associated with fear, summarized as the fight-or-flight response. An innate response for coping with danger, it works by accelerating the breathing rate (hyperventilation), heart rate, vasoconstriction of the peripheral blood vessels leading to blood pooling, dilating the pupils, increasing muscle tension including the muscles attached to each hair follicle to contract and causing \"goosebumps\", or more clinically, piloerection (making a cold person warmer or a frightened animal look more impressive), sweating, increased blood glucose (hyperglycemia), increased serum calcium, increase in white blood cells called neutrophilic leukocytes, alertness leading to sleep disturbance and \"butterflies in the stomach\" (dyspepsia). This primitive mechanism may help an organism survive by either running away or fighting the danger. With the series of physiological changes, the consciousness realizes an emotion of fear.\nThere are observable physical reactions in individuals who experience fear. An individual might experience a feeling of dizziness, lightheaded, like they are being choked, sweating, shortness of breath, vomiting or nausea, numbness or shaking and any other like symptoms. These bodily reactions inform the individual that they are afraid and should proceed to remove or get away from the stimulus that is causing that fear.\nCauses.\nAn influential categorization of stimuli causing fear was proposed by psychologist Jeffrey Alan Gray; namely, intensity, novelty, special evolutionary dangers, stimuli arising during social interaction, and conditioned stimuli. Another categorization was proposed by Archer, who, besides conditioned fear stimuli, categorized fear-evoking (as well as aggression-evoking) stimuli into three groups; namely, pain, novelty, and frustration, although he also described \"looming\", which refers to an object rapidly moving towards the visual sensors of a subject, and can be categorized as \"intensity\". Russell described a more functional categorization of fear-evoking stimuli, in which for instance novelty is a variable affecting more than one category: 1) Predator stimuli (including movement, suddenness, proximity, but also learned and innate predator stimuli); 2) Physical environmental dangers (including intensity and heights); 3) Stimuli associated with increased risk of predation and other dangers (including novelty, openness, illumination, and being alone); 4) Stimuli stemming from conspecifics (including novelty, movement, and spacing behavior); 5) Species-predictable fear stimuli and experience (special evolutionary dangers); and 6) Fear stimuli that are not species predictable (conditioned fear stimuli).\nNature.\nAlthough many fears are learned, the capacity to fear is part of human nature. Many studies have found that certain fears (e.g. animals, heights) are much more common than others (e.g. flowers, clouds). These fears are also easier to induce in the laboratory. This phenomenon is known as preparedness. Because early humans that were quick to fear dangerous situations were more likely to survive and reproduce; preparedness is theorized to be a genetic effect that is the result of natural selection.\nFrom an evolutionary psychology perspective, different fears may be different adaptations that have been useful in our evolutionary past. They may have developed during different time periods. Some fears, such as fear of heights, may be common to all mammals and developed during the mesozoic period. Other fears, such as fear of snakes, may be common to all simians and developed during the cenozoic time period (the still-ongoing geological era encompassing the last 66 million of history). Still others, such as fear of mice and insects, may be unique to humans and developed during the paleolithic and neolithic time periods (when mice and insects become important carriers of infectious diseases and harmful for crops and stored foods).\nConditioning.\nNonhuman animals and humans innovate specific fears as a result of learning. This has been studied in psychology as fear conditioning, beginning with John B. Watson's Little Albert experiment in 1920, which was inspired after observing a child with an irrational fear of dogs. In this study, an 11-month-old boy was conditioned to fear a white rat in the laboratory. The fear became generalized to include other white, furry objects, such as a rabbit, dog, and even a Santa Claus mask with white cotton balls in the beard.\nFear can be learned by experiencing or watching a frightening traumatic accident. For example, if a child falls into a well and struggles to get out, he or she may develop a fear of wells, heights (acrophobia), enclosed spaces (claustrophobia), or water (aquaphobia). There are studies looking at areas of the brain that are affected in relation to fear. When looking at these areas (such as the amygdala), it was proposed that a person learns to fear regardless of whether they themselves have experienced trauma, or if they have observed the fear in others. In a study completed by Andreas Olsson, Katherine I. Nearing and Elizabeth A. Phelps, the amygdala were affected both when subjects observed someone else being submitted to an aversive event, knowing that the same treatment awaited themselves, and when subjects were subsequently placed in a fear-provoking situation. This suggests that fear can develop in both conditions, not just simply from personal history.\nFear is affected by cultural and historical context. For example, in the early 20th century, many Americans feared polio, a disease that can lead to paralysis. There are consistent cross-cultural differences in how people respond to fear. Display rules affect how likely people are to express the facial expression of fear and other emotions.\nFear of victimization is a function of perceived risk and seriousness of potential harm.\nCommon triggers.\nPhobias.\nAccording to surveys, some of the most common fears are of demons and ghosts, the existence of evil powers, cockroaches, spiders, snakes, heights, water, enclosed spaces, tunnels, bridges, needles, social rejection, failure, examinations, and public speaking. \nRegionally some may more so fear terrorist attacks, death, war, criminal or gang violence, being alone, the future, nuclear war, flying, clowns, intimacy, people, and driving.\nUncertainty.\nFear of the unknown or irrational fear is caused by negative thinking (worry) which arises from anxiety accompanied by a subjective sense of apprehension or dread. Irrational fear shares a common neural pathway with other fears, a pathway that engages the nervous system to mobilize bodily resources in the face of danger or threat. Many people are scared of the \"unknown\". The irrational fear can branch out to many areas such as the hereafter, the next ten years or even tomorrow. Chronic irrational fear has deleterious effects since the elicitor stimulus is commonly absent or perceived from delusions. Such fear can create comorbidity with the anxiety disorder umbrella. Being scared may cause people to experience anticipatory fear of what may lie ahead rather than planning and evaluating for the same. For example, \"continuation of scholarly education\" is perceived by many educators as a risk that may cause them fear and stress, and they would rather teach things they've been taught than go and do research.\nThe ambiguity of situations that tend to be uncertain and unpredictable can cause anxiety in addition to other psychological and physical problems in some populations; especially those who engage it constantly, for example, in war-ridden places or in places of conflict, terrorism, abuse, etc. Poor parenting that instills fear can also debilitate a child's psyche development or personality. For example, parents tell their children not to talk to strangers in order to protect them. In school, they would be motivated to not show fear in talking with strangers, but to be assertive and also aware of the risks and the environment in which it takes place. Ambiguous and mixed messages like this can affect their self-esteem and self-confidence. Researchers say talking to strangers is not something to be thwarted but allowed in a parent's presence if required. Developing a sense of equanimity to handle various situations is often advocated as an antidote to irrational fear and as an essential skill by a number of ancient philosophies.\nFear of the unknown (FOTU) \"may be a, or possibly the, fundamental fear\" from early times when there were many threats to life.\nBehavior.\nAlthough fear behavior varies from species to species, it is often divided into two main categories; namely, avoidance/flight and immobility. To these, different researchers have added different categories, such as threat display and attack, protective responses (including startle and looming responses), defensive burying, and social responses (including alarm vocalizations and submission). Finally, immobility is often divided into freezing and tonic immobility.\nThe decision as to which particular fear behavior to perform is determined by the level of fear as well as the specific context, such as environmental characteristics (escape route present, distance to refuge), the presence of a discrete and localized threat, the distance between threat and subject, threat characteristics (speed, size, directness of approach), the characteristics of the subject under threat (size, physical condition, speed, degree of crypsis, protective morphological structures), social conditions (group size), and the amount of experience with the type of the threat.\nMechanism.\nOften laboratory studies with rats are conducted to examine the acquisition and extinction of conditioned fear responses. In 2004, researchers conditioned rats (\"Rattus norvegicus\") to fear a certain stimulus, through electric shock. The researchers were able to then cause an extinction of this conditioned fear, to a point that no medications or drugs were able to further aid in the extinction process. The rats showed signs of avoidance learning, not fear, but simply avoiding the area that brought pain to the test rats. The avoidance learning of rats is seen as a conditioned response, and therefore the behavior can be unconditioned, as supported by the earlier research.\nSpecies-specific defense reactions (SSDRs) or avoidance learning in nature is the specific tendency to avoid certain threats or stimuli, it is how animals survive in the wild. Humans and animals both share these species-specific defense reactions, such as the flight-or-fight, which also include pseudo-aggression, fake or intimidating aggression and freeze response to threats, which is controlled by the sympathetic nervous system. These SSDRs are learned very quickly through social interactions between others of the same species, other species, and interaction with the environment. These acquired sets of reactions or responses are not easily forgotten. The animal that survives is the animal that already knows what to fear and how to avoid this threat. An example in humans is the reaction to the sight of a snake, many jump backwards before cognitively realizing what they are jumping away from, and in some cases, it is a stick rather than a snake.\nAs with many functions of the brain, there are various regions of the brain involved in deciphering fear in humans and other nonhuman species. The amygdala communicates both directions between the prefrontal cortex, hypothalamus, the sensory cortex, the hippocampus, thalamus, septum, and the brainstem. The amygdala plays an important role in SSDR, such as the ventral amygdalofugal, which is essential for associative learning, and SSDRs are learned through interaction with the environment and others of the same species. An emotional response is created only after the signals have been relayed between the different regions of the brain, and activating the sympathetic nervous systems; which controls the flight, fight, freeze, fright, and faint response. Often a damaged amygdala can cause impairment in the recognition of fear (like the human case of patient S.M.). This impairment can cause different species to lack the sensation of fear, and often can become overly confident, confronting larger peers, or walking up to predatory creatures.\nRobert C. Bolles (1970), a researcher at University of Washington, wanted to understand species-specific defense reactions and avoidance learning among animals, but found that the theories of avoidance learning and the tools that were used to measure this tendency were out of touch with the natural world. He theorized the species-specific defense reaction (SSDR). There are three forms of SSDRs: flight, fight (pseudo-aggression), or freeze. Even domesticated animals have SSDRs, and in those moments it is seen that animals revert to atavistic standards and become \"wild\" again. Dr. Bolles states that responses are often dependent on the reinforcement of a safety signal, and not the aversive conditioned stimuli. This safety signal can be a source of feedback or even stimulus change. Intrinsic feedback or information coming from within, muscle twitches, increased heart rate, are seen to be more important in SSDRs than extrinsic feedback, stimuli that comes from the external environment. Dr. Bolles found that most creatures have some intrinsic set of fears, to help assure survival of the species. Rats will run away from any shocking event, and pigeons will flap their wings harder when threatened. The wing flapping in pigeons and the scattered running of rats are considered species-specific defense reactions or behaviors. Bolles believed that SSDRs are conditioned through Pavlovian conditioning, and not operant conditioning; SSDRs arise from the association between the environmental stimuli and adverse events. Michael S. Fanselow conducted an experiment, to test some specific defense reactions, he observed that rats in two different shock situations responded differently, based on instinct or defensive topography, rather than contextual information.\nSpecies-specific defense responses are created out of fear, and are essential for survival. Rats that lack the gene stathmin show no avoidance learning, or a lack of fear, and will often walk directly up to cats and be eaten. Animals use these SSDRs to continue living, to help increase their chance of fitness, by surviving long enough to procreate. Humans and animals alike have created fear to know what should be avoided, and this fear can be learned through association with others in the community, or learned through personal experience with a creature, species, or situations that should be avoided. SSDRs are an evolutionary adaptation that has been seen in many species throughout the world including rats, chimpanzees, prairie dogs, and even humans, an adaptation created to help individual creatures survive in a hostile world.\nFear learning changes across the lifetime due to natural developmental changes in the brain. This includes changes in the prefrontal cortex and the amygdala.\nThe visual exploration of an emotional face does not follow a fixed pattern but modulated by the emotional content of the face. Scheller et al. found that participants paid more attention to the eyes when recognising fearful or neutral faces, while the mouth was fixated on when happy faces are presented, irrespective of task demands and spatial locations of face stimuli. These findings were replicated when fearful eyes are presented and when canonical face configurations are distorted for fearful, neutral and happy expressions.\nNeurocircuitry in mammals.\nThe brain structures that are the center of most neurobiological events associated with fear are the two amygdalae, located behind the pituitary gland. Each amygdala is part of a circuitry of fear learning. They are essential for proper adaptation to stress and specific modulation of emotional learning memory. In the presence of a threatening stimulus, the amygdalae generate the secretion of hormones that influence fear and aggression. Once a response to the stimulus in the form of fear or aggression commences, the amygdalae may elicit the release of hormones into the body to put the person into a state of alertness, in which they are ready to move, run, fight, etc. This defensive response is generally referred to in physiology as the fight-or-flight response regulated by the hypothalamus, part of the limbic system. Once the person is in safe mode, meaning that there are no longer any potential threats surrounding them, the amygdalae will send this information to the medial prefrontal cortex (mPFC) where it is stored for similar future situations, which is known as memory consolidation.\nSome of the hormones involved during the state of fight-or-flight include epinephrine, which regulates heart rate and metabolism as well as dilating blood vessels and air passages, norepinephrine increasing heart rate, blood flow to skeletal muscles and the release of glucose from energy stores, and cortisol which increases blood sugar, increases circulating neutrophilic leukocytes, calcium amongst other things.\nAfter a situation which incites fear occurs, the amygdalae and hippocampus record the event through synaptic plasticity. The stimulation to the hippocampus will cause the individual to remember many details surrounding the situation. Plasticity and memory formation in the amygdala are generated by activation of the neurons in the region. Experimental data supports the notion that synaptic plasticity of the neurons leading to the lateral amygdalae occurs with fear conditioning. In some cases, this forms permanent fear responses such as post-traumatic stress disorder (PTSD) or a phobia. MRI and fMRI scans have shown that the amygdalae in individuals diagnosed with such disorders including bipolar or panic disorder are larger and wired for a higher level of fear.\nPathogens can suppress amygdala activity. Rats infected with the toxoplasmosis parasite become less fearful of cats, sometimes even seeking out their urine-marked areas. This behavior often leads to them being eaten by cats. The parasite then reproduces within the body of the cat. There is evidence that the parasite concentrates itself in the amygdala of infected rats. In a separate experiment, rats with lesions in the amygdala did not express fear or anxiety towards unwanted stimuli. These rats pulled on levers supplying food that sometimes sent out electrical shocks. While they learned to avoid pressing on them, they did not distance themselves from these shock-inducing levers.\nSeveral brain structures other than the amygdalae have also been observed to be activated when individuals are presented with fearful vs. neutral faces, namely the occipitocerebellar regions including the fusiform gyrus and the inferior parietal / superior temporal gyri. Fearful eyes, brows and mouth seem to separately reproduce these brain responses. Scientists from Zurich studies show that the hormone oxytocin related to stress and sex reduces activity in your brain fear center.\nPheromones and contagion.\nIn threatening situations, insects, aquatic organisms, birds, reptiles, and mammals emit odorant substances, initially called alarm substances, which are chemical signals now called alarm pheromones. This is to defend themselves and at the same time to inform members of the same species of danger and leads to observable behavior change like freezing, defensive behavior, or dispersion depending on circumstances and species. For example, stressed rats release odorant cues that cause other rats to move away from the source of the signal.\nAfter the discovery of pheromones in 1959, alarm pheromones were first described in 1968 in ants and earthworms, and four years later also found in mammals, both mice and rats. Over the next two decades, identification and characterization of these pheromones proceeded in all manner of insects and sea animals, including fish, but it was not until 1990 that more insight into mammalian alarm pheromones was gleaned.\nIn 1985, a link between odors released by stressed rats and pain perception was discovered: unstressed rats exposed to these odors developed opioid-mediated analgesia. In 1997, researchers found that bees became less responsive to pain after they had been stimulated with isoamyl acetate, a chemical smelling of banana, and a component of bee alarm pheromone. The experiment also showed that the bees' fear-induced pain tolerance was mediated by an endorphin.\nBy using the forced swimming test in rats as a model of fear-induction, the first mammalian \"alarm substance\" was found. In 1991, this \"alarm substance\" was shown to fulfill criteria for pheromones: well-defined behavioral effect, species specificity, minimal influence of experience and control for nonspecific arousal. Rat activity testing with the alarm pheromone, and their preference/avoidance for odors from cylinders containing the pheromone, showed that the pheromone had very low volatility.\nIn 1993 a connection between alarm chemosignals in mice and their immune response was found. Pheromone production in mice was found to be associated with or mediated by the pituitary gland in 1994.\nIn 2004, it was demonstrated that rats' alarm pheromones had different effects on the \"recipient\" rat (the rat perceiving the pheromone) depending which body region they were released from: Pheromone production from the face modified behavior in the recipient rat, e.g. caused sniffing or movement, whereas pheromone secreted from the rat's anal area induced autonomic nervous system stress responses, like an increase in core body temperature. Further experiments showed that when a rat perceived alarm pheromones, it increased its defensive and risk assessment behavior, and its acoustic startle reflex was enhanced.\nIt was not until 2011 that a link between severe pain, neuroinflammation and alarm pheromones release in rats was found: real time RT-PCR analysis of rat brain tissues indicated that shocking the footpad of a rat increased its production of proinflammatory cytokines in deep brain structures, namely of IL-1\u03b2, heteronuclear Corticotropin-releasing hormone and c-fos mRNA expressions in both the paraventricular nucleus and the bed nucleus of the stria terminalis, and it increased stress hormone levels in plasma (corticosterone).\nThe neurocircuit for how rats perceive alarm pheromones was shown to be related to the hypothalamus, brainstem, and amygdalae, all of which are evolutionary ancient structures deep inside or in the case of the brainstem underneath the brain away from the cortex, and involved in the fight-or-flight response, as is the case in humans.\nAlarm pheromone-induced anxiety in rats has been used to evaluate the degree to which anxiolytics can alleviate anxiety in humans. For this, the change in the acoustic startle reflex of rats with alarm pheromone-induced anxiety (i.e. reduction of defensiveness) has been measured. Pretreatment of rats with one of five anxiolytics used in clinical medicine was able to reduce their anxiety: namely midazolam, phenelzine (a nonselective monoamine oxidase (MAO) inhibitor), propranolol, a nonselective beta blocker, clonidine, an alpha 2 adrenergic agonist or CP-154,526, a corticotropin-releasing hormone antagonist.\nFaulty development of odor discrimination impairs the perception of pheromones and pheromone-related behavior, like aggressive behavior and mating in male rats: The enzyme Mitogen-activated protein kinase 7 (MAPK7) has been implicated in regulating the development of the olfactory bulb and odor discrimination and it is highly expressed in developing rat brains, but absent in most regions of adult rat brains. Conditional deletion of the MAPK7gene in mouse neural stem cells impairs several pheromone-mediated behaviors, including aggression and mating in male mice. These behavior impairments were not caused by a reduction in the level of testosterone, by physical immobility, by heightened fear or anxiety or by depression. Using mouse urine as a natural pheromone-containing solution, it has been shown that the impairment was associated with defective detection of related pheromones, and with changes in their inborn preference for pheromones related to sexual and reproductive activities.\nLastly, alleviation of an acute fear response because a friendly peer (or in biological language: an affiliative conspecific) tends and befriends is called \"social buffering\". The term is in analogy to the 1985 \"buffering\" hypothesis in psychology, where social support has been proven to mitigate the negative health effects of alarm pheromone mediated distress. The role of a \"social pheromone\" is suggested by the recent discovery that olfactory signals are responsible in mediating the \"social buffering\" in male rats. \"Social buffering\" was also observed to mitigate the conditioned fear responses of honeybees. A bee colony exposed to an environment of high threat of predation did not show increased aggression and aggressive-like gene expression patterns in individual bees, but decreased aggression. That the bees did not simply habituate to threats is suggested by the fact that the disturbed colonies also decreased their foraging.\nBiologists have proposed in 2012 that fear pheromones evolved as molecules of \"keystone significance\", a term coined in analogy to keystone species. Pheromones may determine species compositions and affect rates of energy and material exchange in an ecological community. Thus pheromones generate structure in a food web and play critical roles in maintaining natural systems.\nHumans.\nEvidence of chemosensory alarm signals in humans has emerged slowly: Although alarm pheromones have not been physically isolated and their chemical structures have not been identified in humans so far, there is evidence for their presence. Androstadienone, for example, a steroidal, endogenous odorant, is a pheromone candidate found in human sweat, axillary hair and plasma. The closely related compound androstenone is involved in communicating dominance, aggression or competition; sex hormone influences on androstenone perception in humans showed a high testosterone level related to heightened androstenone sensitivity in men, a high testosterone level related to unhappiness in response to androstenone in men, and a high estradiol level related to disliking of androstenone in women.\nA German study from 2006 showed when anxiety-induced versus exercise-induced human sweat from a dozen people was pooled and offered to seven study participants, of five able to olfactorily distinguish exercise-induced sweat from room air, three could also distinguish exercise-induced sweat from anxiety induced sweat. The acoustic startle reflex response to a sound when sensing anxiety sweat was larger than when sensing exercise-induced sweat, as measured by electromyography analysis of the orbital muscle, which is responsible for the eyeblink component. This showed for the first time that fear chemosignals can modulate the startle reflex in humans without emotional mediation; fear chemosignals primed the recipient's \"defensive behavior\" prior to the subjects' conscious attention on the acoustic startle reflex level.\nIn analogy to the social buffering of rats and honeybees in response to chemosignals, induction of empathy by \"smelling anxiety\" of another person has been found in humans.\nA study from 2013 provided brain imaging evidence that human responses to fear chemosignals may be gender-specific. Researchers collected alarm-induced sweat and exercise-induced sweat from donors extracted it, pooled it and presented it to 16 unrelated people undergoing functional brain MRI. While stress-induced sweat from males produced a comparably strong emotional response in both females and males, stress-induced sweat from females produced markedly stronger arousal in women than in men. Statistical tests pinpointed this gender-specificity to the right amygdala and strongest in the superficial nuclei. Since no significant differences were found in the olfactory bulb, the response to female fear-induced signals is likely based on processing the meaning, i.e. on the emotional level, rather than the strength of chemosensory cues from each gender, i.e. the perceptual level.\nAn approach-avoidance task was set up where volunteers seeing either an angry or a happy cartoon face on a computer screen pushed away or pulled toward them a joystick as fast as possible. Volunteers smelling androstadienone, masked with clove oil scent responded faster, especially to angry faces than those smelling clove oil only, which was interpreted as androstadienone-related activation of the fear system. A potential mechanism of action is, that androstadienone alters the \"emotional face processing\". Androstadienone is known to influence the activity of the fusiform gyrus which is relevant for face recognition.\nCognitive-consistency theory.\nCognitive-consistency theories assume that \"when two or more simultaneously active cognitive structures are logically inconsistent, arousal is increased, which activates processes with the expected consequence of increasing consistency and decreasing arousal.\" In this context, it has been proposed that fear behavior is caused by an inconsistency between a preferred, or expected, situation and the actually perceived situation, and functions to remove the inconsistent stimulus from the perceptual field, for instance by fleeing or hiding, thereby resolving the inconsistency. This approach puts fear in a broader perspective, also involving aggression and curiosity. When the inconsistency between perception and expectancy is small, learning as a result of curiosity reduces inconsistency by updating expectancy to match perception. If the inconsistency is larger, fear or aggressive behavior may be employed to alter the perception in order to make it match expectancy, depending on the size of the inconsistency as well as the specific context. Aggressive behavior is assumed to alter perception by forcefully manipulating it into matching the expected situation, while in some cases thwarted escape may also trigger aggressive behavior in an attempt to remove the thwarting stimulus.\nResearch.\nIn order to improve our understanding of the neural and behavioral mechanisms of adaptive and maladaptive fear, investigators use a variety of translational animal models. These models are particularly important for research that would be too invasive for human studies. Rodents such as mice and rats are common animal models, but other species are used. Certain aspects of fear research still requires more research such as sex, gender, and age differences.\nModels.\nThese animal models include, but are not limited to, fear conditioning, predator-based psychosocial stress, single prolonged stress, chronic stress models, inescapable foot/tail shocks, immobilization or restraint, and stress enhanced fear learning. While the stress and fear paradigms differ between the models, they tend to involve aspects such as acquisition, generalization, extinction, cognitive regulation, and reconsolidation.\nPavlovian.\nFear conditioning, also known as Pavlovian or classical conditioning, is a process of learning that involves pairing a neutral stimulus with an unconditional stimulus (US). A neutral stimulus is something like a bell, tone, or room that does not elicit a response normally where a US is a stimulus that results in a natural or unconditioned response (UR) \u2013 in Pavlov's famous experiment the neutral stimulus is a bell and the US would be food with the dog's salvation being the UR. Pairing the neutral stimulus and the US results in the UR occurring not only with the US but also the neutral stimulus. When this occurs the neutral stimulus is referred to as the conditional stimulus (CS) and the response the conditional response (CR). In the fear conditioning model of Pavlovian conditioning the US is an aversive stimulus such as a shock, tone, or unpleasant odor.\nPredator-based psychosocial stress.\nPredator-based psychosocial stress (PPS) involves a more naturalistic approach to fear learning. Predators such as a cat, a snake, or urine from a fox or cat are used along with other stressors such as immobilization or restraint in order to generate instinctual fear responses.\nChronic stress models.\nChronic stress models include chronic variable stress, chronic social defeat, and chronic mild stress. These models are often used to study how long-term or prolonged stress/pain can alter fear learning and disorders.\nSingle prolonged stress.\nSingle prolonged stress (SPS) is a fear model that is often used to study PTSD. Its paradigm involves multiple stressors such as immobilization, a force swim, and exposure to ether delivered concurrently to the subject. This is used to study non-naturalistic, uncontrollable situations that can cause a maladaptive fear responses that is seen in a lot of anxiety and traumatic based disorders.\nStress enhanced fear learning.\nStress enhanced fear learning (SEFL) like SPS is often used to study the maladaptive fear learning involved in PTSD and other traumatic based disorders. SEFL involves a single extreme stressor such as a large number of footshocks simulating a single traumatic stressor that somehow enhances and alters future fear learning.\nManagement.\nPharmaceutical.\nA drug treatment for fear conditioning and phobias via the amygdalae is the use of glucocorticoids. In one study, glucocorticoid receptors in the central nuclei of the amygdalae were disrupted in order to better understand the mechanisms of fear and fear conditioning. The glucocorticoid receptors were inhibited using lentiviral vectors containing Cre-recombinase injected into mice. Results showed that disruption of the glucocorticoid receptors prevented conditioned fear behavior. The mice were subjected to auditory cues which caused them to freeze normally. A reduction of freezing was observed in the mice that had inhibited glucocorticoid receptors.\nPsychological.\nCognitive behavioral therapy has been successful in helping people overcome their fear. Because fear is more complex than just forgetting or deleting memories, an active and successful approach involves people repeatedly confronting their fears. By confronting their fears in a safe manner a person can suppress the \"fear-triggering memories\" or stimuli.\nExposure therapy has known to have helped up to 90% of people with specific phobias to significantly decrease their fear over time.\nAnother psychological treatment is systematic desensitization, which is a type of behavior therapy used to completely remove the fear or produce a disgusted response to this fear and replace it. The replacement that occurs will be relaxation and will occur through conditioning. Through conditioning treatments, muscle tensioning will lessen and deep breathing techniques will aid in de-tensioning.\nLiterary and religious.\nThere are other methods for treating or coping with one's fear, such as writing down rational thoughts regarding fears. Journal entries are a healthy method of expressing one's fears without compromising safety or causing uncertainty. Another suggestion is a fear ladder. To create a fear ladder, one must write down all of their fears and score them on a scale of one to ten. Next, the person addresses their phobia, starting with the lowest number.\nReligion can help some individuals cope with fear.\nIncapability.\nPeople who have damage to their amygdalae, which can be caused by a rare genetic disease known as Urbach\u2013Wiethe disease, are unable to experience fear. The disease destroys both amygdalae in late childhood. Since the discovery of the disease, there have only been 400 recorded cases. A lack of fear can allow someone to get into a dangerous situation they otherwise would have avoided.\nSociety and culture.\nDeath.\nThe fear of the end of life and its existence is, in other words, the fear of death. Historically, attempts were made to reduce this fear by performing rituals which have helped collect the cultural ideas that we now have in the present. These rituals also helped preserve the cultural ideas. The results and methods of human existence had been changing at the same time that social formation was changing.\nWhen people are faced with their own thoughts of death, they either accept that they are dying or will die because they have lived a full life or they will experience fear. A theory was developed in response to this, which is called the terror management theory. The theory states that a person's cultural worldviews (religion, values, etc.) will mitigate the terror associated with the fear of death through avoidance. To help manage their terror, they find solace in their death-denying beliefs, such as their religion. Another way people cope with their death related fears is pushing any thoughts of death into the future or by avoiding these thoughts all together through distractions. Although there are methods for one coping with the terror associated with their fear of death, not everyone suffers from these same uncertainties. People who believe they have lived life to the \"fullest\" typically do not fear death.\nDeath anxiety is multidimensional; it covers \"fears related to one's own death, the death of others, fear of the unknown after death, fear of obliteration, and fear of the dying process, which includes fear of a slow death and a painful death\".\nThe Yale philosopher Shelly Kagan examined fear of death in a 2007 Yale open course by examining the following questions: Is fear of death a reasonable appropriate response? What conditions are required and what are appropriate conditions for feeling fear of death? What is meant by fear, and how much fear is appropriate? According to Kagan for fear in general to make sense, three conditions should be met:\nThe amount of fear should be appropriate to the size of \"the bad\". If the three conditions are not met, fear is an inappropriate emotion. He argues, that death does not meet the first two criteria, even if death is a \"deprivation of good things\" and even if one believes in a painful afterlife. Because death is certain, it also does not meet the third criterion, but he grants that the unpredictability of when one dies \"may\" be cause to a sense of fear.\nIn a 2003 study of 167 women and 121 men, aged 65\u201387, low self-efficacy predicted fear of the unknown after death and fear of dying for women and men better than demographics, social support, and physical health. Fear of death was measured by a \"Multidimensional Fear of Death Scale\" which included the 8 subscales Fear of Dying, Fear of the Dead, Fear of Being Destroyed, Fear for Significant Others, Fear of the Unknown, Fear of Conscious Death, Fear for the Body After Death, and Fear of Premature Death. In hierarchical multiple regression analysis, the most potent predictors of death fears were low \"spiritual health efficacy\", defined as beliefs relating to one's perceived ability to generate spiritually based faith and inner strength, and low \"instrumental efficacy\", defined as beliefs relating to one's perceived ability to manage activities of daily living.\nPsychologists have tested the hypotheses that fear of death motivates religious commitment, and that assurances about an afterlife alleviate the fear, with equivocal results. Religiosity can be related to fear of death when the afterlife is portrayed as time of punishment. \"Intrinsic religiosity\", as opposed to mere \"formal religious involvement\", has been found to be negatively correlated with death anxiety. In a 1976 study of people of various Christian denominations, those who were most firm in their faith, who attended religious services weekly, were the least afraid of dying. The survey found a negative correlation between fear of death and \"religious concern\".\nIn a 2006 study of white, Christian men and women the hypothesis was tested that traditional, church-centered religiousness and de-institutionalized spiritual seeking are ways of approaching fear of death in old age. Both religiousness and spirituality were related to positive psychosocial functioning, but only church-centered religiousness protected subjects against the fear of death.\nReligion.\nStatius in the \"Thebaid\" (Book 3, line 661) aired the irreverent suggestion that \"fear first made gods in the world\".\nFrom a Christian theological perspective, the word \"fear\" can encompass more than simple dread. Robert B. Strimple says that fear includes the \"... convergence of awe, reverence, adoration, humility..\". Some translations of the Bible, such as the New International Version, sometimes express the concept of \"fear\" with the word \"reverence\".\nA similar phrase, \"God-fearing\", is sometimes used as a rough synonym for \"pious\". It is a standard translation for the Arabic word taqwa (; \"forbearance, restraint\") in Muslim contexts. In Judaism, \"fear of God\" describes obedience to Jewish law even when invisible to others.\nManipulation.\nFear may be politically and culturally manipulated to persuade citizenry of ideas which would otherwise be widely rejected or dissuade citizenry from ideas which would otherwise be widely supported. In contexts of disasters, nation-states manage the fear not only to provide their citizens with an explanation about the event or blaming some minorities, but also to adjust their previous beliefs.\nFear can alter how a person thinks or reacts to situations because fear has the power to inhibit one's rational way of thinking. As a result, people who do not experience fear, are able to use fear as a tool to manipulate others. People who are experiencing fear, seek preservation through safety and can be manipulated by a person who is there to provide that safety that is being sought after. \"When we're afraid, a manipulator can talk us out of the truth we see right in front of us. Words become more real than reality\" By this, a manipulator can use our fear to manipulate us out the truth and instead make us believe and trust in their truth. Politicians are notorious for using fear to manipulate the people into supporting their policies.This strategy taps into primal human emotions, leveraging fear of the unknown, external threats, or perceived dangers to influence decision-making.\nFiction and mythology.\nFear is found and reflected in mythology and folklore as well as in works of fiction such as novels and films.\nWorks of dystopian and (post)apocalyptic fiction convey the fears and anxieties of societies.\nThe fear of the world's end is about as old as civilization itself. In a 1967 study, Frank Kermode suggests that the failure of religious prophecies led to a shift in how society apprehends this ancient mode. Scientific and critical thought supplanting religious and mythical thought as well as a public emancipation may be the cause of eschatology becoming replaced by more realistic scenarios. Such might constructively provoke discussion and steps to be taken to prevent depicted catastrophes.\n\"The Story of the Youth Who Went Forth to Learn What Fear Was\" is a German fairy tale dealing with the topic of not knowing fear.\nMany stories also include characters who fear the antagonist of the plot. One important characteristic of historical and mythical heroes across cultures is to be fearless in the face of big and often lethal enemies.\n\"The Magnus Archives\" is a fiction horror podcast written by Jonathan Sims and directed by Alexander J. Newall that, among other things, formulates an archetypal ontology of fear through the dissemination of case files at a paranormal research institute set in a world where the metaphysical basis of paranormal activity and unexplainable horrors is fear incarnate. The diegesis states that true categorization of fear is impossible, that fear is all one unknowable thing; however, there exists an ontological structure of fear archetypes in this universe proposed by a fictional version of the architect Robert Smirke. It is a unique construction of fear in that it is not based on the science or neurology of fear, but on thematic and experiential connections between different phobias. For example, the fear of disease and vermin comes from the same place as the fear of abusive relationships, as both lie in fearing corruptions to the self. The final season of the podcast consists almost entirely of poetic meditations on the nature of fear.\nFear in art has been explored by the Japanese scholar Kyoko Nakano, in a series of books and a 2017 exhibition about \"kowai-e\" (lit. scary pictures).\nAthletics.\nIn the world of athletics, fear is often used as a means of motivation to not fail. This situation involves using fear in a way that increases the chances of a positive outcome. In this case, the fear that is being created is initially a cognitive state to the receiver. This initial state is what generates the first response of the athlete, this response generates a possibility of fight or flight reaction by the athlete (receiver), which in turn will increase or decrease the possibility of success or failure in the certain situation for the athlete. The amount of time that the athlete has to determine this decision is small but it is still enough time for the receiver to make a determination through cognition. Even though the decision is made quickly, the decision is determined through past events that have been experienced by the athlete. The results of these past events will determine how the athlete will make his cognitive decision in the split second that he or she has.\nFear of failure as described above has been studied frequently in the field of sport psychology. Many scholars have tried to determine how often fear of failure is triggered within athletes, as well as what personalities of athletes most often choose to use this type of motivation. Studies have also been conducted to determine the success rate of this method of motivation.\nMurray's Exploration in Personal (1938) was one of the first studies that actually identified fear of failure as an actual motive to avoid failure or to achieve success. His studies suggested that inavoidance, the need to avoid failure, was found in many college-aged men during the time of his research in 1938. This was a monumental finding in the field of psychology because it allowed other researchers to better clarify how fear of failure can actually be a determinant of creating achievement goals as well as how it could be used in the actual act of achievement.\nIn the context of sport, a model was created by R.S. Lazarus in 1991 that uses the cognitive-motivational-relational theory of emotion. \nAnother study was done in 2001 by Conroy, Poczwardowski, and Henschen that created five aversive consequences of failing that have been repeated over time. The five categories include (a) experiencing shame and embarrassment, (b) devaluing one's self-estimate, (c) having an uncertain future, (d) important others losing interest, (e) upsetting important others. These five categories can help one infer the possibility of an individual to associate failure with one of these threat categories, which will lead them to experiencing fear of failure.\nIn summary, the two studies that were done above created a more precise definition of fear of failure, which is \"a dispositional tendency to experience apprehension and anxiety in evaluative situations because individuals have learned that failure is associated with aversive consequences\".\nThe author and internet content creator John Green wrote about \u201cthe yips\u201d\u2014a common colloquialism for a debilitating, often chronic manifestation of athletic anxiety experienced by some professional athletes\u2014in an essay for his podcast and novel \"The Anthropocene Reviewed\". Green discusses famous examples of when athletic anxiety has ruined careers and juxtaposes it with the nature of general anxiety as a whole. Green settles, however, on a conclusion for the essay evoking resilience and hope in the human condition by describing a circumstance where the baseball player Rick Ankiel reset his career back to the minor leagues as an outfielder after getting the yips as a major league pitcher."}
{"id": "10830", "revid": "82432", "url": "https://en.wikipedia.org/wiki?curid=10830", "title": "Football team", "text": "A football team is a group of players selected to play together in the various team sports known as football. Such teams could be selected to play in a match against an opposing team, to represent a football club, group, state or nation, an all-star team or even selected as a hypothetical team (such as a dream team or team of the century) and never play an actual match.\nThe difference between a football team and a football club is incorporation, a football club is an entity which is formed and governed by a committee and has members which may consist of supporters in addition to players. The benefit of club formation is that it gives teams access to additional volunteer or paid support staff, facilities and equipment. \nSummary.\nThere are several varieties of football, including association football, gridiron football, Australian rules football, Gaelic football, rugby league and rugby union. The number of players selected for each team, within these varieties and their associated codes, can vary substantially. Sometimes, the word \"team\" may be limited to those who play on the field in a match and does not always include other players who may take part as replacements or emergency players. \"Football squad\" may be used to be inclusive of these support and reserve players.\nThe words team and club are sometimes used interchangeably by supporters, typically referring to the team within the club playing in the highest division or competition. A football club is a type of sports club which is an organized or incorporated body. Typically these will have a committee, secretary, president, or chairperson, registrar and members. Football clubs typically have a set of rules, including rules under which they play and are themselves typically members of a league or association which are affiliated with a governing body within their sport. Clubs may field multiple teams from their registered players (which may participate in several different divisions or leagues). A club is responsible for ensuring the continued existence of its teams in their respective competitions. The oldest football clubs date back to the early 19th century. While records exist for most incorporated clubs, they do not exist for all football clubs. Standalone clubs are usually run like businesses and appear on official registers. However many football clubs were formed as part of larger organisations (schools, athletic clubs, societies) and therefore public records of their formation and operation may not be kept unless they compete with other teams. Football clubs may also be dormant for periods and be re-formed (for example going into recess for reasons such as war or lack of a league or competition to participate in) and even switch between football codes. Likewise, a football club may fold if it becomes insolvent or is incapable of fielding a team to play matches.\nVariation of player numbers among football codes.\nThe number of players that take part in the sport simultaneously, thus forming the team are:"}
{"id": "10831", "revid": "5128741", "url": "https://en.wikipedia.org/wiki?curid=10831", "title": "F", "text": "F, or f, is the sixth letter of the Latin alphabet and many modern alphabets influenced by it, including the modern English alphabet and the alphabets of all other modern western European languages. Its name in English is \"ef\" (pronounced ), and the plural is \"efs\".\nHistory.\nThe origin of 'F' is the Semitic letter \"waw\" that represented a sound like or . Graphically it probably originally depicted either a hook or a club. It may have been based on a comparable Egyptian hieroglyph such as (transliterated as \u1e25(dj)): T3\nThe Phoenician form of the letter was adopted into Greek as a vowel, \"upsilon\" (which resembled its descendant 'Y' but was also the ancestor of the Roman letters 'U', 'V', and 'W'); and, with another form, as a consonant, \"digamma\", which indicated the pronunciation , as in Phoenician. Latin 'F,' despite being pronounced differently, is ultimately descended from digamma and closely resembles it in form.\nAfter sound changes eliminated from spoken Greek, \"digamma\" was used only as a numeral. However, the Greek alphabet also gave rise to other alphabets, and some of these retained letters descended from digamma. In the Etruscan alphabet, 'F' probably represented , as in Greek, and the Etruscans formed the digraph 'FH' to represent . (At the time these letters were borrowed, there was no Greek letter that represented /f/: the Greek letter phi '\u03a6' then represented an aspirated voiceless bilabial plosive , although in Modern Greek it has come to represent .) When the Romans adopted the alphabet, they used 'V' (from Greek \"upsilon\") not only for the vowel , but also for the corresponding semivowel , leaving 'F' available for . And so out of the various \"vav\" variants in the Mediterranean world, the letter F entered the Roman alphabet attached to a sound which the Greeks did not have. The Roman alphabet forms the basis of the alphabet used today for English and many other languages.\nThe lowercase 'f' is not related to the visually similar long s, '\u017f' (or medial s). The use of the \"long s\" largely died out by the beginning of the 19th century, mostly to prevent confusion with 'f' when using a short mid-bar.\nUse in writing systems.\nEnglish.\nIn the English writing system is used to represent the sound , the voiceless labiodental fricative. It is often doubled at the end of words. Exceptionally, it represents the voiced labiodental fricative in the common word \"of\" and its derivatives.\nF is the eleventh least frequently used letter in the English language (after G, Y, P, B, V, K, J, X, Q, and Z), with a frequency of about 2.23% in words.\nOther languages.\nIn the writing systems of other languages, commonly represents , or .\nOther systems.\nThe International Phonetic Alphabet uses to represent the voiceless labiodental fricative.\nOther representations.\nComputing.\nThese are the code points for the forms of the letter in various systems:"}
{"id": "10834", "revid": "42245696", "url": "https://en.wikipedia.org/wiki?curid=10834", "title": "Food preservation", "text": "Food preservation includes processes that make food more resistant to microorganism growth and slow the oxidation of fats. This slows down the decomposition and rancidification process. Food preservation may also include processes that inhibit visual deterioration, such as the enzymatic browning reaction in apples after they are cut during food preparation. By preserving food, food waste can be reduced, which is an important way to decrease production costs and increase the efficiency of food systems, improve food security and nutrition and contribute towards environmental sustainability. For instance, it can reduce the environmental impact of food production.\nMany processes designed to preserve food involve more than one food preservation method. Preserving fruit by turning it into jam, for example, involves boiling (to reduce the fruit's moisture content and to kill bacteria, etc.), sugaring (to prevent their re-growth) and sealing within an airtight jar (to prevent recontamination).\nDifferent food preservation methods have different impacts on the quality of the food and food systems. Some traditional methods of preserving food have been shown to have a lower energy input and carbon footprint compared to modern methods. Some methods of food preservation are also known to create carcinogens.\nTraditional techniques.\nSome techniques of food preservation pre-date the dawn of agriculture. Others were discovered more recently.\nBoiling.\nBoiling liquids can kill any existing microbes. Milk and water are often boiled to kill any harmful microbes that may be present in them.\nBurial.\nBurial of food can preserve it due to a variety of factors: lack of light, lack of oxygen, cool temperatures, pH level, or desiccants in the soil. Burial may be combined with other methods such as salting or fermentation. Most foods can be preserved in soil that is very dry and salty (thus a desiccant) such as sand, or soil that is frozen.\nMany root vegetables are very resistant to spoilage and require no other preservation than storage in cool dark conditions, for example by burial in the ground, such as in a storage clamp (not to be confused with a root cellar). Cabbage was traditionally buried during autumn in northern US farms for preservation. Some methods keep it crispy while other methods produce sauerkraut. A similar process is used in the traditional production of kimchi.\nSometimes meat is buried under conditions that cause preservation. If buried on hot coals or ashes, the heat can kill pathogens, the dry ash can desiccate, and the earth can block oxygen and further contamination. If buried where the earth is very cold, the earth acts like a refrigerator, or, in areas of permafrost, a freezer.\nIn Odisha, India, it is practical to store rice by burying it underground. This method helps to store for three to six months during the dry season.\nButter and similar substances have been preserved as bog butter in Irish peat bogs for centuries. Century eggs are traditionally created by placing eggs in alkaline mud (or other alkaline substance), resulting in their \"inorganic\" fermentation through raised pH instead of spoiling. The fermentation preserves them and breaks down some of the complex, less flavorful proteins and fats into simpler, more flavorful ones.\nCanning.\nCanning involves cooking food, sealing it in sterilized cans or jars, and boiling the containers to kill or weaken any remaining bacteria as a form of sterilization. It was invented by the French confectioner Nicolas Appert. By 1806, this process was used by the French Navy to preserve meat, fruit, vegetables, and even milk. Although Appert had discovered a new way of preservation, it was not understood until 1864 when Louis Pasteur found the relationship between microorganisms, food spoilage, and illness.\nFoods have varying degrees of natural protection against spoilage and may require that the final step occurs in a pressure cooker. High-acid fruits like strawberries require no preservatives to can and only a short boiling cycle, whereas marginal vegetables such as carrots require longer boiling and the addition of other acidic elements. Low-acid foods, such as vegetables and meats, require pressure canning. Food preserved by canning or bottling is at immediate risk of spoilage once the can or bottle has been opened.\nLack of quality control in the canning process may allow ingress of water or micro-organisms. Most such failures are rapidly detected as decomposition within the can cause gas production and the can will swell or burst. However, there have been examples of poor manufacture (underprocessing) and poor hygiene allowing contamination of canned food by the obligate anaerobe \"Clostridium botulinum\", which produces an acute toxin within the food, leading to severe illness or death. This organism produces no gas or obvious taste and remains undetected by taste or smell. Its toxin is denatured by cooking, however. Cooked mushrooms, when handled poorly and then canned, can support the growth of \"Staphylococcus aureus\", which produces a toxin that is not destroyed by canning or subsequent reheating.\nConfit.\nMeat can be preserved by salting it, cooking it at or near in some kind of fat (such as lard or tallow), and then storing it immersed in the fat. These preparations were popular in Europe before refrigerators became ubiquitous. They are still popular in France, where the term originates. The preparation will keep longer if stored in a cold cellar or buried in cold ground.\nCooling.\nCooling preserves food by slowing down the growth and reproduction of microorganisms and the action of enzymes that causes the food to rot. The introduction of commercial and domestic refrigerators drastically improved the diets of many in the Western world by allowing food such as fresh fruit, salads and dairy products to be stored safely for longer periods, particularly during warm weather.\nBefore the era of mechanical refrigeration, cooling for food storage occurred in the forms of root cellars and iceboxes. Rural people often did their own ice cutting, whereas town and city dwellers often relied on the ice trade. Today, root cellaring remains popular among people who value various goals, including local food, heirloom crops, traditional home cooking techniques, family farming, frugality, self-sufficiency, organic farming, and others.\nAging of wine.\nIn the recent years such PEF techniques are utilised in the artificial aging of red wines, i.e. by utising wood chips.\nCuring.\nThe earliest form of curing was dehydration or drying, used as early as 12,000BC. Smoking and salting techniques improve on the drying process and add antimicrobial agents that aid in preservation. Smoke deposits a number of pyrolysis products onto the food, including the phenols syringol, guaiacol and catechol. Salt accelerates the drying process using osmosis and also inhibits the growth of several common strains of bacteria. More recently nitrites have been used to cure meat, contributing a characteristic pink colour.\nIn 2015, the International Agency for Research on Cancer of the World Health Organization classified processed meat\u2014i.e., meat that has undergone salting, curing, and smoking\u2014as \"carcinogenic to humans\".\nFermentation.\nSome foods, such as many cheeses, wines, and beers, are prepared by fermentation. This involves cultivating specific microorganisms to combat spoilage from other, less benign organisms. These microorganisms keep pathogens in check by producing acid or alcohol, which eventually creates an environment toxic for themselves and other microorganisms.\nMethods of fermentation include, but are not limited to, starter microorganisms, salt, hops, controlled (usually cool) temperatures and controlled (usually low) levels of oxygen. These methods are used to create the specific controlled conditions that will support the desirable organisms that produce food fit for human consumption. Fermentation is the microbial conversion of starch and sugars into alcohol. Not only can fermentation produce alcohol, but it can also be a valuable preservation technique. Fermentation can also make foods more nutritious and palatable.\nWater was also turned into alcoholic beverages through fermentation. When water is used to make beer, the boiling during the brewing process may kill bacteria that could make people sick. The barley and other ingredients also infuse the drink with nutrients, and the microorganisms can also produce vitamins as they ferment. However, the common belief that premodern people avoided drinking ordinary water is a myth. While people avoided drinking dirty or polluted water, they also avoided using it for the production of beer and wine. Water was visually inspected, smelled, tasted, filtered, and boiled if necessary. It was used for drinking as well as for diluting wine, cooking, and many other processes.\nFreezing.\nFreezing is also one of the most commonly used processes, both commercially and domestically, for preserving a very wide range of foods, including prepared foods that would not have required freezing in their unprepared state. For example, potato waffles are stored in the freezer, but potatoes themselves require only a cool dark place to ensure many months' storage. Cold stores provide large-volume, long-term storage for strategic food stocks held in case of national emergency in many countries.\nHeating.\nHeating to temperatures which are sufficient to kill microorganisms inside the food is a method used with perpetual stews.\nJellying.\nFood may be preserved by cooking in a material that solidifies to form a gel. Such materials include gelatin, agar, maize flour, and arrowroot flour.\nSome animal flesh forms a protein gel when cooked. Eels and elvers, and sipunculid worms, are a delicacy in Xiamen, China, as are jellied eels in the East End of London, where they are eaten with mashed potatoes. British cuisine has a rich tradition of potted meats. Meat off-cuts were, until the 1950s, preserved in aspic, a gel made from gelatin and clarified meat broth. Another form of preservation is setting the cooked food in a container and covering it with a layer of fat. Potted chicken liver can be prepared in this way, and so can potted shrimps, to be served on toast. Calf's foot jelly used to be prepared for invalids.\nJellying is one of the steps in producing traditional p\u00e2t\u00e9s. Many jugged meats (see below) are also jellied.\nAnother type of jellying is fruit preserves, which are preparations of cooked fruits, vegetables and sugar, often stored in glass jam jars and Mason jars. Many varieties of fruit preserves are made globally, including sweet fruit preserves, such as those made from strawberry or apricot, and savory preserves, such as those made from tomatoes or squash. The ingredients used and how they are prepared determine the type of preserves; jams, jellies, and marmalades are all examples of different styles of fruit preserves that vary based upon the fruit used. In English, the word \"preserves\", in plural form, is used to describe all types of jams and jellies.\n\"Kangina\".\nIn rural Afghanistan, grapes are preserved in disc-shaped vessels made of mud and straw, called \"kangina\". The vessels, which can preserve fresh grapes for up to 6 months, passively control their internal environments to restrict gas exchange and water loss, prolonging the lives of late-harvested grapes stored within them.\nJugging.\nMeat can be preserved by jugging. Jugging is the process of stewing the meat (commonly game or fish) in a covered earthenware jug or casserole. The animal to be jugged is usually cut into pieces, placed into a tightly sealed jug with brine or gravy, and stewed. Red wine and/or the animal's own blood is sometimes added to the cooking liquid. Jugging was a popular method of preserving meat up until the middle of the 20th century.\nLye.\nSodium hydroxide (lye) makes food too alkaline for bacterial growth. Lye will saponify fats in the food, which will change its flavor and texture. Lutefisk uses lye in its preparation, as do some olive recipes. Modern recipes for century eggs also call for lye.\nPickling.\nPickling is a method of preserving food in an edible, antimicrobial liquid. Pickling can be broadly classified into two categories: chemical pickling and fermentation pickling.\nIn chemical pickling, the food is placed in an edible liquid that inhibits or kills bacteria and other microorganisms. Typical pickling agents include brine (high in salt), vinegar, alcohol, and vegetable oil. Many chemical pickling processes also involve heating or boiling so that the food being preserved becomes saturated with the pickling agent. Common chemically pickled foods include cucumbers, peppers, corned beef, herring, and eggs, as well as mixed vegetables such as piccalilli.\nIn fermentation pickling, bacteria in the liquid produce organic acids as preservation agents, typically by a process that produces lactic acid through the presence of lactobacillales. Fermented pickles include sauerkraut, nukazuke, kimchi, and surstr\u00f6mming.\nSugaring.\nThe earliest cultures have used sugar as a preservative, and it was commonplace to store fruit in honey. Similar to pickled foods, sugar cane was brought to Europe through the trade routes. In northern climates without sufficient sun to dry foods, preserves are made by heating the fruit with sugar. \"Sugar tends to draw water from the microbes (plasmolysis). This process leaves the microbial cells dehydrated, thus killing them. In this way, the food will remain safe from microbial spoilage.\" Sugar is used to preserve fruits, either in an antimicrobial syrup with fruit such as apples, pears, peaches, apricots, and plums, or in crystallized form where the preserved material is cooked in sugar to the point of crystallization and the resultant product is then stored dry. This method is used for the skins of citrus fruit (candied peel), angelica, and ginger. Sugaring can be used in the production of jam and jelly.\nModern industrial techniques.\nTechniques of food preservation were developed in research laboratories for commercial applications.\nAseptic processing.\nAseptic processing works by placing sterilized food (typically by heat, see ultra-high temperature processing) into sterlized packaging material under sterile conditions. The result is a sealed, sterile food product similar to canned food, but depending on the technique used, damage to food quality is typically reduced compared to canned food. A greater variety of packaging materials can be used as well.\nBesides UHT, aseptic processing may be used in conjunction with any of the microbe-reduction technologies listed below. With pasteurization and \"high pressure pasteurization\", the food may not be completely sterilized (instead achieving a specified log reduction), but the use of sterile packaging and environments is retained.\nPasteurization.\nPasteurization is a process for preservation of liquid food. It was originally applied to combat the souring of young local wines. Today, the process is mainly applied to dairy products. In this method, milk is heated at about for 15\u201330 seconds to kill the bacteria present in it and cooling it quickly to to prevent the remaining bacteria from growing. The milk is then stored in sterilized bottles or pouches in cold places. This method was invented by Louis Pasteur, a French chemist, in 1862.\nVacuum packing.\nVacuum-packing stores food in a vacuum environment, usually in an air-tight bag or bottle. The vacuum environment strips bacteria of oxygen needed for survival. Vacuum-packing is commonly used for storing nuts to reduce loss of flavor from oxidization. A major drawback to vacuum packaging, at the consumer level, is that vacuum sealing can deform contents and rob certain foods, such as cheese, of its flavor.\nPreservatives.\nPreservative food additives can be \"antimicrobial\" \u2013 which inhibit the growth of bacteria or fungi, including mold \u2013 or \"antioxidant\", such as oxygen absorbers, which inhibit the oxidation of food constituents. Common antimicrobial preservatives include nisin, sorbates, calcium propionate, sodium nitrate/nitrite, sulfites (sulfur dioxide, sodium bisulfite, potassium hydrogen sulfite, etc.), EDTA, hinokitiol, and \u03b5-polylysine. Antioxidants include tocopherols (Vitamin E), butylated hydroxyanisole (BHA) and butylated hydroxytoluene (BHT). Other preservatives include ethanol.\nThere is also another approach of impregnating packaging materials (plastic films or other) with antioxidants and antimicrobials.\nIrradiation.\nIrradiation of food is the exposure of food to ionizing radiation. Multiple types of ionizing radiation can be used, including beta particles (high-energy electrons) and gamma rays (emitted from radioactive sources such as cobalt-60 or cesium-137). Irradiation can kill bacteria, molds, and insect pests, reduce the ripening and spoiling of fruits, and at higher doses induce sterility. The technology may be compared to pasteurization; it is sometimes called \"cold pasteurization\", as the product is not heated. Irradiation may allow lower-quality or contaminated foods to be rendered marketable.\nNational and international expert bodies have declared food irradiation as \"wholesome\"; organizations of the United Nations, such as the World Health Organization and Food and Agriculture Organization, endorse food irradiation. Consumers may have a negative view of irradiated food based on the misconception that such food is radioactive; in fact, irradiated food does not and cannot become radioactive. Activists have also opposed food irradiation for other reasons, for example, arguing that irradiation can be used to sterilize contaminated food without resolving the underlying cause of the contamination. International legislation on whether food may be irradiated or not varies worldwide from no regulation to a full ban.\nApproximately 500,000 tons of food items are irradiated per year worldwide in over 40 countries. These are mainly spices and condiments, with an increasing segment of fresh fruit irradiated for fruit fly quarantine.\nPulsed electric field electroporation.\nPulsed electric field (PEF) electroporation is a method for processing cells by means of brief pulses of a strong electric field. PEF holds potential as a type of low-temperature alternative pasteurization process for sterilizing food products. In PEF processing, a substance is placed between two electrodes, then the pulsed electric field is applied. The electric field enlarges the pores of the cell membranes, which kills the cells and releases their contents. PEF for food processing is a developing technology still being researched. There have been limited industrial applications of PEF processing for the pasteurization of fruit juices. To date, several PEF treated juices are available on the market in Europe. Furthermore, for several years a juice pasteurization application in the US has used PEF. For cell disintegration purposes especially potato processors show great interest in PEF technology as an efficient alternative for their preheaters. Potato applications are already operational in the US and Canada. There are also commercial PEF potato applications in various countries in Europe, as well as in Australia, India, and China.\nModified atmosphere.\nModifying atmosphere is a way to preserve food by operating on the atmosphere around it. It is often used to package:\nNonthermal plasma.\nThis process subjects the surface of food to a \"flame\" of ionized gas molecules, such as helium or nitrogen. This causes micro-organisms to die off on the surface.\nHigh-pressure food preservation.\nHigh pressure can be used to disable harmful microorganisms and spoilage enzymes while retaining the food's fresh appearance, flavor, texture and nutrients. By 2005, the process was being used for products ranging from orange juice to guacamole to deli meats and widely sold. Depending on temperature and pressure settings, HP processing can achieve either pasteurization-equivalent log reduction or go all the way to achieve sterilization of all microbes.\nBiopreservation.\nBiopreservation is the use of natural or controlled microbiota or antimicrobials as a way of preserving food and extending its shelf life. Beneficial bacteria or the fermentation products produced by these bacteria are used in biopreservation to control spoilage and render pathogens inactive in food. It is a benign ecological approach which is gaining increasing attention.\nLactic acid bacteria (LAB) have antagonistic properties that make them particularly useful as biopreservatives. When LABs compete for nutrients, their metabolites often include active antimicrobials such as lactic acid, acetic acid, hydrogen peroxide, and peptide bacteriocins. Some LABs produce the antimicrobial nisin, which is a particularly effective preservative.\nLAB bacteriocins are used in the present day as an integral part of hurdle technology. Using them in combination with other preservative techniques can effectively control spoilage bacteria and other pathogens, and can inhibit the activities of a wide spectrum of organisms, including inherently resistant Gram-negative bacteria.\nHurdle technology.\nHurdle technology is a method of ensuring that pathogens in food products can be eliminated or controlled by combining more than one approach. These approaches can be thought of as \"hurdles\" the pathogen has to overcome if it is to remain active in the food. The right combination of hurdles can ensure all pathogens are eliminated or rendered harmless in the final product.\nHurdle technology has been defined by Leistner (2000) as an intelligent combination of hurdles that secures the microbial safety and stability as well as the organoleptic and nutritional quality and the economic viability of food products. The organoleptic quality of the food refers to its sensory properties, that is its look, taste, smell, and texture.\nExamples of hurdles in a food system are high temperature during processing, low temperature during storage, increasing the acidity, lowering the water activity or redox potential, and the presence of preservatives or biopreservatives. According to the type of pathogens and how risky they are, the intensity of the hurdles can be adjusted individually to meet consumer preferences in an economical way, without sacrificing the safety of the product."}
{"id": "10835", "revid": "9182658", "url": "https://en.wikipedia.org/wiki?curid=10835", "title": "Frequency modulation", "text": "Frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. The technology is used in telecommunications, radio broadcasting, signal processing, and .\nIn analog frequency modulation, such as radio broadcasting, of an audio signal representing voice or music, the instantaneous frequency deviation, i.e. the difference between the frequency of the carrier and its center frequency, has a functional relation to the modulating signal amplitude.\nDigital data can be encoded and transmitted with a type of frequency modulation known as frequency-shift keying (FSK), in which the instantaneous frequency of the carrier is shifted among a set of frequencies. The frequencies may represent digits, such as '0' and '1'. FSK is widely used in computer modems such as fax modems, telephone caller ID systems, garage door openers, and other low-frequency transmissions. Radioteletype also uses FSK.\nFrequency modulation is widely used for FM radio broadcasting. It is also used in telemetry, radar, seismic prospecting, and monitoring newborns for seizures via EEG, two-way radio systems, sound synthesis, magnetic tape-recording systems and some video-transmission systems. In radio transmission, an advantage of frequency modulation is that it has a larger signal-to-noise ratio and therefore rejects radio frequency interference better than an equal power amplitude modulation (AM) signal. For this reason, most music is broadcast over FM radio. \nHowever, under severe enough multipath conditions it performs much more poorly than AM, with distinct high frequency noise artifacts that are audible with lower volumes and less complex tones. With high enough volume and carrier deviation audio distortion starts to occur that otherwise wouldn't be present without multipath or with an AM signal.\nFrequency modulation and phase modulation are the two complementary principal methods of angle modulation; phase modulation is often used as an intermediate step to achieve frequency modulation. These methods contrast with amplitude modulation, in which the amplitude of the carrier wave varies, while the frequency and phase remain constant.\nTheory.\nIf the information to be transmitted (i.e., the baseband signal) is formula_1 and the sinusoidal carrier is formula_2, where \"fc\" is the carrier's base frequency, and \"Ac\" is the carrier's amplitude, the modulator combines the carrier with the baseband data signal to get the transmitted signal: \nwhere formula_4, formula_5 being the sensitivity of the frequency modulator and formula_6 being the amplitude of the modulating signal or baseband signal.\nIn this equation, formula_7 is the \"instantaneous frequency\" of the oscillator and formula_8 is the \"frequency deviation\", which represents the maximum shift away from \"fc\" in one direction, assuming \"x\"\"m\"(\"t\") is limited to the range \u00b11.\nIt is important to realize that this process of integrating the instantaneous frequency to create an instantaneous phase is quite different from what the term \"frequency modulation\" naively implies, namely directly adding the modulating signal to the carrier frequency\nwhich would result in a modulated signal that has spurious local minima and maxima that do not correspond to those of the carrier. \nWhile most of the energy of the signal is contained within \"fc\" \u00b1 \"f\"\u0394, it can be shown by Fourier analysis that a wider range of frequencies is required to precisely represent an FM signal. The frequency spectrum of an actual FM signal has components extending infinitely, although their amplitude decreases and higher-order components are often neglected in practical design problems.\nSinusoidal baseband signal.\nMathematically, a baseband modulating signal may be approximated by a sinusoidal continuous wave signal with a frequency \"fm\". This method is also named as single-tone modulation. The integral of such a signal formula_10 is:\nIn this case, the expression for y(t) above simplifies to:\nwhere the amplitude formula_13 of the modulating sinusoid is represented in the peak deviation formula_4 (see frequency deviation).\nThe harmonic distribution of a sine wave carrier modulated by such a sinusoidal signal can be represented with Bessel functions; this provides the basis for a mathematical understanding of frequency modulation in the frequency domain.\nModulation index.\nAs in other modulation systems, the modulation index indicates by how much the modulated variable varies around its unmodulated level. It relates to variations in the carrier frequency:\nwhere formula_16 is the highest frequency component present in the modulating signal \"x\"\"m\"(\"t\"), and formula_17 is the peak frequency-deviationi.e. the maximum deviation of the \"instantaneous frequency\" from the carrier frequency. For a sine wave modulation, the modulation index is seen to be the ratio of the peak frequency deviation of the carrier wave to the frequency of the modulating sine wave.\nIf formula_18, the modulation is called narrowband FM (NFM), and its bandwidth is approximately formula_19. Sometimes modulation index formula_20\u00a0is considered NFM and other modulation indices are considered wideband FM (WFM or FM).\nFor digital modulation systems, for example, binary frequency shift keying (BFSK), where a binary signal modulates the carrier, the modulation index is given by:\nwhere formula_22 is the symbol period, and formula_23 is used as the highest frequency of the modulating binary waveform by convention, even though it would be more accurate to say it is the highest \"fundamental\" of the modulating binary waveform. In the case of digital modulation, the carrier formula_24 is never transmitted. Rather, one of two frequencies is transmitted, either formula_25 or formula_26, depending on the binary state 0 or 1 of the modulation signal.\nIf formula_27, the modulation is called \"wideband FM\" and its bandwidth is approximately formula_28. While wideband FM uses more bandwidth, it can improve the signal-to-noise ratio significantly; for example, doubling the value of formula_17, while keeping formula_30 constant, results in an eight-fold improvement in the signal-to-noise ratio. (Compare this with chirp spread spectrum, which uses extremely wide frequency deviations to achieve processing gains comparable to traditional, better-known spread-spectrum modes).\nWith a tone-modulated FM\u00a0wave, if the modulation frequency is held constant and the modulation index is increased, the (non-negligible) bandwidth of the FM signal increases but the spacing between spectra remains the same; some spectral components decrease in strength as others increase. If the frequency deviation is held constant and the modulation frequency increased, the spacing between spectra increases.\nFrequency modulation can be classified as narrowband if the change in the carrier frequency is about the same as the signal frequency, or as wideband if the change in the carrier frequency is much higher (modulation index\u00a0&gt;\u00a01) than the signal frequency. For example, narrowband FM (NFM) is used for two-way radio systems such as Family Radio Service, in which the carrier is allowed to deviate only 2.5\u00a0kHz above and below the center frequency with speech signals of no more than 3.5\u00a0kHz bandwidth. Wideband FM is used for FM broadcasting, in which music and speech are transmitted with up to 75\u00a0kHz deviation from the center frequency and carry audio with up to a 20\u00a0kHz bandwidth and subcarriers up to 92\u00a0kHz.\nBessel functions.\nFor the case of a carrier modulated by a single sine wave, the resulting frequency spectrum can be calculated using Bessel functions of the first kind, as a function of the sideband number and the modulation index. The carrier and sideband amplitudes are illustrated for different modulation indices of FM signals. For particular values of the modulation index, the carrier amplitude becomes zero and all the signal power is in the sidebands.\nSince the sidebands are on both sides of the carrier, their count is doubled, and then multiplied by the modulating frequency to find the bandwidth. For example, 3\u00a0kHz deviation modulated by a 2.2\u00a0kHz audio tone produces a modulation index of 1.36. Suppose that we limit ourselves to only those sidebands that have a relative amplitude of at least 0.01. Then, examining the chart shows this modulation index will produce three sidebands. These three sidebands, when doubled, gives us (6 \u00d7 2.2\u00a0kHz) or a 13.2\u00a0kHz required bandwidth.\nCarson's rule.\nA rule of thumb, \"Carson's rule\" states that nearly all (\u224898 percent) of the power of a frequency-modulated signal lies within a bandwidth formula_31 of:\nwhere formula_33, as defined above, is the peak deviation of the instantaneous frequency formula_34 from the center carrier frequency formula_35, formula_36 is the Modulation index which is the ratio of frequency deviation to highest frequency in the modulating signal and formula_16is the highest frequency in the modulating signal.\nCondition for application of Carson's rule is only sinusoidal signals. For non-sinusoidal signals:\nwhere W is the highest frequency in the modulating signal but non-sinusoidal in nature and D is the Deviation ratio which is the ratio of frequency deviation to highest frequency of modulating non-sinusoidal signal.\nNoise reduction.\nFM provides improved signal-to-noise ratio (SNR), as compared for example with AM. Compared with an optimum AM scheme, FM typically has poorer SNR below a certain signal level called the noise threshold, but above a higher level \u2013 the full improvement or full quieting threshold \u2013 the SNR is much improved over AM. The improvement depends on modulation level and deviation. For typical voice communications channels, improvements are typically 5\u201315\u00a0dB. FM broadcasting using wider deviation can achieve even greater improvements. Additional techniques, such as pre-emphasis of higher audio frequencies with corresponding de-emphasis in the receiver, are generally used to improve overall SNR in FM circuits. Since FM signals have constant amplitude, FM receivers normally have limiters that remove AM noise, further improving SNR.\nImplementation.\nModulation.\nFM signals can be generated using either direct or indirect frequency modulation:\nDemodulation.\nMany FM detector circuits exist. A common method for recovering the information signal is through a Foster\u2013Seeley discriminator or ratio detector. A phase-locked loop can be used as an FM demodulator. \"Slope detection\" demodulates an FM signal by using a tuned circuit which has its resonant frequency slightly offset from the carrier. As the frequency rises and falls the tuned circuit provides a changing amplitude of response, converting FM to AM. AM receivers may detect some FM transmissions by this means, although it does not provide an efficient means of detection for FM broadcasts. In Software-Defined Radio implementations the demodulation may be carried out by using the Hilbert transform (implemented as a filter) to recover the instantaneous phase, and thereafter differentiating this phase (using another filter) to recover the instantaneous frequency. Alternatively, a complex mixer followed by a bandpass filter may be used to translate the signal to baseband, and then proceeding as before.\nApplications.\nDoppler effect.\nWhen an echolocating bat approaches a target, its outgoing sounds return as echoes, which are Doppler-shifted upward in frequency. In certain species of bats, which produce constant frequency (CF) echolocation calls, the bats compensate for the Doppler shift by lowering their call frequency as they approach a target. This keeps the returning echo in the same frequency range of the normal echolocation call. This dynamic frequency modulation is called the Doppler Shift Compensation (DSC), and was discovered by Hans Schnitzler in 1968.\nMagnetic tape storage.\nFM is also used at intermediate frequencies by analog VCR systems (including VHS) to record the luminance (black and white) portions of the video signal. Commonly, the chrominance component is recorded as a conventional AM signal, using the higher-frequency FM signal as bias. FM is the only feasible method of recording the luminance (\"black-and-white\") component of video to (and retrieving video from) magnetic tape without distortion; video signals have a large range of frequency components \u2013 from a few hertz to several megahertz, too wide for equalizers to work with due to electronic noise below \u221260\u00a0dB. FM also keeps the tape at saturation level, acting as a form of noise reduction; a limiter can mask variations in playback output, and the FM capture effect removes print-through and pre-echo. A continuous pilot-tone, if added to the signal \u2013 as was done on V2000 and many Hi-band formats \u2013 can keep mechanical jitter under control and assist timebase correction.\nThese FM systems are unusual, in that they have a ratio of carrier to maximum modulation frequency of less than two; contrast this with FM audio broadcasting, where the ratio is around 10,000. Consider, for example, a 6-MHz carrier modulated at a 3.5-MHz rate; by Bessel analysis, the first sidebands are on 9.5 and 2.5\u00a0MHz and the second sidebands are on 13\u00a0MHz and \u22121\u00a0MHz. The result is a reversed-phase sideband on +1\u00a0MHz; on demodulation, this results in unwanted output at 6 \u2013 1 = 5\u00a0MHz. The system must be designed so that this unwanted output is reduced to an acceptable level.\nSound.\nFM is also used at audio frequencies to synthesize sound. This technique, known as FM synthesis, was popularized by early digital synthesizers and became a standard feature in several generations of personal computer sound cards.\nRadio.\nEdwin Howard Armstrong (1890\u20131954) was an American electrical engineer who invented wideband frequency modulation (FM) radio.\nHe patented the regenerative circuit in 1914, the superheterodyne receiver in 1918 and the super-regenerative circuit in 1922. Armstrong presented his paper, \"A Method of Reducing Disturbances in Radio Signaling by a System of Frequency Modulation\", (which first described FM radio) before the New York section of the Institute of Radio Engineers on November 6, 1935. The paper was published in 1936.\nAs the name implies, wideband FM (WFM) requires a wider signal bandwidth than amplitude modulation by an equivalent modulating signal; this also makes the signal more robust against noise and interference. Frequency modulation is also more robust against signal-amplitude-fading phenomena. As a result, FM was chosen as the modulation standard for high frequency, high fidelity radio transmission, hence the term \"FM radio\" (although for many years the BBC called it \"VHF radio\" because commercial FM broadcasting uses part of the VHF bandthe FM broadcast band). FM receivers employ a special detector for FM signals and exhibit a phenomenon known as the \"capture effect\", in which the tuner \"captures\" the stronger of two stations on the same frequency while rejecting the other (compare this with a similar situation on an AM receiver, where both stations can be heard simultaneously). Frequency drift or a lack of selectivity may cause one station to be overtaken by another on an adjacent channel. Frequency drift was a problem in early (or inexpensive) receivers; inadequate selectivity may affect any tuner.\nA wideband FM signal can also be used to carry a stereo signal; this is done with multiplexing and demultiplexing before and after the FM process. The FM modulation and demodulation process is identical in stereo and monaural processes.\nFM is commonly used at VHF radio frequencies for high-fidelity broadcasts of music and speech. In broadcast services, where audio fidelity is important, wideband FM is generally used. Analog TV sound is also broadcast using FM. Narrowband FM is used for voice communications in commercial and amateur radio settings. In two-way radio, narrowband FM (NBFM) is used to conserve bandwidth for land mobile, marine mobile and other radio services.\nA high-efficiency radio-frequency switching amplifier can be used to transmit FM signals (and other constant-amplitude signals). For a given signal strength (measured at the receiver antenna), switching amplifiers use less battery power and typically cost less than a linear amplifier. This gives FM another advantage over other modulation methods requiring linear amplifiers, such as AM and QAM.\nThere are reports that on October 5, 1924, Professor Mikhail A. Bonch-Bruevich, during a scientific and technical conversation in the Nizhny Novgorod Radio Laboratory, reported about his new method of telephony, based on a change in the period of oscillations. Demonstration of frequency modulation was carried out on the laboratory model.\nHearing assistive technology.\nFrequency modulated systems are a widespread and commercially available assistive technology that make speech more understandable by improving the signal-to-noise ratio in the user's ear. They are also called \"auditory trainers\", a term which refers to any sound amplification system not classified as a hearing aid. They intensify signal levels from the source by 15 to 20 decibels. FM systems are used by hearing-impaired people as well as children whose listening is affected by disorders such as auditory processing disorder or ADHD. For people with sensorineural hearing loss, FM systems result in better speech perception than hearing aids. They can be coupled with behind-the-ear hearing aids to allow the user to alternate the setting. FM systems are more convenient and cost-effective than alternatives such as cochlear implants, but many users use FM systems infrequently due to their conspicuousness and need for recharging."}
{"id": "10837", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=10837", "title": "Faith and rationality", "text": "Faith and rationality exist in varying degrees of conflict or compatibility. Rationality is based on reason or facts. Faith is belief in inspiration, revelation, or authority. The word \"faith\" sometimes refers to a belief that is held in spite of or against reason or empirical evidence, or it can refer to belief based upon a degree of evidential warrant.\nRelationship between faith and reason.\nRationalists point out that many people hold irrational beliefs, for many reasons. There may be evolutionary causes for irrational beliefs\u2014irrational beliefs may increase our ability to survive and reproduce.\nOne more reason for irrational beliefs can perhaps be explained by operant conditioning. For example, in one study by B. F. Skinner in 1948, pigeons were awarded grain at regular time intervals regardless of their behaviour. The result was that each of the pigeons developed their own idiosyncratic response which had become associated with the consequence of receiving grain.\nBelievers in the value of faith\u2014for example those who believe salvation is possible through faith alone\u2014frequently suggest that everyone holds beliefs arrived at by faith, not reason.\nOne form of belief held \"by faith\" may be seen existing in a faith as based on warrant. In this view some degree of evidence provides warrant for faith; it consists in other words in \"explain[ing] great things by small.\"\nChristianity.\nCatholic views.\nThomas Aquinas was the first to write a full treatment of the relationship, differences, and similarities between faith, which he calls \"an intellectual assent\", and reason.\n\"Dei Filius\" was a dogmatic constitution of the First Vatican Council on the Roman Catholic faith. It was adopted unanimously on 24 April 1870. It states that \"not only can faith and reason never be opposed to one another, but they are of mutual aid one to the other\".\nRecent popes have spoken about faith and rationality: \"Fides et ratio\", an encyclical letter promulgated by Pope John Paul II on 14 September 1998, deals with the relationship between faith and reason. Pope Benedict XVI's Regensburg lecture, delivered on 12 September 2006, was on the subject of \"faith, reason and the university\".\nReformed views.\nAlvin Plantinga upholds that faith may be the result of evidence testifying to the reliability of the source of truth claims, but although it may involve this, he sees faith as being the result of hearing the truth of the gospel with the internal persuasion by the Holy Spirit moving and enabling him to believe. \"Christian belief is produced in the believer by the internal instigation of the Holy Spirit, endorsing the teachings of Scripture, which is itself divinely inspired by the Holy Spirit. The result of the work of the Holy Spirit is faith.\"\nEvangelical views.\nAmerican biblical scholar Archibald Thomas Robertson stated that the Greek word \"pistis\" used for faith in the New Testament (over two hundred forty times), and rendered \"assurance\" in Acts 17:31 (KJV), is \"an old verb to furnish, used regularly by Demosthenes for bringing forward evidence.\" Likewise Tom Price (Oxford Centre for Christian Apologetics) affirms that when the New Testament talks about faith positively it only uses words derived from the Greek root [pistis] which means \"to be persuaded.\"\nIn contrast to faith meaning blind trust, in the absence of evidence, even in the teeth of evidence, Alister McGrath quotes Oxford Anglican theologian W. H. Griffith-Thomas (1861\u20131924), who states faith is \"not blind, but intelligent\" and \"commences with the conviction of the mind based on adequate evidence\", which McGrath sees as \"a good and reliable definition, synthesizing the core elements of the characteristic Christian understanding of faith.\"\nJewish views.\nThe 14th-century Jewish philosopher Levi ben Gerson tried to reconcile faith and reason. He wrote: \"the Law cannot prevent us from considering to be true that which our reason urges us to believe.\""}
{"id": "10839", "revid": "1168546283", "url": "https://en.wikipedia.org/wiki?curid=10839", "title": "List of film institutes", "text": "Some notable institutions celebrating film, including both national film institutes and independent and non-profit organizations. For the purposes of this list, institutions that do not have their own article on Wikipedia are not considered notable."}
{"id": "10840", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=10840", "title": "FORTH", "text": ""}
{"id": "10841", "revid": "1241601968", "url": "https://en.wikipedia.org/wiki?curid=10841", "title": "Forth", "text": "Forth or FORTH may refer to:\nPeople.\nInvergordon, Scotland"}
{"id": "10842", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=10842", "title": "F wave", "text": "In neuroscience, an F wave is one of several motor responses which may follow the direct motor response (M) evoked by electrical stimulation of peripheral motor or mixed (sensory and motor) nerves. F-waves are the second of two late voltage changes observed after stimulation is applied to the skin surface above the distal region of a nerve, in addition to the H-reflex (Hoffman's Reflex) which is a muscle reaction in response to electrical stimulation of innervating sensory fibers. Traversal of F-waves along the entire length of peripheral nerves between the spinal cord and muscle, allows for assessment of motor nerve conduction between distal stimulation sites in the arm and leg, and related motoneurons (MN's) in the cervical and lumbosacral cord. F-waves are able to assess both afferent and efferent loops of the alpha motor neuron in its entirety. As such, various properties of F-wave motor nerve conduction are analyzed in nerve conduction studies (NCS), and often used to assess polyneuropathies, resulting from states of neuronal demyelination and loss of peripheral axonal integrity.\nWith respect to its nomenclature, the F-wave is so named as it was initially studied in the smaller muscles of the foot. The observation of F-waves in the same motor units (MU) as those present in the direct motor response (M), along with the presence of F-waves in deafferented animal and human models, indicates that F-waves require direct activation of motor axons to be elicited, and do not involve conduction along afferent sensory nerves. Thus, the F-wave is considered a wave, as opposed to a reflex.\nPhysiology.\nF-waves are evoked by strong electrical stimuli (supramaximal) applied to the skin surface above the distal portion of a nerve. This impulse travels both in orthodromic fashion (towards the muscle fibers) and antidromic fashion (towards the cell body in the spinal cord) along the alpha motor neuron. As the orthodromic impulse reaches innervated muscle fibers, a strong direct motor response (M) is evoked in these muscle fibers, resulting in a primary compound muscle action potential (CMAP). As the antidromic impulse reaches the cell bodies within the anterior horn of the motor neuron pool by retrograde transmission, a select portion of these alpha motor neurons, (roughly 5-10% of available motor neurons), 'backfire' or rebound. This antidromic 'backfiring' elicits an orthodromic impulse that follows back down the alpha motor neuron, towards innervated muscle fibers. Conventionally, axonal segments of motor neurons previously depolarized by preceding antidromic impulses enter a hyperpolarized state, disallowing the travel of impulses along them. However, these same axonal segments remains excitable or relatively depolarized for a sufficient period of time, allowing for rapid antidromic backfiring, and thus the continuation of the orthodromic impulse towards innervated muscle fibers. This successive orthodromic stimulus then evokes a smaller population of muscle fibers, resulting in a smaller CMAP known as an F-wave.\nSeveral physiological factors may possibly influence the presence of F-waves after peripheral nerve stimulation. The shape and size of F-waves, along with the probability of their presence is small, as a high degree of variability exists in motor unit (MU) activation for any given stimulation. Thus, the generation of CMAP's which elicit F-waves is subject to the variability in activation of motor units in a given pool over successive stimuli. Moreover, stimulation of peripheral nerve fibers account for both orthodromic impulses (along sensory fibers, towards the dorsal horn), as well as antidromic activity (along alpha motor neurons towards the ventral horn). Antidromic activity along collateral branches of alpha motor neurons may result in the activation of inhibitory Renshaw cells or direct inhibitory collaterals between motorneurons. Inhibition by these means may lower excitability of adjacent motor neurons and decrease the potential for antidromic backfiring and resultant F-waves; although it has been argued Renshaw cells preferentially inhibit smaller alpha motor neurons limited influence on modulation of antidromic backfiring.\nBecause a different population of anterior horn cells is stimulated with each stimulation, F waves are characterized as ubiquitous, low amplitude, late motor responses, which can vary in amplitude, latency and configuration across a series of stimuli.\nProperties.\nF waves can be analyzed by several properties including:\nMeasurements.\nSeveral measurements can be done on the F responses, including:\nThe minimal F wave latency is typically 25-32 ms in the upper extremities and 45-56 ms in the lower extremities.\nF wave persistence is the number of F waves obtained per the number of stimulations, which is normally 80-100% (or above 50%)."}
{"id": "10843", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=10843", "title": "Fruit", "text": "In botany, a fruit is the seed-bearing structure in flowering plants (angiosperms) that is formed from the ovary after flowering (see Fruit anatomy).\nFruits are the means by which angiosperms disseminate their seeds. Edible fruits in particular have long propagated using the movements of humans and other animals in a symbiotic relationship that is the means for seed dispersal for the one group and nutrition for the other; humans, and many other animals, have become dependent on fruits as a source of food. Consequently, fruits account for a substantial fraction of the world's agricultural output, and some (such as the apple and the pomegranate) have acquired extensive cultural and symbolic meanings.\nIn common language and culinary usage, \"fruit\" normally means the seed-associated fleshy structures (or produce) of plants that typically are sweet (or sour) and edible in the raw state, such as apples, bananas, grapes, lemons, oranges, and strawberries. In botanical usage, the term \"fruit\" also includes many structures that are not commonly called as such in everyday language, such as nuts, bean pods, corn kernels, tomatoes, and wheat grains.\nBotanical vs. culinary.\nMany common language terms used for fruit and seeds differ from botanical classifications. For example, in botany, a \"fruit\" is a ripened ovary or carpel that contains seeds, e.g., an orange, pomegranate, tomato or a pumpkin. A \"nut\" is a type of fruit (and not a seed), and a \"seed\" is a ripened ovule.\nIn culinary language, a \"fruit\" is the sweet- or not sweet- (even sour-) tasting produce of a specific plant (e.g., a peach, pear or lemon); \"nuts\" are hard, oily, non-sweet plant produce in shells (hazelnut, acorn). \"Vegetables\", so-called, typically are savory or non-sweet produce (zucchini, lettuce, broccoli, and tomato). but some may be sweet-tasting (sweet potato).\nExamples of botanically classified fruit that are typically called vegetables include cucumber, pumpkin, and squash (all are cucurbits); beans, peanuts, and peas (all legumes); and corn, eggplant, bell pepper (or sweet pepper), and tomato. Many spices are fruits, botanically speaking, including black pepper, chili pepper, cumin and allspice. In contrast, rhubarb is often called a fruit when used in making pies, but the edible produce of rhubarb is actually the leaf stalk or petiole of the plant. Edible gymnosperm seeds are often given fruit names, e.g., ginkgo nuts and pine nuts.\nBotanically, a cereal grain, such as corn, rice, or wheat is a kind of fruit (termed a caryopsis). However, the fruit wall is thin and fused to the seed coat, so almost all the edible grain-fruit is actually a seed.\nStructure.\nThe outer layer, often edible, of most fruits is called the \"pericarp\". Typically formed from the ovary, it surrounds the seeds; in some species, however, other structural tissues contribute to or form the edible portion. The pericarp may be described in three layers from outer to inner, i.e., the \"epicarp\", \"mesocarp\" and \"endocarp\".\nFruit that bears a prominent pointed terminal projection is said to be \"beaked\".\nDevelopment.\nA fruit results from the fertilizing and maturing of one or more flowers. The gynoecium, which contains the \"stigma-style-ovary\" system, is centered in the flower-head, and it forms all or part of the fruit. Inside the ovary(ies) are one or more ovules. Here begins a complex sequence called \"double fertilization\": a female gametophyte produces an egg cell for the purpose of fertilization. (A female gametophyte is called a \"megagametophyte\", and also called the \"embryo sac\".) After double fertilization, the ovules will become seeds.\nOvules are fertilized in a process that starts with pollination, which is the movement of pollen from the stamens to the stigma-style-ovary system within the flower-head. After pollination, a pollen tube grows from the (deposited) pollen through the stigma down the style into the ovary to the ovule. Two sperm are transferred from the pollen to a megagametophyte. Within the megagametophyte, one sperm unites with the egg, forming a zygote, while the second sperm enters the central cell forming the endosperm mother cell, which completes the double fertilization process. Later, the zygote will give rise to the embryo of the seed, and the endosperm mother cell will give rise to endosperm, a nutritive tissue used by the embryo.\nFruit formation is associated with meiosis, a central aspect of sexual reproduction in flowering plants. During meiosis homologous chromosomes replicate, recombine and randomly segregate, and then undergo segregation of sister chromatids to produce haploid cells. Union of haploid nuclei from pollen and ovule (fertilisation), occurring either by self- or cross-pollination, leads to the formation of a diploid zygote that can then develop into an embryo within the emerging seed. Repeated fertilisations within the ovary are accompanied by maturation of the ovary to form the fruit.\nAs the ovules develop into seeds, the ovary begins to ripen and the ovary wall, the \"pericarp\", may become fleshy (as in berries or drupes), or it may form a hard outer covering (as in nuts). In some multi-seeded fruits, the extent to which a fleshy structure develops is proportional to the number of fertilized ovules. The pericarp typically is differentiated into two or three distinct layers; these are called the \"exocarp\" (outer layer, also called epicarp), \"mesocarp\" (middle layer), and \"endocarp\" (inner layer).\nIn some fruits, the sepals, petals, stamens or the style of the flower fall away as the fleshy fruit ripens. However, for simple fruits derived from an \"inferior ovary\" \u2013 i.e., one that lies the attachment of other floral parts \u2013 there are parts (including petals, sepals, and stamens) that fuse with the ovary and ripen with it. For such a case, when floral parts other than the ovary form a significant part of the fruit that develops, it is called an accessory fruit. Examples of accessory fruits include apple, rose hip, strawberry, and pineapple.\nBecause several parts of the flower besides the ovary may contribute to the structure of a fruit, it is important to understand how a particular fruit forms. There are three general modes of fruit development:\nClassification of fruits.\nConsistent with the three modes of fruit development, plant scientists have classified fruits into three main groups: simple fruits, aggregate fruits, and multiple (or composite) fruits. The groupings reflect how the ovary and other flower organs are arranged and how the fruits develop, but they are not evolutionarily relevant as diverse plant taxa may be in the same group.\nWhile the section of a fungus that produces spores is called a \"fruiting\" body, fungi are members of the fungi kingdom and not of the plant kingdom.\nSimple fruits.\nSimple fruits are the result of the ripening-to-fruit of a simple or compound ovary in a \"single flower\" with a \"single pistil\". In contrast, a single flower with numerous pistils typically produces an aggregate fruit; and the merging of several flowers, or a 'multiple' of flowers, results in a 'multiple' fruit. A simple fruit is further classified as either dry or fleshy.\nTo distribute their seeds, dry fruits may split open and discharge their seeds to the winds, which is called dehiscence. Or the distribution process may rely upon the decay and degradation of the fruit to expose the seeds; or it may rely upon the eating of fruit and excreting of seeds by frugivores \u2013 both are called indehiscence. Fleshy fruits do not split open, but they also are indehiscent and they may also rely on frugivores for distribution of their seeds. Typically, the entire outer layer of the ovary wall ripens into a potentially edible pericarp.\nTypes of dry simple fruits, (with examples) include:\nFruits in which part or all of the \"pericarp\" (fruit wall) is fleshy at maturity are termed \"fleshy simple fruits\".\nTypes of fleshy simple fruits, (with examples) include:\nBerries.\nBerries are a type of simple fleshy fruit that issue from a single ovary. (The ovary itself may be compound, with several carpels.) The botanical term \"true berry\" includes grapes, currants, cucumbers, eggplants (aubergines), tomatoes, chili peppers, and bananas, but excludes certain fruits that are called \"-berry\" by culinary custom or by common usage of the term \u2013 such as strawberries and raspberries. Berries may be formed from one or more carpels (i.e., from the simple or compound ovary) from the same, single flower. Seeds typically are embedded in the fleshy interior of the ovary.\nExamples include:\nThe strawberry, regardless of its appearance, is classified as a dry, not a fleshy fruit. Botanically, it is not a berry; it is an aggregate-accessory fruit, the latter term meaning the fleshy part is derived not from the plant's ovaries but from the receptacle that holds the ovaries. Numerous dry achenes are attached to the outside of the fruit-flesh; they appear to be seeds but each is actually an ovary of a flower, with a seed inside.\nSchizocarps are dry fruits, though some appear to be fleshy. They originate from syncarpous ovaries but do not actually dehisce; rather, they split into segments with one or more seeds. They include a number of different forms from a wide range of families, including carrot, parsnip, parsley, cumin.\nAggregate fruits.\nAn aggregate fruit is also called an aggregation, or \"etaerio\"; it develops from a single flower that presents numerous simple pistils. Each pistil contains one carpel; together, they form a fruitlet. The ultimate (fruiting) development of the aggregation of pistils is called an \"aggregate fruit\", \"etaerio fruit\", or simply an \"etaerio\".\nDifferent types of aggregate fruits can produce different etaerios, such as achenes, drupelets, follicles, and berries.\nSome other broadly recognized species and their etaerios (or aggregations) are:\nThe pistils of the raspberry are called \"drupelets\" because each pistil is like a small drupe attached to the receptacle. In some bramble fruits, such as blackberry, the receptacle, an accessory part, elongates and then develops as part of the fruit, making the blackberry an aggregate-accessory fruit. The strawberry is also an aggregate-accessory fruit, of which the seeds are contained in the achenes. Notably in all these examples, the fruit develops from a single flower, with numerous pistils.\nMultiple fruits.\nA multiple fruit is formed from a cluster of flowers, (a 'multiple' of flowers) \u2013 also called an \"inflorescence\". Each ('smallish') flower produces a single fruitlet, which, as all develop, all merge into one mass of fruit. Examples include pineapple, fig, mulberry, Osage orange, and breadfruit. An inflorescence (a cluster) of white flowers, called a head, is produced first. After fertilization, each flower in the cluster develops into a drupe; as the drupes expand, they develop as a \"connate\" organ, merging into a multiple fleshy fruit called a \"syncarp\".\nProgressive stages of multiple flowering and fruit development can be observed on a single branch of the Indian mulberry, or \"noni\". During the sequence of development, a progression of second, third, and more inflorescences are initiated in turn at the head of the branch or stem.\nAccessory fruit forms.\nFruits may incorporate tissues derived from other floral parts besides the ovary, including the receptacle, hypanthium, petals, or sepals. Accessory fruits occur in all three classes of fruit development \u2013 simple, aggregate, and multiple. Accessory fruits are frequently designated by the hyphenated term showing both characters. For example, a pineapple is a multiple-accessory fruit, a blackberry is an aggregate-accessory fruit, and an apple is a simple-accessory fruit.\nSeedless fruits.\nSeedlessness is an important feature of some fruits of commerce. Commercial cultivars of bananas and pineapples are examples of seedless fruits. Some cultivars of citrus fruits (especially grapefruit, mandarin oranges, navel oranges, satsumas), table grapes, and of watermelons are valued for their seedlessness. In some species, seedlessness is the result of \"parthenocarpy\", where fruits set without fertilization. Parthenocarpic fruit-set may (or may not) require pollination, but most seedless citrus fruits require a stimulus from pollination to produce fruit. Seedless bananas and grapes are triploids, and seedlessness results from the abortion of the embryonic plant that is produced by fertilization, a phenomenon known as \"stenospermocarpy\", which requires normal pollination and fertilization.\nSeed dissemination.\nVariations in fruit structures largely depend on the modes of dispersal applied to their seeds. Dispersal is achieved by wind or water, by explosive dehiscence, and by interactions with animals.\nSome fruits present their outer skins or shells coated with spikes or hooked burrs; these evolved either to deter would-be foragers from feeding on them or to serve to attach themselves to the hair, feathers, legs, or clothing of animals, thereby using them as dispersal agents. These plants are termed zoochorous; common examples include cocklebur, unicorn plant, and beggarticks (or Spanish needle).\nBy developments of mutual evolution, the fleshy produce of fruits typically appeals to hungry animals, such that the seeds contained within are taken in, carried away, and later deposited (i.e., defecated) at a distance from the parent plant. Likewise, the nutritious, oily kernels of nuts typically motivate birds and squirrels to hoard them, burying them in soil to retrieve later during the winter of scarcity; thereby, uneaten seeds are sown effectively under natural conditions to germinate and grow a new plant some distance away from the parent.\nOther fruits have evolved flattened and elongated wings or helicopter-like blades, e.g., elm, maple, and tuliptree. This mechanism increases dispersal distance away from the parent via wind. Other wind-dispersed fruit have tiny \"parachutes\", e.g., dandelion, milkweed, salsify.\nCoconut fruits can float thousands of miles in the ocean, thereby spreading their seeds. Other fruits that can disperse via water are nipa palm and screw pine.\nSome fruits have evolved propulsive mechanisms that fling seeds substantial distances \u2013 perhaps up to in the case of the sandbox tree \u2013 via explosive dehiscence or other such mechanisms (see impatiens and squirting cucumber).\nFood uses.\n A large variety of fruits \u2013 fleshy (simple) fruits from apples to berries to watermelon; dry (simple) fruits including beans and rice and coconuts; aggregate fruits including strawberries, raspberries, blackberries, pawpaw; and multiple fruits such as pineapple, fig, mulberries \u2013 are commercially valuable as human food. They are eaten both fresh and as jams, marmalade and other fruit preserves. They are used extensively in manufactured and processed foods (cakes, cookies, baked goods, flavorings, ice cream, yogurt, canned vegetables, frozen vegetables and meals) and beverages such as fruit juices and alcoholic beverages (brandy, fruit beer, wine). Spices like vanilla, black pepper, paprika, and allspice are derived from berries. Olive fruit is pressed for olive oil and similar processing is applied to other oil-bearing fruits and vegetables. Some fruits are available all year round, while others (such as blackberries and apricots in the UK) are subject to seasonal availability.\nFruits are also used for socializing and gift-giving in the form of fruit baskets and fruit bouquets.\nTypically, many botanical fruits \u2013 \"vegetables\" in culinary parlance \u2013 (including tomato, green beans, leaf greens, bell pepper, cucumber, eggplant, okra, pumpkin, squash, zucchini) are bought and sold daily in fresh produce markets and greengroceries and carried back to kitchens, at home or restaurant, for preparation of meals.\nStorage.\nAll fruits benefit from proper post-harvest care, and in many fruits, the plant hormone ethylene causes ripening. Therefore, maintaining most fruits in an efficient cold chain is optimal for post-harvest storage, with the aim of extending and ensuring shelf life.\nNutritional value.\nA meta-analysis of 83 studies showed fruit or vegetable consumption is associated with reduced markers of inflammation (reduced tumor necrosis factor and C-reactive protein) and enhanced immune cell profile (increased gamma delta T cells).\nVarious culinary fruits provide significant amounts of fiber and water, and many are generally high in vitamin C. An overview of numerous studies showed that fruits (e.g., whole apples or whole oranges) are satisfying (filling) by simply eating and chewing them.\nThe dietary fiber consumed in eating fruit promotes satiety, and may help to control body weight and aid reduction of blood cholesterol, a risk factor for cardiovascular diseases. Fruit consumption is under preliminary research for the potential to improve nutrition and affect chronic diseases. Regular consumption of fruit is generally associated with reduced risks of several diseases and functional declines associated with aging.\nFood safety.\nFor food safety, the CDC recommends proper fruit handling and preparation to reduce the risk of food contamination and foodborne illness. Fresh fruits and vegetables should be carefully selected; at the store, they should not be damaged or bruised; and precut pieces should be refrigerated or surrounded by ice.\nAll fruits and vegetables should be rinsed before eating. This recommendation also applies to produce with rinds or skins that are not eaten. It should be done just before preparing or eating to avoid premature spoilage.\nFruits and vegetables should be kept separate from raw foods like meat, poultry, and seafood, as well as from utensils that have come in contact with raw foods. Fruits and vegetables that are not going to be cooked should be thrown away if they have touched raw meat, poultry, seafood, or eggs.\nAll cut, peeled, or cooked fruits and vegetables should be refrigerated within two hours. After a certain time, harmful bacteria may grow on them and increase the risk of foodborne illness.\nAllergies.\nFruit allergies make up about 10 percent of all food-related allergies.\nNonfood uses.\nBecause fruits have been such a major part of the human diet, various cultures have developed many different uses for fruits they do not depend on for food. For example:"}
{"id": "10844", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=10844", "title": "French materialism", "text": "French materialism is the name given to a handful of French 18th-century philosophers during the Age of Enlightenment, many of them clustered around the salon of Baron d'Holbach. Although there are important differences between them, all of them were materialists who believed that the world was made up of a single substance, matter, the motions and properties of which could be used to explain all phenomena. \nProminent French materialists of the 18th century include:"}
{"id": "10845", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=10845", "title": "February", "text": "February is the second month of the year in the Julian and Gregorian calendars. The month has 28 days in common years and 29 in leap years, with the 29th day being called the \"leap day\". \nFebruary is the third and last month of meteorological winter in the Northern Hemisphere. In the Southern Hemisphere, February is the third and last month of meteorological summer, being the seasonal equivalent of August in the Northern Hemisphere.\nPronunciation.\n\"February\" can be pronounced in several different ways. The beginning of the word is commonly pronounced either as or ; many people drop the first \"r\", replacing it with , as if it were spelled \"Febuary\". This comes about by analogy with \"January\" (), as well as by a dissimilation effect whereby having two \"r\"s close to each other causes one to change. The ending of the word is pronounced in the US and in the UK.\nHistory.\nThe Roman month was named after the Latin term , which means \"purification\", via the purification ritual held on February 15 (full moon) in the old lunar Roman calendar. January and February were the last two months to be added to the Roman calendar, since the Romans originally considered winter a monthless period of the year. They were added by Numa Pompilius about 713\u00a0BC. February remained the last month of the calendar year until the time of the decemvirs (), when it became the second month. At certain times February was truncated to 23 or 24 days, and a 27-day intercalary month, Intercalaris, was occasionally inserted immediately after February to realign the year with the seasons.\nFebruary observances in Ancient Rome included Amburbium (precise date unknown), Sementivae (February 2), Februa (February 13\u201315), Lupercalia (February 13\u201315), Parentalia (February 13\u201322), Quirinalia (February 17), Feralia (February 21), Caristia (February 22), Terminalia (February 23), Regifugium (February 24), and Agonium Martiale (February 27). These days do not correspond to the modern Gregorian calendar.\nUnder the reforms that instituted the Julian calendar, Intercalaris was abolished, leap years occurred regularly every fourth year, and in leap years February gained a 29th day. Thereafter, it remained the second month of the calendar year, meaning the order that months are displayed (January, February, March,\u00a0..., December) within a year-at-a-glance calendar. Even during the Middle Ages, when the numbered Anno Domini year began on March 25 or December 25, the second month was February whenever all twelve months were displayed in order. The Gregorian calendar reforms made slight changes to the system for determining which years were leap years, but also contained a 29-day February.\nHistorical names for February include the Old English terms Solmonath (mud month) and Kale-monath (named for cabbage) as well as Charlemagne's designation Hornung. In Finnish, the month is called , meaning \"month of the pearl\"; when snow melts on tree branches, it forms droplets, and as these freeze again, they are like pearls of ice. In Polish and Ukrainian, respectively, the month is called or (), meaning the month of ice or hard frost. In Macedonian the month is (), meaning month of cutting (wood). In Czech, it is called , meaning month of submerging (of river ice).\nIn Slovene, February is traditionally called , related to icicles or Candlemas. This name originates from , written as in the \"New Carniolan Almanac\" from 1775 and changed to its final form by Franc Metelko in his \"New Almanac\" from 1824. The name was also spelled , meaning \"the month of cutting down of trees\". In 1848, a proposal was put forward in \"Kmetijske in rokodelske novice\" by the Slovene Society of Ljubljana to call this month (related to ice melting), but it did not stick. The idea was proposed by a priest, Bla\u017e Poto\u010dnik. Another name of February in Slovene was , after the mythological character Vesna.\nPatterns.\nHaving only 28 days in common years, February is the only month of the year that can pass without a single full moon. Using Coordinated Universal Time as the basis for determining the date and time of a full moon, this last happened in 2018 and will next happen in 2037. The same is true regarding a new moon: again using Coordinated Universal Time as the basis, this last happened in 2014 and will next happen in 2033.\nFebruary is also the only month of the calendar that, at intervals alternating between one of six years and two of eleven years, has exactly four full 7-day weeks. In countries that start their week on a Monday, it occurs as part of a common year starting on Friday, in which February 1st is a Monday and the 28th is a Sunday; the most recent occurrence was 2021, and the next one will be 2027. In countries that start their week on a Sunday, it occurs in a common year starting on Thursday; the most recent occurrence was 2015 and the next occurrence will be 2026. The pattern is broken by a skipped leap year, but no leap year has been skipped since 1900 and no others will be skipped until 2100.\nAstronomy.\nFebruary meteor showers include the Alpha Centaurids (appearing in early February), the March Virginids (lasting from February 14 to April 25, peaking around March 20), the Delta Cancrids (appearing December 14 to February 14, peaking on January 17), the Omicron Centaurids (late January through February, peaking in mid-February), Theta Centaurids (January 23 \u2013 March 12, only visible in the southern hemisphere), Eta Virginids (February 24 and March 27, peaking around March 18), and Pi Virginids (February 13 and April 8, peaking between March 3 and March 9).\nSymbols.\nThe zodiac signs of February are Aquarius (until February 18) and Pisces (February 19 onward).\nIts birth flowers are the violet (\"Viola\"), the common primrose (\"Primula vulgaris\"), and the Iris. Its birthstone is the amethyst, which symbolizes piety, humility, spiritual wisdom, and sincerity.\nObservances.\n\"This list does not necessarily imply either official status nor general observance.\"\nNon-Gregorian.\n\"(All Baha'i, Islamic, and Jewish observances begin at the sundown prior to the date listed, and end at sundown of the date in question unless otherwise noted.)\"\nMovable.\nFirst Saturday\nFirst Sunday \nFirst Week of February (first Monday, ending on Sunday)\nFirst Monday\nFirst Friday \nSecond Saturday \nSecond Sunday\nSecond Monday\nSecond Tuesday \nWeek of February 22 \nThird Monday\nThird Thursday\nThird Friday \nLast Friday\nLast Saturday\nLast day of February"}
{"id": "10846", "revid": "9505858", "url": "https://en.wikipedia.org/wiki?curid=10846", "title": "February 1", "text": ""}
{"id": "10847", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=10847", "title": "First Lady of the United States", "text": "The first lady of the United States (FLOTUS) is a title typically held by the wife of the president of the United States, concurrent with the president's term in office. Although the first lady's role has never been codified or officially defined, she figures prominently in the political and social life of the United States. The first lady of the United States is the hostess of the White House.\nHistorically, when a president has been unmarried or a widower, he has usually asked a relative to act as White House hostess. While the household always had domestic staff, since the early 20th century, the first lady has been assisted by her event staff, which has grown over the years to include communications, personal, and program staff. Her office is now known as the Office of the First Lady and is headquartered in the East Wing of the White House. \nSince the 1900s, the role of first lady has changed considerably. It has come to include involvement in political campaigns, management of the White House, championship of social causes, and representation of the president at official and ceremonial occasions. Additionally, over the years individual first ladies have held influence in a range of sectors, from fashion to public opinion on policy, as well as advocacy for female empowerment.\nOrigins of the title.\nThe use of the title \"First Lady\" to describe the spouse or hostess of an executive began in the United States. In the early days of the republic, there was not a generally accepted title for the wife of the president. Many early first ladies expressed their own preference for how they were addressed, including the use of such titles as \"Lady\", \"Mrs. President\" and \"Mrs. Presidentress\"; Martha Washington was often referred to as \"Lady Washington\". One of the earliest uses of the term \"First Lady\" was applied to her in an 1838 newspaper article that appeared in the \"St. Johnsbury Caledonian\", the author, \"Mrs. Sigourney\", discusses how Martha Washington had not changed, even after her husband George became president. She wrote that \"The first lady of the nation still preserved the habits of early life. Indulging in no indolence, she left the pillow at dawn, and after breakfast, retired to her chamber for an hour for the study of the scriptures and devotion.\"\nAccording to popular belief, Dolley Madison was referred to as first lady in 1849 at her funeral in a eulogy delivered by President Zachary Taylor; however, no written record of this eulogy exists, nor did any of the newspapers of her day refer to her by that title. Sometime after 1849, the title began being used in Washington, D.C., social circles. The first person to have the title applied to her while she was actually holding the office was Harriet Lane, the niece of James Buchanan; \"Leslie's Illustrated Newspaper\" used the phrase to describe her in an 1860 article about her duties as White House hostess. Another of the earliest known written examples comes from a November 3, 1863, diary entry of William Howard Russell, in which he referred to gossip about \"the First Lady in the Land\", referring to Mary Todd Lincoln. The title first gained nationwide recognition in 1877, when newspaper journalist Mary C. Ames referred to Lucy Webb Hayes as \"the First Lady of the Land\" while reporting on the inauguration of Rutherford B. Hayes. The frequent reporting on Lucy Hayes' activities helped spread use of the title outside Washington. A popular 1911 comedic play about Dolley Madison by playwright Charles Nirdlinger, titled \"The First Lady in the Land\", popularized the title further. By the 1930s, it was in wide use. Use of the title later spread from the United States to other nations.\nWhen Edith Wilson took control of her husband's schedule in 1919 after he had a debilitating stroke, one Republican senator labeled her \"the Presidentress who had fulfilled the dream of the suffragettes by changing her title from First Lady to Acting First Man\". According to the Nexis database, the abbreviation FLOTUS (pronounced ) was first used in 1983 by Donnie Radcliffe, writing in \"The Washington Post\".\nNon-spouses in the role.\nSeveral women (at least thirteen) who were not presidents' wives have served as first lady, as when the president was a bachelor or widower, or when the wife of the president was unable to fulfill the duties of the first lady herself. In these cases, the position has been filled by a female relative of the president, such as Jefferson's daughter Martha Jefferson Randolph, Jackson's daughter-in-law Sarah Yorke Jackson and his wife's niece Emily Donelson, Taylor's daughter Mary Elizabeth Bliss, Benjamin Harrison's daughter Mary Harrison McKee, Buchanan's niece Harriet Lane, Chester A. Arthur's sister Mary Arthur McElroy and Cleveland's sister Rose Cleveland.\nPotential male title.\nEach of the 45 presidents of the United States have been males, and all have either had their wives, or a female hostess, assume the role of first lady. Thus, a male equivalent of the title of first lady has never been needed; in 2016, as Hillary Clinton became the first woman to win a major party's presidential nomination, questions were raised as to what her husband Bill would be titled if she were to win the presidency. During the campaign, the title of First Gentleman of the United States was most frequently suggested for Bill Clinton, although as a former president himself, he might have been called \"Mr. President\". In addition, state governors' male spouses are typically called the first gentleman of their respective state (for example, Michael Haley was the first gentleman of South Carolina while his wife, Nikki, served as governor). Ultimately, Hillary Clinton lost the election, rendering this a moot point.\nIn 2021, Kamala Harris took office as vice president, making her husband Doug Emhoff the first male spouse of a nationally elected officeholder. Emhoff assumed the title of Second Gentleman of the United States (\"gentleman\" replacing \"lady\" in the title) making it likely that any future male spouse of a president will be given the title of first gentleman. Harris would later go on to replace President Joe Biden as the Democratic presidential nominee in the 2024 presidential election. Had Harris' presidential campaign been successful, Emhoff would presumably have been granted this title. However, Harris lost the election, again rendering this a moot point.\nRole.\nThe position of the first lady is not an elected one and carries only ceremonial duties. Nonetheless, first ladies have held a highly visible position in American society. The role of the first lady has evolved over the centuries. She is, first and foremost, the hostess of the White House. She organizes and attends official ceremonies and functions of state either along with, or in place of, the president. Lisa Burns identifies four successive main themes of the first ladyship: as public woman (1900\u20131929); as political celebrity (1932\u20131961); as political activist (1964\u20131977); and as political interloper (1980\u20132001).\nMartha Washington created the role and hosted many affairs of state at the national capital (New York and Philadelphia). This socializing became known as the Republican Court and provided elite women with opportunities to play backstage political roles. Both Martha Washington and Abigail Adams were treated as if they were \"ladies\" of the British royal court.\nDolley Madison popularized the first ladyship by engaging in efforts to assist orphans and women, by dressing in elegant fashions and attracting newspaper coverage, and by risking her life to save iconic treasures during the War of 1812. Madison set the standard for the ladyship and her actions were the model for nearly every first lady until Eleanor Roosevelt in the 1930s. Roosevelt traveled widely and spoke to many groups, often voicing personal opinions to the left of the president's. She authored a weekly newspaper column and hosted a radio show. Jacqueline Kennedy led an effort to redecorate and restore the White House.\nMany first ladies became significant fashion trendsetters. Some have exercised a degree of political influence by virtue of being an important advisor to the president.\nOver the course of the 20th century, it became increasingly common for first ladies to select specific causes to promote, usually ones that are not politically divisive. It is common for the first lady to hire a staff to support these activities. Lady Bird Johnson pioneered environmental protection and beautification. Pat Nixon encouraged volunteerism and traveled extensively abroad; Betty Ford supported women's rights; Rosalynn Carter aided those with mental disabilities; Nancy Reagan founded the Just Say No drug awareness campaign; Barbara Bush promoted literacy; Hillary Clinton sought to reform the healthcare system in the U.S.; Laura Bush supported women's rights groups, and encouraged childhood literacy. Michelle Obama became identified with supporting military families and tackling childhood obesity; and Jill Biden focused her support on military families and White House history. The current first lady Melania Trump has used her position to help children, including prevention of cyberbullying and support for those whose lives are affected by drugs.\nSince 1964, the incumbent and all living former first ladies are honorary members of the board of trustees of the National Cultural Center, the John F. Kennedy Center for the Performing Arts.\nNear the end of her husband's presidency, Hillary Clinton became the first first lady to seek political office, when she ran for United States Senate. During the campaign, her daughter Chelsea took over much of the first lady's role. Victorious, Clinton served as junior senator from New York from 2001 to 2009, when she resigned to become President Obama's secretary of state. Later, she was the Democratic Party nominee for president in the 2016 election, but lost to Donald Trump.\nOffice of the First Lady.\nThe Office of the First Lady of the United States is accountable to the first lady for her to carry out her duties as hostess of the White House, and is also in charge of all social and ceremonial events of the White House. The first lady has her own staff that includes a chief of staff, press secretary, White House social secretary, and chief floral designer. The Office of the First Lady is an entity of the White House Office, a branch of the Executive Office of the President. When First Lady Hillary Clinton decided to pursue a run for Senator of New York, she set aside her duties as first lady and moved to Chappaqua, New York, to establish state residency. She resumed her duties as first lady after winning her senatorial campaign, and retained her duties as both first lady and a U.S. senator for the seventeen-day overlap before Bill Clinton's term came to an end.\nCollections.\nEstablished in 1912, the First Ladies Collection has been one of the most popular attractions at the Smithsonian Institution. The original exhibition opened in 1914 and was one of the first at the Smithsonian to prominently feature women. Originally focused largely on fashion, the exhibition now delves deeper into the contributions of first ladies to the and American society. In 2008, \"First Ladies at the Smithsonian\" opened at the National Museum of American History as part of its reopening year celebration. That exhibition served as a bridge to the museum's expanded exhibition on first ladies' history that opened on November 19, 2011. \"The First Ladies\" explores the unofficial but important position of first lady and the ways that different women have shaped the role to make their own contributions to the presidential administrations and the nation. The exhibition features 26 dresses and more than 160 other objects, ranging from those of Martha Washington to Michelle Obama, and includes White House china, personal possessions and other objects from the Smithsonian's unique collection of first ladies' materials.\nInfluence.\nSome first ladies have garnered attention for their dress and style. Jacqueline Kennedy Onassis, for instance, became a global fashion icon: her style was copied by commercial manufacturers and imitated by many young women, and she was named to the International Best Dressed List Hall of Fame in 1965. Mamie Eisenhower was named one of the twelve best-dressed women in the country by the New York Dress Institute every year that she was First Lady. The \"Mamie Look\" involved a full-skirted dress, charm bracelets, pearls, little hats, and bobbed, banged hair. Michelle Obama also received significant attention for her fashion choices: style writer Robin Givhan praised her in \"The Daily Beast\", arguing that the First Lady's style had helped to enhance the public image of the office.\nCauses and initiatives.\nSince the 1920s, many first ladies have become public speakers, adopting specific causes. It also became common for the First Lady to hire a staff to support her agenda. Recent causes of the First Lady are:"}
{"id": "10852", "revid": "45101433", "url": "https://en.wikipedia.org/wiki?curid=10852", "title": "Frank Herbert", "text": "Franklin Patrick Herbert Jr. (October 8, 1920February 11, 1986) was an American science-fiction author, best known for his 1965 novel \"Dune\" and its five sequels. He also wrote short stories and worked as a newspaper journalist, photographer, book reviewer, ecological consultant, and lecturer.\n\"Dune\" is the best-selling science fiction novel of all time, and the series is a classic of the science-fiction genre. The \"Dune\" saga, set in the distant future and taking place over millennia, explores complex themes, such as the long-term survival of the human species, human evolution, planetary science and ecology, and the intersection of religion, politics, economics, sex, and power in a future where humanity has long since developed interstellar travel and colonized many thousands of worlds.\nThe series has been adapted numerous times, including the feature film David Lynch's \"Dune\" (1984), the miniseries \"Frank Herbert's Dune\" (2000) and \"Children of Dune\" (2003), and a motion picture trilogy currently in production, with Denis Villeneuve's \"Dune\" (2021) and \"\" (2024) having been released.\nBiography.\nEarly life.\nFranklin Patrick Herbert Jr. was born on October 8, 1920, in Tacoma, Washington, to Franklin Patrick Herbert Sr. and Eileen (n\u00e9e McCarthy) Herbert. His paternal grandparents had come west in 1905 to join Burley Colony in Kitsap County, one of many utopian communes springing up in Washington State beginning in the 1890s. His upbringing included spending a lot of time on the rural Olympic and Kitsap Peninsulas. He was fascinated by books, could read much of the newspaper before the age of five, had an excellent memory, and learned quickly. He had an early interest in photography, buying a Kodak box camera at age ten, a new folding camera in his early teens, and a color film camera in the mid-1930s. Due to his parents' drinking, he ran away from home with his little sister, 5-year-old Patricia Lou, in 1938 to live with Frank's favorite maternal aunt, Peggy \"Violet\" Rowntree, and her husband, Ken Rowntree, Sr. Within weeks, Patricia moved back home. But Frank, 18, remained with his aunt and uncle.\nEducation.\nHe enrolled in high school at Salem High School (now North Salem High School), where he graduated the next year. In 1939, his parents and sister had moved to Los Angeles, California, so Frank followed them. He lied about his age to get his first newspaper job at the \"Glendale Star\". Herbert then returned to Salem in 1940 where he worked for the \"Oregon Statesman\" newspaper (now \"Statesman Journal\") in a variety of positions, including photographer.\nHerbert married Flora Lillian Parkinson in San Pedro, California, in 1941. They had one daughter, Penelope (b. February 16, 1942), and divorced in 1943. During 1942, after the U.S. entry into World War II, he served in the U.S. Navy's Seabees for six months as a photographer, but suffered a head injury and was given a medical discharge. Herbert subsequently moved to Portland, Oregon where he reported for \"The Oregon Journal\".\nAfter the war, Herbert attended the University of Washington, where he met Beverly Ann Stuart at a creative writing class in 1946. They were the only students who had sold any work for publication; Herbert had sold two pulp adventure stories to magazines, the first to \"Esquire\" in 1945 titled \"Survival of the Cunning\", and Stuart had sold a story to \"Modern Romance\" magazine. They married in Seattle in 1946, and had two sons, Brian (b. 1947) and Bruce (1951\u20131993). In 1949 Herbert and his wife moved to California to work on the Santa Rosa \"Press-Democrat\". Here they befriended the psychologists Ralph and Irene Slattery. The Slatterys introduced Herbert to the work of several thinkers who would influence his writing, including Freud, Jung, Jaspers and Heidegger; they also familiarized Herbert with Zen Buddhism.\nHerbert never graduated from college. According to his son Brian, he wanted to study only what interested him and so did not complete the required curriculum. He returned to journalism and worked at the \"Seattle Star\" and the \"Oregon Statesman\". He was a writer and editor for the \"San Francisco Examiner\" \"California Living\" magazine for a decade.\nEarly career.\nIn a 1973 interview, Herbert stated that he had been reading science fiction \"about ten years\" before he began writing in the genre, and he listed his favorite authors as H. G. Wells, Robert A. Heinlein, Poul Anderson and Jack Vance.\nHerbert's first science fiction story, \"Looking for Something\", was published in the April 1952 issue of \"Startling Stories\", then a monthly edited by Samuel Mines. Three more of his stories appeared in 1954 issues of \"Astounding Science Fiction\" and \"Amazing Stories\". His career as a novelist began in 1955 with the serial publication of \"Under Pressure\" in \"Astounding\" from November 1955; afterward it was issued as a book by Doubleday titled \"The Dragon in the Sea\". The story explored sanity and madness in the environment of a 21st-century submarine and predicted worldwide conflicts over oil consumption and production. It was a critical success but not a major commercial one. During this time Herbert also worked as a speechwriter for Republican senator Guy Cordon.\n\"Dune\".\nHerbert began researching \"Dune\" in 1959. He was able to devote himself wholeheartedly to his writing career because his wife returned to work full-time as an advertising writer for department stores, becoming their breadwinner during the 1960s. The novel \"Dune\" was published in 1965, which spearheaded the \"Dune\" franchise. He later told Willis E. McNelly that the novel originated when he was assigned to write a magazine article about sand dunes in the Oregon Dunes near Florence, Oregon. He got overinvolved and ended up with far more raw material than needed for an article; while the article was never written, it planted in Herbert the seed that would become \"Dune\". Another possible source of inspiration for \"Dune\" was Herbert's purported experiences with psilocybin, according to mycologist Paul Stamets's account, which describes Herbert's hobby of cultivating chanterelles. The biography of Frank Herbert, \"Dreamer of Dune\", written by his son Brian Herbert, confirms that the author was passionate about culinary mushrooms but not his use of psilocybin.\n\"Dune\" took six years of research and writing to complete and was much longer than other commercial science fiction of the time. \"Analog\" (the renamed \"Astounding\", still edited by John W. Campbell) published it in two parts comprising eight installments, \"Dune World\" from December 1963 and \"Prophet of Dune\" in 1965. It was then rejected by nearly twenty book publishers. One editor prophetically wrote, \"I might be making the mistake of the decade, but...\"\nSterling E. Lanier, an editor of Chilton Book Company (known mainly for its auto-repair manuals), had read the Dune serials and offered a $7,500 advance plus future royalties for the rights to publish them as a hardcover book. Herbert rewrote much of his text.\n\"Dune\" was soon a critical success. It won the Nebula Award for Best Novel in 1965 and shared the Hugo Award in 1966 with \"...And Call Me Conrad\" by Roger Zelazny.\n\"Dune\" was not an immediate bestseller, although by 1968 Herbert had made $20,000 from it, far more than most science fiction novels of the time. It was not, however, enough to let him take up full-time writing. The publication of \"Dune\" did open doors for him; he was the \"Seattle Post-Intelligencer\" education writer from 1969 to 1972 and lecturer in general studies and interdisciplinary studies at the University of Washington (1970\u20131972). He worked in Vietnam and Pakistan as a social and ecological consultant in 1972, and in 1973 he was director-photographer of the television show \"The Tillers\".\nBy the end of 1972, Herbert had retired from newspaper writing and became a full-time fiction writer. During the 1970s and 1980s, he enjoyed considerable commercial success as an author. He divided his time between homes in Hawaii and Washington's Olympic Peninsula; his home in Port Townsend on the peninsula was intended to be an \"ecological demonstration project\". During this time he wrote numerous books and pushed ecological and philosophical ideas. He continued his \"Dune\" saga with \"Dune Messiah\" (1969), \"Children of Dune\" (1976), \"God Emperor of Dune\" (1981), \"Heretics of Dune\" (1984) and \"\" (1985). Herbert planned to write a seventh novel to conclude the series, but his death in 1986 left storylines unresolved.\nOther works by Herbert include \"The Godmakers\" (1972), \"The Dosadi Experiment\" (1977), \"The White Plague\" (1982) and the books he wrote in partnership with Bill Ransom: \"The Jesus Incident\" (1979), \"The Lazarus Effect\" (1983) and \"The Ascension Factor\" (1988), which were sequels to Herbert's 1966 novel \"\". He also helped launch the career of Terry Brooks with a very positive review of Brooks' first novel, \"The Sword of Shannara\", in 1977.\nSuccess, family changes, and death.\nHerbert's change in fortune was shadowed by tragedy. In 1974, his wife Beverly underwent treatment for lung cancer. She lived ten more years, but her health was adversely affected by the treatment. In October 1978, Herbert was the featured speaker at the Octocon II science fiction convention held at the El Rancho Tropicana in Santa Rosa, California. In 1979, he met anthropologist Jim Funaro with whom he conceived the Contact Conference. In June 1981, Herbert was a guest of honour at Advention '81 in Adelaide, South Australia. Beverly Herbert died on February 7, 1984. Herbert completed and published \"Heretics of Dune\" that year. In his afterword to 1985's \"\", Herbert included a dedication to Beverly.\nThe year 1984 was a tumultuous year in Herbert's life. During this same year of his wife's death, his career took off with the release of David Lynch's film version of \"Dune\". Despite high expectations, a big-budget production design and an A-list cast, the movie drew mostly poor reviews in the United States. However, despite a disappointing response in the US, the film was a critical and commercial success in Europe and Japan.\nIn 1985, after Beverly's death, Herbert married his former Putnam representative Theresa Shackleford. The same year he published \"Chapterhouse: Dune\", which tied up many of the saga's story threads. This would be Herbert's final single work (the collection \"Eye\" was published that year, and \"Man of Two Worlds\" was published in 1986). He died of a massive pulmonary embolism while recovering from surgery for pancreatic cancer on February 11, 1986, in Madison, Wisconsin, aged 65.\nPolitical views.\nHerbert was a Republican and an environmentalist. His political views have been variously described as conservative, reactionist, and libertarian. Herbert was politically active within the Republican party, and worked as a speechwriter for several politicians, including Senator Guy Cordon. Herbert also volunteered on the campaign of Republican William Bantz in the 1958 Washington Senate election, who unsuccessfully challenged the incumbent Democrat Henry M. Jackson.\nHerbert was a critic of the Soviet Union. He was a distant relative of the Republican senator Joseph McCarthy, whom he referred to as \"Cousin Joe\". However, he was appalled to learn of McCarthy's blacklisting of suspected communists from working in certain careers and believed that he was endangering essential freedoms of citizens of the United States. Herbert also opposed American involvement in the war in Vietnam. He was also critical of welfare, arguing that it increased dependence on the state.\nHerbert believed that governments lie to protect themselves and that, following the Watergate scandal, President Richard Nixon had unwittingly taught an important lesson in not trusting government. He considered Nixon a better president than John F. Kennedy, calling the latter \"one of the most dangerous presidents this country ever had.\" He praised President Ronald Reagan, for his pro-family and pro-individualist stances, while opposing his foreign policy.\nIn \"Chapterhouse: Dune\", he wrote:\nFrank Herbert believed civil service to be \"one of the most serious errors we made as a democracy\" and that bureaucracy negatively impacts the lives of people in all forms of government. He stated that \"every such bureaucracy eventually becomes an aristocracy\" and uses preferential treatment and nepotism in favor of bureaucrats as his main arguments.\nIdeas and themes.\nFrank Herbert used his science fiction novels to explore complex ideas involving philosophy, religion, psychology, politics and ecology. The underlying thrust of his work was a fascination with the question of human survival and evolution. Herbert has attracted a dedicated fan base, many of whom have attempted to read everything he wrote (fiction or non-fiction); indeed, such was the devotion of some of his readers that Herbert was at times asked if he was founding a cult, a proposition which he very much rejected.\nThere are a number of key themes found in Herbert's work:\nFrank Herbert refrained from offering his readers formulaic answers to many of the questions he explored.\nStatus and influence on science fiction.\n\"Dune\" and the \"Dune\" saga constitute one of the world's best-selling science fiction series and novels; \"Dune\" in particular has received widespread critical acclaim, winning the Nebula Award in 1965 and sharing the Hugo Award in 1966, and is frequently considered one of the best science fiction novels ever, if not the best. \"Locus\" subscribers voted it the all-time best SF novel in 1975, again in 1987, and the best \"before 1990\" in 1998.\n\"Dune\" is considered a landmark novel for a number of reasons:\nHerbert never again equalled the critical acclaim he received for \"Dune\". Neither his sequels to \"Dune\" nor any of his other books won a Hugo or Nebula Award, although almost all of them were \"New York Times\" Best Sellers.\nMalcolm Edwards wrote, in \"The Encyclopedia of Science Fiction\":\nThe Science Fiction Hall of Fame inducted Herbert in 2006.\nCalifornia State University, Fullerton's Pollack Library has several of Herbert's draft manuscripts of \"Dune\" and other works, with the author's notes, in their Frank Herbert Archives.\nMetro Parks Tacoma built Dune Peninsula and the Frank Herbert Trail at Point Defiance Park in July 2019 to honor the hometown writer.\nBibliography.\nPosthumously published works.\nBeginning in 2012, Herbert's estate and WordFire Press have released four previously unpublished novels in e-book and paperback formats: \"High-Opp\" (2012), \"Angels' Fall\" (2013), \"A Game of Authors\" (2013), and \"A Thorn in the Bush\" (2014).\nIn recent years, Frank Herbert's son Brian Herbert and author Kevin J. Anderson have added to the \"Dune\" franchise, using notes left behind by Frank Herbert and discovered over a decade after his death. Brian Herbert and Anderson have written three prequel trilogies (\"Prelude to Dune\", \"Legends of Dune\" and \"Great Schools of Dune\") exploring the history of the \"Dune\" universe before the events of the original novel, two novels that take place between novels of the original \"Dune\" sequels (with plans for more), as well as two post-\"Chapterhouse Dune\" novels that complete the original series (\"Hunters of Dune\" and \"Sandworms of Dune\") based on Frank Herbert's own \"Dune 7\" outline."}
{"id": "10853", "revid": "20908161", "url": "https://en.wikipedia.org/wiki?curid=10853", "title": "Fictional language", "text": "Fictional languages are the subset of constructed languages (conlangs) that have been created as part of a fictional setting (e.g. for use in a book, movie, television show, or video game). Typically they are the creation of one individual, while natural languages evolve out of a particular culture or people group, and other conlangs may have group involvement. Fictional languages are also distinct from natural languages in that they have no native speakers. By contrast, the constructed language of Esperanto now has native speakers.\nFictional languages are intended to be the languages of a fictional world and are often designed with the intent of giving more depth, and an appearance of plausibility, to the fictional worlds with which they are associated. The goal of the author may be to have their characters communicate in a fashion which is both alien and dislocated. Within their fictional world, these languages do function as natural languages, helping to identify certain races or people groups and set them apart from others.\nWhile some less-formed fictional languages are created as distorted versions or dialects of a pre-existing natural language, many are independently designed conlangs with their own lexicon (some more robust than others) and rules of grammar. Some of the latter are fully formed enough to be learned as a speakable language, and many subcultures exist of those who are 'fluent' in one or more of these fictional languages. Often after the creator of a fictional language has accomplished their task, the fandom of that fictional universe will pick up where the creator left off and continue to flesh out the language, making it more like a natural language and therefore more usable.\nPurpose.\nFictional languages are separated from artistic languages by both purpose and relative completion: a fictional language often has the least amount of grammar and vocabulary possible, and rarely extends beyond the absolutely necessary. At the same time, some others have developed languages in detail for their own sake, such as J. R. R. Tolkien's Quenya and Sindarin (two Elvish languages), \"Star Trek\"s Klingon language and \"Avatar\"'s Na'vi language which exist as functioning, usable languages.\nBy analogy with the word \"conlang\", the term \"conworld\" is used to describe these fictional worlds, inhabited by fictional constructed cultures. The conworld influences vocabulary (what words the language will have for flora and fauna, articles of clothing, objects of technology, religious concepts, names of places and tribes, etc.), as well as influencing other factors such as pronouns, or how their cultures view the break-off points between colors or the gender and age of family members. Sound is also a directing factor, as creators seek to show their audience through phonology the type of race or people group to whom the language belongs.\nCommercial fictional languages.\nCommercial fictional languages are those languages created for use in various commercial media, such as:\nWhile some languages are created purely from the desire of the creator, language creation can be a profession. In 1974, Victoria Fromkin was the first person hired to create a language (\"Land of the Lost\"'s Paku). Since then, notable professional language creators have included Marc Okrand (Klingon), David Peterson (Dothraki and others in \"Game of Thrones\"), and Paul Frommer (Na'vi).\nAlien languages.\nA notable subgenre of fictional languages are alien languages, the ones that are used or might be used by putative extraterrestrial life forms. Alien languages are subject of both science fiction and scientific research. Perhaps the most fully developed fictional alien language is the Klingon language of the \"Star Trek\" universe \u2013 a fully developed constructed language.\nThe problem of alien language has confronted generations of science fiction writers; some have created fictional languages for their characters to use, while others have circumvented the problem through translation devices or other fantastic technology. For example, the \"Star Trek\" universe makes use of a \"universal translator\", which explains why such different races, often meeting for the first time, are able to communicate with each other. Another more humorous example would be the Babel fish from \"The Hitchhiker's Guide to the Galaxy\", an aurally-inserted fish that instantaneously translates alien speech to the speaker's native language.\nWhile in many cases an alien language is but an element of a fictional reality, in a number of science fiction works the core of the plot involves linguistic and psychological problems of communication between various alien species.\nVisual alien languages.\nA further subgenre of alien languages are those that are visual, rather than auditory. Notable examples of this type are Sherman's Circular Gallifreyan from BBC's \"Doctor Who\" series and the heptapod's written language, which is distinct from their spoken language, from the 2016 film \"Arrival\".\nInternet-based fictional languages.\nInternet-based fictional languages are hosted along with their \"conworlds\" on the internet, and based at these sites, becoming known to the world through the visitors to these sites. Verdurian, the language of Mark Rosenfelder's Verduria on the planet of Almea, is an Internet-based fictional language."}
{"id": "10854", "revid": "24013162", "url": "https://en.wikipedia.org/wiki?curid=10854", "title": "Formula One", "text": "Formula One, commonly abbreviated as F1, is the highest class of international racing for open-wheel single-seater formula racing cars sanctioned by the F\u00e9d\u00e9ration Internationale de l'Automobile (FIA). The FIA Formula One World Championship has been one of the world's premier forms of motorsport since its inaugural running in 1950 and is often considered to be the pinnacle of motorsport. The word \"formula\" in the name refers to the set of rules all participants' cars must follow. A Formula One season consists of a series of races, known as Grands Prix. Grands Prix take place in multiple countries and continents on either purpose-built circuits or closed roads.\nA point-system is used at Grands Prix to determine two annual World Championships: one for the drivers, and one for the constructors\u2014now synonymous with teams. Each driver must hold a valid Super Licence, the highest class of racing licence the FIA issues, and the races must be held on Grade One tracks, the highest grade rating the FIA issues for tracks.\nFormula One cars are the world's fastest regulated road-course racing cars, owing to high cornering speeds achieved by generating large amounts of aerodynamic downforce, much of which is generated by front and rear wings, as well as underbody tunnels. The cars depend on electronics, aerodynamics, suspension, and tyres. Traction control, launch control, automatic shifting, and other electronic driving aids were first banned in . They were briefly reintroduced in , and have more recently been banned since and , respectively.\nWith the average annual cost of running a team\u2014designing, building, and maintaining cars, pay, transport\u2014at approximately million, Formula One's financial and political battles are widely reported. The Formula One Group is owned by Liberty Media, which acquired it in 2017 from private-equity firm CVC Capital Partners for billion.\nHistory.\nFormula One originated from the World Manufacturers' Championship (1925\u20131930) and European Drivers' Championship (1931\u20131939). The \"formula\" is a set of rules that all participants' cars must follow. Formula One was a formula agreed upon in 1946 to officially become effective in 1947. The first Grand Prix in accordance with the new regulations was the 1946 Turin Grand Prix, anticipating the formula's official start. Before World War II, a number of Grand Prix racing organisations made suggestions for a new championship to replace the European Championship, but due to the suspension of racing during the conflict, the new International Formula for cars did not become formalised until 1946, to become effective in 1947. The new World Championship was instituted to commence in 1950.\nThe first world championship race, the 1950 British Grand Prix, took place at Silverstone Circuit in the United Kingdom on 13 May 1950. Giuseppe Farina, competing for Alfa Romeo, won the first Drivers' World Championship, narrowly defeating his teammate Juan Manuel Fangio. Fangio won the championship in , , , , and . This set the record for the most World Championships won by a single driver, a record that stood for 46 years until Michael Schumacher won his sixth championship in 2003.\nA Constructors' Championship was added in the 1958 season. Stirling Moss, despite often being regarded as one of the greatest Formula One drivers in the 1950s and 1960s, never won the Formula One championship. Between 1955 and 1961, Moss finished second in the championship four times and third the other three times. Fangio won 24 of the 52 races he entered\u2014still the record for the highest Formula One winning percentage by an individual driver. National championships existed in South Africa and the UK in the 1960s and 1970s. Promoters held non-championship Formula One events for many years. Due to the increasing cost of competition, the last of these was held in 1983.\nThis era featured teams managed by road-car manufacturers, such as Alfa Romeo, Ferrari, Mercedes-Benz and Maserati. The first seasons featured prewar cars like Alfa Romeo's 158, which were front-engined, with narrow tyres and 1.5-litre supercharged or 4.5-litre naturally aspirated engines. The and seasons were run to Formula Two regulations, for smaller, less powerful cars, due to concerns over the dearth of Formula One cars. When a new Formula One formula for engines limited to 2.5 litres was reinstated for the 1954 world championship, Mercedes-Benz introduced its W196, which featured things never seen on Formula One cars before, such as desmodromic valves, fuel injection, and enclosed streamlined bodywork. Mercedes drivers won the championship for the next two years, before the team withdrew from all motorsport competitions due to the 1955 Le Mans disaster.\nTechnological developments.\nThe first major technological development in the sport was Bugatti's introduction of mid-engined cars. Jack Brabham, the world champion in , , and , soon proved the mid-engine's superiority over all other engine positions. By all teams had switched to mid-engined cars. The Ferguson P99, a four-wheel drive design, was the last front-engined Formula One car to enter a world championship race. It entered the 1961 British Grand Prix, the only front-engined car to compete that year.\nDuring , Lotus introduced a car with an aluminium-sheet monocoque chassis instead of the traditional space-frame design. This proved to be the greatest technological breakthrough since the introduction of mid-engined cars.\nIn , sponsorship was introduced to the sport. Team Gunston became the first team to run cigarette sponsorship on its Brabham cars, which privately entered in orange, brown and gold colours of Gunston cigarettes in the 1968 South African Grand Prix on 1 January 1968. Five months later, the first works team, Lotus, initially using the British racing green, followed this example when it entered its cars painted in the red, gold, and white colours of the Imperial Tobacco's Gold Leaf livery at the 1968 Spanish Grand Prix.\nAerodynamic downforce slowly gained importance in car design with the appearance of aerofoils during the 1968 season. The wings were introduced by Lotus's owner Colin Chapman who installed modest front wings and a rear spoiler on his Lotus 49B at the 1968 Monaco Grand Prix. In the late 1970s, Lotus introduced ground-effect aerodynamics, previously used on Jim Hall's Chaparral 2J in 1970, that provided enormous downforce and greatly increased cornering speeds. The aerodynamic forces pressing the cars to the track were up to five times the car's weight. As a result, extremely stiff springs were needed to maintain a constant ride height, leaving the suspension virtually solid. This meant that the drivers depended entirely on the tyres for any small amount of cushioning of the car and driver from irregularities of the road surface.\nBig business.\nBeginning in the 1970s, Bernie Ecclestone rearranged the management of Formula One's commercial rights; he is widely credited with transforming the sport into the multibillion-dollar business it now is. When Ecclestone bought the Brabham team during 1971, he gained a seat on the Formula One Constructors' Association, and in 1978, he became its president. Previously, the circuit owners controlled the income of the teams and negotiated with each individually; Ecclestone persuaded the teams to \"hunt as a pack\" through FOCA. He offered Formula One to circuit owners as a package they could take or leave. In return for the package, almost all that was required was to surrender trackside advertising.\nThe formation of the F\u00e9d\u00e9ration Internationale du Sport Automobile (FISA) in 1979 set off the FISA\u2013FOCA war, during which FISA and its president Jean-Marie Balestre argued repeatedly with FOCA over television revenues and technical regulations. \"The Guardian\" said that Ecclestone and Max Mosley \"used [FOCA] to wage a guerrilla war with a very long-term aim in view\". FOCA threatened to establish a rival series and boycotted a Grand Prix, and FISA withdrew its sanction from races. The result was the 1981 Concorde Agreement, which guaranteed technical stability, as teams were to be given reasonable notice of new regulations. Although FISA asserted its right to the TV revenues, it gave FOCA the administration of those rights.\nFISA imposed a ban on ground-effect aerodynamics during . But by then, turbocharged engines, which Renault had pioneered in , were producing over and were essential to be competitive. By , a BMW turbocharged engine achieved a flash reading of pressure, estimated to be over in qualifying for the . The next year, power in race trim reached around , with boost pressure limited to only 4.0\u00a0bar. These cars were the most powerful open-wheel circuit racing cars ever. To reduce engine power output and thus speeds, the FIA limited fuel tank capacity in , and boost pressures in , before banning turbocharged engines completely in .\nThe development of electronic driver aids began in the 1980s. Lotus began to develop a system of active suspension, which first appeared during 1983 on the Lotus 92. By 1987, this system had been perfected and was driven to victory by Ayrton Senna in the Monaco Grand Prix that year. In the early 1990s, other teams followed suit and semi-automatic gearboxes and traction control were a natural progression. The FIA, due to complaints that technology was determining races' outcomes more than driver skill, banned many such aids for the season. This resulted in cars that previously depended on electronic aids becoming very \"twitchy\" and difficult to drive. Observers felt the ban on driver aids was in name only, as they \"proved difficult to police effectively\".\nThe teams signed a second Concorde Agreement in 1992 and a third in 1997.\nOn the track, the McLaren and Williams teams dominated the 1980s and 1990s. Brabham was also competitive during the early 1980s, winning two Drivers' Championships with Nelson Piquet. Powered by Porsche, Honda, and Mercedes-Benz, McLaren won 16 championships (seven constructors' and nine drivers') in that period, while Williams used engines from Ford, Honda, and Renault to also win 16 titles (nine constructors' and seven drivers'). The rivalry between racers Ayrton Senna and Alain Prost became F1's central focus during and continued until Prost retired at the end of . Senna died at the 1994 San Marino Grand Prix after crashing into a wall on the exit of the notorious curve Tamburello. The FIA worked to improve the sport's safety standards since that weekend, during which Roland Ratzenberger also died in an accident during Saturday qualifying. No driver died of injuries sustained on the track at the wheel of a Formula One car for 20 years until the 2014 Japanese Grand Prix, where Jules Bianchi collided with a recovery vehicle after aquaplaning off the circuit, dying nine months later from his injuries. Since 1994, three track marshals have died, one at the 2000 Italian Grand Prix, one at the 2001 Australian Grand Prix and one at the 2013 Canadian Grand Prix.\nSince Senna's and Ratzenberger's deaths, the FIA has used safety as a reason to impose rule changes that otherwise, under the Concorde Agreement, would have had to be agreed upon by all the teams\u2014most notably the changes introduced for . This so-called 'narrow track' era resulted in cars with smaller rear tyres, a narrower track overall, and the introduction of grooved tyres to reduce mechanical grip. The objective was to reduce cornering speeds and produce racing similar to rainy conditions by enforcing a smaller contact patch between tyre and track. According to the FIA, this was to reduce cornering speeds in the interest of safety.\nResults were mixed, as the lack of mechanical grip resulted in the more ingenious designers clawing back the deficit with aerodynamic grip. This resulted in pushing more force onto the tyres through wings and aerodynamic devices, which in turn resulted in less overtaking, as these devices tended to make the wake behind the car turbulent or 'dirty'. This prevented other cars from following closely due to their dependence on 'clean' air to make the car stick to the track. The grooved tyres also had the unfortunate side effect of initially being of a harder compound to be able to hold the grooved tread blocks, which resulted in spectacular accidents in times of aerodynamic grip failure, as the harder compound could not grip the track as well.\nDrivers from McLaren, Williams, Renault (formerly Benetton), and Ferrari, dubbed the \"Big Four\", won every World Championship from to . The teams won every Constructors' Championship from to , as well as placing themselves as the top four teams in the Constructors' Championship in every season between and , and winning every race but one (the 1996 Monaco Grand Prix) between and . Due to the technological advances of the 1990s, the cost of competing in Formula One increased dramatically, thus increasing financial burdens. This, combined with the dominance of four teams (largely funded by big car manufacturers such as Mercedes-Benz), caused the poorer independent teams to struggle not only to remain competitive but to stay in business. This effectively forced several teams to withdraw.\nManufacturers' return.\n Michael Schumacher and Ferrari won five consecutive Drivers' Championships (2000\u20132004) and six consecutive Constructors' Championships (1999\u20132004). Schumacher set many new records, including those for Grand Prix wins (91, since beaten by Lewis Hamilton), wins in a season (13, since beaten by Max Verstappen), and most Drivers' Championships (seven, tied with Lewis Hamilton as of 2021). Schumacher's championship streak ended on 25 September 2005, when Renault driver Fernando Alonso became Formula One's youngest champion at that time (until Lewis Hamilton in and followed by Sebastian Vettel in 2010). During 2006, Renault and Alonso won both titles again. Schumacher retired at the end of 2006 after 16 years in Formula One, but came out of retirement for the 2010 season, racing for the newly formed Mercedes works team, following the rebrand of Brawn GP.\nDuring this period, FIA frequently changed the championship rules with the intention of improving the on-track action and cutting costs. Team orders, legal since the championship started during 1950, were banned during 2002, after several incidents in which teams openly manipulated race results, generating negative publicity, most famously by Ferrari at the 2002 Austrian Grand Prix. Other changes included the qualifying format, the point-scoring system, the technical regulations, and rules specifying how long engines and tyres must last. A 'tyre war' between suppliers Michelin and Bridgestone saw lap times fall, although, at the 2005 United States Grand Prix at Indianapolis, seven out of ten teams did not race when their Michelin tyres were deemed unsafe for use, leading to Bridgestone becoming the sole tyre supplier to Formula One for the 2007 season by default. On 20 December 2007 Bridgestone signed a contract that officially made it the exclusive tyre supplier for the next three seasons.\nDuring 2006, Max Mosley outlined a 'green' future for Formula One, in which efficient use of energy would be an important factor.\nStarting in 2000, with Ford's purchase of Stewart Grand Prix to form the Jaguar Racing team, new manufacturer-owned teams entered Formula One for the first time since Alfa Romeo's and Renault's departures in 1985. By 2006, the manufacturer teams\u2014Renault, BMW, Toyota, Honda, and Ferrari\u2014dominated the championship, taking five of the first six places in the Constructors' Championship. The exception was McLaren, which at the time was part-owned by Mercedes-Benz. Through the Grand Prix Manufacturers Association (GPMA), the manufacturers negotiated a larger share of Formula One's commercial profit and a greater say in the running of the sport.\nManufacturers' decline and return of the privateers.\nIn 2008 and 2009, Honda, BMW, and Toyota all withdrew from Formula One racing within a year, blaming the economic recession. This resulted in the end of manufacturer dominance of the sport. The Honda F1 team went through a management buyout to become Brawn GP, with Ross Brawn and Nick Fry running and owning the majority of the organisation. Brawn GP laid off hundreds of employees, but won the year's world championships. BMW F1 was bought out by the original founder of the team, Peter Sauber. The Lotus F1 Team was another, formerly manufacturer-owned team that reverted to \"privateer\" ownership, together with the buy-out of the Renault team by Genii Capital investors. But a link with its previous owners still survived, with its car continuing to be powered by a Renault engine until 2014.\nMcLaren also announced that it was to reacquire the shares in its team from Mercedes-Benz (McLaren's partnership with Mercedes was reported to have started to sour with the McLaren Mercedes SLR road car project and tough F1 championships, which included McLaren being found guilty of spying on Ferrari). Hence, during the 2010 season, Mercedes-Benz reentered the sport as a manufacturer after it purchased Brawn GP and split with McLaren after 15 seasons with the team.\nDuring the season, Formula One was gripped by the FIA\u2013FOTA dispute. FIA President Max Mosley proposed numerous cost-cutting measures for the next season, including an optional budget cap for the teams; teams electing to take the budget cap would be granted greater technical freedom, adjustable front and rear wings, and an engine not subject to a rev limiter. The Formula One Teams Association (FOTA) believed that allowing some teams to have such technical freedom would have created a 'two-tier' championship, and thus requested urgent talks with the FIA. But talks broke down and FOTA teams announced, with the exception of Williams and Force India, that 'they had no choice' but to form a breakaway championship series.\nOn 24 June, Formula One's governing body and the teams reached an agreement to prevent a breakaway series. It was agreed teams must cut spending to the level of the early 1990s within two years; exact figures were not specified, and Max Mosley agreed he would not stand for reelection to the FIA presidency in October. Following further disagreements, after Mosley suggested he would stand for reelection, FOTA made it clear that breakaway plans were still being pursued. On 8 July, FOTA issued a press release stating it had been informed it was not entered for the 2010 season, and an FIA press release said the FOTA representatives had walked out of the meeting. On 1 August, it was announced FIA and FOTA had signed a new Concorde Agreement, bringing an end to the crisis and securing the sport's future until 2012.\nTo compensate for the loss of manufacturer teams, four new teams were accepted entry into the 2010 season ahead of a much anticipated 'cost-cap'. Entrants included a reborn Team Lotus\u2014led by a Malaysian consortium including Tony Fernandes, the boss of Air Asia; Hispania Racing\u2014the first Spanish Formula One team; and Virgin Racing\u2014Richard Branson's entry into the series following a successful partnership with Brawn the year before. They were also joined by the US F1 Team, which planned to run out of the United States as the only non-European-based team in the sport. Financial issues befell the squad before they even made the grid. Despite the entry of these new teams, the proposed cost-cap was repealed and these teams\u2014which did not have the budgets of the midfield and top-order teams\u2014ran around at the back of the field until they collapsed; HRT in 2012, Caterham (formerly Lotus) in 2014 and Manor (formerly Virgin, then Marussia), having survived falling into administration in 2014, at the end of 2016.\nHybrid era.\nA major rule shakeup in saw the 2.4-litre naturally aspirated V8 engines replaced by 1.6-litre turbocharged hybrid power units. This prompted Honda to return to the sport in 2015 as the championship's fourth power unit manufacturer. Mercedes emerged as the dominant force after the rule shakeup, with Lewis Hamilton winning the championship closely followed by his main rival and teammate, Nico Rosberg, with the team winning 16 out of the 19 races that season. The team continued this form in the next two seasons, again winning 16 races in before taking a record 19 wins in 2016, with Hamilton claiming the title in the former year and Rosberg winning it in the latter by five points. The 2016 season also saw a new team, Haas, join the grid, while Max Verstappen became the youngest-ever race winner at age 18 in Spain.\nAfter revised aerodynamic regulations were introduced, the 2017 and 2018 seasons featured a title battle between Mercedes and Ferrari. Mercedes ultimately won the titles with multiple races to spare and continued to dominate in the next two years, eventually winning seven consecutive Drivers' Championships from 2014 to 2020 and eight consecutive Constructors' titles from 2014 to 2021. During this eight-year period between 2014 and 2021, a Mercedes driver won 111 of the 160 races, with Hamilton winning 81 of these and taking six Drivers' Championships during this period to equal Schumacher's record of seven titles. In 2021, the Honda-powered Red Bull team began to seriously challenge Mercedes, with Verstappen beating Hamilton to the Drivers' Championship after a season-long battle that saw the pair exchange the championship lead multiple times.\nThis era has seen an increase in car manufacturer presence in the sport. After Honda's return as an engine manufacturer in 2015, Renault came back as a team in 2016 after buying back the Lotus F1 team. In 2018, Aston Martin and Alfa Romeo became Red Bull and Sauber's title sponsors, respectively. Sauber was rebranded as Alfa Romeo Racing for the 2019 season, while Racing Point part-owner Lawrence Stroll bought a stake in Aston Martin to rebrand the Racing Point team as Aston Martin for 2021. In August 2020, all ten F1 teams signed a new Concorde Agreement committing them to the sport until 2025, including a $145 million budget cap for car development to support equal competition and sustainable development.\nThe COVID-19 pandemic forced the sport to adapt to budgetary and logistical limitations. A significant overhaul of the technical regulations intended to be introduced in the 2021 season was pushed back to 2022, with constructors instead using their 2020 chassis for two seasons and a token system limiting which parts could be modified introduced. The start of the season was delayed by several months, and both it and seasons were subject to several postponements, cancellations, and rescheduling of races due to shifting restrictions on international travel. Many races took place behind closed doors and with only essential personnel present to maintain social distancing.\nIn 2022, the F1 governing body announced a major rule and car design change intended to promote closer racing through the use of ground effects, new aerodynamics, larger wheels with low-profile tyres, and redesigned nose and wing regulations. Red Bull emerged as the dominant force after the rule shakeup. The 2022 and 2023 Constructors' and Drivers' Championships were won by Red Bull and Verstappen, with multiple races to spare.\nIn 2023 the FIA opened applications for new teams to enter Formula 1 in the then near future. Of the teams that applied, only Andretti were approved by the FIA, with them then being rejected by Formula One Management, though they have launched an appeal.\nIn early 2024, the Formula One landscape underwent a significant change in the sphere of team sponsorships and collaborations. Having competed for five seasons under the Alfa Romeo name, Sauber introduced a title partnership with the online casino Stake.com, resulting in the team's new identity as Stake F1 Team Kick Sauber. Sauber will hold Stake's sponsorship name until the end of 2025, after which it will become the Audi works team for the 2026 season onwards. Scuderia AlphaTauri, Red Bull's junior team, dropped its name and took on sponsors from Hugo Boss and Cash App, becoming Visa Cash App RB, or VCARB for 2024. Also in 2024, Formula One announced partnerships with Mattel to release Hot Wheels die-cast cars, and with Lego, with the first new sets releasing in 2025. Previously, Lego sets based on Formula One cars had been released in 2024.\nThe regulations governing Formula One are set to be revised for the 2026 season, with big changes planned to help encourage closer and more competitive racing. \nChanges include: \nIn November 2024, General Motors reached an agreement to enter Formula 1 in 2026 with its Cadillac brand.\nRacing and strategy.\nA Formula One Grand Prix event spans a weekend. It typically begins with two free practice sessions on Friday, and one free practice session on Saturday. Additional drivers (commonly known as third drivers) are allowed to run on Fridays, but only two cars may be used per team, requiring a race driver to give up their seat. A qualifying session is held after the last free practice session. This session determines the starting order for the race on Sunday.\nTyre rules.\nEach driver may use no more than thirteen sets of dry-weather tyres, four sets of intermediate tyres, and three sets of wet-weather tyres during a race weekend.\nQualifying.\nFor much of the sport's history, qualifying sessions differed little from practice sessions; drivers would have one or more sessions in which to set their fastest time, with the grid order determined by each driver's best single lap, with the fastest getting first place on the grid, referred to as pole position. From 1996 to 2002, the format was a one-hour shootout. This approach lasted until the end of 2002 before the rules were changed again because the teams were not running in the early part of the session to take advantage of better track conditions later on.\nGrids were generally limited to 26 cars \u2013 if the race had more entries, qualification would also decide which drivers would start the race. During the early 1990s, the number of entries was so high that the worst-performing teams had to enter a pre-qualifying session, with the fastest cars allowed through to the main qualifying session. The qualifying format began to change in the early 2000s, with the FIA experimenting with limiting the number of laps, determining the aggregate time over two sessions, and allowing each driver only one qualifying lap.\nThe current qualifying system was adopted in the 2006 season. Known as \"knock-out\" qualifying, it is split into three periods, known as Q1, Q2, and Q3. In each period, drivers run qualifying laps to attempt to advance to the next period, with the slowest drivers being \"knocked out\" of qualification (but not necessarily the race) at the end of the period and their grid positions set within the rearmost five based on their best lap times. Drivers are allowed as many laps as they wish within each period. After each period, all times are reset, and only a driver's fastest lap in that period (barring infractions) counts. Any timed lap started before the end of that period may be completed and will count toward that driver's placement. The number of cars eliminated in each period is dependent on the total number of cars entered into the championship.\nCurrently, with 20 cars, Q1 runs for 18 minutes, and eliminates the slowest five drivers. During this period, any driver whose best lap takes longer than 107% of the fastest time in Q1 will not be allowed to start the race without permission from the stewards. Otherwise, all drivers proceed to the race albeit in the worst starting positions. This rule does not affect drivers in Q2 or Q3. In Q2, the 15 remaining drivers have 15 minutes to set one of the ten fastest times and proceed to the next period. Finally, Q3 lasts 12 minutes and sees the remaining ten drivers decide the first ten grid positions. At the beginning of the 2016 Formula 1 season, the FIA introduced a new qualifying format, whereby drivers were knocked out every 90 seconds after a certain amount of time had passed in each session. The aim was to mix up grid positions for the race, but due to unpopularity, the FIA reverted to the above qualifying format for the Chinese GP, after running the format for only two races.\nEach car is allocated one set of the softest tyres for use in Q3. The cars that qualify for Q3 must return them after Q3; the cars that do not qualify for Q3 can use them during the race. As of 2022, all drivers are given a free choice of tyre to use at the start of the Grand Prix, whereas in previous years only the drivers that did not participate in Q3 had free tyre choice for the start of the race. Any penalties that affect grid position are applied at the end of qualifying. Grid penalties can be applied for driving infractions in the previous or current Grand Prix, or for changing a gearbox or engine component. If a car fails scrutineering, the driver will be excluded from qualifying but will be allowed to start the race from the back of the grid at the race stewards' discretion.\n2021 saw the trialling of a 'sprint qualifying' race on the Saturday of three race weekends, with the intention of testing the new approach to qualifying. The traditional qualifying would determine the starting order for the sprint, and the result of the sprint would then determine the start order for the Grand Prix. The system returned for the 2022 season, now titled the 'sprint'. From 2023, sprint races no longer impacted the start order for the main race, which would be determined by traditional qualifying. Sprints would have their own qualifying session, titled the 'sprint shootout'; such a system made its debut at the 2023 Azerbaijan Grand Prix and is set to be used throughout all sprint sessions in place of the traditional second free practice session. Sprint qualifying sessions are run much shorter than traditional qualifying, and each session required teams to fit new tyres \u2013 mediums for SQ1 and SQ2, and softs for SQ3 \u2013 otherwise they cannot participate in the session.\nRace.\nThe race begins with a warm-up lap, after which the cars assemble on the starting grid in the order they qualified. This lap is often referred to as the formation lap, as the cars lap in formation with no overtaking (although a driver who makes a mistake may regain lost ground). The warm-up lap allows drivers to check the condition of the track and their car, gives the tyres a chance to warm up to increase traction and grip, and also gives the pit crews time to clear themselves and their equipment from the grid for the race start.\nOnce all the cars have formed on the grid, after the medical car positions itself behind the pack, a light system above the track indicates the start of the race: five red lights are illuminated at intervals of one second; they are all then extinguished simultaneously after an unspecified time (typically less than 3 seconds) to signal the start of the race. The start procedure may be abandoned if a driver stalls on the grid or on the track in an unsafe position, signalled by raising their arm. If this happens, the procedure restarts: a new formation lap begins with the offending car removed from the grid. The race may also be restarted in the event of a serious accident or dangerous conditions, with the original start voided. The race may be started from behind the Safety Car if race control feels a racing start would be excessively dangerous, such as extremely heavy rainfall. As of the season, there will always be a standing restart. If due to heavy rainfall a start behind the safety car is necessary, then after the track has dried sufficiently, drivers will form up for a standing start. There is no formation lap when races start behind the Safety Car.\nUnder normal circumstances, the winner of the race is the first driver to cross the finish line having completed a set number of laps. Race officials may end the race early (putting out a red flag) due to unsafe conditions such as extreme rainfall, and it must finish within two hours, although races are only likely to last this long in the case of extreme weather or if the safety car is deployed during the race. When a situation justifies pausing the race without terminating it, the red flag is deployed; since 2005, a ten-minute warning is given before the race is resumed behind the safety car, which leads the field for a lap before it returns to the pit lane (before then the race resumed in race order from the penultimate lap before the red flag was shown).\nIn the 1950s, race distances varied from to . The maximum race length was reduced to in 1966 and in 1971. The race length was standardized to the current in 1989. However, street races like Monaco have shorter distances, to keep under the two-hour limit.\nDrivers may overtake one another for position over the course of the race. If a leader comes across a backmarker (slower car) who has completed fewer laps, the back marker is shown a blue flag telling them that they are obliged to allow the leader to overtake them. The slower car is said to be \"lapped\" and, once the leader finishes the race, is classified as finishing the race \"one lap down\". A driver can be lapped numerous times, by any car in front of them. A driver who fails to complete more than 90% of the race distance is shown as \"not classified\" in the results.\nThroughout the race, drivers may make pit stops to change tyres and repair damage (from 1994 to 2009 inclusive, they could also refuel). Different teams and drivers employ different pit stop strategies in order to maximise their car's potential. Three dry tyre compounds, with different durability and adhesion characteristics, are available to drivers. Over the course of a race, drivers must use two of the three available compounds. The different compounds have different levels of performance and choosing when to use which compound is a key tactical decision to make. Different tyres have different colours on their sidewalls; this allows spectators to understand the strategies.\nUnder wet conditions, drivers may switch to one of two specialised wet weather tyres with additional grooves (one \"intermediate\", for mild wet conditions, such as after recent rain, one \"full wet\", for racing in or immediately after rain). A driver must make at least one stop to use two tyre compounds; up to three stops are typically made, although further stops may be necessary to fix damage or if weather conditions change. If rain tyres are used, drivers are no longer obliged to use two types of dry tyres.\nRace director.\nThis role involves managing the logistics of each F1 Grand Prix, inspecting cars in parc ferm\u00e9 before a race, enforcing FIA rules, and controlling the lights which start each race. As the head of the race officials, the race director also plays a large role in resolving disputes among teams and drivers. The race director may also refer incidents to the race stewards, who may give penalties, such as drive-through penalties (or stop-and-go penalties), demotions on a pre-race start grid, race disqualifications and fines should parties break regulations. As of the 2024 Las Vegas Grand Prix, the race director is Rui Marques, with Herbie Blash as a permanent advisor.\nSafety car.\nIn the event of an incident that risks the safety of competitors or trackside race marshals, race officials may choose to deploy the safety car. This in effect suspends the race, with drivers following the safety car around the track at its speed in race order, with no overtaking permitted. Cars that have been lapped may, during the safety car period and depending on circumstances permitted by the race director, be allowed to un-lap themselves in order to ensure a smoother restart and to avoid blue flags being immediately thrown upon the resumption of the race with many of the cars in very close proximity to each other. The safety car circulates until the danger is cleared; after it comes in, the race restarts with a rolling start. Pit stops under a safety car are permitted, and in many cases can offer a great advantage to teams who are able to pit and change tyres prior to the end of the safety car period. On the lap in which the safety car returns to the pit lane, the leading car takes over the role of the safety car until the timing line. After crossing this line, drivers are allowed to start racing for track position once more.\nMercedes-Benz has supplied a variety of its Mercedes-AMG models to Formula One to use as the safety car since 1996. From 2021 onwards, Aston Martin has supplied the Vantage share duties with Mercedes-AMGs.\nSince 2000, the main safety car driver has been German ex-racing driver Bernd Mayl\u00e4nder. He is usually joined by FIA technical assistant Richard Darker, who relays information between the safety car and race control.\nVirtual Safety Car.\nFollowing an accident at the 2014 Japanese Grand Prix, which saw driver Jules Bianchi suffer a serious head injury that led to his death, the FIA established an \"accident panel\" to investigate the dynamics of the accident and ways to minimise the risk of a crash during similar circumstances that do not warrant the deployment of a safety car and cannot be simply managed with yellow flags. When the virtual safety car is deployed, the virtual marshal panels around the track display \"VSC\". All drivers receive a \"VSC\" notice on their steering wheels, and they must all keep their lap times above a pre-determined minimum, also known as keeping a positive delta. The system was first implemented during the 2015 Monaco Grand Prix, before being upgraded to a full safety car, following a collision between Max Verstappen and Romain Grosjean.\nFlags.\nFlags specifications and usage are prescribed by Appendix H of the FIA's International Sporting Code.\nThe format of the race has changed little through Formula One's history. The main changes have revolved around what is allowed at pit stops. In the early days of Grand Prix racing, a driver would be allowed to continue a race in their teammate's car should theirs develop a problem \u2013 in the modern era, cars are so carefully fitted to drivers that this has become impossible. In recent years, the emphasis has been on changing refuelling and tyre change regulations.\nSince the 2010 season, refuelling \u2013 which was reintroduced in 1994 \u2013 has not been allowed, to encourage less tactical racing following safety concerns. The rule requiring both compounds of tyre to be used during the race was introduced in 2007, again to encourage racing on the track. The safety car is another relatively recent innovation that reduced the need to deploy the red flag, allowing races to be completed on time for a growing international live television audience.\nPoints system.\nVarious systems for awarding championship points have been used since 1950. The current system, in place since 2010, awards the top ten cars points in the Drivers' and Constructors' Championships, with the winner receiving 25 points. All points won at each race are added up, and the driver and constructor with the most points at the end of the season are crowned World Champions. Regardless of whether a driver stays with the same team throughout the season, or switches teams, all points earned by them count for the Drivers' Championship.\nA driver must be classified in order to receive points, , a driver must complete at least 90% of the race distance in order to receive points. Therefore, it is possible for a driver to receive points even if they retired before the end of the race.\nFrom some time between the 1977 and 1980 seasons to the end of the 2021 season if less than 75% of the race laps were completed by the winner, then only half of the points listed in the table were awarded to the drivers and constructors. This has happened on only five occasions in the history of the championship, and it had a notable influence on the final standing of the season. The last occurrence was at the 2021 Belgian Grand Prix when the race was called off after just three laps behind a safety car due to torrential rain. The half points rule was replaced by a distance-dependent gradual scale system for 2022.\nConstructors.\nA Formula One constructor is the entity credited for designing the chassis and the engine. If both are designed by the same company, that company receives sole credit as the constructor (e.g., Ferrari). If they are designed by different companies, both are credited, and the name of the chassis designer is placed before that of the engine designer (e.g., ). All constructors are scored individually, even if they share either chassis or engine with another constructor (e.g., Williams-Ford, Williams-Honda in ).\nSince , Formula One teams have been required to build the chassis in which they compete, and consequently the distinction between the terms \"team\" and \"constructor\" became less pronounced, though engines may still be produced by a different entity. This requirement distinguishes the sport from series such as the IndyCar Series which allows teams to purchase chassis, and \"spec series\" such as Formula 2 which require all cars be kept to an identical specification. It also effectively prohibits privateers, which were common even in Formula One well into the 1970s.\nThe sport's debut season, , saw eighteen teams compete, but due to high costs, many dropped out quickly. In fact, such was the scarcity of competitive cars for much of the first decade of Formula One that Formula Two cars were admitted to fill the grids. Ferrari is the oldest Formula One team, the only still-active team which competed in 1950.\nEarly manufacturer involvement came in the form of a \"factory team\" or \"works team\" (that is, one owned and staffed by a major car company), such as those of Alfa Romeo, Ferrari, or Renault. Ferrari holds the record for having won the most Constructors' Championships (sixteen).\nCompanies such as Climax, Repco, Cosworth, Hart, Judd and Supertec, which had no direct team affiliation, often sold engines to teams that could not afford to manufacture them. In the early years, independently owned Formula One teams sometimes also built their engines, though this became less common with the increased involvement of major car manufacturers such as BMW, Ferrari, Honda, Mercedes-Benz, Renault, and Toyota, whose large budgets rendered privately built engines less competitive. Cosworth was the last independent engine supplier. It is estimated the major teams spend between \u20ac100 and \u20ac200\u00a0million ($125\u2013$225\u00a0million) per year per manufacturer on engines alone.\nIn the 2007 season, for the first time since the 1981 rule, two teams used chassis built by other teams. Super Aguri started the season using a modified Honda Racing RA106 chassis (used by Honda the previous year), while Scuderia Toro Rosso used the same chassis used by the parent Red Bull Racing team, which was formally designed by a separate subsidiary. The usage of these loopholes was ended for 2010 with the publication of new technical regulations, which require each constructor to own the intellectual property rights to their chassis, The regulations continue to allow a team to subcontract the design and construction of the chassis to a third-party, an option used by the HRT team in 2010 and Haas currently.\nAlthough teams rarely disclose information about their budgets, it is estimated they range from US$66\u00a0million to US$400\u00a0million each.\nEntering a new team in the Formula One World Championship requires a $200\u00a0million up-front payment to the FIA, which is then shared equally among the existing teams. As a consequence, constructors desiring to enter Formula One often prefer to buy an existing team: BAR's purchase of Tyrrell and Midland's purchase of Jordan allowed both of these teams to sidestep the large deposit and secure the benefits the team already had, such as TV revenue.\nSeven out of the ten teams competing in Formula One are based close to London in an area centred around Oxford. Ferrari have both their chassis and engine assembly in Maranello, Italy. The RB Formula One Team is based close to Ferrari in Faenza, whilst Sauber Motorsport is based near Zurich in Switzerland.\nDrivers.\nEvery team in Formula One must run two cars in every session in a Grand Prix weekend, and every team may use up to four drivers in a season. A team may also run two additional drivers in Free Practice sessions, which are often used to test potential new drivers for a career as a Formula One driver or gain experienced drivers to evaluate the car. Most drivers are contracted for at least the duration of a season, with driver changes taking place in-between seasons, in comparison to early years when drivers often competed on an ad hoc basis from race to race. Each competitor must be in the possession of a FIA Super Licence to compete in a Grand Prix, which is issued to drivers who have met the criteria of success in junior motorsport categories and having achieved of running in a Formula One car. Drivers may also be issued a Super Licence by the World Motor Sport Council if they fail to meet the criteria. Although most drivers earn their seat on ability, commercial considerations also come into play with teams having to satisfy sponsors and financial demands.\nTeams also contract test and reserve drivers to stand in for regular drivers when necessary and develop the team's car; although with the reduction on testing the reserve drivers' role mainly takes places on a simulator, such as rFactor Pro, which is used by most of the F1 teams.\nEach driver chooses an unassigned number from 2 to 99 (excluding 17 which was retired following the death of Jules Bianchi) upon entering Formula One and keeps that number during their time in the series. The number one is reserved for the reigning Drivers' Champion, who retains their previous number and may choose to use it instead of the number one. At the onset of the championship, numbers were allocated by race organisers on an ad hoc basis from race to race.\nPermanent numbers were introduced in to take effect in , when teams were allocated numbers in ascending order based on the Constructors' Championship standings at the end of the 1973 season. The teams would hold those numbers from season to season with the exception of the team with the World Drivers' Champion, which would swap its numbers with the one and two of the previous champion's team. New entrants were allocated spare numbers, with the exception of the number 13 which had been unused since .\nAs teams kept their numbers for long periods of time, car numbers became associated with a team, such as Ferrari's 27 and 28. A different system was used from to : at the start of each season, the current Drivers' Champion was designated number one, their teammate number two, and the rest of the teams assigned ascending numbers according to previous season's Constructors' Championship order.\n, a total of 34 separate drivers have won the World Drivers' Championship, with Michael Schumacher and Lewis Hamilton holding the record for most championships with seven. Lewis Hamilton achieved the most race wins, too, in 2020. Jochen Rindt is the only posthumous World Champion, after his points total was not surpassed despite his fatal accident at the 1970 Italian Grand Prix, with 4 races still remaining in the season. Drivers from the United Kingdom have been the most successful in the sport, with 20 championships among 10 drivers, and wins.\nPhysical demands.\nDriving in Formula One is highly demanding physically, with drivers typically burning around 1,000 calories per hour and losing of weight per race. A key reason for the physical demands is the extreme g-forces generated by driving at high speeds, with modern Formula One cars capable of generating forces of up to 6.5 \"g\"s when cornering, 6 \"g\"s when braking and 2 \"g\"s when accelerating. When a driver experiences 6 \"g\", they will feel a force equivalent to six times their body weight; for a person weighing , this would be . Another factor is the high temperature inside the car, as the engine is mounted directly behind the driver. The temperature in the cockpit of a Formula One car can be as high as and drivers have to wear several layers of fireproof racing clothing. The steering wheel and brake pedal also require considerable strength to operate. Before the introduction of power steering in the 2000s, drivers had to cope with steering forces of up to , while achieving maximum braking power requires drivers to apply around of force to the brake pedal. Drivers also need to be light, as every extra kilogram of weight noticeably reduces performance. Drivers also need to train on cardiovascular fitness since heart rates can average more than 170 bpm during a race, this is more than a healthy adult would typically experience while running.\nFeeder series.\nMost F1 drivers start in kart racing competitions and then come up through traditional European single-seater series like Formula Ford and Formula Renault to Formula 3, and finally the GP2 Series. GP2 started in 2005, replacing Formula 3000, which itself had replaced Formula Two as the last major stepping-stone into F1. GP2 was rebranded as the FIA Formula 2 Championship in 2017. Most champions from this level graduate into F1, but 2006 GP2 champion Lewis Hamilton became the first F2, F3000 or GP2 champion to win the Formula One drivers' title in 2008.\nDrivers are not required to have competed at this level before entering Formula One. British F3 has supplied many F1 drivers, with champions, including Nigel Mansell, Ayrton Senna and Mika H\u00e4kkinen having moved straight from that series to Formula One, and Max Verstappen made his F1 debut following a single season in European F3. More rarely a driver may be picked from an even lower level, as was the case with 2007 World Champion Kimi R\u00e4ikk\u00f6nen, who went straight from Formula Renault to F1.\nAmerican open-wheel car racing has also contributed to the Formula One grid. CART champions Mario Andretti and Jacques Villeneuve became F1 World Champions, while Juan Pablo Montoya won seven races in F1. Other CART (also known as ChampCar) champions, like Michael Andretti and Alessandro Zanardi won no races in F1. Other drivers have taken different paths to F1; Damon Hill raced motorbikes, and Michael Schumacher raced in sports cars, albeit after climbing through the junior single-seater ranks. Former F1 driver Paul di Resta raced in DTM until he was signed with Force India in 2011.\nGrands Prix.\nThe number of Grands Prix held in a season has varied over the years. The inaugural World Championship season comprised only seven races, while the season contained 24 races, the highest number of World Championship races in one season. There were no more than 11 Grands Prix per season during the early decades of the championship, although a large number of non-championship Formula One events also took place. The number of Grands Prix increased to an average of 16 to 17 by the late 1970s, while non-championship events ended in 1983. More Grands Prix began to be held in the 2000s, and recent seasons have seen an average of 21 races. \nSix of the original seven races took place in Europe; the only non-European race that counted towards the World Championship in 1950 was the Indianapolis 500, which was held to different regulations and later replaced by the United States Grand Prix. The F1 championship gradually expanded to other non-European countries. Argentina hosted the first South American Grand Prix in , and Morocco hosted the first African World Championship race in . Asia and Oceania followed (Japan in and Australia in ), and the first race in the Middle East was held in . The 19 races of the season were spread over every populated continent except for Africa, with 10 Grands Prix held outside Europe.\nSome of the Grands Prix pre-date the formation of the World Championship, such as the French Grand Prix and were incorporated into the championship as Formula One races in 1950. The British and Italian Grands Prix are the only events to have been held every Formula One season; other long-running races include the Belgian, German, and French Grands Prix. The Monaco Grand Prix was first held in 1929 and has run continuously since 1955 (with the exception of 2020) and is widely considered to be one of the most important and prestigious automobile races in the world.\nAll Grands Prix have traditionally been run during the day, until the inaugural hosted the first Formula One night race in 2008, which was followed by the day\u2013night Abu Dhabi Grand Prix in 2009 and the Bahrain Grand Prix which converted to a night race in 2014. Other Grands Prix in Asia have had their start times adjusted to benefit the European television audience.\nContracted Grands Prix.\nThe following twenty-four Grands Prix, all of which appeared on the schedule, have a contract to be hosted at the listed circuits for the 2025 season:\u00a0\nReturning additions (2008\u2013present).\nBold denotes the Grands Prix scheduled as part of the season.\nNew Locations Initiative (2008\u2013present).\nBold denotes the Grands Prix scheduled as part of the season.\nSince 2008, the Formula One Group has been targeting new \"destination cities\" to expand its global reach, with the aim to produce races from countries that have not previously been involved in the sport. This initiative started with the 2008 Singapore Grand Prix.\nCircuits.\nFormula One races must be held on Grade One tracks, the highest grade-rating issued by the FIA for tracks. The layout and lap distance of each circuit can vary significantly as long as they stay within the FIA's regulations. In most cases, the tracks run in a clockwise direction, although there are a handful of tracks in the Championship that run anticlockwise.\nA typical circuit features a stretch of straight road on which the starting grid is situated, with the pit lane normally located right next to it. The pit lane is home to each team's garage, where cars are stored and serviced before a race. During a pit stop, drivers enter the pit lane to change their tyres, receive repairs or aerodynamic adjustments from their pit crew, or retire from the race (if the car is in a condition to do so). Prior to the 2010 season, pit stops also facilitated mid-race refueling of the cars. Special pit roads and track markings help to make sure drivers pit and rejoin the track safely.\nMost of the circuits currently in use are specially constructed for competition, but the calendar also features several circuits that use converted public streets to varying degrees. These tracks include Monaco, Melbourne, Singapore, Baku, Miami, Jeddah, and Las Vegas. Three-time World champion Nelson Piquet famously described racing in Monaco as \"like riding a bicycle around your living room\". The Monaco Grand Prix holds a unique exception to the FIA's minimum race distance requirement\u2014the Grand Prix only needs to last enough laps to cover a distance of 260\u00a0km, versus the standard 305\u00a0km.\nCircuit design to protect the safety of drivers is becoming increasingly sophisticated, as exemplified by the Bahrain International Circuit, added in and designed \u2013 like most of F1's new circuits \u2013 by Hermann Tilke. Several of the new circuits in F1, especially those designed by Tilke, have been criticised as lacking the \"flow\" of such classics as Spa-Francorchamps and Imola. His redesign of the Hockenheim circuit in Germany for example, while providing more capacity for grandstands and eliminating extremely long and dangerous straights, has been frowned upon by many who argue that part of the character of the Hockenheim circuits was the long and blinding straights into dark forest sections. These newer circuits, however, are generally agreed to meet the safety standards of modern Formula One better than the older ones.\nThe Circuit of the Americas in Austin, the Sochi Autodrom in Sochi and the Baku City Circuit in Azerbaijan have all been introduced as brand new tracks since 2012. In 2020, Algarve International Circuit debuted on the F1 calendar as the venue of the Portuguese Grand Prix, with the country having last hosted a race in 1996. In 2021, Circuit Zandvoort returned to the F1 calendar as the Dutch Grand Prix, having last hosted a race in 1985. The Las Vegas Grand Prix entered the sport in 2023.\nCars and technology.\nModern Formula One cars are mid-engined, hybrid, semi-open cockpit, open-wheel single-seaters. The chassis is made largely of carbon-fibre composites, rendering it light but extremely stiff and strong. The whole car, including the driver but not fuel, weighs only \u2013 the minimum weight set by the regulations. If the construction of the car is lighter than the minimum, it can be ballasted up to add the necessary weight. The race teams take advantage of this by placing this ballast at the extreme bottom of the chassis, thereby locating the centre of gravity as low as possible in order to improve handling and weight transfer.\nThe cornering speed of Formula One cars is largely determined by the aerodynamic downforce that they generate, which pushes the car down onto the track. This is provided by \"wings\" mounted at the front and rear of the vehicle, and by ground effect created by low air pressure under the flat bottom of the car. The aerodynamic design of the cars is very heavily constrained to limit performance. The previous generation of cars sported a large number of small winglets, \"barge boards\", and turning vanes designed to closely control the flow of the air over, under, and around the car.\nThe other major factor controlling the cornering speed of the cars is the design of the tyres. From to , the tyres in Formula One were not \"slicks\" (tyres with no tread pattern) as in most other circuit racing series. Instead, each tyre had four large circumferential grooves on its surface designed to limit the cornering speed of the cars. Slick tyres returned to Formula One in the season. Suspension is double wishbone or multilink front and rear, with pushrod operated springs and dampers on the chassis \u2013 one exception being that of the 2009 specification Red Bull Racing car (RB5) which used pullrod suspension at the rear, the first car to do so since the Minardi PS01 in 2001. Ferrari used a pullrod suspension at both the front and rear in their car. Both Ferrari (F138) and McLaren (MP4-28) of the 2013 season used a pullrod suspension at both the front and the rear. In , McLaren (MCL36) and Red Bull Racing (RB18) switched to a pullrod front suspension and push rod rear suspension.\nCarbon-carbon disc brakes are used for reduced weight and increased frictional performance. These provide a very high level of braking performance and are usually the element that provokes the greatest reaction from drivers new to the formula. The carbon material enhances the brakes by maintaining an effective performance under extreme heat. To optimise this, the brakes feature 1,000 ventilation holes, ensuring for maximum performance and cooling.\nIn , the technical regulations changed considerably in order to reduce the turbulence (commonly referred to as \"dirty air\") produced by the aerodynamics of the car. This includes a redesigned front and rear wing, larger wheels with a lower tyre profile, wheel covers, small winglets, the banning of barge boards, and the reintroduction of Ground effect downforce production. These have been changed to promote racing, meaning cars lose less downforce when following another car. It allows cars to follow another at a much closer distance, without extending the gap due to the turbulent air. (See 2022 Formula One World Championship Technical regulations)\nFormula One cars must have four wheels made of the same metallic material, which must be one of two magnesium alloys specified by the FIA. Magnesium alloy wheels made by forging are used to achieve maximum unsprung rotating weight reduction. As of 2022, the wheels are covered with \"spec\" (Standardised) Wheel Covers, the wheel diameter has increased from 13 inches to 18 inches (reducing the \"tyre profile\"), and small winglets have been placed over the front tyres.\nStarting with the 2014 Formula 1 season, the engines have changed from a 2.4-litre naturally aspirated V8 to turbocharged 1.6-litre V6 power-units. These get a significant amount of their power from electric motors. In addition, they include a lot of energy recovery technology. Engines run on unleaded fuel closely resembling publicly available petrol. The oil which lubricates and protects the engine from overheating is very similar in viscosity to water. The 2006 generation of engines spun up to 20,000\u00a0rpm and produced over . For , engines were restricted to 19,000\u00a0rpm with limited development areas allowed, following the engine specification freeze since the end of . For the 2009 Formula One season the engines were further restricted to 18,000\u00a0rpm.\nA wide variety of technologies \u2013 including active suspension are banned under the current regulations. Despite this the current generation of cars can reach speeds in excess of at some circuits. The highest straight line speed recorded during a Grand Prix was , set by Juan Pablo Montoya during the 2005 Italian Grand Prix. During qualifying for the 2016 European Grand Prix, Valtteri Bottas set a record top speed of 378\u00a0km/h (234.9\u00a0mph). A BAR-Honda Formula One car, running with minimum downforce on a runway in the Mojave Desert achieved a top speed of in 2006. According to Honda, the car fully met the FIA Formula One regulations.\nEven with the limitations on aerodynamics, at aerodynamically generated downforce is equal to the weight of the car, and the oft-repeated claim that Formula One cars create enough downforce to \"drive on the ceiling\", while possible in principle, has never been put to the test. Downforce of 2.5 times the car's weight can be achieved at full speed. The downforce means that the cars can achieve a lateral force with a magnitude of up to 3.5 times that of the force of gravity (3.5g) in cornering. Consequently, the driver's head is pulled sideways with a force equivalent to the weight of 20\u00a0kg in corners. Such high lateral forces are enough to make breathing difficult and the drivers need supreme concentration and fitness to maintain their focus for the one to two hours that it takes to complete the race. A high-performance road car like the Enzo Ferrari only achieves around 1g.\n, each team may have no more than two cars available for use at any time. Each driver may use no more than four engines during a championship season unless they drive for more than one team. If more engines are used, they drop ten places on the starting grid of the event at which an additional engine is used. The only exception is where the engine is provided by a manufacturer or supplier taking part in its first championship season, in which case up to five may be used by a driver. Each driver may use no more than one gearbox for six consecutive events; every unscheduled gearbox change requires the driver to drop five places on the grid unless they failed to finish the previous race due to reasons beyond the team's control.\n, each driver is limited to three power units per season, before incurring grid penalties.\nRevenue and profits.\nIn March 2007, \"F1 Racing\" published its annual estimates of spending by Formula One teams. The total spending of all eleven teams in 2006 was estimated at $2.9\u00a0billion US. This was broken down as follows: Toyota $418.5\u00a0million, Ferrari $406.5\u00a0m, McLaren $402\u00a0m, Honda $380.5\u00a0m, BMW Sauber $355\u00a0m, Renault $324\u00a0m, Red Bull $252\u00a0m, Williams $195.5\u00a0m, Midland F1/Spyker-MF1 $120\u00a0m, Toro Rosso $75\u00a0m, and Super Aguri $57\u00a0million.\nCosts vary greatly from team to team. Honda, Toyota, McLaren-Mercedes, and Ferrari were estimated to have spent approximately $200\u00a0million on engines in 2006, Renault spent approximately $125\u00a0million and Cosworth's 2006 V8 was developed for $15\u00a0million. In contrast to the 2006 season on which these figures are based, the 2007 sporting regulations banned all performance-related engine development.\nFormula One teams pay entry fees of $500,000, plus $5,000 per point scored the previous year or $6,000 per point for the winner of the Constructors' Championship. Formula One drivers pay a FIA Super Licence fee, which in 2013 was \u20ac10,000 plus \u20ac1,000 per point.\nThere have been controversies with the way profits are shared among the teams. The smaller teams have complained that the profits are unevenly shared, favouring established top teams. In September 2015, Force India and Sauber officially lodged a complaint with the European Union against Formula One questioning the governance and stating that the system of dividing revenues and determining the rules is unfair and unlawful.\nThe cost of building a brand-new permanent circuit can be up to hundreds of millions of dollars, while the cost of converting a public road, such as Albert Park, into a temporary circuit is much less. Permanent circuits, however, can generate revenue all year round from leasing the track for private races and other races, such as MotoGP. The Shanghai International Circuit cost over $300\u00a0million and the Istanbul Park circuit cost $150\u00a0million to build.\nA number of Formula One drivers earn the highest salary of any drivers in auto racing. The highest-paid driver in 2021 is Lewis Hamilton, who received $55\u00a0million in salary from Mercedes AMG Petronas F1 \u2013 a record for any driver. The very top Formula One drivers get paid more than IndyCar or NASCAR drivers; however, the earnings immediately fall off after the top three F1 drivers, and the majority of NASCAR racers will make more money than their F1 counterparts. Most top IndyCar drivers are paid around a tenth of their Formula One counterparts.\nIn the second quarter of 2020, Formula One reported a loss revenue of $122\u00a0million and an income of $24\u00a0million. This was a result of the delay of the racing championship start as a result of the COVID-19 pandemic. The company grossed revenues of $620\u00a0million for the same quarter the previous year.\nCost cap.\nSince the beginning of Formula 1 back in 1950, the sport's governing body has not had any regulations limiting the spending of a team. This has led to a pattern where teams with large budgets perform significantly better than their competitors and the gap has only continued to increase.\nFor instance, in 2019, the richest teams such as Mercedes and Ferrari spent $420 million and $435 million respectively, whereas teams such as Williams or Haas, only spent $125 million and $150 million respectively. This gap was widening by the season and disparities like this prompted the FIA to introduce a cost cap in February 2021.\nThe FIA proposed the cost cap as a measure to reward engineering prowess over sheer expenditure. They did this in an effort to bridge the gap between the midfield teams and the teams challenging for the driver's and constructors' titles.\nThe cap was $175 million in 2021, although was reduced further to $145 million in response to economic turmoil due to the COVID-19 pandemic. For 2022, the cost cap was further reduced to $140 million and in 2023 it fell to $135 million where it will remain for the 2024 and 2025 seasons.\nThe 2022 season served as a critical test for the effectiveness of the cost cap as it was the year the new regulations were introduced, allowing all teams to start from scratch and build a car that was independent of the previous years. Critics have argued that the cap might not be sufficient enough to close the gap in competition because it excluded certain expenses like driver salaries, compensation for the three highest paid-staff members, and marketing costs along with loopholes that allowed the likes of Adrian Newey's salary of Red Bull to be excluded from the cost cap. They also contended that established teams could exploit existing infrastructures and resources accumulated over years, thus maintaining their competitive edge despite the spending limits.\nHowever, an alternative perspective highlights that the cost cap encourages teams to maximise efficiency and foster innovation within their financial means. McLaren started the 2023 season as the slowest car on the track, with their drivers finishing outside the points with Lando Norris at P17 and Oscar Piastri at P20. Seven months later, with the right upgrades, they managed to be the fastest car on the grid throughout qualifying and race pace. Facing budgetary constraints similar to their competitors, McLaren focused on strategic engineering upgrades and talent development. Their significant mid-season improvements led to notable on-track success, demonstrating that with clever resource management and engineering talent, teams can challenge the dominance of traditionally wealthier competitors.\nMcLaren CEO Zak Brown said that \"the cap has been outstanding for the sport.\" He also went on to say that there is a feeling that at any point in the season, any team can challenge for a place it wasn't equipped to do so at the start of the season.\nThe critics have expressed that the impact of the cost cap suggests that engineering excellence and strategic ingenuity can indeed offset the advantages of larger budgets. By promoting a more balanced competitive environment, the cost cap has made Formula 1 more exciting for fans and more viable for teams.\nFuture.\nThe expense of Formula One has seen the FIA and the Formula One Commission attempt to create new regulations to lower the costs for a team to compete in the sport.\nFollowing their purchase of the commercial rights to the sport in 2017, Liberty Media announced their vision for the future of Formula One at the 2018 Bahrain Grand Prix. The proposal identified five key areas, including streamlining the governance of the sport, emphasising cost-effectiveness, maintaining the sport's relevance to road cars and encouraging new manufacturers to enter the championship whilst enabling them to be competitive.\nOn 19 August 2020, it was announced that all 10 teams had signed the new Concorde Agreement. This came into effect at the start of the 2021 season and changed how prize money and TV revenue is distributed.\nEnvironmental impact.\nFormula One has initiated a plan to become carbon neutral by 2030. By 2025, all events should become \"sustainable\", including eliminating single-use plastics and ensuring all waste is reused, recycled or composted.\nA report conducted by Formula One estimated that the series was responsible for 256,000\u00a0tonnes of carbon dioxide emissions in the 2019 season, finding that 45% of emissions were from logistics and only 0.7% were from emissions from the cars themselves.\nIn January 2020, FIA and Formula One signed the United Nations \"Sports for Climate Action\" framework. After the signing was announced, FIA President Jean Todt said: \"As an international Federation comprising 244 members in 140 countries and the leader in motor sport and mobility development, we are fully committed to global environmental protection. The signing of this UN Sports for Climate Action Framework reinforces the momentum that has been growing in our Federation for many years. Since the introduction of the hybrid power unit in F1 to the creation of the Environment and Sustainability Commission, the entire FIA community has been investing time, energy and financial resources to the benefit of environmental innovations. We aim to inspire greater awareness and best practice in sustainability motor sport standards.\"\nFrom the 2021\u201322 season, all cars will increase the bio-component of their fuel, using E10 fuel, rather than the 5.75% of ethanol currently used. This percentage is expected to grow again in the future. In December 2020, the FIA claimed that it had developed a fuel with 100% sustainability, to be used in Formula One from either 2025 or 2026, when new engine regulations come into force.\nSocial inequities.\nPrior to the beginning of the 2020 Formula One World Championship, F1 announced and launched the #WeRaceAsOne initiative. The initiative primarily focuses on visible displays of solidarity in the fight against racism on Grand Prix Weekends, as well as the creation of a Formula 1 Task Force that will \"listen to people from across the paddock [...] and make conclusions on the actions required to improve the diversity and opportunity in Formula 1 at all levels\". The move spurs from the growing questions about racism and global inequalities perpetuated by the sport. The 70-year history of the World Championship has been dominated by European and white drivers, with the first (and only) black driver, Lewis Hamilton, participating in the world championship since 2007.\nIn addition to organization-wide measures, individual teams have also acknowledged deficiencies in the sport's cultural and political activism. During the 2020 season, the Mercedes-AMG Petronas F1 Team conducted a study of its racial composition and found that approximately 95% of its workforce was white. Due to the results of the study, the team changed the car's livery to promote anti-racism messages and also launched the Accelerate 25 programme. The program vows that approximately 25% of all new hires to the team will come from underrepresented minorities in the sport until 2025.\nThe 20 drivers on the grid have also stood in solidarity on multiple occasions in the fight against racism both on and off the track. Following the murder of George Floyd in the summer of 2020, all twenty drivers wore \"End Racism\" shirts and took part in an organised anti-racism protest during the pre-race formalities. In the year since, Lewis Hamilton has remained vocal in his pre-race attire, with other drivers occasionally wearing change-demanding clothing.\nWomen in Formula One.\nSince the creation of Formula One, in 1950, there have been five women to compete in a Grand Prix, and only one managed to score. The involvement of women in the Formula One paddock ranges from race engineers and strategists to media and communications personnel. With the release of the Netflix show, , the female viewership of the sport has risen. In 2019 20% of the total Formula One viewership was female, and by 2022 this number had increased to 40%.\nF1 Academy.\nF1 Academy, created by Formula One in 2023, is the only female single-seater racing championship. Its inaugural championship was won by Marta Garc\u00eda of Prema Racing. The establishment of F1 Academy has attracted significant levels of attention to women in motorsport; Netflix has announced the release of a docuseries in 2025 about the academy. In addition to this companies such as Tommy Hilfiger, Charlotte Tilbury, Puma, and Red Bull have become sponsors of F1 Academy due to its increasing popularity.\nFemale Formula One drivers.\nMaria Teresa de Filippis was the first female to compete in a Formula One Grand Prix at the 1958 Monaco Grand Prix. She competed in a total of five Grand Prix, racing under the Italian flag and has been hailed a pioneer of women in motorsport.\nLella Lombardi is the only female to place within the points at a Formula One Grand Prix. She competed in three seasons, entering seventeen races, and starting twelve. After finishing sixth in the 1975 Spanish Grand Prix, Lombardi became the first and only female to score points during an official Formula Grand Prix. Due to the race not reaching full completion half points were awarded and Lombardi only gained .5 points.\nDesir\u00e9 Wilson the only woman to win a Formula One race of any kind, winning the second round of the 1980 Aurora AFX F1 Championship.\nRace engineers.\nHannah Schmitz currently holds the role of principal strategy engineer at Red Bull Racing. She has been with the team since 2009 and played a strong presence in its victories in 2021, 2022, and 2023. In 2023 Schmitz won the McLaren Applied Female Engineer of the Year Award winner for her role within Red Bull Racing.\nTeam principals.\nSusie Wolff is the current managing director of F1 Academy, however her presence within the Formula One paddock has lasted several decades. In the beginning of her career she was told to drive a pink car, although she was skeptical, Wolff obliged figuring that young girls would see the car and feel more inspired to begin racing. In 2012 Wolff was a Williams Grand Prix Engineering development driver, during her four years at Williams, she competed in several free practice sessions for the team. After her time at Williams, Wolff became the team principal of Formula E team Venturi Racing, and saw the team to their most successful season to date.\nAustrian Monisha Kaltenborn became the sport's first ever female Team principal when she took over the role at Sauber Formula 1 Team in 2010.\nMedia and presenters.\nNatalie Pinkham is a British television presenter and pit lane reporter for Sky Sports F1. She joined the television channel in 2012, and became the first woman commentator on British TV.\nNaomi Schiff is a retired racing driver who is currently working as a television presenter for Sky Sports F1. After her retirement in 2020 she worked as the diversity and inclusion ambassador for the W Series, before joining the UK based television channel in 2022.\nMedia coverage.\nFormula One is broadcast live, or tape delayed in almost every country and territory and attracts one of the largest global television audiences. The 2008 season attracted a global audience of 600\u00a0million people per race. The cumulative television audience was calculated to be 54\u00a0billion for the 2001 season, broadcast to 200 territories.\nDuring the early 1990s, Formula One Group created a number of trademarks, an official logo, an official TV graphics package and in 2003, an official website for the sport in an attempt to give it a corporate identity.\nTV stations all take what is known as the \"World Feed\", either produced historically by the \"host broadcaster\" or by Formula One Management (FOM). The host broadcaster either had one feed for all, or two separate feeds \u2013 a feed for local viewers and a feed for international viewers. The one size fits all approach meant that there was bias to a certain team or driver during the event, which led to viewers missing out on more important action and incidents, while the two-feed approach meant that replays (for when returning from an ad break) and local bias action could be overlaid on the local feed while the international feed was left unaffected.\nThe only station that differed from this set up was \"DF1\" (re-branded to \"Premiere\" then to \"Sky Deutschland\") \u2013 a German channel which offers all sessions live and interactive, with features such as the onboard and pit-lane channels. This service was purchased by Bernie Ecclestone at the end of 1996 and became F1 Digital Plus, which was made more widely available around Europe until the end of 2002, when the cost of the digital interactive service was thought too much.\nOn 12 January 2011, F1 announced that it would adopt the HD format for the 2011 season.\nIt was announced on 29 July 2011, that Sky Sports and the BBC would team up to show the races in F1 from 2012 to 2018. Sky launched a dedicated channel, Sky Sports F1 which covered all races live without commercial interruption as well as live practice and qualifying sessions, along with F1 programming, including interviews, archive action and magazine shows. In 2012 the BBC broadcast live coverage of half of the races in the season. The BBC ended its television contract after the 2015 season, three years earlier than planned. The free-to-air TV rights were picked up by Channel 4 until the end of the 2018 season. Sky Sports F1 coverage remained unaffected and BBC Radio 5 Live and 5 Sports Extra coverage was extended until 2021. As of 2022, BBC Radio 5 Live and 5 Sports Extra has rights to such coverage until 2024.\nWhile Sky Sports and Channel 4 are the two major broadcasters of Formula 1, other countries show Formula One races. Many use commentary from either Sky Sports or Channel 4. In most of Asia (excluding China), the two main broadcasters of Formula One includes the Fox network and Star Sports (in India). In the United States, ESPN holds the official rights to broadcast the sport while ABC also holds free-to-air rights for some races under the ESPN on ABC banner. In Germany, Austria and Switzerland, the two main broadcasters are RTL Germany and n-TV. In China, there are multiple channels that broadcast Formula One which include CCTV, Tencent, Guangdong TV and Shanghai TV. Currently in France, the only channel that broadcasts Formula One is the pay TV channel Canal+, having renewed its broadcasting rights until 2024.\nThe official Formula One website has live timing charts that can be used during the race to follow the leaderboard in real time. An official application has been available for the Apple App Store since 2009, and on Google Play since 2011, that shows users a real-time feed of driver positions, timing and commentary. On 26 November 2017 Formula One unveiled a new logo, which replaced the previous \"flying one\" in use since 1993.\nIn March 2018, FOM announced the launch of F1 TV, an over-the-top streaming platform that lets viewers watch multiple simultaneous video feeds and timing screens in addition to traditional directed race footage and commentary. In April 2024, FOM launched a free ad-supported streaming television channel known as the Formula 1 Channel in the United States, which shows classic Grands Prix, documentaries and analysis from past races.\nDistinction between Formula One and World Championship races.\nCurrently, the terms \"Formula One race\" and \"World Championship race\" are effectively synonymous. Since 1984, every Formula One race has counted towards the World Championship, and every World Championship race has been run to Formula One regulations. However, the two terms are not interchangeable.\nThe distinction is most relevant when considering career summaries and all-time lists. For example, in the List of Formula One drivers, Clemente Biondetti is shown with a single race against his name. Biondetti actually competed in four Formula One races in 1950, but only one of these counted for the World Championship.\nIn the earlier history of Formula One, many races took place outside the World Championship, and local championships run to Formula One regulations also occurred. These events often took place on circuits that were not always suitable for the World Championship and featured local cars and drivers as well as those competing in the championship.\nEuropean non-championship racing.\nIn the early years of Formula One, before the world championship was established, there were around twenty races held from late Spring to early Autumn in Europe, although not all of these were considered significant. Most competitive cars came from Italy, particularly Alfa Romeo. After the start of the world championship, these non-championship races continued. In the 1950s and 1960s, there were many Formula One races which did not count for the World Championship; in a total of twenty-two Formula One races were held, of which only six counted towards the World Championship. In 1952 and 1953, when the world championship was run to Formula Two regulations, non-championship events were the only Formula One races that took place.\nSome races, particularly in the UK, including the Race of Champions, Oulton Park International Gold Cup and the International Trophy, were attended by the majority of the world championship contenders. Other smaller events were regularly held in locations not part of the championship, such as the Syracuse and Danish Grands Prix, although these only attracted a small amount of the championship teams and relied on private entries and lower Formula cars to make up the grid. These became less common through the 1970s and 1983 saw the last non-championship Formula One race; the 1983 Race of Champions at Brands Hatch, won by reigning World Champion Keke Rosberg in a Williams-Cosworth in a close fight with American Danny Sullivan.\nSouth African Formula One championship.\nSouth Africa's flourishing domestic Formula One championship ran from 1960 through to 1975. The frontrunning cars in the series were recently retired from the world championship although there was also a healthy selection of locally built or modified machines.\nBritish Formula One Championship.\nThe DFV helped in making the UK domestic Formula One championship possible between 1978 and 1980. As in South Africa a decade before, second-hand cars from manufacturers like Lotus and Fittipaldi Automotive were the order of the day, although some, such as the March 781, were built specifically for the series. In 1980, the series saw South African Desir\u00e9 Wilson become the only woman to win a Formula One race when she triumphed at Brands Hatch in a Wolf WR3."}
{"id": "10855", "revid": "41745938", "url": "https://en.wikipedia.org/wiki?curid=10855", "title": "Franco Baresi", "text": "Franchino Baresi (; born 8 May 1960) is an Italian football youth team coach and a former player and manager. He mainly played as a sweeper or as a central defender, and spent his entire 20-year career with Serie A club AC Milan, captaining the club for 15 seasons. He is considered to be one of the best defenders of all time. He was ranked 19th in \"World Soccer\" magazine's list of the 100 greatest players of the 20th century. With Milan, he won three UEFA Champions League titles, six Serie A titles, four Supercoppa Italiana titles, two European Super Cups and two International Cups, as well as a World Cup with Italy.\nWith the Italy national team, he was a member of the Italian squad that won the 1982 FIFA World Cup. He also played in the 1990 World Cup, where he was named in the FIFA World Cup All-Star Team, finishing third in the competition. At the 1994 World Cup, he was named Italy's captain and was part of the squad that reached the final, although he would miss a penalty in the resulting shoot-out as Brazil lifted the trophy. Baresi also represented Italy at two UEFA European Championships, in 1980 and 1988, and at the 1984 Olympics, reaching the semi-finals on each occasion.\nThe younger brother of former footballer Giuseppe Baresi, after joining the Milan senior team as a youngster, Franco Baresi was initially nicknamed \"Piscinin\", Milanese for \"little one\". Due to his skill and success, he was later known as \"Kaiser Franz\", a reference to fellow sweeper Franz Beckenbauer. In 1999, he was voted Milan's Player of the Century. After his final season at Milan in 1997, the club retired Baresi's shirt number 6. He was named by Pel\u00e9 one of the 125 Greatest Living Footballers at the FIFA centenary awards ceremony in 2004. Baresi was inducted into the Italian Football Hall of Fame in 2013.\nEarly life.\nBaresi grew up in a farmstead on the outskirts of a small north Italian town, Travagliato. He did not watch football on television until he was 10.\nClub career.\nOriginally an AC Milan youth product, Baresi went on to spend his entire 20-year professional career with Milan, making his Serie A debut at age 17 during the 1977\u201378 season on 23 April 1978. He had initially been rejected by the Internazionale youth team, who chose his brother Giuseppe instead, hence the Milan youth team signed Franco Baresi. The two brothers ended up captaining their respective teams shortly after, with their image while exchanging pennants became the trademark of Milan's \"derby della Madonnina\" throughout the 80s.\nThe following season, he was made a member of the starting 11, playing as a sweeper or as a centreback, winning the 1978\u201379 Serie A title, Milan's tenth overall, playing alongside Fabio Capello and Gianni Rivera.\nThis success was soon followed by a dark period in the club's history, when Milan was relegated to Serie B twice during the early 1980s. Milan were relegated in 1980 for being involved in the match fixing scandal of 1980, and once again after finishing third-last in the 1981\u201382 season, after having just returned to Serie A the previous season, after winning the 1980\u201381 Serie B title. Despite being a member of the Euro 1980 Italy squad that had finished fourth, and the 1982 World Cup-winning team, Baresi elected to stay with Milan, winning the Serie B title for the second time during the 1982\u201383 season and bringing Milan back to Serie A. After Aldo Maldera and Fulvio Collovati left the club in 1982, Baresi was appointed Milan's captain, at age 22, and would hold this position for much of his time at the club, becoming a symbol and a leader for the team. During this bleak period for Milan, Baresi did manage to win a Mitropa Cup in 1982 and reached the Coppa Italia final during 1984\u201385 season, although the team failed to dominate in Serie A.\nDuring the end of the 1980s and the first half of the 1990s, Baresi was at the heart of a notable all-Italian defence alongside Paolo Maldini, Alessandro Costacurta, Mauro Tassotti and later Christian Panucci, under managers Arrigo Sacchi and Fabio Capello, a defence which is regarded by many as one of the greatest of all time. When the attacking Dutch trio of Marco van Basten, Ruud Gullit and Frank Rijkaard arrived at the club in the late 1980s, Milan began a period of domestic and international triumphs, and between 1987 and 1996, at the height of the club's success, the Milan squad contained many Italian and international stars, such as Roberto Donadoni, Carlo Ancelotti, Marco van Basten, Ruud Gullit, Frank Rijkaard and later Demetrio Albertini, Dejan Savi\u0107evi\u0107, Zvonimir Boban, Marcel Desailly, George Weah, Jean-Pierre Papin, Brian Laudrup and Roberto Baggio. Under Sacchi, Milan won the Serie A title in 1987\u201388, with Baresi helping Milan to concede only 14 goals. This title was immediately followed by a Supercoppa Italiana in 1988 the next season, and back-to-back European Cups in 1988\u201389 and 1989\u201390; In the 1990 European Cup Final, Baresi turned in a dominant performance as the team's captain, helping Milan to defend the European Cup title and keep a clean sheet in a 1\u20130 victory over Benfica. Baresi was also runner-up to teammate Van Basten for the Ballon d'Or in 1989, finishing ahead of his other teammate Frank Rijkaard, and was named Serie A Footballer of the Year in 1989\u201390. Milan also reached the Coppa Italia final during the 1989\u201390 season.\nBaresi went on to win four more Serie A titles with Milan under Fabio Capello, including three consecutive titles in 1991\u201392, 1992\u201393 and the 1993\u201394 seasons. Baresi helped Milan win the 1991\u201392 title undefeated, helping Milan to go unbeaten for an Italian record of 58 matches. Milan also scored a record 74 goals that season. During the 1993\u201394 season, Baresi helped Milan concede a mere 15 goals in Serie A, helping the club to finish the season with the best defence. Baresi also won three consecutive Supercoppa Italiana under Capello, in 1992, 1993 and 1994. Milan also reached three consecutive UEFA Champions League finals during the 1992\u201393, 1993\u201394 and 1994\u201395 seasons, losing to Marseille in 1992\u201393 and Ajax in 1994\u201395. Baresi won the third European Cup/UEFA Champions League of his career in 1993\u201394 when Milan defeated Johan Cruyff's Barcelona \"Dream Team\" 4\u20130 in the final. Baresi also managed to win the 1994 European Super Cup, although Milan were defeated in the 1994 Intercontinental Cup, the 1993 European Super Cup and the 1993 Intercontinental Cup. Under Capello, Milan and Baresi were able to capture another Serie A title during 1995\u201396 season, Baresi's sixth.\nBaresi retired at the end of the 1996\u201397 Serie A season, at age 37. In his 20 seasons with Milan, he won six Serie A titles, three European Cup/UEFA Champions League titles (reaching five finals in total), two Intercontinental Cups (four finals in total), three European Supercups (four finals in total), four Supercoppa Italiana (five finals in total), two Serie B titles and a Mitropa Cup. He scored 31 goals for Milan, 21 of which were on penalties, and, despite being a defender, he was the top scorer of the Coppa Italia during the 1989\u201390 season, the only trophy which he failed to win with Milan, reaching the final twice during his career. His final goal for Milan was scored in a 2\u20131 win against Padova on 27 August 1995. In his honour, Milan retired his number 6 shirt, which he had worn throughout his career. The captain's armband, which he had worn for 15 seasons, was handed over to Paolo Maldini. Milan organised a celebration match in his honour, which was played on 28 October 1997 at the San Siro, featuring many footballing stars.\nInternational career.\nAt age 20, while still playing in the Italy under-21 side, Baresi was named in Italy's 22-man squad for the 1980 European Championship (along with his older brother Giuseppe) by manager Enzo Bearzot. The tournament was held on home soil and Italy finished fourth. However, unlike his brother, Franco Baresi did not play a single match in the tournament. Euro 1980 would be the only time the two brothers were on the Italy squad together at a major tournament. At age 22, Baresi was named in Italy's squad for the 1982 FIFA World Cup. The \"Azzurri\" won their third World Cup, defeating West Germany in the final, but Baresi, once again, was not selected to play a match throughout the tournament. Baresi was also a member of the Italy squad that took part in the 1984 Olympics. Italy finished in fourth place after a semi-final defeat to Brazil, and losing the bronze medal match to Yugoslavia. Baresi scored a goal against the United States during the group stage.\nBaresi won his first senior international cap in a 1984 UEFA Championship qualifying match against Romania in Florence, on 14 December 1982, a 0\u20130 draw. Italy, however, ultimately failed to qualify for the final tournament.\nBaresi was not included in Italy's squad for the 1986 World Cup by coach Enzo Bearzot, who saw him as being more of a midfielder than a defender (although his brother Giuseppe was selected as a defender for the World Cup, as well as Roberto Tricella). He returned to the team for the 1988 European Championship, playing as a sweeper, where Italy reached the semi-finals under Azeglio Vicini, becoming an undisputed first team member and playing in every match. He made his first appearance in a World Cup finals match in the 1990 tournament, which was held on home soil, and he played in every match as one of the starting centre-backs, as Italy finished in third-place, after being eliminated by defending champions Argentina in a penalty shootout in the semi-finals. Baresi helped the Italian defence to keep five consecutive clean sheets, only conceding two goals, and going unbeaten for a World Cup record of 518 minutes, until they were beaten by an Argentinian equaliser in the semi-final. His performances earned him a spot on the 1990 World Cup Team of the tournament.\nAfter replacing Giuseppe Bergomi as captain for the 1994 World Cup under his former manager at Milan, Arrigo Sacchi, Baresi sustained an injury to his meniscus in Italy's second group match, a 1\u20130 win against Norway, and missed most of the tournament. He returned to the squad 25 days later, in time for the final, with a dominant defensive performance, helping Italy to keep a clean sheet against Brazil, despite the key defensive absences of his Milan teammates Alessandro Costacurta and Mauro Tassotti. After a 0\u20130 deadlock following extra time, the match went to a penalty shootout, and Baresi subsequently missed his penalty, suffering from severe cramps and fatigue. Following misses by Daniele Massaro and Roberto Baggio, Italy were defeated by Brazil in the penalty shootout.\nFollowing the World Cup defeat, Baresi made one more appearance for Italy, in an away UEFA Euro 1996 qualifying match against Slovenia on 7 September 1994, which ended in a 1\u20131 draw. Baresi subsequently retired from the national side at age 34, passing the captain's armband to his Milan teammate Paolo Maldini. Baresi amassed 81 caps for Italy, scoring one goal in a friendly win against the Soviet Union, and he is one of seven players to have achieved the rare feat of winning Gold, Silver and Bronze FIFA World Cup medals during his international career.\nStyle of play.\nBaresi is regarded as one of the greatest defenders of all time. He played his entire 20-year career with Milan, becoming a club legend. At Milan, he formed one of the most formidable defensive units of all time, alongside Paolo Maldini, Alessandro Costacurta, Mauro Tassotti, Filippo Galli and later Christian Panucci. He was a complete and consistent defender who combined power with elegance and was gifted with outstanding physical and mental attributes, such as pace, strength, tenacity, concentration and stamina, which made him effective in the air, despite his lack of notable height for a centre-back.\nAlthough Baresi was capable of playing anywhere along the backline, he primarily excelled as a centreback and as sweeper, where he combined his defensive attributes, and his ability to read the game, with his excellent vision, technique, distribution and ball skills. These qualities also enabled him to excel in a zonal marking system, maintain a high defensive line, and play the offside trap, in particular during his time at Milan under Sacchi; indeed, Baresi came to be known for often raising his arm towards the linesman whenever his team attempted to play the offside trap. Baresi's passing range, technical ability and ball control allowed him to advance forward into the midfield to start attacking plays from the back, enabling him to function as a secondary playmaker for his team, and also play as a defensive or central midfielder when necessary. Despite being a defender, he was also an accurate penalty kick taker. Baresi was known for being a strong and accurate tackler, who was very good at winning back possession, and at anticipating and intercepting plays, due to his acute tactical intelligence, speed of thought, marking ability and positional sense. A precocious talent in his youth, throughout the course of his career, he also stood out for his professionalism, athleticism, longevity, and discipline in training, as well as his outstanding leadership, commanding presence on the pitch and his organisational skills; indeed, he captained both Milan and the Italy national team.\nBaresi also shares the record of most own goals scored in Serie A history (eight, along with Riccardo Ferri).\nCoaching career.\nOn 1 June 2002, Baresi was officially appointed as director of football at Fulham, but tensions between Baresi and then Fulham manager Jean Tigana led to resignation from the club in August.\nHe was appointed head coach of Milan's \"Primavera\" Under-20 squad. In 2006, he was moved by the club to coach the \"Berretti\" Under-19 squad, with his former teammate Filippo Galli replacing him at the helm of the Primavera squad. He retired from coaching and was replaced by Roberto Bertuzzo.\nPersonal life.\nFranco Baresi is the younger brother of Internazionale legendary defender Giuseppe Baresi. As youngsters, both players had tryouts for Inter, but Franco was rejected, and purchased by local rivals Milan. As he was the younger player, Franco was initially known as \"Baresi 2\". However, due to Franco's eventual great success and popularity throughout his career, which surpassed even that of his older brother's, Giuseppe later became known as \"the other Baresi\", despite also achieving notable success.\nIn 1981, Baresi suffered from a blood infection that forced him out of play for nearly four months and worsened his health to the point of him needing a wheelchair. While in treatment, he participated in the medical research for the disease.\nMedia.\nBaresi is featured in the EA Sports football video game series \"FIFA 14\"'s Classic XI \u2013 a multi-national all-star team, along with compatriots Bruno Conti, Gianni Rivera and Giacinto Facchetti. He was also named in the Ultimate Team Legends in \"FIFA 15\".\nHonours.\nAC Milan\nIndividual\nOrders"}
{"id": "10856", "revid": "1591", "url": "https://en.wikipedia.org/wiki?curid=10856", "title": "Famous quotations", "text": ""}
{"id": "10857", "revid": "877242", "url": "https://en.wikipedia.org/wiki?curid=10857", "title": "Stage (stratigraphy)", "text": "In chronostratigraphy, a stage is a succession of rock strata laid down in a single age on the geologic timescale, which usually represents millions of years of deposition. A given stage of rock and the corresponding age of time will by convention have the same name, and the same boundaries.\nRock series are divided into stages, just as geological epochs are divided into ages. Stages are divided into smaller stratigraphic units called chronozones or substages, and added together into superstages.\nThe term faunal stage is sometimes used, referring to the fact that the same fauna (animals) are found throughout the layer (by definition).\nDefinition.\nStages are primarily defined by a consistent set of fossils (biostratigraphy) or a consistent magnetic polarity (see paleomagnetism) in the rock. Usually one or more index fossils that are common, found worldwide, easily recognized, and limited to a single, or at most a few, stages are used to define the stage's bottom. \nThus, for example in the local North American subdivision, a paleontologist finding fragments of the trilobite \"Olenellus\" would identify the beds as being from the Waucoban Stage whereas fragments of a later trilobite such as \"Elrathia\" would identify the stage as Albertan. \nStages were important in the 19th and early 20th centuries as they were the major tool available for dating and correlating rock units prior to the development of seismology and radioactive dating in the second half of the 20th century. Microscopic analysis of the rock (petrology) is also sometimes useful in confirming that a given segment of rock is from a particular age.\nOriginally, faunal stages were only defined regionally. As additional stratigraphic and geochronologic tools were developed, they were defined over ever broader areas. More recently, the adjective \"faunal\" has been dropped as regional and global correlations of rock sequences have become relatively certain and there is less need for faunal labels to define the age of formations. A tendency developed to use European and, to a lesser extent, Asian stage names for the same time period worldwide, even though the faunas in other regions often had little in common with the stage as originally defined.\nInternational standardization.\nBoundaries and names are established by the International Commission on Stratigraphy (ICS) of the International Union of Geological Sciences. As of 2008, the ICS is nearly finished with a task begun in 1974, subdividing the Phanerozoic eonothem into internationally accepted stages using two types of benchmark. For younger stages, a Global Boundary Stratotype Section and Point (GSSP), a physical outcrop clearly demonstrates the boundary. For older stages, a Global Standard Stratigraphic Age (GSSA) is an absolute date. The benchmarks will give a much greater certainty that results can be compared with confidence in the date determinations, and such results will have farther scope than any evaluation based solely on local knowledge and conditions. \nIn many regions local subdivisions and classification criteria are still used along with the newer internationally coordinated uniform system, but once the research establishes a more complete international system, it is expected that local systems will be abandoned.\nStages and lithostratigraphy.\nStages can include many lithostratigraphic units (for example formations, beds, members, etc.) of differing rock types that were being laid down in different environments at the same time. In the same way, a lithostratigraphic unit can include a number of stages or parts of them."}
{"id": "10858", "revid": "198939", "url": "https://en.wikipedia.org/wiki?curid=10858", "title": "Franz Kafka", "text": "Franz Kafka (3 July 1883\u00a0\u2013 3 June 1924) was a Jewish Austrian-Czech novelist and writer from Prague who wrote in German. He is widely regarded as a major figure of 20th-century literature. His work fuses elements of realism and the fantastic, and typically features isolated protagonists facing bizarre or surrealistic predicaments and incomprehensible socio-bureaucratic powers. It has been interpreted as exploring themes of alienation, existential anxiety, guilt, and absurdity. His best known works include the novella \"The Metamorphosis\" (1915) and the novels \"The Trial\" (1924) and \"The Castle\" (1926). The term \"\" has entered English to describe absurd situations like those depicted in his writing.\nKafka was born into a middle-class German- and Yiddish-speaking Czech Jewish family in Prague, the capital of the Kingdom of Bohemia, which belonged to the Austrian part of the Austro-Hungarian Empire (today the capital of the Czech Republic, also known as Czechia). He trained as a lawyer, and after completing his legal education was employed full-time in various legal and insurance jobs. Being employed full-time forced Kafka to relegate writing to his spare time. Few of his works were published during his lifetime; the story collections \"Contemplation\" (1912) and \"A Country Doctor\" (1919), and individual stories, such as his novella \"The Metamorphosis\", were published in literary magazines, but they received little attention. Over the course of his life, Kafka wrote hundreds of letters to family and close friends, including his father, with whom he had a strained and formal relationship. He became engaged to several women but never married. He died relatively unknown in 1924 of tuberculosis, at the age of 40.\nKafka was a prolific writer, but he burned an estimated 90 percent of his total work due to persistent struggles with self-doubt. Much of the remaining 10 percent is lost or otherwise unpublished. In his will, Kafka instructed his close friend and literary executor Max Brod to destroy his unfinished works, including his novels \"The Trial\", \"The Castle\", and (1927), but Brod ignored these instructions and had much of his work published. Kafka's writings became famous in German-speaking countries after World War II, influencing German literature, and its influence spread elsewhere in the world in the 1960s. It has also influenced artists, composers, and philosophers.\nLife.\nEarly life.\nKafka was born near the Old Town Square in Prague, then part of the Austro-Hungarian Empire. His family were German-speaking middle-class Ashkenazi Jews. His father, Hermann Kafka (1854\u20131931), was the fourth child of Jakob Kafka, a or ritual slaughterer in Osek, a Czech village with a large Jewish population located near Strakonice in southern Bohemia. Hermann brought the Kafka family to Prague. After working as a travelling sales representative, he eventually became a fashion retailer who employed up to 15 people and used the image of a jackdaw ( in Czech, pronounced and colloquially written as \"kafka\") as his business logo. Kafka's mother, Julie (1856\u20131934), was the daughter of Jakob L\u00f6wy, a prosperous retail merchant in Pod\u011bbrady, and was better educated than her husband.\nKafka's parents, from traditional Jewish society, spoke German replete with influences from their native Yiddish; their children, raised in an acculturated environment, spoke Standard German. Hermann and Julie had six children, of whom Franz was the eldest. Franz's two brothers, Georg and Heinrich, died in infancy before Franz was seven; his three sisters were Gabriele (\"Elli\") (1889\u20131942), Valerie (\"Valli\") (1890\u20131942) and Ottilie (\"Ottla\") (1892\u20131943). All three were murdered in the Holocaust of World War II. Valli was deported to the \u0141\u00f3d\u017a Ghetto in occupied Poland in 1942, but that is the last documentation of her; it is assumed she did not survive the war. Ottilie was Kafka's favourite sister.\nHermann is described by Kafka scholar and translator Stanley Corngold as a \"huge, selfish, overbearing businessman\" and by Franz Kafka as \"a true Kafka in strength, health, appetite, loudness of voice, eloquence, self-satisfaction, worldly dominance, endurance, presence of mind, knowledge of human nature, a certain way of doing things on a grand scale, of course with all the defects and weaknesses that go with all these advantages and into which your temperament and sometimes your hot temper drive you\". On business days, both parents were absent from the home, with Julie Kafka working as many as 12\u00a0hours each day helping to manage the family business. Consequently, Kafka's childhood was somewhat lonely, and the children were reared largely by a series of governesses and servants. Kafka's troubled relationship with his father is evident in his (\"Letter to His Father\") of more than 100\u00a0pages, in which he complains of being profoundly affected by his father's authoritarian and demanding character; his mother, in contrast, was quiet and shy. The dominating figure of Kafka's father had a significant influence on Kafka's writing.\nThe Kafka family had a servant girl living with them in a cramped apartment. Franz's room was often cold. In November 1913, the family moved into a bigger apartment, although Ellie and Valli had married and moved out of the first apartment. In early August 1914, just after World War I began, the sisters did not know where their husbands were in the military and moved back in with the family in this larger apartment. Both Ellie and Valli also had children. Franz at age 31 moved into Valli's former apartment, quiet by contrast, and lived by himself for the first time.\nEducation.\nFrom 1889 to 1893, Kafka attended the German boys' elementary school at the (meat market), now known as Masn\u00e1 Street. His Jewish education ended with his \"bar mitzvah\" celebration at the age of 13. Kafka never enjoyed attending the synagogue and went with his father only on four high holidays each year.\nAfter leaving elementary school in 1893, Kafka was admitted to the rigorous classics-oriented state gymnasium, , an academic secondary school at Old Town Square, located within Kinsk\u00fd Palace. German was the language of instruction, but Kafka also spoke and wrote in Czech. He studied the latter at the gymnasium for eight years, achieving good grades. Although Kafka received compliments for his Czech, he never considered himself fluent in the language, though he spoke German with a Czech accent. He completed his Matura exams in 1901.\nKafka was admitted to the of Prague in 1901. He was originally admitted for philosophy, and he had additionally signed up for chemistry. Kafka began studying chemistry but switched to law after two weeks. Although this field did not excite him, it offered a range of career possibilities, which pleased his father. In addition, law required a longer course of study, giving Kafka time to take classes in German studies and art history. He also joined a student club, (Reading and Lecture Hall of the German students), which organised literary events, readings and other activities. Among Kafka's friends were the journalist Felix Weltsch, who studied philosophy, the actor Yitzchak Lowy who came from an orthodox Hasidic Warsaw family, and the writers Ludwig Winder, Oskar Baum and Franz Werfel.\nAt the end of his first year of studies, Kafka met Max Brod, a fellow law student who became a close friend for life. Years later, Brod coined the term (\"The Close Prague Circle\") to describe the group of writers, which included Kafka, Felix Weltsch and Brod himself. Brod soon noticed that, although Kafka was shy and seldom spoke, what he said was usually profound. Kafka was an avid reader throughout his life; together he and Brod read Plato's \"Protagoras\" in the original Greek, on Brod's initiative, and Flaubert's and (\"The Temptation of Saint Anthony\") in French, at his own suggestion. Kafka considered Fyodor Dostoevsky, Gustave Flaubert, Nikolai Gogol, Franz Grillparzer, and Heinrich von Kleist to be his \"true blood brothers\". Besides these, he took an interest in Czech literature and was also very fond of the works of Goethe. Kafka was awarded the degree of Doctor of Law on 18 June 1906 and performed an obligatory year of unpaid service as a law clerk for the civil and criminal courts.\nEmployment.\nOn 1 November 1907, Kafka was employed at the , an insurance company, where he worked for nearly a year. His correspondence during that period indicates that he was unhappy with a work schedule\u2014from 08:00 until 18:00\u2014that made it extremely difficult to concentrate on writing, which was assuming increasing importance to him. On 15 July 1908, he resigned. Two weeks later, he found employment more amenable to writing when he joined the Worker's Accident Insurance Institute for the Kingdom of Bohemia (). The job involved investigating and assessing compensation for personal injury to industrial workers; accidents such as lost fingers or limbs were commonplace, owing to poor work safety policies at the time. It was especially true of factories fitted with machine lathes, drills, planing machines and rotary saws, which were rarely fitted with safety guards.\nHis father often referred to his son's job as an insurance officer as a , literally \"bread job\", a job done only to pay the bills; Kafka often claimed to despise it. Kafka was rapidly promoted and his duties included processing and investigating compensation claims, writing reports, and handling appeals from businessmen who thought their firms had been placed in too high a risk category, which cost them more in insurance premiums. He would compile and compose the annual report on the insurance institute for the several years he worked there. The reports were well received by his superiors. Kafka usually got off work at 2 p.m., so that he had time to spend on his literary work, to which he was committed. Kafka's father also expected him to help out at and take over the family fancy goods store. In his later years, Kafka's illness often prevented him from working at the insurance bureau and at his writing.\nIn late 1911, Elli's husband Karl Hermann and Kafka became partners in the first asbestos factory in Prague, known as Prager Asbestwerke Hermann &amp; Co., having used dowry money from Hermann Kafka. Kafka showed a positive attitude at first, dedicating much of his free time to the business, but he later resented the encroachment of this work on his writing time. During that period, he also found interest and entertainment in the performances of Yiddish theatre. After seeing a Yiddish theatre troupe perform in October 1911, for the next six months Kafka \"immersed himself in Yiddish language and in Yiddish literature\". This interest also served as a starting point for his growing exploration of Judaism. It was at about this time that Kafka became a vegetarian. Around 1915, Kafka received his draft notice for military service in World WarI, but his employers at the insurance institute arranged for a deferment because his work was considered essential government service. He later attempted to join the military but was prevented from doing so by medical problems associated with tuberculosis, with which he was diagnosed in 1917. In 1918, the Worker's Accident Insurance Institute put Kafka on a pension due to his illness, for which there was no cure at the time, and he spent most of the rest of his life in sanatoriums.\nPrivate life.\nKafka never married. According to Brod, Kafka was \"tortured\" by sexual desire, and Kafka's biographer Reiner Stach states that his life was full of \"incessant womanising\" and that he was filled with a fear of \"sexual failure\". Kafka visited brothels for most of his adult life and pornography was \"part and parcel of his sexual life\" at one time. In addition, he had close relationships with several women during his lifetime. On 13 August 1912, Kafka met Felice Bauer, a relative of Brod's, who worked in Berlin as a representative of a dictaphone company. A week after the meeting at Brod's home, Kafka wrote in his diary:\nShortly after this meeting, Kafka wrote the story \"\" (\"The Judgment\") in only one night and in a productive period worked on (\"The Man Who Disappeared\") and \"Die Verwandlung\" (\"The Metamorphosis\"). Kafka and Felice Bauer communicated mostly through letters over the next five years, met occasionally, and were engaged twice. Kafka's extant letters to Bauer were published as (\"Letters to Felice\"); her letters did not survive. After he had written to Bauer's father asking to marry her, Kafka wrote in his diary:\nAccording to the biographers Stach and James Hawes, Kafka became engaged a third time around 1920, to Julie Wohryzek, a poor and uneducated hotel chambermaid. Kafka's father objected to Julie because of her Zionist beliefs. Although Kafka and Julie rented a flat and set a wedding date, the marriage never took place. During this time, Kafka began a draft of \"Letter to His Father\". Before the date of the intended marriage, he took up with yet another woman. While he needed women and sex in his life, he had low self-confidence, felt sex was dirty, and was cripplingly shy\u2014especially about his body.\nStach and Brod state that during the time that Kafka knew Felice Bauer, he had an affair with a friend of hers, Margarethe \"Grete\" Bloch, a Jewish woman from Berlin. Brod says that Bloch gave birth to Kafka's son, although Kafka never knew about the child. The boy, whose name is not known, was born in 1914 or 1915 and died in Munich in 1921. However, Kafka's biographer Peter-Andr\u00e9 Alt says that, while Bloch had a son, Kafka was not the father, as the pair were never intimate. Stach points out that there is a great deal of contradictory evidence around the claim that Kafka was the father.\nKafka was diagnosed with tuberculosis in August 1917 and moved for a few months to the Bohemian village of Z\u00fcrau (Si\u0159em in Czech), where his sister Ottla worked on the farm of her brother-in-law Karl Hermann. He felt comfortable there and later described this time as perhaps the best period of his life, probably because he had no responsibilities. He kept diaries and made notes in exercise books (). From those notes, Kafka extracted 109 numbered pieces of text on single pieces of paper (); these were later published as (The Z\u00fcrau Aphorisms or Reflections on Sin, Hope, Suffering, and the True Way).\nIn 1920, Kafka began an intense relationship with Milena Jesensk\u00e1, a Czech journalist and writer who was non-Jewish and who was married, but when she met Kafka, her marriage was a \"sham\". His letters to her were later published as . During a vacation in July 1923 to Graal-M\u00fcritz on the Baltic Sea, Kafka met Dora Diamant, a 25-year-old kindergarten teacher from an orthodox Jewish family. Kafka, hoping to escape the influence of his family to concentrate on his writing, moved briefly to Berlin (September 1923-March 1924) and lived with Diamant. She became his lover and sparked his interest in the Talmud. He worked on four stories, including (\"A Hunger Artist\"), which were published shortly after his death.\nSiblings.\nKafka's parents had six children; Franz was the eldest. His two brothers, Georg and Heinrich, died in infancy; his three sisters, Gabriele (\"Elli\") (September 22, 1889 \u2013 fall of 1942), Valerie (\"Valli\") (1890\u20131942) and Ottilie (\"Ottla\") (1892\u20131943), are believed to have been murdered in the Holocaust of the Second World War. Ottilie was Kafka's favourite sister.\nGabriele was Kafka's eldest sister. She was known as Elli or Ellie; her married name is variously rendered as Hermann or Hermannov\u00e1. She attended a German girls' school in Prague's \u0158eznick\u00e1 Street and later a private girls' secondary school. She married Karl Hermann (1883\u20131939), a salesman, in 1910. The couple had a son, Felix (1911\u20131940), and two daughters, Gertrude (Gerti) Kaufmann (1912\u20131972), and Hanna Seidner (1920\u20131941). After her marriage to Hermann, she became closer to her brother, whose letters showed an active interest in the upbringing and education of her children. He accompanied her on a 1915 trip to Hungary to visit Hermann, who was stationed there, and spent a summer with her and her children in M\u00fcritz the year before he died.\nWith the outbreak of the Great Depression in 1929, the Hermann family business experienced financial difficulties and eventually went bankrupt. Karl Hermann died February 27, 1939, and Elli was supported financially by her sisters. On October 21, 1941, she was deported together with her daughter Hanna to the \u0141\u00f3d\u017a Ghetto, where she lived temporarily with her sister Valli and Valli's husband in the spring of 1942. She was probably killed in the Kulmhof extermination camp in the fall of 1942. Of Elli's three children, only her daughter Gerti survived the Second World War. A memorial plaque commemorates the three sisters at the family grave in the New Jewish Cemetery in Prague.\nPersonality.\nKafka had a lifelong suspicion that people found him mentally and physically repulsive. However, many of those who met him found him to possess obvious intelligence and a sense of humour; they also found him handsome, although of austere appearance. Kafka was thought to be \"very self-analytic\". Brod compared Kafka to Heinrich von Kleist, noting that both writers had the ability to describe a situation realistically with precise details. Brod thought Kafka was one of the most entertaining people he had met; Kafka enjoyed sharing his humour with his friends but also helped them in difficult situations with good advice. According to Brod, he was a passionate reciter, able to phrase his speech as though it were music. Brod felt that two of Kafka's most distinguishing traits were \"absolute truthfulness\" () and \"precise conscientiousness\" (). He explored inconspicuous details in depth and with such precision and love that unforeseen things surfaced that seemed strange but absolutely true ().\nKafka's letters and unexpurgated diaries reveal repressed homoerotic desires, including an infatuation with novelist Franz Werfel and fascination with the work of Hans Bl\u00fcher on male bonding. Saul Friedl\u00e4nder argues that this mental struggle may have informed the themes of alienation and psychological brutality in his writing.\nAlthough Kafka showed little interest in exercise as a child, he later developed a passion for games and physical activity and was an accomplished rider, swimmer, and rower. On weekends, he and his friends embarked on long hikes, often planned by Kafka himself. His other interests included alternative medicine, modern education systems such as Montessori, and technological novelties such as airplanes and film. Writing was vitally important to Kafka; he considered it a \"form of prayer\". He was highly sensitive to noise and preferred absolute quiet when writing. Kafka was also a vegetarian and did not drink alcohol.\nP\u00e9rez-\u00c1lvarez has claimed that Kafka had symptomatology consistent with schizoid personality disorder. His style, it is claimed, not only in (\"The Metamorphosis\") but in other writings, appears to show low- to medium-level schizoid traits, which P\u00e9rez-\u00c1lvarez claims to have influenced much of his work. His anguish can be seen in this diary entry from 21 June 1913:\nand in Z\u00fcrau Aphorism number 50:\nItalian medical researchers Alessia Coralli and Antonio Perciaccante have posited in a 2016 article that Kafka may have had borderline personality disorder with co-occurring psychophysiological insomnia. Joan Lachkar interpreted as \"a vivid depiction of the borderline personality\" and described the story as \"model for Kafka's own abandonment fears, anxiety, depression, and parasitic dependency needs. Kafka illuminated the borderline's general confusion of normal and healthy desires, wishes, and needs with something ugly and disdainful\".\nThough Kafka never married, he held marriage and children in high esteem. He had several girlfriends and lovers during his life. He may have suffered from an eating disorder. Doctor Manfred M. Fichter of the Psychiatric Clinic, University of Munich, presented \"evidence for the hypothesis that the writer Franz Kafka had suffered from an atypical anorexia nervosa\", and that Kafka was not just lonely and depressed but also \"occasionally suicidal\". In his 1995 book \"Franz Kafka, the Jewish Patient\", Sander Gilman investigated \"why a Jew might have been considered 'hypochondriacal' or 'homosexual' and how Kafka incorporates aspects of these ways of understanding the Jewish male into his own self-image and writing\". Kafka considered suicide at least once, in late 1912.\nPolitical views.\nBefore World War\u00a0I, Kafka attended several meetings of the \"Klub mlad\u00fdch\", a Czech anarchist, anti-militarist, and anti-clerical organization. Hugo Bergmann, who attended the same elementary and high schools as Kafka, fell out with Kafka during their last academic year (1900\u20131901) because \"[Kafka's] socialism and my Zionism were much too strident\". Bergmann said: \"Franz became a socialist, I became a Zionist in 1898. The synthesis of Zionism and socialism did not yet exist.\" Bergmann claims that Kafka wore a red carnation to school to show his support for socialism. In one diary entry, Kafka made reference to the influential anarchist philosopher Peter Kropotkin: \"Don't forget Kropotkin!\"\nDuring the communist era, the legacy of Kafka's work for Eastern Bloc socialism was hotly debated. Opinions ranged from the notion that he satirised the bureaucratic bungling of a crumbling Austro-Hungarian Empire, to the belief that he embodied the rise of socialism. A further key point was Marx's theory of alienation. While the orthodox position was that Kafka's depictions of alienation were no longer relevant for a society that had supposedly eliminated alienation, a 1963 conference held in Liblice, Czechoslovakia, on the eightieth anniversary of his birth, reassessed the importance of Kafka's portrayal of bureaucracy. Whether Kafka was a political writer is still an issue of debate.\nJudaism and Zionism.\nKafka grew up in Prague as a German-speaking Jew. He was deeply fascinated by the Jews of Eastern Europe, who he thought possessed an intensity of spiritual life that was absent from Jews in the West. His diary contains many references to Yiddish writers. Yet he was at times alienated from Judaism and Jewish life. On 8 January 1914, he wrote in his diary:\nIn his adolescent years, Kafka declared himself an atheist.\nHawes suggests that Kafka, though very aware of his own Jewishness, did not incorporate it into his work, which, according to Hawes, lacks Jewish characters, scenes or themes. In the opinion of literary critic Harold Bloom, although Kafka was uneasy with his Jewish heritage, he was the quintessential Jewish writer. Lothar Kahn is likewise unequivocal: \"The presence of Jewishness in Kafka's is no longer subject to doubt\". Pavel Eisner, one of Kafka's first translators, interprets (\"The Trial\") as the embodiment of the \"triple dimension of Jewish existence in Prague... his protagonist Josef K. is (symbolically) arrested by a German (Rabensteiner), a Czech (Kullich), and a Jew (Kaminer). He stands for the 'guiltless guilt' that imbues the Jew in the modern world, although there is no evidence that he himself is a Jew\".\nIn his essay \"Sadness in Palestine?!\", Dan Miron explores Kafka's connection to Zionism: \"It seems that those who claim that there was such a connection and that Zionism played a central role in his life and literary work, and those who deny the connection altogether or dismiss its importance, are both wrong. The truth lies in some very elusive place between these two simplistic poles.\" Kafka considered moving to Palestine with Felice Bauer, and later with Dora Diamant. He studied Hebrew while living in Berlin, hiring a friend of Brod's from Palestine, Pua Bat-Tovim, to tutor him and attending Rabbi Julius Gr\u00fcnthal and Rabbi Julius Guttmann's classes in the Berlin (College for the Study of Judaism), where he also studied Talmud.\nLivia Rothkirchen calls Kafka the \"symbolic figure of his era\". His contemporaries included numerous Jewish, Czech, and German writers who were sensitive to Jewish, Czech, and German culture. According to Rothkirchen, \"This situation lent their writings a broad cosmopolitan outlook and a quality of exaltation bordering on transcendental metaphysical contemplation. An illustrious example is Franz Kafka\".\nTowards the end of his life Kafka sent a postcard to his friend Hugo Bergmann in Tel Aviv, announcing his intention to emigrate to Palestine. Bergmann refused to host Kafka because he had young children and was afraid that Kafka would infect them with tuberculosis.\nDeath.\nKafka's laryngeal tuberculosis worsened and in March 1924 he returned from Berlin to Prague, where members of his family, principally his sister Ottla and Dora Diamant, took care of him. He went to Hugo Hoffmann's sanatorium in Kierling just outside Vienna for treatment on 10 April, and died there on 3 June 1924. The cause of death seemed to be starvation: the condition of Kafka's throat made eating too painful for him, and since parenteral nutrition had not yet been developed, there was no way to feed him. Kafka was editing \"A Hunger Artist\" on his deathbed, a story whose composition he had begun before his throat closed to the point that he could not take any nourishment. His body was brought back to Prague where he was buried on 11 June 1924, in the New Jewish Cemetery in Prague-\u017di\u017ekov. Kafka was virtually unknown during his own lifetime, but he did not consider fame important. He rose to fame rapidly after his death, particularly after World War II. The Kafka tombstone was designed by architect Leopold Ehrmann.\nWorks.\nAll of Kafka's published works were written in German. What little was published during his lifetime attracted scant public attention.\nKafka finished none of his full-length novels and burned around 90 percent of his work, much of it during the period he lived in Berlin with Diamant, who helped him burn the drafts. In his early years as a writer he was influenced by von Kleist, whose work he described in a letter to Bauer as frightening and whom he considered closer than his own family.\nKafka drew and sketched extensively. Until May 2021, only about 40 of his drawings were known. In 2022, Yale University Press published \"Franz Kafka: The Drawings\".\nStories.\nKafka's earliest published works were eight stories that appeared in 1908 in the first issue of the literary journal \"Hyperion\" under the title (\"Contemplation\"). He wrote the story \"\" (\"Description of a Struggle\") in 1904; in 1905 he showed it to Brod, who advised him to continue writing and convinced him to submit it to \"Hyperion\". Kafka published a fragment in 1908 and two sections in the spring of 1909, all in Munich.\nIn a creative outburst on the night of 22 September 1912, Kafka wrote the story \"Das Urteil\" (\"The Judgment\", literally: \"The Verdict\") and dedicated it to Felice Bauer. Brod noted the similarity in names of the main character and his fictional fianc\u00e9e, Georg Bendemann and Frieda Brandenfeld, to Franz Kafka and Felice Bauer. The story is often considered Kafka's breakthrough work. It deals with the troubled relationship of a son and his dominant father, facing a new situation after the son's engagement. Kafka later described writing it as \"a complete opening of body and soul\", a story that \"evolved as a true birth, covered with filth and slime\". The story was first published in Leipzig in 1912 and dedicated \"to Miss Felice Bauer\", and in subsequent editions \"for F.\"\nIn 1912, Kafka wrote \"Die Verwandlung\" (\"The Metamorphosis\", or \"The Transformation\"), published in 1915 in Leipzig. The story begins with a travelling salesman waking to find himself transformed into an , a monstrous vermin, being a general term for unwanted and unclean pests, especially insects. Critics regard the work as one of the seminal works of fiction of the 20th century. The story \"In der Strafkolonie\" (\"In the Penal Colony\"), dealing with an elaborate torture and execution device, was written in October 1914, revised in 1918, and published in Leipzig during October 1919. The story \"Ein Hungerk\u00fcnstler\" (\"A Hunger Artist\"), published in the periodical in 1924, describes a victimized protagonist who experiences a decline in the appreciation of his strange craft of starving himself for extended periods. His last story, \"Josefine, die S\u00e4ngerin oder Das Volk der M\u00e4use\" (\"Josephine the Singer, or the Mouse Folk\"), also deals with the relationship between an artist and his audience.\nNovels.\nKafka began his first novel in 1912; its first chapter is the story \"Der Heizer\" (\"The Stoker\"). He called the work, which remained unfinished, (\"The Man Who Disappeared\" or \"The Missing Person\"), but when Brod published it after Kafka's death he named it \"Amerika\". The inspiration for the novel was the time Kafka spent in the audience of Yiddish theatre the previous year, bringing him to a new awareness of his heritage, which led to the thought that an innate appreciation for one's heritage lives deep within each person. More explicitly humorous and slightly more realistic than most of Kafka's works, the novel shares the motif of an oppressive and intangible system putting the protagonist repeatedly in bizarre situations. It uses many details of experiences from his relatives who had emigrated to America and is the only work for which Kafka considered an optimistic ending.\nIn 1914 Kafka began the novel (\"The Trial\"), the story of a man arrested and prosecuted by a remote, inaccessible authority, with the nature of his crime revealed neither to him nor to the reader. He did not complete the novel, although he finished the final chapter. According to Nobel Prize winning author Elias Canetti, Felice is central to the plot of \"Der Process\" and Kafka said it was \"her story\". Canetti titled his book on Kafka's letters to Felice \"Kafka's Other Trial\", in recognition of the relationship between the letters and the novel. Michiko Kakutani notes in a review for \"The New York Times\" that Kafka's letters have the \"earmarks of his fiction: the same nervous attention to minute particulars; the same paranoid awareness of shifting balances of power; the same atmosphere of emotional suffocation\u2014combined, surprisingly enough, with moments of boyish ardour and delight.\"\nAccording to his diary, Kafka was already planning his novel (\"The Castle\"), by 11 June 1914; however, he did not begin writing it until 27 January 1922. The protagonist is the (land surveyor) named K., who struggles for unknown reasons to gain access to the mysterious authorities of a castle who govern the village. Kafka's intent was that the castle's authorities notify K. on his deathbed that his \"legal claim to live in the village was not valid, yet, taking certain auxiliary circumstances into account, he was to be permitted to live and work there\". Dark and at times surreal, the novel is focused on alienation, bureaucracy, the seemingly endless frustrations of man's attempts to stand against the system, and the futile and hopeless pursuit of an unattainable goal. Hartmut M. Rastalsky noted in his thesis: \"Like dreams, his texts combine precise 'realistic' detail with absurdity, careful observation and reasoning on the part of the protagonists with inexplicable obliviousness and carelessness.\"\nPublishing history.\nKafka's stories were initially published in literary periodicals. His first eight were printed in 1908 in the first issue of the bi-monthly \"Hyperion\". Franz Blei published two dialogues in 1909 which became part of \"Beschreibung eines Kampfes\" (\"Description of a Struggle\"). A fragment of the story \"Die Aeroplane in Brescia\" (\"The Aeroplanes at Brescia\"), written on a trip to Italy with Brod, appeared in the daily \"Bohemia\" on 28 September 1909. On 27 March 1910, several stories that later became part of the book were published in the Easter edition of \"Bohemia\". In Leipzig during 1913, Brod and publisher Kurt Wolff included \"\" (\"The Judgment. A Story by Franz Kafka.\") in their literary yearbook for the art poetry \"Arkadia\". In the same year, Wolff published \"Der Heizer\" (\"The Stoker\") in the J\u00fcngste Tag series, where it enjoyed three printings. The story \"\" (\"Before the Law\") was published in the 1915 New Year's edition of the independent Jewish weekly ; it was reprinted in 1919 as part of the story collection (\"A Country Doctor\") and became part of the novel . Other stories were published in various publications, including Martin Buber's \"Der Jude\", the paper , and the periodicals , \"Genius\", and \"Prager Presse\".\nKafka's first published book, (\"Contemplation\", or \"Meditation\"), was a collection of 18stories written between 1904 and 1912. On a summer trip to Weimar, Brod initiated a meeting between Kafka and Kurt Wolff; Wolff published in the at the end of 1912 (with the year given as 1913). Kafka dedicated it to Brod, \", and added in the personal copy given to his friend \" (\"As it is already printed here, for my dearest Max\").\nKafka's novella \"Die Verwandlung\" (\"The Metamorphosis\") was first printed in the October 1915 issue of , a monthly edition of expressionist literature, edited by Ren\u00e9 Schickele. Another story collection, (\"A Country Doctor\"), was published by Kurt Wolff in 1919, dedicated to Kafka's father. Kafka prepared a final collection of four stories for print, \"(A Hunger Artist)\", which appeared in 1924 after his death, in . On 20 April 1924, the published Kafka's essay on Adalbert Stifter.\nMax Brod.\nKafka left his work, both published and unpublished, to his friend and literary executor Max Brod with explicit instructions that it should be destroyed on Kafka's death; Kafka wrote: \"Dearest Max, my last request: Everything I leave behind me... in the way of diaries, manuscripts, letters (my own and others'), sketches, and so on, [is] to be burned unread.\" Brod ignored this request and published the novels and collected works between 1925 and 1935. Brod defended his action by claiming that he had told Kafka, \"I shall not carry out your wishes\", and that \"Franz should have appointed another executor if he had been absolutely determined that his instructions should stand\".\nBrod took many of Kafka's papers, which remain unpublished, with him in suitcases to Palestine when he fled there in 1939. Kafka's last lover, Dora Diamant (later, Dymant-Lask), also ignored his wishes, secretly keeping 20notebooks and 35letters. These were confiscated by the Gestapo in 1933, but scholars continue to search for them.\nAs Brod published the bulk of the writings in his possession, Kafka's work began to attract wider attention and critical acclaim. Brod found it difficult to arrange Kafka's notebooks in chronological order. One problem was that Kafka often began writing in different parts of the book; sometimes in the middle, sometimes working backwards from the end. Brod finished many of Kafka's incomplete works for publication. For example, Kafka left with unnumbered and incomplete chapters and with incomplete sentences and ambiguous content; Brod rearranged chapters, copy-edited the text, and changed the punctuation. appeared in 1925 in . Kurt Wolff published two other novels, in 1926 and \"Amerika\" in 1927. In 1931, Brod edited a collection of prose and unpublished stories as \"The Great Wall of China\", including the titular short story [[The Great Wall of China (short story)|\"The Great Wall of China\"]]. The book appeared in the [[Kiepenheuer &amp; Witsch|Gustav Kiepenheuer Verlag]]. Brod's sets are usually called the \"Definitive Editions\".\nModern editions.\nIn 1961 [[Malcolm Pasley]] acquired for the [[University of Oxford|Oxford]] [[Bodleian Library]] most of Kafka's original handwritten works. The text for was later purchased through auction and is stored at the German Literary Archives in [[Marbach am Neckar]], Germany. Subsequently, Pasley headed a team (including Gerhard Neumann, Jost Schillemeit and J\u00fcrgen Born) which reconstructed the German novels; republished them. Pasley was the editor for , published in 1982, and (\"The Trial\"), published in 1990. Jost Schillemeit was the editor of () published in 1983. These are called the \"Critical Editions\" or the \"Fischer Editions\".\nIn 2023, the first unexpurgated edition of [[Franz Kafka's Diaries|Kafka's diaries]] was published in English, \"more than three decades after this complete text appeared in German. The sole previous English edition, with Brod's edits, was issued in the late 1940s\". The new edition revealed that Brod had expunged homoerotic references, and negative comments about Eastern European Jews.\nUnpublished papers.\nWhen Brod died in 1968, he left Kafka's unpublished papers, which are believed to number in the thousands, to his secretary [[Esther Hoffe]]. She released or sold some, but left most to her daughters, Eva and Ruth, who also refused to release the papers. A court battle began in 2008 between the sisters and the [[National Library of Israel]], which claimed these works became the property of the nation of Israel when Brod emigrated to [[Mandatory Palestine|British Palestine]] in 1939. Esther Hoffe sold the original manuscript of for US$2\u00a0million in 1988 to the German Literary Archive [[Museum of Modern Literature]] in Marbach am Neckar. A ruling by a Tel Aviv family court in 2010 held that the papers must be released and a few were, including a previously unknown story, but the legal battle continued. The Hoffes claim the papers are their personal property, while the National Library of Israel argues they are \"cultural assets belonging to the Jewish people\". The National Library also suggests that Brod bequeathed the papers to them in his will. The Tel Aviv Family Court ruled in October 2012, six months after Ruth's death, that the papers were the property of the National Library. The Israeli Supreme Court upheld the decision in December 2016.\nCritical response.\nCritical interpretations.\nThe poet [[W. H. Auden]] called Kafka \"the [[Dante]] of the twentieth century\"; the novelist [[Vladimir Nabokov]] placed him among the greatest writers of the 20th century. [[Gabriel Garc\u00eda M\u00e1rquez]] noted the reading of Kafka's \"The Metamorphosis\" showed him \"that it was possible to write in a different way\". A prominent theme of Kafka's work, first established in the short story \"Das Urteil\", is father\u2013son conflict: the guilt induced in the son is resolved through suffering and atonement. Other prominent themes and archetypes include alienation, physical and psychological brutality, characters on a terrifying quest, and mystical transformation.\nKafka's style has been compared to that of Kleist as early as 1916, in a review of \"Die Verwandlung\" and \"Der Heizer\" by Oscar Walzel in \"Berliner Beitr\u00e4ge\". The nature of Kafka's prose allows for varied interpretations and critics have placed his writing into a variety of literary schools. [[Marxism|Marxists]], for example, have sharply disagreed over how to interpret Kafka's works. Some accused him of distorting reality whereas others claimed he was critiquing capitalism. The hopelessness and absurdity common to his works are seen as emblematic of [[existentialism]]. Some of Kafka's books are influenced by the [[expressionism|expressionist]] movement, though the majority of his literary output was associated with the experimental [[Literary modernism|modernist]] genre. Kafka also touches on the theme of human conflict with bureaucracy. William Burrows claims that such work is centred on the concepts of struggle, pain, solitude, and the need for relationships. Others, such as [[Thomas Mann]], see Kafka's work as allegorical: a quest, metaphysical in nature, for God.\nAccording to [[Gilles Deleuze]] and [[F\u00e9lix Guattari]], the themes of alienation and persecution, although present in Kafka's work, have been overemphasised by critics. They argue that Kafka's work is more deliberate and subversive\u2014and more joyful\u2014than may first appear. They point out that reading Kafka while focusing on the futility of his characters' struggles reveals Kafka's humour; he is not necessarily commenting on his own problems, but rather pointing out how people tend to invent problems. In his work, Kafka often creates malevolent, absurd worlds. Kafka read drafts of his works to his friends, typically concentrating on his humorous prose. The writer [[Milan Kundera]] suggests that Kafka's [[surreal humour|surrealist humour]] may have been an inversion of Dostoevsky's presentation of characters who are punished for a crime. In Kafka's work, a character is punished although a crime has not been committed. Kundera believes that Kafka's inspirations for his characteristic situations came both from growing up in a patriarchal family and from living in a totalitarian state.\nAttempts have been made to identify the influence of Kafka's legal background and the role of law in his fiction. Most interpretations identify aspects of law and legality as important in his work, in which the legal system is often oppressive. The law in Kafka's works, rather than being representative of any particular legal or political entity, is usually interpreted to represent a collection of anonymous, incomprehensible forces. These are hidden from the individual but control the lives of the people, who are innocent victims of systems beyond their control. Critics who support this [[absurdism|absurdist]] interpretation cite instances where Kafka describes himself in conflict with an absurd universe, such as the following entry from his diary:\nHowever, James Hawes argues many of Kafka's descriptions of the legal proceedings in \u2014metaphysical, absurd, bewildering and nightmarish as they might appear\u2014are based on accurate and informed descriptions of German and Austrian criminal proceedings of the time, which were [[Inquisitorial system|inquisitorial]] rather than [[Adversarial system|adversarial]]. Although he worked in insurance, as a trained lawyer Kafka was \"keenly aware of the legal debates of his day\". In an early 21st-century publication that uses Kafka's office writings as its point of departure, Pothik Ghosh states that with Kafka, law \"has no meaning outside its fact of being a pure force of domination and determination\".\nTranslations.\nThe first instance of Kafka being translated into English was in 1925, when William A. Drake published \"A Report for an Academy\" in the \"[[New York Herald Tribune]]\". Eugene Jolas translated Kafka's \"The Judgment\" for the modernist journal \"[[Transition (literary journal) (1927-1938)|transition]]\" in 1928. In 1930, [[Edwin Muir|Edwin]] and [[Willa Muir]] translated the first German edition of . This was published as \"The Castle\" by [[Secker &amp; Warburg]] in England and [[Alfred A. Knopf]] in the United States. A 1941 edition, including a homage by Thomas Mann, spurred a surge in Kafka's popularity in the United States during the late 1940s. The Muirs translated all shorter works that Kafka had seen fit to print; they were published by [[Schocken Books]] in 1948 as \"[[The Penal Colony: Stories and Short Pieces]]\", including additionally \"The First Long Train Journey\", written by Kafka and Brod, Kafka's \"A Novel about Youth\", a review of Felix Sternheim's \"Die Geschichte des jungen Oswald\", his essay on Kleist's \"Anecdotes\", his review of the literary magazine \"[[Hyperion (magazine)|Hyperion]]\", and an epilogue by Brod.\nLater editions, notably those of 1954 (\"[[Dearest Father: Stories and Other Writings]]\"), included text, translated by [[Eithne Wilkins]] and [[Ernst Kaiser]], that had been deleted by earlier publishers. Known as \"Definitive Editions\", they include translations of \"The Trial, Definitive\", \"[[The Castle, Definitive Edition, Muir Translation|The Castle, Definitive]]\", and other writings. These translations are generally accepted to have a number of biases and are considered to be dated in interpretation. Published in 1961 by Schocken Books, \"[[Parables and Paradoxes]]\" presented in a bilingual edition by [[Nahum N. Glatzer]] selected writings, drawn from notebooks, diaries, letters, short fictional works and the novel \"Der Process\".\nNew translations were completed and published based on the recompiled German text of Pasley and Schillemeit\"[[The Castle, Critical Edition, Harman Translation|The Castle, Critical]]\" by [[Mark Harman (translator)|Mark Harman]] ([[Schocken Books]], 1998), \"The Trial, Critical\" by [[Breon Mitchell]] (Schocken Books, 1998), and \"The Man Who Disappeared (Amerika)\" by [[Michael Hofmann]] ([[Penguin Books]], 1996) and \"Amerika: The Missing Person\" by Mark Harman (Schocken Books, 2008).\nTranslation problems to English.\nKafka often made extensive use of a characteristic particular to German, which permits long sentences that sometimes can span an entire page. Kafka's sentences then deliver an unexpected impact just before the full stop\u2014this being the finalizing meaning and focus. This is due to the construction of [[subordinate clauses in German]], which require that the verb be at the end of the sentence. Such constructions are difficult to duplicate in English, so it is up to the translator to provide the reader with the same (or at least equivalent) effect as the original text. German's more flexible word order and [[Syntactic ambiguity|syntactical]] differences provide for multiple ways in which the same German writing can be translated into English. An example is the first sentence of Kafka's [[The Metamorphosis#translation|\"The Metamorphosis\"]], which is crucial to the setting and understanding of the entire story:\nThe sentence above also exemplifies an instance of another difficult problem facing translators: dealing with the author's intentional use of ambiguous [[idiom]]s and words that have several meanings, which results in phrasing that is difficult to translate precisely. English translators often render the word as 'insect'; in Middle German, however, literally means 'an animal unclean for sacrifice'; in today's German, it means 'vermin'. It is sometimes used colloquially to mean 'bug'\u2014a very general term, unlike the scientific 'insect'. Kafka had no intention of labeling Gregor, the protagonist of the story, as any specific thing but instead wanted to convey Gregor's disgust at his transformation. Another example of this can be found in the final sentence of \"[[Das Urteil]]\" (\"The Judgement\"), with Kafka's use of the German noun . Literally, means 'intercourse' and, as in English, can have either a sexual or a non-sexual meaning. The word is additionally used to mean 'transport' or 'traffic'; therefore the sentence can also be translated as: \"At that moment an unending stream of traffic crossed over the bridge.\" The double meaning of \"Verkehr\" is given added weight by Kafka's confession to Brod that when he wrote that final line he was thinking of \"a violent ejaculation\".\nLegacy.\nLiterary and cultural influence.\n[[File:Kafka statue Prague.jpg|thumb|upright=.6|[[Jaroslav R\u00f3na]]'s bronze \"[[Statue of Franz Kafka]]\" in Prague|alt=The statue is a man with no head or arms, with another man sitting on his shoulders]]\nUnlike many famous writers, Kafka is rarely quoted by others. Instead, he is noted more for his visions and perspective. Kafka had a strong influence on [[Gabriel Garc\u00eda M\u00e1rquez]], [[Milan Kundera]] and the novel \"[[The Palace of Dreams]]\" by [[Ismail Kadare]]. Shimon Sandbank, a professor, literary critic, and writer, also identifies Kafka as having influenced [[Jorge Luis Borges]], [[Albert Camus]], [[Eug\u00e8ne Ionesco]], [[J. M. Coetzee]] and [[Jean-Paul Sartre]]. A \"[[Financial Times]]\" literary critic credits Kafka with influencing [[Jos\u00e9 Saramago]], and Al Silverman, a writer and editor, states that [[J. D. Salinger]] loved to read Kafka's works. The Romanian writer [[Mircea C\u0103rt\u0103rescu]] said \"Kafka is the author I love the most and who means, for me, the gate to literature\"; he also described Kafka as \"the saint of literature\".\nKafka has been cited as an influence on the Swedish writer [[Stig Dagerman]], and the Japanese writer [[Haruki Murakami]], who paid homage to Kafka in his novel \"[[Kafka on the Shore]]\" with the namesake protagonist.\n[[File:David-\u010cern\u00fd,-Franz-Kafka,-opposite orientation-2014).jpg|thumb|left|upright|[[David \u010cern\u00fd]]'s \"[[Head of Franz Kafka]]\" sculpture in Prague]]\nIn 1999 a committee of 99 authors, scholars, and literary critics ranked and the second and ninth [[Best German Novels of the Twentieth Century|most significant German-language novels of the 20th century]]. [[Harold Bloom]] said \"when he is most himself, Kafka gives us a continuous inventiveness and originality that rivals [[Dante]] and truly challenges [[Marcel Proust|Proust]] and [[James Joyce|Joyce]] as that of the dominant Western author of our century\". Sandbank argues that despite Kafka's pervasiveness, his enigmatic style has yet to be emulated. Neil Christian Pages, a professor of German Studies and Comparative Literature at [[Binghamton University]] who specialises in Kafka's works, says Kafka's influence transcends literature and literary scholarship; it impacts visual arts, music, and popular culture. Harry Steinhauer, a professor of German and Jewish literature, says that Kafka \"has made a more powerful impact on literate society than any other writer of the twentieth century\". Brod said that the 20th century will one day be known as the \"century of Kafka\".\nMichel-Andr\u00e9 Bossy writes that Kafka created a rigidly inflexible and sterile bureaucratic universe. Kafka wrote in an aloof manner full of legal and scientific terms. Yet his serious universe also had insightful humour, all highlighting the \"irrationality at the roots of a supposedly rational world\". His characters are trapped, confused, full of guilt, frustrated, and lacking understanding of their surreal world. Much post-Kafka fiction, especially science fiction, follows the themes and precepts of Kafka's universe. This can be seen in the works of authors such as [[George Orwell]] and [[Ray Bradbury]].\nThe following are examples of works across a range of dramatic, literary, and musical genres that demonstrate the extent of Kafka's cultural influence:\n\"Kafkaesque\".\nThe term \"Kafkaesque\" is used to describe concepts and situations reminiscent of Kafka's work, particularly (\"[[The Trial]]\") and \"Die Verwandlung\" (\"[[The Metamorphosis]]\"). Examples include instances in which bureaucracies overpower people, often in a [[Surrealism|surreal]], nightmarish milieu that evokes feelings of senselessness, disorientation, and helplessness. Characters in a Kafkaesque setting often lack a clear course of action to escape a [[labyrinthine]] situation. Kafkaesque elements often appear in [[Existentialism#Influence outside philosophy|existential works]], but the term has transcended the literary realm to apply to real-life occurrences and situations that are incomprehensibly complex, bizarre, or illogical.\nNumerous films and television works have been described as Kafkaesque, and the style is particularly prominent in dystopian science fiction. Works in this genre that have been thus described include [[Patrick Bokanowski]]'s film \"[[The Angel (1982 film)|The Angel]]\" (1982), Terry Gilliam's film \"[[Brazil (1985 film)|Brazil]]\" (1985), and [[Alex Proyas]]' science fiction [[film noir]], \"[[Dark City (1998 film)|Dark City]]\" (1998). Films from other genres which have been similarly described include [[Roman Polanski]]'s \"[[The Tenant]]\" (1976), [[Joseph Losey]]\u2019s \"[[Monsieur Klein]]\" (1976) and the [[Coen brothers]]' \"[[Barton Fink]]\" (1991). The television series \"[[The Prisoner]]\" and \"[[The Twilight Zone]]\" are also frequently described as Kafkaesque.\nHowever, with common usage, the term has become so ubiquitous that Kafka scholars note it is often misused. More accurately then, according to author [[Ben Marcus]], paraphrased in \"What it Means to be Kafkaesque\" by Joe Fassler in \"The Atlantic\", \"Kafka's quintessential qualities are affecting use of language, a setting that straddles fantasy and reality, and a sense of striving even in the face of bleakness\u2014hopelessly and full of hope.\"\nCommemorations.\n[[File:Czech-2013-Prague-Plaque (birthplace of Franz Kafka).jpg|thumb|Plaque marking the birthplace of Franz Kafka in Prague, designed by Karel Hlad\u00edk and Jan Kaplick\u00fd, 1966]]\n[[3412 Kafka]] is an [[asteroid]] from the inner regions of the [[asteroid belt]], approximately 6 kilometers in diameter. It was discovered on 10 January 1983 by American astronomers [[Randolph L. Kirk|Randolph Kirk]] and [[Donald James Rudy|Donald Rudy]] at [[Palomar Observatory]] in California, United States, and named after Kafka by them.\nThe [[Franz Kafka Museum]] in Prague is dedicated to Kafka and his work. A major component of the museum is an exhibit, \"The City of K. Franz Kafka and Prague\", which was first shown in Barcelona in 1999, moved to the [[Jewish Museum (Manhattan)|Jewish Museum]] in New York City, and finally established in Prague in [[Mal\u00e1 Strana]] (Lesser Town), along the [[Vltava|Moldau]], in 2005. The museum aims with this exhibit to immerse the visitor into the world in which Kafka lived and about which he wrote.\nThe [[Franz Kafka Prize]], established in 2001, is an annual literary award of the [[Franz Kafka Society]] and the City of Prague. It recognizes the merits of literature as \"humanistic character and contribution to cultural, national, language and religious tolerance, its existential, timeless character, its generally human validity, and its ability to hand over a testimony about our times\". The selection committee and recipients come from all over the world, but are limited to living authors who have had at least one work published in Czech. The recipient receives $10,000, a diploma, and a bronze statuette at a presentation in [[Old Town (Prague)|Prague's Old Town Hall]], on the Czech State Holiday in late October.\n[[San Diego State University]] operates the [[Kafka Project]], which began in 1998 as the official international search for Kafka's last writings.\nFurther reading.\nBooks on Kafka and Prague\nJournals\nExternal links.\n[[Category:Franz Kafka| ]]\n[[Category:1883 births]]\n[[Category:1924 deaths]]\n[[Category:19th-century Austrian people]]\n[[Category:20th-century Austrian novelists]]\n[[Category:20th-century deaths from tuberculosis]]\n[[Category:Absurdist writers]]\n[[Category:Aphorists]]\n[[Category:Jews from Austria-Hungary]]\n[[Category:Austrian atheists]]\n[[Category:Austrian civil servants]]\n[[Category:Austrian male novelists]]\n[[Category:Austrian socialists]]\n[[Category:Austrian surrealist writers]]\n[[Category:Charles University alumni]]\n[[Category:Czech atheists]]\n[[Category:Czech diarists]]\n[[Category:Czechoslovak Jews]]\n[[Category:Czech surrealist writers]]\n[[Category:Czech writers in German]]\n[[Category:Czechoslovak writers]]\n[[Category:Fabulists]]\n[[Category:Jewish atheists]]\n[[Category:Jewish Czech writers]]\n[[Category:Jewish existentialists]]\n[[Category:Jewish novelists]]\n[[Category:Jewish socialists]]\n[[Category:Jewish surrealist writers]]\n[[Category:Magic realism writers]]\n[[Category:Modernist writers]]\n[[Category:20th-century Czech Jews]]\n[[Category:Tuberculosis deaths in Austria]]\n[[Category:Writers from Austria-Hungary]]\n[[Category:Writers from Prague]]\n[[Category:20th-century Austrian male writers]]"}
{"id": "10859", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=10859", "title": "Fields Medal", "text": "The Fields Medal is a prize awarded to two, three, or four mathematicians under 40 years of age at the International Congress of the International Mathematical Union (IMU), a meeting that takes place every four years. The name of the award honours the Canadian mathematician John Charles Fields.\nThe Fields Medal is regarded as one of the highest honors a mathematician can receive, and has been described as the Nobel Prize of Mathematics, although there are several major differences, including frequency of award, number of awards, age limits, monetary value, and award criteria. According to the annual Academic Excellence Survey by ARWU, the Fields Medal is consistently regarded as the top award in the field of mathematics worldwide, and in another reputation survey conducted by IREG in 2013\u201314, the Fields Medal came closely after the Abel Prize as the second most prestigious international award in mathematics.\nThe prize includes a monetary award which, since 2006, has been 15,000. Fields was instrumental in establishing the award, designing the medal himself, and funding the monetary component, though he died before it was established and his plan was overseen by John Lighton Synge.\nThe medal was first awarded in 1936 to Finnish mathematician Lars Ahlfors and American mathematician Jesse Douglas, and it has been awarded every four years since 1950. Its purpose is to give recognition and support to younger mathematical researchers who have made major contributions. In 2014, the Iranian mathematician Maryam Mirzakhani became the first female Fields Medalist. In total, 64 people have been awarded the Fields Medal.\nThe most recent group of Fields Medalists received their awards on 5 July 2022 in an online event which was live-streamed from Helsinki, Finland. It was originally meant to be held in Saint Petersburg, Russia, but was moved following the 2022 Russian invasion of Ukraine.\nConditions of the award.\nThe Fields Medal has for a long time been regarded as the most prestigious award in the field of mathematics and is often described as the Nobel Prize of Mathematics. Unlike the Nobel Prize, the Fields Medal is only awarded every four years. The Fields Medal also has an age limit: a recipient must be under age 40 on 1 January of the year in which the medal is awarded. The under-40 rule is based on Fields's desire that \"while it was in recognition of work already done, it was at the same time intended to be an encouragement for further achievement on the part of the recipients and a stimulus to renewed effort on the part of others.\" Moreover, an individual can only be awarded one Fields Medal; winners are ineligible to be awarded future medals.\nFirst awarded in 1936, 64 people have won the medal as of 2022. With the exception of two PhD holders in physics (Edward Witten and Martin Hairer), only people with a PhD in mathematics have won the medal.\nList of Fields medalists.\nIn certain years, the Fields medalists have been officially cited for particular mathematical achievements, while in other years such specificities have not been given. However, in every year that the medal has been awarded, noted mathematicians have lectured at the International Congress of Mathematicians on each medalist's body of work. In the following table, official citations are quoted when possible (namely for the years 1958, 1998, and every year since 2006). For the other years through 1986, summaries of the ICM lectures, as written by Donald Albers, Gerald L. Alexanderson, and Constance Reid, are quoted. In the remaining years (1990, 1994, and 2002), part of the text of the ICM lecture itself has been quoted. The upcoming awarding of the Fields Medal at the 2026 International Congress of the International Mathematical Union is planned to take place in Philadelphia.\nLandmarks.\nThe medal was first awarded in 1936 to the Finnish mathematician Lars Ahlfors and the American mathematician Jesse Douglas, and it has been awarded every four years since 1950. Its purpose is to give recognition and support to younger mathematical researchers who have made major contributions.\nIn 1954, Jean-Pierre Serre became the youngest winner of the Fields Medal, at 27. He retains this distinction.\nIn 1966, Alexander Grothendieck boycotted the ICM, held in Moscow, to protest Soviet military actions taking place in Eastern Europe. L\u00e9on Motchane, founder and director of the Institut des Hautes \u00c9tudes Scientifiques, attended and accepted Grothendieck's Fields Medal on his behalf.\nIn 1970, Sergei Novikov, because of restrictions placed on him by the Soviet government, was unable to travel to the congress in Nice to receive his medal.\nIn 1978, Grigory Margulis, because of restrictions placed on him by the Soviet government, was unable to travel to the congress in Helsinki to receive his medal. The award was accepted on his behalf by Jacques Tits, who said in his address: \"I cannot but express my deep disappointment\u2014no doubt shared by many people here\u2014in the absence of Margulis from this ceremony. In view of the symbolic meaning of this city of Helsinki, I had indeed grounds to hope that I would have a chance at last to meet a mathematician whom I know only through his work and for whom I have the greatest respect and admiration.\"\nIn 1982, the congress was due to be held in Warsaw but had to be rescheduled to the next year, because of martial law introduced in Poland on 13 December 1981. The awards were announced at the ninth General Assembly of the IMU earlier in the year and awarded at the 1983 Warsaw congress.\nIn 1990, Edward Witten became the first physicist to win the award.\nIn 1998, at the ICM, Andrew Wiles was presented by the chair of the Fields Medal Committee, Yuri I. Manin, with the first-ever IMU silver plaque in recognition of his proof of Fermat's Last Theorem. Don Zagier referred to the plaque as a \"quantized Fields Medal\". Accounts of this award frequently make reference that at the time of the award Wiles was over the age limit for the Fields medal. Although Wiles was slightly over the age limit in 1994, he was thought to be a favorite to win the medal; however, a gap (later resolved by Taylor and Wiles) in the proof was found in 1993.\nIn 2006, Grigori Perelman, who proved the Poincar\u00e9 conjecture, refused his Fields Medal and did not attend the congress.\nIn 2014, Maryam Mirzakhani became the first Iranian as well as the first woman to win the Fields Medal, and Artur Avila became the first South American and Manjul Bhargava became the first person of Indian origin to do so.\nIn 2022, Maryna Viazovska became the first Ukrainian to win the Fields Medal, and June Huh became the first person of Korean ancestry to do so.\nMedal.\nThe medal was designed by Canadian sculptor R. Tait McKenzie. It is made of 14KT gold, has a diameter of 63.5mm, and weighs 169g.\nTranslation: \"Mathematicians gathered from the entire world have awarded [understood but not written: 'this prize'] for outstanding writings.\"\nIn the background, there is the representation of Archimedes' tomb, with the carving illustrating his theorem On the Sphere and Cylinder, behind an olive branch. (This is the mathematical result of which Archimedes was reportedly most proud: Given a sphere and a circumscribed cylinder of the same height and diameter, the ratio between their volumes is equal to .)\nThe rim bears the name of the prizewinner.\nFemale recipients.\nThe Fields Medal has had two female recipients, Maryam Mirzakhani from Iran in 2014, and Maryna Viazovska from Ukraine in 2022.\nIn popular culture.\nThe Fields Medal gained some recognition in popular culture due to references in the 1997 film, \"Good Will Hunting\". In the movie, Gerald Lambeau (Stellan Skarsg\u00e5rd) is an MIT professor who won the award prior to the events of the story. Throughout the film, references made to the award are meant to convey its prestige in the field."}
{"id": "10861", "revid": "41526883", "url": "https://en.wikipedia.org/wiki?curid=10861", "title": "The Trial", "text": "The Trial () is a novel written by Franz Kafka in 1914 and 1915 and published posthumously on 26 April 1925. One of his best-known works, it tells the story of Josef K., a man arrested and prosecuted by a remote, inaccessible authority, with the nature of his crime revealed neither to him nor to the reader. Heavily influenced by Dostoevsky's \"Crime and Punishment\" and \"The Brothers Karamazov\", Kafka even went so far as to call Dostoevsky a blood relative. Like Kafka's two other novels, \"The Castle\" and \"Amerika\", \"The Trial\" was never completed, although it does include a chapter that appears to bring the story to an intentionally abrupt ending.\nAfter Kafka's death in 1924, his friend and literary executor Max Brod edited the text for publication by Verlag Die Schmiede. The original manuscript is held at the Museum of Modern Literature, Marbach am Neckar, Germany. The first English-language translation, by Willa and Edwin Muir, was published in 1937. In 1999, the book was listed in \"Le Monde\" 100 Books of the Century and as No.\u00a02 of the Best German Novels of the Twentieth Century.\nDevelopment.\nKafka drafted the opening sentence of \"The Trial\" in August 1914 and worked on the novel throughout 1915. This was an unusually productive period for Kafka, despite the outbreak of World War I, which significantly increased the pressures of his day job as an insurance agent.\nHaving begun by writing the opening and concluding sections of the novel, Kafka worked on the intervening scenes in a haphazard manner, using several different notebooks simultaneously. His friend Max Brod, knowing Kafka's habit of destroying his own work, eventually took the manuscript for safekeeping. It consisted of 161 loose pages torn from notebooks, which Kafka had bundled together into chapters. The order of the chapters was not made clear to Brod; nor was he told which parts were complete and which were unfinished. Following Kafka's death in 1924, Brod edited the work and assembled it into a novel to the best of his ability. Further editorial work has been done by later scholars, but Kafka's final vision for \"The Trial\" remains unknown.\nPlot summary.\nOn the morning of his thirtieth birthday, Josef K., the chief clerk of a bank, is unexpectedly arrested by two agents from an unidentified agency for an unspecified crime. The agents discuss the situation with Josef in the unoccupied room of his fellow lodger Fr\u00e4ulein B\u00fcrstner, in the unexplained presence of three junior clerks from Josef's bank. Josef is not imprisoned, but left free to go about his business. His landlady, Frau Grubach, tries to console Josef about the trial. He visits B\u00fcrstner to explain the events, and then harasses her by kissing her without consent.\nJosef finds that Fr\u00e4ulein Montag, a lodger from another room, has moved in with Fr\u00e4ulein B\u00fcrstner. He suspects that this is a coy manoeuvre meant to distance him from B\u00fcrstner, and resolves that she will eventually fall for his charms.\nJosef is summoned to appear at the court's address the coming Sunday, without being told the time or location. After a period of exploration he finds the court in the attic of a dilapidated working-class tenement block, at the back of a young washerwoman's home. Josef is rebuked for his lateness and mistaken for a house painter rather than a bank clerk. He arouses the assembly's hostility after a passionate plea about the absurdity of the trial and the falseness of the accusation, despite still not knowing the charges. The proceedings are interrupted by a man sexually assaulting the washerwoman in a corner. Josef notices that all the assembly members are wearing pins on their lapels which he interprets as signifying their membership of a secret organisation.\nThe following Sunday Josef goes to the courtroom again, but the court is not in session. The washerwoman gives him information about the process and attempts to seduce him before a law student, the man who assaulted her the previous week, takes her away, claiming her to be his mistress. The woman's husband, a court usher, then takes Josef on a tour of the court offices, which ends after Josef becomes extremely weak in the presence of other court officials and defendants.\nOne evening, in a storage room at his own bank, Josef discovers the two agents who arrested him being whipped for soliciting bribes from Josef, which he had complained about at court. Josef tries to argue with the flogger, saying that the men need not be whipped, but the flogger cannot be swayed. The next day he returns to the storage room and is shocked to find everything as he had found it the day before, including the whipper and the two agents.\nJosef is visited by his uncle Karl, who lives in the country. Worried by the rumors about his nephew, Karl introduces Josef to Herr Huld, a sickly and bedridden lawyer tended to by Leni, a young woman who shows an immediate attraction to Josef. During a conversation between Karl and Huld about Josef's case, Leni calls Josef away for a sexual encounter. Afterwards, Josef meets his angry uncle outside, who claims that Josef's lack of respect for the advocate, by leaving the meeting and romantically engaging with the woman who is apparently Huld's mistress, has hurt his case.\nJosef has become increasingly preoccupied by his case, to the detriment of his work. He has further meetings with Huld, and continues to engage in discreet trysts with Leni, but the advocate's work appears to be having no effect on the proceedings. At the bank, one of Josef's clients recommends he seek the advice of Titorelli, the court's official painter. Titorelli outlines the options he can help Josef pursue: indefinite postponement of the process, or a temporary acquittal that could at any point result in re-arrest. Unequivocal acquittal is not a viable option. \nSuspicious of the advocate's motives and the apparent lack of progress, Josef finally decides to dismiss Huld and take control of matters himself. Upon arriving at Huld's office, he meets a downtrodden merchant, Rudi Block, who offers Josef some insight from a fellow defendant's perspective. Block's case has continued for five years and he has gone from being a successful businessman to being almost bankrupt and is virtually enslaved by his dependence on the lawyer and Leni, with whom he appears to be sexually involved. The lawyer mocks Block in front of Josef for his dog-like subservience. This experience further poisons Josef's opinion of his lawyer.\nJosef is put in charge of accompanying an important Italian client to the city's cathedral, but the client never meets him there. While inside the cathedral, a priest calls Josef by name and tells him a fable (which was published earlier as \"Before the Law\") that is meant to explain his situation. The priest tells Josef that the parable is an ancient text of the court, and many generations of court officials have interpreted it differently.\nOn the eve of Josef's thirty-first birthday, two men arrive at his apartment. The three walk through the city, and Josef catches a brief glimpse of Fr\u00e4ulein B\u00fcrstner. They arrive at a small quarry outside the city, and the men kill Josef, stabbing him in the heart with a butcher's knife while strangling him. Josef summarizes his situation with his last words: \"Like a dog!\"."}
{"id": "10862", "revid": "34975998", "url": "https://en.wikipedia.org/wiki?curid=10862", "title": "The Metamorphosis", "text": "The Metamorphosis (), also translated as The Transformation, is a novella by Franz Kafka published in 1915. One of Kafka's best-known works, \"The Metamorphosis\" tells the story of salesman Gregor Samsa, who wakes one morning to find himself inexplicably transformed into a huge insect (, \"monstrous vermin\") and struggles to adjust to this condition. The novella has been widely discussed among literary critics, who have offered varied interpretations. In popular culture and adaptations of the novella, the insect is commonly depicted as a cockroach. \nAbout 70 printed pages, it is the longest of the stories Kafka considered complete and published during his lifetime. It was first published in 1915 in the October issue of the journal \"Die wei\u00dfen Bl\u00e4tter\" under the editorship of Ren\u00e9 Schickele. The first edition in book form appeared in December 1915 in the series \"Der j\u00fcngste Tag\", edited by Kurt Wolff.\nPlot.\nGregor Samsa wakes up one morning to find himself transformed into a \"monstrous vermin\". He initially considers the transformation to be temporary and slowly ponders the consequences of his metamorphosis. Stuck on his back and unable to get up and leave the bed, Gregor reflects on his job as a traveling salesman and cloth merchant, which he characterizes as being full of \"temporary and constantly changing human relationships, which never come from the heart\". He sees his employer as a despot and would quickly quit his job if he were not his family's sole breadwinner and working off his bankrupt father's debts. While trying to move, Gregor finds that his office manager, the chief clerk, has shown up to check on him, indignant about Gregor's unexcused absence. Gregor attempts to communicate with both the manager and his family, but all they can hear from behind the door is incomprehensible vocalizations. Gregor laboriously drags himself across the floor and opens the door. The clerk, upon seeing the transformed Gregor, flees the apartment. Gregor's family is horrified, and his father drives him back towards his room. Gregor is injured when he tries to force himself through the doorway (which is too narrow for him), but gets unstuck when his father shoves him through.\nWith Gregor's unexpected transformation, his family is deprived of financial stability. They keep Gregor locked in his room, and he begins to accept his new identity and adapt to his new body. His sister Grete is the only one willing to bring him food, which she finds Gregor only likes if it is rotten. He spends much of his time crawling around on the floor, walls, and ceiling. Upon discovering Gregor's new pastime, Grete decides to remove his furniture to give him more space. She and her mother begin to empty the room of everything, except the sofa under which Gregor hides whenever anyone comes in. He finds their actions deeply distressing, fearing that he might forget his past as a human, and desperately tries to save a particularly loved portrait on the wall of a woman clad in fur. His mother loses consciousness at the sight of him clinging to the image to protect it. When Grete rushes out of the room to get some aromatic spirits, Gregor follows her and is slightly hurt when she drops a medicine bottle and it breaks. Their father returns home and angrily hurls apples at Gregor, one of which becomes lodged in a sensitive spot in his back and severely wounds him.\nGregor suffers from his injuries and eats very little. His father, mother, and sister all get jobs and increasingly begin to neglect him, and his room begins to be used for storage. For a time, his family leaves Gregor's door open in the evenings so he can listen to them talk to each other, but this happens less frequently once they rent a room in the apartment to three male tenants, since they are not told about Gregor. One day, the charwoman, who briefly looks in on Gregor each day when she arrives and before she leaves, neglects to close his door fully. Attracted by Grete's violin-playing in the living room, Gregor crawls out and is spotted by the unsuspecting tenants, who complain about the apartment's unhygienic conditions and say they are leaving, will not pay anything for the time they have already stayed, and may take legal action. Grete, who is tired of taking care of Gregor and realizes the burden his existence puts on each member of the family, tells her parents they must get rid of \"it\" or they will all be ruined. Gregor, understanding that he is no longer wanted, laboriously makes his way back to his room and dies of starvation before sunrise. His body is discovered by the charwoman, who alerts his family and then disposes of the corpse. The relieved and optimistic father, mother, and sister all take the day off work. They travel by tram into the countryside and make plans to move to a smaller apartment to save money. During the short trip, Mr. and Mrs. Samsa realize that, despite the hardships that have brought some paleness to her face, Grete has grown up into a pretty young lady with a good figure and they think about finding her a husband.\nCharacters.\nGregor Samsa.\nGregor is the main character of the story. He works as a traveling salesman in order to provide money for his sister and parents. He wakes up one morning finding himself transformed into an insect. After the metamorphosis, Gregor becomes unable to work and is confined to his room for most of the remainder of the story. This prompts his family to begin working once again. Gregor is depicted as isolated from society and often both misunderstands the true intentions of others and is misunderstood.\nGrete Samsa.\nGrete is Gregor's younger sister, and she becomes his caretaker after his metamorphosis. They initially have a close relationship, but this quickly fades. At first, she volunteers to feed him and clean his room, but she grows increasingly impatient with the burden and begins to leave his room in disarray out of spite. Her initial decision to take care of Gregor may have come from a desire to contribute and be useful to the family, since she becomes angry and upset when the mother cleans his room. It is made clear that Grete is disgusted by Gregor, as she always opens the window upon entering his room to keep from feeling nauseous and leaves without doing anything if Gregor is in plain sight. She plays the violin and dreams of going to the conservatory to study, a dream Gregor had intended to make happen; he had planned on making the announcement on Christmas Day. To help provide an income for the family after Gregor's transformation, she starts working as a salesgirl. Grete is also the first to suggest getting rid of Gregor, which causes Gregor to plan his own death. At the end of the story, Grete's parents realize that she has become beautiful and full-figured and decide to consider finding her a husband.\nMr. Samsa.\nMr. Samsa is Gregor's father. After the metamorphosis, he is forced to return to work in order to support the family financially. His attitude towards his son is harsh. He regards the transformed Gregor with disgust and possibly even fear and attacks Gregor on several occasions. Even when Gregor was human, Mr. Samsa regarded him mostly as a source of income for the family. Gregor's relationship with his father is modelled after Kafka's own relationship with his father. The theme of alienation becomes quite evident here.\nMrs. Samsa.\nMrs. Samsa is Gregor's mother. She is portrayed as a submissive wife. She suffers from asthma, which is a constant source of concern for Gregor. She is initially shocked at Gregor's transformation, but she still wants to enter his room. However, it proves too much for her and gives rise to a conflict between her maternal impulse and sympathy and her fear and revulsion at Gregor's new form.\nThe Charwoman.\nThe charwoman is an old widowed lady who is employed by the Samsa family after their previous maid begs to be dismissed on account of the fright she experiences owing to Gregor's new form. She is paid to take care of their household duties. Apart from Grete and her father, the charwoman is the only person who is in close contact with Gregor, and she is unafraid in her dealings with Gregor. She does not question his changed state; she seemingly accepts it as a normal part of his existence. She is the one who notices Gregor has died and disposes of his body.\nInterpretation.\nLike much of Kafka's work, \"The Metamorphosis\" tends to be given a religious (Max Brod) or psychological interpretation. It has been particularly common to read the story as an expression of Kafka's father complex, as was first done by Charles Neider in his \"The Frozen Sea: A Study of Franz Kafka\" (1948). Besides the psychological approach, interpretations focusing on sociological aspects, which see the Samsa family as a portrayal of general social circumstances, have also gained a large following.\nVladimir Nabokov rejected such interpretations, noting that they do not live up to Kafka's art. He instead chose an interpretation guided by the artistic detail but excluded any symbolic or allegoric meanings. Arguing against the popular father-complex theory, he observed that it is the sister more than the father who should be considered the cruelest person in the story, since she is the one backstabbing Gregor. In Nabokov's view, the central narrative theme is the artist's struggle for existence in a society replete with narrow-minded people who destroy him step by step. Commenting on Kafka's style, he writes, \"The transparency of his style underlines the dark richness of his fantasy world. Contrast and uniformity, style and the depicted, portrayal and fable are seamlessly intertwined\".\nIn 1989, Nina Pelikan Straus wrote a feminist interpretation of \"The Metamorphosis\", noting that the story is not only about the metamorphosis of Gregor but also about the metamorphosis of his family and, in particular, his younger sister Grete. Straus suggested that the social and psychoanalytic resonances of the text depend on Grete's role as a woman, daughter, and sister, and that prior interpretations failed to recognize Grete's centrality to the story.\nIn 1999, Gerhard Rieck pointed out that Gregor and his sister, Grete, form a pair, which is typical of many of Kafka's texts: it is made up of one passive, rather austere, person and another active, more libidinal, person. The appearance of figures with such almost irreconcilable personalities who form couples in Kafka's works has been evident since he wrote his short story \"Description of a Struggle\" (e.g. the narrator/young man and his \"acquaintance\"). They also appear in \"The Judgment\" (Georg and his friend in Russia), in all three of his novels (e.g. Robinson and Delamarche in \"Amerika\") as well as in his short stories \"A Country Doctor\" (the country doctor and the groom) and \"A Hunger Artist\" (the hunger artist and the panther). Rieck views these pairs as parts of one single person (hence the similarity between the names Gregor and Grete) and in the final analysis as the two determining components of the author's personality. Not only in Kafka's life but also in his oeuvre does Rieck see the description of a fight between these two parts.\nReiner Stach argued in 2004 that no elucidating comments were needed to illustrate the story and that it was convincing by itself, self-contained, even absolute. He believes that there is no doubt the story would have been admitted to the canon of world literature even if we had known nothing about its author.\nAccording to Peter-Andr\u00e9 Alt (2005), the figure of the insect becomes a drastic expression of Gregor Samsa's deprived existence. Reduced to carrying out his professional responsibilities, anxious to guarantee his advancement and vexed with the fear of making commercial mistakes, he is the creature of a functionalistic professional life.\nIn 2007, Ralf Sudau took the view that particular attention should be paid to the motifs of self-abnegation and disregard for reality. Gregor's earlier behavior was characterized by self-renunciation and his pride in being able to provide a secure and leisured existence for his family. When he finds himself in a situation where he himself is in need of attention and assistance and in danger of becoming a parasite, he doesn't want to admit this new role to himself and be disappointed by the treatment he receives from his family, which is becoming more and more careless and even hostile over time. According to Sudau, Gregor is self-denyingly hiding his nauseating appearance under the sofa and gradually famishing, thus pretty much complying with the more or less blatant wish of his family. His gradual emaciation and \"self-reduction\" shows signs of a fatal hunger strike (which on the part of Gregor is unconscious and unsuccessful, on the part of his family not understood or ignored). Sudau also lists the names of selected interpreters of \"The Metamorphosis\" (e.g. Beicken, Sokel, Sautermeister and Schwarz). According to them, the narrative is a metaphor for the suffering resulting from leprosy, an escape into the disease or a symptom onset, an image of an existence which is defaced by the career, or a revealing staging which cracks the veneer and superficiality of everyday circumstances and exposes its cruel essence. He further notes that Kafka's representational style is on one hand characterized by an idiosyncratic interpenetration of realism and fantasy, a worldly mind, rationality, and clarity of observation, and on the other hand by folly, outlandishness, and fallacy. He also points to the grotesque and tragicomical, silent film-like elements.\nFernando Bermejo-Rubio (2012) argued that the story is often viewed unjustly as inconclusive. He derives his interpretative approach from the fact that the descriptions of Gregor and his family environment in \"The Metamorphosis\" contradict each other. Diametrically opposed versions exist of Gregor's back, his voice, of whether he is ill or already undergoing the metamorphosis, whether he is dreaming or not, which treatment he deserves, of his moral point of view (false accusations made by Grete), and whether his family is blameless or not. Bermejo-Rubio emphasizes that Kafka ordered in 1915 that there should be no illustration of Gregor. He argues that it is exactly this absence of a visual narrator that is essential for Kafka's project, for he who depicts Gregor would stylize himself as an omniscient narrator. Another reason why Kafka opposed such an illustration is that the reader should not be biased in any way before reading. That the descriptions are not compatible with each other is indicative of the fact that the opening statement is not to be trusted. If the reader isn't hoodwinked by the first sentence and still thinks of Gregor as a human being, he will view the story as conclusive and realize that Gregor is a victim of his own degeneration.\nVolker Dr\u00fcke (2013) believes that the crucial metamorphosis in the story is that of Grete. She is the character the title is directed at. Gregor's metamorphosis is followed by him languishing and ultimately dying. Grete, by contrast, has matured as a result of the new family circumstances and assumed responsibility. In the end \u2013 after the brother's death \u2013 the parents also notice that their daughter, \"who was getting more animated all the time, [...] had recently blossomed into a pretty and shapely girl\", and they want to look for a partner for her. From this standpoint Grete's transition, her metamorphosis from a girl into a woman, is the subtextual theme of the story.\nTranslations of the opening sentence.\n\"The Metamorphosis\" has been translated into English more than twenty times. In Kafka's original, the opening sentence is \"\". In their 1933 translation of the story \u2013 the first into English \u2013 Willa Muir and Edwin Muir rendered it as \"As Gregor Samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect\".\nThe phrase \"ungeheuren Ungeziefer\", describing the creature into which Gregor Samsa metamorphoses, has been translated in at least sixteen different ways. These include the following:\nIn Middle High German, \"Ungeziefer\" literally means \"unclean animal not suitable for sacrifice\" and is sometimes used colloquially to mean \"bug\", with the connotation of \"dirty, nasty bug\". It can also be translated as \"vermin\". English translators of \"The Metamorphosis\" have often rendered it as \"insect\".\nWhat kind of bug or vermin Kafka envisaged remains a debated mystery. Kafka had no intention of labeling Gregor as any specific thing, but instead was trying to convey Gregor's disgust at his transformation. In his letter to his publisher of 25 October 1915, in which he discusses his concern about the cover illustration for the first edition, Kafka does use the term \"Insekt\", though, saying \"The insect itself is not to be drawn. It is not even to be seen from a distance.\"\nVladimir Nabokov, who was a lepidopterist as well as a writer and literary critic, concluded from details in the text that Gregor was not a cockroach, but a beetle with wings under his shell, and capable of flight. Nabokov left a sketch annotated \"just over three feet long\" on the opening page of his English teaching copy. In his accompanying lecture notes, he discusses the type of insect Gregor has been transformed into. Noting that the cleaning lady addressed Gregor as \"dung beetle\" (\"Mistk\u00e4fer\"), e.g., \"Come here for a bit, old dung beetle!\" or \"Hey, look at the old dung beetle!\", Nabokov remarks that this was just her friendly way of addressing him, and that Gregor \"is not, technically, a dung beetle. He is merely a big beetle.\"\nExternal links.\nOnline editions\nCommentary\nRelated"}
{"id": "10865", "revid": "1429183", "url": "https://en.wikipedia.org/wiki?curid=10865", "title": "FSF", "text": "FSF may refer to:"}
{"id": "10868", "revid": "41786382", "url": "https://en.wikipedia.org/wiki?curid=10868", "title": "Francisco Goya", "text": "Francisco Jos\u00e9 de Goya y Lucientes (; ; 30 March 1746 \u2013 16 April 1828) was a Spanish romantic painter and printmaker. He is considered the most important Spanish artist of the late 18th and early 19th centuries. His paintings, drawings, and engravings reflected contemporary historical upheavals and influenced important 19th- and 20th-century painters. Goya is often referred to as the last of the Old Masters and the first of the moderns.\nGoya was born in Fuendetodos, Aragon to a middle-class family in 1746. He studied painting from age 14 under Jos\u00e9 Luz\u00e1n y Martinez and moved to Madrid to study with Anton Raphael Mengs. He married Josefa Bayeu in 1773. Goya became a court painter to the Spanish Crown in 1786 and this early portion of his career is marked by portraits of the Spanish aristocracy and royalty, and Rococo-style tapestry cartoons designed for the royal palace.\nAlthough Goya's letters and writings survive, little is known about his thoughts. He had a severe and undiagnosed illness in 1793 that left him deaf, after which his work became progressively darker and more pessimistic. His later easel and mural paintings, prints and drawings appear to reflect a bleak outlook on personal, social, and political levels and contrast with his social climbing. He was appointed Director of the Royal Academy in 1795, the year Manuel Godoy made an unfavorable treaty with France. In 1799, Goya became \"Primer Pintor de C\u00e1mara\" (Prime Court Painter), the highest rank for a Spanish court painter. In the late 1790s, commissioned by Godoy, he completed his \"La maja desnuda\", a remarkably daring nude for the time and clearly indebted to Diego Vel\u00e1zquez. In 1800\u201301, he painted \"Charles IV of Spain and His Family\", also influenced by Vel\u00e1zquez.\nIn 1807, Napoleon led the French army into the Peninsular War against Spain. Goya remained in Madrid during the war, which seems to have affected him deeply. Although he did not speak his thoughts in public, they can be inferred from his \"Disasters of War\" series of prints (although published 35 years after his death) and his 1814 paintings \"The Second of May 1808\" and \"The Third of May 1808\". Other works from his mid-period include the \"Caprichos\" and \"Los Disparates\" etching series, and a wide variety of paintings concerned with insanity, mental asylums, witches, fantastical creatures and religious and political corruption, all of which suggest that he feared for both his country's fate and his own mental and physical health.\nHis late period culminates with the \"Black Paintings\" of 1819\u20131823, applied on oil on the plaster walls of his house the Quinta del Sordo (\"House of the Deaf Man\") where, disillusioned by political and social developments in Spain, he lived in near isolation. Goya eventually abandoned Spain in 1824 to retire to the French city of Bordeaux, accompanied by his much younger maid and companion, Leocadia Weiss, who may have been his lover. There he completed his \"La Tauromaquia\" series and a number of other works. Following a stroke that left him paralyzed on his right side, Goya died and was buried on 16 April 1828 aged 82.\nEarly years (1746\u20131771).\nFrancisco de Goya was born in Fuendetodos, Arag\u00f3n, Spain, on 30 March 1746 to Jos\u00e9 Benito de Goya y Franque and Gracia de Lucientes y Salvador. The family had moved that year from the city of Zaragoza, but there is no record of why; likely, Jos\u00e9 was commissioned to work there. They were lower middle-class. Jos\u00e9 was the son of a notary and of Basque origin, his ancestors being from Zerain, earning his living as a gilder, specialising in religious and decorative craftwork. He oversaw the gilding and most of the ornamentation during the rebuilding of the Basilica of Our Lady of the Pillar (\"Santa Maria del Pilar\"), the principal cathedral of Zaragoza. Francisco was their fourth child, following his sister Rita (b. 1737), brother Tom\u00e1s (b. 1739) (who was to follow in his father's trade) and second sister Jacinta (b. 1743). There were two younger sons, Mariano (b. 1750) and Camilo (b. 1753).\nHis mother's family had pretensions of nobility and the house, a modest brick cottage, was owned by her family and, perhaps fancifully, bore their crest. About 1749 Jos\u00e9 and Gracia bought a home in Zaragoza and were able to return to live in the city. Although there are no surviving records, it is thought that Goya may have attended the Escuelas P\u00edas de San Ant\u00f3n, which offered free schooling. His education seems to have been adequate but not enlightening; he had reading, writing and numeracy, and some knowledge of the classics. According to Robert Hughes the artist \"seems to have taken no more interest than a carpenter in philosophical or theological matters, and his views on painting ... were very down to earth: Goya was no theoretician.\" At school he formed a close and lifelong friendship with fellow pupil Mart\u00edn Zapater; the 131 letters Goya wrote to him from 1775 until Zapater's death in 1803 give valuable insight into Goya's early years at the court in Madrid.\nVisit to Italy.\nAt age 14 Goya studied under the painter Jos\u00e9 Luz\u00e1n, where he copied stamps for 4 years until he decided to work on his own, as he wrote later on \"paint from my invention\". He moved to Madrid to study with Anton Raphael Mengs, a popular painter with Spanish royalty. He clashed with his master, and his examinations were unsatisfactory. Goya submitted entries for the Real Academia de Bellas Artes de San Fernando in 1763 and 1766 but was denied entrance into the academia.\nRome was then the cultural capital of Europe and held all the prototypes of classical antiquity, while Spain lacked a coherent artistic direction, with all of its significant visual achievements in the past. Having failed to earn a scholarship, Goya relocated at his own expense to Rome in the old tradition of European artists stretching back at least to Albrecht D\u00fcrer. He was an unknown at the time and so the records are scant and uncertain. Early biographers have him travelling to Rome with a gang of bullfighters, where he worked as a street acrobat, or for a Russian diplomat, or fell in love with a beautiful young nun whom he plotted to abduct from her convent. It is possible that Goya completed two surviving mythological paintings during the visit, a \"Sacrifice to Vesta\" and a \"Sacrifice to Pan\", both dated 1771.\nIn 1771 he won second prize in a painting competition organized by the City of Parma. That year he returned to Zaragoza and painted elements of the cupolas of the Basilica of the Pillar (including \"Adoration of the Name of God\"), a cycle of frescoes for the monastic church of the Charterhouse of Aula Dei, and the frescoes of the Sobradiel Palace. He studied with the Aragonese artist Francisco Bayeu y Sub\u00edas and his painting began to show signs of the delicate tonalities for which he became famous. He befriended Francisco Bayeu and married his sister Josefa (he nicknamed her \"Pepa\") on 25 July 1773. Their first child, Antonio Juan Ramon Carlos, was born on 29 August 1774. Of their seven children only one, a son named Javier, survived into adulthood.\nMadrid (1775\u20131789).\nFrancisco Bayeu (Josefa Bayeu's brother), 1765 membership of the Real Academia de Bellas Artes de San Fernando, and directorship of the tapestry works from 1777 helped Goya earn a commission for a series of tapestry cartoons for the Royal Tapestry Factory. Over five years he designed some 42 patterns, many of which were used to decorate and insulate the stone walls of El Escorial and the Palacio Real del Pardo, the residences of the Spanish monarchs. While designing tapestries was neither prestigious nor well paid, his cartoons are mostly popular in a rococo style, and Goya used them to bring himself to wider attention.\nThe cartoons were not his only royal commissions and were accompanied by a series of engravings, mostly copies after old masters such as Marcantonio Raimondi and Vel\u00e1zquez. Goya had a complicated relationship with the latter artist; while many of his contemporaries saw folly in Goya's attempts to copy and emulate him, he had access to a wide range of the long-dead painter's works that had been contained in the royal collection. Nonetheless, etching was a medium that the young artist was to master, a medium that was to reveal both the true depths of his imagination and his political beliefs. His etching of \"The Garrotted Man\" (\"El agarrotado\") was the largest work he had produced to date, and an obvious foreboding of his later \"Disasters of War\" series.\nGoya was beset by illness, and his condition was used against him by his rivals, who looked jealously upon any artist seen to be rising in stature. Some of the larger cartoons, such as \"The Wedding\", were more than 8 by 10 feet, and had proved a drain on his physical strength. Ever resourceful, Goya turned this misfortune around, claiming that his illness had allowed him the insight to produce works that were more personal and informal. However, he found the format limiting, as it did not allow him to capture complex color shifts or texture, and was unsuited to the impasto and glazing techniques he was by then applying to his painted works. The tapestries seem as comments on human types, fashion and fads.\nOther works from the period include a canvas for the altar of the Church of San Francisco El Grande in Madrid, which led to his appointment as a member of the Royal Academy of Fine Art.\nCourt painter.\nIn 1783, the Count of Floridablanca, favorite of King Charles III, commissioned Goya to paint his portrait. He became friends with the King's half-brother Luis, and spent two summers working on portraits of both the Infante and his family. During the 1780s, his circle of patrons grew to include the Duke and Duchess of Osuna, the King and other notable people of the kingdom whom he painted. In 1786, Goya was given a salaried position as a painter to Charles III.\nGoya was appointed court painter to Charles IV in 1789. The following year he became First Court Painter, with a salary of 50,000 reales and an allowance of 500 ducats for a coach. He painted portraits of the king and the queen, and the Spanish Prime Minister Manuel de Godoy and many other nobles. These portraits are notable for their disinclination to flatter; his \"Charles IV of Spain and His Family\" is an especially brutal assessment of a royal family. Modern interpreters view the portrait as satirical; it is thought to reveal the corruption behind the rule of Charles IV. Under his reign his wife Louisa was thought to have had the real power, and thus Goya placed her at the center of the group portrait. From the back left of the painting one can see the artist himself looking out at the viewer, and the painting behind the family depicts Lot and his daughters, thus once again echoing the underlying message of corruption and decay.\nGoya earned commissions from the highest ranks of the Spanish nobility, including Pedro T\u00e9llez-Gir\u00f3n, 9th Duke of Osuna and his wife Mar\u00eda Josefa Pimentel, 12th Countess-Duchess of Benavente, Jos\u00e9 \u00c1lvarez de Toledo, Duke of Alba and his wife Mar\u00eda del Pilar de Silva, and Mar\u00eda Ana de Pontejos y Sandoval, Marchioness of Pontejos. In 1801 he painted Godoy in a commission to commemorate the victory in the brief War of the Oranges against Portugal. The two were friends, even if Goya's 1801 portrait is usually seen as satire. Yet even after Godoy's fall from grace the politician referred to the artist in warm terms. Godoy saw himself as instrumental in the publication of the Caprichos and is widely believed to have commissioned \"La maja desnuda\".\nMiddle period (1793\u20131799).\n\"La Maja Desnuda\" (\"La maja desnuda\") has been described as \"the first totally profane life-size female nude in Western art\" without pretense to allegorical or mythological meaning. The identity of the \"Majas\" is uncertain. The most popularly cited models are the Duchess of Alba, with whom Goya was sometimes thought to have had an affair, and Pepita Tud\u00f3, mistress of Manuel de Godoy. Neither theory has been verified, and it remains as likely that the paintings represent an idealized composite. The paintings were never publicly exhibited during Goya's lifetime and were owned by Godoy. In 1808 all Godoy's property was seized by Ferdinand VII after his fall from power and exile, and in 1813 the Inquisition confiscated both works as 'obscene', returning them in 1836 to the Academy of Fine Arts of San Fernando.\nIn 1798 he painted luminous and airy scenes for the pendentives and cupola of the Real Ermita (Chapel) of San Antonio de la Florida in Madrid. His depiction of a miracle of Saint Anthony of Padua is devoid of the customary angels and instead treats the miracle as if it were a theatrical event performed by ordinary people.\nAt some time between late 1792 and early 1793, an undiagnosed illness left Goya deaf. He became withdrawn and introspective while the direction and tone of his work changed. He began the series of aquatinted etchings, published in 1799 as the \"Caprichos\"\u2014completed in parallel with the more official commissions of portraits and religious paintings. In 1799 Goya published 80 \"Caprichos\" prints depicting what he described as \"the innumerable foibles and follies to be found in any civilized society, and from the common prejudices and deceitful practices which custom, ignorance, or self-interest have made usual\". The visions in these prints are partly explained by the caption \"The sleep of reason produces monsters\". Yet these are not solely bleak; they demonstrate the artist's sharp satirical wit, as in \"Capricho\" number 52, \"What a Tailor Can Do!\"\nWhile convalescing between 1793 and 1794, Goya completed a set of eleven small pictures painted on tin that marked a significant change in the tone and subject matter of his art, and drew from the dark and dramatic realms of fantasy nightmare. \"Yard with Lunatics\" is a vision of loneliness, fear and social alienation. The condemnation of brutality towards prisoners (whether criminal or insane) is a subject that Goya assayed in later works that focused on the degradation of the human figure. It was one of the first of Goya's mid-1790s cabinet paintings, in which his earlier search for ideal beauty gave way to an examination of the relationship between naturalism and fantasy that would preoccupy him for the rest of his career. He was undergoing a nervous breakdown and entering prolonged physical illness, and admitted that the series was created to reflect his own self-doubt, anxiety and fear that he was losing his mind. Goya wrote that the works served \"to occupy my imagination, tormented as it is by contemplation of my sufferings.\" The series, he said, consisted of pictures which \"normally find no place in commissioned works\".\nGoya's physical and mental breakdown seems to have happened a few weeks after the French declaration of war on Spain. A contemporary reported, \"The noises in his head and deafness aren't improving, yet his vision is much better and he is back in control of his balance.\" These symptoms may indicate a prolonged viral encephalitis, or possibly a series of miniature strokes resulting from high blood pressure and which affected the hearing and balance centres of the brain. Symptoms of tinnitus, episodes of imbalance and progressive deafness are typical of M\u00e9ni\u00e8re's disease. It is possible that Goya had cumulative lead poisoning, as he used massive amounts of lead white\u2014which he ground himself\u2014in his paintings, both as a canvas primer and as a primary colour.\nOther postmortem diagnostic assessments include Susac's syndrome or may point toward paranoid dementia, possibly due to brain trauma, as evidenced by marked changes in his work after his recovery, culminating in the \"black\" paintings. Art historians have noted Goya's singular ability to express his personal demons as horrific and fantastic imagery that speaks universally, and allows his audience to find its own catharsis in the images.\nPeninsular War (1808\u20131814).\nThe French army invaded Spain in 1808, leading to the Peninsular War of 1808\u20131814. The extent of Goya's involvement with the court of the \"intruder king\", Joseph I, the brother of Napoleon Bonaparte, is not known; he painted works for French patrons and sympathisers, but kept neutral during the fighting. After the restoration of the Spanish King Ferdinand VII in 1814, Goya denied any involvement with the French. By the time of his wife Josefa's death in 1812, he was painting \"The Second of May 1808\" and \"The Third of May 1808\", and preparing the series of etchings later known as \"The Disasters of War\" (\"Los desastres de la guerra\"). Ferdinand VII returned to Spain in 1814 but relations with Goya were not cordial. The artist completed portraits of the king for a variety of ministries, but not for the king himself.\nAlthough Goya did not make his intention known when creating \"The Disasters of War\", art historians view them as a visual protest against the violence of the 1808 Dos de Mayo Uprising, the subsequent Peninsular War and the move against liberalism in the aftermath of the restoration of the Bourbon monarchy in 1814. The scenes are singularly disturbing, sometimes macabre in their depiction of battlefield horror, and represent an outraged conscience in the face of death and destruction. They were not published until 1863, 35 years after his death. It is likely that only then was it considered politically safe to distribute a sequence of artworks criticising both the French and restored Bourbons.\nThe first 47 plates in the series focus on incidents from the war and show the consequences of the conflict on individual soldiers and civilians. The middle series (plates 48 to 64) record the effects of the famine that hit Madrid in 1811\u201312, before the city was liberated from the French. The final 17 reflect the bitter disappointment of liberals when the restored Bourbon monarchy, encouraged by the Catholic hierarchy, rejected the Spanish Constitution of 1812 and opposed both state and religious reform. Since their first publication, Goya's scenes of atrocities, starvation, degradation and humiliation have been described as the \"prodigious flowering of rage\".\nHis works from 1814 to 1819 are mostly commissioned portraits, but also include the altarpiece of Santa Justa and Santa Rufina for the Cathedral of Seville, the print series of \"La Tauromaquia\" depicting scenes from bullfighting, and probably the etchings of \"Los Disparates\".\nQuinta del Sordo and Black Paintings (1819\u20131822).\nRecords of Goya's later life are relatively scant, and ever politically aware, he suppressed a number of his works from this period, working instead in private. He was tormented by a dread of old age and fear of madness. Goya had been a successful and royally placed artist, but withdrew from public life during his final years. From the late 1810s he lived in near-solitude outside Madrid in a farmhouse converted into a studio. The house had become known as \"La Quinta del Sordo\" (The House of the Deaf Man), after the nearest farmhouse that had coincidentally also belonged to a deaf man.\nArt historians assume Goya felt alienated from the social and political trends that followed the 1814 restoration of the Bourbon monarchy, and that he viewed these developments as reactionary means of social control. In his unpublished art he seems to have railed against what he saw as a tactical retreat into Medievalism. It is thought that he had hoped for political and religious reform, but like many liberals became disillusioned when the restored Bourbon monarchy and Catholic hierarchy rejected the Spanish Constitution of 1812.\nAt the age of 75, alone and in mental and physical despair, he completed the work of his 14 \"Black Paintings\", all of which were executed in oil directly onto the plaster walls of his house. Goya did not intend for the paintings to be exhibited, did not write of them, and likely never spoke of them. Around 1874, 50 years after his death, they were taken down and transferred to a canvas support by owner Baron Fr\u00e9d\u00e9ric \u00c9mile d'Erlanger. Many of the works were significantly altered during the restoration, and in the words of Arthur Lubow what remain are \"at best a crude facsimile of what Goya painted.\" The effects of time on the murals, coupled with the inevitable damage caused by the delicate operation of mounting the crumbling plaster on canvas, meant that most of the murals suffered extensive damage and loss of paint. Today, they are on permanent display at the , Madrid.\nBordeaux (October 1824 \u2013 1828).\nLeocadia Weiss (n\u00e9e Zorrilla, 1790\u20131856), the artist's maid, younger by 35 years, and a distant relative, lived with and cared for Goya after Bayeu's death. She stayed with him in his Quinta del Sordo villa until 1824 with her daughter Rosario. Leocadia was probably similar in features to Goya's first wife Josefa Bayeu, to the point that one of his well-known portraits bears the cautious title of \"Josefa Bayeu (or Leocadia Weiss)\".\nNot much is known about her beyond her fiery temperament. She was likely related to the Goicoechea family, a wealthy dynasty into which the artist's son, Javier, had married. It is known that Leocadia had an unhappy marriage with a jeweler, Isidore Weiss, but was separated from him since 1811, after he had accused her of \"illicit conduct\". She had two children before that time, and bore a third, Rosario, in 1814 when she was 26. Isidore was not the father, and it has often been speculated\u2014although with little firm evidence\u2014that the child belonged to Goya. There has been much speculation that Goya and Weiss were romantically linked; however, it is more likely the affection between them was sentimental.\nGoya died on 16 April 1828. Leocadia was left nothing in Goya's will; mistresses were often omitted in such circumstances, but it is also likely that he did not want to dwell on his mortality by thinking about or revising his will. She wrote to a number of Goya's friends to complain of her exclusion but many of her friends were Goya's also and by then were old men or had died, and did not reply. Largely destitute, she moved into rented accommodation, later passing on her copy of the \"Caprichos\" for free.\nGoya's body was later re-interred in the Real Ermita de San Antonio de la Florida in Madrid. Goya's skull was missing, a detail the Spanish consul immediately communicated to his superiors in Madrid, who wired back, \"Send Goya, with or without head.\"\nGoya's influence on modern and contemporary artists and writers.\nGoya is often referred to as the last of the Old Masters and the first of the moderns. Among the 20th-century painters influenced by Goya are the Spanish masters Pablo Picasso and Salvador Dal\u00ed who drew influence from \"Los caprichos\" and the \"Black Paintings\" of Goya. In the 21st century, American postmodern painters such as Michael Zansky and Bradley Rubenstein draw inspiration from \"The Dream of Reason Produces Monsters\" (1796\u201398) and Goya's \"Black Paintings\". Zanksy's \"Giants and Dwarf Series\" (1990\u20132002) of large-scale paintings and wood carvings use imagery from Goya.\nGoya's influence has extended beyond the visual arts:\nIn 2024, an extensive exhibition of Goya's etchings was held at the Norton Simon Museum in Southern California."}
{"id": "10869", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=10869", "title": "Frequentist probability", "text": "Frequentist probability or frequentism is an interpretation of probability; it defines an event's probability as the limit of its relative frequency in infinitely many trials (the \"long-run probability\").\nProbabilities can be found (in principle) by a repeatable objective process (and are thus ideally devoid of opinion). The continued use of frequentist methods in scientific inference, however, has been called into question.\nThe development of the frequentist account was motivated by the problems and paradoxes of the previously dominant viewpoint, the classical interpretation. In the classical interpretation, probability was defined in terms of the principle of indifference, based on the natural symmetry of a problem, so, for example, the probabilities of dice games arise from the natural symmetric 6-sidedness of the cube. This classical interpretation stumbled at any statistical problem that has no natural symmetry for reasoning.\nDefinition.\nIn the frequentist interpretation, probabilities are discussed only when dealing with well-defined random experiments. The set of all possible outcomes of a random experiment is called the sample space of the experiment. An event is defined as a particular subset of the sample space to be considered. For any given event, only one of two possibilities may hold: It occurs or it does not. The relative frequency of occurrence of an event, observed in a number of repetitions of the experiment, is a measure of the probability of that event. This is the core conception of probability in the frequentist interpretation.\nA claim of the frequentist approach is that, as the number of trials increases, the change in the relative frequency will diminish. Hence, one can view a probability as the \"limiting value\" of the corresponding relative frequencies.\nScope.\nThe frequentist interpretation is a philosophical approach to the definition and use of probabilities; it is one of several such approaches. It does not claim to capture all connotations of the concept 'probable' in colloquial speech of natural languages.\nAs an interpretation, it is not in conflict with the mathematical axiomatization of probability theory; rather, it provides guidance for how to apply mathematical probability theory to real-world situations. It offers distinct guidance in the construction and design of practical experiments, especially when contrasted with the Bayesian interpretation. As to whether this guidance is useful, or is apt to mis-interpretation, has been a source of controversy. Particularly when the frequency interpretation of probability is mistakenly assumed to be the only possible basis for frequentist inference. So, for example, a list of mis-interpretations of the meaning of p-values accompanies the article on -values; controversies are detailed in the article on statistical hypothesis testing. The Jeffreys\u2013Lindley paradox shows how different interpretations, applied to the same data set, can lead to different conclusions about the 'statistical significance' of a result.\nAs Feller notes:\nHistory.\nThe frequentist view may have been foreshadowed by Aristotle, in \"Rhetoric\",\nwhen he wrote:\nPoisson (1837) clearly distinguished between objective and subjective probabilities.\nSoon thereafter a flurry of nearly simultaneous publications by Mill, Ellis (1843)\nand Ellis (1854), Cournot (1843),\nand Fries introduced the frequentist view. Venn (1866, 1876, 1888) provided a thorough exposition two decades later.\nThese were further supported by the publications of Boole and Bertrand. By the end of the 19th\u00a0century the frequentist interpretation was well established and perhaps dominant in the sciences. The following generation established the tools of classical inferential statistics (significance testing, hypothesis testing and confidence intervals) all based on frequentist probability.\nAlternatively,\nBernoulli\nunderstood the concept of frequentist probability and published a critical proof (the weak law of large numbers) posthumously (Bernoulli, 1713).\nHe is also credited with some appreciation for subjective probability (prior to and without Bayes theorem).\nGauss and Laplace used frequentist (and other) probability in derivations of the least squares method a century later, a generation before Poisson.\nLaplace considered the probabilities of testimonies, tables of mortality, judgments of tribunals, etc. which are unlikely candidates for classical probability. In this view, Poisson's contribution was his sharp criticism of the alternative \"inverse\" (subjective, Bayesian) probability interpretation. Any criticism by Gauss or Laplace was muted and implicit. (However, note that their later derivations of least squares did not use inverse probability.)\nMajor contributors to \"classical\" statistics in the early 20th century included Fisher, Neyman, and Pearson. Fisher contributed to most of statistics and made significance testing the core of experimental science, although he was critical of the frequentist concept of \"repeated sampling from the same population\";\nNeyman formulated confidence intervals and contributed heavily to sampling theory; Neyman and Pearson paired in the creation of hypothesis testing. All valued objectivity, so the best interpretation of probability available to them was frequentist.\nAll were suspicious of \"inverse probability\" (the available alternative) with prior probabilities chosen by using the principle of indifference. Fisher said, \"...\u00a0the theory of inverse probability is founded upon an error, [referring to Bayes theorem] and must be wholly rejected.\"\nWhile Neyman was a pure frequentist,\nFisher's views of probability were unique: Both Fisher and Neyman had nuanced view of probability. von Mises offered a combination of mathematical and philosophical support for frequentism in the era.\nEtymology.\nAccording to the \"Oxford English Dictionary\", the term \"frequentist\" was first used by M.G. Kendall in 1949, to contrast with Bayesians, whom he called \"non-frequentists\".\nKendall observed\n\"The Frequency Theory of Probability\" was used a generation earlier as a chapter title in Keynes (1921).\nThe historical sequence:\nThe primary historical sources in probability and statistics did not use the current terminology of \"classical\", \"subjective\" (Bayesian), and \"frequentist\" probability.\nAlternative views.\nProbability theory is a branch of mathematics. While its roots reach centuries into the past, it reached maturity with the axioms of Andrey Kolmogorov in 1933. The theory focuses on the valid operations on probability values rather than on the initial assignment of values; the mathematics is largely independent of any interpretation of probability.\nApplications and interpretations of probability are considered by philosophy, the sciences and statistics. All are interested in the extraction of knowledge from observations\u2014inductive reasoning. There are a variety of competing interpretations;\nAll have problems. The frequentist interpretation does resolve difficulties with the classical interpretation, such as any problem where the natural symmetry of outcomes is not known. It does not address other issues, such as the dutch book."}
{"id": "10870", "revid": "47965501", "url": "https://en.wikipedia.org/wiki?curid=10870", "title": "List of French-language poets", "text": "List of poets who have written in the French language:\nA.\nC\u00e9line Arnauld (1885-1952)"}
{"id": "10871", "revid": "30690290", "url": "https://en.wikipedia.org/wiki?curid=10871", "title": "FM-2030", "text": "FM-2030 (born Fereidoun M. Esfandiary; ; October 15, 1930 \u2013 July 8, 2000) was a Belgian-born Iranian-American author, teacher, transhumanist philosopher, futurist, consultant, and Olympic athlete.\nHe became notable as a transhumanist with the book \"Are You a Transhuman?: Monitoring and Stimulating Your Personal Rate of Growth in a Rapidly Changing World\", published in 1989. In addition, he wrote a number of works of fiction under his original name F. M. Esfandiary.\nEarly life and education.\nFM-2030 was born Fereydoon M. Esfandiary on October 15, 1930, in Belgium to Iranian diplomat Abdol-Hossein \u201cA. H.\u201d Sadigh Esfandiary (1894\u20131986), who served from 1920 to 1960. He travelled widely as a child, having lived in 17 countries including Iran, India, and Afghanistan, by age 11. He represented Iran as a basketball player and wrestler at the 1948 Olympic Games in London. He attended primary school in Iran and England and completed his secondary education at Colleges Des Freres, a Jesuit school in Jerusalem. By the time he was 18, aside from his native Persian, he learned to speak 4 languages: Arabic, Hebrew, French and English. He then started his college education at the University of California, Berkeley, but later transferred to the University of California, Los Angeles, where he graduated in 1952. Afterwards, he served on the United Nations Conciliation Commission for Palestine from 1952 to 1954.\nName change and opinions.\nIn 1970, after publishing his book \"Optimism One\", F. M. Esfandiary started going by FM-2030 for two main reasons: firstly, to reflect the hope and belief that he would live to celebrate his 100th birthday in 2030; secondly, and more importantly, to break free of the widespread practice of naming conventions that he saw as rooted in a collectivist mentality, and existing only as a relic of humankind's tribalistic past. He formalized his name change in 1988. He viewed traditional names as almost always stamping a label of collective identity \u2013 varying from gender to nationality \u2013 on the individual, thereby existing as prima facie elements of thought processes in the human cultural fabric, that tended to degenerate into stereotyping, factionalism, and discrimination. In his own words, \"Conventional names define a person's past: ancestry, ethnicity, nationality, religion. I am not who I was ten years ago and certainly not who I will be in twenty years. [...] The name 2030 reflects my conviction that the years around 2030 will be a magical time. In 2030 we will be ageless and everyone will have an excellent chance to live forever. 2030 is a dream and a goal.\" As a staunch anti-nationalist, he believed \"There are no illegal immigrants, only irrelevant borders.\".\nIn 1973, he published a political manifesto \"UpWingers: A Futurist Manifesto\" in which he portrays both the ideological left and right as outdated, and in their place proposes a schema of UpWingers (those who look to the sky and the future) and DownWingers (those who look to the earth and the past). FM-2030 identified with the former. He argued that the nuclear family structure and the idea of a city would disappear, being replaced by modular social communities he called \"mobilia\", powered by communitarianism, which would persist and then disappear.\nFM-2030 believed that synthetic body parts would one day make life expectancy irrelevant; shortly before his death from pancreatic cancer, he described the pancreas as \"a stupid, dumb, wretched organ\".\nIn terms of civilization, he stated: \"No civilization of the past was great. They were all primitive and persecutory, founded on mass subjugation and mass murder.\" In terms of identity, he stated \"The young modern is not losing his identity. He is gladly disencumbering himself of it.\" He believed that eventually, nations would disappear, and that identities would shift from cultural to personal. In a 1972 op-Ed in \"The New York Times\", he wrote that the leadership in the Arab\u2013Israeli conflict had failed, and that the warring sides were \"acting like adolescents, refuse to resolve their wasteful 25-year-old brawl\", and he believed that the world was \"irreversibly evolving beyond the concept of national homeland\".\nPersonal life.\nFM-2030 was a lifelong vegetarian and said he would not eat anything that had a mother. He famously refused to answer any questions about his nationality, age and upbringing, claiming that such questions were irrelevant and that he was a \u201cglobal person\u201d. FM-2030 once said, \"I am a 21st century person who was accidentally launched in the 20th. I have a deep nostalgia for the future.\" As he spent much of his childhood in India, he was noted to have spoken English with a slight Indian accent. He taught at The New School, University of California, Los Angeles, and Florida International University. He worked as a corporate consultant for Lockheed and J. C. Penney. He was also an atheist.\nFM-2030 was, in his own words, a follower of \"upwing\" politics (i.e. neither right-wing nor left-wing but something else), and by which he meant that he endorsed universal progress. He had been in a non-exclusive \"friendship\" (his preferred term for relationship) with Flora Schnall, a lawyer and fellow Harvard Law Class of 1959 graduate, from the 1960s until his death. FM-2030 and Schnall attended the same class as Ruth Bader Ginsburg. He resided in Westwood, Los Angeles as well as Miami.\nDeath.\nFM-2030 died on July 8, 2000, from pancreatic cancer at a friend's apartment in Manhattan. He was placed in cryonic suspension at the Alcor Life Extension Foundation in Scottsdale, Arizona, where his body remains today. He did not yet have remote standby arrangements, so no Alcor team member was present at his death, but FM-2030 was the first person to be vitrified, rather than simply frozen as previous cryonics patients had been. FM-2030 was survived by four sisters and one brother."}
{"id": "10874", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=10874", "title": "West Flemish", "text": "West Flemish (\"West-Vlams\" or \"West-Vloams\" or \"Vlaemsch\" (in French Flanders), , ) is a collection of Low Franconian varieties spoken in western Belgium and the neighbouring areas of France and the Netherlands.\nWest Flemish is spoken by about a million people in the Belgian province of West Flanders, and a further 50,000 in the neighbouring Dutch coastal district of Zeelandic Flanders (200,000 if including the closely related dialects of Zeelandic) and 10-20,000 in the northern part of the French department of Nord. Some of the main cities where West Flemish is widely spoken are Bruges, Dunkirk, Kortrijk, Ostend, Roeselare and Ypres.\nWest Flemish is listed as a \"vulnerable\" language in UNESCO's online Red Book of Endangered Languages.\nPhonology.\nWest Flemish has a phonology that differs significantly from that of Standard Dutch, being similar to Afrikaans in the case of long E, O and A. Also where Standard Dutch has \"sch\", in some parts of West Flanders, West-Flemish, like Afrikaans, has \"sk\". However, the best known traits are the replacement of Standard Dutch (pre-)velar fricatives \"g\" and \"ch\" in Dutch () with glottal \"h\" . The following differences are listed by their Dutch spelling, as some different letters have merged their sounds in Standard Dutch but remained separate sounds in West Flemish. Pronunciations can also differ slightly from region to region.\nThe absence of and in West Flemish makes pronouncing them very difficult for native speakers. That often causes hypercorrection of the sounds to a or .\nStandard Dutch also has many words with an \"-en\" () suffix (mostly plural forms of verbs and nouns). While Standard Dutch and most dialects do not pronounce the final \"n\", West Flemish typically drops the \"e\" and pronounces the \"n\" inside the base word. For base words already ending with \"n\", the final \"n\" sound is often lengthened to clarify the suffix. That makes many words become similar to those of English: \"beaten\", \"listen\" etc.\nThe short \"o\" () can also be pronounced as a short \"u\" (), a phenomenon also occurring in Russian and some other Slavic languages, called akanye. That happens spontaneously to some words, but other words keep their original short \"o\" sounds. Similarly, the short \"a\" () can turn into a short \"o\" () in some words spontaneously.\nThe diphthong \"ui\" () does not exist in West Flemish and is replaced by a long \"u\" () or a long \"ie\" (). Like for the \"ui\", the long \"o\" () can be replaced by an (\"eu\") for some words but a for others. That often causes similarities to ranchers English. \nHere are some examples showing the sound shifts that are part of the vocabulary:\nGrammar.\nPlural form.\nPlural forms in Standard Dutch most often add \"-en\", but West Flemish usually uses \"-s\", like the Low Saxon dialects and even more prominently in English in which \"-en\" has become very rare. Under the influence of Standard Dutch, \"-s\" is being used by fewer people, and younger speakers tend to use \"-en\".\nVerb conjugation.\nThe verbs \"zijn\" (\"to be\") and \"hebben\" (\"to have\") are also conjugated differently.\nDouble subject.\nWest Flemish often has a double subject.\nArticles.\nStandard Dutch has an indefinite article that does not depend on gender, unlike in West Flemish. However, a gender-independent article is increasingly used. Like in English, \"n\" is pronounced only if the next word begins with a vowel sound.\nConjugation of \"yes\" and \"no\".\nAnother feature of West Flemish is the conjugation of \"ja\" and \"nee\" (\"yes\" and \"no\") to the subject of the sentence. That is somewhat related to the double subject, but even when the rest of the sentence is not pronounced, \"ja\" and \"nee\" are generally used with the first part of the double subject.\nThis conjugation can be negated with the extra word, \"toet\" (), or strenght strengthened by adding mo- or ba- (or both). "}
{"id": "10875", "revid": "11555324", "url": "https://en.wikipedia.org/wiki?curid=10875", "title": "Fritz Leiber", "text": "Fritz Reuter Leiber Jr. ( ; December 24, 1910\u00a0\u2013 September 5, 1992) was an American writer of fantasy, horror, and science fiction. With writers such as Robert E. Howard and Michael Moorcock, Leiber is one of the fathers of sword and sorcery.\nLife.\nFritz Leiber was born December 24, 1910, in Chicago, Illinois, to the actors Fritz Leiber and Virginia Bronson Leiber. For a time, he seemed inclined to follow in his parents' footsteps; the theater and actors feature in his fiction. He spent 1928 touring with his parents' Shakespeare company (Fritz Leiber &amp; Co.) before entering the University of Chicago, where he was elected to Phi Beta Kappa and received an undergraduate Ph.B. degree in psychology and physiology or biology with honors in 1932. From 1932 to 1933, he worked as a lay reader and studied as a candidate for the ministry, without taking a degree, at the General Theological Seminary in Chelsea, Manhattan, an affiliate of the Episcopal Church.\nAfter pursuing graduate studies in philosophy at the University of Chicago from 1933 to 1934 and again not taking a degree, he remained in Chicago while touring under the stage name of \"Francis Lathrop\" intermittently with his parents' company and pursuing a literary career. Six short stories later included in the 2010 collection \"Strange Wonders: A Collection of Rare Fritz Leiber Works\" carry 1934 and 1935 dates. He also appeared alongside his father in uncredited parts in George Cukor's \"Camille\" (1936), James Whale's \"The Great Garrick\" (1937), and William Dieterle's \"The Hunchback of Notre Dame\" (1939).\nIn 1936, he initiated a brief, intense correspondence with H. P. Lovecraft, who \"encouraged and influenced [Leiber's] literary development\" before Lovecraft died in March 1937. Leiber introduced Fafhrd and the Gray Mouser in \"Two Sought Adventure\", his first professionally published short story in the August 1939 edition of \"Unknown\", edited by John W. Campbell.\nLeiber married Jonquil Stephens on January 16, 1936. Their only child, philosopher and science fiction writer Justin Leiber, was born in 1938. From 1937 to 1941, Fritz Leiber was employed by Consolidated Book Publishing as a staff writer for the \"Standard American Encyclopedia\". In 1941, the family moved to California, where Leiber served as a speech and drama instructor at Occidental College during the 1941\u20131942 academic year.\nUnable to conceal his disdain for academic politics as the United States entered World War II, he decided that the struggle against fascism mattered more than his long-held pacifist convictions. He accepted a position with Douglas Aircraft in quality inspection, primarily working on the C-47 Skytrain. Throughout the war, he continued to regularly publish fiction.\nThereafter, the family returned to Chicago, where Leiber served as associate editor of \"Science Digest\" from 1945 to 1956. During this decade (forestalled by a fallow interregnum from 1954 to 1956), his output (including the 1947 Arkham House anthology \"Night's Black Agents\") was characterized by Poul Anderson as \"a lot of the best science fiction and fantasy in the business\". In 1958, the Leibers returned to Los Angeles. By then, he could afford to relinquish his journalistic career and support his family as a full-time fiction writer.\nJonquil's death in 1969 precipitated Leiber's permanent relocation to San Francisco and exacerbated his longstanding alcoholism after twelve years of fellowship in Alcoholics Anonymous. He gradually regained sobriety, an effort impeded by comorbid barbiturate abuse, over the next two decades. Perhaps as a result of his substance abuse, Leiber seems to have suffered periods of penury in the 1970s; Harlan Ellison wrote of his anger at finding that the much-awarded Leiber had to write his novels on a manual typewriter propped up over the sink in his apartment. Marc Laidlaw wrote that, when visiting Leiber as a fan in 1976, he \"was shocked to find him occupying one small room of a seedy San Francisco residence hotel, its squalor relieved mainly by walls of books\". Other reports suggest that Leiber preferred to live simply in the city, spending his money on dining, movies, and travel. In the last years of his life, royalty checks from TSR, Inc. (the makers of \"Dungeons &amp; Dragons\", who had licensed the mythos of the Fafhrd and Gray Mouser series) were enough in themselves to ensure that he lived comfortably. In 1977, he returned to his original form with a fantasy novel set in modern-day San Francisco, \"Our Lady of Darkness\", which is about a writer of weird tales who must deal with the death of his wife and his recovery from alcoholism.\nIn 1992, the last year of his life, Leiber married his second wife, Margo Skinner, a journalist and poet with whom he had been friends for years. Leiber died a few weeks after a physical collapse while traveling from a science fiction convention in London, Ontario, with Skinner. His cause of death was a stroke.\nHe wrote a 100-page-plus memoir, \"Not Much Disorder and Not So Early Sex\", which can be found in \"The Ghost Light\" (1984).\nLeiber's own literary criticism, including several essays on Lovecraft, was collected in the volume \"Fafhrd and Me\" (1990).\nTheater.\nAs the child of two Shakespearean actors, Leiber was fascinated with the stage, describing itinerant Shakespearean companies in stories like \"No Great Magic\" and \"Four Ghosts in Hamlet\", and creating an actor/producer protagonist for his novel \"A Specter is Haunting Texas\".\nAlthough his \"Change War\" novel, \"The Big Time\", is about a war between two factions, the \"Snakes\" and the \"Spiders\", changing and rechanging history throughout the universe, all the action takes place in a small bubble of isolated space-time the size of a theatrical stage, and with only a handful of characters. Judith Merril (in the July 1969 issue of \"The Magazine of Fantasy &amp; Science Fiction\") remarks on Leiber's acting skills when the writer won a science fiction convention costume ball. Leiber's costume consisted of a cardboard military collar over turned-up jacket lapels, cardboard insignia, an armband, and a spider pencilled large in black on his forehead, thus turning him into an officer of the Spiders, one of the combatants in his Change War stories. \"The only other component,\" Merril writes, \"was the Leiber instinct for theatre.\"\nFilms.\nThe similarity of the names of the father and the son caused some filmographies to incorrectly attribute to Fritz Jr. roles which were in fact played by his father, Fritz Leiber Sr., who was the evil Inquisitor in the Errol Flynn adventure film \"The Sea Hawk\" (1940) and had played in many other movies from 1917 to the late 1950s. It is the elder Leiber, not the younger, who appears in the Vincent Price vehicle \"The Web\" (1947) and in Charlie Chaplin's \"Monsieur Verdoux\" (1947).\nThe younger Leiber can be seen briefly as Valentin in the 1936 film version of \"Camille\" starring Greta Garbo. In the cult horror film \"Equinox\" (1970) directed by Dennis Muren and Jack Woods, Leiber has a cameo appearance as a geologist, Dr. Watermann. In the edited second version of the movie, Leiber has no spoken dialogue but appears in a few scenes. The original version of the movie has a longer appearance by Leiber recounting the ancient book and a brief speaking role; all were cut from the re-release.\nHe also appears as Chavez in the 1979 Schick Sunn Classics documentary \"The Bermuda Triangle\", based on the book by Charles Berlitz.\nWriting career.\nLeiber was heavily influenced by H. P. Lovecraft, Robert Graves, John Webster, and Shakespeare in the first two decades of his career. Beginning in the late 1950s, he was increasingly influenced by the works of Carl Jung, particularly by the concepts of the anima and the shadow. In the mid-1960s, he began incorporating elements of Joseph Campbell's \"The Hero with a Thousand Faces\". These concepts are often mentioned in his stories, especially the anima, which becomes a method of exploring his fascination with, but estrangement from, the female.\nLeiber liked cats, which are featured in many of his stories. Tigerishka, for example, is a cat-like alien who is sexually attractive to the human protagonist yet repelled by human customs in the novel \"The Wanderer\". Leiber's \"Gummitch\" stories feature a kitten with an I.Q. of 160, just waiting for his ritual cup of coffee so that he can become human, too.\nHis first stories in the 1930s and 40s were inspired by Lovecraft's Cthulhu Mythos. A notable critic and historian of the wider Mythos, S. T. Joshi, has singled out Leiber's \"The Sunken Land\" (\"Unknown Worlds\", February 1942) as the most accomplished of the early stories based on Lovecraft's Mythos. Leiber also later wrote several essays on Lovecraft the man, such as \"A Literary Copernicus\" (1949), the publication of which formed a key moment in the emergence of a serious critical appreciation of Lovecraft's life and work.\nLeiber's first professional sale was \"Two Sought Adventure\" (\"Unknown\", August 1939), which introduced his most famous characters, Fafhrd and the Gray Mouser. In 1943, his first two novels were serialized in \"Unknown\" (the supernatural horror-oriented \"Conjure Wife\", inspired by his experiences on the faculty of Occidental College) and \"Astounding Science Fiction\" (\"Gather, Darkness\").\n1947 marked the publication of his first book, \"Night's Black Agents\", a short story collection containing seven stories grouped as 'Modern Horrors', one as a 'Transition', and two grouped as 'Ancient Adventures': \"The Sunken Land\" and \"Adept's Gambit\", which are both stories of Fafhrd and the Gray Mouser.\nThe science fiction novel \"Gather, Darkness\" followed in 1950. It deals with a futuristic world that follows the Second Atomic Age which is ruled by scientists, until in the throes of a new Dark Age, the witches revolt.\nIn 1951, Leiber was Guest of Honor at the World Science Fiction Convention in New Orleans. Further novels followed during the 1950s, and in 1958 \"The Big Time\" won the Hugo Award for Best Novel.\nLeiber continued to publish in the 1960s. His novel \"The Wanderer\" (1964) also won the Hugo for Best Novel. In the novel, an artificial planet nicknamed the Wanderer materializes from hyperspace within earth's orbit. The Wanderer's gravitational field captures the moon and shatters it into something like one of Saturn's rings. On Earth, the Wanderer's gravity well triggers earthquakes, tsunamis, and tidal phenomena. The multi-threaded plot follows the exploits of an ensemble cast as they struggle to survive the global disaster.\nIn the same period, Leiber published \"Black Gondolier\", a short story in which a protagonist uncovers a cosmic conspiracy in which oil from ancient fossils preys upon human beings and human civilizations. Leiber received the Hugo Award for Best Novella in 1970 and 1971 for \"Ship of Shadows\" (1969) and \"Ill Met in Lankhmar\" (1970). \"Gonna Roll the Bones\" (1967), his contribution to Harlan Ellison's \"Dangerous Visions\" anthology, won the Hugo Award for Best Novelette and the Nebula Award for Best Novelette in 1968.\n\"Our Lady of Darkness\" (1977), originally serialized in short form in \"The Magazine of Fantasy &amp; Science Fiction\" under the title \"The Pale Brown Thing\" (1977), featured cities as the breeding grounds for new types of elementals called paramentals, summonable by the dark art of megapolisomancy, with such activities centering on the Transamerica Pyramid. Its main characters include Franz Westen, Jaime Donaldus Byers, and the magician Thibault de Castries. \"Our Lady of Darkness\" won the World Fantasy Award\u2014Novel.\nLeiber also wrote the 1966 novelization of the Clair Huffaker screenplay of \"Tarzan and the Valley of Gold\".\nMany of Leiber's most acclaimed works are short stories, especially in the horror genre, including \"The Smoke Ghost\", \"The Girl With the Hungry Eyes\", and \"You're All Alone\" (later expanded as \"The Sinful Ones\"). Leiber also challenged the conventions of science fiction through reflexive narratives such as \"A Bad Day For Sales\" (first published in \"Galaxy Science Fiction\", July 1953), in which the protagonist, Robie, \"America\u2019s only genuine mobile salesrobot\", references the title character of Isaac Asimov's idealistic robot story, \"Robbie\". Questioning Isaac Asimov's Three Laws of Robotics, Leiber imagines the futility of automatons in a post-apocalyptic New York City. In his later years, Leiber returned to short story horror in such works as \"Horrible Imaginings\", \"Black Has Its Charms\" and the award-winning \"The Button Moulder\".\nThe short parallel worlds story \"Catch That Zeppelin!\" (1975) won the Hugo Award for Best Short Story and the Nebula Award for Best Short Story in 1976. It presents an alternate reality much better than our own, as opposed to the usual parallel universe story depicting a world worse than our own. \"Belsen Express\" (1975) won the World Fantasy Award\u2014Short Fiction.\nLeiber was named the second Gandalf Grand Master of Fantasy by participants in the 1975 World Science Fiction Convention (Worldcon), after the posthumous inaugural award to J. R. R. Tolkien. Next year he won the World Fantasy Award for Life Achievement. He was Guest of Honor at the 1979 Worldcon in Brighton, England (1979). The Science Fiction Writers of America made him its fifth SFWA Grand Master in 1981; the Horror Writers Association made him an inaugural winner of the Bram Stoker Award for Lifetime Achievement in 1988 (named in 1987); and the Science Fiction and Fantasy Hall of Fame inducted him in 2001, its sixth class of two deceased and two living writers.\nLeiber was a founding member of the Swordsmen and Sorcerers' Guild of America (SAGA), a loose-knit group of Heroic fantasy authors founded in the 1960s and led by Lin Carter. Some works by SAGA members were published in Lin Carter's \"Flashing Swords!\" anthologies. Leiber himself is credited with inventing the term sword and sorcery for the particular subgenre of epic fantasy exemplified by his Fafhrd and Grey Mouser stories.\nIn an appreciation in the July 1969 \"Special Fritz Leiber Issue\" of \"The Magazine of Fantasy &amp; Science Fiction\", Judith Merril writes of Leiber's connection with his readers: \"That this kind of \"personal\" response...is shared by thousands of other readers, has been made clear on several occasions.\" The November 1959 issue of \"Fantastic\", for instance: Leiber had just come out of one of his recurrent dry spells, and editor Cele Lalli bought up all his new material until there was enough [five stories] to fill an issue; the magazine came out with a big black headline across its cover \u2014 \"Leiber Is Back!\"\nFafhrd and the Gray Mouser.\nHis legacy has been consolidated by his most famous creations, the \"Fafhrd and the Gray Mouser\" stories, written over a span of 50 years. The first, \"Two Sought Adventure\", appeared in \"Unknown\", August 1939. The stories are about an unlikely pair of heroes found in and around the city of Lankhmar. Fafhrd was based on Leiber himself and the Mouser on his friend Harry Otto Fischer, and the two characters were created in a series of letters exchanged by the two in the mid-1930s. These stories were among the progenitors of many of the tropes of sword and sorcery.\nSome Fafhrd and Mouser stories were recognized by annual genre awards: \"Scylla's Daughter\" (1961) was \"Short Story\" Hugo finalist, and \"Ill Met in Lankhmar\" (1970) won the \"Best Novella\" Hugo and Nebula Awards. Leiber's last major work, \"The Knight and Knave of Swords\" (1991), closed out the series while leaving room for possible sequels. In his last year, Leiber considered allowing other writers to continue the series, but his sudden death made this more difficult. One new Fafhrd and the Mouser novel, \"Swords Against the Shadowland\", by Robin Wayne Bailey, appeared in 1998.\nThe stories influenced the shaping of sword and sorcery and other works. Joanna Russ' stories about thief-assassin Alyx (collected in 1976 in \"The Adventures of Alyx\") were in part inspired by Fafhrd and the Gray Mouser, and Alyx made guest appearances in two of Leiber's stories. More recently, playing off the visit of Fafhrd and the Grey Mouser to our world in \"Adept's Gambit\" (set in second century B.C. Tyre), Steven Saylor's short story \"Ill Seen in Tyre\" takes his Roma Sub Rosa series hero Gordianus to the city of Tyre a hundred years later, where the two visitors from Nehwon are remembered as local legends.\nFischer and Leiber contributed to the original design of the 1976 wargame \"Lankhmar\" from TSR.\nSelected works.\nScreen adaptations.\n\"Conjure Wife\" has been made into feature films four times under other titles:\n\"The Girl with the Hungry Eyes\" was filmed under that title by Kastenbaum Films in 1995. (This film is not to be confused with the 1967 William Rotsler film \"The Girl with the Hungry Eyes\" which is entirely unrelated to Leiber's story).\nTwo Leiber stories were filmed for TV for Rod Serling's \"Night Gallery\". These were \"The Girl with the Hungry Eyes\" (1970) (adapted by Robert M. Young and directed by John Badham) and \"The Dead Man\" (adapted and directed by Douglas Heyes)."}
{"id": "10878", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=10878", "title": "Flanders", "text": "Flanders ( or ; ) is the Dutch-speaking northern portion of Belgium and one of the communities, regions and language areas of Belgium. However, there are several overlapping definitions, including ones related to culture, language, politics, and history, and sometimes involving neighbouring countries. The demonym associated with Flanders is Fleming, while the corresponding adjective is Flemish, which can also refer to the collective of Dutch dialects spoken in that area, or more generally the Belgian variant of Standard Dutch. \nMost Flemings live within the Flemish Region, which is a federal state within Belgium with its own elected government. However, like Belgium itself, the official capital of Flanders is the City of Brussels, which lies within the Brussels-Capital Region, not the Flemish Region, and the majority of residents there are French speaking. The powers of the Flemish Government in Brussels are limited mainly to Flemish culture and education.\nGeographically, Flanders is mainly flat, and incorporates the whole coast of Belgium on the North Sea. It borders the French department of Nord to the south-west near the coast, the Dutch provinces of Zeeland, North Brabant and Limburg to the north and east, and the Walloon provinces of Hainaut, Walloon Brabant and Li\u00e8ge to the south. Despite accounting for only 45% of Belgium's territory, more than half the population lives there \u2013 6,821,770 (or 58%) out of 11,763,650 Belgian inhabitants, as of January 2024. Much of Flanders is agriculturally fertile and densely populated at . The Brussels Region is an officially bilingual enclave within the Flemish Region. Flanders also has exclaves of its own: Voeren in the east is between Wallonia and the Netherlands and Baarle-Hertog in the north consists of 22 exclaves surrounded by the Netherlands. Not including Brussels, there are five present-day Flemish provinces: Antwerp, East Flanders, Flemish Brabant, Limburg and West Flanders. The official language is Dutch.\nThe area of today's Flanders has figured prominently in European history since the Middle Ages. The original County of Flanders stretched around AD 900 from the Strait of Dover to the Scheldt estuary and expanded from there. This county also still corresponds roughly with the modern-day Belgian provinces of West Flanders and East Flanders, along with neighbouring parts of France and the Netherlands. In this period, cities such as Ghent and Bruges of the historic County of Flanders, and later Antwerp of the Duchy of Brabant made it one of the richest and most urbanised parts of Europe, trading, and weaving the wool of neighbouring lands into cloth for both domestic use and export. As a consequence, a very sophisticated culture developed, with impressive achievements in the arts and architecture, rivaling those of northern Italy.\nBelgium was one of the centres of the 19th-century Industrial Revolution, but this occurred mainly in French-speaking Wallonia. In the second half of the 20th century, and due to massive national investments in port infrastructure, Flanders' economy modernised rapidly, and today Flanders and Brussels are much wealthier than Wallonia, being among the wealthiest regions in Europe and the world. In accordance with late 20th century Belgian state reforms, Flanders was made into two political entities: the Flemish Region () and the Flemish Community (). These entities were merged, although geographically the Flemish Community, which has a broader cultural mandate, covers Brussels, whereas the Flemish Region does not.\nTerminology.\nModern Belgium.\nThe term \"Flanders\" has several main modern meanings:\nHistorical.\nThe name originally applied to the \"ancien r\u00e9gime\" territory called the County of Flanders, that existed from the 8th century (Latin \"Flandria\") until its absorption by the French First Republic. Until the 1600s, this county also extended over parts of what are now France and the Netherlands.\nHowever, the term came to be used for a bigger territory, and this is critical to the evolution of modern terminology. Once the Counts of Flanders (who were also Dukes of Burgundy) expanded their regional power to create the bigger entity, now referred to by historians as the Burgundian Netherlands, \"Flanders\", along with Latin \"Belgium\", were the first two common names to describe this regional block. With the breakaway of the northern Netherlands in the early modern period, the term Flanders continued to be associated with the whole southern part of the Low Countries\u2014the Southern, Spanish or Austrian Netherlands, which were the successors of the Burgundian state, and also predecessors of modern Belgium. The restriction of the term Flanders to the Germanic speaking part of the population occurred later.\nDutch-speaking part of Belgium.\nThe term \"Flemish\" came to be a term for the language Dutch, and during the 19th and 20th centuries, it became increasingly common to refer exclusively to the Dutch-speaking part of Belgium as \"Flanders\". Belgium divided itself into official French- and Dutch-speaking parts starting in the early '60s. Today Flanders extends over the northern part of Belgium, including not only the Dutch-speaking Belgian parts of the medieval Duchy of Brabant, which was united with Flanders since the Middle Ages, but also Belgian Limburg, which corresponds closely to the medieval County of Loon, and was never under Burgundian control.\nThe ambiguity between this wider cultural area and that of the county or province still remains in discussions about the region. In most present-day contexts however, the term Flanders is taken to refer to either the political, social, cultural, and linguistic community (and the corresponding official institution, the Flemish Community), or the geographical area, one of the three institutional regions in Belgium, namely the Flemish Region.\nIn the history of art and other fields, the adjectives Flemish and Netherlandish are commonly used to designate all the artistic production in this area before about 1580, after which it refers specifically to the southern Netherlands. For example, the term \"Flemish Primitives\", now outdated in English but used in French, Dutch and other languages, is a synonym for \"Early Netherlandish painting\", and it is not uncommon to see Mosan art categorized as Flemish art. In music the \"Franco-Flemish School\" is also known as the \"Dutch School\".\nWithin this Dutch-speaking part of Belgium, French has never ceased to be spoken by some citizens, and Jewish groups have been speaking Yiddish in Antwerp for centuries. Regardless of nationality or linguistic background, according to Belgian Law education in schools located in the Flemish Region must be mainly in the Dutch language. In Brussels, teaching is also done in French.\nHistory.\nEarly history.\nWhen Julius Caesar conquered the area he described it as the less economically developed and more warlike part of \"Gallia Belgica\". His informants told him that especially in the east, the tribes claimed ancestral connections and kinship with the \"Germanic\" peoples then east of the Rhine. Under the Roman empire the whole of \"Gallia Belgica\" became an administrative province. The future counties of Flanders and Brabant remained part of this province connected to what is now France, but in the east modern Limburg became part of the Rhine frontier province of \"Germania Inferior\" connected to what is now the Netherlands and Germany. \"Gallia Belgica\" and \"Germania Inferior\" were the two most northerly continental provinces of the Roman empire.\nIn the future county of Flanders, the main Belgic tribe in early Roman times was the Menapii, but also on the coast were the Marsacii and Morini. In the central part of modern Belgium were the Nervii, whose territory corresponded to medieval Brabant as well as French-speaking Hainaut. In the east was the large district of the Tungri which covered both French- and Dutch-speaking parts of eastern Belgium. The Tungri were understood to have links to Germanic tribes east of the Rhine. Another notable group were the Toxandrians who appear to have lived in the Kempen region, in the northern parts of both the Nervian and Tungrian districts, probably stretching into the modern Netherlands. The Roman administrative districts (\"civitates\") of the Menapii, Nervii and Tungri therefore corresponded roughly with the medieval counties of Flanders, Brabant and Loon, and the modern Flemish provinces of East and West Flanders (Menapii), Brabant and Antwerp (the northern Nervii), and Belgian Limburg (part of the Tungri). Brabant appears to have been separated from the Tungri by a relatively unpopulated forest area, the Silva Carbonaria, forming a natural boundary between northeast and southwest Belgium.\nLinguistically, the tribes in this area were under Celtic influence in the south, and Germanic influence in the east, but there is disagreement about what languages were spoken locally (apart from Vulgar Latin), and there may even have been an intermediate \"Nordwestblock\" language related to both. By the first century AD, Germanic languages appear to have become prevalent in the area of the Tungri.\nAs Roman influence waned, Frankish populations settled in the Tungiran area east of the Silva Carbonaria, and eventually pushed through it under Chlodio. They had kings in each Roman district (\"civitas\"). In the meantime, the Franks contributed to the Roman military. The first Merovingian king Childeric I was king of the Franks within the military of Gaul. He became leader of the administration of \"Belgica Secunda\", which included the \"civitas\" of the Menapii (the future county of Flanders). From there, his son Clovis I managed to conquer both the Roman populations of northern France and the Frankish populations beyond the forest areas.\nHistorical Flanders.\nThe County of Flanders was a feudal fief in West Francia. The first certain Count in the comital family, Baldwin I of Flanders, is first reported in a document of 862, when he eloped with a daughter of his king Charles the Bald. The region developed as a medieval economic power with a large degree of political autonomy. While its trading cities remained strong, it was weakened and divided when districts fell under direct French royal rule in the late 12th century. The remaining parts of Flanders came under the rule of the counts of neighbouring imperial Hainaut under Baldwin V of Hainaut in 1191.\nDuring the late Middle Ages, Flanders's trading towns (notably Ghent, Bruges and Ypres) made it one of the richest and most urbanized parts of Europe, weaving the wool of neighbouring lands into cloth for both domestic use and export. As a consequence, a sophisticated culture developed, with impressive art and architecture, rivaling those of northern Italy. Ghent, Bruges, Ypres and the Franc of Bruges formed the Four Members, a form of parliament that exercised considerable power in Flanders.\nIncreasingly powerful from the 12th century, the territory's autonomous urban communes were instrumental in defeating a French attempt at annexation (1300\u20131302), finally defeating the French in the Battle of the Golden Spurs (11 July 1302), near Kortrijk. Two years later, the uprising was defeated and Flanders indirectly remained part of the French Crown. Flemish prosperity waned in the following century, due to widespread European population decline following the Black Death of 1348, the disruption of trade during the Anglo-French Hundred Years' War (1337\u20131453), and increased English cloth production. Flemish weavers had gone over to Worstead and North Walsham in Norfolk in the 12th century and established the woolen industry.\nThe County of Flanders started to take control of the neighbouring County of Brabant during the life of Louis II, Count of Flanders (1330\u20131384), who fought his sister-in-law Joanna, Duchess of Brabant for control of it.\nThe entire area, straddling the ancient boundary of France and the Holy Roman Empire, later passed to Philip the Bold in 1384, the Duke of Burgundy, with his capital in Brussels. The titles were eventually more clearly united under his grandson Philip the Good (1396 \u2013 1467). This large Duchy passed in to the Habsburg dynasty, and in 1556 to the kings of Spain. Western and southern districts of Flanders were confirmed under French rule under successive treaties of 1659 (Artois), 1668 and 1678.\nThe County of Loon, approximately the modern Flemish province of Limburg, remained independent of France, forming a part of the Prince-Bishopric of Li\u00e8ge until the French Revolution, but surrounded by the Burgundians, and under their influence.\nLow Countries.\nBeeldenstorm.\nIn 1500, Charles V was born in Ghent. He inherited the Seventeen Provinces (1506), Spain (1516) with its colonies and in 1519 was elected Holy Roman Emperor. Charles V issued the Pragmatic Sanction of 1549, which established the Low Countries as the Seventeen Provinces (or Spanish Netherlands in its broad sense) as an entity separate from the Holy Roman Empire and from France. In 1556 Charles V abdicated due to ill health (he suffered from crippling gout). Spain and the Seventeen Provinces went to his son, Philip II of Spain.\nOver the first half of the 16th century Antwerp grew to become the second-largest European city north of the Alps by 1560. Antwerp was the richest city in Europe at this time. According to Luc-Normand Tellier \"It is estimated that the port of Antwerp was earning the Spanish crown seven times more revenues than the Americas.\"\nMeanwhile, Protestantism had reached the Low Countries. Among the wealthy traders of Antwerp, the Lutheran beliefs of the German Hanseatic traders found appeal, perhaps partly for economic reasons. The spread of Protestantism in this city was aided by the presence of an Augustinian cloister (founded 1514) in the St. Andries quarter. Luther, an Augustinian himself, had taught some of the monks, and his works were in print by 1518. The first Lutheran martyrs came from Antwerp. The Reformation resulted in consecutive but overlapping waves of reform: a Lutheran, followed by a militant Anabaptist, then a Mennonite, and finally a Calvinistic movement. These movements existed independently of each other.\nPhilip II, a devout Catholic and self-proclaimed protector of the Counter-Reformation, suppressed Calvinism in Flanders, Brabant and Holland (what is now approximately Belgian Limburg was part of the Prince-Bishopric of Li\u00e8ge and was Catholic \"de facto\"). In 1566, the wave of iconoclasm known as the \"Beeldenstorm\" was a prelude to religious war between Catholics and Protestants, especially the Anabaptists. The \"Beeldenstorm\" started in what is now French Flanders, with open-air sermons () that spread through the Low Countries, first to Antwerp and Ghent, and from there further east and north.\nThe Eighty Years' War and its consequences.\nSubsequently, Philip II of Spain sent the Duke of Alba to the Provinces to repress the revolt. Alba recaptured the southern part of the Provinces, who signed the Union of Atrecht, which meant that they would accept the Spanish government on condition of more freedom. But the northern part of the provinces signed the Union of Utrecht and settled in 1581 the Republic of the Seven United Netherlands. Spanish troops quickly started fighting the rebels, and the Spanish armies conquered the important trading cities of Bruges and Ghent. Antwerp, which was then the most important port in the world, also had to be conquered. But before the revolt was defeated, a war between Spain and England broke out, forcing Spanish troops to halt their advance. On 17 August 1585, Antwerp fell. This ended the Eighty Years' War for the (from now on) Southern Netherlands. The United Provinces (the Northern Netherlands) fought on until 1648 \u2013 the Peace of Westphalia.\nDuring the war with England, the rebels from the north, strengthened by refugees from the south, started a campaign to reclaim areas lost to Philip II's Spanish troops. They conquered a considerable part of Brabant (the later North Brabant of the Netherlands), and the south bank of the Scheldt estuary (Zeelandic Flanders), before being stopped by Spanish troops. The front at the end of this war stabilized and became the border between present-day Belgium and the Netherlands. The Dutch (as they later became known) had managed to reclaim enough of Spanish-controlled Flanders to close off the river Scheldt, effectively cutting Antwerp off from its trade routes.\nThe fall of Antwerp to the Spanish and the closing of the Scheldt caused considerable emigration. Many Calvinist merchants of Antwerp and other Flemish cities left Flanders and migrated north. Many of them settled in Amsterdam, which was a smaller port, important only in the Baltic trade. The Flemish exiles helped to rapidly transform Amsterdam into one of the world's most important ports. This is why the exodus is sometimes described as \"creating a new Antwerp\".\nFlanders and Brabant, went into a period of relative decline from the time of the Thirty Years' War. In the Northern Netherlands, the mass emigration from Flanders and Brabant became an important driving force behind the Dutch Golden Age.\nSouthern Netherlands (1581\u20131795).\nAlthough arts remained relatively impressive for another century with Peter Paul Rubens (1577\u20131640) and Anthony van Dyck, Flanders lost its former economic and intellectual power under Spanish, Austrian, and French rule. Heavy taxation and rigid imperial political control compounded the effects of industrial stagnation and Spanish-Dutch and Franco-Austrian conflict. The Southern Netherlands suffered severely under the Franco-Dutch War, Nine Years' War and War of the Spanish Succession. But under the reign of Empress Maria-Theresia, these lands again flourished economically. Influenced by the Enlightenment, the Austrian Emperor Joseph II was the first sovereign who had been in the Southern Netherlands since King Philip II of Spain left them in 1559.\nFrench Revolution and Napoleonic France (1795\u20131815).\nIn 1794, the French Republican Army started using Antwerp as the northernmost naval port of France. The following year, France officially annexed Flanders as the \"d\u00e9partements\" of Lys, Escaut, Deux-N\u00e8thes, Meuse-Inf\u00e9rieure and Dyle. Obligatory (French) army service for all men aged 16\u201325 years was a main reason for the uprising against the French in 1798, known as the \"Boerenkrijg\" (\"Peasants' War\"), with the heaviest fighting in the Campine area.\nUnited Kingdom of the Netherlands (1815\u20131830).\nAfter the defeat of Napoleon Bonaparte at the 1815 Battle of Waterloo in Brabant, the Congress of Vienna (1815) gave sovereignty over the Austrian Netherlands \u2013 Belgium minus the East Cantons and Luxembourg \u2013 to the United Netherlands (Dutch: \"Verenigde Nederlanden\") under Prince William I of Orange Nassau, making him William I of the United Kingdom of the Netherlands. William I started rapid industrialisation of the southern parts of the Kingdom. But the political system failed to forge a true union between the north and south. Most of the southern bourgeoisie was Roman Catholic and French-speaking, while the north was mainly Protestant and Dutch-speaking.\nIn 1815, the Dutch Senate was reinstated (Dutch: \"Eerste Kamer der Staaten Generaal\"). The nobility, mainly coming from the south, became more and more estranged from their northern colleagues. Resentment grew between the Roman Catholics from the south and the Protestants from the north, and also between the powerful liberal bourgeoisie from the south and their more moderate colleagues from the north. On 25 August 1830 (after the showing of the opera 'La Muette de Portici' of Daniel Auber in Brussels) the Belgian Revolution sparked. On 4 October 1830, the Provisional Government (Dutch: \"Voorlopig Bewind\") proclaimed its independence, which was later confirmed by the National Congress that issued a new Liberal Constitution and declared the new state a Constitutional Monarchy, under the House of Saxe-Coburg. Flanders now became part of the Kingdom of Belgium, which was recognized by the major European Powers on 20 January 1831. The cessation was recognized by the United Kingdom of the Netherlands on 19 April 1839.\nKingdom of Belgium.\nIn 1830, the Belgian Revolution led to the splitting up of the two countries. Belgium was confirmed as an independent state by the Treaty of London of 1839, but deprived of the eastern half of Limburg (now Dutch Limburg), and the Eastern half of Luxembourg (now the Grand-Duchy of Luxembourg). Sovereignty over Zeelandic Flanders, south of the Westerscheldt river delta, was left with the Kingdom of the Netherlands, which was allowed to levy a toll on all traffic to Antwerp harbour until 1863.\nRise of the Flemish Movement.\nIn 1873, Dutch became an official language in public secondary schools. In 1898, Dutch and French were declared equal languages in laws and Royal orders. In 1930, the first Flemish university was opened.\nThe first official translation of the Belgian constitution in Dutch was not published until 1967.\nWorld War I and its consequences.\nFlanders (and Belgium as a whole) saw some of the greatest loss of life on the Western Front of the First World War, in particular from the three battles of Ypres.\nThe war strengthened Flemish identity and consciousness. The occupying German authorities took several Flemish-friendly measures. The resulting suffering of the war is remembered by Flemish organizations during the yearly Yser pilgrimage in Diksmuide at the monument of the Yser Tower.\nRight-wing nationalism in the interbellum and World War II.\nDuring the interbellum and World War II, several right-wing fascist and/or national-socialistic parties emerged in Belgium. Since these parties were promised more rights for the Flemings by the German government during World War II, many of them collaborated with the Nazi regime. After the war, collaborators (or people who were \"Zwart\", \"Black\" during the war) were prosecuted and punished, among them many Flemish nationalists whose main political goal had been the emancipation of Flanders. As a result, until today Flemish nationalism is often associated with right-wing. Flemish nationalism is however a direct consequence of the events of the years prior to the first World War, in which many were oppressed by the French speaking majority. This ultimately gave way to a rising feeling of cultural autonomy and even a sense of a nationalism.\nFlemish autonomy.\nAfter World War II, the differences between Dutch-speaking and French-speaking Belgians became clear in a number of conflicts, such as the Royal Question, the question whether King Leopold III should return (which most Flemings supported but Walloons did not) and the use of Dutch in the Catholic University of Leuven. As a result, several state reforms took place in the second half of the 20th century, which transformed the unitary Belgium into a federal state with communities, regions and language areas. This resulted also in the establishment of a Flemish Parliament and Government. During the 1970s, all major political parties split into a Dutch and French-speaking party.\nSeveral Flemish parties still advocate for more Flemish autonomy, some even for Flemish independence (see Partition of Belgium), whereas the French-speakers would like to keep the current state as it is. Recent governments (such as Verhofstadt I Government) have transferred certain federal competences to the regional governments.\nOn 13 December 2006, a spoof news broadcast by the Belgian Francophone public broadcasting station RTBF announced that Flanders had decided to declare independence from Belgium.\nThe 2007 federal elections showed more support for Flemish autonomy, marking the start of the 2007\u20132011 Belgian political crisis. All the political parties that advocated a significant increase of Flemish autonomy gained votes as well as seats in the Belgian federal parliament. This was especially the case for Christian Democratic and Flemish and New Flemish Alliance (N-VA) (who had participated on a shared electoral list). The trend continued during the 2009 regional elections, where CD&amp;V and N-VA were the clear winners in Flanders, and N-VA became even the largest party in Flanders and Belgium during the 2010 federal elections, followed by the longest-ever government formation after which the Di Rupo I Government was formed excluding N-VA. Eight parties agreed on a sixth state reform which aim to solve the disputes between Flemings and French-speakers. However, the 2012 provincial and municipal elections continued the trend of N-VA becoming the biggest party in Flanders.\nHowever, sociological studies show no parallel between the rise of nationalist parties and popular support for their agenda. Instead, a recent study revealed a majority in favour of returning regional competences to the federal level.\nGovernment and politics.\nBoth the Flemish Community and the Flemish Region are constitutional institutions of the Kingdom of Belgium, exercising certain powers within their jurisdiction, granted following a series of state reforms. In practice, the Flemish Community and Region together form a single body, with its own parliament and government, as the Community legally absorbed the competences of the Region. The parliament is a directly elected legislative body composed of 124 representatives. The government consists of up to 11 members and is presided by a Minister-President, currently Geert Bourgeois (New Flemish Alliance) leading a coalition of his party (N-VA) with Christen-Democratisch en Vlaams (CD&amp;V) and Open Vlaamse Liberalen en Democraten (Open VLD).\nThe area of the Flemish Community is represented on the maps above, including the area of the Brussels-Capital Region (hatched on the relevant map). Roughly, the Flemish Community exercises competences originally oriented towards the individuals of the Community's language: culture (including audiovisual media), education, and the use of the language. Extensions to personal matters less directly associated with language comprise sports, health policy (curative and preventive medicine), and assistance to individuals (protection of youth, social welfare, aid to families, immigrant assistance services, etc.)\nThe area of the Flemish Region is represented on the maps above. It has a population of more than 6 million (excluding the Dutch-speaking community in the Brussels Region, grey on the map for it is not a part of the Flemish Region). Roughly, the Flemish Region is responsible for territorial issues in a broad sense, including economy, employment, agriculture, water policy, housing, public works, energy, transport, the environment, town and country planning, nature conservation, credit, and foreign trade. It supervises the provinces, municipalities, and intercommunal utility companies.\nThe number of Dutch-speaking Flemish people in the Capital Region is estimated to be between 11% and 15% (official figures do not exist as there is no language census and no official subnationality). According to a survey conducted by the University of Louvain (UCLouvain) in Louvain-la-Neuve and published in June 2006, 51% of respondents from Brussels claimed to be bilingual, even if they do not have Dutch as their first language. They are governed by the Brussels Region for economics affairs and by the Flemish Community for educational and cultural issues.\nAs mentioned above, Flemish institutions such as the Flemish Parliament and Government, represent the Flemish Community and the Flemish Region. The region and the community thus \"de facto\" share the same parliament and the same government. All these institutions are based in Brussels. Nevertheless, both types of subdivisions (the Community and the Region) still exist legally and the distinction between both is important for the people living in Brussels. Members of the Flemish Parliament who were elected in the Brussels Region cannot vote on affairs belonging to the competences of the Flemish Region.\nThe official language for all Flemish institutions is Dutch. French enjoys a limited official recognition in a dozen municipalities along the borders with French-speaking Wallonia, and a large recognition in the bilingual Brussels Region. French is widely known in Flanders, with 59% claiming to know French according to a survey conducted by UCLouvain in Louvain-la-Neuve and published in June 2006.\nPolitics.\nHistorically, the political parties reflected the pillarisation (\"verzuiling\") in Flemish society. The traditional political parties of the three pillars are Christian-Democratic and Flemish (CD&amp;V), the Open Flemish Liberals and Democrats (Open Vld) and the Socialist Party \u2013 Differently (sp.a).\nHowever, during the last half century, many new political parties were founded in Flanders. One of the first was the nationalist People's Union, of which the right nationalist Flemish Block (now Flemish Interest) split off, and which later dissolved into the now-defunct Spirit or Social Liberal Party, moderate nationalism rather left of the spectrum, on the one hand, and the New Flemish Alliance (N-VA), more conservative but independentist, on the other hand. Other parties are the leftist alternative/ecological Green party; the short-lived anarchistic libertarian spark ROSSEM and more recently the conservative-right liberal List Dedecker, founded by Jean-Marie Dedecker, and the socialist Workers' Party.\nParticularly the Flemish Block/Flemish Interest has seen electoral success roughly around the turn of the century, and the New Flemish Alliance during the last few elections, even becoming the largest party in the 2010 federal elections.\nFlemish independence.\nFor some inhabitants, Flanders is more than just a geographical area or the federal institutions (Flemish Community and Region). Supporters of the Flemish Movement even call it a nation and pursue Flemish independence, but most people (approximately 75%) living in Flanders say they are proud to be Belgian and opposed to the dissolution of Belgium. 20% is even \"very proud\", while some 25% are not proud and 8% is \"very not proud\". Mostly students claim to be proud of their nationality, with 90% of them saying so. Of the people older than 55, 31% claim to be proud of being a Belgian. Particular opposition to secession comes from women, people employed in services, the highest social classes and people from big families. Strongest of all opposing the notion are housekeepers\u2014both housewives and house husbands.\nIn 2012, the Flemish government drafted a \"Charter for Flanders\" (\"Handvest voor Vlaanderen\") of which the first article says \"Vlaanderen is een deelstaat van de federale Staat Belgi\u00eb en maakt deel uit van de Europese Unie.\" (\"Flanders is a component state of the federal State of Belgium and is part of the European Union\").\nGeography.\nFlanders shares its borders with Wallonia in the south, Brussels being an enclave within the Flemish Region. The rest of the border is shared with the Netherlands (Zeelandic Flanders in Zeeland, North Brabant and Limburg) in the north and east, and with France (French Flanders in Hauts-de-France) and the North Sea in the west. Voeren is an exclave of Flanders between Wallonia and the Netherlands, while Baarle-Hertog in Flanders forms a complicated series of enclaves and exclaves with Baarle-Nassau in the Netherlands. Germany, although bordering Wallonia and close to Voeren in Limburg, does not share a border with Flanders. The German-speaking Community of Belgium, also close to Voeren, does not border Flanders either. (The commune of Plombi\u00e8res, majority French speaking, lies between them.)\nFlanders is a highly urbanised area, lying completely within the Blue Banana. Antwerp, Ghent, Bruges and Leuven are the largest cities of the Flemish Region. Antwerp has a population of more than 500,000 citizens and is the largest city, Ghent has a population of 250,000 citizens, followed by Bruges with 120,000 citizens and Leuven counts almost 100,000 citizens.\nBrussels is a part of Flanders as far as community matters are concerned, but does not belong to the Flemish Region.\nFlanders has two main geographical regions: the coastal Yser basin plain in the north-west and a central plain. The first consists mainly of sand dunes and clayey alluvial soils in the polders. Polders are areas of land, close to or below sea level that have been reclaimed from the sea, from which they are protected by dikes or, a little further inland, by fields that have been drained with canals. With similar soils along the lowermost Scheldt basin starts the central plain, a smooth, slowly rising fertile area irrigated by many waterways that reaches an average height of about above sea level with wide valleys of its rivers upstream as well as the Campine region to the east having sandy soils at altitudes around thirty metres. Near its southern edges close to Wallonia one can find slightly rougher land, richer in calcium, with low hills reaching up to and small valleys, and at the eastern border with the Netherlands, in the Meuse basin, there are marl caves (\"mergelgrotten\"). Its exclave around Voeren between the Dutch border and Wallonia's Li\u00e8ge Province attains a maximum altitude of above sea level.\nAdministrative divisions.\nThe present-day Flemish Region covers and is divided into five provinces, 22 arrondissements and 285 cities or municipalities.\nThe province of Flemish Brabant is the most recently created, being formed in 1995 after the splitting of the province of Brabant on a linguistic basis.\nMost municipalities are made up of several former municipalities, now called \"deelgemeenten\". The largest municipality (both in terms of population and area) is Antwerp, having more than half a million inhabitants. Its nine \"deelgemeenten\" have a special status and are called districts, which have an elected council and a college. While any municipality with more than 100,000 inhabitants can establish districts, only Antwerp did this so far. The smallest municipality (also both in terms of population and area) is Herstappe (Limburg).\nThe Flemish Community covers both the Flemish Region and, together with the French Community, the Brussels-Capital Region. Brussels, an enclave within the province of Flemish Brabant, is not divided into any province nor is it part of any. It coincides with the Arrondissement of Brussels-Capital and includes 19 municipalities.\nThe Flemish Government has its own local institutions in the Brussels-Capital Region, being the \"Vlaamse Gemeenschapscommissie\" (VGC), and its municipal antennae (\"Gemeenschapscentra\", community centres for the Flemish community in Brussels). These institutions are independent from the educational, cultural and social institutions that depend directly on the Flemish Government. They exert, among others, all those cultural competences that outside Brussels fall under the provinces.\nClimate.\nThe climate is maritime temperate, with significant precipitation in all seasons (K\u00f6ppen climate classification: \"Cfb\"; the average temperature is in January, and in July; the average precipitation is in January, and in July).\nEconomy.\nTotal gross regional product (GRP) of Flanders in 2021 was \u20ac296 billion (excluding Brussels). Per capita GDP at purchasing power parity was 20% above the EU average. Flemish productivity per capita is about 13% higher than that in Wallonia, and wages are about 7% higher than in Wallonia.\nFlanders was one of the first continental European areas to undergo the Industrial Revolution, in the 19th century. Initially, the modernization relied heavily on food processing and textile. However, by the 1840s the textile industry of Flanders was in severe crisis and there was famine in Flanders (1846\u201350). After World War II, Antwerp and Ghent experienced a fast expansion of the chemical and petroleum industries. Flanders also attracted a large majority of foreign investments in Belgium. The 1973 and 1979 oil crises sent the economy into a recession. The steel industry remained in relatively good shape. In the 1980s and 90s, the economic centre of Belgium continued to shift further to Flanders and is now concentrated in the populous Flemish Diamond area. Nowadays, the Flemish economy is mainly service-oriented.\nBelgium is a founding member of the European Coal and Steel Community in 1951, which evolved into the present-day European Union. In 1999, the euro, the single European currency, was introduced in Flanders. It replaced the Belgian franc in 2002.\nThe Flemish economy is strongly export-oriented, in particular of high value-added goods. The main imports are food products, machinery, rough diamonds, petroleum and petroleum products, chemicals, clothing and accessories, and textiles. The main exports are automobiles, food and food products, iron and steel, finished diamonds, textiles, plastics, petroleum products, and non-ferrous metals. Since 1922, Belgium and Luxembourg have been a single trade market within a customs and currency union\u2014the Belgium\u2013Luxembourg Economic Union. Its main trading partners are Germany, the Netherlands, France, the United Kingdom, Italy, the United States, and Spain.\nAntwerp is the number one diamond market in the world, diamond exports account for roughly 1/10 of Belgian exports. The Antwerp-based BASF plant is the largest BASF-base outside Germany, and accounts on its own for about 2% of Belgian exports. Other industrial and service activities in Antwerp include car manufacturing, telecommunications, photographic products.\nFlanders is home to several science and technology institutes, such as IMEC, VITO, Flanders DC, and Flanders Make.\nInfrastructure.\nFlanders has developed an extensive transportation infrastructure of ports, canals, railways and highways. The Port of Antwerp is the second-largest in Europe, after Rotterdam. Other ports are Bruges-Zeebrugge, Ghent and Ostend, of which Zeebrugge and Ostend are located at the .\nWhereas railways are managed by the federal National Railway Company of Belgium, other public transport (De Lijn) and roads are managed by the Flemish region.\nThe main airport is Brussels Airport, the only other civilian airport with scheduled services in Flanders is Antwerp International Airport, but there are two other ones with cargo or charter flights: Ostend-Bruges International Airport and Kortrijk-Wevelgem International Airport, both in West Flanders.\nDemographics.\nThe highest population density is found in the area circumscribed by the Brussels-Antwerp-Ghent-Leuven agglomerations that surround Mechelen and is known as the Flemish Diamond, in other important urban centres as Bruges, Roeselare and Kortrijk to the west, and notable centres Turnhout and Hasselt to the east. On 1 January 2015, the Flemish Region had a population of 6,444,127 and about 15% of the 1,175,173 people in the Brussels Region are also considered Flemish.\nReligion.\nThe Belgian constitution provides for freedom of religion, and the various governments in general respect this right in practice. Since independence, Catholicism, counterbalanced by strong freethought movements, has had an important role in Belgium's politics, since the 20th century in Flanders mainly via the Christian trade union ACV and the Christian Democratic and Flemish party (CD&amp;V). According to the \"2001 Survey and Study of Religion\", about 47 percent of the Belgian population identify themselves as belonging to the Catholic Church, while Islam is the second-largest religion at 3.5 percent. A 2006 inquiry in Flanders, considered more religious than Wallonia, showed that 55% considered themselves religious, and 36% believed that God created the world.\nJews have been present in Flanders for a long time, in particular in Antwerp. More recently, Muslims have immigrated to Flanders, now forming the largest minority religion with about 3.9% in the Flemish Region and 25% in Brussels. The largest Muslim group is Moroccan in origin, while the second largest is Turkish in origin.\nEducation.\nEducation is compulsory from the ages of six to 18, but most Flemings continue to study until around 23. Among the Organisation for Economic Co-operation and Development countries in 1999, Flanders had the third-highest proportion of 18- to 21-year-olds enrolled in postsecondary education. Flanders also scores very high in international comparative studies on education. Its secondary school students consistently rank among the top three for mathematics and science. However, the success is not evenly spread: ethnic minority youth score consistently lower, and the difference is larger than in most comparable countries.\nMirroring the historical political conflicts between the secular and Catholic segments of the population, the Flemish educational system is split into a secular branch controlled by the communities, the provinces, or the municipalities, and a subsidised religious\u2014mostly Catholic\u2014branch. For the subsidised schools, the main costs such as the teacher's wages and building maintenance completely borne by the Flemish government. Subsidised schools are also free to determine their own teaching and examination methods, but in exchange, they must be able to prove that certain minimal terms are achieved by keeping records of the given lessons and exams. It should however be noted that\u2014at least for the Catholic schools\u2014the religious authorities have very limited power over these schools, neither do the schools have a lot of power on their own. Instead, the Catholic schools are a member of the Catholic umbrella organisation . The VSKO determines most practicalities for schools, like the advised schedules per study field. However, there's freedom of education in Flanders, which doesn't only mean that every pupil can choose his/her preferred school, but also that every organisation can found a school, and even be subsidised when abiding the different rules. This resulted also in some smaller school systems follow 'methodical pedagogies' (e.g. Steiner, Montessori, or Freinet) or serve the Jewish and Protestant minorities.\nDuring the school year 2003\u20132004, 68.30% of the total population of children between the ages of six and 18 went to subsidized private schools (both religious schools or 'methodical pedagogies' schools).\nThe big freedom given to schools results in a constant competition to be the \"best\" school. The schools get certain reputations amongst parents and employers. So it's important for schools to be the best school since the subsidies depend on the number of pupils. This competition has been pinpointed as one of the main reasons for the high overall quality of the Flemish education. However, the importance of a school's reputation also makes schools more eager to expel pupils that don't perform well. Resulting in the ethnic differences and the well-known waterfall system: pupils start high in the perceived hierarchy, and then drop towards more professional oriented directions or \"easier\" schools when they can't handle the pressure any longer.\nHealthcare.\nHealthcare is a federal matter, but the Flemish Government is responsible for care, health education and preventive care.\nCulture.\nLanguage and literature.\nThe standard language in Flanders is Dutch; spelling and grammar are regulated by a single authority, the Dutch Language Union (\"Nederlandse Taalunie\"), comprising a committee of ministers of the Flemish and Dutch governments, their advisory council of appointed experts, a controlling commission of 22 parliamentarians, and a secretariate. The term Flemish can be applied to the Dutch spoken in Flanders; it shows many regional and local variations.\nThe biggest difference between Belgian Dutch and Dutch used in the Netherlands is in the pronunciation of words. The Dutch spoken in the north of the Netherlands is typically described as being \"sharper\", while Belgian Dutch is \"softer\". In Belgian Dutch, there are also fewer vowels pronounced as diphthongs. When it comes to spelling, Belgian Dutch language purists historically avoided writing words using a French spelling, or searched for specific translations of words derived from French, while the Dutch often retain the French spelling. For example, the Dutch word \"punaise\" (English: \"Drawing pin\") is derived directly from the French language. Belgian Dutch language purists have lobbied to accept the word \"duimspijker\" (literally: \"thumb spike\") as official Dutch, though the Dutch Language Union never accepted it as standard Dutch. Other proposals by purists were sometimes accepted, and sometimes reverted again in later spelling revisions. As language purists were quite often professionally involved in language (e.g. as a teacher), these unofficial purist translations are found more often in Belgian Dutch texts.\nThe earliest example of literature in non-standardized dialects in the current area of Flanders is Hendrik van Veldeke's \"Eneas Romance\", the first courtly romance in a Germanic language (12th century). With a writer of Hendrik Conscience's stature, Flemish literature rose ahead of French literature in Belgium's early history. Guido Gezelle not only explicitly referred to his writings as Flemish but used it in many of his poems, and strongly defended it:\nOriginal \n&lt;poem&gt;Gij zegt dat 't vlaamsch te niet zal gaan:\n't en zal!\ndat 't waalsch gezwets zal boven slaan:\n't en zal!\nDat hopen, dat begeren wij:\ndat zeggen en dat zweren wij:\nzoo lange als wij ons weren, wij:\n't en zal, 't en zal,\n't en zal!&lt;/poem&gt;\n&lt;poem&gt;You say Flemish will fade away:\nIt shan't!\nthat Walloon twaddle will have its way:\nIt shan't!\nThis we hope, for this we hanker:\nthis we say and this we vow:\nas long as we fight back, we:\nIt shan't, It shan't,\nIt shan't!&lt;/poem&gt;\nThe distinction between Dutch and Flemish literature, often perceived politically, is also made on intrinsic grounds by some experts such as Kris Humbeeck, professor of literature at the University of Antwerp. Nevertheless, most Dutch-language literature read (and appreciated to varying degrees) in Flanders is the same as that in the Netherlands.\nInfluential Flemish writers include Ernest Claes, Stijn Streuvels and Felix Timmermans. Their novels mostly describe rural life in Flanders in the 19th century and at beginning of the 20th. Widely read by the older generations, they are considered somewhat old-fashioned by present-day critics. Some famous Flemish writers of the early 20th century wrote in French, including Nobel Prize winners (1911) Maurice Maeterlinck and Emile Verhaeren. They were followed by a younger generation, including Paul van Ostaijen and Gaston Burssens, who \"activated\" the Flemish Movement. Still widely read and translated into other languages (including English) are the novels of authors such as Willem Elsschot, Louis Paul Boon and Hugo Claus. The recent crop of writers includes the novelists Tom Lanoye and Herman Brusselmans, and poets such as the married couple Herman de Coninck and Kristien Hemmerechts.\nLanguages.\nAt the creation of the Belgian state, French was the only official language. Historically Flanders was a Dutch-speaking region. For a long period, French was used as a second language and, like elsewhere in Europe, commonly spoken among the aristocracy. There is still a French-speaking minority in Flanders, especially in the municipalities with language facilities, along the language border and the Brussels periphery (Vlaamse Rand), though many of them are French-speakers that migrated to Flanders in recent decades.\nIn French Flanders, French is the only official language and now the native language of the majority of the population, but there is still a minority of Dutch-speakers living there. French is also the primary language in the officially bilingual Brussels Capital Region (see Francization of Brussels).\nMany Flemings are also able to speak French, children in Flanders generally get their first French lessons in the 5th primary year (normally around 10 years). But the current lack of French outside the educational context makes it hard to maintain a decent level of French. As such, the proficiency of French is declining. Flemish pupils are also obligated to follow English lessons as their third language. Normally from the second secondary year (around 14 years old), but the ubiquity of English in movies, music, IT and even advertisements makes it easier to learn and maintain the English language.\nMedia.\nThe public radio and television broadcaster in Flanders is VRT, which operates the TV channels \u00e9\u00e9n, Canvas, Ketnet, OP12 and (together with the Netherlands) BVN. Flemish provinces each have up to two TV channels as well. Commercial television broadcasters include vtm and Vier (VT4). Popular TV series are for example \"Thuis\" and \"F.C. De Kampioenen\".\nThe five most successful Flemish films were \"Loft\" (2008; 1,186,071 visitors), \"Koko Flanel\" (1990; 1,082,000 tickets sold), \"Hector\" (1987; 933,000 tickets sold), \"Daens\" (1993; 848,000 tickets sold) and \"De Zaak Alzheimer\" (2003; 750,000 tickets sold). The first and last ones were directed by Erik Van Looy, and an American remake is being made of both of them, respectively \"The Loft\" (2012) and \"The Memory of a Killer\". The other three ones were directed by Stijn Coninx.\nNewspapers are grouped under three main publishers: De Persgroep with , the most popular newspaper in Flanders, \"De Morgen\" and \"De Tijd\". Then Corelio with \"\", the oldest extant Flemish newspaper, and . Lastly, Concentra publishes and \"Het Belang van Limburg\".\nMagazines include \"Knack\" and \"HUMO\".\nSports.\nAssociation football (soccer) is one of the most popular sports in both parts of Belgium, together with cycling, tennis, swimming and judo.\nIn cycling, the Tour of Flanders is considered one of the five \"Monuments\". Other \"Flanders Classics\" races include \"Dwars door Vlaanderen\" and Gent\u2013Wevelgem. Eddy Merckx is widely regarded as the greatest cyclist of all time, with five victories in the Tour de France and numerous other cycling records. His hour speed record (set in 1972) stood for 12 years.\nJean-Marie Pfaff, a former Belgian goalkeeper, is considered one of the greatest in the history of football (soccer).\nKim Clijsters (as well as the French-speaking Belgian Justine Henin) was Player of the Year twice in the Women's Tennis Association as she was ranked the number one female tennis player.\nKim Gevaert and Tia Hellebaut are notable track and field stars from Flanders.\nThe 1920 Summer Olympics were held in Antwerp. Jacques Rogge was president of the International Olympic Committee from 2001 to 2013.\nThe Flemish government agency for sports is Bloso.\nMusic.\nFlanders is known for its music festivals, like the annual Rock Werchter, Tomorrowland and Pukkelpop. The Gentse Feesten is another very large yearly event.\nThe best-selling Flemish group or artist is the (Flemish-Dutch) group 2 Unlimited, followed by (Italian-born) Rocco Granata, Technotronic, Helmut Lotti and Vaya Con Dios.\nThe weekly charts of best-selling singles is the Ultratop 50. \"Kvraagetaan\" by the Fixkes holds the current record for longest time at No. 1 on the chart."}
{"id": "10879", "revid": "1252038552", "url": "https://en.wikipedia.org/wiki?curid=10879", "title": "Freud (disambiguation)", "text": "Sigmund Freud (1856\u20131939) was the inventor of psychoanalysis, psychosexual stages, and the personality theory of Ego, Superego, and Id.\nFreud or Freudian may also refer to:"}
{"id": "10880", "revid": "1273119229", "url": "https://en.wikipedia.org/wiki?curid=10880", "title": "Plurality voting", "text": "Plurality voting refers to electoral systems in which the candidates in an electoral district who poll more than any other (that is, receive a plurality) are elected.\nUnder single-winner plurality voting, and in systems based on single-member districts, plurality voting is called single member [district] plurality (SMP), which is widely known as \"first-past-the-post\". In SMP/FPTP the leading candidate, whether or not they have a majority of votes, is elected.\nThere are several versions of plurality voting for multi-member district. The system that elects multiple winners at once with the plurality rule and where each voter casts as many X votes as the number of seats in a multi-seat district is referred to as plurality block voting. A semi-proportional system that elects multiple winners elected at once with the plurality rule and where each voter casts more than one vote but fewer than the number of seats to fill in a multi-seat district is known as limited voting. A semi-proportional system that elects multiple winners elected at once with the plurality rule and where each voter casts just one vote in a multi-seat district is known as single non-transferable voting.\nPlurality voting is widely used throughout the English-speaking world as a result of its spread by the British Empire, including in most of the United States. Outside of the English-speaking world, it is less popular than its close relatives in the runoff family of methods. Overall, more countries in the world use a form of proportional representation than use plurality or a form of runoff.\nPlurality voting procedures.\nSingle-winner and single-member systems.\nIn single-winner plurality voting (first-past-the-post), each voter is allowed to vote for only one candidate, and the winner of the election is the candidate who represents a plurality of voters or, in other words, received more votes than any other candidate. In an election for a single seat, such as for president in a presidential system, voters may vote for one candidate from a list of the candidates who are competing, and the winner is whichever candidate receives the highest number of votes. Compare first-past-the-post to a \"majority\" system, the two-round system, where usually the top two candidates in the first ballot progress to the second round, also called the runoff. A runoff is by default not held, if a candidate already received an absolute majority in the first ballot (more than half of votes), and in the second ballot, where there are only two candidates, one of the candidates will (except for a tie) receive a majority. Under plurality rules, the candidates are not at any point in the election required to have majority support.\nIn an election for a legislative body with single-member seats, each voter in a geographically defined electoral district may vote for one candidate from a list of the candidates who are competing to represent that district. Under the plurality system, the winner of the election then becomes the representative of the whole electoral district and serves with representatives of other electoral districts. That makes plurality voting among the simplest of all electoral systems for voters and vote counting officials; however, the drawing of district boundary lines can be contentious in the plurality system (see gerrymandering). The system is also independent of parties; the party with the most votes overall may not win the most seats overall (electoral inversion). Note that issues arising from single-member districts are still in place with majority voting systems, like the two-round system and instant-runoff voting too.\nThe same principle used in single-winner plurality voting (electing the candidate with the most votes) is also used in approval voting, however with very different effects, as voters can choose to support as many or few candidates as they choose, not just one. For this reason, approval voting is usually distinguished from plurality voting, while technically being a sub-type of it.\nMulti-winner systems.\nMulti-member plurality elections are only slightly more complicated. Where \"n\" is the number of seats in the district, the \"n\" candidates who get more votes than the others are elected; the winners are the \"n\" candidates with the largest number of votes. The rules may allow the voter to vote for one candidate, for a number of candidates more than one but less than \"n\", for as many as \"n\" candidates, or some other number.\nWhen voters may vote for only one candidate, it is called the single non-transferable vote. While seemingly most similar to first-past-the-post, in effect it is a semi-proportional system allowing for mixed representation in one district, and representation of both majority parties and electoral minorities within a district.\nWhen voters can vote for one or more candidates, but in total less than the number of winners, it is called limited voting.\nThe multi-winner version considered to be the extension of first-past-the-post to multi-winner cases is plurality block voting. Here voters may vote for as many candidates as there are seats to fill, which means usually candidates from the largest party will fill all the seats in the district.\nThe party-list version of plurality voting in multi-member districts is called party block voting. Here the party receiving a plurality of votes wins all of the seats available.\nBallot types.\nGenerally, plurality ballots can be categorized into two forms. The simplest form is a blank ballot in which the name of a candidate(s) is written in by hand. A more structured ballot will list all the candidates and allow a mark to be made next to the name of a single candidate (or more than one, in some cases); however, a structured ballot can also include space for a write-in candidate.\nExamples.\nSingle-winner.\nThis is a general example for single-winner plurality voting (\"first-past-the-post\"), using population percentages taken from one state for illustrative purposes.\nIf each voter in each city naively selects one city on the ballot (Memphis voters select Memphis, Nashville voters select Nashville, and so on), Memphis will be selected, as it has the most votes 42%. The system does not require that the winner have a majority, only a plurality. Memphis wins because it has the most votes even though 58% of the voters in the example preferred Memphis least. The opposite result would occur in instant-runoff, where Knoxville (the city furthest to the east, and the \"second-worst\" choice) would accumulate a majority from vote transfers from voter who initially voted for Chattanooga and Nashville. Nashville is the majority-preferred winner, and as a result would be elected by any Condorcet method.\nMulti-winner.\nCandidates are running in a 3-member district of 10 000 voters.\nUnder non-transferable (and non-cumulative) plurality voting, each voter may cast no more than one vote for a single candidate, even if they have multiple votes to cast.\nParty A has about 35% support among the electorate (with one particularly well-liked candidate), Party B around 25% (with two well-liked candidates) and the remaining voters primarily support independent candidates, but mostly lean towards party B if they have to choose between the two parties. All voters vote sincerely; there is no tactical voting. (Percentage of votes under MNTV and Limited Voting is the percentage of voters who voted for the candidate, not the percentage of votes cast.)\nUnder all three versions of multi-winner plurality voting, the three most popular candidates according to voters' first preferences are elected, regardless of party affiliation, but with three different results.\nIssues.\nIn all plurality systems.\nWasted votes.\nWasted votes are those cast for candidates or parties who did not get elected. Some number of wasted votes by this definition is practically unavoidable, but plurality systems suffer from large numbers of wasted votes. For example, in the UK general election of 2005, 52% of votes were cast for losing candidates and 18% were excess votes, a total of 70% wasted votes. That is perhaps the most fundamental criticism of FPTP, the single-member plurality system, since at least half the votes are always wasted in a district, either as being placed on un-elected candidates or being surplus to what could be needed to win.\nSMP is in practice similar in plurality block voting. They both operate under the \"winner-takes-all\" principle, which means that the party of the losing candidates in each district receive no representation, regardless of the number of votes they receive. Even the single non-transferable vote can result in very inefficient results if many candidates with small support compete or the most-popular candidates receive a large excess of votes. This is because like other plurality systems, STNV does not transfer loser and surplus votes.\nAnother way to count wasted votes, is to see the ones that may play no part in determining the outcome. Under FPTP for example, usually only votes for the top two candidates can be seen as really competing for the position, with only one possible to win; votes placed on other candidates are almost certain not to be used to elect anyone and therefore wasted. Sometimes not even two candidate are seen as being competitive. Due to having a history of repeatedly electing candidates of a certain party, many districts are known to have safe seats. On such, a candidate or party has a near 100% chance that they win the seats. Supporters of others sometimes do not even bother to vote knowing of the odds that face their candidate.\nAlternative electoral systems, such as proportional representation, attempt to ensure that almost all of the votes are effective in influencing the result and electing a representative, which minimizes vote wastage. Such systems decreases disproportionality in election results and are also credited for increasing voter turnout.\nTactical voting.\nTo a much greater extent than many other electoral methods, plurality electoral systems encourage tactical voting techniques like \"compromising\". Voters are under pressure to vote for one of the two candidates most likely to win, even if their true preference is neither of them; because a vote for any other candidate is unlikely to lead to the preferred candidate being elected. In single-member plurality, this will instead reduce support for one of the two major candidates whom the voter might prefer to the other. Electors who prefer not to waste their vote by voting for a candidate with a very low chance of winning their constituency vote for their lesser preferred candidate who has a higher chance of winning. The minority party will then simply take votes away from one of the major parties, which could change the outcome and gain nothing for the voters. Any other party will typically need to build up its votes and credibility over a series of elections before it is seen as electable.\nIn the Tennessee example, if all the voters for Chattanooga and Knoxville had instead voted for Nashville, Nashville would have won (with 58% of the vote). That would have only been the third choice for those voters, but voting for their respective first choices (their own cities) actually results in their fourth choice (Memphis) being elected.\nThe difficulty is sometimes summed up in an extreme form, as \"All votes for anyone other than the second place are votes for the winner\". That is because by voting for other candidates, voters have denied those votes to the second-place candidate, who could have won had they received them. It is often claimed by United States Democrats that Democrat Al Gore lost the 2000 Presidential Election to Republican George W. Bush because some voters on the left voted for Ralph Nader of the Green Party, who, exit polls indicated, would have preferred Gore at 45% to Bush at 27%, with the rest not voting in Nader's absence.\nThat thinking is illustrated by elections in Puerto Rico and its three principal voter groups: the Independentistas (pro-independence), the Populares (pro-commonwealth), and the Estadistas (pro-statehood). Historically, there has been a tendency for Independentista voters to elect Popular candidates and policies. This results in more Popular victories even though the Estadistas have the most voters on the island. It is so widely recognised that the Puerto Ricans sometimes call the Independentistas who vote for the Populares \"melons\" in reference to the party colours, because the fruit is green on the outside but red on the inside.\nSuch tactical voting can cause significant perturbation to the system:\nProponents of other single-winner electoral systems argue that their proposals would reduce the need for tactical voting and reduce the spoiler effect. Other systems include the commonly used two-round system of runoffs and instant-runoff voting, along with less-tested and perhaps less-understood systems such as approval voting, score voting and Condorcet methods.\nThis is when a voter decides to vote in a way that does not represent their true preference or choice, motivated by an intent to influence election outcomes. Strategic behaviour by voters can and does influence the outcome of voting in different plurality voting systems. Strategic behaviour is when a voter casts their vote for a different party or alternative district/constituency/riding in order to induce, in their opinion, a better outcome. An example of this is when a person really likes party A but votes for party B because they do not like party C or D or because they believe that party A has little to no chance of winning. This can cause the outcome of very close votes to be swayed for the wrong reason. This might have had an impact on the 2000 United States election that was essentially decided by fewer than 600 votes, with the winner being President Bush. When voters behave in a strategic way and expect others to do the same, they end up voting for one of the two leading candidates, making the Condorcet alternative more likely to be elected. The prevalence of strategic voting in an election makes it difficult to evaluate the true political state of the population, as their true political ideologies are not reflected in their votes.\nSpoiler effect.\nThe spoiler effect is especially severe in plurality voting, where candidates with similar ideologies are forced to split the vote with each other. One spoiler candidate's presence in the election draws votes from a major candidate with similar politics, which causes a strong opponent of both or several to win. Even extremely small parties with very little first-preference support can therefore affect the outcome of an FPTP election.\nManipulation charges.\nThe presence of spoilers often gives rise to suspicions that manipulation of the slate has taken place. The spoiler may have received incentives to run. A spoiler may also drop out at the last moment, which induces charges that such an act was intended from the beginning. Voters who are uninformed do not have a comparable opportunity to manipulate their votes as voters who understand all opposing sides, understand the pros and cons of voting for each party.\nGerrymandering.\nBecause FPTP permits a high level of wasted votes, an election under FPTP is easily gerrymandered unless safeguards are in place. In gerrymandering, a party in power deliberately manipulates constituency boundaries to increase the number of seats that it wins unfairly.\nIn brief, if a governing party G wishes to reduce the seats that will be won by opposition party O in the next election, it can create a number of constituencies in each of which O has an overwhelming majority of votes. O will win these seats, but many of its voters will waste their votes. Then, the rest of the constituencies are designed to have small majorities for G. Few G votes are wasted, and G will win many seats by small margins. As a result of the gerrymander, O's seats have cost it more votes than G's seats.\nEfficiency gap: The \"efficiency gap\" measures gerrymandering and has been scrutinized in the Supreme Court of the United States. The efficiency gap is the difference between the two parties' wasted votes, divided by the total number of votes.\nIn some plurality systems.\nFewer political parties.\nDuverger's law is a theory that constituencies that use first-past-the-post systems will eventually become a two-party system after enough time. The two dominating parties regularly alternate in power and easily win constituencies due to the structure of plurality voting systems. This puts smaller parties who struggle to meet the threshold of votes at a disadvantage, and inhibits growth.\nPlurality voting tends to reduce the number of political parties to a greater extent than most other methods do, making it more likely that a single party will hold a majority of legislative seats. (In the United Kingdom, 22 out of 27 general elections since 1922 have produced a single-party majority government or, in the case of the National Governments, a parliament from which such a single-party government could have been drawn.)\nPlurality voting's tendency toward fewer parties and more-frequent majorities of one party can also produce a government that may not consider as wide a range of perspectives and concerns. It is entirely possible that a voter finds all major parties to have similar views on issues, and that a voter does not have a meaningful way of expressing a dissenting opinion through their vote.\nAs fewer choices are offered to voters, voters may vote for a candidate although they disagree with them because they disagree even more with their opponents. That will make candidates less closely reflect the viewpoints of those who vote for them.\nFurthermore, one-party rule is more likely to lead to radical changes in government policy even though the changes are favoured only by a plurality or a bare majority of the voters, but a multi-party system usually requires more consensus to make dramatic changes in policy.\nVoter turnout.\nPolitical apathy is prevalent in plurality voting systems such as FPTP. Studies suggest that plurality voting system fails to incentivize citizens to vote, which results in very low voter turnouts. Under this system, many people feel that voting is an empty ritual that has no influence on the composition of legislature. Voters are not assured that the number of seats that political parties are accorded will reflect the popular vote, which disincentivizes them from voting and sends the message that their votes are not valued, and participation in elections does not seem necessary.\nIssues specific to particular countries.\nSolomon Islands.\nIn August 2008, Sir Peter Kenilorea commented on what he perceived as the flaws of a first-past-the-post electoral system in the Solomon Islands:\nArguments for plurality.\nSimplicity and familiarity.\nPlurality voting is generally considered one of the simplest methods and of the most widely known. Because of its widespread use, in situations where people become voters, it will not be a new concept for most and may even be expected. Other systems may specifically need to be explained to the voters and may be perceived as more complicated.\nWidespread familiarity with the system does not imply widespread familiarity with the effects. Voters may not be aware of the issues in plurality voting, therefore they may vote sincerely even in situations where voting theory would suggest they should vote tactically, thereby voting against their rational interests.\nAnother counter-argument is that plurality voting is partially considered simple because of its familiarity, which in turn results from its prevalence. Such argument is made by proponents of another plurality-based system, approval voting, where unlike usual plurality voting, voters may vote for any number of candidates. If approval voting is default, plurality voting (where voters only cast one otherwise fixed number of votes) would be seen at least equally unfamiliar to voters.\nEase of balloting.\nUnder plurality voting, ballots use simple marks instead of ranking or scoring, which can make especially paper-based ballots simpler. However, non-plurality systems such as closed list PR may also use just as simple ballots.\nIn cases without ballots, such as open voting by raised hands, for example, there are simpler methods that do not require checking for people who voted more than they are allowed to, for example, approval voting.\nEase of counting.\nWith plurality voting, counting and summing up votes is generally an easy process, and this may be done on a precinct level and then summed up for a total with the same results. Some alternative methods, such as instant-runoff-voting do not work this way and either counting has to take place centrally, or complete (non-aggregated) results from precincts need to be submitted to the central authority for results.\nArguments for single-member plurality.\nCommon arguments for specifically the single-winner variant of plurality voting are constituency representation (which all other single-winner systems provide to the same degree) and governmental stability (which is dependent on other factors as well). These arguments can be made for some multi-member versions and plurality voting in general too.\nVoting system attributes and comparison to non-plurality systems.\nAttributes and criteria.\nMajority criterion: Will a candidate always win who is ranked as the unique favorite by a majority of voters?\nNo favorite betrayal: Can voters be sure that they do not need to rank any other candidate above their favorite in order to obtain a result they prefer?\nComparison to non-plurality systems.\nPlurality voting is often contrasted with (absolute) majority voting where variant of runoff voting (multi-round voting) are also classified. However, in formal social choice theory, the term majority voting has a different definition, and runoff voting methods could also be classified under plurality. \nInternational examples.\nPlurality voting is used for local and/or national elections in 43 of the 193 countries that are members of the United Nations. It is particularly prevalent in the United Kingdom, the United States, Canada and India.\nGeneral elections in the United Kingdom.\nThe United Kingdom, like the United States and Canada, uses single-member districts as the base for national elections. Each electoral district (constituency) chooses one member of parliament, the candidate who gets the most votes, whether or not they get at least 50% of the votes cast (\"first past the post\"). In 1992, for example, a Liberal Democrat in Scotland won a seat (Inverness, Nairn and Lochaber) with just 26% of the votes. The system of single-member districts with plurality winners tends to produce two large political parties. In countries with proportional representation there is not such a great incentive to vote for a large party, which contributes to multi-party systems.\nScotland, Wales and Northern Ireland use the first-past-the-post system for UK general elections but versions of proportional representation for elections to their own assemblies and parliaments. All of the UK used one form or another of proportional representation for European Parliament elections.\nThe countries that inherited the British majoritarian system tend toward two large parties: one left and the other right, such as the U.S. Democrats and Republicans. Canada is an exception, with three major political parties consisting of the New Democratic Party, which is to the left; the Conservative Party, which is to the right; and the Liberal Party, which is slightly off-centre but to the left. A fourth party that no longer has major party status is the separatist Bloc Qu\u00e9b\u00e9cois party, which is territorial and runs only in Quebec. New Zealand once used the British system, which yielded two large parties as well. It also left many New Zealanders unhappy because other viewpoints were ignored, which made the New Zealand Parliament in 1993 adopt a new electoral law modelled on Germany's system of proportional representation (PR) with a partial selection by constituencies. New Zealand soon developed a more complex party system.\nAfter the 2015 UK general election, there were calls from UKIP for a switch to the use of proportional representation after it received 3,881,129 votes that produced only one MP. The Green Party was similarly underrepresented, which contrasted greatly with the SNP, a Scottish separatist party that received only 1,454,436 votes but won 56 seats because of more geographically concentrated support.\nThe United Kingdom continues to use the first-past-the-post electoral system for general elections, and for local government elections in England and Wales. Changes to the UK system have been proposed, and alternatives were examined by the Jenkins Commission in the late 1990s. After the formation of a new coalition government in 2010, it was announced as part of the coalition agreement that a referendum would be held on switching to the alternative vote system. However the alternative vote system was rejected 2\u20131 by British voters in a referendum held on 5 May 2011.\nOutside the United Kingdom.\nCanada also uses FPTP for national and provincial elections. In May 2005 the Canadian province of British Columbia had a referendum on abolishing single-member district plurality in favour of multi-member districts with the Single Transferable Vote system after the Citizens' Assembly on Electoral Reform made a recommendation for the reform. The referendum obtained 57% of the vote, but failed to meet the 60% requirement for passing. A second referendum was held in May 2009, this time the province's voters defeated the change with 39% voting in favour.\nAn October 2007 referendum in the Canadian province of Ontario on adopting a Mixed Member Proportional system, also requiring 60% approval, failed with only 36.9% voting in favour. British Columbia again called a referendum on the issue in 2018 which was defeated by 62% voting to keep current system.\nNorthern Ireland, Scotland, Wales, the Republic of Ireland, Australia and New Zealand are notable examples of countries within the UK, or with previous links to it, that use non-FPTP electoral systems (Northern Ireland, Scotland and Wales use FPTP in United Kingdom general elections, however).\nNations which have undergone democratic reforms since 1990 but have not adopted the FPTP system include South Africa, almost all of the former Eastern bloc nations, Russia, and Afghanistan.\nList of countries.\nCountries that use plurality voting to elect the lower or only house of their legislature include: (Some of these may be undemocratic systems where there is effectively only one candidate allowed anyway.)\nReferences.\nThe fatal flaws of Plurality (first-past-the-post) electoral systems \u2013 Proportional Representation Society of Australia"}
{"id": "10881", "revid": "36768958", "url": "https://en.wikipedia.org/wiki?curid=10881", "title": "Fetish", "text": "Fetish may refer to:"}
{"id": "10882", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=10882", "title": "February 14", "text": "It is observed in most countries as Valentine's Day."}
{"id": "10883", "revid": "42445653", "url": "https://en.wikipedia.org/wiki?curid=10883", "title": "Free trade area", "text": "A free trade area is the region encompassing a trade bloc whose member countries have signed a free trade agreement (FTA). Such agreements involve cooperation between at least two countries to reduce trade barriers, import quotas and tariffs, and to increase trade of goods and services with each other. If natural persons are also free to move between the countries, in addition to a free trade agreement, it would also be considered an open border. It can be considered the second stage of economic integration.\nCustoms unions are a special type of free trade area. All such areas have internal arrangements which parties conclude in order to liberalize and facilitate trade among themselves. The crucial difference between customs unions and free trade areas is their approach to third parties. While a customs union requires all parties to establish and maintain identical external tariffs with regard to trade with non-parties, parties to a free trade area are not subject to this requirement. Instead, they may establish and maintain whatever tariff regime applying to imports from non-parties as deemed necessary. In a free trade area without harmonized external tariffs, to eliminate the risk of trade deflection, parties will adopt a system of preferential rules of origin.\nThe term \"free trade area\" was originally meant by the General Agreement on Tariffs and Trade (GATT 1994) to include only trade in goods. An agreement with a similar purpose, i.e., to enhance liberalization of trade in services, is named under Article V of the General Agreement on Trade in Services (GATS) as an \"economic integration agreement\". However, in practice, the term is now widely used to refer to agreements covering not only goods but also services and even investment.\nLegal aspects of free trade areas.\nThe formation of free trade areas is considered an exception to the most favored nation (MFN) principle in the World Trade Organization (WTO) because the preferences that parties to a free trade area exclusively grant each other go beyond their accession commitments. Although Article XXIV of the GATT allows WTO members to establish free trade areas or to adopt interim agreements necessary for the establishment thereof, there are several conditions with respect to free trade areas, or interim agreements leading to the formation of free trade areas.\nFirstly, duties and other regulations maintained in each of the signatory parties to a free trade area, which are applicable at the time such free trade area is formed, to the trade with non-parties to such free trade area shall not be higher or more restrictive than the corresponding duties and other regulations existing in the same signatory parties prior to the formation of the free trade area. In other words, the establishment of a free trade area to grant preferential treatment among its member is legitimate under WTO law, but the parties to a free trade area are not permitted to treat non-parties less favorably than before the area was established. A second requirement stipulated by Article XXIV is that tariffs and other barriers to trade must be eliminated to substantially all the trade within the free trade area.\nFree trade agreements forming free trade areas generally lie outside the realm of the multilateral trading system. However, WTO members must notify to the Secretariat when they conclude new free trade agreements and in principle the texts of free trade agreements are subject to review under the Committee on Regional Trade Agreements. Although a dispute arising within free trade areas is not subject to litigation at the WTO's Dispute Settlement Body, \"there is no guarantee that WTO panels will abide by them and decline to exercise jurisdiction in a given case\".\nEconomic aspects of free trade areas.\nTrade diversion and trade creation\nIn general, \"trade diversion\" means that a free trade area would divert trade away from more efficient suppliers outside the area towards less efficient ones within the areas. Whereas, \"trade creation\" implies that a free trade area creates trade which may not have otherwise existed. In all cases trade creation will raise a country's national welfare.\nBoth trade creation and trade diversion are crucial effects found upon the establishment of a free trade area. Trade creation will cause consumption to shift from a high-cost producer to a low-cost one, and trade will thus expand. In contrast, trade diversion will lead to trade shifting from a lower-cost producer outside the area to a higher-cost one inside the area. Such a shift will not benefit consumers within the free trade area as they are deprived the opportunity to purchase cheaper imported goods. However, economists find that trade diversion does not always harm aggregate national welfare: it can even improve aggregate national welfare if the volume of diverted trade is small.\nFree trade areas as public goods\nEconomists have made attempts to evaluate the extent to which free trade areas can be considered public goods. They firstly address one key element of free trade areas, which is the system of embedded tribunals which act as arbitrators in international trade disputes. This system as a force of clarification for existing statutes and international economic policies is affirmed within the trade treaties.\nThe second way in which free trade areas are considered public goods is tied to the evolving trend of them becoming \"deeper\". The depth of a free trade area refers to the added types of structural policies that it covers. While older trade deals are deemed \"shallower\" as they cover fewer areas (such as tariffs and quotas), more recently concluded agreements address a number of other fields, from services to e-commerce and data localization. Since transactions among parties to a free trade area are relatively cheaper as compared to those with non-parties, free trade areas are conventionally found to be excludable. Now that deep trade deals will enhance regulatory harmonization and increase trade flows with non-parties, thus reduce the excludability of FTA benefits, new generation free trade areas are obtaining essential characteristics of public goods.\nQualifying for preferences under a free trade area.\nUnlike a customs union, parties to a free trade area do not maintain common external tariffs, which means they apply different customs duties, as well as other policies with respect to non-members. This feature creates the possibility of non-parties may free riding preferences under a free trade area by penetrating the market with the lowest external tariffs. Such risk necessitates the introduction of rules to determine originating goods eligible for preferences under a free trade area, a need that does not arise upon the formation of a customs union. Basically, there is a requirement for a minimum extent of processing that results in \"substantial transformation\" to the goods so that they can be considered originating. By defining which goods are originating in the PTA, preferential rules of origin distinguish between originating and non-originating goods: only the former will be entitled to preferential tariffs scheduled by the free trade area, the latter must pay MFN import duties.\nIt is noted that in qualifying for origin criteria, there is a differential treatment between inputs originating within and outside a free trade area. Normally inputs originating in one FTA party will be considered as originating in the other party if they are incorporated in the manufacturing process in that other party. Sometimes, production costs arising in one party is also considered as that arising in another party. In preferential rules of origin, such differential treatment is normally provided for in the cumulation or accumulation provision. Such clause further explains the trade creation and trade diversion effects of a free trade area mentioned above, because a party to a free trade area has the incentive to use inputs originating in another party so that their products may qualify for originating status.\nDatabases on free trade areas.\nSince there are hundreds of free trade areas currently in force and being negotiated (about 800 according to ITC's Rules of Origin Facilitator, counting also non-reciprocal trade arrangements), it is important for businesses and policy-makers to keep track of their status. There are a number of depositories of free trade agreements available either at national, regional or international levels. Some significant ones include the database on Latin American free trade agreements constructed by the Latin American Integration Association (ALADI), the database maintained by the Asian Regional Integration Center (ARIC) providing information agreements of Asian countries, and the portal on the European Union's free trade negotiations and agreements.\nAt the international level, there are two important free access databases developed by international organizations for policy-makers and businesses:\nWTO's Regional Trade Agreements Information System\nAs WTO members are obliged to notify to the Secretariat their free trade agreements, this database is constructed based on the most official source of information on free trade agreements (referred to as regional trade agreements in the WTO language). The database allows users to seek information on trade agreements notified to the WTO by country or by topic (goods, services or goods and services). This database provides users with an updated list of all agreements in force, however, those not notified to the WTO may be missing. It also displays reports, tables and graphs containing statistics on these agreements, and particularly preferential tariff analysis.\nITC's Market Access Map\nThe Market Access Map was developed by the International Trade Centre (ITC) with the objectives to facilitate businesses, governments and researchers in market access issues. The database, visible via the online tool Market Access Map, includes information on tariff and non-tariff barriers in all active trade agreements, not limited to those officially notified to the WTO. It also documents data on non-preferential trade agreements (for instance, Generalized System of Preferences schemes). Up until 2019, Market Access Map has provided downloadable links to texts agreements and their rules of origin. The new version of Market Access Map forthcoming this year will provide direct web links to relevant agreement pages and connect itself to other ITC's tools, particularly the Rules of Origin Facilitator. It is expected to become a versatile tool which assists enterprises in understanding free trade agreements and qualifying for origin requirements under these agreements."}
{"id": "10885", "revid": "281303", "url": "https://en.wikipedia.org/wiki?curid=10885", "title": "French fries", "text": "French fries (or simply fries, also known as chips among other names) are \"batonnet\" or \"julienne\"-cut deep-fried potatoes of disputed origin. They are prepared by cutting potatoes into even strips, drying them, and frying them, usually in a deep fryer. Pre-cut, blanched, and frozen russet potatoes are widely used, and sometimes baked in a regular or convection oven, such as an air fryer.\nFrench fries are served hot, either soft or crispy, and are generally eaten as part of lunch or dinner or by themselves as a snack, and they commonly appear on the menus of diners, fast food restaurants, pubs, and bars. They are typically salted and may be served with ketchup, vinegar, mayonnaise, tomato sauce, or other sauces. Fries can be topped more heavily, as in the dishes of poutine, loaded fries or chili cheese fries, and are occasionally made from sweet potatoes instead of potatoes. \nPreparation.\nThe standard method for cooking French fries is deep frying, which submerges them in hot fat, nowadays most commonly oil. Vacuum fryers produce potato chips with lower oil content, while maintaining their color and texture.\nThe potatoes are prepared by first cutting them (peeled or unpeeled) into even strips, which are then wiped off or soaked in cold water to remove the surface starch, and thoroughly dried. They may then be fried in one or two stages. Chefs generally agree that the \"two-bath\" technique produces better results. Potatoes fresh out of the ground can have too high a water content resulting in soggy fries, so preference is for those that have been stored for a while.\nIn the two-stage or two-bath method, the first bath, sometimes called blanching, is in hot fat (around 160\u00a0\u00b0C/320\u00a0\u00b0F) to cook the fries through. This step can be done in advance. Then they are more briefly fried in very hot fat (190\u00a0\u00b0C/375\u00a0\u00b0F) to crisp the exterior. They are then placed in a colander or on a cloth to drain, then served. The exact times of the two baths depend on the size of the fries. For example, for 2\u20133\u00a0mm strips, the first bath takes about 3 minutes, and the second bath takes only seconds.\nSince the 1960s, most French fries in the US have been produced from frozen Russet potatoes which have been blanched or at least air-dried industrially. The usual fat for making french fries is vegetable oil. In the past, beef suet was recommended as superior, with vegetable shortening as an alternative. McDonald's used a mixture of 93% beef tallow and 7% cottonseed oil until 1990, when they changed to vegetable oil with beef flavoring. Horse fat was standard in northern France and Belgium until recently, and is recommended by some chefs.\nChemical and physical changes.\nFrench fries are fried in a two-step process: the first time is to cook the starch throughout the entire cut at low heat, and the second time is to create the golden crispy exterior of the fry at a higher temperature. This is necessary because if the potato cuts are only fried once, the temperature would either be too hot, causing only the exterior to be cooked and not the inside, or not hot enough where the entire fry is cooked, but its crispy exterior will not develop. Although the potato cuts may be baked or steamed as a preparation method, this section will only focus on french fries made using frying oil. During the initial frying process (approximately 150\u00a0\u00b0C), water on the surface of the cuts evaporates off the surface and the water inside the cuts gets absorbed by the starch granules, causing them to swell and produce the fluffy interior of the fry.\nThe starch granules are able to retain the water and expand due to gelatinization. The water and heat break the glycosidic linkages between amylopectin and amylose strands, allowing a new gel matrix to form via hydrogen bonds which aid in water retention. The moisture that gets trapped within the gel matrix is responsible for the fluffy interior of the fry. The gelatinized starch molecules move towards the surface of the fries \"forming a thick layer of gelatinized starch\" and this layer of pre-gelatinized starch becomes the crisp exterior after the potato cuts are fried for a second time. During the second frying process (approximately 180\u00a0\u00b0C), the remaining water on the surface of the cuts evaporates and the gelatinized starch molecules that collected towards the potato surface are cooked again, forming the crisp exterior. The golden-brown color of the fry will develop when the amino acids and glucose on the exterior participate in a Maillard browning reaction.\nName and etymology.\nIn the United States and most of Canada, the term \"french fries\", sometimes capitalised as \"French fries\", or shortened to \"fries\", refers to all dishes of fried elongated pieces of potatoes. in shape and size may have names such as \"curly fries\", \"shoestring fries\", etc.\nIn the United Kingdom, Australia, South Africa, Ireland and New Zealand, the term \"chips\" is generally used instead, though thinly cut fried potatoes are sometimes called \"french fries\" or \"skinny fries\", to distinguish them from \"chips\", which are cut thicker. In the US or Canada these more thickly-cut \"chips\" might be called \"steak fries\", depending on the shape.\nThe word \"chips\" is more often used in North America to refer to \"potato chips\", commonly known in the UK, Ireland, New Zealand, and South Africa as \"crisps\". In Australia, \"chips\" are often referred to as \"hot chips\" to distinguish them from \"potato chips\", although the type of 'chip' is often implied through context.\nThomas Jefferson had \"potatoes served in the French manner\" at a White House dinner in 1802. The expression \"french fried potatoes\" first occurred in print in English in the 1856 work \"Cookery for Maids of All Work\" by Eliza Warren: \"French Fried Potatoes. \u2013 Cut new potatoes in thin slices, put them in boiling fat, and a little salt; fry both sides of a light golden brown colour; drain.\" This account referred to thin, shallow-fried slices of potato. It is not clear where or when the now familiar deep-fried batons or fingers of potato were first prepared. In the early 20th century, the term \"french fried\" was being used in the sense of \"deep-fried\" for foods like onion rings or chicken.\nOne story about the name \"french fries\" claims that when the American Expeditionary Forces arrived in Belgium during World War I, they assumed that chips were a French dish because French was spoken in the Belgian Army. But the name existed long before that in English, and the popularity of the term did not increase for decades after 1917. The term was in use in the United States as early as 1886. An 1899 item in \"Good Housekeeping\" specifically references \"Kitchen Economy in France\": \"The perfection of French fries is due chiefly to the fact that plenty of fat is used.\"\nOrigin.\nChile.\nThe oldest documents where a fried potato is mentioned are from Chile in 1629 in the city of Nacimiento, extracted from \"Happy Captivity\", written in 1673 by Chilean Francisco N\u00fa\u00f1ez de Pineda, where he narrates his experiences as a captive war soldier in 1629 at the hands of Mapuche warriors. In the text, he mentioned eating \"papas fritas\" (fried potatoes) in 1629 and women \"sent fried and stewed potatoes\" to the chiefs. The exact shape is unclear, likely cubes fried in butter which was customary. However, the cane shape originates from Europe.\nSpain.\nFrench fries as we know them may have been invented in Spain, the first European country in which the potato appeared from the New World colonies. Professor Paul Ilegems, curator of the Frietmuseum in Bruges, Belgium, believes that Saint Teresa of \u00c1vila of Spain cooked the first French fries, and refers also to the tradition of frying in Mediterranean cuisine as evidence. \nBelgian\u2013French dispute.\nThe Belgians and French have an ongoing dispute about where fries were invented.\nThe Belgian food historian Pierre Leclercq has traced the history of the french fry and asserts that \"it is clear that fries are of French origin\". They became an emblematic Parisian dish in the 19th century. Fr\u00e9d\u00e9ric Krieger, a Bavarian musician, learned to cook fries at a roaster on rue Montmartre in Paris in 1842, and took the recipe to Belgium in 1844, where he created his business Fritz and sold \"la pomme de terre frite \u00e0 l'instar de Paris\" (\"Paris-style fried potatoes\"). The modern style of fries born in Paris around 1855 is different from the domestic fried potato that existed in the 18th century.\nFrom the Belgian standpoint, the popularity of the term \"french fries\" is explained as \"French gastronomic hegemony\" into which the cuisine of Belgium was assimilated, because of a lack of understanding coupled with a shared language and geographic proximity of the countries. The Belgian journalist claimed that a 1781 family manuscript recounts that potatoes were deep-fried prior to 1680 in the Meuse valley, as a substitute for frying fish when the rivers were frozen. G\u00e9rard never produced the manuscript that supports this claim, and \"the historical value of this story is open to question\". In any case, it is unrelated to the later history of the french fry, as the potato did not arrive in the region until around 1735; furthermore, given 18th-century economic conditions: \"it is absolutely unthinkable that a peasant could have dedicated large quantities of fat for cooking potatoes. At most they were saut\u00e9ed in a pan\".\nGlobal use.\nBelgium.\nFries are very popular in Belgium, where they are known as (in Flemish) or (in Belgian French), and the Netherlands, where among the working classes they are known as \"patat\" in the north and, in the south, \"friet(en)\". In Belgium, fries are sold in shops called (French), / (Flemish), (Dutch in The Netherlands) or / (German). They are served with a large variety of Belgian sauces and eaten either on their own or with other snacks. Traditionally fries are served in a (French), // (Dutch/Flemish), or (German), a white cardboard cone, then wrapped in paper, with a spoonful of sauce (often mayonnaise) on top.\nFrance.\nIn France and other French-speaking countries, fried potatoes are formally , but more commonly (\"fried apples\"), , or simply . The words (\"needle-ettes\") or (\"matchsticks\") are used when the French fries are very small and thin. One enduring origin story holds that french fries were invented by street vendors on the Pont Neuf bridge in Paris in 1789, just before the outbreak of the French Revolution. However, a reference exists in France from 1775 to \"a few pieces of fried potato\" and to \"fried potatoes\". Eating potatoes for sustenance was promoted in France by Antoine-Augustin Parmentier, but he did not mention \"fried\" potatoes in particular. A note in a manuscript in U.S. president Thomas Jefferson's hand (circa 1801\u20131809) mentions \"Pommes de terre frites \u00e0 cru, en petites tranches\" (\"Potatoes deep-fried while raw, in small slices\"). The recipe almost certainly comes from his French chef, Honor\u00e9 Julien. \nThe thick-cut fries are called or simply (about ); thinner variants are (matchstick potatoes; about ), and (potato straws; ). are waffle fries. A popular dish in France is steak frites, which is steak accompanied by thin french fries.\nGermany.\nFrench fries migrated to the German-speaking countries during the 19th century. In Germany, they are usually known by the French words , or only or (derived from the French words, but pronounced as German words). Often served with ketchup or mayonnaise, they are popular as a side dish in restaurants, or as a street-food snack purchased at an (snack stand). Since the 1950s, \"currywurst\" has become a widely-popular dish that is commonly offered with fries. Currywurst is a sausage (often bratwurst or bockwurst) in a spiced ketchup-based sauce, dusted with curry powder and served with fries.\nUnited Kingdom.\nThe standard deep-fried cut potatoes in the United Kingdom are called chips, and are cut into pieces between thick. They are occasionally made from unpeeled potatoes (skins showing). British \"chips\" are not the same thing as potato chips (an American term); those are called \"crisps\" in the UK and some other countries. In the UK, chips are part of the popular, and now international, fast food dish fish and chips. In the UK, the name chips are a separate item to french fries; with chips being more thickly cut than french fries, they can be cooked once or multiple times at different temperatures. From 1813 on, recipes for deep-fried cut potatoes occur in popular cookbooks. By the late 1850s, at least one cookbook refers to \"French Fried Potatoes\".\nThe first commercially available chips in the UK were sold by Mrs 'Granny' Duce in one of the West Riding towns in 1854. A blue plaque in Oldham marks the origin of the fish-and-chip shop, and thus the start of the fast food industry in Britain. In Scotland, chips were first sold in Dundee: \"in the 1870s, that glory of British gastronomy \u2013 the chip \u2013 was first sold by Belgian immigrant Edward De Gernier in the city's Greenmarket\". In Ireland the first chip shop was \"opened by Giuseppe Cervi\", an Italian immigrant, \"who arrived there in the 1880s\". It was estimated in 2011 that in the UK, 80% of households bought frozen chips each year. Although chips were a popular dish in most Commonwealth countries, the \"thin style\" french fries have been popularised worldwide in large part by the large American fast food chains such as McDonald's and Burger King.\nNetherlands.\n\" or just \" (French), \"\"frieten\" (a word used in Flanders and the southern provinces of the Netherlands) or \"patat\"\" (used in the north and central parts of the Netherlands) became a national snack. Fries also come in the form of a common Dutch street food, known as \"Patatje Oorlog\", translated to as \"war fries\". It consists of fries dressed with mayonnaise, a peanut-based satay sauce and garnished with diced raw onions along with a variety of other optional ingredients.\nUnited States.\nIn the United States, the J. R. Simplot Company is credited with successfully commercialising french fries in frozen form during the 1940s. Subsequently, in 1967, Ray Kroc of McDonald's contracted the Simplot company to supply them with frozen fries, replacing fresh-cut potatoes. In 2004, 29% of the United States' potato crop was used to make frozen fries; 90% consumed by the food services sector and 10% by retail. The United States supplies China with most of their french fries, as 70% of China's french fries are imported. Pre-made french fries have been available for home cooking since the 1960s, having been pre-fried (or sometimes baked), frozen and placed in a sealed plastic bag. Some fast-food chains dip the fries in a sugar solution or a starch batter, to alter the appearance or texture. French fries are one of the most popular dishes in the United States, commonly being served as a side dish to main dishes and in fast food restaurants. The average American eats around of french fries a year.\nNew Brunswick.\nThe town of Florenceville-Bristol, New Brunswick in Canada, headquarters of McCain Foods, calls itself \"the French fry capital of the world\" and also hosts a museum about potatoes called Potato World. McCain Foods is the world's largest manufacturer of frozen french fries and other potato specialities.\nQu\u00e9bec.\nFrench fries are the main ingredient in the Qu\u00e9b\u00e9cois dish known as \"poutine\", a dish consisting of fried potatoes covered with cheese curds and brown gravy. Poutine has a growing number of variations, but it is generally considered to have been developed in rural Qu\u00e9bec sometime in the 1950s, although precisely where in the province it first appeared is a matter of contention. Canada is also responsible for providing 22% of China's french fries.\nSpain.\nIn Spain, fried potatoes are called \"patatas fritas\" or \"papas fritas\". Another common form, involving larger irregular cuts, is \"patatas bravas\". The potatoes are cut into big chunks, partially boiled and then fried. They are usually seasoned with a spicy tomato sauce. Fries are a common side dish in Latin American cuisine or part of larger preparations such as the salchipapas in Peru or chorrillana in Chile.\nSouth Africa.\nWhilst eating 'regular' crispy french fries is common in South Africa, a regional favourite, particularly in Cape Town, is a soft soggy version doused in white vinegar called \"slap-chips\" (pronounced \"\"slup-chips\" in English or \"slaptjips\"\" in Afrikaans). These chips are typically thicker and fried at a lower temperature for a longer period of time than regular french fries. Slap-chips are an important component of a Gatsby sandwich, also a common Cape Town delicacy. Slap-chips are also commonly served with deep fried fish which are also served with the same white vinegar.\nJapan.\n is a standard fast-food side dish in Japan. Inspired by Japanese cuisine, okonomiyaki fries are served with a topping of unagi sauce, mayonnaise, katsuobushi, nori seasoning (furikake) and stir-fried cabbage.\nVariants.\nFrench fries come in multiple variations and toppings. Some examples include:\nAccompaniments.\nFries tend to be served with a variety of accompaniments, such as salt and vinegar (malt, balsamic or white), pepper, Cajun seasoning, grated cheese, melted cheese, mushy peas, heated curry sauce, curry ketchup, hot sauce, relish, mustard, mayonnaise, bearnaise sauce, tartar sauce, chili, tzatziki, feta cheese, garlic sauce, fry sauce, butter, sour cream, ranch dressing, barbecue sauce, gravy, honey, aioli, brown sauce, ketchup, lemon juice, piccalilli, pickled cucumber, pickled gherkins, pickled onions or pickled eggs. In Australia, a popular flavoring added to chips is chicken salt.\nNutrition.\nFrench fries primarily contain carbohydrates (mostly in the form of starch) and protein from the potato, and fat absorbed during the deep-frying process. Salt, which contains sodium, is almost always applied as a surface seasoning. For example, a large serving of french fries at McDonald's in the United States is 154 grams and includes 350\u00a0mg of sodium. The 510 calories come from 66\u00a0g of carbohydrates, 24\u00a0g of fat and 7\u00a0g of protein.\nA number of experts have criticised french fries for being very unhealthy. According to Jonathan Bonnet in a \"Time\" magazine article, \"fries are nutritionally unrecognizable from a spud\" because they \"involve frying, salting, and removing one of the healthiest parts of the potato: the skin, where many of the nutrients and fiber are found.\" Kristin Kirkpatrick calls french fries \"an extremely starchy vegetable dipped in a fryer that then loads on the unhealthy fat, and what you have left is a food that has no nutritional redeeming value in it at all.\" David Katz states that \"French fries are often the super-fatty side dish to a burger\u2014and both are often used as vehicles for things like sugar-laced ketchup and fatty mayo.\" Eric Morrissette, spokesperson for Health Canada, states that people should limit their intake of french fries, but eating them occasionally is not likely to be a health concern.\nFrying french fries in beef tallow, lard, or other animal fats adds saturated fat to them. Replacing animal fats with tropical vegetable oils, such as palm oil, simply substitutes one saturated fat for another. For many years partially hydrogenated vegetable oils were used as a means of avoiding cholesterol and reducing saturated fatty acid content, but in time the trans fat content of these oils was perceived as contributing to cardiovascular disease. Starting in 2008, many restaurant chains and manufacturers of pre-cooked frozen french fries for home reheating phased out trans-fat\u2013containing vegetable oils.\nFrench fries contain some of the highest levels of acrylamides of any foodstuff, and experts have raised concerns about the effects of acrylamides on human health. According to the American Cancer Society, it is not clear whether acrylamide consumption affects people's risk of getting cancer. A meta-analysis indicated that dietary acrylamide is not related to the risk of most common cancers, but could not exclude a modest association for kidney, endometrial or ovarian cancers. A lower-fat method for producing a french-fry\u2013like product is to coat \"frenched\" or wedge potatoes in oil and spices/flavoring before baking them. The temperature will be lower compared to deep frying, which reduces acrylamide formation.\nIn April 2023, researchers from China suggested a possible link between the consumption of fried food and mental health problems. According to the study, those who frequently consume fried food, especially potatoes, have an increased risk of depression and anxiety, by 7% and 12% respectively, compared to those who do not. The connection was particularly prominent among younger males. However, the causal relationship is not conclusive. The results are still preliminary, and the researchers are uncertain whether consuming fried foods causes mental health problems or individuals with symptoms of anxiety and depression tend to opt for fried foods.\nLegal issues.\nIn June 2004, the United States Department of Agriculture (USDA), with the advisement of a federal district judge from Beaumont, Texas, classified batter-coated french fries as a vegetable under the Perishable Agricultural Commodities Act. This was primarily for trade reasons; french fries do not meet the standard to be listed as a processed food. This classification, referred to as the \"French fry rule\", was upheld in the United States Court of Appeals for the Fifth Circuit case \"Fleming Companies, Inc. v. USDA\".\nEnvironmental impact.\nA 2022 study estimated the environmental impact of 57,000 food products in the UK and Ireland, finding that French fries have a lower impact on the environment than many other foods."}
{"id": "10886", "revid": "15130", "url": "https://en.wikipedia.org/wiki?curid=10886", "title": "Field hockey", "text": "Field hockey (or simply hockey) is a team sport structured in standard hockey format, in which each team plays with 11 players in total, made up of 10 field players and a goalkeeper. Teams must move a hockey ball around a field by hitting it with a hockey stick towards the rival team's shooting circle and then into the goal. The match is won by the team that scores the most goals. Matches are played on grass, watered turf, artificial turf, or indoor boarded surface.\nThe stick is made of wood, carbon fibre, fibreglass and carbon, or a combination of carbon fibre and fibreglass in different quantities. The stick has two sides; one rounded and one flat; only the flat face of the stick is allowed to progress the ball. During play, goalkeepers are the only players allowed to touch the ball with any part of their body. A player's hand is considered part of the stick if holding the stick. If the ball is \"played\" with the rounded part of the stick (i.e., deliberately stopped or hit), it will result in a penalty (accidental touches are not an offence if they do not materially affect play). Goalkeepers often have a different design of stick; they also cannot play the ball with the round side of their stick.\nThe modern game was developed at public schools in 19th-century England and it is now played globally. The governing body is the International Hockey Federation (FIH), called the in French. Men and women are represented internationally in competitions including the Olympic Games, World Cup, FIH Pro League, Junior World Cup and in past also World League, Champions Trophy. Many countries run extensive junior, senior, and masters club competitions. The FIH is also responsible for organizing the Hockey Rules Board and developing the sport's rules.\nThe sport is known simply as \"hockey\" in countries where it is the more common form of hockey. The term \"field hockey\" is used primarily in Canada and the United States, where \"hockey\" more often refers to ice hockey. In Sweden and Finland, the term ' and ' respectively are used, translating to \"ground\" hockey in opposition to the more standard ice hockey variant. A popular variant is indoor field hockey, which differs in a number of respects while embodying the primary principles of hockey.\nHistory.\nAccording to the International Hockey Federation (FIH), \"the roots of hockey are buried deep in antiquity\". There are historical records which suggest early forms of hockey were played in Egypt and Persia , and in Ethiopia . Later evidence suggest that the ancient Greeks, Romans and Aztecs all played hockey-like games. In Ancient Egypt, there is a depiction of two figures playing with sticks and ball in the Beni Hasan tomb of Khety, an administrator of Dynasty XI.\nIn Ancient Greece, there is a similar image dated , which may have been called () because it was played with a horn (, in Ancient Greek) and a ball. Researchers disagree over how to interpret this image. It could have been a team or one-on-one activity (the depiction shows two active players, and other figures who may be team-mates awaiting a face-off, or non-players waiting for their turn at play). Billiards historians Stein and Rubino believe it was among the games ancestral to lawn-and-field games like hockey and ground billiards, and near-identical depictions appear in later European illuminated manuscripts and other works of the 14th through 17th centuries, showing contemporary courtly and clerical life.\nIn East Asia, a similar game was entertained, using a carved wooden stick and ball, prior to 300 BC. In Inner Mongolia, China, the Daur people have for about 1,000 years been playing \"beikou\", a game with some similarities to field hockey. A similar field hockey or ground billiards variant, called \"suigan\", was played in China during the Ming dynasty (1368\u20131644, post-dating the Mongol-led Yuan dynasty). A game similar to field hockey was played in the 17th century in Punjab state in India under name ( refers to the woolen ball, and to the stick).\nIn South America, most specifically in Chile, the local natives of the 16th century used to play a game called \"chueca\", which also shares common elements with hockey.\nIn Northern Europe, the games of hurling (Ireland) and ' (Iceland), both team ball games involving sticks to drive a ball to the opponents' goal, date at least as far back as the Early Middle Ages. By the 12th century, a team ball game called ' or \"\", akin to a chaotic and sometimes long-distance version of hockey or rugby football (depending on whether sticks were used in a particular local variant), was regularly played in France and southern Britain between villages or parishes. Throughout the Middle Ages to the Early Modern era, such games often involved the local clergy or secular aristocracy, and in some periods were limited to them by various anti-gaming edicts, or even banned altogether. Stein and Rubino, among others, ultimately trace aspects of these games both to rituals in antiquity involving orbs and sceptres (on the aristocratic and clerical side), and to ancient military training exercises (on the popular side); polo (essentially hockey on horseback) was devised by the Ancient Persians for cavalry training, based on the local proto-hockey foot game of the region.\nThe word \"hockey\" itself has no clear origin. One belief is that it was recorded in 1363 when Edward III of England issued the proclamation: \"Moreover we ordain that you prohibit under penalty of imprisonment all and sundry from such stone, wood and iron throwing; handball, football, or hockey; coursing and cock-fighting, or other such idle games\". The belief is based on modern translations of the proclamation, which was originally in Latin and explicitly forbade the games \"Pilam Manualem, Pedivam, &amp; Bacularem: &amp; ad Canibucam &amp; Gallorum Pugnam\". The word is the Latin for , so the reference would appear to be to a game played with sticks. The English historian and biographer John Strype did not use the word \"hockey\" when he translated the proclamation in 1720, and the word \"hockey\" remains of unknown origin.\nThe modern game developed at public schools in 19th century England. It is now played globally, particularly in parts of Western Europe, South Asia, Southern Africa, Australia, New Zealand, Argentina, and parts of the United States, primarily New England and the mid-Atlantic states. The term \"field hockey\" is used primarily in Canada and the United States where \"hockey\" more often refers to ice hockey. In Sweden, the term is used, and to some degree in Norway, where the game is governed by Norges Bandyforbund.\nThe first known club was formed in 1849 at Blackheath in south-east London, but the modern rules grew out of a version played by Middlesex cricket clubs as a winter activity. Teddington Hockey Club formed the modern game by introducing the striking circle and changing the ball to a sphere from a rubber cube. The Hockey Association was founded in 1876. It lasted just six years, before being revived by nine founding members. The first international competition took place in 1895 (Ireland 3, Wales 0), and the International Rules Board was founded in 1900.\nField hockey was played at the Summer Olympics in 1908 and 1920. It was dropped in 1924, leading to the foundation of the F\u00e9d\u00e9ration Internationale de Hockey sur Gazon (FIH) as an international governing body by seven continental European nations; and hockey was reinstated as an Olympic game in 1928. Men's hockey united under the FIH in 1970.\nThe two oldest trophies are the Irish Senior Cup, which dates back to 1894, and the Irish Junior Cup, a second XI-only competition instituted in 1895.\nIn India, the Beighton Cup and the Aga Khan tournament commenced within ten years. Entering the Olympics in 1928, India won all five games without conceding a goal, and won from 1932 until 1956 and then in 1964 and 1980. Pakistan won Olympics gold in men's hockey in 1960, 1968 and 1984. In fact, all but three of Pakistan's 11 Olympics medals so far have been in field hockey, including three gold, three silver and two bronze medals.\nIn the early 1970s, artificial turf began to be used. Synthetic pitches changed most aspects of field hockey, gaining speed. New tactics and techniques such as the Indian dribble developed, followed by new rules to take account. The switch to synthetic surfaces ended Indian and Pakistani domination because artificial turf was too expensive in developing countries. Since the 1970s, Australia, the Netherlands, and Germany have dominated at the Olympics and World Cup stages.\nWomen's field hockey was first played at British universities and schools. The first club, the Molesey Ladies, was founded in 1887. The first national association was the Irish Ladies Hockey Union in 1894, and though rebuffed by the Hockey Association, women's field hockey grew rapidly around the world. This led to the International Federation of Women's Hockey Association (IFWHA) in 1927, though this did not include many continental European countries where women played as sections of men's associations and were affiliated to the FIH. The IFWHA held conferences every three years, and tournaments associated with these were the primary IFWHA competitions. These tournaments were non-competitive until 1975.\nBy the early 1970s, there were 22 associations with women's sections in the FIH and 36 associations in the IFWHA. Discussions started about a common rule book. The FIH introduced competitive tournaments in 1974, forcing the acceptance of the principle of competitive field hockey by the IFWHA in 1973. It took until 1982 for the two bodies to merge, but this allowed the introduction of women's field hockey to the Olympic games from 1980 where, as in the men's game, the Netherlands, Germany, and Australia have been consistently strong. Argentina has emerged as a team to be reckoned with since 2000, winning the world championship in 2002 and 2010 and medals at the last three Olympics.\nIn the United States, field hockey is played predominantly by girls and women. There are few field hockey clubs, most play taking place between high school or college sides. The sport was largely introduced in the U.S. by Constance Applebee, starting with a tour of Seven Sisters colleges in 1901 and continuing through Applebee's 24-year tenure as athletic director of Bryn Mawr College. The strength of college field hockey reflects the impact of Title IX, which mandated that colleges should fund men's and women's games programmes comparably. Hockey has been predominantly played on the East Coast, specifically the Mid-Atlantic in states such as New Jersey, New York, Pennsylvania, Maryland, and Virginia. In recent years, it has become increasingly played on the West Coast and in the Midwest.\nIn other countries, participation is fairly evenly balanced between men and women. For example, in the 2008\u201309 season, England Hockey reported 2,488 registered men's teams, 1,969 women's teams, 1,042 boys' teams, 966 girls' teams and 274 mixed teams. In 2006, the Irish Hockey Association reported that the gender split among its players was approximately 65% female and 35% male. In its 2008 census, Hockey Australia reported 40,534 male club players and 41,542 female.\nField of play.\nMost hockey field dimensions were originally fixed using whole numbers of imperial measures. Metric measurements are now the official dimensions as laid down by the International Hockey Federation (FIH) in the \"Rules of Hockey\".\nThe pitch is a rectangular field. At each end is a goal high and wide, as well as lines across the field from each end-line (generally referred to as the 23-metre lines or the 25-yard lines) and in the center of the field. A spot in diameter, called the penalty spot or stroke mark, is placed with its centre from the centre of each goal. The shooting circle is from the base line.\nField hockey goals are made of two upright posts, joined at the top by a horizontal crossbar, with a net positioned to catch the ball when it passes through the goalposts. The goalposts and crossbar must be white and rectangular in shape, and should be wide and deep.\nField hockey goals also include sideboards and a backboard, which stand from the ground. The backboard runs the full width of the goal, while the sideboards are deep.\nPlaying surface.\nHistorically the game developed on natural grass turf. In the early 1970s, synthetic grass fields began to be used for hockey, with the first Olympic Games on this surface being held at Montreal in 1976. Synthetic pitches are now mandatory for all international tournaments and for most national competitions. While hockey is still played on traditional grass fields at some local levels and lesser national divisions, it has been replaced by synthetic surfaces almost everywhere in the western world. There are three main types of artificial hockey surface:\nSince the 1970s, sand-based pitches have been favoured as they dramatically speed up the game. However, in recent years there has been a massive increase in the number of \"water-based\" artificial turfs. Water-based synthetic turfs enable the ball to be transferred more quickly than on sand-based surfaces. It is this characteristic that has made them the surface of choice for international and national league competitions. Water-based surfaces are also less abrasive than sand-based surfaces and reduce the level of injury to players when they come into contact with the surface. Following the 2018 FIH Congress it was decided that new surfaces being laid should be of a hybrid variety which require less watering. This is due to the negative ecological effects of the high water requirements of water-based synthetic fields. It has also been stated that the decision to make artificial surfaces mandatory greatly favoured more affluent countries who could afford these new pitches.\nRules and play.\nOverview.\nThe game is played between two teams of eleven; 10 field players and one goal keeper are permitted to be on the pitch at any one time. The remaining players may be substituted in any combination. There is an unlimited number of times a team can sub in and out. Substitutions are permitted at any point in the game, apart from between the award and end of a penalty corner; two exceptions to this rule is for injury or suspension of the defending goalkeeper, which is not allowed when playing with a field keep, or a player can exit the field, but you must wait until after the penalty corner is complete. Play is not stopped for a substitution (except of a goalkeeper), the players leave and rejoin the match simultaneously at the half-way line.\nPlayers are permitted to play the ball with the flat of the 'face side' and with the edges of the head and handle of the field hockey stick with the exception that, for reasons of safety, the ball may not be struck 'hard' with a forehand edge stroke, because of the difficulty of controlling the height and direction of the ball from that stroke.\nThe flat side is always on the \"natural\" side for a right-handed person swinging the stick at the ball from right to left. Left-handed sticks are rare, as International Hockey Federation rules forbid their use in a game. To make a strike at the ball with a left-to-right swing the player must present the flat of the 'face' of the stick to the ball by 'reversing' the stick head, i.e. by turning the handle through approximately 180\u00b0 (while a reverse edge hit would turn the stick head through approximately 90\u00b0 from the position of an upright forehand stroke with the 'face' of the stick head).\nEdge hitting of the ball underwent a two-year \"experimental period\", twice the usual length of an \"experimental trial\" and is still a matter of some controversy within the game. Ric Charlesworth, the former Australian coach, has been a strong critic of the unrestricted use of the reverse edge hit. The 'hard' forehand edge hit was banned after similar concerns were expressed about the ability of players to direct the ball accurately, but the reverse edge hit does appear to be more predictable and controllable than its counterpart. This type of hit is now more commonly referred to as the \"forehand sweep\" where the ball is hit with the flat side or \"natural\" side of the stick and not the rounded edge.\nOther rules include; no foot-to-ball contact, no use of hands, no obstructing other players, no high back swing, no hacking, and no third party. If a player is dribbling the ball and either loses control and kicks the ball or another player interferes that player is not permitted to gain control and continue dribbling. The rules do not allow the person who kicked the ball to gain advantage from the kick, so the ball will automatically be passed on to the opposing team. Conversely, if no advantage is gained from kicking the ball, play should continue. Players may not obstruct another's chance of hitting the ball in any way. No shoving/using your body/stick to prevent advancement in the other team. Penalty for this is the opposing team receives the ball and if the problem continues, the player can be carded. While a player is taking a free hit or starting a corner the back swing of their hit cannot be too high for this is considered dangerous. Finally there may not be three players touching the ball at one time. Two players from opposing teams can battle for the ball, however if another player interferes it is considered third party and the ball automatically goes to the team who only had one player involved in the third party.\nThe game.\nA match ordinarily consists of two periods of 35 minutes and a halftime interval of 5 minutes. Other periods and interval may be agreed by both teams except as specified in regulations for particular competitions. Since 2014, some international games have four 15-minute quarters with 2 minutes break between each quarter and 5 minutes break between quarter two and three. At the 2018 Commonwealth Games, held on the Gold Coast in Brisbane, the hockey games for both men and women were played in four 15-minute quarters.\nIn December 2018, the FIH announced rule changes that would make 15-minute quarters universal from January 2019. England Hockey confirmed that while no changes would be made to the domestic game mid-season, the new rules would be implemented at the start of the 2019\u201320 season. However, in July 2019 England Hockey announced that 17.5-minute quarters would only be implemented in elite domestic club games.\nThe game begins with a pass back from the centre-forward usually to the centre-half back from the halfway line. The opposing team cannot try to tackle this play until the ball has been pushed back. The team consists of eleven players, usually aligned as follows: goalkeeper, right fullback, left fullback, three half-backs and five forwards who are right wing, right inner, centre forward, left inner and left wing. These positions can change and adapt throughout the course of the game depending on the attacking and defensive style of the opposition.\nPositions.\nWhen hockey positions are discussed, notions of fluidity are very common. Each team can be fielded with a maximum of 11 players and will typically arrange themselves into forwards, midfielders, and defensive players (fullbacks) with players frequently moving between these lines with the flow of play. Each team may also play with:\nFormations.\nAs hockey has a very dynamic style of play, it is difficult to simplify positions to the static formations which are common in association football. Although positions will typically be categorised as either fullback, halfback, midfield/inner or striker, it is important for players to have an understanding of every position on the field. For example, it is not uncommon to see a halfback overlap and end up in either attacking position, with the midfield and strikers being responsible for re-adjusting to fill the space they left. Movement between lines like this is particularly common across all positions.\nThis fluid Australian culture of hockey has been responsible for developing an international trend towards players occupying spaces on the field, not having assigned positions. Although they may have particular spaces on the field which they are more comfortable and effective as players, they are responsible for occupying the space nearest them. This fluid approach to hockey and player movement has made it easy for teams to transition between formations such as: \"3 at the back\", \"5 midfields\", \"2 at the front\", and more.\nGoalkeepers.\nWhen the ball is inside the circle, they are defending and they have their stick in their hand, goalkeepers wearing full protective equipment are permitted to use their stick, feet, kickers or leg guards to propel the ball and to use their stick, feet, kickers, leg guards or any other part of their body to stop the ball or deflect it in any direction including over the back line. Similarly, field players are permitted to use their stick. They are not allowed to use their feet and legs to propel the ball, stop the ball or deflect it in any direction including over the back line. However, neither goalkeepers, or players with goalkeeping privileges are permitted to conduct themselves in a manner which is dangerous to other players by taking advantage of the protective equipment they wear.\nNeither goalkeepers or players with goalkeeping privileges may lie on the ball, however, they are permitted to use arms, hands and any other part of their body to push the ball away. Lying on the ball deliberately will result in a penalty stroke, whereas if an umpire deems a goalkeeper has lain on the ball accidentally (e.g. it gets stuck in their protective equipment), a penalty corner is awarded.\n\"* The action above is permitted only as part of a goal saving action or to move the ball away from the possibility of a goal scoring action by opponents. It does not permit a goalkeeper or player with goalkeeping privileges to propel the ball forcefully with arms, hands or body so that it travels a long distance\"\nWhen the ball is outside the circle they are defending, goalkeepers or players with goalkeeping privileges are only permitted to play the ball with their stick. Further, a goalkeeper, or player with goalkeeping privileges who is wearing a helmet, must not take part in the match outside the 23m area they are defending, except when taking a penalty stroke. A goalkeeper must wear protective headgear at all times, except when taking a penalty stroke.\nGeneral play.\nFor the purposes of the rules, all players on the team in possession of the ball are attackers, and those on the team without the ball are defenders, yet throughout the game being played you are always \"defending\" your goal and \"attacking\" the opposite goal.\nThe match is officiated by two field umpires. Traditionally each umpire generally controls half of the field, divided roughly diagonally. These umpires are often assisted by a technical bench including a timekeeper and record keeper.\nPrior to the start of the game, a coin is tossed and the winning captain can choose a starting end or whether to start with the ball. Since 2017 the game consists of four periods of 15 minutes with a 2-minute break after every period, and a 15-minute intermission at half time before changing ends. At the start of each period, as well as after goals are scored, play is started with a pass from the centre of the field. All players must start in their defensive half (apart from the player making the pass), but the ball may be played in any direction along the floor. Each team starts with the ball in one half, and the team that conceded the goal has possession for the restart. Teams trade sides at halftime.\nField players may only play the ball with the face of the stick. If the back side of the stick is used, it is a penalty and the other team will get the ball back. Tackling is permitted as long as the tackler does not make contact with the attacker or the other person's stick before playing the ball (contact after the tackle may also be penalised if the tackle was made from a position where contact was inevitable). Further, the player with the ball may not deliberately use his body to push a defender out of the way.\nField players may not play the ball with their feet, but if the ball accidentally hits the feet, and the player gains no benefit from the contact, then the contact is not penalised. Although there has been a change in the wording of this rule from 1 January 2007, the current FIH umpires' briefing instructs umpires not to change the way they interpret this rule.\nObstruction typically occurs in three circumstances\u00a0\u2013 when a defender comes between the player with possession and the ball in order to prevent them tackling; when a defender's stick comes between the attacker's stick and the ball or makes contact with the attacker's stick or body; and also when blocking the opposition's attempt to tackle a teammate with the ball (called \"third party obstruction\").\nWhen the ball passes completely over the sidelines (on the sideline is still in), it is returned to play with a sideline hit, taken by a member of the team whose players were not the last to touch the ball before crossing the sideline. The ball must be placed on the sideline, with the hit taken from as near the place the ball went out of play as possible. If it crosses the back line after last touched by an attacker, a hit is awarded. A 15\u00a0m hit is also awarded for offences committed by the attacking side within 15\u00a0m of the end of the pitch they are attacking.\nSet plays.\nSet plays are often utilised for specific situations such as a penalty corner or free hit. For instance, many teams have penalty corner variations that they can use to beat the defensive team. The coach may have plays that sends the ball between two defenders and lets the player attack the opposing team's goal. There are no set plays unless your team has them.\nFree hits.\nFree hits are awarded when offences are committed outside the scoring circles (the term 'free hit' is standard usage but the ball need not be hit). The ball may be hit, pushed or lifted in any direction by the team offended against. The ball can be lifted from a free hit but not by hitting, the ball must be flicked or scooped to lift from a free hit. (In previous versions of the rules, hits in the area outside the circle in open play have been permitted but lifting one direction from a free hit was prohibited). Opponents must move from the ball when a free hit is awarded. A free hit must be taken from within playing distance of the place of the offence for which it was awarded and the ball must be stationary when the free hit is taken.\nAs mentioned above, a 15\u00a0m hit is awarded if an attacking player commits a foul forward of that line, or if the ball passes over the back line off an attacker. These free hits are taken in-line with where the foul was committed (taking a line parallel with the sideline between where the offence was committed, or the ball went out of play). When an attacking free hit is awarded within 5\u00a0m of the circle everyone including the person taking the penalty must be five meters from the circle and everyone apart from the person taking the free hit must be five meters away from the ball. When taking an attacking free hit, the ball may not be hit straight into the circle if the hitting player is within their attacking 23-meter area (25-yard area). It has to travel 5 meters before going in.\n2009 experimental changes.\nIn February 2009 the FIH introduced, as a \"Mandatory Experiment\" for international competition, an updated version of the free-hit rule. The changes allows a player taking a free hit to pass the ball to themselves. Importantly, this is not a \"play on\" situation, but to the untrained eye it may appear to be. The player must play the ball any distance in two separate motions, before continuing as if it were a play-on situation. They may raise an aerial or overhead immediately as the second action, or any other stroke permitted by the rules of field hockey. At high-school level, this is called a self pass and was adopted in Pennsylvania in 2010 as a legal technique for putting the ball in play.\nAlso, all players (from both teams) must be at least 5\u00a0m from any free hit awarded to the attack within the 23\u00a0m area. The ball may not travel directly into the circle from a free hit to the attack within the 23 m area without first being touched by another player or being dribbled at least 5 m by a player making a \"self-pass\". These experimental rules apply to all free-hit situations, including sideline and corner hits. National associations may also choose to introduce these rules for their domestic competitions.\nLong corner.\nA free hit from the 23-metre line \u2013 called a long corner \u2013 is awarded to the attacking team if the ball goes over the back-line after last being touched by a defender, provided they do not play it over the back-line deliberately, in which case a penalty corner is awarded. This free hit is played by the attacking team from a spot on the 23-metre line, in line with where the ball went out of play. All the parameters of an attacking free hit within the attacking quarter of the playing surface apply.\nPenalty corner.\nThe short or penalty corner is awarded: \nShort corners begin with five defenders (usually including the keeper) positioned behind the back line and the ball placed at least 10 yards from the nearest goal post. All other players in the defending team must be beyond the centre line, that is not in their 'own' half of the pitch, until the ball is in play. Attacking players begin the play standing outside the scoring circle, except for one attacker who starts the corner by playing the ball from a mark 10\u00a0m either side of the goal (the circle has a 14.63\u00a0m radius). This player puts the ball into play by pushing or hitting the ball to the other attackers outside the circle; the ball must pass outside the circle and then put back into the circle before the attackers may make a shot at the goal from which a goal can be scored. FIH rules do not forbid a shot at goal before the ball leaves the circle after being 'inserted', nor is a shot at the goal from outside the circle prohibited, but a goal cannot be scored at all if the ball has not gone out of the circle and cannot be scored from a shot from outside the circle if it is not again played by an attacking player before it enters the goal.\nFor safety reasons, the first shot of a penalty corner must not exceed 460\u00a0mm high (the height of the \"backboard\" of the goal) at the point it crosses the goal line if it is hit. However, if the ball is deemed to be below backboard height, the ball can be subsequently deflected above this height by another player (defender or attacker), providing that this deflection does not lead to danger. The \"Slap\" stroke (a sweeping motion towards the ball, where the stick is kept on or close to the ground when striking the ball) is classed as a hit, and so the first shot at goal must be below backboard height for this type of shot also.\nIf the first shot at goal in a short corner situation is a push, flick or scoop, in particular the \"drag flick\" (which has become popular at international and national league standards), the shot is permitted to rise above the height of the backboard, as long as the shot is not deemed dangerous to any opponent. This form of shooting was developed because it is not height restricted in the same way as the first hit shot at the goal and players with good technique are able to drag-flick with as much power as many others can hit a ball.\nPenalty stroke.\nA penalty stroke is awarded when a defender commits a foul in the circle (accidental or otherwise) that prevents a probable goal or commits a deliberate foul in the circle or if defenders repeatedly run from the back line too early at a penalty corner. The penalty stroke is taken by a single attacker in the circle, against the goalkeeper, from a spot 6.4\u00a0m from goal. The ball is played only once at goal by the attacker using a push, flick or scoop stroke. If the shot is saved, play is restarted with a 15 m hit to the defenders. When a goal is scored, play is restarted in the normal way.\nDangerous play and raised balls.\nAccording to the Rules of Hockey 2015 issued by the FIH there are only two criteria for a dangerously played ball. The first is legitimate evasive action by an opponent (what constitutes legitimate evasive action is an umpiring judgment). The second is specific to the rule concerning a shot at goal at a penalty corner but is generally, if somewhat inconsistently, applied throughout the game and in all parts of the pitch: it is that a ball lifted above knee height and at an opponent who is within 5m of the ball is certainly dangerous.\nThe velocity of the ball is not mentioned in the rules concerning a dangerously played ball. A ball that hits a player above the knee may on some occasions not be penalised, this is at the umpire's discretion. A jab tackle, for example, might accidentally lift the ball above knee height into an opponent from close range but at such low velocity as not to be, in the opinion of the umpire, dangerous play. In the same way a high-velocity hit at very close range into an opponent, but below knee height, could be considered to be dangerous or reckless play in the view of the umpire, especially when safer alternatives are open to the striker of the ball.\nA ball that has been lifted high so that it will fall among close opponents may be deemed to be potentially dangerous and play may be stopped for that reason. A lifted ball that is falling to a player in clear space may be made potentially dangerous by the actions of an opponent closing to within 5m of the receiver before the ball has been controlled to ground\u00a0\u2013 a rule which is often only loosely applied; the distance allowed is often only what might be described as playing distance, 2\u20133\u00a0m, and opponents tend to be permitted to close on the ball as soon as the receiver plays it: these unofficial variations are often based on the umpire's perception of the skill of the players i.e. on the level of the game, in order to maintain game flow, which umpires are in general in both Rules and Briefing instructed to do, by not penalising when it is unnecessary to do so; this is also a matter at the umpire's discretion.\nThe term \"falling ball\" is important in what may be termed encroaching offences. It is generally only considered an offence to encroach on an opponent receiving a lifted ball that has been lifted to above head height (although the height is not specified in rule) and is falling. So, for example, a lifted shot at the goal which is still rising as it crosses the goal line (or would have been rising as it crossed the goal line) can be legitimately followed up by any of the attacking team looking for a rebound.\nIn general even potentially dangerous play is not penalised if an opponent is not disadvantaged by it or, obviously, not injured by it so that he cannot continue. A personal penalty, that is a caution or a suspension, rather than a team penalty, such as a free ball or a penalty corner, may be (many would say should be or even must be, but again this is at the umpire's discretion) issued to the guilty party after an advantage allowed by the umpire has been played out in any situation where an offence has occurred, including dangerous play (but once advantage has been allowed the umpire cannot then call play back and award a team penalty).\nIt is not an offence to lift the ball over an opponent's stick (or body on the ground), provided that it is done with consideration for the safety of the opponent and not dangerously. For example, a skilful attacker may lift the ball over a defender's stick or prone body and run past them, however if the attacker lifts the ball into or at the defender's body, this would almost certainly be regarded as dangerous.\nIt is not against the rules to bounce the ball on the stick and even to run with it while doing so, as long as that does not lead to a potentially dangerous conflict with an opponent who is attempting to make a tackle. For example, two players trying to play at the ball in the air at the same time, would probably be considered a dangerous situation and it is likely that the player who first put the ball up or who was so 'carrying' it would be penalised.\nDangerous play rules also apply to the usage of the stick when approaching the ball, making a stroke at it (replacing what was at one time referred to as the \"sticks\" rule, which once forbade the raising of any part of the stick above the shoulder during any play. This last restriction has been removed but the stick should still not be used in a way that endangers an opponent) or attempting to tackle, (fouls relating to tripping, impeding and obstruction). The use of the stick to strike an opponent will usually be much more severely dealt with by the umpires than offences such as barging, impeding and obstruction with the body, although these are also dealt with firmly, especially when these fouls are intentional.\nWarnings and suspensions.\nHockey uses a three-tier penalty card system of warnings and suspensions:\nIf a coach is sent off, depending on local rules, a player may have to leave the field for the remaining length of the match.\nIn addition to their colours, field hockey penalty cards are often shaped differently, so they can be recognised easily. Green cards are normally triangular, yellow cards rectangular and red cards circular.\nUnlike football, a player may receive more than one green or yellow card. However, they cannot receive the same card for the same offence (for example two yellows for dangerous play), and the second must always be a more serious card. In the case of a second yellow card for a different breach of the rules (for example a yellow for deliberate foot, and a second later in the game for dangerous play) the temporary suspension would be expected to be of considerably longer duration than the first. However, local playing conditions may mandate that cards are awarded only progressively, and not allow any second awards.\nUmpires, if the free hit would have been in the attacking 23\u00a0m area, may upgrade the free hit to a penalty corner for dissent or other misconduct after the free hit has been awarded.\nScoring.\nThe teams' object is to play the ball into their attacking circle and, from there, hit, push or flick the ball into the goal, scoring a goal. The team with more goals after 60 minutes wins the game. The playing time may be shortened, particularly when younger players are involved, or for some tournament play. If the game is played in a countdown clock, like ice hockey, a goal can only count if the ball completely crosses the goal line and into the goal \"before\" time expires, not when the ball leaves the stick in the act of shooting.\nIf the score is tied at the end of the game, either a draw is declared or the game goes into extra time, or there is a penalty shoot-out, depending on the format of the competition. In many competitions (such as regular club competition, or in pool games in FIH international tournaments such as the Olympics or the World Cup), a tied result stands and the overall competition standings are adjusted accordingly. Since March 2013, when tie breaking is required, the official FIH Tournament Regulations mandate to no longer have extra time and go directly into a penalty shoot-out when a classification match ends in a tie. However, many associations follow the previous procedure consisting of two periods of 7.5 minutes of \"golden goal\" extra time during which the game ends as soon as one team scores.\nThere are many variations to overtime play that depend on the league or tournament rules. In American college play, a seven-a-side overtime period consists of a 10-minute golden goal period with seven players for each team. If the scores remain equal, the game enters a one-on-one competition where each team chooses five players to dribble from the line down to the circle against the opposing goalkeeper. The player has eight seconds to score against the goalkeeper while keeping the ball in bounds. The game ends after a goal is scored, the ball goes out of bounds, a foul is committed (ending in either a penalty stroke or flick or the end of the one-on-one) or time expires. If the tie still persists, more rounds are played until one team has scored.\nRule change procedure.\nThe FIH implemented a two-year rules cycle with the 2007\u201308 edition of the rules, with the intention that the rules be reviewed on a biennial basis. The 2009 rulebook was officially released in early March 2009 (effective 1 May 2009), however the FIH published the major changes in February. The current rule book is effective from 1 January 2024.\nLocal rules.\nThere are sometimes minor variations in rules from competition to competition; for instance, the duration of matches is often varied for junior competitions or for carnivals. Different national associations also have slightly differing rules on player equipment.\nThe new Euro Hockey League and the Olympics has made major alterations to the rules to aid television viewers, such as splitting the game into four-quarters, and to try to improve player behavior, such as a two-minute suspension for green cards\u2014the latter was also used in the 2010 World Cup and 2016 Olympics. In the United States, the NCAA has its own rules for inter-collegiate competitions; high school associations similarly play to different rules, usually using the rules published by the National Federation of State High School Associations (NFHS). This article assumes FIH rules unless otherwise stated. USA Field Hockey produces an annual summary of the differences.\nIn the United States, the games at the junior high level consist of four 12-minute periods, while the high-school level consists of four 15-minute periods. Many private American schools play 12-minute quarters, and some have adopted FIH rules rather than NFHS rules.\nPlayers are required to wear mouth guards and shin guards in order to play the game. Also, there is a newer rule requiring certain types of sticks be used. In recent years, the NFHS rules have moved closer to FIH, but in 2011 a new rule requiring protective eyewear was introduced for the 2011 Fall season. Further clarification of NFHS's rule requiring protective eyewear states, \"effective 1 January 2019, all eye protection shall be permanently labeled with the current ASTM 2713 standard for field hockey\". Metal 'cage style' goggles favored by US high school lacrosse and permitted in high school field hockey is prohibited under FIH rules.\nEquipment.\nField hockey stick.\nEach player carries a hockey stick that normally measures between ; shorter or longer sticks are available. The length of the stick is based on the player's individual height: the top of the stick usually comes to the player's hip, and taller players typically have longer sticks. Goalkeepers can use either a specialised stick, or an ordinary field hockey stick. The specific goal-keeping sticks have another curve at the end of the stick, to give it more surface area to block the ball.\nSticks were traditionally made of wood, but are now often made also with fibreglass, kevlar or carbon fibre composites. Metal is forbidden from use in field hockey sticks, due to the risk of injury from sharp edges if the stick were to break. The stick has a rounded handle, has a J-shaped hook at the bottom, and is flattened on the left side (when looking down the handle with the hook facing upwards). All sticks must be right-handed; left-handed ones are prohibited.\nThere was traditionally a slight curve (called the bow, or rake) from the top to bottom of the face side of the stick and another on the 'heel' edge to the top of the handle (usually made according to the angle at which the handle part was inserted into the splice of the head part of the stick), which assisted in the positioning of the stick head in relation to the ball and made striking the ball easier and more accurate.\nThe hook at the bottom of the stick was only recently the tight curve (Indian style) that we have nowadays. The older 'English' sticks had a longer bend, making it very hard to use the stick on the reverse. For this reason players now use the tight curved sticks.\nThe handle makes up about the top third of the stick. It is wrapped in a grip similar to that used on tennis racket. The grip may be made of a variety of materials, including chamois leather, which improves grip in the wet and gives the stick a softer touch and different weighting it wrapped over a preexisting grip.\nIt was recently discovered that increasing the depth of the face bow made it easier to get high speeds from the dragflick and made the stroke easier to execute. At first, after this feature was introduced, the Hockey Rules Board placed a limit of 50\u00a0mm on the maximum depth of bow over the length of the stick but experience quickly demonstrated this to be excessive. New rules now limit this curve to under 25\u00a0mm so as to limit the power with which the ball can be flicked.\nField hockey ball.\nStandard field hockey balls are hard spherical balls, made of solid plastic (sometimes over a cork core), and are usually white, although they can be any colour as long as they contrast with the playing surface. The balls have a diameter of and a mass of . The ball is often covered with indentations to reduce aquaplaning that can cause an inconsistent ball speed on wet surfaces.\nUniforms.\nInternational Hockey Federation rules for women are written so players may choose between shorts, skorts, or skirts if they have the same design and color across the team. A previous requirement was for women to wear skirts during play.\nGoalkeeping equipment.\nThe 2007 rulebook saw major changes regarding goalkeepers. A fully equipped goalkeeper must wear a helmet, leg guards and kickers, and like all players, they must carry a stick. Goalkeepers may use either a field player's stick or a specialised goalkeeping stick provided always the stick is of legal dimensions. Usually field hockey goalkeepers also wear extensive additional protective equipment including chest guards, padded shorts, heavily padded hand protectors, groin protectors, neck protectors and arm guards. A goalie may not cross the 23\u00a0m line, the sole exception to this being if the goalkeeper is to take a penalty stroke at the other end of the field, when the clock is stopped. The goalkeeper can also remove their helmet for this action. While goalkeepers are allowed to use their feet and hands to clear the ball, like field players they may only use the one side of their stick. Slide tackling is permitted as long as it is with the intention of clearing the ball, not aimed at a player.\nIt is now also even possible for teams to have a full eleven outfield players and no goalkeeper at all. No player may wear a helmet or other goalkeeping equipment, neither will any player be able to play the ball with any other part of the body than with their stick. This may be used to offer a tactical advantage, for example, if a team is trailing with only a short time to play, or to allow for play to commence if no goalkeeper or kit is available.\nTactics.\nThe basic tactic in field hockey, as in association football and many other team games, is to outnumber the opponent in a particular area of the field at a moment in time. When in possession of the ball this temporary numerical superiority can be used to pass the ball around opponents so that they cannot effect a tackle because they cannot get within playing reach of the ball and to further use this numerical advantage to gain time and create clear space for making scoring shots on the opponent's goal. When not in possession of the ball numerical superiority is used to isolate and channel an opponent in possession and 'mark out' any passing options so that an interception or a tackle may be made to gain possession. Highly skillful players can sometimes get the better of more than one opponent and retain the ball and successfully pass or shoot but this tends to use more energy than quick early passing.\nEvery player has a role depending on their relationship to the ball if the team communicates throughout the play of the game. There will be players on the ball (offensively \u2013 ball carriers; defensively \u2013 pressure, support players, and movement players.\nThe main methods by which the ball is moved around the field by players are a) passing b) pushing the ball and running with it controlled to the front or right of the body and c) \"dribbling\"; where the player controls the ball with the stick and moves in various directions with it to elude opponents. To make a pass the ball may be propelled with a pushing stroke, where the player uses their wrists to push the stick head through the ball while the stick head is in contact with it; the \"flick\" or \"scoop\", similar to the push but with an additional arm and leg and rotational actions to lift the ball off the ground; and the \"hit\", where a swing at ball is taken and contact with it is often made very forcefully, causing the ball to be propelled at velocities in excess of . In order to produce a powerful hit, usually for travel over long distances or shooting at the goal, the stick is raised higher and swung with maximum power at the ball, a stroke sometimes known as a \"drive\".\nTackles are made by placing the stick into the path of the ball or playing the stick head or shaft directly at the ball. To increase the effectiveness of the tackle, players will often place the entire stick close to the ground horizontally, thus representing a wider barrier. To avoid the tackle, the ball carrier will either pass the ball to a teammate using any of the push, flick, or hit strokes, or attempt to maneuver or \"drag\" the ball around the tackle, trying to deceive the tackler.\nIn recent years, the penalty corner has gained importance as a goal scoring opportunity. Particularly with the technical development of the drag flick. Tactics at penalty corners to set up time for a shot with a drag flick or a hit shot at the goal involve various complex plays, including multiple passes before deflections towards the goal is made but the most common method of shooting is the direct flick or hit at the goal.\nAt the highest level, field hockey is a fast moving, highly skilled game, with players using fast moves with the stick, quick accurate passing, and hard hits, in attempts to keep possession and move the ball towards the goal. Tackling with physical contact and otherwise physically obstructing players is not permitted. Some of the tactics used resemble football (soccer), but with greater ball speed.\nWith the 2009 changes to the rules regarding free hits in the attacking 23\u00a0m area, the common tactic of hitting the ball hard into the circle was forbidden. Although at higher levels this was considered tactically risky and low-percentage at creating scoring opportunities, it was used with some effect to 'win' penalty corners by forcing the ball onto a defender's foot or to deflect high (and dangerously) off a defender's stick. The FIH felt it was a dangerous practice that could easily lead to raised deflections and injuries in the circle, which is often crowded at a free-hit situation, and outlawed it.\nInternational competition.\nThe biggest two field hockey tournaments are the Olympic Games tournament, and the Hockey World Cup, which is also held every four years. Apart from this, there is the men's and women's Pro League held each year for the nine top-ranked teams.\nOf the men's teams, Pakistan has won the Hockey World Cup four times, more times than any other side. India has won the Hockey at the Summer Olympics eight times, including in six successive Olympiads. \nOf the female teams, the Netherlands has won the Hockey World cup the most times, with six titles. At the Olympics, Australia and the Netherlands have both won three Olympic tournaments.\nIndia and Pakistan dominated men's hockey until the early 1980s, winning eight Olympic golds and three of the first five world cups, respectively, but have become less prominent with the ascendancy of Belgium, the Netherlands, Germany, New Zealand, Australia, and Spain since the late 1980s, as grass playing surfaces were replaced with artificial turf. Other notable men's nations include Argentina, England (who combine with other British \"Home Nations\" to form the Great Britain side at Olympic events) and South Korea.\nThe Netherlands, Australia and Argentina are the most successful national teams among women. The Netherlands was the predominant women's team before field hockey was added to Olympic events. In the early 1990s, Australia emerged as the strongest women's country, though retirement of a number of players has weakened the team somewhat. Argentina improved its play in the 2000s, heading IFH rankings in 2003, 2010 and 2013. Other prominent women's teams are Germany, Great Britain, China, South Korea and India. Four nations have won Olympic gold medals in both men's and women's hockey: Germany, Netherlands, Australia and Great Britain.\n the Australian men's team and the Dutch women's teams lead the FIH world rankings.\nFor a couple of years, Belgium has emerged as a leading nation, with a World Champions title (2018), a European Champions title (2019), a silver medal (2016) followed with a title (2021) at the Olympics, and a lead in the FIH men's team world ranking.\nThis is a list of the major international field hockey tournaments, in chronological order. Tournaments included are:\nDefunct tournaments:\nOther international tournaments include:\nVariants.\nIndoor field hockey.\nA popular variant of field hockey is indoor hockey, which is 6-a-side (5-a-side during 2014\u20132015) using a field which is reduced to approximately . Although many of the rules remain the same, including obstruction and feet, there are several key variations: players may not raise the ball unless shooting at goal, players may not hit the ball, instead using pushes to transfer it, and the sidelines are replaced with solid barriers, from which the ball will rebound and remain in play. In addition, the regulation guidelines for the indoor field hockey stick require a slightly thinner, lighter stick than an outdoor one.\nHockey5s.\nAs the name suggests, Hockey5s is a hockey variant which features five players on each team (including a goalkeeper). The field of play is 55\u00a0m long and 41.70\u00a0m wide\u2014this is approximately half the size of a regular pitch. Few additional markings are needed as there is no penalty circle nor penalty corners; shots can be taken from anywhere on the pitch. Penalty strokes are replaced by a \"challenge\" which is like the one-on-one method used in a penalty shoot-out. The duration of the match is three 12-minute periods with an interval of two minutes between periods; golden goal periods are multiple 5-minute periods. The rules are simpler and it is intended that the game is faster, creating more shots on goal with less play in midfield, and more attractive to spectators.\nAn Asian qualification tournament for two places at the 2014 Youth Olympic Games was the first time an FIH event used the Hockey5s format. Hockey5s was also used for the Pacific Games in 2015 and at the African Youth Games in 2018.\nIn 2022, the FIH staged its first senior international Hockey5s event, with a men's and women's event being held in Lausanne. The FIH Men's Hockey5s World Cup and FIH Women's Hockey5s World Cup are set to debut in 2024.\nReferences.\nNOTE: Many of the sources here are suspect and may be unreliable. indicates a reference has been reviewed and is approved. All ticks will be removed when the article reconstruction is complete."}
{"id": "10887", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=10887", "title": "Finagle's law", "text": "Finagle's law of dynamic negatives (also known as Melody's law, Sod's Law or Finagle's corollary to Murphy's law) is usually rendered as \"Anything that can go wrong, will\u2014at the worst possible moment.\"\nThe term \"Finagle's law\" was first used by John W. Campbell Jr., the influential editor of \"Astounding Science Fiction\" (later \"Analog\"). He used it frequently in his editorials for many years in the 1940s to 1960s, but it never came into general usage the way Murphy's law has.\nVariants.\nOne variant (known as O'Toole's corollary of Finagle's law) favored among hackers is a takeoff on the second law of thermodynamics (related to the augmentation of entropy):\nIn the \"\" episode \"Amok Time\" (written by Theodore Sturgeon in 1967), Captain Kirk tells Spock, \"As one of Finagle's laws puts it: 'Any home port the ship makes will be somebody else's, not mine.\nThe term \"Finagle's law\" was popularized by science fiction author Larry Niven in several stories (for example, \"Protector\" [Ballantine Books paperback edition, 4th printing, p.\u00a023]), depicting a frontier culture of asteroid miners; this \"Belter\" culture professed a religion or running joke involving the worship of the dread god Finagle and his mad prophet Murphy.\n\"Finagle's law\" can also be the related belief \"Inanimate objects are out to get us\", also known as Resistentialism.\nSimilar to Finagle's law is the verbless phrase of the German novelist Friedrich Theodor Vischer: \"\" (the perfidy of inanimate objects).\nA related concept, the \"Finagle factor\", is an \"ad hoc\" multiplicative or additive term in an equation, which can be justified only by the fact that it gives more correct results. Also known as Finagle's variable constant, it is sometimes defined as the correct answer divided by your answer.\nOne of the first records of \"Finagle factor\" is probably a December 1962 article in \"The Michigan Technic\", credited to Campbell, but bylined \"I Finaglin\" \nThe term is also used in a 1960 wildlife management article."}
{"id": "10888", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=10888", "title": "Finagles law", "text": ""}
