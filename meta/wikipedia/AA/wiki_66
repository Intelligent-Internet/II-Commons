{"id": "7502", "revid": "1272846942", "url": "https://en.wikipedia.org/wiki?curid=7502", "title": "Christianity and Judaism", "text": "Christianity began as a movement within Second Temple Judaism, but the two religions gradually diverged over the first few centuries of the Christian era. Today, differences of opinion vary between denominations in both religions, but the most important distinction is Christian acceptance and Jewish non-acceptance of Jesus as the Messiah prophesied in the Hebrew Bible and Jewish tradition. Early Christianity distinguished itself by determining that observance of halakha (Jewish law) was not necessary for non-Jewish converts to Christianity (see Pauline Christianity). Another major difference is the two religions' conceptions of God. Depending on the denomination followed, the Christian God is either believed to consist of three persons of one essence (Father, Son and Holy Spirit), with the doctrine of the incarnation of the Son in Jesus being of special importance, or like Judaism, believes in and emphasizes the Oneness of God. Judaism, however, rejects the Christian concept of God in human form. Christianity recognizes the Hebrew Bible (called the Old Testament by Christians) as part of its scriptural canon, Judaism does not recognize the Christian New Testament.\nThe relative importance of belief and practice constitute an important area of difference. Most forms of Protestant Christianity emphasize correct belief (or orthodoxy), focusing on the New Covenant as mediated through Jesus Christ, as recorded in the New Testament. Judaism places emphasis on correct conduct (or orthopraxy), focusing on the Mosaic covenant, as recorded in the Torah and Talmud. Mainstream Roman Catholicism occupies a middle position, stating that both faith and works are factors in a person's salvation. Some schools of thought within Catholicism, such as Franciscanism and liberation theology, explicitly favor orthopraxy over orthodoxy. Praxis is of central importance to Eastern Christianity as well, with Saint Maximus the Confessor going as far as to say that \"theology without action is the theology of demons.\" Christian conceptions of right practice vary (e.g., Catholic social teaching and its preferential option for the poor; the Eastern Orthodox Church's practices of fasting, hesychasm, and asceticism; the Protestant work ethic of Calvinists and others), but differ from Judaism in that they are not based on following halakha or any other interpretation of the Mosaic covenant. While more liberal Jewish denominations may not require observance of halakha, Jewish life remains centred on individual and collective participation in an eternal dialogue with God through tradition, rituals, prayers and ethical actions.\nJewish self-identification.\nJudaism's purpose is to carry out what it holds to be the covenant between God and the Jewish people. The Torah (), both written and oral, tells the story of this covenant, and provides Jews with the terms of the covenant. The Oral Torah is the primary guide for Jews to abide by these terms, as expressed in tractate Gittin 60b (\"the Holy One, Blessed be He, did not make His covenant with Israel except by virtue of the Oral Law\") to help them learn how to live a holy life, and to bring holiness, peace and love into the world and into every part of life, so that life may be elevated to a high level of kedusha, originally through study and practice of the Torah, and since the destruction of the Second Temple, through prayer as expressed in tractate Sotah 49a \"Since the destruction of the Temple, every day is more cursed than the preceding one; and the existence of the world is assured only by the kedusha...and the words spoken after the study of Torah.\"\nSince the adoption of the Amidah, the acknowledgement of God through the declaration from Isaiah 6:3 \"Kadosh [holy], kadosh, kadosh, is HaShem, Master of Legions; the whole world is filled with His glory\". as a replacement for the study of Torah, which is a daily obligation for Jews, and sanctifies God in itself. This continuous maintenance of relationship between the individual Jew and God through either study, or prayer repeated three times daily, is the confirmation of the original covenant. This allows the Jewish people as a community to strive and fulfill the prophecy \"I, the Lord, have called you in righteousness, and will hold your hand and keep you. And I will establish you as a covenant of the people, for a light unto the nations.\" (i.e., a role model) over the course of history, and a part of the divine intent of bringing about an age of peace and sanctity where ideally a faithful life and good deeds should be ends in themselves, not means (see also Jewish principles of faith).\nAccording to Christian theologian Alister McGrath, the Jewish Christians affirmed every aspect of then contemporary Second Temple Judaism with the addition of the belief that Jesus was the messiah, with Isaiah 49:6, \"an explicit parallel to 42:6\" quoted by Paul the Apostle in Acts 13:47 and reinterpreted by Justin Martyr. According to Christian writers, most notably Paul, the Bible teaches that people are, in their current state, sinful, and the New Testament reveals that Jesus is both the Son of man and the Son of God, united in the hypostatic union, God the Son, God made incarnate; that Jesus' death by crucifixion was a sacrifice to atone for all of humanity's sins, and that acceptance of Jesus as Savior and Lord saves one from Divine Judgment, giving Eternal life. Jesus is the mediator of the New Covenant. His famous Sermon on the Mount is considered by some Christian scholars to be the proclamation of the New Covenant ethics, in contrast to the Mosaic Covenant of Moses from Mount Sinai.\nBut some scholars, like Margaret Barker, propose that early Christianity has roots in First Temple Israelite religion, which is dubbed as the \"Temple Theology\". Baker's works have been criticized for engaging in parallelomania and failing to engage in the broader scholarly literature but it has gained some religious and academic support.\nSacred texts.\nThe Hebrew Bible is composed of three parts; the Torah (Instruction, the Septuagint translated the Hebrew to \"nomos\" or \"Law\"), the Nevi'im (Prophets) and the Ketuvim (Writings). Collectively, these are known as the Tanakh. According to Rabbinic Judaism the Torah was revealed by God to Moses; within it, Jews find 613 Mitzvot (commandments).\nRabbinic tradition asserts that God revealed two Torahs to Moses, one that was written down, and one that was transmitted orally. Whereas the written Torah has a fixed form, the Oral Torah is a living tradition that includes not only specific supplements to the written Torah (for instance, what is the proper manner of \"shechita\" and what is meant by \"Frontlets\" in the Shema), but also procedures for understanding and talking about the written Torah (thus, the Oral Torah revealed at Sinai includes debates among rabbis who lived long after Moses). The Oral Law elaborations of narratives in the Bible and stories about the rabbis are referred to as \"aggadah\". It also includes elaboration of the 613 commandments in the form of laws referred to as \"halakha\". Elements of the Oral Torah were committed to writing and edited by Judah HaNasi in the Mishnah in 200 CE; much more of the Oral Torah were committed to writing in the Babylonian and Jerusalem Talmuds, which were edited around 600 CE and 450 CE, respectively. The Talmuds are notable for the way they combine law and lore, for their explication of the midrashic method of interpreting texts, and for their accounts of debates among rabbis, which preserve divergent and conflicting interpretations of the Bible and legal rulings.\nSince the transcription of the Talmud, notable rabbis have compiled law codes that are generally held in high regard: the Mishneh Torah, the Tur, and the Shulchan Aruch. The latter, which was based on earlier codes and supplemented by the commentary by Moshe Isserles that notes other practices and customs practiced by Jews in different communities, especially among Ashkenazim, is generally held to be authoritative by Orthodox Jews. The Zohar, which was written in the 13th century, is generally held as the most important esoteric treatise of the Jews.\nAll contemporary Jewish movements consider the Tanakh, and the Oral Torah in the form of the Mishnah and Talmuds as sacred, although movements are divided as to claims concerning their divine revelation, and also their authority. For Jews, the Torah\u2014written and oral\u2014is the primary guide to the relationship between God and man, a living document that has unfolded and will continue to unfold whole new insights over the generations and millennia. A saying that captures this goes, \"Turn it [the Torah's words] over and over again, for everything is in it.\"\nChristians accept the Written Torah and other books of the Hebrew Bible (alternatively called Old Testament) as Scripture, although they generally give readings from the Koine Greek Septuagint translation instead of the Biblical Hebrew/Biblical Aramaic Masoretic Text. Two notable examples are:\nInstead of the traditional Jewish order and names for the books, Christians organize and name the books closer to that found in the Septuagint. Some Christian denominations (such as Anglican, Roman Catholic, and Eastern Orthodox), include a number of books that are not in the Hebrew Bible (the biblical apocrypha or deuterocanonical books or Anagignoskomena, see Development of the Old Testament canon) in their biblical canon that are not in today's Jewish canon, although they were included in the Septuagint. Christians reject the Jewish Oral Torah, which was still in oral, and therefore unwritten, form in the time of Jesus.\nCovenant theology.\nChristians believe that God has established a New Covenant with people through Jesus, as recorded in the Gospels, Acts of the Apostles, Epistles, and other books collectively called the New Testament (the word \"testament\" attributed to Tertullian is commonly interchanged with the word \"covenant\"). For some Christians, such as Roman Catholics and Orthodox Christians, this New Covenant includes authoritative sacred traditions and canon law. Others, especially Protestants, reject the authority of such traditions and instead hold to the principle of \"sola scriptura\", which accepts only the Bible itself as the final rule of faith and practice. Anglicans do not believe in \"sola scriptura\". For them scripture is the longest leg of a 3-legged stool: scripture, tradition and reason. Scripture cannot stand on its own since it must be interpreted in the light of the Church's patristic teaching and ecumenical creeds. Additionally, some denominations include the \"oral teachings of Jesus to the Apostles\", which they believe have been handed down to this day by apostolic succession.\nChristians refer to the biblical books about Jesus as the New Testament, and to the canon of Hebrew books as the Old Testament. Judaism does not accept the retronymic labeling of its sacred texts as the \"Old Testament\", and some Jews refer to the New Testament as the Christian Testament or Christian Bible. Judaism rejects all claims that the Christian New Covenant supersedes, abrogates, fulfills, or is the unfolding or consummation of the covenant expressed in the Written and Oral Torahs. Therefore, just as Christianity does not accept that Mosaic law has any authority over Christians, Judaism does not accept that the New Testament has any religious authority over Jews.\nLaw.\nMany Jews view Christians as having quite an ambivalent view of the Torah, or Mosaic law: on one hand Christians speak of it as God's absolute word, but on the other, they apply its commandments with a certain selectivity. Some Jews contend that Christians cite commandments from the Old Testament to support one point of view but then ignore other commandments of a similar class and of equal weight. Examples of this are certain commandments that God states explicitly be a \"lasting covenant.\" Some translate the Hebrew as a \"perpetual covenant.\"\nChristians explain that such selectivity is based on rulings made by early Jewish Christians in the Book of Acts, at the Council of Jerusalem, that, while believing gentiles did not need to fully convert to Judaism, they should follow some aspects of Torah like avoiding idolatry and fornication and blood. This view is also reflected by modern Judaism, in that Righteous gentiles need not convert to Judaism and need to observe only the Noahide Laws, which also contain prohibitions against idolatry and fornication and blood.\nSome Christians agree that Jews who accept Jesus should still observe all of Torah, see for example Dual-covenant theology, based on warnings by Jesus to Jews not to use him as an excuse to disregard it, and they support efforts of those such as Messianic Jews (Messianic Judaism is considered by most Christians and Jews to be a form of Christianity) to do that, but some Protestant forms of Christianity oppose all observance to the Mosaic law, even by Jews, which Luther criticised as Antinomianism.\nA minority view in Christianity, known as Christian Torah-submission, holds that the Mosaic law as it is written is binding on all followers of God under the New Covenant, even for gentiles, because it views God's commands as \"everlasting\" and \"good.\"\nConcepts of God.\nTraditionally, both Judaism and Christianity believe in the God of Abraham, Isaac and Jacob, for Jews the God of the Tanakh, for Christians the God of the Old Testament, the creator of the universe. Judaism and major sects of Christianity reject the view that God is entirely immanent and within the world as a physical presence (although Christians believe in the incarnation of God). Both religions reject the view that God is entirely transcendent, and thus separate from the world, as the pre-Christian Greek Unknown God. Both religions reject atheism on one hand and polytheism on the other.\nBoth religions agree that God shares both transcendent and immanent qualities. How these religions resolve this issue is where the religions differ. Christianity posits that God exists as a Trinity; in this view God exists as three distinct persons who share a single divine essence, or substance. In those three there is one, and in that one there are three; the one God is indivisible, while the three persons are distinct and unconfused, God the Father, God the Son, and God the Holy Spirit. It teaches that God became especially immanent in physical form through the Incarnation of God the Son who was born as Jesus of Nazareth, who is believed to be at once fully God and fully human. There are denominations self-describing as Christian who question one or more of these doctrines, however, see Nontrinitarianism. By contrast, Judaism sees God as a single entity, and views trinitarianism as both incomprehensible and a violation of the Bible's teaching that God is one. It rejects the notion that Jesus or any other object or living being could be 'God', that God could have a literal 'son' in physical form or is divisible in any way, or that God could be made to be joined to the material world in such fashion. Although Judaism provides Jews with a word to label God's transcendence (\"Ein Sof\", without end) and immanence (\"Shekhinah\", in-dwelling), these are merely human words to describe two ways of experiencing God; God is one and indivisible.\nShituf.\nA minority Jewish view maintains that while Christian worship is polytheistic (due to the multiplicity of the Trinity), it is permissible for them to swear in God's name, since they are referring to the one God. This theology is referred to in Hebrew as Shituf (literally \"partnership\" or \"association\"). Although worship of a trinity is considered to be not different from any other form of idolatry for Jews, it may be an acceptable belief for non-Jews (according to the ruling of some Rabbinic authorities).\nRight action.\nFaith versus good deeds.\nJudaism teaches that the purpose of the Torah is to teach us how to act correctly. God's existence is a given in Judaism, and not something that most authorities see as a matter of required belief. Although some authorities see the Torah as commanding Jews to believe in God, Jews see belief in God as a necessary, but not sufficient, condition for a Jewish life. The quintessential verbal expression of Judaism is the Shema Yisrael, the statement that the God of the Bible is their God, and that this God is unique and one. The quintessential physical expression of Judaism is behaving in accordance with the 613 Mitzvot (the commandments specified in the Torah), and thus live one's life in God's ways.\nThus fundamentally in Judaism, one is enjoined to bring holiness into life (with the guidance of God's laws), rather than removing oneself from life to be holy.\nMuch of Christianity also teaches that God wants people to perform good works, but all branches hold that good works alone will not lead to salvation, which is called Legalism, the exception being dual-covenant theology. Some Christian denominations hold that salvation depends upon transformational faith in Jesus, which expresses itself in good works as a testament (or witness) to ones faith for others to see (primarily Eastern Orthodox Christianity and Roman Catholicism), while others (including most Protestants) hold that faith alone is necessary for salvation. Some argue that the difference is not as great as it seems, because it really hinges on the definition of \"faith\" used. The first group generally uses the term \"faith\" to mean \"intellectual and heartfelt assent and submission\". Such a faith will not be salvific until a person has allowed it to effect a life transforming conversion (turning towards God) in their being (see Ontotheology). The Christians that hold to \"salvation by faith alone\" (also called by its Latin name \"sola fide\") define faith as being implicitly ontological\u2014mere intellectual assent is not termed \"faith\" by these groups. Faith, then, is life-transforming by definition.\nSin.\nIn both religions, offenses against the will of God are called sin. These sins can be thoughts, words, or deeds.\nCatholicism categorizes sins into various groups. A wounding of the relationship with God is often called venial sin; a complete rupture of the relationship with God is often called mortal sin. Without salvation from sin (see below), a person's separation from God is permanent, causing such a person to enter Hell in the afterlife. Both the Catholic Church and the Orthodox Church define sin more or less as a \"macula\", a spiritual stain or uncleanliness that constitutes damage to man's image and likeness of God.\nHebrew has several words for sin, each with its own specific meaning. The word \"pesha\", or \"trespass\", means a sin done out of rebelliousness. The word \"aveira\" means \"transgression\". And the word \"avone\", or \"iniquity\", means a sin done out of moral failing. The word most commonly translated simply as \"sin\", \"het\", literally means \"to go astray\". Just as Jewish law, \"halakha\" provides the proper \"way\" (or path) to live, sin involves straying from that path. Judaism teaches that humans are born with free will, and morally neutral, with both a \"yetzer hatov\", (literally, \"the good inclination\", in some views, a tendency towards goodness, in others, a tendency towards having a productive life and a tendency to be concerned with others) and a \"yetzer hara\", (literally \"the evil inclination\", in some views, a tendency towards evil, and in others, a tendency towards base or animal behavior and a tendency to be selfish). In Judaism all human beings are believed to have free will and can choose the path in life that they will take. It does not teach that choosing good is impossible\u2014only at times more difficult. There is almost always a \"way back\" if a person wills it. (Although texts mention certain categories for whom the way back will be exceedingly hard, such as the slanderer, the habitual gossip, and the malicious person)\nThe rabbis recognize a positive value to the \"yetzer hara\": one tradition identifies it with the observation on the last day of creation that God's accomplishment was \"very good\" (God's work on the preceding days was just described as \"good\") and explain that without the yetzer ha'ra there would be no marriage, children, commerce or other fruits of human labor; the implication is that yetzer ha'tov and yetzer ha'ra are best understood not as moral categories of good and evil but as selfless versus selfish orientations, either of which used rightly can serve God's will.\nIn contrast to the Jewish view of being morally balanced, Original Sin refers to the idea that the sin of Adam and Eve's disobedience (sin \"at the origin\") has passed on a spiritual heritage, so to speak. Christians teach that human beings inherit a corrupted or damaged human nature in which the tendency to do bad is greater than it would have been otherwise, so much so that human nature would not be capable now of participating in the afterlife with God. This is not a matter of being \"guilty\" of anything; each person is only personally guilty of their own actual sins. However, this understanding of original sin is what lies behind the Christian emphasis on the need for spiritual salvation from a spiritual Saviour, who can forgive and set aside sin even though humans are not inherently pure and worthy of such salvation. Paul the Apostle in Romans and I Corinthians placed special emphasis on this doctrine, and stressed that belief in Jesus would allow Christians to overcome death and attain salvation in the hereafter.\nRoman Catholics, Eastern Orthodox Christians, and some Protestants teach the Sacrament of Baptism is the means by which each person's damaged human nature is healed and sanctifying grace (capacity to enjoy and participate in the spiritual life of God) is restored. This is referred to as \"being born of water and the Spirit\", following the terminology in the Gospel of St. John. Most Protestants believe this salvific grace comes about at the moment of personal decision to follow Jesus, and that baptism is a symbol of the grace already received.\nLove.\nThe Hebrew word for \"love\", \"ahavah\" (\u05d0\u05d4\u05d1\u05d4), is used to describe intimate or romantic feelings or relationships, such as the love between parent and child in Genesis 22:2; 25: 28; 37:3; the love between close friends in I Samuel 18:2, 20:17; or the love between a young man and young woman in Song of Songs. Christians will often use the Greek of the Septuagint to make distinctions between the types of love: \"philia\" for brotherly, \"eros\" for romantic and \"agape\" for self-sacrificing love.\nLike many Jewish scholars and theologians, literary critic Harold Bloom understands Judaism as fundamentally a religion of love. But he argues that one can understand the Hebrew conception of love only by looking at one of the core commandments of Judaism, Leviticus 19:18, \"Love your neighbor as yourself\", also called the second Great Commandment. Talmudic sages Hillel and Rabbi Akiva commented that this is a major element of the Jewish religion. Also, this commandment is arguably at the center of the Jewish faith. As the third book of the Torah, Leviticus is literally the central book. Historically, Jews have considered it of central importance: traditionally, children began their study of the Torah with Leviticus, and the midrashic literature on Leviticus is among the longest and most detailed of midrashic literature. Bernard Jacob Bamberger considers Leviticus 19, beginning with God's commandment in verse 3\u2014\"You shall be holy, for I the Lord your God, am holy\"\u2014to be \"the climactic chapter of the book, the one most often read and quoted\" (1981:889). Leviticus 19:18 is itself the climax of this chapter.\nAbortion.\nThe only statements in the Tanakh about the status of a fetus state that killing an unborn infant does not have the same status as killing a born human being, and mandates a much lesser penalty. (Although this interpretation is disputed, the passage could refer to an injury to a woman that causes a premature, live birth).\nThe Talmud states that the fetus is not yet a full human being until it has been born (either the head or the body is mostly outside of the woman), therefore killing a fetus is not murder, and abortion\u2014in restricted circumstances\u2014has always been legal under Jewish law. Rashi, the great 12th century commentator on the Bible and Talmud, states clearly of the fetus \"lav nefesh hu\": \"it is not a person\". The Talmud contains the expression \"ubar yerech imo\"\u2014the fetus is as the thigh of its mother,' i.e., the fetus is deemed to be part and parcel of the pregnant woman's body.\" The Babylonian Talmud Yevamot 69b states that: \"the embryo is considered to be mere water until the fortieth day.\" Afterwards, it is considered subhuman until it is born. Christians who agree with these views may refer to this idea as abortion before the quickening of the fetus.\nJudaism unilaterally supports, in fact mandates, abortion if doctors believe that it is necessary to save the life of the woman. Many rabbinic authorities allow abortions on the grounds of gross genetic imperfections of the fetus. They also allow abortion if the woman were suicidal because of such defects. However, Judaism holds that abortion is impermissible for family planning or convenience reasons. Each case must be decided individually, however, and the decision should lie with the pregnant woman, the man who impregnated her, and their Rabbi.\nWar, violence and pacifism.\nJews and Christians accept as valid and binding many of the same moral principles taught in the Torah. There is a great deal of overlap between the ethical systems of these two faiths. Nonetheless, there are some highly significant doctrinal differences.\nJudaism has many teachings about peace and compromise, and its teachings make physical violence the last possible option. Nonetheless, the Talmud teaches that \"If someone comes with the intention to murder you, then one is obligated to kill in self-defense [rather than be killed]\". The clear implication is that to bare one's throat would be tantamount to suicide (which Jewish law forbids) and it would also be considered helping a murderer kill someone and thus would \"place an obstacle in front of a blind man\" (i.e., makes it easier for another person to falter in their ways). The tension between the laws dealing with peace, and the obligation to self-defense, has led to a set of Jewish teachings that have been described as tactical-pacifism. This is the avoidance of force and violence whenever possible, but the use of force when necessary to save the lives of one's self and one's people.\nAlthough killing oneself is forbidden under normal Jewish law as being a denial of God's goodness in the world, under extreme circumstances when there has seemed no choice but to either be killed or forced to betray their religion, Jews have committed suicide or mass suicide (see Masada, First French persecution of the Jews, and York Castle for examples). As a grim reminder of those times, there is even a prayer in the Jewish liturgy for \"when the knife is at the throat\", for those dying \"to sanctify God's Name\". These acts have received mixed responses by Jewish authorities. Where some Jews regard them as examples of heroic martyrdom, but others saying that while Jews should always be willing to face martyrdom if necessary, it was wrong for them to take their own lives.\nBecause Judaism focuses on this life, many questions to do with survival and conflict (such as the classic moral dilemma of two people in a desert with only enough water for one to survive) were analysed in great depth by the rabbis within the Talmud, in the attempt to understand the principles a godly person should draw upon in such a circumstance.\nThe Sermon on the Mount records that Jesus taught that if someone comes to harm you, then one must turn the other cheek. This has led four Protestant Christian denominations to develop a theology of pacifism, the avoidance of force and violence at all times. They are known historically as the \"peace churches\", and have incorporated Christ's teachings on nonviolence into their theology so as to apply it to participation in the use of violent force; those denominations are the Quakers, Mennonites, Amish, and the Church of the Brethren. Many other churches have people who hold to the doctrine without making it a part of their doctrines, or who apply it to individuals but not to governments, see also Evangelical counsels. The vast majority of Christian nations and groups have not adopted this theology, nor have they followed it in practice. See also But to bring a sword.\nCapital punishment.\nAlthough the Hebrew Bible has many references to capital punishment, the Jewish sages used their authority to make it nearly impossible for a Jewish court to impose a death sentence. Even when such a sentence might have been imposed, the Cities of Refuge and other sanctuaries, were at hand for those unintentionally guilty of capital offences. It was said in the Talmud about the death penalty in Judaism, that if a court killed more than one person in seventy years, it was a barbarous (or \"bloody\") court and should be condemned as such.\nChristianity usually reserved the death penalty for heresy, the denial of the orthodox view of God's view, and witchcraft or similar non-Christian practices. For example, in Spain, unrepentant Jews were exiled, and it was only those crypto-Jews who had accepted baptism under pressure but retained Jewish customs in private, who were punished in this way. It is presently acknowledged by most of Christianity that these uses of capital punishment were deeply immoral.\nTaboo food and drink.\nOrthodox Jews, unlike most Christians, still practice a restrictive diet that has many rules. Most Christians believe that the kosher food laws have been superseded. For example, they cite what Jesus taught in Mark 7: what you eat doesn't make you unclean but what comes out of a man's heart makes him unclean\u2014although Roman Catholicism and Eastern Orthodoxy have their own set of dietary observances. Eastern Orthodoxy, in particular has very elaborate and strict rules of fasting, and continues to observe the Council of Jerusalem's apostolic decree of Act 15.\nSome Christian denominations observe some biblical food laws, for example, the practice of Ital in Rastafari. Jehovah's Witnesses do not eat blood products and are known for their refusal to accept blood transfusions based on not \"eating blood\".\nSalvation.\nJudaism does not see human beings as inherently flawed or sinful and needful of being saved from it, but rather capable with a free will of being righteous, and unlike Christianity does not closely associate ideas of \"salvation\" with a New Covenant delivered by a Jewish messiah, although in Judaism Jewish people will have a renewed national commitment of observing God's commandments under the New Covenant, and the Jewish Messiah will also be ruling at a time of global peace and acceptance of God by all people.\nJudaism holds instead that proper living is accomplished through good works and heartfelt prayer, as well as a strong faith in God. Judaism also teaches that gentiles can receive a share in \"the world to come\". This is codified in the Mishna Avot 4:29, the Babylonian Talmud in tractates Avodah Zarah 10b, and Ketubot 111b, and in Maimonides's 12th century law code, the \"Mishneh Torah\", in \"Hilkhot Melachim\" (Laws of Kings) 8.11.\nThe Protestant view is that every human is a sinner, and being saved by God's grace, not simply by the merit of one's own actions, pardons a damnatory sentence to Hell.\nForgiveness.\nIn Judaism, one must go \"to those he has harmed\" to be entitled to forgiveness. This means that in Judaism a person cannot obtain forgiveness from God for wrongs the person has done to other people. This also means that, unless the victim forgave the perpetrator before he died, murder is unforgivable in Judaism, and they will answer to God for it, though the victims' family and friends can forgive the murderer for the grief they caused them.\nThus the \"reward\" for forgiving others is not God's forgiveness for wrongs done to others, but rather help \"in obtaining forgiveness from the other person\".\nSir Jonathan Sacks, Chief Rabbi of the United Hebrew Congregations of the Commonwealth, summarized: \"it is not that God forgives, while human beings do not. To the contrary, we believe that just as only God can forgive sins against God, so only human beings can forgive sins against human beings.\"\nJudgment.\nBoth Christianity and Judaism believe in some form of judgment. Most Christians (the exception is Full Preterism) believe in the future Second Coming of Jesus, which includes the Resurrection of the Dead and the Last Judgment. Those who have accepted Jesus as their personal saviour will be saved and live in God's presence in the Kingdom of Heaven, those who have not accepted Jesus as their saviour, will be cast into the Lake of fire (eternal torment, finite torment, or simply annihilated), see for example The Sheep and the Goats.\nIn Jewish liturgy there is significant prayer and talk of a \"book of life\" that one is written into, indicating that God judges each person each year even after death. This annual judgment process begins on Rosh Hashanah and ends with Yom Kippur. Additionally, God sits daily in judgment concerning a person's daily activities. Upon the anticipated arrival of the Messiah, God will judge the nations for their persecution of Israel during the exile. Later, God will also judge the Jews over their observance of the Torah.\nHeaven and Hell.\nThere is little Jewish literature on heaven or hell as actual places, and there are few references to the afterlife in the Hebrew Bible. One is the ghostly apparition of Samuel, called up by the Witch of Endor at King Saul's command. Another is a mention by the Prophet Daniel of those who sleep in the earth rising to either everlasting life or everlasting abhorrence.\nEarly Hebrew views were more concerned with the fate of the nation of Israel as a whole, rather than with individual immortality. A stronger belief in an afterlife for each person developed during the Second Temple period but was contested by various Jewish sects. Pharisees believed that in death, people rest in their graves until they are physically resurrected with the coming of the Messiah, and within that resurrected body the soul would exist eternally. Maimonides also included the concept of resurrection in his Thirteen Principles of Faith.\nJudaism's view is summed up by a biblical observation about the Torah: in the beginning God clothes the naked (Adam), and at the end God buries the dead (Moses). The Children of Israel mourned for 40\u00a0days, then got on with their lives.\nIn Judaism, Heaven is sometimes described as a place where God debates Talmudic law with the angels, and where Jews spend eternity studying the Written and Oral Torah. Jews do not believe in \"Hell\" as a place of eternal torment. Gehenna is a place or condition of purgatory where Jews spend up to twelve months purifying to get into heaven, depending on how sinful they have been, although some suggest that certain types of sinners can never be purified enough to go to heaven and rather than facing eternal torment, simply cease to exist. Therefore, some violations like suicide would be punished by separation from the community, such as not being buried in a Jewish cemetery (in practice, rabbis often rule suicides to be mentally incompetent and thus not responsible for their actions). Judaism also does not have a notion of hell as a place ruled by Satan since God's dominion is total and Satan is only one of God's angels.\nCatholics also believe in a purgatory for those who are going to heaven, but Christians in general believe that Hell is a fiery place of torment that never ceases, called the Lake of Fire. A small minority believe this is not permanent, and that those who go there will eventually either be saved or cease to exist. Heaven for Christians is depicted in various ways. As the Kingdom of God described in the New Testament and particularly the Book of Revelation, Heaven is a new or restored earth, a World to Come, free of sin and death, with a New Jerusalem led by God, Jesus, and the most righteous of believers starting with 144,000 Israelites from every tribe, and all others who received salvation living peacefully and making pilgrimages to give glory to the city.\nIn Christianity, promises of Heaven and Hell as rewards and punishments are often used to motivate good and bad behavior, as threats of disaster were used by prophets like Jeremiah to motivate the Israelites. Modern Judaism generally rejects this form of motivation, instead teaching to do the right thing because it's the right thing to do. As Maimonides wrote:\n\"A man should not say: I shall carry out the precepts of the Torah and study her wisdom in order to receive all the blessings written therein or in order to merit the life of the World to Come and I shall keep away from the sins forbidden by the Torah in order to be spared the curses mentioned in the Torah or in order not to be cut off from the life of the World to Come. It is not proper to serve God in this fashion. For one who serves thus serves out of fear. Such a way is not that of the prophets and sages. Only the ignorant, and the women and children serve God in this way. These are trained to serve out of fear until they obtain sufficient knowledge to serve out of love. One who serves God out of love studies the Torah and practices the precepts and walks in the way of wisdom for no ulterior motive at all, neither out of fear of evil nor in order to acquire the good, but follows the truth because it is true and the good will follow the merit of attaining to it. It is the stage of Abraham our father whom the Holy One, blessed be God, called \"My friend\" (Isaiah 41:8 \u2013 \"ohavi\" = the one who loves me) because he served out of love alone. It is regarding this stage that the Holy One, Blessed be God, commanded us through Moses, as it is said: \"You shall love the Lord your God\" (Deuteronomy 6:5). When man loves God with a love that is fitting he automatically carries out all the precepts of love.\nThe Messiah.\nJews believe that a descendant of King David will one day appear to restore the Kingdom of Israel and usher in an era of peace, prosperity, and spiritual understanding for Israel and all the nations of the world. Jews refer to this person as Moshiach or \"anointed one\", translated as messiah in English. The traditional Jewish understanding of the messiah is that he is fully human and born of human parents without any supernatural element. The messiah is expected to have a relationship with God similar to that of the prophets of the Tanakh. In his commentary on the Talmud, Maimonides (Rabbi Moshe ben Maimon) wrote:\nHe adds:\nHe also clarified the nature of the Messiah:\nThe Christian view of Jesus as Messiah goes beyond such claims and is the fulfillment and union of three anointed offices; a prophet like Moses who delivers God's commands and covenant and frees people from bondage, a High Priest in the order of Melchizedek overshadowing the Levite priesthood and a king like King David ruling over Jews, and like God ruling over the whole world and coming from the line of David.\nFor Christians, Jesus is also fully human and fully divine as the Word of God who sacrifices himself so that humans can receive salvation. Jesus sits in Heaven at the Right Hand of God and will judge humanity in the end times when he returns to earth.\nChristian readings of the Hebrew Bible find many references to Jesus. This can take the form of specific prophesy, and in other cases of foreshadowing by types or forerunners. Traditionally, most Christian readings of the Bible maintained that almost every prophecy was actually about the coming of Jesus, and that the entire Old Testament of the Bible is a prophecy about the coming of Jesus.\nCatholic views.\nCatholicism teaches \"Extra Ecclesiam Nulla Salus\" (\"Outside the Church there is no salvation\"), which some, like Fr. Leonard Feeney, interpreted as limiting salvation to Catholics only. At the same time, it does not deny the possibility that those not visibly members of the Church may attain salvation as well. In recent times, its teaching has been most notably expressed in the Vatican II council documents \"Unitatis Redintegratio\" (1964), \"Lumen gentium\" (1964), \"Nostra aetate\" (1965), an encyclical issued by Pope John Paul II: \"Ut unum sint\" (1995), and in a document issued by the Congregation for the Doctrine of the Faith, \"Dominus Iesus\" in 2000. The latter document has been criticised for claiming that non-Christians are in a \"gravely deficient situation\" as compared to Catholics, but also adds that \"for those who are not formally and visibly members of the Church, salvation in Christ is accessible by virtue of a grace which, while having a mysterious relationship to the Church, does not make them formally part of the Church, but enlightens them in a way which is accommodated to their spiritual and material situation.\"\nPope John Paul II on 2 October 2000 emphasized that this document did not say that non-Christians were actively denied salvation: \"...this confession does not deny salvation to non-Christians, but points to its ultimate source in Christ, in whom man and God are united\". On 6 December the Pope issued a statement to further emphasize that the Church continued to support its traditional stance that salvation was available to believers of other faiths: \"The gospel teaches us that those who live in accordance with the Beatitudes\u2014the poor in spirit, the pure of heart, those who bear lovingly the sufferings of life\u2014will enter God's kingdom.\" He further added, \"All who seek God with a sincere heart, including those who do not know Christ and his church, contribute under the influence of Grace to the building of this Kingdom.\" On 13 August 2002 American Catholic bishops issued a joint statement with leaders of Reform and Conservative Judaism, called \"Reflections on Covenant and Mission\", which affirmed that Christians should not target Jews for conversion. The document stated: \"Jews already dwell in a saving covenant with God\" and \"Jews are also called by God to prepare the world for God's Kingdom.\" However, many Christian denominations still believe it is their duty to reach out to \"unbelieving\" Jews.\nIn December 2015, the Vatican released a 10,000-word document that, among other things, stated that Jews do not need to be converted to find salvation, and that Catholics should work with Jews to fight antisemitism.\nEastern Orthodox views.\nEastern Orthodox Christianity emphasizes a continuing life of repentance or \"metanoia\", which includes an increasing improvement in thought, belief and action. Regarding the salvation of Jews, Muslims, and other non-Christians, the Orthodox have traditionally taught that there is no salvation outside the church. Orthodoxy recognizes that other religions may contain truth, to the extent that they are in agreement with Christianity.\nGod is thought to be good, just, and merciful; it would not seem just to condemn someone because they never heard the Gospel message, or were taught a distorted version of the Gospel by heretics. Therefore, the reasoning goes, they must at some point have an opportunity to make a genuine informed decision. Ultimately, those who persist in rejecting God condemn themselves, by cutting themselves off from the ultimate source of all Life, and from the God who is Love embodied. Jews, Muslims, and members of other faiths, then, are expected to convert to Christianity in the afterlife.\nProselytizing.\nJudaism is not a proselytizing religion. Orthodox Judaism deliberately makes it very difficult to convert and become a Jew, and requires a significant and full-time effort in living, study, righteousness, and conduct over several years. The final decision is by no means a foregone conclusion. A person cannot become Jewish by marrying a Jew, or by joining a synagogue, nor by any degree of involvement in the community or religion, but only by explicitly undertaking intense, formal, and supervised work over years aimed towards that goal. Some less strict versions of Judaism have made this process somewhat easier but it is still far from common.\nIn the past, scholars understood Judaism to have an evangelistic drive, but today's scholars are inclined to the view that it was often more akin just to \"greater openness to converts\" rather than active soliciting of conversions. Since Jews believe that one need not be a Jew to approach God, there is no religious pressure to convert non-Jews to their faith. Indeed, Scholars have revisited the traditional claims about Jewish proselytizing and have brought forward a variety of new insights. McKnight and Goodman have argued persuasively that a distinction ought to be made between the passive reception of converts or interested Pagans, and an active desire or intent to convert the non-Jewish world to Judaism.\nThe Chabad-Lubavitch branch of Hasidic Judaism has been an exception to this non-proselytizing standard, since in recent decades it has been actively promoting Noahide Laws for gentiles as an alternative to Christianity.\nBy contrast, Christianity is an explicitly evangelistic religion. Christians are commanded by Jesus to \"Therefore, go and make disciples of all nations\". Historically, evangelism has on rare occasions led to forced conversion under threat of death or mass expulsion.\nMutual views.\nCommon Jewish views of Christianity.\nMany Jews view Jesus as one in a long list of failed Jewish claimants to be the Messiah, none of whom fulfilled the tests of a prophet specified in the Law of Moses. Others see Jesus as a teacher who worked with the gentiles and ascribe the messianic claims that Jews find objectionable to his later followers. Because much physical and spiritual violence was done to Jews in the name of Jesus and his followers, and because evangelism is still an active aspect of many churches' activities, many Jews are uncomfortable with discussing Jesus and treat him as a non-person. In answering the question \"What do Jews think of Jesus\", philosopher Milton Steinberg claims, for Jews, Jesus cannot be accepted as anything more than a teacher. \"In only a few respects did Jesus deviate from the Tradition,\" Steinberg concludes, \"and in all of them, Jews believe, he blundered.\"\nJudaism does not believe that God requires the sacrifice of any human. This is emphasized in Jewish traditions concerning the story of the Akedah, the binding of Isaac. In the Jewish explanation, this is a story in the Torah whereby God wanted to test Abraham's faith and willingness, and Isaac was never going to be actually sacrificed. Thus, Judaism rejects the notion that anyone can or should die for anyone else's sin. Judaism is more focused on the practicalities of understanding how one may live a sacred life in the world according to God's will, rather than a hope of a future one. Judaism does not believe in the Christian concept of hell but does have a punishment stage in the afterlife (i.e. Gehenna, a term that also appears in the New Testament and translated as hell) as well as a Heaven (Gan Eden), but the religion does not intend it as a focus.\nJudaism views the worship of Jesus as inherently polytheistic, and rejects the Christian attempts to explain the Trinity as a complex monotheism. Christian festivals have no religious significance in Judaism and are not celebrated, but some secular Jews in the West treat Christmas as a secular holiday.\nCommon Christian views of Judaism.\nChristians believe that Christianity is the fulfillment and successor of Judaism, retaining much of its doctrine and many of its practices including monotheism, the belief in a Messiah, and certain forms of worship like prayer and reading from religious texts. Christians believe that Judaism requires blood sacrifice to atone for sins, and believe that Judaism has abandoned this since the destruction of the Second Temple. Most Christians consider the Mosaic Law to have been a necessary intermediate stage, but that once the crucifixion of Jesus occurred, adherence to civil and ceremonial Law was superseded by the New Covenant.\nSome Christians adhere to New Covenant theology, which states that with the arrival of his New Covenant, Jews have ceased being blessed under his Mosaic covenant. This position has been softened or disputed by other Christians, where Jews are recognized to have a special status under the Abrahamic covenant. New Covenant theology is thus in contrast to Dual-covenant theology.\nSome Christians who view the Jewish people as close to God seek to understand and incorporate elements of Jewish understanding or perspective into their beliefs as a means to respect their \"parent\" religion of Judaism, or to more fully seek out and return to their Christian roots. Christians embracing aspects of Judaism are sometimes criticized as Biblical Judaizers by Christians when they pressure gentile Christians to observe Mosaic teachings rejected by most modern Christians.\nCommonwealth Theology (CT) asserts that Judeo-Christian tensions were exacerbated in the fall of Jerusalem and by the subsequent Jewish Revolt. As a result, early Christian theologies formulated in the Roman capitals of Rome and Constantinople began to include antisemitic attitudes, which have been carried forward and embraced by the Protestant Reformers. Dispensation Theology, formalized in the 1830s by John Darby, holds that \"God has not rejected His people whom He foreknew.\" Dispensationalism, however, maintains that God's special dealings with Israel have been interrupted by the Church Age. Commonwealth Theology, on the other hand, recognizes the continuity of God's \"congregation in the wilderness\" as presently consisting of the Jews (house of Judah) and the Nations (Gentiles), among whom are abiding the historically scattered Northern Kingdom (house of Israel). Commonwealth Theology views the Jews as already included in Commonwealth of Israel even while in unbelief, but nevertheless unsaved in their unbelieving state. CT recognizes that both the reconciliation of the Jewish house and the reconciliation of the estranged house of Israel (among the Gentiles) was accomplished by the cross; and that the salvation of \"All Israel\" is a process that began on the Day of Pentecost. The full realization of the \"one new man\" created through the peace (between the Jews and \"you Gentiles\") made by his cross will take place in Ezekiel's two sticks made one, when both houses of Israel will be united under the Kingdom of David.\nJewish Christians.\nSome scholars have found evidence of continuous interactions between Jewish-Christian and rabbinic movements from the mid- to late second century CE to the fourth century CE. Of particular importance is the figure of James the brother of Jesus, the leader of the Christian Church in Jerusalem until he was killed in the year 62, who was known for his righteous behavior as a Jew, and set the terms of the relationship between Jewish Christians and Gentile Christians in dialogue with Paul. To him is attributed a letter which emphasizes the view that faith must be expressed in works. The neglect of this mediating figure has often damaged Christian-Jewish relations. Modern scholarship is engaged in an ongoing debate over which term should be used as the proper designation for Jesus' first followers. Many scholars believe that the term Jewish Christians is anachronistic given the fact that there is no consensus on the date of the birth of Christianity. The very concepts of Christianity and Judaism can be seen as essentializing, since these are changing and plural traditions. Clearly, the first Christians would not have believed that they were exchanging one religion for another, because they believed that the resurrection of Jesus was the fulfillment of Jewish prophecies, and they believed that the mission to the gentiles which was initiated by Saul (Paul of Tarsus) was a secondary activity. Some modern scholars have suggested that the designations \"Jewish believers in Jesus\" and \"Jewish followers of Jesus\" better reflect the original context.\nInter-faith relationship.\nIn addition to Christianity and Judaism's varying views on each other as religions, there has also been a long and often painful history of conflict, persecution and at times, tolerance, reconciliation, between the two religions, which have influenced their mutual views of their relationship with each other over time. Since the end of the Second World War and The Holocaust, Christianity has embarked on a process of introspection with regard to its Jewish roots and its attitudes toward Judaism. The eradication of the anti-Jewish tendencies is but one dimension of this ongoing Christian introspection, that attempts to engage a variety of legacies that disturb modern believers (Antisemitism, slavery, racial and ethnic prejudice, colonialism, sexism, homophobia and religious persecution).\nSince the Middle Ages, the Catholic Church upheld (Formal Statement on the Jews), which stated \nPersecution, forcible conversion, and forcible displacement of Jews (i.e. hate crimes) occurred for many centuries, along with occasional gestures at reconciliation which also occurred from time to time. Pogroms were a common occurrence throughout Christian Europe, including organized violence, restrictions on land ownership and professional lives, forcible relocation and ghettoization, mandatory dress codes, and at times, humiliating actions and torture. All of these actions and restrictions had major effects on Jewish cultures. From the fifth century onward, Church councils imposed ever-increasing burdens and limitations on the Jews. Among the decrees:\nBy the end of the first millennium, the Jewish population in the Christian lands had been decimated, expelled, forced into conversion or worse. Only a few small and scattered communities survived.\nThere have also been non-coercive outreach and missionary efforts such as the Church of England's Ministry Among Jewish People, founded in 1809.\nFor Martin Buber, Judaism and Christianity were variations on the same theme of messianism. Buber made this theme the basis of a famous definition of the tension between Judaism and Christianity:\nPre-messianically, our destinies are divided. Now to the Christian, the Jew is the incomprehensibly obdurate man who declines to see what has happened; and to the Jew, the Christian is the incomprehensibly daring man who affirms in an unredeemed world that its redemption has been accomplished. This is a gulf which no human power can bridge.\nThe Nazi Party was known for its persecution of Christian Churches; many of them, such as the Protestant Confessing Church and the Catholic Church, as well as Quakers and Jehovah's Witnesses, aided and rescued Jews who were being targeted by the r\u00e9gime.\nFollowing the Holocaust, attempts have been made to construct a new Jewish-Christian relationship of mutual respect for differences, through the inauguration of the interfaith body the Council of Christians and Jews in 1942 and International Council of Christians and Jews. The Seelisberg Conference in 1947 established 10 points relating to the sources of Christian antisemitism. The ICCJ's \"Twelve points of Berlin\" sixty years later aim to reflect a recommitment to interreligious dialogue between the two communities.\nPope Paul VI wrote that \"the Jewish people, who still retain the religion of the Old Testament, ... are indeed worthy of our respect and love\". Pope John Paul II and the Catholic Church have \"upheld the Church's acceptance of the continuing and permanent election of the Jewish people\" as well as a reaffirmation of the covenant between God and the Jews. In December 2015, the Vatican released a 10,000-word document which, among other things, stated that Catholics should work with Jews to fight antisemitism.\nOrthodox Rabbinic Statement on Christianity.\nIn 2012, the book \"Kosher Jesus\" by Orthodox Rabbi Shmuley Boteach was published. In it, he takes the position that Jesus was a wise and learned Torah-observant Jewish rabbi. Boteach says he was a beloved member of the Jewish community. At the same time, Jesus is said to have despised the Romans for their cruelty, and fought them courageously. The book states that the Jews had nothing whatsoever to do with the murder of Jesus, but rather that blame for his trial and killing lies with the Romans and Pontius Pilate. Boteach states clearly that he does not believe in Jesus as the Jewish Messiah. At the same time, Boteach argues that \"Jews have much to learn from Jesus - and from Christianity as a whole - without accepting Jesus' divinity. There are many reasons for accepting Jesus as a man of great wisdom, beautiful ethical teachings, and profound Jewish patriotism.\" He concludes by writing, as to Judeo-Christian values, that \"the hyphen between Jewish and Christian values is Jesus himself.\"\nOn 3 December 2015, the Center for Jewish-Christian Understanding and Cooperation (CJCUC) spearheaded a petition of Orthodox rabbis from around the world calling for increased partnership between Jews and Christians.\nThe unprecedented Orthodox Rabbinic Statement on Christianity, entitled \"To Do the Will of Our Father in Heaven: Toward a Partnership between Jews and Christians\", was initially signed by over 25 prominent Orthodox rabbis in Israel, the United States, and Europe, and as of 2016 had over 60 signatories.\nBetween Jerusalem and Rome.\nOn 31 August 2017, representatives of the Conference of European Rabbis, the Rabbinical Council of America, and the Commission of the Chief Rabbinate of Israel issued and presented the Holy See with a statement entitled \"Between Jerusalem and Rome\". The document pays particular tribute to the Second Vatican Council's Declaration \"Nostra Aetate\", whose fourth chapter represents the \"Magna Carta\" of the Holy See's dialogue with the Jewish world. The Statement \"Between Jerusalem and Rome\" does not hide the theological differences that exist between the two faith traditions while all the same it expresses a firm resolve to collaborate more closely, now and in the future."}
{"id": "7504", "revid": "4390761", "url": "https://en.wikipedia.org/wiki?curid=7504", "title": "Cesare Borgia", "text": "Cesare Borgia (13 September 1475 \u2013 12 March 1507) was a Roman Catholic deacon\u2014cardinal and later an Italian \"condottiero\" (mercenary). He was the illegitimate son of Pope Alexander VI of the Aragonese House of Borgia and was a sibling to Lucrezia Borgia.\nAfter initially entering the Church and becoming a cardinal on his father's election to the papacy, he resigned his diaconal profession after the death of his brother in 1498. He was employed as a \"condottiero\" for King Louis XII of France around 1500, and occupied both Milan and Naples during the Italian Wars. At the same time, he carved out a state for himself in Central Italy, but he was unable to retain power for long after his father's death. His quest for political power was a major inspiration for \"The Prince\" by the renowned Florentine historian, Niccol\u00f2 Machiavelli.\nEarly life.\nLike many aspects of Cesare Borgia's life, the date of his birth is a subject of dispute. He was born in Subiaco in Lazio, Italy in either 1475 or 1476, the illegitimate son of Cardinal Roderic Llan\u00e7ol i de Borja, usually known as \"Rodrigo Borgia\", later Pope Alexander VI, and his Italian mistress Vannozza dei Cattanei, about whom information is sparse. The Borgia family originally came from the Kingdom of Valencia, and rose to prominence during the mid-15th century. Cesare's great-uncle Alphonso Borgia (1378\u20131458), bishop of Valencia, was elected Pope Callixtus III in 1455. Cesare's father, Pope Alexander VI, was the first pope who openly recognized his children born out of wedlock.\nThe Italian historian Stefano Infessura writes that Cardinal Borgia falsely claimed Cesare to be the legitimate son of another man\u2014Domenico d'Arignano, the nominal husband of Vannozza dei Cattanei. More likely, Pope Sixtus IV granted Cesare a release from the necessity of proving his birth in a papal bull of 1 October 1480.\nCareer.\nDiaconate.\nCesare was initially groomed for a career in the Roman Catholic Church. Following school in Perugia and Pisa, Cesare studied law at the \"Studium Urbis\" (today as the Sapienza University of Rome). He was made Bishop of Archdiocese of Pamplona and Tudela (aged 15) and Archbishop of Valencia (aged 17). In 1493, he had also been appointed bishop of both Castres and Elne. In 1494, he also received the title of abbot of the abbey of Saint-Michel-de-Cuxa. Along with his father's elevation to Pope, Cesare was made Cardinal at the age of 18.\nAlexander VI staked the hopes of the Borgia family on Cesare's brother Giovanni, who was made captain-general of the military forces of the papacy. Giovanni was assassinated in 1497 under mysterious circumstances. Several contemporaries suggested that Cesare might have been his killer, as Giovanni's disappearance could finally open to him a long-awaited military career and also solve the jealousy over Sancha of Aragon, wife of Cesare's younger brother, Gioffre, and mistress of both Cesare and Giovanni. Cesare's role in the act has never been clear. However, he had no definitive motive, as he was likely to be given a powerful secular position, whether or not his brother lived. It is possible that Giovanni was killed as a result of a sexual liaison.\nOn 17 August 1498, Cesare resigned from the cardinalate, in order to pursue a military career. On the same day, Louis XII of France named Cesare Duke of Valentinois. This random title was selected as being homophonous with his nickname \"Il Valentino\" (\"The Valencian\"), derived from his father's papal epithet in Latin \"Valentinus\" (\"The Valencian\") indicating his birth in X\u00e0tiva in the Kingdom of Valencia under the Crown of Aragon, and along with Cesare's former position as Cardinal of Valencia. On 6 September 1499, he was released from all ecclesiastical duties and laicised from his diaconal orders (because he only was ordained deacon on 26 March 1494 and never received other major orders as priesthood and bishop consecration).\nMilitary.\nCesare's career was founded upon his father's ability to distribute patronage, along with his alliance with France (reinforced by his marriage with Charlotte d'Albret, sister of John III of Navarre), in the course of the Italian Wars. Louis XII invaded Italy in 1499; after Gian Giacomo Trivulzio had ousted its duke Ludovico Sforza, Cesare accompanied the king in his entrance into Milan.\nAt this point, Alexander decided to profit from the favourable situation and carve out for Cesare a state of his own in northern Italy. To this end, he declared that all his vicars in Romagna and Marche were deposed. Though in theory subject directly to the pope, these rulers had been practically independent or dependent on other states for generations. In the view of the citizens, these vicars were cruel and petty. When Cesare eventually took power, he was viewed by the citizens as a great improvement.\nCesare was appointed commander of the papal armies with a number of Italian mercenaries, supported by 300 cavalry and 4,000 Swiss infantry sent by the king of France. Alexander sent him to capture Imola and Forl\u00ec, ruled by Caterina Sforza (mother of the Medici \"condottiero\" Giovanni dalle Bande Nere). Despite being deprived of his French troops after the conquest of those two cities, Borgia returned to Rome to celebrate a triumph and to receive the title of Papal Gonfalonier from his father. In 1500 the creation of twelve new cardinals granted Alexander enough money for Cesare to hire the \"condottieri,\" Vitellozzo Vitelli, Gian Paolo Baglioni, Giulio and Paolo Orsini, and Oliverotto Euffreducci, who resumed his campaign in Romagna.\nGiovanni Sforza, first husband of Cesare's sister Lucrezia, was soon ousted from Pesaro; Pandolfo Malatesta lost Rimini; Faenza surrendered, its young lord Astorre III Manfredi being later drowned in the Tiber by Cesare's order. In May 1501 the latter was created duke of Romagna. Hired by Florence, Cesare subsequently added the lordship of Piombino to his new lands.\nWhile his \"condottieri\" took over the siege of Piombino which ended in 1502, Cesare commanded the French troops in the sieges of Naples and Capua, defended by Prospero and Fabrizio Colonna. On 24 June 1501, Borgia's troops stormed the latter to end the siege of Capua.\nIn June 1502, he set out for Marche, where he was able to capture Urbino and Camerino by treason. He planned to conquer Bologna next. However, his \"condottieri\", most notably Vitellozzo Vitelli and the Orsini brothers (Giulio, Paolo and Francesco), feared Cesare's cruelty and set up a plot against him. Guidobaldo da Montefeltro and Giovanni Maria da Varano returned to Urbino and Camerino, and Fossombrone revolted. The fact that his subjects had enjoyed his rule thus far meant that his opponents had to work much harder than they would have liked. He eventually recalled his loyal generals to Imola, where he waited for his opponents' loose alliance to collapse. Cesare called for a reconciliation, but imprisoned his \"condottieri\" in Senigallia, then called Sinigaglia, a feat described as a \"wonderful deceiving\" by historian Paolo Giovio, and had them strangled. In 1503 he conquered the Republic of San Marino.\nLater years and death.\nAlthough he was an immensely capable general and statesman, Cesare had trouble maintaining his domain without continued papal patronage. Niccol\u00f2 Machiavelli cites Cesare's dependence on the goodwill of the papacy, under the control of his father, as being the principal disadvantage of his rule. Machiavelli argued that, had Cesare been able to win the favour of the new Pope, he would have been a very successful ruler. The news of his father's death in 1503 arrived when Cesare was planning the conquest of Tuscany. While he was convalescing in Castel Sant'Angelo from an attack of malarial fever (likely contracted on the same occasion when Alexander contracted his fatal illness), his troops controlled the September 1503 papal conclave.\nThe new pope, Pope Pius III, supported Cesare Borgia and reconfirmed him as Gonfaloniere, but after a brief pontificate of twenty-six days, he died. Borgia's deadly enemy, Giuliano Della Rovere, then succeeded by dexterous diplomacy in tricking the weakened Cesare Borgia into supporting him by offering him money and continued papal backing for Borgia policies in the Romagna; promises which he disregarded upon his election as Pope Julius II by the near-unanimous vote of the cardinals in the October 1503 papal conclave. Realizing his mistake by then, Cesare tried to correct the situation in his favour, but Pope Julius II made sure of its failure at every turn. Cesare was for example forced by Julius to give up San Marino, after occupying the republic for six months.\nCesare Borgia, who was facing the hostility of Ferdinand II of Aragon, was betrayed while in Naples by Gonzalo Fern\u00e1ndez de C\u00f3rdoba, a man he had considered his ally, and imprisoned there, while his lands were retaken by the papacy. In 1504 he was transferred to Spain and imprisoned first in the Castle of Chinchilla de Montearag\u00f3n in La Mancha, but after an attempted escape he was moved north to the Castle of La Mota, Medina del Campo, near Segovia. He did manage to escape from the Castle of La Mota with assistance, and after running across Santander, Durango and Gipuzkoa, he arrived in Pamplona on 3 December 1506, and was much welcomed by King John III of Navarre, who was missing an experienced military commander, ahead of the feared Castilian invasion.\nBorgia recaptured Viana, Navarre, which had been in the hands of forces loyal to Louis de Beaumont, the count of Ler\u00edn and Ferdinand II of Aragon's conspiratorial ally in Navarre, but not the castle, which he then besieged. In the early morning of 11 March 1507, an enemy party of knights fled from the castle during a heavy storm. Outraged at the ineffectiveness of the siege, Borgia chased them, only to find himself on his own. The party of knights, discovering that he was alone, trapped him in an ambush, where he received a fatal injury from a spear. He was then stripped of all his luxurious garments, valuables, and a leather mask covering half his face (disfigured, possibly by syphilis, during his late years). Borgia was left lying naked, with just a red tile covering his genitals.\nMortal remains.\nBorgia was originally buried in a marbled mausoleum King John III had ordered built at the altar of the Church of Santa Mar\u00eda in Viana in Navarre in northern Spain, set on one of the stops on the Camino de Santiago. In the 16th century the Bishop of Mondo\u00f1edo, Antonio de Guevara, published from memory what he had seen written on the tomb when he had paid a visit to the church. This epitaph underwent several changes in wording and meter throughout the years and the version most commonly cited today is that published by the priest and historian Francisco de Ales\u00f3n in the 18th century. It reads:\nBorgia was an old enemy of Ferdinand of Aragon, and he was fighting the count who paved the way for Ferdinand's 1512 invasion against John III and Catherine of Navarre. While the circumstances are not well known, the tomb was destroyed sometime between 1523 and 1608, during which time Santa Mar\u00eda was undergoing renovation and expansion. Tradition goes that a Bishop of Calahorra considered it inappropriate to have the remains of \"that degenerate\" lying in the church, so the opportunity was taken to tear down the monument and expel Borgia's bones to where they were reburied under the street in front of the church to be trodden on by all who walked through the town.\nVicente Blasco Ib\u00e1\u00f1ez, in \"A los pies de Venus\", writes that the then Bishop of Santa Mar\u00eda had Borgia expelled from the church because his own father had died after being imprisoned under Alexander VI. It was held for many years that the bones were lost, although in fact local tradition continued to mark their place quite accurately and folklore sprung up around Borgia's death and ghost. The bones were in fact dug up twice and reburied once by historians (both local and international\u2014the first dig in 1886 involved the French historian Charles Yriarte, who also published works on the Borgias) seeking the resting place of the infamous Cesare Borgia. After Borgia was unearthed for the second time in 1945 his bones were taken for a rather lengthy forensic examination by Victoriano Juaristi, a surgeon by trade and Borgia aficionado, and the tests concurred with the preliminary ones carried out in the 19th century. There was evidence that the bones belonged to Borgia.\nCesare Borgia's remains then were sent to Viana's town hall, directly across from Santa Mar\u00eda, where they remained until 1953. They were then reburied immediately outside of the Church of Santa Mar\u00eda, no longer under the street and in direct danger of being stepped on. A memorial stone was placed over it which, translated into English, declared Borgia the \"Generalissimo\" of the papal as well as the Navarrese forces. A movement was made in the late 1980s to have Borgia dug up once more and put back into Santa Mar\u00eda, but this proposal was ultimately rejected by church officials due to a recent ruling against the interment of anyone who did not hold the title of pope or cardinal.\nSince Borgia had renounced the cardinalate it was decided that it would be inappropriate for his bones to be moved into the church. It was reported that Fernando Sebasti\u00e1n Aguilar, the Archbishop of Pamplona, would acquiesce after more than 50 years of petitions and Borgia would finally be moved back inside the church on 11 March 2007, the day before the 500th anniversary of his death, but an Archbishopric spokesman declared that the church doesn't authorize any such practice. The local church said that \"we have nothing against the transfer of his remains. Whatever he may have done in life, he deserves to be forgiven now.\"\nAccording to Niccolo Machiavelli.\n Niccol\u00f2 Machiavelli met the Duke on a diplomatic mission in his function as Secretary of the Florentine Chancellery. Machiavelli was at Borgia's court from 7 October 1502 through 18 January 1503. During this time he wrote regular dispatches to his superiors in Florence, many of which have survived and are published in \"Machiavelli's Collected Works\". In \"The Prince\", Machiavelli uses Borgia as an example to elucidate the dangers of acquiring a principality by virtue of another. Although Cesare Borgia's father gave him the power to set up, Cesare ruled the Romagna with skill and tact for the most part. However, when his father died, and a rival to the Borgia family entered the Papal seat, Cesare was overthrown in a matter of months.\nMachiavelli attributes two episodes to Cesare Borgia: the method by which the Romagna was pacified, which Machiavelli describes in chapter VII of \"The Prince\", and the assassination of his captains on New Year's Eve of 1502 in Senigallia.\nMachiavelli's use of Borgia is subject to controversy. Some scholars see Machiavelli's Borgia as the precursor of state crimes in the 20th century. Others, including Macaulay and Lord Acton, have historicized Machiavelli's Borgia, explaining the admiration for such violence as an effect of the general criminality and corruption of the time.\nLeonardo da Vinci.\nCesare Borgia briefly employed the artisan Leonardo da Vinci as a military architect and engineer between 1502 and 1503. Cesare provided Leonardo with an unlimited pass to inspect and direct all ongoing and planned construction in his domain. While in Romagna, Leonardo built the canal from Cesena to the Porto Cesenatico.\nBefore meeting Cesare, Leonardo had worked at the Milanese court of Ludovico Sforza for many years, until Louis XII of France drove Sforza out of Italy. After Cesare, Leonardo was unsuccessful in finding another patron in Italy. King Francis I of France was able to convince Leonardo to enter his service, and the last three years of Leonardo's life were spent working in France.\nPersonal life.\nOn 10 May 1499, Cesare married Charlotte of Albret (1480 \u2013 11 March 1514), a sister of King John III of Navarre. The arrangement was part of a plan by the Navarrese monarchs to ease tensions with the newly proclaimed French King Louis XII by offering a royal blood bride in his dealings with the Holy See. They were parents to a daughter, Louise Borgia (1500\u20131553).\nCesare was also the father to at least 11 illegitimate children. Among them are Girolamo Borgia who married Isabella Contessa di Carpi and Camilla Lucrezia Borgia (the younger) who, after Cesare's death, was moved to Ferrara to the court of her aunt Lucrezia Borgia (the elder).\nThere are accounts recorded by Machiavelli during his time spent with Cesare Borgia during his diplomatic trips. Machiavelli found that he could be at times secretive and taciturn, at other times loquacious and boastful. He alternated bursts of demonic activity when he stayed up all night receiving and dispatching messengers, with moments of unaccountable sloth when he remained in bed refusing to see anyone. He was quick to take offence and rather remote from his immediate entourage, yet he was very open with his subjects, loving to join local sports and cutting a dashing figure. However, at other times, Machiavelli observed Cesare as having \"inexhaustible\" energy and an unrelenting genius in military matters, and also diplomatic affairs, and he would go days and nights on end without seemingly requiring sleep.\nReferences.\nSources"}
{"id": "7505", "revid": "126715", "url": "https://en.wikipedia.org/wiki?curid=7505", "title": "Cellular telephone", "text": ""}
{"id": "7507", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=7507", "title": "Chronicle", "text": "A chronicle (, from Greek \"chronik\u00e1\", from , \"chr\u00f3nos\" \u2013 \"time\") is a historical account of events arranged in chronological order, as in a timeline. Typically, equal weight is given for historically important events and local events, the purpose being the recording of events that occurred, seen from the perspective of the chronicler. A chronicle which traces world history is a universal chronicle. This is in contrast to a narrative or history, in which an author chooses events to interpret and analyze and excludes those the author does not consider important or relevant.\nThe information sources for chronicles vary. Some are written from the chronicler's direct knowledge, others from witnesses or participants in events, still others are accounts passed down from generation to generation by oral tradition. Some used written material, such as charters, letters, and earlier chronicles. Still others are tales of unknown origin that have mythical status. Copyists also changed chronicles in creative copying, making corrections or in updating or continuing a chronicle with information not available to the original chronicler. Determining the reliability of particular chronicles is important to historians.\nMany newspapers and other periodical literature have adopted \"chronicle\" as part of their name. \nSubgroups.\nScholars categorize the genre of chronicle into two subgroups: live chronicles, and dead chronicles. A \"dead\" chronicle is one where the author assembles a list of events up to the time of their writing, but does not record further events as they occur. A \"live\" chronicle is where one or more authors add to a chronicle in a regular fashion, recording contemporary events shortly after they occur. Because of the immediacy of the information, historians tend to value live chronicles, such as annals, over dead ones.\nThe term often refers to a book written by a chronicler in the Middle Ages describing historical events in a country, or the lives of a nobleman or a clergyman, although it is also applied to a record of public events. The earliest medieval chronicle to combine both retrospective (\"dead\") and contemporary (\"live\") entries, is the Chronicle of Ireland, which spans the years 431 to 911.\nChronicles are the predecessors of modern \"time lines\" rather than analytical histories. They represent accounts, in prose or verse, of local or distant events over a considerable period of time, both the lifetime of the individual chronicler and often those of several subsequent continuators. If the chronicles deal with events year by year, they are often called annals. Unlike the modern historian, most chroniclers tended to take their information as they found it, and made little attempt to separate fact from legend. The point of view of most chroniclers is highly localised, to the extent that many anonymous chroniclers can be sited in individual abbeys.\nIt is impossible to say how many chronicles exist, as the many ambiguities in the definition of the genre make it impossible to draw clear distinctions of what should or should not be included. However, the \"Encyclopedia of the Medieval Chronicle\" lists some 2,500 items written between 300 and 1500 AD.\nCitation of entries.\nEntries in chronicles are often cited using the abbreviation \"s.a.\", meaning \"sub anno\" (under the year), according to the year under which they are listed. For example, \"\"ASC\" MS A, s.a. 855\" means the entry for the year 855 in manuscript A of the \"Anglo-Saxon Chronicle\". The same event may be recorded under a different year in another manuscript of the chronicle, and may be cited for example as \"\"ASC\" MS D, s.a. 857\".\nEnglish chronicles.\nThe most important English chronicles are the \"Anglo-Saxon Chronicle\", started under the patronage of King Alfred in the 9th century and continued until the 12th century, and the \"Chronicles of England, Scotland and Ireland\" (1577\u201387) by Raphael Holinshed and other writers; the latter documents were important sources of materials for Elizabethan drama. Later 16th century Scottish chronicles, written after the Reformation, shape history according to Catholic or Protestant viewpoints.\nCronista.\nA cronista is a term for a historical chronicler, a role that held historical significance in the European Middle Ages. Until the European Enlightenment, the occupation was largely equivalent to that of a historian, describing events chronologically that were of note in a given country or region. As such, it was often an official governmental position rather than an independent practice. The appointment of the official chronicler often favored individuals who had distinguished themselves by their efforts to study, investigate and disseminate population-related issues. The position was granted on a local level based on the mutual agreements of a city council in plenary meetings. Often, the occupation was honorary, unpaid, and stationed for life. In modern usage, the term usually refers to a type of journalist who writes chronicles as a form of journalism or non-professional historical documentation.\nCronista in the Middle Ages.\nBefore the development of modern journalism and the systematization of chronicles as a journalistic genre, cronista were tasked with narrating chronological events considered worthy of remembrance that were recorded year by year. Unlike writers who created epic poems regarding living figures, cronista recorded historical events in the lives of individuals in an ostensibly truthful and reality-oriented way. \nEven from the time of early Christian historiography, cronistas were clearly expected to place human history in the context of a linear progression, starting with the creation of man until the second coming of Christ, as prophesied in biblical texts.\nLists of chronicles.\nRhymed chronicles.\nRhymed or poetic chronicles, as opposed to prosaic chronicles, include:"}
{"id": "7512", "revid": "1431158", "url": "https://en.wikipedia.org/wiki?curid=7512", "title": "Concentration", "text": "In chemistry, concentration is the abundance of a constituent divided by the total volume of a mixture. Several types of mathematical description can be distinguished: \"mass concentration\", \"molar concentration\", \"number concentration\", and \"volume concentration\". The concentration can refer to any kind of chemical mixture, but most frequently refers to solutes and solvents in solutions. The molar (amount) concentration has variants, such as normal concentration and osmotic concentration. Dilution is reduction of concentration, e.g. by adding solvent to a solution. The verb means to increase concentration, the opposite of dilute.\nEtymology.\n\"Concentration-\", \"concentratio\", action or an act of coming together at a single place, bringing to a common center, was used in post-classical Latin in 1550 or earlier, similar terms attested in Italian (1589), Spanish (1589), English (1606), French (1632).\nQualitative description.\nOften in informal, non-technical language, concentration is described in a qualitative way, through the use of adjectives such as \"dilute\" for solutions of relatively low concentration and \"concentrated\" for solutions of relatively high concentration. To concentrate a solution, one must add more solute (for example, alcohol), or reduce the amount of solvent (for example, water). By contrast, to dilute a solution, one must add more solvent, or reduce the amount of solute. Unless two substances are miscible, there exists a concentration at which no further solute will dissolve in a solution. At this point, the solution is said to be saturated. If additional solute is added to a saturated solution, it will not dissolve, except in certain circumstances, when supersaturation may occur. Instead, phase separation will occur, leading to coexisting phases, either completely separated or mixed as a suspension. The point of saturation depends on many variables, such as ambient temperature and the precise chemical nature of the solvent and solute.\nConcentrations are often called levels, reflecting the mental schema of levels on the vertical axis of a graph, which can be high or low (for example, \"high serum levels of bilirubin\" are concentrations of bilirubin in the blood serum that are greater than normal).\nQuantitative notation.\nThere are four quantities that describe concentration:\nMass concentration.\nThe mass concentration formula_1 is defined as the mass of a constituent formula_2 divided by the volume of the mixture formula_3:\nThe SI unit is kg/m3 (equal to g/L).\nMolar concentration.\nThe molar concentration formula_5 is defined as the amount of a constituent formula_6 (in moles) divided by the volume of the mixture formula_3:\nThe SI unit is mol/m3. However, more commonly the unit mol/L (= mol/dm3) is used.\nNumber concentration.\nThe number concentration formula_9 is defined as the number of entities of a constituent formula_10 in a mixture divided by the volume of the mixture formula_3:\nThe SI unit is 1/m3.\nVolume concentration.\nThe volume concentration formula_13 (not to be confused with volume fraction) is defined as the volume of a constituent formula_14 divided by the volume of the mixture formula_3:\nBeing dimensionless, it is expressed as a number, e.g., 0.18 or 18%.\nThere seems to be no standard notation in the English literature. The letter formula_13 used here is normative in German literature (see ).\nRelated quantities.\nSeveral other quantities can be used to describe the composition of a mixture. These should not be called concentrations.\nNormality.\nNormality is defined as the molar concentration formula_5 divided by an equivalence factor formula_19. Since the definition of the equivalence factor depends on context (which reaction is being studied), the International Union of Pure and Applied Chemistry and National Institute of Standards and Technology discourage the use of normality.\nMolality.\nThe molality of a solution formula_20 is defined as the amount of a constituent formula_6 (in moles) divided by the mass of the solvent formula_22 (not the mass of the solution):\nThe SI unit for molality is mol/kg.\nMole fraction.\nThe mole fraction formula_24 is defined as the amount of a constituent formula_6 (in moles) divided by the total amount of all constituents in a mixture formula_26:\nThe SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole fractions.\nMole ratio.\nThe mole ratio formula_28 is defined as the amount of a constituent formula_6 divided by the total amount of all \"other\" constituents in a mixture:\nIf formula_6 is much smaller than formula_26, the mole ratio is almost identical to the mole fraction.\nThe SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole ratios.\nMass fraction.\nThe mass fraction formula_33 is the fraction of one substance with mass formula_2 to the mass of the total mixture formula_35, defined as:\nThe SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass fractions.\nMass ratio.\nThe mass ratio formula_37 is defined as the mass of a constituent formula_2 divided by the total mass of all \"other\" constituents in a mixture:\nIf formula_2 is much smaller than formula_35, the mass ratio is almost identical to the mass fraction.\nThe SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass ratios.\nDependence on volume and temperature.\nConcentration depends on the variation of the volume of the solution with temperature, due mainly to thermal expansion."}
{"id": "7514", "revid": "4967956", "url": "https://en.wikipedia.org/wiki?curid=7514", "title": "Christine Lavin", "text": "Christine Lavin (born January 2, 1952) is a New York City\u2013based singer-songwriter and promoter of contemporary folk music. She has recorded numerous solo albums, and has also recorded under the name Four Bitchin' Babes with three bandmates. She is known for her sense of humor, which is expressed in both her music and her onstage performances. Many of her songs alternate between comedy and emotional reflections on romance.\nLavin worked at Caffe Lena in Saratoga Springs, New York, until Dave Van Ronk convinced her to move to New York City and make a career as a singer-songwriter. She followed his advice and accepted his offer of guitar lessons. She was the original host of \"Sunday Breakfast\" on WFUV in New York City and a founding member of the Four Bitchin' Babes when they were formed in 1990.\nShe is a lifelong astrophysics hobbyist and has included those themes in her music."}
{"id": "7515", "revid": "16583778", "url": "https://en.wikipedia.org/wiki?curid=7515", "title": "Cutter Expansive Classification", "text": "The Cutter Expansive Classification system is a library classification system devised by Charles Ammi Cutter. The system was the basis for the top categories of the Library of Congress Classification.\nHistory of the Expansive Classification.\nCharles Ammi Cutter (1837\u20131903), inspired by the decimal classification of his contemporary Melvil Dewey, and with Dewey's initial encouragement, developed his own classification scheme for the Winchester, Massachusetts town library and then the Boston Athenaeum, at which he served as librarian for twenty-four years. He began work on it around the year 1880, publishing an overview of the new system in 1882. The same classification would later be used, but with a different notation, also devised by Cutter, at the Cary Library in Lexington, Massachusetts.\nMany libraries found this system too detailed and complex for their needs, and Cutter received many requests from librarians at small libraries who wanted the classification adapted for their collections. While numbers and letters are required in large library classifications, small libraries did not need their classification system to be too specific. He devised the Expansive Classification in response, to meet the needs of growing libraries, and to address some of the complaints of his critics. Cutter completed and published an introduction and schedules for the first six classifications of his new system (\"Expansive Classification: Part I: The First Six Classifications\"), but his work on the seventh was interrupted by his death in 1903.\nThe Cutter Expansive Classification, although adopted by comparatively few libraries, has been called one of the most logical and scholarly of American classifications. Library historian Leo E. LaMontagne wrote:\nCutter produced the best classification of the nineteenth century. While his system was less \"scientific\" than that of J. P. Lesley, its other key features \u2013 notation, specificity, and versatility \u2013 make it deserving of the praise it has received.\nIts top level divisions served as a basis for the Library of Congress classification, which also took over some of its features. It did not catch on as did Dewey's system because Cutter died before it was completely finished, making no provision for the kind of development necessary as the bounds of knowledge expanded and scholarly emphases changed throughout the twentieth century.\nStructure of the Expansive Classification.\nThe Expansive Classification uses seven separate schedules, each designed to be used by libraries of different sizes. After the first, each schedule was an expansion of the previous one, and Cutter provided instructions for how a library might change from one expansion to another as it grows.\nSummary of the Expansive Classification schedules.\nFirst classification.\nThe first classification is meant for very small libraries. The first classification has only seven top-level classes, and only eight classes in total:\nFurther classifications.\nFurther expansions add more top-level classes and subdivisions. Many subclasses arranged systematically, with common divisions, such as those by geography and language, following a consistent system throughout.\nBy the fifth classification all the letters of the alphabet are in use for top-level classes. These are:\nThese schedules were not meant to be fixed, but were to be adapted to meet the needs of each library. For example, books on the English language may be put in X, and books on language in general in a subclass of X, or this can be reversed. The first option is less logical, but results in shorter marks for most English language libraries.\nConstruction of call numbers.\nMost call numbers in the Expansive Classification follow conventions offering clues to the book's subject. The first line represents the subject, the second the author (and perhaps title), the third and fourth dates of editions, indications of translations, and critical works on particular books or authors. All numbers in the Expansive Classification are (or should be) shelved as if in decimal order.\nSize of volumes is indicated by points (.), pluses (+), or slashes (/ or //).\nFor some subjects a numerical geographical subdivision follows the classification letters on the first line. The number 83 stands for the United States\u2014hence, F83 is U.S. history, G83 U.S. travel, JU83 U.S. politics, WP83 U.S. painting. Geographical numbers are often further expanded decimally to represent more specific areas, sometimes followed by a capital letter indicating a particular city.\nThe second line usually represents the author's name by a capital letter plus one or more numbers arranged decimally. This may be followed by the first letter or letters of the title in lower-case, and/or sometimes the letters a, b, c indicating other printings of the same title. When appropriate, the second line may begin with a 'form' number\u2014e.g., 1 stands for history and criticism of a subject, 2 for a bibliography, 5 for a dictionary, 6 for an atlas or maps, 7 for a periodical, 8 for a society or university publication, 9 for a collection of works by different authors.\nOn the third line a capital Y indicates a work about the author or book represented by the first two lines, and a capital E (for English\u2014other letters are used for other languages) indicates a translation into English. If both criticism and translation apply to a single title, the number expands into four lines.\nCutter numbers (Cutter codes).\nOne of the features adopted by other systems, including Library of Congress, is the Cutter number. It is an alphanumeric device to code text so that it can be arranged in alphabetical order using the fewest characters. It contains one or two initial letters and Arabic numbers, treated as a decimal. To construct a Cutter number, a cataloguer consults a Cutter table as required by the classification rules. Although Cutter numbers are mostly used for coding the names of authors, the system can be used for titles, subjects, geographic areas, and more.\nInitial letters Qa\u2013Qt are assigned Q2\u2013Q29, while entries beginning with numerals have a Cutter number A12\u2013A19, therefore sorting before the first A entry.\nSo to make the three-digit Cutter number for \"Cutter\", one would start with \"C\", then looking under \"other consonants\", find that \"u\" gives the number 8, and under \"additional letters\", \"t\" is 8, giving a Cutter number of \"C88\"."}
{"id": "7516", "revid": "1271853846", "url": "https://en.wikipedia.org/wiki?curid=7516", "title": "Cem Karaca", "text": "Muhtar Cem Karaca (5 April 1945 \u2013 8 February 2004) was a Turkish rock musician and one of the most important figures in the Anatolian rock movement. He was a graduate of Robert College. He worked with various Turkish rock bands such as Apa\u015flar, Karda\u015flar, Mo\u011follar and Dervi\u015fan. With these bands, he brought a new understanding and interpretation to Turkish rock. \nBiography.\nHe was the only child of Mehmet \u0130brahim Karaca, a theatre actor of Azerbaijani origin, and \u0130rma Felekyan, a popular opera, theatre, and movie actress of Armenian origin. His first group was called \"Dynamites\" and was a classic rock cover band. Later he joined \"Jaguars\", an Elvis Presley cover band. In 1967, he started to write his own music, joining the band \"Apa\u015flar\" (The Rowdies), his first Turkish language group. The same year, he participated in the Golden Microphone () contest, a popular music contest in which he won second place with his song \"Emrah\". In 1969, Karaca and bass-player Serhan Karabay left Apa\u015flar and started an original Anatolian group called \"Karda\u015flar\" (The Brothers).\nIn 1972, Karaca joined the group \"Mo\u011follar\" (The Mongols) and wrote one of his best-known songs, \"Namus Belas\u0131\". However, Cahit Berkay, the leader of Mo\u011follar, wanted an international reputation for his band, and he left for France to take the group to the next level. Karaca, who wanted to continue his Anatolian beat sound, left Mo\u011follar and started his own band \"Dervi\u015fan\" (Dervishes) in 1974. Karaca and Dervi\u015fan sang poetic and progressive songs.\nIn the 1970s, Turkey was dealing with political violence between supporters of the left and the right, separatist movements and the rise of Islamism. As the country fell into chaos, the government suspected Cem Karaca of involvement in rebel organisations. He was accused of treason for being a separatist thinker and a Marxist-Leninist. The Turkish government tried to portray Karaca as a man who was unknowingly writing songs to start a revolution. One politician was quoted as saying, \"Karaca is simply calling citizens to a bloody war against the state.\" \"Dervi\u015fan\" was ultimately dissolved at the end of 1977. In 1978, he founded \"Edirdahan\", an acronym for \"from Edirne to Ardahan\"; the westernmost and the easternmost provinces of Turkey. He recorded one LP with \"Edirdahan\" called \"\"Safinaz\".\nIn early 1979, Karaca left for Cologne, West Germany for business reasons. In 1980 he began singing in German with the song Nazim Hikmet - \"K\u0131z \u00c7ocu\u011fu\" (\"Little girl\"): Cem performed the German verses alternating with his best friend, manager, producer, arranger and bandleader/bass player/keyboarder/drummer, guitar player \"Ralf M\u00e4hnh\u00f6fer\" accompanying him on grand piano, solo or with the band \"Anatology\", singing the song in the Turkish language.\nTurkey continued to spin out of control with military curfews and the 1980 Turkish coup d'\u00e9tat on September 12, 1980. General Kenan Evren took over the government and temporarily banned all the nation's political parties. After the coup, many intellectuals, including writers, artists and journalists, were arrested. A warrant was issued for the arrest of Karaca by the government of Turkey.\nThe state invited Karaca back several times, but Karaca, not knowing what would happen upon his return, decided not to come back.\nWhile Karaca was in Germany his father died, but he could not return to attend the funeral. After some time, the Turkish government decided to strip Cem Karaca of his Turkish citizenship, keeping the arrest warrant active.\nSeveral years later, in 1987, the prime minister and leader of the Turkish Motherland Party, Turgut \u00d6zal, issued an amnesty for Karaca. Shortly afterwards, he returned to Turkey. His return also brought a new album with it, which released in September 12 of that year, \"Merhaba Gen\u00e7ler ve Her Zaman Gen\u00e7 Kalanlar\" (\"Hello, The Young and The Young at Heart\"\"), one of his most influential works. His return home was received cheerfully by his fans, but during his absence Karaca had lost the young audience and acquired only a few new listeners. He died of a heart attack on February 8, 2004, and was interred at Karacaahmet Cemetery in the \u00dcsk\u00fcdar district of Istanbul.\nMusical Style.\nThe apreciation towards Cem Karaca won't be easy while at the same time he is also one of the most powerful voices of the Turkish rock scene. But the music styles audiance will find him singing however will range very much, from severe mellowness chanson until powerful progressive song-based rock music. His first records were surely progressive, in a rock-sense, and Safinaz is symphonic piece comparable to a more western progressive rock albums. It remains rock music. Especially the period with Mogollar should appeal to collectors."}
{"id": "7517", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=7517", "title": "Calista Flockhart", "text": "Calista Kay Flockhart (born November 11, 1964) is an American actress. She is best known for portraying the title character on the Fox television series \"Ally McBeal\" (1997\u20132002), for which she received a Golden Globe Award in 1998 and was thrice nominated for the Primetime Emmy Award for Outstanding Lead Actress in a Comedy Series. From 2006 to 2011, she starred as Kitty Walker on the ABC drama series \"Brothers &amp; Sisters\", and between 2015 and 2021, Flockhart appeared as Cat Grant on the superhero drama \"Supergirl\". In film, she is known for roles in \"The Birdcage\" (1996), \"A Midsummer Night's Dream\" (1999), and \"Things You Can Tell Just by Looking at Her\" (2000).\nEarly life.\nFlockhart was born in Freeport, Illinois, the daughter of Kay Calista, an English teacher, and Ronald Flockhart, a Kraft Foods executive. Her parents retired to Morristown, Tennessee, where her father lived until his death and her mother continues to reside. She has one older brother, Gary. Her mother reversed her own first and middle names in naming her Calista Kay.\nFlockhart attended Mason Gross School of the Arts at Rutgers University\u2013New Brunswick. People began recognizing Flockhart's acting ability when William Esper (Mason Gross theater director and Flockhart's acting teacher) made an exception to policy by allowing Flockhart to perform on the main stage. Though this venue usually is reserved for juniors and seniors, Harold Scott insisted that Flockhart perform there in his production of William Inge's \"Picnic\". Flockhart graduated with a Bachelor of Fine Arts in theater in 1988 from Rutgers as one of the few students who successfully completed the acting course. Rutgers inducted her into the Hall of Distinguished Alumni on May 3, 2003.\nCareer.\nEarly career.\nIn spring 1989, Flockhart made her first television appearance in a minor role in an episode of \"Guiding Light\" as a babysitter. She also appeared in a one-hour afternoon special for \"\", playing a teenager battling an eating disorder. Flockhart made her professional debut on the New York stage, appearing in \"Beside Herself\" alongside Melissa Joan Hart, at the Circle Repertory Theatre. Two years later, Flockhart appeared in the television movie \"Darrow\". Though she later appeared in films \"Naked in New York\" (1993) and \"Getting In\" (1994), her first substantial speaking part in a film was in \"Quiz Show\", directed by Robert Redford.\nFlockhart debuted on Broadway in 1994, as Laura in \"The Glass Menagerie\". Flockhart received a Clarence Derwent Award for her performance. In 1995, Flockhart became acquainted with actors such as Dianne Wiest and Faye Dunaway when she appeared in the movie \"Drunks\". In 1996, Flockhart appeared as the daughter of Dianne Wiest and Gene Hackman's characters in \"The Birdcage\". Later that year, Flockhart starred in \"Jane Doe\" as a drug addict, though it was not released until 1999, over three years after filming ended. Throughout that year, she continued to work on Broadway, playing the role of Natasha in Anton Chekhov's \"Three Sisters\".\n\"Ally McBeal\".\nIn 1997, Flockhart was asked to audition for the starring role in David E. Kelley's Fox television series \"Ally McBeal\". Kelley, having heard of Flockhart, wanted her to audition for the contract part. Though she hesitated due to the necessary commitment to the show in a negotiable contract, she was swayed by the script and traveled to Los Angeles to audition for the part, which she won. She earned a Golden Globe Award for the role in 1998. Flockhart also appeared on the June 29, 1998, cover of \"Time\" magazine, placed as the newest iteration in the evolution of feminism, relating to the ongoing debate about the role depicted by her character. Flockhart starred on the show until it was canceled in 2002.\n\"Brothers &amp; Sisters\".\nFlockhart performed in a starring role as Kitty Walker, opposite Sally Field, Rachel Griffiths and Matthew Rhys, in the critically acclaimed ABC prime time series \"Brothers &amp; Sisters\", which premiered in September 2006 in the time slot after \"Desperate Housewives\". The show was cancelled in May 2011 after running for five years. Flockhart's character was significant throughout the series' first four years, but her appearances were reduced for the 2010\u20132011 season, coinciding with the departure of TV husband Rob Lowe.\nOther work.\nFlockhart played the role of Helena in \"A Midsummer Night's Dream\", a 1999 film version of Shakespeare's play. In 2000, she appeared in \"Things You Can Tell Just by Looking at Her\" and \"\", later accompanying Eve Ensler to Kenya in order to protest violence against women, particularly female genital mutilation. Flockhart also starred in the off-Broadway production of Ensler's \"The Vagina Monologues\".\nIn 2004, Flockhart appeared as Matthew Broderick's deranged girlfriend in \"The Last Shot\". In the same year, Flockhart traveled to Spain for the filming of \"Fragile\", which premiered in September 2005 at the Venice Film Festival. She was offered the role of Susan Mayer on \"Desperate Housewives\" but declined, and the role later went to Teri Hatcher.\nIn 2014, Flockhart landed a role in \"Full Circle\" second season, as mob boss Ellen. It was expected to air in 2015. This had been Flockhart's first acting role in three years, after her hiatus when \"Brothers &amp; Sisters\" ended.\nIn 2015, Flockhart was cast in the television series \"Supergirl\" as Cat Grant, a \"self-made media magnate and founder of CatCo\" and boss to Kara (Supergirl's alter ego). The series premiered on October 26, 2015, on CBS. Due to the network's wish to reduce the show's budget, it was moved to sister network The CW after its first season, along with a move to filming in Vancouver. Flockhart remained with the show (albeit as a recurring character), despite her previous aversion to working outside Los Angeles.\nIn 2022, she played the role of Martha opposite Zachary Quinto in Edward Albee's \"Who's Afraid of Virginia Woolf?\" at the Geffen Playhouse in Los Angeles. The production was directed by Gordon Greenberg and also starred Aimee Carrero and Graham Phillips.\nIn 2024, Flockhart appeared as Lee Radziwill in \"\", the second season of the anthology series \"Feud\". Regarding playing Radziwill in an interview with \"The New York Times\", Flockhart said, \u201cTruman Capote recognized that she was living in her sister\u2019s shadow... and he would say things: \u2018You\u2019re so much prettier. You\u2019re so much smarter. You\u2019re more interesting. You have better style.\u2019 She really needed to hear that. I think it made her really love Truman. He was fun, and she confided in him, like they all did.\u201d\nPersonal life.\nIn January 2001, Flockhart announced that she had adopted a baby boy.\nFlockhart is married to actor Harrison Ford, whom she first met at the Golden Globe Awards on January 20, 2002. They became engaged on Valentine's Day in 2009, and were married on June 15, 2010, in Santa Fe, New Mexico. The ceremony was presided over by New Mexico Governor Bill Richardson and New Mexico Supreme Court Chief Justice Charles W. Daniels.\nFrom 2004 to 2014, Flockhart served as the national spokeswoman for Peace Over Violence.\nExternal links.\n! colspan=\"3\" style=\"background: #DAA520;\" | Theatre World Award\n "}
{"id": "7519", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7519", "title": "Convolution", "text": "In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (formula_1 and formula_2) that produces a third function (formula_3). The term \"convolution\" refers to both the resulting function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reflected about the y-axis and shifted. The integral is evaluated for all values of shift, producing the convolution function. The choice of which function is reflected and shifted before the integral does not change the integral result (see commutativity). Graphically, it expresses how the 'shape' of one function is modified by the other.\nSome features of convolution are similar to cross-correlation: for real-valued functions, of a continuous or discrete variable, convolution differs from cross-correlation (formula_4) only in that either formula_5 or formula_6 is reflected about the y-axis in convolution; thus it is a cross-correlation of formula_7 and formula_5, or formula_9 and formula_6.\u00a0For complex-valued functions, the cross-correlation operator is the adjoint of the convolution operator.\nConvolution has applications that include probability, statistics, acoustics, spectroscopy, signal processing and image processing, geophysics, engineering, physics, computer vision and differential equations.\nThe convolution can be defined for functions on Euclidean space and other groups (as algebraic structures). For example, periodic functions, such as the discrete-time Fourier transform, can be defined on a circle and convolved by periodic convolution. (See row 18 at .) A \"discrete convolution\" can be defined for functions on the set of integers.\nGeneralizations of convolution have applications in the field of numerical analysis and numerical linear algebra, and in the design and implementation of finite impulse response filters in signal processing.\nComputing the inverse of the convolution operation is known as deconvolution.\nDefinition.\nThe convolution of formula_1 and formula_2 is written formula_13, denoting the operator with the symbol formula_14. It is defined as the integral of the product of the two functions after one is reflected about the y-axis and shifted. As such, it is a particular kind of integral transform:\nAn equivalent definition is (see commutativity):\nWhile the symbol formula_17 is used above, it need not represent the time domain. At each formula_17, the convolution formula can be described as the area under the function formula_19 weighted by the function formula_20 shifted by the amount formula_17. As formula_17 changes, the weighting function formula_23 emphasizes different parts of the input function formula_19; If formula_17 is a positive value, then formula_23 is equal to formula_20 that slides or is shifted along the formula_28-axis toward the right (toward formula_29) by the amount of formula_17, while if formula_17 is a negative value, then formula_23 is equal to formula_20 that slides or is shifted toward the left (toward formula_34) by the amount of formula_35.\nFor functions formula_1, formula_2 supported on only formula_38 (i.e., zero for negative arguments), the integration limits can be truncated, resulting in:\nFor the multi-dimensional formulation of convolution, see \"domain of definition\" (below).\nNotation.\nA common engineering notational convention is:\nwhich has to be interpreted carefully to avoid confusion. For instance, formula_41 is equivalent to formula_42, but formula_43 is in fact equivalent to formula_44.\nRelations with other transforms.\nGiven two functions formula_45 and formula_46 with bilateral Laplace transforms (two-sided Laplace transform)\nand\nrespectively, the convolution operation formula_49 can be defined as the inverse Laplace transform of the product of formula_50 and formula_51. More precisely,\nLet formula_53, then\nNote that formula_55 is the bilateral Laplace transform of formula_49. A similar derivation can be done using the unilateral Laplace transform (one-sided Laplace transform).\nThe convolution operation also describes the output (in terms of the input) of an important class of operations known as \"linear time-invariant\" (LTI). See LTI system theory for a derivation of convolution as the result of LTI constraints. In terms of the Fourier transforms of the input and output of an LTI operation, no new frequency components are created. The existing ones are only modified (amplitude and/or phase). In other words, the output transform is the pointwise product of the input transform with a third transform (known as a transfer function). See Convolution theorem for a derivation of that property of convolution. Conversely, convolution can be derived as the inverse Fourier transform of the pointwise product of two Fourier transforms.\nHistorical developments.\nOne of the earliest uses of the convolution integral appeared in D'Alembert's derivation of Taylor's theorem in \"Recherches sur diff\u00e9rents points importants du syst\u00e8me du monde,\" published in 1754.\nAlso, an expression of the type:\nis used by Sylvestre Fran\u00e7ois Lacroix on page 505 of his book entitled \"Treatise on differences and series\", which is the last of 3 volumes of the encyclopedic series: , Chez Courcier, Paris, 1797\u20131800. Soon thereafter, convolution operations appear in the works of Pierre Simon Laplace, Jean-Baptiste Joseph Fourier, Sim\u00e9on Denis Poisson, and others. The term itself did not come into wide use until the 1950s or 1960s. Prior to that it was sometimes known as \"Faltung\" (which means \"folding\" in German), \"composition product\", \"superposition integral\", and \"Carson's integral\". Yet it appears as early as 1903, though the definition is rather unfamiliar in older uses.\nThe operation:\nis a particular case of composition products considered by the Italian mathematician Vito Volterra in 1913.\nCircular convolution.\nWhen a function formula_59 is periodic, with period formula_60, then for functions, formula_1, such that formula_62 exists, the convolution is also periodic and identical to:\nwhere formula_64 is an arbitrary choice. The summation is called a periodic summation of the function formula_1.\nWhen formula_59 is a periodic summation of another function, formula_2, then formula_68 is known as a \"circular\" or \"cyclic\" convolution of formula_1 and formula_2.\nAnd if the periodic summation above is replaced by formula_71, the operation is called a \"periodic\" convolution of formula_71 and formula_59.\nDiscrete convolution.\nFor complex-valued functions formula_1 and formula_2 defined on the set formula_76 of integers, the \"discrete convolution\" of formula_1 and formula_2 is given by:\nor equivalently (see commutativity) by:\nThe convolution of two finite sequences is defined by extending the sequences to finitely supported functions on the set of integers. When the sequences are the coefficients of two polynomials, then the coefficients of the ordinary product of the two polynomials are the convolution of the original two sequences. This is known as the Cauchy product of the coefficients of the sequences.\nThus when has finite support in the set formula_81 (representing, for instance, a finite impulse response), a finite summation may be used:\nCircular discrete convolution.\nWhen a function formula_83 is periodic, with period formula_84 then for functions, formula_85 such that formula_86 exists, the convolution is also periodic and identical to:\nThe summation on formula_88 is called a periodic summation of the function formula_89\nIf formula_83 is a periodic summation of another function, formula_91 then formula_86 is known as a circular convolution of formula_1 and formula_94\nWhen the non-zero durations of both formula_1 and formula_2 are limited to the interval formula_97\u00a0 formula_86 reduces to these common forms:\nThe notation formula_99 for \"cyclic convolution\" denotes convolution over the cyclic group of integers modulo.\nCircular convolution arises most often in the context of fast convolution with a fast Fourier transform (FFT) algorithm.\nFast convolution algorithms.\nIn many situations, discrete convolutions can be converted to circular convolutions so that fast transforms with a convolution property can be used to implement the computation. For example, convolution of digit sequences is the kernel operation in multiplication of multi-digit numbers, which can therefore be efficiently implemented with transform techniques (; ).\n requires arithmetic operations per output value and operations for outputs. That can be significantly reduced with any of several fast algorithms. Digital signal processing and other applications typically use fast convolution algorithms to reduce the cost of the convolution to O( log ) complexity.\nThe most common fast convolution algorithms use fast Fourier transform (FFT) algorithms via the circular convolution theorem. Specifically, the circular convolution of two finite-length sequences is found by taking an FFT of each sequence, multiplying pointwise, and then performing an inverse FFT. Convolutions of the type defined above are then efficiently implemented using that technique in conjunction with zero-extension and/or discarding portions of the output. Other fast convolution algorithms, such as the Sch\u00f6nhage\u2013Strassen algorithm or the Mersenne transform, use fast Fourier transforms in other rings. The Winograd method is used as an alternative to the FFT. It significantly speeds up 1D, 2D, and 3D convolution.\nIf one sequence is much longer than the other, zero-extension of the shorter sequence and fast circular convolution is not the most computationally efficient method available. Instead, decomposing the longer sequence into blocks and convolving each block allows for faster algorithms such as the overlap\u2013save method and overlap\u2013add method. A hybrid convolution method that combines block and FIR algorithms allows for a zero input-output latency that is useful for real-time convolution computations.\nDomain of definition.\nThe convolution of two complex-valued functions on is itself a complex-valued function on , defined by:\nand is well-defined only if and decay sufficiently rapidly at infinity in order for the integral to exist. Conditions for the existence of the convolution may be tricky, since a blow-up in at infinity can be easily offset by sufficiently rapid decay in . The question of existence thus may involve different conditions on and :\nCompactly supported functions.\nIf and are compactly supported continuous functions, then their convolution exists, and is also compactly supported and continuous . More generally, if either function (say ) is compactly supported and the other is locally integrable, then the convolution is well-defined and continuous.\nConvolution of and is also well defined when both functions are locally square integrable on and supported on an interval of the form (or both supported on ).\nIntegrable functions.\nThe convolution of and exists if and are both Lebesgue integrable functions in (), and in this case is also integrable . This is a consequence of Tonelli's theorem. This is also true for functions in , under the discrete convolution, or more generally for the convolution on any group.\nLikewise, if ()\u00a0 and \u00a0()\u00a0 where ,\u00a0 then \u00a0(),\u00a0 and\nIn the particular case , this shows that is a Banach algebra under the convolution (and equality of the two sides holds if and are non-negative almost everywhere).\nMore generally, Young's inequality implies that the convolution is a continuous bilinear map between suitable spaces. Specifically, if satisfy:\nthen\nso that the convolution is a continuous bilinear mapping from to .\nThe Young inequality for convolution is also true in other contexts (circle group, convolution on ). The preceding inequality is not sharp on the real line: when , there exists a constant such that:\nThe optimal value of was discovered in 1975 and independently in 1976, see Brascamp\u2013Lieb inequality.\nA stronger estimate is true provided :\nwhere formula_106 is the weak norm. Convolution also defines a bilinear continuous map formula_107 for formula_108, owing to the weak Young inequality:\nFunctions of rapid decay.\nIn addition to compactly supported functions and integrable functions, functions that have sufficiently rapid decay at infinity can also be convolved. An important feature of the convolution is that if \"f\" and \"g\" both decay rapidly, then \"f\"\u2217\"g\" also decays rapidly. In particular, if \"f\" and \"g\" are rapidly decreasing functions, then so is the convolution \"f\"\u2217\"g\". Combined with the fact that convolution commutes with differentiation (see #Properties), it follows that the class of Schwartz functions is closed under convolution .\nDistributions.\nIf \"f\" is a smooth function that is compactly supported and \"g\" is a distribution, then \"f\"\u2217\"g\" is a smooth function defined by\nMore generally, it is possible to extend the definition of the convolution in a unique way with formula_111 the same as \"f\" above, so that the associative law\nremains valid in the case where \"f\" is a distribution, and \"g\" a compactly supported distribution .\nMeasures.\nThe convolution of any two Borel measures \"\u03bc\" and \"\u03bd\" of bounded variation is the measure formula_113 defined by \nIn particular,\nwhere formula_116 is a measurable set and formula_117 is the indicator function of formula_118.\nThis agrees with the convolution defined above when \u03bc and \u03bd are regarded as distributions, as well as the convolution of L1 functions when \u03bc and \u03bd are absolutely continuous with respect to the Lebesgue measure.\nThe convolution of measures also satisfies the following version of Young's inequality\nwhere the norm is the total variation of a measure. Because the space of measures of bounded variation is a Banach space, convolution of measures can be treated with standard methods of functional analysis that may not apply for the convolution of distributions.\nProperties.\nAlgebraic properties.\nThe convolution defines a product on the linear space of integrable functions. This product satisfies the following algebraic properties, which formally mean that the space of integrable functions with the product given by convolution is a commutative associative algebra without identity . Other linear spaces of functions, such as the space of continuous functions of compact support, are closed under the convolution, and so also form commutative associative algebras.\nProof (using convolution theorem):\nformula_132\nformula_133\nformula_134\nIntegration.\nIf \"f\" and \"g\" are integrable functions, then the integral of their convolution on the whole space is simply obtained as the product of their integrals:\nThis follows from Fubini's theorem. The same result holds if \"f\" and \"g\" are only assumed to be nonnegative measurable functions, by Tonelli's theorem.\nDifferentiation.\nIn the one-variable case,\nwhere formula_142 is the derivative. More generally, in the case of functions of several variables, an analogous formula holds with the partial derivative:\nA particular consequence of this is that the convolution can be viewed as a \"smoothing\" operation: the convolution of \"f\" and \"g\" is differentiable as many times as \"f\" and \"g\" are in total.\nThese identities hold for example under the condition that \"f\" and \"g\" are absolutely integrable and at least one of them has an absolutely integrable (L1) weak derivative, as a consequence of Young's convolution inequality. For instance, when \"f\" is continuously differentiable with compact support, and \"g\" is an arbitrary locally integrable function,\nThese identities also hold much more broadly in the sense of tempered distributions if one of \"f\" or \"g\" is a \nrapidly decreasing tempered distribution, a \ncompactly supported tempered distribution or a Schwartz function and the other is a tempered distribution. On the other hand, two positive integrable and infinitely differentiable functions may have a nowhere continuous convolution.\nIn the discrete case, the difference operator \"D\" \"f\"(\"n\") = \"f\"(\"n\" + 1) \u2212 \"f\"(\"n\") satisfies an analogous relationship:\nConvolution theorem.\nThe convolution theorem states that\nwhere formula_147 denotes the Fourier transform of formula_1.\nConvolution in other types of transformations.\nVersions of this theorem also hold for the Laplace transform, two-sided Laplace transform, Z-transform and Mellin transform.\nConvolution on matrices.\nIf formula_149 is the Fourier transform matrix, then\nwhere formula_151 is face-splitting product, formula_152 denotes Kronecker product, formula_153 denotes Hadamard product (this result is an evolving of count sketch properties).\nThis can be generalized for appropriate matrices formula_154:\nfrom the properties of the face-splitting product.\nTranslational equivariance.\nThe convolution commutes with translations, meaning that\nwhere \u03c4\"x\"f is the translation of the function \"f\" by \"x\" defined by\nIf \"f\" is a Schwartz function, then \"\u03c4xf\" is the convolution with a translated Dirac delta function \"\u03c4\"\"x\"\"f\" = \"f\" \u2217 \"\u03c4\"\"x\" \"\u03b4\". So translation invariance of the convolution of Schwartz functions is a consequence of the associativity of convolution.\nFurthermore, under certain conditions, convolution is the most general translation invariant operation. Informally speaking, the following holds\nThus some translation invariant operations can be represented as convolution. Convolutions play an important role in the study of time-invariant systems, and especially LTI system theory. The representing function \"g\"\"S\" is the impulse response of the transformation \"S\".\nA more precise version of the theorem quoted above requires specifying the class of functions on which the convolution is defined, and also requires assuming in addition that \"S\" must be a continuous linear operator with respect to the appropriate topology. It is known, for instance, that every continuous translation invariant continuous linear operator on \"L\"1 is the convolution with a finite Borel measure. More generally, every continuous translation invariant continuous linear operator on \"L\"\"p\" for 1 \u2264 \"p\" &lt; \u221e is the convolution with a tempered distribution whose Fourier transform is bounded. To wit, they are all given by bounded Fourier multipliers.\nConvolutions on groups.\nIf \"G\" is a suitable group endowed with a measure \u03bb, and if \"f\" and \"g\" are real or complex valued integrable functions on \"G\", then we can define their convolution by\nIt is not commutative in general. In typical cases of interest \"G\" is a locally compact Hausdorff topological group and \u03bb is a (left-) Haar measure. In that case, unless \"G\" is unimodular, the convolution defined in this way is not the same as formula_159. The preference of one over the other is made so that convolution with a fixed function \"g\" commutes with left translation in the group:\nFurthermore, the convention is also required for consistency with the definition of the convolution of measures given below. However, with a right instead of a left Haar measure, the latter integral is preferred over the former.\nOn locally compact abelian groups, a version of the convolution theorem holds: the Fourier transform of a convolution is the pointwise product of the Fourier transforms. The circle group T with the Lebesgue measure is an immediate example. For a fixed \"g\" in \"L\"1(T), we have the following familiar operator acting on the Hilbert space \"L\"2(T):\nThe operator \"T\" is compact. A direct calculation shows that its adjoint \"T* \" is convolution with\nBy the commutativity property cited above, \"T\" is normal: \"T\"* \"T\" = \"TT\"* . Also, \"T\" commutes with the translation operators. Consider the family \"S\" of operators consisting of all such convolutions and the translation operators. Then \"S\" is a commuting family of normal operators. According to spectral theory, there exists an orthonormal basis {\"hk\"} that simultaneously diagonalizes \"S\". This characterizes convolutions on the circle. Specifically, we have\nwhich are precisely the characters of T. Each convolution is a compact multiplication operator in this basis. This can be viewed as a version of the convolution theorem discussed above.\nA discrete example is a finite cyclic group of order \"n\". Convolution operators are here represented by circulant matrices, and can be diagonalized by the discrete Fourier transform.\nA similar result holds for compact groups (not necessarily abelian): the matrix coefficients of finite-dimensional unitary representations form an orthonormal basis in \"L\"2 by the Peter\u2013Weyl theorem, and an analog of the convolution theorem continues to hold, along with many other aspects of harmonic analysis that depend on the Fourier transform.\nConvolution of measures.\nLet \"G\" be a (multiplicatively written) topological group.\nIf \u03bc and \u03bd are Radon measures on \"G\", then their convolution \"\u03bc\"\u2217\"\u03bd\" is defined as the pushforward measure of the group action and can be written as\nfor each measurable subset \"E\" of \"G\". The convolution is also a Radon measure, whose total variation satisfies\nIn the case when \"G\" is locally compact with (left-)Haar measure \u03bb, and \u03bc and \u03bd are absolutely continuous with respect to a \u03bb, so that each has a density function, then the convolution \u03bc\u2217\u03bd is also absolutely continuous, and its density function is just the convolution of the two separate density functions. In fact, if \"either\" measure is absolutely continuous with respect to the Haar measure, then so is their convolution.\nIf \u03bc and \u03bd are probability measures on the topological group then the convolution \"\u03bc\"\u2217\"\u03bd\" is the probability distribution of the sum \"X\" + \"Y\" of two independent random variables \"X\" and \"Y\" whose respective distributions are \u03bc and \u03bd.\nInfimal convolution.\nIn convex analysis, the infimal convolution of proper (not identically formula_29) convex functions formula_167 on formula_168 is defined by:\nformula_169\nIt can be shown that the infimal convolution of convex functions is convex. Furthermore, it satisfies an identity analogous to that of the Fourier transform of a traditional convolution, with the role of the Fourier transform is played instead by the Legendre transform:\nformula_170\nWe have:\nformula_171\nBialgebras.\nLet (\"X\", \u0394, \u2207, \"\u03b5\", \"\u03b7\") be a bialgebra with comultiplication \u0394, multiplication \u2207, unit \u03b7, and counit \"\u03b5\". The convolution is a product defined on the endomorphism algebra End(\"X\") as follows. Let \"\u03c6\", \"\u03c8\" \u2208 End(\"X\"), that is, \"\u03c6\", \"\u03c8\": \"X\" \u2192 \"X\" are functions that respect all algebraic structure of \"X\", then the convolution \"\u03c6\"\u2217\"\u03c8\" is defined as the composition\nThe convolution appears notably in the definition of Hopf algebras . A bialgebra is a Hopf algebra if and only if it has an antipode: an endomorphism \"S\" such that\nApplications.\nConvolution and related operations are found in many applications in science, engineering and mathematics."}
{"id": "7521", "revid": "36090741", "url": "https://en.wikipedia.org/wiki?curid=7521", "title": "Calico", "text": "Calico (; in British usage since 1505) is a heavy plain-woven textile made from unbleached, and often not fully processed, cotton. It may also contain unseparated husk parts. The fabric is far coarser than muslin, but less coarse and thick than canvas or denim. However, it is still very cheap owing to its unfinished and undyed appearance.\nThe fabric was originally from the city of Calicut in southwestern India. It was made by the traditional weavers called c\u0101liyans. The raw fabric was dyed and printed in bright hues, and calico prints became popular in Europe.\nHistory.\nOrigins.\nCalico originated in Calicut, from which the name of the textile came, in South India, now Kerala, during the 11th century, where the cloth was known as \"chaliyan\". It was mentioned in Indian literature by the 12th century when the polymath and writer Hemachandra described calico fabric prints with a lotus design. Calico was woven using Gujarati cotton from Surat for both the warp and weft. By the 15th century, calico from Gujarat made its appearance in Cairo, then capital of the Egypt Eyalet under the Ottoman Empire. Trade with Europe followed from the 17th century onwards.\nPolitics of cotton in the British Empire.\nIn the 18th century, England was famous for its woollen and worsted cloth. That industry, centered in the east and south in towns such as Norwich, jealously protected their product. Cotton processing was tiny: in 1701, only of cottonwool was imported into England, and by 1730 this had fallen to . This was due to commercial legislation to protect the woollen industry. Cheap calico prints, imported by the East India Company from Hindust\u0101n (India), had become popular. In 1700 an Act of Parliament passed to prevent the importation of dyed or printed calicoes from India, China or Persia. This caused demand to switch to imported grey cloth instead\u2014calico that had not been finished\u2014dyed or printed. These were printed with popular patterns in southern England. Also, Lancashire businessmen produced grey cloth with linen warp and cotton weft, known as fustian, which they sent to London for finishing. Cottonwool imports recovered though, and by 1720 were almost back to their 1701 levels. Coventry woollen manufacturers claimed that the imports were taking jobs away from their workers. The Woollen, etc., Manufactures Act 1720 was passed, enacting fines against anyone caught wearing printed or stained calico muslins, but neckcloths and fustians were exempted. The Lancashire manufacturers exploited this exemption; coloured cotton weft with linen warp were specifically permitted by the 1736 Manchester Act.\nIn 1764, of cottonwool was imported. \nCalico printing.\nEarly Indian chintz, that is, glazed calico with a large floral pattern, was primarily produced using painting techniques. Later, the hues were applied by wooden blocks, and the cloth manufacturers in Britain printed calico using wooden block printing. Calico printers at work are depicted in one of the stained glass windows made by Stephen Adam for the Maryhill Burgh Halls, Glasgow. Confusingly, linen and silk printed this way were known as \"linen calicoes\" and \"silk calicoes\". Early European calicoes (1680) were cheap plain weave white cotton fabric, or cream or unbleached cotton, with a design block-printed using a single alizarin dye fixed with two mordants, giving a red and black pattern. Polychromatic prints were possible, using two sets of blocks and an additional blue dye. The Indian taste was for dark printed backgrounds, while the European market preferred a pattern on a cream base. As the century progressed the European preference moved from the large chintz patterns to smaller, tighter patterns.\nThomas Bell patented a printing technique in 1783 that used copper rollers. In 1785, Livesey, Hargreaves and Company put the first machine that used this technique into operation in Walton-le-Dale, Lancashire. The production volume for printed cloth in Lancashire in 1750 was estimated at 50,000 pieces of ; in 1850, it was 20,000,000 pieces. The commercial method of calico printing using engraved rollers was invented in 1821 in New Mills, Derbyshire, in the United Kingdom. John Potts of Potts, Oliver and Potts used a copper-engraved master to produce rollers to transfer the inks. After 1888, block printing was only used for short-run specialized jobs. After 1880, profits from printing fell due to overcapacity and the firms started to form combines. In the first, three Scottish firms formed the United Turkey Red Co. Ltd in 1897, and the second, in 1899, was the much larger Calico Printers' Association 46 printing concerns and 13 merchants combined, representing 85% of the British printing capacity. Some of this capacity was removed and in 1901 Calico had 48% of the printing trade. In 1916, they and the other printers formed and joined a trade association, which then set minimum prices for each 'price section' of the industry.\nThe trade association remained in operation until 1954, when the arrangement was challenged by the government Monopolies Commission. Over the intervening period much trade had been lost overseas.\nTerminology.\nIn the UK, Australia and New Zealand:\nIn the US:\nPrinted calico was imported into the United States from Lancashire in the 1780s, and here a linguistic separation occurred. While Europe maintained the word calico for the fabric, in the States it was used to refer to the printed design.\nThese colourful, small-patterned printed fabrics gave rise to the use of the word calico to describe a cat coat colour: calico cat. The patterned fabric also gave its name to two species of North American crabs; see Ovalipes ocellatus."}
{"id": "7522", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7522", "title": "Calorimetry", "text": "In chemistry and thermodynamics, calorimetry () is the science or act of measuring changes in \"state variables\" of a body for the purpose of deriving the heat transfer associated with changes of its state due, for example, to chemical reactions, physical changes, or phase transitions under specified constraints. Calorimetry is performed with a calorimeter. Scottish physician and scientist Joseph Black, who was the first to recognize the distinction between heat and temperature, is said to be the founder of the science of calorimetry.\nIndirect calorimetry calculates heat that living organisms produce by measuring either their production of carbon dioxide and nitrogen waste (frequently ammonia in aquatic organisms, or urea in terrestrial ones), or from their consumption of oxygen. Lavoisier noted in 1780 that heat production can be predicted from oxygen consumption this way, using multiple regression. The dynamic energy budget theory explains why this procedure is correct. Heat generated by living organisms may also be measured by \"direct calorimetry\", in which the entire organism is placed inside the calorimeter for the measurement.\nA widely used modern instrument is the differential scanning calorimeter, a device which allows thermal data to be obtained on small amounts of material. It involves heating the sample at a controlled rate and recording the heat flow either into or from the specimen.\nClassical calorimetric calculation of heat.\nCases with differentiable equation of state for a one-component body.\nBasic classical calculation with respect to volume.\nCalorimetry requires that a reference material that changes temperature have known definite thermal constitutive properties. The classical rule, recognized by Clausius and Kelvin, is that the pressure exerted by the calorimetric material is fully and rapidly determined solely by its temperature and volume; this rule is for changes that do not involve phase change, such as melting of ice. There are many materials that do not comply with this rule, and for them, the present formula of classical calorimetry does not provide an adequate account. Here the classical rule is assumed to hold for the calorimetric material being used, and the propositions are mathematically written:\nThe thermal response of the calorimetric material is fully described by its pressure formula_1 as the value of its constitutive function formula_2 of just the volume formula_3 and the temperature formula_4. All increments are here required to be very small. This calculation refers to a domain of volume and temperature of the body in which no phase change occurs, and there is only one phase present. An important assumption here is continuity of property relations. A different analysis is needed for phase change\nWhen a small increment of heat is gained by a calorimetric body, with small increments, formula_5 of its volume, and formula_6 of its temperature, the increment of heat, formula_7, gained by the body of calorimetric material, is given by\nwhere\nThe latent heat with respect to volume is the heat required for unit increment in volume at constant temperature. It can be said to be 'measured along an isotherm', and the pressure the material exerts is allowed to vary freely, according to its constitutive law formula_18. For a given material, it can have a positive or negative sign or exceptionally it can be zero, and this can depend on the temperature, as it does for water about 4 C. The concept of latent heat with respect to volume was perhaps first recognized by Joseph Black in 1762. The term 'latent heat of expansion' is also used. The latent heat with respect to volume can also be called the 'latent energy with respect to volume'. For all of these usages of 'latent heat', a more systematic terminology uses 'latent heat capacity'.\nThe heat capacity at constant volume is the heat required for unit increment in temperature at constant volume. It can be said to be 'measured along an isochor', and again, the pressure the material exerts is allowed to vary freely. It always has a positive sign. This means that for an increase in the temperature of a body without change of its volume, heat must be supplied to it. This is consistent with common experience.\nQuantities like formula_7 are sometimes called 'curve differentials', because they are measured along curves in the formula_20 surface.\nClassical theory for constant-volume (isochoric) calorimetry.\nConstant-volume calorimetry is calorimetry performed at a constant volume. This involves the use of a constant-volume calorimeter. Heat is still measured by the above-stated principle of calorimetry.\nThis means that in a suitably constructed calorimeter, called a bomb calorimeter, the increment of volume formula_5 can be made to vanish, formula_22. For constant-volume calorimetry:\nwhere\nClassical heat calculation with respect to pressure.\nFrom the above rule of calculation of heat with respect to volume, there follows one with respect to pressure.\nIn a process of small increments, formula_26 of its pressure, and formula_6 of its temperature, the increment of heat, formula_7, gained by the body of calorimetric material, is given by\nwhere\nThe new quantities here are related to the previous ones:\nwhere\nand\nThe latent heats formula_9 and formula_30 are always of opposite sign.\nIt is common to refer to the ratio of specific heats as\nCalorimetry through phase change, equation of state shows one jump discontinuity.\nAn early calorimeter was that used by Laplace and Lavoisier, as shown in the figure above. It worked at constant temperature, and at atmospheric pressure. The latent heat involved was then not a latent heat with respect to volume or with respect to pressure, as in the above account for calorimetry without phase change. The latent heat involved in this calorimeter was with respect to phase change, naturally occurring at constant temperature. This kind of calorimeter worked by measurement of mass of water produced by the melting of ice, which is a phase change.\nCumulation of heating.\nFor a time-dependent process of heating of the calorimetric material, defined by a continuous joint progression formula_53 of formula_54 and formula_55, starting at time formula_56 and ending at time formula_57, there can be calculated an accumulated quantity of heat delivered, formula_58 . This calculation is done by mathematical integration along the progression with respect to time. This is because increments of heat are 'additive'; but this does not mean that heat is a conservative quantity. The idea that heat was a conservative quantity was invented by Lavoisier, and is called the 'caloric theory'; by the middle of the nineteenth century it was recognized as mistaken. Written with the symbol formula_59, the quantity formula_58 is not at all restricted to be an increment with very small values; this is in contrast with formula_7.\nOne can write\nThis expression uses quantities such as formula_65 which are defined in the section below headed 'Mathematical aspects of the above rules'.\nMathematical aspects of the above rules.\nThe use of 'very small' quantities such as formula_7 is related to the physical requirement for the quantity formula_2 to be 'rapidly determined' by formula_3 and formula_4; such 'rapid determination' refers to a physical process. These 'very small' quantities are used in the Leibniz approach to the infinitesimal calculus. The Newton approach uses instead 'fluxions' such as formula_70, which makes it more obvious that formula_2 must be 'rapidly determined'.\nIn terms of fluxions, the above first rule of calculation can be written\nwhere\nThe increment formula_7 and the fluxion formula_65 are obtained for a particular time formula_73 that determines the values of the quantities on the righthand sides of the above rules. But this is not a reason to expect that there should exist a mathematical function formula_82. For this reason, the increment formula_7 is said to be an 'imperfect differential' or an 'inexact differential'. Some books indicate this by writing formula_84 instead of formula_7. Also, the notation \"\u0111Q\" is used in some books. Carelessness about this can lead to error.&lt;ref name=\"Planck 1923/1926 57\"&gt;Planck, M. (1923/1926), page 57.&lt;/ref&gt;\nThe quantity formula_62 is properly said to be a functional of the continuous joint progression formula_53 of formula_54 and formula_55, but, in the mathematical definition of a function, formula_62 is not a function of formula_20. Although the fluxion formula_65 is defined here as a function of time formula_73, the symbols formula_94 and formula_82 respectively standing alone are not defined here.\nPhysical scope of the above rules of calorimetry.\nThe above rules refer only to suitable calorimetric materials. The terms 'rapidly' and 'very small' call for empirical physical checking of the domain of validity of the above rules.\nThe above rules for the calculation of heat belong to pure calorimetry. They make no reference to thermodynamics, and were mostly understood before the advent of thermodynamics. They are the basis of the 'thermo' contribution to thermodynamics. The 'dynamics' contribution is based on the idea of work, which is not used in the above rules of calculation.\nExperimentally conveniently measured coefficients.\nEmpirically, it is convenient to measure properties of calorimetric materials under experimentally controlled conditions.\nPressure increase at constant volume.\nFor measurements at experimentally controlled volume, one can use the assumption, stated above, that the pressure of the body of calorimetric material is can be expressed as a function of its volume and temperature.\nFor measurement at constant experimentally controlled volume, the isochoric coefficient of pressure rise with temperature, is defined by \nExpansion at constant pressure.\nFor measurements at experimentally controlled pressure, it is assumed that the volume formula_3 of the body of calorimetric material can be expressed as a function formula_98 of its temperature formula_4 and pressure formula_1. This assumption is related to, but is not the same as, the above used assumption that the pressure of the body of calorimetric material is known as a function of its volume and temperature; anomalous behaviour of materials can affect this relation.\nThe quantity that is conveniently measured at constant experimentally controlled pressure, the isobar volume expansion coefficient, is defined by \nCompressibility at constant temperature.\nFor measurements at experimentally controlled temperature, it is again assumed that the volume formula_3 of the body of calorimetric material can be expressed as a function formula_98 of its temperature formula_4 and pressure formula_1, with the same provisos as mentioned just above.\nThe quantity that is conveniently measured at constant experimentally controlled temperature, the isothermal compressibility, is defined by \nRelation between classical calorimetric quantities.\nAssuming that the rule formula_18 is known, one can derive the function of formula_108 that is used above in the classical heat calculation with respect to pressure. This function can be found experimentally from the coefficients formula_109 and formula_110 through the mathematically deducible relation\nConnection between calorimetry and thermodynamics.\nThermodynamics developed gradually over the first half of the nineteenth century, building on the above theory of calorimetry which had been worked out before it, and on other discoveries. According to Gislason and Craig (2005): \"Most thermodynamic data come from calorimetry...\" According to Kondepudi (2008): \"Calorimetry is widely used in present day laboratories.\"\nIn terms of thermodynamics, the internal energy formula_112 of the calorimetric material can be considered as the value of a function formula_113 of formula_20, with partial derivatives formula_115 and formula_116.\nThen it can be shown that one can write a thermodynamic version of the above calorimetric rules:\nwith\nand\nAgain, further in terms of thermodynamics, the internal energy formula_112 of the calorimetric material can sometimes, depending on the calorimetric material, be considered as the value of a function formula_121 of formula_122, with partial derivatives formula_123 and formula_116, and with formula_3 being expressible as the value of a function formula_126 of formula_122, with partial derivatives formula_128 and formula_129 .\nThen, according to Adkins (1975), it can be shown that one can write a further thermodynamic version of the above calorimetric rules:\nwith\nand\nBeyond the calorimetric fact noted above that the latent heats formula_9 and formula_30 are always of opposite sign, it may be shown, using the thermodynamic concept of work, that also\nSpecial interest of thermodynamics in calorimetry: the isothermal segments of a Carnot cycle.\nCalorimetry has a special benefit for thermodynamics. It tells about the heat absorbed or emitted in the isothermal segment of a Carnot cycle.\nA Carnot cycle is a special kind of cyclic process affecting a body composed of material suitable for use in a heat engine. Such a material is of the kind considered in calorimetry, as noted above, that exerts a pressure that is very rapidly determined just by temperature and volume. Such a body is said to change reversibly. A Carnot cycle consists of four successive stages or segments:\n(3) another isothermal change in volume from formula_140 to a volume formula_142 at constant temperature formula_143 such as to incur a flow or heat out of the body and just such as to precisely prepare for the following change\n(4) another adiabatic change of volume from formula_142 back to formula_136 just such as to return the body to its starting temperature formula_138.\nIn isothermal segment (1), the heat that flows into the body is given by\nand in isothermal segment (3) the heat that flows out of the body is given by\nBecause the segments (2) and (4) are adiabats, no heat flows into or out of the body during them, and consequently the net heat supplied to the body during the cycle is given by\nThis quantity is used by thermodynamics and is related in a special way to the net work done by the body during the Carnot cycle. The net change of the body's internal energy during the Carnot cycle, formula_150, is equal to zero, because the material of the working body has the special properties noted above.\nSpecial interest of calorimetry in thermodynamics: relations between classical calorimetric quantities.\nRelation of latent heat with respect to volume, and the equation of state.\nThe quantity formula_9, the latent heat with respect to volume, belongs to classical calorimetry. It accounts for the occurrence of energy transfer by work in a process in which heat is also transferred; the quantity, however, was considered before the relation between heat and work transfers was clarified by the invention of thermodynamics. In the light of thermodynamics, the classical calorimetric quantity is revealed as being tightly linked to the calorimetric material's equation of state formula_18. Provided that the temperature formula_153 is measured in the thermodynamic absolute scale, the relation is expressed in the formula\nDifference of specific heats.\nAdvanced thermodynamics provides the relation\nFrom this, further mathematical and thermodynamic reasoning leads to another relation between classical calorimetric quantities. The difference of specific heats is given by\nPractical constant-volume calorimetry (bomb calorimetry) for thermodynamic studies.\nConstant-volume calorimetry is calorimetry performed at a constant volume. This involves the use of a constant-volume calorimeter.\nNo work is performed in constant-volume calorimetry, so the heat measured equals the change in internal energy of the system. The heat capacity at constant volume is assumed to be independent of temperature.\nHeat is measured by the principle of calorimetry.\nwhere\nIn \"constant-volume calorimetry\" the pressure is not held constant. If there is a pressure difference between initial and final states, the heat measured needs adjustment to provide the \"enthalpy change\". One then has\nwhere"}
{"id": "7525", "revid": "1271321399", "url": "https://en.wikipedia.org/wiki?curid=7525", "title": "Charles Evans Hughes", "text": "Charles Evans Hughes (April 11, 1862 \u2013 August 27, 1948) was an American politician, academic, and jurist who served as the 11th chief justice of the United States from 1930 to 1941. A member of the Republican Party, he previously was the 36th governor of New York (1907\u20131910), an associate justice of the Supreme Court (1910\u20131916), and 44th U.S. secretary of state (1921\u20131925). As the Republican nominee in the 1916 presidential election, he narrowly lost to Woodrow Wilson.\nBorn to a Welsh immigrant preacher and his wife in Glens Falls, New York, Hughes graduated from Brown University and Columbia Law School and practiced law in New York City. After working in private practice for several years, in 1905 he led successful state investigations into public utilities and the life insurance industry. He won election as the governor of New York in 1906, and implemented several progressive reforms. In 1910, President William Howard Taft appointed Hughes as an associate justice of the Supreme Court of the United States. During his tenure on the Supreme Court, Hughes often joined Associate Justice Oliver Wendell Holmes Jr. in voting to uphold state and federal regulations.\nHughes served as an associate justice until 1916, when he resigned from the bench to accept the Republican presidential nomination. Though Hughes was widely viewed as the favorite in the race against incumbent Democratic president Woodrow Wilson, Wilson won a narrow victory. After Warren G. Harding won the 1920 presidential election, Hughes accepted Harding's invitation to serve as secretary of state. Serving under Harding and Calvin Coolidge, he negotiated the Washington Naval Treaty, which was designed to prevent a naval arms race among the United States, the United Kingdom and Japan. Hughes left office in 1925 and returned to private practice, becoming one of the most prominent attorneys in the country.\nIn 1930, President Herbert Hoover appointed him to succeed Chief Justice Taft. Along with Associate Justice Owen Roberts, Hughes emerged as a key swing vote on the bench, positioned between the liberal Three Musketeers and the conservative Four Horsemen. The Hughes Court struck down several New Deal programs in the early and the mid-1930s; 1937 marked a turning point for the Supreme Court and the New Deal as Hughes and Roberts joined with the Three Musketeers to uphold the Wagner Act and a state minimum wage law. That same year saw the defeat of the Judicial Procedures Reform Bill of 1937, which would have expanded the size of the Supreme Court. Hughes served until 1941, when he retired and was succeeded by Associate Justice Harlan F. Stone.\nEarly life and family.\nHughes's father, David Charles Hughes, was Welsh. He immigrated to the United States from Wales in 1855 after he was inspired by \"The Autobiography of Benjamin Franklin\". David became a Baptist preacher in Glens Falls, New York, and married Mary Catherine Connelly, whose family had been in the United States for several generations. Charles Evans Hughes, the only child of David and Mary, was born in Glens Falls on April 11, 1862. The Hughes family moved to Oswego, New York, in 1866, but relocated soon after to Newark, New Jersey, and then to Brooklyn. With the exception of a brief period of attendance at Newark High School, Hughes received no formal education until 1874, instead being educated by his parents. In September 1874, he enrolled in New York City's prestigious Public School 35, graduating the following year.\nAt the age of 14, Hughes attended Madison University (now Colgate University) for two years before transferring to Brown University. He graduated from Brown third in his class at the age of 19, having been elected to Phi Beta Kappa in his junior year. He was also a member of the Delta Upsilon fraternity, where he served as the first international President later on. During his time at Brown, Hughes volunteered for the successful presidential campaign of Republican nominee James A. Garfield in the 1880 presidential election, a fraternity brother of his in Delta Upsilon where Garfield was an undergraduate at Williams College, and served as the editor of the college newspaper. After graduating from Brown, Hughes spent a year working as a teacher in Delhi, New York. He then enrolled in Columbia Law School, graduating with a Bachelor of Laws in 1884 ranked first in his class. That same year, he passed the New York bar exam with the highest score ever awarded.\nIn 1888, Hughes married Antoinette Carter, the daughter of the senior partner of the law firm where he worked. Their first child, Charles Evans Hughes Jr., was born the following year, and Hughes purchased a house in Manhattan's Upper West Side neighborhood. Hughes and his wife had one son and three daughters. Their youngest child, Elizabeth Hughes, was one of the first humans injected with insulin, and later served as president of the Supreme Court Historical Society.\nLegal and academic career.\nHughes took a position with the Wall Street law firm of Chamberlain, Carter &amp; Hornblower in 1883, focusing primarily on matters related to contracts and bankruptcies. He was made a partner in the firm in 1888, and the firm changed its name to Carter, Hughes &amp; Cravath (it later became known as Hughes Hubbard &amp; Reed). Hughes left the firm and became a professor at Cornell Law School from 1891 to 1893. He returned to Carter, Hughes &amp; Cravath in 1893. He also joined the board of Brown University and served on a special committee that recommended revisions to New York's Code of Civil Procedure.\nExposing corrupt utilities.\nResponding to newspaper stories run by the \"New York World\", Governor Frank W. Higgins appointed a legislative committee to investigate the state's public utilities in 1905. On the recommendation of a former state judge who had been impressed by Hughes's performance in court, the legislative committee appointed Hughes to lead the investigation. Hughes was reluctant to take on the powerful utility companies, but Senator Frederick C. Stevens, the leader of the committee, convinced Hughes to accept the position. Hughes decided to center his investigation on Consolidated Gas, which controlled the production and sale of gas in New York City. Though few expected the committee to have any impact on public corruption, Hughes was able to show that Consolidated Gas had engaged in a pattern of tax evasion and fraudulent bookkeeping. To eliminate or mitigate those abuses, Hughes drafted and convinced the state legislature to pass bills that established a commission to regulate public utilities and lowered gas prices.\nExposing corrupt insurance companies.\nHughes's success made him a popular public figure in New York, and he was appointed counsel to the Armstrong Insurance Commission, which investigated the major life insurance companies headquartered in New York. His examination of the insurance industry uncovered payments made to journalists and lobbyists as well as payments and other forms of compensation directed to legislators serving throughout the country. His investigation also showed that many top insurance executives had various conflicts of interest and had received huge raises at the same time that dividends to policyholders had fallen. Seeking to remove Hughes from the investigation, Republican leaders nominated him as the party's candidate for Mayor of New York City, but Hughes refused the nomination. His efforts ultimately resulted in the resignation or firing of most of the top-ranking officials in the three major life insurance companies in the United States. Following the investigation, Hughes convinced the state legislature to bar insurance companies from owning corporate stock, underwriting securities, or engaging in other banking practices.\nGovernor of New York.\nSeeking a strong candidate to defeat newspaper mogul William Randolph Hearst in the 1906 New York gubernatorial election, President Theodore Roosevelt convinced New York Republican leaders to nominate Hughes for governor. A progressive conservative, Roosevelt described Hughes as \"a sane and sincere reformer, who really has fought against the very evils which Hearst denounces,\u00a0... [but is] free from any taint of demagogy.\" In his campaign for governor, Hughes attacked the corruption of specific companies but defended corporations as a necessary part of the economy. He also called for an eight-hour workday on public works projects and favored prohibitions on child labor. Hughes was not a charismatic speaker, but he campaigned vigorously throughout the state and won the endorsements of most newspapers. Ultimately, Hughes defeated Hearst in a close election, taking 52 percent of the vote.\nReforming state government.\nHughes's governorship focused largely on reforming the government and addressing political corruption. He expanded the number of civil service positions, increased the power of the public utility regulatory commissions, and won passage of laws that placed limits on political donations by corporations and required political candidates to track campaign receipts and expenditures. He also signed laws that barred younger workers from several dangerous occupations and established a maximum 48-hour workweek for manufacturing workers under the age of 16. To enforce those laws, Hughes reorganized the New York State Department of Labor. Hughes's labor policies were influenced by economist Richard T. Ely, who sought to improve working conditions for laborers, but rejected the more far-reaching reforms favored by union leaders like Samuel Gompers.\nOrganizing the Baptists.\nThe busy governor found time to get involved in religious matters. A lifelong Northern Baptist, Hughes participated in the creation of the Northern Baptist Convention in May 1907. Hughes served the convention as its first president, beginning the task of unifying the thousands of independent Baptist churches across the North into one denomination. Previously, northern Baptists had only connected between local churches through mission societies and benevolent causes. The Northern Baptist Convention went on to become the historically important American Baptist Churches USA, which made this aspect of Hughes's life during his governorship a key part of his historical influence.\nDisappointing second term as governor.\nHowever, Hughes's political role was changing. He had previously been close with Roosevelt, but relations between Hughes and the president cooled after a dispute over a minor federal appointment. Roosevelt chose not to seek re-election in 1908, instead endorsing Secretary of War William Howard Taft as his preferred successor. Taft won the Republican presidential nomination and asked Hughes to serve as his running mate, but Hughes declined the offer. Hughes also considered retiring from the governorship, but Taft and Roosevelt convinced him to seek a second term. Despite having little support among some of the more conservative leaders of the state party, Hughes won re-election in the 1908 election. Hughes's second term proved to be less successful than his first. His highest priority was a direct primary law, and it repeatedly failed to pass. He did obtain increased regulation over telephone and telegraph companies and won passage of the first workers' compensation bill in U.S. history.\nAccording to historian and journalist Henry F. Pringle, Hughes's sense of civic duty was a poor fit in a party-machine age, leaving \"many faithful Republicans\" with bitter memories of Hughes's \"horrid notions of efficiency in government\" that \"ruthlessly disregarded necessary rewards for party workers.\"\nAssociate Justice.\nBy early 1910, Hughes was anxious to retire from his position as governor. A vacancy on the Supreme Court arose following the death of Associate Justice David J. Brewer, and Taft offered the position to Hughes, who quickly accepted the offer. His nomination was formally received by the Senate on April 25, 1910. The Senate Judiciary Committee reported favorably on his nomination on May 2, 1910, and the Senate unanimously confirmed him the same day. Two months after Hughes's confirmation, but prior to his taking the judicial oath, Chief Justice Melville W. Fuller died. Taft elevated Associate Justice Edward Douglass White to the position of Chief Justice despite having previously indicated to Hughes that he might select Hughes as Chief Justice. White's candidacy for the position was bolstered by his long experience on the bench and popularity among his fellow justices, as well as Theodore Roosevelt's coolness towards Hughes.\nHughes was sworn in to the Supreme Court on October 10, 1910, and quickly struck up friendships with other members of the Court, including Chief Justice White, Associate Justice John Marshall Harlan, and Associate Justice Oliver Wendell Holmes Jr. In the disposition of cases, however, Hughes tended to align with Holmes. He voted to uphold state laws providing for minimum wages, workmen's compensation, and maximum work hours for women and children. He also wrote several opinions upholding the power of Congress to regulate interstate commerce under the Commerce Clause. His majority opinion in \"Baltimore &amp; Ohio Railroad vs. Interstate Commerce Commission\" upheld the right of the federal government to regulate the hours of railroad workers. His majority opinion in the 1914 Shreveport Rate Case upheld the Interstate Commerce Commission's decision to void discriminatory railroad rates imposed by the Railroad Commission of Texas. The decision established that the federal government could regulate intrastate commerce when it affected interstate commerce, though Hughes avoided directly overruling the 1895 case of \"United States v. E. C. Knight Co.\"\nHe also wrote a series of opinions that upheld civil liberties; in one such case, \"McCabe v. Atchison, Topeka &amp; Santa Fe Railway Co.\", Hughes's majority opinion required railroad carriers to give African-Americans \"equal treatment.\" Hughes's majority opinion in \"Bailey v. Alabama\" invalidated a state law that had made it a crime for a laborer to fail to complete obligations agreed to in a labor contract. Hughes held that this law violated the Thirteenth Amendment and discriminated against African-American workers. He also joined the majority decision in the 1915 case of \"Guinn v. United States\", which outlawed the use of grandfather clauses to determine voter enfranchisement. Hughes and Holmes were the only dissenters from the court's ruling that affirmed a lower court's decision to withhold a writ of habeas corpus from Leo Frank, a Jewish factory manager convicted of murder in the state of Georgia.\nPresidential candidate.\nTaft and Roosevelt endured a bitter split during Taft's presidency, and Roosevelt challenged Taft for the 1912 Republican presidential nomination. Taft won re-nomination, but Roosevelt ran on the ticket of a third party, the Progressive Party. With the split in the Republican Party, Democratic Governor Woodrow Wilson defeated Taft and Roosevelt in the 1912 presidential election and enacted his progressive New Freedom agenda. Seeking to bridge the divide in the Republican Party and limit Wilson to a single term, several Republican leaders asked Hughes to consider running in the 1916 presidential election. Hughes at first rebuffed those entreaties, but his potential candidacy became the subject of widespread speculation and polls showed that he was the preferred candidate of many Republican voters.\nBy the time of the June 1916 Republican National Convention, Hughes had won two presidential primaries, and his backers had lined up the support of numerous delegates. Hughes led on the first presidential ballot of the convention and clinched the nomination on the third ballot. Hughes accepted the nomination, becoming the first and only sitting Supreme Court Justice to serve as a major party's presidential nominee, and submitted his resignation to President Wilson. Roosevelt, meanwhile, declined to run again on a third party ticket, leaving Hughes and Wilson as the only major candidates in the race.\nBecause of the Republican Party's dominance in presidential elections held since the election of Abraham Lincoln in 1860, Hughes was widely regarded as the favorite even though Wilson was the incumbent. His candidacy was further boosted by his own reputation for intelligence, personal integrity, and moderation. Hughes also won the public support of both Taft and Roosevelt, though Roosevelt remained uneasy with Hughes, who he feared would be a \"Wilson with whiskers.\" However, the 1912 split in Republican ranks remained a lingering issue, and Hughes damaged his campaign by deciding to base his California campaign with the conservative Republican regulars. Hiram Johnson, the Governor of California who had been Roosevelt's running mate in the 1912 election, endorsed Hughes but the Progressive forces ignored Hughes. Nationally, because of Hughes's opposition to the Adamson Act and the Sixteenth Amendment, most former Progressive Party leaders endorsed Wilson. By election day, Hughes was still generally considered to be the favorite. He performed strongly in the Northeast and early election returns looked good. Nevertheless, Woodrow Wilson, as expected, swept the Solid South while also winning several states in the Midwest and Great Plains, where his candidacy was boosted by a strong antiwar sentiment. Wilson ultimately prevailed after winning the decisive state of California by fewer than 4,000 votes.\nReturn to law practice and political advising.\nAfter the election, Hughes turned down offers from larger organizations and returned to his small law firm, now known as Hughes, Rounds, Schurman &amp; Dwight. In March 1917, Hughes joined with many other Republican leaders in demanding that Wilson declare war on the Central Powers after Germany sank several American merchant ships. The next month, Wilson asked Congress for a declaration of war, and the United States entered World War I. Hughes supported Wilson's military policies, including the imposition of the draft, and he served as chairman of New York City's draft appeals board. He also investigated the aircraft industry on behalf of the Wilson administration, exposing numerous inefficiencies. He once again returned to private practice after the war, serving a wide array of clients, including five Socialists who had been expelled from the New York legislature for their political beliefs. He sought to broker a compromise between President Wilson and Senate Republicans regarding US entrance into Wilson's proposed League of Nations, but the Senate rejected the League and the Treaty of Versailles.\nWith Wilson's popularity declining, many Republican leaders believed that their party would win the 1920 presidential election. Hughes remained popular in the party, and many influential Republicans favored him as the party's candidate in 1920. Hughes was struck by personal tragedy when his daughter, Helen, died in 1920 of tuberculosis, and he refused to allow his name to be considered for the presidential nomination at the 1920 Republican National Convention. The party instead nominated a ticket consisting of Senator Warren G. Harding of Ohio and Governor Calvin Coolidge of Massachusetts. The Republican ticket won in a landslide, taking 61 percent of the popular vote.\nSecretary of State.\nShortly after Harding's victory in the 1920 election, Hughes accepted the position of Secretary of State. After the death of Chief Justice White in May 1921, Hughes was mentioned as a potential successor. Hughes told Harding he was uninterested in leaving the State Department, and Harding instead appointed former President Taft as the Chief Justice.\nHarding granted Hughes a great deal of discretion in his leadership of the State Department and US foreign policy. Harding and Hughes frequently communicated, Hughes worked within some broad outlines, and the president remained well-informed. However, the President rarely overrode any of Hughes's decisions, with the big and obvious exception of the League of Nations.\nAfter taking office, President Harding hardened his stance on the League of Nations to deciding the US would not join even a scaled-down version. Another view is that Harding favored joining with reservations when he assumed office on March 4, 1921, but senators staunchly opposed (the \"Irreconcilables\"), per Ronald E. Powaski's 1991 book, \"threatened to wreck the new administration.\"\nHughes favored membership in the League. Early in his tenure as Secretary of State, he asked the Senate to vote on the Treaty of Versailles, but he yielded to either Harding's changing views and/or the political reality within the Senate. Instead, he convinced Harding of the necessity of a separate treaty with Germany, resulting in the signing and eventual ratification of the U.S.\u2013German Peace Treaty. Hughes also favored US entrance into the Permanent Court of International Justice but was unable to convince the Senate to provide support.\nWashington Naval Treaty.\nHughes's major initiative in office was preventing an arms race among the three great naval powers of Britain, Japan, and the United States. After Senator William Borah led passage of a resolution calling on the Harding administration to negotiate an arms reduction treaty with Japan and Britain, Hughes convinced those countries as well as Italy and France to attend a naval conference in Washington. Hughes selected an American delegation consisting of himself, former Secretary of State Elihu Root, Republican Senator Henry Cabot Lodge, and Democratic Senator Oscar Underwood. Hughes hoped that the selection of Underwood would ensure bipartisan support for any treaty arising from the conference.\nPrior to the conference, Hughes had carefully considered possible treaty terms since each side would seek terms that would provide its respective navy with subtle advantages. He decided to propose an arms reduction formula based on the immediate halting of all naval construction, with future construction limits based on the ship tonnage of each country. The formula would be based on the ship tonnage ratio of 1920, which stood at roughly 5:5:3 for the United States, Britain, and Japan, respectively. Knowing that US and foreign naval leaders would resist his proposal, he anxiously guarded it from the press, but he won the support of Root, Lodge, and Underwood.\nThe Washington Naval Conference opened in November 1921, attended by five national delegations, and in the gallery by hundreds of reporters and dignitaries such as Chief Justice Taft and William Jennings Bryan. On the first day of the conference, Hughes unveiled his proposal to limit naval armaments. Hughes's ambitious proposal to scrap all US capital ships under construction stunned the delegates, as did his proposals for the Japanese and British Navies. The British delegation, led by Arthur Balfour, supported the proposal, but the Japanese delegation, under the leadership of Kat\u014d Tomosabur\u014d, asked for several modifications. Kat\u014d asked for the ratio to be adjusted to 10:10:7 and refused to destroy the \"Mutsu\", a dreadnought that many Japanese saw as a symbol of national pride. Kat\u014d eventually relented on the naval ratios, but Hughes acquiesced to the retention of the \"Mutsu\", leading to protests from British leaders. Hughes clinched an agreement after convincing Balfour to agree to limit the size of the Admiral-class battlecruisers despite objections from the British Navy. Hughes also won agreement on the Four-Power Treaty, which called for a peaceful resolution of territorial claims in the Pacific Ocean, as well as the Nine-Power Treaty, which guaranteed the territorial integrity of China. News of the success of the conference was warmly received around the world. Franklin D. Roosevelt later wrote that the conference \"brought to the world the first important voluntary agreement for limitation and reduction of armament.\"\nOther issues.\nIn the aftermath of World War I, the German economy struggled from the strain of postwar rebuilding and war reparations owed to the Entente, and the Entente powers in turn owed large war debts to the United States. Though many economists favored cancellation of all European war debts, French leaders were unwilling to cancel the reparations, and Congress refused to consider forgiving the war debts. Hughes helped organize the creation of an international committee of economists to study the possibility of lowering Germany's reparations, and Hughes selected Charles G. Dawes to lead that committee. The resulting Dawes Plan, which provided for annual payments by Germany, was accepted at a 1924 conference held in London.\nHughes favored a closer relationship with the United Kingdom, and sought to coordinate US foreign policy with Great Britain concerning matters in Europe and Asia. Hughes sought better relations with the countries of Latin America, and he favored removing US troops when he believed that doing so was practicable. He formulated plans for the withdrawal of US soldiers from the Dominican Republic and Nicaragua but decided that instability in Haiti required the continued presence of US soldiers. He also settled a border dispute between Panama and Costa Rica by threatening to send soldiers into Panama.\nHughes was the keynote speaker at the 1919 National Conference on Lynching.\nReturn to private practice.\nHughes stayed on as Secretary of State in the Coolidge administration after the death of Harding in 1923, but he left office in early 1925. He once again returned to his law firm, becoming one of the highest-earning lawyers in the country. He also served as a special master in a case concerning Chicago's sewage system, was elected president of the American Bar Association, and co-founded the National Conference on Christians and Jews.\nState party leaders asked him to run against Al Smith in New York's 1926 gubernatorial election, and some national party leaders suggested that he run for president in 1928, but Hughes declined to seek public office. After the 1928 Republican National Convention nominated Herbert Hoover, Hughes gave Hoover his full support and campaigned for him across the United States. Hoover won the election in a landslide and asked Hughes to serve as his Secretary of State, but Hughes declined the offer to keep his commitment to serve as a judge on the Permanent Court of International Justice.\nJudge of the Permanent Court of International Justice.\nHughes served on the Permanent Court of International Justice from 1928 until 1930.\nChief Justice.\nRejoining the Supreme Court.\nOn February 3, 1930, President Hoover nominated Hughes to succeed Chief Justice Taft, who was gravely ill. Though many had expected Hoover to elevate his close friend, Associate Justice Harlan Stone, Hughes was the top choice of Taft and Attorney General William D. Mitchell. Though Hughes had compiled a progressive record during his tenure as an Associate Justice, by 1930 Taft believed that Hughes would be a consistent conservative on the court. The nomination faced resistance from progressive Republicans such as senators George W. Norris and William E. Borah, who were concerned that Hughes would be overly friendly to big business after working as a corporate lawyer. Many of those progressives, as well some Southern states' rights advocates, were outraged by the Taft Court's tendency to strike down state and federal legislation on the basis of the doctrine of substantive due process and feared that a Hughes Court would emulate the Taft Court. Adherents of the substantive due process doctrine held that economic regulations such as restrictions on child labor and minimum wages violated freedom of contract, which, they argued, could not be abridged by federal and state laws because of the Fifth Amendment and the Fourteenth Amendment.\nThe Senate Judiciary Committee held no hearings, and voted to favorably report on Hughes's nomination by a 10\u20132 vote on February 10, 1930. On February 13, 1930, the Senate voted 31\u201349 against sending his nomination back to committee. After a brief but bitter confirmation battle, Hughes was confirmed by the Senate on February 13, 1930, in a 52\u201326 vote, and he took his judicial oath of office on February 24, 1930. Hughes's son, Charles Jr., was subsequently forced to resign as Solicitor General after his father took office as Chief Justice. Hughes quickly emerged as a leader of the Court, earning the admiration of his fellow justices for his intelligence, energy, and strong understanding of the law. Shortly after Hughes was confirmed, Hoover nominated federal judge John J. Parker to succeed deceased Associate Justice Edward Terry Sanford. The Senate rejected Parker, whose earlier rulings had alienated labor unions and the NAACP, but confirmed Hoover's second nominee, Owen Roberts. In early 1932, the other justices asked Hughes to request the resignation of Oliver Wendell Holmes, whose health had declined as he entered his nineties. Hughes privately asked his old friend to retire, and Holmes immediately sent a letter of resignation to President Hoover. To replace Holmes, Hoover nominated Benjamin N. Cardozo, who quickly won confirmation.\nThe early Hughes Court was divided between the conservative \"Four Horsemen\" and the liberal \"Three Musketeers\". The primary difference between these two blocs was that the Four Horsemen embraced the substantive due process doctrine, but the liberals, including Louis Brandeis, advocated for judicial restraint, or deference to legislative bodies. Hughes and Roberts were the swing justices between the two blocs for much of the 1930s.In one of the first major cases of his tenure, Hughes joined with Roberts and the Three Musketeers to strike down a piece of state legislation in the 1931 landmark case of \"Near v. Minnesota\". In his majority opinion, Hughes held that the First Amendment barred states from violating freedom of the press. Hughes also wrote the majority opinion in \"Stromberg v. California\", which represented the first time the Supreme Court struck down a state law on the basis of the incorporation of the Bill of Rights. In another early case, \"O'Gorman &amp; Young, Inc. v. Hartford Fire Insurance Co.\", Hughes and Roberts joined with the liberal bloc in upholding a state regulation that limited commissions for the sale of fire insurance.\nRoosevelt takes office.\nDuring Hoover's presidency, the country plunged into the Great Depression. As the country faced an ongoing economic calamity, Franklin D. Roosevelt decisively defeated Hoover in the 1932 presidential election. Responding to the Great Depression, Roosevelt passed a bevy of domestic legislation as part of his New Deal domestic program, and the response to the New Deal became one of the key issues facing the Hughes Court. In the Gold Clause Cases, a series of cases that presented some of the first major tests of New Deal laws, the Hughes Court upheld the voiding of the \"gold clauses\" in private and public contracts that was favored by the Roosevelt administration. Roosevelt, who had expected the Supreme Court to rule adversely to his administration's position, was elated by the outcome, writing that \"as a lawyer it seems to me that the Supreme Court has at last definitely put human values ahead of the 'pound of flesh' called for by a contract.\" The Hughes Court also continued to adjudicate major cases concerning the states. In the 1934 case of \"Home Building &amp; Loan Ass'n v. Blaisdell\", Hughes and Roberts joined the Three Musketeers in upholding a Minnesota law that established a moratorium on mortgage payments. Hughes's majority opinion in that case stated that \"while an emergency does not create power, an emergency may furnish the occasion for the exercise of power.\"Beginning with the 1935 case of \"Railroad Retirement Board v. Alton Railroad Co.\", Roberts started siding with the Four Horsemen, creating a majority bloc that struck down New Deal laws. The court held that Congress had, in passing an act that provided a mandatory retirement and pension system for railroad industry workers, violated due process and exceeded the regulatory powers granted to it by the Commerce Clause. Hughes strongly criticized Roberts's majority opinion in his dissent, writing that \"the power committed to Congress to govern interstate commerce does not require that its government should be wise, much less that it be perfect. The power implies a broad discretion.\" Nonetheless, in May 1935, the Supreme Court unanimously struck down three New Deal laws. Writing the majority opinion in \"A.L.A. Schechter Poultry Corp. v. United States\", Hughes held that Roosevelt's National Industrial Recovery Act of 1933 was doubly unconstitutional, falling afoul of both the Commerce Clause and the nondelegation doctrine.\nIn the 1936 case of \"United States v. Butler\", Hughes surprised many observers by joining with Roberts and the Four Horsemen in striking down the Agricultural Adjustment Act. In doing so, the court dismantled the Agricultural Adjustment Administration, the major New Deal agricultural program. In another 1936 case, \"Carter v. Carter Coal Co.\", the Supreme Court struck down the Guffey Coal Act, which regulated the bituminous coal industry. Hughes wrote a concurring opinion in \"Carter\" in which he agreed with the majority's holding that Congress could not use its Commerce Clause powers to \"regulate activities and relations within the states which affect interstate commerce only indirectly.\" In the final case of the 1936 term, \"Morehead v. New York ex rel. Tipaldo\", Roberts joined with the Four Horsemen in striking down New York's minimum wage law. President Roosevelt had held up the New York minimum wage law as a model for other states to follow, and many Republicans as well as Democrats attacked the decision for interfering with the states. In December 1936, the court handed down its near-unanimous opinion in \"United States v. Curtiss-Wright Export Corp.\", upholding a law that granted the president the power to place an arms embargo on Bolivia and Paraguay. Justice Sutherland's majority opinion, which Hughes joined, explained that the Constitution had granted the president broad powers to conduct foreign policy.\nJudicial Procedures Reform Bill of 1937.\nRoosevelt won re-election in a landslide in the 1936 presidential election, and congressional Democrats grew their majorities in both houses of Congress. As the Supreme Court had already struck down both the National Industrial Recovery Act and the Agricultural Adjustment Act, the president feared that the court would next strike down other key New Deal laws, including the National Labor Relations Act of 1935 (also known as the Wagner Act) and the Social Security Act. In early 1937, Roosevelt proposed to increase the number of Supreme Court seats through the Judicial Procedures Reform Bill of 1937 (also known as the \"court-packing plan\"). Roosevelt argued that the bill was necessary because Supreme Court justices were unable to meet their case load. With large Democratic majorities in both houses of Congress, Roosevelt's bill had a strong chance of passage in early 1937. However, the bill was poorly received by the public, as many saw the bill as power grab or as an attack on a sacrosanct institution. Hughes worked behind the scenes to defeat the effort, rushing important New Deal legislation through the Supreme Court in an effort to quickly uphold the constitutionality of the laws. He also sent a letter to Senator Burton K. Wheeler, asserting that the Supreme Court was fully capable of handling its case load. Hughes's letter had a powerful impact in discrediting Roosevelt's argument about the practical need for more Supreme Court justices.\nWhile the debate over the court-packing plan continued, the Supreme Court upheld, in a 5\u20134 vote, the state of Washington's minimum wage law in the case of \"West Coast Hotel Co. v. Parrish\". Joined by the Three Musketeers and Roberts, Hughes wrote the majority opinion, which overturned the 1923 case of \"Adkins v. Children's Hospital\". In his majority opinion, Hughes wrote that the \"Constitution does not speak of freedom of contract\", and further held that the Washington legislature \"was entitled to adopt measures to reduce the evils of the 'sweating system,' the exploiting of workers at wages so low as to be insufficient to meet the bare cost of living.\" Because Roberts had previously sided with the four conservative justices in \"Tipaldo\", a similar case, it was widely perceived that Roberts agreed to uphold the constitutionality of minimum wage as a result of the pressure that was put on the Supreme Court by the court-packing plan (a theory referred to as \"the switch in time that saved nine\"). However, Hughes and Roberts both later indicated that Roberts had committed to changing his judicial stance on state minimum wage law months before Roosevelt announced his court-packing plan. Roberts had voted to grant \"certiorari\" to hear the \"Parrish\" case even before the 1936 presidential election, and oral arguments for the case had taken place in late 1936. In an initial conference vote held on December 19, 1936, Roberts had voted to uphold the law. Scholars continue to debate why Roberts essentially switched his vote with regards to state minimum wage laws, but Hughes may have played an important role in influencing Roberts to uphold the law.\nWeeks after the court handed down its decision in \"Parrish\", Hughes wrote for the majority again in \"NLRB v. Jones &amp; Laughlin Steel Corp.\" Joined by Roberts and the Three Musketeers, Hughes upheld the constitutionality of the Wagner Act. The Wagner Act case marked a turning point for the Supreme Court, as the court began a pattern of upholding New Deal laws. Later in 1937, the court upheld both the old age benefits and the taxation system established by the Social Security Act. Meanwhile, conservative Associate Justice Willis Van Devanter announced his retirement, undercutting Roosevelt's arguments for the necessity of the Judicial Procedures Reform Bill of 1937. By the end of the year, the court-packing plan had died in the Senate, and Roosevelt had been dealt a serious political wound that emboldened the conservative coalition of Southern Democrats and Republicans. However, throughout 1937, Hughes had presided over a massive shift in jurisprudence that marked the end of the Lochner era, a period during which the Supreme Court had frequently struck down state and federal economic regulations. Hugo Black, Roosevelt's nominee to succeed Van Devanter, was confirmed by the Senate in August 1937. He was joined by Stanley Forman Reed, who succeeded Sutherland, the following year, leaving pro-New Deal liberals with a majority on the Supreme Court.\nLater tenure.\nAfter 1937, the Hughes Court continued to uphold economic regulations, with McReynolds and Butler often being the lone dissenters. The liberal bloc was strengthened even further in 1940, when Butler was succeeded by another Roosevelt appointee, Frank Murphy. In the case of \"United States v. Carolene Products Co.\", Justice Stone's majority opinion articulated a broad theory of deference to economic regulations. \"Carolene Products\" established that the Supreme Court would conduct a \"rational basis review\" of economic regulations, meaning that the Court would only strike down a regulation if legislators lacked a \"rational basis\" for passing the regulation. The Supreme Court showed that it would defer to state legislators in the cases of \"Madden v. Kentucky\" and \"Olsen v. Nebraska\". Hughes joined the majority in another case, \"United States v. Darby Lumber Co.\", which upheld the Fair Labor Standards Act of 1938.\nThe Hughes Court also faced several civil rights cases. Hughes wrote the majority opinion in \"Missouri ex rel. Gaines v. Canada\", which required the state of Missouri to either integrate its law school or establish a separate law school for African-Americans. He joined and helped arrange unanimous support for Black's majority opinion in \"Chambers v. Florida\", which overturned the conviction of a defendant who had been coerced into confessing a crime. In the 1940 case of \"Minersville School District v. Gobitis\", Hughes joined the majority decision, which held that public schools could require students to salute the American flag despite the students' religious objections to these practices.\nHughes began to consider retiring in 1940, partly due to the declining health of his wife. In June 1941, he informed Roosevelt of his impending retirement. Hughes suggested that Roosevelt elevate Stone to the position of Chief Justice, a suggestion that Roosevelt accepted. Hughes retired in 1941, and Stone was confirmed as the new Chief Justice, beginning the Stone Court.\nRetirement and death.\nDuring his retirement, Hughes generally refrained from re-entering public life or giving advice on public policy, but he agreed to review the United Nations Charter for Secretary of State Cordell Hull, and recommended that President Harry S. Truman appoint Fred M. Vinson as Chief Justice after the death of Stone. He lived in New York City with his wife, Antoinette, until she died in December 1945. On August 27, 1948, at the age of 86, Hughes died in what is now the Tiffany Cottage of the Wianno Club in Osterville, Massachusetts. When he died, Hughes was the last living Justice to have served on the White Court.\nHe is interred at Woodlawn Cemetery in the Bronx, New York City.\nLegacy.\nIn the evaluation of historian Dexter Perkins, in domestic politics:\nIn the consensus view of scholars, Hughes as a diplomat was:\nHughes has been honored in a variety of ways, including in the names of several schools, rooms, and events. Other things named for Hughes include the Hughes Range in Antarctica. On April 11, 1962, the 100th anniversary of Hughes's birth, the U.S. Post Office issued a commemorative stamp in his honor. The Charles Evans Hughes House, now the Burmese ambassador's residence, in Washington, D.C., was declared a National Historic Landmark in 1972.\nJudge Learned Hand once observed that Hughes was the greatest lawyer he had ever known, \"except that his son (Charles Evans Hughes Jr.) was even greater.\""}
{"id": "7526", "revid": "16861812", "url": "https://en.wikipedia.org/wiki?curid=7526", "title": "Caustic soda", "text": ""}
{"id": "7527", "revid": "1197008", "url": "https://en.wikipedia.org/wiki?curid=7527", "title": "Concept album", "text": "A concept album is an album whose tracks hold a larger purpose or meaning collectively than they do individually. This is typically achieved through a single central narrative or theme, which can be instrumental, compositional, or lyrical. Sometimes the term is applied to albums considered to be of \"uniform excellence\" rather than an LP with an explicit musical or lyrical motif. There is no consensus among music critics as to the specific criteria for what a \"concept album\" is.\nThe format originates with folk singer Woody Guthrie's \"Dust Bowl Ballads\" (1940) and was subsequently popularized by traditional pop singer Frank Sinatra's 1940s\u201350s string of albums, although the term is more often associated with rock music. In the 1960s several well-regarded concept albums were released by various rock bands, which eventually led to the invention of progressive rock and rock opera.\nDefinitions.\nThere is no clear definition of a \"concept album\". Fiona Sturges of \"The Independent\" stated that the concept album \"was originally defined as a long-player where the songs were based on one dramatic idea \u2013 but the term is subjective.\" A precursor to this type of album can be found in the 19th-century song cycle, which ran into similar difficulties in classification. The extremely broad definitions of a \"concept album\" could potentially encompass all soundtracks, compilations, cast recordings, greatest hits albums, tribute albums, Christmas albums, and live albums.\nThe most common definitions refer to an expanded approach to a rock album (as a story, play, or opus), or a project that either revolves around a specific theme or a collection of related materials. AllMusic writes, \"A concept album could be a collection of songs by an individual songwriter or a particular theme \u2013 these are the concept LPs that reigned in the '50s ... the phrase 'concept album' is inextricably tied to the late 1960s, when rock &amp; rollers began stretching the limits of their art form.\"&lt;ref name=\"AllMusic/Concept albums\"&gt;&lt;/ref&gt; Author Jim Cullen describes it as \"a collection of discrete but thematically unified songs whose whole is greater than the sum of its parts ... sometimes [erroneously] assumed to be a product of the rock era.\" Author Roy Shuker defines concept albums and rock operas as albums that are \"unified by a theme, which can be instrumental, compositional, narrative, or lyrical. ... In this form, the album changed from a collection of heterogeneous songs into a narrative work with a single theme, in which individual songs segue into one another.\"\nSpeaking of concepts in albums during the 1970s, Robert Christgau wrote in \"\" (1981), because \"overall impression\" of an album matters, \"concept intensifies the impact\" of certain albums \"in more or less the way \"Sgt. Pepper\" intended\", as well as \"a species of concept that pushes a rhythmically unrelenting album like \"The Wild Magnolias\" or a vocally irresistible one like Shirley Brown's \"Woman to Woman\", to a deeper level of significance.\"\nHistory.\n1940s\u201350s: Origins.\nIn the 2016 BBC documentary \"When Pop Went Epic: The Crazy World of the Concept Album\", it is suggested that the first concept album is Woody Guthrie's 1940 album \"Dust Bowl Ballads\". \"The Independent\" regards it as \"perhaps\" one of the first concept albums, consisting exclusively of semi-autobiographical songs about the hardships of American migrant labourers during the 1930s. In the late 1940s, the LP record was introduced, with space age pop composers producing concept albums soon after. Themes included exploring wild life and dealing with emotions, with some albums meant to be played while dining or relaxing. This was accompanied in the mid-1950s with the invention of the gatefold, which allowed room for liner notes to explain the concept.\nSinger Frank Sinatra recorded several concept albums prior to the 1960s rock era, including \"In the Wee Small Hours\" (1955) and \"Frank Sinatra Sings for Only the Lonely\" (1958). Sinatra is occasionally credited as the inventor of the concept album, beginning with \"The Voice of Frank Sinatra\" (1946), which led to similar work by Bing Crosby. According to biographer Will Friedwald, Sinatra \"sequenced the songs so that the lyrics created a flow from track to track, affording an impression of a narrative, as in musical comedy or opera. ... [He was the] first pop singer to bring a consciously artistic attitude to recording.\"\nSinger/pianist Nat \"King\" Cole (who, along with Sinatra, often collaborated with arranger Nelson Riddle during this era) was also an early pioneer of concept albums, as with his \"Wild Is Love\" (1960), a suite of original songs about a man's search for love.\n1960s: Rock and country music.\nIn the early 1960s, concept albums began featuring highly in American country music, but the fact went largely unacknowledged by rock/pop fans and critics, who would only begin noting \"concept albums\" as a phenomenon later in the decade, when albums became closely aligned with countercultural ideology, resulting in a recognised \"album era\" and the introduction of the rock concept album. The author Carys Wyn Jones writes that the Beach Boys' \"Pet Sounds\" (1966), the Beatles' \"Revolver\" (1966) and \"Sgt. Pepper's Lonely Hearts Club Band\" (1967), and the Who's \"Tommy\" (1969) are variously cited as \"the first concept album\", usually for their \"uniform excellence rather than some lyrical theme or underlying musical motif\".\nOther records have been claimed as \"early\" or \"first\" concept albums. The Beach Boys' first six albums, released over 1962\u201364, featured collections of songs unified respectively by a central concept, such as cars, surfing, and teenage lifestyles. Writing in \"101 Albums That Changed Popular Music\", Chris Smith commented: \"Though albums such as Frank Sinatra's 1955 \"In the Wee Small Hours\" and Marty Robbins' 1959 \"Gunfighter Ballads and Trail Songs\" had already introduced concept albums, [the Beach Boys' 1963 album] \"Little Deuce Coupe\" was the first to comprise almost all original material rather than standard covers.\" Music historian Larry Starr, who identifies the Beach Boys' 1964 releases \"Shut Down Volume 2\" and \"All Summer Long\" as heralding the album era, cites \"Pet Sounds\" as the first rock concept album on the basis that it had been \"conceived as an integrated whole, with interrelated songs arranged in a deliberate sequence.\"\n\"The 100 Greatest Bands of All Time\" (2015) states that the Ventures \"pioneered the idea of the rock concept album years before the genre is generally acknowledged to have been born\". Writing in his \"Concise Dictionary of Popular Culture\", Marcel Danesi identifies the Beatles' \"Rubber Soul\" (1965) and the Who's \"The Who Sell Out\" (1967) as other examples of early concept albums. Brian Boyd of \"The Irish Times\" names the Kinks' \"Face to Face\" (1966) as the first concept album: \"Written entirely by Ray Davies, the songs were supposed to be linked by pieces of music, so that the album would play without gaps, but the record company baulked at such radicalism. It's not one of the band's finest works, but it did have an impact.\"\n\"Popular consensus\" for the first rock concept album, according to AllMusic, favours \"Sgt. Pepper\". According to music critic Tim Riley, \"Strictly speaking, the Mothers of Invention's \"Freak Out!\" [1966] has claims as the first 'concept album', but \"Sgt. Pepper\" was the record that made that idea convincing to most ears.\" Musicologist Allan Moore says that \"Even though previous albums had set a unified mood (notably Sinatra's \"Songs for Swingin' Lovers!\"), it was on the basis of the influence of \"Sgt. Pepper\" that the penchant for the concept album was born.\" Adding to \"Sgt. Pepper\"s claim, the artwork reinforced its central theme by depicting the four Beatles in uniform as members of the Sgt. Pepper band, while the record omitted the gaps that usually separated album tracks. Music critic and journalist Neil Slaven stated that Frank Zappa's \"Absolutely Free\", released the same day as \"Sgt. Pepper\", was \"very much a concept album, but The Beatles effortlessly stole his thunder\", and subsequently \"Sgt. Pepper\" was hailed as \"perhaps the first 'concept album' even though the songs were unrelated.\"\n1960s\u201370s: Rock operas and progressive rock.\nAuthor Bill Martin relates the assumed concept albums of the 1960s to progressive rock:\n\"Popmatters\" Sarah Zupko notes that while the Who's \"Tommy\" is \"popularly thought of as the first rock opera, an extra-long concept album with characters, a consistent storyline, and a slight bit of pomposity\", it is preceded by the shorter concept albums \"Ogdens' Nut Gone Flake\" (Small Faces, 1968) and \"S.F. Sorrow\" (The Pretty Things, 1968). Author Jim Cullen states: \"The concept album reached its apogee in the 1970s in ambitious records like Pink Floyd's \"Dark Side of the Moon\" (1973) and the Eagles' \"Hotel California\" (1976).\" In 2015, \"Rolling Stone\" ranked \"Dark Side of the Moon\" at number one among the 50 greatest progressive rock albums of all time, also noting the LP's stature as the second-best-selling album of all time. Pink Floyd's \"The Wall\" (1979), a semi-autobiographical story modeled after the band's Roger Waters and former member Syd Barrett, is one of the most famous concept albums by any artist. In addition to \"The Wall\", Danesi highlights Genesis' \"The Lamb Lies Down on Broadway\" (1974) and Frank Zappa's \"Joe's Garage\" (1979) as other culturally significant concept albums.\nAccording to author Edward Macan, concept albums as a recurrent theme in progressive rock was directly inspired by the counterculture associated with \"the proto-progressive bands of the 1960s\", observing: \"the consistent use of lengthy forms such as the programmatic song cycle of the concept album and the multimovement suite underscores the hippies' new, drug-induced conception of time.\" Progressive soul musicians inspired by this approach conceived concept albums during this era reflecting themes and concerns of the African-American experience, including Marvin Gaye (1971's \"What's Going On\") and George Clinton (the 1975 Parliament album \"Mothership Connection\" and \"Dope Dogs\").\n1980s\u2013present: Decline and return to popularity.\nWith the emergence of MTV as a music video network which valued singles over albums, concept albums became less dominant in the 1980s. Some artists, however, still released concept albums and experienced success in the 1990s and 2000s. \"NME\"s Emily Barker cites Green Day's \"American Idiot\" (2004) as one of the \"more notable\" examples, having brought the concept album back to high-charting positions. My Chemical Romance\u2019s \"The Black Parade\" (2006) is another example of a modern concept album. Dorian Lynskey, writing for \"GQ\", noted a resurgence of concept albums in the 2010s due to streaming: \"This is happening not in spite of the rise of streaming and playlists, but because of it. Threatened with redundancy in the digital era, albums have fought back by becoming more album-like.\" Cucchiara argues that concept albums should also describe \"this new generation of concept albums, for one key reason. This is because the unison between the songs on a particular album has now been expanded into a broader field of visual and artistic design and marketing strategies that play into the themes and stories that form the album.\"\nTowards the end of the 80s, however, as heavy metal suited a fairly niche crowd, a few heavy metal artists began producing concept albums, particularly among the more progressive groups. King Diamond's \"Abigail\" and Savatage's \"Hall of the Mountain King\", both released in 1987, stand some of the earliest examples of concept albums produced by a heavy metal artist. A year later, Iron Maiden's, \"Seventh Son of a Seventh Son\", released in 1988, would become one of the most notable examples of a heavy metal concept album at the time. Around this time, progressive metal began taking form with artists such as Queensr\u00ffche, Fates Warning, and Savatage. Shortly later in 1988, Queensr\u00ffche would release ', which would be considered one of the first progressive metal albums, and was also a concept album. Thus it could be argued that from the genre's inception, progressive metal has been a hotspot for concept albums, like its rock counterpart. Other notable progressive metal concept albums are Dream Theater's ', Opeth's \"Still Life\", and Orphaned Land's \"Mabool\".\nIn the 21st century, the field of classical music has adopted the idea of the concept album, citing such historical examples as Schubert's \"Winterreise\" and Schumann's \"Liederkreis\" as prototypes for contemporary composers and musicians. Classical composers and performers increasingly adopt production and marketing strategies that unify otherwise disparate works into concept albums or concerts. Since 2019, the classical music magazine \"Gramophone\" has included a special category for \"concept album\" in its annual recordings of the year awards, to celebrate \"albums where a creative mind has curated something visionary, a programme whose whole speaks more powerfully than its parts. A thought-through journey, which compels to be heard in one sitting.\"\nIn a year-ending essay on the album in 2019, Ann Powers wrote for \"Slate\" that the year found the medium in a state of flux. In her observation, many recording artists revitalized the concept album around autobiographical narratives and personal themes, such as intimacy, intersectionality, African-American life, boundaries among women, and grief associated with death. She cited such albums as Brittany Howard's \"Jaime\", Raphael Saadiq's \"Jimmy Lee\", Jamila Woods' \"Legacy! Legacy!\", Rapsody's \"Eve\", Jenny Lewis' \"On the Line\", Julia Jacklin's \"Crushing\", Joe Henry's \"The Gospel According to Water\", and Nick Cave's \"Ghosteen\". \"\", a series of concept albums retelling \"The Odyssey\", arose to massive popularity, with its first release in January 2023 surpassing three million streams within its first week of release and the musical remaining popular as subsequent \"saga\" albums were released."}
{"id": "7530", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=7530", "title": "Cro-hook", "text": "The cro-hook is a special double-ended crochet hook used to make double-sided crochet. \nIt employs the use of a long double-ended hook, which permits the maker to work stitches on or off from either end. Because the hook has two ends, two alternating colors of thread can be used simultaneously and freely interchanged, working loops over the hook. Crafts using a double-ended hook are commercially marketed as Cro-hook and Crochenit. Cro-hook is a variation of Tunisian crochet and also shows similarities with the Afghan stitch used to make Afghan scarves, but the fabric is typically softer with greater elasticity."}
{"id": "7531", "revid": "21621158", "url": "https://en.wikipedia.org/wiki?curid=7531", "title": "Clavichord", "text": "The clavichord is a stringed rectangular keyboard instrument that was used largely in the Late Middle Ages, through the Renaissance, Baroque and Classical eras.\nHistorically, it was mostly used as a practice instrument and as an aid to composition, not being loud enough for larger performances. The clavichord produces sound by striking brass or iron strings with small metal blades called tangents. Vibrations are transmitted through the bridge(s) to the soundboard.\nEtymology.\nThe name is derived from the Latin word \"clavis\", meaning \"key\" (associated with more common \"clavus\", meaning \"nail, rod, etc.\") and \"chorda\" (from Greek \u03c7\u03bf\u03c1\u03b4\u03ae) meaning \"string, especially of a musical instrument\". An analogous name is used in other European languages (It. \"clavicordio\", \"clavicordo\"; Fr. \"clavicorde\"; Germ. \"Klavichord\"; Lat. \"clavicordium\"; Port. \"clavic\u00f3rdio\"; Sp. \"clavicordio\"). Many languages also have another name derived from Latin \"manus\", meaning \"hand\" (It. \"manicordo\"; Fr. \"manicorde\", \"manicordion\"; Sp. \"manicordio\", \"manucordio\"). Other names refer to the monochord-like nature of a fully fretted clavichord (It. \"monacordo\" or \"monocordo\"; Sp. \"monacordio\"). Italian also used \"sordino\", a reference to its quiet sound (sordino usually designates a mute).\nHistory and use.\nThe clavichord was invented in the early fourteenth century. In 1404, the German poem \"\" mentions the terms \"clavicimbalum\" (a term used mainly for the harpsichord) and \"clavichordium\", designating them as the best instruments to accompany melodies.\nOne of the earliest references to the clavichord in England occurs in the privy-purse expenses of Elizabeth of York, queen of Henry VII, in an entry dated August 1502:\nItem. The same day, Hugh Denys for money by him delivered to a stranger that gave the queen a payre of clavycordes. In crowns form his reward iiii libres.\nThe clavichord was very popular from the 16th century to the 18th century, but mainly flourished in German-speaking lands, Scandinavia, and the Iberian Peninsula in the latter part of this period. It had fallen out of use by 1850. In the late 1890s, Arnold Dolmetsch revived clavichord construction and Violet Gordon-Woodhouse, among others, helped to popularize the instrument. Although most of the instruments built before the 1730s were small (four octaves, four feet long), the latest instruments were built up to seven feet long with a six octave range. \nIt was a preferred instrument in the 18th century due to its unique expressive features, size, elegance, and affordability.\nDue to its lower cost compared to other instruments, the clavichord was accessible, making it the first choice for individuals who wanted to learn the keyboard. Composers such as Wolfgang Amadeus Mozart (1756\u20131791), used to bring the clavichord with them on their travels to practice.\nDuring the Mozart family's visit to Augsburg, they had the chance to visit the outstanding German keyboard instruments maker, Johann Andreas Stein (1728\u20131792), and purchased a clavichord from him. In a letter to his friend, Leopold Mozart (1719\u20131787) described it as \n\"A pretty little keyboard instrument, which does us good service for practicing on during our travels.\"\nUntil electronic amplification in the twentieth century, it was impossible to use the quiet clavichord in anything but a small room. However, during the clavichord's heyday, evenings of music-making in the home formed the largest part of people's musical experiences. In the home the clavichord was the ideal instrument for solo keyboard music and instrumental accompaniment.Organists also were known to practice in their homes on pedal clavichords.\nToday clavichords are played primarily by Renaissance, Baroque, and Classical music enthusiasts. They attract many interested buyers, and are manufactured worldwide. There are now numerous clavichord societies around the world, and some 400 recordings of the instrument have been made in the past 70 years. Leading modern exponents of the instrument have included Christopher Hogwood and Thurston Dart.\nModern music.\nThe clavichord has also gained attention in other genres of music, in the form of the Clavinet, which is a solid body electric clavichord with magnetic pickups that plug into an amp. Stevie Wonder uses a Clavinet in many of his songs, such as \"Superstition\" and \"Higher Ground\". A Clavinet played through an instrument amplifier with guitar effect pedals is often associated with funky, disco-infused 1970s rock.\nGuy Sigsworth has played clavichord in a modern setting with Bj\u00f6rk, notably on the studio recording of \"All Is Full of Love\". Bj\u00f6rk also made extensive use of and even played the instrument herself on the song \"My Juvenile\" of her 2007 album \"Volta\".\nTori Amos uses the instrument on \"Caught a Lite Sneeze\" from the album \"Boys for Pele\" and on the song \"Smokey Joe\" from her 2007 album \"American Doll Posse\". Amos also featured her use of the Clavinet on her 2004 recording \"Not David Bowie\", released as part of her 2006 box set, \"\".\nIn 1976 Oscar Peterson played (with Joe Pass on acoustic guitar) songs from \"Porgy And Bess\" on the clavichord. Keith Jarrett also recorded an album titled \"Book of Ways\" (1986) in which he plays a series of clavichord improvisations. The Beatles' \"For No One\" (1966) features Paul McCartney playing the clavichord. Rick Wakeman plays the Clavinet in the track \"The Battle\" from the album \"Journey to the Centre of the Earth\".\nStructure and action.\nIn the clavichord, strings run transversely from the hitchpin rail at the left-hand end to tuning pegs on the right. Towards the right end they pass over a curved wooden bridge. The action is simple, with the keys being levers with a small brass tangent, a small piece of metal similar in shape and size to the head of a flat-bladed screwdriver, at the far end. The strings, which are usually of brass, or else a combination of brass and iron, are usually arranged in pairs, like a lute or mandolin. When the key is pressed, the tangent strikes the strings above, causing them to sound in a similar fashion to the \"hammering\" technique on a guitar. Unlike in a piano action, the tangent does not rebound from the string; rather, it stays in contact with the string as long as the key is held, acting as both the nut and as the initiator of sound. The volume of the note can be changed by striking harder or softer, and the pitch can also be affected by varying the force of the tangent against the string (known as \"Bebung\"). When the key is released, the tangent loses contact with the string and the vibration of the string is silenced by strips of damping cloth.\nThe action of the clavichord is unique among all keyboard instruments in that one part of the action simultaneously initiates the sound vibration while at the same time defining the endpoint of the vibrating string, and thus its pitch. Because of this intimate contact between the player's hand and the production of sound, the clavichord has been referred to as the most intimate of keyboard instruments. Despite its many (serious) limitations, including extremely low volume, it has considerable expressive power, the player being able to control attack, duration, and volume, and even provide certain subtle effects of swelling of tone and a type of vibrato unique to the clavichord.\nFretting.\nSince the string vibrates from the bridge only as far as the tangent, multiple keys with multiple tangents can be assigned to the same string. This is called \"fretting\". Early clavichords frequently had many notes played on each string, even going so far as the keyed monochord\u2014an instrument with only one string\u2014though most clavichords were triple- or double-fretted. Since only one note can be played at a time on each string, the fretting pattern is generally chosen so that notes rarely heard together (such as C and C) share a string pair. The advantages of this system compared with unfretted instruments (see below) include relative ease of tuning (with around half as many strings to keep in tune), greater volume (though still not really enough for use in chamber music), and a clearer, more direct sound. Among the disadvantages: temperament could not be re-set without bending the tangents; and playing required a further refinement of touch, since notes sharing a single string played in quick succession had to be slightly separated to avoid a disagreeable deadening of the sound, potentially disturbing a legato line.\nSome clavichords have been built with a single pair of strings for each note. The first known reference to one was by Johann Speth in 1693 and the earliest such extant signed and dated clavichord was built in 1716 by Johann Michael Heinitz. Such instruments are referred to as \"unfretted\" whereas instruments using the same strings for several notes are called \"fretted\". Among the advantages to unfretted instruments are flexibility in tuning (the temperament can be easily altered) and the ability to play any music exactly as written without concern for \"bad\" notes. Disadvantages include a smaller volume, even though many or most unfretted instruments tend to be significantly larger than fretted instruments; and \"many\" more strings to keep in tune. Unfretted instruments tend to have a sweeter, less incisive tone due to the greater load on the bridge resulting from the greater number of strings, though the large, late (early 19th century) Swedish clavichords tend to be the loudest of any of the historic clavichords.\nPedal clavichord.\nWhile clavichords were typically single manual instruments, they could be stacked, one clavichord on top of another, to provide multiple keyboards. With the addition of a pedal clavichord, which included a pedal keyboard for the lower notes, a clavichord could be used to practice organ repertoire. Most often, the addition of a pedal keyboard only involved connecting the keys of the pedalboard to the lower notes on the manual clavichord using string so the lower notes on the manual instrument could be operated by the feet. In the era of pipe organs, which used man-powered bellows that required several people to operate, and of churches only heated during church services if at all, organists used pedal harpsichords and pedal clavichords as practice instruments (see also: pedal piano). There is speculation that some works written for organ may have been intended for pedal clavichord. An interesting case is made by that Bach's \"Eight Little Preludes and Fugues\", now thought spurious, may actually be authentic. The keyboard writing seems unsuited to organ, but Speerstra argues that they are idiomatic on the pedal clavichord. As Speerstra and also note, the compass of the keyboard parts of Bach's six trio sonatas for organ (BWV 525\u2013530) rarely go below the tenor C, so they could have been played on a single manual pedal clavichord, by moving the left hand down an octave, a customary practice in the 18th century.\nRepertoire.\nMuch of the musical repertoire written for harpsichord and organ from the period circa 1400\u20131800 can be played on the clavichord; however, it does not have enough (unamplified) volume to participate in chamber music, with the possible exception of providing accompaniment to a soft baroque flute, recorder, or single singer. J. S. Bach's son Carl Philipp Emanuel Bach was a great proponent of the instrument, and most of his German contemporaries regarded it as a central keyboard instrument, for performing, teaching, composing and practicing. The fretting of a clavichord provides new problems for some repertoire, but scholarship suggests that these problems are not insurmountable in Bach's Well-Tempered Clavier.\nC. P. E. Bach, one of the leading representatives of the 'Empfindsamer stil' or 'Sensitive Style,' emphasized emotional depth and expressiveness in his compositions. The clavichord was very successful in conveying these characteristics. With its unique sound, touch sensitivity, and ability to convey the most delicate nuances, the clavichord became C. P. E. Bach's most preferred instrument. C. P. E. Bach also used the fortepiano in his compositions, but he was much more interested in the technical features provided by the clavichord. He mentioned this in his book (Versuch \u00fcber die wahre, Art das Clavier zu spielen, Carl Philipp Emanuel Bach, Berlin, 1759.):\n\"Of the many keyboard instruments, many of which are little known because of defects, or because they have not yet been introduced everywhere, there are two which have been most widely acclaimed, the harpsichord and the clavichord. The former is used mainly in louder music, the latter alone. The more recent pianofortes, when they are durable and well built, have many advantages, although their touch must be carefully worked out, a task which is not without difficulties. They sound well by themselves and in small ensembles. Yet, I hold that a good clavichord, except for its weaker tone, shares equally in the attractiveness of the pianoforte and in addition features the vibrato (Bebung) and portato (Tragen der T\u00f6ne) which I produce by means of added pressure after each stroke. It is at the clavichord that a keyboard player may be most exactly evaluated.\"\nAmong recent clavichord recordings, those by Christopher Hogwood (\"The Secret Bach\", \"The Secret Handel\", and \"The Secret Mozart\"), break new ground. In his liner notes, Hogwood pointed out that these composers would typically have played the clavichord in the privacy of their homes. In England, the composer Herbert Howells (1892\u20131983) wrote two significant collections of pieces for clavichord (\"Lambert's Clavichord\" and \"Howells' Clavichord\"), and Stephen Dodgson (1924\u20132013) wrote two clavichord suites.\nIn a note written by Wolfgang Amadeus Mozart's wife, Constanze Mozart (1761\u20131842), found inside Mozart's clavichord, it is mentioned that Mozart composed his works, including The Magic Flute, La Clemenza di Tito, The Requiem, and a Masonic Cantata, on this clavichord. \nHaydn composed the greater part of \"The Creation\", one of his masterpieces, on the clavichord. He used the clavichord to accompany the voice."}
{"id": "7532", "revid": "1862829", "url": "https://en.wikipedia.org/wiki?curid=7532", "title": "Centrifugal force (rotating reference frame)", "text": ""}
{"id": "7534", "revid": "262666", "url": "https://en.wikipedia.org/wiki?curid=7534", "title": "Centripetal force", "text": "A centripetal force (from Latin \"centrum\", \"center\" and \"petere\", \"to seek\") is a force that makes a body follow a curved path. The direction of the centripetal force is always orthogonal to the motion of the body and towards the fixed point of the instantaneous center of curvature of the path. Isaac Newton described it as \"a force by which bodies are drawn or impelled, or in any way tend, towards a point as to a centre\". In Newtonian mechanics, gravity provides the centripetal force causing astronomical orbits.\nOne common example involving centripetal force is the case in which a body moves with uniform speed along a circular path. The centripetal force is directed at right angles to the motion and also along the radius towards the centre of the circular path. The mathematical description was derived in 1659 by the Dutch physicist Christiaan Huygens.\nFormula.\nFrom the kinematics of curved motion it is known that an object moving at tangential speed \"v\" along a path with radius of curvature \"r\" accelerates toward the center of curvature at a rate \nformula_1\nHere, formula_2 is the centripetal acceleration and formula_3 is the difference between the velocity vectors at formula_4 and formula_5.\nBy Newton's second law, the cause of acceleration is a net force acting on the object, which is proportional to its mass \"m\" and its acceleration. The force, usually referred to as a \"centripetal force\", has a magnitude\nformula_6\nand is, like centripetal acceleration, directed toward the center of curvature of the object's trajectory.\nDerivation.\nThe centripetal acceleration can be inferred from the diagram of the velocity vectors at two instances. In the case of uniform circular motion the velocities have constant magnitude. Because each one is perpendicular to its respective position vector, simple vector subtraction implies two similar isosceles triangles with congruent angles \u2013 one comprising a base of formula_3 and a leg length of formula_8, and the other a base of formula_9 (position vector difference) and a leg length of formula_10:\nformula_11\nformula_12\nTherefore, formula_13 can be substituted with formula_14:\nformula_15\nThe direction of the force is toward the center of the circle in which the object is moving, or the osculating circle (the circle that best fits the local path of the object, if the path is not circular).\nThe speed in the formula is squared, so twice the speed needs four times the force, at a given radius.\nThis force is also sometimes written in terms of the angular velocity \"\u03c9\" of the object about the center of the circle, related to the tangential velocity by the formula\nformula_16\nso that\nformula_17\nExpressed using the orbital period \"T\" for one revolution of the circle,\nformula_18\nthe equation becomes\nformula_19\nIn particle accelerators, velocity can be very high (close to the speed of light in vacuum) so the same rest mass now exerts greater inertia (relativistic mass) thereby requiring greater force for the same centripetal acceleration, so the equation becomes:\nformula_20\nwhere\nformula_21\nis the Lorentz factor.\nThus the centripetal force is given by:\nformula_22\nwhich is the rate of change of relativistic momentum formula_23.\nSources.\nIn the case of an object that is swinging around on the end of a rope in a horizontal plane, the centripetal force on the object is supplied by the tension of the rope. The rope example is an example involving a 'pull' force. The centripetal force can also be supplied as a 'push' force, such as in the case where the normal reaction of a wall supplies the centripetal force for a wall of death or a Rotor rider.\nNewton's idea of a centripetal force corresponds to what is nowadays referred to as a central force. When a satellite is in orbit around a planet, gravity is considered to be a centripetal force even though in the case of eccentric orbits, the gravitational force is directed towards the focus, and not towards the instantaneous center of curvature.\nAnother example of centripetal force arises in the helix that is traced out when a charged particle moves in a uniform magnetic field in the absence of other external forces. In this case, the magnetic force is the centripetal force that acts towards the helix axis.\nAnalysis of several cases.\nBelow are three examples of increasing complexity, with derivations of the formulas governing velocity and acceleration.\nUniform circular motion.\nUniform circular motion refers to the case of constant rate of rotation. Here are two approaches to describing this case.\nCalculus derivation.\nIn two dimensions, the position vector formula_24, which has magnitude (length) formula_10 and directed at an angle formula_26 above the x-axis, can be expressed in Cartesian coordinates using the unit vectors formula_27 and formula_28:\nformula_29\nThe assumption of uniform circular motion requires three things:\nThe velocity formula_34 and acceleration formula_35 of the motion are the first and second derivatives of position with respect to time:\nformula_36\nformula_37\nformula_38\nThe term in parentheses is the original expression of formula_24 in Cartesian coordinates. Consequently,\nformula_40\nnegative shows that the acceleration is pointed towards the center of the circle (opposite the radius), hence it is called \"centripetal\" (i.e. \"center-seeking\"). While objects naturally follow a straight path (due to inertia), this centripetal acceleration describes the circular motion path caused by a centripetal force.\nDerivation using vectors.\nThe image at right shows the vector relationships for uniform circular motion. The rotation itself is represented by the angular velocity vector \u03a9, which is normal to the plane of the orbit (using the right-hand rule) and has magnitude given by:\nwith \"\u03b8\" the angular position at time \"t\". In this subsection, d\"\u03b8\"/d\"t\" is assumed constant, independent of time. The distance traveled d\u2113 of the particle in time d\"t\" along the circular path is\nwhich, by properties of the vector cross product, has magnitude \"r\"d\"\u03b8\" and is in the direction tangent to the circular path.\nConsequently,\nDifferentiating with respect to time,\nformula_44\nLagrange's formula states:\nformula_45\nApplying Lagrange's formula with the observation that \u03a9 \u2022 r(\"t\") = 0 at all times,\nformula_46\nIn words, the acceleration is pointing directly opposite to the radial displacement r at all times, and has a magnitude:\nformula_47\nwhere vertical bars |...| denote the vector magnitude, which in the case of r(\"t\") is simply the radius \"r\" of the path. This result agrees with the previous section, though the notation is slightly different.\nWhen the rate of rotation is made constant in the analysis of nonuniform circular motion, that analysis agrees with this one.\nA merit of the vector approach is that it is manifestly independent of any coordinate system.\nExample: The banked turn.\nThe upper panel in the image at right shows a ball in circular motion on a banked curve. The curve is banked at an angle \"\u03b8\" from the horizontal, and the surface of the road is considered to be slippery. The objective is to find what angle the bank must have so the ball does not slide off the road. Intuition tells us that, on a flat curve with no banking at all, the ball will simply slide off the road; while with a very steep banking, the ball will slide to the center unless it travels the curve rapidly.\nApart from any acceleration that might occur in the direction of the path, the lower panel of the image above indicates the forces on the ball. There are \"two\" forces; one is the force of gravity vertically downward through the center of mass of the ball \"mg, where \"m\" is the mass of the ball and g is the gravitational acceleration; the second is the upward normal force exerted by the road at a right angle to the road surface \"man. The centripetal force demanded by the curved motion is also shown above. This centripetal force is not a third force applied to the ball, but rather must be provided by the net force on the ball resulting from vector addition of the normal force and the force of gravity. The resultant or net force on the ball found by vector addition of the normal force exerted by the road and vertical force due to gravity must equal the centripetal force dictated by the need to travel a circular path. The curved motion is maintained so long as this net force provides the centripetal force requisite to the motion.\nThe horizontal net force on the ball is the horizontal component of the force from the road, which has magnitude . The vertical component of the force from the road must counteract the gravitational force: , which implies . Substituting into the above formula for yields a horizontal force to be:\nformula_48\nOn the other hand, at velocity |v| on a circular path of radius \"r\", kinematics says that the force needed to turn the ball continuously into the turn is the radially inward centripetal force Fc of magnitude:\nformula_49\nConsequently, the ball is in a stable path when the angle of the road is set to satisfy the condition:\nformula_50\nor,\nformula_51\nAs the angle of bank \"\u03b8\" approaches 90\u00b0, the tangent function approaches infinity, allowing larger values for |v|2/\"r\". In words, this equation states that for greater speeds (bigger |v|) the road must be banked more steeply (a larger value for \"\u03b8\"), and for sharper turns (smaller \"r\") the road also must be banked more steeply, which accords with intuition. When the angle \"\u03b8\" does not satisfy the above condition, the horizontal component of force exerted by the road does not provide the correct centripetal force, and an additional frictional force tangential to the road surface is called upon to provide the difference. If friction cannot do this (that is, the coefficient of friction is exceeded), the ball slides to a different radius where the balance can be realized.\nThese ideas apply to air flight as well. See the FAA pilot's manual.\nNonuniform circular motion.\nAs a generalization of the uniform circular motion case, suppose the angular rate of rotation is not constant. The acceleration now has a tangential component, as shown the image at right. This case is used to demonstrate a derivation strategy based on a polar coordinate system.\nLet r(\"t\") be a vector that describes the position of a point mass as a function of time. Since we are assuming circular motion, let , where \"R\" is a constant (the radius of the circle) and ur is the unit vector pointing from the origin to the point mass. The direction of u\"r\" is described by \"\u03b8\", the angle between the x-axis and the unit vector, measured counterclockwise from the x-axis. The other unit vector for polar coordinates, u\u03b8 is perpendicular to u\"r\" and points in the direction of increasing \"\u03b8\". These polar unit vectors can be expressed in terms of Cartesian unit vectors in the \"x\" and \"y\" directions, denoted formula_52 and formula_53 respectively:\nformula_54 and formula_55\nOne can differentiate to find velocity:\nformula_56\nwhere is the angular velocity .\nThis result for the velocity matches expectations that the velocity should be directed tangentially to the circle, and that the magnitude of the velocity should be . Differentiating again, and noting that\nformula_57\nwe find that the acceleration, a is:\nformula_58\nThus, the radial and tangential components of the acceleration are:\nformula_59 and formula_60\nwhere is the magnitude of the velocity (the speed).\nThese equations express mathematically that, in the case of an object that moves along a circular path with a changing speed, the acceleration of the body may be decomposed into a perpendicular component that changes the direction of motion (the centripetal acceleration), and a parallel, or tangential component, that changes the speed.\nGeneral planar motion.\nPolar coordinates.\nThe above results can be derived perhaps more simply in polar coordinates, and at the same time extended to general motion within a plane, as shown next. Polar coordinates in the plane employ a radial unit vector u\u03c1 and an angular unit vector u\u03b8, as shown above. A particle at position r is described by:\nformula_61\nwhere the notation \"\u03c1\" is used to describe the distance of the path from the origin instead of \"R\" to emphasize that this distance is not fixed, but varies with time. The unit vector u\u03c1 travels with the particle and always points in the same direction as r(\"t\"). Unit vector u\u03b8 also travels with the particle and stays orthogonal to u\u03c1. Thus, u\u03c1 and u\u03b8 form a local Cartesian coordinate system attached to the particle, and tied to the path travelled by the particle. By moving the unit vectors so their tails coincide, as seen in the circle at the left of the image above, it is seen that u\u03c1 and u\u03b8 form a right-angled pair with tips on the unit circle that trace back and forth on the perimeter of this circle with the same angle \"\u03b8\"(\"t\") as r(\"t\").\nWhen the particle moves, its velocity is\nTo evaluate the velocity, the derivative of the unit vector u\u03c1 is needed. Because u\u03c1 is a unit vector, its magnitude is fixed, and it can change only in direction, that is, its change du\u03c1 has a component only perpendicular to u\u03c1. When the trajectory r(\"t\") rotates an amount d\"\u03b8\", u\u03c1, which points in the same direction as r(\"t\"), also rotates by d\"\u03b8\". See image above. Therefore, the change in u\u03c1 is\nor\nIn a similar fashion, the rate of change of u\u03b8 is found. As with u\u03c1, u\u03b8 is a unit vector and can only rotate without changing size. To remain orthogonal to u\u03c1 while the trajectory r(\"t\") rotates an amount d\"\u03b8\", u\u03b8, which is orthogonal to r(\"t\"), also rotates by d\"\u03b8\". See image above. Therefore, the change du\u03b8 is orthogonal to u\u03b8 and proportional to d\"\u03b8\" (see image above):\nThe equation above shows the sign to be negative: to maintain orthogonality, if du\u03c1 is positive with d\"\u03b8\", then du\u03b8 must decrease.\nSubstituting the derivative of u\u03c1 into the expression for velocity:\nTo obtain the acceleration, another time differentiation is done:\nSubstituting the derivatives of u\u03c1 and u\u03b8, the acceleration of the particle is:\nAs a particular example, if the particle moves in a circle of constant radius \"R\", then d\"\u03c1\"/d\"t\" = 0, v = v\u03b8, and:\nformula_69\nwhere formula_70\nThese results agree with those above for nonuniform circular motion. See also the article on non-uniform circular motion. If this acceleration is multiplied by the particle mass, the leading term is the centripetal force and the negative of the second term related to angular acceleration is sometimes called the Euler force.\nFor trajectories other than circular motion, for example, the more general trajectory envisioned in the image above, the instantaneous center of rotation and radius of curvature of the trajectory are related only indirectly to the coordinate system defined by u\u03c1 and u\u03b8 and to the length |r(\"t\")| = \"\u03c1\". Consequently, in the general case, it is not straightforward to disentangle the centripetal and Euler terms from the above general acceleration equation. To deal directly with this issue, local coordinates are preferable, as discussed next.\nLocal coordinates.\nLocal coordinates mean a set of coordinates that travel with the particle, and have orientation determined by the path of the particle. Unit vectors are formed as shown in the image at right, both tangential and normal to the path. This coordinate system sometimes is referred to as \"intrinsic\" or \"path coordinates\" or \"nt-coordinates\", for \"normal-tangential\", referring to these unit vectors. These coordinates are a very special example of a more general concept of local coordinates from the theory of differential forms.\nDistance along the path of the particle is the arc length \"s\", considered to be a known function of time.\nA center of curvature is defined at each position \"s\" located a distance \"\u03c1\" (the radius of curvature) from the curve on a line along the normal un (\"s\"). The required distance \"\u03c1\"(\"s\") at arc length \"s\" is defined in terms of the rate of rotation of the tangent to the curve, which in turn is determined by the path itself. If the orientation of the tangent relative to some starting position is \"\u03b8\"(\"s\"), then \"\u03c1\"(\"s\") is defined by the derivative d\"\u03b8\"/d\"s\":\nThe radius of curvature usually is taken as positive (that is, as an absolute value), while the \"curvature\" \"\u03ba\" is a signed quantity.\nA geometric approach to finding the center of curvature and the radius of curvature uses a limiting process leading to the osculating circle. See image above.\nUsing these coordinates, the motion along the path is viewed as a succession of circular paths of ever-changing center, and at each position \"s\" constitutes non-uniform circular motion at that position with radius \"\u03c1\". The local value of the angular rate of rotation then is given by:\nwith the local speed \"v\" given by:\nAs for the other examples above, because unit vectors cannot change magnitude, their rate of change is always perpendicular to their direction (see the left-hand insert in the image above):\nConsequently, the velocity and acceleration are:\nand using the chain-rule of differentiation:\nIn this local coordinate system, the acceleration resembles the expression for nonuniform circular motion with the local radius \"\u03c1\"(\"s\"), and the centripetal acceleration is identified as the second term.\nExtending this approach to three dimensional space curves leads to the Frenet\u2013Serret formulas.\nAlternative approach.\nLooking at the image above, one might wonder whether adequate account has been taken of the difference in curvature between \"\u03c1\"(\"s\") and \"\u03c1\"(\"s\" + d\"s\") in computing the arc length as d\"s\" = \"\u03c1\"(\"s\")d\"\u03b8\". Reassurance on this point can be found using a more formal approach outlined below. This approach also makes connection with the article on curvature.\nTo introduce the unit vectors of the local coordinate system, one approach is to begin in Cartesian coordinates and describe the local coordinates in terms of these Cartesian coordinates. In terms of arc length \"s\", let the path be described as:\nformula_80\nThen an incremental displacement along the path d\"s\" is described by:\nformula_81\nwhere primes are introduced to denote derivatives with respect to \"s\". The magnitude of this displacement is d\"s\", showing that:\nThis displacement is necessarily a tangent to the curve at \"s\", showing that the unit vector tangent to the curve is:\nformula_83\nwhile the outward unit vector normal to the curve is\nformula_84\nOrthogonality can be verified by showing that the vector dot product is zero. The unit magnitude of these vectors is a consequence of Eq. 1. Using the tangent vector, the angle \"\u03b8\" of the tangent to the curve is given by:\nformula_85 and formula_86\nThe radius of curvature is introduced completely formally (without need for geometric interpretation) as:\nformula_87\nThe derivative of \"\u03b8\" can be found from that for sin\"\u03b8\":\nformula_88\nNow:\nformula_89\nin which the denominator is unity. With this formula for the derivative of the sine, the radius of curvature becomes:\nformula_90\nwhere the equivalence of the forms stems from differentiation of Eq. 1:\nformula_91\nWith these results, the acceleration can be found:\nformula_92\nas can be verified by taking the dot product with the unit vectors ut(\"s\") and un(\"s\"). This result for acceleration is the same as that for circular motion based on the radius \"\u03c1\". Using this coordinate system in the inertial frame, it is easy to identify the force normal to the trajectory as the centripetal force and that parallel to the trajectory as the tangential force. From a qualitative standpoint, the path can be approximated by an arc of a circle for a limited time, and for the limited time a particular radius of curvature applies, the centrifugal and Euler forces can be analyzed on the basis of circular motion with that radius.\nThis result for acceleration agrees with that found earlier. However, in this approach, the question of the change in radius of curvature with \"s\" is handled completely formally, consistent with a geometric interpretation, but not relying upon it, thereby avoiding any questions the image above might suggest about neglecting the variation in \"\u03c1\".\nExample: circular motion.\nTo illustrate the above formulas, let \"x\", \"y\" be given as:\nThen:\nwhich can be recognized as a circular path around the origin with radius \"\u03b1\". The position \"s\" = 0 corresponds to [\"\u03b1\", 0], or 3 o'clock. To use the above formalism, the derivatives are needed:\nWith these results, one can verify that:\nThe unit vectors can also be found:\nwhich serve to show that \"s\" = 0 is located at position [\"\u03c1\", 0] and \"s\" = \"\u03c1\"\u03c0/2 at [0, \"\u03c1\"], which agrees with the original expressions for \"x\" and \"y\". In other words, \"s\" is measured counterclockwise around the circle from 3 o'clock. Also, the derivatives of these vectors can be found:\nTo obtain velocity and acceleration, a time-dependence for \"s\" is necessary. For counterclockwise motion at variable speed \"v\"(\"t\"):\nwhere \"v\"(\"t\") is the speed and \"t\" is time, and \"s\"(\"t\" = 0) = 0. Then:\nwhere it already is established that \u03b1 = \u03c1. This acceleration is the standard result for non-uniform circular motion."}
{"id": "7535", "revid": "12845131", "url": "https://en.wikipedia.org/wiki?curid=7535", "title": "Commodore", "text": "Commodore may refer to:"}
{"id": "7536", "revid": "47130321", "url": "https://en.wikipedia.org/wiki?curid=7536", "title": "Conditioning", "text": "Conditioning may refer to:"}
{"id": "7538", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=7538", "title": "Checksum", "text": "A checksum is a small-sized block of data derived from another block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage. By themselves, checksums are often used to verify data integrity but are not relied upon to verify data authenticity.\nThe procedure which generates this checksum is called a checksum function or checksum algorithm. Depending on its design goals, a good checksum algorithm usually outputs a significantly different value, even for small changes made to the input. This is especially true of cryptographic hash functions, which may be used to detect many data corruption errors and verify overall data integrity; if the computed checksum for the current data input matches the stored value of a previously computed checksum, there is a very high probability the data has not been accidentally altered or corrupted.\nChecksum functions are related to hash functions, fingerprints, randomization functions, and cryptographic hash functions. However, each of those concepts has different applications and therefore different design goals. For instance, a function returning the start of a string can provide a hash appropriate for some applications but will never be a suitable checksum. Checksums are used as cryptographic primitives in larger authentication algorithms. For cryptographic systems with these two specific design goals, see HMAC.\nCheck digits and parity bits are special cases of checksums, appropriate for small blocks of data (such as Social Security numbers, bank account numbers, computer words, single bytes, etc.). Some error-correcting codes are based on special checksums which not only detect common errors but also allow the original data to be recovered in certain cases.\nAlgorithms.\nParity byte or parity word.\nThe simplest checksum algorithm is the so-called longitudinal parity check, which breaks the data into \"words\" with a fixed number of bits, and then computes the bitwise exclusive or (XOR) of all those words. The result is appended to the message as an extra word. In simpler terms, for =1 this means adding a bit to the end of the data bits to guarantee that there is an even number of '1's. To check the integrity of a message, the receiver computes the bitwise exclusive or of all its words, including the checksum; if the result is not a word consisting of zeros, the receiver knows a transmission error occurred.\nWith this checksum, any transmission error which flips a single bit of the message, or an odd number of bits, will be detected as an incorrect checksum. However, an error that affects two bits will not be detected if those bits lie at the same position in two distinct words. Also swapping of two or more words will not be detected. If the affected bits are independently chosen at random, the probability of a two-bit error being undetected is .\nSum complement.\nA variant of the previous algorithm is to add all the \"words\" as unsigned binary numbers, discarding any overflow bits, and append the two's complement of the total as the checksum. To validate a message, the receiver adds all the words in the same manner, including the checksum; if the result is not a word full of zeros, an error must have occurred. This variant, too, detects any single-bit error, but the pro modular sum is used in SAE J1708.\nPosition-dependent.\nThe simple checksums described above fail to detect some common errors which affect many bits at once, such as changing the order of data words, or inserting or deleting words with all bits set to zero. The checksum algorithms most used in practice, such as Fletcher's checksum, Adler-32, and cyclic redundancy checks (CRCs), address these weaknesses by considering not only the value of each word but also its position in the sequence. This feature generally increases the cost of computing the checksum.\nFuzzy checksum.\nThe idea of fuzzy checksum was developed for detection of email spam by building up cooperative databases from multiple ISPs of email suspected to be spam. The content of such spam may often vary in its details, which would render normal checksumming ineffective. By contrast, a \"fuzzy checksum\" reduces the body text to its characteristic minimum, then generates a checksum in the usual manner. This greatly increases the chances of slightly different spam emails producing the same checksum. The ISP spam detection software, such as SpamAssassin, of co-operating ISPs, submits checksums of all emails to the centralised service such as DCC. If the count of a submitted fuzzy checksum exceeds a certain threshold, the database notes that this probably indicates spam. ISP service users similarly generate a fuzzy checksum on each of their emails and request the service for a spam likelihood.\nGeneral considerations.\nA message that is bits long can be viewed as a corner of the -dimensional hypercube. The effect of a checksum algorithm that yields an -bit checksum is to map each -bit message to a corner of a larger hypercube, with dimension . The corners of this hypercube represent all possible received messages. The valid received messages (those that have the correct checksum) comprise a smaller set, with only corners.\nA single-bit transmission error then corresponds to a displacement from a valid corner (the correct message and checksum) to one of the adjacent corners. An error which affects bits moves the message to a corner which is steps removed from its correct corner. The goal of a good checksum algorithm is to spread the valid corners as far from each other as possible, to increase the likelihood \"typical\" transmission errors will end up in an invalid corner.\nSee also.\nGeneral topic\nError correction\nHash functions\nFile systems\nRelated concepts"}
{"id": "7539", "revid": "21491290", "url": "https://en.wikipedia.org/wiki?curid=7539", "title": "Cosmic Background Radiation", "text": ""}
{"id": "7540", "revid": "30746614", "url": "https://en.wikipedia.org/wiki?curid=7540", "title": "Cultural evolution (disambiguation)", "text": "Cultural evolution is cultural change viewed from an evolutionary perspective.\nIt may also refer to:"}
{"id": "7541", "revid": "49069143", "url": "https://en.wikipedia.org/wiki?curid=7541", "title": "City University of New York", "text": "The City University of New York (CUNY, pronounced , ) is the public university system of New York City. It is the largest urban university system in the United States, comprising 25 campuses: eleven senior colleges, seven community colleges, and seven professional institutions. The university enrolls more than 275,000 students and counts thirteen Nobel Prize winners and twenty-four MacArthur Fellows among its alumni.\nThe oldest constituent college of CUNY, City College of New York, was originally founded in 1847 and became the first free public institution of higher learning in the United States. In 1960, John R. Everett became the first chancellor of the Municipal College System of New York City, later known as the City University of New York (CUNY). CUNY, established by New York state legislation in 1961 and signed into law by governor Nelson Rockefeller, was an amalgamation of existing institutions and a new graduate school.\nThe system was governed by the Board of Higher Education of the City of New York, created in 1926, and later renamed the Board of Trustees of CUNY in 1979. The institutions merged into CUNY included the Free Academy (later City College of New York), the Female Normal and High School (later Hunter College), Brooklyn College, and Queens College. CUNY has historically provided accessible education, especially to those excluded or unable to afford private universities. The first community college in New York City was established in 1955 with shared funding between the state and the city, but unlike the senior colleges, community college students had to pay tuition.\nThe integration of CUNY's colleges into a single university system took place in 1961, under a chancellor and with state funding. The Graduate Center, serving as the principal doctorate-granting institution, was also established that year. In 1964, Mayor Robert F. Wagner Jr. extended the senior colleges' free tuition policy to community colleges. The 1960s saw student protests demanding more racial diversity and academic representation in CUNY, leading to the establishment of Medgar Evers College and the implementation of the Open Admissions policy in 1970. This policy dramatically increased student diversity but also introduced challenges like low retention rates. The 1976 fiscal crisis ended the free tuition policy, leading to the introduction of tuition fees for all CUNY colleges.\nHistory.\nFounding.\nIn 1960, John R. Everett became the first chancellor of the Municipal College System of the City of New York, later renamed CUNY, for a salary of $25,000 ($ in current dollar terms). CUNY was created in 1961, by New York State legislation, signed into law by Governor Nelson Rockefeller. The legislation integrated existing institutions and a new graduate school into a coordinated system of higher education for the city, under the control of the \"Board of Higher Education of the City of New York\", which had been created by New York State legislation in 1926. By 1979, the Board of Higher Education had become the \"Board of Trustees of the CUNY\".\nThe institutions that were merged to create CUNY were:\nAccessible education.\nCUNY has served a diverse student body, especially those excluded from or unable to afford private universities. Its four-year colleges offered a high-quality, tuition-free education to the poor, the working class, and the immigrants of New York City who met the grade requirements for matriculated status. During the post-World War I era, when some Ivy League universities, such as Yale University, discriminated against Jews, many Jewish academics and intellectuals studied and taught at CUNY. The City College of New York developed a reputation of being \"the Harvard of the proletariat.\"\nAs New York City's population and public college enrollment grew during the early 20th century and the city struggled for resources, the municipal colleges slowly began adopting selective tuition, also known as instructional fees, for a handful of courses and programs. During the Great Depression, with funding for public colleges severely constrained, limits were imposed on the size of the colleges' free Day Sessions, and tuition was imposed upon students deemed \"competent\" but not academically qualified for the day program. Most of these \"limited matriculation\" students enrolled in the Evening Sessions, and paid tuition. Additionally, as the population of New York grew, CUNY was not able to accommodate the demand for higher education. Higher and higher requirements for admission were imposed; in 1965, a student seeking admission to CUNY needed an average grade of 92 or A\u2212. This helped to ensure that the student population of CUNY remained largely white and middle-class.\nDemand in the United States for higher education rapidly grew after World War II, and during the mid-1940s a movement began to create community colleges to provide accessible education and training. In New York City, however, the community college movement was constrained by many factors including \"financial problems, narrow perceptions of responsibility, organizational weaknesses, adverse political factors, and other competing priorities.\"\nCommunity colleges would have drawn from the same city coffers that were funding the senior colleges, and city higher education officials were of the view that the state should finance them. It was not until 1955, under a shared-funding arrangement with New York State, that New York City established its first community college, on Staten Island. Unlike the day college students attending the city's public baccalaureate colleges for free, community college students had to pay tuition fees under the state-city funding formula. Community college students paid tuition fees for approximately 10 years.\nOver time, tuition fees for limited-matriculated students became an important source of system revenues. In fall 1957, for example, nearly 36,000 attended Hunter, Brooklyn, Queens and City Colleges for free, but another 24,000 paid tuition fees of up to $300 a year ($ in current dollar terms). Undergraduate tuition and other student fees in 1957 comprised 17 percent of the colleges' $46.8 million in revenues, about $7.74 million ($ in current dollar terms).\nThree community colleges had been established by early 1961 when New York City's public colleges were codified by the state as a single university with a chancellor at the helm and an infusion of state funds. But the city's slowness in creating the community colleges as demand for college seats was intensifying and had resulted in mounting frustration, particularly on the part of minorities, that college opportunities were not available to them.\nIn 1964, as New York City's Board of Higher Education moved to take full responsibility for the community colleges, city officials extended the senior colleges' free tuition policy to them, a change that was included by Mayor Robert F. Wagner Jr. in his budget plans and took effect with the 1964\u201365 academic year.\nCalls for greater access to public higher education from the black and Puerto Rican communities in New York, especially in Brooklyn, led to the founding of \"Community College Number 7,\" later Medgar Evers College, in 1966\u20131967. In 1969, a group of black and Puerto Rican students occupied City College and demanded the racial integration of CUNY, which at the time had an overwhelmingly white student body.\nStudent protests.\nStudents at some campuses became increasingly frustrated with the university's and Board of Higher Education's handling of university administration. At Baruch College in 1967, over a thousand students protested the plan to make the college an upper-division school limited to junior, senior, and graduate students. At Brooklyn College in 1968, students attempted a sit-in to demand the admission of more black and Puerto Rican students and additional black studies curriculum. Students at Hunter College also demanded a Black studies program. Members of the SEEK program, which provided academic support for underprepared and underprivileged students, staged a building takeover at Queens College in 1969 to protest the decisions of the program's director, who would later be replaced by a black professor. Puerto Rican students at Bronx Community College filed a report with the New York State Division of Human Rights in 1970, contending that the intellectual level of the college was inferior and discriminatory. Hunter College was crippled for several days by a protest of 2,000 students who had a list of demands focusing on more student representation in college administration. Across CUNY, students boycotted their campuses in 1970 to protest a rise in student fees and other issues, including the proposed (and later implemented) open admissions plan.\nLike many college campuses in 1970, CUNY faced a number of protests and demonstrations after the Kent State massacre and Cambodian Campaign. The Administrative Council of the City University of New York sent U.S. president Richard Nixon a telegram in 1970 stating, \"No nation can long endure the alienation of the best of its young people.\" Some colleges, including John Jay College of Criminal Justice, historically the \"college for cops,\" held teach-ins in addition to student and faculty protests.\nIn April 2024, CUNY students joined other campuses across the United States in protests against the Israel\u2013Hamas war. The student protestors demanded that CUNY divest from companies with ties to Israel and that CUNY officials cancel any upcoming trips to Israel and protect students involved in the demonstrations.\nOpen admissions.\nUnder pressure from community activists and CUNY Chancellor Albert Bowker, the Board of Higher Education (BHE) approved an open admissions plan in 1966, but it was not scheduled to be fully implemented until 1975. However, in 1969, students and faculty across CUNY participated in rallies, student strikes, and class boycotts demanding an end to CUNY's restrictive admissions policies. CUNY administrators and Mayor John Lindsay expressed support for these demands, and the BHE voted to implement the plan immediately in the fall of 1970.\nAll high school graduates were guaranteed entrance to the university without having to fulfill traditional requirements such as exams or grades. The policy nearly doubled the number of students enrolled in the CUNY system to 35,000 (compared to 20,000 the year before). Black and Hispanic student enrollment increased threefold. Remedial education, to supplement the training of under-prepared students, became a significant part of CUNY's offerings. Additionally, ethnic and Black Studies programs and centers were instituted on many CUNY campuses, contributing to the growth of similar programs nationwide.\nHowever, retention of students in CUNY during this period was low; two-thirds of students enrolled in the early 1970s left within four years without graduating.\nFinancial crisis of 1976.\nIn fall 1976, during New York City's fiscal crisis, the free tuition policy was discontinued under pressure from the federal government, the financial community that had a role in rescuing the city from bankruptcy, and New York State, which would take over the funding of CUNY's senior colleges. Tuition, which had been in place in the State University of New York system since 1963, was instituted at all CUNY colleges.\nMeanwhile, CUNY students were added to the state's need-based Tuition Assistance Program (TAP), which had been created to help private colleges. Full-time students who met the income eligibility criteria were permitted to receive TAP, ensuring for the first time that financial hardship would deprive no CUNY student of a college education. Within a few years, the federal government would create its own need-based program, known as Pell Grants, providing the neediest students with a tuition-free college education. Joseph S. Murphy was Chancellor of the City University of New York from 1982 to 1990, when he resigned. CUNY at the time was the third-largest university in the United States, with over 180,000 students.\nBy 2011, nearly six of ten full-time undergraduates qualified for a tuition-free education at CUNY due in large measure to state, federal and CUNY financial aid programs. CUNY's enrollment dipped after tuition was re-established, and there were further enrollment declines through the 1980s and into the 1990s.\nFinancial crisis of 1995.\nIn 1995, CUNY suffered another fiscal crisis when Governor George Pataki proposed a drastic cut in state financing. Faculty cancelled classes and students staged protests. By May, CUNY adopted deep cuts to college budgets and class offerings. By June, to save money spent on remedial programs, CUNY adopted a stricter admissions policy for its senior colleges: students deemed unprepared for college would not be admitted, this a departure from the 1970 Open Admissions program. That year's final state budget cut funding by $102\u00a0million, which CUNY absorbed by increasing tuition by $750 and offering a retirement incentive plan for faculty.\nIn 1999, a task force appointed by Mayor Rudolph Giuliani issued a report that described CUNY as \"an institution adrift\" and called for an improved, more cohesive university structure and management, as well as more consistent academic standards. Following the report, Matthew Goldstein, a mathematician and City College graduate who had led CUNY's Baruch College and briefly, Adelphi University, was appointed chancellor. CUNY ended its policy of open admissions to its four-year colleges, raised its admissions standards at its most selective four-year colleges (Baruch, Brooklyn, City, Hunter and Queens), and required new enrollees who needed remediation to begin their studies at a CUNY open-admissions community college.\n2010 onward.\nCUNY's enrollment of degree-credit students reached 220,727 in 2005 and 262,321 in 2010 as the university broadened its academic offerings. The university added more than 2,000 full-time faculty positions, opened new schools and programs, and expanded the university's fundraising efforts to help pay for them. Fundraising increased from $35\u00a0million in 2000 to more than $200\u00a0million in 2012.\nBy autumn 2013, all CUNY undergraduates were required to take an administration-dictated common core of courses which have been claimed to meet specific \"learning outcomes\" or standards. Since the courses are accepted university-wide, the administration claims it will be easier for students to transfer course credits between CUNY colleges. It also reduced the number of core courses some CUNY colleges had required, to a level below national norms, particularly in the sciences. The program is the target of several lawsuits by students and faculty, and was the subject of a \"no confidence\" vote by the faculty, who rejected it by an overwhelming 92% margin.\nChancellor Goldstein retired on July 1, 2013, and was replaced on June 1, 2014, by James Milliken, president of the University of Nebraska, and a graduate of the University of Nebraska and New York University School of Law. Milliken retired at the end of the 2018 academic year and moved on to become the chancellor for the University of Texas system.\nIn 2018, CUNY opened its 25th campus, the CUNY School of Labor and Urban Studies, named after former president Joseph S. Murphy and combining some forms and functions of the Murphy Institute that were housed at the CUNY School of Professional Studies.\nOn February 13, 2019, the board of trustees voted to appoint Queens College president Felix V. Matos Rodriguez as the chancellor of the City University of New York. Matos became both the first Latino and minority educator to head the university. He assumed the post May 1.\nEnrollment and demographics.\nCUNY is the fourth-largest university system in the United States by enrollment, behind the California State University, State University of New York (SUNY), and University of California systems. More than 271,000-degree-credit students, continuing, and professional education students are enrolled at campuses located in all five New York City boroughs.\nThe university has one of the most diverse student bodies in the United States, with students hailing from around the world, although most students live in New York City. The black, white and Hispanic undergraduate populations each comprise more than a quarter of the student body, and Asian undergraduates make up 18 percent. Fifty-eight percent are female, and 28 percent are 25 or older. In the 2017\u20132018 award year, 144,380 CUNY students received the Federal Pell Grant.\nCUNY Citizenship Now!\nFounded in 1997 by immigration lawyer Allan Wernick, CUNY Citizenship Now! is an immigration assistance organization that provides free and confidential immigration law services to help individuals and families on their path to U.S. citizenship. In 2021, CUNY launched a College Immigrant Ambassador Program in partnership with the New York City Department of Education.\nManagement structure.\nThe forerunner of today's City University of New York was governed by the Board of Education of New York City. Members of the Board of Education, chaired by the president of the board, served as \"ex officio\" trustees. For the next four decades, the board members continued to serve as \"ex officio\" trustees of the College of the City of New York and the city's other municipal college, the Normal College of the City of New York.\nIn 1900, the New York State Legislature created separate boards of trustees for the College of the City of New York and the Normal College, which became Hunter College in 1914. In 1926, the legislature established the Board of Higher Education of the City of New York, which assumed supervision of both municipal colleges.\nIn 1961, the New York State Legislature established the City University of New York, uniting what had become seven municipal colleges at the time: the City College of New York, Hunter College, Brooklyn College, Queens College, Staten Island Community College, Bronx Community College and Queensborough Community College. In 1979, the CUNY Financing and Governance Act was adopted by the State and the Board of Higher Education became the City University of New York board of trustees.\nToday, the City University is governed by the board of trustees composed of 17 members, ten of whom are appointed by the governor of New York \"with the advice and consent of the senate,\" and five by the mayor of New York City \"with the advice and consent of the senate.\" The final two trustees are \"ex officio\" members. One is the chair of the university's student senate, and the other is non-voting and is the chair of the university's faculty senate. Both the mayoral and gubernatorial appointments to the CUNY Board are required to include at least one resident of each of New York City's five boroughs. Trustees serve seven-year terms, which are renewable for another seven years. The chancellor is elected by the board of trustees, and is the \"chief educational and administrative officer\" of the City University.\nThe administrative offices are in Midtown Manhattan.\nFaculty.\nCUNY employs 6,700 full-time faculty members and over 10,000 adjunct faculty members. Faculty and staff are represented by the Professional Staff Congress (PSC), a labor union and chapter of the American Federation of Teachers.\nPublic Safety Department.\nCUNY has a unified public safety department, the City University of New York Public Safety Department, with branches at each of the 26 CUNY campuses. The New York City Police Department is the primary policing and investigation agency within the New York City as per the NYC Charter, which includes all CUNY campuses and facilities.\nThe Public Safety Department came under heavy criticism from student groups, after several students protesting tuition increases tried to occupy the lobby of the Baruch College. The occupiers were forcibly removed from the area and several were arrested on November 21, 2011.\nAntisemitism at CUNY.\nIn recent years, there have been a number of antisemitic incidents on CUNY campuses, including:\nCUNY has taken steps to address antisemitism on its campuses. In 2020, the university created a task force to combat antisemitism. The task force has developed a number of initiatives, including training for faculty and staff on how to identify and address antisemitism.\nIn June 2024, the United States Department of Education concluded that CUNY has failed to protect Jewish students from discrimination following the October 7 attacks. CUNY's Hunter College also faced scrutiny for incidents dating back to 2021. In response, Chancellor F\u00e9lix V. Matos Rodr\u00edguez stated that CUNY is dedicated to maintaining a discrimination-free and hate-free environment, and that new measures will ensure consistent and transparent investigation and resolution of complaints.\nCity University Television (CUNY TV).\nCUNY also has a broadcast TV service, CUNY TV (channel 75 on Spectrum, digital HD broadcast channel 25.3), which airs telecourses, classic and foreign films, magazine shows, and panel discussions in foreign languages.\nCity University Film Festival (CUNYFF).\nThe City University Film Festival is CUNY's official film festival. The festival was founded in 2009.\nNotable alumni.\nCUNY graduates include 13 Nobel laureates, 2 Fields Medalists, 2 U.S. Secretaries of State, a Supreme Court Justice, several New York City mayors, members of Congress, state legislators, scientists, artists, and Olympians."}
{"id": "7543", "revid": "49085933", "url": "https://en.wikipedia.org/wiki?curid=7543", "title": "Computational complexity theory", "text": "In theoretical computer science and mathematics, computational complexity theory focuses on classifying computational problems according to their resource usage, and explores the relationships between these classifications. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.\nA problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying their computational complexity, i.e., the amount of resources needed to solve them, such as time and storage. Other measures of complexity are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do. The P versus NP problem, one of the seven Millennium Prize Problems, is part of the field of computational complexity.\nClosely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kinds of problems can, in principle, be solved algorithmically.\nComputational problems.\nProblem instances.\nA computational problem can be viewed as an infinite collection of \"instances\" together with a set (possibly empty) of \"solutions\" for every instance. The input string for a computational problem is referred to as a problem instance, and should not be confused with the problem itself. In computational complexity theory, a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g., 15) and the solution is \"yes\" if the number is prime and \"no\" otherwise (in this case, 15 is not prime and the answer is \"no\"). Stated another way, the \"instance\" is a particular input to the problem, and the \"solution\" is the output corresponding to the given input.\nTo further highlight the difference between a problem and an instance, consider the following instance of the decision version of the travelling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 15 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances.\nRepresenting problem instances.\nWhen considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.\nEven though some proofs of complexity-theoretic theorems regularly assume some concrete choice of input encoding, one tries to keep the discussion abstract enough to be independent of the choice of encoding. This can be achieved by ensuring that different representations can be transformed into each other efficiently.\nDecision problems as formal languages.\nDecision problems are one of the central objects of study in computational complexity theory. A decision problem is a type of computational problem where the answer is either \"yes\" or \"no\" (alternatively, 1 or 0). A decision problem can be viewed as a formal language, where the members of the language are instances whose output is yes, and the non-members are those instances whose output is no. The objective is to decide, with the aid of an algorithm, whether a given input string is a member of the formal language under consideration. If the algorithm deciding this problem returns the answer \"yes\", the algorithm is said to accept the input string, otherwise it is said to reject the input.\nAn example of a decision problem is the following. The input is an arbitrary graph. The problem consists in deciding whether the given graph is connected or not. The formal language associated with this decision problem is then the set of all connected graphs \u2014 to obtain a precise definition of this language, one has to decide how graphs are encoded as binary strings.\nFunction problems.\nA function problem is a computational problem where a single output (of a total function) is expected for every input, but the output is more complex than that of a decision problem\u2014that is, the output is not just yes or no. Notable examples include the traveling salesman problem and the integer factorization problem.\nIt is tempting to think that the notion of function problems is much richer than the notion of decision problems. However, this is not really the case, since function problems can be recast as decision problems. For example, the multiplication of two integers can be expressed as the set of triples formula_1 such that the relation formula_2 holds. Deciding whether a given triple is a member of this set corresponds to solving the problem of multiplying two numbers.\nMeasuring the size of an instance.\nTo measure the difficulty of solving a computational problem, one may wish to see how much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. The input size is typically measured in bits. Complexity theory studies how algorithms scale as input size increases. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with formula_3 vertices compared to the time taken for a graph with formula_4 vertices?\nIf the input size is formula_4, the time taken can be expressed as a function of formula_4. Since the time taken on different inputs of the same size can be different, the worst-case time complexity formula_7 is defined to be the maximum time taken over all inputs of size formula_4. If formula_7 is a polynomial in formula_4, then the algorithm is said to be a polynomial time algorithm. Cobham's thesis argues that a problem can be solved with a feasible amount of resources if it admits a polynomial-time algorithm.\nMachine models and complexity measures.\nTuring machine.\nA Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a general model of a computing machine\u2014anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church\u2013Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata, lambda calculus or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.\nMany types of Turing machines are used to define complexity classes, such as deterministic Turing machines, probabilistic Turing machines, non-deterministic Turing machines, quantum Turing machines, symmetric Turing machines and alternating Turing machines. They are all equally powerful in principle, but when resources (such as time or space) are bounded, some of these may be more powerful than others.\nA deterministic Turing machine is the most basic Turing machine, which uses a fixed set of rules to determine its future actions. A probabilistic Turing machine is a deterministic Turing machine with an extra supply of random bits. The ability to make probabilistic decisions often helps algorithms solve problems more efficiently. Algorithms that use random bits are called randomized algorithms. A non-deterministic Turing machine is a deterministic Turing machine with an added feature of non-determinism, which allows a Turing machine to have multiple possible future actions from a given state. One way to view non-determinism is that the Turing machine branches into many possible computational paths at each step, and if it solves the problem in any of these branches, it is said to have solved the problem. Clearly, this model is not meant to be a physically realizable model, it is just a theoretically interesting abstract machine that gives rise to particularly interesting complexity classes. For examples, see non-deterministic algorithm.\nOther machine models.\nMany machine models different from the standard multi-tape Turing machines have been proposed in the literature, for example random-access machines. Perhaps surprisingly, each of these models can be converted to another without providing any extra computational power. The time and memory consumption of these alternate models may vary. What all these models have in common is that the machines operate deterministically.\nHowever, some computational problems are easier to analyze in terms of more unusual resources. For example, a non-deterministic Turing machine is a computational model that is allowed to branch out to check many different possibilities at once. The non-deterministic Turing machine has very little to do with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.\nComplexity measures.\nFor a precise definition of what it means to solve a problem using a given amount of time and space, a computational model such as the deterministic Turing machine is used. The time required by a deterministic Turing machine formula_11 on input formula_12 is the total number of state transitions, or steps, the machine makes before it halts and outputs the answer (\"yes\" or \"no\"). A Turing machine formula_11 is said to operate within time formula_14 if the time required by formula_11 on each input of length formula_4 is at most formula_14. A decision problem formula_18 can be solved in time formula_14 if there exists a Turing machine operating in time formula_14 that solves the problem. Since complexity theory is interested in classifying problems based on their difficulty, one defines sets of problems based on some criteria. For instance, the set of problems solvable within time formula_14 on a deterministic Turing machine is then denoted by DTIME(formula_14).\nAnalogous definitions can be made for space requirements. Although time and space are the most well-known complexity resources, any complexity measure can be viewed as a computational resource. Complexity measures are very generally defined by the Blum complexity axioms. Other complexity measures used in complexity theory include communication complexity, circuit complexity, and decision tree complexity.\nThe complexity of an algorithm is often expressed using big O notation.\nBest, worst and average case complexity.\nThe best, worst and average case complexity refer to three different ways of measuring the time complexity (or any other complexity measure) of different inputs of the same size. Since some inputs of size formula_4 may be faster to solve than others, we define the following complexities:\nThe order from cheap to costly is: Best, average (of discrete uniform distribution), amortized, worst.\nFor example, the deterministic sorting algorithm quicksort addresses the problem of sorting a list of integers. The worst-case is when the pivot is always the largest or smallest value in the list (so the list is never divided). In this case, the algorithm takes time O(formula_27). If we assume that all possible permutations of the input list are equally likely, the average time taken for sorting is formula_28. The best case occurs when each pivoting divides the list in half, also needing formula_28 time.\nUpper and lower bounds on the complexity of problems.\nTo classify the computation time (or similar resources, such as space consumption), it is helpful to demonstrate upper and lower bounds on the maximum amount of time required by the most efficient algorithm to solve a given problem. The complexity of an algorithm is usually taken to be its worst-case complexity unless specified otherwise. Analyzing a particular algorithm falls under the field of analysis of algorithms. To show an upper bound formula_7 on the time complexity of a problem, one needs to show only that there is a particular algorithm with running time at most formula_7. However, proving lower bounds is much more difficult, since lower bounds make a statement about all possible algorithms that solve a given problem. The phrase \"all possible algorithms\" includes not just the algorithms known today, but any algorithm that might be discovered in the future. To show a lower bound of formula_7 for a problem requires showing that no algorithm can have time complexity lower than formula_7.\nUpper and lower bounds are usually stated using the big O notation, which hides constant factors and smaller terms. This makes the bounds independent of the specific details of the computational model used. For instance, if formula_34, in big O notation one would write formula_35.\nComplexity classes.\nDefining complexity classes.\nA complexity class is a set of problems of related complexity. Simpler complexity classes are defined by the following factors:\nSome complexity classes have complicated definitions that do not fit into this framework. Thus, a typical complexity class has a definition like the following:\nBut bounding the computation time above by some concrete function formula_14 often yields complexity classes that depend on the chosen machine model. For instance, the language formula_39 can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that \"the time complexities in any two reasonable and general models of computation are polynomially related\" . This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.\nImportant complexity classes.\nMany important complexity classes can be defined by bounding the time or space used by the algorithm. Some important complexity classes of decision problems defined in this manner are the following:\nLogarithmic-space classes do not account for the space required to represent the problem.\nIt turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch's theorem.\nOther important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using Boolean circuits; and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems.\nHierarchy theorems.\nFor the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME(formula_4) is contained in DTIME(formula_27), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved.\nMore precisely, the time hierarchy theorem states that\nformula_42.\nThe space hierarchy theorem states that\nformula_43.\nThe time and space hierarchy theorems form the basis for most separation results of complexity classes. For instance, the time hierarchy theorem tells us that P is strictly contained in EXPTIME, and the space hierarchy theorem tells us that L is strictly contained in PSPACE.\nReduction.\nMany complexity classes are defined using the concept of a reduction. A reduction is a transformation of one problem into another problem. It captures the informal notion of a problem being at most as difficult as another problem. For instance, if a problem formula_44 can be solved using an algorithm for formula_45, formula_44 is no more difficult than formula_45, and we say that formula_44 \"reduces\" to formula_45. There are many different types of reductions, based on the method of reduction, such as Cook reductions, Karp reductions and Levin reductions, and the bound on the complexity of reductions, such as polynomial-time reductions or log-space reductions.\nThe most commonly used reduction is a polynomial-time reduction. This means that the reduction process takes polynomial time. For example, the problem of squaring an integer can be reduced to the problem of multiplying two integers. This means an algorithm for multiplying two integers can be used to square an integer. Indeed, this can be done by giving the same input to both inputs of the multiplication algorithm. Thus we see that squaring is not more difficult than multiplication, since squaring can be reduced to multiplication.\nThis motivates the concept of a problem being hard for a complexity class. A problem formula_44 is \"hard\" for a class of problems formula_51 if every problem in formula_51 can be reduced to formula_44. Thus no problem in formula_51 is harder than formula_44, since an algorithm for formula_44 allows us to solve any problem in formula_51. The notion of hard problems depends on the type of reduction being used. For complexity classes larger than P, polynomial-time reductions are commonly used. In particular, the set of problems that are hard for NP is the set of NP-hard problems.\nIf a problem formula_44 is in formula_51 and hard for formula_51, then formula_44 is said to be \"complete\" for formula_51. This means that formula_44 is the hardest problem in formula_51. (Since many problems could be equally hard, one might say that formula_44 is one of the hardest problems in formula_51.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, formula_67, to another problem, formula_68, would indicate that there is no known polynomial-time solution for formula_68. This is because a polynomial-time solution to formula_68 would yield a polynomial-time solution to formula_67. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.\nImportant open problems.\nP versus NP problem.\nThe complexity class P is often seen as a mathematical abstraction modeling those computational tasks that admit an efficient algorithm. This hypothesis is called the Cobham\u2013Edmonds thesis. The complexity class NP, on the other hand, contains many problems that people would like to solve efficiently, but for which no efficient algorithm is known, such as the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem. Since deterministic Turing machines are special non-deterministic Turing machines, it is easily observed that each problem in P is also member of the class NP.\nThe question of whether P equals NP is one of the most important open questions in theoretical computer science because of the wide implications of a solution. If the answer is yes, many important problems can be shown to have more efficient solutions. These include various types of integer programming problems in operations research, many problems in logistics, protein structure prediction in biology, and the ability to find formal proofs of pure mathematics theorems. The P versus NP problem is one of the Millennium Prize Problems proposed by the Clay Mathematics Institute. There is a US$1,000,000 prize for resolving the problem.\nProblems in NP not known to be in P or NP-complete.\nIt was shown by Ladner that if formula_72 then there exist problems in formula_73 that are neither in formula_74 nor formula_73-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in formula_74 or to be formula_73-complete.\nThe graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in formula_74, formula_73-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to L\u00e1szl\u00f3 Babai and Eugene Luks has run time formula_80 for graphs with formula_4 vertices, although some recent work by Babai offers some potentially new perspectives on this.\nThe integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a prime factor less than formula_82. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in formula_73 and in formula_84 (and even in UP and co-UP). If the problem is formula_73-complete, the polynomial time hierarchy will collapse to its first level (i.e., formula_73 will equal formula_84). The best known algorithm for integer factorization is the general number field sieve, which takes time formula_88 to factor an odd integer formula_4. However, the best known quantum algorithm for this problem, Shor's algorithm, does run in polynomial time. Unfortunately, this fact doesn't say much about where the problem lies with respect to non-quantum complexity classes.\nSeparations between other complexity classes.\nMany known complexity classes are suspected to be unequal, but this has not been proved. For instance formula_90, but it is possible that formula_91. If formula_74 is not equal to formula_73, then formula_74 is not equal to formula_95 either. Since there are many known complexity classes between formula_74 and formula_95, such as formula_98, formula_99, formula_100, formula_101, formula_102, formula_103, etc., it is possible that all these complexity classes collapse to one class. Proving that any of these classes are unequal would be a major breakthrough in complexity theory.\nAlong the same lines, formula_84 is the class containing the complement problems (i.e. problems with the \"yes\"/\"no\" answers reversed) of formula_73 problems. It is believed that formula_73 is not equal to formula_84; however, it has not yet been proven. It is clear that if these two complexity classes are not equal then formula_74 is not equal to formula_73, since formula_110. Thus if formula_111 we would have formula_112 whence formula_113.\nSimilarly, it is not known if formula_114 (the set of all problems that can be solved in logarithmic space) is strictly contained in formula_74 or equal to formula_74. Again, there are many complexity classes between the two, such as formula_117 and formula_118, and it is not known if they are distinct or equal classes.\nIt is suspected that formula_74 and formula_99 are equal. However, it is currently open if formula_121.\nIntractability.\nA problem that can theoretically be solved, but requires impractical and finite resources (e.g., time) to do so, is known as an . Conversely, a problem that can be solved in practice is called a , literally \"a problem that can be handled\". The term \"infeasible\" (literally \"cannot be done\") is sometimes used interchangeably with \"intractable\", though this risks confusion with a feasible solution in mathematical optimization.\nTractable problems are frequently identified with problems that have polynomial-time solutions (formula_74, formula_123); this is known as the Cobham\u2013Edmonds thesis. Problems that are known to be intractable in this sense include those that are EXPTIME-hard. If formula_73 is not the same as formula_74, then NP-hard problems are also intractable in this sense.\nHowever, this identification is inexact: a polynomial-time solution with large degree or large leading coefficient grows quickly, and may be impractical for practical size problems; conversely, an exponential-time solution that grows slowly may be practical on realistic input, or a solution that takes a long time in the worst case may take a short time in most cases or the average case, and thus still be practical. Saying that a problem is not in formula_74 does not imply that all large cases of the problem are hard or even that most of them are. For example, the decision problem in Presburger arithmetic has been shown not to be in formula_74, yet algorithms have been written that solve the problem in reasonable times in most cases. Similarly, algorithms can solve the NP-complete knapsack problem over a wide range of sizes in less than quadratic time and SAT solvers routinely handle large instances of the NP-complete Boolean satisfiability problem.\nTo see why exponential-time algorithms are generally unusable in practice, consider a program that makes formula_128 operations before halting. For small formula_4, say 100, and assuming for the sake of example that the computer does formula_130 operations each second, the program would run for about formula_131 years, which is the same order of magnitude as the age of the universe. Even with a much faster computer, the program would only be useful for very small instances and in that sense the intractability of a problem is somewhat independent of technological progress. However, an exponential-time algorithm that takes formula_132 operations is practical until formula_4 gets relatively large.\nSimilarly, a polynomial time algorithm is not always practical. If its running time is, say, formula_134, it is unreasonable to consider it efficient and it is still useless except on small instances. Indeed, in practice even formula_135 or formula_27 algorithms are often impractical on realistic sizes of problems.\nContinuous complexity theory.\nContinuous complexity theory can refer to complexity theory of problems that involve continuous functions that are approximated by discretizations, as studied in numerical analysis. One approach to complexity theory of numerical analysis is information based complexity.\nContinuous complexity theory can also refer to complexity theory of the use of analog computation, which uses continuous dynamical systems and differential equations. Control theory can be considered a form of computation and differential equations are used in the modelling of continuous-time and hybrid discrete-continuous-time systems.\nHistory.\nAn early example of algorithm complexity analysis is the running time analysis of the Euclidean algorithm done by Gabriel Lam\u00e9 in 1844.\nBefore the actual research explicitly devoted to the complexity of algorithmic problems started off, numerous foundations were laid out by various researchers. Most influential among these was the definition of Turing machines by Alan Turing in 1936, which turned out to be a very robust and flexible simplification of a computer.\nThe beginning of systematic studies in computational complexity is attributed to the seminal 1965 paper \"On the Computational Complexity of Algorithms\" by Juris Hartmanis and Richard E. Stearns, which laid out the definitions of time complexity and space complexity, and proved the hierarchy theorems. In addition, in 1965 Edmonds suggested to consider a \"good\" algorithm to be one with running time bounded by a polynomial of the input size.\nEarlier papers studying problems solvable by Turing machines with specific bounded resources include John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). Somewhat earlier, Boris Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers:\nIn 1967, Manuel Blum formulated a set of axioms (now known as Blum axioms) specifying desirable properties of complexity measures on the set of computable functions and proved an important result, the so-called speed-up theorem. The field began to flourish in 1971 when Stephen Cook and Leonid Levin proved the existence of practically relevant problems that are NP-complete. In 1972, Richard Karp took this idea a leap forward with his landmark paper, \"Reducibility Among Combinatorial Problems\", in which he showed that 21 diverse combinatorial and graph theoretical problems, each infamous for its computational intractability, are NP-complete."}
{"id": "7544", "revid": "47070250", "url": "https://en.wikipedia.org/wiki?curid=7544", "title": "Cadence (disambiguation)", "text": "A cadence is a melodic or harmonic configuration that creates a sense of resolution.\nCadence may also refer to:"}
{"id": "7546", "revid": "5718152", "url": "https://en.wikipedia.org/wiki?curid=7546", "title": "Camelot", "text": "Camelot is a legendary castle and court associated with King Arthur. Absent in the early Arthurian material, Camelot first appeared in 12th-century French romances and, since the Lancelot-Grail cycle, eventually came to be described as the fantastic capital of Arthur's realm and a symbol of the Arthurian world.\nMedieval texts locate it somewhere in Great Britain and sometimes associate it with real cities, though more usually its precise location is not revealed. Most scholars regard it as being entirely fictional, its unspecified geography being perfect for chivalric romance writers. Nevertheless, arguments about the location of the \"real Camelot\" have occurred since the 15th century and continue today in popular works and for tourism purposes.\nEtymology.\nThe name's derivation is uncertain. It has numerous different spellings in medieval French Arthurian romances, including \"Camaalot\", \"Camalot\", \"Chamalot\", \"Camehelot\" (sometimes read as \"Camchilot\"), \"Camaaloth\", \"Caamalot\", \"Camahaloth\", \"Camaelot\", \"Kamaalot\", \"Kamaaloth\", \"Kaamalot\", \"Kamahaloth\", \"Kameloth\", \"Kamaelot\", \"Kamelot\", \"Kaamelot\", \"Cameloth\", and \"Gamalaot\". Arthurian scholar Ernst Brugger suggested that it was a corruption of the site of Arthur's final battle, the Battle of Camlann, in Welsh tradition. Roger Sherman Loomis believed it was derived from \"Cavalon\", a place name that he suggested was a corruption of Avalon (under the influence of the Breton place name \"Cavallon\"). He further suggested that Cavalon became Arthur's capital due to confusion with Arthur's other traditional court at Caerleon (\"Caer Lleon\" in Welsh).\nOthers have suggested a derivation from the British Iron Age and Romano-British place name Camulodunum, one of the first capitals of Roman Britain and which would have significance in Romano-British culture. Indeed, John Morris, the English historian who specialized in the study of the institutions of the Roman Empire and the history of Sub-Roman Britain, suggested in his book \"The Age of Arthur\" that as the descendants of Romanized Britons looked back to a golden age of peace and prosperity under Rome, the name \"Camelot\" of Arthurian legend may have referred to the capital of Britannia (Camulodunum) in Roman times. It is unclear, however, where Chr\u00e9tien de Troyes would have encountered the name Camulodunum, or why he would render it as \"Camaalot\", though Urban T. Holmes argued Chr\u00e9tien could have had access to Book 2 of Pliny's \"Natural History\", where it is rendered as \"Camaloduno\".\nMedieval literature.\nArthur's court at Camelot is mentioned for the first time in Chr\u00e9tien's poem \"Lancelot, the Knight of the Cart\", dating to the 1170s, though it does not appear in all the manuscripts. In the C manuscript (Paris, Biblioth\u00e8que Nationale de France, fonds fran\u00e7ais 794, folio 27r), which might in fact contain the proper reading of Chretien's original text, instead of the place name there is the Old French phrase \"con lui plot\", meaning \"as he pleased\". The other manuscripts spell the name variously as \"Chamalot\" (MS A, f. f. 196r), \"Camehelot\" (MS E, f. 1r), \"Chamaalot\" (MS G, f. 34f), and \"Camalot\" (MS T, f. 41v); the name is missing, along with the rest of the passage containing it, in MS V (Vatican, Biblioteca Vaticana, Regina 1725). Camelot is mentioned only in passing and is not described:\nNothing in Chr\u00e9tien's poem suggests the level of importance Camelot would have in later romances. For Chr\u00e9tien, Arthur's chief court was in Caerleon in Wales; this was the king's primary base in Geoffrey of Monmouth's \"Historia Regum Britanniae\" and subsequent literature. Chr\u00e9tien depicts Arthur, like a typical medieval monarch, holding court at a number of cities and castles.\nIt is not until the 13th-century French prose romances, including the Vulgate and Post-Vulgate cycles, that Camelot began to supersede Caerleon, and even then, many descriptive details applied to Camelot derive from Geoffrey's earlier grand depiction of the Welsh town. Most Arthurian romances of this period produced in English or Welsh did not follow this trend; Camelot was referred to infrequently, and usually in translations from French. One exception is \"Sir Gawain and the Green Knight\", which locates Arthur's court at \"Camelot\"; however, in Britain, Arthur's court was generally located at Caerleon, or at Carlisle, which is usually identified with the \"Carduel\" of the French romances.\nThe \"Lancelot-Grail\" cycle and the texts it influenced depict the city of Camelot as standing along a river, downstream from Astolat. It is surrounded by plains and forests, and its magnificent cathedral, St. Stephen's, originally established by Josephus, the son of Joseph of Arimathea, is the religious centre for Arthur's Knights of the Round Table. There, Arthur and Guinevere are married and there are the tombs of many kings and knights. In a mighty castle stands the Round Table, created by Merlin and Uther Pendragon; it is here that Galahad conquers the Siege Perilous, and where the knights see a vision of the Holy Grail and swear to find it. Jousts are often held in a meadow outside the city.\nIts imprecise geography serves the romances well, as Camelot becomes less a literal place than a powerful symbol of Arthur's court and universe. There is also a Kamaalot featured as the home of Percival's mother in the romance \"Perlesvaus\". In \"Palamedes\" and some other works, including the Post-Vulgate cycle, King Arthur's Camelot is eventually razed to the ground by the treacherous King Mark of Cornwall (who had besieged it earlier) in his invasion of Logres after the Battle of Camlann. In the \"Tavola Ritonda\", Camelot is abandoned and falls to ruin after the death of Arthur.\nFrom Geoffrey's grand description of Caerleon, Camelot gains its impressive architecture, its many churches and the chivalry and courtesy of its inhabitants. Geoffrey's description in turn drew on an already established tradition in Welsh oral tradition of the grandeur of Arthur's court. The tale \"Culhwch and Olwen\", associated with the \"Mabinogion\" and perhaps first written in the 11th century, draws a dramatic picture of Arthur's hall and his many powerful warriors who go from there on great adventures, placing it in Celliwig, an uncertain locale in Cornwall.\nAlthough the court at Celliwig is the most prominent in remaining early Welsh manuscripts, the various versions of the Welsh Triads agree in giving Arthur multiple courts, one in each of the areas inhabited by the Celtic Britons: Cornwall, Wales and the Hen Ogledd. This perhaps reflects the influence of widespread oral traditions common by the 9th century which are recorded in various place names and features such as Arthur's Seat, indicating Arthur was a hero known and associated with many locations across Brittonic areas of Britain as well as Brittany. Even at this stage Arthur could not be tied to one location. Many other places are listed as a location where Arthur holds court in the later romances, Carlisle and London perhaps being the most prominent.\nIn the 15th century, the English writer Thomas Malory created the image of Camelot most familiar today in his \"Le Morte d'Arthur\", a work based mostly on the French romances. He firmly identifies Camelot with Winchester in England, an identification that remained popular over the centuries, though it was rejected by Malory's own editor, William Caxton, who preferred a Welsh location. \nIdentifications.\nArthurian scholar Norris J. Lacy commented that \"Camelot, located nowhere in particular, can be anywhere.\" The romancers' versions of Camelot draw on earlier traditions of Arthur's fabulous court. The Celliwig of \"Culhwch and Olwen\" appears in the Welsh Triads as well; this early Welsh material places Wales' greatest leader outside its national boundaries. Geoffrey's description of Caerleon is probably based on his personal familiarity with the town and its Roman ruins; it is less clear that Caerleon was associated with Arthur before Geoffrey. Several French romances (\"Perlesvaus\", the Didot \"Perceval\" attributed to Robert de Boron, and even the early romances of Chr\u00e9tien such as \"Erec and Enide\" and \"Yvain, the Knight of the Lion\") have Arthur hold court at \"Carduel in Wales\", a northern city based on the real Carlisle. Malory's identification of Camelot as Winchester was probably partially inspired by the latter city's history: it had been the capital of Wessex under Alfred the Great, and boasted the Winchester Round Table, an artefact constructed in the 13th century but widely believed to be the original by Malory's time. Caxton rejected the association, saying Camelot was in Wales and that its ruins could still be seen; this is a likely reference to the Roman ruins at Caerwent.\nIn 1542, John Leland reported that the locals around Cadbury Castle (formerly known as Camalet) in Somerset considered it to be the original Camelot. This theory, which was repeated by later antiquaries, is bolstered, or may have derived from, Cadbury's proximity to the River Cam and the villages of Queen Camel and West Camel, and remained popular enough to help inspire a large-scale archaeological dig in the 20th century. These excavations, led by archaeologist Leslie Alcock from 1966 to 1970, were titled \"Cadbury-Camelot\" and won much media attention. The dig revealed that the site seems to have been occupied as early as the 4th millennium BC and to have been refortified and occupied by a major Brittonic ruler and his war band from . This early medieval settlement continued until around 580. The works were by far the largest known fortification of the period, double the size of comparative \"caers\" and with Mediterranean artefacts representing extensive trade and Saxon ones showing possible conquest. The use of the name Camelot and the support of Geoffrey Ashe helped ensure much publicity for the finds, but Alcock himself later grew embarrassed by the supposed Arthurian connection to the site. Following the arguments of David Dumville, Alcock felt the site was too late and too uncertain to be a tenable Camelot. Modern archaeologists follow him in rejecting the name, calling it instead Cadbury Castle hill fort. Despite this, Cadbury remains widely associated with Camelot.\nThe name of the Romano-British town of Camulodunum (modern Colchester) was derived from the Celtic god Camulus. However, it was located well within territory usually thought to have been conquered early in the 5th century by Saxons, so it is unlikely to have been the location of any \"true\" Camelot, as Arthur is traditionally dated to the late 5th and early 6th century. The town was definitely known as Colchester as early as the \"Anglo-Saxon Chronicle\" in 917. Even Colchester Museum argues strongly regarding the historical Arthur: \"It would be impossible and inconceivable to link him to the Colchester area, or to Essex more generally,\" pointing out that the connection between the name Camulodunum and Colchester was unknown until the 18th century. Arthurian scholar Peter Field has suggested that another Camulodunum, a former Roman fort, is a likely location of King Arthur's Camelot and that \"Slack, on the outskirts of Huddersfield in West Yorkshire,\" is where Arthur would have held court. This is because of the name, and also regarding its strategic location: it is but a few miles from the extreme south-west of Hen Ogledd (also making close to North Wales), and would have been a flagship point in staving off attacks to the Celtic kingdoms from the Angles and others.\nOther places in Britain with names related to \"Camel\" have also been suggested, such as Camelford in Cornwall, located down the River Camel from where Geoffrey places Camlann, the scene of Arthur's final battle. The area's connections with Camelot and Camlann are merely speculative. Further north, Camelon and its connections with Arthur's O'on have been mentioned in relation to Camelot, but Camelon may be an antiquarian neologism coined after the 15th century, with its earlier name being \"Carmore\" or \"Carmure\". Graham Phillips rejected the word \"Camelot\" entirely as just Chr\u00e9tien's invention and instead proposed the old Roman city of Viroconium (near Shrewsbury in modern England) as Arthur's capital, citing archaeological evidence of a grand palace having been in use around 500 AD. Alistair Moffat identified Camelot with Roxburgh in Scotland.\nModern culture.\nCamelot has become a permanent fixture in modern interpretations of the Arthurian legend. The symbolism of Camelot so impressed Alfred, Lord Tennyson that he wrote up a prose sketch on the castle as one of his earliest attempts to treat the legend. Modern stories typically retain Camelot's lack of precise location and its status as a symbol of the Arthurian world, though they typically transform the castle itself into romantically lavish visions of a High Middle Ages palace. Some writers of the \"realist\" strain of modern Arthurian fiction have attempted a more sensible Camelot. Inspired by Alcock's Cadbury-Camelot excavation, some authors such as Marion Zimmer Bradley and Mary Stewart place their Camelots in that place and describe it accordingly.\nCamelot lends its name to the musical \"Camelot\", which was adapted into a film of the same title, featuring the Castle of Coca, Segovia as Camelot. An Arthurian television series \"Camelot\" was also named after the castle, as were some other works including the video game \"Camelot\" and the comic book series \"Camelot 3000\". French television series \"Kaamelott\" presents a humorous alternative version of the Arthurian legend; Camelot Theme Park is a now-abandoned Arthurian theme park resort located in the English county of Lancashire. The Camelot Group was the first operator of the UK National Lottery with lottery machines named after characters, places, and objects in Arthurian legend.\nIn American contexts, Camelot era refers to the presidency of John F. Kennedy. In a 1963 \"Life\" interview, Jacqueline, his widow, referenced a line from the Lerner and Loewe musical to describe the Kennedy era White House: \"Don't let it be forgot, that once there was a spot, for one brief shining moment, that was known as Camelot.\" She indicated that it was one of Kennedy's favourite lyrics from the musical and added, \"there'll be great Presidents again [...] but there'll never be another Camelot again.\"\nThe cultural impact of Camelot in Anglo-American culture can be understood in the numerous applications in \u2018high\u2019 and \u2018popular\u2019 culture by artists, filmmakers, public relations specialists, tableware and game makers, youth groups, stamp designers. The 2024 exhibit, Visualizing Camelot, at the University of Rochester Libraries offered an impressive cross-section of these applications."}
{"id": "7548", "revid": "327289", "url": "https://en.wikipedia.org/wiki?curid=7548", "title": "Contras", "text": "In the history of Nicaragua, the Contras (Spanish: \"La contrarrevoluci\u00f3n\", the counter-revolution) were the right-wing militias who waged anti-communist guerilla warfare (1979\u20131990) against the Marxist governments of the Sandinista National Liberation Front and the Junta of National Reconstruction, which came to power after the Nicaraguan Revolution in 1979.\nMonths after the political dynasty (1936\u20131979) of the Somoza family lost the Nicaraguan Revolution to the Sandinistas, the US government sponsored the remaining national-guard soldiers and Somocista politicians of the losing side as \"la Contra\", the right-wing counter-revolution. The American military assistance and financial aid granted the Contras a measure of political credibility and military utility as anti-communist militias useful to U.S. foreign policy in Latin America. In 1986, consequent to complaints of the Contras' regular violation of the human rights of Nicaraguan civilians, the Boland Amendment (1982\u20131986) ended U.S. financing of the Contras; yet the Reagan government illegally continued financing the anti-communist secret war of the Contras against Sandinista Nicaragua, known in the US as the Iran\u2013Contra affair. By 1987, the CIA had organized most of the Contra militias into the anti-communist Nicaraguan Resistance, within which the Nicaraguan Democratic Force (FDN) was the greatest militia.\nFor eleven years, the Contras' counter-revolutionary war against the Sandinista government of Nicaragua featured terrorism and human rights violations against the civilian population of Nicaragua. In defense of the Contras, the Reagan government said that the anti-communist strategy of the US in Latin America did not include attacks upon civilian populations. The CIA said that the Contras' terrorism against Nicaraguan civilians resulted from \"the poor discipline characteristic of irregular forces\", and that terrorism was not official military doctrine of the Contras, and that the responsible Contra leader was put to death because of the excessive brutality of his Contra guerrillas against Nicaraguan civilians. The Global Terrorism Database reports that Contras carried out more than 1,300 terrorist attacks.\nHistory.\nOrigins.\nThe Contras were not a monolithic group, but a combination of three distinct elements of Nicaraguan society:\nMain groups.\nThe CIA and Argentine intelligence, seeking to unify the anti-Sandinista cause before initiating large-scale aid, persuaded 15 September Legion, the UDN and several former smaller groups to merge in September 1981 as the Nicaraguan Democratic Force (\"Fuerza Democr\u00e1tica Nicarag\u00fcense\", FDN). Although the FDN had its roots in two groups made up of former National Guardsmen (of the Somoza regime), its joint political directorate was led by businessman and former anti-Somoza activist Adolfo Calero Portocarrero. \u00c9dgar Chamorro later stated that there was strong opposition within the UDN against working with the Guardsmen and that the merging only took place because of insistence by the CIA.\nBased in Honduras, Nicaragua's northern neighbor, under the command of former National Guard Colonel Enrique Berm\u00fadez, the new FDN commenced to draw in other smaller insurgent forces in the north. Largely financed, trained, equipped, armed and organized by the U.S., it emerged as the largest and most active contra group.\nIn April 1982, Ed\u00e9n Pastora (\"Comandante Cero\"), one of the heroes in the fight against Somoza, organized the Sandinista Revolutionary Front (FRS) \u2013 embedded in the Democratic Revolutionary Alliance (ARDE) \u2013 and declared war on the Sandinista government. Himself a former Sandinista who had held several high posts in the government, he had resigned abruptly in 1981 and defected, believing that the newly found power had corrupted the Sandinistas' original ideas. A popular and charismatic leader, Pastora initially saw his group develop quickly. He confined himself to operate in the southern part of Nicaragua; after a press conference he was holding on 30 May 1984 was bombed, he \"voluntarily withdrew\" from the contra struggle.\nA third force, Misurasata, appeared among the Miskito, Sumo and Rama Amerindian peoples of Nicaragua's Atlantic coast, who in December 1981 found themselves in conflict with the authorities following the government's efforts to nationalize Indian land. In the course of this conflict, forced removal of at least 10,000 Indians to relocation centers in the interior of the country and subsequent burning of some villages took place. The Misurasata movement split in 1983, with the breakaway Misura group of Stedman Fagoth Muller allying itself more closely with the FDN, and the rest accommodating themselves with the Sandinistas: on 8 December 1984 a ceasefire agreement known as the Bogota Accord was signed by Misurasata and the Nicaraguan government. A subsequent autonomy statute in September 1987 largely defused Miskito resistance.\nUnity efforts.\nU.S. officials were active in attempting to unite the Contra groups. In June 1985 most of the groups reorganized as the United Nicaraguan Opposition (UNO), under the leadership of Adolfo Calero, Arturo Cruz and Alfonso Robelo, all originally supporters of the anti-Somoza revolution. After UNO's dissolution early in 1987, the Nicaraguan Resistance (RN) was organized along similar lines in May.\nU.S. military and financial assistance.\nIn front of the International Court of Justice, the Nicaraguan government claimed that the Contras were altogether a creation of the U.S. This claim was rejected but the evidence of a very close relationship between the Contras and the United States was considered overwhelming and incontrovertible. The U.S. played a very large role in financing, training, arming, and advising the Contras over a long period, and it is unlikely that the Contras would have been capable of carrying out significant military operations without this support, given the large amount of training and weapons shipments that the Sandinistas had received from Cuba and the Soviet Union.\nPolitical background.\nThe US government viewed the leftist Sandinistas as a threat to economic interests of American corporations in Nicaragua and to national security. US President Ronald Reagan stated in 1983 that \"The defense of [the USA's] southern frontier\" was at stake. \"In spite of the Sandinista victory being declared fair, the United States continued to oppose the left-wing Nicaraguan government.\" and opposed its ties to Cuba and the Soviet Union. Ronald Reagan, who had assumed the American presidency in January 1981, accused the Sandinistas of importing Cuban-style socialism and aiding leftist guerrillas in El Salvador. The Reagan administration continued to view the Sandinistas as undemocratic despite the 1984 Nicaraguan elections being generally declared fair by foreign observers. Throughout the 1980s the Sandinista government was regarded as \"Partly Free\" by Freedom House, an organization financed by the U.S. government. \nOn 4 January 1982, Reagan signed the top secret National Security Decision Directive 17 (NSDD-17), giving the CIA the authority to recruit and support the contras with $19 million in military aid. The effort to support the Contras was one component of the Reagan Doctrine, which called for providing military support to movements opposing Soviet-supported, communist governments.\nBy December 1981, the United States had already begun to support armed opponents of the Sandinista government. From the beginning, the CIA was in charge. The arming, clothing, feeding and supervision of the contras became the most ambitious paramilitary and political action operation mounted by the agency in nearly a decade.\nIn the fiscal year 1984, the U.S. Congress approved $24 million in contra aid. After this, since the Contras failed to win widespread popular support or military victories within Nicaragua, opinion polls indicated that a majority of the U.S. public was not supportive of the Contras, the Reagan administration lost much of its support regarding its Contra policy within Congress after disclosure of CIA mining of Nicaraguan ports, and a report of the Bureau of Intelligence and Research commissioned by the State Department found Reagan's allegations about Soviet influence in Nicaragua \"exaggerated\", Congress cut off all funds for the contras in 1985 by the third Boland Amendment. The Boland Amendment had first been passed by Congress in December 1982. At this time, it only outlawed U.S. assistance to the contras \"for the purpose of overthrowing the Nicaraguan government\", while allowing assistance for other purposes. In October 1984, it was amended to forbid action by not only the Defense Department and the Central Intelligence Agency but all U.S. government agencies.\nNevertheless, the case for support of the Contras continued to be made in Washington, D.C., by both the Reagan administration and the Heritage Foundation, which argued that support for the Contras would counter Soviet influence in Nicaragua.\nOn 1 May 1985 President Reagan announced that his administration perceived Nicaragua to be \"an unusual and extraordinary threat to the national security and foreign policy of the United States\", and declared a \"national emergency\" and a trade embargo against Nicaragua to \"deal with that threat\". It \"is now a given; it is true\", the Washington Post declared in 1986, \"the Sandinistas are communists of the Cuban or Soviet school\"; that \"The Reagan administration is right to take Nicaragua as a serious menace\u2014to civil peace and democracy in Nicaragua and to the stability and security of the region\"; that we must \"fit Nicaragua back into a Central American mode\" and \"turn Nicaragua back toward democracy\", and with the \"Latin American democracies\" \"demand reasonable conduct by regional standard.\"\nSoon after the embargo was established, Managua re-declared \"a policy of nonalignment\" and sought the aid of Western Europe, who were opposed to U.S. policy, to escape dependency on the Soviet Union. Since 1981 U.S. pressures had curtailed Western credit to and trade with Nicaragua, forcing the government to rely almost totally on the Eastern bloc for credit, other aid, and trade by 1985. In his 1997 study on U.S. low intensity warfare, Kermit D. Johnson, a former Chief of the U.S. Army Chaplains, contends that U.S. hostility toward the revolutionary government was motivated not by any concern for \"national security\", but rather by what the world relief organization Oxfam termed \"the threat of a good example\":\nIt was alarming that in just a few months after the Sandinista revolution, Nicaragua received international acclaim for its rapid progress in the fields of literacy and health. It was alarming that a socialist-mixed-economy state could do in a few short months what the Somoza dynasty, a U.S. client state, could not do in 45 years! It was truly alarming that the Sandinistas were intent on providing the very services that establish a government's political and moral legitimacy.\nThe government's program included increased wages, subsidized food prices, and expanded health, welfare, and education services. And though it nationalized Somoza's former properties, it preserved a private sector that accounted for between 50 and 60 percent of GDP.\nAtrocities.\nThe United States began to support Contra activities against the Sandinista government by December 1981, with the CIA at the forefront of operations. The CIA supplied the funds and the equipment, coordinated training programs, and provided intelligence and target lists. While the Contras had little military successes, they did prove adept at carrying out CIA guerrilla warfare strategies from training manuals which advised them to incite mob violence, \"neutralize\" civilian leaders and government officials and attack \"soft targets\" \u2014 including schools, health clinics and cooperatives. The agency added to the Contras' sabotage efforts by blowing up refineries and pipelines, and mining ports. Finally, according to former Contra leader Edgar Chamorro, CIA trainers also gave Contra soldiers large knives. \"A commando knife [was given], and our people, everybody wanted to have a knife like that, to kill people, to cut their throats\". In 1985 \"Newsweek\" published a series of photos taken by Frank Wohl, a conservative student admirer traveling with the Contras, entitled \"Execution in the Jungle\":\nThe victim dug his own grave, scooping the dirt out with his hands\u00a0... He crossed himself. Then a contra executioner knelt and rammed a k-bar knife into his throat. A second enforcer stabbed at his jugular, then his abdomen. When the corpse was finally still, the contras threw dirt over the shallow grave \u2014 and walked away.\nThe CIA officer in charge of the covert war, Duane \"Dewey\" Clarridge, admitted to the House Intelligence Committee staff in a secret briefing in 1984 that the Contras were routinely murdering \"civilians and Sandinista officials in the provinces, as well as heads of cooperatives, nurses, doctors and judges\". But he claimed that this did not violate President Reagan's executive order prohibiting assassinations because the agency defined it as just 'killing'. \"After all, this is war\u2014a paramilitary operation\", Clarridge said in conclusion. Edgar Chamorro explained the rationale behind this to a U.S. reporter. \"Sometimes terror is very productive. This is the policy, to keep putting pressure until the people cry 'uncle'\". The CIA manual for the Contras, \"Tayacan\", states that the Contras should gather the local population for a public tribunal to \"shame, ridicule and humiliate\" Sandinista officials to \"reduce their influence\". It also recommends gathering the local population to witness and take part in public executions. These types of activities continued throughout the war. After the signing of the Central American Peace Accord in August 1987, the year war related deaths and economic destruction reached its peak, the Contras eventually entered negotiations with the Sandinista government (1988), and the war began to deescalate.\nBy 1989 the U.S.-backed Contra war and economic isolation had inflicted severe economic suffering on Nicaraguans. The US government knew that the Nicaraguans had been exhausted from the war, which had cost 30,865 lives, and that voters usually vote the incumbents out during economic decline. By the late 1980s Nicaragua's internal conditions had changed so radically that the US approach to the 1990 elections differed greatly from 1984. A united opposition of fourteen political parties organized into the National Opposition Union (Uni\u00f3n Nacional Oppositora, UNO) with the support of the United States National Endowment for Democracy. UNO presidential nominee Violeta Chamorro was received by President Bush at the White House.\nThe Contra war escalated over the year before the election. The US promised to end the economic embargo should Chamorro win.\nThe UNO scored a decisive victory on 25 February 1990. Chamorro won with 55 percent of the presidential vote as compared to Ortega's 41 percent. Of 92 seats in the National Assembly, UNO gained 51, and the FSLN won 39. On 25 April 1990, Chamorro assumed presidency from Daniel Ortega.\nIllegal covert operations.\nWith Congress blocking further aid to the Contras, the Reagan administration sought to arrange funding and military supplies by means of third countries and private sources. Between 1984 and 1986, $34 million from third countries and $2.7 million from private sources were raised this way. The secret contra assistance was run by the National Security Council, with officer Lt. Col. Oliver North in charge. With the third-party funds, North created an organization called \"The Enterprise\", which served as the secret arm of the NSC staff and had its own airplanes, pilots, airfield, ship, operatives, and secret Swiss bank accounts. It also received assistance from personnel from other government agencies, especially from CIA personnel in Central America. This operation functioned, however, without any of the accountability required of U.S. government activities. The Enterprise's efforts culminated in the Iran\u2013Contra Affair of 1986\u20131987, which facilitated contra funding through the proceeds of arms sales to Iran.\nAccording to the London Spectator, U.S. journalists in Central America had long known that the CIA was flying in supplies to the Contras inside Nicaragua before the scandal broke. No journalist paid it any attention until the alleged CIA supply man, Eugene Hasenfus, was shot down and captured by the Nicaraguan army. Similarly, reporters neglected to investigate many leads indicating that Oliver North was running the Contra operation from his office in the National Security Council.\nAccording to the National Security Archive, Oliver North had been in contact with Manuel Noriega, the military leader of Panama later convicted on drug charges, whom he personally met. The issue of drug money and its importance in funding the Nicaraguan conflict was the subject of various reports and publications. The contras were funded by drug trafficking, of which the United States was aware. Senator John Kerry's 1988 Committee on Foreign Relations report on Contra drug links concluded that \"senior U.S. policy makers were not immune to the idea that drug money was a perfect solution to the Contras' funding problems\".\nThe Reagan administration's support for the Contras continued to stir controversy well into the 1990s. In August 1996, \"San Jose Mercury News\" reporter Gary Webb published a series titled \"Dark Alliance\", alleging that the contras contributed to the rise of crack cocaine in California.\nGary Webb's career as a journalist was subsequently discredited by the leading U.S. papers, \"The New York Times\", the Washington Post, and the \"Los Angeles Times\". An internal CIA report, entitled, \"Managing a Nightmare\", shows the agency used \"a ground base of already productive relations with journalists\" to help counter what it called \"a genuine public relations crisis.\" In the 1980s, Douglas Farah worked as a journalist, covering the civil wars in Central America for the Washington Post. According to Farah, while it was common knowledge that the Contras were involved in cocaine trafficking, the editors of the Washington Post refused to take it seriously:\nIf you're talking about our intelligence community tolerating \u2014 if not promoting \u2014 drugs to pay for black ops, it's rather an uncomfortable thing to do when you're an establishment paper like the Post. If you were going to be directly rubbing up against the government, they wanted it more solid than it could probably ever be done.\nAn investigation by the United States Department of Justice also stated that their \"review did not substantiate the main allegations stated and implied in the \"Mercury News\" articles.\" Regarding the specific charges towards the CIA, the DOJ wrote \"the implication that the drug trafficking by the individuals discussed in the \"Mercury News\" articles was connected to the CIA was also not supported by the facts.\" The CIA also investigated and rejected the allegations.\nPropaganda.\nDuring the time the US Congress blocked funding for the contras, the Reagan government engaged in a campaign to alter public opinion and change the vote in Congress on contra aid. For this purpose, the NSC established an interagency working group, which in turn coordinated the Office of Public Diplomacy for Latin America and the Caribbean (managed by Otto Reich), which conducted the campaign. The S/LPD produced and widely disseminated a variety of pro-contra publications, arranged speeches and press conferences. It also disseminated \"white propaganda\"\u2014pro-contra newspaper articles by paid consultants who did not disclose their connection to the Reagan administration.\nOn top of that, Oliver North helped Carl Channell's tax-exempt organization, the National Endowment for the Preservation of Liberty, to raise $10 million, by arranging numerous briefings for groups of potential contributors at the premises of the White House and by facilitating private visits and photo sessions with President Reagan for major contributors. Channell in turn, used part of that money to run a series of television advertisements directed at home districts of Congressmen considered swing votes on contra aid. Out of the $10 million raised, more than $1 million was spent on pro-contra publicity.\nInternational Court of Justice ruling.\nIn 1984 the Sandinista government filed a suit in the International Court of Justice (ICJ) against the United States (\"Nicaragua v. United States\"), which resulted in a 1986 judgment against the United States. The ICJ held that the U.S. had violated international law by supporting the contras in their rebellion against the Nicaraguan government and by mining Nicaragua's harbors. Regarding the alleged human rights violations by the contras, however, the ICJ took the view that the United States could be held accountable for them only if it would have been proven that the U.S. had effective control of the contra operations resulting in these alleged violations. Nevertheless, the ICJ found that the U.S. encouraged acts contrary to general principles of humanitarian law by producing the manual \"Psychological Operations in Guerrilla Warfare (Operaciones sicol\u00f3gicas en guerra de guerrillas\") and disseminating it to the contras. The manual, amongst other things, advised on how to rationalize killings of civilians and recommended to hire professional killers for specific selective tasks.\nThe United States, which did not participate in the merits phase of the proceedings, maintained that the ICJ's power did not supersede the Constitution of the United States and argued that the court did not seriously consider the Nicaraguan role in El Salvador, while it accused Nicaragua of actively supporting armed groups there, specifically in the form of supply of arms. The ICJ had found that evidence of a responsibility of the Nicaraguan government in this matter was insufficient. The U.S. argument was affirmed, however, by the dissenting opinion of ICJ member U.S. Judge Schwebel, who concluded that in supporting the contras, the United States acted lawfully in collective self-defence in El Salvador's support. The U.S. blocked enforcement of the ICJ judgment by the United Nations Security Council and thereby prevented Nicaragua from obtaining any actual compensation. The Nicaraguan government finally withdrew the complaint from the court in September 1992 (under the later, post-FSLN, government of Violeta Chamorro), following a repeal of the law requiring the country to seek compensation.\nHuman rights violations.\nAmericas Watch, which subsequently became part of Human Rights Watch, accused the Contras of:\nHuman Rights Watch released a report on the situation in 1989, which stated: \"[The] contras were major and systematic violators of the most basic standards of the laws of armed conflict, including by launching indiscriminate attacks on civilians, selectively murdering non-combatants, and mistreating prisoners.\"\nIn his affidavit to the World Court, former contra Edgar Chamorro testified that \"The CIA did not discourage such tactics. To the contrary, the Agency severely criticized me when I admitted to the press that the FDN had regularly kidnapped and executed agrarian reform workers and civilians. We were told that the only way to defeat the Sandinistas was to\u00a0...kill, kidnap, rob and torture\".\nContra leader Adolfo Calero denied that his forces deliberately targeted civilians: \"What they call a cooperative is also a troop concentration full of armed people. We are not killing civilians. We are fighting armed people and returning fire when fire is directed at us.\"\nControversy.\nSeveral articles were published by U.S. press, including by \"The Wall Street Journal\" and \"The New Republic\", accusing Americas Watch and other bodies of ideological bias and unreliable reporting. The articles alleged that Americas Watch gave too much credence to alleged Contra abuses and systematically tried to discredit Nicaraguan human rights groups such as the Permanent Commission on Human Rights, which blamed the most human rights abuses on the Sandinistas.\nIn 1985, \"The Wall Street Journal\" reported:\nHuman Rights Watch, the umbrella organization of Americas Watch, replied to these allegations: \"Almost invariably, U.S. pronouncements on human rights exaggerated and distorted the real human rights violations of the Sandinista regime, and exculpated those of the U.S.-supported insurgents, known as the contras\u00a0... The Bush administration is responsible for these abuses, not only because the contras are, for all practical purposes, a U.S. force, but also because the Bush administration has continued to minimize and deny these violations, and has refused to investigate them seriously.\"\nMilitary successes and election of Violeta Chamorro.\nBy 1986 the contras were besieged by charges of corruption, human-rights abuses, and military ineptitude. A much-vaunted early 1986 offensive never materialized, and Contra forces were largely reduced to isolated acts of terrorism. In October 1987, however, the contras staged a successful attack in southern Nicaragua. Then on 21 December 1987, the FDN launched attacks at Bonanza, Siuna, and Rosita in Zelaya province, resulting in heavy fighting. ARDE Frente Sur attacked at El Almendro and along the Rama road. These large-scale raids mainly became possible as the contras were able to use U.S.-provided Redeye missiles against Sandinista Mi-24 helicopter gunships, which had been supplied by the Soviets. Nevertheless, the Contras remained tenuously encamped within Honduras and were not able to hold Nicaraguan territory.\nThere were isolated protests among the population against the draft implemented by the Sandinista government, which even resulted in full-blown street clashes in Masaya in 1988. However, a June 1988 survey in Managua showed the Sandinista government still enjoyed strong support but that support had declined since 1984. Three times as many people identified with the Sandinistas (28%) than with all the opposition parties put together (9%); 59% did not identify with any political party. Of those polled, 85% opposed any further US aid to the Contras; 40% believed the Sandinista government to be democratic, while 48% believed it to be not democratic. People identified the war as the largest problem but were less likely to blame it for economic problems compared to a December 1986 poll; 19% blamed the war and US blockade as the main cause of economic problems while 10% blamed the government. Political opposition groups were splintered and the Contras began to experience defections, although United States aid maintained them as a viable military force.\nAfter a cutoff in U.S. military support, and with both sides facing international pressure to bring an end to the conflict, the contras agreed to negotiations with the FSLN. With the help of five Central American presidents, including Ortega, the sides agreed that a voluntary demobilization of the contras should start in early December 1989. They chose this date to facilitate free and fair elections in Nicaragua in February 1990 (even though the Reagan administration had pushed for a delay of contra disbandment).\nIn the resulting February 1990 elections, Violeta Chamorro and her party the UNO won an upset victory of 55% to 41% over Daniel Ortega. Opinion polls leading up to the elections divided along partisan lines, with 10 of 17 polls analyzed in a contemporary study predicting an UNO victory while seven predicted the Sandinistas would retain power.\nPossible explanations include that the Nicaraguan people were disenchanted with the Ortega government as well as the fact that already in November 1989, the White House had announced that the economic embargo against Nicaragua would continue unless Violeta Chamorro won. Also, there had been reports of intimidation from the side of the contras, with a Canadian observer mission claiming that 42 people were killed by the contras in \"election violence\" in October 1989. Sandinistas were also accused of intimidation and abuses during the election campaign. According to the Puebla Institute, by mid-December 1989, seven opposition leaders had been murdered, 12 had disappeared, 20 had been arrested, and 30 others assaulted. In late January 1990, the OAS observer team reported that \"a convoy of troops attacked four truckloads of UNO sympathizers with bayonets and rifle butts, threatening to kill them.\" This led many commentators to conclude that Nicaraguans voted against the Sandinistas out of fear of a continuation of the contra war and economic deprivation."}
{"id": "7550", "revid": "19404073", "url": "https://en.wikipedia.org/wiki?curid=7550", "title": "Craig Venter", "text": "John Craig Venter (born October 14, 1946) is an American scientist. He is known for leading one of the first draft sequences of the human genome and led the first team to transfect a cell with a synthetic chromosome. Venter founded Celera Genomics, the Institute for Genomic Research (TIGR) and the J. Craig Venter Institute (JCVI). He was the co-founder of Human Longevity Inc. and Synthetic Genomics. He was listed on \"Time\" magazine's 2007 and 2008 \"Time\" 100 list of the most influential people in the world. In 2010, the British magazine \"New Statesman\" listed Craig Venter at 14th in the list of \"The World's 50 Most Influential Figures 2010\". In 2012, Venter was honored with Dan David Prize for his contribution to genome research. He was elected to the American Philosophical Society in 2013. He is a member of the USA Science and Engineering Festival's advisory board.\nEarly life and education.\nVenter was born in Salt Lake City, Utah, the son of Elisabeth and John Venter. His family moved to Millbrae, California during his childhood. In his youth, he did not take his education seriously, preferring to spend his time on the water in boats or surfing. According to his biography, \"A Life Decoded\", he was said never to be a terribly engaged student, having Cs and Ds on his eighth-grade report cards. Venter considered that his behavior in his adolescence was indicative of attention deficit hyperactivity disorder (ADHD), and later found ADHD-linked genetic variants in his own DNA. He graduated from Mills High School. His father died suddenly at age 59 from cardiac arrest, giving him a lifelong awareness of his own mortality. He quotes a saying: \"If you want immortality, do something meaningful with your life.\"\nAlthough he opposed the Vietnam War, Venter was drafted and enlisted in the United States Navy where he worked as a hospital corpsman in the intensive-care ward of a field hospital. He served from 1967 to 1968 at the Naval Support Activity Danang in Vietnam. While in Vietnam, he attempted suicide by swimming out to sea, but changed his mind more than a mile out.\nBeing confronted with severely injured and dying marines on a daily basis instilled in him a desire to study medicine, although he later switched to biomedical research.\nVenter began his college education in 1969 at a community college, College of San Mateo in California, and later transferred to the University of California, San Diego, where he studied under biochemist Nathan O. Kaplan. He received a Bachelor of Science in biochemistry in 1972 and a Doctor of Philosophy in physiology and pharmacology in 1975 from UCSD.\nCareer.\nAfter working as an associate professor, and later as full professor, at the State University of New York at Buffalo, he joined the National Institutes of Health in 1984.\nEST controversy.\nWhile an employee of the NIH, Venter learned how to identify mRNA and began to learn more about those expressed in the human brain. The short cDNA sequence fragments Venter discovered by automated DNA sequencing, he named expressed sequence tags, or ESTs. The NIH Office of Technology Transfer decided to file a patent on the ESTs discovered by Venter. patent the genes identified based on studies of mRNA expression in the human brain. When Venter disclosed the NIH strategy during a Congressional hearing, a firestorm of controversy erupted. The NIH later stopped the effort and abandoned the patent applications it had filed, following public outcry.\nHuman Genome Project.\nVenter was passionate about the power of genomics to transform healthcare radically. Venter believed that shotgun sequencing was the fastest and most effective way to get useful human genome data. The method was rejected by the Human Genome Project however, since some geneticists felt it would not be accurate enough for a genome as complicated as that of humans, that it would be logistically more difficult, and that it would cost significantly more.\nVenter viewed the slow pace of progress in the Human Genome project as an opportunity to continue his interest in trying his shotgun sequencing method to speed up the human genome sequencing so when he was offered funding from a DNA sequencing company to start Celera Genomics. The company planned to profit from their work by creating genomic data to which users could subscribe for a fee. The goal consequently put pressure on the public genome program and spurred several groups to redouble their efforts to produce the full sequence. Venter's effort won him renown as he and his team at Celera Corporation shared credit for sequencing the first draft human genome with the publicly funded Human Genome Project.\nIn 2000, Venter and Francis Collins of the National Institutes of Health and U.S. Public Genome Project jointly made the announcement of the mapping of the human genome, a full three years ahead of the expected end of the Public Genome Program. The announcement was made along with U.S. President Bill Clinton, and UK Prime Minister Tony Blair. Venter and Collins thus shared an award for \"Biography of the Year\" from A&amp;E Network.\nOn February 15, 2001, the Human Genome Project consortium published the first Human Genome in the journal \"Nature\", followed one day later by a Celera publication in \"Science\". Despite some claims that shotgun sequencing was in some ways less accurate than the clone-by-clone method chosen by the Human Genome Project, the technique became widely accepted by the scientific community.\nVenter was fired by Celera in early 2002. According to his biography, Venter was fired because of a conflict with the main investor, Tony White, specifically barring him from attending the White House ceremony celebrating the achievement of sequencing the human genome.\nGlobal Ocean Sampling Expedition.\nThe Global Ocean Sampling Expedition (GOS) is an ocean exploration genome project with the goal of assessing the genetic diversity in marine microbial communities and to understand their role in nature's fundamental processes. Begun as a Sargasso Sea pilot sampling project in August 2003, the full Expedition was announced by Venter on March 4, 2004. The project, which used Venter's personal yacht, \"Sorcerer II\", started in Halifax, Canada, circumnavigated the globe and returned to the U.S. in January 2006.\nSynthetic Genomics.\nIn June 2005, Venter co-founded Synthetic Genomics, a firm dedicated to using modified microorganisms to produce clean fuels and biochemicals. In July 2009, ExxonMobil announced a $600 million collaboration with Synthetic Genomics to research and develop next-generation biofuels. \nVenter continues to work on the creation of engineered diatomic microalgae for the production of biofuels.\nVenter is seeking to patent the first partially synthetic species possibly to be named \"Mycoplasma laboratorium\". There is speculation that this line of research could lead to producing bacteria that have been engineered to perform specific reactions, for example, produce fuels, make medicines, combat global warming, and so on.\nIn May 2010, a team of scientists led by Venter became the first to create successfully what was described as \"synthetic life\". This was done by synthesizing a very long DNA molecule containing an entire bacterium genome, and introducing this into another cell, analogous to the accomplishment of Eckard Wimmer's group, who synthesized and ligated an RNA virus genome and \"booted\" it in cell lysate. The single-celled organism contains four \"watermarks\"\nwritten into its DNA to identify it as synthetic and to help trace its descendants. The watermarks include \nOn March 25, 2016, Venter reported the creation of Syn 3.0, a synthetic genome having the fewest genes of any freely living organism (473 genes). Their aim was to strip away all nonessential genes, leaving only the minimal set necessary to support life.\nThis stripped-down, fast reproducing cell is expected to be a valuable tool for researchers in the field.\nIn August 2018, Venter retired as chairman of the board, saying he wanted to focus on his work at the J. Craig Venter Institute. He will remain as a scientific advisor to the board.\nJ. Craig Venter Institute.\nIn 2006 Venter founded the J. Craig Venter Institute (JCVI), a nonprofit which conducts research in synthetic biology. It has facilities in La Jolla and in Rockville, Maryland and employs over 200 people.\nIn April 2022 Venter sold the La Jolla JCVI facility to the University of California, San Diego for $25 million. Venter will continue to lead a separate nonprofit research group, also known as the J. Craig Venter Institute, and stressed that he is not retiring. The Venter Institute has out grown its current building with multiple new facility hires and will be moving into new space in 2025.\nIndividual human genome.\nOn September 4, 2007, a team led by Sam Levy published one of the first genomes of an individual human\u2014Venter's own DNA sequence. Some of the sequences in Venter's genome are associated with wet earwax, increased risk of antisocial behavior, Alzheimer's and cardiovascular diseases. \nThe Human Reference Genome Browser is a web application for the navigation and analysis of Venter's recently published genome. The HuRef database consists of approximately 32 million DNA reads sequenced using microfluidic Sanger sequencing, assembled into 4,528 scaffolds and 4.1 million DNA variations identified by genome analysis. These variants include single-nucleotide polymorphisms (SNPs), block substitutions, short and large indels, and structural variations like insertions, deletions, inversions and copy number changes.\nThe browser enables scientists to navigate the HuRef genome assembly and sequence variations, and to compare it with the NCBI human build 36 assembly in the context of the NCBI and Ensembl annotations. The browser provides a comparative view between NCBI and HuRef consensus sequences, the sequence multi-alignment of the HuRef assembly, Ensembl and dbSNP annotations, HuRef variants, and the underlying variant evidence and functional analysis. The interface also represents the haplotype blocks from which diploid genome sequence can be inferred and the relation of variants to gene annotations. The display of variants and gene annotations are linked to external public resources including dbSNP, Ensembl, Online Mendelian Inheritance in Man (OMIM) and Gene Ontology (GO).\nUsers can search the HuRef genome using HUGO gene names, Ensembl and dbSNP identifiers, HuRef contig or scaffold locations, or NCBI chromosome locations. Users can then easily and quickly browse any genomic region via the simple and intuitive pan and zoom controls; furthermore, data relevant to specific loci can be exported for further analysis.\nHuman Longevity, Inc..\nOn March 4, 2014, Venter and co-founders Peter Diamandis and Robert Hariri announced the formation of Human Longevity, Inc., a company focused on extending the healthy, \"high performance\" human lifespan. At the time of the announcement the company had already raised $70\u00a0million in venture financing, which was expected to last 18\u00a0months. Venter served as the chairman and chief executive officer\u00a0(CEO) until May 2018, when he retired. The company said that it plans to sequence 40,000 genomes per year, with an initial focus on cancer genomes and the genomes of cancer patients.\nHuman Longevity filed a lawsuit in 2018 against Venter, accusing him of stealing trade secrets. Allegations were made stating that Venter had departed with his company computer that contained valuable information that could be used to start a competing business. The lawsuit was ultimately dismissed by a California judge on the basis that Human Longevity were unable to present a case that met the legal threshold required for a company, or individual, to sue when its trade secrets have been stolen.\nHuman Longevity's mission is to extend healthy human lifespan by the use of high-resolution big data diagnostics from genomics, metabolomics, microbiomics, and proteomics, and the use of stem cell therapy.\nPublished books.\nVenter is the author of three books, the first of which is an autobiography titled \"A Life Decoded\". In Venter's second book, \"Life at the Speed of Light\", he announced his theory that this is the generation in which there appears to be a dovetailing of the two previously diverse fields of science represented by computer programming and the genetic programming of life by DNA sequencing. He was applauded for his position on this by futurist Ray Kurzweil. Venter's most recent book, co-authored by David Ewing Duncan, \"The Voyage of Sorcerer II: The Expedition that Unlocked the Secrets of the Ocean\u2019s Microbiome\", details the Global Ocean Sampling Expedition, spanning a 15-year period during which microbes from the world's oceans were collected and their DNA sequenced.\nPersonal life.\nAfter a 12-year marriage to Barbara Rae-Venter, with whom he had a son, Christopher, he married Claire M. Fraser remaining married to her until 2005. In late 2008 he married Heather Kowalski. They live in the La Jolla neighborhood of San Diego, CA. Venter is an atheist.\nVenter was 75 when he sold his main research building to UCSD in 2022. The institute had out grown the space and will be moving to a new facility in 2025. The Venter Institute campus in Rockville MD also continues to expand. He said he has no intention of retiring. He has a home in La Jolla and a ranch in Borrego Springs, California, as well as homes in two small towns in Maine. He indulges in two passions: sailing and flying a Cirrus 22T plane, which he calls \"the ultimate freedom\".\nIn popular culture.\nVenter has been the subject of articles in several magazines, including \"Wired\", \"The Economist\", Australian science magazine \"Cosmos\", and \"The Atlantic\".\nVenter appears in the two-hour 2001 \"NOVA\" special, \"Cracking the code of life\".\nOn May 16, 2004, Venter gave the commencement speech at Boston University.\nOn December 4, 2007, Venter gave the Dimbleby lecture for the BBC in London.\nVenter gave the Distinguished Public Lecture during the 2007 Michaelmas Term at the James Martin 21st Century School at Oxford University. Its title was \"Genomics \u2013 From humans to the environment\".\nVenter delivered the 2008 convocation speech for Faculty of Science honours and specialization students at the University of Alberta.\nIn February 2008, he gave a speech about his current work at the TED conference.\nVenter was featured in \"Time\" magazine's \"The Top 10 Everything of 2008\" article. Number three in 2008's Top 10 Scientific Discoveries was a piece outlining his work stitching together the 582,000 base pairs necessary to invent the genetic information for a whole new bacterium.\nOn May 20, 2010, Venter announced the creation of first self-replicating semi-synthetic bacterial cell.\nIn the June 2011 issue of \"Men's Journal\", Venter was featured as the \"Survival Skills\" celebrity of the month. He shared various anecdotes and advice, including stories of his time in Vietnam, as well as mentioning a bout with melanoma on his back, which subsequently resulted in his \"giving a pound of flesh\" to surgery.\nIn May 2011, Venter was the commencement speaker at the 157th commencement of Syracuse University.\nIn May 2017, Venter was the guest of honor and keynote speaker at the inauguration ceremony of the Center for Systems Biology Dresden.\nWorks.\nVenter has authored over 200 publications in scientific journals."}
{"id": "7551", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7551", "title": "Chemical Evolution", "text": ""}
{"id": "7552", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=7552", "title": "Chemical evolution", "text": "Chemical evolution may refer to:"}
{"id": "7554", "revid": "19234557", "url": "https://en.wikipedia.org/wiki?curid=7554", "title": "Carl Rogers", "text": "Carl Ransom Rogers (January 8, 1902 \u2013 February 4, 1987) was an American psychologist who was one of the founders of humanistic psychology and was known especially for his person-centered psychotherapy. Rogers is widely considered one of the founding fathers of psychotherapy research and was honored for his research with the Award for Distinguished Scientific Contributions by the American Psychological Association (APA) in 1956.\nThe person-centered approach, Rogers's approach to understanding personality and human relationships, found wide application in various domains, such as psychotherapy and counseling (client-centered therapy), education (student-centered learning), organizations, and other group settings. For his professional work he received the Award for Distinguished Professional Contributions to Psychology from the APA in 1972. In a study by Steven J. Haggbloom and colleagues using six criteria such as citations and recognition, Rogers was found to be the sixth most eminent psychologist of the 20th century and second, among clinical psychologists, only to Sigmund Freud. Based on a 1982 survey of 422 respondents of U.S. and Canadian psychologists, he was considered the most influential psychotherapist in history (Freud ranked third).\nBiography.\nRogers was born on January 8, 1902, in Oak Park, Illinois, a suburb of Chicago. His father, Walter A. Rogers, was a civil engineer and a Congregationalist by religious denomination. His mother, Julia M. Cushing, was a homemaker and devout Baptist. Carl was the fourth of their six children.\nRogers was intelligent and could read well before kindergarten. After being raised in a strict religious environment as an altar boy at the vicarage of Jimpley, he became isolated, independent, and disciplined, gaining knowledge and an appreciation for the scientific method in a practical world. At the University of Wisconsin\u2013Madison, he joined the fraternity Alpha Kappa Lambda and initially planned to study agriculture before switching to history and finally settling on religion.\nAt age 20, following his 1922 trip to Beijing, China, for an international Christian conference, Rogers started to doubt his religious convictions. To help him clarify his career choice, he attended a seminar entitled \"Why Am I Entering the Ministry?\" after which he decided to change careers. In 1924, he graduated from the University of Wisconsin, married fellow Wisconsin student and Oak Park resident Helen Elliott, and enrolled at Union Theological Seminary in New York City. Sometime later, he reportedly became an atheist. Although referred to as an atheist early in his career, Rogers was eventually described as an agnostic. He reportedly spoke about spirituality quite often in his later years. Brian Thorne, who knew and collaborated with Rogers throughout the latter's final decade of life, writes: \"In his later years his openness to experience compelled him to acknowledge the existence of a dimension to which he attached such adjectives as mystical, spiritual, and transcendental\". Rogers concluded that there is a realm \"beyond\" scientific psychology\u2014a realm he came to prize as \"the indescribable, the spiritual.\"\nAfter two years at Union, Rogers left to attend Teachers College, Columbia University, obtaining an M.A. in 1927 and a Ph.D. in 1931. While completing his doctoral work, he engaged in scientific studies of children. As an intern in 1927\u20131928 at the now-defunct Institute for Child Guidance in New York, Rogers studied with psychologist Alfred Adler. Later in life, Rogers recalled: In 1930, Rogers served as director of the Society for the Prevention of Cruelty to Children in Rochester, New York. From 1935 to 1940, he lectured at the University of Rochester and wrote \"The Clinical Treatment of the Problem Child\" (1939), based on his experience in working with troubled children. He was strongly influenced in constructing his client-centered approach by the post-Freudian psychotherapeutic practice of Otto Rank, especially as embodied in the work of Rank's disciple: noted clinician and social work educator Jessie Taft. In 1940, Rogers became professor of clinical psychology at Ohio State University, where he wrote his second book, \"Counseling and Psychotherapy\" (1942). In it, Rogers suggests that by establishing a relationship with an understanding, accepting therapist, a client can resolve difficulties and gain the insight necessary to restructure their life.\nIn 1945, Rogers was invited to set up a counseling center at the University of Chicago. While a professor of psychology at the University of Chicago (1945\u20131957), Rogers helped establish a counseling center connected with the university and conducted studies to determine his methods' effectiveness. His findings and theories appeared in \"Client-Centered Therapy\" (1951) and \"Psychotherapy and Personality Change\" (1954). One of his graduate students at the University of Chicago, Thomas Gordon, established the Parent Effectiveness Training movement. Another student, Eugene T. Gendlin, who was getting his Ph.D. in philosophy, developed the psychotherapeutic method of focusing based on Rogerian listening.\nIn 1947, he was elected president of the American Psychological Association. In 1956, Rogers became the first president of the American Academy of Psychotherapists. He taught psychology at the University of Wisconsin, Madison (1957\u20131963). During this time, he wrote one of his best-known books, \"On Becoming a Person\" (1961). A student of his there, Marshall Rosenberg, went on to develop Nonviolent Communication. Rogers and Abraham Maslow pioneered a movement called humanistic psychology, which reached its peak in the 1960s. In 1961, he was elected a Fellow of the American Academy of Arts and Sciences. Rogers was also one of the people who questioned the rise of McCarthyism in the 1950s. In articles, he criticized society for its backward-looking affinities.\nRogers continued teaching at the University of Wisconsin until 1963 when he became a resident at the new Western Behavioral Sciences Institute (WBSI) in La Jolla, California. Rogers left the WBSI to help found the Center for Studies of the Person in 1968. His later books include \"Carl Rogers on Personal Power\" (1977) and \"Freedom to Learn for the '80s\" (1983). He remained a La Jolla resident for the rest of his life, doing therapy, giving speeches, and writing.\nIn his later years, Rogers focused on applying his theories to address political oppression and social conflict globally. He facilitated dialogue between Protestants and Catholics in Belfast, Blacks and Whites in South Africa, and people transitioning to democracy in Brazil. In the U.S., he worked with health consumers and providers. At 85, his final trip was to the Soviet Union, where he conducted workshops that promoted communication and creativity, impressed by the awareness of his work among Russians.\nBetween 1974 and 1984, Rogers, his daughter Natalie Rogers, and psychologists Maria Bowen, Maureen O'Hara, and John K. Wood convened a series of residential programs in the U.S., Europe, Brazil, and Japan: the Person-Centered Approach Workshops. The workshops focused on cross-cultural communications, personal growth, self-empowerment, and learning for social change.\nIn 1987, Rogers suffered a fall that resulted in a fractured pelvis; he had life alert and was able to contact paramedics. He had a successful operation, but his pancreas failed the next night, and he died a few days later after a heart attack.\nOne of Rogers's most famous quotations is: \"Death is final, and accepting that is the most difficult thing to undertake. That loved one is not coming back and nothing can change that. Nothing compares to them. Life is precious and vulnerable, so be wise with how you choose to spend it, because once death arrives there is no turning back.\"\nTheory.\nRogers's theory of the self is considered humanistic, existential, and phenomenological. It is based directly on the \"phenomenal field\" personality theory of Combs and Snygg (1949). Rogers's elaboration of his theory is extensive. He wrote 16 books and many more journal articles about it. Prochaska and Norcross (2003) states Rogers \"consistently stood for an empirical evaluation of psychotherapy. He and his followers have demonstrated a humanistic approach to conducting therapy and a scientific approach to evaluating therapy need not be incompatible.\"\nNineteen propositions.\nRogers's theory (as of 1951) was based on 19 propositions:\nIn relation to No. 17, Rogers is known for practicing \"unconditional positive regard\", which is defined as accepting a person \"without negative judgment of ... [a person's] basic worth\".\nDevelopment of the personality.\nWith regard to development, Rogers described principles rather than stages. The main issue is the development of a self-concept and the progress from an undifferentiated self to being fully differentiated.\nIn the development of the self-concept, he saw conditional and unconditional positive regard as key. Those raised in an environment of unconditional positive regard have the opportunity to fully actualize themselves. Those raised in an environment of conditional positive regard feel worthy only if they match conditions (what Rogers describes as \"conditions of worth\") that others have laid down for them.\nFully functioning person.\nOptimal development, as referred to in proposition 14, results in a certain process rather than static state. Rogers calls this \"the good life\", where the organism continually aims to fulfill its potential. He listed the characteristics of a fully functioning person (Rogers 1961):\nIncongruity.\nRogers identified the \"real self\" as the aspect of a person that is founded in the actualizing tendency, follows organismic values and needs, and receives positive regard from others and self. On the other hand, to the extent that society is out of sync with the actualizing tendency and people are forced to live with conditions of worth that are out of step with organismic valuing, receiving only conditional positive regard and self-regard, Rogers said that people develop instead an \"ideal self\". By \"ideal\", he was suggesting something not real, something always out of reach, a standard people cannot meet. This gap between the real self and the ideal self, the \"I am\" and the \"I should\", Rogers called \"incongruity\".\nPsychopathology.\nRogers described the concepts of \"congruence\" and \"incongruence\" as important in his theory. In proposition #6, he refers to the actualizing tendency. At the same time, he recognized the need for \"positive regard\". In a fully congruent person, realizing their potential is not at the expense of experiencing positive regard. They are able to lead authentic and genuine lives. Incongruent individuals, in their pursuit of positive regard, lead lives that include falsity and do not realize their potential. Conditions put on them by those around them make it necessary for them to forgo their genuine, authentic lives to meet with others' approval. They live lives that are not true to themselves.\nRogers suggested that the incongruent individual, who is always on the defensive and cannot be open to all experiences, is not functioning ideally and may even be malfunctioning. They work hard at maintaining and protecting their self-concept. Because their lives are not authentic, this is difficult, and they are under constant threat. They deploy \"defense mechanisms\" to achieve this. He describes two mechanisms: \"distortion\" and \"denial\". Distortion occurs when the individual perceives a threat to their self-concept. They distort the perception until it fits their self-concept. This defensive behavior reduces the consciousness of the threat but not the threat itself. And so, as the threats mount, the work of protecting the self-concept becomes more difficult and the individual becomes more defensive and rigid in their self-structure. If the incongruity is immoderate this process may lead the individual to a state that would typically be described as neurotic. Their functioning becomes precarious and psychologically vulnerable. If the situation worsens it is possible that the defenses cease to function altogether and the individual becomes aware of the incongruity of their situation. Their personality becomes disorganised and bizarre; irrational behavior, associated with earlier denied aspects of self, may erupt uncontrollably.\nApplications.\nPerson-centered therapy.\nRogers originally developed his theory as the foundation for a system of therapy. He initially called it \"non-directive therapy\" but later replaced the term \"non-directive\" with \"client-centered\", and still later \"person-centered\". Even before the publication of \"Client-Centered Therapy\" in 1951, Rogers believed the principles he was describing could be applied in a variety of contexts, not just in therapy. As a result, he started to use the term \"person-centered approach\" to describe his overall theory. Person-centered therapy is the application of the person-centered approach to therapy. Other applications include a theory of personality, interpersonal relations, education, nursing, cross-cultural relations and other \"helping\" professions and situations. In 1946 Rogers co-authored \"Counseling with Returned Servicemen\" with John L. Wallen (the creator of the behavioral model known as \"The Interpersonal Gap\"), documenting the application of person-centered approach to counseling military personnel returning from World War II.\nThe first empirical evidence of the client-centered approach's effectiveness was published in 1941 at the Ohio State University by Elias Porter, using the recordings of therapeutic sessions between Rogers and his clients. Porter used Rogers's transcripts to devise a system to measure the degree of directiveness or non-directiveness a counselor employed. The counselor's attitude and orientation were shown to be instrumental in the decisions the client made.\nLearner-centered teaching.\nThe application to education has a large robust research tradition similar to that of therapy, with studies having begun in the late 1930s and continuing today (Cornelius-White, 2007). Rogers described the approach to education in \"Client-Centered Therapy\" and wrote \"Freedom to Learn\" devoted exclusively to the subject in 1969. \"Freedom to Learn\" was revised twice. The new Learner-Centered Model is similar in many regards to this classical person-centered approach to education.\nBefore Rogers's death, he and Harold Lyon began a book, \"On Becoming an Effective Teacher\u2014Person-centered Teaching, Psychology, Philosophy, and Dialogues with Carl R. Rogers and Harold Lyon\", that Lyon and Reinhard Tausch completed and published in 2013. It contains Rogers's last unpublished writings on person-centered teaching. Rogers had the following five hypotheses regarding learner-centered education:\nRogerian rhetorical approach.\nIn 1970, Richard Young, Alton L. Becker, and Kenneth Pike published \"Rhetoric: Discovery and Change\", a widely influential college writing textbook that used a Rogerian approach to communication to revise the traditional Aristotelian framework for rhetoric. The Rogerian method of argument involves each side restating the other's position to the satisfaction of the other, among other principles. In a paper, it can be expressed by carefully acknowledging and understanding the opposition, rather than dismissing them.\nCross-cultural relations.\nThe application to cross-cultural relations has involved workshops in highly stressful situations and global locations, including conflicts and challenges in South Africa, Central America, and Ireland. Rogers, Alberto Zucconi, and Charles Devonshire co-founded the Istituto dell'Approccio Centrato sulla Persona (Person-Centered Approach Institute) in Rome, Italy.\nRogers's international work for peace culminated in the Rust Peace Workshop, which took place in November 1985 in Rust, Austria. Leaders from 17 nations convened to discuss the topic \"The Central America Challenge\". The meeting was notable for several reasons: it brought national figures together as people (not as their positions), it was a private event, and was an overwhelming positive experience where members heard one another and established real personal ties, as opposed to stiffly formal and regulated diplomatic meetings.\nPerson-centered, dialogic politics.\nSome scholars believe there is a politics implicit in Rogers's approach to psychotherapy. Toward the end of his life, Rogers came to that view himself. The central tenet of Rogerian, person-centered politics is that public life need not consist of an endless series of winner-take-all battles among sworn opponents; rather, it can and should consist of an ongoing dialogue among all parties. Such dialogue is characterized by respect among the parties, authentic speaking by each, and\u2014ultimately\u2014empathic understanding among all parties. Out of such understanding, mutually acceptable solutions will (or at least can) flow.\nDuring his last decade, Rogers facilitated or participated in a wide variety of dialogic activities among politicians, activists, and other social leaders, often outside the U.S. He also lent his support to several non-traditional U.S. political initiatives, including the \"12-Hour Political Party\" of the Association for Humanistic Psychology and the founding of a \"transformational\" political organization, the New World Alliance. By the 21st century, interest in dialogic approaches to political engagement and change had become widespread, especially among academics and activists. Theorists of a specifically Rogerian, person-centered approach to politics as dialogue have made substantial contributions to that project.\nCentral Intelligence Agency (CIA).\nFrom the late 1950s into the '60s, Rogers served on the board of the Human Ecology Fund, a CIA-funded organization that provided grants to researchers looking into personality. In addition, he and other people in the field of personality and psychotherapy were given a lot of information about Khrushchev. \"We were asked to figure out what we thought of him and what would be the best way of dealing with him. And that seemed to be an entirely principled and legitimate aspect. I don't think we contributed very much, but, anyway, we tried.\"\nResearch on his work.\nHoward Kirschenbaum has conducted extensive research on the work of Carl Rogers and the person-centered/client centered approach. Kirschenbaum published the first thorough book in English on Rogers\u2019 life and work, titled, \"On Becoming Carl Rogers\" in 1979, followed by the biography, \"The Life and Work of Carl Rogers\" in 2007."}
{"id": "7555", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7555", "title": "Casimir effect", "text": "In quantum field theory, the Casimir effect (or Casimir force) is a physical force acting on the macroscopic boundaries of a confined space which arises from the quantum fluctuations of a field. The term Casimir pressure is sometimes used when it is described in units of force per unit area. It is named after the Dutch physicist Hendrik Casimir, who predicted the effect for electromagnetic systems in 1948.\nIn the same year Casimir, together with Dirk Polder, described a similar effect experienced by a neutral atom in the vicinity of a macroscopic interface which is called the Casimir\u2013Polder force. Their result is a generalization of the London\u2013van der Waals force and includes retardation due to the finite speed of light. The fundamental principles leading to the London\u2013van der Waals force, the Casimir force, and the Casimir\u2013Polder force can be formulated on the same footing.\nIn 1997 a direct experiment by Steven K. Lamoreaux quantitatively measured the Casimir force to be within 5% of the value predicted by the theory.\nThe Casimir effect can be understood by the idea that the presence of macroscopic material interfaces, such as electrical conductors and dielectrics, alter the vacuum expectation value of the energy of the second-quantized electromagnetic field. Since the value of this energy depends on the shapes and positions of the materials, the Casimir effect manifests itself as a force between such objects.\nAny medium supporting oscillations has an analogue of the Casimir effect. For example, beads on a string as well as plates submerged in turbulent water or gas illustrate the Casimir force.\nIn modern theoretical physics, the Casimir effect plays an important role in the chiral bag model of the nucleon; in applied physics it is significant in some aspects of emerging microtechnologies and nanotechnologies.\nPhysical properties.\nThe typical example is of two uncharged conductive plates in a vacuum, placed a few nanometers apart. In a classical description, the lack of an external field means that no field exists between the plates, and no force connects them. When this field is instead studied using the quantum electrodynamic vacuum, it is seen that the plates do affect the virtual photons that constitute the field, and generate a net force \u2013 either an attraction or a repulsion depending on the plates' specific arrangement. Although the Casimir effect can be expressed in terms of virtual particles interacting with the objects, it is best described and more easily calculated in terms of the zero-point energy of a quantized field in the intervening space between the objects. This force has been measured and is a striking example of an effect captured formally by second quantization.\nThe treatment of boundary conditions in these calculations is controversial. In fact, \"Casimir's original goal was to compute the van der Waals force between polarizable molecules\" of the conductive plates. Thus it can be interpreted without any reference to the zero-point energy (vacuum energy) of quantum fields.\nBecause the strength of the force falls off rapidly with distance, it is measurable only when the distance between the objects is small. This force becomes so strong that it becomes the dominant force between uncharged conductors at submicron scales. In fact, at separations of 10\u00a0nm \u2013 about 100\u00a0times the typical size of an atom \u2013 the Casimir effect produces the equivalent of about 1\u00a0atmosphere of pressure (the precise value depends on surface geometry and other factors).\nHistory.\nDutch physicists Hendrik Casimir and Dirk Polder at Philips Research Labs proposed the existence of a force between two polarizable atoms and between such an atom and a conducting plate in 1947; this special form is called the Casimir\u2013Polder force. After a conversation with Niels Bohr, who suggested it had something to do with zero-point energy, Casimir alone formulated the theory predicting a force between neutral conducting plates in 1948. This latter phenomenon is called the Casimir effect.\nPredictions of the force were later extended to finite-conductivity metals and dielectrics, while later calculations considered more general geometries. Experiments before 1997 observed the force qualitatively, and indirect validation of the predicted Casimir energy was made by measuring the thickness of liquid helium films. Finally, in 1997 Lamoreaux's direct experiment quantitatively measured the force to within 5% of the value predicted by the theory. Subsequent experiments approached an accuracy of a few percent.\nPossible causes.\nVacuum energy.\nThe causes of the Casimir effect are described by quantum field theory, which states that all of the various fundamental fields, such as the electromagnetic field, must be quantized at each and every point in space. In a simplified view, a \"field\" in physics may be envisioned as if space were filled with interconnected vibrating balls and springs, and the strength of the field can be visualized as the displacement of a ball from its rest position. Vibrations in this field propagate and are governed by the appropriate wave equation for the particular field in question. The second quantization of quantum field theory requires that each such ball-spring combination be quantized, that is, that the strength of the field be quantized at each point in space. At the most basic level, the field at each point in space is a simple harmonic oscillator, and its quantization places a quantum harmonic oscillator at each point. Excitations of the field correspond to the elementary particles of particle physics. However, even the vacuum has a vastly complex structure, so all calculations of quantum field theory must be made in relation to this model of the vacuum.\nThe vacuum has, implicitly, all of the properties that a particle may have: spin, or polarization in the case of light, energy, and so on. On average, most of these properties cancel out: the vacuum is, after all, \"empty\" in this sense. One important exception is the vacuum energy or the vacuum expectation value of the energy. The quantization of a simple harmonic oscillator states that the lowest possible energy or zero-point energy that such an oscillator may have is\nformula_1\nSumming over all possible oscillators at all points in space gives an infinite quantity. Since only \"differences\" in energy are physically measurable (with the notable exception of gravitation, which remains beyond the scope of quantum field theory), this infinity may be considered a feature of the mathematics rather than of the physics. This argument is the underpinning of the theory of renormalization. Dealing with infinite quantities in this way was a cause of widespread unease among quantum field theorists before the development in the 1970s of the renormalization group, a mathematical formalism for scale transformations that provides a natural basis for the process.\nWhen the scope of the physics is widened to include gravity, the interpretation of this formally infinite quantity remains problematic. There is currently no compelling explanation as to why it should not result in a cosmological constant that is many orders of magnitude larger than observed. However, since we do not yet have any fully coherent quantum theory of gravity, there is likewise no compelling reason as to why it should instead actually result in the value of the cosmological constant that we observe.\nThe Casimir effect for fermions can be understood as the spectral asymmetry of the fermion operator, where it is known as the Witten index.\nRelativistic van der Waals force.\nAlternatively, a 2005 paper by Robert Jaffe of MIT states that \"Casimir effects can be formulated and Casimir forces can be computed without reference to zero-point energies. They are relativistic, quantum forces between charges and currents. The Casimir force (per unit area) between parallel plates vanishes as alpha, the fine structure constant, goes to zero, and the standard result, which appears to be independent of alpha, corresponds to the alpha approaching infinity limit\", and that \"The Casimir force is simply the (relativistic, retarded) van der Waals force between the metal plates.\" Casimir and Polder's original paper used this method to derive the Casimir\u2013Polder force. In 1978, Schwinger, DeRadd, and Milton published a similar derivation for the Casimir effect between two parallel plates. More recently, Nikolic proved from first principles of quantum electrodynamics that the Casimir force does not originate from the vacuum energy of the electromagnetic field, and explained in simple terms why the fundamental microscopic origin of Casimir force lies in van der Waals forces.\nEffects.\nCasimir's observation was that the second-quantized quantum electromagnetic field, in the presence of bulk bodies such as metals or dielectrics, must obey the same boundary conditions that the classical electromagnetic field must obey. In particular, this affects the calculation of the vacuum energy in the presence of a conductor or dielectric.\nConsider, for example, the calculation of the vacuum expectation value of the electromagnetic field inside a metal cavity, such as, for example, a radar cavity or a microwave waveguide. In this case, the correct way to find the zero-point energy of the field is to sum the energies of the standing waves of the cavity. To each and every possible standing wave corresponds an energy; say the energy of the th standing wave is . The vacuum expectation value of the energy of the electromagnetic field in the cavity is then\nformula_2\nwith the sum running over all possible values of enumerating the standing waves. The factor of is present because the zero-point energy of the th mode is , where is the energy increment for the th mode. (It is the same as appears in the equation .) Written in this way, this sum is clearly divergent; however, it can be used to create finite expressions.\nIn particular, one may ask how the zero-point energy depends on the shape of the cavity. Each energy level depends on the shape, and so one should write for the energy level, and for the vacuum expectation value. At this point comes an important observation: The force at point on the wall of the cavity is equal to the change in the vacuum energy if the shape of the wall is perturbed a little bit, say by , at . That is, one has\nformula_3\nThis value is finite in many practical calculations.\nAttraction between the plates can be easily understood by focusing on the one-dimensional situation. Suppose that a moveable conductive plate is positioned at a short distance from one of two widely separated plates (distance apart). With , the states within the slot of width are highly constrained so that the energy of any one mode is widely separated from that of the next. This is not the case in the large region where there is a large number of states (about ) with energy evenly spaced between and the next mode in the narrow slot, or in other words, all slightly larger than . Now on shortening by an amount (which is negative), the mode in the narrow slot shrinks in wavelength and therefore increases in energy proportional to , whereas all the states that lie in the large region lengthen and correspondingly decrease their energy by an amount proportional to (note the different denominator). The two effects nearly cancel, but the net change is slightly negative, because the energy of all the modes in the large region are slightly larger than the single mode in the slot. Thus the force is attractive: it tends to make slightly smaller, the plates drawing each other closer, across the thin slot.\nDerivation of Casimir effect assuming zeta-regularization.\nIn the original calculation done by Casimir, he considered the space between a pair of conducting metal plates at distance apart. In this case, the standing waves are particularly easy to calculate, because the transverse component of the electric field and the normal component of the magnetic field must vanish on the surface of a conductor. Assuming the plates lie parallel to the -plane, the standing waves are\nformula_4\nwhere stands for the electric component of the electromagnetic field, and, for brevity, the polarization and the magnetic components are ignored here. Here, and are the wavenumbers in directions parallel to the plates, and\nformula_5\nis the wavenumber perpendicular to the plates. Here, is an integer, resulting from the requirement that vanish on the metal plates. The frequency of this wave is\nformula_6\nwhere is the speed of light. The vacuum energy is then the sum over all possible excitation modes. Since the area of the plates is large, we may sum by integrating over two of the dimensions in -space. The assumption of periodic boundary conditions yields,\nformula_7\nwhere is the area of the metal plates, and a factor of 2 is introduced for the two possible polarizations of the wave. This expression is clearly infinite, and to proceed with the calculation, it is convenient to introduce a regulator (discussed in greater detail below). The regulator will serve to make the expression finite, and in the end will be removed. The zeta-regulated version of the energy per unit-area of the plate is\nformula_8\nIn the end, the limit is to be taken. Here is just a complex number, not to be confused with the shape discussed previously. This integral sum is finite for real and larger than 3. The sum has a pole at , but may be analytically continued to , where the expression is finite. The above expression simplifies to:\nformula_9\nwhere polar coordinates were introduced to turn the double integral into a single integral. The in front is the Jacobian, and the comes from the angular integration. The integral converges if , resulting in\nformula_10\nThe sum diverges at in the neighborhood of zero, but if the damping of large-frequency excitations corresponding to analytic continuation of the Riemann zeta function to is assumed to make sense physically in some way, then one has\nformula_11\nBut and so one obtains\nformula_12\nThe analytic continuation has evidently lost an additive positive infinity, somehow exactly accounting for the zero-point energy (not included above) outside the slot between the plates, but which changes upon plate movement within a closed system. The Casimir force per unit area for idealized, perfectly conducting plates with vacuum between them is\nformula_13\nwhere\nThe force is negative, indicating that the force is attractive: by moving the two plates closer together, the energy is lowered. The presence of shows that the Casimir force per unit area is very small, and that furthermore, the force is inherently of quantum-mechanical origin.\nBy integrating the equation above it is possible to calculate the energy required to separate to infinity the two plates as:\nformula_14\nwhere\nIn Casimir's original derivation, a moveable conductive plate is positioned at a short distance from one of two widely separated plates (distance apart). The zero-point energy on \"both\" sides of the plate is considered. Instead of the above \"ad hoc\" analytic continuation assumption, non-convergent sums and integrals are computed using Euler\u2013Maclaurin summation with a regularizing function (e.g., exponential regularization) not so anomalous as in the above.\nMore recent theory.\nCasimir's analysis of idealized metal plates was generalized to arbitrary dielectric and realistic metal plates by Evgeny Lifshitz and his students. Using this approach, complications of the bounding surfaces, such as the modifications to the Casimir force due to finite conductivity, can be calculated numerically using the tabulated complex dielectric functions of the bounding materials. Lifshitz's theory for two metal plates reduces to Casimir's idealized force law for large separations much greater than the skin depth of the metal, and conversely reduces to the force law of the London dispersion force (with a coefficient called a Hamaker constant) for small , with a more complicated dependence on for intermediate separations determined by the dispersion of the materials.\nLifshitz's result was subsequently generalized to arbitrary multilayer planar geometries as well as to anisotropic and magnetic materials, but for several decades the calculation of Casimir forces for non-planar geometries remained limited to a few idealized cases admitting analytical solutions. For example, the force in the experimental sphere\u2013plate geometry was computed with an approximation (due to Derjaguin) that the sphere radius is much larger than the separation , in which case the nearby surfaces are nearly parallel and the parallel-plate result can be adapted to obtain an approximate force (neglecting both skin-depth and higher-order curvature effects). However, in the 2010s a number of authors developed and demonstrated a variety of numerical techniques, in many cases adapted from classical computational electromagnetics, that are capable of accurately calculating Casimir forces for arbitrary geometries and materials, from simple finite-size effects of finite plates to more complicated phenomena arising for patterned surfaces or objects of various shapes.\nMeasurement.\nOne of the first experimental tests was conducted by Marcus Sparnaay at Philips in Eindhoven (Netherlands), in 1958, in a delicate and difficult experiment with parallel plates, obtaining results not in contradiction with the Casimir theory, but with large experimental errors.\nThe Casimir effect was measured more accurately in 1997 by Steve K. Lamoreaux of Los Alamos National Laboratory, and by Umar Mohideen and Anushree Roy of the University of California, Riverside. In practice, rather than using two parallel plates, which would require phenomenally accurate alignment to ensure they were parallel, the experiments use one plate that is flat and another plate that is a part of a sphere with a very large radius.\nIn 2001, a group (Giacomo Bressi, Gianni Carugno, Roberto Onofrio and Giuseppe Ruoso) at the University of Padua (Italy) finally succeeded in measuring the Casimir force between parallel plates using microresonators. Numerous variations of these experiments are summarized in the 2009 review by Klimchitskaya.\nIn 2013, a conglomerate of scientists from Hong Kong University of Science and Technology, University of Florida, Harvard University, Massachusetts Institute of Technology, and Oak Ridge National Laboratory demonstrated a compact integrated silicon chip that can measure the Casimir force. The integrated chip defined by electron-beam lithography does not need extra alignment, making it an ideal platform for measuring Casimir force between complex geometries. In 2017 and 2021, the same group from Hong Kong University of Science and Technology demonstrated the non-monotonic Casimir force and distance-independent Casimir force, respectively, using this on-chip platform.\nRegularization.\nIn order to be able to perform calculations in the general case, it is convenient to introduce a regulator in the summations. This is an artificial device, used to make the sums finite so that they can be more easily manipulated, followed by the taking of a limit so as to remove the regulator.\nThe heat kernel or exponentially regulated sum is\nformula_15\nwhere the limit is taken in the end. The divergence of the sum is typically manifested as\nformula_16\nfor three-dimensional cavities. The infinite part of the sum is associated with the bulk constant which \"does not\" depend on the shape of the cavity. The interesting part of the sum is the finite part, which is shape-dependent. The Gaussian regulator\nformula_17\nis better suited to numerical calculations because of its superior convergence properties, but is more difficult to use in theoretical calculations. Other, suitably smooth, regulators may be used as well. The zeta function regulator\nformula_18\nis completely unsuited for numerical calculations, but is quite useful in theoretical calculations. In particular, divergences show up as poles in the complex plane, with the bulk divergence at . This sum may be analytically continued past this pole, to obtain a finite part at .\nNot every cavity configuration necessarily leads to a finite part (the lack of a pole at ) or shape-independent infinite parts. In this case, it should be understood that additional physics has to be taken into account. In particular, at extremely large frequencies (above the plasma frequency), metals become transparent to photons (such as X-rays), and dielectrics show a frequency-dependent cutoff as well. This frequency dependence acts as a natural regulator. There are a variety of bulk effects in solid state physics, mathematically very similar to the Casimir effect, where the cutoff frequency comes into explicit play to keep expressions finite. (These are discussed in greater detail in \"Landau and Lifshitz\", \"Theory of Continuous Media\".)\nGeneralities.\nThe Casimir effect can also be computed using the mathematical mechanisms of functional integrals of quantum field theory, although such calculations are considerably more abstract, and thus difficult to comprehend. In addition, they can be carried out only for the simplest of geometries. However, the formalism of quantum field theory makes it clear that the vacuum expectation value summations are in a certain sense summations over so-called \"virtual particles\".\nMore interesting is the understanding that the sums over the energies of standing waves should be formally understood as sums over the eigenvalues of a Hamiltonian. This allows atomic and molecular effects, such as the Van der Waals force, to be understood as a variation on the theme of the Casimir effect. Thus one considers the Hamiltonian of a system as a function of the arrangement of objects, such as atoms, in configuration space. The change in the zero-point energy as a function of changes of the configuration can be understood to result in forces acting between the objects.\nIn the chiral bag model of the nucleon, the Casimir energy plays an important role in showing the mass of the nucleon is independent of the bag radius. In addition, the spectral asymmetry is interpreted as a non-zero vacuum expectation value of the baryon number, cancelling the topological winding number of the pion field surrounding the nucleon.\nA \"pseudo-Casimir\" effect can be found in liquid crystal systems, where the boundary conditions imposed through anchoring by rigid walls give rise to a long-range force, analogous to the force that arises between conducting plates.\nDynamical Casimir effect.\nThe dynamical Casimir effect is the production of particles and energy from an accelerated \"moving mirror\". This reaction was predicted by certain numerical solutions to quantum mechanics equations made in the 1970s. In May 2011 an announcement was made by researchers at the Chalmers University of Technology, in Gothenburg, Sweden, of the detection of the dynamical Casimir effect. In their experiment, microwave photons were generated out of the vacuum in a superconducting microwave resonator. These researchers used a modified SQUID to change the effective length of the resonator in time, mimicking a mirror moving at the required relativistic velocity. If confirmed this would be the first experimental verification of the dynamical Casimir effect. In March 2013 an article appeared on the PNAS scientific journal describing an experiment that demonstrated the dynamical Casimir effect in a Josephson metamaterial. In July 2019 an article was published describing an experiment providing evidence of optical dynamical Casimir effect in a dispersion-oscillating fibre. In 2020, Frank Wilczek et al., proposed a resolution to the information loss paradox associated with the moving mirror model of the dynamical Casimir effect. Constructed within the framework of quantum field theory in curved spacetime, the dynamical Casimir effect (moving mirror) has been used to help understand the Unruh effect.\nRepulsive forces.\nThere are few instances wherein the Casimir effect can give rise to repulsive forces between uncharged objects. Evgeny Lifshitz showed (theoretically) that in certain circumstances (most commonly involving liquids), repulsive forces can arise. This has sparked interest in applications of the Casimir effect toward the development of levitating devices. An experimental demonstration of the Casimir-based repulsion predicted by Lifshitz was carried out by Munday et al. who described it as \"quantum levitation\". Other scientists have also suggested the use of gain media to achieve a similar levitation effect, though this is controversial because these materials seem to violate fundamental causality constraints and the requirement of thermodynamic equilibrium (Kramers\u2013Kronig relations). Casimir and Casimir\u2013Polder repulsion can in fact occur for sufficiently anisotropic electrical bodies; for a review of the issues involved with repulsion see Milton et al. A notable recent development on repulsive Casimir forces relies on using chiral materials. Q.-D. Jiang at Stockholm University and Nobel Laureate Frank Wilczek at MIT show that chiral \"lubricant\" can generate repulsive, enhanced, and tunable Casimir interactions.\nTimothy Boyer showed in his work published in 1968 that a conductor with spherical symmetry will also show this repulsive force, and the result is independent of radius. Further work shows that the repulsive force can be generated with materials of carefully chosen dielectrics.\nSpeculative applications.\nIt has been suggested that the Casimir forces have application in nanotechnology, in particular silicon integrated circuit technology based micro- and nanoelectromechanical systems, and so-called Casimir oscillators.\nIn 1995 and 1998 Maclay et al. published the first models of a microelectromechanical system (MEMS) with Casimir forces. While not exploiting the Casimir force for useful work, the papers drew attention from the MEMS community due to the revelation that Casimir effect needs to be considered as a vital factor in the future design of MEMS. In particular, Casimir effect might be the critical factor in the stiction failure of MEMS.\nIn 2001, Capasso et al. showed how the force can be used to control the mechanical motion of a MEMS device, The researchers suspended a polysilicon plate from a torsional rod \u2013 a twisting horizontal bar just a few microns in diameter. When they brought a metallized sphere close up to the plate, the attractive Casimir force between the two objects made the plate rotate. They also studied the dynamical behaviour of the MEMS device by making the plate oscillate. The Casimir force reduced the rate of oscillation and led to nonlinear phenomena, such as hysteresis and bistability in the frequency response of the oscillator. According to the team, the system's behaviour agreed well with theoretical calculations.\nThe Casimir effect shows that quantum field theory allows the energy density in very small regions of space to be negative relative to the ordinary vacuum energy, and the energy densities cannot be arbitrarily negative as the theory breaks down at atomic distances. Such prominent physicists such as Stephen Hawking and Kip Thorne, have speculated that such effects might make it possible to stabilize a traversable wormhole."}
{"id": "7558", "revid": "33049997", "url": "https://en.wikipedia.org/wiki?curid=7558", "title": "Coin", "text": "A coin is a small object, usually round and flat, used primarily as a medium of exchange or legal tender. They are standardized in weight, and produced in large quantities at a mint in order to facilitate trade. They are most often issued by a government. Coins often have images, numerals, or text on them. The faces of coins or medals are sometimes called the \"obverse\" and the \"reverse\", referring to the front and back sides, respectively. The obverse of a coin is commonly called \"heads\", because it often depicts the head of a prominent person, and the reverse is known as \"tails\".\nThe first metal coins \u2013 invented in the ancient Greek world and disseminated during the Hellenistic period \u2013 were precious metal\u2013based, and were invented in order to simplify and regularize the task of measuring and weighing bullion (bulk metal) carried around for the purpose of transactions. They carried their value within the coins themselves, but the stampings also induced manipulations, such as the clipping of coins to remove some of the precious metal.\nMost modern coinage metals are base metal, and their value comes from their status as fiat money \u2014 the value of the coin is established by law. In the last hundred years, the face value of circulated coins has occasionally been lower than the value of the metal they contain, primarily due to inflation. If the difference becomes significant, the issuing authority may decide to withdraw these coins from circulation, possibly issuing new equivalents with a different composition, or the public may decide to melt the coins down or hoard them (see Gresham's law). Currently coins are used as money in everyday transactions, circulating alongside banknotes. Usually, the highest value coin in circulation (excluding bullion coins) is worth less than the lowest-value note. Coins are usually more efficient than banknotes because they last longer: banknotes last only about four years, compared with 30 years for a coin.\nExceptions to the rule of face value being higher than content value currently occur for bullion coins made of copper, silver, or gold (and rarely other metals, such as platinum or palladium), intended for collectors or investors in precious metals. Examples of modern gold collector/investor coins include the British sovereign minted by the United Kingdom, the American Gold Eagle minted by the United States, the Canadian Gold Maple Leaf minted by Canada, and the Krugerrand, minted by South Africa. While the Eagle and Sovereign coins have nominal (purely symbolic) face values, the Krugerrand does not. Commemorative coins usually serve as collectors items only, although some countries also issue commemorative coins for regular circulation, such as the 2\u20ac commemorative coins and U.S. America the Beautiful quarters.\nHistory.\nEarly metal coinage came into use about the time of the Axial Age in West Asia, in the Greek world, in northern India, and in China.\nBullion and unmarked metals.\nMetal ingots, silver bullion or unmarked bars were probably in use for exchange among many of the civilizations that mastered metallurgy. The weight and purity of bullion would be the key determinant of value. In the Achaemenid Empire in the early 6th century BC, coinage was yet unknown. The barter system, as well as silver bullion were used instead for trade. The practice of using silver bars for currency also seems to have been current in Central Asia from the 6th century BC. Coins were an evolution of \"currency\" systems of the Late Bronze Age, when various cultures used standard-sized ingots and tokens such as knife money to store and transfer value. Phoenician metal ingots had to be stamped with the name of a current ruler to guarantee their worth and value, which is probably how stamping busts and designs began, although political advertising \u2013 glorification of a state or of a ruler \u2013 may also play a role.\nTongbei in Bronze Age China (c. 1100 BC).\nIn the late Chinese Bronze Age, standardized cast tokens were made, such as those discovered in a tomb near Anyang. These were replicas in bronze of earlier Chinese currency, cowrie shells, so they were named \"Bronze Shell\".\nChina Henan Coin Factory (c. 640 \u2013 550 BC).\nThe world's oldest known coin factory has been excavated in the ancient city \"Guanzhuang\" in Henan province in China. The factory produced shovel-shaped bronze coins between 640 B.C. and 550 B.C., making it the oldest securely-dated minting-site.\nIron Age.\nLydian and Ionian electrum coins (c. 600 BC).\nThe earliest coins are mostly associated with Iron Age Anatolia of the late 7th century BC, and especially with the kingdom of Lydia. Early electrum coins (an alluvial alloy of gold and silver, varying wildly in proportion, and usually about 40\u201355% gold) were not standardized in weight, and in their earliest stage may have been ritual objects, such as badges or medals, issued by priests. The unpredictability of the composition of naturally occurring electrum implied that it had a variable value, which greatly hampered its development.\nMost of the early Lydian coins include no writing (\"myth\" or \"inscription\"), only an image of a symbolic animal. Therefore, the dating of these coins relies primarily on archaeological evidence, with the most commonly cited evidence coming from excavations at the Temple of Artemis at Ephesus, also called the Ephesian Artemision (which would later evolve into one of the Seven Wonders of the Ancient World). This was the site of the earliest known deposit of electrum coins. Anatolian Artemis was the \u03a0\u03cc\u03c4\u03bd\u03b9\u03b1 \u0398\u03b7\u03c1\u1ff6\u03bd (\"Potnia Th\u00ear\u00f4n\", \"Mistress of Animals\"), whose symbol was the stag. It took some time before ancient coins were used for commerce and trade. Even the smallest-denomination electrum coins, perhaps worth about a day's subsistence, would have been too valuable for buying a loaf of bread. Maybe the first coins to be used for retailing on a large-scale basis were likely small silver fractions, Hemiobol, Ancient Greek coinage minted by the Ionian Greeks in the late sixth century BC.\nIn contrast Herodotus mentioned the innovation made by the Lydians:\nAnd both Aristotle (fr. 611,37, ed. V. Rose) and Pollux (Onamastikon IX.83), mention that the first issuer of coinage was Hermodike/Demodike of Cyme. Cyme was a city in Aeolia, nearby Lydia.\nMany early Lydian and Greek coins were minted under the authority of private individuals and are thus more akin to tokens or badges than to modern coins, though due to their numbers it is evident that some were official state issues. The earliest inscribed coins are those of Phanes, dated to 625\u2013600 BC from Ephesus in Ionia, with the legend \u03a6\u0391\u0395\u039d\u039f\u03a3 \u0395\u039c\u0399 \u03a3H\u039c\u0391 (or similar) (\"I am the badge/sign/mark of Phanes/light\") or just bearing the name \u03a6\u0391\u039d\u0395\u039f\u03a3 (\"of Phanes\").\nThe first electrum coins issued by a monarch are those minted by king Alyattes of Lydia (died ), for which reason this king is sometimes mentioned as the originator of coinage.\nCroesus: Pure gold and silver coins.\nThe successor of Alyattes, king Croesus (r. c. 560\u2013546 BC), became associated with great wealth in Greek historiography. He is credited with issuing the \"Croeseid\", the first true gold coins with a standardized purity for general circulation. and the world's first bimetallic monetary system c. 550 BC.\nCoins spread rapidly in the 6th and 5th centuries BC, leading to the development of Ancient Greek coinage and Achaemenid coinage, and further to Illyrian coinage.\nAchaemenid coinage (546\u2013330 BC).\nWhen Cyrus the Great (550\u2013530 BC) came to power, coinage was unfamiliar in his realm. Barter and to some extent silver bullion was used instead for trade. The practice of using silver bars for currency also seems to have been current in Central Asia from the 6th century.\nCyrus the Great introduced coins to the Persian Empire after 546 BC, following his conquest of Lydia and the defeat of its king Croesus, who had put in place the first coinage in history. With his conquest of Lydia, Cyrus acquired a region in which coinage was invented, developed through advanced metallurgy, and had already been in circulation for about 50 years, making the Lydian Kingdom one of the leading trade powers of the time. It seems Cyrus initially adopted the Lydian coinage as such, and continued to strike Lydia's lion-and-bull coinage.\nOriginal coins of the Achaemenid Empire were issued from 520 BC \u2013 450 BC to 330 BC. The Persian Daric was the first truly Achaemenid gold coin which, along with a similar silver coin, the Siglos, represented the bimetallic monetary standard of the Achaemenid Persian Empire.\nCoinage of Southern Asia under the Achaemenid Empire.\nThe Achaemenid Empire already reached the doors of India during the original expansion of Cyrus the Great, and the Achaemenid conquest of the Indus Valley is dated to c. 515 BC under Darius I. An Achaemenid administration was established in the area. The Kabul hoard, also called the Chaman Hazouri hoard, is a coin hoard discovered in the vicinity of Kabul, Afghanistan, containing numerous Achaemenid coins as well as many Greek coins from the 5th and 4th centuries BC. The deposit of the hoard is dated to the Achaemenid period, in approximately 380 BC. The hoard also contained many locally produced silver coins, minted by local authorities under Achaemenid rule. Several of these issues follow the \"western designs\" of the facing bull heads, a stag, or Persian column capitals on the obverse, and incuse punch on the reverse.\nAccording to numismatist Joe Cribb, these finds suggest that the idea of coinage and the use of punch-marked techniques was introduced to India from the Achaemenid Empire during the 4th century BC. More Achaemenid coins were also found in Pushkalavati and in Bhir Mound.\nGreek Archaic coinage (until about 480 BC).\nAccording to Aristotle (fr. 611,37, ed. V. Rose) and Pollux (Onamastikon IX.83), the first issuer of Greek coinage was Hermodike of Kyme.\nA small percentage of early Lydian/Greek coins have a legend. The most ancient inscribed coin known is from nearby Caria. This coin has a Greek legend reading \"phaenos emi sema\" interpreted variously as \"I am the badge of Phanes\", or \"I am the sign of light\". The Phanes coins are among the earliest of Greek coins; a hemihekte of the issue was found in the foundation deposit of the temple of Artemis at Ephesos (the oldest deposit of electrum coins discovered). One assumption is that Phanes was a mercenary mentioned by Herodotus, another that this coin is associated with the primeval god Phanes or \"Phanes\" might have been an epithet of the local goddess identified with Artemis. Barclay V. Head found these suggestions unlikely and thought it more probably \"the name of some prominent citizen of Ephesus\".\nAnother candidate for the site of the earliest coins is Aegina, where Chelone (\"turtle\") coins were first minted c. 700 BC. Coins from Athens and Corinth appeared shortly thereafter, known to exist at least since the late 6th century BC.\nAntiquity.\nClassical Greek antiquity (480 BC~).\nThe Classical period saw Greek coinage reach a high level of technical and aesthetic quality. Larger cities now produced a range of fine silver and gold coins, most bearing a portrait of their patron god or goddess or a legendary hero on one side, and a symbol of the city on the other. Some coins employed a visual pun: some coins from Rhodes featured a rose, since the Greek word for rose is \"rhodon\". The use of inscriptions on coins also began, usually the name of the issuing city.\nThe wealthy cities of Sicily produced some especially fine coins. The large silver \"decadrachm\" (10-drachm) coin from Syracuse is regarded by many collectors as the finest coin produced in the ancient world, perhaps ever. Syracusan issues were rather standard in their imprints, one side bearing the head of the nymph Arethusa and the other usually a victorious quadriga. The tyrants of Syracuse were fabulously rich, and part of their public relations policy was to fund quadrigas for the Olympic chariot race, a very expensive undertaking. As they were often able to finance more than one quadriga at a time, they were frequent victors in this highly prestigious event. Syracuse was one of the epicenters of numismatic art during the classical period. Led by the engravers Kimon and Euainetos, Syracuse produced some of the finest coin designs of antiquity.\nAmongst the first centers to produce coins during the Greek colonization of Southern Italy (the so-called \"Magna Graecia\") were Paestum, Crotone, Sybaris, Caulonia, Metapontum, and Taranto. These ancient cities started producing coins from 550\u00a0BC to 510\u00a0BC.\nAmisano, in a general publication, including the Etruscan coinage, attributing it the beginning to in Populonia, a chronology that would leave out the contribution of the Greeks of Magna Graecia and attribute to the Etruscans the burden of introducing the coin in Italy. In this work, constant reference is made to classical sources, and credit is given to the origin of the Etruscan Lydia, a source supported by Herodotus, and also to the invention of coin in Lydia.\nAppearance of dynastic portraiture (5th century BC).\nAlthough many of the first coins illustrated the images of various gods, the first portraiture of actual rulers appears with the coinage of Lycia in the 5th century BC. No ruler had dared illustrating his own portrait on coinage until that time. The Achaemenids had been the first to illustrate the person of their king or a hero in a stereotypical manner, showing a bust or the full body but never an actual portrait, on their Sigloi and Daric coinage from c. 500 BC. A slightly earlier candidate for the first portrait-coin is Themistocles the Athenian general, who became a Governor of Magnesia on the Meander, c. 465\u2013459 BC, for the Achaemenid Empire, although there is some question as to whether his coins may have represented Zeus rather than himself. Themistocles may have been in a unique position in which he could transfer the notion of individual portraiture, already current in the Greek world, and at the same time wield the dynastic power of an Achaemenid dynasty who could issue his own coins and illustrate them as he wished. From the time of Alexander the Great, portraiture of the issuing ruler would then become a standard, generalized, feature of coinage.\nIndian coins (c. 400 BC \u2013 AD 100).\nThe Karshapana is the earliest punch-marked coin found in India, produced from at least the mid-4th century BC, and possibly as early as 575 BC, influenced by similar coins produced in Gandhara under the Achaemenid empire, such as those of the Kabul hoard, or other examples found at Pushkalavati and in Bhir Mound.\nChinese round coins (350 BC~).\nIn China, early round coins appeared in the 4th century BC and were adopted for all China by Emperor Qin Shi Huang Di at the end of 3rd century BC. The round coin, the precursor of the familiar cash coin, circulated in both the spade and knife money areas in the Zhou period, from around 350 BC. Apart from two small and presumably late coins from the State of Qin, coins from the spade money area have a round hole and refer to the \"jin\" and \"liang\" units. Those from the knife money area have a square hole and are denominated in \"hua\" (\u5316).\nAlthough for discussion purposes the Zhou coins are divided up into categories of knives, spades, and round coins, it is apparent from archaeological finds that most of the various kinds circulated together. A hoard found in 1981, near Hebi in north Henan province, consisted of: 3,537 Gong spades, 3 Anyi arched foot spades, 8 Liang \"Dang Lie\" spades, 18 Liang square foot spades and 1,180 Yuan round coins, all contained in three clay jars.\nHellenistic period (320 BC \u2013 AD 30).\nThe Hellenistic period was characterized by the spread of Greek culture across a large part of the known world. Greek-speaking kingdoms were established in Egypt and Syria, and for a time also in Iran and as far east as what is now Afghanistan and northwestern India. Greek traders spread Greek coins across this vast area, and the new kingdoms soon began to produce their own coins. Because these kingdoms were much larger and wealthier than the Greek city states of the classical period, their coins tended to be more mass-produced, as well as larger, and more frequently in gold. They often lacked the aesthetic delicacy of coins of the earlier period.\nStill, some of the Greco-Bactrian coins, and those of their successors in India, the Indo-Greeks, are considered the finest examples of Greek numismatic art with \"a nice blend of realism and idealization\", including the largest coins to be minted in the Hellenistic world: the largest gold coin was minted by Eucratides (reigned 171\u2013145 BC), the largest silver coin by the Indo-Greek king Amyntas Nikator (reigned c. 95\u201390 BC). The portraits \"show a degree of individuality never matched by the often bland depictions of their royal contemporaries further West\" (Roger Ling, \"Greece and the Hellenistic World\").\nRoman period (290 BC~).\nCoinage followed Greek colonization and influence first around the Mediterranean and soon after to North Africa (including Egypt), Syria, Persia, and the Balkans. Coins came late to the Roman Republic compared with the rest of the Mediterranean, especially Greece and Asia Minor where coins were invented in the 7th century BC. The currency of central Italy was influenced by its natural resources, with bronze being abundant (the Etruscans were famous metal workers in bronze and iron) and silver ore being scarce. The coinage of the Roman Republic started with a few silver coins apparently devised for trade with Celtic in northern Italy and the Greek colonies in Southern Italy, and heavy cast bronze pieces for use in Central Italy. The first Roman coins, which were crude, heavy cast bronzes, were issued c. 289 BC.\nAmisano, in a general publication, including the Etruscan coinage, attributing it the beginning to about 550 BC in Populonia, a chronology that would leave out the contribution of the Greeks of Magna Graecia and attribute to the Etruscans the burden of introducing the coin in Italy. In this work, constant reference is made to classical sources, and credit is given to the origin of the Etruscan Lydia, a source supported by Herodotus, and also to the invention of coin in Lydia.\nMiddle Ages.\nCharlemagne, in 800 AD, implemented a series of reforms upon becoming \"Holy Roman Emperor\", including the issuance of a standard coin, the silver penny. Between 794 and 1200 the penny was the only denomination of coin in Western Europe. Minted without oversight by bishops, cities, feudal lords and fiefdoms, by 1160, coins in Venice contained only 0.05g of silver, while England's coins were minted at 1.3g. Large coins were introduced in the mid-13th century. In England, a dozen pennies was called a \"shilling\" and twenty shillings a \"pound\": consistent with e.g. France.\nDebasement of coin was widespread. There were periods of significant debasement in 1340\u201360 and 1417\u201329, when no small coins were minted, and by the 15th century the issuance of small coin was further restricted by government restrictions and even prohibitions. With the exception of the Great Debasement, England's coins were consistently minted from sterling silver (silver content of 92.5%). A lower quality of silver with more copper mixed in, used in Barcelona, was called billon. The first European coin to use Arabic numerals to date the year in which the coin was minted was the St. Gall silver \"Plappart\" of 1424.\nItaly has been influential at a coinage point of view: the Florentine florin, one of the most used coinage types in European history and one of the most important coins in Western history, was struck in Florence in the 13th century, while the Venetian sequin, minted from 1284 to 1797, was the most prestigious gold coin in circulation in the commercial centers of the Mediterranean Sea. The Florentine florin was the first European gold coin struck in sufficient quantities since the 7th century to play a significant commercial role. The Florentine florin was used for larger transactions such as those used in dowries, international trade or for tax-related matters.\nModern history.\nGenoese coins became important in the 16th century during the Golden age of Genoese banking, with the Spanish Empire funnelling its massive wealth from Spanish America through the Bank of Saint George. With the decline in the fortunes of the Genoese banks and the Spanish Empire in the 17th century, however, the Genoese lira also depreciated substantially. The silver scudo's value increased to 6.5 lire in 1646, 7.4 lire in 1671, and 8.74 lire just before the Austrian occupation of Genoa in 1746.\nVariations in the mass of precious metals used in international trade, particularly in imports of spices and textiles into Europe, explain the numerous monetary reforms that occurred in this period. The effect of these transactions on the available reserves of gold and silver was at the origin of the various monetary reforms, which changed the price of silver compared to gold. Faced with the distinct monetary systems developed by Genoa, Venice or Florence, the widespread use in the 15th century of the silver thaler, of constant size and mass, allowed conversion operations to be limited and therefore exchanges facilitated. The thaler was the monetary unit of the Germanic countries until the 19th century and is considered the ancestor of the United States dollar. At the same time, the Mexican Mint was established on May 11, 1535, by order of the Spanish king following the Spanish colonization of the Americas. Opened in April 1536, this mint had the right to mint silver Spanish real which became the basis of the monetary system of the Spanish Empire. Louis XIII had the Louis d'or minted in 1640 to compete with these coins.\nThe first attested siege coins appeared at the siege of Pavia in 1524. Auxiliary coins consisted, among the Greeks and Romans as in our modern societies, of coins strongly linked to copper. In particular, the red copper alloy was used for its physical properties, suitable for objects constantly subjected to manipulation: malleability, resistance to impacts, wear and corrosion (only gold has better resistance to corrosion). This alloy was often mixed with a little tin, zinc and especially nickel for their anti-corrosive, ductile and anti-fouling properties.\nValue.\nCurrency.\nMost coins presently are made of a base metal, and their value comes from their status as fiat money. This means that the value of the coin is established by law, and thus is determined by the free market only in as much as national currencies are used in domestic trade and also traded in the international market. Thus, these coins are monetary tokens, just as paper currency is: their value is usually not backed by metal, but rather by some form of government guarantee. Thus, there is very little economic difference between notes and coins of equivalent face value.\nCoins may be in circulation with face values lower than the value of their component metals, but they are never initially issued with such value, and the shortfall only arises over time due to inflation, as market values for the metal overtake the face value of the coin. Examples are the pre-1965 US dime, quarter, half dollar, and dollar (containing slightly less than a tenth, quarter, half, and full ounce of silver, respectively), US nickel, and pre-1982 US penny. As a result of the increase in the value of copper, the United States greatly reduced the amount of copper in each penny. Since mid-1982, United States pennies are made of 97.5% zinc, with the remaining 2.5% being a coating of copper. Extreme differences between face values and metal values of coins cause coins to be hoarded or removed from circulation by illicit smelters in order to realize the value of their metal content. This is an example of Gresham's law. The United States Mint, in an attempt to avoid this, implemented new interim rules on December 14, 2006, subject to public comment for 30 days, which criminalized the melting and export of pennies and nickels. Violators can be fined up to $10,000 and/or imprisoned for up to five years.\nCollector's items.\nA coin's value as a collector's item or as an investment generally depends on its condition, specific historical significance, rarity, quality, beauty of the design and general popularity with collectors. If a coin is greatly lacking in all of these, it is unlikely to be worth much. The value of bullion coins is also influenced to some extent by those factors, but is largely based on the value of their gold, silver, or platinum content. Sometimes non-monetized bullion coins such as the Canadian Maple Leaf and the American Gold Eagle are minted with nominal face values less than the value of the metal in them, but as such coins are never intended for circulation, these face values have no relevance.\nCollector catalogs often include information about coins to assists collectors with identifying and grading. Additional resources can be found online for collectors These are collector clubs, collection management tools, marketplaces, trading platforms, and forums,\nMedia of expression.\nCoins can be used as creative media of expression \u2013 from fine art sculpture to the penny machines that can be found in most amusement parks. In the Code of Federal Regulations (CFR) in the United States there are some regulations specific to nickels and pennies that are informative on this topic. 31 CFR \u00a7\u00a082.1 forbids unauthorized persons from exporting, melting, or treating any 5 or 1 cent coins.\nThis has been a particular problem with nickels and dimes (and with some comparable coins in other currencies) because of their relatively low face value and unstable commodity prices. For a while, the copper in US pennies was worth more than one cent, so people would hoard pennies and then melt them down for their metal value. It cost more than face value to manufacture pennies or nickels, so any widespread loss of the coins in circulation could be expensive for the US Treasury. This was more of a problem when coins were still made of precious metals like silver and gold, so strict laws against alteration make more sense historically.\n31 CFR \u00a7\u00a082.2(b) goes on to state that: \"The prohibition contained in \u00a7\u00a082.1 against the treatment of 5-cent coins and one-cent coins shall not apply to the treatment of these coins for educational, amusement, novelty, jewelry, and similar purposes as long as the volumes treated and the nature of the treatment makes it clear that such treatment is not intended as a means by which to profit solely from the value of the metal content of the coins.\"\nDebasement and clipping.\nThroughout history, monarchs and governments have often created more coinage than their supply of precious metals would allow if the coins were pure metal. By replacing some fraction of a coin's precious metal content with a base metal (often copper or nickel), the intrinsic value of each individual coin was reduced (thereby \"debasing\" the money), allowing the coining authority to produce more coins than would otherwise be possible. Debasement occasionally occurs in order to make the coin physically harder and therefore less likely to be worn down as quickly, but the more usual reason is to profit from the difference between face value and metal value. Debasement of money almost always leads to price inflation. Sometimes price controls are at the same time also instituted by the governing authority, but historically these have generally proved unworkable.\nThe United States is unusual in that it has only slightly modified its coinage system (except for the images and symbols on the coins, which have changed a number of times) to accommodate two centuries of inflation. The one-cent coin has changed little since 1856 (though its composition was changed in 1982 to remove virtually all copper from the coin) and still remains in circulation, despite a greatly reduced purchasing power. On the other end of the spectrum, the largest coin in common circulation is valued at 25 cents, a very low value for the largest denomination coin compared to many other countries. Increases in the prices of copper, nickel, and zinc meant that both the US one- and five-cent coins became worth more for their raw metal content than their face (fiat) value. In particular, copper one-cent pieces (those dated prior to 1982 and some 1982-dated coins) contained about two cents' worth of copper.\nSome denominations of circulating coins that were formerly minted in the United States are no longer made. These include coins with a face value of a half cent, two cents, three cents, and twenty cents. (The half dollar and dollar coins are still produced, but mostly for vending machines and collectors.) In the past, the US also coined the following denominations for circulation in gold: One dollar, $2.50, three dollars, five dollars, ten dollars, and twenty dollars. In addition, cents were originally slightly larger than the modern quarter and weighed nearly half an ounce, while five-cent coins (known then as \"half dimes\") were smaller than a dime and made of a silver alloy. Dollar coins were also much larger, and weighed approximately an ounce. One-dollar gold coins are no longer produced and rarely used. The US also issues bullion and commemorative coins with the following denominations: 50\u00a2, $1, $5, $10, $25, $50, and $100.\nCirculating coins commonly suffered from \"shaving\" or \"clipping\": the public would cut off small amounts of precious metal from their edges to sell it and then pass on the mutilated coins at full value. Unmilled British sterling silver coins were sometimes reduced to almost half their minted weight. This form of debasement in Tudor England was commented on by Sir Thomas Gresham, whose name was later attached to Gresham's law. The monarch would have to periodically recall circulating coins, paying only the bullion value of the silver, and reminting them. This, also known as recoinage, is a long and difficult process that was done only occasionally. Many coins have milled or reeded edges, originally designed to make it easier to detect clipping.\nCutting.\nSome coins made of precious metals were manufactured with a cross on one side to make it easier to split the coin into halves or quarters.\nOther uses.\nSome convicted criminals from the British Isles who were sentenced to transportation to Australia in the 18th and 19th centuries used coins to leave messages of remembrance to loved ones left behind in Britain. The coins were defaced, smoothed and inscribed, either by stippling or engraving, with sometimes touching words of loss. These coins were called \"convict love tokens\" or \"leaden hearts\". Some of these tokens are in the collection of the National Museum of Australia.\nModern features.\nThe side of a coin carrying an image of a monarch, other authority (\"see List of people on coins\"), or a national emblem is called the \"obverse\" (colloquially, \"heads\"); the other side, carrying various types of information, is called the \"reverse\" (colloquially, \"tails\"). The year of minting is usually shown on the obverse, although some Chinese coins, most Canadian coins, the pre-2008 British 20p coin, the post-1999 American quarter, and all Japanese coins are exceptions.\nThe relation of the images on the obverse and reverse of a coin is the coin's orientation. If the image on the obverse of the coin is right side up and turning the coin left or right on its vertical axis reveals that the reverse of the coin is also right side up, then the coin is said to have medallic orientation\u2014typical of the Euro and pound sterling; if, however, turning the coin left or right shows that the reverse image is upside down, then the coin is said to have coin orientation, characteristic of the coins of the United States dollar.\nBimetallic coins are sometimes used for higher values and for commemorative purposes. In the 1990s, France used a tri-metallic coin. Common circulating bimetallic examples include the \u20ac1, \u20ac2, British \u00a31, \u00a32 and Canadian $2 and several peso coins in Mexico.\nThe \"exergue\" is the space on a coin beneath the main design, often used to show the coin's date, although it is sometimes left blank or contains a mint mark, privy mark, or some other decorative or informative design feature. Many coins do not have an exergue at all, especially those with few or no legends, such as the Victorian bun penny.\nNot all coins are round; they come in a variety of shapes. The Australian 50-cent coin, for example, has twelve flat sides. Some coins have wavy edges, e.g. the $2 and 20-cent coins of Hong Kong and the 10-cent coins of Bahamas. Some are square-shaped, such as the 15-cent coin of the Bahamas and the 50-cent coin from Aruba. During the 1970s, Swazi coins were minted in several shapes, including squares, polygons, and wavy edged circles with 8 and 12 waves.\nHistorically, a considerable variety of coinage metals (including alloys) and other materials (e.g. porcelain) have been used to produce coins for circulation, collection, and metal investment: bullion coins often serve as more convenient stores of assured metal quantity and purity than other bullion.\nSome other coins, like the British 20 and 50 pence coins and the Canadian Loonie, have an odd number of sides, with the edges rounded off. This way the coin has a constant diameter, recognizable by vending machines whichever direction it is inserted.\nA triangular coin with a face value of \u00a35 (produced to commemorate the 2007/2008 Tutankhamun exhibition at The O2 Arena) was commissioned by the Isle of Man: it became legal tender on 6 December 2007. Other triangular coins issued earlier include: Cabinda coin, Bermuda coin, 2 Dollar Cook Islands 1992 triangular coin, Uganda Millennium Coin and Polish Sterling-Silver 10-Zloty Coin.\nSome medieval coins, called bracteates, were so thin they were struck on only one side.\nMany coins over the years have been manufactured with integrated holes such as Chinese \"cash\" coins, Japanese coins, Colonial French coins, etc. This may have been done to permit their being strung on cords, to facilitate storage and being carried. Nowadays, holes help to differentiate coins of similar size and metal, such as the Japanese 50 yen and 100 yen coin.\nThe Royal Canadian Mint is now able to produce holographic-effect gold and silver coinage. However, this procedure is not limited to only bullion or commemorative coinage. The 500 yen coin from Japan was subject to a massive amount of counterfeiting. The Japanese government in response produced a circulatory coin with a holographic image.\nThe Royal Canadian Mint has also released several coins that are colored, the first of which was in commemoration of Remembrance Day. The subject was a colored poppy on the reverse of a 25-cent piece minted through a patented process.\nAn example of non-metallic composite coins (sometimes incorrectly called plastic coins) was introduced into circulation in Transnistria on 22 August 2014. Most of these coins are also non-circular, with different shapes corresponding to different coin values.\nFor a list of many pure metallic elements and their alloys which have been used in actual circulation coins and for trial experiments, see coinage metals.\nPhysics and chemistry.\nFlipping.\nTo flip a coin to see whether it lands \"heads\" or \"tails\" is to use it as a two-sided die in what is known in mathematics as a Bernoulli trial: if the probability of heads (in the parlance of Bernoulli trials, a \"success\") is exactly 0.5, the coin is fair.\nSpinning.\nCoins can also be spun on a flat surface such as a table. This results in the following phenomenon: as the coin falls over and rolls on its edge, it spins faster and faster (formally, the precession rate of the symmetry axis of the coin, i.e., the axis passing from one face of the coin to the other) before coming to an abrupt stop. This is mathematically modeled as a finite-time singularity \u2013 the precession rate is accelerating to infinity, before it suddenly stops, and has been studied using high speed photography and devices such as Euler's Disk. The slowing down is predominantly caused by rolling friction (air resistance is minor), and the singularity (divergence of the precession rate) can be modeled as a power law with exponent approximately \u22121/3.\nOdor.\nIron and copper coins have a characteristic metallic smell that is produced upon contact with oils in the skin. Perspiration is chemically reduced upon contact with these metals, which causes the skin oils to decompose, forming with iron the volatile molecule 1-octen-3-one.\nRegional examples.\nPhilippines.\nIn the Philippines, small, engraved gold coins called Piloncitos have been excavated, some as lightweight as 0.09 to 2.65 grams. Piloncitos have been unearthed from Mandaluyong, Bataan, the banks of the Pasig River, Batangas, Marinduque, Samar, Leyte and some areas in Mindanao. Large quantities were found in Indonesian archaeological sites, suggesting that they may not have originated in the Philippines, but rather were imported. However, numerous Spanish accounts state that the gold coins were mined and made in the Philippines, such as the following from 1586:\nThe term \"Piloncitos\" is a contemporary word, used by modern-day antique collectors, who thought that the cone-shaped pieces looked like a pilon of sugar. Early historical descriptions of the term include the Spanish \"granitas de oro\" (small grains of gold), or simply by whatever local language terms were used to mean \"gold\" in those times, such as \"bulawan.\"\nPiloncitos are presumably an offshoot of silver coinage and may have evolved into the bullet or pod duang coinage of Sukhothai in Thailand.\nEarly historical records document the extensive use of gold throughout the Philippine archipelago before the arrival of European colonists. It was used extensively as currency, and also used in everyday items such as clothing and finery."}
{"id": "7560", "revid": "15179295", "url": "https://en.wikipedia.org/wiki?curid=7560", "title": "College of the City of New York", "text": "College of the City of New York may refer to:"}
{"id": "7561", "revid": "1270050037", "url": "https://en.wikipedia.org/wiki?curid=7561", "title": "Classical Kuiper belt object", "text": "A classical Kuiper belt object, also called a cubewano ( \"QB1-o\"), is a low-eccentricity Kuiper belt object (KBO) that orbits beyond Neptune and is not controlled by an orbital resonance with Neptune. Cubewanos have orbits with semi-major axes in the 40\u201350\u00a0AU range and, unlike Pluto, do not cross Neptune's orbit. That is, they have low-eccentricity and sometimes low-inclination orbits like the classical planets.\nThe name \"cubewano\" derives from the first trans-Neptunian object (TNO) found after Pluto and Charon: 15760 Albion, which until January 2018 had only the provisional designation (15760) . Similar objects found later were often called \"QB1-os\", or \"cubewanos\", after this object, though the term \"classical\" is much more frequently used in the scientific literature.\nObjects identified as cubewanos include:\n136108 Haumea was provisionally listed as a cubewano by the Minor Planet Center in 2006, but was later found to be in a resonant orbit.\nThere are two basic dynamical classes of classical Kuiper-belt bodies: those with relatively unperturbed ('cold') orbits, and those with markedly perturbed ('hot') orbits.\nMost cubewanos are found between the 2:3 orbital resonance with Neptune (populated by plutinos) and the 1:2 resonance. 50000 Quaoar, for example, has a near-circular orbit close to the ecliptic. Plutinos, on the other hand, have more eccentric orbits bringing some of them closer to the Sun than Neptune.\nThe majority of classical objects, the so-called \"cold population\", have low inclinations (&lt;\u20095\u00b0) and near-circular orbits, lying between 42 and 47\u00a0AU. A smaller population (the \"hot population\") is characterised by highly inclined, more eccentric orbits. The terms 'hot' and 'cold' has nothing to do with surface or internal temperatures, but rather refer to the orbits of the objects, by analogy to molecules in a gas, which increase their relative velocity as they heat up.\nThe Deep Ecliptic Survey reports the distributions of the two populations; one with the inclination centered at 4.6\u00b0 (named \"Core\") and another with inclinations extending beyond 30\u00b0 (\"Halo\").\nDistribution.\nThe vast majority of KBOs (more than two-thirds) have inclinations of less than 5\u00b0 and eccentricities of less than 0.1\u00a0. Their semi-major axes show a preference for the middle of the main belt; arguably, smaller objects close to the limiting resonances have been either captured into resonance or have their orbits modified by Neptune.\nThe 'hot' and 'cold' populations are strikingly different: more than 30% of all cubewanos are in low inclination, near-circular orbits. The parameters of the plutinos\u2019 orbits are more evenly distributed, with a local maximum in moderate eccentricities in 0.15\u20130.2 range, and low inclinations 5\u201310\u00b0.\nSee also the comparison with scattered disk objects.\nCubewanos form a clear 'belt' outside Neptune's orbit, whereas the plutinos approach, or even cross Neptune's orbit. When orbital inclinations are compared, 'hot' cubewanos can be easily distinguished by their higher inclinations, as the plutinos typically keep orbits &lt;20\u00b0. The high inclination of 'hot' cubewanos has not been explained.\nCold and hot populations: physical characteristics.\nIn addition to the distinct orbital characteristics, the two populations display different physical characteristics.\nThe difference in colour between the red cold population, such as 486958 Arrokoth, and more heterogeneous hot population was observed as early as in 2002.\nRecent studies, based on a larger data set, indicate the cut-off inclination of 12\u00b0 (instead of 5\u00b0) between the cold and hot populations and confirm the distinction between the homogenous red cold population and the bluish hot population.\nAnother difference between the low-inclination (cold) and high-inclination (hot) classical objects is the observed number of binary objects. Binaries are quite common on low-inclination orbits and are typically similar-brightness systems. Binaries are less common on high-inclination orbits and their components typically differ in brightness. This correlation, together with the differences in colour, support further the suggestion that the currently observed classical objects belong to at least two different overlapping populations, with different physical properties and orbital history.\nToward a formal definition.\nThere is no official definition of 'cubewano' or 'classical KBO'. However, the terms are normally used to refer to objects free from significant perturbation from Neptune, thereby excluding KBOs in orbital resonance with Neptune (resonant trans-Neptunian objects). The Minor Planet Center (MPC) and the Deep Ecliptic Survey (DES) do not list cubewanos (classical objects) using the same criteria. Many TNOs classified as cubewanos by the MPC, such as dwarf planet Makemake, are classified as ScatNear (possibly scattered by Neptune) by the DES. may be an inner cubewano near the plutinos. Furthermore, there is evidence that the Kuiper belt has an 'edge', in that an apparent lack of low-inclination objects beyond 47\u201349\u00a0AU was suspected as early as 1998 and shown with more data in 2001. Consequently, the traditional usage of the terms is based on the orbit's semi-major axis, and includes objects situated between the 2:3 and 1:2 resonances, that is between 39.4 and 47.8 AU (with exclusion of these resonances and the minor ones in-between).\nThese definitions lack precision: in particular the boundary between the classical objects and the scattered disk remains blurred. , there are 870 objects with perihelion (q) &gt; 40 AU and aphelion (Q) &lt; 48 AU.\nDES classification.\nIntroduced by the report from the Deep Ecliptic Survey by J. L. Elliott et al. in 2005 uses formal criteria based on the mean orbital parameters. Put informally, the definition includes the objects that have never crossed the orbit of Neptune. According to this definition, an object qualifies as a classical KBO if:\nSSBN07 classification.\nAn alternative classification, introduced by B. Gladman, B. Marsden and C. van Laerhoven in 2007, uses a 10-million-year orbit integration instead of the Tisserand's parameter. Classical objects are defined as not resonant and not being currently scattered by Neptune.\nFormally, this definition includes as \"classical\" all objects with their \"current\" orbits that\nUnlike other schemes, this definition includes the objects with major semi-axis less than 39.4 AU (2:3 resonance)\u2014termed inner classical belt, or more than 48.7 (1:2 resonance) \u2013 termed outer classical belt, and reserves the term main classical belt for the orbits between these two resonances.\nFamilies.\nThe first known collisional family in the classical Kuiper belt\u2014a group of objects thought to be remnants from the breakup of a single body\u2014is the Haumea family. It includes Haumea, its moons, and seven smaller bodies. The objects not only follow similar orbits but also share similar physical characteristics. Unlike many other KBO their surface contains large amounts of water ice (H2O) and no or very little tholins. The surface composition is inferred from their neutral (as opposed to red) colour and deep absorption at 1.5 and 2. \u03bcm in infrared spectrum. Several other collisional families might reside in the classical Kuiper belt.\nExploration.\nAs of January 2019, only one classical Kuiper belt object has been observed up close by spacecraft. Both Voyager spacecraft have passed through the region before the discovery of the Kuiper belt. New Horizons was the first mission to visit a classical KBO. After its successful exploration of the Pluto system in 2015, the NASA spacecraft has visited the small KBO 486958 Arrokoth at a distance of on 1\u00a0January 2019.\nList.\nHere is a very generic list of classical Kuiper belt objects. , there are about 870\u00a0objects with and ."}
{"id": "7564", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=7564", "title": "Foreign policy of the United States", "text": " \nThe officially stated goals of the foreign policy of the United States of America, including all the bureaus and offices in the United States Department of State, as mentioned in the \"Foreign Policy Agenda\" of the Department of State, are \"to build and sustain a more democratic, secure, and prosperous world for the benefit of the American people and the international community\". Liberalism has been a key component of US foreign policy since its independence from Britain. Since the end of World War II, the United States has had a grand strategy which has been characterized as being oriented around primacy, \"deep engagement\", and/or liberal hegemony. This strategy entails that the United States maintains military predominance; builds and maintains an extensive network of allies (exemplified by NATO, bilateral alliances and foreign US military bases); integrates other states into US-designed international institutions (such as the IMF, WTO/GATT and World Bank); and limits the spread of nuclear weapons.\nThe United States House Committee on Foreign Affairs states as some of its jurisdictional goals: \"export controls, including nonproliferation of nuclear technology and nuclear hardware; measures to foster commercial interaction with foreign nations and to safeguard American business abroad; international commodity agreements; international education; protection of American citizens abroad; and expulsion\". U.S. foreign policy and foreign aid have been the subject of much debate, praise, and criticism, both domestically and abroad.\nForeign policy development.\nArticle Two of the United States Constitution grants power of foreign policy to the President of the United States, including powers to command the military, negotiate treaties, and appoint ambassadors. The Department of State carries out the president's foreign policy. The State Department is usually pulled between the wishes of Congress, and the wishes of the residing president. The Department of Defense carries out the president's military policy. The Central Intelligence Agency is an independent agency responsible for gathering intelligence on foreign activity. Some checks and balances are applied to the president's powers of foreign policy. Treaties negotiated by the president require ratification by the Senate to take force as United States law. The president's ambassadorial nominations also require Senate approval before taking office. Military actions must first be approved by both chambers of Congress.\nThe Constitution grants Congress the power to approve the president's picks for ambassadors and the power to declare war. The president is commander-in-chief of the United States Armed Forces. He appoints a Secretary of State and ambassadors with the advice and consent of the Senate. The Secretary acts similarly to a foreign minister, because they are the primary conductor of foreign affairs. While foreign policy has varied slightly from president to president, there have generally been consistently similar goals throughout different administrations.\nGenerally speaking there are 4 schools of thought regarding foreign policy. First is Neo-Isolationists, who believe the United States should maintain a very narrow focus and avoid all involvement in the rest of the world. Second is selective-engagement which avoids all conflicts with other nations, and is semi-restrictive on its foreign policy. Third is cooperative security, which requires more involvement throughout the world, occasionally countering threats to the country. Finally is the idea of primacy which seeks to advance the United States well beyond all other nations of the world, placing it first in all matters.\nInternational law.\nMuch of American foreign policy consists of international agreements made with other countries. Treaties are governed by the Treaty Clause of the United States Constitution. This clause dictates that the president negotiates treaties with other countries or political entities, and signs them. For a treaty to be ratified by the provisions of this clause, it must be approved by two-thirds of the United States Senate. Typically treaties are first discussed and voted on by the Senate Committee on Foreign Relations. If approved, the United States exchanges the instruments of ratification with the relevant foreign states. In \"Missouri v. Holland\", the Supreme Court ruled that the power to make treaties under the U.S. Constitution is a power separate from the other enumerated powers of the federal government, and hence the federal government can use treaties to legislate in areas which would otherwise fall within the exclusive authority of the states. Between 1789 and 1990, the Senate approved more than 1,500 treaties, rejected 21 and withdrew 85 without further action. As of 2019, 37 treaties were pending Senate approval.\nInternational agreements, sometimes also collectively referred to as treaties, can also be entered into by other mechanisms, though they have different legal implications than Senate-ratified treaties. The president can unilaterally make executive agreements. Under the Supreme Court decisions \"United States v. Pink\" (1942) and \"Reid v. Covert\" (1957), these have the force of law only to the degree they were made by exercising a power in the scope of the president's authority.\nCongressional-executive agreements are commonly used to enshrine the provisions of an international compact into federal law. Under this procedure, the executive branch negotiates the language, which is then approved by Congress and signed by the President as a regular piece of legislation, only requiring a simple majority of both houses. This procedure has been upheld by federal courts, though some scholars question its constitutionality because it bypasses the explicit Senate ratification procedure spelled out for treaties.\nThe State Department has taken the position that the Vienna Convention on the Law of Treaties represents established law. Following ratification, the United States incorporates treaty law into the body of U.S. federal law. As a result, Congress can modify or repeal treaties after they are ratified. This can overrule an agreed-upon treaty obligation even if that is seen as a violation of the treaty under international law. Several U.S. court rulings confirmed this understanding, including Supreme Court decisions in \"Paquete Habana v. the United States\" (1900), and \"Reid v. Covert\" (1957), as well as a lower court ruling in \"Garcia-Mir v. Meese\" (1986). As a result of the \"Reid v. Covert\" decision, the United States adds a reservation to the text of every treaty that says in effect that the United States intends to abide by the treaty but that if the treaty is found to be in violation of the Constitution, the United States legally is then unable to abide by the treaty since the American signature would be \"ultra vires\".\nHistorical overview.\nThe main trend regarding the history of U.S. foreign policy since the American Revolution is the shift from non-interventionism before and after World War I, to its growth as a world power and global hegemon during World War II and throughout the Cold War in the 20th century. Since the 19th century, U.S. foreign policy also has been characterized by a shift from the realist school to the idealistic or Wilsonian school of international relations. Over time, other themes, key goals, attitudes, or stances have been variously expressed by presidential 'doctrines'.\n18th century.\nForeign policy themes were expressed considerably in George Washington's farewell address; these included, among other things, observing good faith and justice towards all nations and cultivating peace and harmony with all, excluding both \"inveterate antipathies against particular nations, and passionate attachments for others\", \"steer[ing] clear of permanent alliances with any portion of the foreign world\", and advocating trade with all nations. Foreign policy in the first years of American independence constituted the balancing of relations with Great Britain and France. The Federalist Party supported Washington's foreign policy and sought close ties with Britain, but the Democratic-Republican Party favored France. Under the Federalist government of John Adams, the United States engaged in conflict with France in the Quasi-War, but the rival Jeffersonians feared Britain and favored France in the 1790s, declaring the War of 1812 on Britain. Jeffersonians vigorously opposed a large standing army and any navy until attacks against American shipping by Barbary corsairs spurred the country into developing a navy, resulting in the First Barbary War in 1801.\n19th century.\nAmerican foreign policy was mostly peaceful and marked by steady expansion of its foreign trade during the 19th century. As the Jeffersonians took power in the 1800s, they opposed a large standing army and any navy until attacks against American shipping by Barbary corsairs spurred the country into developing a naval force projection capability, resulting in the First Barbary War in 1801. The Louisiana Purchase in 1803 doubled the nation's geographical area. The American policy of neutrality had caused tensions to rise with Britain in the Atlantic and with Native American nations in the frontier. This led to the War of 1812 and helped cement American foreign policy as independent of Europe. After the War of 1812, there were diagreements between Thomas Jefferson and Alexander Hamilton as to whether the United States should be isolated or be more involved in global activities.\nIn the 1820s, the Monroe Doctrine was established as the primary foreign policy doctrine of the United States, establishing Latin America as an American sphere of influence and rejecting European colonization in the region. The 1830s and 1840s were marked by increasing conflict with Mexico, exacerbated by the Texas annexation and culminating in the Mexican\u2013American War in 1846. Following the war, the United States claimed much of what is now the Southwestern United States, and the Gadsden Purchase further expanded this territory. Relations with Britain continued to be strained as a result of border conflicts until they were resolved by the Webster\u2013Ashburton Treaty in 1842. The Perry Expedition of 1853 led to Japan establishing relations with the United States.\nThe Diplomacy of the American Civil War emphasized preventing European involvement in the war. During the Civil War, Spain and France defied the Monroe Doctrine and expanded their colonial influence in the Dominican Republic and Mexico, respectively. The Alaska Purchase was negotiated with Russia in 1867 and the Newlands Resolution annexed Hawaii in 1898. The Spanish\u2013American War took place during 1898, resulting in the United States claiming Guam, Puerto Rico, and the Philippines, and causing Spain to retract claims upon Cuba. Generally speaking the Foreign Policy of the United States during this era was anchored in a policy of wealth building for the nation.\n20th century.\nFollowing the Spanish\u2013American War, the United States entered the 20th century as an emerging great power with colonies in the Caribbean and the Pacific. Under Theodore Roosevelt, the United States adopted the Roosevelt Corollary, which indicated American willingness to use its military strength to end conflicts and wrongdoings in Latin America. Following the independence of Panama, the United States and Panama negotiated the construction of the Panama Canal, during which time the Panama Canal Zone was placed under American jurisdiction. The United States established the Open Door Policy with China during this time as well. The 20th century was marked by two world wars in which Allied powers, along with the United States, defeated their enemies, and through this participation the United States increased its international reputation.\nWorld War I and Interbellum.\nEntry into the First World War was a hotly debated issue in the 1916 presidential election.\nIn response to the Russian revolutions,\nPresident Wilson's Fourteen Points was developed from his idealistic Wilsonianism program of spreading democracy and fighting militarism to prevent future wars. It became the basis of the German Armistice (which amounted to a military surrender) and the 1919 Paris Peace Conference. The resulting Treaty of Versailles, due to European allies' punitive and territorial designs, showed insufficient conformity with these points, and the U.S. signed separate treaties with each of its adversaries; due to Senate objections also, the U.S. never joined the League of Nations, which was established as a result of Wilson's initiative. In the 1920s, the United States followed an independent course, and succeeded in a program of naval disarmament, and refunding the German economy. Operating outside the League it became a dominant player in diplomatic affairs. New York became the financial capital of the world, but the Wall Street Crash of 1929 hurled the Western industrialized world into the Great Depression. American trade policy relied on high tariffs under the Republicans, and reciprocal trade agreements under the Democrats, but in any case exports were at very low levels in the 1930s. Post WWI, the United States entered back into isolation from world events. This was largely due to the Great Depression of 1929.\nWorld War II.\nThe United States adopted an isolationist foreign policy from 1932 to 1938, but this position was challenged by the outbreak of World War II in 1939. Franklin D. Roosevelt advocated strong support of the allies, establishing the United States as the Arsenal of Democracy by providing military equipment without entering the war. Following the attack on Pearl Harbor, the United States joined the allies as combatants in World War II.\nRoosevelt mentioned four fundamental freedoms, which ought to be enjoyed by people \"everywhere in the world\"; these included the freedom of speech and religion, as well as freedom from want and fear. Roosevelt helped establish terms for a post-war world among potential allies at the Atlantic Conference; specific points were included to correct earlier failures, which became a step toward the United Nations. American policy was to counter Japan, to force out of China, and to prevent attacking the Soviet Union. Japan reacted with an attack on Pearl Harbor in December 1941, and the United States was at war with Japan, Germany, and Italy. Instead of the loans given to allies in World War I, the United States provided Lend-Lease grants of $50,000,000,000. Working closely with Winston Churchill of Britain, and Joseph Stalin of the Soviet Union, Roosevelt sent his forces into the Pacific against Japan, then into North Africa against Italy and Germany, and finally into Europe starting with France and Italy in 1944 against the Germans. The American economy roared forward, doubling industrial production, and building vast quantities of airplanes, ships, tanks, munitions, and, finally, the atomic bomb. The culmination of World War II ended in the defeat of Nazi Germany, and the dropping of the atomic bombs on Hiroshima and Nagasaki. The post World War II era saw the rise of the United States as the global leader, which necessitated an effort by the United States to instill liberal democracy around the world.\nCold War.\nAfter the war, the U.S. rose to become the dominant economic power with broad influence in much of the world, with the key policies of the Marshall Plan and the Truman Doctrine. Almost immediately, two broad camps formed during the Cold War; one side was led by the U.S. and the other by the Soviet Union, but this situation also led to the establishment of the Non-Aligned Movement. This period lasted until almost the end of the 20th century and is thought to be both an ideological and power struggle between the two superpowers. The United States extended its influence in the years after World War II, enacting the Marshall Plan to support the reconstruction process in European countries and seeking to combat Communism through containment. This strategy of containment resulted in the Korean War and the Vietnam War. The Vietnam War in particular was highly controversial, and its perceived failures reduced popularity for foreign intervention in the United States. The invasion of Afghanistan by the Soviet Union contributed directly to fueling tensions between the United States and the Soviet Union. This began with President Carter announcing the United States interests in maintaining the status quo within the Persian Gulf region, resulting in the Carter Doctrine. The Regan administration escalated the tensions by supporting freedom fighters around the world, most notably in Afghanistan during the Soviet invasion. The Soviet Union and the United States did not engage in direct conflict, but rather supported small proxies that opposed the other. In 1991, the Soviet Union dissolved into separate nations, and the Cold War formally ended as the United States gave separate diplomatic recognition to the Russian Federation and other former Soviet states.\nIn domestic politics, foreign policy was not usually a central issue. In 1945\u20131970, the Democratic Party took a strong anti-Communist line and supported wars in Korea and Vietnam. Then the party split with a strong, \"dovish\", pacifist element (typified by 1972 presidential candidate George McGovern). Many \"hawks\", advocates for war, joined the neoconservative movement and started supporting the Republicans\u2014especially Reagan\u2014based on foreign policy. Meanwhile, down to 1952 the Republican Party was split between an isolationist wing, based in the Midwest and led by Senator Robert A. Taft, and an internationalist wing based in the East and led by Dwight D. Eisenhower. Eisenhower defeated Taft for the 1952 nomination largely on foreign policy grounds. Since then the Republicans have been characterized by American nationalism, strong opposition to Communism, and strong support for Israel.\n21st century.\nFollowing the end of the Cold War, the United States entered the 21st century as the sole superpower, though this status has been challenged by China, India, Russia, and the European Union. Substantial problems remain, such as climate change, nuclear proliferation, and the specter of international terrorism.\nThe September 11 attacks in 2001 caused a policy shift, in which America declared a \"war on terror\". The United States invaded Afghanistan in 2001 and invaded Iraq in 2003, emphasizing nation-building and the neutralization of terrorist threats in the Middle East. During the war on terror, the United States significantly expanded its military and intelligence capacities while also pursuing economic methods of targeting opposing governments. After a phased withdrawal from Iraq, In 2014, the Islamic State emerged as a major hostile power in the Middle East, and the United States led a military intervention in Iraq and Syria to combat it. The extended nature of American involvement in Iraq and Afghanistan has resulted in support for isolationism and reduced involvement in foreign conflicts.\nIn 2011, the United States led a NATO intervention in Libya. In 2013, disclosures of American surveillance programs revealed that United States intelligence policy included extensive global surveillance activities against foreign governments and citizens.\nIn 2017, diplomats from other countries developed new tactics to engage with President Donald Trump's brand of American nationalism. Peter Baker of \"The New York Times\" reported on the eve of his first foreign trip as president that the global diplomatic community had devised a strategy of keeping interactions brief, complimenting him, and giving him something he can consider a victory. Before the Trump presidency, foreign policy in the U.S. was the result of bipartisan consensus on an agenda of strengthening its position as the number one power. That consensus has since fractured, with Republican and Democratic politicians increasingly calling for a more restrained approach. Foreign policy under the Trump administration involved heightened tensions with Iran, a trade war through increased tariffs, and a reduced role in international organizations.\nAdvancing a \"Free and Open Indo-Pacific\" has become the core of the U.S. national security strategy and has been embraced by both Democratic and Republican administrations. The United States ended its wars in the Greater Middle East with the withdrawal from Afghanistan in 2021. Unlike the Trump administration, which is more concerned with containing China's influence, foreign policy of the Biden-Harris administration shifted to an increased focus on Russia following the attempted Russian election interference in 2016 and developments in the Russo-Ukrainian War. With the rise of Russia and China as co-superpowers, the United States has had to shift its relations to more cooperation rather than coercion, with Russia and China pursuing a more self serving global system.\nIn early 2023, when China brokered the long-awaited reconciliation of Saudi-Arabia Iran relations, the U.S. found itself on the sidelines of political developments in the Middle East. The JCPOA, which attempted to control the nuclear capabilities of Iran, was not fully reinstated after the Trump administration abandoned the international agreement supported by European powers in 2018. As China attempted to fill this vacuum, the 2022 Russian invasion of Ukraine further tested the international alliances with the U.S. Iran and other larger powers such as India as well as Arab nations did not adopt any of the economic sanctions imposed on Russia but to the contrary, increased their economic and strategic alliances with Russia or China. As China is focussing primarily on the global expansion of its economy, Russia was able to maintain its military and energy-related influence not only in Asia but also in Africa and South America. With regard to the Middle East, trade from these nations with China is three times greater than the trade with the U.S. As China is extending its mid-East reach, Russia despite its battered economy from sanctions still remains influential in South America with trade relations that are difficult to deconstruct through U.S. American influence. While China's influence in the UAE, Saudi Arabia and Africa is still hindered by commercial and currency-related U.S. trade policies, it is perceived more and more as a peace negotiator than a communist aggressor, particularly outside of Europe and North America. While the U.S. still upholds its moral dominance by advocating for democracy, its foreign policies are increasingly marked by a perceived inability to defend its image as an exporter of peace and prosperity.\nDiplomatic policy.\nThe diplomatic policy of the United States is created by the president and carried out by the Department of State. The department's stated mission is to \"protect and promote U.S. security, prosperity, and democratic values and shape an international environment in which all Americans can thrive.\" Its objectives during the 2022-2026 period include renewing U.S. leadership, promoting global prosperity, strengthening democratic institutions, revitalizing the diplomatic workforce and institutions, and serving U.S. citizens abroad. As of 2022, the United States has bilateral relations with all but four United Nations members.\nThe United States government emphasizes human rights in foreign policy. Annual reports produced by the Department of State, such as \"Advancing Freedom and Democracy\" and the \"Country Reports on Human Rights Practices\", track the status of human rights around the world. The National Endowment for Democracy provides financial aid to promote democracy internationally.\nInternational agreements.\nThe United States is party to thousands of international agreements with other countries, territories, and international organizations. These include arms control agreements, human rights treaties, environmental protocols, and free trade agreements. Under the Compact of Free Association, the United States also maintains a relationship of free association with the countries of Micronesia, the Marshall Islands, and Palau, grants the United States military access to the countries in exchange for military protection, foreign aid, and access domestic American agencies.\nThe United States is a member of many international organizations. It is a founding member of the United Nations and holds a permanent seat on the United Nations Security Council. The United States is also a member of other global organizations, including the World Trade Organization. Regional organizations in which the United States is a member include NATO, Organization of American States, the Organization for Security and Co-operation in Europe, the United States\u2013Mexico\u2013Canada Agreement, and the Asia-Pacific Economic Cooperation. As the largest economy in the world, the United States is also a member of organizations for the most developed nations, including the OECD, the Group of Seven, and the G20.\nNon-participation in multi-lateral agreements.\nThe United States notably does not participate in various international agreements adhered to by almost all other industrialized countries, by almost all the countries of the Americas, or by almost all other countries in the world. With a large population and economy, on a practical level this can undermine the effect of certain agreements, or give other countries a precedent to cite for non-participation in various agreements.\nIn some cases the arguments against participation include that the United States should maximize its sovereignty and freedom of action, or that ratification would create a basis for lawsuits that would treat American citizens unfairly. In other cases, the debate became involved in domestic political issues, such as gun control, climate change, and the death penalty.\nExamples include:\nForeign aid.\nForeign assistance is a core component of the State Department's international affairs budget, and aid is considered an essential instrument of U.S. foreign policy. There are four major categories of non-military foreign assistance: bilateral development aid, economic assistance supporting U.S. political and security goals, humanitarian aid, and multilateral economic contributions (for example, contributions to the World Bank and International Monetary Fund). In absolute dollar terms, the United States government is the largest international aid donor. The United States Agency for International Development (USAID) manages the bulk of bilateral economic assistance, while the Treasury Department handles most multilateral aid. Foreign aid is a highly partisan issue in the United States, with liberals, on average, supporting foreign aid much more than conservatives do.\nThe United States first began distributing regular foreign aid in the aftermath of World War II and the onset of the Cold War. Foreign aid has been used to foster closer relations with foreign nations, strengthen countries that could potentially become future allies and trading partners, and provide assistance for people of countries most in need. American foreign aid contributed to the Green Revolution in the 1960s and the democratization of Taiwan and Colombia. Since the 1970s, issues of human rights have become increasingly important in American foreign policy, and several acts of Congress served to restrict foreign aid from governments that \"engage in a consistent pattern of gross violations of internationally recognized human rights\". In 2011, President Obama instructed agencies to consider LGBT rights when issuing financial aid to foreign countries. In the 2019 fiscal year, the United States spent $39.2 billion in foreign aid, constituting less than one percent of the federal budget.\nWar on Drugs.\nUnited States foreign policy is influenced by the efforts of the U.S. government to control imports of illicit drugs, including cocaine, heroin, methamphetamine, and cannabis. This is especially true in Latin America, a focus for the U.S. War on Drugs. These foreign policy efforts date back to at least the 1900s, when the U.S. banned the importation of non-medical opium and participated in the 1909 International Opium Commission, one of the first international drug conferences.\nOver a century later, the Foreign Relations Authorization Act requires the President to identify the major drug transit or major illicit drug-producing countries. In September 2005, the following countries were identified: Bahamas, Bolivia, Brazil, Burma, Colombia, Dominican Republic, Ecuador, Guatemala, Haiti, India, Jamaica, Laos, Mexico, Nigeria, Pakistan, Panama, Paraguay, Peru and Venezuela. Two of these, Burma and Venezuela are countries that the U.S. considers to have failed to adhere to their obligations under international counternarcotics agreements during the previous 12 months. Notably absent from the 2005 list were Afghanistan, the People's Republic of China and Vietnam; Canada was also omitted in spite of evidence that criminal groups there are increasingly involved in the production of MDMA destined for the United States and that large-scale cross-border trafficking of Canadian-grown cannabis continues. The U.S. believes that the Netherlands are successfully countering the production and flow of MDMA to the U.S.\nIn 2011, overdose deaths in the U.S. were on a decline mostly due to interdiction efforts and international cooperation to reduce the production of illicit drugs. Since about 2014, a reversal of this trend could be clearly seen as legal semi-synthetic opioids and cocaine stimulants were replaced by the fully synthetic fentanyl and methamphetamine. By 2022, overdose deaths caused by illicit fentanyl led to the worst drug crisis the U.S. has ever experienced in its history, with 1,500 people dying every week of overdose-related cases. By 2022, deaths caused by fentanyl significantly reduced the life expectancy in the U.S. and were also seen as a major drag on the U.S. economy. Despite efforts to control the trade of chemicals used in the synthesis of fentanyl, the tide of fentanyl-related deaths continues to be a major threat to U.S. national security.\nRegional diplomacy.\nAfrica.\nAmerican involvement with Africa has historically been limited. During the war on terror, the United States increased its activities in Africa to fight terrorism in conjunction with African countries as well as to support democracy in Africa through the Millennium Challenge Corporation. Africa has also been the subject of competition between American and Chinese investment strategies. In 2007 the U.S. was Sub-Saharan Africa's largest single export market accounting for 28% of exports (second in total to the EU at 31%). 81% of U.S. imports from this region were petroleum products.\nAsia.\nAmerica's relations with Asia have tended to be based on a \"hub and spoke\" model instead of multilateral relations, using a series of bilateral relationships where states coordinate with the United States instead of through a unified bloc. On May 30, 2009, at the Shangri-La Dialogue, Defense Secretary Robert M. Gates urged the nations of Asia to build on this hub and spoke model as they established and grew multilateral institutions such as ASEAN, APEC and the ad hoc arrangements in the area. In 2011, Gates said the United States must serve as the \"indispensable nation\", for building multilateral cooperation. As of 2022, the Department of Defense considers China to be the greatest threat to the policy goals of the United States.\nCanada.\nCanada has historically been a close ally to the United States, and their foreign policies often work in conjunction. The armed forces of Canada and the United States have a high level of interoperability, and domestic air force operations have been fully integrated between the two countries through NORAD. Almost all of Canada's energy exports go to the United States, making it the largest foreign source of U.S. energy imports; Canada is consistently among the top sources for U.S. oil imports, and it is the largest source of U.S. natural gas and electricity imports. Trade between the United States and Canada as well as Mexico is facilitated through the USMCA.\nEurope.\nThe United States has close ties with the European Union, and it is a member of NATO along with several European countries. The United States has close relations with most countries of Europe. Much of American foreign policy has involved combating the Soviet Union in the 20th century and Russia in the 21st century.\nLatin America.\nThe Monroe Doctrine has historically made up the foreign policy of the United States in regard to Latin America. Under this policy, the United States would consider Latin America to be under its sphere of influence and defend Latin American countries from European hostilities. The United States was heavily involved in the politics of Panama during the early-20th century in order to construct the Panama Canal. Cuba was an ally of the United States following its independence, but it was identified as a major national security threat following the Cuban Revolution; Cuba\u2013United States relations remain poor.\nMiddle East.\nThe Middle East region was first proclaimed to be of national interest to the United States during World War II, and relations were secured with Saudi Arabia to secure additional oil supplies. The Middle East continued to be regarded as an area of vital importance to the United States during the Cold War, and American containment policy emphasized preventing Soviet influence from taking hold in the Middle East. The Truman Doctrine, the Eisenhower Doctrine, and the Nixon Doctrine all played roles in the formulation of the Carter Doctrine, which stated that the United States would use military force if necessary to defend its national interests in the Persian Gulf region. Carter's successor, President Ronald Reagan, extended the policy in October 1981 with the Reagan Doctrine, which proclaimed that the United States would intervene to protect Saudi Arabia, whose security was threatened after the outbreak of the Iran\u2013Iraq War. During the so-called war on terror, the United States increased its involvement in the region; some analysts have argued that the implementation of the Carter Doctrine and the Reagan Doctrine also played a role in the outbreak of the 2003 Iraq War.\nTwo-thirds of the world's proven oil reserves are estimated to be found in the Persian Gulf, and the United States imports oil from several Middle Eastern countries. While its imports have exceeded domestic production since the early 1990s, new hydraulic fracturing techniques and discovery of shale oil deposits in Canada and the American Dakotas offer the potential for increased energy independence from oil exporting countries such as OPEC.\nOceania.\nAustralia and New Zealand are close allies of the United States. Together, the three countries compose the ANZUS collective security agreement. The United States and the United Kingdom also have a separate agreement, AUKUS, with Australia. After it captured the islands from Japan during World War II, the United States administered the Trust Territory of the Pacific Islands from 1947 to 1986 (1994 for Palau). The Northern Mariana Islands became a U.S. territory (part of the United States), while Federated States of Micronesia, the Marshall Islands, and Palau became independent countries. Each has signed a Compact of Free Association that gives the United States exclusive military access in return for U.S. defense protection and conduct of military foreign affairs (except the declaration of war) and a few billion dollars of aid. These agreements also generally allow citizens of these countries to live and work in the United States with their spouses (and vice versa), and provide for largely free trade. The federal government also grants access to services from domestic agencies, including the Federal Emergency Management Agency, National Weather Service, the United States Postal Service, the Federal Aviation Administration, the Federal Communications Commission, and U.S. representation to the International Frequency Registration Board of the International Telecommunication Union.\nDefense policy.\nDefense policy of the United States is established by the president under the role of commander-in-chief, and it is carried out by the Department of Defense and the Department of Homeland Security. As of 2022, the stated objective of the Department of Defense is to deter attacks against the United States and its allies in order to protect the American people, expand America's prosperity, and defend democratic values. The department recognizes China as the greatest foreign threat to the United States, with Russia, North Korea, Iran, and violent extremist organizations recognized as other major foreign threats. Most American troops stationed in foreign countries operate in non-combat roles. As of 2021, about 173,000 troops are deployed in 159 countries. Japan, Germany, and South Korea are host to the largest numbers of American troops due to continued military cooperation following World War II and the Korean War. The United States has not been involved in a major war since the conclusion of the War in Afghanistan in 2021, though American forces continue to operate against terrorist groups in the Middle East and Africa through the Authorization for Use of Military Force of 2001. The United States also provides billions of dollars of military aid to allied countries each year.\nThe Constitution of the United States requires that Congress authorize any military conflict initiated by the president. This has been carried out through formal declarations of war, Congressional authorizations without formal declaration, and through United Nations Security Council Resolutions that are legally recognized by Congress. The War Powers Resolution of 1973 limited the ability of the president to use the military without Congressional authorization. Prior to 2001, 125 instances of American presidents using military force without Congressional authorization had been identified. Since 2001, the Authorization for Use of Military Force of 2001 (AUMF) has granted the president the power to engage in military conflict with any country, organization, or person that was involved in carrying out the September 11 attacks. American presidents have since interpreted the AUMF to authorize military campaigns against terrorist groups associated with Al-Qaeda in several countries.\nAlliances and partnerships.\nThe Department of Defense considers cooperation with American allies and partners to be \"critical\" to achieving American defense objectives. The department makes a distinction between alliances, which are formal military agreements between countries through a treaty, and strategic partnerships, which are military cooperation agreements that aren't bound by specific terms. The United States military works in cooperation with many national governments, and the United States has approximately 750 military bases in at least 80 different countries. In addition to military agreements, the United States is a member of multiple international disarmament organizations, including the International Atomic Energy Agency and the Organisation for the Prohibition of Chemical Weapons.\nThe United States is a founding member of NATO, an alliance of 29 North American and European nations formed to defend Western Europe against the Soviet Union during the Cold War. Under the NATO charter, the United States legally recognizes any attack on a NATO member as an attack on all NATO members. The United States is also a founding member of the Inter-American Treaty of Reciprocal Assistance, an alliance of 19 North and South American nations. The United States is one of the three members of ANZUS, along with Australia and New Zealand, and it also has military alliances with Japan, South Korea, the Philippines, and Thailand. Under the Compact of Free Association, the United States is responsible for the defense of Micronesia, the Marshall Islands, and Palau. The United States has also designated several countries as major non-NATO allies. These are countries that are not members of NATO but are granted certain privileges in regard to defense trade and security cooperation, including eligibility for certain trade deals and research collaboration. The president is empowered to designate additional foreign countries as major non-NATO allies.\nSince it became a superpower in the mid-20th century, the United States has primarily carried out defense operations by leading and participating in multilateral coalitions. These coalitions may be constructed around existing defensive alliances, such as NATO, or through separate coalitions constructed through diplomatic negotiations and acting in a common interest. The United States has not engaged in unilateral military action since the invasion of Panama in 1989. United States military action may take place in accordance with or in opposition to the wishes of the United Nations. The United States has opposed the expansion of United Nations peacekeeping beyond its previous scope, instead supporting the use of multilateral coalitions in hostile countries and territories.\nMilitary aid.\nThe U.S. provides military aid through many channels, including direct funding, support for training, or distribution of military equipment. Military aid spending has varied over time, with spending reaching as high as $35 billion in 1952, adjusted for inflation. The United States established a cohesive military aid policy during World War II, when the Lend-Lease program was implemented to support the Allied powers. After the war, the United States continued to provide military aid in line with other foreign aid programs to support American allies. Programs such as Foreign Military Financing and Foreign Military Sales oversee distribution of military aid.\nAccording to a 2016 report by the Congressional Research Service, the U.S. topped the market in global weapon sales for 2015, with $40\u00a0billion sold. The largest buyers were Qatar, Egypt, Saudi Arabia, South Korea, Pakistan, Israel, the United Arab Emirates and Iraq. In 2020, the United States distributed $11.6 billion in military aid, the lowest since 2004. Military aid is one of the main forms of foreign aid, with 23% of American foreign aid in 2020 taking the form of military aid. Afghanistan was the primary recipient of American military aid in the 2010s. In 2022, military aid policy in the United States shifted from Afghanistan to Ukraine following the end of the War in Afghanistan and the Russian invasion of Ukraine. As of 2021, the United States has military bases in at least 80 countries.\nThe table below outlines the ten largest recipients of United States military aid in 2020 and their estimated aid in billions.\nMissile defense.\nThe Strategic Defense Initiative (SDI) was a proposal by U.S. President Ronald Reagan on March 23, 1983 to use ground and space-based systems to protect the United States from attack by strategic nuclear ballistic missiles, later dubbed \"Star Wars\". The initiative focused on strategic defense rather than the prior strategic offense doctrine of mutual assured destruction (MAD). Though it was never fully developed or deployed, the research and technologies of SDI paved the way for some anti-ballistic missile systems of today.\nIn February 2007, the U.S. started formal negotiations with Poland and Czech Republic concerning construction of missile shield installations in those countries for a Ground-Based Midcourse Defense system (in April 2007, 57% of Poles opposed the plan). According to press reports, the government of the Czech Republic agreed (while 67% Czechs disagree) to host a missile defense radar on its territory while a base of missile interceptors is supposed to be built in Poland.\nRussia threatened to place short-range nuclear missiles on the Russia's border with NATO if the United States refuses to abandon plans to deploy 10 interceptor missiles and a radar in Poland and the Czech Republic. In April 2007, Putin warned of a new Cold War if the Americans deployed the shield in Central Europe. Putin also said that Russia is prepared to abandon its obligations under an Intermediate-Range Nuclear Forces Treaty of 1987 with the United States.\nOn August 14, 2008, the United States and Poland announced a deal to implement the missile defense system in Polish territory, with a tracking system placed in the Czech Republic. \"The fact that this was signed in a period of very difficult crisis in the relations between Russia and the United States over the situation in Georgia shows that, of course, the missile defense system will be deployed not against Iran but against the strategic potential of Russia\", Dmitry Rogozin, Russia's NATO envoy, said.\nKeir A. Lieber and Daryl G. Press, argue in Foreign Affairs that U.S. missile defenses are designed to secure Washington's nuclear primacy and are chiefly directed at potential rivals, such as Russia and China. The authors note that Washington continues to eschew nuclear first strike and contend that deploying missile defenses \"would be valuable primarily in an offensive context, not a defensive one; as an adjunct to a US First Strike capability, not as a stand-alone shield\":\nIf the United States launched a nuclear attack against Russia (or China), the targeted country would be left with only a tiny surviving arsenal, if any at all. At that point, even a relatively modest or inefficient missile defense system might well be enough to protect against any retaliatory strikes.\nThis analysis is corroborated by the Pentagon's 1992 Defense Planning Guidance (DPG), prepared by then Secretary of Defense Richard Cheney and his deputies. The DPG declares that the United States should use its power to \"prevent the reemergence of a new rival\" either on former Soviet territory or elsewhere. The authors of the Guidance determined that the United States had to \"Field a missile defense system as a shield against accidental missile launches or limited missile strikes by 'international outlaws'\" and also must \"Find ways to integrate the 'new democracies' of the former Soviet bloc into the U.S.-led system\". The National Archive notes that Document 10 of the DPG includes wording about \"disarming capabilities to destroy\" which is followed by several blacked out words. \"This suggests that some of the heavily excised pages in the still-classified DPG drafts may include some discussion of preventive action against threatening nuclear and other WMD programs.\"\nRobert David English, writing in \"Foreign Affairs\", observes that the DPG's second recommendation has also been proceeding on course. \"Washington has pursued policies that have ignored Russian interests (and sometimes international law as well) in order to encircle Moscow with military alliances and trade blocs conducive to U.S. interests.\"\nOn September 12, 2024, the U.S. disclosed that Russia obtained ballistic missiles from Iran for its war in Ukraine, leading to new sanctions on Russian entities involved. The U.S. also targeted Iran Air and other organizations linked to Iran\u2019s missile activities, though Iran denies supplying the weapons. Secretary of State Antony Blinken is set to visit Ukraine and Poland to discuss further support, as Ukraine urges stronger actions.\nExporting democracy.\nStudies have been devoted to the historical success rate of the U.S. in exporting democracy abroad. Some studies of American intervention have been pessimistic about the overall effectiveness of U.S. efforts to encourage democracy in foreign nations. Until recently, scholars have generally agreed with international relations professor Abraham Lowenthal that U.S. attempts to export democracy have been \"negligible, often counterproductive, and only occasionally positive\". Other studies find U.S. intervention has had mixed results, and another by Hermann and Kegley has found that military interventions have improved democracy in other countries.\nIntelligence policy.\nIntelligence policy is developed by the president and carried out by the United States Intelligence Community, led by the Director of National Intelligence. The Intelligence Community includes 17 offices and bureaus within various executive departments as well as the Central Intelligence Agency. Its stated purpose is to utilize insights, protected information, and understanding of adversaries to advance national security, economic strength, and technological superiority.\nThe Intelligence Community provides support for all diplomatic and military action undertaken by the United States and serves to inform government and military decision-making, as well as collecting and analyzing global economic and environmental information. The primary functions of the Intelligence Community are the collection and analysis of information, and it is responsible for collecting information on foreign subjects that is not available publicly or through diplomatic channels. Collection of information typically takes the form of signals intelligence, imagery intelligence, and human intelligence. Information collected by American intelligence is used to counter foreign intelligence, terrorism, narcotics trafficking, WMD proliferation, and international organized crime.\nCounterintelligence.\nThe Intelligence Community is responsible for counterintelligence to protect the United States from foreign intelligence services. The Central Intelligence Agency is responsible for counterintelligence activities abroad, while the Federal Bureau of Investigation is responsible for combating foreign intelligence operations in the United States. The goal of American counterintelligence is to protect classified government information as well as trade secrets of American industry. Offensive counterintelligence operations undertaken by the United States include recruiting foreign intelligence agents, monitoring suspected foreign agents, and collecting information on the intentions of foreign intelligence services, while defensive counterintelligence operations include investigating suspected cases of espionage and producing analyses of foreign intelligence threats.\nCounterintelligence operations in the United States began when the Espionage Act of 1917 was used to prosecute German infiltrators and saboteurs during World War I. Today, counterintelligence is applied in the United States as a tool of national security. Due to its global influence, the United States is considered to be the world's greatest target for intelligence operations. Terrorists, tyrants, foreign adversaries, and economic competitors have all been found to engage in \"a range of intelligence activities\" directed against the United States. Terrorist organizations such as al Qaeda have been found to employ intelligence practices similar to those of foreign powers, and American counterintelligence operations play a significant role in counterterrorism.\nCovert action.\nIn addition to intelligence gathering, the Central Intelligence Agency is authorized by the National Security Act of 1947 to engage in covert action. Covert action is undertaken to influence conditions in foreign countries without evidence of American involvement. This may include enacting propaganda campaigns, offering support to factions within a country, providing logistical assistance to foreign governments, or disrupting illegal activities. The use of covert action is controversial within the Intelligence Community due to the potential harm to foreign relations and public image, but most individuals involved in American intelligence cite it as an \"essential\" option to prevent terrorism, drug trafficking, and the proliferation of weapons of mass destruction.\nExamples of covert involvement in regime change.\nUnited States foreign policy also includes covert actions to topple foreign governments that have been opposed to the United States. According to J. Dana Stuster, writing in \"Foreign Policy\", there are seven \"confirmed cases\" where the U.S.\u2014acting principally through the Central Intelligence Agency (CIA), but sometimes with the support of other parts of the U.S. government, including the Navy and State Department\u2014covertly assisted in the overthrow of a foreign government: Iran in 1953, Guatemala in 1954, Congo in 1960, the Dominican Republic in 1961, South Vietnam in 1963, Brazil in 1964, and Chile in 1973. Stuster states that this list excludes \"U.S.-supported insurgencies and failed assassination attempts\" such as those directed against Cuba's Fidel Castro, as well as instances where U.S. involvement has been alleged but not proven (such as Syria in 1949).\nIn 1953 the CIA, working with the British government, initiated \"Operation Ajax\" against the Prime Minister of Iran Mohammad Mossadegh who had attempted to nationalize Iran's oil, threatening the interests of the Anglo-Persian Oil Company. This had the effect of restoring and strengthening the authoritarian monarchical reign of Shah Mohammad Reza Pahlavi. In 1957, the CIA and Israeli Mossad aided the Iranian government in establishing its intelligence service, SAVAK, later blamed for the torture and execution of the regime's opponents.\nA year later, in \"Operation PBSuccess\", the CIA assisted the local military in toppling the democratically elected left-wing government of Jacobo \u00c1rbenz in Guatemala and installing the military dictator Carlos Castillo Armas. The United Fruit Company lobbied for \u00c1rbenz's overthrow as his land reforms jeopardized their land holdings in Guatemala, and painted these reforms as a communist threat. The coup triggered a decades long civil war which claimed the lives of an estimated 200,000 people (42,275 individual cases have been documented), mostly through 626 massacres against the Maya population perpetrated by the U.S.-backed Guatemalan military. An independent Historical Clarification Commission found that U.S. corporations and government officials \"exercised pressure to maintain the country's archaic and unjust socio-economic structure\", and that U.S. military assistance had a \"significant bearing on human rights violations during the armed confrontation\".\nDuring the massacre of at least 500,000 alleged communists in 1960s Indonesia, U.S. government officials encouraged and applauded the mass killings while providing covert assistance to the Indonesian military which helped facilitate them. This included the U.S. Embassy in Jakarta supplying Indonesian forces with lists of up to 5,000 names of suspected members of the Communist Party of Indonesia (PKI), who were subsequently killed in the massacres. In 2001, the CIA attempted to prevent the publication of the State Department volume \"Foreign Relations of the United States, 1964\u20131968\", which documents the U.S. role in providing covert assistance to the Indonesian military for the express purpose of the extirpation of the PKI. In July 2016, an international panel of judges ruled the killings constitute crimes against humanity, and that the US, along with other Western governments, were complicit in these crimes.\nIn 1970, the CIA worked with coup-plotters in Chile in the attempted kidnapping of General Ren\u00e9 Schneider, who was targeted for refusing to participate in a military coup upon the election of Salvador Allende. Schneider was shot in the botched attempt and died three days later. The CIA later paid the group $35,000 for the failed kidnapping.\nAccording to one peer-reviewed study, the U.S. intervened in 81 foreign elections between 1946 and 2000.\nThe failed 1961 CIA Bay of Pigs Invasion in Cuba was an attempt by the U.S. government to overthrow a regime. Not only did this cause a diplomatic embarrassment, it also damaged the CIA's credibility internationally.\nPublic image.\nUnited States foreign policy has been the subject of debate, receiving praise and criticism domestically and abroad. As of 2019, public opinion in the United States is closely divided on American involvement in world affairs. 53% of Americans wish for the United States to be active in world affairs, while 46% of Americans wish for less involvement overseas. American involvement in the global economy is received more positively by the American people, with 73% considering it to be a \"good thing\".\nGlobal opinion.\nOverall, the United States is viewed positively by the rest of the world. The Eurasia Group Foundation reported that as of 2021, 85% of respondents from 10 countries have a favorable opinion of the United States and 81% favor American hegemony over Chinese hegemony. Those with an unfavorable view of the United States most commonly cited interventionism, and in particular the War in Afghanistan, as their reason. It was also found that the exercise of soft power increased favorable opinions while the exercise of hard power decreased favorable opinions. Citizens of Brazil, Nigeria, and India were found to have more favorable opinions of the United States, while citizens of China and Germany were found to have less favorable opinions of the United States.\nInternational opinion about the US has often changed with different executive administrations. For example, in 2009, the French public favored the United States when President Barack Obama (75% favorable) replaced President George W. Bush (42%). After President Donald Trump took the helm in 2017, French public opinion about the US fell from 63% to 46%. These trends were also seen in other European countries.\nMany democracies have voluntary military ties with the United States. See NATO, ANZUS, U.S.-Japan Security Treaty, Mutual Defense Treaty with South Korea, and Major non-NATO ally. Those nations with military alliances with the U.S. can spend less on the military since they can count on U.S. protection. This may give a false impression that the U.S. is less peaceful than those nations. A 2013 global poll in 65 countries found that the United States is perceived as the biggest threat to world peace, with 24% of respondents identifying it as such. A majority of Russian respondents named the United States as the greatest threat, as well as significant minorities in China, Bosnia and Herzegovina, Argentina, Greece, Turkey, and Pakistan.\nForeign intervention.\nEmpirical studies (see democide) have found that democracies, including the United States, inflict significantly fewer civilian casualties than dictatorships. Media may be biased against the U.S. regarding reporting human rights violations. Studies have found that \"The New York Times\" coverage of worldwide human rights violations predominantly focuses on the human rights violations in nations where there is clear U.S. involvement, while having relatively little coverage of the human rights violations in other nations. For example, the bloodiest war in recent time, involving eight nations and killing millions of civilians, was the Second Congo War, which was almost completely ignored by the media.\nJournalists and human rights organizations have been critical of US-led airstrikes and targeted killings by drones which have in some cases resulted in collateral damage of civilian populations. In early 2017, the U.S. faced criticism from some scholars, activists and media outlets for dropping 26,171 bombs on seven countries throughout 2016: Syria, Iraq, Afghanistan, Libya, Yemen, Somalia and Pakistan.\nResearch on the democratic peace theory has generally found that democracies, including the United States, have not made war on one another. There have been U.S. support for coups against some democracies, but for example Spencer R. Weart argues that part of the explanation was the perception, correct or not, that these states were turning into Communist dictatorships. Also important was the role of rarely transparent United States government agencies, who sometimes mislead or did not fully implement the decisions of elected civilian leaders.\nCritics from the left cite episodes that undercut leftist governments or showed support for Israel. Others cite human rights abuses and violations of international law. Critics have charged that the U.S. presidents have used democracy to justify military intervention abroad. Critics also point to declassified records which indicate that the CIA under Allen Dulles and the FBI under J. Edgar Hoover aggressively recruited more than 1,000 Nazis, including those responsible for war crimes, to use as spies and informants against the Soviet Union in the Cold War.\nStudies have been devoted to the historical success rate of the U.S. in exporting democracy abroad. Some studies of American intervention have been pessimistic about the overall effectiveness of U.S. efforts to encourage democracy in foreign nations. Some scholars have generally agreed with international relations professor Abraham Lowenthal that U.S. attempts to export democracy have been \"negligible, often counterproductive, and only occasionally positive\". Other studies find U.S. intervention has had mixed results, and another by Hermann and Kegley has found that military interventions have improved democracy in other countries.\nAmerica's history of non-intervention has been criticized as well. In his World Policy Journal review of Bill Kauffman's 1995 book \"America First! Its History, Culture, and Politics\", Benjamin Schwartz described America's history of isolationism as a \"tragedy\" and being rooted in Puritan thinking.\nToday the U.S. states that democratic nations best support U.S. national interests. According to the U.S. State Department, \"Democracy is the one national interest that helps to secure all the others. Democratically governed nations are more likely to secure the peace, deter aggression, expand open markets, promote economic development, protect American citizens, combat international terrorism and crime, uphold human and worker rights, avoid humanitarian crises and refugee flows, improve the global environment, and protect human health.\" According to former U.S. President Bill Clinton, \"Ultimately, the best strategy to ensure our security and to build a durable peace is to support the advance of democracy elsewhere. Democracies don't attack each other.\" In one view mentioned by the U.S. State Department, democracy is also good for business. Countries that embrace political reforms are also more likely to pursue economic reforms that improve the productivity of businesses. Accordingly, since the mid-1980s, under President Ronald Reagan, there has been an increase in levels of foreign direct investment going to emerging market democracies relative to countries that have not undertaken political reforms. Leaked cables in 2010 suggested that the \"dark shadow of terrorism still dominates the United States' relations with the world\".\nThe United States officially maintains that it supports democracy and human rights through several tools. Examples of these tools are as follows:\nSupport for authoritarian governments.\nBoth currently and historically, the United States has been willing to cooperate with authoritarian governments to pursue its geopolitical goals. The U.S. has faced criticism for backing right-wing dictators that systematically violated human rights, such as Augusto Pinochet of Chile, Alfredo Stroessner of Paraguay, Efra\u00edn R\u00edos Montt of Guatemala, Jorge Rafael Videla of Argentina, Hiss\u00e8ne Habr\u00e9 of Chad Yahya Khan of Pakistan and Suharto of Indonesia. Critics have also accused the United States of facilitating and supporting state terrorism in the Global South during the Cold War, such as Operation Condor, an international campaign of political assassination and state terror organized by right-wing military dictatorships in the Southern Cone of South America.\nRegarding support for certain anti-Communist dictatorships during the Cold War, a response is that they were seen as a necessary evil, with the alternatives even worse Communist or fundamentalist dictatorships. David Schmitz says this policy did not serve U.S. interests. Friendly tyrants resisted necessary reforms and destroyed the political center (though not in South Korea), while the 'realist' policy of coddling dictators brought a backlash among foreign populations with long memories. Some critical scholars and journalists, including Jason Hickel and Vincent Bevins, argue that the U.S. backed such dictators in order to reinforce Western business interests and to expand capitalism into countries of the Global South who were attempting to pursue alternative paths.\nThe U.S. has been accused of complicity in war crimes for backing the Saudi Arabian-led intervention into the Yemeni Civil War, which has triggered a humanitarian catastrophe, including a cholera outbreak and millions facing starvation.\nNiall Ferguson argues that the U.S. is incorrectly blamed for all of the human rights violations perpetrated by U.S.-supported governments. Ferguson writes that there is general agreement that Guatemala was the worst of the U.S.-backed regimes during the Cold War, but the U.S. cannot be credibly blamed for all of the estimated 200,000 deaths during the long Guatemalan Civil War. The U.S. Intelligence Oversight Board writes that military aid was cut for long periods because of such violations, that the U.S. helped stop a coup in 1993, and that efforts were made to improve the conduct of the security services.\nHuman rights.\nSince the 1970s, issues of human rights have become increasingly important in American foreign policy. Congress took the lead in the 1970s. Following the Vietnam War, the feeling that U.S. foreign policy had grown apart from traditional American values was seized upon by Representative Donald M. Fraser (D, MN), leading the Subcommittee on International Organizations and Movements, in criticizing Republican Foreign Policy under the Nixon administration. In the early 1970s, Congress concluded the Vietnam War and passed the War Powers Act. As \"part of a growing assertiveness by Congress about many aspects of Foreign Policy\", human rights concerns became a battleground between the Legislative and the Executive branches in the formulation of foreign policy. David Forsythe points to three specific, early examples of Congress interjecting its own thoughts on foreign policy:\nThese measures were repeatedly used by Congress, with varying success, to affect U.S. foreign policy towards the inclusion of Human Rights concerns. Specific examples include El Salvador, Nicaragua, Guatemala and South Africa. The Executive (from Nixon to Reagan) argued that the Cold War required placing regional security in favor of U.S. interests over any behavioral concerns of national allies. Congress argued the opposite, in favor of distancing the United States from oppressive regimes. Nevertheless, according to historian Daniel Goldhagen, during the last two decades of the Cold War, the number of American client states practicing mass murder outnumbered those of the Soviet Union. John Henry Coatsworth, a historian of Latin America and the provost of Columbia University, suggests the number of repression victims in Latin America alone far surpassed that of the USSR and its East European satellites during the period 1960 to 1990. W. John Green contends that the United States was an \"essential enabler\" of \"Latin America's political murder habit, bringing out and allowing to flourish some of the region's worst tendencies\".\nOn December 6, 2011, Obama instructed agencies to consider LGBT rights when issuing financial aid to foreign countries. He also criticized Russia's law discriminating against gays, joining other western leaders in the boycott of the 2014 Winter Olympics in Russia.\nIn June 2014, a Chilean court ruled that the United States played a key role in the murders of Charles Horman and Frank Teruggi, both American citizens, shortly after the 1973 Chilean coup d'\u00e9tat."}
{"id": "7565", "revid": "19158033", "url": "https://en.wikipedia.org/wiki?curid=7565", "title": "Christmas in Poland", "text": "Christmas in Poland, known in the Polish language as Bo\u017ce Narodzenie (God's Birth) or Gwiazdka (Little Star), is a major annual celebration, as in most countries of the Christian world. The observance of Christmas in Poland developed gradually over the centuries, beginning in ancient times; combining old Polish pagan customs with the religious practice introduced after the Christianization of Poland by the Catholic Church. Later influences include the mutual permeating of local traditions, lore, and folk culture. It is one of the most important religious holidays for Poles, who follow strict traditional customs, some of which are not found elsewhere in Europe.\nThe Day of Saint Nicholas on 6 December is the unofficial beginning of the festive season in Poland. Well-behaved children receive small gifts on the day, whereas naughty children receive a lump of coal or a \"r\u00f3zga\" twig. The highlight of the holiday is Christmas Eve on 24 December; Christmas trees are traditionally decorated and lit in family rooms on the morning of Christmas Eve. The Polish Wigilia supper begins with the appearance of the first star, which corresponds to the Star of Bethlehem. During preparation, hay is spread beneath the tablecloth as a reminder that Jesus Christ was born in a manger. An empty place setting is left symbolically at the table for the Lord or lost wanderer. The supper begins with the breaking of the Christmas wafer (\"op\u0142atek\"). The meals must be vegetarian (with the exception of fish) as a sign of fasting and twelve different dishes are prepared, thus symbolizing the Twelve Apostles. The celebration ends with the exchange of presents and a midnight mass in churches.\nOther aspects of Polish Christmas include nativity plays called \"Jase\u0142ka\" or \"Herody\", outdoor nativity scenes, the singing of carols, notably \"God Is Born\" or \"Midst Quiet Night\", and Kulig, a horse-pulled sleigh ride. The tradition of crafting and hand-making Christmas szopkas in Krak\u00f3w was declared UNESCO Intangible Cultural Heritage.\nAdvent.\nAmong the special tasks carried out in private homes during Advent (a time of waiting for the celebration of the Nativity of Jesus) is the baking of the Christmas piernik (gingerbread), and the making of Christmas decorations. Pierniks are made in a variety of shapes, including hearts, animals, and St. Nicholas figures. St. Nicholas does not play a major role on Christmas Day, but is celebrated on his Saint feast day of December 6. He visits good children in secret and leaves presents for them.\nTraditionally, the Christmas trees are decorated with glass baubles, garlands and many homemade ornaments including painted eggshells, shiny red apples, walnuts, wrapped chocolate shapes, candles, etc. They are lit on Christmas Eve before Wigilia. At the top of each tree there is a star or a glittering tree topper. In many homes, sparklers are hung on the branches of the trees for wintery ambiance. Sometimes the trees are left standing until February 2, the feast day of St. Mary of the Candle of Lighting.\nDuring Advent and all the way until Epiphany, or the baptism of Jesus (day of January 6), the \"gwiazdory\", or the star carriers walk through the villages. Some of them sing carols; others recite verses or put on \"szopki\", or \"herody\" (nativity scenes). The last two customs are inspired by the traditional manger scenes or \"Jase\u0142ka\" (crib). One tradition unique to Poland is the sharing of the \"op\u0142atek\", a thin wafer into which a holy picture is pressed. In the old days, people carried these wafers from house to house wishing their neighbors a Merry Christmas. Nowadays, op\u0142atek is mostly shared with members of the family and immediate neighbors before the Christmas Eve supper (Wigilia in the Polish language). As each person shares pieces of the wafer with another, they are supposed to forgive each other any hurts that have occurred over the past year and wish them happiness in the coming year.\n\"Wigilia\", the Christmas Eve supper.\nIn Poland, Christmas Eve is a day first of fasting, then of feasting. The Wigilia feast begins at the appearance of the first star. There is no red meat served but fish, usually carp. The supper, which includes many traditional dishes and desserts can sometimes last for over two hours. It is followed by the exchange of gifts. The next day, the Christmas Day, is often spent visiting friends. In Polish tradition, people combine religion and family closeness at Christmas. Although gift-giving plays a major role in the rituals, the emphasis is placed more on the making of special foods and decorations.\nOn the night of Christmas Eve, so important is the appearance of the first star in remembrance of the Star of Bethlehem, that it has been given an affectionate name of \"the little star\" or Gwiazdka (the female counterpart of St. Nicholas). On that evening, children watch the sky anxiously hoping to be the first to cry out, \"The star has come!\" Only after it appears, the family members sit down to a dinner table.\nAccording to tradition, bits of hay are spread beneath the tablecloth as a reminder that Christ was born in a manger. Others partake in the practice of placing money under the tablecloth for each guest, in order to wish for prosperity in the coming year. Some practice the superstition that an even number of people must be seated around the table. In many homes an empty place setting is symbolically left at the table for the Baby Jesus or, for a lonely wanderer who may be in need of food, or if a deceased relative should come and would like to share in the meal.\nThe supper begins with the breaking of the op\u0142atek wafer. Everyone at the table breaks off a piece and eats it as a symbol of their unity with Christ. They then share a piece with each family member. A tradition exists among some families to serve twelve different dishes at Wigilia symbolizing the Twelve Apostles, or perhaps, an odd number of dishes for good luck (usually five, seven, or nine).\nA traditional Wigilia supper in Poland includes fried carp and borscht (beetroot soup) or mushroom consomm\u00e9 with uszka (tortellini). Carp provides a main component of the Christmas Eve meal across Poland; carp fillet, carp in aspic and gefilte fish. Universal Polish Christmas foods are pierogi as well as some herring dishes, and for dessert, makowiec or noodles with poppy seed. Often, there is a compote of dry fruits for a drink.\nThe remainder of the evening is given to stories and songs around the Christmas tree. In some areas of the country, children are taught that \"The Little Star\" brings gifts. As presents are unwrapped, carollers may walk from house to house receiving treats along the way.\nChristmas Eve ends with \"Pasterka\", the Midnight Mass at the local church. The tradition commemorates the arrival of the shepherds to Bethlehem and their paying of respect and bearing witness to the newborn Messiah. The custom of Christmas night liturgy was introduced in the Christian churches after the second half of the 5th century. In Poland that custom arrived together with the coming of Christianity. The next day (December 25) begins with the early morning mass followed by daytime masses. According to scripture, the Christmas Day masses are interchangeable allowing for greater flexibility in choosing the religious services by individual parishioners.\n\"Kol\u0119dy\", the Christmas carols.\nChristmas carols are not celebrated in Poland until during-and-after the Christmas Vigil Mass called \"Pasterka\" held between 24 and 25 of December. The Christmas season often runs until February 2. The early hymns sung in the Catholic church were brought to Poland by the Franciscan Brothers in the Middle Ages. The early Christmas music was Latin in origin. When the Polish words and melodies started to become popular, including many new secular pastorals (, or shepherd's songs), they were not written down originally, but rather taught among people by heart. Notably, the song \"God Is Born\" (\"B\u00f3g si\u0119 rodzi\") with lyrics written by Franciszek Karpi\u0144ski in 1792 became the Christmas hymn of Poland already in the court of King Stefan Batory. Many of the early Polish carols were collected in 1838 by in a book called \"Pastora\u0142ki i Kol\u0119dy z Melodiami\" (Pastorals and Carols with Melodies), including \"Midst Quiet Night\".\nPolish hand-made Christmas ornaments.\nPoland produces some of the finest hand blown glass Christmas ornaments in Europe. Families and collectors value these ornaments for high quality, traditional artwork, and unique decorations.\nPolish blown-glass Christmas ornaments are generally manufactured only in the winter season. The modern glass workshops and manufacturers tend to be localized in the southern regions of Poland."}
{"id": "7566", "revid": "1329099", "url": "https://en.wikipedia.org/wiki?curid=7566", "title": "Carousel (musical)", "text": "Carousel is the second musical by the team of Richard Rodgers (music) and Oscar Hammerstein II (book and lyrics). The 1945 work was adapted from Ferenc Moln\u00e1r's 1909 play \"Liliom\", transplanting its Budapest setting to the Maine coastline. The story revolves around carousel barker Billy Bigelow, whose romance with millworker Julie Jordan comes at the price of both their jobs. He participates in a robbery to provide for Julie and their unborn child; after it goes tragically wrong, he is given a chance to make things right. A secondary plot line deals with millworker Carrie Pipperidge and her romance with ambitious fisherman Enoch Snow. The show includes the songs \"If I Loved You\", \"June Is Bustin' Out All Over\" and \"You'll Never Walk Alone\". Richard Rodgers later wrote that \"Carousel\" was his favorite of all his musicals.\nFollowing the spectacular success of the first Rodgers and Hammerstein musical, \"Oklahoma!\" (1943), the pair sought to collaborate on another piece, knowing that any resulting work would be compared with \"Oklahoma!\", most likely unfavorably. They were initially reluctant to seek the rights to \"Liliom\"; Moln\u00e1r had refused permission for the work to be adapted in the past, and the original ending was considered too depressing for the musical theatre. After acquiring the rights, the team created a work with lengthy sequences of music and made the ending more hopeful.\nThe musical required considerable modification during out-of-town tryouts, but once it opened on Broadway on April 19, 1945, it was an immediate hit with both critics and audiences. \"Carousel\" initially ran for 890 performances and duplicated its success in the West End in 1950. Though it has never achieved as much commercial success as \"Oklahoma!\", the piece has been repeatedly revived, recorded several times and was filmed in 1956. A production by Nicholas Hytner enjoyed success in 1992 in London, in 1994 in New York and on tour. Another Broadway revival opened in 2018. In 1999, \"Time\" magazine named \"Carousel\" the best musical of the 20th century.\nBackground.\n\"Liliom\".\nFerenc Moln\u00e1r's Hungarian-language drama, \"Liliom\", premiered in Budapest in 1909. The audience was puzzled by the work, and it lasted only thirty-odd performances before being withdrawn, the first shadow on Moln\u00e1r's successful career as a playwright. \"Liliom\" was not presented again until after World War I. When it reappeared on the Budapest stage, it was a tremendous hit.\nExcept for the ending, the plots of \"Liliom\" and \"Carousel\" are very similar. Andreas Zavocky (nicknamed Liliom, the Hungarian word for \"lily\", a slang term for \"tough guy\"), a carnival barker, falls in love with Julie Zeller, a servant girl, and they begin living together. With both discharged from their jobs, Liliom is discontented and contemplates leaving Julie, but decides not to do so on learning that she is pregnant. A subplot involves Julie's friend Marie, who has fallen in love with Wolf Biefeld, a hotel porter\u2014after the two marry, he becomes the owner of the hotel. Desperate to make money so that he, Julie and their child can escape to America and a better life, Liliom conspires with lowlife Ficsur to commit a robbery, but it goes badly, and Liliom stabs himself. He dies, and his spirit is taken to heaven's police court. As Ficsur suggested while the two waited to commit the crime, would-be robbers like them do not come before God Himself. Liliom is told by the magistrate that he may go back to Earth for one day to attempt to redeem the wrongs he has done to his family, but must first spend sixteen years in a fiery purgatory.\nOn his return to Earth, Liliom encounters his daughter Louise, who, like her mother, is now a factory worker. Saying that he knew her father, he tries to give her a star he stole from the heavens. When Louise refuses to take it, he strikes her. Not realizing who he is, Julie confronts him, but finds herself unable to be angry with him. Liliom is ushered off to his fate, presumably Hell, and Louise asks her mother if it is possible to feel a hard slap as if it was a kiss. Julie reminiscently tells her daughter that it is very possible for that to happen.\nAn English translation of \"Liliom\" was credited to Benjamin \"Barney\" Glazer, though there is a story that the actual translator, uncredited, was Rodgers' first major partner Lorenz Hart. The Theatre Guild presented it in New York City in 1921, with Joseph Schildkraut as Liliom, and the play was a success, running 300\u00a0performances. A 1940 revival with Burgess Meredith and Ingrid Bergman was seen by both Hammerstein and Rodgers. Glazer, in introducing the English translation of \"Liliom\", wrote of the play's appeal:\nAnd where in modern dramatic literature can such pearls be matched\u2014Julie incoherently confessing to her dead lover the love she had always been ashamed to tell; Liliom crying out to the distant carousel the glad news that he is to be a father; the two thieves gambling for the spoils of their prospective robbery; Marie and Wolf posing for their portrait while the broken-hearted Julie stands looking after the vanishing Liliom, the thieves' song ringing in her ears; the two policemen grousing about pay and pensions while Liliom lies bleeding to death; Liliom furtively proffering his daughter the star he has stolen for her in heaven.\u00a0... The temptation to count the whole scintillating string is difficult to resist.\nInception.\nIn the 1920s and 1930s, Rodgers and Hammerstein both became well known for creating Broadway hits with other partners. Rodgers, with Lorenz Hart, had produced a string of over two dozen musicals, including such popular successes as \"Babes in Arms\" (1937), \"The Boys from Syracuse\" (1938) and \"Pal Joey\" (1940). Some of Rodgers' work with Hart broke new ground in musical theatre: \"On Your Toes\" was the first use of ballet to sustain the plot (in the \"Slaughter on Tenth Avenue\" scene), while \"Pal Joey\" flouted Broadway tradition by presenting a knave as its hero. Hammerstein had written or co-written the words for such hits as \"Rose-Marie\" (1924), \"The Desert Song\" (1926), \"The New Moon\" (1927) and \"Show Boat\" (1927). Though less productive in the 1930s, he wrote material for musicals and films, sharing an Oscar for his song with Jerome Kern, \"The Last Time I Saw Paris\", which was included in the 1941 film \"Lady Be Good\".\nBy the early 1940s, Hart had sunk into alcoholism and emotional turmoil, becoming unreliable and prompting Rodgers to approach Hammerstein to ask if he would consider working with him. Hammerstein was eager to do so, and their first collaboration was \"Oklahoma!\" (1943). Thomas Hischak states, in his \"The Rodgers and Hammerstein Encyclopedia\", that \"Oklahoma!\" is \"the single most influential work in the American musical theatre. In fact, the history of the Broadway musical can accurately be divided into what came before \"Oklahoma!\" and what came after it.\" An innovation for its time in integrating song, character, plot and dance, \"Oklahoma!\" would serve, according to Hischak, as \"the model for Broadway shows for decades\", and proved a huge popular and financial success. Once it was well-launched, what to do as an encore was a daunting challenge for the pair. Film producer Samuel Goldwyn saw \"Oklahoma!\" and advised Rodgers to shoot himself, which, according to Rodgers, \"was Sam's blunt but funny way of telling me that I'd never create another show as good as \"Oklahoma!\"\" As they considered new projects, Hammerstein wrote, \"We're such fools. No matter what we do, everyone is bound to say, 'This is not another \"Oklahoma!\"' \"\n\"Oklahoma!\" had been a struggle to finance and produce. Hammerstein and Rodgers met weekly in 1943 with Theresa Helburn and Lawrence Langner of the Theatre Guild, producers of the blockbuster musical, who together formed what they termed \"the Gloat Club\". At one such luncheon, Helburn and Langner proposed to Rodgers and Hammerstein that they turn Moln\u00e1r's \"Liliom\" into a musical. Both men refused\u2014they had no feeling for the Budapest setting and thought that the unhappy ending was unsuitable for musical theatre. In addition, given the unstable wartime political situation, they might need to change the setting from Hungary while in rehearsal. At the next luncheon, Helburn and Langner again proposed \"Liliom\", suggesting that they move the setting to Louisiana and make Liliom a Creole. Rodgers and Hammerstein played with the idea over the next few weeks, but decided that Creole dialect, filled with \"zis\" and \"zose\", would sound corny and would make it difficult to write effective lyrics.\nA breakthrough came when Rodgers, who owned a house in Connecticut, proposed a New England setting. Hammerstein wrote of this suggestion in 1945,\nI began to see an attractive ensemble\u2014sailors, whalers, girls who worked in the mills up the river, clambakes on near-by islands, an amusement park on the seaboard, things people could do in crowds, people who were strong and alive and lusty, people who had always been depicted on the stage as thin-lipped puritans\u2014a libel I was anxious to refute\u00a0... as for the two leading characters, Julie with her courage and inner strength and outward simplicity seemed more indigenous to Maine than to Budapest. Liliom is, of course, an international character, indigenous to nowhere.\nRodgers and Hammerstein were also concerned about what they termed \"the tunnel\" of Moln\u00e1r's second act\u2014a series of gloomy scenes leading up to Liliom's suicide\u2014followed by a dark ending. They also felt it would be difficult to set Liliom's motivation for the robbery to music. Moln\u00e1r's opposition to having his works adapted was also an issue; he had famously turned down Giacomo Puccini when the great composer wished to transform \"Liliom\" into an opera, stating that he wanted the piece to be remembered as his, not Puccini's. In 1937, Moln\u00e1r, who had recently emigrated to the United States, had declined another offer from Kurt Weill to adapt the play into a musical.\nThe pair continued to work on the preliminary ideas for a \"Liliom\" adaptation while pursuing other projects in late 1943 and early 1944\u2014writing the film musical \"State Fair\" and producing \"I Remember Mama\" on Broadway. Meanwhile, the Theatre Guild took Moln\u00e1r to see \"Oklahoma!\" Moln\u00e1r stated that if Rodgers and Hammerstein could adapt \"Liliom\" as beautifully as they had modified \"Green Grow the Lilacs\" into \"Oklahoma!\", he would be pleased to have them do it. The Guild obtained the rights from Moln\u00e1r in October 1943. The playwright received one percent of the gross and $2,500 for \"personal services\". The duo insisted, as part of the contract, that Moln\u00e1r permit them to make changes in the plot. At first, the playwright refused, but eventually yielded. Hammerstein later stated that if this point had not been won, \"we could never have made \"Carousel\".\"\nIn seeking to establish through song Liliom's motivation for the robbery, Rodgers remembered that he and Hart had a similar problem in \"Pal Joey\". Rodgers and Hart had overcome the problem with a song that Joey sings to himself, \"I'm Talking to My Pal\". This inspired \"Soliloquy\". Both partners later told a story that \"Soliloquy\" was only intended to be a song about Liliom's dreams of a son, but that Rodgers, who had two daughters, insisted that Liliom consider that Julie might have a girl. However, the notes taken at their meeting of December 7, 1943 state: \"Mr. Rodgers suggested a fine musical number for the end of the scene where Liliom discovers he is to be a father, in which he sings first with pride of the growth of a boy, and then suddenly realizes it might be a girl and changes completely.\"\nHammerstein and Rodgers returned to the \"Liliom\" project in mid-1944. Hammerstein was uneasy as he worked, fearing that no matter what they did, Moln\u00e1r would disapprove of the results. \"Green Grow the Lilacs\" had been a little-known work; \"Liliom\" was a theatrical standard. Moln\u00e1r's text also contained considerable commentary on the Hungarian politics of 1909 and the rigidity of that society. A dismissed carnival barker who hits his wife, attempts a robbery and commits suicide seemed an unlikely central character for a musical comedy. Hammerstein decided to use the words and story to make the audience sympathize with the lovers. He also built up the secondary couple, who are incidental to the plot in \"Liliom\"; they became Enoch Snow and Carrie Pipperidge. \"This Was a Real Nice Clambake\" was repurposed from a song, \"A Real Nice Hayride\", written for \"Oklahoma!\" but not used.\nMoln\u00e1r's ending was unsuitable, and after a couple of false starts, Hammerstein conceived the graduation scene that ends the musical. According to Frederick Nolan in his book on the team's works: \"From that scene the song \"You'll Never Walk Alone\" sprang almost naturally.\" In spite of Hammerstein's simple lyrics for \"You'll Never Walk Alone\", Rodgers had great difficulty in setting it to music. Rodgers explained his rationale for the changed ending,\n\"Liliom\" was a tragedy about a man who cannot learn to live with other people. The way Moln\u00e1r wrote it, the man ends up hitting his daughter and then having to go back to purgatory, leaving his daughter helpless and hopeless. We couldn't accept that. The way we ended \"Carousel\" it may still be a tragedy but it's a hopeful one because in the final scene it is clear that the child has at last learned how to express herself and communicate with others.\nWhen the pair decided to make \"This Was a Real Nice Clambake\" into an ensemble number, Hammerstein realized he had no idea what a clambake was like, and researched the matter. Based on his initial findings, he wrote the line, \"First came codfish chowder\". However, further research convinced him the proper term was \"codhead chowder\", a term unfamiliar to many playgoers. He decided to keep it as \"codfish\". When the song proceeded to discuss the lobsters consumed at the feast, Hammerstein wrote the line \"We slit 'em down the back/And peppered 'em good\". He was grieved to hear from a friend that lobsters are always slit down the front. The lyricist sent a researcher to a seafood restaurant and heard back that lobsters are always slit down the back. Hammerstein concluded that there is disagreement about which side of a lobster is the back. One error not caught involved the song \"June Is Bustin' Out All Over\", in which sheep are depicted as seeking to mate in late spring\u2014they actually do so in the winter. Whenever this was brought to Hammerstein's attention, he told his informant that 1873 was a special year, in which sheep mated in the spring.\nRodgers early decided to dispense with an overture, feeling that the music was hard to hear over the banging of seats as latecomers settled themselves. In his autobiography, Rodgers complained that only the brass section can be heard during an overture because there are never enough strings in a musical's small orchestra. He determined to force the audience to concentrate from the beginning by opening with a pantomime scene accompanied by what became known as \"The Carousel Waltz\". The pantomime paralleled one in the Moln\u00e1r play, which was also used to introduce the characters and situation to the audience. Author Ethan Mordden described the effectiveness of this opening:\nOther characters catch our notice\u2014Mr. Bascombe, the pompous mill owner, Mrs. Mullin, the widow who runs the carousel and, apparently, Billy; a dancing bear; an acrobat. But what draws us in is the intensity with which Julie regards Billy\u2014the way she stands frozen, staring at him, while everyone else at the fair is swaying to the rhythm of Billy's spiel. And as Julie and Billy ride together on the swirling carousel, and the stage picture surges with the excitement of the crowd, and the orchestra storms to a climax, and the curtain falls, we realize that R &amp; H have not only skipped the overture \"and\" the opening number but the exposition as well. They have plunged into the story, right into the middle of it, in the most intense first scene any musical ever had.\nCasting and out-of-town tryouts.\nThe casting for \"Carousel\" began when \"Oklahoma!\"'s production team, including Rodgers and Hammerstein, was seeking a replacement for the part of Curly (the male lead in \"Oklahoma!\"). Lawrence Langner had heard, through a relative, of a California singer named John Raitt, who might be suitable for the part. Langner went to hear Raitt, then urged the others to bring Raitt to New York for an audition. Raitt asked to sing \"Largo al factotum\", Figaro's aria from \"The Barber of Seville\", to warm up. The warmup was sufficient to convince the producers that not only had they found a Curly, they had found a Liliom (or Billy Bigelow, as the part was renamed). Theresa Helburn made another California discovery, Jan Clayton, a singer/actress who had made a few minor films for MGM. She was brought east and successfully auditioned for the part of Julie.\nThe producers sought to cast unknowns. Though many had played in previous Hammerstein or Rodgers works, only one, Jean Casto (cast as carousel owner Mrs. Mullin, and a veteran of \"Pal Joey\"), had ever played on Broadway before. It proved harder to cast the ensemble than the leads, due to the war\u2014Rodgers told his casting director, John Fearnley, that the sole qualification for a dancing boy was that he be alive. Rodgers and Hammerstein reassembled much of the creative team that had made \"Oklahoma!\" a success, including director Rouben Mamoulian and choreographer Agnes de Mille. Miles White was the costume designer while Jo Mielziner (who had not worked on \"Oklahoma!\") was the scenic and lighting designer. Even though \"Oklahoma!\" orchestrator Russell Bennett had informed Rodgers that he was unavailable to work on \"Carousel\" due to a radio contract, Rodgers insisted he do the work in his spare time. He orchestrated \"The Carousel Waltz\" and \"(When I Marry) Mister Snow\" before finally being replaced by Don Walker. A new member of the creative team was Trude Rittmann, who arranged the dance music. Rittmann initially felt that Rodgers mistrusted her because she was a woman, and found him difficult to work with, but the two worked together on Rodgers' shows until the 1970s.\nRehearsals began in January 1945; either Rodgers or Hammerstein was always present. Raitt was presented with the lyrics for \"Soliloquy\" on a five-foot long sheet of paper\u2014the piece ran nearly eight minutes. Staging such a long solo number presented problems, and Raitt later stated that he felt that they were never fully addressed. At some point during rehearsals, Moln\u00e1r came to see what they had done to his play. There are a number of variations on the story. As Rodgers told it, while watching rehearsals with Hammerstein, the composer spotted Moln\u00e1r in the rear of the theatre and whispered the news to his partner. Both sweated through an afternoon of rehearsal in which nothing seemed to go right. At the end, the two walked to the back of the theatre, expecting an angry reaction from Moln\u00e1r. Instead, the playwright said enthusiastically, \"What you have done is so beautiful. And you know what I like best? The ending!\" Hammerstein wrote that Moln\u00e1r became a regular attendee at rehearsals after that.\nLike most of the pair's works, \"Carousel\" contains a lengthy ballet, \"Billy Makes a Journey\", in the second act, as Billy looks down to the Earth from \"Up There\" and observes his daughter. In the original production the ballet was choreographed by de Mille. It began with Billy looking down from heaven at his wife in labor, with the village women gathered for a \"birthing\". The ballet involved every character in the play, some of whom spoke lines of dialogue, and contained a number of subplots. The focus was on Louise, played by Bambi Linn, who at first almost soars in her dance, expressing the innocence of childhood. She is teased and mocked by her schoolmates, and Louise becomes attracted to the rough carnival people, who symbolize Billy's world. A youth from the carnival attempts to seduce Louise, as she discovers her own sexuality, but he decides she is more girl than woman, and he leaves her. After Julie comforts her, Louise goes to a children's party, where she is shunned. The carnival people reappear and form a ring around the children's party, with Louise lost between the two groups. At the end, the performers form a huge carousel with their bodies.\nThe play opened for tryouts in New Haven, Connecticut on March 22, 1945. The first act was well-received; the second act was not. Casto recalled that the second act finished about 1:30\u00a0a.m. The staff immediately sat down for a two-hour conference. Five scenes, half the ballet, and two songs were cut from the show as the result. John Fearnley commented, \"Now I see why these people have hits. I never witnessed anything so brisk and brave in my life.\" De Mille said of this conference, \"not three minutes had been wasted pleading for something cherished. Nor was there any idle joking.\u00a0... We cut and cut and cut and then we went to bed.\" By the time the company left New Haven, de Mille's ballet was down to forty minutes.\nA major concern with the second act was the effectiveness of the characters He and She (later called by Rodgers \"Mr. and Mrs. God\"), before whom Billy appeared after his death. Mr. and Mrs. God were depicted as a New England minister and his wife, seen in their parlor. The couple was still part of the show at the Boston opening. Rodgers said to Hammerstein, \"We've got to get God out of that parlor\". When Hammerstein inquired where he should put the deity, Rodgers replied, \"I don't care where you put Him. Put Him on a ladder for all I care, only get Him out of that parlor!\" Hammerstein duly put Mr. God (renamed the Starkeeper) atop a ladder, and Mrs. God was removed from the show. Rodgers biographer Meryle Secrest terms this change a mistake, leading to a more fantastic afterlife, which was later criticized by \"The New Republic\" as \"a Rotarian atmosphere congenial to audiences who seek not reality but escape from reality, not truth but escape from truth\".\nHammerstein wrote that Moln\u00e1r's advice, to combine two scenes into one, was key to pulling together the second act and represented \"a more radical departure from the original than any change we had made\". A reprise of \"If I Loved You\" was added in the second act, which Rodgers felt needed more music. Three weeks of tryouts in Boston followed the brief New Haven run, and the audience there gave the musical a warm reception. An even shorter version of the ballet was presented the final two weeks in Boston, but on the final night there, de Mille expanded it back to forty minutes, and it brought the house down, causing both Rodgers and Hammerstein to embrace her.\nSynopsis.\nAct 1.\nTwo young female millworkers in 1873 Maine visit the town's carousel after work. One of them, Julie Jordan, attracts the attention of the barker, Billy Bigelow (\"The Carousel Waltz\"). When Julie lets Billy put his arm around her during the ride, Mrs. Mullin, the widowed owner of the carousel, tells Julie never to return. Julie and her friend, Carrie Pipperidge, argue with Mrs. Mullin. Billy arrives and, seeing that Mrs. Mullin is jealous, mocks her; he is fired from his job. Billy, unconcerned, invites Julie to join him for a drink. As he goes to get his belongings, Carrie presses Julie about her feelings toward him, but Julie is evasive (\"You're a Queer One, Julie Jordan\"). Carrie has a beau too, fisherman Enoch Snow (\"(When I Marry) Mister Snow\"), to whom she is newly engaged. Billy returns for Julie as the departing Carrie warns that staying out late means the loss of Julie's job. Mr. Bascombe, owner of the mill, happens by along with a policeman, and offers to escort Julie to her home, but she refuses and is fired. Left alone, she and Billy talk about what life might be like if they were in love, but neither quite confesses to the growing attraction they feel for each other (\"If I Loved You\").\nOver a month passes, and preparations for the summer clambake are under way (\"June Is Bustin' Out All Over\"). Julie and Billy, now married, live at Julie's cousin Nettie's spa. Julie confides in Carrie that Billy, frustrated over being unemployed, hit her. Carrie has happier news\u2014she is engaged to Enoch, who enters as she discusses him (\"(When I Marry) Mister Snow (reprise))\". Billy arrives with his ne'er-do-well whaler friend, Jigger. Billy is openly rude to Enoch and Julie, then leaves with Jigger, followed by a distraught Julie. Enoch tells Carrie that he expects to become rich selling herring and to have a large family, larger perhaps than Carrie is comfortable having (\"When the Children Are Asleep\").\nJigger and his shipmates, joined by Billy, then sing about life on the sea (\"Blow High, Blow Low\"). The whaler tries to recruit Billy to help with a robbery, but Billy declines, as the victim\u2014Julie's former boss, Mr. Bascombe\u2014might have to be killed. Mrs. Mullin enters and tries to tempt Billy back to the carousel (and to her). He would have to abandon Julie; a married barker cannot evoke the same sexual tension as one who is single. Billy reluctantly mulls it over as Julie arrives and the others leave. She tells him that she is pregnant, and Billy is overwhelmed with happiness, ending all thoughts of returning to the carousel. Once alone, Billy imagines the fun he will have with Bill Jr.\u2014until he realizes that his child might be a girl, and reflects soberly that \"you've got to be a \"father\" to a girl\" (\"Soliloquy\"). Determined to provide financially for his future child, whatever the means, Billy decides to be Jigger's accomplice.\nThe whole town leaves for the clambake. Billy, who had earlier refused to go, agrees to join in, to Julie's delight, as he realizes that being seen at the clambake is integral to his and Jigger's alibi (\"Act I Finale\").\nAct 2.\nEveryone reminisces about the huge meal and much fun (\"This Was a Real Nice Clambake\"). Jigger tries to seduce Carrie; Enoch walks in at the wrong moment, and declares that he is finished with her (\"Geraniums In the Winder\"), as Jigger jeers (\"There's Nothin' So Bad for a Woman\"). The girls try to comfort Carrie, but for Julie all that matters is that \"he's your feller and you love him\" (\"What's the Use of Wond'rin'?\"). Julie sees Billy trying to sneak away with Jigger and, trying to stop him, feels the knife hidden in his shirt. She begs him to give it to her, but he refuses and leaves to commit the robbery.\nAs they wait, Jigger and Billy gamble with cards. They stake their shares of the anticipated robbery spoils. Billy loses: his participation is now pointless. Unknown to Billy and Jigger, Mr. Bascombe, the intended victim, has already deposited the mill's money. The robbery fails: Bascombe pulls a gun on Billy while Jigger escapes. Billy stabs himself with his knife; Julie arrives just in time for him to say his last words to her and die. Julie strokes his hair, finally able to tell him that she loved him. Carrie and Enoch, reunited by the crisis, attempt to console Julie; Nettie arrives and gives Julie the resolve to keep going despite her despair (\"You'll Never Walk Alone\").\nBilly's defiant spirit (\"The Highest Judge of All\") is taken Up There to see the Starkeeper, a heavenly official. The Starkeeper tells Billy that the good he did in life was not enough to get into heaven, but so long as there is a person alive who remembers him, he can return for a day to try to do good to redeem himself. He informs Billy that fifteen years have passed on Earth since his suicide, and suggests that Billy can get himself into heaven if he helps his daughter, Louise. He helps Billy look down from heaven to see her (instrumental ballet: \"Billy Makes a Journey\"). Louise has grown up to be lonely and bitter. The local children ostracize her because her father was a thief and a wife-beater. In the dance, a young ruffian, much like her father at that age, flirts with her and abandons her as too young. The dance concludes, and Billy is anxious to return to Earth and help his daughter. He steals a star to take with him, as the Starkeeper pretends not to notice.\nOutside Julie's cottage, Carrie describes her visit to New York with the now-wealthy Enoch. Carrie's husband and their many children enter to fetch her\u2014the family must get ready for the high school graduation later that day. Enoch Jr., the oldest son, remains behind to talk with Louise, as Billy and the Heavenly Friend escorting him enter, invisible to the other characters. Louise confides in Enoch Jr. that she plans to run away from home with an acting troupe. He says that he will stop her by marrying her, but that his father will think her an unsuitable match. Louise is outraged: each insults the other's father, and Louise orders Enoch Jr. to go away. Billy, able to make himself visible at will, reveals himself to the sobbing Louise, pretending to be a friend of her father. He offers her a gift\u2014the star he stole from heaven. She refuses it and, frustrated, he slaps her hand. He makes himself invisible, and Louise tells Julie what happened, stating that the slap miraculously felt like a kiss, not a blow\u2014and Julie understands her perfectly. Louise retreats to the house, as Julie notices the star that Billy dropped; she picks it up and seems to feel Billy's presence (\"If I Loved You (Reprise)\").\nBilly invisibly attends Louise's graduation, hoping for one last chance to help his daughter and redeem himself. The beloved town physician, Dr. Seldon (who resembles the Starkeeper) advises the graduating class not to rely on their parents' success or be held back by their failure (words directed at Louise). Seldon prompts everyone to sing an old song, \"You'll Never Walk Alone\". Billy, still invisible, whispers to Louise, telling her to believe Seldon's words, and when she tentatively reaches out to another girl, she learns she does not have to be an outcast. Billy goes to Julie, telling her at last that he loved her. As his widow and daughter join in the singing, Billy is taken to his heavenly reward.\nPrincipal roles and notable performers.\n\u00b0 denotes original Broadway cast\nMusical numbers.\nAct I\nAct II\nProductions.\nEarly productions.\nThe original Broadway production opened at the Majestic Theatre on April 19, 1945. The dress rehearsal the day before had gone badly, and the pair feared the new work would not be well received. One successful last-minute change was to have de Mille choreograph the pantomime. The movement of the carnival crowd in the pantomime had been entrusted to Mamoulian, and his version was not working. Rodgers had injured his back the previous week, and he watched the opening from a stretcher propped in a box behind the curtain. Sedated with morphine, he could see only part of the stage. As he could not hear the audience's applause and laughter, he assumed the show was a failure. It was not until friends congratulated him later that evening that he realized that the curtain had been met by wild applause. Bambi Linn, who played Louise, was so enthusiastically received by the audience during her ballet that she was forced to break character, when she next appeared, and bow. Rodgers' daughter Mary caught sight of her friend, Stephen Sondheim, both teenagers then, across several rows; both had eyes wet with tears.\nThe original production ran for 890 performances, closing on May 24, 1947. The original cast included John Raitt (Billy), Jan Clayton (Julie), Jean Darling (Carrie), Eric Mattson (Enoch Snow), Christine Johnson (Nettie Fowler), Murvyn Vye (Jigger), Bambi Linn (Louise) and Russell Collins (Starkeeper). In December 1945, Clayton left to star in the Broadway revival of \"Show Boat\" and was replaced by Iva Withers; Raitt was replaced by Henry Michel in January 1947; Darling was replaced by Margot Moser.\nAfter closing on Broadway, the show went on a national tour for two years. It played for five months in Chicago alone, visited twenty states and two Canadian cities, covered and played to nearly two million people. The touring company had a four-week run at New York City Center in January 1949.&lt;ref name=\"NYT/Calta 1949-01-25\"&gt;Calta, Louis. \"'Carousel' opens tonight at City Center\". \"The New York Times\", January 25, 1949, p. 27. Retrieved on December 21, 2010.&lt;/ref&gt; Following the City Center run, the show was moved back to the Majestic Theatre starring Stephen Douglass (Billy) and Iva Withers (Julie), in the hopes of filling the theatre until \"South Pacific\" opened in early April. Ticket sales were mediocre, however, and the show closed almost a month early.&lt;ref name=\"NYT/Calta 1949-02-28\"&gt;Calta, Louis. \"'Carousel' to end run on Saturday\". \"The New York Times\", February 28, 1949, p. 15. Retrieved on December 21, 2010.&lt;/ref&gt;\nThe musical premiered in the West End, London, at the Theatre Royal, Drury Lane, on June 7, 1950. The production was restaged by Jerome Whyte, with a cast that included Douglass and Withers reprising their roles as Billy and Julie, and Margot Moser as Carrie. \"Carousel\" ran in London for 566 performances, remaining there for over a year and a half.\nSubsequent productions.\n\"Carousel\" was revived in 1954 and 1957 at City Center, presented by the New York City Center Light Opera Company. Both times, the production featured Barbara Cook, though she played Carrie in 1954 and Julie in 1957 (playing alongside Howard Keel as Billy). The production was then taken to Belgium to be performed at the 1958 Brussels World's Fair, with David Atkinson as Billy, Ruth Kobart as Nettie, and Clayton reprising the role of Julie, which she had originated.\nIn August 1965, Rodgers and the Music Theater of Lincoln Center produced \"Carousel\" for 47 performances. John Raitt reprised the role of Billy, with Jerry Orbach as Jigger and Reid Shelton as Enoch Snow. The roles of the Starkeeper and Dr. Seldon were played by Edward Everett Horton in his final stage appearance. The following year, New York City Center Light Opera Company brought \"Carousel\" back to City Center for 22 performances, with Bruce Yarnell as Billy and Constance Towers as Julie.\nNicholas Hytner directed a new production of \"Carousel\" in 1992, at London's Royal National Theatre, with choreography by Sir Kenneth MacMillan and designs by Bob Crowley. In this staging, the story begins at the mill, where Julie and Carrie work, with the music slowed down to emphasize the drudgery. After work ends, they move to the shipyards and then to the carnival. As they proceed on a revolving stage, carnival characters appear, and at last the carousel is assembled onstage for the girls to ride. Louise is seduced by the ruffian boy during her Act 2 ballet, set around the ruins of a carousel. Michael Hayden played Billy not as a large, gruff man, but as a frustrated smaller one, a time bomb waiting to explode. Joanna Riding (Julie) and Janie Dee (Carrie) won Olivier Awards for their performances, the production won Best Musical Revival, and Hytner won as director. Patricia Routledge played Nettie. Clive Rowe, as Enoch, was nominated for an Olivier Award. Enoch and Carrie were cast as an interracial couple whose eight children, according to the review in \"The New York Times\", looked like \"a walking United Colors of Benetton ad\". The production's limited run from December 1992 through March 1993 was a sellout. It re-opened at the Shaftesbury Theatre in London in September 1993, presented by Cameron Mackintosh, where it continued until May 1994.\nThe Hytner production moved to New York's Vivian Beaumont Theater, where it opened on March 24, 1994, and ran for 322 performances. This won five Tony Awards, including best musical revival, as well as awards for Hytner, MacMillan, Crowley and Audra McDonald (as Carrie). The cast also included Sally Murphy as Julie, Shirley Verrett as Nettie, Fisher Stevens as Jigger and Eddie Korbich as Enoch. Replacements for Billy included Marcus Lovett and James Barbour. One change made from the London to the New York production was to have Billy strike Louise across the face, rather than on the hand. According to Hayden, \"He does the one unpardonable thing, the thing we can't forgive. It's a challenge for the audience to like him after that.\" The Hytner \"Carousel\" was presented in Japan in May 1995. A U.S. national tour with a scaled-down production began in February 1996 in Houston and closed in May 1997 in Providence, Rhode Island. Producers sought to feature young talent on the tour, with Patrick Wilson as Billy and Sarah Uriarte Berry, and later Jennifer Laura Thompson, as Julie.\nA revival opened at London's Savoy Theatre on December 2, 2008, after a week of previews, starring Jeremiah James (Billy), Alexandra Silber (Julie) and Lesley Garrett (Nettie). The production received warm to mixed reviews. It closed in June 2009, a month early. Michael Coveney, writing in \"The Independent\", admired Rodgers' music but stated, \"Lindsay Posner's efficient revival doesn't hold a candle to the National Theatre 1992 version\". A production at Theater Basel, Switzerland, in 2016 to 2017, with German dialogue, was directed by Alexander Charim and choreographed by Teresa Rotemberg. Bryony Dwyer, Christian Miedl and Cheryl Studer starred, respectively, as Julie Jordan, Billy Bigelow and Nettie Fowler. A semi-staged revival by the English National Opera opened at the London Coliseum in 2017. The production was directed by Lonny Price, conducted by David Charles Abell, and starred Alfie Boe as Billy, Katherine Jenkins as Julie and Nicholas Lyndhurst as the Starkeeper. The production received mixed to positive reviews.\nThe third Broadway revival began previews on February 28, 2018, at the Imperial Theatre and officially opened on April 12. It closed on September 16, 2018. The production starred Jessie Mueller, Joshua Henry, Ren\u00e9e Fleming, Lindsay Mendez and Alexander Gemignani. The production was directed by Jack O'Brien and choreographed by Justin Peck. The songs \"Geraniums in the Winder\" and \"There's Nothin' So Bad for a Woman\" were cut from this revival. Ben Brantley wrote in \"The New York Times\", \"The tragic inevitability of \"Carousel\" has seldom come across as warmly or as chillingly as it does in this vividly reimagined revival. ... [W]ith thoughtful and powerful performances by Mr. Henry and Ms. Mueller, the love story at the show's center has never seemed quite as ill-starred or, at the same time, as sexy. ... [T]he Starkeeper ... assumes new visibility throughout, taking on the role of Billy's angelic supervisor.\" Brantley strongly praised the choreography, all the performances and the designers. He was unconvinced, however, by the \"mother-daughter dialogue that falls so abrasively on contemporary ears\", where Julie tries to justify loving an abusive man, and other scenes in Act 2, particularly those set in heaven, and the optimism of the final scene. Most of the reviewers agreed that while the choreography and performances (especially the singing) were excellent, characterizing the production as sexy and sumptuous, O'Brien's direction did little to help the show deal with modern sensibilities about men's treatment of women, instead indulging in nostalgia.\nFrom July to September 2021 the Regent's Park Open Air Theatre in London is presenting a staging by its artistic director Timothy Sheader, with choreography by Drew McOnie. The cast included Carly Bawden as Julie, Declan Bennett as Billy and Joanna Riding as Nettie.\nFilm, television and concert versions.\nA film version of the musical was made in 1956, starring Gordon MacRae and Shirley Jones. It follows the musical's story fairly closely, although a prologue, set in the Starkeeper's heaven, was added. The film was released only a few months after the release of the film version of \"Oklahoma!\" It garnered some good reviews, and the soundtrack recording was a best seller. As the same stars appeared in both pictures, however, the two films were often compared, generally to the disadvantage of \"Carousel\". Thomas Hischak, in \"The Rodgers and Hammerstein Encyclopedia\", later wondered \"if the smaller number of \"Carousel\" stage revivals is the product of this often-lumbering [film] musical\".\nThere was also an abridged (100 minute) 1967 network television version that starred Robert Goulet, with choreography by Edward Villella. BBC Radio Theatre broadcast a concert of \"Carousel\" in July 1995 starring Mandy Patinkin as Billy. In 2002, Carnegie Hall presented a concert of the musical starring Hugh Jackman and Audra McDonald as Billy and Julie, directed by Walter Bobbie. Other cast members included Jason Danieley, Judy Kaye, Lauren Ward, Norbert Leo Butz, Philip Bosco and Blythe Danner.\nThe New York Philharmonic presented a staged concert version of the musical from February 28 to March 2, 2013, at Avery Fisher Hall. Kelli O'Hara played Julie, with Nathan Gunn as Billy, Stephanie Blythe as Nettie, Jessie Mueller as Carrie, Danieley as Enoch, Shuler Hensley as Jigger, John Cullum as the Starkeeper, and Kate Burton as Mrs. Mullin. Tiler Peck danced the role of Louise to choreography by Warren Carlyle. The production was directed by John Rando and conducted by Rob Fisher. Charles Isherwood of \"The New York Times\" wrote, \"this is as gorgeously sung a production of this sublime 1945 Broadway musical as you are ever likely to hear.\" It was broadcast as part of the PBS \"Live from Lincoln Center\" series, premiering on April 26, 2013.\nMusic and recordings.\nMusical treatment.\nRodgers designed \"Carousel\" to be an almost continuous stream of music, especially in Act 1. In later years, Rodgers was asked if he had considered writing an opera. He stated that he had been sorely tempted to, but saw \"Carousel\" in operatic terms. He remembered, \"We came very close to opera in the Majestic Theatre.\u00a0... There's much that is operatic in the music.\"\nRodgers uses music in \"Carousel\" in subtle ways to differentiate characters and tell the audience of their emotional state. In \"You're a Queer One, Julie Jordan\", the music for the placid Carrie is characterized by even eighth-note rhythms, whereas the emotionally restless Julie's music is marked by dotted eighths and sixteenths; this rhythm will characterize her throughout the show. When Billy whistles a snatch of the song, he selects Julie's dotted notes rather than Carrie's. Reflecting the close association in the music between Julie and the as-yet unborn Louise, when Billy sings in \"Soliloquy\" of his daughter, who \"gets hungry every night\", he uses Julie's dotted rhythms. Such rhythms also characterize Julie's Act 2 song, \"What's the Use of Wond'rin'\". The stable love between Enoch and Carrie is strengthened by her willingness to let Enoch not only plan his entire life, but hers as well. This is reflected in \"When the Children Are Asleep\", where the two sing in close harmony, but Enoch musically interrupts his intended's turn at the chorus with the words \"Dreams that won't be interrupted\". Rodgers biographer Geoffrey Block, in his book on the Broadway musical, points out that though Billy may strike his wife, he allows her musical themes to become a part of him and never interrupts her music. Block suggests that, as reprehensible as Billy may be for his actions, Enoch requiring Carrie to act as \"the little woman\", and his having nine children with her (more than she had found acceptable in \"When the Children are Asleep\") can be considered to be even more abusive.\nThe twelve-minute \"bench scene\", in which Billy and Julie get to know each other and which culminates with \"If I Loved You\", according to Hischak, \"is considered the most completely integrated piece of music-drama in the American musical theatre\". The scene is almost entirely drawn from Moln\u00e1r and is one extended musical piece; Stephen Sondheim described it as \"probably the single most important moment in the revolution of contemporary musicals\". \"If I Loved You\" has been recorded many times, by such diverse artists as Frank Sinatra, Barbra Streisand, Sammy Davis Jr., Mario Lanza and Chad and Jeremy. The D-flat major theme that dominates the music for the second act ballet seems like a new melody to many audience members. It is, however, a greatly expanded development of a theme heard during \"Soliloquy\" at the line \"I guess he'll call me 'The old man'\u00a0\".\nWhen the pair discussed the song that would become \"Soliloquy\", Rodgers improvised at the piano to give Hammerstein an idea of how he envisioned the song. When Hammerstein presented his collaborator with the lyrics after two weeks of work (Hammerstein always wrote the words first, then Rodgers would write the melodies), Rodgers wrote the music for the eight-minute song in two hours. \"What's the Use of Wond'rin'\u00a0\", one of Julie's songs, worked well in the show but was never as popular on the radio or for recording, and Hammerstein believed that the lack of popularity was because he had concluded the final line, \"And all the rest is talk\" with a hard consonant, which does not allow the singer a vocal climax.\nIrving Berlin later stated that \"You'll Never Walk Alone\" had the same sort of effect on him as the 23rd Psalm. When singer Mel Torm\u00e9 told Rodgers that \"You'll Never Walk Alone\" had made him cry, Rodgers nodded impatiently. \"You're supposed to.\" The frequently recorded song has become a widely accepted hymn. The cast recording of \"Carousel\" proved popular in Liverpool, like many Broadway albums, and in 1963, the Brian Epstein-managed band, Gerry and the Pacemakers had a number-one hit with the song. At the time, the top ten hits were played before Liverpool F.C. home matches; even after \"You'll Never Walk Alone\" dropped out of the top ten, fans continued to sing it, and it has become closely associated with the soccer team and the city of Liverpool. A BBC program, \"Soul Music\", ranked it alongside \"Silent Night\" and \"Abide With Me\" in terms of its emotional impact and iconic status.\nRecordings.\nThe cast album of the 1945 Broadway production was issued on 78s, and the score was significantly cut\u2014as was the 1950 London cast recording. Theatre historian John Kenrick notes of the 1945 recording that a number of songs had to be abridged to fit the 78 format, but that there is a small part of \"Soliloquy\" found on no other recording, as Rodgers cut it from the score immediately after the studio recording was made.\nA number of songs were cut for the 1956 film, but two of the deleted numbers had been recorded and were ultimately retained on the soundtrack album. The expanded CD version of the soundtrack, issued in 2001, contains all of the singing recorded for the film, including the cut portions, and nearly all of the dance music. The recording of the 1965 Lincoln Center revival featured Raitt reprising the role of Billy. Studio recordings of \"Carousel\"'s songs were released in 1956 (with Robert Merrill as Billy, Patrice Munsel as Julie, and Florence Henderson as Carrie), 1962 and 1987. The 1987 version featured a mix of opera and musical stars, including Samuel Ramey, Barbara Cook and Sarah Brightman. Kenrick recommends the 1962 studio recording for its outstanding cast, including Alfred Drake, Roberta Peters, Claramae Turner, Lee Venora, and Norman Treigle.\nBoth the London (1993) and New York (1994) cast albums of the Hytner production contain portions of dialogue that, according to Hischak, speak to the power of Michael Hayden's portrayal of Billy. Kenrick judges the 1994 recording the best all-around performance of \"Carousel\" on disc, despite uneven singing by Hayden, due to Sally Murphy's Julie and the strong supporting cast (calling Audra McDonald the best Carrie he has heard). The Stratford Festival issued a recording in 2015.\nCritical reception and legacy.\nThe musical received almost unanimous rave reviews after its opening in 1945. According to Hischak, reviews were not as exuberant as for \"Oklahoma!\" as the critics were not taken by surprise this time. John Chapman of the \"Daily News\" termed it \"one of the finest musical plays I have ever seen and I shall remember it always\". \"The New York Times\"'s reviewer, Lewis Nichols, stated that \"Richard Rodgers and Oscar Hammerstein 2d, who can do no wrong, have continued doing no wrong in adapting \"Liliom\" into a musical play. Their \"Carousel\" is on the whole delightful.\" Wilella Waldorf of the \"New York Post\", however, complained, \"\"Carousel\" seemed to us a rather long evening. The \"Oklahoma!\" formula is becoming a bit monotonous and so are Miss de Mille's ballets. All right, go ahead and shoot!\" \"Dance Magazine\" gave Linn plaudits for her role as Louise, stating, \"Bambi doesn't come on until twenty minutes before eleven, and for the next forty minutes, she practically holds the audience in her hand\". Howard Barnes in the \"New York Herald Tribune\" also applauded the dancing: \"It has waited for Miss de Mille to come through with peculiarly American dance patterns for a musical show to become as much a dance as a song show.\"\nWhen the musical returned to New York in 1949, \"The New York Times\" reviewer Brooks Atkinson described \"Carousel\" as \"a conspicuously superior musical play\u00a0... \"Carousel\", which was warmly appreciated when it opened, seems like nothing less than a masterpiece now.\" In 1954, when \"Carousel\" was revived at City Center, Atkinson discussed the musical in his review:\n\"Carousel\" has no comment to make on anything of topical importance. The theme is timeless and universal: the devotion of two people who love each other through thick and thin, complicated in this case by the wayward personality of the man, who cannot fulfill the responsibilities he has assumed. \u00a0... Billy is a bum, but \"Carousel\" recognizes the decency of his motives and admires his independence. There are no slick solutions in \"Carousel\".\nStephen Sondheim noted the duo's ability to take the innovations of \"Oklahoma!\" and apply them to a serious setting: \"\"Oklahoma!\" is about a picnic, \"Carousel\" is about life and death.\" Critic Eric Bentley, on the other hand, wrote that \"the last scene of \"Carousel\" is an impertinence: I refuse to be lectured to by a musical comedy scriptwriter on the education of children, the nature of the good life, and the contribution of the American small town to the salvation of souls.\"\n\"New York Times\" critic Frank Rich said of the 1992 London production: \"What is remarkable about Mr. Hytner's direction, aside from its unorthodox faith in the virtues of simplicity and stillness, is its ability to make a 1992 audience believe in Hammerstein's vision of redemption, which has it that a dead sinner can return to Earth to do godly good.\" The Hytner production in New York was hailed by many critics as a grittier \"Carousel\", which they deemed more appropriate for the 1990s. Clive Barnes of the \"New York Post\" called it a \"defining \"Carousel\"\u2014hard-nosed, imaginative, and exciting.\"\nCritic Michael Billington has commented that \"lyrically [\"Carousel\"] comes perilously close to acceptance of the inevitability of domestic violence.\" BroadwayWorld.com stated in 2013 that \"Carousel\" is now \"considered somewhat controversial in terms of its attitudes on domestic violence\" because Julie chooses to stay with Billy despite the abuse; actress Kelli O'Hara noted that the domestic violence that Julie \"chooses to deal with \u2013 is a real, existing and very complicated thing. And exploring it is an important part of healing it.\"\nRodgers considered \"Carousel\" his favorite of all his musicals and wrote, \"it affects me deeply every time I see it performed\". In 1999, \"Time\" magazine, in its \"Best of the Century\" list, named \"Carousel\" the Best Musical of the 20th century, writing that Rodgers and Hammerstein \"set the standards for the 20th century musical, and this show features their most beautiful score and the most skillful and affecting example of their musical storytelling\". Hammerstein's grandson, Oscar Andrew Hammerstein, in his book about his family, suggested that the wartime situation made \"Carousel\"'s ending especially poignant to its original viewers, \"Every American grieved the loss of a brother, son, father, or friend\u00a0... the audience empathized with [Billy's] all-too-human efforts to offer advice, to seek forgiveness, to complete an unfinished life, and to bid a proper good-bye from beyond the grave.\" Author and composer Ethan Mordden agreed with that perspective:\nIf \"Oklahoma!\" developed the moral argument for sending American boys overseas, \"Carousel\" offered consolation to those wives and mothers whose boys would only return in spirit. The meaning lay not in the tragedy of the present, but in the hope for a future where no one walks alone.\nAwards and nominations.\nOriginal 1945 Broadway production.\n\"Note: The Tony Awards were not established until 1947, and so \"Carousel\" was not eligible to win any Tonys at its premiere.\""}
{"id": "7569", "revid": "6291052", "url": "https://en.wikipedia.org/wiki?curid=7569", "title": "Ceylon", "text": ""}
{"id": "7570", "revid": "3552", "url": "https://en.wikipedia.org/wiki?curid=7570", "title": "Cyber sex", "text": ""}
{"id": "7572", "revid": "46469420", "url": "https://en.wikipedia.org/wiki?curid=7572", "title": "Christian alternative rock", "text": "Christian alternative rock is a form of alternative rock music that is lyrically grounded in a Christian worldview. Some critics have suggested that unlike CCM and older Christian rock, Christian alternative rock generally emphasizes musical style over lyrical content as a defining genre characteristic, though the degree to which the faith appears in the music varies from artist to artist.\nHistory.\nChristian alternative music has its roots in the early 1980s, as the earliest efforts at Christian punk and new wave were recorded by artists like Andy McCarroll and Moral Support, Undercover, the 77s, Steve Scott, Adam Again, Quickflight, Daniel Amos, Youth Choir (later renamed the Choir), Lifesavers Underground, Michael Knott, the Prayer Chain, Altar Boys, Breakfast with Amy, Steve Taylor, 4-4-1, David Edwards and Vector. Early labels, most now-defunct, included Blonde Vinyl, Frontline, Exit, and Refuge.\nBy the 1990s, many of these bands and artists had disbanded, were no longer performing, or were being carried by independent labels because their music tended to be more lyrically complex (and often more controversial) than mainstream Christian pop. The modern market is currently supported by labels such as Tooth &amp; Nail, Gotee and Floodgate. These companies are often children of, or partially owned, by general market labels such as Warner, EMI, and Capitol Records, giving successful artists an opportunity to \"cross over\" into mainstream markets."}
{"id": "7573", "revid": "6969503", "url": "https://en.wikipedia.org/wiki?curid=7573", "title": "Clive Barker", "text": "Clive Barker (born 5 October 1952) is an English writer, filmmaker and visual artist. He came to prominence in the mid-1980s with a series of short stories, the \"Books of Blood\", which established him as a leading horror writer. He has since written many novels and other works. His fiction has been adapted into films, notably the \"Hellraiser\" series, the first installment of which he also wrote and directed, and the \"Candyman\" series.\nBarker's paintings and illustrations have been shown in galleries in the United States, and have appeared in his books. He has also created characters and series for comic books, and some of his more popular horror stories have been featured in ongoing comics series.\nEarly life.\nBarker was born on 5 October 1952 in Liverpool, the son of Joan Ruby (n\u00e9e Revill), a painter and school welfare officer, and Leonard Barker, a personnel director for an industrial relations firm. He was educated at Dovedale Primary School, Quarry Bank High School and the University of Liverpool, where he studied English and philosophy.\nWhen he was three, Barker witnessed the French skydiver L\u00e9o Valentin plummet to his death in 1956 during a performance at an air show in Liverpool. He later alluded to Valentin in many of his stories.\nTheatrical work.\nBarker's involvement in live theatre began while still in school with productions of \"Voodoo\" and \"Inferno\" in 1967. He collaborated on six plays with \"Theatre of the Imagination\" in 1974 and two more that he was the sole writer of, \"A Clowns' Sodom\" and \"Day of the Dog,\" for \"The Mute Pantomime Theatre\" in 1976 and 1977.\nHe co-founded the avant-garde theatrical troupe \"The Dog Company\" in 1978 with former school friends and up and coming actors, many of whom would go on to become key collaborators in Barker's film work. Doug Bradley took on the iconic role of Pinhead in the \"Hellraiser\" series while Peter Atkins wrote the scripts for the first three Hellraiser sequels. Over the next five years Barker wrote nine plays, often serving as director, including some of his best-known stage productions, \"The History of The Devil\", \"Frankenstein in Love\", and \"The Secret Life of Cartoons\".\nFrom 1982 to 1983, he wrote \"Crazyface\", \"Subtle Bodies\" and \"Colossus\" for the Cockpit Youth Theatre.\nHis theatrical work came to a close as he shifted focus to writing the \"Books of Blood\".\nWriting career.\nBarker is an author of horror and fantasy. He began writing horror early in his career, mostly in the form of short stories (collected in \"Books of Blood\" 1\u20136) and the Faustian novel \"The Damnation Game\" (1985). Later he moved toward modern-day fantasy and urban fantasy with horror elements in \"Weaveworld\" (1987), \"The Great and Secret Show\" (1989), the world-spanning \"Imajica\" (1991), and \"Sacrament\" (1996).\nWhen \"Books of Blood\" was first published in the United States in paperback, Stephen King was quoted on the book covers: \"I have seen the future of horror and his name is Clive Barker.\" As influences on his writing, Barker lists Herman Melville, Edgar Allan Poe, Ray Bradbury, William S. Burroughs, William Blake, and Jean Cocteau, among others.\nHe is the writer of the best-selling \"Abarat\" series.\nIn early 2024, he announced he would stop attending conventions and public events so he could focus more on his writing, as he was working on the manuscripts for 31 different projects, some closer to completion than others.\nPersonal life.\nDuring his early years as a writer, Barker occasionally worked as an escort when his writing did not provide sufficient income. \nIn 2003, he received the Davidson/Valentini Award at the 15th GLAAD Media Awards.\nHe has been open about his experiences with sadomasochism, and says that \"on S&amp;M's sliding scale, I'm probably a 6\".\nBarker is critical of organized religion, but has said that the Bible influences his work and spirituality. Years later, he said on Facebook that he did not identify himself as a Christian.\nBarker said in a December 2008 online interview (published in March 2009) that he had throat polyps which were so severe, a doctor told him he was taking in only 10% of the air he was supposed to. He has had two surgical procedures to remove them and believes his voice has improved as a result. He said he did not have cancer, and has given up cigars.\nIn 2012, Barker entered a coma for several days after contracting toxic shock syndrome, triggered by a visit to a dentist where a spillage of poisonous bacteria entered his bloodstream, almost killing him. Realising he might have just a short time to live, he decided to put his personal concerns about the world and society into the upcoming novel \"Deep Hill\", which he thought could be his final book.\nAs of 2015, he is a member of the board of advisers for the Hollywood Horror Museum.\nRelationships.\nWhile appearing on the radio call-in show \"Loveline\" on 20 August 1996, Barker said that in his teens he had several relationships with older women, but came to identify himself as homosexual by 18 or 19.\nHis relationship with John Gregson lasted from 1975 until 1986. He later spent 13 years with photographer David Armstrong, described as his husband in the introduction to \"Coldheart Canyon\"; they separated in 2009.\nFilm work.\nBarker wrote the screenplays for \"Underworld\" (1985) and \"Rawhead Rex\" (1986), both directed by George Pavlou. Displeased by how his material was handled, he moved to directing with \"Hellraiser\" (1987), based on his novella \"The Hellbound Heart\". After his film \"Nightbreed\" (1990) flopped, Barker returned to write and direct \"Lord of Illusions\" (1995). The short story \"The Forbidden\", from Barker's \"Books of Blood\", provided the basis for the 1992 film \"Candyman\" and its three sequels. He had been working on a series of film adaptations of his \"The Abarat Quintet\" books under The Walt Disney Company's management, but due to creative differences, the project was cancelled.\nHe served as an executive producer for the 1998 film \"Gods and Monsters\", a semi-fictional tale of \"Frankenstein\" director James Whale's later years, which won an Academy Award for Best Adapted Screenplay. Barker said of his interest in the project: \"Whale was gay, I'm gay; Whale was English, I'm English\u2026Whale made some horror movies, and I've made some horror movies. It seemed as if I should be helping to tell this story.\" Barker also provided the foreword on the published shooting script.\nIn 2005, Barker and horror film producer Jorge Saralegui created the film production company Midnight Picture Show with the intent of producing two horror films per year.\nIn October 2006, Barker announced through his website that he will be writing the script to a forthcoming remake of the original \"Hellraiser\" film. He was developing a film based on his \"Tortured Souls\" line of toys from McFarlane Toys. In 2020, Barker regained control of the \"Hellraiser\" franchise, and served as executive producer on a 2022 reboot film for the streaming service Hulu.\nTelevision work.\nIn May 2015, \"Variety\" reported that Clive Barker was developing a television series adaptation of various creepypastas in partnership with Warner Brothers, to be called \"Clive Barker's Creepypastas\", a feature arc based on \"Slender Man\" and \"Ben Drowned\". Barker was involved in a streaming service film adaptation of \"The Books of Blood\" in 2020, and is developing a \"Nightbreed\" television series directed by Michael Dougherty and written by Josh Stolberg for SyFy. In April 2020, HBO was announced to be developing a \"Hellraiser\" television series that would serve as \"an elevated continuation and expansion\" of its mythology with Mark Verheiden and Michael Dougherty writing the series and David Gordon Green directing several episodes. Verheiden, Dougherty and Green will also be executive producing the series with Danny McBride, Jody Hill, Brandon James and Roy Lee of Vertigo Entertainment.\nVisual art.\nBarker is a prolific visual artist, often illustrating his own books. His paintings have been seen first on the covers of his official fan club magazine, \"Dread\", published by Fantaco in the early '90s; on the covers of the collections of his plays, \"Incarnations\" (1995) and \"Forms of Heaven\" (1996); and on the second printing of the original British publications of his \"Books of Blood\" series. Barker also provided the artwork for his young adult novel \"The Thief of Always\" and for the \"Abarat\" series. His artwork has been exhibited at Bert Green Fine Art in Los Angeles and Chicago, at the Bess Cutler Gallery in New York and La Luz De Jesus in Los Angeles. Many of his sketches and paintings can be found in the collection \"Clive Barker, Illustrator\", published in 1990 by Arcane/Eclipse Books, and in \"Visions of Heaven and Hell\", published in 2005 by Rizzoli Books.\nHe worked on the horror video game \"Clive Barker's Undying\", providing the voice for the character Ambrose. \"Undying\" was developed by DreamWorks Interactive and released in 2001. He worked on \"Clive Barker's Jericho\" for Codemasters, which was released in late 2007.\nBarker created Halloween costume designs for Disguise Costumes.\nAround 150 art works by Barker were used in the set of the Academy of the Unseen Arts for the Netflix TV series \"Chilling Adventures of Sabrina\".\nComic books.\nBarker published his Razorline imprint via Marvel Comics in 1993.\nBarker horror adaptations and spin-offs in comics include the Marvel/Epic Comics series \"Hellraiser\", \"Nightbreed\", \"Pinhead\", \"The Harrowers\", \"Book of the Damned\", and \"Jihad\"; Eclipse Books' series and graphic novels \"Tapping The Vein\", \"Dread\", \"Son of Celluloid\", \"Revelations\", \"The Life of Death\", \"Rawhead Rex\" and \"The Yattering and Jack\", and Dark Horse Comics' \"Primal\", among others. Barker served as a consultant and wrote issues of the \"Hellraiser\" anthology comic book.\nIn 2005, IDW published a three-issue adaptation of Barker's children's fantasy novel \"The Thief of Always\", written and painted by Kris Oprisko and Gabriel Hernandez. IDW is publishing a 12 issue adaptation of Barker's novel \"The Great and Secret Show\".\nIn December 2007, Chris Ryall and Clive Barker announced an upcoming collaboration of an original comic book series, \"Torakator\", to be published by IDW.\nIn 2008, Barker authored a foreword for the first volume of the \"DEMONICSEX\" comic series by Chuck Conner and Sean Platter.\nIn October 2009, IDW published \"Seduth\", co-written by Barker. The work was released with three variant covers.\nIn 2011, Boom! Studios began publishing an original \"Hellraiser\" comic book series.\nIn 2013, Boom! Studios announced \"Next Testament\", the first original story by Barker to be published in comic book format.\nWorks.\nShort stories.\nCollections:\nUncollected short stories:\nPlays.\nCollections:\nAll plays:\nPoems.\nUncollected poems:\nExternal links.\n "}
{"id": "7574", "revid": "41592078", "url": "https://en.wikipedia.org/wiki?curid=7574", "title": "Fantasy comedy", "text": "Fantasy comedy or comic fantasy is a subgenre of fantasy that is primarily humorous in intent and tone. Typically set in imaginary worlds, fantasy comedy often involves puns on, and parodies of, other works of fantasy.\nLiterature.\nThe subgenre rose in the nineteenth century. Elements of fantasy comedy can be found in such nineteenth century works\nas some of Hans Christian Andersen's fairy tales, Charles Dickens' \"Christmas Books\", and Lewis Carroll's Alice books. The first writer to specialize in the subgenre was \"F. Anstey\" in novels such as \"Vice Versa\" (1882), where magic disrupts Victorian society with humorous results. Anstey's work was popular enough to inspire several imitations, including E. Nesbit's light-hearted children's fantasies, \"The Phoenix and the Carpet\" (1904) and \"The Story of the Amulet\" (1906). The United States had several writers of fantasy comedy, including James Branch Cabell, whose satirical fantasy \"Jurgen, A Comedy of Justice\" (1919) was the subject of an unsuccessful prosecution for obscenity. Another American writer in a similar vein was Thorne Smith, whose works (such as \"Topper\" and \"The Night Life of the Gods\") were popular and influential, and often adapted for film and television. Humorous fantasies narrated in a \"gentleman's club\" setting are common; they include John Kendrick Bangs' \"A Houseboat on the Styx\" (1895), Lord Dunsany's \"Jorkens\" stories, and Maurice Richardson's \n\"The Exploits of Englebrecht\" (1950).\nAccording to Lin Carter, T. H. White's works exemplify fantasy comedy, L. Sprague de Camp and Fletcher Pratt's Harold Shea stories are early exemplars. The overwhelming bulk of de Camp's fantasy was comic. Pratt and de Camp were among several contributors to \"Unknown Worlds\", a pulp magazine which emphasized fantasy with a comedic element. The work of Fritz Leiber also appeared in \"Unknown Worlds\", including his Fafhrd and the Gray Mouser stories, a jocose take on the sword and sorcery subgenre.\nIn more modern times, Terry Pratchett's \"Discworld\" books, Piers Anthony's \"Xanth\" books, Robert Asprin's \"MythAdventures\" of Skeeve and Aahz books, and Tom Holt's books provide good examples, as do many of the works by Christopher Moore. There are also comic-strips/graphic novels in the humorous fantasy genre, including Chuck Whelon's Pewfell series and the webcomics \"8-Bit Theater\" and \"The Order of the Stick\". Other authors of the genre in modern times include C.K. McDonnell, Jasper Fforde, Neil Gaiman, Robert Rankin, John Brosnan, Craig Shaw Gardner, David Lee Stone and Esther Freisner, as well as countless independent authors.\nOther media.\nThe subgenre has also been represented in television, such as in the television series \"I Dream of Jeannie\", \"Kr\u00f6d M\u00e4ndoon\". Examples on radio are the BBC's \"Hordes of the Things\" and \"ElvenQuest\". Fantasy comedy films can either be parodies (\"Monty Python and the Holy Grail\"), comedies with fantastical elements (\"Being John Malkovich, Barbie\") or animated (\"Shrek\"). It has also been used with fantasy as the primary genre and comedy as the secondary, as in the case of \"\" and its ."}
{"id": "7575", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7575", "title": "CLU (programming language)", "text": "CLU is a programming language created at the Massachusetts Institute of Technology (MIT) by Barbara Liskov and her students starting in 1973. While it did not find extensive use, it introduced many features that are used widely now, and is seen as a step in the development of object-oriented programming (OOP).\nKey contributions include abstract data types, call-by-sharing, iterators, multiple return values (a form of parallel assignment), type-safe parameterized types, and type-safe variant types. It is also notable for its use of classes with constructors and methods, but without inheritance.\nClusters.\nThe syntax of CLU was based on ALGOL, then the starting point for most new language designs. The key addition was the concept of a \"cluster\", CLU's type extension system and the root of the language's name (CLUster). Clusters correspond generally to the concept of a \"class\" in an OO language. For instance, here is the CLU syntax for a cluster that implements complex numbers:\nA cluster is a module that encapsulates all of its components except for those explicitly named in the \"is\" clause. These correspond to the public components of a class in recent OO languages. A cluster also defines a type that can be named outside the cluster (in this case, \"complex_number\"), but its representation type (rep) is hidden from external clients.\nCluster names are global, and no namespace mechanism was provided to group clusters or allow them to be created \"locally\" inside other clusters.\nIn a cluster, the explicit type conversions \"up\" and \"down\" change between the abstract type and the representation; implicit conversions between these types are signified using the special type \"cvt\". CLU does not otherwise perform implicit type conversions. There is a universal type \"any\", and a procedure force[] to check that an object is a certain type. Objects may be mutable or immutable, the latter being \"base types\" such as integers, booleans, characters and strings.\nOther features.\nAnother key feature of the CLU type system are \"iterators\", which return objects from a collection serially, one after another. Iterators offer an identical application programming interface (API) no matter what data they are being used with. Thus the iterator for a collection of codice_1s can be used interchangeably with that for an array of codice_2s. A distinctive feature of CLU iterators is that they are implemented as coroutines, with each value being provided to the caller via a \"yield\" statement. Iterators like those in CLU are now a common feature of many modern languages, such as C#, Ruby, and Python, though recently they are often referred to as generators.\nCLU also includes exception handling, based on various attempts in other languages; exceptions are raised using codice_3 and handled with codice_4. Unlike most other languages with exception handling, exceptions are not implicitly resignaled up the calling chain. Also unlike most other languages that provide exception handling, exceptions in CLU are considered part of ordinary execution flow and are considered a \"normal\" and efficient type-safe way to break out of loops or to return from functions; this allows for direct assignment of return values \"except when\" other conditions apply. Exceptions that are neither caught nor resignaled explicitly are immediately converted into a special failure exception that typically terminates the program.\nCLU is often credited as being the first language with type-safe variant types, called \"oneofs\", before the language ML had them.\nA final distinctive feature in CLU is parallel assignment (multiple assignment), where more than one variable can appear on the left hand side of an assignment operator. For instance, writing codice_5 would exchange values of codice_6 and codice_7. In the same way, functions could return several values, like . Parallel assignment (though not multiple return values) predates CLU, appearing in CPL (1963), named \"simultaneous assignment\", but CLU popularized it and is often credited as the direct influence leading to parallel assignment in later languages.\nAll objects in a CLU program live in the heap, and memory management is automatic.\nCLU supports type-parameterized user-defined data abstractions. It was the first language to offer type-safe bounded parameterized types, using \"where clauses\" to express constraints on actual type arguments. Unlike in languages with template-based generics, a use of such a data abstraction can be type-checked without access to the implementation of the abstraction.\nInfluence.\nCLU and Ada were major inspirations for C++ templates.\nCLU's exception handling mechanisms influenced later languages like C++ and Java.\nSather, Python, and C# include iterators, which first appeared in CLU.\nPerl and Lua took multiple assignment and multiple returns from function calls from CLU.\nPython and Ruby borrowed call by sharing, the \"yield\" statement, and multiple assignment."}
{"id": "7577", "revid": "3664477", "url": "https://en.wikipedia.org/wiki?curid=7577", "title": "History of the Soviet Union (1982\u20131991)", "text": "The history of the Soviet Union from 1982 through 1991 spans the period from the Soviet leader Leonid Brezhnev's death until the dissolution of the Soviet Union. Due to the years of Soviet military buildup at the expense of domestic development, and complex systemic problems in the command economy, Soviet output stagnated. Failed attempts at reform, a standstill economy, and the success of the proxies of the United States against the Soviet Union's forces in the war in Afghanistan led to a general feeling of discontent, especially in the Soviet-occupied Baltic countries and Eastern Europe.\nGreater political and social freedoms, instituted by the last Soviet leader Mikhail Gorbachev, created an atmosphere of open criticism of the communist regime, and also \"perestroika\". The dramatic drop of the price of oil in 1985 and 1986 profoundly influenced actions of the Soviet leadership.\nNikolai Tikhonov, the Chairman of the Council of Ministers, was succeeded by Nikolai Ryzhkov, and Vasili Kuznetsov, the acting Chairman of the Presidium of the Supreme Soviet, was succeeded by Andrei Gromyko, the former Minister of Foreign Affairs.\nSeveral republics began resisting central control, and increasing democratization led to a weakening of the central government. The Soviet Union finally collapsed in 1991 when Boris Yeltsin seized power in the aftermath of a failed coup that had attempted to topple the reform-minded Gorbachev.\nLeadership transition.\nBy 1982, the stagnation of the Soviet economy was obvious, as evidenced by the fact that the Soviet Union had been importing grain from the U.S. throughout the 1970s, but the system was so firmly entrenched that any real change seemed impossible. A huge rate of defense spending consumed large parts of the economy. The transition period that separated the Brezhnev and Gorbachev eras resembled the former much more than the latter, although hints of reform emerged as early as 1983.\nAndropov interregnum.\nBrezhnev died on 10 November 1982. After a two-day power struggle Yuri Andropov became the new General Secretary. He maneuvered his way into power both through his KGB connections and by gaining the support of the military by promising not to cut defense spending. For comparison, some of his rivals such as Konstantin Chernenko were skeptical of a continued high military budget. Aged 68, Andropov was the oldest person ever appointed as General Secretary. Andropov began a thorough house-cleaning throughout the party and state bureaucracy, a decision made easy by the fact that the Central Committee had an average age of 69. He replaced more than one-fifth of the Soviet ministers and regional party first secretaries and more than one-third of the department heads within the Central Committee apparatus. As a result, he replaced the aging leadership with younger, more vigorous administrators. But Andropov's ability to reshape the top leadership was constrained by his own age and poor health and the influence of Chernenko, his rival and longtime ally of Brezhnev who had previously supervised personnel matters in the Central Committee.\nThe transition of power from Brezhnev to Andropov was notably the first one in Soviet history to occur completely peacefully with no one being imprisoned, killed, or forced from office.\nDomestic policies.\nAndropov's domestic policy leaned heavily towards restoring discipline and order to Soviet society. He eschewed radical political and economic reforms, promoting instead a small degree of candor in politics and mild economic experiments similar to those that had been associated with the late Premier Alexei Kosygin's initiatives in the mid-1960s. In tandem with such economic experiments, Andropov launched an anti-corruption drive that reached high into the government and party ranks. Unlike Brezhnev, who possessed several mansions and a fleet of luxury cars, he lived quite simply. While visiting Budapest in early 1983, he expressed interest in Hungary's Goulash Communism and that the sheer size of the Soviet economy made strict top-down planning impractical. Changes were needed in a hurry for 1982 had witnessed the country's worst economic performance, with real GDP growth at almost zero percent.\nForeign policies.\nAndropov faced a series of foreign policy crises: the hopeless situation of the Soviet army in Afghanistan, threatened revolt in Poland, growing animosity with China, the polarization threat of war in the Middle East, and troubles in Ethiopia and South Africa. The most critical threat was the \"Second Cold War\" launched by American President Ronald Reagan and a specific attack on rolling back what he denounced as the \"Evil Empire\". Reagan was using American economic power, and Soviet economic weakness, to escalate massive spending on the Cold War, emphasizing high technology that Moscow lacked. The main response was raising the military budget to 70 percent of the national budget, and supplying billions of dollars worth of military aid to Syria, Iraq, Libya, South Yemen, the PLO, Cuba, and North Korea. That included tanks and armored troop carriers, hundreds of fighter planes, as well as anti-aircraft systems, artillery systems, and all sorts of high tech equipment for which the USSR was the main supplier for its allies. Andropov's main goal was to avoid an open war.\nIn foreign policy, the conflict in Afghanistan continued even though Andropov\u2014who now felt the invasion was a mistake\u2014half-heartedly explored options for a negotiated withdrawal. Andropov's rule was also marked by deterioration of relations with the United States. During a much-publicized \"walk in the woods\" with Soviet dignitary Yuli Kvitsinsky, American diplomat Paul Nitze suggested a compromise for reducing nuclear missiles in Europe on both sides that was ultimately ignored by the Politburo. Kvitsinsky would later write that, despite his own efforts, the Soviet leadership was not interested in compromise, instead calculating that peace movements in the West would force the Americans to capitulate. On 8 March 1983, during Andropov's reign as General Secretary, U.S. President Ronald Reagan famously labeled the Soviet Union an \"evil empire\". The same month, on 23 March, Reagan announced the Strategic Defense Initiative. Reagan claimed this research program into ballistic missile defense would be \"consistent with our obligations under the ABM Treaty\". However, Andropov was dismissive of this claim, and said that \"It is time they [Washington] stopped ... search[ing] for the best ways of unleashing nuclear war. ... Engaging in this is not just irresponsible. It is insane\".\nIn August 1983, Andropov announced that the country was stopping all work on space-based weapons. Meanwhile, Soviet\u2013U.S. arms control talks on intermediate-range nuclear weapons in Europe were suspended by the Soviet Union in November 1983 and by the end of the year, the Soviets had broken off all arms control negotiations.\nMassive bad publicity worldwide came when Soviet fighters shot down a civilian jet liner, Korean Air Flight KAL-007, which carried 269 passengers and crew. It had strayed over the Soviet Union on 1 September 1983 on its scheduled route from Anchorage, Alaska, to Seoul, South Korea. The Soviet system was unprepared to deal with a civilian airliner, and the shooting down was a matter of following orders without question. Instead of admitting an accident, Soviet media proclaimed a brave decision to meet a Western provocation. Together with its low credibility explanation in 1986 of the meltdown of the nuclear reactor at Chernobyl, the episode demonstrated an inability to deal with public relations crises; the propaganda system was only aimed at people who already were committed friends of the Soviet Union. Both crises were escalated by technological and organizational failures, compounded by human error.\nUS\u2212Soviet relations deteriorated rapidly especially after March 1983, when Reagan dubbed the Soviet Union an \"evil empire\". The official press agency TASS accused Reagan of \"thinking only in terms of confrontation and bellicose, lunatic anti-communism\". Further Soviet outrage was directed at Reagan's stationing of intermediate-range nuclear missiles in Western Europe. In Afghanistan, Angola, Nicaragua and elsewhere, under the Reagan Doctrine, the US began undermining Soviet-supported governments by supplying arms to anti-communist resistance movements in these countries.\nPresident Reagan's decision to deploy medium-range Pershing II missiles in Western Europe met with mass protests in countries such as France and West Germany, sometimes numbering 1 million people at a time. Many Europeans became convinced that the US and not the Soviet Union was the more aggressive country, and there was fear over the prospect of a war, especially since there was a widespread conviction in Europe that the US, being separated from the Red Army by two oceans as opposed to a short land border, was insensitive to the people of Germany and other countries. Moreover, the memory of World War II was still strong and many Germans could not forget the destruction and mass rapes committed by Soviet troops in the closing days of that conflict. This attitude was helped along by the Reagan Administration's comments that a war between NATO and the Warsaw Pact would not necessarily result in the use of nuclear weapons.\nAndropov's health declined rapidly during the tense summer and fall of 1983, and he became the first Soviet leader to miss the anniversary celebrations of the 1917 revolution that November. He died in February 1984 of kidney failure after disappearing from public view for several months. His most significant legacy to the Soviet Union was his discovery and promotion of Mikhail Gorbachev. Beginning in 1978, Gorbachev advanced in two years through the Kremlin hierarchy to full membership in the Politburo. His responsibilities for the appointment of personnel allowed him to make the contacts and distribute the favors necessary for a future bid to become general secretary. At this point, Western experts believed that Andropov was grooming Gorbachev as his successor. However, although Gorbachev acted as a deputy to the general secretary throughout Andropov's illness, Gorbachev's time had not yet arrived when his patron died early in 1984.\nChernenko interregnum.\nAt 73, Konstantin Chernenko was in poor health, suffering from emphysema, and unable to play an active role in policy making when he was chosen, after lengthy discussion, to succeed Andropov. But Chernenko's short time in office did bring some significant policy changes. The personnel changes and investigations into corruption undertaken under Andropov's tutelage came to an end. Chernenko advocated more investment in consumer goods and services and in agriculture. He also called for a reduction in the Communist Party of the Soviet Union's (CPSU) micromanagement of the economy and greater attention to public opinion. However, KGB repression of Soviet dissidents also increased. In February 1983, Soviet representatives withdrew from the World Psychiatric Organization in protest of that group's continued complaints about the use of psychiatry to suppress dissent. This policy was underlined in June when Vladimir Danchev, a broadcaster for Radio Moscow, referred to the Soviet troops in Afghanistan as \"invaders\" while conducting English-language broadcasts. After refusing to retract this statement, he was sent to a mental institution for several months. Valery Senderov, a leader of an unofficial union of professional workers, was sentenced to seven years in a labor camp early in the year for speaking out on discrimination practiced against Jews in education and the professions.\nAlthough Chernenko had called for renewed \"d\u00e9tente\" with the West, little progress was made towards closing the rift in East\u2212West relations during his rule. The Soviet Union boycotted the 1984 Summer Olympics in Los Angeles, retaliating for the United States-led boycott of the 1980 Summer Olympics in Moscow. In September 1984, the Soviet Union also prevented a visit to West Germany by East German leader Erich Honecker. Fighting in the Afghan Democratic Republic also intensified, but in the late autumn of 1984 the United States and the Soviet Union did agree to resume arms control talks in early 1985.\nRise of Gorbachev.\nIn addition to the failing economy, the prolonged war in Afghanistan, often referred to as the Soviet Union's \"Vietnam War\", led to increased public dissatisfaction with the Communist regime. Also, the Chernobyl disaster in 1986 added motive force to Gorbachev's glasnost and perestroika reforms, which eventually spiraled out of control and caused the Soviet system to collapse.\nOusting the old guard.\nAfter years of stagnation, the \"new thinking\" of younger Communist apparatchik began to emerge. Following the death of terminally ill Konstantin Chernenko, the Politburo elected Mikhail Gorbachev to the position of General Secretary of the Communist Party of the Soviet Union in March 1985. At 54, Gorbachev was the youngest person since Joseph Stalin to become General Secretary and the country's first head of state born a Soviet citizen instead of a subject of the tsar. During his official confirmation on 11 March, Foreign Minister Andrei Gromyko spoke of how the new Soviet leader had filled in for Chernenko as CC Secretariat, and praised his intelligence and flexible, pragmatic ideas instead of rigid adherence to party ideology. Gorbachev was aided by a lack of serious competition in the Politburo. He immediately began appointing younger men of his generation to important party posts, including Nikolai Ryzhkov, Secretary of Economics, Viktor Cherbrikov, KGB Chief, Foreign Minister Eduard Shevardnadze (replacing the 75-year-old Gromyko), Secretary of Defense Industries , and Secretary of Construction Boris Yeltsin. Removed from the Politburo and Secretariat was Grigory Romanov, who had been Gorbachev's most significant rival for the position of General Secretary. Gromyko's removal as Foreign Minister was the most unexpected change given his decades of unflinching, faithful service compared to the unknown, inexperienced Shevardnadze.\nMore predictably, the 80-year-old Nikolai Tikhonov, the Chairman of the Council of Ministers, was succeeded by Nikolai Ryzhkov, and Vasili Kuznetsov, the acting Chairman of the Presidium of the Supreme Soviet, was succeeded by Andrei Gromyko, the former Minister of Foreign Affairs.\nFurther down the chain, up to 40% of the first secretaries of the \"oblasts\" (provinces) were replaced with younger, better educated, and more competent men. The defense establishment was also given a thorough shakeup with the commanders of all 16 military districts replaced along with all theaters of military operation, as well as the three Soviet fleets. Not since World War II had the Soviet military had such a rapid turnover of officers. Sixty-eight-year-old Marshal Nikolai Ogarkov was fully rehabilitated after having fallen from favor in 1983\u201384 due to his handling of the KAL 007 shootdown and his ideas about improving Soviet strategic and tactical doctrines were made into an official part of defense policy, although some of his other ambitions such as developing the military into a smaller, tighter force based on advanced technology were not considered feasible for the time being. Many, but not all, of the younger army officers appointed during 1985 were proteges of Ogarkov.\nGorbachev got off to an excellent start during his first months in power. He projected an aura of youth and dynamism compared to his aged predecessors and made frequent walks in the streets of the major cities answering questions from ordinary citizens. He became the first leader that spoke with the Soviet people in person. When he made public speeches, he made clear that he was interested in constructive exchanges of ideas instead of merely reciting lengthy platitudes about the excellence of the Soviet system. He also spoke candidly about the slackness and run-down condition of Soviet society in recent years, blaming alcohol abuse, poor workplace discipline, and other factors for these situations. Alcohol was a particular nag of Gorbachev's, especially as he himself did not drink, and he made one of his major policy aims curbing the consumption of it.\nForeign policy.\nIn terms of foreign policy, the most important one, relations with the United States, remained twitchy through 1985. In October, Gorbachev made his first visit to a non-communist country when he traveled to France and was warmly received. The fashion-conscious French were also captivated by his wife Raisa and political pundits widely believed that the comparatively young Soviet leader would have a PR advantage over President Reagan, who was 20 years his senior.\nReagan and Gorbachev met for the first time in Geneva in November. The three weeks preceding the summit meeting were marked by an unprecedented Soviet media campaign against the Strategic Defense Initiative (SDI), taking advantage of opposition at home in the US to the program. When it finally took place, the two superpower leaders established a solid rapport that boded well for the future despite Reagan's refusal to compromise on abandonment of SDI. A joint communique by both parties stated that they were in agreement that nuclear war could not be won by either side and must never be allowed to happen. It was also agreed that Reagan and Gorbachev would carry out two more summit meetings in 1986\u201387.\nJimmy Carter had decisively ended the policy of d\u00e9tente, by financially aiding the Mujahideen movement in neighboring Socialist Afghanistan, which served as a pretext for the Soviet intervention in Afghanistan six months later, with the aims of supporting the Afghan government, controlled by the People's Democratic Party of Afghanistan. Tensions between the superpowers increased during this time, when Carter placed trade embargoes on the Soviet Union and stated that the Soviet invasion of Afghanistan was \"the most serious threat to the peace since the Second World War.\"\nEconomy.\nEast-West tensions increased during the first term of US President Ronald Reagan (1981\u201385), reaching levels not seen since the Cuban Missile Crisis as Reagan increased US military spending to 7% of the GDP. To match the military buildup, the Soviet Union increased its own military spending to 27% of its GDP and froze production of civilian goods at 1980 levels, causing a sharp economic decline in the already failing Soviet economy.\nThe US financed the training for the Mujahideen warlords such as Jalaluddin Haqqani, Gulbudin Hekmatyar and Burhanuddin Rabbani eventually culminated to the fall of the Soviet satellite the Democratic Republic of Afghanistan. While the CIA and MI6 and the People's Liberation Army of China financed the operation along with the Pakistan government against the Soviet Union, eventually the Soviet Union began looking for a withdrawal route and in 1988 the Geneva Accords were signed between Communist-Afghanistan and the Islamic Republic of Pakistan; under the terms Soviet troops were to withdraw. Once the withdrawal was complete the Pakistan ISI continued to support the Mujahideen against the Communist Government and by 1992, the government collapsed. US President Reagan also actively hindered the Soviet Union's ability to sell natural gas to Europe whilst simultaneously actively working to keep gas prices low, which kept the price of Soviet oil low and further starved the Soviet Union of foreign capital. This \"long-term strategic offensive,\" which \"contrasts with the essentially reactive and defensive strategy of \"containment\", accelerated the fall of the Soviet Union by encouraging it to overextend its economic base. The proposition that special operations by the CIA in Saudi Arabia affected the prices of Soviet oil was refuted by Marshall Goldman\u2014one of the leading experts on the economy of the Soviet Union\u2014in his latest book. He pointed out that the Saudis decreased their production of oil in 1985 (it reached a 16-year low), whereas the peak of oil production was reached in 1980. They increased the production of oil in 1986, reduced it in 1987 with a subsequent increase in 1988, but not to the levels of 1980 when production reached its highest level. The real increase happened in 1990, by which time the Cold War was almost over. In his book he asked why, if Saudi Arabia had such an effect on Soviet oil prices, did prices not fall in 1980 when the production of oil by Saudi Arabia reached its highest level\u2014three times as much oil as in the mid-eighties\u2014and why did the Saudis wait till 1990 to increase their production, five years after the CIA's supposed intervention? Why didn't the Soviet Union collapse in 1980 then?\nBy the time Gorbachev ushered in the process that would lead to the dismantling of the Soviet administrative command economy through his programs of \"uskoreniye\" (speed-up of economic development) and \"perestroika\" (political and economic restructuring) announced in 1986, the Soviet economy suffered from both hidden inflation and pervasive supply shortages aggravated by an increasingly open black market that undermined the official economy. Additionally, the costs of superpower status\u2014the military, space program, subsidies to client states\u2014were out of proportion to the Soviet economy. The new wave of industrialization based upon information technology had left the Soviet Union desperate for Western technology and credits in order to counter its increasing backwardness.\nReforms.\nThe Law on Cooperatives enacted in May 1988 was perhaps the most radical of the economic reforms during the early part of the Gorbachev era. For the first time since Vladimir Lenin's New Economic Policy, the law permitted private ownership of businesses in the services, manufacturing, and foreign-trade sectors. Under this provision, cooperative restaurants, shops, and manufacturers became part of the Soviet scene.\n\"Glasnost\" resulted in greater freedom of speech and the press becoming far less controlled. Thousands of political prisoners and many dissidents were also released. Soviet social science became free to explore and publish on many subjects that had previously been off limits, including conducting public opinion polls. The All\u2212Union Center for Public Opinion Research (VCIOM)\u2014the most prominent of several polling organizations that were started then\u2014 was opened. State archives became more accessible, and some social statistics that had been kept secret became open for research and publication on sensitive subjects such as income disparities, crime, suicide, abortion, and infant mortality. The first center for gender studies was opened within a newly formed Institute for the Socio\u2212Economic Study of Human Population.\nIn January 1987, Gorbachev called for democratization: the infusion of democratic elements such as multi-candidate elections into the Soviet political process. A 1987 conference convened by Soviet economist and Gorbachev adviser Leonid Abalkin, concluded: \"Deep transformations in the management of the economy cannot be realized without corresponding changes in the political system.\"\nIn June 1988, at the CPSU's Nineteenth Party Conference, Gorbachev launched radical reforms meant to reduce party control of the government apparatus. On 1 December 1988, the Supreme Soviet amended the Soviet constitution to allow for the establishment of a Congress of People's Deputies as the Soviet Union's new supreme legislative body.\nElections to the new Congress of People's Deputies were held throughout the USSR in March and April 1989. Gorbachev, as General Secretary of the Communist Party, could be forced to resign at any moment if the communist elite became dissatisfied with him. To proceed with reforms opposed by the majority of the communist party, Gorbachev aimed to consolidate power in a new position, President of the Soviet Union, which was independent from the CPSU and the soviets (councils) and whose holder could be impeached only in case of direct violation of the law. On 15 March 1990, Gorbachev was elected as the first executive president. At the same time, Article 6 of the constitution was changed to deprive the CPSU of a monopoly on political power.\nUnintended consequences.\nGorbachev's efforts to streamline the Communist system offered promise, but ultimately proved uncontrollable and resulted in a cascade of events that eventually concluded with the dissolution of the Soviet Union. Initially intended as tools to bolster the Soviet economy, the policies of \"perestroika\" and \"glasnost\" soon led to unintended consequences.\nRelaxation under \"glasnost\" resulted in the Communist Party losing its absolute grip on the media. Before long, and much to the embarrassment of the authorities, the media began to expose severe social and economic problems the Soviet government had long denied and actively concealed. Problems receiving increased attention included poor housing, alcoholism, drug abuse, pollution, outdated Stalin-era factories, and petty to large-scale corruption, all of which the official media had ignored. Media reports also exposed crimes committed by Joseph Stalin and the Soviet regime, such as the gulags, his treaty with Adolf Hitler, and the Great Purges, which had been ignored by the official media. Moreover, the ongoing war in Afghanistan, and the mishandling of the 1986 Chernobyl disaster, further damaged the credibility of the Soviet government at a time when dissatisfaction was increasing.\nIn all, the positive view of Soviet lifelong presented to the public by the official media was rapidly fading, and the negative aspects of life in the Soviet Union were brought into the spotlight. This undermined the faith of the public in the Soviet system and eroded the Communist Party's social power base, threatening the identity and integrity of the Soviet Union itself.\nFraying amongst the members of the Warsaw Pact countries and instability of its western allies, first indicated by Lech Wa\u0142\u0119sa's 1980 rise to leadership of the trade union Solidarity, accelerated, leaving the Soviet Union unable to depend upon its Eastern European satellite states for protection as a buffer zone. By 1989, following his doctrine of \"new political thinking\", Gorbachev had repudiated the Brezhnev Doctrine in favor of non-intervention in the internal affairs of its Warsaw Pact allies (\"Sinatra Doctrine\"). Gradually, each of the Warsaw Pact countries saw their communist governments fall to popular elections and, in the case of Romania, a violent uprising. By 1990, the governments of Bulgaria, Czechoslovakia, East Germany, Hungary, Poland and Romania, all of which had been imposed after World War II, were brought down as revolutions swept Eastern Europe.\nThe Soviet Union also began experiencing upheaval as the political consequences of \"glasnost\" reverberated throughout the country. Despite efforts at containment, the upheaval in Eastern Europe inevitably spread to nationalities within the USSR. In elections to the regional assemblies of the Soviet Union's constituent republics, nationalists as well as radical reformers swept the board. As Gorbachev had weakened the system of internal political repression, the ability of the USSR's central Moscow government to impose its will on the USSR's constituent republics had been largely undermined. Massive peaceful protests in the Baltic republics such as the Baltic Way and the Singing Revolution drew international attention and bolstered independence movements in various other regions.\nThe rise of nationalism under \"freedom of speech\" soon re-awakened simmering ethnic tensions in various Soviet republics, further discrediting the ideal of a unified Soviet people. One instance occurred in February 1988, when the government in Nagorno-Karabakh, a predominantly ethnic Armenian region in the Azerbaijan SSR, passed a resolution calling for unification with the Armenian SSR. Violence against local Azerbaijanis was reported on Soviet television, provoking massacres of Armenians in the Azerbaijani city of Sumgait.\nEmboldened by the liberalized atmosphere of \"glasnost\", public dissatisfaction with economic conditions was much more overt than ever before in the Soviet period. Although \"perestroika\" was considered bold in the context of Soviet history, Gorbachev's attempts at economic reform were not radical enough to restart the country's chronically sluggish economy in the late 1980s. The reforms made some inroads in decentralization, but Gorbachev and his team left intact most of the fundamental elements of the Stalinist system, including price controls, inconvertibility of the ruble, exclusion of private property ownership, and the government monopoly over most means of production.\nThe value of all consumer goods manufactured in 1990 in retail prices was about 459 billion rubles ($2.1 trillion). Nevertheless, the Soviet government had lost control over economic conditions. Government spending increased sharply as an increasing number of unprofitable enterprises required state support and consumer price subsidies to continue. Tax revenues declined as republic and local governments withheld tax revenues from the central government under the growing spirit of regional autonomy. The anti\u2212alcohol campaign reduced tax revenues as well, which in 1982 accounted for about 12% of all state revenue. The elimination of central control over production decisions, especially in the consumer goods sector, led to the breakdown in traditional supplier\u2212producer relationships without contributing to the formation of new ones. Thus, instead of streamlining the system, Gorbachev's decentralization caused new production bottlenecks.\nDissolution of the Soviet Union.\nThe dissolution of the Soviet Union' was a process of systematic disintegration, which occurred in the economy, social structure and political structure. It resulted in the abolition of the Soviet Federal Government (\"the Union center\") and independence of the USSR's republics on 26 December 1991. The process was caused by a weakening of the Soviet government, which led to disintegration and took place from about 19 January 1990 to 26 December 1991. The process was characterized by many of the republics of the Soviet Union declaring their independence and being recognized as sovereign nation-states.\nAndrei Grachev, the Deputy Head of the Intelligence Department of the Central Committee, summed up the denouement of the downfall quite cogently:\nPost-Soviet restructuring.\nTo restructure the Soviet administrative command system and implement a transition to a market economy, Yeltsin's shock program was employed within days of the dissolution of the Soviet Union. The subsidies to money-losing farms and industries were cut, price controls abolished, and the ruble moved towards convertibility. New opportunities for Yeltsin's circle and other entrepreneurs to seize former state property were created, thus restructuring the old state-owned economy within a few months.\nAfter obtaining power, the vast majority of \"idealistic\" reformers gained huge possessions of state property using their positions in the government and became business oligarchs in a manner that appeared antithetical to an emerging democracy. Existing institutions were conspicuously abandoned prior to the establishment of new legal structures of the market economy such as those governing private property, overseeing financial markets, and enforcing taxation.\nMarket economists believed that the dismantling of the administrative command system in Russia would raise GDP and living standards by allocating resources more efficiently. They also thought the collapse would create new production possibilities by eliminating central planning, substituting a decentralized market system, eliminating huge macroeconomic and structural distortions through liberalization, and providing incentives through privatization.\nSince the USSR's collapse, Russia faced many problems that free market proponents in 1992 did not expect. Among other things, 25% of the population lived below the poverty line, life expectancy had fallen, birthrates were low, and the GDP was halved. There was a sharp increase in economic inequality between 1988/1989 and 1993/1995, with the Gini ratio increasing by an average of 9 points for all former socialist countries. These problems led to a series of crises in the 1990s, which nearly led to the election of Yeltsin's Communist challenger, Gennady Zyuganov, in the 1996 presidential election. After the turn of the century, the economy of Russia has begun to improve greatly, due to major investments and business development and also due to high prices of natural resources.\nHistoriography.\nAccording to Boris N. Mironov, by 2020 Russian scholars had produced over 300 books, 3000 articles, and 20 dissertations trying to explain the collapse. Two approaches were taken. The first is to look at the short term, 1985\u20131991, emphasizing personalities. external causes and policy mistakes. The second looks at long-term economic, political, cultural, and social structures."}
{"id": "7578", "revid": "39999417", "url": "https://en.wikipedia.org/wiki?curid=7578", "title": "Corsican language", "text": "Corsican (, , or , ) is a Romance language consisting of the continuum of the Tuscan Italo-Dalmatian dialects spoken on the Mediterranean island of Corsica, a territory of France, and in the northern regions of the island of Sardinia, an autonomous region of Italy.\nCorsica is situated approximately 123.9\u00a0km (77.0 miles; 66 nautical miles) off the western coast of Tuscany; and with historical connections, the Corsican language is considered a part of Tuscan varieties, from that part of the Italian peninsula, and thus is closely related to Florentine-based standard Italian.\nUnder the long-standing influence of Tuscany's Pisa, and the historic Republic of Genoa, over Corsica, the Corsican language once filled the role of a vernacular, with Italian functioning as the island's official language until France acquired the island from the Republic of Genoa (1768); by 1859, French had replaced Italian as Corsica's first language so much so that, by the time of the Liberation of France (1945), nearly every islander had at least a working-knowledge of French. The 20th century saw a vast language shift, with the islanders adapting and changing their communications to the extent that there were no monolingual Corsican-speakers left by the 1960s. By 1995, an estimated 65% of islanders had some degree of proficiency in Corsican, and a minority of around 10% used Corsican as a first language.\nClassification.\nCorsican is classed as a regional language under French law. It is almost universally agreed that Corsican is typologically and traditionally Italo-Romance, but its specific position therein is more controversial. Some scholars argue that Corsican belongs to the Centro-Southern Italian dialects, while others are of the opinion that it is closely related to, or as part of, Italy's Tuscan dialect varieties. Italian and the dialects of Corsican (especially Northern Corsican) are in fact very mutually intelligible. Southern Corsican, in spite of the geographical proximity, has as its closest linguistic neighbour not Sardinian (a separate group with which it is not mutually intelligible), but rather the Extreme Southern Italian dialects like Siculo-Calabrian. It has been theorised, on the other hand, that a Sardinian variety, or a variety very similar to Sardo-Romance, might have been originally spoken in Corsica prior to the island's Tuscanisation under Pisan and Genoese rule.\nThe matter is controversial in light of the historical, cultural and particularly strong linguistic bonds that Corsica had traditionally formed with the Italian Mainland from the Middle Ages until the 19th century: in contrast to the neighbouring Sardinia, Corsica's installment into a diglossic system with Italian as the island's prestige language ran so deep that both Corsican and Italian might be even, and in fact were, perceived as two sociolinguistic levels of a single language. Corsican and Italian traditionally existed on a spectrum, and the dividing lines between them were blurred enough that the locals needed little else but a change of register to communicate in an official setting. \"Tuscanising\" their tongue, or as the Corsican elites would have once said, \"parl\u00e0 in crusca\" (\"speaking in \"crusca\"\", from the name of the Academy dedicated to the standardisation of the Italian language), allowed for a practice not of code-switching, but rather of code-mixing which is quite typical of the Mainland Italian dialects. Italian was perceived as different from Corsican, but not as much as the differences between the two main isoglosses of Northern and Southern Corsican, as spoken by their respective native speakers. When Pasquale Paoli found himself exiled in London, he replied to Samuel Johnson's query on the peculiar existence of a \"rustic language\" very different from Italian that such a language existed only in Sardinia; in fact, the existence of Corsican as the island's native vernacular did not take anything away from Paoli's claims that Corsica's official language was Italian.\nToday's Corsican is the result of these historical vicissitudes, which have morphed the language to an idiom that bears a strong resemblance to the medieval Tuscan once spoken at the time of Dante and Boccaccio, and still existing in peripheral Tuscany (Lucca, Garfagnana, Elba, Capraia). The correspondence of modern Corsican to ancient Tuscan can be seen from almost any aspect of the language, ranging from the phonetics, morphology, lexicon to the syntax. One of the characteristics of standard Italian is the retention of the -\"re\" infinitive ending, as in Latin \"mittere\" \"send\"; such infinitival ending is lost in Tuscan as well as Corsican, resulting in the outcome \"mette\" / \"metta\", \"to put\". Whereas the relative pronoun in Italian for \"who\" is \"chi\" and \"what\" is \"che\"/\"(che) cosa\", it is an uninflected \"ch\u00ec\" in Corsican. The only unifying, as well as distinctive, feature which separates the Corsican dialects from the mainland Tuscan ones, with the exception of Amiatino, Pitiglianese, and Capraiese, is the retention of word-final \"o\"-\"u\". For example, the Italian demonstrative pronouns \"questo\" \"this\" and \"quello\" \"that\" become in Corsican \"questu\" or \"quistu\" and \"quellu\" or \"quiddu\": this feature was also typical of the early Italian texts during the Middle Ages.\nEven after the acquisition of Corsica by Louis XV, Italian continued to be the island's language of education, literature, religion and local affairs. The affluent youth still went to Italy to pursue higher studies. (It has been estimated that Corsican presence in Pisa amounted to a fourth of the University's total student body in 1830.) Local civil registers continued to be written in Italian until 1855; it was on 9 May 1859, that Italian was replaced by French as the island's official language, although the latter would start to take root among the islanders from 1882 onwards, through the Jules Ferry laws aimed at spreading literacy across the French provinces. Even so, a specifically homegrown Corsican (rather than Italian) literature in Corsica only developed belatedly and, in its earliest phase, there were no autonomous cultural instances; Corsican writers, such as Salvatore Viale, even prided themselves on their affiliation to the broader Italian sphere, considering Corsican \"one of the lowest, impure dialects of Italy\".\nIt was the Italian Fascist aggressive claims to the island in the 20th century, followed by their invasion, that provoked a popular backlash, estranging the native islanders from standard Italian and, if anything, only accelerated their shifting to the French even further. By the Liberation of France, any previously existing link between the two linguistic varieties and with Italy altogether had been severed; any promotion of Corsican, which had been politicized by the local collaborators with the regime, would be met with popular criticism and even suspicion of potentially harboring irredentist sentiments. From then on, Corsican would grow independently of Italian to become, later in the 1970s, a centerpiece of the \"Riacquistu\" (\"reacquisition\") movement for the rediscovery of Corsican culture. Nationalist calls for Corsican to be put on the same footing as French led the French National Assembly, in 1974, to extend the 1951 Deixonne Law, which initially recognized only a few languages (Breton, Basque, Catalan and Occitan), to including Corsican as well, among others, not as a dialect of Italian, but as one of France's full-fledged regional languages. (See governmental support.)\nOrigins.\nThe common relationship between Corsica and central Italy can be traced from as far back as the Etruscans, who asserted their presence on the island in as early as 500 BC. In 40 AD, the natives of Corsica reportedly did not speak Latin. The Roman exile, Seneca the Younger, reported that both coast and interior were occupied by natives whose language he was not able to understand. More specifically, Seneca claimed that the island's population was the result of the stratification of different ethnic groups, such as the Greeks, the Ligures (see the Ligurian hypothesis) and the Iberians, whose language had long since stopped being recognizable among the population due to the intermixing of the other two groups. The occupation of the island by the Vandals around the year 469 marked the end of authoritative influence by Latin speakers. (See Medieval Corsica.) If the natives of that time spoke Latin, they must have acquired it during the late empire.\nModern Corsican has been influenced by the languages of the major powers taking an interest in Corsican affairs; earlier by those of the medieval Italian powers, such as the Papal States (828\u20131077), the Republic of Pisa (1077\u20131282) and the Republic of Genoa (1282\u20131768), and finally by France which, since 1859, has promulgated the official Parisian French. The term \"gallicised Corsican\" refers to the evolution of Corsican starting from about the year 1950, whereas \"distanciated Corsican\" refers to an idealized variety of Corsican following linguistic purism, by means of removing any French-derived elements.\nDialects.\nCorsica.\nThe two most widely spoken forms of the Corsican language are the groups spoken in the Bastia and Corte area (generally throughout the northern half of the island, known as Haute-Corse, \"Cismonte\" or \"Corsica suprana\"), and the groups spoken around Sart\u00e8ne and Porto-Vecchio (generally throughout the southern half of the island, known as Corse-du-Sud, \"Pumonti\" or ). The dialect of Ajaccio has been described as in transition. The dialects spoken at Calvi and Bonifacio (Bonifacino) are dialects of the Ligurian language.\nThis division along the Girolata-Porto Vecchio line was due to the massive immigration from Tuscany which took place in Corsica during the lower Middle Ages: as a result, the northern Corsican dialects became very close to a central Italian dialect like Tuscan, while the southern Corsican varieties could keep the original characteristics of the language which make it much more similar to Sicilian and, only to some extent, Sardinian.\nNorthern Corsican.\nThe Northern Corsican macro variety (\"Supranacciu\", \"Supranu\", \"Cismuntincu\" or \"Cismontano\") is the most widespread on the island and standardised as well, and is spoken in North-West Corsica around the districts of Bastia and Corte. The dialects of Bastia and Cap Corse belong to the Western Tuscan dialects; they being, with the exception of Florentine, the closest to standard Italian. All the dialects presenting, in addition to what has already been stated, the conditional formed in (e.g. \"she would love\") are generally considered \"Cismontani\" dialects, situated north of a line uniting the villages of Piana, Vico, Vizzavona, Ghisoni and Ghisonaccia, and also covering the subgroups from the Cap Corse (which, unlike the rest of the island and similarly to Italian, uses \"lu\", \"li\", \"la\", \"le\" as definite articles), Bastia (besides i &gt; e and a &gt; e, u &gt; o: , , , ; a &gt; o: , , ), Balagna, Niolo and Corte (which retain the general Corsican traits: , , , , , , , , , , , , , , ).\nTransitional area.\nAcross the Northern and Southern borders of the line separating the Northern dialects from the Southern ones, there is a transitional area picking up linguistic phenomena associated with either of the two groups, with some local peculiarities. Along the Northern line are the dialects around Piana and Calcatoggio, from Cinarca with Vizzavona (which form the conditional as in the South), and Fiumorbo through Ghisonaccia and Ghisoni, which have the retroflex sound (written \"-dd-\") for historical ; along the Southern line, the dialects of Ajaccio (retroflex \"-dd-\", realized as -\"ghj\"-, feminine plurals ending in \"i\", some Northern words like \"cane\" and \"accatt\u00e0\" instead of \"ghjacaru\" and \"cumpr\u00e0\", as well as \"ellu\"/\"ella\" and not \"eddu\"/\"edda\"; minor variations: \"sabbatu\" &gt; \"sabbitu\", \"u li d\u00e0\" &gt; \"ghi lu d\u00e0\"; final syllables often stressed and truncated: \"marinari\" &gt; \"marin\u00e0\", &gt; \"panatt\u00e8\", \"castellu\" &gt; \"cast\u00e8\", \"cuchjari\" &gt; \"cuchj\u00e0\"), the Gravona area, Bastelica (which would be classified as Southern, but is also noted for its typical rhotacism: \"Basterga\") and Solenzara, which did not preserve the Latin short vowels: \"seccu\", \"peru\", \"rossu\", \"croci\", \"pozzu\".\nSouthern Corsican.\nThe Southern Corsican macro variety (\"Suttanacciu\", \"Suttanu\", \"Pumuntincu\" or \"Oltramontano\") is the most archaic and conservative group, spoken in the districts of Sart\u00e8ne and Porto-Vecchio. Unlike the Northern varieties and similarly to Sardinian, the group retains the distinction of the Latin short vowels \"\u012d\" and \"\u016d\" (e.g. \"pilu\", \"bucca\"). It is also strongly marked by the presence of the voiced retroflex stop, like Sicilian (e.g. \"aceddu\", \"beddu\", \"quiddu\", \"ziteddu\", \"famidda\"), and the conditional mood formed in \"-\u00eca\" (e.g. \"(idda) amar\u00eca\" \"she would love\"). All the \"Oltramontani\" dialects are from an area located to the South of Porticcio, Bastelica, Col di Verde and Solenzara. Notable dialects are those from around Taravo (retroflex -\"dd\"- only for historical : \"frateddu\", \"suredda\", \"beddu\"; preservation of the palatal lateral approximant: \"pigli\u00e0\", \"famiglia\", \"figliolu\", ; does not preserve the Latin short vowels: \"seccu\", \"peru\", \"rossu\", \"croci\", \"pozzu\"), Sart\u00e8ne (preserving the Latin short vowels: \"siccu\", \"piru\", \"russu\", \"cruci\", \"puzzu\"; changing historical \"-rn-\" to \"-rr-\": \"forru\", \"carri\", \"corru\"; substituting the stop for the palatal lateral approximant: \"pidd\u00e0\", \"famidda\", \"fiddolu\", \"voddu\"; imperfect tense like \"cant\u00e0vami\", \"cant\u00e0vani\"; masculine plurals ending in \"a\": \"l'ochja\", \"i poma\"; having \"eddu/edda/eddi\" as personal pronouns), the Alta Rocca (the most conservative area in Corsica, being very close to the varieties spoken in Northern Sardinia), and the Southern region located between the hinterlands of Porto-Vecchio and Bonifacio (masculine singulars always ending in \"u\": \"fiumu\", \"paesu\", \"patronu\"; masculine plurals always ending in \"a\": \"i letta\", \"i solda\", \"i ponta\", \"i foca\", \"i mura\", \"i loca\", \"i balcona\"; imperfect tense like \"cant\u00e0iami\", \"cant\u00e0iani\").\nSardinia.\nSome Italo-Romance languages that might have originated from Southern Corsican, but are also heavily influenced by the Sardinian language, are spoken in the neighbouring island of Sardinia.\nGallurese is spoken in the extreme north of the island, including the region of Gallura, while Sassarese is spoken in Sassari and in its neighbourhood, in the northwest of Sardinia. Their geographical position in Sardinia has been theorised to be the result of different migration waves from the already tuscanized Corsicans and the Tuscans, who then proceeded to settle in Sardinia and slowly displace the indigenous Logudorese Sardinian varieties spoken therein (at present, Luras is the only town in the middle of Gallura that has retained the original language).\nOn the Maddalena archipelago, which was culturally Corsican but had been annexed to the Savoyard Kingdom of Sardinia a short while before Corsica was ceded by Genoa to France in 1767, the local dialect (called \"isulanu\" or \"maddaleninu\") was brought by fishermen and shepherds from Bonifacio over a long period of immigration in the 17th and 18th centuries. Though influenced by Gallurese, it has maintained the original characteristics of Southern Corsican. In the dialect of \"maddalenino\", as it is known in Italian, there are also numerous words of Genoese and Ponzese origin.\nAlthough Gallurese and Sassarese both belong to Italo-Dalmatian, which is a group typologically different from Sardinian, it has long been a subject of debate whether the two should be included as dialects either of Corsican or of Sardinian or, in light of their historical development, even considered languages of their own. It has been argued that all these varieties should be placed in a single category, Southern Romance, but such classification has not garnered universal support among linguists.\nOn 14 October 1997, Article 2 Item 4 of Law Number 26 of the Autonomous Region of Sardinia granted \"the Sassarese and Gallurese dialects\" (\u00ab\"al dialetto sassarese e a quello gallurese\"\u00bb) equal legal status with the other languages indigenous to Sardinia. Thus, even though they would technically not be covered by the national law pertaining to the historical linguistic minorities, among which is Sardinian, Sassarese and Gallurese are nonetheless recognized by the Sardinian government on a regional level.\nNumber of speakers.\nThe situation of Corsican with regard to French as the country's national language is analogous to that of many other French regions and provinces, which have or used to have a traditional language of their own, even though the islanders' switch from their local idiom to regional French has happened relatively later and the presence of Corsican, albeit declining, is still strongly felt among the population. In 1980, about 70 percent of the island's population \"had some command of the Corsican language.\" In 1990, out of a total population of about 254,000, the percentage had declined to 50 percent, with 10 percent of the island's residents using it as a first language. The language appeared to be in serious decline when the French government reversed its unsupportive stand and initiated some strong measures to save it.\nThe January 2007 estimated population of Corsica was 281,000, whereas the figure for the March 1999 census, when most of the studies\u2014though not the linguistic survey work referenced in this article\u2014were performed, was about 261,000. Only a fraction of the population at either time spoke Corsican with any fluency.\nAccording to an official survey run on behalf of the Territorial Collectivity of Corsica which took place in April 2013, in Corsica, the Corsican language had a number of speakers between 86,800 and 130,200, out of a total population amounting to 309,693 inhabitants. 28% of the overall population was able to speak Corsican well, while an additional 14% had a capacity to speak it \"quite well.\" The percentage of those who had a solid oral understanding of the language varies between a minimum of 25 percent in the 25\u201334 age group and the maximum of 65 percent in the over-65 age group: almost a quarter of the former age group reported that they were not able to understand Corsican, while only a small minority of the older people did not understand it. While 32 percent of the population of Northern Corsica was reported to speak Corsican quite well, this percentage dropped to 22 percent for Southern Corsica. Moreover, 10 percent of the population of Corsica spoke only French, while 62 percent code-switched between French and at least some Corsican. 8 percent of the Corsicans knew how to write correctly in Corsican, while about 60 percent of the population did not know how to write in Corsican. While 90 percent of the population was in favor of a Corsican-French bilingualism, 3 percent would have liked to have only Corsican as the official language in the island, and 7 percent would have preferred French to have this role.\nUNESCO classifies Corsican as a \"definitely endangered language.\" The Corsican language is a key vehicle for Corsican culture, which is notably rich in proverbs and in polyphonic song.\nGovernmental support.\nWhen the French Assembly passed the Deixonne Law in 1951, which made it possible for regional languages to be taught at school, Alsatian, Flemish and Corsican were not included on the ground of being classified as \"dialectes allog\u00e8nes\" of German, Dutch and Italian respectively, i.e. dialects of foreign languages and not languages in themselves. Only in 1974 were they too politically recognized as regional languages for their teaching on a voluntary basis.\nThe 1991 Joxe Statute, in setting up the Collectivit\u00e9 Territoriale de Corse, also provided for the Corsican Assembly, and charged it with developing a plan for the optional teaching of Corsican. The University of Corsica Pasquale Paoli at Corte, Haute-Corse took a central role in the planning.\nAt the primary school level Corsican is taught up to a fixed number of hours per week (three in the year 2000) and is a voluntary subject at the secondary school level, but is required at the University of Corsica. It is available through adult education. It can be spoken in court or in the conduct of other government business if the officials concerned speak it. The Cultural Council of the Corsican Assembly advocates for its use, for example, on public signs.\nIn 2023, in a judgement initiated by local prefect and going in opposite direction of recent trends, usage of the Corsican language in French public offices and the regional parliament was legally banned, the existence of the \"Corsican people\" was also deemed unconstitutional.\nLiterature.\nAccording to the anthropologist Dumenica Verdoni, writing new literature in modern Corsican, known as the \"Riacquistu\", is an integral part of affirming Corsican identity. Some individuals have returned from careers in continental France to write in Corsican, including Dumenicu Togniotti, director of the \"Teatru Paisanu\", which produced polyphonic musicals, 1973\u20131982, followed in 1980 by Michel Raffaelli's \"Teatru di a Testa Mora\", and Saveriu Valentini's \"Teatru Cupabbia\" in 1984. Modern prose writers include Alanu di Meglio, Ghjacumu Fusina, Lucia Santucci, and Marcu Biancarelli.\nThere were writers working in Corsican in the 1700s and 1800s.\nFerdinand Gregorovius, a 19th-century traveller and enthusiast of Corsican culture, reported that the preferred form of the literary tradition of his time was the \"vocero\", a type of polyphonic ballad originating from funeral obsequies. These laments were similar in form to the chorales of Greek drama except that the leader could improvise. Some performers were noted at this, such as the 1700s Mariola della Piazzole and Clorinda Franseschi. However, the trail of written popular literature of known date in Corsican currently goes no further back than the 17th century. An undated corpus of proverbs from communes may well precede it (see under \"External links\" below). Corsican has also left a trail of legal documents ending in the late 12th century. At that time the monasteries held considerable land on Corsica and many of the churchmen were notaries.\nBetween 1200 and 1425 the monastery of Gorgona, which belonged to the Order of Saint Benedict for much of that time and was in the territory of Pisa, acquired about 40 legal papers of various sorts related to Corsica. As the church was replacing Pisan prelates with Corsican ones there, the legal language shows a transition from entirely Latin through partially Latin and partially Corsican to entirely Corsican. The first known surviving document containing some Corsican is a bill of sale from Patrimonio dated to 1220. These documents were moved to Pisa before the monastery closed its doors and were published there. Research into earlier evidence of Corsican is ongoing.\nAlphabet and spelling.\nCorsican is written in the standard Latin script, using 21 of the letters for native words. The letters j, k, w, x, and y are found only in foreign names and French vocabulary. The digraphs and trigraphs \"chj\", \"ghj\", \"sc\" and \"sg\" are also defined as \"letters\" of the alphabet in its modern scholarly form (compare the presence of \"ch\" or \"ll\" in the old Spanish alphabet) and appear respectively after \"c\", \"g\" and \"s\".\nThe primary diacritic used is the grave accent, indicating word stress when it is not penultimate. In scholarly contexts, disyllables may be distinguished from diphthongs by use of the diaeresis on the former vowel (as in Italian and distinct from French and English). In older writing, the acute accent is sometimes found on stressed , the circumflex on stressed , indicating respectively () and () phonemes.\nCorsican has been regarded as a dialect of Italian historically, similar to the Romance lects developed on the Italian peninsula, and in writing, it also resembles Italian (with the generalised substitution of -\"u\" for final -\"o\" and the articles \"u\" and \"a\" for \"il/lo\" and \"la\" respectively; however, both the dialect of Cap Corse and Gallurese retain the original articles \"lu\" and \"la\"). On the other hand, the phonemes of the modern Corsican dialects have undergone complex and sometimes irregular phenomena depending on phonological context, so the pronunciation of the language for foreigners familiar with other Romance languages is not straightforward.\nPhonology.\nVowels.\nAs in Italian, the grapheme appears in some digraphs and trigraphs in which it does not represent the phonemic vowel. All vowels are pronounced except in a few well-defined instances. is not pronounced between and : \"sciarpa\" ; or initially in some words: \"istu\" \nVowels may be nasalized before (which is assimilated to before or ) and the palatal nasal consonant represented by . The nasal vowels are represented by the vowel plus , or . The combination is a digraph or trigraph indicating the nasalized vowel. The consonant is pronounced in weakened form. The same combination of letters might not be the digraph or trigraph but might be just the non-nasal vowel followed by the consonant at full weight. The speaker must know the difference. Example of nasal: is pronounced and not .\nThe Northern and central dialects in the vicinity of the Taravo river adopt the Italian seven-vowel system, whereas all the Southern ones around the so-called \"archaic zone\" with its centre being the town of Sart\u00e8ne (including the Gallurese dialect spoken in Northern Sardinia) resort to a five-vowel system without length differentiation, like Sardinian.\nThe vowel inventory, or collection of phonemic vowels (and the major allophones), transcribed in IPA symbols, is:"}
{"id": "7580", "revid": "87591", "url": "https://en.wikipedia.org/wiki?curid=7580", "title": "Commodore International", "text": "Commodore International Corporation was a home computer and electronics manufacturer with its head office in The Bahamas and its executive office in the United States founded in 1976 by Jack Tramiel and Irving Gould. It was the successor company to Commodore Business Machines (Canada) Ltd., established in 1958 by Tramiel and Manfred Kapp. Commodore International (CI), along with its U.S. subsidiary Commodore Business Machines, Inc. (CBM), was a significant participant in the development of the home computer industry, and at one point in the 1980s was the world's largest in the industry.\nThe company released its first home computer, the Commodore PET, in 1977; it was followed by the VIC-20, the first ever computer to reach one million units of sales. In 1982, the company developed and marketed the world's best selling computer, the Commodore 64; its success made Commodore one of the world's largest personal computer manufacturers, with sales peaking in the last quarter of 1983 at $ (equivalent to $ in ). However an internal struggle led to co-founder Tramiel quitting, then rivalling Commodore under Atari Corporation joined by a number of other employees. Commodore in 1985 launched the Amiga 1000 personal computer \u2014 running on AmigaOS featuring a full color graphical interface and preemptive multitasking \u2014 which would initially become a popular platform for computer games and creative software. The company did particularly well in European markets; in West Germany, Commodore machines were ubiquitous as of 1989.\nThe company's position started declining in the late 1980s amid internal conflicts and mismanagement, and while the Amiga line was popular, newer models failed to keep pace against competing IBM PC-compatibles and Apple Macintosh. By 1992, MS-DOS and 16-bit video game consoles offered by Nintendo and Sega had eroded Amiga's status as a solid gaming platform. Under co-founding chairman Irving Gould and president Mehdi Ali, Commodore filed for bankruptcy on April 29, 1994 and was soon liquidated, with its assets purchased by German company Escom. The Amiga line was revitalized and continued to be developed by Escom until it too went bankrupt, in July 1996. Commodore's computer systems, mainly the C64 and Amiga series, retain a cult following decades after its demise.\nCommodore's assets have been passed through various companies since then. After Escom's demise and liquidation, its core assets were sold to Gateway 2000 while the Commodore brand name was eventually passed to Tulip Computers of the Netherlands, and remains under ownership of a Dutch company today. Gateway 2000 attempted but failed to market a modern Amiga, and eventually sold the copyrights, Amiga trademark and other intellectual properties to Amiga, Inc., while retaining the Commodore patents, which are now under Acer since its acquisition of Gateway. Amiga Corp., a sister company of Cloanto, owns the Amiga properties since 2019. Hyperion Entertainment of Belgium has continued development of AmigaOS (version 4) to this day under license, and have released AmigaOne computers based on PowerPC.\nHistory.\nCommodore Business Machines (Canada) Ltd. (1954\u20131976).\nJack Tramiel and Manfred Kapp met in the early 1950s while both employed by the Ace Typewriter Repair Company in New York City. In 1954, they partnered to sell used and reconditioned typewriters and used their profits to purchase the Singer Typewriter Company. After acquiring a local dealership selling Everest adding machines, Tramiel convinced Everest to give him and Kapp exclusive Canadian rights to its products and established Everest Office Machines in Toronto in 1955.\nBy 1958, the adding machine business was slowing. Tramiel made a connection with an Everest agent in England who alerted him to a business opportunity to import portable typewriters manufactured by a Czechoslovakian company into Canada. On October 10, 1958, Tramiel and Kapp incorporated Commodore Portable Typewriter, Ltd. in Toronto to sell the imported typewriters. Commodore funded its operations through factoring over its first two years but faced a continual cash crunch. To bolster the company's financial condition, Tramiel and Kapp sold a portion of the company to Atlantic Acceptance Corporation, one of Canada's largest financing companies, and Atlantic President C. Powell Morgan became the chairman of Commodore. In 1962, the company went public on the Montreal Stock Exchange, under the name of Commodore Business Machines (Canada), Ltd.\nWith the financial backing of Atlantic Acceptance, Commodore expanded rapidly in the early 1960s. It purchased a factory in West Germany to manufacture its typewriters, began distributing office furniture for a Canadian manufacturer, and sold Pearlsound radio and stereo equipment. In 1965, it purchased the furniture company for which it served as the distributor and moved its headquarters to its facilities on Warden Avenue in the Scarborough district of Toronto. That same year, the company made a deal with a Japanese manufacturer to produce adding machines for Commodore, and purchased the office supply retailer Wilson Stationers to serve as an outlet for its typewriters.\nIn 1965, Atlantic Acceptance collapsed when it failed to make a routine payment. A subsequent investigation by a royal commission revealed a massive fraud scheme in which the company falsified financial records to acquire loans funneled into a web of subsidiaries where C. Powell Morgan held a personal stake. Morgan then pocketed the money or invested it in several unsuccessful ventures. Commodore was one of the Atlantic subsidiaries directly implicated in this scheme. Despite heavy suspicion, the commission could not find evidence of wrongdoing by Tramiel or Kapp. The scandal left Commodore in a worse financial position as it had borrowed heavily from Atlantic to purchase Wilson, and the loan was called in. Due to the financial scandal, Tramiel could only secure a bridge loan by paying interest well above the prime rate and putting the German factory up as collateral. Tramiel worked with a financier named Irving Gould to extricate himself, who brokered a deal to sell Wilson Stationers to an American company. Commodore now owed Gould money and still did not have sufficient capital to meet its payments, so Tramiel sold 17.9% of the company to Gould in 1966 for $ (equivalent to $ in ). As part of the deal, Gould became the company's new chairman.\nTramiel saw some of the first electronic calculators through his Japanese contacts in the late 1960s. He pivoted from adding machines to marketing calculators produced by companies like Casio under the Commodore brand name. In 1969, Commodore began manufacturing its electronic calculators. Commodore soon had a profitable calculator line and was one of the more popular brands in the early 1970s, producing both consumer and scientific/programmable calculators. However, in 1975, Texas Instruments, the leading supplier of calculator parts, entered the market directly and put out a line of machines priced at less than Commodore's cost for the parts. Commodore obtained an infusion of cash from Gould, which Tramiel used beginning in 1976 to purchase several second-source chip suppliers, including MOS Technology, Inc., to assure his supply. He agreed to buy MOS, which was having troubles of its own, on the condition that its chip designer Chuck Peddle join Commodore directly as head of engineering.\nIn 1976, Commodore Business Machines (Canada) Ltd. was dissolved and replaced by the newly formed Bahamanian corporation Commodore International, which became the new parent of the Commodore group of companies.\nEntry into the computer market and success (1977\u20131984).\nChuck Peddle convinced Jack Tramiel that calculators were a dead end business and that they should turn their attention to home computers. Peddle packaged his single-board computer design in a metal case, initially with a keyboard using calculator keys, later with a full-travel QWERTY keyboard, monochrome monitor, and tape recorder for program and data storage, to produce the Commodore PET (Personal Electronic Transactor). From PET's 1977 debut, Commodore was primarily a computer company.\nCommodore had been reorganized the year before into Commodore International, Ltd., moving its financial headquarters to the Bahamas and its operational base to West Chester, Pennsylvania, near the MOS Technology site. The operational headquarters, where research and development of new products occurred, retained the name Commodore Business Machines, Inc. In 1980, Commodore launched production for the European market in Braunschweig, Germany. This site once employed up to 2000 employees, and in February 2017 an exhibition room for about 200 Commodore products was opened here to commemorate its past. \nBy 1980, Commodore was one of the three largest microcomputer companies and the largest in the Common Market. The company had lost its early domestic-market sales leadership, however by mid-1981 its US market share was less than 5% and US computer magazines rarely discussed Commodore products. \"BYTE\" stated \"the lack of a marketing strategy by Commodore, as well as its past nonchalant attitude toward the encouragement and development of good software, has hurt its credibility, especially in comparison to the other systems on the market\". Writing for \"Programming the PET/CBM\", Raeto Collin West wrote \"CBM's product manuals are widely recognized to be unhelpful; this is one of the reasons for the existence of this book.\"\nCommodore re-emphasized the US market with the VIC-20. The PET computer line was used primarily in schools, where its tough all-metal construction and ability to share printers and disk drives on a simple local area network were advantages, but PETs did not compete well in the home setting where graphics and sound were important. This was addressed with the VIC-20 in 1981, which was introduced at a cost of (equivalent to $ in ) and sold in retail stores. Commodore bought aggressive advertisements featuring William Shatner asking consumers, \"Why buy just a video game?\" The strategy worked, and the VIC-20 became the first computer to ship more than one million units, with 2.5 million units sold over the machine's lifetime, which helped Commodore's sales in Canadian schools. In promotions aimed at schools and to reduce unsold inventory, PET models labeled 'Teacher's PET' were given away as part of a \"buy 2 get 1 free\" promotion. As of calendar year 1980, Commodore sales were $40 million, behind Apple Computer and Tandy Corporation in the market.\nIn 1982, Commodore introduced the Commodore 64 (C64) as the successor to the VIC-20. Due to its chips designed by MOS Technology, the C64 possessed advanced sound and graphics for its time, and is often credited with starting the computer demo scene. Its (equivalent to $ in ) price was high compared to that of the VIC-20 but was much less expensive than any other 64K computer. Early C64 advertisements boasted that \"You can't buy a better computer at twice the price\", with Australian adverts in the mid-1980s using the slogan \"Are you keeping up with the Commodore? Because the Commodore is keeping up with you.\"\nIn 1983, Tramiel decided to focus on market share and cut the price of the VIC-20 and C64 dramatically, starting the home computer war. TI responded by cutting prices on its 1981 TI-99/4A, leading to a price war involving most vendors other than Apple Computer, including Commodore, TI and Atari. Commodore began selling the VIC-20 and C64 through mass-market retailers such as K-Mart, in addition to traditional computer stores. By the end of this conflict, Commodore had shipped around 22 million C64s, making the C64 the best-selling computer, until the Raspberry Pi overtook it in 2019.\nAt the June 1983 Consumer Electronics Show, Commodore lowered the retail price of the C64 to , and stores sold it for as little as . At one point, the company was selling as many computers as the rest of the industry combined. Prices for the VIC-20 and C64 were $50 lower than Atari's prices for the 600XL and 800XL. Commodore's strategy was to, according to a spokesman, devote 50% of its efforts to the under- market, 30% on the market, and 20% on the over- market. Its vertical integration and Tramiel's focus on cost control helped Commodore do well during the price war, with in 1983 sales. Although the company and Tramiel's focus on cost cutting over product testing caused hardware defects in the initial C64, some resolved in later iterations. By early 1984, Synapse Software, the largest provider of third-party Atari 8-bit software, received 65% of sales from the Commodore market, and Commodore sold almost three times as many computers as Atari that year.\nDespite its focus on the lower end of the market, Commodore's computers were also sold in upmarket department stores such as Harrods. The company also attracted several high-profile customers. In 1984, the company's British branch became the first manufacturer to receive a royal warrant for computer business systems. NASA's Kennedy Space Center was another noted customer, with over 60 Commodore systems processing documentation, tracking equipment and employees, costing jobs, and ensuring the safety of hazardous waste.\nDeparture of Tramiel, acquisition of Amiga and competition with Atari (1984\u20131987).\nBy early 1984, Commodore was the most successful home computer company, with more than (equivalent to $ in ) in annual revenue and (equivalent to $ in ) in net income, whilst competitors had large losses. The company's revenue of $425 million in the fourth calendar quarter of 1983 more than doubled its revenue of a year earlier. Although \"Creative Computing\" compared the company to \"a well-armed battleship [which] rules the micro waves\" and threatened to destroy rivals like Atari and Coleco, Commodore's board of directors, affected by the price spiral, decided to exit the company. In January 1984, an internal power struggle resulted after Tramiel resigned due to disagreements with the board chairman, Irving Gould. Gould replaced Tramiel with Marshall F. Smith, a steel executive without a computer or consumer marketing experience. Tramiel's departure at the moment of Commodore's greatest financial success surprised the industry.\nIn May 1984, Tramiel founded a new company, Tramel Technology, and hired several Commodore engineers to begin work on a next-generation computer design. That same year, Tramiel discovered Warner Communications wanted to sell Atari, which was rumored to be losing about a day. Interested in Atari's overseas manufacturing and worldwide distribution network for a new computer, he approached Atari and entered negotiations. After several talks with Atari in May and June 1984, Tramiel had secured funding and bought Atari's Consumer Division (which included the console and home computer departments) in July. In July 1984 Tramiel bought the consumer side of Atari Inc. from Warner Communications and released the Atari ST earlier in 1985 for about . As more executives and researchers left Commodore after the announcement to join Tramiel's new company Atari Corp., Commodore followed by filing lawsuits against four former engineers for theft of trade secrets in late July. This was intended, in effect, to bar Tramiel from releasing his new computer. One of Tramiel's first acts after forming Atari Corp. was to fire most of Atari's remaining staff and to cancel almost all ongoing projects to review their continued viability. In late July to early August, Tramiel representatives discovered the original Amiga contract from the previous fall. Seeing a chance to gain some leverage, Tramiel immediately used the agreement to counter-sue Commodore on August 13.\nThe remaining Commodore management sought to salvage the company's fortunes and plan for the future, and did so by buying a small startup company called Amiga Corporation in August 1984 for ( in cash and $550,000 in common shares). Amiga became a subsidiary of Commodore, called Commodore-Amiga, Inc. During development in 1981, Amiga had exhausted venture capital and needed more financing. Jay Miner and his company had approached their former employer, the Warner-owned Atari, who paid Amiga to continue development work. In return, Atari received the exclusive use of the design as a video game console for one year, after which Atari would have the right to add a keyboard and market it as a complete Amiga computer. The Atari-Amiga contract and engineering logs identify the Atari-Amiga product was designated as the 1850XLD. As Atari was heavily involved with Disney at the time, it was later code-named \"Mickey\", and the 256K memory expansion board was codenamed \"Minnie\".\nStill suffering serious financial problems, Amiga sought more monetary support from investors that entire spring. At around the same time that Tramiel was negotiating with Atari, Amiga entered into discussions with Commodore. The discussions ultimately led to Commodore's intentions to purchase Amiga outright, which Commodore viewed would cancel any outstanding contracts including Atari Inc.'s. Tramiel counter-sued on the basis of this interpretation, and sought damages and an injunction to bar Amiga and effectively Commodore from producing any resembling technology, to render Commodore's new acquisition and the source for its next generation of computers useless. The resulting court case lasted several years.\nCommodore introduced a new 32-bit computer design to market in the fall of 1985 named the Amiga 1000 for , first demonstrated at the CES in 1984. An Atari-Commodore rivalry continued throughout the life of the ST and Amiga platforms. While the rivalry was a holdover from the competition between the C64 and Atari 800, the events leading to the launch of the ST and Amiga served to further alienate fans of each computer, who disagreed as to which platform was superior. This was reflected in sales numbers for the two platforms until the release of the Amiga 500 in 1987, which led the Amiga sales to exceed the ST by about 1.5 to 1, despite reaching the market later. However, neither platform captured a significant share of the world computer market, with only the Apple Macintosh surviving the industry-wide shift to Intel-based x86 computers using Microsoft Windows.\nCommodore and Atari both sought to compete in the workstation market, with Commodore announcing in 1988 a Transputer-driven system based on the Amiga 2000 in response to the Atari Transputer Workstation. Similarly, a Unix workstation based on the Amiga 2000, featuring the 68020 CPU, was detailed as Atari announced developer shipments of its own 68030-based Unix workstation within a claimed \"to or three months\". Atari's workstation, the TT030, eventually arrived in 1990 without a version of Unix available, this only eventually becoming available to developers in late 1991. Commodore's workstation arrived in 1990 in the form of the Amiga 3000UX.\nDecline and later years (1987\u20131994).\nCommodore suffered a poor reputation with its dealers and customers, and upon the 1987 introduction of the Amiga 2000, Commodore retreated from its earlier strategy of selling its computers to discount outlets and toy stores and favored authorized dealers. Adam Osborne stated in April 1981 that \"the microcomputer industry abounds with horror stories describing the way Commodore treats its dealers and its customers.\" Commodore under Tramiel had a reputation for cannibalizing its own products with newer ones; Doug Carlston and others in the industry believed rumors in late 1983 that Commodore would discontinue the C64 despite its success because they disliked the company's business practices, including its poor treatment of dealers and introducing new computers incompatible with existing ones. A Boston reseller said, \"It's too unsettling to be one of their dealers and not know where you stand with them.\" After Tramiel's departure, another journalist wrote that he \"had never been able to establish excellent relations with computer dealers ... computer retailers have accused Commodore of treating them as harshly as if they were suppliers or competitors, and as a result, many have become disenchanted with Commodore and dropped the product line\". Software developers also disliked the company, with one stating that \"Dealing with Commodore was like dealing with Attila the Hun.\" At the 1987 Comdex, an informal \"InfoWorld\" survey found that none of the developers present planned to write for Commodore platforms. Commodore's software had a poor reputation; \"InfoWorld\" in 1984, for example, stated that \"so far, the normal standard for Commodore software is mediocrity\".\nTramiel's successor, Marshall F. Smith, left the company in 1986, as did his successor Thomas Rattigan in 1987 after a failed boardroom coup. The head of Blue Chip Electronics, a former Commodore employee, described the company as \"a well-known revolving door\". Commodore faced the problem when marketing the Amiga of still being seen as the company that made cheap computers like the C64 and VIC. The C64 remained the company's cash cow but its technology was aging. By the late 1980s, the personal computer market had become dominated by the IBM PC and Apple Macintosh platforms. Commodore's marketing efforts for the Amiga were less successful in breaking the new computer into an established market compared to the success of its 8-bit line. The company put effort into developing and promoting consumer products that would not be in demand for years, such as an Amiga 500-based HTPC called CDTV.\nAs early as 1986, the mainstream press was predicting Commodore's demise, and in 1990 \"Computer Gaming World\" wrote of its \"abysmal record of customer and technical support in the past\". Nevertheless, as profits and the stock price began to slide, \"The Philadelphia Inquirer's\" Top 100 Businesses Annual continued to list several Commodore executives among the highest-paid in the region and the paper documented the company's questionable hiring practices and large bonuses paid to executives amid shareholder discontent.\nCommodore failed to update the Amiga to keep pace as the PC platform advanced. CBM continued selling the Amiga 2000 with 7.14\u00a0MHz 68000 CPUs, even though the Amiga 3000 with its 25\u00a0MHz 68030 was on the market. Apple, by this time, was using the 68040 and had relegated the 68000 to its lowest-end model, the black and white Macintosh Classic. The 68000 was used in the Sega Genesis, one of the leading game consoles of the era, Computers fitted with high-color VGA graphics cards and SoundBlaster (or compatible) sound cards had also caught up with the Amiga's performance, and Commodore began to fade from the consumer market.\nAlthough the Amiga was originally conceived as a gaming machine, Commodore had always emphasized the Amiga's potential for professional applications, but the Amiga's high-performance sound and graphics were irrelevant to MS-DOS-based routine business word-processing and data-processing requirements, and the machine could not successfully compete with computers in a business market that was rapidly undergoing commoditization. Commodore introduced a range of PC compatible systems designed by its German division, and while the Commodore name was better known in the US than some of its competition, the systems' price and specifications were only average.\nSales of the PC range were strong in Germany, however, seeing Commodore acquire a 28% share of this market segment in 1990, second only to IBM. Things were less rosy in the United States, where Commodore had a 6% share in the market segment as of 1989, down from 26% in 1984. \"Forbes\"'s Evan McGlinn wrote regarding the firm's decline, citing management as the source cause: \"the absentee-landlord management style of globe-trotting chairman and chief executive Irving Gould.\" With the Amiga only representing less that 20% of the company's sales in the 1987 fiscal year, product lines such as PC-compatibles and Commodore's 8-bit computers remained important to the company's finances even as the Amiga's share of total sales increased. In 1989, with the Amiga accounting for 45% of total sales, the PC business showed modest growth to 24% of total sales, and the Commodore 64 and 128 products still generated 31% of the company's revenues.\nCommodore attempted to develop new chipsets during the early 1990s, first the Advanced Amiga Architecture and later the Hombre. Funding problems meant that they did not materialize as ultimately the company would go bust. In 1992, the Amiga 600 replaced the Amiga 500, which removed the numeric keypad, Zorro expansion slot, and other functionality, but added IDE, PCMCIA, and intended as a cost-reduced design. Designed as the Amiga 300, a non-expandable model to sell for less than the Amiga 500, the 600 became a replacement for the 500 due to the unexpectedly higher cost of manufacture. Productivity developers increasingly moved to PC and Macintosh, while the console wars took over the gaming market. David Pleasance, managing director of Commodore UK, described the Amiga 600 as a \"complete and utter screw-up\". In the same year, Commodore released the Amiga 1200 and Amiga 4000 computers, which featured an improved graphics chipset, the AGA. The advent of PC games using 3D graphics such as \"Doom\" and \"Wolfenstein 3D\" spelled the end of Amiga as a gaming platform.\nIn 1993, Commodore launched a 32-bit CD-ROM-based game console called the Amiga CD32, described as a 'make or break' system, according to Pleasance. The Amiga CD32 was not sufficiently profitable to return Commodore to solvency, however this was not a universal opinion at Commodore, with Commodore Germany hardware expert Rainer Benda stating \"The CD32 was a year late for Commodore. In other words, here, too, it might have been better to focus on the core business than jump on a console and hope to sell 300,000 or more units quickly to avoid bankruptcy.\"\nIn 1992, all UK servicing and warranty repairs were outsourced to Wang Laboratories, which was replaced by ICL after failing to meet repair demand during the Christmas rush in 1992. Commodore International's Canadian subsidiary authorized 3D Microcomputers of Ontario to manufacture IBM PC clones with the Commodore brand in late 1993. Commodore exited the IBM PC clone market entirely during the 1993 fiscal year, citing the low profitability of this market. PC sales had remained relatively stable and, accounting for 37% of revenue from sales in 1993, had grown modestly as declines in both unit sales and revenues were recorded for the Amiga and Commodore 64 product lines.\nBy 1994, only Commodore's operations in Canada, Germany, and the United Kingdom were still profitable. Commodore announced voluntary bankruptcy and liquidation on April 29, 1994, causing the board of directors to \"authorize the transfer of its assets to trustees for the benefit of its creditors\", according to an official statement. With Commodore International having reported a quarterly loss in the US, hopes were expressed that European divisions might be able to continue trading and even survive the demise of the parent company, with a management buyout considered a possibility. Other possibilities included the sale of profitable parts of the company to other parties, with Philips and Samsung considered \"likely choices\". However, no sale was ever completed.\nAfter Commodore (1994\u2013present).\nSale to Escom and bankruptcy.\nCommodore's former assets went separate ways following liquidation, with none of the descendant companies repeating Commodore's early success. Subsidiaries Commodore UK and Commodore B.V. (Netherlands) survived bankruptcy. The UK division filed a buyout proposal to the Supreme Court in the Bahamas and was considered the front runner in the bid due to press exposure at the time; the other initial bidders were Samsung, Philips and Amstrad in mid-1994. Commodore UK and Commodore BV stayed in business by selling old inventory and making computer speakers and other types of computer peripherals, however Commodore BV dissolved in early 1995. Commodore UK withdrew its bid at the start of the auction process after several larger companies, including Gateway Computers and Dell Inc., became interested, primarily for Commodore's patents relating to the Amiga. The only companies who entered bids at the end were Dell and Escom; the successful bidder was German PC maker Escom AG on April 22, 1995, beating Dell's bid by $6.6 million. Escom paid US$14 million for the assets of Commodore International. Commodore UK went into liquidation on August 30, 1995. \nEscom separated the Commodore and Amiga operations into separate divisions, the latter becoming Amiga Technologies GmbH, and quickly started using the Commodore brand name on a line of PCs sold in Europe while concepting and developing new Amiga computers. They also debuted a brand new logo for Amiga. However, it soon started losing money due to over-expansion, declared bankruptcy on July 15, 1996, and was liquidated. Escom's Dutch arm, Escom B.V., survived bankruptcy and went on to purchase the Commodore brand from its bankrupt parent. The company then renamed itself to Commodore B.V. Meanwhile, a deal for Chicago-based VisCorp to purchase Amiga Technologies GmbH fell through, and instead it was acquired by Gateway 2000 in March 1997, taking both the Amiga properties and the Commodore patents.\nBrand name.\nIn September 1997, Dutch computer maker Tulip Computers acquired the Commodore brand name from Commodore B.V. and made a number of Wintel computers under subsidiary Commodore International B.V., although it did not find much success. In July 2004, Tulip announced a new series of products using the Commodore name: fPET, a flash memory-based USB flash drive; mPET, a flash-based MP3 Player and digital recorder; eVIC, a 20 GB music player. Tulip also licensed the Commodore trademark and logo to the producers of the C64 DTV, a single-chip implementation of the Commodore 64 computer with 30 built-in games.\nIn late 2004, Tulip sold Commodore International B.V. to Yeahronimo Media Ventures (YMV), a digital music software startup providing legal music downloads in the Netherlands, for \u20ac22 million, to be paid in instalments over several years until 2010. The sale was completed in March 2005 after months of negotiations; YMV would not become the sole owner until 2010 after buying the remaining shares from Tulip (by then renamed to Nedfield Holding B.V.) which had gone bankrupt. YMV soon renamed itself to Commodore International Corporation (CIC) \u2014 its operational office was in the Netherlands but had headquarters in California \u2014 and started an operation intended to relaunch the Commodore brand in the video gaming field. The company then launched its Gravel line of products: Gravel in Pocket personal multimedia players equipped with Wi-Fi and the Gravel in Home, hoping the Commodore brand would help them take off, introduced at CeBIT 2007 with a media \"entertainment platform\" called CommodoreWorld, and also launched gaming PCs running Windows Vista 64-bit. However the company did not find success with these products. On June 24, 2009, CIC in the United States renamed itself to Reunite Investments, Inc., with the Commodore brand retaining under ownership by its subsidiary CIC Europe Holding B.V. (which would later be renamed into C= Holdings B.V.), trading as Commodore Consumer Electronics (CCE).\nCIC's founder, Ben van Wijhe, bought a Hong Kong-based company called Asiarim. Reunite Investments then sold the brand to Commodore Licensing B.V., a subsidiary of Asiarim, later in 2010. It was sold again on November 7, 2011. This transaction became the basis of a legal dispute between Asiarim \u2014 which, even after that date, made commercial use of the Commodore trademark, among others by advertising for sale Commodore-branded computers, and dealing licensing agreements for the trademarks \u2014 and the new owners, that was resolved by the United States District Court for the Southern District of New York on December 16, 2013, in favor of the new owners. Since then the company holding the brand name turned into Polabe Holding N.V., then Net B.V., and is currently named Commodore Corporation B.V.\nCopyrights and patents.\nOwnership of the remaining assets of Commodore International, including the copyrights and patents, and the Amiga trademarks, passed from bankrupt Escom to Gateway 2000 in 1997. Jim Collas became director of Amiga Technologies and he assembled a new team to work on a new generation of Amiga computers and other products on a new platform, prototyping one called the Amiga MCC and planning a potential tablet computer. However when Jeffrey Weitzen was chosen to become CEO of Gateway, who was not convinced of Collas's plans, he informed that Amiga Technologies division will be sold. On the final day of 1999, Gateway sold the copyrights and trademarks of Amiga to Amino, a Washington-based company founded, among others, by former Gateway subcontractors Bill McEwen and Fleecy Moss; Amino immediately renamed itself to Amiga, Inc. Gateway retained the patents but gave a license to Amiga, Inc. to use the patents. Gateway itself was acquired by Taiwanese Acer in 2007.\nOn March 15, 2004, Amiga, Inc. announced that on April 23, 2003, it had transferred its rights over past and future versions of the AmigaOS (but not yet over other intellectual property) to Itec, LLC, later acquired by KMOS, Inc., a Delaware-based company. Shortly afterwards, based on loans and security agreements between Amiga, Inc. and Itec, LLC, the remaining intellectual property assets were transferred from Amiga, Inc. to KMOS, Inc. On March 16, 2005, KMOS, Inc. announced that it had completed all registrations with the State of Delaware to change its corporate name to Amiga, Inc. The Commodore/Amiga copyrights, including all their works up to 1993, were later sold to Cloanto in 2015. A number of legal challenges and lawsuits have involved these companies and Hyperion Entertainment, the Belgian software company that continues development of AmigaOS.\nSemiconductor subsidiary.\nThe Commodore Semiconductor Group (formerly MOS Technology, Inc.), the silicon wafer foundry and integrated circuit manufacturing unit of Commodore International, was bought by its former management in January 1995 and resumed operations under the name GMT Microelectronics, utilizing a troubled facility in Norristown, Pennsylvania that Commodore had closed in 1992. In 2001, the United States Environmental Protection Agency shut the plant down, and GMT ceased operations and was liquidated.\nCurrent and recent developments.\nAmigaOS (as well as spin-offs MorphOS and AROS) is still maintained and updated by Hyperion Entertainment. Enthusiasts continue to make software and games for both AmigaOS and the Commodore 64 computer.\nThe brand was acquired under license in 2010 by two young entrepreneurs to become Commodore USA in Florida, until 2013. On December 26, 2014, two Italian entrepreneurs licensed the brand and founded Commodore Business Machines Ltd. in London, to manufacture smartphones. \nProduct line.\nThe product line consists of original Commodore products.\nCalculators.\n774D, 776M, 796M, 9R23, C108, C110, F4146R, F4902, MM3, Minuteman 6, P50, PR100, SR1800, SR4120D, SR4120R, SR4148D, SR4148R, SR4190R, SR4212, SR4912, SR4921RPN, SR5120D, SR5120R, SR5148D, SR5148R, SR5190R, SR59, SR7919, SR7949, SR9150R, SR9190R, US*3, US*8 and The Specialist series: M55 (The Mathematician), N60 (The Navigator), S61 (The Statistician).\n6502-based computers.\n\"(listed chronologically)\"\nMonitors.\n1000, 1024, 1070, 1080, 1081, 1083S, 1084, 1084S, 1084ST, 1085S, 1201, 1402, 1403, 1404, 1405, 1407, 1428, 1428x, 1432D, 1432V, 1701, 1702, 1703, 1801, 1802, 1803, 1900M/DM602, 1901/75BM13/M1, 1902, 1902A, 1930, 1930-II, 1930-III, 1934, 1935, 1936, 1936ALR, 1940, 1942, 1950, 1960, 1962, 2002, A2024, 2080, 76M13, CM-141, DM-14, DM602\nPrinters.\nVIC 1520 plotter.\nThe VIC 1520 plotter used the ALPS mechanicals and four-color rotary pen setup that scrolled a 4\u00bc\" roll of paper. The ALPS mechanism was shared with several other 8 bit computers of the era, including Tandy, Atari, and Apple."}
{"id": "7581", "revid": "7061136", "url": "https://en.wikipedia.org/wiki?curid=7581", "title": "Commodore (rank)", "text": "Commodore is a senior naval rank used in many navies which is equivalent to brigadier or brigadier general and air commodore. It is superior to a navy captain, but below a rear admiral. It is either regarded as the most junior of the flag officers rank or may not hold the jurisdiction of a flag officer at all depending on the officer's appointment. Non-English-speaking nations commonly use the rank of flotilla admiral, counter admiral, or senior captain as an equivalent, although counter admiral may also correspond to \"rear admiral lower half\" abbreviated as RDML.\nTraditionally, \"commodore\" is the title for any officer assigned to command more than one ship, even temporarily, much as \"captain\" is the traditional title for the commanding officer of a single ship even if the officer's official title in the service is a lower rank. As an official rank, a commodore typically commands a flotilla or squadron of ships as part of a larger task force or naval fleet commanded by an admiral. A commodore's ship is typically designated by the flying of a broad pennant, as compared to an admiral's flag.\n\"Commodore\" is typically regarded as a one-star rank with a NATO code of OF-6, known in the U.S. as \"rear admiral (lower half)\", but whether it is regarded as a flag rank varies among countries.\nIt is sometimes abbreviated as \"Cdre\" in British Royal Navy, \"CDRE\" in the US Navy, \"Cmdre\" in the Royal Canadian Navy, \"COMO\" in the Spanish Navy and in some navies speaking the Spanish language, or \"CMDE\" as used in the Indian Navy and in navies of several other countries.\nEtymology.\nThe rank of commodore derives from the French \"commandeur\", which was the second highest rank in the orders of knighthood, and in military orders the title of the knight in charge of a commandery.\nHistory.\nThe Dutch Navy also used the rank of \"commandeur\" from the end of the 16th century for a variety of temporary positions, until it became a conventional permanent rank in 1955. The Royal Netherlands Air Force has adopted the English spelling of \"commodore\" for an equivalent rank.\nIn the Royal Navy, the position was introduced in the 17th century to combat the cost of appointing more admirals\u2014a costly business with a fleet as large as the Royal Navy's at that time.\nThe rank of commodore was at first a position created as a temporary title to be bestowed upon captains who commanded squadrons of more than one vessel. In many navies, the rank of commodore was merely viewed as a senior captain position, whereas other naval services bestowed upon the rank of commodore the prestige of flag officer status.\nUnited States.\nIn 1899, the substantive rank of commodore was discontinued in the United States Navy, but revived during World War II in both the United States Navy and United States Coast Guard. It was discontinued as a rank in these services during the postwar period, but as an appointment, the title \"commodore\" was then used to identify senior U.S. Navy captains who commanded squadrons of more than one vessel or functional air wings or air groups that were not part of a carrier air wing or carrier air group. Concurrently, until the early 1980s, U.S. Navy and U.S. Coast Guard captains selected for promotion to the rank of rear admiral (lower half), would wear the same insignia as rear admiral (upper half), i.e., two silver stars for collar insignia or sleeve braid of one wide and one narrow gold stripe, even though they were actually only equivalent to one-star officers and paid at the one-star rate.\nTo correct this inequity, the rank of commodore as a single-star flag officer was reinstated by both services in the early 1980s. This immediately caused confusion with those senior U.S. Navy captains commanding destroyer squadrons, submarine squadrons, functional air wings and air groups, and so on, who held the temporary \"title\" of commodore while in their major command billet. As a result of this confusion, the services soon renamed the new one-star rank commodore admiral (CADM) within the first six months following the rank's reintroduction. However, this was considered an awkward title and the one-star flag rank was renamed a few months later, giving it its current title of rear admiral (lower half), later abbreviated by the U.S. Navy and U.S. Coast Guard as RDML. The United States Public Health Service Commissioned Corps, and NOAA Commissioned Corps, whose rank structures follow the naval pattern, also use this title and abbreviation.\nThe \"title\" of commodore continues to be used in the U.S. Navy and U.S. Coast Guard for those senior captains in command of organizations consisting of groups of ships or submarines organized into squadrons; air wings or air groups of multiple aviation squadrons other than carrier air wings (the latter whose commanders still use the title \"CAG\"); explosive ordnance disposal (EOD), mine warfare and special warfare (SEAL) groups; Mobile Inshore Underwater Warfare (MIUW) groups; and construction (SeaBee) regiments. Although not flag officers, modern day commodores in the U.S. Navy rate a blue and white command pennant, also known as a broad pennant, that is normally flown at their headquarters facilities ashore or from ships that they are embarked aboard when they are the Senior Officer Present Afloat (SOPA).\nArgentina.\nIn the Argentine Navy, the position of commodore was created in the late 1990s, and is usually, but not always, issued to senior captains holding rear-admirals' positions. It is not a rank but a distinction and, as such, can be issued by the chief of staff without congressional approval. Its equivalents are colonel-major in the Army and commodore-major in the Air Force. It is usually\u2014but incorrectly\u2014referred to as \"navy commodore\", to avoid confusion with the \"air force commodore\", which is equivalent to the navy's captain and army's colonel. The sleeve lace is identical to that of the Royal Navy, and wears one star on the epaulette.\nAir force ranks.\nCommodore, in Spanish \"comodoro\", is a rank in the Argentine Air Force. This rank is the equivalent of a colonel in the Argentine Army, and a colonel or group captain in other air forces of the world. The Argentine rank below commodore is the rank of vice-commodore (Spanish \"vicecomodoro\") equivalent to a lieutenant-colonel in the Argentine Army, and a lieutenant-colonel or wing commander in other air forces.\nCommodore is a rank in the Royal Netherlands Air Force. It is a one-star rank and has essentially the same rank insignia as the British air commodore.\nMany air forces use the rank of air commodore. This rank was first used by the Royal Air Force and is now used in many countries such as Australia, Bangladesh, Greece, India, New Zealand, Nigeria, Pakistan, Thailand and Zimbabwe. It is the equivalent rank to the navy rank of \"commodore\", and the army ranks of brigadier and brigadier general.\nThe German air force used the concept of a unit commodore for the commander of a wing, usually in the rank of colonel (OF-5).\nMerchant Service (Merchant Marine) rank and Yacht Club chief directors.\nCommodore is also a title held by many captains as recognition of exceptional navigation ability and seagoing seniority in the Merchant Service, and by the directors of a few yacht clubs and boating associations. Commodores 'in command' as Master aboard Merchant Marine ships wear distinctive rank and cap insignia denoting their honorific high rank position. In a few country the honorific high position of commodore it is indicated with the high rank denomination of senior captain. Traditionally, commodore is the title of the president of a yacht club.\nConvoy commodore.\nDuring wartime, a shipping convoy will have a ranking officer\u2014sometimes an active-duty naval officer, at other times a civilian master or retired naval officer\u2014designated as the \"convoy commodore\". This title is not related to the individuals military rank (if any), but instead is the title of the senior individual responsible for the overall operation of the merchant ships and naval auxiliary ships that make up the convoy. The convoy commodore does not command the convoy escort forces (if any), which are commanded by a naval officer who serves as escort commander.\nCivilian use.\nCommodore in Yachting Leadership.\nCivilian yacht clubs, yachting associations and fellowships with formal hierarchical structures, began to use the title \"commodore\" in countries around the world for their presidents in the early twentieth century along with \"vice commodore\" in the same manner as \"vice president,\"and \"rear-commodore\" and \"port captain' or \"international bridge member\" in the same manner as board members.\nCommodores, vice-commodores and rear-commodores are also known as civilian flag officers because they have an epaulettes, regalia and maritime flags with designated symbols and number of stars for their ranks. Many of the clubs that are more than a century old, such as the Los Angeles Yacht Club have formal ceremonies, where commodores from more than 100 surrounding yacht clubs, flag officers of the US Navy and Coast Guard attend a ceremony at the beginning of the year. The ceremony includes a bagpipe entrance, a presentation of the country flag by commissioned officers of the country's navy and a cannon shot upon the raising of each individual officer's flags on a flag staff, (also known as flagpoles) for each flag officer (commodore, vice commodore, rear commodore) as their term of office officially begins. Sometimes a trumpet fanfare is also include for special occasions like ribbon cutting in 2019 for the 50th Transpacific Yacht Race. Salutes are given to commodores for special ceremonies, including opening days of the racing season.\nOther uses.\nThe U.S. Coast Guard Auxiliary also employs variants of the \"title\" of commodore. Members of the Auxiliary serve in the Coast Guard's uniformed auxiliary service and they do not have military rank, but who do wear modified U.S. Coast Guard uniforms and U.S. military-style officer rank insignia to indicate office. Auxiliary members who have been elected or appointed to positions in the highest levels of the organization, similar in nature to active and reserve rear admirals and vice admirals use the term commodore (e.g., district commodore, assistant national commodore, deputy national commodore, national commodore, etc.). These Coast Guard auxiliarists may permanently append the title commodore, sometimes abbreviated COMO, to their names (e.g., Commodore James A. Smith, National Commodore; or COMO Jim Smith, (NACO)).\nIn the Philippine Coast Guard Auxiliary\u2014PCGA\u2014each of the directors in command of the ten Coast Guard Auxiliary districts are commodores, as well as most of the Deputy National Directors (some may be rear admirals). Commodore is abbreviated to COMMO in the PCGA.\nVanderbilt University's intercollegiate athletics teams are nicknamed the \"Commodores\", a reference to Cornelius Vanderbilt's self-appointed title (he was the master of a large shipping fleet).\nIn the U.S. Sea Scouting program (which is part of the Boy Scouts of America), all National, Regional, Area, and Council committee chairs are titled as commodore, while senior committee members are addressed as vice commodore. Ship committee chairs do not hold this recognition."}
{"id": "7582", "revid": "698909", "url": "https://en.wikipedia.org/wiki?curid=7582", "title": "Chlorinated fluorocarbons", "text": ""}
{"id": "7583", "revid": "32173325", "url": "https://en.wikipedia.org/wiki?curid=7583", "title": "Cauchy\u2013Riemann equations", "text": "In the field of complex analysis in mathematics, the Cauchy\u2013Riemann equations, named after Augustin Cauchy and Bernhard Riemann, consist of a system of two partial differential equations which form a necessary and sufficient condition for a complex function of a complex variable to be complex differentiable. \nThese equations are \nand\nwhere and are real differentiable bivariate functions.\nTypically, and are respectively the real and imaginary parts of a complex-valued function of a single complex variable where and are real variables; and are real differentiable functions of the real variables. Then is complex differentiable at a complex point if and only if the partial derivatives of and satisfy the Cauchy\u2013Riemann equations at that point.\nA holomorphic function is a complex function that is differentiable at every point of some open subset of the complex plane formula_1. It has been proved that holomorphic functions are analytic and analytic complex functions are complex-differentiable. In particular, holomorphic functions are infinitely complex-differentiable.\nThis equivalence between differentiability and analyticity is the starting point of all complex analysis.\nHistory.\nThe Cauchy\u2013Riemann equations first appeared in the work of Jean le Rond d'Alembert. Later, Leonhard Euler connected this system to the analytic functions. Cauchy then used these equations to construct his theory of functions. Riemann's dissertation on the theory of functions appeared in 1851.\nSimple example.\nSuppose that formula_2. The complex-valued function formula_3 is differentiable at any point in the complex plane. \nformula_4\nThe real part formula_5 and the imaginary part formula_6 are\nformula_7\nand their partial derivatives are\nformula_8\nWe see that indeed the Cauchy\u2013Riemann equations are satisfied, formula_9 and formula_10.\nInterpretation and reformulation.\nThe Cauchy-Riemann equations are one way of looking at the condition for a function to be differentiable in the sense of complex analysis: in other words, they encapsulate the notion of function of a complex variable by means of conventional differential calculus. In the theory there are several other major ways of looking at this notion, and the translation of the condition into other language is often needed.\nConformal mappings.\nFirst, the Cauchy\u2013Riemann equations may be written in complex form\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is of the form\nformula_11\nwhere formula_12 and formula_13. A matrix of this form is the matrix representation of a complex number. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a function takes infinitesimal line segments at the intersection of two curves in and rotates them to the corresponding segments in . Consequently, a function satisfying the Cauchy\u2013Riemann equations, with a nonzero derivative, preserves the angle between curves in the plane. That is, the Cauchy\u2013Riemann equations are the conditions for a function to be conformal.\nMoreover, because the composition of a conformal transformation with another conformal transformation is also conformal, the composition of a solution of the Cauchy\u2013Riemann equations with a conformal map must itself solve the Cauchy\u2013Riemann equations. Thus the Cauchy\u2013Riemann equations are conformally invariant.\nComplex differentiability.\nLet\nformula_14\nwhere formula_15 and formula_16 are real-valued functions, be a complex-valued function of a complex variable formula_17 where formula_18 and formula_19 are real variables. formula_20 so the function can also be regarded as a function of real variables formula_21 and formula_19. Then, the \"complex-derivative\" of formula_23 at a point formula_24 is defined by\nformula_25\nprovided this limit exists (that is, the limit exists along every path approaching formula_26, and does not depend on the chosen path).\nA fundamental result of complex analysis is that formula_27 is complex differentiable at formula_28 (that is, it has a complex-derivative), if and only if the bivariate real functions formula_29 and formula_30 are differentiable at formula_31 and satisfy the Cauchy\u2013Riemann equations at this point.\nIn fact, if the complex derivative exists at formula_32, then it may be computed by taking the limit at formula_32 along the real axis and the imaginary axis, and the two limits must be equal. Along the real axis, the limit is \nformula_34\nand along the imaginary axis, the limit is\nformula_35\nSo, the equality of the derivatives implies \nformula_36\nwhich is the complex form of Cauchy\u2013Riemann equations at formula_32.\nConversely, if is differentiable at formula_26 (in the real sense) and satisfies the Cauchy-Riemann equations there, then it is complex-differentiable at this point. Assume that as a function of two real variables and is differentiable at (real differentiable). This is equivalent to the existence of the following linear approximation formula_47where formula_48, formula_49, , and formula_50 as . \nSince formula_51 and formula_52, the above can be re-written as\nformula_53formula_54 \nNow, if formula_55 is real, formula_56, while if it is imaginary, then formula_57. Therefore, the second term is independent of the path of the limit formula_58 when (and only when) it vanishes identically: formula_59, which is precisely the Cauchy\u2013Riemann equations in the complex form. This proof also shows that, in that case,\nformula_60\nNote that the hypothesis of real differentiability at the point formula_28 is essential and cannot be dispensed with. For example, the function formula_62, regarded as a complex function with imaginary part identically zero, has both partial derivatives at formula_63, and it moreover satisfies the Cauchy\u2013Riemann equations at that point, but it is not differentiable in the sense of real functions (of several variables), and so the first condition, that of real differentiability, is not met. Therefore, this function is not complex differentiable.\nSome sources state a sufficient condition for the complex differentiability at a point formula_28 as, in addition to the Cauchy\u2013Riemann equations, the partial derivatives of formula_65 and formula_16 be continuous at the point because this continuity condition ensures the existence of the aforementioned linear approximation. Note that it is not a necessary condition for the complex differentiability. For example, the function formula_67 is complex differentiable at 0, but its real and imaginary parts have discontinuous partial derivatives there. Since complex differentiability is usually considered in an open set, where it in fact implies continuity of all partial derivatives (see below), this distinction is often elided in the literature.\nIndependence of the complex conjugate.\nThe above proof suggests another interpretation of the Cauchy\u2013Riemann equations. The complex conjugate of formula_68, denoted formula_69, is defined by\nformula_70\nfor real variables \"formula_71\" and formula_72. Defining the two Wirtinger derivatives asformula_73\nthe Cauchy\u2013Riemann equations can then be written as a single equation\nformula_74\nand the complex derivative of \"formula_75\" in that case is formula_76 In this form, the Cauchy\u2013Riemann equations can be interpreted as the statement that a complex function \"formula_75\" of a complex variable \"formula_78\" is independent of the variable formula_69. As such, we can view analytic functions as true functions of \"one\" complex variable (\"formula_78\") instead of complex functions of \"two\" real variables (\"formula_21\" and \"formula_82\").\nPhysical interpretation.\nA standard physical interpretation of the Cauchy\u2013Riemann equations going back to Riemann's work on function theory is that \"u\" represents a velocity potential of an incompressible steady fluid flow in the plane, and \"v\" is its stream function. Suppose that the pair of (twice continuously differentiable) functions \"u\" and \"v\" satisfies the Cauchy\u2013Riemann equations. We will take \"u\" to be a velocity potential, meaning that we imagine a flow of fluid in the plane such that the velocity vector of the fluid at each point of the plane is equal to the gradient of \"u\", defined by\nformula_83\nBy differentiating the Cauchy\u2013Riemann equations for the functions \"u\" and \"v\", with the symmetry of second derivatives, one shows that \"u\" solves Laplace's equation:\nformula_84\nThat is, \"u\" is a harmonic function. This means that the divergence of the gradient is zero, and so the fluid is incompressible.\nThe function \"v\" also satisfies the Laplace equation, by a similar analysis. Also, the Cauchy\u2013Riemann equations imply that the dot product formula_85 (formula_86), i.e., the direction of the maximum slope of \"u\" and that of \"v\" are orthogonal to each other. This implies that the gradient of \"u\" must point along the formula_87 curves; so these are the streamlines of the flow. The formula_88 curves are the equipotential curves of the flow.\nA holomorphic function can therefore be visualized by plotting the two families of level curves formula_89 and formula_90. Near points where the gradient of \"u\" (or, equivalently, \"v\") is not zero, these families form an orthogonal family of curves. At the points where formula_91, the stationary points of the flow, the equipotential curves of formula_89 intersect. The streamlines also intersect at the same point, bisecting the angles formed by the equipotential curves.\nHarmonic vector field.\nAnother interpretation of the Cauchy\u2013Riemann equations can be found in P\u00f3lya &amp; Szeg\u0151. Suppose that \"u\" and \"v\" satisfy the Cauchy\u2013Riemann equations in an open subset of R2, and consider the vector field\nformula_93\nregarded as a (real) two-component vector. Then the second Cauchy\u2013Riemann equation () asserts that formula_94 is irrotational (its curl is 0):\nformula_95\nThe first Cauchy\u2013Riemann equation () asserts that the vector field is solenoidal (or divergence-free):\nformula_96\nOwing respectively to Green's theorem and the divergence theorem, such a field is necessarily a conservative one, and it is free from sources or sinks, having net flux equal to zero through any open domain without holes. (These two observations combine as real and imaginary parts in Cauchy's integral theorem.) In fluid dynamics, such a vector field is a potential flow. In magnetostatics, such vector fields model static magnetic fields on a region of the plane containing no current. In electrostatics, they model static electric fields in a region of the plane containing no electric charge.\nThis interpretation can equivalently be restated in the language of differential forms. The pair \"u\" and \"v\" satisfy the Cauchy\u2013Riemann equations if and only if the one-form formula_97 is both closed and coclosed (a harmonic differential form).\nPreservation of complex structure.\nAnother formulation of the Cauchy\u2013Riemann equations involves the complex structure in the plane, given by\nformula_98\nThis is a complex structure in the sense that the square of \"J\" is the negative of the 2\u00d72 identity matrix: formula_99. As above, if \"u\"(\"x\",\"y\") and \"v\"(\"x\",\"y\") are two functions in the plane, put\nformula_100\nThe Jacobian matrix of \"f\" is the matrix of partial derivatives\nformula_101\nThen the pair of functions \"u\", \"v\" satisfies the Cauchy\u2013Riemann equations if and only if the 2\u00d72 matrix \"Df\" commutes with \"J\".\nThis interpretation is useful in symplectic geometry, where it is the starting point for the study of pseudoholomorphic curves.\nOther representations.\nOther representations of the Cauchy\u2013Riemann equations occasionally arise in other coordinate systems. If () and () hold for a differentiable pair of functions \"u\" and \"v\", then so do\nformula_102\nfor any coordinate system such that the pair formula_103 is orthonormal and positively oriented. As a consequence, in particular, in the system of coordinates given by the polar representation formula_104, the equations then take the form\nformula_105\nCombining these into one equation for gives\nformula_106\nThe inhomogeneous Cauchy\u2013Riemann equations consist of the two equations for a pair of unknown functions and of two real variables\nformula_107\nfor some given functions and defined in an open subset of R2. These equations are usually combined into a single equation\nformula_108\nwhere \"f\" = \"u\" + i\"v\" and \"\ud835\udf11\" = (\"\u03b1\" + i\"\u03b2\")/2.\nIf \"\ud835\udf11\" is \"C\"\"k\", then the inhomogeneous equation is explicitly solvable in any bounded domain \"D\", provided \"\ud835\udf11\" is continuous on the closure of \"D\". Indeed, by the Cauchy integral formula,\nformula_109\nfor all \"\u03b6\" \u2208 \"D\".\nGeneralizations.\nGoursat's theorem and its generalizations.\nSuppose that is a complex-valued function which is differentiable as a function formula_110. Then Goursat's theorem asserts that \"f\" is analytic in an open complex domain \u03a9 if and only if it satisfies the Cauchy\u2013Riemann equation in the domain. In particular, continuous differentiability of \"f\" need not be assumed.\nThe hypotheses of Goursat's theorem can be weakened significantly. If is continuous in an open set \u03a9 and the partial derivatives of \"f\" with respect to \"x\" and \"y\" exist in \u03a9, and satisfy the Cauchy\u2013Riemann equations throughout \u03a9, then \"f\" is holomorphic (and thus analytic). This result is the Looman\u2013Menchoff theorem.\nThe hypothesis that \"f\" obey the Cauchy\u2013Riemann equations throughout the domain \u03a9 is essential. It is possible to construct a continuous function satisfying the Cauchy\u2013Riemann equations at a point, but which is not analytic at the point (e.g., . Similarly, some additional assumption is needed besides the Cauchy\u2013Riemann equations (such as continuity), as the following example illustrates\nformula_111\nwhich satisfies the Cauchy\u2013Riemann equations everywhere, but fails to be continuous at \"z\"\u00a0=\u00a00.\nNevertheless, if a function satisfies the Cauchy\u2013Riemann equations in an open set in a weak sense, then the function is analytic. More precisely:\nThis is in fact a special case of a more general result on the regularity of solutions of hypoelliptic partial differential equations.\nSeveral variables.\nThere are Cauchy\u2013Riemann equations, appropriately generalized, in the theory of several complex variables. They form a significant overdetermined system of PDEs. This is done using a straightforward generalization of the Wirtinger derivative, where the function in question is required to have the (partial) Wirtinger derivative with respect to each complex variable vanish.\nComplex differential forms.\nAs often formulated, the \"d-bar operator\"\nformula_113\nannihilates holomorphic functions. This generalizes most directly the formulation\nformula_114\nwhere\nformula_115\nB\u00e4cklund transform.\nViewed as conjugate harmonic functions, the Cauchy\u2013Riemann equations are a simple example of a B\u00e4cklund transform. More complicated, generally non-linear B\u00e4cklund transforms, such as in the sine-Gordon equation, are of great interest in the theory of solitons and integrable systems.\nDefinition in Clifford algebra.\nIn the Clifford algebra formula_116, the complex number formula_117 is represented as formula_118 where formula_119, (formula_120, so formula_121). The Dirac operator in this Clifford algebra is defined as formula_122. The function formula_123 is considered analytic if and only if formula_124, which can be calculated in the following way:\nformula_125\nGrouping by formula_126 and formula_127:\nformula_128\nHence, in traditional notation:\nformula_129\nConformal mappings in higher dimensions.\nLet \u03a9 be an open set in the Euclidean space formula_130. The equation for an orientation-preserving mapping formula_131 to be a conformal mapping (that is, angle-preserving) is that\nformula_132\nwhere \"Df\" is the Jacobian matrix, with transpose formula_133, and \"I\" denotes the identity matrix. For , this system is equivalent to the standard Cauchy\u2013Riemann equations of complex variables, and the solutions are holomorphic functions. In dimension , this is still sometimes called the Cauchy\u2013Riemann system, and Liouville's theorem implies, under suitable smoothness assumptions, that any such mapping is a M\u00f6bius transformation.\nLie pseudogroups.\nOne might seek to generalize the Cauchy-Riemann equations instead by asking more generally when are the solutions of a system of PDEs closed under composition. The theory of Lie Pseudogroups addresses these kinds of questions."}
{"id": "7585", "revid": "44144402", "url": "https://en.wikipedia.org/wiki?curid=7585", "title": "Chaim Topol", "text": "Chaim Topol (; 9 September 1935 \u2013 8 March 2023), mononymously known as Topol, was an Israeli actor and singer. He is best known for his portrayal of Tevye, the lead role in the stage musical \"Fiddler on the Roof\" and the 1971 film adaptation, performing this role more than 3,500 times from 1967 through 2009.\nTopol began acting during his Israeli army service as a member of the Nahal entertainment troupe. He later toured Israel with kibbutz theatre and satirical theatre companies. He was a co-founder of the Haifa Theatre. His breakthrough film role came in 1964 as the title character in \"Sallah Shabati\", by Israeli writer Ephraim Kishon, for which he won a Golden Globe for Most Promising Newcomer\u2014Male. Topol went on to appear in more than 30 films in Israel and the United States, including \"Galileo\" (1975), \"Flash Gordon\" (1980), and \"For Your Eyes Only\" (1981). He was described as Israel's only internationally recognized entertainer from the 1960s through the 1980s. He won a Golden Globe for Best Actor and was nominated for an Academy Award for Best Actor for his 1971 film portrayal of Tevye, and was nominated for a Tony Award for Best Actor for a 1991 Broadway revival of \"Fiddler on the Roof\".\nTopol was a founder of Variety Israel, an organization serving children with special needs, and Jordan River Village, a year-round camp for Arab and Jewish children with life-threatening illnesses, for which he served as chairman of the board. In 2015 he was awarded the Israel Prize for lifetime achievement.\nBiography.\nChaim Topol was born on September 9, 1935, in Tel Aviv, in what was then Mandatory Palestine. His father Jacob Topol was born in Russia and in the early 1930s immigrated to Mandatory Palestine, where he worked as a plasterer; he also served in the Haganah paramilitary organization. His mother Imrela \"Rel\" (n\u00e9e Goldman) Topol was a seamstress.\nTopol's parents had been members of the Betar Zionist youth movement in Warsaw. His father had Hasidic roots, with a mother coming from a family of Gerrer Hasidim and a father from Aleksander Hasidim.\nTopol and his two younger sisters grew up in the South Tel Aviv working-class neighborhood of Florentin. As a young child, although he wanted to become a commercial artist, his elementary school teacher, the writer Yemima Avidar-Tchernovitz, saw a theatrical side to him, and encouraged him to act in school plays and read stories to the class.\nAt age 14 he began working as a printer at \"Davar\" newspaper while pursuing his high school studies at night. He graduated at age 17 and moved to Kibbutz Geva. A year later, he enlisted in the Israeli army and became a member of the Nahal entertainment troupe, singing and acting in traveling shows. He rose in rank to troupe commander.\nTwenty-three days after being discharged from military service on October 2, 1956, and two days after marrying Galia Finkelstein, a fellow Nahal troupe member, Topol was called up for reserve duty in the Sinai Campaign. He performed for soldiers stationed in the desert.\nAfter the war, he and his wife settled in Kibbutz Mishmar David, where Topol worked as a garage mechanic. Topol assembled a kibbutz theatre company made up of friends from his Nahal troupe; the group toured four days a week, worked on their respective kibbutzim for two days a week, and had one day off. The theatre company was in existence from early 1957 to the mid-1960s. Topol both sang and acted with the group, doing both \"loudly\".\nTopol and his wife Galia Finkelstein had three children: a son and two daughters. The couple resided in Galia's childhood home in Tel Aviv. Topol's hobbies included sketching and sculpting.\nIn June 2022, Topol's son, Omer, revealed that his father was suffering from Alzheimer's disease.\nOn March 8, 2023, Topol's family notified the press that he was near death and \"living his final hours\", and asked the public to respect the family's privacy. He died overnight at the age of 87. The day before his burial at Kvutzat Shiller on March 10, a memorial was held at the Cameri Theater in Tel Aviv.\nSinging and acting career.\nBetween 1960 and 1964, Topol performed with the Batzal Yarok (\"Green Onion\") satirical theatre company, which also toured Israel. Other members of the group included Uri Zohar, Nechama Hendel, Zaharira Harifai, Arik Einstein, and Oded Kotler. In 1960, Topol co-founded the Haifa Municipal Theatre with Yosef Milo, serving as assistant to the director and acting in plays by Shakespeare, Ionesco, and Brecht. In 1965 he performed in the Cameri Theatre in Tel Aviv.\nTopol's first film appearance was in the 1961 film \"I Like Mike\", followed by the 1963 Israeli film \"El Dorado\". His breakthrough role came as the lead character in the 1964 film \"Sallah Shabati\". Adapted for the screen by Ephraim Kishon from his original play, the social satire depicts the hardships of a Sephardic immigrant family in the rough conditions of ma'abarot, immigrant absorption camps in Israel in the 1950s, satirizing \"just about every pillar of Israeli society: the Ashkenazi establishment, the pedantic bureaucracy, corrupt political parties, rigid kibbutz ideologues and ... the Jewish National Fund's tree-planting program\". Topol, who was 29 during the filming, was familiar playing the role of the family patriarch, having performed skits from the play with his Nahal entertainment troupe during his army years. He contributed his ideas to the part, playing the character as a more universal Mizrahi Jew instead of specifically a Yemenite, Iraqi, or Moroccan Jew, and asking Kishon to change the character's first name from Saadia (a recognizably Yemenite name) to Sallah (a more general Mizrahi name).\nThe film won the Golden Globe Award for Best Foreign Language Film, and Topol won the 1964 Golden Gate Award for Best Actor at the San Francisco International Film Festival and the 1965 Golden Globe for Most Promising Newcomer\u2014Male, alongside Harve Presnell and George Segal. \"Sallah Shabati\" was nominated for the Academy Award for Best Foreign Language Film, losing to the Italian-language \"Yesterday, Today and Tomorrow\".\nIn 1966, Topol made his English-language film debut as Abou Ibn Kaqden in the Mickey Marcus biopic \"Cast a Giant Shadow\".\nTevye the Dairyman.\nTopol came to greatest prominence in his portrayal of Tevye the Dairyman on stage and screen. He first played the lead role in the Israeli production of the musical \"Fiddler on the Roof\" in 1966, replacing Shmuel Rodensky for 10 weeks when Rodensky fell ill. Harold Prince, producer of the original \"Fiddler on the Roof\" that opened on Broadway in 1964, had seen Topol in \"Sallah Shabati\" and called him to audition for the role of the fifty-something Tevye in a new production scheduled to open at Her Majesty's Theatre in London on February 16, 1967. Not yet fluent in English, Topol memorized the score from listening to the original Broadway cast album and practiced the lyrics with a British native.\nWhen Topol arrived at the audition, Prince was surprised that this 30-year-old man had played Shabati, a character in his sixties. Topol explained, \"A good actor can play an old man, a sad face, a happy man. Makeup is not an obstacle\". Topol also surprised the producers with his familiarity with the staging, since he had already acted in the Israeli production, and was hired. He spent six months in London learning his part phonetically with vocal coach Cicely Berry. Jerome Robbins, director and choreographer of the 1964 Broadway show who came over to direct the London production, \"re-directed\" the character of Tevye for Topol and helped the actor deliver a less caricatured performance. Topol's performance received positive reviews.\nA few months after the opening, Topol was called up for reserve duty in the Six-Day War and returned to Israel. He was assigned to an army entertainment troupe on the Golan Heights. Afterward he returned to the London production, appearing in a total of 430 performances.\nIt was during the London run that he began being known by his last name only, as the English producers were unable to pronounce the voiceless uvular fricative consonant \u1e24et at the beginning of his first name, Chaim, instead calling him \"Shame\".\nIn casting the 1971 film version of \"Fiddler on the Roof\", director Norman Jewison and his production team sought an actor other than Zero Mostel for the lead role. This decision was a controversial one, as Mostel had made the role famous in the long-running Broadway musical and wanted to star in the film. But Jewison and his team felt Mostel would eclipse the character with his larger-than-life personality. Jewison flew to London in February 1968 to see Topol perform as Tevye during his last week with the London production, and chose him over Danny Kaye, Herschel Bernardi, Rod Steiger, Danny Thomas, Walter Matthau, Richard Burton, and Frank Sinatra, who had also expressed interest in the part.\nThen 36 years old, Topol was made to look 20 years older and heavier with makeup and costuming. As in his role as Shabati, Topol used the technique of \"locking his muscles\" to convincingly play an older character. He later explained:\nAs a young man, I had to make sure that I didn't break the illusion for the audience. You have to tame yourself. I'm now someone who is supposed to be 50, 60 years old. I cannot jump. I cannot suddenly be young. You produce a certain sound [in your voice] that is not young.\nFor his performance, Topol won the Golden Globe Award for Best Actor in a Motion Picture \u2013 Musical or Comedy, the Sant Jordi Award for Best Performance in a Foreign Film, and the 1972 David di Donatello for Best Foreign Actor, sharing the latter with Elizabeth Taylor. He was also nominated for the 1971 Academy Award for Best Actor, losing to Gene Hackman in \"The French Connection\".\nIn 1983 Topol reprised the role of Tevye in a revival of \"Fiddler on the Roof\" on the West End in London. In 1989, he played the role in a 30-city U.S. touring production. As he was by then the approximate age of the character, he commented, \"I didn't have to spend the energy playing the age\". In 1990\u20131991, he again starred as Tevye in a Broadway revival of \"Fiddler\" at the Gershwin Theatre. In that production Rosalind Harris, who had played eldest daughter Tzeitel in the film, played Tevye's wife Golde opposite Topol. In 1991, he was nominated for a Tony Award for Best Performance by a Leading Actor in a Musical, losing to Jonathan Pryce in \"Miss Saigon\". Topol again played Tevye in a 1994 London revival, which became a touring production. In that production, the role of one of his daughters was played by his daughter, Adi Topol Margalith.\nTopol reprised the role of Tevye for a 1997\u20131998 touring production in Israel, as well as a 1998 show at the Regent Theatre in Melbourne. In September 2005 he returned to Australia for a \"Fiddler on the Roof\" revival at the Capitol Theatre in Sydney, followed by an April 2006 production at the Lyric Theatre in Brisbane, and a June 2006 production at Her Majesty's Theatre in Melbourne. In May 2007, he starred in a production at the Auckland Civic Theatre.\nIn 2009, Topol began a farewell tour of \"Fiddler on the Roof\" as Tevye, opening in Wilmington, Delaware. He was forced to withdraw from the tour in Boston owing to a shoulder injury, and was replaced by Theodore Bikel and Harvey Fierstein, both of whom had portrayed Tevye on Broadway. Topol estimated that he performed the role more than 3,500 times.\nIn 2014, he appeared in \"Raising the Roof\", a 50th-anniversary tribute to \"Fiddler\" at New York City's Town Hall produced by National Yiddish Theatre. The evening featured Chita Rivera, Joshua Bell, Sheldon Harnick, Andrea Martin, Jerry Zaks, and more, and was co-directed by Gary John La Rosa and Erik Liberman.\nOther stage and film roles.\nIn 1976, Topol played the lead role of the baker, Amiable, in the new musical \"The Baker's Wife\", but was fired after eight months by producer David Merrick. In her autobiography, Patti LuPone, his co-star in the production, claimed that Topol had behaved unprofessionally on stage and had a strained relationship with her off-stage. The show's composer, Stephen Schwartz, claimed that Topol's behavior greatly disturbed the cast and directors and resulted in the production not reaching Broadway as planned. In 1988, Topol starred in the title role in \"Ziegfeld\" at the London Palladium. He returned to the London stage in 2008 in the role of Honor\u00e9, played by Maurice Chevalier in the 1958 film \"Gigi\".\nTopol appeared in more than 30 films in Israel and abroad. Among his notable English-language appearances are the title role in \"Galileo\" (1975), Dr. Hans Zarkov in \"Flash Gordon\" (1980), and Milos Columbo in the James Bond film \"For Your Eyes Only\" (1981). He was said to be Israel's \"only internationally-recognized entertainer\" from the 1960s through to the 1980s.\nIn Israel, Topol acted in and produced dozens of films and television series. As a voice artist, he dubbed the voice of Bagheera in the Hebrew-language versions of \"The Jungle Book\" and the 2003 sequel as well as Rubeus Hagrid in the first two films of the \"Harry Potter\" film series. He was also a playwright and screenwriter.\nTopol was featured on two BBC One programmes , the six-part series \"Topol's Israel\" (1985) and earlier \"It's Topol\" (1968). A Hebrew-language documentary of his life, \"Chaim Topol \u2013 Life as a Film\", aired on Israel's Channel 1 in 2011, featuring interviews with his longtime actor friends in Israel and abroad.\nMusical recordings.\nA baritone, Topol recorded several singles and albums, including film soundtracks, children's songs, and Israeli war songs. His albums include \"Topol With Roger Webb And His Orchestra - Topol '68\" (1967), \"Topol Sings Israeli Freedom Songs\" (1967), \"War Songs By Topol\" (1968), and \"Topol's Israel\" (1984). He appeared on the soundtrack album for the film production of \"Fiddler on the Roof\" (1971) and the London cast album (1967).\nMossad missions.\nAfter Topol's death, the family revealed that he had been involved in Mossad missions in the 1960s and 1970s. They said he went on unexplained trips abroad while equipped with a miniature state-of-the-art camera and tape recorder, and that he was in regular contact with Mossad officer Peter Malkin, who came on visits to the family home through the backyard in disguise. On several occasions, Topol carried out wiretapping and other operations with Malkin, using his international acclaim to divert attention from Malkin.\nLiterary and art career.\nHis autobiography, \"Topol by Topol\", was published in London by Weindenfel and Nicholson (1981). He also authored \"To Life!\" (1994) and \"Topol's Treasury of Jewish Humor, Wit and Wisdom\" (1995).\nTopol illustrated approximately 25 books in both Hebrew and English. He also produced drawings of Israeli national figures. His sketches of Israeli presidents were reproduced in a 2013 stamp series issued by the Israel Philatelic Federation, as was his self-portrait as Tevye for 2014 commemorative stamp marking the 50th anniversary of the Broadway debut of \"Fiddler on the Roof\".\nPhilanthropy.\nIn 1967, Topol founded Variety Israel, an organization serving children with special needs. He was also a co-founder and chairman of the board of Jordan River Village, a vacation village for Arab and Jewish children with life-threatening illnesses, which opened in 2012. It was inspired by Paul Newman's Hole in the Wall Gang Camp. The village is operated almost entirely by volunteers. Topol described it as the project he was \"most connected to.\"\nAwards and recognition.\nTopol was a recipient of Israel's Kinor David award in arts and entertainment in 1964. He received a Best Actor award from the San Sebasti\u00e1n International Film Festival for his performance in the 1972 film \"Follow Me!\" In 2008, he was named an Outstanding Member of the Israel Festival for his contribution to Israeli culture.\nIn 2014, the University of Haifa conferred upon Topol an honorary degree in recognition of his 50 years of activity in Israel's cultural and public life. In 2015, he received the Israel Prize for lifetime achievement.\nIn 2015, Chaim Topol was honoured by the Chief Rabbi of Ukraine, Rabbi Moshe Reuven Azman and the Ukrainian Jewish Community. Topol's portrayal of Tevye in Fiddler on the Roof led to the inspiration for the Anatevka Refugee Village which was named in commemoration of the fictional village.\nLegacy.\nShortly after Topol's death, President Isaac Herzog issued a statement honouring \"one of the most prominent Israeli stage artists, a gifted actor who conquered many stages in Israel and overseas, filled the cinema screens with his presence and, above all, deeply entered our hearts\". Prime minister Benjamin Netanyahu stated \"his wide smile, warm voice, and unique sense of humour made him a folk hero who won the hearts of the people\" and former prime minister Yair Lapid remarked \"He and his smile will continue to accompany Israeli culture, his rich legacy will forever remain a part of Israel\"."}
{"id": "7586", "revid": "22677691", "url": "https://en.wikipedia.org/wiki?curid=7586", "title": "Christadelphians", "text": "The Christadelphians () are a restorationist and nontrinitarian (Biblical Unitarian) Christian denomination. The name means 'brothers and sisters in Christ', from the Greek words for Christ (\"Christos\") and brothers (\"adelphoi\").\nChristadelphians believe in the inspiration of the Bible, the Virgin Birth, the status of Jesus Christ as the son of God, believer's baptism, the resurrection of the dead, the second coming of Christ, and the future kingdom of God on earth. However, they reject a number of mainstream Christian doctrines, for example the Trinity and the immortality of the soul, believing these to be corruptions of original Christian teaching.\nThe movement developed in the United Kingdom and North America in the 19th century around the teachings of John Thomas and they were initially found predominantly in the developed English-speaking world, expanding in developing countries after the Second World War. There are approximately 50,000 Christadelphians in around 120 countries. Congregations are traditionally referred to as \"ecclesias\".\nHistory.\n19th century.\nThe Christadelphian movement traces its origins to John Thomas (1805\u20131871). He initially associated with emerging Restoration Movement in the United States but later separated from them. The Christadelphian community in the United Kingdom effectively dates from Thomas's first lecturing tour of Britain (May 1848 \u2013 October 1850). During this period, he wrote \"Elpis Israel\" in which he laid out his understanding of the main doctrines of the Bible. Since his medium for bringing change was print and debate, it was natural for the origins of the Christadelphian body to be associated with books and journals, such as Thomas's \"Herald of the Kingdom\". His message was particularly welcomed in Scotland, and Campbellite, Unitarian and Adventist friends separated to form groups of \"Baptised Believers\".\nIn his desire to seek to establish Biblical truth and test orthodox Christian beliefs through independent scriptural study he was not alone. Among other churches, he had links with the Adventist movement and with Benjamin Wilson (who later set up the Church of God of the Abrahamic Faith in the 1860s). Although the Christadelphian movement originated through the activities of John Thomas, he never saw himself as making his own disciples. He believed rather that he had rediscovered 1st century beliefs from the Bible alone, and sought to prove that through a process of challenge and debate and writing journals. Through that process a number of people became convinced and set up various fellowships that had sympathy with that position. Groups associated with John Thomas met under various names, including Believers, Baptised Believers, the Royal Association of Believers, Baptised Believers in the Kingdom of God, Nazarines (or Nazarenes), and The Antipas until the time of the American Civil War (1861\u20131865). At that time, church affiliation was required in the United States and in the Confederate States of America in order to register for conscientious objector status, and in 1864 Thomas chose for registration purposes the name \"Christadelphian\".\nThrough the teaching of John Thomas and the need in the American Civil War for a name, the Christadelphians emerged as a denomination, but they were formed into a lasting structure through a passionate follower of Thomas's interpretation of the Bible, Robert Roberts. In 1864, he began to publish \"The Ambassador of the Coming Age\" magazine. John Thomas, out of concern that someone else might start a publication and call it \"The Christadelphian\", urged Robert Roberts to change the name of his magazine to \"The Christadelphian\", which he did in 1869. His editorship of the magazine continued with some assistance until his death in 1898. In church matters, Roberts was prominent in the period following the death of John Thomas in 1871, and helped craft the structures of the Christadelphian body.\nInitially, the denomination grew in the English-speaking world, particularly in the English Midlands and in parts of North America. Two thirds of ecclesias, and members, in Britain before 1864 were in Scotland. In the early days after the death of John Thomas, the group could have moved in a number of directions. Doctrinal issues arose, debates took place, and statements of faith were created and amended as other issues arose. These attempts were felt necessary by many to both settle and define a doctrinal stance for the newly emerging denomination and to keep out error. As a result of these debates, several groups separated from the main body of Christadelphians, most notably the Suffolk Street fellowship in 1885 (with members believing that the whole of the Bible was not inspired), and the Unamended fellowship.\n20th century.\nThe Christadelphian position on conscientious objection came to the fore with the introduction of conscription during the First World War. Varying degrees of exemption from military service were granted to Christadelphians in the United Kingdom, Canada, Australia, New Zealand, and the United States. In the Second World War, this frequently required the person seeking exemption to undertake civilian work under the direction of the authorities.\nDuring the Second World War, the Christadelphians in Britain assisted in the Kindertransport, helping to relocate several hundred Jewish children away from Nazi persecution by founding a hostel, Elpis Lodge, for that purpose. In Germany, the small Christadelphian community founded by Albert Maier went underground from 1940 to 1945, and a leading brother, Albert Merz, was imprisoned as a conscientious objector and later executed.\nAfter the Second World War, moves were taken to try to reunite various of the earlier divisions. By the end of the 1950s, most Christadelphians had united into one community, but there are still a number of small groups of Christadelphians who remain separate.\nToday.\nThe post-war and post-reunions periods saw an increase in co-operation and interaction between ecclesias, resulting in the establishment of a number of week-long Bible schools and the formation of national and international organisations such as the Christadelphian Bible Mission (for preaching and pastoral support overseas), the Christadelphian Support Network (for counselling), and the Christadelphian Meal-A-Day Fund (for charity and humanitarian work).\nThe period following the reunions was accompanied by expansion in the developing world, which now accounts for around 40% of Christadelphians.\nBeliefs.\nThe Christadelphian body has no central authority or co-ordinating organisation to establish and maintain a standardised set of beliefs, but there are core doctrines accepted by most Christadelphians. In the formal statements of faith a more complete list is found; for instance, the Birmingham Amended Statement of Faith has 30 doctrines to be accepted and 35 to be rejected.\nThe Bible.\nChristadelphians state that their beliefs are based wholly on the Bible, and they do not see other works as inspired by God. They regard the Bible as inspired by God and, therefore, believe that in its original form, it is error-free apart from errors in later copies due to errors of transcription or translation.\nGod.\nChristadelphians believe that God, Jehovah, is the creator of all things and the father of true believers, that he is a separate being from his son, Jesus (who is subordinate to him). They reject the doctrine of the Trinity.\nJesus.\nChristadelphians believe that Jesus is the promised Jewish Messiah, in whom the prophecies and promises of the Old Testament find their fulfilment. They believe he is the Son of Man, in that he inherited human nature (with its inclination to sin) from his mother, and the Son of God by virtue of his miraculous conception by the power of God. Christadelphians reject the doctrine of Christ's pre-existence. They teach that he was part of God's plans from the beginning and was foreshadowed in the Old Testament, but was no independent creature prior to his earthly birth. Although he was tempted, Jesus committed no sin, and was therefore a perfect representative sacrifice to bring salvation to sinful humankind. They believe that God raised Jesus from death and gave him immortality, and he has ascended to Heaven, God's dwelling place, until he returns to set up the Kingdom of God on earth.\nThe Holy Spirit.\nChristadelphians believe that the Holy Spirit is the power of God used in creation and for salvation. They also believe that the phrase \"Holy Spirit\" sometimes refers to God's character/mind, depending on the context in which the phrase appears, but reject the view that people need strength, guidance and power from the Holy Spirit to live the Christian life, believing instead that the spirit a believer needs within themselves is the mind/character of God, which is developed in a believer by their reading of the Bible (which, they believe, contains words God gave by his Spirit) and trying to live by what it says during the events of their lives which God uses to help shape their character. Christadelphians deny the personhood of the Holy Spirit, and the present-day possession of the Holy Spirit (both \"gift of\" and \"gifts of\") (see cessationism).\nThe Kingdom of God.\nChristadelphians believe that Jesus Christ will return to the Earth in person to set up the Kingdom of God in fulfilment of the promises made to Abraham and David. This includes the belief that the coming Kingdom will be the restoration of God's first Kingdom of Israel, which was under David and Solomon. For Christadelphians, this is the focal point of the gospel taught by Jesus and the apostles. They believe that the Kingdom will be centred upon Israel, but Jesus Christ will also reign over all the other nations on the Earth. Old Paths Christadelphians continue to believe that the Kingdom of God is to be restored to the land of Israel promised to Abraham and ruled over in the past by David, with a worldwide empire.\nThe Devil.\nChristadelphians believe that the word \"devil\" is a reference in the scriptures to sin and human nature in opposition to God, while the word \"satan\" is merely a reference to an adversary or opponent (be it good or bad) and is frequently applied to human beings. According to Christadelphians, these terms are used in reference to specific political systems or individuals in opposition or conflict and not to an independent spiritual being or fallen angel. Accordingly, they do not define Hell as a place of eternal torment for sinners, but as a state of eternal death and non-existence due to annihilation of body and mind.\nSalvation.\nChristadelphians believe that people are separated from God because of their sins but that humankind can be reconciled to him by becoming disciples of Jesus Christ. This is by belief in the gospel, through repentance, and through baptism by total immersion in water. They reject assurance of salvation, believing instead that salvation comes as a result of remaining \"in Christ\". After death, believers are in a state of non-existence, knowing nothing until the Resurrection at the return of Christ. Following the judgement at that time, the accepted receive the gift of immortality, and live with Christ on a restored Earth, assisting him to establish the Kingdom of God and to rule over the mortal population for a thousand years (the Millennium). Christadelphians deny the immortality of the soul.\nLife in Christ.\nThe \"Commandments of Christ\" demonstrates the community's recognition of the importance of biblical teaching on morality. Marriage and family life are important. Most Christadelphians believe that sexual relationships should be limited to heterosexual marriage, ideally between baptised believers.\nOrganisation.\nGeneral organisation.\nIn the absence of centralised organisation, some differences exist amongst Christadelphians on matters of belief and practice. This is because each congregation (commonly styled 'ecclesias') is organised autonomously, typically following common practices which have altered little since the 19th century. Many avoid the word \"church\" due to its association with mainstream Christianity, and its focus on the building as opposed to the congregation. Most ecclesias have a constitution, which includes a 'Statement of Faith', a list of 'Doctrines to be Rejected' and a formalised list of 'The Commandments of Christ'. With no central authority, individual congregations are responsible for maintaining orthodoxy in belief and practice, and the statement of faith is seen by many as useful to this end. The statement of faith acts as the official standard of most ecclesias to determine fellowship within and between ecclesias, and as the basis for co-operation between ecclesias. Congregational discipline and conflict resolution are applied using various forms of consultation, mediation, and discussion, with disfellowship (similar to excommunication) being the final response to those with unorthodox practices or beliefs.\nThe relative uniformity of organisation and practice is undoubtedly due to the influence of a booklet, written early in Christadelphian history by Robert Roberts, called \"A Guide to the Formation and Conduct of Christadelphian Ecclesias\". It recommends a basically democratic arrangement by which congregational members elect 'brothers' to do arranging and serving duties, and includes guidelines for the organisation of committees, as well as conflict resolution between congregational members and between congregations. Christadelphians do not have paid ministers. Male members (and increasingly female in some places) are assessed by the congregation for their eligibility to teach and perform other duties, which are usually assigned on a rotation basis, as opposed to having a permanently appointed preacher. Congregational polity typically follows a democratic model, with an elected arranging committee for each individual ecclesia. This unpaid committee is responsible for the day-to-day running of the ecclesia and is answerable to the rest of the ecclesia's members.\nInter-ecclesial organisations co-ordinate the running of, among other things, Christadelphian schools and elderly care homes, the Christadelphian Isolation League (which cares for those prevented by distance or infirmity from attending an ecclesia regularly) and the publication of .\nAdherents.\nNo official membership figures are published, but the \"Columbia Encyclopaedia\" gives an estimated figure of 50,000 Christadelphians, spread across approximately 120 countries. Estimates for the main centers of Christadelphian population are as follows: Mozambique (17,800), Australia (9,734), the United Kingdom (8,200), Malawi (7,000), United States (6,500), Canada (3,000), Kenya (2,700), India (2,300) and New Zealand (1,785). Figures from Christadelphian mission organisations are as follows: Africa (32,500), Asia (4,000), the Caribbean (400), Europe (including Russia) (700), Latin America (275), and the Pacific (200).\nFellowships.\nThe Christadelphian body consists of a number of \"fellowships\" \u2013 groups of ecclesias which associate with one another, often to the exclusion of ecclesias outside their group. They are to some degree localised. The Unamended Fellowship, for example, exists only in North America. Christadelphian fellowships have often been named after ecclesias or magazines who took a lead in developing a particular stance.\nThe majority of Christadelphians today belong to what is commonly known as the \"Central Fellowship\". The term \"Central\" came into use around 1933 to identify ecclesias worldwide who were in fellowship with the Birmingham (Central) Ecclesia. These were previously known as the \"Temperance Hall Fellowship\". The \"Suffolk Street Fellowship\" arose in 1885 over disagreements surrounding the inspiration of the Bible. Meanwhile, in Australia, division concerning the nature of Jesus Christ resulted in the formation of the \"Shield Fellowship\". Discussions in 1957\u20131958 resulted in a worldwide reunion between the Central, Suffolk Street and Shield Fellowships.\nThe \"Unamended Fellowship\", consisting of around 1,850 members, is found in the East Coast and Midwest USA and Ontario, Canada. This group separated in 1898 as a result of differing views on who would be raised to judgement at the return of Christ. The majority of Christadelphians believe that the judgement will include anyone who had sufficient knowledge of the gospel message, and is not limited to baptised believers. The majority in England, Australia and North America amended their statement of faith accordingly. Those who opposed the amendment became known as the \"Unamended Fellowship\" and allowed the teaching that God either could not or would not raise those who had no covenant relationship with him. Opinions vary as to what the established position was on this subject prior to the controversy. Prominent in the formation of the Unamended Fellowship was Thomas Williams, editor of the Christadelphian Advocate magazine. The majority of the Unamended Fellowship outside North America joined the Suffolk Street Fellowship before its eventual incorporation into Central Fellowship. There is also some co-operation between the Central (Amended) and Unamended Fellowships in North America \u2013 most recently in the Great Lakes region, where numerous Amended and Unamended ecclesias are working together to unify their ecclesias. The Central Fellowship in North America is still often referred to today as the \"Amended Fellowship\".\nThe \"Berean Fellowship\" was formed in 1923 as a result of varying views on military service in England, and on the atonement in North America. The majority of the North American Bereans re-joined the main body of Christadelphians in 1952. A number continue as a separate community, numbering around 200 in Texas, 100 in Kenya and 30 in Wales. Most of the divisions still in existence within the Christadelphian community today stem from further divisions of the \"Berean\" \"Fellowship\".\nThe \"Dawn Fellowship\" are the result of an issue which arose in 1942 among the Berean Fellowship regarding divorce and remarriage. The stricter party formed the Dawn Fellowship who, following re-union on the basis of unity of belief with the Lightstand Fellowship in Australia in 2007 increased in number. There are now thought to be around 800 members in England, Australia, Canada, India, Jamaica, Poland, the Philippines, Russia and Kenya.\nThe \"Old Paths Fellowship\" was formed in 1957 in response to the reunion of the Central and Suffolk Street Fellowships. A minority from the Central Fellowship held that the reasons for separation remained and that full unity of belief on all fundamental principles of Bible teaching was necessary; thus reunion was only possible with the full agreement and understanding of all members rather than a decision by majority vote. Ecclesias forming the Old Paths Fellowship arose in England, Australia, New Zealand and Canada numbering around 500 members in total. They now number around 250 members in total, with members in Australia, England, Mexico and New Zealand. They maintain that they hold to the original Central Fellowship position held prior to the 1957 Reunion.\nOther fellowships (ranging in numbers from as few as 10 to over 200 members) include the \"Watchman Fellowship\", the \"Companion Fellowship\" and the \"Pioneer Fellowship\".\nAccording to Bryan Wilson, functionally the definition of a \"fellowship\" within Christadelphian history has been mutual or unilateral exclusion of groupings of ecclesias from the breaking of bread. This functional definition still holds true in North America, where the Unamended Fellowship and the Church of God of the Abrahamic Faith are not received by most North American Amended ecclesias. But outside North America this functional definition no longer holds. Many articles and books on the doctrine and practice of fellowship now reject the notion itself of separate \"fellowships\" among those who recognise the same baptism, viewing such separations as schismatic. Many ecclesias in the Central fellowship would not refuse a baptised Christadelphian from a minority fellowship from breaking bread; the exclusion is more usually the other way.\nThey tend to operate organisationally fairly similarly, although there are different emphases. Despite their differences, the Central, Old Paths, Dawn and Berean fellowships generally subscribe to the \"Birmingham Amended Statement of Faith\" (BASF), though the latter two have additional clauses or supporting documents to explain their position. Most Unamended ecclesias use the \"Birmingham Unamended Statement of Faith\" (BUSF) with one clause being different. Within the Central fellowship individual ecclesias also may have their own statement of faith, whilst still accepting the statement of faith of the larger community. Some ecclesias have statements around their positions, especially on divorce and re-marriage, making clear that offence would be caused by anyone in that position seeking to join them at the 'Breaking of Bread' service. Others tolerate a degree of divergence from commonly held Christadelphian views. While some communities of Christadelphian origin have viewed previous statements of faith as set in stone, others have felt it necessary to revise them in order to meet contemporary issues, update language or add supporting Biblical quotations.\nFor each fellowship, anyone who publicly assents to the doctrines described in the statement and is in good standing in their \"home ecclesia\" is generally welcome to participate in the activities of any other ecclesia.\nRelated groups.\nThere are a number of groups who, while sharing a common heritage and many Christadelphian teachings, have adopted alternative names in order to dissociate themselves from what they believe to be false teachings and/or practice within the main Christadelphian body. Ranging in size from two or three members in size to around 50, each group restricts fellowship to its own members. These include the Nazarene Fellowship, the Ecclesia of Christ, the Remnant of Christ's Ecclesia, the Apostolic Fellowship of Christ and the Apostolic Ecclesia.\nThe Church of God of the Abrahamic Faith (CGAF) also has common origins with Christadelphians and shares Christadelphian beliefs. Numbering around 400 (primarily Ohio and Florida, USA), they are welcomed into fellowship by some \"Central\" Christadelphians and are currently involved in unity talks.\nHistorical antecedents.\nOne criticism of the Christadelphian movement has been over the claim of John Thomas and Robert Roberts to have \"re-discovered\" scriptural truth. However one might argue that \"all\" Protestant groups make the same claims to some extent. Although both men believed that they had \"recovered\" the true doctrines for themselves and contemporaries, they also believed there had always existed a group of true believers throughout the ages, albeit marred by the apostasy.\nThe most notable Christadelphian attempts to find a continuity of those with doctrinal similarities since that point have been geographer Alan Eyre's two books \"The Protesters\" (1975) and \"Brethren in Christ\" (1982) in which he shows that many individual Christadelphian doctrines had been previously believed. Eyre focused in particular on the Radical Reformation, and also among the Socinians and other early Unitarians and the English Dissenters. In this way, Eyre was able to demonstrate substantial historical precedents for individual Christadelphian teachings and practices, and believed that the Christadelphian community was the 'inheritor of a noble tradition, by which elements of the Truth were from century to century hammered out on the anvil of controversy, affliction and even anguish'. Although noting in the introduction to 'The Protestors' that 'Some recorded herein perhaps did not have \"all the truth\" \u2014 so the writer has been reminded', Eyre nevertheless claimed that the purpose of the work was to 'tell how a number of little-known individuals, groups and religious communities strove to preserve or revive the original Christianity of apostolic times', and that 'In faith and outlook they were far closer to the early springing shoots of first-century Christianity and the penetrating spiritual challenge of Jesus himself than much that has passed for the religion of the Nazarene in the last nineteen centuries'.\nEyre's research has been criticized by some of his Christadelphian peers, and as a result Christadelphian commentary on the subject has subsequently been more cautious and circumspect, with caveats being issued concerning Eyre's claims, and the two books less used and publicised than in previous years.\nNevertheless, even with most source writings of those later considered heretics destroyed, evidence can be provided that since the first century BC there have been various groups and individuals who have held certain individual Christadelphian beliefs or similar ones. For example, all the distinctive Christadelphian doctrines (with the exception of the non-literal devil), down to interpretations of specific verses, can be found particularly among sixteenth century Socinian writers (e.g. the rejection of the doctrines of the trinity, pre-existence of Christ, immortal souls, a literal hell of fire, original sin). Early English Unitarian writings also correspond closely to those of Christadelphians. Also, recent discoveries and research have shown a large similarity between Christadelphian beliefs and those held by Isaac Newton who, among other things, rejected the doctrines of the trinity, immortal souls, a personal devil and literal demons. Further examples are as follows:\nOrganised worship in England for those whose beliefs anticipated those of Christadelphians only truly became possible in 1779 when the Act of Toleration 1689 was amended to permit denial of the Trinity, and only fully when property penalties were removed in the Doctrine of the Trinity Act 1813. This is only 35 years before John Thomas' 1849 lecture tour in Britain which attracted significant support from an existing non-Trinitarian Adventist base, particularly, initially, in Scotland where Arian, Socinian, and unitarian (with a small 'u' as distinct from the Unitarian Church of Theophilus Lindsey) views were prevalent.\nPractices and worship.\nChristadelphians are organised into local congregations, that commonly call themselves \"ecclesias\", which is taken from usage in the New Testament and is Greek for \"gathering of those summoned\". Congregational worship, which usually takes place on Sunday, centres on the remembrance of the death and celebration of the resurrection of Jesus Christ by the taking part in the \"memorial service\". Additional meetings are often organised for worship, prayer, preaching and Bible study.\nEcclesias are typically involved in preaching the gospel (evangelism) in the form of public lectures on Bible teaching, college-style seminars on reading the Bible, and Bible Reading Groups. Correspondence courses are also used widely, particularly in areas where there is no established Christadelphian presence. Some ecclesias, organisations or individuals also preach through other media like video, \n and internet forums. There are also a number of Bible Education/Learning Centres around the world.\nOnly baptised (by complete immersion in water) believers are considered members of the ecclesia. Ordinarily, baptism follows someone making a \"good confession\" (cf. 1 Tim. 6:12) of their faith before two or three nominated elders of the ecclesia they are seeking to join. The good confession has to demonstrate a basic understanding of the main elements \u2013 \"first principles\" \u2013 of the faith of the community. The children of members are encouraged to attend Christadelphian Sunday schools and youth groups. Interaction between youth from different ecclesias is encouraged through regional and national youth gatherings, conferences and camping holidays.\nChristadelphians understand the Bible to teach that male and female believers are equal in God's sight, and also that there is a distinction between the roles of male and female members. Women are typically not eligible to teach in formal gatherings of the ecclesia when male believers are present, are expected to cover their heads (using hat or scarf, etc.) during formal services, and do not sit on the main ecclesial arranging (organising) committees. They do, however: participate in other ecclesial and inter-ecclesial committees; participate in discussions; teach children in Sunday schools as well as at home, teach other women and non-members; perform music; discuss and vote on business matters; and engage in the majority of other activities. Generally, at formal ecclesial and inter-ecclesial meetings the women wear head coverings when there are acts of worship and prayer.\nThere are ecclesially accountable committees for co-ordinated preaching, youth and Sunday school work, conscientious objection issues, care of the elderly, and humanitarian work. These do not have any legislative authority, and are wholly dependent upon ecclesial support. Ecclesias in an area may regularly hold joint activities combining youth groups, fellowship, preaching, and Bible study.\nChristadelphians refuse to participate in any military or police force because they are conscientious objectors (not to be confused with pacifists).\nThere is a strong emphasis on personal Bible reading and study and many Christadelphians use the Bible Companion to help them systematically read the Bible each year.\nHymnody and music.\nChristadelphian hymnody makes considerable use of the hymns of the Anglican and English Protestant traditions (even in US ecclesias the hymnody is typically more English than American). In many Christadelphian hymn books a sizeable proportion of hymns are drawn from the Scottish Psalter and non-Christadelphian hymn-writers including Isaac Watts, Charles Wesley, William Cowper and John Newton. Despite incorporating non-Christadelphian hymns however, Christadelphian hymnody preserves the essential teachings of the community.\nThe earliest hymn book published was the \"Sacred Melodist\" which was published by Benjamin Wilson in Geneva, Illinois in 1860. The next was the hymn book published for the use of \"Baptised Believers in the Kingdom of God\" (an early name for Christadelphians) by George Dowie in Edinburgh in 1864. In 1865 Robert Roberts published a collection of Scottish psalms and hymns called \"The Golden Harp\" (which was subtitled \"Psalms, Hymns, and Spiritual Songs, compiled for the use of Immersed Believers in 'The Things concerning the Kingdom of God and the Name of Jesus Christ). This was replaced only five years later by the first \"Christadelphian Hymn Book\" (1869), compiled by J. J. and A. Andrew, and this was revised and expanded in 1874, 1932 and 1964. A thorough revision by the Christadelphian Magazine and Publishing Association resulted in the latest (2002) edition which is almost universally used by English-speaking Christadelphian ecclesias. In addition some Christadelphian fellowships have published their own hymn books.\nSome ecclesias use the \"Praise the Lord\" songbook. It was produced with the aim of making contemporary songs which are consistent with Christadelphian theology more widely available. Another publication, the \"Worship\" book is a compilation of songs and hymns that have been composed only by members of the Christadelphian community. This book was produced with the aim of providing extra music for non-congregational music items within services (e.g. voluntaries, meditations, et cetera) but has been adopted by congregations worldwide and is now used to supplement congregational repertoire.\nIn the English-speaking world, worship is typically accompanied by organ or piano, though in recent years a few ecclesias have promoted the use of other instruments (e.g. strings, wind and brass as mentioned in the Psalms). This trend has also seen the emergence of some Christadelphian bands and the establishment of the Christadelphian Art Trust to support performing, visual and dramatic arts within the Christadelphian community.\nIn other countries, hymn books have been produced in local languages, sometimes resulting in styles of worship which reflect the local culture. It has been noted that Christadelphian hymnody has historically been a consistent witness to Christadelphian beliefs, and that hymnody occupies a significant role in the community."}
{"id": "7587", "revid": "2766075", "url": "https://en.wikipedia.org/wiki?curid=7587", "title": "Cable television", "text": "Cable television is a system of delivering television programming to consumers via radio frequency (RF) signals transmitted through coaxial cables, or in more recent systems, light pulses through fibre-optic cables. This contrasts with broadcast television, in which the television signal is transmitted over-the-air by radio waves and received by a television antenna, or satellite television, in which the television signal is transmitted over-the-air by radio waves from a communications satellite and received by a satellite dish on the roof. FM radio programming, high-speed Internet, telephone services, and similar non-television services may also be provided through these cables. Analog television was standard in the 20th century, but since the 2000s, cable systems have been upgraded to digital cable operation.\nA cable channel (sometimes known as a cable network) is a television network available via cable television. Many of the same channels are distributed through satellite television. Alternative terms include \"non-broadcast channel\" or \"programming service\", the latter being mainly used in legal contexts. The abbreviation CATV is used in the US for cable television and originally stood for community antenna television, from cable television's origins in 1948; in areas where over-the-air TV reception was limited by distance from transmitters or mountainous terrain, large \"community antennas\" were constructed, and cable was run from them to individual homes.\nIn 1968, 6.4% of Americans had cable television. The number increased to 7.5% in 1978. By 1988, 52.8% of all households were using cable. The number further increased to 62.4% in 1994.\nDistribution.\nTo receive cable television at a given location, cable distribution lines must be available on the local utility poles or underground utility lines. Coaxial cable brings the signal to the customer's building through a service drop, an overhead or underground cable. If the subscriber's building does not have a cable service drop, the cable company will install one. The standard cable used in the U.S. is RG-6, which has a 75 ohm impedance, and connects with a type F connector. The cable company's portion of the wiring usually ends at a distribution box on the building exterior, and built-in cable wiring in the walls usually distributes the signal to jacks in different rooms to which televisions are connected. Multiple cables to different rooms are split off the incoming cable with a small device called a splitter. There are two standards for cable television; older analog cable, and newer digital cable which can carry data signals used by digital television receivers such as high-definition television (HDTV) equipment. All cable companies in the United States have switched to or are in the course of switching to digital cable television since it was first introduced in the late 1990s.\nMost cable companies require a set-top box (cable converter box) or a slot on one's TV set for conditional access module cards to view their cable channels, even on newer televisions with digital cable QAM tuners, because most digital cable channels are now encrypted, or \"scrambled\", to reduce cable service theft. A cable from the jack in the wall is attached to the input of the box, and an output cable from the box is attached to the television, usually the RF-IN or composite input on older TVs. Since the set-top box only decodes the single channel that is being watched, each television in the house requires a separate box. Some unencrypted channels, usually traditional over-the-air broadcast networks, can be displayed without a receiver box. The cable company will provide set-top boxes based on the level of service a customer purchases, from basic set-top boxes with a standard-definition picture connected through the standard coaxial connection on the TV, to high-definition wireless digital video recorder (DVR) receivers connected via HDMI or component. Older analog television sets are \"cable ready\" and can receive the old analog cable without a set-top box. To receive digital cable channels on an analog television set, even unencrypted ones, requires a different type of box, a digital television adapter supplied by the cable company or purchased by the subscriber. Another new distribution method that takes advantage of the low cost high quality DVB distribution to residential areas, uses TV gateways to convert the DVB-C, DVB-C2 stream to IP for distribution of TV over IP network in the home. Many cable companies offer internet access through DOCSIS.\nPrinciple of operation.\nIn the most common system, multiple television channels (as many as 500, although this varies depending on the provider's available channel capacity) are distributed to subscriber residences through a coaxial cable, which comes from a trunkline supported on utility poles originating at the cable company's local distribution facility, called the headend. Many channels can be transmitted through one coaxial cable by a technique called frequency division multiplexing. At the headend, each television channel is translated to a different frequency. By giving each channel a different frequency \"slot\" on the cable, the separate television signals do not interfere with each other. At an outdoor cable box on the subscriber's residence, the company's service drop cable is connected to cables distributing the signal to different rooms in the building. At each television, the subscriber's television or a set-top box provided by the cable company translates the desired channel back to its original frequency (baseband), and it is displayed onscreen. Due to widespread cable theft in earlier analog systems, the signals are typically encrypted on modern digital cable systems, and the set-top box must be activated by an activation code sent by the cable company before it will function, which is only sent after the subscriber signs up. If the subscriber fails to pay their bill, the cable company can send a signal to deactivate the subscriber's box, preventing reception.\nThere are also usually upstream channels on the cable to send data from the customer box to the cable headend, for advanced features such as requesting pay-per-view shows or movies, cable internet access, and cable telephone service. The downstream channels occupy a band of frequencies from approximately 50\u00a0MHz to 1\u00a0GHz, while the upstream channels occupy frequencies of 5 to 42\u00a0MHz. Subscribers pay with a monthly fee. Subscribers can choose from several levels of service, with premium packages including more channels but costing a higher rate. At the local headend, the feed signals from the individual television channels are received by dish antennas from communication satellites. Additional local channels, such as local broadcast television stations, educational channels from local colleges, and community access channels devoted to local governments (PEG channels) are usually included on the cable service. Commercial advertisements for local business are also inserted in the programming at the headend (the individual channels, which are distributed nationally, also have their own nationally oriented commercials).\nHybrid fiber-coaxial.\nModern cable systems are large, with a single network and headend often serving an entire metropolitan area. Most systems use hybrid fiber-coaxial (HFC) distribution; this means the trunklines that carry the signal from the headend to local neighborhoods are optical fiber to provide greater bandwidth and also extra capacity for future expansion. At the headend, the electrical signal is translated into an optical signal and sent through the fiber. The fiber trunkline goes to several \"distribution hubs\", from which multiple fibers fan out to carry the signal to boxes called \"optical nodes\" in local communities. At the optical node, the optical signal is translated back into an electrical signal and carried by coaxial cable distribution lines on utility poles, from which cables branch out to a series of signal amplifiers and line extenders. These devices carry the signal to customers via passive RF devices called taps.\nHistory.\nThe very first cable networks were operated locally, notably in 1936 by Rediffusion in London in the United Kingdom and the same year in Berlin in Germany, notably for the Olympic Games, and from 1948 onwards in the United States and Switzerland. This type of local cable network was mainly used to relay terrestrial channels in geographical areas poorly served by terrestrial television signals.\nIn the United States.\nCable television began in the United States as a commercial business in 1950s.\nThe early systems simply received weak (broadcast) channels, amplified them, and sent them over unshielded wires to the subscribers, limited to a community or to adjacent communities. The receiving antenna would be taller than any individual subscriber could afford, thus bringing in stronger signals; in hilly or mountainous terrain it would be placed at a high elevation.\nAt the outset, cable systems only served smaller communities without television stations of their own, and which could not easily receive signals from stations in cities because of distance or hilly terrain. In Canada, however, communities with their own signals were fertile cable markets, as viewers wanted to receive American signals. Rarely, as in the college town of Alfred, New York, U.S. cable systems retransmitted Canadian channels.\nAlthough early (VHF) television receivers could receive 12 channels (2\u201313), the maximum number of channels that could be broadcast in one city was 7: channels 2, 4, either 5 or 6, 7, 9, 11 and 13, as receivers at the time were unable to receive strong (local) signals on adjacent channels without distortion. (There were frequency gaps between 4 and 5, and between 6 and 7, which allowed both to be used in the same city).\nAs equipment improved, all twelve channels could be utilized, except where a local VHF television station broadcast. Local broadcast channels were not usable for signals deemed to be a priority, but technology allowed low-priority signals to be placed on such channels by synchronizing their blanking intervals. TVs were unable to reconcile these blanking intervals and the slight changes due to travel through a medium, causing ghosting. The bandwidth of the amplifiers also was limited, meaning frequencies over 250\u00a0MHz were difficult to transmit to distant portions of the coaxial network, and UHF channels could not be used at all. To expand beyond 12 channels, non-standard \"midband\" channels had to be used, located between the FM band and Channel 7, or \"superband\" beyond Channel 13 up to about 300\u00a0MHz; these channels initially were only accessible using separate tuner boxes that sent the chosen channel into the TV set on Channel 2, 3 or 4. Initially, UHF broadcast stations were at a disadvantage because the standard TV sets in use at the time were unable to receive their channels. With the passage of the All-Channel Receiver Act in 1964, all new television sets were required to include a UHF tuner, nonetheless, it would still take a few years for UHF stations to become competitive.\nBefore being added to the cable box itself, these midband channels were used for early incarnations of pay TV, e.g. The Z Channel (Los Angeles) and HBO but transmitted in the clear i.e. not scrambled as standard TV sets of the period could not pick up the signal nor could the average consumer \"de-tune\" the normal stations to be able to receive it.\nOnce tuners that could receive select mid-band and super-band channels began to be incorporated into standard television sets, broadcasters were forced to either install scrambling circuitry or move these signals further out of the range of reception for early cable-ready TVs and VCRs. However, once consumer sets had the ability to receive all 181 FCC allocated channels, premium broadcasters were left with no choice but to scramble.\nThe descrambling circuitry was often published in electronics hobby magazines such as \"Popular Science\" and \"Popular Electronics\" allowing anybody with anything more than a rudimentary knowledge of broadcast electronics to be able to build their own and receive the programming without cost.\nLater, the cable operators began to carry FM radio stations, and encouraged subscribers to connect their FM stereo sets to cable. Before stereo and bilingual TV sound became common, Pay-TV channel sound was added to the FM stereo cable line-ups. About this time, operators expanded beyond the 12-channel dial to use the \"midband\" and \"superband\" VHF channels adjacent to the \"high band\" 7\u201313 of North American television frequencies. Some operators as in Cornwall, Ontario, used a dual distribution network with Channels 2\u201313 on each of the two cables.\nDuring the 1980s, United States regulations not unlike public, educational, and government access (PEG) created the beginning of cable-originated live television programming. As cable penetration increased, numerous cable-only TV stations were launched, many with their own news bureaus that could provide more immediate and more localized content than that provided by the nearest network newscast.\nSuch stations may use similar on-air branding as that used by the nearby broadcast network affiliate, but the fact that these stations do not broadcast over the air and are not regulated by the FCC, their call signs are meaningless. These stations evolved partially into today's over-the-air digital subchannels, where a main broadcast TV station e.g. NBC 37* would \u2013 in the case of no local CBS or ABC station being available \u2013 rebroadcast the programming from a nearby affiliate but fill in with its own news and other community programming to suit its own locale. Many live local programs with local interests were subsequently created all over the United States in most major television markets in the early 1980s.\nThis evolved into today's many cable-only broadcasts of diverse programming, including cable-only produced television movies and miniseries. Cable specialty channels, starting with channels oriented to show movies and large sporting or performance events, diversified further, and narrowcasting became common. By the late 1980s, cable-only signals outnumbered broadcast signals on cable systems, some of which by this time had expanded beyond 35 channels. By the mid-1980s in Canada, cable operators were allowed by the regulators to enter into distribution contracts with cable networks on their own.\nBy the 1990s, tiers became common, with customers able to subscribe to different tiers to obtain different selections of additional channels above the basic selection. By subscribing to additional tiers, customers could get specialty channels, movie channels, and foreign channels. Large cable companies used addressable descramblers to limit access to premium channels for customers not subscribing to higher tiers, however the above magazines often published workarounds for that technology as well.\nDuring the 1990s, the pressure to accommodate the growing array of offerings resulted in digital transmission that made more efficient use of the VHF signal capacity; fibre optics was common to carry signals into areas near the home, where coax could carry higher frequencies over the short remaining distance. Although for a time in the 1980s and 1990s, television receivers and VCRs were equipped to receive the mid-band and super-band channels. Due to the fact that the descrambling circuitry was for a time present in these tuners, depriving the cable operator of much of their revenue, such cable-ready tuners are rarely used now \u2013 requiring a return to the set-top boxes used from the 1970s onward.\nThe digital television transition in the United States has put all signals, broadcast and cable, into digital form, rendering analog cable television service a rarity, found in an ever-dwindling number of markets. Analog television sets are accommodated, their tuners mostly obsolete and dependent entirely on the set-top box.\nDeployments by continent.\nCable television is mostly available in North America, Europe, Australia, Asia and South America. Cable television has had little success in Africa, as it is not cost-effective to lay cables in sparsely populated areas. Multichannel multipoint distribution service, a microwave-based system, may be used instead.\nOther cable-based services.\nCoaxial cables are capable of bi-directional carriage of signals as well as the transmission of large amounts of data. Cable television signals use only a portion of the bandwidth available over coaxial lines. This leaves plenty of space available for other digital services such as cable internet, cable telephony and wireless services, using both unlicensed and licensed spectra. Broadband internet access is achieved over coaxial cable by using cable modems to convert the network data into a type of digital signal that can be transferred over coaxial cable. One problem with some cable systems is the older amplifiers placed along the cable routes are unidirectional thus in order to allow for uploading of data the customer would need to use an analog telephone modem to provide for the upstream connection. This limited the upstream speed to 31.2 Kbp/s and prevented the always-on convenience broadband internet typically provides. Many large cable systems have upgraded or are upgrading their equipment to allow for bi-directional signals, thus allowing for greater upload speed and always-on convenience, though these upgrades are expensive.\nIn North America, Australia and Europe, many cable operators have already introduced cable telephone service, which operates just like existing fixed line operators. This service involves installing a special telephone interface at the customer's premises that converts the analog signals from the customer's in-home wiring into a digital signal, which is then sent on the local loop (replacing the analog last mile, or plain old telephone service (POTS) to the company's switching center, where it is connected to the public switched telephone network (PSTN). The biggest obstacle to cable telephone service is the need for nearly 100% reliable service for emergency calls. One of the standards available for digital cable telephony, PacketCable, seems to be the most promising and able to work with the quality of service (QOS) demands of traditional analog plain old telephone service (POTS) service. The biggest advantage to digital cable telephone service is similar to the advantage of digital cable, namely that data can be compressed, resulting in much less bandwidth used than a dedicated analog circuit-switched service. Other advantages include better voice quality and integration to a Voice over Internet Protocol (VoIP) network providing cheap or unlimited nationwide and international calling. In many cases, digital cable telephone service is separate from cable modem service being offered by many cable companies and does not rely on Internet Protocol (IP) traffic or the Internet.\nTraditional cable television providers and traditional telecommunication companies increasingly compete in providing voice, video and data services to residences. The combination of television, telephone and Internet access is commonly called \"triple play\", regardless of whether CATV or telcos offer it."}
{"id": "7588", "revid": "4977632", "url": "https://en.wikipedia.org/wiki?curid=7588", "title": "Charles S. Peirce", "text": ""}
{"id": "7591", "revid": "21112944", "url": "https://en.wikipedia.org/wiki?curid=7591", "title": "Cholera", "text": "Cholera () is an infection of the small intestine by some strains of the bacterium \"Vibrio cholerae\". Symptoms may range from none, to mild, to severe. The classic symptom is large amounts of watery diarrhea lasting a few days. Vomiting and muscle cramps may also occur. Diarrhea can be so severe that it leads within hours to severe dehydration and electrolyte imbalance. This may result in sunken eyes, cold skin, decreased skin elasticity, and wrinkling of the hands and feet. Dehydration can cause the skin to turn bluish. Symptoms start two hours to five days after exposure.\nCholera is caused by a number of types of \"Vibrio cholerae\", with some types producing more severe disease than others. It is spread mostly by unsafe water and unsafe food that has been contaminated with human feces containing the bacteria. Undercooked shellfish is a common source. Humans are the only known host for the bacteria. Risk factors for the disease include poor sanitation, insufficient clean drinking water, and poverty. Cholera can be diagnosed by a stool test, or a rapid dipstick test, although the dipstick test is less accurate.\nPrevention methods against cholera include improved sanitation and access to clean water. Cholera vaccines that are given by mouth provide reasonable protection for about six months, and confer the added benefit of protecting against another type of diarrhea caused by \"E.\u00a0coli\". In 2017, the US Food and Drug Administration (FDA) approved a single-dose, live, oral cholera vaccine called Vaxchora for adults aged 18\u201364 who are travelling to an area of active cholera transmission. It offers limited protection to young children. People who survive an episode of cholera have long-lasting immunity for at least three years (the period tested).\nThe primary treatment for affected individuals is oral rehydration salts (ORS), the replacement of fluids and electrolytes by using slightly sweet and salty solutions. Rice-based solutions are preferred. In children, zinc supplementation has also been found to improve outcomes. In severe cases, intravenous fluids, such as Ringer's lactate, may be required, and antibiotics may be beneficial. The choice of antibiotic is aided by antibiotic sensitivity testing.\nCholera continues to affect an estimated 3\u20135\u00a0million people worldwide and causes 28,800\u2013130,000\u00a0deaths a year. To date, seven cholera pandemics have occurred, with the most recent beginning in 1961, and continuing today. The illness is rare in high-income countries, and affects children most severely. Cholera occurs as both outbreaks and chronically in certain areas. Areas with an ongoing risk of disease include Africa and Southeast Asia. The risk of death among those affected is usually less than 5%, given improved treatment, but may be as high as 50% without such access to treatment. Descriptions of cholera are found as early as the 5th century BCE in Sanskrit literature. In Europe, cholera was a term initially used to describe any kind of gastroenteritis, and was not used for this disease until the early 19th century. The study of cholera in England by John Snow between 1849 and 1854 led to significant advances in the field of epidemiology because of his insights about transmission via contaminated water, and a map of the same was the first recorded incidence of epidemiological tracking. \nSigns and symptoms.\nThe primary symptoms of cholera are profuse diarrhea and vomiting of clear fluid. These symptoms usually start suddenly, half a day to five days after ingestion of the bacteria. The diarrhea is frequently described as \"rice water\" in nature and may have a fishy odor. An untreated person with cholera may produce of diarrhea a day. Severe cholera, without treatment, kills about half of affected individuals. If the severe diarrhea is not treated, it can result in life-threatening dehydration and electrolyte imbalances. Estimates of the ratio of asymptomatic to symptomatic infections have ranged from 3 to 100. Cholera has been nicknamed the \"blue death\" because a person's skin may turn bluish-gray from extreme loss of fluids.\nFever is rare and should raise suspicion for secondary infection. Patients can be lethargic and might have sunken eyes, dry mouth, cold clammy skin, or wrinkled hands and feet. Kussmaul breathing, a deep and labored breathing pattern, can occur because of acidosis from stool bicarbonate losses and lactic acidosis associated with poor perfusion. Blood pressure drops due to dehydration, peripheral pulse is rapid and thready, and urine output decreases with time. Muscle cramping and weakness, altered consciousness, seizures, or even coma due to electrolyte imbalances are common, especially in children.\nCause.\nTransmission.\nCholera bacteria have been found in shellfish and plankton.\nTransmission is usually through the fecal-oral route of contaminated food or water caused by poor sanitation. Most cholera cases in developed countries are a result of transmission by food, while in developing countries it is more often water. Food transmission can occur when people harvest seafood such as oysters in waters infected with sewage, as \"Vibrio cholerae\" accumulates in planktonic crustaceans and the oysters eat the zooplankton.\nPeople infected with cholera often have diarrhea, and disease transmission may occur if this highly liquid stool, colloquially referred to as \"rice-water\", contaminates water used by others. A single diarrheal event can cause a one-million fold increase in numbers of \"V.\u00a0cholerae\" in the environment. The source of the contamination is typically other people with cholera when their untreated diarrheal discharge is allowed to get into waterways, groundwater or drinking water supplies. Drinking any contaminated water and eating any foods washed in the water, as well as shellfish living in the affected waterway, can cause a person to contract an infection. Cholera is rarely spread directly from person to person.\n\"V. cholerae\" also exists outside the human body in natural water sources, either by itself or through interacting with phytoplankton, zooplankton, or biotic and abiotic detritus. Drinking such water can also result in the disease, even without prior contamination through fecal matter. Selective pressures exist however in the aquatic environment that may reduce the virulence of \"V.\u00a0cholerae\". Specifically, animal models indicate that the transcriptional profile of the pathogen changes as it prepares to enter an aquatic environment. This transcriptional change results in a loss of ability of \"V.\u00a0cholerae\" to be cultured on standard media, a phenotype referred to as 'viable but non-culturable' (VBNC) or more conservatively 'active but non-culturable' (ABNC). One study indicates that the culturability of \"V.\u00a0cholerae\" drops 90% within 24 hours of entering the water, and furthermore that this loss in culturability is associated with a loss in virulence.\nBoth toxic and non-toxic strains exist. Non-toxic strains can acquire toxicity through a temperate bacteriophage.\nSusceptibility.\nAbout 100million bacteria must typically be ingested to cause cholera in a normal healthy adult. This dose, however, is less in those with lowered gastric acidity (for instance those using proton pump inhibitors). Children are also more susceptible, with two- to four-year-olds having the highest rates of infection. Individuals' susceptibility to cholera is also affected by their blood type, with those with type O blood being the most susceptible. Persons with lowered immunity, such as persons with AIDS or malnourished children, are more likely to develop a severe case if they become infected. Any individual, even a healthy adult in middle age, can undergo a severe case, and each person's case should be measured by the loss of fluids, preferably in consultation with a professional health care provider.\nThe cystic fibrosis genetic mutation known as delta-F508 in humans has been said to maintain a selective heterozygous advantage: heterozygous carriers of the mutation (who are not affected by cystic fibrosis) are more resistant to \"V.\u00a0cholerae\" infections. In this model, the genetic deficiency in the cystic fibrosis transmembrane conductance regulator channel proteins interferes with bacteria binding to the intestinal epithelium, thus reducing the effects of an infection.\nMechanism.\nWhen consumed, most bacteria do not survive the acidic conditions of the human stomach. The few surviving bacteria conserve their energy and stored nutrients during the passage through the stomach by shutting down protein production. When the surviving bacteria exit the stomach and reach the small intestine, they must propel themselves through the thick mucus that lines the small intestine to reach the intestinal walls where they can attach and thrive.\nOnce the cholera bacteria reach the intestinal wall, they no longer need the flagella to move. The bacteria stop producing the protein flagellin to conserve energy and nutrients by changing the mix of proteins that they express in response to the changed chemical surroundings. On reaching the intestinal wall, \"V.\u00a0cholerae\" start producing the toxic proteins that give the infected person a watery diarrhea. This carries the multiplying new generations of \"V.\u00a0cholerae\" bacteria out into the drinking water of the next host if proper sanitation measures are not in place.\nThe cholera toxin (CTX or CT) is an oligomeric complex made up of six protein subunits: a single copy of the A subunit (part A), and five copies of the B subunit (part B), connected by a disulfide bond. The five B subunits form a five-membered ring that binds to GM1 gangliosides on the surface of the intestinal epithelium cells. The A1 portion of the A subunit is an enzyme that ADP-ribosylates G proteins, while the A2 chain fits into the central pore of the B subunit ring. Upon binding, the complex is taken into the cell via receptor-mediated endocytosis. Once inside the cell, the disulfide bond is reduced, and the A1 subunit is freed to bind with a human partner protein called ADP-ribosylation factor 6 (Arf6). Binding exposes its active site, allowing it to permanently ribosylate the Gs alpha subunit of the heterotrimeric G protein. This results in constitutive cAMP production, which in turn leads to the secretion of water, sodium, potassium, and bicarbonate into the lumen of the small intestine and rapid dehydration. The gene encoding the cholera toxin was introduced into \"V.\u00a0cholerae\" by horizontal gene transfer. Virulent strains of \"V.\u00a0cholerae\" carry a variant of a temperate bacteriophage called CTX\u03c6.\nMicrobiologists have studied the genetic mechanisms by which the \"V.\u00a0cholerae\" bacteria turn off the production of some proteins and turn on the production of other proteins as they respond to the series of chemical environments they encounter, passing through the stomach, through the mucous layer of the small intestine, and on to the intestinal wall. Of particular interest have been the genetic mechanisms by which cholera bacteria turn on the protein production of the toxins that interact with host cell mechanisms to pump chloride ions into the small intestine, creating an ionic pressure which prevents sodium ions from entering the cell. The chloride and sodium ions create a salt-water environment in the small intestines, which through osmosis can pull up to six liters of water per day through the intestinal cells, creating the massive amounts of diarrhea. The host can become rapidly dehydrated unless treated properly.\nBy inserting separate, successive sections of \"V.\u00a0cholerae\" DNA into the DNA of other bacteria, such as \"E. coli\" that would not naturally produce the protein toxins, researchers have investigated the mechanisms by which \"V.\u00a0cholerae\" responds to the changing chemical environments of the stomach, mucous layers, and intestinal wall. Researchers have discovered a complex cascade of regulatory proteins controls expression of \"V.\u00a0cholerae\" virulence determinants. In responding to the chemical environment at the intestinal wall, the \"V.\u00a0cholerae\" bacteria produce the TcpP/TcpH proteins, which, together with the ToxR/ToxS proteins, activate the expression of the ToxT regulatory protein. ToxT then directly activates expression of virulence genes that produce the toxins, causing diarrhea in the infected person and allowing the bacteria to colonize the intestine. Current research aims at discovering \"the signal that makes the cholera bacteria stop swimming and start to colonize (that is, adhere to the cells of) the small intestine.\"\nGenetic structure.\nAmplified fragment length polymorphism fingerprinting of the pandemic isolates of \"V.\u00a0cholerae\" has revealed variation in the genetic structure. Two clusters have been identified: Cluster I and Cluster II. For the most part, Cluster I consists of strains from the 1960s and 1970s, while Cluster II largely contains strains from the 1980s and 1990s, based on the change in the clone structure. This grouping of strains is best seen in the strains from the African continent.\nAntibiotic resistance.\nIn many areas of the world, antibiotic resistance is increasing within cholera bacteria. In Bangladesh, for example, most cases are resistant to tetracycline, trimethoprim-sulfamethoxazole, and erythromycin. Rapid diagnostic assay methods are available for the identification of multi-drug resistant cases. New generation antimicrobials have been discovered which are effective against cholera bacteria in \"in vitro\" studies.\nDiagnosis.\nA rapid dipstick test is available to determine the presence of \"V.\u00a0cholerae\". In those samples that test positive, further testing should be done to determine antibiotic resistance. In epidemic situations, a clinical diagnosis may be made by taking a patient history and doing a brief examination. Treatment via hydration and over-the-counter hydration solutions can be started without or before confirmation by laboratory analysis, especially where cholera is a common problem.\nStool and swab samples collected in the acute stage of the disease, before antibiotics have been administered, are the most useful specimens for laboratory diagnosis. If an epidemic of cholera is suspected, the most common causative agent is \"V.\u00a0cholerae\" O1. If \"V.\u00a0cholerae\" serogroup O1 is not isolated, the laboratory should test for \"V.\u00a0cholerae\" O139. However, if neither of these organisms is isolated, it is necessary to send stool specimens to a reference laboratory.\nInfection with \"V.\u00a0cholerae\" O139 should be reported and handled in the same manner as that caused by \"V.\u00a0cholerae\" O1. The associated diarrheal illness should be referred to as cholera and must be reported in the United States.\nPrevention.\nThe World Health Organization (WHO) recommends focusing on prevention, preparedness, and response to combat the spread of cholera. They also stress the importance of an effective surveillance system. Governments can play a role in all of these areas.\nWater, sanitation and hygiene.\nAlthough cholera may be life-threatening, prevention of the disease is normally straightforward if proper sanitation practices are followed. In developed countries, due to their nearly universal advanced water treatment and sanitation practices, cholera is rare. For example, the last major outbreak of cholera in the United States occurred in 1910\u20131911. Cholera is mainly a risk in developing countries in those areas where access to WASH (water, sanitation and hygiene) infrastructure is still inadequate.\nEffective sanitation practices, if instituted and adhered to in time, are usually sufficient to stop an epidemic. There are several points along the cholera transmission path at which its spread may be halted:\nHandwashing with soap or ash after using a toilet and before handling food or eating is also recommended for cholera prevention by WHO Africa.\nSurveillance.\nSurveillance and prompt reporting allow for containing cholera epidemics rapidly. Cholera exists as a seasonal disease in many endemic countries, occurring annually mostly during rainy seasons. Surveillance systems can provide early alerts to outbreaks, therefore leading to coordinated response and assist in preparation of preparedness plans. Efficient surveillance systems can also improve the risk assessment for potential cholera outbreaks. Understanding the seasonality and location of outbreaks provides guidance for improving cholera control activities for the most vulnerable. For prevention to be effective, it is important that cases be reported to national health authorities.\nVaccination.\nSpanish physician Jaume Ferran i Clua developed the first successful cholera inoculation in 1885, the first to immunize humans against a bacterial disease. His vaccine and inoculation was rather controversial and was rejected by his peers and several investigation commissions but it ended up demonstrating its effectiveness and being recognized for it: out of the 30 thousand people he vaccinated only 54 died. Russian-Jewish bacteriologist Waldemar Haffkine also developed a human cholera vaccine in July 1892. He conducted a massive inoculation program in British India.\nPersons who survive an episode of cholera have long-lasting immunity for at least 3 years (the period tested). A number of safe and effective oral vaccines for cholera are available. The World Health Organization (WHO) has three prequalified oral cholera vaccines (OCVs): Dukoral, Sanchol, and Euvichol. Dukoral, an orally administered, inactivated whole-cell vaccine, has an overall efficacy of about 52% during the first year after being given and 62% in the second year, with minimal side effects. It is available in over 60 countries. However, it is not currently recommended by the Centers for Disease Control and Prevention (CDC) for most people traveling from the United States to endemic countries. The vaccine that the US Food and Drug Administration (FDA) recommends, Vaxchora, is an oral attenuated live vaccine, that is effective for adults aged 18\u201364 as a single dose.\nOne injectable vaccine was found to be effective for two to three years. The protective efficacy was 28% lower in children less than five years old. However, , it has limited availability. Work is under way to investigate the role of mass vaccination. The WHO recommends immunization of high-risk groups, such as children and people with HIV, in countries where this disease is endemic. If people are immunized broadly, herd immunity results, with a decrease in the amount of contamination in the environment.\nWHO recommends that oral cholera vaccination be considered in areas where the disease is endemic (with seasonal peaks), as part of the response to outbreaks, or in a humanitarian crisis during which the risk of cholera is high. OCV has been recognized as an adjunct tool for prevention and control of cholera. The WHO has prequalified three bivalent cholera vaccines\u2014Dukoral (SBL Vaccines), containing a non-toxic B-subunit of cholera toxin and providing protection against \"V.\u00a0cholerae\" O1; and two vaccines developed using the same transfer of technology\u2014ShanChol (Shantha Biotec) and Euvichol (EuBiologics Co.), which have bivalent O1 and O139 oral killed cholera vaccines. Oral cholera vaccination could be deployed in a diverse range of situations from cholera-endemic areas and locations of humanitarian crises, but no clear consensus exists.\nSari filtration.\nDeveloped for use in Bangladesh, the \"sari filter\" is a simple and cost-effective appropriate technology method for reducing the contamination of drinking water. Used sari cloth is preferable but other types of used cloth can be used with some effect, though the effectiveness will vary significantly. Used cloth is more effective than new cloth, as the repeated washing reduces the space between the fibers. Water collected in this way has a greatly reduced pathogen count\u2014though it will not necessarily be perfectly safe, it is an improvement for poor people with limited options. In Bangladesh this practice was found to decrease rates of cholera by nearly half. It involves folding a \"sari\" four to eight times. Between uses the cloth should be rinsed in clean water and dried in the sun to kill any bacteria on it. A nylon cloth appears to work as well but is not as affordable.\nTreatment.\nContinued eating speeds the recovery of normal intestinal function. The WHO recommends this generally for cases of diarrhea no matter what the underlying cause. A CDC training manual specifically for cholera states: \"Continue to breastfeed your baby if the baby has watery diarrhea, even when traveling to get treatment. Adults and older children should continue to eat frequently.\"\nFluids.\nThe most common error in caring for patients with cholera is to underestimate the speed\nand volume of fluids required. In most cases, cholera can be successfully treated with oral rehydration therapy (ORT), which is highly effective, safe, and simple to administer. Rice-based solutions are preferred to glucose-based ones due to greater efficiency. In severe cases with significant dehydration, intravenous rehydration may be necessary. Ringer's lactate is the preferred solution, often with added potassium. Large volumes and continued replacement until diarrhea has subsided may be needed. Ten percent of a person's body weight in fluid may need to be given in the first two to four hours. This method was first tried on a mass scale during the Bangladesh Liberation War, and was found to have much success. Despite widespread beliefs, fruit juices and commercial fizzy drinks like cola are not ideal for rehydration of people with serious infections of the intestines, and their excessive sugar content may even harm water uptake.\nIf commercially produced oral rehydration solutions are too expensive or difficult to obtain, solutions can be made. One such recipe calls for 1 liter of boiled water, 1/2 teaspoon of salt, 6 teaspoons of sugar, and added mashed banana for potassium and to improve taste.\nElectrolytes.\nAs there frequently is initially acidosis, the potassium level may be normal, even though large losses have occurred. As the dehydration is corrected, potassium levels may decrease rapidly, and thus need to be replaced. This is best done by Oral Rehydration Solution (ORS).\nAntibiotics.\nAntibiotic treatments for one to three days shorten the course of the disease and reduce the severity of the symptoms. Use of antibiotics also reduces fluid requirements. People will recover without them, however, if sufficient hydration is maintained. The WHO only recommends antibiotics in those with severe dehydration.\nDoxycycline is typically used first line, although some strains of \"V.\u00a0cholerae\" have shown resistance. Testing for resistance during an outbreak can help determine appropriate future choices. Other antibiotics proven to be effective include cotrimoxazole, erythromycin, tetracycline, chloramphenicol, and furazolidone. Fluoroquinolones, such as ciprofloxacin, also may be used, but resistance has been reported.\nAntibiotics improve outcomes in those who are both severely and not severely dehydrated. Azithromycin and tetracycline may work better than doxycycline or ciprofloxacin.\nZinc supplementation.\nIn Bangladesh zinc supplementation reduced the duration and severity of diarrhea in children with cholera when given with antibiotics and rehydration therapy as needed. It reduced the length of disease by eight hours and the amount of diarrhea stool by 10%. Supplementation appears to be also effective in both treating and preventing infectious diarrhea due to other causes among children in the developing world.\nPrognosis.\nIf people with cholera are treated quickly and properly, the mortality rate is less than 1%; however, with untreated cholera, the mortality rate rises to 50\u201360%.\nFor certain genetic strains of cholera, such as the one present during the 2010 epidemic in Haiti and the 2004 outbreak in India, death can occur within two hours of becoming ill.\nEpidemiology.\nCholera affects an estimated 2.8\u00a0million people worldwide, and causes approximately 95,000\u00a0deaths a year (uncertainty range: 21,000\u2013143,000) . This occurs mainly in the developing world.\nIn the early 1980s, death rates are believed to have still been higher than three million a year. It is difficult to calculate exact numbers of cases, as many go unreported due to concerns that an outbreak may have a negative impact on the tourism of a country. As of 2004, cholera remained both epidemic and endemic in many areas of the world.\nRecent major outbreaks are the 2010s Haiti cholera outbreak and the 2016\u20132022 Yemen cholera outbreak. In October 2016, an outbreak of cholera began in war-ravaged Yemen. WHO called it \"the worst cholera outbreak in the world\". In 2019, 93% of the reported 923,037 cholera cases were from Yemen (with 1911 deaths reported). Between September 2019 and September 2020, a global total of over 450,000 cases and over 900 deaths was reported; however, the accuracy of these numbers suffer from over-reporting from countries that report suspected cases (and not laboratory confirmed cases), as well as under-reporting from countries that do not report official cases (such as Bangladesh, India and Philippines).\nAlthough much is known about the mechanisms behind the spread of cholera, researchers still do not have a full understanding of what makes cholera outbreaks happen in some places and not others. Lack of treatment of human feces and lack of treatment of drinking water greatly facilitate its spread. Bodies of water have been found to serve as a reservoir of infection, and seafood shipped long distances can spread the disease.\nCholera had disappeared from the Americas for most of the 20th century, but it reappeared toward the end of that century, beginning with a severe outbreak in Peru. This was followed by the 2010s Haiti cholera outbreak and another outbreak of cholera in Haiti amid the 2018\u20132023 Haitian crisis. the disease is endemic in Africa and some areas of eastern and western Asia (Bangladesh, India and Yemen). Cholera is not endemic in Europe; all reported cases had a travel history to endemic areas.\nHistory of outbreaks.\nThe word cholera is from \"kholera\" from \u03c7\u03bf\u03bb\u03ae \"khol\u0113\" \"bile\". Cholera likely has its origins in the Indian subcontinent as evidenced by its prevalence in the region for centuries.\nReferences to cholera appear in the European literature as early as 1642, from the Dutch physician Jakob de Bondt's description in his De Medicina Indorum. (The \"Indorum\" of the title refers to the East Indies. He also gave first European descriptions of other diseases.) But at the time, the word \"cholera\" was historically used by European physicians to refer to any gastrointestinal upset resulting in yellow diarrhea. De Bondt thus used a common word already in regular use to describe the new disease. This was a frequent practice of the time. It was not until the 1830s that the name for severe yellow diarrhea changed in English from \"cholera\" to \"cholera morbus\" to differentiate it from what was then known as \"Asiatic cholera\", or that associated with origins in India and the East.\nEarly outbreaks in the Indian subcontinent are believed to have been the result of crowded, poor living conditions, as well as the presence of pools of still water, both of which provide ideal conditions for cholera to thrive. The disease first spread by travelers along trade routes (land and sea) to Russia in 1817, later to the rest of Europe, and from Europe to North America and the rest of the world, (hence the name \"Asiatic cholera\"). Seven cholera pandemics have occurred since the early 19th century; the first one did not reach the Americas. The seventh pandemic originated in Indonesia in 1961.\nThe first cholera pandemic occurred in the Bengal region of India, near Calcutta starting in 1817 through 1824. The disease dispersed from India to Southeast Asia, the Middle East, Europe, and Eastern Africa. The movement of British Army and Navy ships and personnel is believed to have contributed to the range of the pandemic, since the ships carried people with the disease to the shores of the Indian Ocean, from Africa to Indonesia, and north to China and Japan.\nThe second pandemic lasted from 1826 to 1837 and particularly affected North America and Europe. Advancements in transport and global trade, and increased human migration, including soldiers, meant that more people were carrying the disease more widely.\nThe third pandemic erupted in 1846, persisted until 1860, extended to North Africa, and reached North and South America. It was introduced to North America at Quebec, Canada, via Irish immigrants from the Great Famine. In this pandemic, Brazil was affected for the first time.\nThe fourth pandemic lasted from 1863 to 1875, spreading from India to Naples and Spain, and reaching the United States at New Orleans, Louisiana in 1873. It spread throughout the Mississippi River system on the continent.\nThe fifth pandemic was from 1881 to 1896. It started in India and spread to Europe, Asia, and South America. The sixth pandemic ran from 1899 to 1923. These epidemics had a lower number of fatalities because physicians and researchers had a greater understanding of the cholera bacteria. Egypt, the Arabian peninsula, Persia, India, and the Philippines were hit hardest during these epidemics. Other areas, such as Germany in 1892 (primarily the city of Hamburg, where more than 8.600 people died) and Naples from 1910 to 1911, also had severe outbreaks.\nThe seventh pandemic originated in 1961 in Indonesia and is marked by the emergence of a new strain, nicknamed \"El Tor\", which still persists () in developing countries. This pandemic had initially subsided about 1975 and was thought to have ended, but, as noted, it has persisted. There were a rise in cases in the 1990s and since.\nCholera became widespread in the 19th century. Since then it has killed tens of millions of people. In Russia alone, between 1847 and 1851, more than one million people died from the disease. It killed 150,000 Americans during the second pandemic. Between 1900 and 1920, perhaps eight million people died of cholera in India. Cholera officially became the first reportable disease in the United States due to the significant effects it had on health. John Snow, in England, in 1854 was the first to identify the importance of contaminated water as its source of transmission. Cholera is now no longer considered a pressing health threat in Europe and North America due to filtering and chlorination of water supplies, but it still strongly affects populations in developing countries.\nIn the past, vessels flew a yellow quarantine flag if any crew members or passengers had cholera. No one aboard a vessel flying a yellow flag would be allowed ashore for an extended period, typically 30 to 40 days.\nHistorically many different claimed remedies have existed in folklore. Many of the older remedies were based on the miasma theory, that the disease was transmitted by bad air. Some believed that abdominal chilling made one more susceptible, and flannel and cholera belts were included in army kits. In the 1854\u20131855 outbreak in Naples, homeopathic camphor was used according to Hahnemann. Dr. Hahnemann laid down three main remedies that would be curative in that disease; in early and simple cases camphor; in later stages with excessive cramping, cuprum or with excessive evacuations and profuse cold sweat, veratrum album. These are the Trio Cholera remedies used by homoeopaths around the world.\nT. J. Ritter's \"Mother's Remedies\" book lists tomato syrup as a home remedy from northern America. Elecampane was recommended in the United Kingdom, according to William Thomas Fernie. The first effective human vaccine was developed in 1885, and the first effective antibiotic was developed in 1948.\nCholera cases are much less frequent in developed countries where governments have helped to establish water sanitation practices and effective medical treatments. In the 19th century the United States, for example, had a severe cholera problem similar to those in some developing countries. It had three large cholera outbreaks in the 1800s, which can be attributed to \"Vibrio cholerae\" spread through interior waterways such as the Erie Canal and the extensive Mississippi River valley system, as well as the major ports along the Eastern Seaboard and their cities upriver. The island of Manhattan in New York City touches the Atlantic Ocean, where cholera collected from river waters and ship discharges just off the coast. At this time, New York City did not have as effective a sanitation system as it developed in the later 20th century, so cholera spread through the city's water supply.\nCholera morbus is a historical term that was used to refer to gastroenteritis rather than specifically to what is now defined as the disease of cholera.\nResearch.\nOne of the major contributions to fighting cholera was made by the physician and pioneer medical scientist John Snow (1813\u20131858), who in 1854 found a link between cholera and contaminated drinking water. Dr. Snow proposed a microbial origin for epidemic cholera in 1849. In his major \"state of the art\" review of 1855, he proposed a substantially complete and correct model for the cause of the disease. In two pioneering epidemiological field studies, he was able to demonstrate human sewage contamination was the most probable disease vector in two major epidemics in London in 1854. His model was not immediately accepted, but it was increasingly seen as plausible as medical microbiology developed over the next 30 years or so. For his work on cholera, John Snow is often regarded as the \"Father of Epidemiology\".\nThe bacterium was isolated in 1854 by Italian anatomist Filippo Pacini, but its exact nature and his results were not widely known. In the same year, the Catalan Joaquim Balcells i Pascual discovered the bacterium. In 1856 Ant\u00f3nio Augusto da Costa Sim\u00f5es and Jos\u00e9 Ferreira de Macedo Pinto, two Portuguese researchers, are believed to have done the same.\nBetween the mid-1850s and the 1900s, cities in developed nations made massive investment in clean water supply and well-separated sewage treatment infrastructures. This eliminated the threat of cholera epidemics from the major developed cities in the world. In 1883, Robert Koch identified \"V.\u00a0cholerae\" with a microscope as the bacillus causing the disease.\nHemendra Nath Chatterjee, a Bengali scientist, was the first to formulate and demonstrate the effectiveness of oral rehydration salt (ORS) to treat diarrhea. In his 1953 paper, published in \"The Lancet\", he states that promethazine can stop vomiting during cholera and then oral rehydration is possible. The formulation of the fluid replacement solution was 4\u00a0g of sodium chloride, 25\u00a0g of glucose and 1000\u00a0ml of water.\nIndian medical scientist Sambhu Nath De discovered the cholera toxin, the \"animal model of cholera\", and successfully demonstrated the method of transmission of cholera pathogen \"Vibrio cholerae\".\nRobert Allan Phillips, working at US Naval Medical Research Unit Two in Southeast Asia, evaluated the pathophysiology of the disease using modern laboratory chemistry techniques. He developed a protocol for rehydration. His research led the Lasker Foundation to award him its prize in 1967.\nMore recently, in 2002, Alam, \"et al.\", studied stool samples from patients at the International Centre for Diarrhoeal Disease in Dhaka, Bangladesh. From the various experiments they conducted, the researchers found a correlation between the passage of \"V.\u00a0cholerae\" through the human digestive system and an increased infectivity state. Furthermore, the researchers found the bacterium creates a hyperinfected state where genes that control biosynthesis of amino acids, iron uptake systems, and formation of periplasmic nitrate reductase complexes were induced just before defecation. These induced characteristics allow the cholera vibrios to survive in the \"rice water\" stools, an environment of limited oxygen and iron, of patients with a cholera infection.\nGlobal Strategy.\nIn 2017, the WHO launched the \"Ending Cholera: a global roadmap to 2030\" strategy which aims to reduce cholera deaths by 90% by 2030. The strategy was developed by the Global Task Force on Cholera Control (GTFCC) which develops country-specific plans and monitors progress. The approach to achieve this goal combines surveillance, water sanitation, rehydration treatment and oral vaccines. Specifically, the control strategy focuses on three approaches: i) early detection and response to outbreaks to contain outbreaks, ii) stopping cholera transmission through improved sanitation and vaccines in hotspots, and iii) a global framework for cholera control through the GTFCC.\nThe WHO and the GTFCC do not consider global cholera eradication a viable goal. Even though humans are the only host of cholera, the bacterium can persist in the environment without a human host. While global eradication is not possible, elimination of human to human transmission may be possible. Local elimination is possible, which has been underway most recently during the 2010s Haiti cholera outbreak. Haiti aims to achieve certification of elimination by 2022.\nThe GTFCC targets 47 countries, 13 of which have established vaccination campaigns.\nSociety and culture.\nHealth policy.\nIn many developing countries, cholera still reaches its victims through contaminated water sources, and countries without proper sanitation techniques have greater incidence of the disease. Governments can play a role in this. In 2008, for example, the Zimbabwean cholera outbreak was due partly to the government's role, according to a report from the James Baker Institute. The Haitian government's inability to provide safe drinking water after the 2010 earthquake led to an increase in cholera cases as well.\nSimilarly, South Africa's cholera outbreak was exacerbated by the government's policy of privatizing water programs. The wealthy elite of the country were able to afford safe water while others had to use water from cholera-infected rivers.\nAccording to Rita R. Colwell of the James Baker Institute, if cholera does begin to spread, government preparedness is crucial. A government's ability to contain the disease before it extends to other areas can prevent a high death toll and the development of an epidemic or even pandemic. Effective disease surveillance can ensure that cholera outbreaks are recognized as soon as possible and dealt with appropriately. Oftentimes, this will allow public health programs to determine and control the cause of the cases, whether it is unsanitary water or seafood that have accumulated a lot of \"Vibrio cholerae\" specimens. Having an effective surveillance program contributes to a government's ability to prevent cholera from spreading. In the year 2000 in the state of Kerala in India, the Kottayam district was determined to be \"Cholera-affected\"; this pronouncement led to task forces that concentrated on educating citizens with 13,670 information sessions about human health. These task forces promoted the boiling of water to obtain safe water, and provided chlorine and oral rehydration salts. Ultimately, this helped to control the spread of the disease to other areas and minimize deaths. On the other hand, researchers have shown that most of the citizens infected during the 1991 cholera outbreak in Bangladesh lived in rural areas, and were not recognized by the government's surveillance program. This inhibited physicians' abilities to detect cholera cases early.\nAccording to Colwell, the quality and inclusiveness of a country's health care system affects the control of cholera, as it did in the Zimbabwean cholera outbreak. While sanitation practices are important, when governments respond quickly and have readily available vaccines, the country will have a lower cholera death toll. Affordability of vaccines can be a problem; if the governments do not provide vaccinations, only the wealthy may be able to afford them and there will be a greater toll on the country's poor. The speed with which government leaders respond to cholera outbreaks is important.\nBesides contributing to an effective or declining public health care system and water sanitation treatments, government can have indirect effects on cholera control and the effectiveness of a response to cholera. A country's government can impact its ability to prevent disease and control its spread. A speedy government response backed by a fully functioning health care system and financial resources can prevent cholera's spread. This limits cholera's ability to cause death, or at the very least a decline in education, as children are kept out of school to minimize the risk of infection. Inversely, poor government response can lead to civil unrest and cholera riots.\nIn popular culture.\nUnlike tuberculosis (\"consumption\") which in literature and the arts was often romanticized as a disease of denizens of the demimonde or those with an artistic temperament, cholera is a disease which almost entirely affects the poor living in unsanitary conditions. This, and the unpleasant course of the disease \u2013 which includes voluminous \"rice-water\" diarrhea, the hemorrhaging of liquids from the mouth, and violent muscle contractions which continue even after death \u2013 has discouraged the disease from being romanticized, or even being factually presented in popular culture.\nCountry examples.\nZambia.\nIn Zambia, widespread cholera outbreaks have occurred since 1977, most commonly in the capital city of Lusaka. In 2017, an outbreak of cholera was declared in Zambia after laboratory confirmation of \"Vibrio cholerae\" O1, biotype El Tor, serotype Ogawa, from stool samples from two patients with acute watery diarrhea. There was a rapid increase in the number of cases from several hundred cases in early December 2017 to approximately 2,000 by early January 2018. With intensification of the rains, new cases increased on a daily basis reaching a peak on the first week of January 2018 with over 700 cases reported.\nIn collaboration with partners, the Zambia Ministry of Health (MoH) launched a multifaceted public health response that included increased chlorination of the Lusaka municipal water supply, provision of emergency water supplies, water quality monitoring and testing, enhanced surveillance, epidemiologic investigations, a cholera vaccination campaign, aggressive case management and health care worker training, and laboratory testing of clinical samples.\nThe Zambian Ministry of Health implemented a reactive one-dose Oral Cholera Vaccine (OCV) campaign in April 2016 in three Lusaka compounds, followed by a pre-emptive second-round in December.\nNigeria\nIn June 2024, the Nigeria Centre for Disease Control and Prevention (NCDC) announced a total of 1,141 suspected and 65 confirmed cases of cholera with 30 deaths from 96 Local Government Areas (LGAs) in 30 states of the country. NCDC, in its public health advisory, said Abia, Bayelsa, Bauchi, Cross River, Delta, Imo, Katsina, Lagos, Nasarawa and Zamfara states were the 10 states that contributed 90 percent of the burden of cholera in the country at the time.\nIndia.\nThe city of Kolkata, India in the state of West Bengal in the Ganges delta has been described as the \"homeland of cholera\", with regular outbreaks and pronounced seasonality. In India, where the disease is endemic, cholera outbreaks occur every year between dry seasons and rainy seasons. India is also characterized by high population density, unsafe drinking water, open drains, and poor sanitation which provide an optimal niche for survival, sustenance and transmission of \"Vibrio cholerae\".\nDemocratic Republic of Congo.\nIn Goma in the Democratic Republic of Congo, cholera has left an enduring mark on human and medical history. Cholera pandemics in the 19th and 20th centuries led to the growth of epidemiology as a science and in recent years it has continued to press advances in the concepts of disease ecology, basic membrane biology, and transmembrane signaling and in the use of scientific information and treatment design."}
{"id": "7592", "revid": "41840956", "url": "https://en.wikipedia.org/wiki?curid=7592", "title": "Caldera", "text": "A caldera ( ) is a large cauldron-like hollow that forms shortly after the emptying of a magma chamber in a volcanic eruption. An eruption that ejects large volumes of magma over a short period of time can cause significant detriment to the structural integrity of such a chamber, greatly diminishing its capacity to support its own roof, and any substrate or rock resting above. The ground surface then collapses into the emptied or partially emptied magma chamber, leaving a large depression at the surface (from one to dozens of kilometers in diameter). Although sometimes described as a crater, the feature is actually a type of sinkhole, as it is formed through subsidence and collapse rather than an explosion or impact. Compared to the thousands of volcanic eruptions that occur over the course of a century, the formation of a caldera is a rare event, occurring only a few times within a given window of 100 years. Only eight caldera-forming collapses are known to have occurred between 1911 and 2018, with a caldera collapse at K\u012blauea, Hawaii in 2018. Volcanoes that have formed a caldera are sometimes described as \"caldera volcanoes\".\nEtymology.\nThe term \"caldera\" comes from Spanish ', and Latin ', meaning \"cooking pot\". In some texts the English term \"cauldron\" is also used, though in more recent work the term \"cauldron\" refers to a caldera that has been deeply eroded to expose the beds under the caldera floor. The term \"caldera\" was introduced into the geological vocabulary by the German geologist Leopold von Buch when he published his memoirs of his 1815 visit to the Canary Islands, where he first saw the Las Ca\u00f1adas caldera on Tenerife, with Mount Teide dominating the landscape, and then the Caldera de Taburiente on La Palma.\nCaldera formation.\nA collapse is triggered by the emptying of the magma chamber beneath the volcano, sometimes as the result of a large explosive volcanic eruption (see Tambora in 1815), but also during effusive eruptions on the flanks of a volcano (see Piton de la Fournaise in 2007) or in a connected fissure system (see B\u00e1r\u00f0arbunga in 2014\u20132015). If enough magma is ejected, the emptied chamber is unable to support the weight of the volcanic edifice above it. A roughly circular fracture, the \"ring fault\", develops around the edge of the chamber. Ring fractures serve as feeders for fault intrusions which are also known as ring dikes. Secondary volcanic vents may form above the ring fracture. As the magma chamber empties, the center of the volcano within the ring fracture begins to collapse. The collapse may occur as the result of a single cataclysmic eruption, or it may occur in stages as the result of a series of eruptions. The total area that collapses may be hundreds of square kilometers.\nMineralization in calderas.\nSome calderas are known to host rich ore deposits. Metal-rich fluids can circulate through the caldera, forming hydrothermal ore deposits of metals such as lead, silver, gold, mercury, lithium, and uranium. One of the world's best-preserved mineralized calderas is the Sturgeon Lake Caldera in northwestern Ontario, Canada, which formed during the Neoarchean era about 2.7\u00a0billion years ago. In the San Juan volcanic field, ore veins were emplaced in fractures associated with several calderas, with the greatest mineralization taking place near the youngest and most silicic intrusions associated with each caldera.\nTypes of caldera.\nExplosive caldera eruptions.\nExplosive caldera eruptions are produced by a magma chamber whose magma is rich in silica. Silica-rich magma has a high viscosity, and therefore does not flow easily like basalt. The magma typically also contains a large amount of dissolved gases, up to 7 wt% for the most silica-rich magmas. When the magma approaches the surface of the Earth, the drop in confining pressure causes the trapped gases to rapidly bubble out of the magma, fragmenting the magma to produce a mixture of volcanic ash and other tephra with the very hot gases.\nThe mixture of ash and volcanic gases initially rises into the atmosphere as an eruption column. However, as the volume of erupted material increases, the eruption column is unable to entrain enough air to remain buoyant, and the eruption column collapses into a tephra fountain that falls back to the surface to form pyroclastic flows. Eruptions of this type can spread ash over vast areas, so that ash flow tuffs emplaced by silicic caldera eruptions are the only volcanic product with volumes rivaling those of flood basalts. For example, when Yellowstone Caldera last erupted some 650,000 years ago, it released about 1,000\u00a0km3 of material (as measured in dense rock equivalent (DRE)), covering a substantial part of North America in up to two metres of debris.\nEruptions forming even larger calderas are known, such as the La Garita Caldera in the San Juan Mountains of Colorado, where the Fish Canyon Tuff was blasted out in eruptions about 27.8\u00a0million years ago.\nThe caldera produced by such eruptions is typically filled in with tuff, rhyolite, and other igneous rocks. The caldera is surrounded by an outflow sheet of ash flow tuff (also called an ash flow sheet).\nIf magma continues to be injected into the collapsed magma chamber, the center of the caldera may be uplifted in the form of a \"resurgent dome\" such as is seen at the Valles Caldera, Lake Toba, the San Juan volcanic field, Cerro Gal\u00e1n, Yellowstone, and many other calderas.\nBecause a silicic caldera may erupt hundreds or even thousands of cubic kilometers of material in a single event, it can cause catastrophic environmental effects. Even small caldera-forming eruptions, such as Krakatoa in 1883 or Mount Pinatubo in 1991, may result in significant local destruction and a noticeable drop in temperature around the world. Large calderas may have even greater effects. The ecological effects of the eruption of a large caldera can be seen in the record of the Lake Toba eruption in Indonesia.\nAt some points in geological time, rhyolitic calderas have appeared in distinct clusters. The remnants of such clusters may be found in places such as the Eocene Rum Complex of Scotland, the San Juan Mountains of Colorado (formed during the Oligocene, Miocene, and Pliocene epochs) or the Saint Francois Mountain Range of Missouri (erupted during the Proterozoic eon).\nValles.\nFor their 1968 paper that first introduced the concept of a resurgent caldera to geology, R.L. Smith and R.A. Bailey chose the Valles caldera as their model. Although the Valles caldera is not unusually large, it is relatively young (1.25 million years old) and unusually well preserved, and it remains one of the best studied examples of a resurgent caldera. The ash flow tuffs of the Valles caldera, such as the Bandelier Tuff, were among the first to be thoroughly characterized.\nToba.\nAbout 74,000 years ago, this Indonesian volcano released about dense-rock equivalent of ejecta. This was the largest known eruption during the ongoing Quaternary period (the last 2.6\u00a0million years) and the largest known explosive eruption during the last 25\u00a0million years. In the late 1990s, anthropologist Stanley Ambrose proposed that a volcanic winter induced by this eruption reduced the human population to about 2,000\u201320,000 individuals, resulting in a population bottleneck. More recently, Lynn Jorde and Henry Harpending proposed that the human species was reduced to approximately 5,000\u201310,000 people. There is no direct evidence, however, that either theory is correct, and there is no evidence for any other animal decline or extinction, even in environmentally sensitive species. There is evidence that human habitation continued in India after the eruption.\nNon-explosive calderas.\nSome volcanoes, such as the large shield volcanoes K\u012blauea and Mauna Loa on the island of Hawaii, form calderas in a different fashion. The magma feeding these volcanoes is basalt, which is silica poor. As a result, the magma is much less viscous than the magma of a rhyolitic volcano, and the magma chamber is drained by large lava flows rather than by explosive events. The resulting calderas are also known as subsidence calderas and can form more gradually than explosive calderas. For instance, the caldera atop Fernandina Island collapsed in 1968 when parts of the caldera floor dropped .\nExtraterrestrial calderas.\nSince the early 1960s, it has been known that volcanism has occurred on other planets and moons in the Solar System. Through the use of crewed and uncrewed spacecraft, volcanism has been discovered on Venus, Mars, the Moon, and Io, a satellite of Jupiter. None of these worlds have plate tectonics, which contributes approximately 60% of the Earth's volcanic activity (the other 40% is attributed to hotspot volcanism). Caldera structure is similar on all of these planetary bodies, though the size varies considerably. The average caldera diameter on Venus is . The average caldera diameter on Io is close to , and the mode is ; Tvashtar Paterae is likely the largest caldera with a diameter of . The average caldera diameter on Mars is , smaller than Venus. Calderas on Earth are the smallest of all planetary bodies and vary from as a maximum.\nThe Moon.\nThe Moon has an outer shell of low-density crystalline rock that is a few hundred kilometers thick, which formed due to a rapid creation. The craters of the Moon have been well preserved through time and were once thought to have been the result of extreme volcanic activity, but are currently believed to have been formed by meteorites, nearly all of which took place in the first few hundred million years after the Moon formed. Around 500\u00a0million years afterward, the Moon's mantle was able to be extensively melted due to the decay of radioactive elements. Massive basaltic eruptions took place generally at the base of large impact craters. Also, eruptions may have taken place due to a magma reservoir at the base of the crust. This forms a dome, possibly the same morphology of a shield volcano where calderas universally are known to form. Although caldera-like structures are rare on the Moon, they are not completely absent. The Compton-Belkovich Volcanic Complex on the far side of the Moon is thought to be a caldera, possibly an ash-flow caldera.\nMars.\nThe volcanic activity of Mars is concentrated in two major provinces: Tharsis and Elysium. Each province contains a series of giant shield volcanoes that are similar to what we see on Earth and likely are the result of mantle hot spots. The surfaces are dominated by lava flows, and all have one or more collapse calderas. Mars has the tallest volcano in the Solar System, Olympus Mons, which is more than three times the height of Mount Everest, with a diameter of 520\u00a0km (323 miles). The summit of the mountain has six nested calderas.\nVenus.\nBecause there is no plate tectonics on Venus, heat is mainly lost by conduction through the lithosphere. This causes enormous lava flows, accounting for 80% of Venus' surface area. Many of the mountains are large shield volcanoes that range in size from in diameter and high. More than 80 of these large shield volcanoes have summit calderas averaging across.\nIo.\nIo, unusually, is heated by solid flexing due to the tidal influence of Jupiter and Io's orbital resonance with neighboring large moons Europa and Ganymede, which keep its orbit slightly eccentric. Unlike any of the planets mentioned, Io is continuously volcanically active. For example, the NASA \"Voyager 1\" and \"Voyager 2\" spacecraft detected nine erupting volcanoes while passing Io in 1979. Io has many calderas with diameters tens of kilometers across."}
{"id": "7593", "revid": "16711097", "url": "https://en.wikipedia.org/wiki?curid=7593", "title": "Calculator", "text": "An electronic calculator is typically a portable electronic device used to perform calculations, ranging from basic arithmetic to complex mathematics.\nThe first solid-state electronic calculator was created in the early 1960s. Pocket-sized devices became available in the 1970s, especially after the Intel 4004, the first microprocessor, was developed by Intel for the Japanese calculator company Busicom. Modern electronic calculators vary from cheap, give-away, credit-card-sized models to sturdy desktop models with built-in printers. They became popular in the mid-1970s as the incorporation of integrated circuits reduced their size and cost. By the end of that decade, prices had dropped to the point where a basic calculator was affordable to most and they became common in schools.\nIn addition to general purpose calculators, there are those designed for specific markets. For example, there are scientific calculators, which include trigonometric and statistical calculations. Some calculators even have the ability to do computer algebra. Graphing calculators can be used to graph functions defined on the real line, or higher-dimensional Euclidean space. , basic calculators cost little, but scientific and graphing models tend to cost more.\nComputer operating systems as far back as early Unix have included interactive calculator programs such as dc and hoc, and interactive BASIC could be used to do calculations on most 1970s and 1980s home computers. Calculator functions are included in most smartphones, tablets, and personal digital assistant (PDA) type devices. With the very wide availability of smartphones and the like, dedicated hardware calculators, while still widely used, are less common than they once were. In 1986, calculators still represented an estimated 41% of the world's general-purpose hardware capacity to compute information. By 2007, this had diminished to less than 0.05%.\nDesign.\nInput.\nElectronic calculators contain a keyboard with buttons for digits and arithmetical operations; some even contain \"00\" and \"000\" buttons to make larger or smaller numbers easier to enter. Most basic calculators assign only one digit or operation on each button; however, in more specific calculators, a button can perform multi-function working with key combinations.\nDisplay output.\nCalculators usually have liquid-crystal displays (LCD) as output in place of historical light-emitting diode (LED) displays and vacuum fluorescent displays (VFD); details are provided in the section \"Technical improvements\".\nLarge-sized figures are often used to improve readability; while using decimal separator (usually a point rather than a comma) instead of or in addition to vulgar fractions. Various symbols for function commands may also be shown on the display. Fractions such as are displayed as decimal approximations, for example rounded to . Also, some fractions (such as , which is ; to 14 significant figures) can be difficult to recognize in decimal form; as a result, many scientific calculators are able to work in vulgar fractions or mixed numbers.\nMemory.\nCalculators also have the ability to save numbers into computer memory. Basic calculators usually store only one number at a time; more specific types are able to store many numbers represented in variables. Usually these variables are named ans or ans(0). The variables can also be used for constructing formulas. Some models have the ability to extend memory capacity to store more numbers; the extended memory address is termed an array index.\nPower source.\nPower sources of calculators are batteries, solar cells or mains electricity (for old models), turning on with a switch or button. Some models even have no turn-off button but they provide some way to put off (for example, leaving no operation for a moment, covering solar cell exposure, or closing their lid). Crank-powered calculators were also common in the early computer era.\nKey layout.\nThe following keys are common to most pocket calculators. While the arrangement of the digits is standard, the positions of other keys vary from model to model; the illustration is an example.\nThe arrangement of digits on calculator and other numeric keypads with the -- keys two rows above the -- keys is derived from calculators and cash registers. It is notably different from the layout of telephone Touch-Tone keypads which have the -- keys on top and -- keys on the third row.\nInternal workings.\nIn general, a basic electronic calculator consists of the following components:\nClock rate of a processor chip refers to the frequency at which the central processing unit (CPU) is running. It is used as an indicator of the processor's speed, and is measured in \"clock cycles per second\" or hertz (Hz). For basic calculators, the speed can vary from a few hundred hertz to the kilohertz range.\nExample.\nA basic explanation as to how calculations are performed in a simple four-function calculator:\nTo perform the calculation , one presses keys in the following sequence on most calculators: \u00a0\u00a0\u00a0\u00a0.\nOther functions are usually performed using repeated additions or subtractions.\nNumeric representation.\nMost pocket calculators do all their calculations in binary-coded decimal (BCD) rather than binary. BCD is common in electronic systems where a numeric value is to be displayed, especially in systems consisting solely of digital logic, and not containing a microprocessor. By employing BCD, the manipulation of numerical data for display can be greatly simplified by treating each digit as a separate single sub-circuit. This matches much more closely the physical reality of display hardware\u2014a designer might choose to use a series of separate identical seven-segment displays to build a metering circuit, for example. If the numeric quantity were stored and manipulated as pure binary, interfacing to such a display would require complex circuitry. Therefore, in cases where the calculations are relatively simple, working throughout with BCD can lead to a simpler overall system than converting to and from binary. (For example, CDs keep the track number in BCD, limiting them to 99 tracks.)\nThe same argument applies when hardware of this type uses an embedded microcontroller or other small processor. Often, smaller code results when representing numbers internally in BCD format, since a conversion from or to binary representation can be expensive on such limited processors. For these applications, some small processors feature BCD arithmetic modes, which assist when writing routines that manipulate BCD quantities.\nWhere calculators have added functions (such as square root, or trigonometric functions), software algorithms are required to produce high precision results. Sometimes significant design effort is needed to fit all the desired functions in the limited memory space available in the calculator chip, with acceptable calculation time.\nHistory.\nPrecursors to the electronic calculator.\nThe first known tools used to aid arithmetic calculations were: bones (used to tally items), pebbles, and counting boards, and the abacus, known to have been used by Sumerians and Egyptians before 2000\u00a0BC. Except for the Antikythera mechanism (an \"out of the time\" astronomical device), development of computing tools arrived near the start of the 17th century: the geometric-military compass (by Galileo), logarithms and Napier bones (by Napier), and the slide rule (by Edmund Gunter).\nThe Renaissance saw the invention of the mechanical calculator by Wilhelm Schickard in 1623, and later by Blaise Pascal in 1642. A device that was at times somewhat over-promoted as being able to perform all four arithmetic operations with minimal human intervention. Pascal's calculator could add and subtract two numbers directly and thus, if the tedium could be borne, multiply and divide by repetition. Schickard's machine, constructed several decades earlier, used a clever set of mechanised multiplication tables to ease the process of multiplication and division with the adding machine as a means of completing this operation. There is a debate about whether Pascal or Shickard should be credited as the known inventor of a calculating machine due to the differences (like the different aims) of both inventions. Schickard and Pascal were followed by Gottfried Leibniz who spent forty years designing a four-operation mechanical calculator, the stepped reckoner, inventing in the process his leibniz wheel, but who couldn't design a fully operational machine. There were also five unsuccessful attempts to design a calculating clock in the 17th century.\nThe 18th century saw the arrival of some notable improvements, first by Poleni with the first fully functional calculating clock and four-operation machine, but these machines were almost always \"one of a kind\". Luigi Torchi invented the first direct multiplication machine in 1834: this was also the second key-driven machine in the world, following that of James White (1822). It was not until the 19th century and the Industrial Revolution that real developments began to occur. Although machines capable of performing all four arithmetic functions existed prior to the 19th century, the refinement of manufacturing and fabrication processes during the eve of the industrial revolution made large scale production of more compact and modern units possible. The Arithmometer, invented in 1820 as a four-operation mechanical calculator, was released to production in 1851 as an adding machine and became the first commercially successful unit; forty years later, by 1890, about 2,500 arithmometers had been sold plus a few hundreds more from two arithmometer clone makers (Burkhardt, Germany, 1878 and Layton, UK, 1883) and Felt and Tarrant, the only other competitor in true commercial production, had sold 100 comptometers.\nIt wasn't until 1902 that the familiar push-button user interface was developed, with the introduction of the Dalton Adding Machine, developed by James L. Dalton in the United States.\nIn 1921, Edith Clarke invented the \"Clarke calculator\", a simple graph-based calculator for solving line equations involving hyperbolic functions. This allowed electrical engineers to simplify calculations for inductance and capacitance in power transmission lines.\nThe Curta calculator was developed in 1948 and, although costly, became popular for its portability. This purely mechanical hand-held device could do addition, subtraction, multiplication and division. By the early 1970s electronic pocket calculators ended manufacture of mechanical calculators, although the Curta remains a popular collectable item.\nDevelopment of electronic calculators.\nThe first mainframe computers, initially using vacuum tubes and later transistors in the logic circuits, appeared in the 1940s and 1950s. Electronic circuits developed for computers also had application to electronic calculators.\nThe Casio Computer Company, in Japan, released the Model \"14-A\" calculator in 1957, which was the world's first all-electric (relatively) compact calculator. It did not use electronic logic but was based on relay technology, and was built into a desk. The IBM 608 plugboard programmable calculator was IBM's first all-transistor product, released in 1957; this was a console type system, with input and output on punched cards, and replaced the earlier, larger, vacuum-tube IBM 603. \nIn October 1961, the world's first \"all-electronic desktop\" calculator, the British Bell Punch/Sumlock Comptometer ANITA (A New Inspiration To Arithmetic/Accounting) was announced. This machine used vacuum tubes, cold-cathode tubes and Dekatrons in its circuits, with 12 cold-cathode \"Nixie\" tubes for its display. Two models were displayed, the Mk VII for continental Europe and the Mk VIII for Britain and the rest of the world, both for delivery from early 1962. The Mk VII was a slightly earlier design with a more complicated mode of multiplication, and was soon dropped in favour of the simpler Mark VIII. The ANITA had a full keyboard, similar to mechanical comptometers of the time, a feature that was unique to it and the later Sharp CS-10A among electronic calculators. The ANITA weighed roughly due to its large tube system. Bell Punch had been producing key-driven mechanical calculators of the comptometer type under the names \"Plus\" and \"Sumlock\", and had realised in the mid-1950s that the future of calculators lay in electronics. They employed the young graduate Norbert Kitz, who had worked on the early British Pilot ACE computer project, to lead the development. The ANITA sold well since it was the only electronic desktop calculator available, and was silent and quick.\nThe tube technology of the ANITA was superseded in June 1963 by the U.S. manufactured Friden EC-130, which had an all-transistor design, a stack of four 13-digit numbers displayed on a cathode-ray tube (CRT), and introduced Reverse Polish Notation (RPN) to the calculator market for a price of $2200, which was about three times the cost of an electromechanical calculator of the time. Like Bell Punch, Friden was a manufacturer of mechanical calculators that had decided that the future lay in electronics. In 1964 more all-transistor electronic calculators were introduced: Sharp introduced the CS-10A, which weighed and cost 500,000 yen ($), and Industria Macchine Elettroniche of Italy introduced the IME 84, to which several extra keyboard and display units could be connected so that several people could make use of it (but apparently not at the same time). The Victor 3900 was the first to use integrated circuits in place of individual transistors, but production problems delayed sales until 1966.\nThere followed a series of electronic calculator models from these and other manufacturers, including Canon, Mathatronics, Olivetti, SCM (Smith-Corona-Marchant), Sony, Toshiba, and Wang. The early calculators used hundreds of germanium transistors, which were cheaper than silicon transistors, on multiple circuit boards. Display types used were CRT, cold-cathode Nixie tubes, and filament lamps. Memory technology was usually based on the delay-line memory or the magnetic-core memory, though the Toshiba \"Toscal\" BC-1411 appears to have used an early form of dynamic RAM built from discrete components. Already there was a desire for smaller and less power-hungry machines.\nBulgaria's ELKA 6521, introduced in 1965, was developed by the Central Institute for Calculation Technologies and built at the Elektronika factory in Sofia. The name derives from \"ELektronen KAlkulator\", and it weighed around . It is the first calculator in the world which includes the square root function. Later that same year were released the ELKA 22 (with a luminescent display) and the ELKA 25, with an built-in printer. Several other models were developed until the first pocket model, the ELKA 101, was released in 1974. The writing on it was in Roman script, and it was exported to western countries.\nProgrammable calculators.\nThe first desktop \"programmable calculators\" were produced in the mid-1960s. They included the Mathatronics Mathatron (1964) and the Olivetti Programma 101 (late 1965) which were solid-state, desktop, printing, floating point, algebraic entry, programmable, stored-program electronic calculators. Both could be programmed by the end user and print out their results. The Programma 101 saw much wider distribution and had the added feature of offline storage of programs via magnetic cards.\nAnother early programmable desktop calculator (and maybe the first Japanese one) was the Casio (AL-1000) produced in 1967. It featured a nixie tubes display and had transistor electronics and ferrite core memory.\nThe \"Monroe Epic\" programmable calculator came on the market in 1967. A large, printing, desk-top unit, with an attached floor-standing logic tower, it could be programmed to perform many computer-like functions. However, the only \"branch\" instruction was an implied unconditional branch (GOTO) at the end of the operation stack, returning the program to its starting instruction. Thus, it was not possible to include any conditional branch (IF-THEN-ELSE) logic. During this era, the absence of the conditional branch was sometimes used to distinguish a programmable calculator from a computer.\nThe first Soviet programmable desktop calculator ISKRA 123, powered by the power grid, was released at the start of the 1970s.\n1970s to mid-1980s.\nThe electronic calculators of the mid-1960s were large and heavy desktop machines due to their use of hundreds of transistors on several circuit boards with a large power consumption that required an AC power supply. There were great efforts to put the logic required for a calculator into fewer and fewer integrated circuits (chips) and calculator electronics was one of the leading edges of semiconductor development. U.S. semiconductor manufacturers led the world in large scale integration (LSI) semiconductor development, squeezing more and more functions into individual integrated circuits. This led to alliances between Japanese calculator manufacturers and U.S. semiconductor companies: Canon Inc. with Texas Instruments, Hayakawa Electric (later renamed Sharp Corporation) with North-American Rockwell Microelectronics (later renamed Rockwell International), Busicom with Mostek and Intel, and General Instrument with Sanyo.\nPocket calculators.\nBy 1970, a calculator could be made using just a few chips of low power consumption, allowing portable models powered from rechargeable batteries. The first handheld calculator was a 1967 prototype called Cal Tech, whose development was led by Jack Kilby at Texas Instruments in a research project to produce a portable calculator. It could add, multiply, subtract, and divide, and its output device was a paper tape. As a result of the \"Cal-Tech\" project, Texas Instruments was granted master patents on portable calculators.\nThe first commercially produced portable calculators appeared in Japan in 1970, and were soon marketed around the world. These included the Sanyo ICC-0081 \"Mini Calculator\", the Canon Pocketronic, and the Sharp QT-8B \"micro Compet\". The Canon Pocketronic was a development from the \"Cal-Tech\" project. It had no traditional display; numerical output was on thermal paper tape.\nSharp put in great efforts in size and power reduction and introduced in January 1971 the Sharp EL-8, also marketed as the Facit 1111, which was close to being a pocket calculator. It weighed 1.59 pounds (721 grams), had a vacuum fluorescent display, rechargeable NiCad batteries, and initially sold for US$395.\nHowever, integrated circuit development efforts culminated in early 1971 with the introduction of the first \"calculator on a chip\", the MK6010 by Mostek, followed by Texas Instruments later in the year. Although these early hand-held calculators were very costly, these advances in electronics, together with developments in display technology (such as the vacuum fluorescent display, LED, and LCD), led within a few years to the cheap pocket calculator available to all.\nIn 1971, Pico Electronics and General Instrument also introduced their first collaboration in ICs, a full single chip calculator IC for the Monroe Royal Digital III calculator. Pico was a spinout by five GI design engineers whose vision was to create single chip calculator ICs. Pico and GI went on to have significant success in the burgeoning handheld calculator market.\nThe first truly pocket-sized electronic calculator was the Busicom LE-120A \"HANDY\", which was marketed early in 1971. Made in Japan, this was also the first calculator to use an LED display, the first hand-held calculator to use a single integrated circuit (then proclaimed as a \"calculator on a chip\"), the Mostek MK6010, and the first electronic calculator to run off replaceable batteries. Using four AA-size cells the LE-120A measures .\nThe first European-made pocket-sized calculator, DB 800 was made in May 1971 by Digitron in Buje, Croatia (former Yugoslavia) with four functions and an eight-digit display and special characters for a negative number and a warning that the calculation has too many digits to display.\nThe first American-made pocket-sized calculator, the Bowmar 901B (popularly termed \"The Bowmar Brain\"), measuring , came out in the Autumn of 1971, with four functions and an eight-digit red LED display, for , while in August 1972 the four-function Sinclair Executive became the first slimline pocket calculator measuring and weighing . It retailed for around \u00a379 ( at the time). By the end of the decade, similar calculators were priced less than \u00a35 ($). Following protracted development over the course of two years including a botched partnership with Texas Instruments, Eldorado Electrodata released five pocket calculators in 1972. One called the Touch Magic was \"no bigger than a pack of cigarettes\" according to \"Administrative Management\".\nThe first Soviet Union made pocket-sized calculator, the \"Elektronika B3-04\" was developed by the end of 1973 and sold at the start of 1974.\nOne of the first low-cost calculators was the Sinclair Cambridge, launched in August 1973. It retailed for \u00a329.95 ($), or \u00a35 ($) less in kit form, and later models included some scientific functions. The Sinclair calculators were successful because they were far cheaper than the competition; however, their design led to slow and less accurate computations of transcendental functions (maximum three decimal places of accuracy).\nScientific pocket calculators.\nMeanwhile, Hewlett-Packard (HP) had been developing a pocket calculator. Launched in early 1972, it was unlike the other basic four-function pocket calculators then available in that it was the first pocket calculator with \"scientific\" functions that could replace a slide rule. The $395 HP-35, along with nearly all later HP engineering calculators, uses reverse Polish notation (RPN), also called postfix notation. A calculation like \"8 plus 5\" is, using RPN, performed by pressing , , , and ; instead of the algebraic infix notation: , , , . It had 35 buttons and was based on Mostek Mk6020 chip.\nThe first Soviet \"scientific\" pocket-sized calculator the \"B3-18\" was completed by the end of 1975.\nIn 1973, Texas Instruments (TI) introduced the SR-10, (\"SR\" signifying slide rule) an \"algebraic entry\" pocket calculator using scientific notation for $150. Shortly after the SR-11 featured an added key for entering pi (\u03c0). It was followed the next year by the SR-50 which added log and trig functions to compete with the HP-35, and in 1977 the mass-marketed TI-30 line which is still produced.\nIn 1978, a new company, Calculated Industries arose which focused on specialized markets. Their first calculator, the Loan Arranger (1978) was a pocket calculator marketed to the Real Estate industry with preprogrammed functions to simplify the process of calculating payments and future values. In 1985, CI launched a calculator for the construction industry called the Construction Master which came preprogrammed with common construction calculations (such as angles, stairs, roofing math, pitch, rise, run, and feet-inch fraction conversions). This would be the first in a line of construction related calculators.\nProgrammable pocket calculators.\nThe first programmable pocket calculator was the HP-65, in 1974; it had a capacity of 100 instructions, and could store and retrieve programs with a built-in magnetic card reader. Two years later the HP-25C introduced \"continuous memory\", i.e., programs and data were retained in CMOS memory during power-off. In 1979, HP released the first \"alphanumeric\", programmable, \"expandable\" calculator, the HP-41C. It could be expanded with random-access memory (RAM, for memory) and read-only memory (ROM, for software) modules, and peripherals like bar code readers, microcassette and floppy disk drives, paper-roll thermal printers, and miscellaneous communication interfaces (RS-232, HP-IL, HP-IB).\nThe first Soviet pocket battery-powered programmable calculator, Elektronika \"B3-21\", was developed by the end of 1976 and released at the start of 1977. The successor of B3-21, the Elektronika B3-34 wasn't backward compatible with B3-21, even if it kept the reverse Polish notation (RPN). Thus B3-34 defined a new command set, which later was used in a series of later programmable Soviet calculators. Despite very limited abilities (98 bytes of instruction memory and about 19 stack and addressable registers), people managed to write all kinds of programs for them, including adventure games and libraries of calculus-related functions for engineers. Hundreds, perhaps thousands, of programs were written for these machines, from practical scientific and business software, which were used in real-life offices and labs, to fun games for children. The Elektronika MK-52 calculator (using the extended B3-34 command set, and featuring internal EEPROM memory for storing programs and external interface for EEPROM cards and other periphery) was used in Soviet spacecraft program (for Soyuz TM-7 flight) as a backup of the board computer.\nThis series of calculators was also noted for a large number of highly counter-intuitive mysterious undocumented features, somewhat similar to \"synthetic programming\" of the American HP-41, which were exploited by applying normal arithmetic operations to error messages, jumping to nonexistent addresses and other methods. A number of respected monthly publications, including the popular science magazine \"Nauka i Zhizn\" (\"\u041d\u0430\u0443\u043a\u0430 \u0438 \u0436\u0438\u0437\u043d\u044c\", \"Science and Life\"), featured special columns, dedicated to optimization methods for calculator programmers and updates on undocumented features for hackers, which grew into a whole esoteric science with many branches, named \"yeggogology\" (\"\u0435\u0433\u0433\u043e\u0433\u043e\u043b\u043e\u0433\u0438\u044f\"). The error messages on those calculators appear as a Russian word \"YEGGOG\" (\"\u0415\u0413\u0413\u041e\u0413\") which, unsurprisingly, is translated to \"Error\".\nA similar hacker culture in the US revolved around the HP-41, which was also noted for a large number of undocumented features and was much more powerful than B3-34.\nTechnical improvements.\nThrough the 1970s the hand-held electronic calculator underwent rapid development. The red LED and blue/green vacuum fluorescent displays consumed a lot of power and the calculators either had a short battery life (often measured in hours, so rechargeable nickel-cadmium batteries were common) or were large so that they could take larger, higher capacity batteries. In the early 1970s liquid-crystal displays (LCDs) were in their infancy and there was a great deal of concern that they only had a short operating lifetime. Busicom introduced the Busicom \"LE-120A \"HANDY\"\" calculator, the first pocket-sized calculator and the first with an LED display, and announced the Busicom \"LC\" with LCD. However, there were problems with this display and the calculator never went on sale. The first successful calculators with LCDs were manufactured by Rockwell International and sold from 1972 by other companies under such names as: Dataking \"LC-800\", Harden \"DT/12\", Ibico \"086\", Lloyds \"40\", Lloyds \"100\", Prismatic \"500\" (a.k.a. \"P500\"), Rapid Data \"Rapidman 1208LC\". The LCDs were an early form using the \"Dynamic Scattering Mode DSM\" with the numbers appearing as bright against a dark background. To present a high-contrast display these models illuminated the LCD using a filament lamp and solid plastic light guide, which negated the low power consumption of the display. These models appear to have been sold only for a year or two.\nA more successful series of calculators using a reflective DSM-LCD was launched in 1972 by Sharp Inc with the Sharp \"EL-805\", which was a slim pocket calculator. This, and another few similar models, used Sharp's \"Calculator On Substrate\" (COS) technology. An extension of one glass plate needed for the liquid crystal display was used as a substrate to mount the needed chips based on a new hybrid technology. The COS technology may have been too costly since it was only used in a few models before Sharp reverted to conventional circuit boards.\nIn the mid-1970s the first calculators appeared with field-effect, \"twisted nematic\" (TN) LCDs with dark numerals against a grey background, though the early ones often had a yellow filter over them to cut out damaging ultraviolet rays. The advantage of LCDs is that they are passive light modulators reflecting light, which require much less power than light-emitting displays such as LEDs or VFDs. This led the way to the first credit-card-sized calculators, such as the Casio \"Mini Card LC-78\" of 1978, which could run for months of normal use on button cells.\nThere were also improvements to the electronics inside the calculators. All of the logic functions of a calculator had been squeezed into the first \"calculator on a chip\" integrated circuits (ICs) in 1971, but this was leading edge technology of the time and yields were low and costs were high. Many calculators continued to use two or more ICs, especially the scientific and the programmable ones, into the late 1970s.\nThe power consumption of the integrated circuits was also reduced, especially with the introduction of CMOS technology. Appearing in the Sharp \"EL-801\" in 1972, the transistors in the logic cells of CMOS ICs only used any appreciable power when they changed state. The LED and VFD displays often required added driver transistors or ICs, whereas the LCDs were more amenable to being driven directly by the calculator IC itself.\nWith this low power consumption came the possibility of using solar cells as the power source, realised around 1978 by calculators such as the Royal \"Solar 1\", Sharp \"EL-8026\", and Teal \"Photon\".\nMass-market phase.\nAt the start of the 1970s, hand-held electronic calculators were very costly, at two or three weeks' wages, and so were a luxury item. The high price was due to their construction requiring many mechanical and electronic components which were costly to produce, and production runs that were too small to exploit economies of scale. Many firms saw that there were good profits to be made in the calculator business with the margin on such high prices. However, the cost of calculators fell as components and their production methods improved, and the effect of economies of scale was felt.\nBy 1976, the cost of the cheapest four-function pocket calculator had dropped to a few dollars, about 1/20 of the cost five years before. The results of this were that the pocket calculator was affordable, and that it was now difficult for the manufacturers to make a profit from calculators, leading to many firms dropping out of the business or closing. The firms that survived making calculators tended to be those with high outputs of higher quality calculators, or producing high-specification scientific and programmable calculators.\nMid-1980s to present.\nThe first calculator capable of symbolic computing was the HP-28C, released in 1987. It could, for example, solve quadratic equations symbolically. The first graphing calculator was the Casio fx-7000G released in 1985.\nThe two leading manufacturers, HP and TI, released increasingly feature-laden calculators during the 1980s and 1990s. At the turn of the millennium, the line between a graphing calculator and a handheld computer was not always clear, as some very advanced calculators such as the TI-89, the Voyage 200 and HP-49G could differentiate and integrate functions, solve differential equations, run word processing and PIM software, and connect by wire or IR to other calculators/computers.\nThe HP 12c financial calculator is still produced. It was introduced in 1981 and is still being made with few changes. The HP 12c featured the reverse Polish notation mode of data entry. In 2003 several new models were released, including an improved version of the HP 12c, the \"HP 12c platinum edition\" which added more memory, more built-in functions, and the addition of the algebraic mode of data entry.\nCalculated Industries competed with the HP 12c in the mortgage and real estate markets by differentiating the key labeling; changing the \"I\", \"PV\", \"FV\" to easier labeling terms such as \"Int\", \"Term\", \"Pmt\", and not using the reverse Polish notation. However, CI's more successful calculators involved a line of construction calculators, which evolved and expanded in the 1990s to present. According to Mark Bollman, a mathematics and calculator historian and associate professor of mathematics at Albion College, the \"Construction Master is the first in a long and profitable line of CI construction calculators\" which carried them through the 1980s, 1990s, and to the present.\nUse in education.\nIn most countries, students use calculators for schoolwork. There was some initial resistance to the idea out of fear that basic or elementary arithmetic skills would suffer. There remains disagreement about the importance of the ability to perform calculations \"in the head\", with some curricula restricting calculator use until a certain level of proficiency has been obtained, while others concentrate more on teaching estimation methods and problem-solving. Research suggests that inadequate guidance in the use of calculating tools can restrict the kind of mathematical thinking that students engage in. Others have argued that calculator use can even cause core mathematical skills to atrophy, or that such use can prevent understanding of advanced algebraic concepts. In December 2011 the UK's Minister of State for Schools, Nick Gibb, voiced concern that children can become \"too dependent\" on the use of calculators. As a result, the use of calculators is to be included as part of a review of the Curriculum. In the United States, many math educators and boards of education have enthusiastically endorsed the National Council of Teachers of Mathematics (NCTM) standards and actively promoted the use of classroom calculators from kindergarten through high school.\nCalculators may in some circumstances be used within school and college examinations. In the United Kingdom there are limitations on the type of calculator which may be used in an examination to avoid malpractice. Some calculators which offer additional functionality have an \"exam mode\" setting which makes them compliant with examination regulations.\nPersonal computers.\nPersonal computers often come with a calculator utility program that emulates the appearance and functions of a calculator, using the graphical user interface to portray a calculator. Examples include the Windows Calculator, Apple's Calculator, and KDE's KCalc. Most personal data assistants (PDAs) and smartphones also have such a feature.\nCalculators compared to computers.\nThe fundamental difference between a calculator and computer is that a computer can be programmed in a way that allows the program to take different branches according to intermediate results, while calculators are pre-designed with specific functions (such as addition, multiplication, and logarithms) built in. The distinction is not clear-cut: some devices classed as programmable calculators have programming functions, sometimes with support for programming languages (such as RPL or TI-BASIC).\nFor instance, instead of a hardware multiplier, a calculator might implement floating point mathematics with code in read-only memory (ROM), and compute trigonometric functions with the CORDIC algorithm because CORDIC does not require much multiplication. Bit serial logic designs are more common in calculators whereas bit parallel designs dominate general-purpose computers, because a bit serial design minimizes chip complexity, but takes many more clock cycles. This distinction blurs with high-end calculators, which use processor chips associated with computer and embedded systems design, more so the Z80, MC68000, and ARM architectures, and some custom designs specialized for the calculator market."}
{"id": "7594", "revid": "476843", "url": "https://en.wikipedia.org/wiki?curid=7594", "title": "Cash register", "text": "A cash register, sometimes called a till or automated money handling system, is a mechanical or electronic device for registering and calculating transactions at a point of sale. It is usually attached to a drawer for storing cash and other valuables. A modern cash register is usually attached to a printer that can print out receipts for record-keeping purposes.\nHistory.\nAn early mechanical cash register was invented by James Ritty and John Birch following the American Civil War. James was the owner of a saloon in Dayton, Ohio, US, and wanted to stop employees from pilfering his profits. The Ritty Model I was invented in 1879 after seeing a tool that counted the revolutions of the propeller on a steamship. With the help of James' brother John Ritty, they patented it in 1879. It was called \"Ritty's Incorruptible Cashier\" and it was invented to stop cashiers from pilfering and eliminate employee theft and embezzlement.\nEarly mechanical registers were entirely mechanical, without receipts. The employee was required to ring up every transaction on the register, and when the total key was pushed, the drawer opened and a bell would ring, alerting the manager to a sale taking place. Those original machines were nothing but simple adding machines. For example, the Rittys\u2019 patent application filed in 1879 for their \u201cimproved cash register\u201d describes the device as follows: \u201cThe machine consists, essentially, of an inclosed case or frame provided with an index dial and indicator operated by a system of levers or keys and connected with a series of co-operating disks marked with numbers on their peripheries, a row of which numbers are disclosed by a transverse opening or openings in the case to show at a glance the sum-total of cash receipts.\u201d \nSince the registration is done with the process of returning change, according to Bill Bryson odd pricing came about because by charging odd amounts like 49 and 99 cents (or 45 and 95 cents when nickels are more used than pennies), the cashier very probably had to open the till for the penny change and thus announce the sale.\nShortly after the patent, Ritty became overwhelmed with the responsibilities of running two businesses, so he sold all of his interests in the cash register business to Jacob H. Eckert of Cincinnati, a china and glassware salesman, who formed the National Manufacturing Company. In 1884 Eckert sold the company to John H. Patterson, who renamed the company the National Cash Register Company and improved the cash register by adding a paper roll to record sales transactions, thereby creating the journal for internal bookkeeping purposes, and the receipt for external bookkeeping purposes. The original purpose of the receipt was enhanced fraud protection. The business owner could read the receipts to ensure that cashiers charged customers the correct amount for each transaction and did not embezzle the cash drawer. It also prevents a customer from defrauding the business by falsely claiming receipt of a lesser amount of change or a transaction that never happened in the first place. The first evidence of an actual cash register was used in Coalton, Ohio, at the old mining company.\nIn 1906, while working at the National Cash Register company, inventor Charles F. Kettering designed a cash register with an electric motor.\nA leading designer, builder, manufacturer, seller and exporter of cash registers from the 1950s until the 1970s was London-based (and later Brighton-based) Gross Cash Registers Ltd., founded by brothers Sam and Henry Gross. Their cash registers were particularly popular around the time of decimalisation in Britain in early 1971, Henry having designed one of the few known models of cash register which could switch currencies from \u00a3sd to \u00a3p so that retailers could easily change from one to the other on or after Decimal Day. Sweda also had decimal-ready registers where the retailer used a special key on Decimal Day for the conversion.\nIn current use.\nIn some jurisdictions the law also requires customers to collect the receipt and keep it at least for a short while after leaving the shop, again to check that the shop records sales, so that it cannot evade sales taxes.\nOften cash registers are attached to scales, barcode scanners, checkstands, and debit card or credit card terminals. Increasingly, dedicated cash registers are being replaced with general purpose computers with POS software.\nToday, point of sale systems scan the barcode (usually EAN or UPC) for each item, retrieve the price from a database, calculate deductions for items on sale (or, in British retail terminology, \"special offer\", \"multibuy\" or \"buy one, get one free\"), calculate the sales tax or VAT, calculate differential rates for preferred customers, actualize inventory, time and date stamp the transaction, record the transaction in detail including each item purchased, record the method of payment, keep totals for each product or type of product sold as well as total sales for specified periods, and do other tasks as well. These POS terminals will often also identify the cashier on the receipt, and carry additional information or offers.\nCurrently, many cash registers are individual computers. They may be running traditionally in-house software or general purpose software such as DOS. Many of the newer ones have touch screens. They may be connected to computerized point of sale networks using any type of protocol. Such systems may be accessed remotely for the purpose of obtaining records or troubleshooting. Many businesses also use tablet computers as cash registers, utilizing the sale system as downloadable app-software.\nCash drawer.\nA cash drawer is usually a compartment underneath a cash register in which the cash from transactions is kept. The drawer typically contains a removable till. The till is usually a plastic or wooden tray divided into compartments used to store each denomination of bank notes and coins separately in order to make counting easier. The removable till allows money to be removed from the sales floor to a more secure location for counting and creating bank deposits. Some modern cash drawers are individual units separate from the rest of the cash register.\nA cash drawer is usually of strong construction and may be integral with the register or a separate piece that the register sits atop. It slides in and out of its lockable box and is secured by a spring-loaded catch. When a transaction that involves cash is completed, the register sends an electrical impulse to a solenoid to release the catch and open the drawer. Cash drawers that are integral to a stand-alone register often have a manual release catch underneath to open the drawer in the event of a power failure. More advanced cash drawers have eliminated the manual release in favor of a cylinder lock, requiring a key to manually open the drawer. The cylinder lock usually has several positions: locked, unlocked, online (will open if an impulse is given), and release. The release position is an intermittent position with a spring to push the cylinder back to the unlocked position. In the \"locked\" position, the drawer will remain latched even when an electric impulse is sent to the solenoid.\nSome cash drawers are designed to store notes upright &amp; facing forward, instead of the traditional flat and front to back position. This allows more varieties of notes to be stored. Some cash drawers are flip top in design, where they flip open instead of sliding out like an ordinary drawer, resembling a cashbox instead.\nA cash register's drawer can only be opened by an instruction from the cash register except when using special keys, generally held by the owner and some employees (e.g. manager). This reduces the amount of contact most employees have with cash and other valuables. It also reduces risks of an employee taking money from the drawer without a record and the owner's consent, such as when a customer does not expressly ask for a receipt but still has to be given change (cash is more easily checked against recorded sales than inventory). Cash registers include a key labeled \"No Sale\", abbreviated \"NS\" on many modern electronic cash registers. Its function is to open the drawer, printing a receipt stating \"No Sale\" and recording in the register log that the register was opened. Some cash registers require a numeric password or physical key to be used when attempting to open the till.\nManagement functions.\nAn often used non-sale function is the aforementioned \"no sale\". In case of needing to correct change given to the customer, or to make change from a neighboring register, this function will open the cash drawer of the register. Where non-management staff are given access, management can scrutinize the count of \"no sales\" in the log to look for suspicious patterns. Generally requiring a management key, besides programming prices into the register, are the report functions. An X-report will read the current sales figures from memory and produce a paper printout. A Z-report will act like an \"X\" report, except that counters will be reset to zero.\nManual input.\nRegisters will typically feature a numerical pad, QWERTY or custom keyboard, touch screen interface, or a combination of these input methods for the cashier to enter products and fees by hand and access information necessary to complete the sale. For older registers as well as at restaurants and other establishments that do not sell barcoded items, the manual input may be the only method of interacting with the register. While customization was previously limited to larger chains that could afford to have physical keyboards custom-built for their needs, the customization of register inputs is now more widespread with the use of touch screens that can display a variety of point of sale software.\nScanner.\nModern cash registers may be connected to a handheld or stationary barcode reader so that a customer's purchases can be more rapidly scanned than would be possible by keying numbers into the register by hand. The use of scanners should also help prevent errors that result from manually entering the product's barcode or pricing. At grocers, the register's scanner may be combined with a scale for measuring product that is sold by weight.\nReceipt printer.\nCashiers are often required to provide a receipt to the customer after a purchase has been made. Registers typically use thermal printers to print receipts, although older dot matrix printers are still in use at some retailers. Alternatively, retailers can forgo issuing paper receipts in some jurisdictions by instead asking the customer for an email to which their receipt can be sent. The receipts of larger retailers tend to include unique barcodes or other information identifying the transaction so that the receipt can be scanned to facilitate returns or other customer services.\nSecurity deactivation.\nIn stores that use electronic article surveillance, a pad or other surface will be attached to the register that deactivates security devices embedded in or attached to the items being purchased. This will prevent a customer's purchase from setting off security alarms at the store's exit.\nRemote peripherals.\nIn settings like a restaurant, remote pheripherals are sometimes used to speed up processing of orders. These include printers or screens in the kitchen to show staff the incoming orders. Waiters often use mobile devices like phones or tablets connected to a central cash register to takes orders and can use small, mobile bluetooth printers to print receipts directly at the table.\nSelf-service cash register.\nSome corporations and supermarkets have introduced self-checkout machines, where the customer is trusted to scan the barcodes (or manually identify uncoded items like fruit), and place the items into a bagging area. The bag is weighed, and the machine halts the checkout when the weight of something in the bag does not match the weight in the inventory database. Normally, an employee is watching over several such checkouts to prevent theft or exploitation of the machines' weaknesses (for example, intentional misidentification of expensive produce or dry goods). Payment on these machines is accepted by debit card/credit card, or cash via coin slot and bank note scanner. Store employees are also needed to authorize \"age-restricted\" purchases, such as alcohol, solvents or knives, which can either be done remotely by the employee observing the self-checkout, or by means of a \"store login\" which the operator has to enter."}
{"id": "7595", "revid": "949717", "url": "https://en.wikipedia.org/wiki?curid=7595", "title": "Chronometer", "text": ""}
{"id": "7597", "revid": "47740145", "url": "https://en.wikipedia.org/wiki?curid=7597", "title": "Processor design", "text": "Processor design is a subfield of computer science and computer engineering (fabrication) that deals with creating a processor, a key component of computer hardware.\nThe design process involves choosing an instruction set and a certain execution paradigm (e.g. VLIW or RISC) and results in a microarchitecture, which might be described in e.g. VHDL or Verilog. For microprocessor design, this description is then manufactured employing some of the various semiconductor device fabrication processes, resulting in a die which is bonded onto a chip carrier. This chip carrier is then soldered onto, or inserted into a socket on, a printed circuit board (PCB).\nThe mode of operation of any processor is the execution of lists of instructions. Instructions typically include those to compute or manipulate data values using registers, change or retrieve values in read/write memory, perform relational tests between data values and to control program flow.\nProcessor designs are often tested and validated on one or several FPGAs before sending the design of the processor to a foundry for semiconductor fabrication.\nDetails.\nBasics.\nCPU design is divided into multiple components. Information is transferred through datapaths (such as ALUs and pipelines). These datapaths are controlled through logic by control units. Memory components include register files and caches to retain information, or certain actions. Clock circuitry maintains internal rhythms and timing through clock drivers, PLLs, and clock distribution networks. Pad transceiver circuitry with allows signals to be received and sent and a logic gate cell library which is used to implement the logic. Logic gates are the foundation for processor design as they are used to implement most of the processor's components.\nCPUs designed for high-performance markets might require custom (optimized or application specific (see below)) designs for each of these items to achieve frequency, power-dissipation, and chip-area goals whereas CPUs designed for lower performance markets might lessen the implementation burden by acquiring some of these items by purchasing them as intellectual property. Control logic implementation techniques (logic synthesis using CAD tools) can be used to implement datapaths, register files, and clocks. Common logic styles used in CPU design include unstructured random logic, finite-state machines, microprogramming (common from 1965 to 1985), and Programmable logic arrays (common in the 1980s, no longer common).\nImplementation logic.\nDevice types used to implement the logic include:\nA CPU design project generally has these major tasks:\nRe-designing a CPU core to a smaller die area helps to shrink everything (a \"photomask shrink\"), resulting in the same number of transistors on a smaller die. It improves performance (smaller transistors switch faster), reduces power (smaller wires have less parasitic capacitance) and reduces cost (more CPUs fit on the same wafer of silicon). Releasing a CPU on the same size die, but with a smaller CPU core, keeps the cost about the same but allows higher levels of integration within one very-large-scale integration chip (additional cache, multiple CPUs or other components), improving performance and reducing overall system cost.\nAs with most complex electronic designs, the logic verification effort (proving that the design does not have bugs) now dominates the project schedule of a CPU.\nKey CPU architectural innovations include index register, cache, virtual memory, instruction pipelining, superscalar, CISC, RISC, virtual machine, emulators, microprogram, and stack.\nResearch topics.\nA variety of have been proposed,\nincluding reconfigurable logic, clockless CPUs, computational RAM, and optical computing.\nPerformance analysis and benchmarking.\nBenchmarking is a way of testing CPU speed. Examples include SPECint and SPECfp, developed by Standard Performance Evaluation Corporation, and ConsumerMark developed by the Embedded Microprocessor Benchmark Consortium EEMBC.\nSome of the commonly used metrics include:\nThere may be tradeoffs in optimizing some of these metrics. In particular, many design techniques that make a CPU run faster make the \"performance per watt\", \"performance per dollar\", and \"deterministic response\" much worse, and vice versa.\nMarkets.\nThere are several different markets in which CPUs are used. Since each of these markets differ in their requirements for CPUs, the devices designed for one market are in most cases inappropriate for the other markets.\nGeneral purpose computing.\n, in the general-purpose computing market, that is, desktop, laptop, and server computers commonly used in businesses and homes, the Intel IA-32 and the 64-bit version x86-64 architecture dominate the market, with its rivals PowerPC and SPARC maintaining much smaller customer bases. Yearly, hundreds of millions of IA-32 architecture CPUs are used by this market. A growing percentage of these processors are for mobile implementations such as netbooks and laptops.\nSince these devices are used to run countless different types of programs, these CPU designs are not specifically targeted at one type of application or one function. The demands of being able to run a wide range of programs efficiently has made these CPU designs among the more advanced technically, along with some disadvantages of being relatively costly, and having high power consumption.\nHigh-end processor economics.\nIn 1984, most high-performance CPUs required four to five years to develop.\nScientific computing.\nScientific computing is a much smaller niche market (in revenue and units shipped). It is used in government research labs and universities. Before 1990, CPU design was often done for this market, but mass market CPUs organized into large clusters have proven to be more affordable. The main remaining area of active hardware design and research for scientific computing is for high-speed data transmission systems to connect mass market CPUs.\nEmbedded design.\nAs measured by units shipped, most CPUs are embedded in other machinery, such as telephones, clocks, appliances, vehicles, and infrastructure. Embedded processors sell in the volume of many billions of units per year, however, mostly at much lower price points than that of the general purpose processors.\nThese single-function devices differ from the more familiar general-purpose CPUs in several ways:\nEmbedded processor economics.\nThe embedded CPU family with the largest number of total units shipped is the 8051, averaging nearly a billion units per year. The 8051 is widely used because it is very inexpensive. The design time is now roughly zero, because it is widely available as commercial intellectual property. It is now often embedded as a small part of a larger system on a chip. The silicon cost of an 8051 is now as low as US$0.001, because some implementations use as few as 2,200 logic gates and take 0.4730 square millimeters of silicon.\nAs of 2009, more CPUs are produced using the ARM architecture family instruction sets than any other 32-bit instruction set.\nThe ARM architecture and the first ARM chip were designed in about one and a half years and 5 human years of work time.\nThe 32-bit Parallax Propeller microcontroller architecture and the first chip were designed by two people in about 10 human years of work time.\nThe 8-bit AVR architecture and first AVR microcontroller was conceived and designed by two students at the Norwegian Institute of Technology.\nThe 8-bit 6502 architecture and the first MOS Technology 6502 chip were designed in 13 months by a group of about 9 people.\nResearch and educational CPU design.\nThe 32-bit Berkeley RISC I and RISC II processors were mostly designed by a series of students as part of a four quarter sequence of graduate courses.\nThis design became the basis of the commercial SPARC processor design.\nFor about a decade, every student taking the 6.004 class at MIT was part of a team\u2014each team had one semester to design and build a simple 8 bit CPU out of 7400 series integrated circuits.\nOne team of 4 students designed and built a simple 32 bit CPU during that semester.\nSome undergraduate courses require a team of 2 to 5 students to design, implement, and test a simple CPU in a FPGA in a single 15-week semester.\nThe MultiTitan CPU was designed with 2.5 man years of effort, which was considered \"relatively little design effort\" at the time.\n24 people contributed to the 3.5 year MultiTitan research project, which included designing and building a prototype CPU.\nSoft microprocessor cores.\nFor embedded systems, the highest performance levels are often not needed or desired due to the power consumption requirements. This allows for the use of processors which can be totally implemented by logic synthesis techniques. These synthesized processors can be implemented in a much shorter amount of time, giving quicker time-to-market."}
{"id": "7598", "revid": "47133325", "url": "https://en.wikipedia.org/wiki?curid=7598", "title": "Carinatae", "text": "Carinatae is the group of all birds and their extinct relatives to possess a keel, or \"carina\", on the underside of the breastbone used to anchor large flight muscles.\nDefinition.\nTraditionally, Carinatae were defined as all birds whose sternum (breast bone) has a keel (\"carina\"). The keel is a strong median ridge running down the length of the sternum. This is an important area for the attachment of flight muscles. Thus, all flying birds have a pronounced keel. Ratites, all of which are flightless, lack a strong keel. Thus, living birds were divided into carinatae (keeled) and ratites (from \"ratis\", \"raft\", referring to the flatness of the sternum). The difficulty with this scheme phylogenetically was that some flightless birds, without strong keels, are descended directly from ordinary flying birds possessing one. Examples include the k\u0101k\u0101p\u014d, a flightless parrot, and the dodo, a columbiform (the pigeon family). Neither of these birds are a ratite. Thus, this supposedly distinctive feature was easy to use, but had nothing to do with actual phylogenetic relationship.\nBeginning in the 1980s, Carinatae was given several phylogenetic definitions. The first was as a node-based clade uniting \"Ichthyornis\" with modern birds. However, in many analyses, this definition would be synonymous with the more widely used name Ornithurae. An alternate definition was provided in 2001, naming Carinatae an apomorphy-based clade defined by the presence of a keeled sternum.\nThe most primitive known bird relative with a keeled breastbone is \"Confuciusornis\". While some specimens of this stem-bird have flat breastbones, some show a small ridge that could have supported a cartilaginous keel."}
{"id": "7599", "revid": "1267075867", "url": "https://en.wikipedia.org/wiki?curid=7599", "title": "Cocktail", "text": "A cocktail is a mixed drink, usually alcoholic. Most commonly, a cocktail is a combination of one or more spirits mixed with other ingredients, such as juices, flavored syrups, tonic water, shrubs, and bitters. Cocktails vary widely across regions of the world, and many websites publish both original recipes and their own interpretations of older and more famous cocktails.\nHistory.\nA well-known 'cocktail' in ancient Greece was named kykeon. It is mentioned in the Homeric texts and was used in the Eleusinian Mysteries. 'Cocktail' accessories are exposed in the Museum of the Royal Tombs of Aigai (Greece). They were used in the court of Philip II of Macedon to prepare and serve mixtures of wine, water, honey as well as extracts of aromatic herbs and flowers, during the banquets. \nIn the United States, a written mention of 'cocktail' as a beverage appeared in \"The Farmers Cabinet,\" 1803. The first definition of a cocktail as an alcoholic beverage appeared three years later in \"The Balance and Columbian Repository\" (Hudson, New York) May 13, 1806. Traditionally, cocktail ingredients included spirits, sugar, water and bitters; however, this definition evolved throughout the 1800s to include the addition of a liqueur.\nIn 1862, Jerry Thomas published a bartender's guide called \"How to Mix Drinks; or, The Bon Vivant's Companion\" which included 10 cocktail recipes using bitters, to differentiate from other drinks such as punches and cobblers.\nCocktails continued to evolve and gain popularity throughout the 1900s, with the term eventually expanding to cover all mixed drinks. In 1917, the term \"cocktail party\" was coined by Julius S. Walsh Jr. of St. Louis, Missouri. With wine and beer being less available during the Prohibition in the United States (1920\u20131933), liquor-based cocktails became more popular due to accessibility, followed by a decline in popularity during the late 1960s. The early to mid-2000s saw the rise of cocktail culture through the style of mixology which mixes traditional cocktails and other novel ingredients. By 2023, the so-called \"cocktail in a can\" had proliferated (at least in the United States) to become a common item in liquor stores.\nIn the modern world and the Information Age, cocktail recipes are widely shared online on websites. Cocktails and restaurants that serve them are frequently covered and reviewed in tourism magazines and guides. Some cocktails, such as the Mojito, Manhattan, and Martini, have become staples in restaurants and pop culture.\nComponents.\nIn general terms the most important elements consist of the base, a modifying, smoothing or aromatizing agent, and an additional special flavouring or coloring agent.\nThe base will always be the most dominant ingredient. It constitutes at least 50% of the entire volume of the cocktail, and always consists of spirit based liquors or wine based liquors. The type of base will determine the style of liquor, thus gin based cocktails, such as the Martini, will differ from whisky based cocktails, such as the Manhattan. It is possible to mix a cocktail combining a number of bases, as long as they share essential characteristics, though it is considered \"dangerous\".\nThe modifying agent functions as a buffer for the sharp bite of the base, and adds character to its natural flavour. Modifiers can be classified into the three categories of aromatics and bitters, fruit juices (with or without sugar), and smoothing agents (such as cream, sugar or eggs). Modifiers are often used sparingly so as not to overpower the base, Embury suggested a maximum of half an egg white, one quarter of a whole egg, one tablespoon of heavy cream or one teaspoon of sugar per drink.\nSpecial flavouring agents, including not only non-alcoholic syrups but also various liqueurs and cordials, as well as other ingredients which could also be used as modifiers. Like the modifiers, special care must be taken so that the special flavouring agent does not overpower the base. For this reason quantities are often limited to drops and dashes.\nUsage and related terms.\nThe term \"cocktail\" can refer to a wide variety of drinks; it is typically a mixed drink containing alcohol.\nWhen a combined drink contains only a distilled spirit and a mixer, such as soda or fruit juice, it is a highball. Many of the International Bartenders Association Official Cocktails are highballs. When a mixed drink contains only a distilled spirit and a liqueur, it is a duo, and when it adds cream or a cream-based liqueur, it is a trio. Additional ingredients may be sugar, honey, milk, cream, and various herbs.\nMixed drinks without alcohol that resemble cocktails can be known as \"zero-proof\" or \"virgin\" cocktails or \"mocktails\".\nEtymology.\nThe origin of the word \"cocktail\" is disputed. It is presumably from \"cock-tail\", meaning \"with tail standing up, like a cock's\", in particular of a horse, but how this came to be applied to alcoholic mixed drinks is unclear. The most prominent theories are that it refers to a stimulant, hence a \"stimulating\" drink, or to a non-purebred horse, hence a \"mixed\" drink.\nCocktail historian David Wondrich speculates that \"cocktail\" is a reference to gingering, a practice for perking up an old horse by means of a ginger suppository so that the animal would \"cock its tail up and be frisky\", hence by extension a stimulating drink, like \"pick-me-up\". This agrees with usage in early citations (1798: \"'cock-tail' (vulgarly called ginger)\", 1803: drink at 11 a.m. to clear the head, 1806: \"stimulating liquor\"), and suggests that a cocktail was initially considered a medicinal drink, which accords with the use of bitters.\nEtymologist Anatoly Liberman endorses as \"highly probable\" the theory advanced by L\u00e5ftman (1946), which Liberman summarizes as follows:\nCitations.\nThe first recorded use of cocktail not referring to a horse is found in \"The Morning Post and Gazetteer\" in London, England, March 20, 1798:\nThe \"Oxford English Dictionary\" cites the word as originating in the U.S. The first recorded use of \"cocktail\" as a beverage (possibly non-alcoholic) in the United States appears in \"The Farmer's Cabinet\", April 28, 1803:\nThe first definition of cocktail known to be an alcoholic beverage appeared in \"The Balance and Columbian Repository\" (Hudson, New York) May 13, 1806; editor Harry Croswell answered the question, \"What is a cocktail?\":\nFolk etymologies.\nOther origins have been suggested, as corruptions of other words or phrases. These can be dismissed as folk etymologies, given the well-attested term \"cock-tail\" for a horse.\nDale DeGroff hypothesizes that the word evolved from the French , for an eggcup in which Antoine A. Peychaud, creator of Peychaud's Bitters, allegedly used to serve his guests a mix of cognac with a dash of his bitters.\nSeveral authors have theorized that \"cocktail\" may be a corruption of \"cock ale\".\nDevelopment.\nThere is a lack of clarity on the origins of cocktails. Traditionally cocktails were a mixture of spirits, sugar, water, and bitters. By the 1860s, however, a cocktail frequently included a liqueur.\nThe first publication of a bartenders' guide which included cocktail recipes was in 1862 \u2013 \"How to Mix Drinks; or, The Bon Vivant's Companion\", by \"Professor\" Jerry Thomas. In addition to recipes for punches, sours, slings, cobblers, shrubs, toddies, flips, and a variety of other mixed drinks were 10 recipes for \"cocktails\". A key ingredient distinguishing cocktails from other drinks in this compendium was the use of bitters. Mixed drinks popular today that conform to this original meaning of \"cocktail\" include the Old Fashioned whiskey cocktail, the Sazerac cocktail, and the Manhattan cocktail.\nThe ingredients listed (spirits, sugar, water, and bitters) match the ingredients of an Old Fashioned, which originated as a term used by late 19th-century bar patrons to distinguish cocktails made the \"old-fashioned\" way from newer, more complex cocktails.\nIn the 1869 recipe book \"Cooling Cups and Dainty Drinks\", by William Terrington, cocktails are described as:\nThe term highball appears during the 1890s to distinguish a drink composed only of a distilled spirit and a mixer.\nPublished in 1902 by Farrow and Jackson, \"Recipes of American and Other Iced Drinks\" contains recipes for nearly two dozen cocktails, some still recognizable today.\nThe first \"cocktail party\" ever thrown was allegedly by Julius S. Walsh Jr. of St. Louis, Missouri, in May 1917. Walsh invited 50 guests to her home at noon on a Sunday. The party lasted an hour until lunch was served at 1p.m. The site of this first cocktail party still stands. In 1924, the Roman Catholic Archdiocese of St. Louis bought the Walsh mansion at 4510 Lindell Boulevard, and it has served as the local archbishop's residence ever since.\nDuring Prohibition in the United States (1920\u20131933), when alcoholic beverages were illegal, cocktails were still consumed illegally in establishments known as speakeasies. The quality of the liquor available during Prohibition was much worse than previously. There was a shift from whiskey to gin, which does not require aging and is, therefore, easier to produce illicitly. Honey, fruit juices, and other flavorings served to mask the foul taste of the inferior liquors. Sweet cocktails were easier to drink quickly, an important consideration when the establishment might be raided at any moment. With wine and beer less readily available, liquor-based cocktails took their place, even becoming the centerpiece of the new cocktail party.\nCocktails became less popular in the late 1960s and through the 1970s, until resurging in the 1980s with vodka often substituting for the original gin in drinks such as the martini. Traditional cocktails began to make a comeback in the 2000s, and by the mid-2000s there was a renaissance of cocktail culture in a style typically referred to as mixology that draws on traditional cocktails for inspiration but uses novel ingredients and often complex flavors."}
{"id": "7601", "revid": "18054835", "url": "https://en.wikipedia.org/wiki?curid=7601", "title": "Coptic Orthodox Church", "text": "The Coptic Orthodox Church (), also known as the Coptic Orthodox Patriarchate of Alexandria, is an Oriental Orthodox Christian church based in Egypt. The head of the church and the See of Alexandria is the pope of Alexandria on the Holy Apostolic See of Saint Mark, who also carries the title of Father of fathers, Shepherd of shepherds, Ecumenical Judge and the 13th among the Apostles. \nThe See of Alexandria is titular. The Coptic pope presides from Saint Mark's Coptic Orthodox Cathedral in the Abbassia District in Cairo. The church follows the Coptic Rite for its liturgy, prayer and devotional patrimony. Adherents of the Coptic Orthodox Church make up Egypt's largest and most significant minority population, and the largest population of Christians in the Middle East and North Africa (MENA). They make up the largest share of the approximately 20 million Christians in Egypt.\nThe Coptic Orthodox Church was established by Mark, an apostle and evangelist, during the middle of the 1st century (). Due to disputes concerning the nature of Christ, the Oriental Orthodox Churches and the Eastern Orthodox Church were in schism after the Council of Chalcedon in AD 451, resulting in a conflict with the Greek Orthodox Church of Alexandria.\nAfter AD 639, Egypt was ruled by its Islamic conquerors from Arabia. In the 12th century, the church relocated its seat from Alexandria to Cairo. The same century also saw the Copts become a religious minority. During the 14th and 15th centuries, Nubian Christianity was supplanted by Islam. In the 19th and 20th centuries, the larger body of ethnic Egyptian Christians began to call themselves Coptic Orthodox, to distinguish themselves from the Catholic Copts and from the Eastern Orthodox, who are mostly Greek. In 1959, the Ethiopian Orthodox Tewahedo Church was granted autocephaly. This was extended to the Eritrean Orthodox Tewahedo Church in 1998 following the successful Eritrean War of Independence from Ethiopia. Since the 2011 Egyptian revolution, Coptic Christians have suffered increased religious discrimination and violence.\nHistory.\nApostolic foundation.\nAccording to tradition, the Coptic Church was founded by Mark the Evangelist , and regards itself as the subject of many prophecies in the Old Testament. \nCoptic language in the church.\nThe Coptic language is a universal language used in Coptic churches in every country. It descends from Ancient Egyptian and uses the Coptic alphabet, a script descended from the Greek alphabet with added characters derived from the Demotic script. Today, the Bohairic dialect of Coptic is used primarily for liturgical purposes. Many of the hymns in the liturgy are in Coptic and have been passed down for many centuries. The language is used to preserve Egypt's original language, which was banned by the Arab invaders, who ordered Arabic to be used instead. However, most Copts speak Arabic, the official language of Egypt. Hence, Arabic is also used in church services nowadays. The service books, though written in Coptic, have the Arabic text in parallel columns.\nCatechetical School of Alexandria.\nThe Catechetical School of Alexandria is the oldest catechetical school in the world. Jerome records that the Christian School of Alexandria was founded by Mark himself.\nThe theological college of the catechetical school was re-established in 1893.\nThe school became a leading center of the allegorical method of biblical interpretation, espoused a rapprochement between Greek culture and Christian faith, and attempted to assert orthodox Christian teachings against heterodox views in an era of doctrinal flux.\nCouncil of Nicaea.\nIn the 4th century, an Alexandrian presbyter named Arius began a theological dispute about the nature of Christ that spread throughout the Christian world and is now known as Arianism. The Council of Nicea in AD\u00a0325 was convened by Emperor Constantine I after Pope Alexander I of Alexandria requested to hold a council to respond to heresies, under the presidency of Hosius of Cordova to resolve the dispute. This eventually led to the formulation of the Symbol of Faith, also known as the Nicene Creed.\nCouncil of Constantinople.\nIn AD\u00a0381, Pope Timothy I of Alexandria presided over the second ecumenical council known as the First Council of Constantinople, to judge Macedonius, who denied the Divinity of the Holy Spirit. This council completed the Nicene Creed with this confirmation of the divinity of the Holy Spirit:\nWe believe in the Holy Spirit, the Lord, the Giver of Life, who proceeds from the Father, who with the Father and the Son is worshiped and glorified who spoke by the Prophets and in One, Holy, Catholic, and Apostolic church. We confess one Baptism for the remission of sins and we look for the resurrection of the dead and the life of the coming age, Amen\nCouncil of Ephesus.\nAnother theological dispute in the 5th century occurred over the teachings of Nestorius, the patriarch of Constantinople who taught that God the Word was not hypostatically joined with human nature, but rather dwelt in the man Jesus. As a consequence of this, he denied the title \"Mother of God\" (Theotokos) to the Virgin Mary, declaring her instead to be \"Mother of Christ\" \"Christotokos\".\nThe council confirmed the teachings of Athanasius and confirmed the title of Mary as \"Mother of God\". It also clearly stated that anyone who separated Christ into two hypostases was anathema, as Cyril had said that there is \"One Nature for God the Word Incarnate\" (\"Mia Physis tou Theou Logou Sesark\u014dmen\u0113\"). The introduction to the creed is formulated as follows:\nWe magnify you O Mother of the True Light and we glorify you O saint and Mother of God \"(Theotokos)\" for you have borne unto us the Saviour of the world. Glory to you O our Master and King: Christ, the pride of the Apostles, the crown of the martyrs, the rejoicing of the righteous, firmness of the churches and the forgiveness of sins. We proclaim the Holy Trinity in One Godhead: we worship Him, we glorify Him, Lord have mercy, Lord have mercy, Lord bless us, Amen.\nCouncil of Chalcedon.\nThe church of Alexandria was part in communion with the rest of Christendom until the Council of Chalcedon. When, in AD\u00a0451, Emperor Marcian attempted to heal divisions in the church, the response of Pope Dioscorus\u2013the Pope of Alexandria who was later exiled\u2013was that the emperor should not intervene in the affairs of the church. It was at Chalcedon that the emperor, through the imperial delegates, enforced harsh disciplinary measures against Pope Dioscorus in response to his boldness. In AD\u00a0449, Pope Dioscorus headed the 2nd Council of Ephesus, called the \"Robber Council\" by Chalcedonian historians. It held to the Miaphysite formula which upheld the Christology of \"One Incarnate Nature of God the Word\" (Greek: \u03bc\u03af\u03b1 \u03c6\u03cd\u03c3\u03b9\u03c2 \u0398\u03b5\u03bf\u1fe6 \u039b\u03cc\u03b3\u03bf\u03c5 \u03c3\u03b5\u03c3\u03b1\u03c1\u03ba\u03c9\u03bc\u03ad\u03bd\u03b7 (\"mia physis Theou Logou sesark\u014dmen\u0113\")).\nIn terms of Christology, the Oriental Orthodox (Non-Chalcedonians) understanding is that Christ is \"One Nature\u2014the Logos Incarnate,\" \"of\" the full humanity and full divinity. The Chalcedonians' understanding is that Christ is \"recognized in\" two natures, full humanity and full divinity. Oriental Orthodoxy contends that such a formulation is no different from what the Nestorians teach.\nFrom that point onward, Alexandria would have two patriarchs: the non-Chalcedonian native Egyptian one, now known as the Coptic pope of Alexandria and patriarch of All Africa on the Holy Apostolic See of St. Mark, and the Melkite or Imperial patriarch, now known as the Greek Orthodox patriarch of Alexandria.\nAlmost the entire Egyptian population rejected the terms of the Council of Chalcedon and remained faithful to the native Egyptian Church (now known as the Coptic Orthodox Church).\nBy anathematizing Pope Leo because of the tone and content of his tome, as per Alexandrine Theology perception, Pope Dioscorus was found guilty of doing so without due process; in other words, the Tome of Leo was not a subject of heresy in the first place, but it was a question of questioning the reasons behind not having it either acknowledged or read at the Second Council of Ephesus in AD\u00a0449. Pope Dioscorus of Alexandria was never labeled as a heretic by the council's canons.\nCopts also believe that the pope of Alexandria was forcibly prevented from attending the third congregation of the council from which he was ousted, apparently the result of a conspiracy tailored by the Roman delegates.\nBefore the current positive era of Eastern and Oriental Orthodox dialogues, Chalcedonians sometimes used to call the non-Chalcedonians \"Monophysites\", though the Coptic Orthodox Church in reality regards Monophysitism as a heresy. The Chalcedonian doctrine in turn came to be known as \"Dyophysite\". A term that comes closer to Coptic Orthodoxy is Miaphysite, which refers to a conjoined nature for Christ, both human and divine, united indivisibly in the Incarnate Logos.\nMuslim conquest of Egypt.\nThe Muslim invasion of Egypt took place in AD\u00a0639. Relying on eyewitness testimony, Bishop John of Nikiu in his Chronicle provides a graphic account of the invasion from a Coptic perspective. Although the Chronicle has only been preserved in an Ethiopic (Ge'ez) text, some scholars believe that it was originally written in Coptic. John's account is critical of the invaders who he says \"despoiled the Egyptians of their possessions and dealt cruelly with them\", and he details the atrocities committed by the Muslims against the native population during the conquest:And when with great toil and exertion they had cast down the walls of the city, they forthwith made themselves masters of it, and put to the sword thousands of its inhabitants and of the soldiers, and they gained an enormous booty, and took the women and children captive and divided them amongst themselves, and they made that city a desolation.\nThough critical of the Muslim commander (Amr ibn al-As), who, during the campaign, he says \"had no mercy on the Egyptians, and did not observe the covenant they had made with him, for he was of a barbaric race\", he does note that following the completion of the conquest, Amr \"took none of the property of the Churches, and he committed no act of spoilation or plunder, and he preserved them throughout all his days.\"\nDespite the political upheaval, the Egyptian population remained mainly Christian. However, gradual conversions to Islam over the centuries had changed Egypt from a Christian to a largely Muslim country by the end of the 12th century. Another scholar writes that a combination of \"repression of Coptic revolts\", Arab-Muslim immigration, and Coptic conversion to Islam resulted in the demographic decline of the Copts. Egypt's Umayyad rulers taxed Christians at a higher rate than Muslims, driving merchants towards Islam and undermining the economic base of the Coptic Church. Although the Coptic Church did not disappear, the Umayyad tax policies made it difficult for the church to retain the Egyptian elites.\nUnder Islamic rule (640\u20131800).\nIn 969, Egypt entered the Fatimid dynasty (in Egypt from 969 to 1171), who adopted a largely favorable attitude toward the Christians. The major exception to this was the persecution led by Caliph al-Hakim between 1004 and 1013, which included clothing regulations, prohibition of publicly celebrating Christian festivals, and dismissal of Christian and Jewish functionaries. However, at the end of his reign al-Hakim rescinded these measures, allowing the Copts to regain privileged positions within the administration.\nThe Coptic patriarchal residence moved from Alexandria to Cairo during the patriarchate of Cyril II (1078\u201392). This move was at the demand of the grand vizier Badr al-Jamali, who insisted that the pope establish himself in the capital. When Saladin entered Egypt in 1163, this ushered in a government focused on defending Sunni Islam. Christians were again discriminated against, and meant to show modesty in their religious ceremonies and buildings.\nDuring the Ottoman period, Copts were classified alongside other Oriental Orthodox and Nestorian peoples under the Armenian millet.\nIn 1798, the French invaded Egypt unsuccessfully and the British helped the Turks to regain power over Egypt under the Muhammad Ali dynasty.\nFrom the 19th century to the 1952 revolution.\nThe position of Copts began to improve early in the 19th century under the stability and tolerance of the Muhammad Ali Dynasty. The Coptic community ceased to be regarded by the state as an administrative unit. In 1855 the jizya tax was abolished by Sa'id Pasha. Shortly thereafter, the Copts started to serve in the Egyptian army.\nTowards the end of the 19th century, the Coptic Church underwent phases of new development. In 1853, Pope Cyril IV established the first modern Coptic schools, including the first Egyptian school for girls. He also founded a printing press, which was only the second national press in the country. The pope established very friendly relations with other denominations, to the extent that when the Greek Patriarch in Egypt had to absent himself from the country for a long period of time, he left his church under the guidance of the Coptic patriarch.\nThe Theological College of the School of Alexandria was reestablished in 1893. It began its new history with five students, one of whom was later to become its dean. Today it has campuses in Alexandria and Cairo, and in various dioceses throughout Egypt, as well as outside Egypt. It has campuses in New Jersey, Los Angeles, Sydney, Melbourne, and London, where potential clergymen and other qualified men and women study many subjects, including theology, church history, missionary studies, and the Coptic language.\nPresent day.\nIn 1959, the Ethiopian Orthodox Tewahedo Church was granted its first own Patriarch Abuna Basilios by Pope Cyril VI. Furthermore, the Eritrean Orthodox Tewahedo Church similarly became independent of the Ethiopian Orthodox Tewahedo Church in 1994, when four bishops were consecrated by Pope Shenouda III of Alexandria to form the basis of a local Holy Synod of the Eritrean Church. In 1998, the Eritrean Orthodox Tewahedo Church gained its autocephaly from the Coptic Orthodox Church when its first Patriarch was enthroned by Pope Shenouda III.\nSince the 1980s theologians from the Oriental (non-Chalcedonian) Orthodox and Eastern (Chalcedonian) Orthodox churches have been meeting in a bid to resolve theological differences, and have concluded that many of the differences are caused by the two groups using different terminology to describe the same thing.\nIn the summer of 2001, the Coptic Orthodox and Greek Orthodox patriarchates of Alexandria agreed to mutually recognize baptisms performed in each other's churches, making re-baptisms unnecessary, and to recognize the sacrament of marriage as celebrated by the other.\nIn Tahrir Square, Cairo, on Wednesday 2 February 2011, Coptic Christians joined hands to provide a protective cordon around their Muslim neighbors during salat (prayers) in the midst of the 2011 Egyptian Revolution.\nModern persecution.\nWhile Copts have cited instances of persecution throughout their history, Human Rights Watch has noted growing religious intolerance and sectarian violence against Coptic Christians in recent years, and a failure by the Egyptian government to effectively investigate properly and prosecute those responsible. More than a hundred Egyptian copts were killed in sectarian clashes from 2011 to 2017, and many homes and businesses destroyed. In Minya, 77 cases of sectarian attacks on Copts between 2011 and 2016 were documented by the Egyptian Initiative for Personal Rights. Coptic Christian women and girls are often abducted and disappear.\nIn 2015, 21 men traveled to Libya to support their families. There, they would be kidnapped and beheaded by the Islamic State in Libya.\nRecent Church reforms.\nUnder Pope Shenouda, from 1971 to 2012, the church underwent a large transformation. Writing in 2013, the theologian Samuel Tadros stated \"Today's Coptic Church as an institution is built solely on his vision\". For the first time in its history, the synod codified its internal laws. It also established numerous coptic institutions within and outside of Egypt. Shenouda raised the number of bishops from 26 to 117 and ordained hundreds of priests, which greatly reduced the influence of any one bishop. Shenouda also instituted a yearly meeting of the synod, which greatly expanded the number of laws governing the church. This included instituting church curriculums for the education of new priests, new deacons, and newly weds. For the first time in the Coptic Church's modern history, women could become ordained as deacons. The synod also adopted a model for community development, dramatically increasing the scope of community services provided by the church, including: hospitals, adult literacy schools, orphanages, libraries, and community centres. Much of this work was fuelled by donations from wealthy Coptic industrialists and Copts from abroad. Shenouda also held talks with the Eastern Orthodox and Roman Catholic churches, in an effort to promote ecumenism . On 10 May 1973, Pope Shenouda visited the Vatican, where a joint Christological declaration was issued jointly by the Coptic Orthodox and Catholic churches.\nPope Shenouda III also increased the Church's involvement in politics, seeing it as a way to advocate for the interest of Copts, during the rise of Islamism in Egypt and increase in terrorist attacks. The president of Egypt, Anwar Sadat ordered that Shenouda be put into exile in a Coptic Monastery far away from Cairo in 1981. This exile was short lived, ending when Sadat was assassinated by Muslim extremists a few months later. Under president Hosni Mubarak, Shenouda continued his political stance and often protested persecution of Copts by leaving Cairo and staying in seclusion, which often caused the regime to quickly address issues. Shenouda's political involvement drew criticism from some church members, including the prominent monk Father Matta El Meskeen.\nOn 17 March 2012, the Coptic Orthodox Pope, Pope Shenouda III died, leaving many Copts mourning and worrying as tensions rose with Muslims. Pope Shenouda III constantly met with Muslim leaders in order to create peace. Many were worried about Muslims controlling Egypt as the Muslim Brotherhood won 70% of the parliamentary elections. Shenouda's approach to church leadership has, in part, been adopted by the current patriarch. Pope Tawadros II of Alexandria maintains relations with the Egyptian government and other churches. However, while Shenouda was critical of the expanded influence of Protestant teaching and books in Coptic churches, Tawadros has increased ecumenical dialogue with several Protestant churches. Tawadros is also not as involved political protests and does not publicly criticize the Egyptian regime, often resorting to advocacy instead.\nIn 2020, a woman in Florida accused a former priest of sexual assault when she was a minor. She claimed that he was defrocked in 2014, but continued presenting himself as a priest. In response, the synod issued a public statement disavowing him and instituted anti-abuse measures. Several diocese in North America and Europe, issued statements in support of sexual assault survivors.\nOn 10 May 2023, Pope Tawadros visited the Vatican to celebrate Coptic Catholic Friendship day and the 50 year anniversary of the meeting between Pope Paul VI and Pope Shenouda. Pope Francis announced that the 21 Coptic Martyrs killed by ISIS in Libya in 2015 would be added to the Catholic Roman Martyrology. Pope Tawadros gifted relics from each of the 21 martyrs to the Vatican.\nFasts, feasts, liturgy and canonical hours.\nCommunicants of the Coptic Orthodox Church use a breviary known as the Agpeya to pray the canonical hours at seven fixed prayer times while facing in the eastward direction, in anticipation of the Second Coming of Jesus; this Christian practice has its roots in Psalm 119:164, in which the prophet David prays to God seven times a day. Church bells enjoin Christians to pray at these hours. Before praying, they wash their hands and face to be clean before and present their best to God; shoes are removed to acknowledge that one is offering prayer before a holy God. During each of the seven fixed prayer times, Coptic Orthodox Christians pray \"prostrating three times in the name of the Trinity; at the end of each Psalm \u2026 while saying the 'Alleluia';\" and 41 times for each of the Kyrie eleisons present in a canonical hour. In the Coptic Orthodox Church, it is customary for women to wear a Christian headcovering when praying. The Coptic Orthodox Church observes days of ritual purification. However, while meat that still contains blood after cooking is discouraged from being eaten, the Coptic Church does not forbid its members from consuming any particular type of food, unlike in Islam or Judaism.\nAll churches of the Coptic Orthodox Church are designed to face the eastward direction of prayer and efforts are made to remodel churches obtained from other Christian denominations that are not built in this fashion.\nIn Coptic Orthodox Christianity, fasting is defined as going without meat or dairy. With respect to Eucharistic discipline, Coptic Orthodox Christians fast from midnight onwards (or at least nine hours) prior to receiving the sacrament of Holy Communion. They fast every Wednesday and Friday of the year (Wednesdays in remembrance of the betrayal of Christ, and on Fridays in remembrance of His crucifixion and death). In total, fast days in a year for Coptic Orthodox Christians numbers between 210 and 240. This means that Copts abstain from all animal products for up to two-thirds of each year. The fasts for Advent and Lent are 43 days and 55 days, respectively. In August, before the celebration of the Dormition of the Mother of God, Coptic Christians fast 15 days; fasting is also done before the feast of Feast of Saints Peter and Paul, starting from the day of Pentecost. Married couples refrain from sexual relations during Lent \"to give themselves time for fasting and prayer\".\nChristmas has been a national holiday in Egypt since 2003. It is the only Christian holiday in Egypt. Coptic Christmas, which usually falls on January 6 or 7 is a major feast. Other major feasts are Epiphany, Palm Sunday, Easter, Pentecost, Ascension, and Annunciation. These are known in the Coptic world as the Seven Major Feasts. Major feasts are always preceded by fasts. Additionally, the Coptic Orthodox Church also has Seven Minor Feasts: the Circumcision of the Lord, Entrance into the Temple, Entrance into Egypt, Transfiguration, Maundy Thursday, Thomas Sunday, and Great Lent. Furthermore, there are several indigenous feasts of the Theotokos. There are also other feasts commemorating the martyrdom of important saints from Coptic history.\nDemographics.\nAvailable Egyptian census figures and other third-party survey reports have not reported more than 4 million Coptic Orthodox Christians in Egypt. However media and other agencies, sometimes taking into account the claims of the church itself, generally approximate the Coptic Orthodox population at 10% of the Egyptian population or 10 million people. Egyptian Copts are the biggest Christian community in the Arab world. Estimates of their numbers vary, but generally range between 4.7 and 7.1 million. The majority of them live in Egypt under the jurisdiction of the Coptic Orthodox Church. Since 2006, Egyptian censuses have not reported on religion and church leaders have alleged that Christians were under-counted in government surveys. In 2017, a government owned newspaper Al Ahram estimated the percentage of Copts at 10 to 15% and the membership claimed by the Coptic Orthodox Church is in the range of 20 to 25 million.\nThere are also significant numbers in the diaspora outside Africa in countries such as the United States, Canada, Australia, France, and Germany. The exact number of Egyptian born Coptic Orthodox Christians in the diaspora is hard to determine and is roughly estimated to be close to 1 million.\nThere are between 150,000 and 200,000 adherents in Sudan.\nJurisdiction outside Egypt.\nBesides Egypt, the Church of Alexandria has jurisdiction over all of Africa. The following autocephalous churches have strong historical ties to the Coptic Orthodox Church.\nEthiopian Orthodox Tewahedo Church.\nTradition holds that Ethiopia was first evangelized by St. Matthew and St. Bartholomew in the 1st century ce, and the first Ethiopian convert is thought to have been the eunuch in Jerusalem mentioned in The Acts of the Apostles (8:27\u201340). Ethiopia was further Christianized in the 4th century ce by two men (likely brothers) from Tyre\u2014St. Frumentius. Ever since the conversion of Ezana of Axum to Christianity by Frumentius in 325 AD, the Ethiopian Orthodox Tewahedo Church has received its archbishops from the Coptic Orthodox Church. Until the mid-twentieth century, the metropolitans of the Ethiopian church were ethnic Copts. Joseph II consecrated Archbishop Abuna Basilios as the first native head of the Ethiopian Church on 14 January 1951. In 1959, Pope Cyril VI of Alexandria crowned Abuna Basilios as the first Patriarch of Ethiopia.\nEritrean Orthodox Tewahedo Church.\nFollowing the independence of Eritrea from Ethiopia in 1993, the newly independent Eritrean government appealed to Pope Shenouda III of Alexandria for Eritrean Orthodox autocephaly. In 1994, Pope Shenouda ordained Abune Phillipos as first Archbishop of Eritrea.\nAdministration.\nThe Coptic Orthodox Patriarchate of Alexandria is governed by its Holy Synod, which is headed by the Patriarch of Alexandria. Under his authority are the metropolitan archbishops, metropolitan bishops, diocesan bishops, patriarchal exarchs, missionary bishops, auxiliary bishops, suffragan bishops, assistant bishops, chorbishops and the patriarchal vicars for the Church of Alexandria."}
{"id": "7602", "revid": "14965160", "url": "https://en.wikipedia.org/wiki?curid=7602", "title": "The Family International", "text": "The Family International (TFI) is an American new religious movement founded in 1968 by David Brandt Berg. The group has gone under a number of different names since its inception, including Teens for Christ, The Children of God (COG), The Family of Love, or simply The Family.\nA British court case found the group was an authoritarian cult which engaged in the systematic physical and sexual abuse of children, resulting in lasting trauma among survivors. The group has also been accused of targeting vulnerable people.\nOverview.\nAccording to the Canadian Broadcasting Corporation, \"at its height\" the Family movement had \"tens of thousands of members, including River and Joaquin Phoenix, Rose McGowan, and Jeremy Spencer\".\nTFI initially spread a message of salvation, apocalypticism, spiritual \"revolution and happiness,\" and distrust of the outside world, which the members called \"The System\". Like some other fundamentalist groups, it \"foretold the coming of a dictator called the anti-Christ, the rise of a brutal One World Government, and its eventual overthrow by Jesus Christ, in the Second Coming\".\nIn 1976, it began a method of evangelism called Flirty Fishing that used sex to \"show God's love and mercy\" and win converts, resulting in controversy. TFI's founder and prophetic leader, David Berg \u2013 who adopted the name \"Moses David\" while in Laurentide, Canada, and was also referred to \"Father David\" by members) \u2013 gave himself the titles of \"King,\" \"The Last Endtime Prophet,\" \"Moses,\" and \"David.\"\nBerg communicated with his followers via \"Mo Letters\"\u2014letters of instruction and counsel on myriad spiritual and practical subjects\u2014until his death in late 1994. After his death, his widow Karen Zerby became the leader of TFI, taking the titles of \"Queen\" and \"Prophetess.\" Zerby married Steve Kelly (also known as Peter Amsterdam), an assistant of Berg's whom Berg had handpicked as her \"consort.\" Kelly took the title of \"King Peter\" and became the face of TFI, speaking in public more often than either Berg or Zerby. There have been multiple allegations of child sexual abuse made by past members.\nBerg preached a combination of traditional Christian evangelism, with elements popular with the counterculture of the 1960s. There was much \"end-of-the-world imagery\" found in the Book of Revelation of the New Testament, preaching of impending doom for America and the ineffectiveness of established churches. Berg \"urged a return to the early Christian community described in the Bible's Book of Acts, in which believers lived together and shared all,\" resembling the communal living of late 1960s hippies.\nHistory.\nThe Children of God (1968\u20131977).\nThe founder of the movement, David Brandt Berg (1919\u20131994), was a former Christian and Missionary Alliance pastor. Berg started in 1968 as an evangelical preacher with a following of \"born-again hippies\" who gathered at a coffeehouse in Huntington Beach, in Orange County, California. In 1969, after having a revelation \"that California would be hit by a major earthquake\", he left Huntington Beach and \"took his followers on the road\".\nThey would proselytize in the streets and distribute pamphlets. Leaders within COG were referred to as \"The Chain\". Members of The Children of God (COG) founded communes, first called colonies (now referred to as homes), in various cities.\nBerg communicated with his followers by writing letters. He published nearly 3,000 letters over a period of 24 years, referred to as the \"Mo Letters\". In a letter written in January 1972, Berg stated that he was God's prophet for the contemporary world, attempting to further solidify his spiritual authority within the group. Berg's letters also contained public acknowledgement of his own failings and weaknesses, for example, he issued a Mo Letter entitled \"My confession -- I was an alcoholic!\" (ML #1406 Summer 1982) relating his depression after some of his closest supporters quit in 1978.\nIn 1972, a Mo Letter reportedly entitled \"Flee as a Bird to Your Mountain\" was interpreted by some members, including Ruth Gordon, author of \"Children of Darkness\" about the cult, as a warning to leave America. \"God was going to destroy the U.S. ... and we had to get out.\" This, along with the pressure members felt that parents were trying to \"rescue\" children who had joined CoG, encouraged members to \"[migrate] abroad -- first to Europe, eventually to Latin America and East Asia\".\nBy 1972, COG stated it had 130 communities around the world, and by the mid-1970s, it had \"colonies\" in an estimated 70 countries. BBC reported 10,000 full-time COG members in the 1970s.\nIn 1976, Berg had introduced a new proselytizing method called Flirty Fishing (or FFing), which encouraged female members to \"show God's love\" through sexual relationships with potential converts. Flirty Fishing was practiced by members of Berg's inner circle starting in 1973, and was introduced to the general membership in 1976.\nThe Family of Love (1978\u20131981).\nThe Children of God was abolished in February 1978, and Berg renamed his group \"The Family of Love\" In what Berg called the \"Re-organization Nationalization Revolution\" (or RNR). Berg reorganized the movement, dismissing \"more than 300 leading members after hearing unspecified 'reports of serious misconduct and abuse of their positions.\" Reportedly involved were The Chain's abuse of authority, and disagreements within it about the continued use of Flirty Fishing. The group was also accused of sexually abusing and raping minors within the organization, with considerable evidence to support this claim. One eighth of the total membership left the movement. Those who remained became part of a reorganized movement called the Family of Love, and later, The Family. The majority of the group's beliefs remained the same.\nThe Family of Love era was characterized by international expansion.\nAfter 1978 Flirty Fishing \"increased drastically\" and became common practice within the group. A Mo Letter from 1980 (ML #999 May 1980) for example was headlined \"The Devil Hates Sex! --- But God Loves It!\". \nIn some areas flirty fishers used escort agencies to meet potential converts. According to TFI \"over 100,000 received God's gift of salvation through Jesus, and some chose to live the life of a disciple and missionary\" as a result of Flirty Fishing. Researcher Bill Bainbridge obtained data from TFI suggesting that, from 1974 until 1987, members had sexual contact with 223,989 people while practicing Flirty Fishing.\nThe Family (1982\u20131994).\nAccording to the Family's official history, the group had \"far fewer common standards of conduct\" during The Family of Love stage than it had previously. In the late 1980s the group \"tightened its standards\" \"to ensure that all member communities provide a very wholesome environment for all, particularly the children\", and changed its name to \"The Family\". In March 1989, TF issued a statement that, in \"early 1985\", an urgent memorandum had been sent to all members \"reminding them that any such activities [adult\u2013child sexual contact] are within our group\" (emphasis in original), and such activities were grounds for immediate excommunication from the group. In January 2005, Claire Borowik, a spokesperson for TFI, stated:\n Due to the fact that our current zero-tolerance policy regarding sexual interaction between adults and underage minors was not in our literature published before 1986, we came to the realization that during a transitional stage of our movement, from 1978 until 1986, there were cases when some minors were subject to sexually inappropriate advances\u00a0... This was corrected officially in 1986, when any contact between an adult and minor (any person under 21 years of age) was declared an excommunicable offense.\nAfter a 1993 expose in the \"Los Angeles Times\", the group broke \"years of virtual silence\" and began \"inviting reporters and religious scholars\" to visit its commune in La Habra, California, where at least a \"Washington Post\" journalist (Gustav Niebuhr) found its members to be \"a clean-cut bunch, friendly and courteous\". At that time The Family claimed to have \"about 9,000 members worldwide, with about 750 scattered across the United States\". The group emphasized its mainstream Christian opposition to abortion, homosexuality, drugs and drunkenness and its respect for Rev. Billy Graham.\nThe Family (1995\u20132003).\nAfter Berg's death in October 1994, Karen Zerby (known in the group as Mama Maria, Queen Maria, Maria David, or Maria Fontaine) assumed leadership of the group.\nIn February 1995, the group introduced the \"Love Charter\", which defined the rights and responsibilities of Charter Members and Homes. The Charter also included the \"Fundamental Family Rules\", a summary of rules and guidelines from past TF publications which were still in effect.\nIn the 1994\u201395 British court case, the Rt. Hon. Lord Justice Alan Ward ruled that the group, including some of its top leaders, had in the past engaged in abusive sexual practices involving minors and had also used severe corporal punishment and sequestration of minors. He found that by 1995 TF had abandoned these practices and concluded that they were a safe environment for children. Nevertheless, he did require that the group cease all corporal punishment of children in the United Kingdom and denounce any of Berg's writings that were \"responsible for children in TF having been subjected to sexually inappropriate behaviour\".\nThe Family International (2004\u2013present).\nThe Love Charter is The Family's set governing document that entails each member's rights, responsibilities and requirements, while the \"Missionary Member Statutes\" and \"Fellow Member Statutes\" were written for the governance of TFI's Missionary member and Fellow Member circles, respectively. FD Homes were reviewed every six months against a published set of criteria. The Love Charter increased the number of single family homes as well as homes that relied on jobs such as self-employment.\nRecent teachings.\nTFI's recent teachings are based on beliefs which they term the \"new [spiritual] weapons\". TFI members believe that they are soldiers in the spiritual war of good versus evil for the souls and hearts of men.\nSpirit Helpers.\n\"Spirit Helpers\" include angels, other religious and mythical figures, and departed humans, including celebrities; for example the goddess Aphrodite, the Snowman, Merlin, the Sphinx, Elvis, Marilyn Monroe, Audrey Hepburn, Richard Nixon, and Winston Churchill.\nThe Keys of the Kingdom.\nTFI believes that the Biblical passage \"I will give you the keys of the kingdom of heaven, and whatsoever you bind on earth will be bound in heaven, and whatsoever you loose on earth will be loosed in heaven\" (Matthew 16:19), refers to an increasing amount of spiritual authority that was given to Peter and the early disciples. According to TFI beliefs, this passage refers to keys that were hidden and unused in the centuries that followed, but were again revealed through Karen Zerby as more power to pray and obtain miracles. TFI members call on the various Keys of the Kingdom for extra effect during prayer. The Keys, like most TFI beliefs, were published in magazines that looked like comic-books in order to make them teachable to children.\nLoving Jesus.\n\"Loving Jesus\" is a term TFI members use to describe their intimate, sexual relationship with Jesus. TFI describes its \"Loving Jesus\" teaching as a radical form of bridal theology. They believe the church of followers is Christ's bride, called to love and serve him with wifely fervor; however, this bridal theology is taken further, encouraging members to imagine Jesus is joining them during sexual intercourse and masturbation. Male members are cautioned to visualize themselves as women, in order to avoid a homosexual relationship with Jesus. Many TFI publications, and spirit messages claimed to be from Jesus himself, elaborate this intimate, sexual relation they believe Jesus desires and needs. TFI imagines itself as his special \"bride\" in graphic poetry, guided visualizations, artwork, and songs. Some TFI literature is not brought into conservative countries for fear it may be classified at customs as pornography. The literature outlining this view of Jesus and his desire for a sexual relationship with believers was edited for younger teens, then further edited for children.\nCriticism.\nThe Family has been found liable in a British court, and also criticized by the press and the anti-cult movement. Ex-members have accused the Family's leadership of following \"a policy of lying to outsiders,\" being \"steeped in a history of sexual deviance\" and even meddling \"in Third World politics\". The Family replies that it is a victim of \"persecution.\"\nAllegations of abuse and mistreatment have been publicly expressed by some of those who have left the group; examples include sisters Celeste Jones, Kristina Jones, and Juliana Buhring and Daniella Mestyanek Young, who both wrote books on their lives in TFI.\nIn 1971, an organization called FREECOG was founded by concerned parents and others, including deprogrammer Ted Patrick to free members of the COG from their involvement in the group.\nAt least one individual growing up in the family (Verity Carter) during the Children of God era described being sexually abused \"from the age of four by members of the... cult, including her own father\". She blames the philosophy of David Berg, who told members that \"God was love and love was sex\", so that sex should not be limited by age or relationship. Carter also complains of being \"repeatedly beaten and whipped for the smallest of transgressions\", being denied \"music or television or culture,\" or other \"contact with the outside world,\" so that she had \"no idea how the world worked\" other than how to manipulate the \"systemites\" (outsiders), like social workers.\nAuthor Don Lattin interviewed numerous members of the Family for his book \"Jesus Freaks\". In a review of his book, Paul Burgarino describes Berg as \"drawing from the remnants of hippie life\u2014people with nothing to lose, nowhere to go, and no Christian background\" to alert them to deviations in Berg's preaching. One ex\u2013Children of God member, Jerry Golland, describes himself at the time of joining the group as penniless and so depressed that the Children of God scraped him \"off the street\". Members would \"learn to spot, you know... a vulnerable person. We called them sheep\", Golland told the Canadian Broadcasting Corporation.\nPressure to raise money could also be intense. Ex-member Golland says that members who were good at raising money and distributing the pamphlets were called \"Shiners\". Those with poor sales were called \"Shamers\". \"If you missed your quota you could not come home for dinner\", he said."}
{"id": "7603", "revid": "19404073", "url": "https://en.wikipedia.org/wiki?curid=7603", "title": "CIT", "text": "CIT or cit may refer to:"}
{"id": "7604", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=7604", "title": "Code of Hammurabi", "text": "The Code of Hammurabi is a Babylonian legal text composed during 1755\u20131750 BC. It is the longest, best-organized, and best-preserved legal text from the ancient Near East. It is written in the Old Babylonian dialect of Akkadian, purportedly by Hammurabi, sixth king of the First Dynasty of Babylon. The primary copy of the text is inscribed on a basalt stele tall.\nThe stele was rediscovered in 1901 at the site of Susa in present-day Iran, where it had been taken as plunder six hundred years after its creation. The text itself was copied and studied by Mesopotamian scribes for over a millennium. The stele now resides in the Louvre Museum.\nThe top of the stele features an image in relief of Hammurabi with Shamash, the Babylonian sun god and god of justice. Below the relief are about 4,130 lines of cuneiform text: one fifth contains a prologue and epilogue in poetic style, while the remaining four fifths contain what are generally called the laws. In the prologue, Hammurabi claims to have been granted his rule by the gods \"to prevent the strong from oppressing the weak\". The laws are casuistic, expressed as \"if... then\" conditional sentences. Their scope is broad, including, for example, criminal law, family law, property law, and commercial law.\nModern scholars responded to the Code with admiration at its perceived fairness and respect for the rule of law, and at the complexity of Old Babylonian society. There was also much discussion of its influence on the Mosaic Law. Scholars quickly identified \u2014the \"eye for an eye\" principle\u2014underlying the two collections. Debate among Assyriologists has since centred around several aspects of the Code: its purpose, its underlying principles, its language, and its relation to earlier and later law collections.\nDespite the uncertainty surrounding these issues, Hammurabi is regarded outside Assyriology as an important figure in the history of law and the document as a true legal code. The U.S. Capitol has a relief portrait of Hammurabi alongside those of other historic lawgivers. There are replicas of the stele in numerous institutions, including the headquarters of the United Nations in New York City and the Pergamon Museum in Berlin.\nBackground.\nHammurabi.\nHammurabi (or Hammurapi), the sixth king of the Amorite First Dynasty of Babylon, ruled from 1792 to 1750 BC (middle chronology). He secured Babylonian dominance over the Mesopotamian plain through military prowess, diplomacy, and treachery. When Hammurabi inherited his father Sin-Muballit's throne, Babylon held little local sway; the local hegemon was Rim-Sin of Larsa. Hammurabi waited until Rim-Sin grew old, then conquered his territory in one swift campaign, leaving his organisation intact. Later, Hammurabi betrayed allies in Eshnunna, Elam, and Mari to gain their territories.\nHammurabi had an aggressive foreign policy, but his letters suggest he was concerned with the welfare of his many subjects and was interested in law and justice. He commissioned extensive construction works, and in his letters, he frequently presents himself as his people's shepherd. Justice is also a theme of the prologue to the Code, and \"the word translated 'justice' []... is one whose root runs through both prologue and epilogue\".\nEarlier law collections.\nAlthough Hammurabi's Code was the first Mesopotamian law collection to be discovered, it was not the first written; several earlier collections survive. These collections were written in Sumerian and Akkadian. They also purport to have been written by rulers. There were almost certainly more such collections, as statements of other rulers suggest the custom was widespread. The similarities between these law collections make it tempting to assume a consistent underlying legal system. As with the Code of Hammurabi, however, it is difficult to interpret the purpose and underlying legal systems of these earlier collections, prompting numerous scholars to question whether this should be attempted. Extant collections include:\nThere are additionally thousands of documents from the practice of law, from before and during the Old Babylonian period. These documents include contracts, judicial rulings, letters on legal cases, and reform documents such as that of Urukagina, king of Lagash in the mid-3rd millennium BC, whose reforms combatted corruption. Mesopotamia has the most comprehensive surviving legal corpus from before the \" Digest\" of Justinian, even compared to those from ancient Greece and Rome.\nCopies.\nLouvre stele.\nThe first copy of the text found, and still the most complete, is on a stele. The stele is now displayed on the ground floor of the Louvre, in Room 227 of the Richelieu wing. At the top is an image of Hammurabi with Shamash, the Babylonian sun god and god of justice. Below the image are about 4,130 lines of cuneiform text: One-fifth contains a prologue and epilogue, while the remaining four-fifths contain what are generally called the laws. Near the bottom, seven columns of the laws, each with more than eighty lines, were polished and erased in antiquity. The stele was found in three large fragments and reconstructed. It is high, with a circumference is at the summit and at the base. Hammurabi's image is high and wide.\nThe Louvre stele was found at the site of the ancient Elamite city of Susa. Susa is in modern-day Khuzestan Province, Iran (Persia at the time of excavation). The stele was excavated by the French Archaeological Mission under the direction of Jacques de Morgan. Father Jean-Vincent Scheil published the initial report in the fourth volume of the \"Reports of the Delegation to Persia\" (). According to Scheil, the stele's fragments were found on the tell of the Susa acropolis (), between December 1901 and January 1902. The few, large fragments made assembly easy.\nScheil hypothesised that the stele had been taken to Susa by the Elamite king Shutruk-Nakhunte and that he had commissioned the erasure of several columns of laws to write his legend there. It has been proposed that the relief portion of the stele, especially the beards of Hammurabi and Shamash, was reworked at the same time. Roth suggests the stele was taken as plunder from Sippar, where Hammurabi lived towards the end of his reign.\nOther copies.\nFragments of a second and possibly third stele recording the Code were found along with the Louvre stele at Susa. Over fifty manuscripts containing the laws are known. They were found not only in Susa but also in Babylon, Nineveh, Assur, Borsippa, Nippur, Sippar, Ur, Larsa, and more. Copies were created during Hammurabi's reign, and also after it, since the text became a part of the scribal curriculum. Copies have been found dating from one thousand years after the stele's creation, and a catalog from the library of Neo-Assyrian king Ashurbanipal (685\u2013631 BC) lists a copy of the \"judgments of Hammurabi\". The additional copies fill in most of the stele's original text, including much of the erased section.\nEarly scholarship.\nThe of the Code was published by Father Jean-Vincent Scheil in 1902, in the fourth volume of the \"Reports of the Delegation to Persia\" (). After a brief introduction with details of the excavation, Scheil gave a transliteration and a free translation into French, as well as a selection of images. Editions in other languages soon followed: in German by Hugo Winckler in 1902, in English by C. H. W. Johns in 1903, and in Italian by Pietro Bonfante, also in 1903.\nThe Code was thought to be the earliest Mesopotamian law collection when it was rediscovered in 1902\u2014for example, C. H. W. Johns' 1903 book was titled \"The Oldest Code of Laws in the World\". The English writer H. G. Wells included Hammurabi in the first volume of \"The Outline of History\", and to Wells too the Code was \"the earliest known code of law\". However, three earlier collections were rediscovered afterwards: the Code of Lipit-Ishtar in 1947, the Laws of Eshnunna in 1948, and the Code of Ur-Nammu in 1952. Early commentators dated Hammurabi and the stele to the 23rd century BC. However, this is an earlier estimate than even the \"ultra-long chronology\" would support. The Code was compiled near the end of Hammurabi's reign. This was deduced partly from the list of his achievements in the prologue.\nScheil enthused about the stele's importance and perceived fairness, calling it \"a moral and political masterpiece\". C. H. W. Johns called it \"one of the most important monuments in the history of the human race\". He remarked that \"there are many humanitarian clauses and much protection is given the weak and the helpless\", and even lauded a \"wonderful modernity of spirit\". John Dyneley Prince called the Code's rediscovery \"the most important event which has taken place in the development of Assyriological science since the days of Rawlinson and Layard\". Charles Francis Horne commended the \"wise law-giver\" and his \"celebrated code\". James Henry Breasted noted the Code's \"justice to the widow, the orphan, and the poor\", but remarked that it \"also allows many of the old and na\u00efve ideas of justice to stand\". Commentators praised the advanced society they believed the Code evinced. Several singled out perceived secularism: Owen Jenkins, for example, but even Charles Souvay for the \"Catholic Encyclopedia\", who opined that unlike the Mosaic Law the Code was \"founded upon the dictates of reason\". The question of the Code's influence on the Mosaic Law received much early attention. Scholars also identified Hammurabi with the Biblical figure Amraphel, but this proposal has since been abandoned.\nFrame.\nRelief.\nThe relief appears to show Hammurabi standing before a seated Shamash. Shamash wears the horned crown of divinity and has a solar attribute, flames, spouting from his shoulders. Contrastingly, Scheil, in his , identified the seated figure as Hammurabi and the standing figure as Shamash. Scheil also held that the scene showed Shamash dictating to Hammurabi while Hammurabi held a scribe's stylus, gazing attentively at the god. Martha Roth lists other interpretations: \"that the king is offering the laws to the god; that the king is accepting or offering the emblems of sovereignty of the rod and ring; or\u2014most probably\u2014that these emblems are the measuring tools of the rod-measure and rope-measure used in temple-building\". Hammurabi may even be imitating Shamash. It is certain, though, that the draughtsman showed Hammurabi's close links to the divine realm, using composition and iconography.\nPrologue.\nThe prologue and epilogue together occupy one-fifth of the text. Out of around 4,130 lines, the prologue occupies 300 lines and the epilogue occupies 500. They are in ring composition around the laws, though there is no visual break distinguishing them from the laws. Both are written in poetic style, and, as William W. Davies wrote, \"contain much... which sounds very like braggadocio\".\nThe 300-line prologue begins with an etiology of Hammurabi's royal authority (1\u201349). Anum, the Babylonian sky god and king of the gods, granted rulership over humanity to Marduk. Marduk chose the centre of his earthly power to be Babylon, which in the real world worshipped him as its tutelary god. Marduk established the office of kingship within Babylon. Finally, Anum, along with the Babylonian wind god Enlil, chose Hammurabi to be Babylon's king. Hammurabi was to rule \"to prevent the strong from oppressing the weak\" (37\u201339: ). He was to rise like Shamash over the Mesopotamians (the , literally the \"black-headed people\") and illuminate the land (40\u201344).\nHammurabi then lists his achievements and virtues (50\u2013291). These are expressed in noun form, in the Akkadian first person singular nominal sentence construction \"[noun]... \" (\"I am [noun]\"). The first nominal sentence (50\u201353) is short: \"I am Hammurabi, the shepherd, selected by the god Enlil\" (). Then Hammurabi continues for over 200 lines in a single nominal sentence with the delayed to the very end (291).\nHammurabi repeatedly calls himself , \"pious\" (lines 61, 149, 241, and 272). The metaphor of Hammurabi as his people's shepherd also recurs. It was a common metaphor for ancient Near Eastern kings, but is perhaps justified by Hammurabi's interest in his subjects' affairs. His affinities with many different gods are stressed throughout. He is portrayed as dutiful in restoring and maintaining temples and peerless on the battlefield. The list of his accomplishments has helped establish that the text was written late in Hammurabi's reign. After the list, Hammurabi explains that he fulfilled Marduk's request to establish \"truth and justice\" () for the people (292\u2013302), although the prologue never directly references the laws. The prologue ends \"at that time:\" (303: ) and the laws begin.\nEpilogue.\nUnlike the prologue, the 500-line epilogue is explicitly related to the laws. The epilogue begins (3144'\u20133151'): \"These are the just decisions which Hammurabi... has established\" (). He exalts his laws and his magnanimity (3152'\u20133239'). He then expresses a hope that \"any wronged man who has a lawsuit\" () may have the laws of the stele read aloud to him and know his rights (3240'\u20133256'). This would bring Hammurabi praise (3257'\u20133275') and divine favour (3276'\u20133295'). Hammurabi wishes for good fortune for any ruler who heeds his pronouncements and respects his stele (3296'\u20133359'). However, he invokes the wrath of the gods on any man who disobeys or erases his pronouncements (3360'\u20133641', the end of the text).\nThe epilogue contains much legal imagery, and the phrase \"to prevent the strong from oppressing the weak\" (3202'\u20133203': ) is reused from the prologue. However, the king's main concern appears to be ensuring that his achievements are not forgotten and his name not sullied. The list of curses heaped upon any future defacer is 281 lines long and extremely forceful. Some of the curses are very vivid: \"may the god Sin... decree for him a life that is no better than death\" (3486'\u20133508': ); \"may he [the future defacer] conclude every day, month, and year of his reign with groaning and mourning\" (3497'\u20133501': ); may he experience \"the spilling of his life force like water\" (3435'\u20133436': ). Hammurabi implores a variety of gods individually to turn their particular attributes against the defacer. For example: \"may the [storm] god Adad... deprive him of the benefits of rain from heaven and flood from the springs\" (3509'\u20133515': ); \"may the god [of wisdom] Ea... deprive him of all understanding and wisdom, and may he lead him into confusion\" (3440'\u20133451': ). Gods and goddesses are invoked in this order:\nLaws.\nThe Code of Hammurabi is the longest and best-organised legal text from the ancient Near East, as well as the best-preserved. The classification below (columns 1\u20133) is Driver &amp; Miles', with several amendments, and Roth's translation is used. Laws represented by letters are those reconstructed primarily from documents other than the Louvre stele.\nTheories of purpose.\nThe purpose and legal authority of the Code have been disputed since the mid-20th century. Theories fall into three main categories: that it is legislation, whether a code of law or a body of statutes; that it is a sort of law report, containing records of past cases and judgments; and that it is an abstract work of jurisprudence. The jurisprudence theory has gained much support within Assyriology.\nLegislation.\nThe term \"code\" presupposes that the document was intended to be enforced as legislation. It was used by Scheil in his , and widely adopted afterwards. C. H. W. Johns, one of the most prolific early commentators on the document, proclaimed that \"the Code well deserves its name\". Recent Assyriologists have used the term without comment, as well as scholars outside Assyriology. However, only if the text was intended as enforced legislation can it truly be called a code of law and its provisions laws.\nThe document, on first inspection, resembles a highly organised code similar to the Code of Justinian and the Napoleonic Code. There is also evidence that , which in the Code of Hammurabi sometimes denote individual \"laws\", were enforced. One copy of the Code calls it a , \"royal decree\", which denotes a kind of enforced legislation.\nHowever, the arguments against this view are strong. Firstly, it would make a very unusual code\u2014Reuven Yaron called the designation \"Code\" a \"persistent misnomer\". Vital areas of society and commerce are omitted. For example, Marc Van De Mieroop observes that the Code \"deals with cattle and agricultural fields, but it almost entirely ignores the work of shepherds, vital to Babylonia's economy\". Then, against the legislation theory more generally, highly implausible circumstances are covered, such as threshing with goats, animals far too unruly for the task (law 270). The laws are also strictly casuistic (\"if... then\"); unlike in the Mosaic Law, there are no apodictic laws (general commands). These would more obviously suggest prescriptive legislation. The strongest argument against the legislation theory, however, is that most judges appear to have paid the Code no attention. This line of criticism originated with Benno Landsberger in 1950. No Mesopotamian legal document explicitly references the Code or any other law collection, despite the great scale of the corpus. Two references to prescriptions on \"a stele\" () come closest. In contrast, numerous judgments cite royal -decrees. Raymond Westbrook held that this strengthened the argument from silence that ancient Near Eastern legal \"codes\" had legal import. Furthermore, many Old Babylonian judgments run entirely counter to the Code's prescriptions.\nLaw report.\nA second theory is that the Code is a sort of law report, and as such contains records of past cases and judgments, albeit phrased abstractly. This would provide one explanation for the casuistic format of the \"laws\"; indeed, Jean Bott\u00e9ro believed he had found a record of a case that inspired one. However, such finds are inconclusive and very rare, despite the scale of the Mesopotamian legal corpus. Furthermore, legal judgments were frequently recorded in Mesopotamia, and they recount the facts of the case without generalising them. These judgments were concerned almost exclusively with points of fact, prompting Martha Roth to comment: \"I know of only one case out of thousands extant that might be said to revolve around a point of law\".\nJurisprudence.\nA third theory, which has gained traction within Assyriology, is that the Code is not a true code but an abstract treatise on how judgments should be formulated. This led Fritz Rudolf Kraus, in an early formulation of the theory, to call it jurisprudence (). Kraus proposed that it was a work of Mesopotamian scholarship in the same category as omen collections like and . Others have provided their own versions of this theory. A. Leo Oppenheim remarked that the Code of Hammurabi and similar Mesopotamian law collections \"represent an interesting formulation of social criticism and should not be taken as normative directions\".\nThis interpretation bypasses the problem of low congruence between the Code and actual legal judgments. Secondly, the Code does bear striking similarities to other works of Mesopotamian scholarship. Key points of similarity are the list format and the order of the items, which Ann Guinan describes as a complex \"serial logic\". Marc Van De Mieroop explains that, in common with other works of Mesopotamian scholarship such as omen lists, king lists, and god lists, the entries of the Code of Hammurabi are arranged according to two principles. These are \"opposition\"\u2014whereby a variable in one entry is altered to make another entry\u2014and \"pointillism\"\u2014whereby new conditions are added to an entry, or paradigmatic series pursued, to generate a sequence. Van De Mieroop provides the following examples:\nLaws 215 and 218 illustrate the principle of opposition: one variable of the first law, the outcome of the operations, is altered to create the second.\nHere, following the principle of pointillism, circumstances are added to the first entry to create more entries. Pointillism also lets list entries be generated by following paradigmatic series common to multiple branches of scholarship. It can thus explain the implausible entries. For example, in the case of the goat used for threshing (law 270), the previous laws concern other animals that \"were\" used for threshing. The established series of domesticated beasts dictated that a goat come next.\nWolfram von Soden, who decades earlier called this way of thinking (\"list science\"), often denigrated it. However, more recent writers, such as Marc Van De Mieroop, Jean Bott\u00e9ro, and Ann Guinan, have either avoided value judgments or expressed admiration. Lists were central to Mesopotamian science and logic, and their distinctive structural principles let entries be generated infinitely. Linking the Code to the scribal tradition within which \"list science\" emerged also explains why trainee scribes copied and studied it for over a millennium. The Code appears in a late Babylonian (7th\u20136th century BC) list of literary and scholarly texts. No other law collection became so entrenched in the curriculum. Rather than a code of laws, then, it may be a scholarly treatise.\nMuch has been written on what the Code suggests about Old Babylonian society and its legal system. For example, whether it demonstrates that there were no professional advocates, or that there were professional judges. Scholars who approach the Code as a self-contained document renounce such claims.\nUnderlying principles.\nOne principle widely accepted to underlie the Code is , or \"eye for an eye\". Laws 196 and 200 respectively prescribe an eye for an eye and a tooth for a tooth when one man destroys another's. Punishments determined by could be transferred to the sons of the wrongdoer. For example, law 229 states that the death of a homeowner in a house collapse necessitates the death of the house's builder. The following law 230 states that if the homeowner's son died, the builder's son must die also.\nPersons were not equal before the law; not just age and profession but also class and gender dictated the punishment or remedy they received. Three main kinds of person, , , and (male)/ (female), are mentioned throughout the Code. A / was a male/female slave. As for and , though contentious, it seems likely that the difference was one of social class, with meaning something like \"gentleman\" and something like \"commoner\". The penalties were not necessarily stricter for a than an : a 's life may have been cheaper, but so were some of his fines. There was also inequality within these classes: laws 200 and 202, for example, show that one could be of higher rank than another.\nThe above principles are distant in spirit from modern systems of common and civil law, but some may be more familiar. One such principle is the presumption of innocence; the first two laws of the stele prescribe punishments, determined by , for unsubstantiated accusations. Written evidence was valued highly, especially in matters of contract. One crime was given only one punishment. The laws also recognized the importance of the intentions of a defendant. Lastly, the Code's establishment on public stelae was supposedly intended to increase access to justice. Whether or not this was true, suggesting that a wronged man have the stele read aloud to him (lines 3240'\u20133254') is a concrete measure in this direction, given the inaccessibility of scribal education in the Old Babylonian period.\nThe prologue asserts that Hammurabi was chosen by the gods. Raymond Westbrook observed that in ancient Near Eastern law, \"the king was the primary source of legislation\". However, they could delegate their god-given legal authority to judges. However, as Owen B. Jenkins observed, the prescriptions themselves bear \"an astonishing absence... of all theological or even ceremonial law\".\nLanguage.\nThe laws are written in the Old Babylonian dialect of Akkadian. Their style is regular and repetitive, and today they are a standard set text for introductory Akkadian classes. However, as A. Leo Oppenheim summarises, the cuneiform signs themselves are \"vertically arranged... within boxes placed in bands side by side from right to left\", an arrangement already antiquated by Hammurabi's time.\nThe laws are expressed in casuistic format: they are conditional sentences with the case detailed in the protasis (\"if\" clause) and the remedy given in the apodosis (\"then\" clause). The protasis begins , \"if\", except when it adds to circumstances already specified in a previous law (e.g. laws 36, 38, and 40). The preterite is used for simple past verbs in the protasis, or possibly for a simple conditional. The perfect often appears at the end of the protasis after one or more preterites to convey sequence of action, or possibly a hypothetical conditional. The durative, sometimes called the \"present\" in Assyriology, may express intention in the laws. For ease of English reading, some translations give preterite and perfect verbs in the protasis a present sense. In the apodosis, the verbs are in the durative, though the sense varies between permissive\u2014\"it is permitted that \"x\" happen\"\u2014and instructive\u2014\"\"x\" must/will happen\". In both protasis and apodosis, sequence of action is conveyed by suffixing verbs with , \"and\". can also have the sense \"but\".\nThe Code is relatively well-understood, but some items of its vocabulary are controversial. As mentioned, the terms and have proved difficult to translate. They probably denote respectively a male member of a higher and lower social class. Wolfram von Soden, in his \"Akkadisches Handw\u00f6rterbuch\", proposed that was derived from , \"to bow down/supplicate\". As a word for a man of low social standing, it has endured, possibly from a Sumerian root, into Arabic (), Italian (), Spanish (), and French (). However, some earlier translators, also seeking to explain the 's special treatment, translated it as \"leper\" and even \"noble\". Some translators have supplied stilted readings for , such as \"seignior\", \"elite man\", and \"member of the aristocracy\"; others have left it untranslated. Certain legal terms have also proved difficult to translate. For example, and can denote the law in general as well as individual laws, verdicts, divine pronouncements and other phenomena. can likewise denote the law in general as well as a kind of royal decree.\nRelation to other law collections.\nOther Mesopotamian.\nThe Code of Hammurabi bears strong similarities to earlier Mesopotamian law collections. Many purport to have been written by rulers, and this tradition was probably widespread. Earlier law collections express their god-given legitimacy similarly. Like the Code of Hammurabi, they feature prologues and epilogues: the Code of Ur-Nammu has a prologue, the Code of Lipit-Ishtar a prologue and an epilogue, and the Laws of Eshnunna an epilogue. Also, like the Code of Hammurabi, they uphold the \"one crime, one punishment\" principle. The cases covered and language used are, overall, strikingly similar. Scribes were still copying earlier law collections, such as the Code of Ur-Nammu, when Hammurabi produced his own Code. This suggests that earlier collections may have not only resembled the Code but influenced it. Raymond Westbrook maintained that there was a fairly consistent tradition of \"ancient Near Eastern law\" which included the Code of Hammurabi, and that this was largely customary law. Nonetheless, there are differences: for example, Stephen Bertman has suggested that where earlier collections are concerned with compensating victims, the Code is concerned with physically punishing offenders. Additionally, the above conclusions of similarity and influence apply only to the law collections themselves. The actual legal practices from the context of each code are mysterious.\nThe Code of Hammurabi also bears strong similarities to later Mesopotamian law collections: to the casuistic Middle Assyrian Laws and to the Neo-Babylonian Laws, whose format is largely relative (\"a man who...\"). It is easier to posit direct influence for these later collections, given the Code's survival through the scribal curriculum. Lastly, although influence is more difficult to trace, there is evidence that the Hittite laws may have been part of the same tradition of legal writing outside Mesopotamia proper.\nMosaic, Graeco-Roman, and modern.\nThe relationship of the Code of Hammurabi to the Mosaic Law, specifically the Covenant Code of Exodus 20:22\u201323:19, has been a subject of discussion since its discovery. Friedrich Delitzsch argued the case for strong influence in a 1902 lecture, in one episode of the \"\" (\"Babel and Bible\", or \"Panbabylonism\") debate on the influence of ancient Mesopotamian cultures on ancient Israel. However, he was met with strong resistance. There was cultural contact between Mesopotamia and the Levant, and Middle Bronze Age tablets of casuistic cuneiform law have been found at Hazor. There are also similarities between the Code of Hamurabi and the Covenant Code: in the casuistic format, in principles such as (\"eye for an eye\"), and in the content of the provisions. Some similarities are striking, such as in the provisions concerning a man-goring ox (Code of Hammurabi laws 250\u2013252, Exodus 21:28\u201332). Certain writers have posited direct influence: David P. Wright, for example, asserts that the Covenant Code is \"directly, primarily, and throughout dependent upon the Laws of Hammurabi\", \"a creative rewriting of Mesopotamian sources... to be viewed as an academic abstraction rather than a digest of laws\". Others posit indirect influence, such as via Aramaic or Phoenician intermediaries. The consensus, however, is that the similarities are a result of inheriting common traditions. In 1916, George A. Barton cited \"a similarity of antecedents and of general intellectual outlook\". More recently, David Winton Thomas has stated: \"There is no ground for assuming any direct borrowing by the Hebrew from the Babylonian. Even where the two sets of laws differ little in the letter, they differ much in the spirit\".\nThe influence of the Code of Hammurabi on later law collections is difficult to establish. Marc Van De Mieroop suggests that it may have influenced the Greek Gortyn Code and the Roman Twelve Tables. However, even Van De Mieroop acknowledges that most Roman law is not similar to the Code, or likely to have been influenced by it.\nKnowing the Code's influence on modern law requires knowing its influence on Mosaic and Graeco-Roman law. Since this is contentious, commentators have restricted themselves to observing similarities and differences between the Code and, e.g., United States law and medieval law. Some have remarked that the punishments found in the Code are no more severe, and, in some cases, less so.\nLaw 238 stipulates that a sea captain, ship-manager, or ship charterer that saved a ship from total loss was only required to pay one-half the value of the ship to the ship-owner. In the \"Digesta seu Pandectae\" (533), the second volume of the codification of laws ordered by Justinian I (527\u2013565) of the Eastern Roman Empire, a legal opinion written by the Roman jurist Paulus at the beginning of the Crisis of the Third Century in 235 AD was included about the \"Lex Rhodia\" (\"Rhodian law\") that articulates the general average principle of marine insurance established on the island of Rhodes in approximately 1000 to 800 BC as a member of the Doric Hexapolis, plausibly by the Phoenicians during the proposed Dorian invasion and emergence of the purported Sea Peoples during the Greek Dark Ages (c.\u00a01100 \u2013 c.\u00a0750) that led to the proliferation of the Doric Greek dialect. The law of general average constitutes the fundamental principle that underlies all insurance.\nReception outside Assyriology.\nThe Code is often referred to in legal scholarship, where its provisions are assumed to be laws, and the document is assumed to be a true code of laws. This is also true outside academia.\nThere is a relief portrait of Hammurabi over the doors to the House Chamber of the U.S. Capitol, along with portraits of 22 others \"noted for their work in establishing the principles that underlie American law\". There are replicas of the Louvre stele in institutions around the world, including the Headquarters of the United Nations in New York City and the Peace Palace in The Hague (seat of the International Court of Justice).\nMedico-legal legacy and political implications.\nHammurabi's Code is notable for its comprehensive approach to law, covering subjects from criminal acts to medical practices. The Code includes specific rules that regulate medical treatments, set surgery fees, and punish malpractice. For instance, if a physician caused the death of a noble during surgery, they would be severely punished, sometimes having their hand cut off. This harshness portrays how seriously medical responsibility was taken even in ancient times.\nFrom a political science perspective, Hammurabi's Code is valuable and fundamental because it demonstrates how law was used to reinforce social hierarchies and maintain control. writes that the Code's laws were applied differently depending on a person's social class, so nobles received greater protection than commoners and enslaved people. This legal stratification reflects the power dynamic of Babylonian society and shows how law was used not just to govern but also to preserve the social order.\nFinally, the Hammurabi's Code impresses us by its power (even though it is now irrelevant, we still sense its greatness) and severity. The harsh punishments may seem extreme by modern standards, but they were likely necessary to maintain order in a society where survival depended on strict adherence to rules. At the same time, Hammurabi's Code represents a significant step forward in the development of law, medicine and the medico-legal system. By codifying laws and making them public, Hammurabi established a system that would influence generations so that the principles of justice, fairness, and accountability that underpin the Code continue to resonate today."}
{"id": "7605", "revid": "1984595", "url": "https://en.wikipedia.org/wiki?curid=7605", "title": "Rum and Coke", "text": "Rum and Coke, or the Cuba libre ( , ; literally \"Free Cuba\"), is a highball cocktail consisting of cola, rum, and in many recipes lime juice, on ice. Traditionally, the cola ingredient is tuKola or Coca-Cola (\"Coke\") and the alcohol is a light rum such as Bacardi; however, the drink may be made with various types of rums and cola brands, and lime juice may or may not be included.\nThe cocktail originated in the early 20th century in Cuba, after the country won independence in the Spanish\u2013American War. It subsequently became popular across Cuba, the United States, and other countries. Its simple recipe and inexpensive, ubiquitous ingredients have made it one of the world's most-popular alcoholic drinks. Drink critics often consider the drink mediocre, but it has been noted for its historical significance.\nHistory.\nThe drink was created in Cuba in the early 1900s, but its exact origins are not certain. It became popular shortly after 1900, when bottled Coca-Cola was first imported into Cuba from the United States. Its origin is associated with the heavy U.S. presence in Cuba following the Spanish\u2013American War of 1898; the drink's traditional name, \"Cuba libre\" (Free Cuba), was the slogan of the Cuban independence movement. The Cuba libre is sometimes said to have been created during the Spanish\u2013American War. However, this predates the first distribution of Coca-Cola to Cuba in 1900. A drink called a \"Cuba libre\" was indeed known in 1898, but this was a mix of water and brown sugar.\nFausto Rodriguez, a Bacardi advertising executive, claimed to have been present when the drink was first poured, and produced a notarized affidavit to that effect in 1965. According to Rodriguez, this took place in August 1900, when he was a 14-year-old messenger working for a member of the U.S. Army Signal Corps in Havana. One day at a local bar, Rodriguez's employer ordered Bacardi rum mixed with Coca-Cola. This intrigued a nearby group of American soldiers, who ordered a round for themselves, giving birth to a popular new drink. Bacardi published Rodriguez's affidavit in a \"Life\" magazine ad in 1966. However, Rodriguez's status as a Bacardi executive has led some commentators to doubt the veracity of his story. Another story states that the drink was first created in 1902 at Havana's El Floridita restaurant to celebrate the anniversary of Cuban independence.\nThe drink became a staple in Cuba, catching on due to the pervasiveness of its ingredients. Havana was already known for its iced drinks in the 19th century, as it was one of the few warm-weather cities that had abundant stores of ice shipped down from colder regions. Bacardi and other Cuban rums also boomed after independence brought in large numbers of foreign tourists and investors, as well as new opportunities for exporting alcohol. Light rums such as Bacardi became favored for cocktails as they were considered to mix well. Coca-Cola had been a common mixer in the United States ever since it was first bottled in 1886, and it became a ubiquitous drink in many countries after it was first exported in 1900.\nRum and Coke quickly spread from Cuba to the United States. In the early 20th century the cocktail, like Coca-Cola itself, was most popular in the Southern United States. During the Prohibition era from 1922 to 1933, Coca-Cola became a favored mixer for disguising the taste of low-quality rums, as well as other liquors. In 1921 H. L. Mencken jokingly wrote of a South Carolina variant called the \"jump stiddy\", which consisted of Coca-Cola mixed with denatured alcohol drained from automobile radiators. After Prohibition, rum and Coke became prevalent in the northern and western U.S. as well, and in both high-brow and low-brow circles.\nRum and Coke achieved a new level of popularity during World War II. Starting in 1940, the United States established a series of outposts in the British West Indies to defend against the German Navy. The American presence created cross-cultural demand, with American servicemen and the locals developing tastes for each other's products. In particular, American military personnel took to Caribbean rum due to its inexpensiveness, while Coca-Cola became especially prevalent in the islands thanks to the company shipping it out with the military. Within the United States, imported rum became increasingly popular, as government quotas for industrial alcohol reduced the output of American distillers of domestic liquors.\nIn 1943, Lord Invader's Calypso song \"Rum and Coca-Cola\" drew further attention to the drink in Trinidad. The song was an adaptation of Lionel Belasco's 1904 composition \"L'Ann\u00e9e Pass\u00e9e\" with new lyrics about American soldiers in Trinidad cavorting with local girls and drinking rum and Coke. Comedian Morey Amsterdam plagiarized \"Rum and Coca-Cola\" and licensed it to the Andrews Sisters as his own work. The Andrews Sisters' version was a major hit in 1945 and further boosted the popularity of rum and Coke, especially in the military. Lord Invader and the owners of Belasco's composition successfully sued Amsterdam for the song's rights.\nDuring the Cuban Revolution in 1959, Bacardi fled to Puerto Rico. The following year, the U.S. placed an embargo against Cuba which prohibited the importation of Cuban products. With Cuban-made rum unavailable in the U.S. and Coca-Cola largely unavailable in Cuba, it became difficult to make a rum and Coke with its traditional ingredients in either country.\nPopularity and reception.\nThe rum and Coke is very popular; Bacardi says that it is the world's second-most-popular alcoholic drink. Its popularity derives from the ubiquity and low cost of the main ingredients, and the fact that it is very easy to make. As it can be made with any quantity or style of rum, it is simple to prepare and difficult to ruin.\nDrink critics often have a low opinion of the cocktail. Writer Wayne Curtis called it \"a drink of inspired blandness\", while Jason Wilson of \"The Washington Post\" called it \"a lazy person's drink\". Troy Patterson of \"Slate\" called it \"the classic mediocre Caribbean-American highball\", which \"became a classic despite not being especially good\".\nCharles A. Coulombe considers the Cuba libre a historically important drink, writing that it is \"a potent symbol of a changing world order \u2013 the marriage of rum, lubricant of the old colonial empires, and Coca-Cola, icon of modern American global capitalism\". Additionally, both rum and Coca-Cola are made from Caribbean ingredients and became global commodities through European and American commerce. According to Coulombe, the drink \"seems to reflect perfectly the historical elements of the modern world\".\nRecipe and variations.\nRecipes vary somewhat in measures and additional ingredients, but the main ingredients are always rum and cola. The International Bartenders Association recipe calls for 5 centiliters of light rum, 12\u00a0cl of cola, and 1\u00a0cl of fresh lime juice on ice. However, any amount and proportion of rum and cola may be used. Additionally, while light rum is traditional, dark rums and other varieties are also common.\nCoca-Cola is the conventional cola in the drink, to the point that customers rarely order anything else. This dates back to the origin of the drink in Cuba and was solidified in the 1920s when Coca-Cola emerged as the primary cola brand following the bankruptcy of Pepsi and Chero-Cola, and therefore the preferred cola mixer in alcoholic drinks. Pepsi's later attempts to enter the cocktail market were unsuccessful, especially after the song \"Rum and Coca-Cola\" solidified the association in the public imagination.\nNonetheless, different colas are sometimes used. In Cuba, as Coca-Cola has not been imported since the U.S. embargo of 1960, the domestic TuKola is used in Cuba libres. Other common variants call for Mexican Coke (which uses cane sugar instead of high-fructose corn syrup), Moxie, Diet Coke (the Cuba Lite or rum and Diet) and Dr. Pepper (the Captain and Pepper, featuring Captain Morgan spiced rum).\nLime is traditionally included in the drink, though it is often left out, especially when the order is for just \"rum and Coke\". Some early recipes called for lime juice to be mixed in; others included lime only as a garnish. Other early recipes called for additional ingredients such as gin and bitters. Some sources consider lime essential for a drink to be a true Cuba libre, which they distinguish from a mere rum and Coke. However, lime is frequently included even in orders for \"rum and Coke\".\nWhen aged a\u00f1ejo rum is used, the drink is sometimes called a \"Cubata\", a name also used informally in Spain for any Cuba libre. Some modern recipes inspired by older ones include additional ingredients such as bitters. More elaborate variants with further ingredients include the cinema highball, which uses rum infused with buttered popcorn and mixed with cola. Another is the Mandeville cocktail, which includes light and dark rum, cola, and citrus juice along with Pernod absinthe and grenadine."}
{"id": "7607", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=7607", "title": "Collagen helix", "text": "In molecular biology, the collagen triple helix or type-2 helix is the main secondary structure of various types of fibrous collagen, including type I collagen. In 1954, Ramachandran &amp; Kartha (13, 14) advanced a structure for the collagen triple helix on the basis of fiber diffraction data. It consists of a triple helix made of the repetitious amino acid sequence glycine-X-Y, where X and Y are frequently proline or hydroxyproline. Collagen folded into a triple helix is known as tropocollagen. Collagen triple helices are often bundled into fibrils which themselves form larger fibres, as in tendons.\nStructure.\nGlycine, proline, and hydroxyproline must be in their designated positions with the correct configuration. For example, hydroxyproline in the Y position increases the thermal stability of the triple helix, but not when it is located in the X position. The thermal stabilization is also hindered when the hydroxyl group has the wrong configuration. Due to the high abundance of glycine and proline contents, collagen fails to form a regular \u03b1-helix and \u03b2-sheet structure. Three left-handed helical strands twist to form a right-handed triple helix. A collagen triple helix has 3.3 residues per turn.\nEach of the three chains is stabilized by the steric repulsion due to the pyrrolidine rings of proline and hydroxyproline residues. The pyrrolidine rings keep out of each other's way when the polypeptide chain assumes this extended helical form, which is much more open than the tightly coiled form of the alpha helix.\nThe three chains are hydrogen bonded to each other. The hydrogen bond donors are the peptide NH groups of glycine residues. The hydrogen bond acceptors are the CO groups of residues on the other chains. The OH group of hydroxyproline does not participate in hydrogen bonding but stabilises the trans isomer of proline by stereoelectronic effects, therefore stabilizing the entire triple helix.\nThe rise of the collagen helix (superhelix) is 2.9 \u00c5 (0.29\u00a0nm) per residue. The center of the collagen triple helix is very small and hydrophobic, and every third residue of the helix must have contact with the center. Due to the very tiny and tight space at the center, only the small hydrogen of the glycine side chain is capable of interacting with the center. This contact is impossible even when a slightly bigger amino acid residue is present other than glycine."}
{"id": "7609", "revid": "41814246", "url": "https://en.wikipedia.org/wiki?curid=7609", "title": "Cosmic censorship hypothesis", "text": "The weak and the strong cosmic censorship hypotheses are two mathematical conjectures about the structure of gravitational singularities arising in general relativity.\nSingularities that arise in the solutions of Einstein's equations are typically hidden within event horizons, and therefore cannot be observed from the rest of spacetime. Singularities that are not so hidden are called \"naked\". The weak cosmic censorship hypothesis was conceived by Roger Penrose in 1969 and posits that no naked singularities exist in the universe.\nBasics.\nSince the physical behavior of singularities is unknown, if singularities can be observed from the rest of spacetime, causality may break down, and physics may lose its predictive power. The issue cannot be avoided, since according to the Penrose\u2013Hawking singularity theorems, singularities are inevitable in physically reasonable situations. Still, in the absence of naked singularities, the universe, as described by the general theory of relativity, is deterministic: it is possible to predict the entire evolution of the universe (possibly excluding some finite regions of space hidden inside event horizons of singularities), knowing only its condition at a certain moment of time (more precisely, everywhere on a spacelike three-dimensional hypersurface, called the Cauchy surface). Failure of the cosmic censorship hypothesis leads to the failure of determinism, because it is yet impossible to predict the behavior of spacetime in the causal future of a singularity. Cosmic censorship is not merely a problem of formal interest; some form of it is assumed whenever black hole event horizons are mentioned.\nThe hypothesis was first formulated by Roger Penrose in 1969, and it is not stated in a completely formal way. In a sense it is more of a research program proposal: part of the research is to find a proper formal statement that is physically reasonable, falsifiable, and sufficiently general to be interesting. Because the statement is not a strictly formal one, there is sufficient latitude for (at least) two independent formulations: a weak form, and a strong form.\nWeak and strong cosmic censorship hypothesis.\nThe weak and the strong cosmic censorship hypotheses are two conjectures concerned with the global geometry of spacetimes.\nThe weak cosmic censorship hypothesis asserts there can be no singularity visible from future null infinity. In other words, singularities need to be hidden from an observer at infinity by the event horizon of a black hole. Mathematically, the conjecture states that, for generic initial data, the causal structure is such that the maximal Cauchy development possesses a complete future null infinity.\nThe strong cosmic censorship hypothesis asserts that, generically, general relativity is a deterministic theory, in the same sense that classical mechanics is a deterministic theory. In other words, the classical fate of all observers should be predictable from the initial data. Mathematically, the conjecture states that the maximal Cauchy development of generic compact or asymptotically flat initial data is locally inextendible as a regular Lorentzian manifold. Taken in its strongest sense, the conjecture suggests locally inextendibility of the maximal Cauchy development as a continuous Lorentzian manifold [very Strong Cosmic Censorship]. This strongest version was disproven in 2018 by Mihalis Dafermos and Jonathan Luk for the Cauchy horizon of an uncharged, rotating black hole. \nThe two conjectures are mathematically independent, as there exist spacetimes for which weak cosmic censorship is valid but strong cosmic censorship is violated and, conversely, there exist spacetimes for which weak cosmic censorship is violated but strong cosmic censorship is valid.\nExample.\nThe Kerr metric, corresponding to a black hole of mass formula_1 and angular momentum formula_2, can be used to derive the effective potential for particle orbits restricted to the equator (as defined by rotation). This potential looks like:\nformula_3\nwhere formula_4 is the coordinate radius, formula_5 and formula_6 are the test-particle's conserved energy and angular momentum respectively (constructed from the Killing vectors).\nTo preserve \"cosmic censorship\", the black hole is restricted to the case of formula_7. For there to exist an event horizon around the singularity, the requirement formula_7 must be satisfied. This amounts to the angular momentum of the black hole being constrained to below a critical value, outside of which the horizon would disappear. \nThe following thought experiment is reproduced from Hartle's \"Gravity\":\nProblems with the concept.\nThere are a number of difficulties in formalizing the hypothesis:\nIn 1991, John Preskill and Kip Thorne bet against Stephen Hawking that the hypothesis was false. Hawking conceded the bet in 1997, due to the discovery of the special situations just mentioned, which he characterized as \"technicalities\". Hawking later reformulated the bet to exclude those technicalities. The revised bet is still open (although Hawking died in 2018), the prize being \"clothing to cover the winner's nakedness\".\nCounter-example.\nAn exact solution to the scalar-Einstein equations formula_11 which forms a counterexample to many formulations of the \ncosmic censorship hypothesis was found by Mark D. Roberts in 1985:\nformula_12\nwhere formula_13 is a constant."}
