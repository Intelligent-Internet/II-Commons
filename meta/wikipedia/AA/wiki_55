{"id": "6271", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=6271", "title": "Chemical reaction", "text": "A chemical reaction is a process that leads to the chemical transformation of one set of chemical substances to another. When chemical reactions occur, the atoms are rearranged and the reaction is accompanied by an energy change as new products are generated. Classically, chemical reactions encompass changes that only involve the positions of electrons in the forming and breaking of chemical bonds between atoms, with no change to the nuclei (no change to the elements present), and can often be described by a chemical equation. Nuclear chemistry is a sub-discipline of chemistry that involves the chemical reactions of unstable and radioactive elements where both electronic and nuclear changes can occur.\nThe substance (or substances) initially involved in a chemical reaction are called reactants or reagents. Chemical reactions are usually characterized by a chemical change, and they yield one or more products, which usually have properties different from the reactants. Reactions often consist of a sequence of individual sub-steps, the so-called elementary reactions, and the information on the precise course of action is part of the reaction mechanism. Chemical reactions are described with chemical equations, which symbolically present the starting materials, end products, and sometimes intermediate products and reaction conditions.\nChemical reactions happen at a characteristic reaction rate at a given temperature and chemical concentration. Some reactions produce heat and are called exothermic reactions, while others may require heat to enable the reaction to occur, which are called endothermic reactions. Typically, reaction rates increase with increasing temperature because there is more thermal energy available to reach the activation energy necessary for breaking bonds between atoms.\nA reaction may be classified as redox in which oxidation and reduction occur or non-redox in which there is no oxidation and reduction occurring. Most simple redox reactions may be classified as a combination, decomposition, or single displacement reaction.\nDifferent chemical reactions are used during chemical synthesis in order to obtain the desired product. In biochemistry, a consecutive series of chemical reactions (where the product of one reaction is the reactant of the next reaction) form metabolic pathways. These reactions are often catalyzed by protein enzymes. Enzymes increase the rates of biochemical reactions, so that metabolic syntheses and decompositions impossible under ordinary conditions can occur at the temperature and concentrations present within a cell.\nThe general concept of a chemical reaction has been extended to reactions between entities smaller than atoms, including nuclear reactions, radioactive decays and reactions between elementary particles, as described by quantum field theory.\nHistory.\nChemical reactions such as combustion in fire, fermentation and the reduction of ores to metals were known since antiquity. Initial theories of transformation of materials were developed by Greek philosophers, such as the Four-Element Theory of Empedocles stating that any substance is composed of the four basic elements \u2013 fire, water, air and earth. In the Middle Ages, chemical transformations were studied by alchemists. They attempted, in particular, to convert lead into gold, for which purpose they used reactions of lead and lead-copper alloys with sulfur.\nThe artificial production of chemical substances already was a central goal for medieval alchemists. Examples include the synthesis of ammonium chloride from organic substances as described in the works (c. 850\u2013950) attributed to J\u0101bir ibn \u1e24ayy\u0101n, or the production of mineral acids such as sulfuric and nitric acids by later alchemists, starting from c. 1300. The production of mineral acids involved the heating of sulfate and nitrate minerals such as copper sulfate, alum and saltpeter. In the 17th century, Johann Rudolph Glauber produced hydrochloric acid and sodium sulfate by reacting sulfuric acid and sodium chloride. With the development of the lead chamber process in 1746 and the Leblanc process, allowing large-scale production of sulfuric acid and sodium carbonate, respectively, chemical reactions became implemented into the industry. Further optimization of sulfuric acid technology resulted in the contact process in the 1880s, and the Haber process was developed in 1909\u20131910 for ammonia synthesis.\nFrom the 16th century, researchers including Jan Baptist van Helmont, Robert Boyle, and Isaac Newton tried to establish theories of experimentally observed chemical transformations. The phlogiston theory was proposed in 1667 by Johann Joachim Becher. It postulated the existence of a fire-like element called \"phlogiston\", which was contained within combustible bodies and released during combustion. This proved to be false in 1785 by Antoine Lavoisier who found the correct explanation of the combustion as a reaction with oxygen from the air.\nJoseph Louis Gay-Lussac recognized in 1808 that gases always react in a certain relationship with each other. Based on this idea and the atomic theory of John Dalton, Joseph Proust had developed the law of definite proportions, which later resulted in the concepts of stoichiometry and chemical equations.\nRegarding the organic chemistry, it was long believed that compounds obtained from living organisms were too complex to be obtained synthetically. According to the concept of vitalism, organic matter was endowed with a \"vital force\" and distinguished from inorganic materials. This separation was ended however by the synthesis of urea from inorganic precursors by Friedrich W\u00f6hler in 1828. Other chemists who brought major contributions to organic chemistry include Alexander William Williamson with his synthesis of ethers and Christopher Kelk Ingold, who, among many discoveries, established the mechanisms of substitution reactions.\nCharacteristics.\nThe general characteristics of chemical reactions are:\nEquations.\nChemical equations are used to graphically illustrate chemical reactions. They consist of chemical or structural formulas of the reactants on the left and those of the products on the right. They are separated by an arrow (\u2192) which indicates the direction and type of the reaction; the arrow is read as the word \"yields\". The tip of the arrow points in the direction in which the reaction proceeds. A double arrow () pointing in opposite directions is used for equilibrium reactions. Equations should be balanced according to the stoichiometry, the number of atoms of each species should be the same on both sides of the equation. This is achieved by scaling the number of involved molecules (A, B, C and D in a schematic example below) by the appropriate integers \"a, b, c\" and \"d\".\nMore elaborate reactions are represented by reaction schemes, which in addition to starting materials and products show important intermediates or transition states. Also, some relatively minor additions to the reaction can be indicated above the reaction arrow; examples of such additions are water, heat, illumination, a catalyst, etc. Similarly, some minor products can be placed below the arrow, often with a minus sign.\nRetrosynthetic analysis can be applied to design a complex synthesis reaction. Here the analysis starts from the products, for example by splitting selected chemical bonds, to arrive at plausible initial reagents. A special arrow (\u21d2) is used in retro reactions.\nElementary reactions.\nThe elementary reaction is the smallest division into which a chemical reaction can be decomposed, it has no intermediate products. Most experimentally observed reactions are built up from many elementary reactions that occur in parallel or sequentially. The actual sequence of the individual elementary reactions is known as reaction mechanism. An elementary reaction involves a few molecules, usually one or two, because of the low probability for several molecules to meet at a certain time.\nThe most important elementary reactions are unimolecular and bimolecular reactions. Only one molecule is involved in a unimolecular reaction; it is transformed by isomerization or a dissociation into one or more other molecules. Such reactions require the addition of energy in the form of heat or light. A typical example of a unimolecular reaction is the cis\u2013trans isomerization, in which the cis-form of a compound converts to the trans-form or vice versa.\nIn a typical dissociation reaction, a bond in a molecule splits (ruptures) resulting in two molecular fragments. The splitting can be homolytic or heterolytic. In the first case, the bond is divided so that each product retains an electron and becomes a neutral radical. In the second case, both electrons of the chemical bond remain with one of the products, resulting in charged ions. Dissociation plays an important role in triggering chain reactions, such as hydrogen\u2013oxygen or polymerization reactions.\nFor bimolecular reactions, two molecules collide and react with each other. Their merger is called chemical synthesis or an addition reaction.\nAnother possibility is that only a portion of one molecule is transferred to the other molecule. This type of reaction occurs, for example, in redox and acid-base reactions. In redox reactions, the transferred particle is an electron, whereas in acid-base reactions it is a proton. This type of reaction is also called metathesis.\nfor example\nChemical equilibrium.\nMost chemical reactions are reversible; that is, they can and do run in both directions. The forward and reverse reactions are competing with each other and differ in reaction rates. These rates depend on the concentration and therefore change with the time of the reaction: the reverse rate gradually increases and becomes equal to the rate of the forward reaction, establishing the so-called chemical equilibrium. The time to reach equilibrium depends on parameters such as temperature, pressure, and the materials involved, and is determined by the minimum free energy. In equilibrium, the Gibbs free energy of reaction must be zero. The pressure dependence can be explained with the Le Chatelier's principle. For example, an increase in pressure due to decreasing volume causes the reaction to shift to the side with fewer moles of gas.\nThe reaction yield stabilizes at equilibrium but can be increased by removing the product from the reaction mixture or changed by increasing the temperature or pressure. A change in the concentrations of the reactants does not affect the equilibrium constant but does affect the equilibrium position.\nThermodynamics.\nChemical reactions are determined by the laws of thermodynamics. Reactions can proceed by themselves if they are exergonic, that is if they release free energy. The associated free energy change of the reaction is composed of the changes of two different thermodynamic quantities, enthalpy and entropy:\nReactions can be exothermic, where \u0394\"H\" is negative and energy is released. Typical examples of exothermic reactions are combustion, precipitation and crystallization, in which ordered solids are formed from disordered gaseous or liquid phases. In contrast, in endothermic reactions, heat is consumed from the environment. This can occur by increasing the entropy of the system, often through the formation of gaseous or dissolved reaction products, which have higher entropy. Since the entropy term in the free-energy change increases with temperature, many endothermic reactions preferably take place at high temperatures. On the contrary, many exothermic reactions such as crystallization occur preferably at lower temperatures. A change in temperature can sometimes reverse the sign of the enthalpy of a reaction, as for the carbon monoxide reduction of molybdenum dioxide:\nThis reaction to form carbon dioxide and molybdenum is endothermic at low temperatures, becoming less so with increasing temperature. \u0394\"H\"\u00b0 is zero at , and the reaction becomes exothermic above that temperature.\nChanges in temperature can also reverse the direction tendency of a reaction. For example, the water gas shift reaction\nis favored by low temperatures, but its reverse is favored by high temperatures. The shift in reaction direction tendency occurs at .\nReactions can also be characterized by their internal energy change, which takes into account changes in the entropy, volume and chemical potentials. The latter depends, among other things, on the activities of the involved substances.\nKinetics.\nThe speed at which reactions take place is studied by reaction kinetics. The rate depends on various parameters, such as:\nSeveral theories allow calculating the reaction rates at the molecular level. This field is referred to as reaction dynamics. The rate \"v\" of a first-order reaction, which could be the disintegration of a substance A, is given by:\nIts integration yields:\nHere \"k\" is the first-order rate constant, having dimension 1/time, [A](\"t\") is the concentration at a time \"t\" and [A]0 is the initial concentration. The rate of a first-order reaction depends only on the concentration and the properties of the involved substance, and the reaction itself can be described with a characteristic half-life. More than one time constant is needed when describing reactions of higher order. The temperature dependence of the rate constant usually follows the Arrhenius equation:\nwhere \"E\"a is the activation energy and \"k\"B is the Boltzmann constant. One of the simplest models of reaction rate is the collision theory. More realistic models are tailored to a specific problem and include the transition state theory, the calculation of the potential energy surface, the Marcus theory and the Rice\u2013Ramsperger\u2013Kassel\u2013Marcus (RRKM) theory.\nReaction types.\nFour basic types.\nSynthesis.\nIn a synthesis reaction, two or more simple substances combine to form a more complex substance. These reactions are in the general form:\n&lt;chem display=\"block\"&gt;A + B-&gt;AB&lt;/chem&gt;\nTwo or more reactants yielding one product is another way to identify a synthesis reaction. One example of a synthesis reaction is the combination of iron and sulfur to form iron(II) sulfide:\n&lt;chem display=\"block\"&gt;8Fe + S8-&gt;8FeS&lt;/chem&gt;\nAnother example is simple hydrogen gas combined with simple oxygen gas to produce a more complex substance, such as water.\nDecomposition.\nA decomposition reaction is when a more complex substance breaks down into its more simple parts. It is thus the opposite of a synthesis reaction and can be written as\n&lt;chem display=\"block\"&gt;AB-&gt;A + B&lt;/chem&gt;\nOne example of a decomposition reaction is the electrolysis of water to make oxygen and hydrogen gas:\n&lt;chem display=\"block\"&gt;2H2O-&gt;2H2 + O2&lt;/chem&gt;\nSingle displacement.\nIn a single displacement reaction, a single uncombined element replaces another in a compound; in other words, one element trades places with another element in a compound These reactions come in the general form of:\n&lt;chem display=\"block\"&gt;A + BC-&gt;AC + B&lt;/chem&gt;\nOne example of a single displacement reaction is when magnesium replaces hydrogen in water to make solid magnesium hydroxide and hydrogen gas:\n&lt;chem display=\"block\"&gt;Mg + 2H2O-&gt;Mg(OH)2 (v) + H2 (^)&lt;/chem&gt;\nDouble displacement.\nIn a double displacement reaction, the anions and cations of two compounds switch places and form two entirely different compounds. These reactions are in the general form:\n&lt;chem display=\"block\"&gt;AB + CD-&gt;AD + CB&lt;/chem&gt;\nFor example, when barium chloride (BaCl2) and magnesium sulfate (MgSO4) react, the SO42\u2212 anion switches places with the 2Cl\u2212 anion, giving the compounds BaSO4 and MgCl2.\nAnother example of a double displacement reaction is the reaction of lead(II) nitrate with potassium iodide to form lead(II) iodide and potassium nitrate:\n&lt;chem display=\"block\"&gt;Pb(NO3)2 + 2KI-&gt;PbI2(v) + 2KNO3&lt;/chem&gt;\nForward and backward reactions.\nAccording to Le Chatelier's Principle, reactions may proceed in the forward or reverse direction until they end or reach equilibrium.\nForward reactions.\nReactions that proceed in the forward direction (from left to right) to approach equilibrium are often called spontaneous reactions, that is, formula_7 is negative, which means that if they occur at constant temperature and pressure, they decrease the Gibbs free energy of the reaction. They require less energy to proceed in the forward direction. Reactions are usually written as forward reactions in the direction in which they are spontaneous. Examples:\nBackward reactions.\nReactions that proceed in the backward direction to approach equilibrium are often called non-spontaneous reactions, that is, formula_7 is positive, which means that if they occur at constant temperature and pressure, they increase the Gibbs free energy of the reaction. They require input of energy to proceed in the forward direction. Examples include:\nCombustion.\nIn a combustion reaction, an element or compound reacts with an oxidant, usually oxygen, often producing energy in the form of heat or light. Combustion reactions frequently involve a hydrocarbon. For instance, the combustion of 1 mole (114 g) of octane in oxygen\n&lt;chem display=\"block\"&gt;C8H18(l) + 25/2 O2(g)-&gt;8CO2 + 9H2O(l)&lt;/chem&gt;\nreleases 5500 kJ. A combustion reaction can also result from carbon, magnesium or sulfur reacting with oxygen.\n&lt;chem display=\"block\"&gt;2Mg(s) + O2-&gt;2MgO(s)&lt;/chem&gt;\n&lt;chem display=\"block\"&gt;S(s) + O2(g)-&gt;SO2(g)&lt;/chem&gt;\nOxidation and reduction.\nRedox reactions can be understood in terms of the transfer of electrons from one involved species (reducing agent) to another (oxidizing agent). In this process, the former species is \"oxidized\" and the latter is \"reduced\". Though sufficient for many purposes, these descriptions are not precisely correct. Oxidation is better defined as an increase in oxidation state of atoms and reduction as a decrease in oxidation state. In practice, the transfer of electrons will always change the oxidation state, but there are many reactions that are classed as \"redox\" even though no electron transfer occurs (such as those involving covalent bonds).\nIn the following redox reaction, hazardous sodium metal reacts with toxic chlorine gas to form the ionic compound sodium chloride, or common table salt:\n&lt;chem display=\"block\"&gt;2Na(s) + Cl2(g)-&gt;2NaCl(s)&lt;/chem&gt;\nIn the reaction, sodium metal goes from an oxidation state of 0 (a pure element) to +1: in other words, the sodium lost one electron and is said to have been oxidized. On the other hand, the chlorine gas goes from an oxidation of 0 (also a pure element) to \u22121: the chlorine gains one electron and is said to have been reduced. Because the chlorine is the one reduced, it is considered the electron acceptor, or in other words, induces oxidation in the sodium \u2013 thus the chlorine gas is considered the oxidizing agent. Conversely, the sodium is oxidized or is the electron donor, and thus induces a reduction in the other species and is considered the \"reducing agent\".\nWhich of the involved reactants would be a reducing or oxidizing agent can be predicted from the electronegativity of their elements. Elements with low electronegativities, such as most metals, easily donate electrons and oxidize \u2013 they are reducing agents. On the contrary, many oxides or ions with high oxidation numbers of their non-oxygen atoms, such as , , , , or , can gain one or two extra electrons and are strong oxidizing agents.\nFor some main-group elements the number of electrons donated or accepted in a redox reaction can be predicted from the electron configuration of the reactant element. Elements try to reach the low-energy noble gas configuration, and therefore alkali metals and halogens will donate and accept one electron, respectively. Noble gases themselves are chemically inactive.\nThe overall redox reaction can be balanced by combining the oxidation and reduction half-reactions multiplied by coefficients such that the number of electrons lost in the oxidation equals the number of electrons gained in the reduction.\nAn important class of redox reactions are the electrolytic electrochemical reactions, where electrons from the power supply at the negative electrode are used as the reducing agent and electron withdrawal at the positive electrode as the oxidizing agent. These reactions are particularly important for the production of chemical elements, such as chlorine or aluminium. The reverse process, in which electrons are released in redox reactions and chemical energy is converted to electrical energy, is possible and used in batteries.\nComplexation.\nIn complexation reactions, several ligands react with a metal atom to form a coordination complex. This is achieved by providing lone pairs of the ligand into empty orbitals of the metal atom and forming dipolar bonds. The ligands are Lewis bases, they can be both ions and neutral molecules, such as carbon monoxide, ammonia or water. The number of ligands that react with a central metal atom can be found using the 18-electron rule, saying that the valence shells of a transition metal will collectively accommodate 18 electrons, whereas the symmetry of the resulting complex can be predicted with the crystal field theory and ligand field theory. Complexation reactions also include ligand exchange, in which one or more ligands are replaced by another, and redox processes which change the oxidation state of the central metal atom.\nAcid\u2013base reactions.\nIn the Br\u00f8nsted\u2013Lowry acid\u2013base theory, an acid\u2013base reaction involves a transfer of protons (H+) from one species (the acid) to another (the base). When a proton is removed from an acid, the resulting species is termed that acid's conjugate base. When the proton is accepted by a base, the resulting species is termed that base's conjugate acid. In other words, acids act as proton donors and bases act as proton acceptors according to the following equation:\n&lt;chem display=\"block\"&gt;\\underset{acid}{HA} + \\underset{base}{B} &lt;=&gt; \\underset{conjugated\\ base}{A^-} + \\underset{conjugated\\ acid}{HB+}&lt;/chem&gt;\nThe reverse reaction is possible, and thus the acid/base and conjugated base/acid are always in equilibrium. The equilibrium is determined by the acid and base dissociation constants (\"K\"a and \"K\"b) of the involved substances. A special case of the acid-base reaction is the neutralization where an acid and a base, taken at the exact same amounts, form a neutral salt.\nAcid-base reactions can have different definitions depending on the acid-base concept employed. Some of the most common are:\nPrecipitation.\nPrecipitation is the formation of a solid in a solution or inside another solid during a chemical reaction. It usually takes place when the concentration of dissolved ions exceeds the solubility limit and forms an insoluble salt. This process can be assisted by adding a precipitating agent or by the removal of the solvent. Rapid precipitation results in an amorphous or microcrystalline residue and a slow process can yield single crystals. The latter can also be obtained by recrystallization from microcrystalline salts.\nSolid-state reactions.\nReactions can take place between two solids. However, because of the relatively small diffusion rates in solids, the corresponding chemical reactions are very slow in comparison to liquid and gas phase reactions. They are accelerated by increasing the reaction temperature and finely dividing the reactant to increase the contacting surface area.\nReactions at the solid/gas interface.\nThe reaction can take place at the solid|gas interface, surfaces at very low pressure such as ultra-high vacuum. Via scanning tunneling microscopy, it is possible to observe reactions at the solid|gas interface in real space, if the time scale of the reaction is in the correct range. Reactions at the solid|gas interface are in some cases related to catalysis.\nPhotochemical reactions.\nIn photochemical reactions, atoms and molecules absorb energy (photons) of the illumination light and convert it into an excited state. They can then release this energy by breaking chemical bonds, thereby producing radicals. Photochemical reactions include hydrogen\u2013oxygen reactions, radical polymerization, chain reactions and rearrangement reactions.\nMany important processes involve photochemistry. The premier example is photosynthesis, in which most plants use solar energy to convert carbon dioxide and water into glucose, disposing of oxygen as a side-product. Humans rely on photochemistry for the formation of vitamin D, and vision is initiated by a photochemical reaction of rhodopsin. In fireflies, an enzyme in the abdomen catalyzes a reaction that results in bioluminescence. Many significant photochemical reactions, such as ozone formation, occur in the Earth atmosphere and constitute atmospheric chemistry.\nCatalysis.\nIn catalysis, the reaction does not proceed directly, but through a reaction with a third substance known as catalyst. Although the catalyst takes part in the reaction, forming weak bonds with reactants or intermediates, it is returned to its original state by the end of the reaction and so is not consumed. However, it can be inhibited, deactivated or destroyed by secondary processes. Catalysts can be used in a different phase (heterogeneous) or in the same phase (homogeneous) as the reactants. In heterogeneous catalysis, typical secondary processes include coking where the catalyst becomes covered by polymeric side products. Additionally, heterogeneous catalysts can dissolve into the solution in a solid-liquid system or evaporate in a solid\u2013gas system. Catalysts can only speed up the reaction \u2013 chemicals that slow down the reaction are called inhibitors. Substances that increase the activity of catalysts are called promoters, and substances that deactivate catalysts are called catalytic poisons. With a catalyst, a reaction that is kinetically inhibited by high activation energy can take place in the circumvention of this activation energy.\nHeterogeneous catalysts are usually solids, powdered in order to maximize their surface area. Of particular importance in heterogeneous catalysis are the platinum group metals and other transition metals, which are used in hydrogenations, catalytic reforming and in the synthesis of commodity chemicals such as nitric acid and ammonia. Acids are an example of a homogeneous catalyst, they increase the nucleophilicity of carbonyls, allowing a reaction that would not otherwise proceed with electrophiles. The advantage of homogeneous catalysts is the ease of mixing them with the reactants, but they may also be difficult to separate from the products. Therefore, heterogeneous catalysts are preferred in many industrial processes.\nReactions in organic chemistry.\nIn organic chemistry, in addition to oxidation, reduction or acid-base reactions, a number of other reactions can take place which involves covalent bonds between carbon atoms or carbon and heteroatoms (such as oxygen, nitrogen, halogens, etc.). Many specific reactions in organic chemistry are name reactions designated after their discoverers.\nOne of the most industrially important reactions is the cracking of heavy hydrocarbons at oil refineries to create smaller, simpler molecules. This process is used to manufacture gasoline. Specific types of organic reactions may be grouped by their reaction mechanisms (particularly substitution, addition and elimination) or by the types of products they produce (for example, methylation, polymerisation and halogenation).\nSubstitution.\nIn a substitution reaction, a functional group in a particular chemical compound is replaced by another group. These reactions can be distinguished by the type of substituting species into a nucleophilic, electrophilic or radical substitution.\nIn the first type, a nucleophile, an atom or molecule with an excess of electrons and thus a negative charge or partial charge, replaces another atom or part of the \"substrate\" molecule. The electron pair from the nucleophile attacks the substrate forming a new bond, while the leaving group departs with an electron pair. The nucleophile may be electrically neutral or negatively charged, whereas the substrate is typically neutral or positively charged. Examples of nucleophiles are hydroxide ion, alkoxides, amines and halides. This type of reaction is found mainly in aliphatic hydrocarbons, and rarely in aromatic hydrocarbon. The latter have high electron density and enter nucleophilic aromatic substitution only with very strong electron withdrawing groups. Nucleophilic substitution can take place by two different mechanisms, SN1 and SN2. In their names, S stands for substitution, N for nucleophilic, and the number represents the kinetic order of the reaction, unimolecular or bimolecular.\nThe SN1 reaction proceeds in two steps. First, the leaving group is eliminated creating a carbocation. This is followed by a rapid reaction with the nucleophile.\nIn the SN2 mechanisms, the nucleophile forms a transition state with the attacked molecule, and only then the leaving group is cleaved. These two mechanisms differ in the stereochemistry of the products. SN1 leads to the non-stereospecific addition and does not result in a chiral center, but rather in a set of geometric isomers (\"cis/trans\"). In contrast, a reversal (Walden inversion) of the previously existing stereochemistry is observed in the SN2 mechanism.\nElectrophilic substitution is the counterpart of the nucleophilic substitution in that the attacking atom or molecule, an electrophile, has low electron density and thus a positive charge. Typical electrophiles are the carbon atom of carbonyl groups, carbocations or sulfur or nitronium cations. This reaction takes place almost exclusively in aromatic hydrocarbons, where it is called electrophilic aromatic substitution. The electrophile attack results in the so-called \u03c3-complex, a transition state in which the aromatic system is abolished. Then, the leaving group, usually a proton, is split off and the aromaticity is restored. An alternative to aromatic substitution is electrophilic aliphatic substitution. It is similar to the nucleophilic aliphatic substitution and also has two major types, SE1 and SE2\nIn the third type of substitution reaction, radical substitution, the attacking particle is a radical. This process usually takes the form of a chain reaction, for example in the reaction of alkanes with halogens. In the first step, light or heat disintegrates the halogen-containing molecules producing radicals. Then the reaction proceeds as an avalanche until two radicals meet and recombine.\nAddition and elimination.\nThe addition and its counterpart, the elimination, are reactions that change the number of substituents on the carbon atom, and form or cleave multiple bonds. Double and triple bonds can be produced by eliminating a suitable leaving group. Similar to the nucleophilic substitution, there are several possible reaction mechanisms that are named after the respective reaction order. In the E1 mechanism, the leaving group is ejected first, forming a carbocation. The next step, the formation of the double bond, takes place with the elimination of a proton (deprotonation). The leaving order is reversed in the E1cb mechanism, that is the proton is split off first. This mechanism requires the participation of a base. Because of the similar conditions, both reactions in the E1 or E1cb elimination always compete with the SN1 substitution.\nThe E2 mechanism also requires a base, but there the attack of the base and the elimination of the leaving group proceed simultaneously and produce no ionic intermediate. In contrast to the E1 eliminations, different stereochemical configurations are possible for the reaction product in the E2 mechanism, because the attack of the base preferentially occurs in the anti-position with respect to the leaving group. Because of the similar conditions and reagents, the E2 elimination is always in competition with the SN2-substitution.\nThe counterpart of elimination is an addition where double or triple bonds are converted into single bonds. Similar to substitution reactions, there are several types of additions distinguished by the type of the attacking particle. For example, in the electrophilic addition of hydrogen bromide, an electrophile (proton) attacks the double bond forming a carbocation, which then reacts with the nucleophile (bromine). The carbocation can be formed on either side of the double bond depending on the groups attached to its ends, and the preferred configuration can be predicted with the Markovnikov's rule. This rule states that \"In the heterolytic addition of a polar molecule to an alkene or alkyne, the more electronegative (nucleophilic) atom (or part) of the polar molecule becomes attached to the carbon atom bearing the smaller number of hydrogen atoms.\"\nIf the addition of a functional group takes place at the less substituted carbon atom of the double bond, then the electrophilic substitution with acids is not possible. In this case, one has to use the hydroboration\u2013oxidation reaction, wherein the first step, the boron atom acts as electrophile and adds to the less substituted carbon atom. In the second step, the nucleophilic hydroperoxide or halogen anion attacks the boron atom.\nWhile the addition to the electron-rich alkenes and alkynes is mainly electrophilic, the nucleophilic addition plays an important role in the carbon-heteroatom multiple bonds, and especially its most important representative, the carbonyl group. This process is often associated with elimination so that after the reaction the carbonyl group is present again. It is, therefore, called an addition-elimination reaction and may occur in carboxylic acid derivatives such as chlorides, esters or anhydrides. This reaction is often catalyzed by acids or bases, where the acids increase the electrophilicity of the carbonyl group by binding to the oxygen atom, whereas the bases enhance the nucleophilicity of the attacking nucleophile.\nNucleophilic addition of a carbanion or another nucleophile to the double bond of an alpha, beta-unsaturated carbonyl compound can proceed via the Michael reaction, which belongs to the larger class of conjugate additions. This is one of the most useful methods for the mild formation of C\u2013C bonds.\nSome additions which can not be executed with nucleophiles and electrophiles can be succeeded with free radicals. As with the free-radical substitution, the radical addition proceeds as a chain reaction, and such reactions are the basis of the free-radical polymerization.\nOther organic reaction mechanisms.\nIn a rearrangement reaction, the carbon skeleton of a molecule is rearranged to give a structural isomer of the original molecule. These include hydride shift reactions such as the Wagner-Meerwein rearrangement, where a hydrogen, alkyl or aryl group migrates from one carbon to a neighboring carbon. Most rearrangements are associated with the breaking and formation of new carbon-carbon bonds. Other examples are sigmatropic reaction such as the Cope rearrangement.\nCyclic rearrangements include cycloadditions and, more generally, pericyclic reactions, wherein two or more double bond-containing molecules form a cyclic molecule. An important example of cycloaddition reaction is the Diels\u2013Alder reaction (the so-called [4+2] cycloaddition) between a conjugated diene and a substituted alkene to form a substituted cyclohexene system.\nWhether a certain cycloaddition would proceed depends on the electronic orbitals of the participating species, as only orbitals with the same sign of wave function will overlap and interact constructively to form new bonds. Cycloaddition is usually assisted by light or heat. These perturbations result in a different arrangement of electrons in the excited state of the involved molecules and therefore in different effects. For example, the [4+2] Diels-Alder reactions can be assisted by heat whereas the [2+2] cycloaddition is selectively induced by light. Because of the orbital character, the potential for developing stereoisomeric products upon cycloaddition is limited, as described by the Woodward\u2013Hoffmann rules.\nBiochemical reactions.\nBiochemical reactions are mainly controlled by complex proteins called enzymes, which are usually specialized to catalyze only a single, specific reaction. The reaction takes place in the active site, a small part of the enzyme which is usually found in a cleft or pocket lined by amino acid residues, and the rest of the enzyme is used mainly for stabilization. The catalytic action of enzymes relies on several mechanisms including the molecular shape (\"induced fit\"), bond strain, proximity and orientation of molecules relative to the enzyme, proton donation or withdrawal (acid/base catalysis), electrostatic interactions and many others.\nThe biochemical reactions that occur in living organisms are collectively known as metabolism. Among the most important of its mechanisms is the anabolism, in which different DNA and enzyme-controlled processes result in the production of large molecules such as proteins and carbohydrates from smaller units. Bioenergetics studies the sources of energy for such reactions. Important energy sources are glucose and oxygen, which can be produced by plants via photosynthesis or assimilated from food and air, respectively. All organisms use this energy to produce adenosine triphosphate (ATP), which can then be used to energize other reactions. Decomposition of organic material by fungi, bacteria and other micro-organisms is also within the scope of biochemistry.\nApplications.\nChemical reactions are central to chemical engineering, where they are used for the synthesis of new compounds from natural raw materials such as petroleum, mineral ores, and oxygen in air. It is essential to make the reaction as efficient as possible, maximizing the yield and minimizing the number of reagents, energy inputs and waste. Catalysts are especially helpful for reducing the energy required for the reaction and increasing its reaction rate.\nSome specific reactions have their niche applications. For example, the thermite reaction is used to generate light and heat in pyrotechnics and welding. Although it is less controllable than the more conventional oxy-fuel welding, arc welding and flash welding, it requires much less equipment and is still used to mend rails, especially in remote areas.\nMonitoring.\nMechanisms of monitoring chemical reactions depend strongly on the reaction rate. Relatively slow processes can be analyzed in situ for the concentrations and identities of the individual ingredients. Important tools of real-time analysis are the measurement of pH and analysis of optical absorption (color) and emission spectra. A less accessible but rather efficient method is the introduction of a radioactive isotope into the reaction and monitoring how it changes over time and where it moves to; this method is often used to analyze the redistribution of substances in the human body. Faster reactions are usually studied with ultrafast laser spectroscopy where utilization of femtosecond lasers allows short-lived transition states to be monitored at a time scaled down to a few femtoseconds."}
{"id": "6272", "revid": "152145", "url": "https://en.wikipedia.org/wiki?curid=6272", "title": "Charleston", "text": "Charleston most commonly refers to:\nCharleston may also refer to:"}
{"id": "6276", "revid": "374244", "url": "https://en.wikipedia.org/wiki?curid=6276", "title": "Casiquiare canal", "text": "The Casiquiare river or canal () is a natural distributary of the upper Orinoco flowing southward into the Rio Negro, in Venezuela, South America. As such, it forms a unique natural canal between the Orinoco and Amazon river systems. It is the world's largest river of the kind that links two major river systems, a so-called bifurcation. The area forms a water divide, more dramatically at regional flood stage.\nThis rare phenomenon ends up forming an immense natural island, roughly the Guyana Shield, and thus technically the world's second largest, after Greenland, despite there not being a consensus on its island status.\nEtymology.\nThe name \"Casiquiare\", first used in that form by Manuel Rom\u00e1n, likely derives from the Ye'kuana language name of the river, \"Kashishiwadi\".\nDiscovery.\nThe first European to describe it was Spanish Jesuit missionary and explorer Crist\u00f3bal Diatrist\u00e1n de Acu\u00f1a in 1639.\nIn 1744 a Jesuit priest named Manuel Rom\u00e1n, while ascending the Orinoco River in the region of La Esmeralda, met some Portuguese slave-traders from the settlements on the Rio Negro. The Portuguese insisted they were not in Spanish territory but on a tributary of the Amazon; they invited Rom\u00e1n back with them to prove their claim. He accompanied them on their return, by way of the Casiquiare canal, and afterwards retraced his route to the Orinoco. Along the way, he made first contact with the Ye'kuana people, whom he enlisted to help in his journey. Charles Marie de La Condamine, seven months later, was able to give to the \"Acad\u00e9mie fran\u00e7aise\" an account of Father Rom\u00e1n's voyage, and thus confirm the existence of this waterway, first reported by Father Acu\u00f1a in 1639.\nLittle credence was given to Rom\u00e1n's statement until it was verified, in 1756, by the Spanish Boundary-line Commission of Jos\u00e9 Yturriaga and Solano. In 1800 German scientist Alexander von Humboldt and French botanist Aim\u00e9 Bonpland explored the river. In 1968 the Casiquiare was navigated by an SRN6 hovercraft during a The Geographical Journal expedition.\nGeography.\nThe origin of the Casiquiare, at the River Orinoco, is below the mission of La Esmeralda at , and about above sea level. Its mouth at the Rio Negro, an affluent of the Amazon River, is near the town of San Carlos and is above sea level.\nThe general course is south-west, and its length, including windings, is about . Its width, at its bifurcation with the Orinoco, is approximately , with a current towards the Rio Negro of . However, as it gains in volume from the very numerous tributary streams, large and small, that it receives en route, its velocity increases, and in the wet season reaches , even in certain stretches. It broadens considerably as it approaches its mouth, where it is about wide. The volume of water the Casiquiare captures from the Orinoco is small in comparison to what it accumulates in its course. Nevertheless, the geological processes are ongoing, and evidence points to a slow and gradual increase in the size of Casiquiare. It is likely that stream capture is in progress, i.e. what currently is the uppermost Orinoco basin, including Cunucunuma River, eventually will be entirely diverted by the Casiquiare into the Amazon basin.\nIn flood time, it is said to have a second connection with the Rio Negro by a branch, which it throws off to the westward, called the Itinivini, which leaves it at a point about above its mouth. In the dry season, it has shallows, and is obstructed by sandbanks, a few rapids and granite rocks. Its shores are densely wooded, and the soil more fertile than that along the Rio Negro. The general slope of the plains through which the canal runs is south-west, but those of the Rio Negro slope south-east.\nThe Casiquiare is not a sluggish canal on a flat tableland, but a great, rapid river which, if its upper waters had not found contact with the Orinoco, perhaps by cutting back, would belong entirely to the Negro branch of the Amazon.\nTo the west of the Casiquiare, there is a much shorter and easier portage between the Orinoco and Amazon basins, called the isthmus of Pimichin, which is reached by ascending the Temi branch of the Atabapo River, an affluent of the Orinoco. Although the Temi is somewhat obstructed, it is believed that it could easily be made navigable for small craft. The isthmus is across, with undulating ground, nowhere over high, with swamps and marshes. In the early 20th century, it was much used for the transit of large canoes, which were hauled across it from the Temi River and reached the Rio Negro by a little stream called the Pimichin.\nHydrographic divide.\nThe Casiquiare canal \u2013 Orinoco River hydrographic divide is a representation of the hydrographic water divide that delineates the separation between the Orinoco Basin and the Amazon Basin. (The Orinoco Basin flows west\u2013north\u2013northeast into the Caribbean; the Amazon Basin flows east into the western Atlantic in the extreme northeast of Brazil.)\nEssentially the river divide is a west-flowing, upriver section of Venezuela's Orinoco River with an outflow to the south into the Amazon Basin. This named outflow is the Casiquiare canal, which, as it heads downstream (southerly), picks up speed and also accumulates water volume.\nThe greatest manifestation of the divide is during floods. During flood stage, the Casiquiare's main outflow point into the Rio Negro is supplemented by an overflow that is a second, and more minor, entry river bifurcation into the Rio Negro and upstream from its major, common low-water entry confluence with the Rio Negro. At flood, the river becomes an area flow source, far more than a narrow confined river.\nThe Casiquiare canal connects the upper Orinoco, below the mission of Esmeraldas, with the Rio Negro affluent of the Amazon River near the town of San Carlos.\nThe simplest description (besides the entire area-floodplain) of the water divide is a \"south-bank Orinoco River strip\" at the exit point of the Orinoco, also the origin of the Casiquiare canal. However, during the Orinoco's flood stage, that single, simply defined \"origin of the canal\" is turned into a region, and an entire strip along the southern bank of the Orinoco River."}
{"id": "6278", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=6278", "title": "Complete normed vector space", "text": ""}
{"id": "6279", "revid": "44208334", "url": "https://en.wikipedia.org/wiki?curid=6279", "title": "Capetian dynasty", "text": "The Capetian dynasty ( ; ), also known as the \"House of France\" (), is a dynasty of Frankish origin, and a branch of the Robertians agnatically, and the Karlings through female lines. It is among the largest and oldest royal houses in Europe and the world, and consists of Hugh Capet, the founder of the dynasty, and his male-line descendants, who ruled in France without interruption from 987 to 1792, and again from 1814 to 1848. The senior line ruled in France as the House of Capet from the election of Hugh Capet in 987 until the death of Charles IV in 1328. That line was succeeded by cadet branches, the Houses of Valois and then Bourbon, which ruled without interruption until the French Revolution abolished the monarchy in 1792. The Bourbons were restored in 1814 in the aftermath of Napoleon's defeat, but had to vacate the throne again in 1830 in favor of the last Capetian monarch of France, Louis Philippe I, who belonged to the House of Orl\u00e9ans. Cadet branches of the Capetian House of Bourbon are still reigning over Spain and Luxembourg.\nThe dynasty had a crucial role in the formation of the French state. From a power base initially confined to their own demesne, the \u00cele-de-France, the Capetian kings slowly but steadily increased their power and influence until it grew to cover the entirety of their realm. For a detailed narration on the growth of French royal power, see \"Crown lands of France\".\nMembers of the dynasty were traditionally Catholic, and the early Capetians had an alliance with the Church. The French were also the most active participants in the Crusades, culminating in a series of five Crusader kings \u2013 Louis VII, Philip Augustus, Louis VIII, Louis IX, and Philip III. The Capetian alliance with the papacy suffered a severe blow after the disaster of the Aragonese Crusade. Philip III's son and successor, Philip IV, arrested Pope Boniface VIII and brought the papacy under French control. The later Valois, starting with Francis I, ignored religious differences and allied with the Ottoman sultan to counter the growing power of the Holy Roman Empire. Henry IV was a Protestant at the time of his accession, but realized the necessity of conversion after four years of religious warfare.\nThe Capetians generally enjoyed a harmonious family relationship. By tradition, younger sons and brothers of the king of France were given appanages for them to maintain their rank and to dissuade them from claiming the French crown itself. When Capetian cadets did aspire for kingship, their ambitions were directed not at the French throne, but at foreign thrones. As a result, the Capetians have reigned at different times in the kingdoms of Portugal, Sicily and Naples, Navarre, Hungary and Croatia, Poland, Spain and Sardinia, grand dukedoms of Lithuania and Luxembourg, and in Latin and Brazilian empires.\nIn modern times, King Felipe VI of Spain is a member of this family, while Grand Duke Henri of Luxembourg is related to the family by agnatic kinship; both through the Bourbon branch of the dynasty. Along with the House of Habsburg, arguably its greatest historic rival, it was one of the two oldest European royal dynasties. It was also one of the most powerful royal family in European history, having played a major role in its politics for much of its existence. According to Oxford University, 75% of all royal families in European history, are related to the Capetian dynasty.\nName origins and usage.\nThe name of the dynasty derives from its founder, Hugh, who was known as \"Hugh Capet\". The meaning of \"Capet\" (a nickname rather than a surname of the modern sort) is unknown. While folk etymology identifies it with \"cape\", other suggestions indicate it might be connected to the Latin word \"caput\" (\"head\"), and explain it as meaning \"chief\" or \"head\".\nHistorians in the 19th century (see House of France) came to apply the name \"Capetian\" to both the ruling house of France and to the wider-spread male-line descendants of Hugh Capet. It was not a contemporary practice. The name \"Capet\" has also been used as a surname for French royalty, particularly but not exclusively those of the House of Capet. One notable use was during the French Revolution, when the dethroned King Louis XVI (a member of the House of Bourbon and a direct male-line descendant of Hugh Capet) and Queen Marie Antoinette (a member of the House of Habsburg-Lorraine) were referred to as \"Louis and Antoinette Capet\" (the queen being addressed as \"the Widow Capet\" after the execution of her husband).\nCapetian miracle.\nThe Capetian miracle () refers to the dynasty's ability to attain and hold onto the French crown.\nIn 987, Hugh Capet was elected to succeed Louis V of the Carolingian dynasty that had ruled France for over three centuries. By a process of associating elder sons with them in the kingship, the early Capetians established the hereditary succession in their family and transformed a theoretically electoral kingship into a sacral one. By the time of Philip II Augustus, who became king in 1180, the Capetian hold on power was so strong that the practice of associate kingship was dropped. While the Capetian monarchy began as one of the weakest in Europe, drastically eclipsed by the new Anglo-Norman realm in England (who, as dukes of Normandy, were technically their vassals) and even other great lords of France, the political value of orderly succession in the Middle Ages cannot be overstated. The orderly succession of power from father to son over such a long period of time meant that the French monarchs, who originally were essentially just the direct rulers of the \u00cele-de-France, were able to preserve and extend their power, while over the course of centuries the great peers of the realm would eventually lose their power in one succession crisis or another.\nBy comparison, the Crusader Kingdom of Jerusalem was constantly beset with internal succession disputes because each generation only produced female heirs who tended to die young. Even the English monarchy encountered severe succession crises, such as The Anarchy of the 1120s between Stephen and Matilda, and the murder of Arthur I, Duke of Brittany, the primogeniture heir of Richard I of England. The latter case would deal a severe blow to the prestige of King John, leading to the eventual destruction of Angevin hegemony in France. In contrast, the French kings were able to maintain uncontested father-to-son succession from the time of Hugh Capet until the succession crisis which began the Hundred Years' War of the 14th century.\nCapetians through history.\nOver the succeeding centuries, Capetians spread throughout Europe, ruling every form of provincial unit from kingdoms to manors.\nSalic law.\nSalic law, re-established during the Hundred Years' War from an ancient Frankish tradition, caused the French monarchy to permit only male (agnatic) descendants of Hugh to succeed to the throne of France.\nWithout Salic law, upon the death of John I, the crown would have passed to his half-sister, Joan (later Joan II of Navarre). However, Joan's paternity was suspect due to her mother's adultery in the Tour de Nesle Affair; the French magnates adopted Salic law to avoid the succession of a possible bastard.\nIn 1328, King Charles IV of France died without male heirs, as his brothers did before him. Philip of Valois, the late king's first cousin, acted as regent, pending the birth of the king's posthumous child, which proved to be a girl. Isabella of France, sister of Charles IV, claimed the throne for her son, Edward III of England. The English king did not find support among the French lords, who made Philip of Valois their king. From then on the French succession not only excluded females but also rejected claims based on the female line of descent.\nThus the French crown passed from the House of Capet after the death of Charles IV to Philip VI of France of the House of Valois, a cadet branch of the Capetian dynasty,\nThis did not affect monarchies not under that law such as Portugal, Spain, Navarre, and various smaller duchies and counties. Therefore, many royal families appear and disappear in the French succession or become cadet branches upon marriage. A complete list of the senior-most line of Capetians is available below.\nCapetian cadet branches.\nThe Capetian dynasty has been broken many times into (sometimes rival) cadet branches. A cadet branch is a line of descent from another line than the senior-most. This list of cadet branches shows most of the Capetian cadet lines and designating their royal French progenitor, although some sub-branches are not shown.\nSenior Capets.\nThroughout most of history, the Senior Capet and the King of France were synonymous terms. Only in the time before Hugh Capet took the crown for himself and after the reign of Charles X is there a distinction such that the senior Capet must be identified independently from succession to the French Crown. However, since primogeniture and the Salic law provided for the succession of the French throne for most of French history, here is a list of all the French kings from Hugh until Charles, and all the Legitimist pretenders thereafter. All dates are for seniority, not reign.\nKing of France:\nLegitimist Pretenders:\nThe Capetian dynasty today.\nMany years have passed since the Capetian monarchs ruled a large part of Europe; however, they still remain as kings, as well as other titles. Currently two Capetian monarchs still rule in Spain and Luxembourg. In addition, seven pretenders represent exiled dynastic monarchies in Brazil, France, Spain, Portugal, Parma and Two Sicilies. The current legitimate, senior family member is Louis-Alphonse de Bourbon, known by his supporters as Duke of Anjou, who also holds the Legitimist (\"Blancs d'Espagne\") claim to the French throne. Overall, dozens of branches of the Capetian dynasty still exist throughout Europe.\nExcept for the House of Braganza (founded by an illegitimate son of King John I of Portugal, who was himself illegitimate), all current major Capetian branches are of the Bourbon cadet branch. Within the House of Bourbon, many of these lines are themselves well-defined cadet lines of the House.\nFamily tree.\nMale, male-line, legitimate, non-morganatic members of the house who either lived to adulthood, or who held a title as a child, are included. Heads of the house are in bold."}
{"id": "6280", "revid": "35839912", "url": "https://en.wikipedia.org/wiki?curid=6280", "title": "Cuboctahedron", "text": "A cuboctahedron is a polyhedron with 8 triangular faces and 6 square faces. A cuboctahedron has 12 identical vertices, with 2 triangles and 2 squares meeting at each, and 24 identical edges, each separating a triangle from a square. As such, it is a quasiregular polyhedron, i.e., an Archimedean solid that is not only vertex-transitive but also edge-transitive. It is radially equilateral. Its dual polyhedron is the rhombic dodecahedron.\nConstruction.\nThe cuboctahedron can be constructed in many ways:\nFrom all of these constructions, the cuboctahedron has 14 faces: 8 equilateral triangles and 6 squares. It also has 24 edges and 12 vertices.\nThe Cartesian coordinates for the vertices of a cuboctahedron with edge length formula_1 centered at the origin are:\nformula_2\nProperties.\nMeasurement and other metric properties.\nThe surface area of a cuboctahedron formula_3 can be determined by summing all the area of its polygonal faces. The volume of a cuboctahedron formula_4 can be determined by slicing it off into two regular triangular cupolas, summing up their volume. Given that the edge length formula_5, its surface area and volume are:\nformula_6\nThe dihedral angle of a cuboctahedron can be calculated with the angle of triangular cupolas. The dihedral angle of a triangular cupola between square-to-triangle is approximately 125\u00b0, that between square-to-hexagon is 54.7\u00b0, and that between triangle-to-hexagon is 70.5\u00b0. Therefore, the dihedral angle of a cuboctahedron between square-to-triangle, on the edge where the base of two triangular cupolas are attached is 54.7\u00b0 + 70.5\u00b0 approximately 125\u00b0. Therefore, the dihedral angle of a cuboctahedron between square-to-triangle is approximately 125\u00b0.\nBuckminster Fuller found that the cuboctahedron is the only polyhedron in which the distance between its center to the vertex is the same as the distance between its edges. In other words, it has the same length vectors in three-dimensional space, known as \"vector equilibrium\". The rigid struts and the flexible vertices of a cuboctahedron may also be transformed progressively into a regular icosahedron, regular octahedron, regular tetrahedron. Fuller named this the \"jitterbug transformation\".\nA cuboctahedron has the Rupert property, meaning there is a polyhedron of the same or larger size that can pass through its hole.\nSymmetry and classification.\nThe cuboctahedron is an Archimedean solid, meaning it is a highly symmetric and semi-regular polyhedron, and two or more different regular polygonal faces meet in a vertex. The cuboctahedron has two symmetries, resulting from the constructions as has mentioned above: the same symmetry as the regular octahedron or cube, the octahedral symmetry formula_7, and the same symmetry as the regular tetrahedron, tetrahedral symmetry formula_8. The polygonal faces that meet for every vertex are two equilateral triangles and two squares, and the vertex figure of a cuboctahedron is 3.4.3.4. The dual of a cuboctahedron is rhombic dodecahedron.\nRadial equilateral symmetry.\nIn a cuboctahedron, the long radius (center to vertex) is the same as the edge length; thus its long diameter (vertex to opposite vertex) is 2 edge lengths. Its center is like the apical vertex of a canonical pyramid: one edge length away from \"all\" the other vertices. (In the case of the cuboctahedron, the center is in fact the apex of 6 square and 8 triangular pyramids). This radial equilateral symmetry is a property of only a few uniform polytopes, including the two-dimensional hexagon, the three-dimensional cuboctahedron, and the four-dimensional 24-cell and 8-cell (tesseract). \"Radially equilateral\" polytopes are those that can be constructed, with their long radii, from equilateral triangles which meet at the center of the polytope, each contributing two radii and an edge. Therefore, all the interior elements which meet at the center of these polytopes have equilateral triangle inward faces, as in the dissection of the cuboctahedron into 6 square pyramids and 8 tetrahedra. \nEach of these radially equilateral polytopes also occurs as cells of a characteristic space-filling tessellation: the tiling of regular hexagons, the rectified cubic honeycomb (of alternating cuboctahedra and octahedra), the 24-cell honeycomb and the tesseractic honeycomb, respectively. Each tessellation has a dual tessellation; the cell centers in a tessellation are cell vertices in its dual tessellation. The densest known regular sphere-packing in two, three and four dimensions uses the cell centers of one of these tessellations as sphere centers.\nBecause it is radially equilateral, the cuboctahedron's center is one edge length distant from the 12 vertices.\nRelated polyhedra and honeycomb.\nThe cuboctahedron shares its skeleton with the two nonconvex uniform polyhedra, the cubohemioctahedron and octahemioctahedron. These polyhedrons are constructed from the skeleton of a cuboctahedron in which the four hexagonal planes bisect its diagonal, intersecting its interior. Adding six squares or eight equilateral triangles results in the cubohemicotahedron or octahemioctahedron, respectively.\nThe cuboctahedron 2-covers the tetrahemihexahedron, which accordingly has the same abstract vertex figure (two triangles and two squares: formula_9) and half the vertices, edges, and faces. (The actual vertex figure of the tetrahemihexahedron is formula_10, with the formula_11 factor due to the cross.)\nThe cuboctahedron can be dissected into 6 square pyramids and 8 tetrahedra meeting at a central point. This dissection is expressed in the tetrahedral-octahedral honeycomb where pairs of square pyramids are combined into octahedra.\nGraph.\nThe skeleton of a cuboctahedron may be represented as the graph, one of the Archimedean graph. It has 12 vertices and 24 edges. It is quartic graph, which is four vertices connecting each vertex.\nThe graph of a cuboctahedron may be constructed as the line graph of the cube, making it becomes the locally linear graph.\nAppearance.\nThe cuboctahedron was probably known to Plato: Heron's \"Definitiones\" quotes Archimedes as saying that Plato knew of a solid made of 8 triangles and 6 squares."}
{"id": "6281", "revid": "949717", "url": "https://en.wikipedia.org/wiki?curid=6281", "title": "Canton", "text": "Canton may refer to: "}
{"id": "6282", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=6282", "title": "Class", "text": "Class, Classes, or The Class may refer to:"}
{"id": "6283", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=6283", "title": "Critical point", "text": "Critical point may refer to:"}
{"id": "6285", "revid": "41633080", "url": "https://en.wikipedia.org/wiki?curid=6285", "title": "Cube", "text": "In geometry, a cube or regular hexahedron is a three-dimensional solid object bounded by six congruent square faces, a type of polyhedron. It has twelve congruent edges and eight vertices. It is a type of parallelepiped, with pairs of parallel opposite faces, and more specifically a rhombohedron, with congruent edges, and a rectangular cuboid, with right angles between pairs of intersecting faces and pairs of intersecting edges. It is an example of many classes of polyhedra: Platonic solid, regular polyhedron, parallelohedron, zonohedron, and plesiohedron. The dual polyhedron of a cube is the regular octahedron.\nThe cube is the three-dimensional hypercube, a family of polytopes also including the two-dimensional square and four-dimensional tesseract. A cube with unit side length is the canonical unit of volume in three-dimensional space, relative to which other solid objects are measured.\nThe cube can be represented in many ways, one of which is the graph known as the cubical graph. It can be constructed by using the Cartesian product of graphs. The cube was discovered in antiquity. It was associated with the nature of earth by Plato, the founder of Platonic solid. It was used as the part of the Solar System, proposed by Johannes Kepler. It can be derived differently to create more polyhedrons, and it has applications to construct a new polyhedron by attaching others.\nProperties.\nA cube is a special case of rectangular cuboid in which the edges are equal in length. Like other cuboids, every face of a cube has four vertices, each of which connects with three congruent lines. These edges form square faces, making the dihedral angle of a cube between every two adjacent squares being the interior angle of a square, 90\u00b0. Hence, the cube has six faces, twelve edges, and eight vertices. Because of such properties, it is categorized as one of the five Platonic solids, a polyhedron in which all the regular polygons are congruent and the same number of faces meet at each vertex.\nMeasurement and other metric properties.\nGiven a cube with edge length formula_1. The face diagonal of a cube is the diagonal of a square formula_2, and the space diagonal of a cube is a line connecting two vertices that is not in the same face, formulated as formula_3. Both formulas can be determined by using Pythagorean theorem. The surface area of a cube formula_4 is six times the area of a square: formula_5\nThe volume of a cuboid is the product of its length, width, and height. Because all the edges of a cube are equal in length, it is: formula_6\nOne special case is the unit cube, so-named for measuring a single unit of length along each edge. It follows that each face is a unit square and that the entire figure has a volume of 1 cubic unit. Prince Rupert's cube, named after Prince Rupert of the Rhine, is the largest cube that can pass through a hole cut into the unit cube, despite having sides approximately 6% longer. A polyhedron that can pass through a copy of itself of the same size or smaller is said to have the Rupert property.\nA geometric problem of doubling the cube\u2014alternatively known as the \"Delian problem\"\u2014requires the construction of a cube with a volume twice the original by using a compass and straightedge solely. Ancient mathematicians could not solve this old problem until French mathematician Pierre Wantzel in 1837 proved it was impossible.\nRelation to the spheres.\nWith edge length formula_1, the inscribed sphere of a cube is the sphere tangent to the faces of a cube at their centroids, with radius formula_8. The midsphere of a cube is the sphere tangent to the edges of a cube, with radius formula_9. The circumscribed sphere of a cube is the sphere tangent to the vertices of a cube, with radius formula_10.\nFor a cube whose circumscribed sphere has radius formula_11, and for a given point in its three-dimensional space with distances formula_12 from the cube's eight vertices, it is:\nformula_13\nSymmetry.\nThe cube has octahedral symmetry formula_14. It is composed of reflection symmetry, a symmetry by cutting into two halves by a plane. There are nine reflection symmetries: the five are cut the cube from the midpoints of its edges, and the four are cut diagonally. It is also composed of rotational symmetry, a symmetry by rotating it around the axis, from which the appearance is interchangeable. It has octahedral rotation symmetry formula_15: three axes pass through the cube's opposite faces centroid, six through the cube's opposite edges midpoints, and four through the cube's opposite vertices; each of these axes is respectively four-fold rotational symmetry (0\u00b0, 90\u00b0, 180\u00b0, and 270\u00b0), two-fold rotational symmetry (0\u00b0 and 180\u00b0), and three-fold rotational symmetry (0\u00b0, 120\u00b0, and 240\u00b0).\nThe dual polyhedron can be obtained from each of the polyhedron's vertices tangent to a plane by the process known as polar reciprocation. One property of dual polyhedrons generally is that the polyhedron and its dual share their three-dimensional symmetry point group. In this case, the dual polyhedron of a cube is the regular octahedron, and both of these polyhedron has the same symmetry, the octahedral symmetry.\nThe cube is face-transitive, meaning its two squares are alike and can be mapped by rotation and reflection. It is vertex-transitive, meaning all of its vertices are equivalent and can be mapped isometrically under its symmetry. It is also edge-transitive, meaning the same kind of faces surround each of its vertices in the same or reverse order, all two adjacent faces have the same dihedral angle. Therefore, the cube is regular polyhedron because it requires those properties.\nClassifications.\nThe cube is a special case among every cuboids. As mentioned above, the cube can be represented as the rectangular cuboid with edges equal in length and all of its faces are all squares. The cube may be considered as the parallelepiped in which all of its edges are equal edges.\nThe cube is a plesiohedron, a special kind of space-filling polyhedron that can be defined as the Voronoi cell of a symmetric Delone set. The plesiohedra include the parallelohedrons, which can be translated without rotating to fill a space\u2014called honeycomb\u2014in which each face of any of its copies is attached to a like face of another copy. There are five kinds of parallelohedra, one of which is the cuboid. Every three-dimensional parallelohedron is zonohedron, a centrally symmetric polyhedron whose faces are centrally symmetric polygons,\nConstruction.\nAn elementary way to construct a cube is using its net, an arrangement of edge-joining polygons constructing a polyhedron by connecting along the edges of those polygons. Eleven nets for the cube are shown here.\nIn analytic geometry, a cube may be constructed using the Cartesian coordinate systems. For a cube centered at the origin, with edges parallel to the axes and with an edge length of 2, the Cartesian coordinates of the vertices are formula_16. Its interior consists of all points formula_17 with formula_18 for all formula_19. A cube's surface with center formula_20 and edge length of formula_21 is the locus of all points formula_22 such that\nformula_23\nThe cube is Hanner polytope, because it can be constructed by using Cartesian product of three line segments. Its dual polyhedron, the regular octahedron, is constructed by direct sum of three line segments.\nRepresentation.\nAs a graph.\nAccording to Steinitz's theorem, the graph can be represented as the skeleton of a polyhedron; roughly speaking, a framework of a polyhedron. Such a graph has two properties. It is planar, meaning the edges of a graph are connected to every vertex without crossing other edges. It is also a 3-connected graph, meaning that, whenever a graph with more than three vertices, and two of the vertices are removed, the edges remain connected. The skeleton of a cube can be represented as the graph, and it is called the cubical graph, a Platonic graph. It has the same number of vertices and edges as the cube, twelve vertices and eight edges.\nThe cubical graph is a special case of hypercube graph or cube\u2014denoted as formula_24\u2014because it can be constructed by using the operation known as the Cartesian product of graphs. To put it in a plain, its construction involves two graphs connecting the pair of vertices with an edge to form a new graph. In the case of the cubical graph, it is the product of two formula_25; roughly speaking, it is a graph resembling a square. In other words, the cubical graph is constructed by connecting each vertex of two squares with an edge. Notationally, the cubical graph can be denoted as formula_26. As a part of the hypercube graph, it is also an example of a unit distance graph.\nLike other graphs of cuboids, the cubical graph is also classified as a prism graph.\nIn orthogonal projection.\nAn object illuminated by parallel rays of light casts a shadow on a plane perpendicular to those rays, called an orthogonal projection. A polyhedron is considered \"equiprojective\" if, for some position of the light, its orthogonal projection is a regular polygon. The cube is equiprojective because, if the light is parallel to one of the four lines joining a vertex to the opposite vertex, its projection is a regular hexagon. Conventionally, the cube is 6-equiprojective.\nAs a configuration matrix.\nThe cube can be represented as configuration matrix. A configuration matrix is a matrix in which the rows and columns correspond to the elements of a polyhedron as in the vertices, edges, and faces. The diagonal of a matrix denotes the number of each element that appears in a polyhedron, whereas the non-diagonal of a matrix denotes the number of the column's elements that occur in or at the row's element. As mentioned above, the cube has eight vertices, twelve edges, and six faces; each element in a matrix's diagonal is denoted as 8, 12, and 6. The first column of the middle row indicates that there are two vertices in (i.e., at the extremes of) each edge, denoted as 2; the middle column of the first row indicates that three edges meet at each vertex, denoted as 3. The following matrix is:\nformula_27\nAppearances.\nIn antiquity.\nThe Platonic solid is a set of polyhedrons known since antiquity. It was named after Plato in his \"Timaeus\" dialogue, who attributed these solids with nature. One of them, the cube, represented the classical element of earth because of its stability. Euclid's \"Elements\" defined the Platonic solids, including the cube, and using these solids with the problem involving to find the ratio of the circumscribed sphere's diameter to the edge length.\nFollowing its attribution with nature by Plato, Johannes Kepler in his \"Harmonices Mundi\" sketched each of the Platonic solids, one of them is a cube in which Kepler decorated a tree on it. In his \"Mysterium Cosmographicum\", Kepler also proposed the Solar System by using the Platonic solids setting into another one and separating them with six spheres resembling the six planets. The ordered solids started from the innermost to the outermost: regular octahedron, regular icosahedron, regular dodecahedron, regular tetrahedron, and cube.\nPolyhedron, honeycombs, and polytopes.\nThe cube can appear in the construction of a polyhedron, and some of its types can be derived differently in the following:\nThe honeycomb is the space-filling or tessellation in three-dimensional space, meaning it is an object in which the construction begins by attaching any polyhedrons onto their faces without leaving a gap. The cube can be represented as the cell, and examples of a honeycomb are cubic honeycomb, order-5 cubic honeycomb, order-6 cubic honeycomb, and order-7 cubic honeycomb. The cube can be constructed with six square pyramids, tiling space by attaching their apices.\nPolycube is a polyhedron in which the faces of many cubes are attached. Analogously, it can be interpreted as the polyominoes in three-dimensional space. When four cubes are stacked vertically, and the other four are attached to the second-from-top cube of the stack, the resulting polycube is Dali cross, after Salvador Dali. The Dali cross is a tile space polyhedron, which can be represented as the net of a tesseract. A tesseract is a cube analogous' four-dimensional space bounded by twenty-four squares, and it is bounded by the eight cubes known as its cells."}
{"id": "6286", "revid": "29489308", "url": "https://en.wikipedia.org/wiki?curid=6286", "title": "Commuter rail", "text": "Commuter rail or suburban rail is a passenger rail transport service that primarily operates within a metropolitan area, connecting commuters to a central city from adjacent suburbs or commuter towns. Commuter rail systems can use locomotive-hauled trains or multiple units, using electric or diesel propulsion. Distance charges or zone pricing may be used.\nThe term can refer to systems with a wide variety of different features and service frequencies, but is often used in contrast to rapid transit or light rail.\nSome services share similarities with both commuter rail and high-frequency rapid transit; examples include German S-Bahn in some cities, the R\u00e9seau Express R\u00e9gional (RER) in Paris, the S Lines in Milan, many Japanese commuter systems, the East Rail line in Hong Kong, and some Australasian suburban networks, such as Sydney Trains. Many commuter rail systems share tracks with other passenger services and freight.\nIn North America, commuter rail sometimes refers only to systems that primarily operate during rush hour and offer little to no service for the rest of the day, with regional rail being used to refer to systems that offer all-day service.\nCharacteristics.\nMost commuter (or suburban) trains are built to main line rail standards, differing from light rail or rapid transit (metro rail) systems by:\nTrain schedule.\nCompared to rapid transit (or metro rail), commuter/suburban rail often has lower frequency, following a schedule rather than fixed intervals, and fewer stations spaced further apart. They primarily serve lower density suburban areas (non inner-city), generally only having one or two stops in a city's central business district, and often share right-of-way with intercity or freight trains. Some services operate only during peak hours and others use fewer departures during off peak hours and weekends. Average speeds are high, often 50\u00a0km/h (30\u00a0mph) or higher. These higher speeds better serve the longer distances involved. Some services include express services which skip some stations in order to run faster and separate longer distance riders from short-distance ones. \nThe general range of commuter trains' travel distance varies between 15 and 200\u00a0km (10 and 125 miles), but longer distances can be covered when the trains run between two or several cities (e.g. S-Bahn in the Ruhr area of Germany). Distances between stations may vary, but are usually much longer than those of urban rail systems. In city centres the train either has a terminal station or passes through the city centre with notably fewer station stops than those of urban rail systems. Toilets are often available on-board trains and in stations.\nTrack.\nTheir ability to coexist with freight or intercity services in the same right-of-way can drastically reduce system construction costs. However, frequently they are built with dedicated tracks within that right-of-way to prevent delays, especially where service densities have converged in the inner parts of the network.\nMost such trains run on the local standard gauge track. Some systems may run on a narrower or broader gauge. Examples of narrow gauge systems are found in Japan, Indonesia, Malaysia, Thailand, Taiwan, Switzerland, in the Brisbane (Queensland Rail's City network) and Perth (Transperth) systems in Australia, in some systems in Sweden, and on the in Italy. Some countries and regions, including Finland, India, Pakistan, Russia, Brazil and Sri Lanka, as well as San Francisco (BART) in the US and Melbourne and Adelaide in Australia, use broad gauge track.\nDistinction between other modes of rail.\nMetro.\nMetro rail and rapid transit usually cover smaller inner-urban areas within of city centers, with shorter stop spacing, use rolling stocks with larger standing spaces, lower top speed and higher acceleration, designed for short-distance travel. They also run more frequently, to a headway rather than a published timetable and use dedicated tracks (underground or elevated), whereas commuter rail often shares tracks, technology and the legal framework within mainline railway systems, and uses rolling stocks with more seating and higher speed for comfort on longer city-suburban journeys. \nHowever, the classification as a metro or rapid rail can be difficult as both may typically cover a metropolitan area exclusively, run on separate tracks in the centre, and often feature purpose-built rolling stock. The fact that the terminology is not standardised across countries (even across English-speaking countries) further complicates matters. This distinction is most easily made when there are two (or more) systems such as New York's subway and the LIRR and Metro-North Railroad, Paris' M\u00e9tro and RER along with Transilien, Washington D.C.'s Metro along with its MARC and VRE, London's tube lines of the Underground and the Overground, Elizabeth line, Thameslink along with other commuter rail operators, Madrid's Metro and Cercan\u00edas, Barcelona's Metro and Rodalies, and Tokyo's subway and the JR lines along with various privately owned and operated commuter rail systems.\nRegional rail.\nRegional rail usually provides rail services between towns and cities, rather than purely linking major population hubs in the way inter-city rail does. Regional rail operates outside major cities. Unlike Inter-city, it stops at most or all stations between cities. It provides a service between smaller communities along the line that are often byproducts of ribbon developments, and also connects with long-distance services at interchange stations located at junctions, terminals, or larger towns along the line. Alternative names are \"local train\" or \"stopping train\". Examples include the former BR's Regional Railways, France's TER (\"Transport express r\u00e9gional\"), Germany's Regionalexpress and Regionalbahn, and South Korea's Tonggeun and Mugunghwa-ho services.\nInter-city rail.\nIn some European countries, the distinction between commuter trains and long-distance/intercity trains is subtle, due to the relatively short distances involved. For example, so-called \"intercity\" trains in Belgium and the Netherlands carry many commuters, while their equipment, range, and speeds are similar to those of commuter trains in some larger countries. \nThe United Kingdom has a privatised rail system, with different routes and services covered by different private operators. The distinction between commuter and intercity rail is not as clear as it was before privatisation (when InterCity existed as a brand of its own), but usually it is still possible to tell them apart. Some operators, for example Thameslink, focus solely on commuter services. Others, such as Avanti West Coast and LNER, run solely intercity services. Others still, such as GWR and EMR, run a mixture of commuter, regional and intercity services. Some of these operators use different branding for different types of service (for example EMR brands its trains as either \"InterCity\", \"Connect\" for London commuter services, and \"Regional\") but even for those operators that do not, the type of train, amenities offered, and stopping pattern, usually tell the services apart.\nRussian commuter trains, on the other hand, frequently cover areas larger than Belgium itself, although these are still short distances by Russian standards. They have a different ticketing system from long-distance trains, and in major cities they often operate from a separate section of the train station.\nSome consider \"inter-city\" service to be that which operates as an express service between two main city stations, bypassing intermediate stations. However, this term is used in Australia (Sydney for example) to describe the regional trains operating beyond the boundaries of the suburban services, even though some of these \"inter-city\" services stop all stations similar to German regional services. In this regard, the German service delineations and naming conventions are clearer and better used for academic purposes.\nHigh-speed rail.\nSometimes high-speed rail can serve daily use of commuters. The Japanese Shinkansen high speed rail system is heavily used by commuters in the Greater Tokyo Area, who commute between by Shinkansen. To meet the demand of commuters, JR sells commuter discount passes. Before 2021, they operated 16-car bilevel E4 Series Shinkansen trains at rush hour, providing a capacity of 1,600 seats. Several lines in China, such as the Beijing\u2013Tianjin Intercity Railway and the Shanghai\u2013Nanjing High-Speed Railway, serve a similar role with many more under construction or planned.\nIn South Korea, some sections of the high-speed rail network are also heavily used by commuters, such as the section between Gwangmyeong Station and Seoul Station on the KTX network (Gyeongbu HSR Line), or the section between Dongtan Station and Suseo station on the SRT Line. \nThe high-speed services linking Zurich, Bern and Basel in Switzerland () have brought the Central Business Districts (CBDs) of these three cities within 1 hour of each other. This has resulted in unexpectedly high demand for new commuter trips between the three cities and a corresponding increase in suburban rail passengers accessing the high-speed services at the main city-centre stations (). The Regional-Express commuter service between Munich and Nuremberg in Germany runs at on the Nuremberg\u2013Ingolstadt high-speed railway.\nThe regional trains Stockholm\u2013Uppsala, Stockholm\u2013V\u00e4ster\u00e5s, Stockholm\u2013Eskilstuna and Gothenburg\u2013Trollh\u00e4ttan in Sweden reach and have many daily commuters.\nIn Great Britain, the HS1 domestic services between London and Ashford runs at a top speed of 225 km/h, and in peak hours the trains can be full with commuters standing. \nThe Athens Suburban Railway in Greece consists of five lines, 4 of which are electrified. The Kiato\u2013Piraeus line and the Aigio\u2013Airport lines reach speeds of up to . The Athens\u2013Chalcis line is also expected to attain speeds of up to upon upgrading of the SKA\u2013Oinoi railway sector. These lines also have many daily commuters, with the number expected to rise even higher upon full completion of the Acharnes Railway Center.\nEski\u015fehir-Ankara and Konya-Ankara high speed train routes serve as high speed commuter trains in Turkey.\nTrain types.\nCommuter/suburban trains are usually optimized for maximum passenger volume, in most cases without sacrificing too much comfort and luggage space, though they seldom have all the amenities of long-distance trains. Cars may be single- or double-level, and aim to provide seating for all. Compared to intercity trains, they have less space, fewer amenities and limited baggage areas.\nMultiple unit type.\nCommuter rail trains are usually composed of multiple units, which are self-propelled, bidirectional, articulated passenger rail cars with driving motors on each (or every other) bogie. Depending on local circumstances and tradition they may be powered either by diesel engines located below the passenger compartment (diesel multiple units) or by electricity picked up from third rails or overhead lines (electric multiple units). Multiple units are almost invariably equipped with control cabs at both ends, which is why such units are so frequently used to provide commuter services, due to the associated short turn-around time.\nLocomotive hauled services.\nLocomotive hauled services are used in some countries or locations. This is often a case of asset sweating, by using a single large combined fleet for intercity and regional services. Loco hauled services are usually run in push-pull formation, that is, the train can run with the locomotive at the \"front\" or \"rear\" of the train (pushing or pulling). Trains are often equipped with a control cab at the other end of the train from the locomotive, allowing the train operator to operate the train from either end. The motive power for locomotive-hauled commuter trains may be either electric or diesel\u2013electric, although some countries, such as Germany and some of the former Soviet-bloc countries, also use diesel\u2013hydraulic locomotives.\nSeat plans.\nIn the US and some other countries, a three-and-two seat plan is used. Middle seats on these trains are often less popular because passengers feel crowded and uncomfortable.\nIn Japan, South Korea and Indonesia, longitudinal (sideways window-lining) seating is widely used in many commuter rail trains to increase capacity in rush hours. Carriages are usually not organized to increase seating capacity (although in some trains at least one carriage would feature more doors to facilitate easier boarding and alighting and bench seats so that they can be folded up during rush hour to provide more standing room) even in the case of commuting longer than 50\u00a0km and commuters in the Greater Tokyo Area, Seoul metropolitan area, and Jabodetabek area have to stand in the train for more than an hour.\nCommuter rail systems around the world.\nAfrica.\nCurrently there are not many examples of commuter rail in Africa. Metrorail operates in the major cities of South Africa, and there are some commuter rail services in Algeria, Botswana, Kenya, Morocco, Egypt and Tunisia.\nIn Algeria, SNTF operates commuter rail lines between the capital Algiers and its southern and eastern suburbs. They also serve to connect Algiers' main universities to each other. The Dar es Salaam commuter rail offers intracity services in Dar es Salaam, Tanzania. In Botswana, the (Botswana Railways) \"BR Express\" has a commuter train between Lobatse and Gaborone.\nAsia.\nEast Asia.\nIn Japan, commuter rail systems have extensive network and frequent service and are heavily used. In many cases, Japanese commuter rail is operationally more like a typical metro system (frequent trains, an emphasis on standing passengers, short station spacings) than it is like commuter rail in other countries. Japanese commuter rail commonly interline with city center subway lines, with commuter rail trains continuing into the subway network, and then out onto different commuter rail systems on the other side of the city. Many Japanese commuter systems operate various stopping patterns to reduce the travel time to distant locations, often using station passing loops instead of dedicated express tracks. It is notable that the larger Japanese commuter rail systems are owned and operated by for-profit private railway companies, without public subsidy.\nEast Japan Railway Company operates a large suburban train network in Tokyo with various lines connecting the suburban areas to the city center. While the Yamanote Line, Keihin Tohoku Line, Ch\u016b\u014d\u2013S\u014dbu Line services arguably are more akin to rapid transit with frequent stops, simple stopping patterns (relative to other JR East lines) no branching services and largely serving the inner suburbs; other services along the Ch\u016b\u014d Rapid Line, S\u014dbu Rapid Line/Yokosuka Line, Ueno\u2013Tokyo Line, Sh\u014dnan\u2013Shinjuku Line etc. are mid-distance services from suburban lines in the outer reaches of Greater Tokyo through operating into these lines to form a high frequency corridor though central Tokyo.\nOther commuter rail routes in Japan include:\nCommuter rail systems have been inaugurated in several cities in China such as Beijing, Shanghai, Zhengzhou, Wuhan, Changsha and the Pearl River Delta. With plans for large systems in northeastern Zhejiang, Jingjinji, and Yangtze River Delta areas. The level of service varies considerably from line to line ranging high to near high speeds. More developed and established lines such as the Guangshen Railway have more frequent metro-like service. \nThe two MTR lines which are owned and formerly operated by the Kowloon-Canton Railway Corporation (East Rail line and Tuen Ma line which is integrated from the former West Rail line and Ma On Shan line in 2021), then the \"KCR\"), and MTR's own Tung Chung line connect the new towns in New Territories and the city centre Kowloon together with frequent intervals, and some New Territories-bound trains terminate at intermediate stations, providing more frequent services in Kowloon and the towns closer to Kowloon. They use rolling stocks with a faster maximum speed and have longer stop spacing compared to other lines which only run in the inner urban area, but in order to maximise capacity and throughput, these rolling stocks have longitudinal seatings, 5 pairs of doors in each carriage with large standing spaces like the urban lines, and run as frequent as well. Most of the sections of these four lines are overground and some sections of the East Rail Line share tracks with intercity trains to mainland China. The three KCR lines are integrated into the MTR network since 2008 and most passengers do not need to exit and re-enter the system through separate fare gates and purchase separate tickets to transfer between such lines and the rest of the network (the exceptions are between the Tuen Ma line's East Tsim Sha Tsui station and the Tsuen Wan line's Tsim Sha Tsui station.\nIn Taiwan, the Western line in the Taipei-Taoyuan Metropolitan Area, Taichung Metropolitan Area and Tainan-Kaohsiung Metropolitan Area as well as the Neiwan-Liujia line in the Hsinchu Area are considered commuter rail.\nIn South Korea, the Seoul Metropolitan Subway includes a total of 22 lines, and some of its lines are suburban lines. This is especially the case for lines operated by Korail, such as the Gyeongui-Jungang Line, the Gyeongchun Line, the Suin-Bundang Line, or the Gyeonggang Line. Even some lines not operated by Korail, such as the AREX Line, the Seohae Line or the Shinbundang Line mostly function as commuter rail. Lastly, even for the \"numbered lines\" (1\u20139) of the Seoul Metropolitan Subway which mostly travel in the dense parts of Seoul, some track sections extend far outside of the city, and operate large sections at ground level, such as on the Line 1, Line 3 and Line 4. In Busan, the Donghae Line, while part of the Busan Metro system, mostly functions as a commuter rail line.\nSoutheast Asia.\nIn Indonesia, the KRL Commuterline is the largest commuter rail system in the country, serving the Greater Jakarta. It connects the Jakarta city center with surrounding cities and sub-urbans in Banten and West Java provinces, including Depok, Bogor, Tangerang, Serpong, Rangkasbitung, Bekasi and Cikarang. In July 2015, KRL Commuterline served more than 850,000 passengers per day, which is almost triple of the 2011 figures, but still less than 3.5% of all Jabodetabek commutes. Other commuter rail systems in Indonesia include the Metro Surabaya Commuter Line, Commuter Line Bandung, KAI Commuter Yogyakarta\u2013Solo Line, Kedung Sepur, and the Sri Lelawangsa.\nIn the Philippines, the Philippine National Railways has two commuter rail systems currently operational; the PNR Metro Commuter Line in the Greater Manila Area and the PNR Bicol Commuter in the Bicol Region. A new commuter rail line in Metro Manila, the North\u2013South Commuter Railway, is currently under construction. Its North section is set to be partially opened by 2021.\nIn Malaysia, there are two commuter services operated by Keretapi Tanah Melayu. They are the KTM Komuter that serves Kuala Lumpur and the surrounding Klang Valley area, and the KTM Komuter Northern Sector that serves Greater Penang, Perak, Kedah and Perlis in the northern region of Peninsular Malaysia.\nIn Thailand, the Greater Bangkok Commuter rail and the Airport Rail Link serve the Bangkok Metropolitan Region. The SRT Red Lines, a new commuter line in Bangkok, started construction in 2009. It opened in 2021.\nAnother commuter rail system in Southeast Asia is the Yangon Circular Railway in Myanmar.\nSouth Asia.\nIn India, commuter rail systems are present in major cities and form an important part of people's daily lives. Mumbai Suburban Railway, the oldest suburban rail system in Asia, carries more than 7.24 million commuters on a daily basis which constitutes more than half of the total daily passenger capacity of the Indian Railways itself. Kolkata Suburban Railway, one of the largest suburban railway networks in the world, consists of more than 450 stations and carries more than 3.5 million commuters per day. The Chennai Suburban Railway along with the Chennai MRTS, also covers over 300 stations and carries more than 2.5 million people daily to different areas in Chennai and its surroundings. Other commuter railways in India include the Hyderabad MMTS, Delhi Suburban Railway, Pune Suburban Railway and Lucknow-Kanpur Suburban Railway.\nIn 2020, Government of India approved Bengaluru Suburban Railway to connect Bengaluru and its suburbs. It will be unique and first of its kind in India as it will have metro like facilities and rolling stock.\nIn Bangladesh, there is one suburban rail called the Chittagong Circular Railway. Another suburban railway called the Dhaka Circular Railway is currently proposed.\nKarachi in Pakistan has a circular railway since 1969.\nWest Asia.\nTehran Metro currently operates the Line 5 commuter line between Tehran and Karaj.\nTurkey has lines connecting Ba\u015fkentray, \u0130ZBAN, Marmaray and Gaziray.\nEurope.\nMajor metropolitan areas in most European countries are usually served by extensive commuter/suburban rail systems. Well-known examples include BG Voz in Belgrade (Serbia), S-Bahn in Germany, Austria and German-speaking areas of Switzerland, Proastiakos in Greece, RER in France and Belgium, Servizio ferroviario suburbano in Italy, Cercan\u00edas and Rodalies (Catalonia) in Spain, CP Urban Services in Portugal, Esko in Prague and Ostrava (Czech Republic), H\u00c9V in Budapest (Hungary) and DART in Dublin (Ireland).\nWestern Europe.\nLondon has multiple commuter rail routes:\nThe Merseyrail network in Liverpool consists of two commuter rail routes powered by third rail, both of which branch out at one end. At the other, the Northern line continues out of the city centre to a mainline rail interchange, while the Wirral line has a city-centre loop.\nBirmingham has four suburban routes which operate out of Birmingham New Street &amp; Birmingham Moor Street stations, one of which is operated using diesel trains.\nThe Tyneside Electrics system in Newcastle upon Tyne existed from 1904 to 1967 using DC third rail. British Rail did not have the budget to maintain the ageing electrification system. The Riverside Branch was closed, while the remaining lines were de-electrified. 13 years later, they were re-electrified using DC overhead wires, and now form the Tyne &amp; Wear Metro Yellow Line.\nMany of the rail services around Glasgow are branded as Strathclyde Partnership for Transport. The network includes most electrified Scottish rail routes.\nThe West Yorkshire Passenger Transport Executive run eleven services which feed into Leeds, connecting the city with commuter areas and neighbouring urban centres in the West Yorkshire Built-up Area.\nMetroWest is a proposed network in Bristol, northern Somerset &amp; southern Gloucestershire. The four-tracking of the line between Bristol Temple Meads and Bristol Parkway stations will enable local rail services to be separated from long-distance trains.\nThe R\u00e9seau express r\u00e9gional d'\u00cele-de-France (RER) is a commuter rail network in the agglomeration of Paris. In the centre the RER has high frequency underground corridors where several suburban branches feed similar to a rapid transit system.\nCommuter rail systems in German-speaking regions are called S-Bahn. While in some major cities S-Bahn services run on separate lines exclusively other systems use the existing regional rail tracks.\nIn Italy fifteen cities have commuter rail systems:\nRandstadspoor is a network of Sprinter train services in and around the city of Utrecht in the Netherlands. For the realisation of this network, new stations were opened. Separate tracks have been built for these trains, so they can call frequently without disturbing high-frequent Intercity services parallel to these routes. Similar systems are planned for The Hague and Rotterdam.\nNorthern Europe.\nIn Sweden, electrified commuter rail systems known as \"Pendelt\u00e5g\" are present in the cities of Stockholm and Gothenburg. The Stockholm commuter rail system, which began in 1968, shares railway tracks with inter-city trains and freight trains, but for the most part runs on its own dedicated tracks. It is primarily used to transport passengers from nearby towns and other suburban areas into the city centre, not for transportation inside the city centre. The Gothenburg commuter rail system, which began in 1960, is similar to the Stockholm system, but does fully share tracks with long-distance trains.\nIn Norway, the Oslo commuter rail system is from 2022 more limited but the remaining commuter lines go on tracks mostly not much used by other trains. From 2022 several lines with hourly frequency and travel times to endpoints of over one hour are redefined as regional trains. Before 2022 Oslo had the largest commuter rail system in the Nordic countries in terms of line lengths and number of stations. Also Bergen, Stavanger and Trondheim have commuter rail systems. These have only one or two lines each and they share tracks with other trains.\nIn Finland, the Helsinki commuter rail network runs on dedicated tracks from Helsinki Central railway station to Lepp\u00e4vaara and Kerava. The Ring Rail Line serves Helsinki Airport and northern suburbs of Vantaa and is exclusively used by the commuter rail network. On 15 December 2019, the Tampere region got its own commuter rail service, with trains running from Tampere to Nokia, Lemp\u00e4\u00e4l\u00e4 and Orivesi.\nSouthern Europe.\nIn Spain, \"Cercan\u00edas\" networks exist in Madrid, Sevilla, Murcia/Alicante, San Sebasti\u00e1n, C\u00e1diz, Valencia, Asturias, Santander, Zaragoza, Bilbao and M\u00e1laga. All these systems include underground sections in the city centre. There is also a network of narrow-gauge commuter systems in North Spain and Murcia.\nCercan\u00edas Madrid is one of the most important train services in the country, more than 900,000 passengers move in the system. It has underground stations in Madrid like Recoletos, Sol or Nuevos Ministerios and in the metropolitan area in cities like Parla or Getafe.\nIn the autonomous community of Catalonia, and unlike the rest of Spain, the commuter service is not managed by Renfe Operadora. Since 2010, the Government of Catalonia has managed all the regular commuter services with the \"transfer of \"Rodalies\"\". There are two companies that manage the Catalan commuter network:\nThe Government of Catalonia will assume full control of the current R12 regional line in 2024 and it will be owned by the FGC. It will eliminate the current line and replace it with the new commuter lines RL3 and RL4, towards Cervera and Manresa from Lleida respectively.\nIn Italy there are several commuter rail networks:\nEastern Europe.\nIn Poland, commuter rail systems exist in Tricity, Warsaw, Krak\u00f3w (SKA) and Katowice (SKR). There is also a similar system planned in Wroc\u0142aw and Szczecin. The terms used are \"Szybka Kolej Miejska\" (fast urban rail) and \"kolej aglomeracyjna\" (agglomeration rail). These systems are:\nThe Proastiakos (; \"suburban\") is Greece's suburban railway (commuter rail) services, which are run by TrainOSE, on infrastructure owned by the Hellenic Railways Organisation (OSE). There are three Proastiakos networks, servicing the country's three largest cities: Athens, Thessaloniki and Patras. In particular, the Athenian network is undergoing modifications to completely separate it from mainline traffic, by re-routing the tracks via a tunnel underneath the city center. A similar project is planned for the Patras network, whereas a new line is due to be constructed for the Thessalonian network.\nIn Romania, the first commuter trains were introduced in December 2019. They operate between Bucharest and Funduea or Buftea.\nBG Voz is an urban rail system that serves Belgrade. It currently has only two routes, with plans for further expansion. Between the early 1990s and mid-2010s, there was another system, known as Beovoz, that was used to provide mass-transit service within the Belgrade metropolitan area, as well as to nearby towns, similarly to RER in Paris. Beovoz had more lines and far more stops than the current system. However, it was abandoned in favor of more accurate BG Voz, mostly due to inefficiency. While current services rely mostly on the existing infrastructure, any further development means furthering capacities (railways expansion and new trains). Plans for further extension of system include another two lines, one of which should reach Belgrade Nikola Tesla Airport.\nIn Russia, Ukraine and some other countries of the former Soviet Union, electrical multiple unit passenger suburban trains called Elektrichka are widespread. The first such system in Russia is the Oranienbaum Electric Line in St. Petersburg. In Moscow the Beskudnikovskaya railway branch existed between the 1940s and 1980s. The trains that shuttled along it did not go to the main lines, so it was a city transport. Today there are the Moscow Central Circle and the Moscow Central Diameters.\nIn Turkey, Marmaray line stations from Sirkeci to Halkal\u0131 are located at the European side.\nAmericas.\nNorth America.\nIn the United States, Canada, Costa Rica, El Salvador and Mexico regional passenger rail services are provided by governmental or quasi-governmental agencies, with the busiest and most expansive rail networks located in the Northeastern US, California, and Eastern Canada. Most North American commuter railways utilize diesel locomotive propulsion, with the exception of services in New York City, Philadelphia, Chicago, Denver, San Francisco, and Mexico City; New York's commuter rail lines use a combination of third rail and overhead wire power generation, while Chicago only has two out of twelve services that are electrified. Many newer and proposed systems in Canada and the United States are often are geared to serving peak-hour commutes as opposed to the all-day systems of Europe, East Asia, and Australia.\nUnited States.\nEight commuter rail systems in the United States carried over ten million trips each in 2018, those being in descending order:\nOther commuter rail systems in the United States (not in ridership order) are:\nSouth America.\nExamples include an commuter system in the Buenos Aires metropolitan area, the long Supervia in Rio de Janeiro, the Metrotr\u00e9n in Santiago, Chile, and the Valpara\u00edso Metro in Valpara\u00edso, Chile.\nAnother example is Companhia Paulista de Trens Metropolitanos (CPTM) in Greater S\u00e3o Paulo, Brazil. CPTM has 94 stations with seven lines, numbered starting on 7 (the lines 1 to 6 and the line 15 belong to the S\u00e3o Paulo Metro), with a total length of . Trains operates at high frequencies on tracks used exclusively for commuter traffic. In Rio de Janeiro SuperVia provides electrified commuter rail services.\nOceania.\nThe five major cities in Australia have suburban railway systems in their metropolitan areas. These networks have frequent services, with frequencies varying from every 10 to every 30 minutes on most suburban lines, and up to 3\u20135 minutes in peak on bundled underground lines in the city centres of Sydney, Brisbane, Perth and Melbourne. The networks in each state developed from mainline railways and have never been completely operationally separate from long distance and freight traffic, unlike metro systems. The suburban networks are almost completely electrified.\nThe main suburban rail networks in Australia are:\nNew Zealand has two frequent suburban rail services comparable to those in Australia: the Auckland rail network is operated by Auckland One Rail and the Wellington rail network is operated by Transdev Wellington.\nHybrid systems.\nHybrid urban-suburban rail systems exhibiting characteristics of both rapid transit and commuter rail serving a metropolitan region are common in German-speaking countries, where they are known as S-Bahn. Other examples include: Lazio regional railways in Rome, the RER in France and the Elizabeth line, London Underground Metropolitan line, London Overground and Merseyrail in the UK. Comparable systems can be found in Australia such as Sydney Trains and Metro Trains Melbourne, and in Japan with many urban and suburban lines operated by JR East/West and third-party companies running at metro-style frequencies. In contrast, comparable systems of this type are generally rare in the United States and Canada, where peak hour frequencies are more common. \nIn Asia, the construction of higher speed urban-suburban rail links has gained traction in various countries, such as in India, with the Delhi RRTS, in China, with the Pearl River Delta Metropolitan Region intercity railway, and in South Korea, with the Great Train eXpress system. These systems usually run on dedicated elevated or underground tracks for most of their route and have features comparable to Higher-speed rail."}
{"id": "6287", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=6287", "title": "List of city listings by country", "text": ""}
{"id": "6288", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=6288", "title": "Cambridgeshire", "text": "Cambridgeshire (abbreviated Cambs.) is a ceremonial county in the East of England and East Anglia. It is bordered by Lincolnshire to the north, Norfolk to the north-east, Suffolk to the east, Essex and Hertfordshire to the south, Northamptonshire to the west, and Bedfordshire to the south-west. The largest settlement is the city of Peterborough, and the city of Cambridge is the county town.\nThe county has an area of and had an estimated population of 906,814 in 2022. Peterborough, in the north-west, and Cambridge, in the south, are by far the largest settlements. The remainder of the county is rural, and contains the city of Ely in the east, Wisbech in the north-east, and St Neots and Huntingdon in the west. For local government purposes Cambridgeshire comprises a non-metropolitan county, with five districts, and the unitary authority area of Peterborough; their local authorities collaborate through Cambridgeshire and Peterborough Combined Authority. The county did not historically include Huntingdonshire or the Soke of Peterborough, which was part of Northamptonshire.\nThe north and east of the county are dominated by the Fens, an extremely flat, drained marsh maintained by drainage ditches and dykes; Holme Fen is the UK's lowest physical point, at 2.75\u00a0m (9\u00a0ft) below sea level. The flatness of the landscape makes the few areas of higher ground, such as that Ely is built on, very conspicuous. The landscape in the south and west is gently undulating. Cambridgeshire's principal rivers are the Nene, which flows through the north of the county and is canalised east of Peterborough; the Great Ouse, which flows from west to east past Huntingdon and Ely; and the Cam, a tributary of the Great Ouse which flows through Cambridge.\nHistory.\nCambridgeshire is noted as the site of Flag Fen in Fengate, one of the earliest-known Neolithic permanent settlements in the United Kingdom, compared in importance to Balbridie in Aberdeen, Scotland. Must Farm quarry, at Whittlesey, has been described as \"Britain's Pompeii due to its relatively good condition, including the 'best-preserved Bronze Age dwellings ever found in the UK'\". A great quantity of archaeological finds from the Stone Age, the Bronze Age, and the Iron Age were made in East Cambridgeshire. Most items were found in Isleham.\nThe area was settled by the Anglo-Saxons starting in the fifth century. Genetic testing on seven skeletons found in Anglo-Saxon era graves in Hinxton and Oakington found that five were either migrants or descended from migrants from the continent, one was a native Briton, and one had both continental and native ancestry, suggesting intermarriage.\nCambridgeshire was recorded in the \"Domesday Book\" as \"Grantbridgeshire\" (or rather \"Grentebrigescire\") (related to the river Granta). Covering a large part of East Anglia, Cambridgeshire today is the result of several local government unifications. In 1888 when county councils were introduced, separate councils were set up, following the traditional division of Cambridgeshire, for\nIn 1965, these two administrative counties were merged to form Cambridgeshire and the Isle of Ely.\nUnder the Local Government Act 1972 this merged with the county to the west, Huntingdon and Peterborough, which had been formed in 1965, by the merger of Huntingdonshire with the Soke of Peterborough (the latter previously a part of Northamptonshire with its own county council). The resulting county was called simply Cambridgeshire.\nSince 1998, the City of Peterborough has been separately administered as a unitary authority area. It is associated with Cambridgeshire for ceremonial purposes such as Lieutenancy and joint functions such as policing and the fire service.\nIn 2002, the conservation charity Plantlife unofficially designated Cambridgeshire's county flower as the Pasqueflower.\nThe Cambridgeshire Regiment (nicknamed the Fen Tigers), the county-based army unit, fought in the Boer War in South Africa, the First World War and Second World War.\nDue to the county's flat terrain and proximity to the continent, during the Second World War the military built many airfields here for RAF Bomber Command, RAF Fighter Command, and the allies USAAF. In recognition of this collaboration, the Cambridge American Cemetery and Memorial is located in Madingley. It is the only WWII burial ground in England for American servicemen who died during that event.\nMost English counties have nicknames for their people, such as a \"Tyke\" from Yorkshire and a \"Yellowbelly\" from Lincolnshire. The historical nicknames for people from Cambridgeshire are \"Cambridgeshire Camel\" or \"Cambridgeshire Crane\", the latter referring to the wildfowl that were once abundant in the Fens. The term \"Fen Tigers\" is sometimes used to describe the people who live and work in the Fens.\nOriginal historical documents relating to Cambridgeshire are held by Cambridgeshire Archives. Cambridgeshire County Council Libraries maintains several Local Studies collections of printed and published materials, significantly at the Cambridgeshire Collection held in the Cambridge Central Library.\nFlag.\nCambridgeshire's county flag was made official on 1 February 2015, after the design was selected as an entry from a design competition that ran during 2014. The design features three golden crowns, two on the top, one on the bottom that are separated by two wavy lines in the middle. The crowns are meant to represent East Anglia, and the two lines represent the River Cam and are in the Cambridge University's colours.\nGeography.\nLarge areas of the county are extremely low-lying and Holme Fen is notable for being the UK's lowest physical point at 2.75\u00a0m (9\u00a0ft) below sea level. The highest point of the modern administrative county is in the village of Great Chishill at 146\u00a0m (480\u00a0ft) above sea level. However, this parish was historically a part of Essex, having been moved to Cambridgeshire in boundary changes in 1895. The historic county top is close to the village of Castle Camps where a point on the disused RAF airfield reaches a height of above sea level (grid reference TL 63282 41881).\nOther prominent hills are Little Trees Hill and Wandlebury Hill (both at ) in the Gog Magog Hills, Rivey Hill above Linton, Rowley's Hill and the Madingley Hills.\nWicken Fen is a biological Site of Special Scientific Interest west of Wicken. A large part of it is owned and managed by the National Trust.\nThe Cambridge Green Belt around the city of Cambridge extends to places such as Waterbeach, Lode, Duxford, Little &amp; Great Abington and other communities a few miles away in nearby districts, to afford a protection from the conurbation. It was first drawn up in the 1950s.\nPolitics.\nCambridgeshire County Council is controlled by an alliance of the Liberal Democrats, the Labour Party and independent groups, while Peterborough City Council is currently controlled by a Conservative Party minority administration.\nThe county contains eight Parliamentary constituencies:\nEconomy.\nThis is a chart of trend of regional gross value added of Cambridgeshire at current basic prices published (pp.\u00a0240\u2013253) by \"Office for National Statistics\" with figures in millions of British Pounds Sterling.\nAWG plc is based in Huntingdon. The RAF has several stations in the Huntingdon and St Ives area. RAF Alconbury, three miles north of Huntingdon, is being reorganised after a period of obsolescence following the departure of the USAF, to be the focus of RAF/USAFE intelligence operations, with activities at Upwood and Molesworth being transferred there. Most of Cambridgeshire is agricultural. Close to Cambridge is the so-called Silicon Fen area of high-technology (electronics, computing and biotechnology) companies. ARM Limited is based in Cherry Hinton. The inland Port of Wisbech on the River Nene is the county's only remaining port.\nEducation.\nPrimary and secondary.\nCambridgeshire has a comprehensive education system with over 240 state schools, not including sixth form colleges. The independent sector includes King's Ely and Wisbech Grammar School, founded in 970 and 1379 respectively, they are two of the oldest schools in the country.\nSome of the secondary schools act as Village Colleges, institutions unique to Cambridgeshire. For example, Comberton Village College.\nTertiary.\nCambridgeshire is home to a number of institutes of higher education:\nIn addition, Cambridge Regional College and Huntingdonshire Regional College both offer a limited range of higher education courses in conjunction with partner universities.\nSettlements.\nThese are the settlements in Cambridgeshire with a town charter, city status or a population over 5,000; for a complete list of settlements see list of places in Cambridgeshire.\nSee the List of Cambridgeshire settlements by population page for more detail.\nThe town of Newmarket is surrounded on three sides by Cambridgeshire, being connected by a narrow strip of land to the rest of Suffolk.\nCambridgeshire has seen 32,869 dwellings created from 2002 to 2013 and there are a further 35,360 planned new dwellings between 2016 and 2023.\nCollyweston Slate in Regional Architecture.\nCollyweston slate has been a hallmark of traditional roofing in the local region encompassing Cambridgeshire, Northamptonshire, Lincolnshire (specifically in and around Stamford), and the county of Rutland. \nThis distinctive material adorns many historic cottages, churches and buildings, defining the architectural character of many of the area's villages, hamlets, and market towns. The roof of King's College Cambridge was constructed (and later re-constructed) with Collyweston slate.\nClimate.\nCambridgeshire has a maritime temperate climate which is broadly similar to the rest of the United Kingdom, though it is drier than the UK average due to its low altitude and easterly location, the prevailing southwesterly winds having already deposited moisture on higher ground further west. Average winter temperatures are cooler than the English average, due to Cambridgeshire's inland location and relative nearness to continental Europe, which results in the moderating maritime influence being less strong. Snowfall is slightly more common than in western areas, due to the relative winter coolness and easterly winds bringing occasional snow from the North Sea. In summer temperatures are average or slightly above, due to less cloud cover. It reaches on around ten days each year, and is comparable to parts of Kent and East Anglia.\nCulture.\nSports.\nVarious forms of football have been popular in Cambridgeshire since medieval times at least. In 1579 one match played at Chesterton between townspeople and University of Cambridge students ended in a violent brawl that led the Vice-Chancellor to issue a decree forbidding them to play \"footeball\" outside of college grounds. During the nineteenth century, several formulations of the laws of football, known as the Cambridge rules, were created by students at the university. One of these codes, dating from 1863, had a significant influence on the creation of the original laws of the Football Association.\nCambridgeshire is also the birthplace of bandy, now an IOC accepted sport. According to documents from 1813, Bury Fen Bandy Club was undefeated for 100 years. A member of the club, Charles Goodman Tebbutt, wrote down the first official rules in 1882. Tebbutt was instrumental in spreading the sport to many countries. Great Britain Bandy Association is based in Cambridgeshire.\nFen skating is a traditional form of skating in the Fenland. The National Ice Skating Association was set up in Cambridge in 1879, they took the top Fen skaters to the world speedskating championships where James Smart (skater) became world champion.\nOn 6\u20137 June 2015, the inaugural Tour of Cambridgeshire cycle race took place on closed roads across the county. The event was an official UCI qualification event, and consisted of a Time Trial on the 6th, and a Gran Fondo event on the 7th. The Gran Fondo event was open to the public, and over 6000 riders took part in the race.\nThe River Cam is the main river flowing through Cambridge, parts of the River Nene and River Great Ouse lie within the county. In 2021 the latter was used as the course for The Boat Race. The River Cam serves as the course for the university Lent Bumps and May Bumps and the non-college rowing organised by Cambridgeshire Rowing Association.\nThere is only one racecourse in Cambridgeshire, located at Huntingdon.\nContemporary art.\nCambridge is home to the Kettle's Yard gallery and the artist-run Aid and Abet project space. Nine miles west of Cambridge next to the village of Bourn is Wysing Arts Centre.\nWisbech has been home to the Wisbech Gallery, South Brink since 2023.\nCambridge Open Studios is the region's large arts organisation with over 500 members. Every year, more than 370 artists open their doors to visitors during four weekends in July.\nLiterature.\nThe annual Fenland Poet Laureate awards were instigated for poets in the North of the county in 2012 at Wisbech &amp; Fenland Museum.\nTheatre.\nThe county was visited by travelling companies of comedians in the Georgian period. These came from different companies. The Lincoln Circuit included, at various times, Wisbech and Whittlesey. The Wisbech Georgian theatre still survives as an operating theatre now known as The Angles Theatre.\nIn Cambridge the ADC Theatre is the venue for the Footlights.\nMedia.\nThe county is covered by BBC East and ITV Anglia. Local radio includes BBC Radio Cambridgeshire, Greatest Hits Radio East, Heart East, Smooth East Midlands (only covering Peterborough), and Star Radio. The community radio stations are Black Cat Radio in St Neots; Cam FM and Cambridge 105 in Cambridge; Huntingdon Community Radio; and Peterborough Community Radio and Salaam Radio in Peterborough."}
{"id": "6290", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=6290", "title": "Christian Goldbach", "text": "Christian Goldbach ( , ; 18 March 1690 \u2013 20 November 1764) was a Prussian mathematician connected with some important research mainly in number theory; he also studied law and took an interest in and a role in the Russian court. After traveling around Europe in his early life, he landed in Russia in 1725 as a professor at the newly founded Saint Petersburg Academy of Sciences. Goldbach jointly led the Academy in 1737. However, he relinquished duties in the Academy in 1742 and worked in the Russian Ministry of Foreign Affairs until his death in 1764. He is remembered today for Goldbach's conjecture and the Goldbach\u2013Euler Theorem. He had a close friendship with famous mathematician Leonhard Euler, serving as inspiration for Euler's mathematical pursuits.\nBiography.\nEarly life.\nBorn in the Duchy of Prussia's capital K\u00f6nigsberg, part of Brandenburg-Prussia, Goldbach was the son of a pastor. He studied at the Royal Albertus University. After finishing his studies he went on long educational trips from 1710 to 1724 through Europe, visiting other German states, England, the Netherlands, Italy, and France, meeting with many famous mathematicians, such as Gottfried Leibniz, Leonhard Euler, and Nicholas I Bernoulli. These acquaintances started Goldbach's interest in mathematics. He briefly attended Oxford University in 1713 and, while he was there, Goldbach studied mathematics with John Wallis and Isaac Newton. Also, Goldbach's travels fostered his interest in philology, archaeology, metaphysics, ballistics, and medicine. Between 1717 and 1724, Goldbach published his first few papers which, while minor, credited his mathematical ability. Back in K\u00f6nigsberg, he became acquainted with Georg Bernhard Bilfinger and Jakob Hermann.\nSaint Petersburg Academy of Sciences.\nGoldbach followed Bilfinger and Hermann to the newly opened St. Petersburg Academy of Sciences in 1725. Christian Wolff had invited and had written recommendations for all the Germans who traveled to Saint Petersburg for the academy except Goldbach. Goldbach wrote to the president-designate of the academy, petitioning for a position in the academy, using his past publications and knowledge in medicine and law as qualifications. Goldbach was then hired to a five-year contract as a professor of mathematics and historian of the academy. As historian of the academy, he recorded each academy meeting from the opening of the school in 1725 until January 1728. Goldbach worked with famous mathematicians like Leonhard Euler, Daniel Bernoulli, Johann Bernoulli, and Jean le Rond d'Alembert. Goldbach also played a part in Euler's decision to academically pursue mathematics instead of medicine, cementing mathematics as the premier research field of the academy in the 1730s.\nRussian government work.\nIn 1728, when Peter II became Tsar of Russia, Goldbach became Peter II and Anna's, Peter II's cousin, tutor. Peter II moved the Russian court from St. Petersburg to Moscow in 1729, so Goldbach followed him to Moscow. Goldbach started a correspondence with Euler in 1729, in which some of Goldbach's most important mathematics contributions can be found. Upon Peter II's death in 1730, Goldbach stopped teaching but continued to assist Empress Anna. In 1732, Goldbach returned to the St. Petersburg Academy of Sciences and stayed in the Russian government when Anna moved the court back to St. Petersburg. Upon return to the academy, Goldbach was named corresponding secretary. With Goldbach's return, his friend Euler continued his teaching and research at the academy as well. Then, in 1737, Goldbach and J.D. Schumacher took over the administration of the academy. Also, Goldbach took on duty in Russian court under Empress Anna. He managed to retain his influence in court after the death of Anna and the rule of Empress Elizabeth. In 1742 he entered the Russian Ministry of Foreign Affairs, stepping away from the academy once more. Goldbach was gifted land and increased salary for his good work and rise in the Russian government. In 1760, Goldbach created new guidelines for the education of the royal children which would remain in place for 100 years. He died on 20 November 1764, aged 74, in Moscow.\nChristian Goldbach was multilingual \u2013 he wrote a diary in German and Latin, his letters were written in German, Latin, French, and Italian and for official documents he used Russian, German and Latin.\nContributions.\nGoldbach is most noted for his correspondence with Leibniz, Euler, and Bernoulli, especially in his 1742 letter to Euler stating his Goldbach's conjecture. He also studied and proved some theorems on perfect powers, such as the Goldbach\u2013Euler theorem, and made several notable contributions to analysis. He also proved a result concerning Fermat numbers that is called Goldbach's theorem.\nImpact on Euler.\nIt is Goldbach and Euler's correspondence that contains some of Goldbach's most important contributions to mathematics, specifically number theory. Goldbach and Euler's friendship survived Goldbach's move to Moscow in 1728 and communication ensued. Their correspondence spanned 196 letters over 35 years written in Latin, German, and French. These letters spanned a wide range of topics, including various mathematics topics. Goldbach was the leading influence on Euler's interest and work in number theory. Most of the letters discuss Euler's research in number theory as well as differential calculus. Until the late 1750s, Euler's correspondence on his number theory research was almost exclusively with Goldbach.\nGoldbach's earlier mathematical work and ideas in letters to Euler directly influenced some of Euler's work. In 1729, Euler solved two problems pertaining to sequences which had stumped Goldbach. Ensuingly, Euler outlined the solutions to Goldbach. Also, in 1729 Goldbach closely approximated the Basel problem, which prompted Euler's interest and concurring breakthrough solution. Goldbach, through his letters, kept Euler focused on number theory in the 1730s by discussing Fermat's conjecture with Euler. Euler subsequently offered a proof to the conjecture, crediting Goldbach with introducing him to the subfield. Euler proceeded to write 560 writings, published posthumously in four volumes of Opera omnia, with Goldbach's influence guiding some of the writings. Goldbach's famous conjecture and his writings with Euler prove him to be one of a handful of mathematicians who understood complex number theory in light of Fermat's revolutionary ideas on the topic."}
{"id": "6291", "revid": "46658932", "url": "https://en.wikipedia.org/wiki?curid=6291", "title": "Roman censor", "text": "The censor was a magistrate in ancient Rome who was responsible for maintaining the census, supervising public morality, and overseeing certain aspects of the government's finances.\nEstablished under the Roman Republic, power of the censor was limited in subject matter but absolute within his sphere: in matters reserved for the censors, no magistrate could oppose his decisions, and only another censor who succeeded him could cancel those decisions. Censors were also given unusually long terms of office; unlike other elected offices of the Republic, which (excluding certain priests elected for life) had terms of 12 months or less, censors' terms were generally 18 months to 5 years (depending on the era). The censorate was thus highly prestigious, preceding all other regular magistracies in dignity if not in power and reserved with rare exceptions for former consuls. Attaining the censorship would thus be considered the crowning achievement of a Roman politician on the \"cursus honorum\". However, the magistracy as a regular office did not survive the transition from the Republic to the Empire.\nThe censor's regulation of public morality is the origin of the modern meaning of the words \"censor\" and \"censorship\".\nEarly history of the magistracy.\nThe \"census\" was first instituted by Servius Tullius, sixth king of Rome, BC. After the abolition of the monarchy and the founding of the Republic in 509 BC, the consuls had responsibility for the census until 443 BC. In 442 BC, no consuls were elected, but tribunes with consular power were appointed instead. This was a move by the plebeians to try to attain higher magistracies: only patricians could be elected consuls, while some military tribunes were plebeians. To prevent the possibility of plebeians obtaining control of the census, the patricians removed the right to take the census from the consuls and tribunes, and appointed for this duty two magistrates, called \"censores\" (censors), elected exclusively from the patricians in Rome. \nThe magistracy continued to be controlled by patricians until 351 BC, when Gaius Marcius Rutilus was appointed the first plebeian censor. Twelve years later, in 339 BC, one of the Publilian laws required that one censor had to be a plebeian. Despite this, no plebeian censor performed the solemn purification of the people (the \"lustrum\"; Livy \"Periochae\" 13) until 280 BC. In 131 BC, for the first time, both censors were plebeians.\nThe reason for having two censors was that the two consuls had previously taken the census together. If one of the censors died during his term of office, another was chosen to replace him, just as with consuls. This happened only once, in 393 BC. However, the Gauls captured Rome in that \"lustrum\" (five-year period), and the Romans thereafter regarded such replacement as \"an offense against religion\". From then on, if one of the censors died, his colleague resigned, and two new censors were chosen to replace them.\nThe office of censor was limited to eighteen months by a law proposed by the dictator Mamercus Aemilius Mamercinus. During the censorship of Appius Claudius Caecus (312\u2013308 BC) the prestige of the censorship massively increased. Caecus built the first-ever Roman road (the Via Appia) and the first Roman aqueduct (the Aqua Appia), both named after him. He changed the organisation of the Roman tribes and was the first censor to draw the list of senators. He also advocated the founding of Roman \"coloniae\" throughout Latium and Campania to support the Roman war effort in the Second Samnite War. With these efforts and reforms, Appius Claudius Caecus was able to hold the censorship for a whole \"lustrum\" (five-year period), and the office of censor, subsequently entrusted with various important duties, eventually attained one of the highest political statuses in the Roman Republic, second only to that of the consuls.\nElection.\nThe censors were elected in the Centuriate Assembly, which met under the presidency of a consul. Barthold Niebuhr suggests that the censors were at first elected by the Curiate Assembly, and that the Assembly's selections were confirmed by the Centuriate, but William Smith believes that \"there is no authority for this supposition, and the truth of it depends entirely upon the correctness of [Niebuhr's] views respecting the election of the consuls\". Both censors had to be elected on the same day, and accordingly if the voting for the second was not finished in the same day, the election of the first was invalidated, and a new assembly had to be held.\nThe assembly for the election of the censors was held under different auspices from those at the election of the consuls and praetors, so the censors were not regarded as their colleagues, although they likewise possessed the \"maxima auspicia\". The assembly was held by the new consuls shortly after they began their term of office; and the censors, as soon as they were elected and the censorial power had been granted to them by a decree of the Centuriate Assembly (\"lex centuriata\"), were fully installed in their office.\nAs a general principle, the only ones eligible for the office of censor were those who had previously been consuls, but there were a few exceptions. At first, there was no law to prevent a person being censor twice, but the only person who was elected to the office twice was Gaius Marcius Rutilus in 265 BC. In that year, he originated a law stating that no one could be elected censor twice. In consequence of this, he received the \"cognomen\" of Censorinus.\nAttributes.\nThe censorship differed from all other Roman magistracies in the length of office. The censors were originally chosen for a whole \"lustrum\" (a period of five years), but as early as ten years after its institution (433 BC) their office was limited to eighteen months by a law of Dictator Mamercus Aemilius Mamercinus. The censors were also unique with respect to rank and dignity. They had no \"imperium\", and accordingly no lictors. Their rank was granted to them by the Centuriate Assembly, and not by the \"curiae\", and in that respect they were inferior in power to the consuls and praetors.\nNotwithstanding this, the censorship was regarded as the highest dignity in the state, with the exception of the dictatorship; it was a \"sacred magistracy\" (\"sanctus magistratus\"), to which the deepest reverence was due. The high rank and dignity which the censorship obtained was due to the various important duties gradually entrusted to it, and especially to its possessing the \"regimen morum\", or general control over the conduct and the morals of the citizens. In the exercise of this power, they were regulated solely by their own views of duty, and were not responsible to any other power in the state.\nThe censors possessed the official stool called a \"curule chair\" (\"sella curulis\"), but some doubt exists with respect to their official dress. A well-known passage of Polybius describes the use of the \"imagines\" at funerals; we may conclude that a consul or praetor wore the purple-bordered \"toga praetexta\", one who triumphed the embroidered \"toga picta\", and the censor a purple toga peculiar to him, but other writers speak of their official dress as being the same as that of the other higher magistrates. The funeral of a censor was always conducted with great pomp and splendour, and hence a \"censorial funeral\" (\"funus censorium\") was voted even to the emperors.\nAbolition.\nThe censorship continued in existence for 421 years, from 443 BC to 22 BC, but during this period, many \"lustra\" passed by without any censor being chosen at all. According to one statement, the office was abolished by Lucius Cornelius Sulla. Although the authority on which this statement rests is not of much weight, the fact itself is probable, since there was no census during the two \"lustra\" which elapsed from Sulla's dictatorship to Gnaeus Pompeius Magnus (Pompey)'s first consulship (82\u201370 BC), and any strict \"imposition of morals\" would have been found inconvenient to the aristocracy that supported Sulla.\nIf the censorship had been done away with by Sulla, it was at any rate restored in the consulship of Pompey and Marcus Licinius Crassus. Its power was limited by one of the laws of the tribune Publius Clodius Pulcher (58 BC), which prescribed certain regular forms of proceeding before the censors in expelling a person from the Roman Senate, and required that the censors be in agreement to exact this punishment. This law, however, was repealed in the third consulship of Pompey in 52 BC, on the urging of his colleague Q. Caecilius Metellus Scipio, but the office of the censorship never recovered its former power and influence.\nDuring the civil wars which followed soon afterwards, no censors were elected; it was only after a long interval that they were again appointed, namely in 23 BC, when Augustus caused Lucius Munatius Plancus and Aemilius Lepidus Paullus to fill the office. This was the last time that such magistrates were appointed; the emperors in future discharged the duties of their office under the name of Praefectura Morum (\"prefect of the morals\").\nSome of the emperors sometimes took the name of censor when they held a census of the Roman people; this was the case with Claudius, who appointed the elder Lucius Vitellius as his colleague, and with Vespasian, who likewise had a colleague in his son Titus. Domitian assumed the title of \"perpetual censor\" (\"censor perpetuus\"), but this example was not imitated by succeeding emperors. In the reign of Decius, the elder Valerian was nominated to the censorship, but declined the position.\nDuties.\nThe duties of the censors may be divided into three classes, all of which were closely connected with one another:\nThe original business of the censorship was at first of a much more limited kind, and was restricted almost entirely to taking the census, but the possession of this power gradually brought with it fresh power and new duties, as is shown below. A general view of these duties is briefly expressed in the following passage of Cicero: \"Censores populi aevitates, soboles, familias pecuniasque censento: urbis templa, vias, aquas, aerarium, vectigalia tuento: populique partes in tribus distribunto: exin pecunias, aevitates, ordines patiunto: equitum, peditumque prolem describunto: caelibes esse prohibento: mores populi regunto: probrum in senatu ne relinquunto.\" This can be translated as: \"The Censors are to determine the generations, origins, families, and properties of the people; they are to (watch over/protect) the city's temples, roads, waters, treasury, and taxes; they are to divide the people into three parts; next, they are to (allow/approve) the properties, generations, and ranks [of the people]; they are to describe the offspring of knights and footsoldiers; they are to forbid being unmarried; they are to guide the behavior of the people; they are not to overlook abuse in the Senate.\" \nCensus.\nThe Census, the first and principal duty of the censors, was always held in the Campus Martius, and from the year 435 BC onwards, in a special building called Villa publica, which was erected for that purpose by the second pair of censors, Gaius Furius Pacilus Fusus and Marcus Geganius Macerinus. An account of the formalities with which the census was opened is given in a fragment of the \"Tabulae Censoriae\", preserved by Varro. After the auspices had been taken, the citizens were summoned by a public crier to appear before the censors. Each tribe was called up separately, and the names in each tribe were probably taken according to the lists previously made out by the tribunes of the tribes. Every \"pater familias\" had to appear in person before the censors, who were seated in their curule chairs, and those names were taken first which were considered to be of good omen, such as Valerius, Salvius, Statorius, etc.\nThe Census was conducted according to the judgement of the censor (\"ad arbitrium censoris\"), but the censors laid down certain rules, sometimes called \"leges censui censendo\", in which mention was made of the different kinds of property subject to the census, and in what way their value was to be estimated. According to these laws, each citizen had to give an account of himself, of his family, and of his property upon oath, \"declared from the heart\". First he had to give his full name (\"praenomen\", \"nomen\", and \"cognomen\") and that of his father, or if he were a \"libertus\" (\"freedman\") that of his patron, and he was likewise obliged to state his age. He was then asked, \"You, declaring from your heart, do you have a wife?\" and if married he had to give the name of his wife, and likewise the number, names, and ages of his children, if any. Single women and orphans were represented by their guardians; their names were entered in separate lists, and they were not included in the sum total of heads.\nAfter a citizen had stated his name, age, family, etc., he then had to give an account of all his property, so far as it was subject to the census. Only such things were liable to the census (\"censui censendo\") as were property according to the Quiritary law. At first, each citizen appears to have merely given the value of his whole property in general without entering into details; but it soon became the practice to give a minute specification of each article, as well as the general value of the whole. Land formed the most important article of the census, but public land, the possession of which only belonged to a citizen, was excluded as not being Quiritarian property. Judging from the practice of the imperial period, it was the custom to give a most minute specification of all such land as a citizen held according to the Quiritarian law. He had to state the name and location of the land, and to specify what portion of it was arable, what meadow, what vineyard, and what olive-ground: and of the land thus described, he had to give his assessment of its value.\nSlaves and cattle formed the next most important item. The censors also possessed the right of calling for a return of such objects as had not usually been given in, such as clothing, jewels, and carriages. It has been doubted by some modern writers whether the censors possessed the power of setting a higher valuation on the property than the citizens themselves gave, but given the discretionary nature of the censors' powers, and the necessity almost that existed, in order to prevent fraud, that the right of making a surcharge should be vested in somebody's hands, it is likely that the censors had this power. It is moreover expressly stated that on one occasion they made an extravagant surcharge on articles of luxury; and even if they did not enter in their books the property of a person at a higher value than he returned it, they accomplished the same end by compelling him to pay a tax upon the property at a higher rate than others. The tax was usually one per thousand upon the property entered in the books of the censors, but on one occasion the censors compelled a person to pay eight per thousand as a punishment.\nA person who voluntarily absented himself from the census was considered \"incensus\" and subject to the severest punishment. Servius Tullius is said to have threatened such individuals with imprisonment and death, and in the Republican period he might be sold by the state as a slave. In the later period of the Republic, a person who was absent from the census might be represented by another, and be thus registered by the censors. Whether the soldiers who were absent on service had to appoint a representative is uncertain. In ancient times, the sudden outbreaks of war prevented the census from being taken, because a large number of the citizens would necessarily be absent. It is supposed from a passage in Livy that in later times the censors sent commissioners into the provinces with full powers to take the census of the Roman soldiers there, but this seems to have been a special case. It is, on the contrary, probable from the way in which Cicero pleads the absence of Archias from Rome with the army under Lucullus, as a sufficient reason for his not having been enrolled in the census, that service in the army was a valid excuse for absence.\nAfter the censors had received the names of all the citizens with the amount of their property, they then had to make out the lists of the tribes, and also of the classes and centuries; for by the legislation of Servius Tullius the position of each citizen in the state was determined by the amount of his property (Comitia Centuriata). These lists formed a most important part of the \"Tabulae Censoriae\", under which name were included all the documents connected in any way with the discharge of the censors' duties. These lists, insofar as they were connected with the finances of the state, were deposited in the \"aerarium\", located in the Temple of Saturn; but the regular depository for all the archives of the censors was in earlier times the Atrium Libertatis, near the Villa publica, and in later times the temple of the Nymphs.\nBesides the division of the citizens into tribes, centuries, and classes, the censors had also to make out the lists of the senators for the ensuing five years, or until new censors were appointed, striking out the names of such as they considered unworthy, and making additions to the body from those who were qualified. In the same manner they held a review of the \"equites\" who received a horse from public funds (\"equites equo publico\"), and added and removed names as they judged proper. They also confirmed the \"princeps senatus\", or appointed a new one. The princeps himself had to be a former censor. After the lists had been completed, the number of citizens was counted up, and the sum total announced. Accordingly, we find that in the account of a census, the number of citizens is likewise usually given. They are in such cases spoken of as \"capita\" (\"heads\"), sometimes with the addition of the word \"civium\" (\"of the citizens\"), and sometimes not. Hence, to be registered in the census was the same thing as \"having a head\" (\"caput habere\").\nCensus beyond Rome.\nA census was sometimes taken in the provinces, even under the Republic. The emperor sent into the provinces special officers called \"censitores\" to take the census; but the duty was sometimes discharged by the Imperial \"legati\". The \"censitores\" were assisted by subordinate officers, called \"censuales\", who made out the lists, etc. In Rome, the census was still taken under the Empire, but the old ceremonies connected with it were no longer performed, and the ceremony of the \"lustratio\" was not performed after the time of Vespasian. The jurists Paulus and Ulpian each wrote works on the census in the imperial period; and several extracts from these works are given in a chapter in the \"Digest\" (50 15). \nOther uses of census.\nThe word \"census\", besides the conventional meaning of \"valuation\" of a person's estate, has other meaning in Rome; it could refer to: \n\"Regimen morum\".\nKeeping the public morals (\"regimen morum\", or in the Empire \"cura morum\" or \"praefectura morum\") was the second most important branch of the censors' duties, and the one which caused their office to be one of the most revered and the most dreaded; hence they were also known as \"castigatores\" (\"chastisers\"). It naturally grew out of the right which they possessed of excluding persons from the lists of citizens; for, as has been well remarked, \"they would, in the first place, be the sole judges of many questions of fact, such as whether a citizen had the qualifications required by law or custom for the rank which he claimed, or whether he had ever incurred any judicial sentence, which rendered him infamous: but from thence the transition was easy, according to Roman notions, to the decisions of questions of right; such as whether a citizen was really worthy of retaining his rank, whether he had not committed some act as justly degrading as those which incurred the sentence of the law.\" \nIn this manner, the censors gradually assumed at least nominal complete superintendence over the whole public and private life of every citizen. They were constituted as the conservators of public morality; they were not simply to prevent crime or particular acts of immorality, but rather to maintain the traditional Roman character, ethics, and habits (\"mos majorum\")\u2014\"regimen morum\" also encompassed this protection of traditional ways, which was called in the times of the Empire \"cura\" (\"supervision\") or \"praefectura\" (\"command\"). The punishment inflicted by the censors in the exercise of this branch of their duties was called \"nota\" (\"mark, letter\") or \"notatio\", or \"animadversio censoria\" (\"censorial reproach\"). In inflicting it, they were guided only by their conscientious convictions of duty; they had to take an oath that they would act biased by neither partiality nor favour; and, in addition to this, they were bound in every case to state in their lists, opposite the name of the guilty citizen, the cause of the punishment inflicted on him, \"subscriptio censoria\".\nThis part of the censors' office invested them with a peculiar kind of jurisdiction, which in many respects resembled the exercise of public opinion in modern times; for there are innumerable actions which, though acknowledged by everyone to be prejudicial and immoral, still do not come within the reach of the positive laws of a country; as often said, \"immorality does not equal illegality\". Even in cases of real crimes, the positive laws frequently punish only the particular offence, while in public opinion the offender, even after he has undergone punishment, is still incapacitated for certain honours and distinctions which are granted only to persons of unblemished character.\nHence, the Roman censors might brand a man with their \"censorial mark\" (\"nota censoria\") in case he had been convicted of a crime in an ordinary court of justice, and had already suffered punishment for it. The consequence of such a \"nota\" was only \"ignominia\" and not \"infamia\". \"Infamia\" and the censorial verdict was not a \"judicium\" or \"res judicata\", for its effects were not lasting, but might be removed by the following censors, or by a \"lex\" (roughly \"law\"). A censorial mark was moreover not valid unless both censors agreed. The \"ignominia\" was thus only a transitory reduction of status, which does not even appear to have deprived a magistrate of his office, and certainly did not disqualify persons labouring under it for obtaining a magistracy, for being appointed as \"judices\" by the praetor, or for serving in the Roman army. Mamercus Aemilius Mamercinus was thus, notwithstanding the reproach of the censors (\"animadversio censoria\"), made dictator.\nA person might be branded with a censorial mark in a variety of cases, which it would be impossible to specify, as in a great many instances it depended upon the discretion of the censors and the view they took of a case; and sometimes even one set of censors would overlook an offence which was severely chastised by their successors. But the offences which are recorded to have been punished by the censors are of a threefold nature.\nA person who had been branded with a \"nota censoria\", might, if he considered himself wronged, endeavour to prove his innocence to the censors, and if he did not succeed, he might try to gain the protection of one of the censors, that he might intercede on his behalf.\nPunishments.\nThe punishments inflicted by the censors generally differed according to the station which a man occupied, though sometimes a person of the highest rank might suffer all the punishments at once, by being degraded to the lowest class of citizens. The punishments are generally divided into four classes:\nIt was this authority of the Roman censors which eventually developed into the modern meaning of \"censor\" and \"censorship\"\u2014i.e., officials who review published material and forbid the publication of material judged to be contrary to \"public morality\" as the term is interpreted in a given political and social environment.\nAdministration of the finances of the state.\nThe administration of the state's finances was another part of the censors' office. In the first place the \"tributum\", or property-tax, had to be paid by each citizen according to the amount of his property registered in the census, and, accordingly, the regulation of this tax naturally fell under the jurisdiction of the censors. They also had the superintendence of all the other revenues of the state, the \"vectigalia\", such as the tithes paid for the public lands, the salt works, the mines, the customs, etc.\nThe censors typically auctioned off to the highest bidder for the space of a \"lustrum\" the collection of the tithes and taxes (tax farming). This auctioning was called \"venditio\" or \"locatio\", and seems to have taken place in the month of March, in a public place in Rome The terms on which they were let, together with the rights and duties of the purchasers, were all specified in the \"leges censoriae\", which the censors published in every case before the bidding commenced. For further particulars see Publicani.\nThe censors also possessed the right, though probably not without the assent of the Senate, of imposing new \"vectigalia\", and even of selling the land belonging to the state. It would thus appear that it was the duty of the censors to bring forward a budget for a five-year period, and to take care that the income of the state was sufficient for its expenditure during that time. In part, their duties resembled those of a modern minister of finance. The censors, however, did not receive the revenues of the state. All the public money was paid into the \"aerarium\", which was entirely under the jurisdiction of the Senate; and all disbursements were made by order of this body, which employed the quaestors as its officers.\nOverseeing public works.\nIn one important department, the public works, the censors were entrusted with the expenditure of the public money (though the actual payments were no doubt made by the quaestors).\nThe censors had the general superintendence of all the public buildings and works (\"opera publica\"), and to meet the expenses connected with this part of their duties, the Senate voted them a certain sum of money or certain revenues, to which they were restricted, but which they might at the same time employ according to their discretion. They had to see that the temples and all other public buildings were in a good state of repair, that no public places were encroached upon by the occupation of private persons, and that the aqueducts, roads, drains, etc. were properly attended to.\nThe repairs of the public works and the keeping of them in proper condition were let out by the censors by public auction to the lowest bidder, just as the \"vectigalia\" were let out to the highest bidder. These expenses were called \"ultrotributa\", and hence we frequently find \"vectigalia\" and \"ultrotributa\" contrasted with one another. The persons who undertook the contract were called \"conductores\", \"mancipes\", \"redemptores\", \"susceptores\", etc., and the duties they had to discharge were specified in the Leges Censoriae. The censors had also to superintend the expenses connected with the worship of the gods, even for instance the feeding of the sacred geese in the Capitol; these various tasks were also let out on contract. It was ordinary for censors to expend large amounts of money (\u201cby far the largest and most extensive\u201d of the state) in their public works.\nBesides keeping existing public buildings and facilities in a proper state of repair, the censors were also in charge of constructing new ones, either for ornament or utility, both in Rome and in other parts of Italy, such as temples, basilicae, theatres, porticoes, fora, aqueducts, town walls, harbours, bridges, cloacae, roads, etc. These works were either performed by them jointly, or they divided between them the money, which had been granted to them by the Senate. They were let out to contractors, like the other works mentioned above, and when they were completed, the censors had to see that the work was performed in accordance with the contract: this was called \"opus probare\" or \"in acceptum referre\".\nThe first ever Roman road, the Via Appia, and the first Roman aqueduct, the Aqua Appia, were all constructed under the censorship of Appius Claudius Caecus, one of the most influential censors.\nThe aediles had likewise a superintendence over the public buildings, and it is not easy to define with accuracy the respective duties of the censors and aediles, but it may be remarked in general that the superintendence of the aediles had more of a police character, while that of the censors were more financial in subject matter.\nLustrum.\nAfter the censors had performed their various duties and taken the five-yearly census, the \"lustrum\", a solemn purification of the people, followed. When the censors entered upon their office, they drew lots to see which of them should perform this purification; but both censors were of course obliged to be present at the ceremony.\nLong after the Roman census was no longer taken, the Latin word \"lustrum\" has survived, and been adopted in some modern languages, in the derived sense of a period of five years, i.e., half a decennium."}
{"id": "6292", "revid": "2051880", "url": "https://en.wikipedia.org/wiki?curid=6292", "title": "Convex set", "text": "In geometry, a set of points is convex if it contains every line segment between two points in the set. Equivalently, a convex set or a convex region is a set that intersects every line in a line segment, single point, or the empty set.\nFor example, a solid cube is a convex set, but anything that is hollow or has an indent, for example, a crescent shape, is not convex.\nThe boundary of a convex set in the plane is always a convex curve. The intersection of all the convex sets that contain a given subset of Euclidean space is called the convex hull of . It is the smallest convex set containing .\nA convex function is a real-valued function defined on an interval with the property that its epigraph (the set of points on or above the graph of the function) is a convex set. Convex minimization is a subfield of optimization that studies the problem of minimizing convex functions over convex sets. The branch of mathematics devoted to the study of properties of convex sets and convex functions is called convex analysis.\nSpaces in which convex sets are defined include the Euclidean spaces, the affine spaces over the real numbers, and certain non-Euclidean geometries. The notion of a convex set in Euclidean spaces can be generalized in several ways by modifying its definition, for instance by restricting the line segments that such a set is required to contain.\nDefinitions.\nLet be a vector space or an affine space over the real numbers, or, more generally, over some ordered field (this includes Euclidean spaces, which are affine spaces). A subset of is convex if, for all and in , the line segment connecting and is included in . \nThis means that the affine combination belongs to for all in and in the interval . This implies that convexity is invariant under affine transformations. Further, it implies that a convex set in a real or complex topological vector space is path-connected (and therefore also connected).\nA set is if every point on the line segment connecting and other than the endpoints is inside the topological interior of . A closed convex subset is strictly convex if and only if every one of its boundary points is an extreme point.\nA set is absolutely convex if it is convex and balanced.\nExamples.\nThe convex subsets of (the set of real numbers) are the intervals and the points of . Some examples of convex subsets of the Euclidean plane are solid regular polygons, solid triangles, and intersections of solid triangles. Some examples of convex subsets of a Euclidean 3-dimensional space are the Archimedean solids and the Platonic solids. The Kepler-Poinsot polyhedra are examples of non-convex sets.\nNon-convex set.\nA set that is not convex is called a \"non-convex set\". A polygon that is not a convex polygon is sometimes called a concave polygon, and some sources more generally use the term \"concave set\" to mean a non-convex set, but most authorities prohibit this usage.\nThe complement of a convex set, such as the epigraph of a concave function, is sometimes called a \"reverse convex set\", especially in the context of mathematical optimization.\nProperties.\nGiven points in a convex set , and \nnonnegative numbers such that , the affine combination \nformula_1\nbelongs to . As the definition of a convex set is the case , this property characterizes convex sets.\nSuch an affine combination is called a convex combination of .\nIntersections and unions.\nThe collection of convex subsets of a vector space, an affine space, or a Euclidean space has the following properties:\nClosed convex sets.\nClosed convex sets are convex sets that contain all their limit points. They can be characterised as the intersections of \"closed half-spaces\" (sets of points in space that lie on and to one side of a hyperplane).\nFrom what has just been said, it is clear that such intersections are convex, and they will also be closed sets. To prove the converse, i.e., every closed convex set may be represented as such intersection, one needs the supporting hyperplane theorem in the form that for a given closed convex set and point outside it, there is a closed half-space that contains and not . The supporting hyperplane theorem is a special case of the Hahn\u2013Banach theorem of functional analysis.\nConvex sets and rectangles.\nLet be a convex body in the plane (a convex set whose interior is non-empty). We can inscribe a rectangle \"r\" in such that a homothetic copy \"R\" of \"r\" is circumscribed about . The positive homothety ratio is at most 2 and:\nformula_2\nBlaschke-Santal\u00f3 diagrams.\nThe set formula_3 of all planar convex bodies can be parameterized in terms of the convex body diameter \"D\", its inradius \"r\" (the biggest circle contained in the convex body) and its circumradius \"R\" (the smallest circle containing the convex body). In fact, this set can be described by the set of inequalities given by\nformula_4\nformula_5\nformula_6\nformula_7\nand can be visualized as the image of the function \"g\" that maps a convex body to the point given by (\"r\"/\"R\", \"D\"/2\"R\"). The image of this function is known a (\"r\", \"D\", \"R\") Blachke-Santal\u00f3 diagram.\nAlternatively, the set formula_3 can also be parametrized by its width (the smallest distance between any two different parallel support hyperplanes), perimeter and area.\nOther properties.\nLet \"X\" be a topological vector space and formula_9 be convex. \nConvex hulls and Minkowski sums.\nConvex hulls.\nEvery subset of the vector space is contained within a smallest convex set (called the convex hull of ), namely the intersection of all convex sets containing . The convex-hull operator Conv() has the characteristic properties of a hull operator:\nThe convex-hull operation is needed for the set of convex sets to form a lattice, in which the \"join\" operation is the convex hull of the union of two convex sets\nformula_20\nThe intersection of any collection of convex sets is itself convex, so the convex subsets of a (real or complex) vector space form a complete lattice.\nMinkowski addition.\nIn a real vector-space, the \"Minkowski sum\" of two (non-empty) sets, and , is defined to be the set formed by the addition of vectors element-wise from the summand-sets\nformula_21\nMore generally, the \"Minkowski sum\" of a finite family of (non-empty) sets is the set formed by element-wise addition of vectors\nformula_22\nFor Minkowski\u00a0addition, the \"zero set\"\u00a0 containing only the zero\u00a0vector\u00a0 has special importance: For every non-empty subset\u00a0S of a vector space\nformula_23\nin algebraic terminology, is the identity element of Minkowski addition (on the collection of non-empty sets).\nConvex hulls of Minkowski sums.\nMinkowski addition behaves well with respect to the operation of taking convex hulls, as shown by the following proposition:\nLet be subsets of a real vector-space, the convex hull of their Minkowski sum is the Minkowski sum of their convex hulls\nformula_24\nThis result holds more generally for each finite collection of non-empty sets:\nformula_25\nIn mathematical terminology, the operations of Minkowski summation and of forming convex hulls are commuting operations.\nMinkowski sums of convex sets.\nThe Minkowski sum of two compact convex sets is compact. The sum of a compact convex set and a closed convex set is closed.\nThe following famous theorem, proved by Dieudonn\u00e9 in 1966, gives a sufficient condition for the difference of two closed convex subsets to be closed. It uses the concept of a recession cone of a non-empty convex subset \"S\", defined as:\nformula_26\nwhere this set is a convex cone containing formula_27 and satisfying formula_28. Note that if \"S\" is closed and convex then formula_29 is closed and for all formula_30,\nformula_31\nTheorem (Dieudonn\u00e9). Let \"A\" and \"B\" be non-empty, closed, and convex subsets of a locally convex topological vector space such that formula_32 is a linear subspace. If \"A\" or \"B\" is locally compact then \"A\"\u00a0\u2212\u00a0\"B\" is closed.\nGeneralizations and extensions for convexity.\nThe notion of convexity in the Euclidean space may be generalized by modifying the definition in some or other aspects. The common name \"generalized convexity\" is used, because the resulting objects retain certain properties of convex sets.\nStar-convex (star-shaped) sets.\nLet be a set in a real or complex vector space. is star convex (star-shaped) if there exists an in such that the line segment from to any point in is contained in . Hence a non-empty convex set is always star-convex but a star-convex set is not always convex.\nOrthogonal convexity.\nAn example of generalized convexity is orthogonal convexity.\nA set in the Euclidean space is called orthogonally convex or ortho-convex, if any segment parallel to any of the coordinate axes connecting two points of lies totally within . It is easy to prove that an intersection of any collection of orthoconvex sets is orthoconvex. Some other properties of convex sets are valid as well.\nNon-Euclidean geometry.\nThe definition of a convex set and a convex hull extends naturally to geometries which are not Euclidean by defining a geodesically convex set to be one that contains the geodesics joining any two points in the set.\nOrder topology.\nConvexity can be extended for a totally ordered set endowed with the order topology.\nLet . The subspace is a convex set if for each pair of points in such that , the interval is contained in . That is, is convex if and only if for all in , implies .\nA convex set is connected in general: a counter-example is given by the subspace {1,2,3} in , which is both convex and not connected.\nConvexity spaces.\nThe notion of convexity may be generalised to other objects, if certain properties of convexity are selected as axioms.\nGiven a set , a convexity over is a collection of subsets of satisfying the following axioms:\nThe elements of are called convex sets and the pair is called a convexity space. For the ordinary convexity, the first two axioms hold, and the third one is trivial.\nFor an alternative definition of abstract convexity, more suited to discrete geometry, see the \"convex geometries\" associated with antimatroids.\nConvex spaces.\nConvexity can be generalised as an abstract algebraic structure: a space is convex if it is possible to take convex combinations of points."}
{"id": "6293", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=6293", "title": "Cairo", "text": "Cairo ( ; , ) is the capital and largest city of Egypt and the Cairo Governorate, being home to more than 10 million people. It is also part of the largest urban agglomeration in Africa, the Arab world and the Middle East. The Greater Cairo metropolitan area is the 12th-largest in the world by population with over 22.1 million people.\nThe area that would become Cairo was part of ancient Egypt, as the Giza pyramid complex and the ancient cities of Memphis and Heliopolis are near-by. Located near the Nile Delta, the predecessor settlement was Fustat following the Muslim conquest of Egypt in 641 next to an existing ancient Roman fortress, Babylon. Subsequently, Cairo was founded by the Fatimid dynasty in 969. It later superseded Fustat as the main urban centre during the Ayyubid and Mamluk periods (12th\u201316th centuries). \nCairo has since become a longstanding centre of political and cultural life, and is titled \"the city of a thousand minarets\" for its preponderance of Islamic architecture. Cairo's historic center was awarded World Heritage Site status in 1979. Cairo is considered a World City with a \"Beta +\" classification according to GaWC.\nCairo has the oldest and largest film and music industry in the Arab world, as well as Egypt's oldest institution of higher learning, Al-Azhar University. Many international media, businesses, and organizations have regional headquarters in the city; the Arab League has had its headquarters in Cairo for most of its existence.\nCairo, like many other megacities, suffers from high levels of pollution and traffic. The Cairo Metro, opened in 1987, is the oldest metro system in Africa, and ranks amongst the fifteen busiest in the world, with over 1 billion annual passenger rides. The economy of Cairo was ranked first in the Middle East in 2005, and 43rd globally on \"Foreign Policy\" 2010 Global Cities Index.\nEtymology.\nThe name of Cairo is derived from the Arabic ' (), meaning 'the Vanquisher' or 'the Conqueror', given by the Fatimid Caliph al-Mu'izz following the establishment of the city as the capital of the Fatimid dynasty. Its full, formal name was ' (\u0627\u0644\u0642\u0627\u0647\u0631\u0629 \u0627\u0644\u0645\u0639\u0632\u064a\u0651\u0629), meaning 'the Vanquisher of al-Mu'izz'. It is also supposedly due to the fact that the planet Mars, known in Arabic by names such as (, 'the Conquering Star'), was rising at the time of the city's founding.\nEgyptians often refer to Cairo as \"\" (; ), the Egyptian Arabic name for Egypt itself, emphasizing the city's importance for the country.\nThere are a number of Coptic names for the city. \"Tike\u0161r\u014dmi\" ( ) is attested in the 1211 text \"The Martyrdom of John of Phanijoit\" and is either a calque meaning 'man breaker' (, 'the', , 'to break', and , 'man'), akin to Arabic \"\", or a derivation from Arabic (\"qa\u1e63r ar-r\u016bm\", \"the Roman castle\"), another name of Babylon Fortress in Old Cairo. The Arabic name is also calqued as , \"the victor city\" in the Coptic antiphonary.\nThe form Khairon () is attested in the modern Coptic text \u2ca0\u2c93\u2cab\u2c93\u2ca3\u2c93 \u2c9b\u0300\u2ca7\u2c89 \u03ef\u2c81\u2c85\u2c93\u2c81 \u2c99\u0300\u2c99\u2c8f\u2c93 \u2c82\u2c89\u2ca3\u2c8f\u2c9b\u2c81 (The Tale of Saint Verina). ( ) or ( ) is another name which is descended from the Greek name of Heliopolis (). Some argue that ( ) or ( ) is another Coptic name for Cairo, although others think that it is rather a name for the Abbasid province capital al-Askar. () is a popular modern rendering of an Arabic name (others being [Kairon] and [Kahira]) which is modern folk etymology meaning 'land of sun'. Some argue that it was the name of an Egyptian settlement upon which Cairo was built, but it is rather doubtful as this name is not attested in any Hieroglyphic or Demotic source, although some researchers, like Paul Casanova, view it as a legitimate theory. Cairo is also referred to as ( ) or ( ), which means Egypt in Coptic, the same way it is referred to in Egyptian Arabic.\nSometimes the city is informally referred to as \"\" by people from Alexandria (; ).\nHistory.\nAncient settlements.\nThe area around present-day Cairo had long been a focal point of Ancient Egypt due to its strategic location at the junction of the Nile Valley and the Nile Delta regions (roughly Upper Egypt and Lower Egypt), which also placed it at the crossing of major routes between North Africa and the Levant. Memphis, the capital of Egypt during the Old Kingdom and a major city up until the Ptolemaic period, was located a short distance south west of present-day Cairo. Heliopolis, another important city and major religious center, was located in what are now the modern districts of Matariya and Ain Shams in northeastern Cairo. It was largely destroyed by the Persian invasions in 525 BC and 343 BC and partly abandoned by the late first century BC.\nHowever, the origins of modern Cairo are generally traced back to a series of settlements in the first millennium AD. Around the turn of the fourth century, as Memphis was continuing to decline in importance, the Romans established a large fortress along the east bank of the Nile. The fortress, called Babylon, was built by the Roman emperor Diocletian (r. 285\u2013305) at the entrance of a canal connecting the Nile to the Red Sea that was created earlier by emperor Trajan (r. 98\u2013117). Further north of the fortress, near the present-day district of al-Azbakiya, was a port and fortified outpost known as Tendunyas () or Umm Dunayn. While no structures older than the 7th century have been preserved in the area aside from the Roman fortifications, historical evidence suggests that a sizeable city existed. The city was important enough that its bishop, Cyrus, participated in the Second Council of Ephesus in 449.\nThe Byzantine-Sassanian War between 602 and 628 caused great hardship and likely caused much of the urban population to leave for the countryside, leaving the settlement partly deserted. The site today remains at the nucleus of the Coptic Orthodox community, which separated from the Roman and Byzantine churches in the late 4th century. Cairo's oldest extant churches, such as the Church of Saint Barbara and the Church of Saints Sergius and Bacchus (from the late 7th or early 8th century), are located inside the fortress walls in what is now known as Old Cairo or Coptic Cairo.\nFustat and other early Islamic settlements.\nThe Muslim conquest of Byzantine Egypt was led by Amr ibn al-As from 639 to 642. Babylon Fortress was besieged in September 640 and fell in April 641. In 641 or early 642, after the surrender of Alexandria (the Egyptian capital at the time), he founded a new settlement next to Babylon Fortress. The city, known as Fustat (), served as a garrison town and as the new administrative capital of Egypt. Historians such as Janet Abu-Lughod and Andr\u00e9 Raymond trace the genesis of present-day Cairo to the foundation of Fustat. The choice of founding a new settlement at this inland location, instead of using the existing capital of Alexandria on the Mediterranean coast, may have been due to the new conquerors' strategic priorities. One of the first projects of the new Muslim administration was to clear and re-open Trajan's ancient canal in order to ship grain more directly from Egypt to Medina, the capital of the caliphate in Arabia. Ibn al-As also founded a mosque for the city at the same time, now known as the Mosque of Amr Ibn al-As, the oldest mosque in Egypt and Africa (although the current structure dates from later expansions).\nIn 750, following the overthrow of the Umayyad caliphate by the Abbasids, the new rulers created their own settlement to the northeast of Fustat which became the new provincial capital. This was known as al-Askar () as it was laid out like a military camp. A governor's residence and a new mosque were also added, with the latter completed in 786. The Red Sea canal re-excavated in the 7th century was closed by the Abbasid caliph al-Mansur in al-Mansur (), but a part of the canal, known as the Khalij, continued to be a major feature of Cairo's geography and of its water supply until the 19th century. In 861, on the orders of the Abbasid caliph al-Mutawakkil, a Nilometer was built on Roda Island near Fustat. Although it was repaired and given a new roof in later centuries, its basic structure is still preserved today, making it the oldest preserved Islamic-era structure in Cairo today.\nIn 868 a commander of Turkic origin named Bakbak was sent to Egypt by the Abbasid caliph al-Mu'taz to restore order after a rebellion in the country. He was accompanied by his stepson, Ahmad ibn Tulun, who became effective governor of Egypt. Over time, Ibn Tulun gained an army and accumulated influence and wealth, allowing him to become the \"de facto\" independent ruler of both Egypt and Syria by 878. In 870, he used his growing wealth to found a new administrative capital, al-Qata'i (), to the northeast of Fustat and of al-Askar. The new city included a palace known as the \"Dar al-Imara\", a parade ground known as \"al-Maydan\", a bimaristan (hospital), and an aqueduct to supply water. Between 876 and 879 Ibn Tulun built a great mosque, now known as the Mosque of Ibn Tulun, at the center of the city, next to the palace. After his death in 884, Ibn Tulun was succeeded by his son and his descendants who continued a short-lived dynasty, the Tulunids. In 905, the Abbasids sent general Muhammad Sulayman al-Katib to re-assert direct control over the country. Tulunid rule was ended and al-Qatta'i was razed to the ground, except for the mosque which remains standing today.\nFoundation and expansion of Cairo.\nIn 969, the Shi'a Isma'ili Fatimid empire conquered Egypt after ruling from Ifriqiya. The Fatimid general Jawhar Al Saqili founded a new fortified city northeast of Fustat and of former al-Qata'i. It took four years to build the city, initially known as al-Man\u1e63\u016briyyah, which was to serve as the new capital of the caliphate. During that time, the construction of the al-Azhar Mosque was commissioned by order of the caliph, which developed into the third-oldest university in the world. Cairo would eventually become a centre of learning, with the library of Cairo containing hundreds of thousands of books. When Caliph al-Mu'izz li Din Allah arrived from the old Fatimid capital of Mahdia in Tunisia in 973, he gave the city its present name, \"Q\u0101hirat al-Mu'izz\" (\"The Vanquisher of al-Mu'izz\"), from which the name \"Cairo\" (\"al-Q\u0101hira\") originates. The caliphs lived in a vast and lavish palace complex that occupied the heart of the city. Cairo remained a relatively exclusive royal city for most of this era, but during the tenure of Badr al-Gamali as vizier (1073\u20131094) the restrictions were loosened for the first time and richer families from Fustat were allowed to move into the city. Between 1087 and 1092 Badr al-Gamali also rebuilt the city walls in stone and constructed the city gates of Bab al-Futuh, Bab al-Nasr, and Bab Zuweila that still stand today.\nDuring the Fatimid period Fustat reached its apogee in size and prosperity, acting as a center of craftsmanship and international trade and as the area's main port on the Nile. Historical sources report that multi-story communal residences existed in the city, particularly in its center, which were typically inhabited by middle and lower-class residents. Some of these were as high as seven stories and could house some 200 to 350 people. They may have been similar to Roman \"insulae\" and may have been the prototypes for the rental apartment complexes which became common in the later Mamluk and Ottoman periods.\nHowever, in 1168 the Fatimid vizier Shawar set fire to unfortified Fustat to prevent its potential capture by Amalric, the Crusader king of Jerusalem. While the fire did not destroy the city and it continued to exist afterward, it did mark the beginning of its decline. Over the following centuries it was Cairo, the former palace-city, that became the new economic center and attracted migration from Fustat.\nWhile the Crusaders did not capture the city in 1168, a continuing power struggle between Shawar, King Amalric, and the Zengid general Shirkuh led to the downfall of the Fatimid establishment. In 1169, Shirkuh's nephew Saladin was appointed as the new vizier of Egypt by the Fatimids and two years later he seized power from the family of the last Fatimid caliph, al-'\u0100\u1e0did. As the first Sultan of Egypt, Saladin established the Ayyubid dynasty, based in Cairo, and aligned Egypt with the Sunni Abbasids, who were based in Baghdad. In 1176, Saladin began construction on the Cairo Citadel, which was to serve as the seat of the Egyptian government until the mid-19th century. The construction of the Citadel definitively ended Fatimid-built Cairo's status as an exclusive palace-city and opened it up to common Egyptians and to foreign merchants, spurring its commercial development. Along with the Citadel, Saladin also began the construction of a new 20-kilometre-long wall that would protect both Cairo and Fustat on their eastern side and connect them with the new Citadel. These construction projects continued beyond Saladin's lifetime and were completed under his Ayyubid successors.\nApogee and decline under the Mamluks.\nIn 1250, during the Seventh Crusade, the Ayyubid dynasty had a crisis with the death of al-Salih and power transitioned instead to the Mamluks, partly with the help of al-Salih's wife, Shajar ad-Durr, who ruled for a brief period around this time. Mamluks were soldiers who were purchased as young slaves and raised to serve in the sultan's army. Between 1250 and 1517 the throne of the Mamluk Sultanate passed from one mamluk to another in a system of succession that was generally non-hereditary, but also frequently violent and chaotic. The Mamluk Empire nonetheless became a major power in the region and was responsible for repelling the advance of the Mongols (most famously at the Battle of Ain Jalut in 1260) and for eliminating the last Crusader states in the Levant.\nDespite their military character, the Mamluks were also prolific builders and left a rich architectural legacy throughout Cairo. Continuing a practice started by the Ayyubids, much of the land occupied by former Fatimid palaces was sold and replaced by newer buildings, becoming a prestigious site for the construction of Mamluk religious and funerary complexes. Construction projects initiated by the Mamluks pushed the city outward while also bringing new infrastructure to the centre of the city. Meanwhile, Cairo flourished as a centre of Islamic scholarship and a crossroads on the spice trade route among the civilisations in Afro-Eurasia. Under the reign of the Mamluk sultan al-Nasir Muhammad (1293\u20131341, with interregnums), Cairo reached its apogee in terms of population and wealth. By 1340, Cairo had a population of close to half a million, making it the largest city west of China.\nMulti-story buildings occupied by rental apartments, known as a \"rab'\" (plural \"rib\u0101\"' or \"urbu\"), became common in the Mamluk period and continued to be a feature of the city's housing during the later Ottoman period. These apartments were often laid out as multi-story duplexes or triplexes. They were sometimes attached to caravanserais, where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants. The oldest partially-preserved example of this type of structure is the Wikala of Amir Qawsun, built before 1341. Residential buildings were in turn organized into close-knit neighbourhoods called a \"harat\", which in many cases had gates that could be closed off at night or during disturbances.\nWhen the traveller Ibn Battuta first came to Cairo in 1326, he described it as the principal district of Egypt. When he passed through the area again on his return journey in 1348, the Black Death was ravaging most major cities. He cited reports of thousands of deaths per day in Cairo. Although Cairo avoided Europe's stagnation during the Late Middle Ages, it could not escape the Black Death, which struck the city more than fifty times between 1348 and 1517. During its initial, and most deadly waves, approximately 200,000 people were killed by the plague, and, by the 15th century, Cairo's population had been reduced to between 150,000 and 300,000. The population decline was accompanied by a period of political instability between 1348 and 1412. It was nonetheless in this period that the largest Mamluk-era religious monument, the Madrasa-Mosque of Sultan Hasan, was built. In the late 14th century, the Burji Mamluks replaced the Bahri Mamluks as rulers of the Mamluk state, but the Mamluk system continued to decline.\nThough the plagues returned frequently throughout the 15th century, Cairo remained a major metropolis and its population recovered in part through rural migration. More conscious efforts were conducted by rulers and city officials to redress the city's infrastructure and cleanliness. Its economy and politics also became more deeply connected with the wider Mediterranean. Some Mamluk sultans in this period, such as Barbsay (r. 1422\u20131438) and Qaytbay (r. 1468\u20131496), had relatively long and successful reigns. After al-Nasir Muhammad, Qaytbay was one of the most prolific patrons of art and architecture of the Mamluk era. He built or restored numerous monuments in Cairo, in addition to commissioning projects beyond Egypt. The crisis of Mamluk power and of Cairo's economic role deepened after Qaytbay. The city's status was diminished after Vasco da Gama discovered a sea route around the Cape of Good Hope between 1497 and 1499, thereby allowing spice traders to avoid Cairo.\nOttoman rule.\nCairo's political influence diminished significantly after the Ottomans defeated Sultan al-Ghuri in the Battle of Marj Dabiq in 1516 and conquered Egypt in 1517. Ruling from Constantinople, Sultan Selim I relegated Egypt to a province, with Cairo as its capital. For this reason, the history of Cairo during Ottoman times is often described as inconsequential, especially in comparison to other time periods.\nDuring the 16th and 17th centuries, Cairo still remained an important economic and cultural centre. Although no longer on the spice route, the city facilitated the transportation of Yemeni coffee and Indian textiles, primarily to Anatolia, North Africa, and the Balkans. Cairene merchants were instrumental in bringing goods to the barren Hejaz, especially during the annual hajj to Mecca. It was during this same period that al-Azhar University reached the predominance among Islamic schools that it continues to hold today; pilgrims on their way to hajj often attested to the superiority of the institution, which had become associated with Egypt's body of Islamic scholars. The first printing press of the Middle East, printing in Hebrew, was established in Cairo by a scion of the Soncino family of printers, Italian Jews of Ashkenazi origin who operated a press in Constantinople. The existence of the press is known solely from two fragments discovered in the Cairo Geniza.\nUnder the Ottomans, Cairo expanded south and west from its nucleus around the Citadel. The city was the second-largest in the empire, behind Constantinople, and, although migration was not the primary source of Cairo's growth, twenty percent of its population at the end of the 18th century consisted of religious minorities and foreigners from around the Mediterranean. Still, when Napoleon arrived in Cairo in 1798, the city's population was less than 300,000, forty percent lower than it was at the height of Mamluk\u2014and Cairene\u2014influence in the mid-14th century.\nThe French occupation was short-lived as British and Ottoman forces, including a sizeable Albanian contingent, recaptured the country in 1801. Cairo itself was besieged by a British and Ottoman force culminating with the French surrender on 22 June 1801. The British vacated Egypt two years later, leaving the Ottomans, the Albanians, and the long-weakened Mamluks jostling for control of the country. Continued civil war allowed an Albanian named Muhammad Ali Pasha to ascend to the role of commander and eventually, with the approval of the religious establishment, viceroy of Egypt in 1805.\nModern era.\nUntil his death in 1848, Muhammad Ali Pasha instituted a number of social and economic reforms that earned him the title of founder of modern Egypt. However, while Muhammad Ali initiated the construction of public buildings in the city, those reforms had minimal effect on Cairo's landscape. Bigger changes came to Cairo under Isma'il Pasha (r. 1863\u20131879), who continued the modernisation processes started by his grandfather. Drawing inspiration from Paris, Isma'il envisioned a city of maidans and wide avenues; due to financial constraints, only some of them, in the area now composing Downtown Cairo, came to fruition. Isma'il also sought to modernize the city, which was merging with neighbouring settlements, by establishing a public works ministry, bringing gas and lighting to the city, and opening a theatre and opera house.\nThe immense debt resulting from Isma'il's projects provided a pretext for increasing European control, which culminated with the British invasion in 1882. The city's economic centre quickly moved west toward the Nile, away from the historic Islamic Cairo section and toward the contemporary, European-style areas built by Isma'il. Europeans accounted for five percent of Cairo's population at the end of the 19th century, by which point they held most top governmental positions.\nIn 1906 the Heliopolis Oasis Company headed by the Belgian industrialist \u00c9douard Empain and his Egyptian counterpart Boghos Nubar, built a suburb called Heliopolis (city of the sun in Greek) ten kilometers from the center of Cairo. In 1905\u20131907 the northern part of the Gezira island was developed by the Baehler Company into Zamalek, which would later become Cairo's upscale \"chic\" neighbourhood. In 1906 construction began on Garden City, a neighbourhood of urban villas with gardens and curved streets.\nThe British occupation was intended to be temporary, but it lasted well into the 20th century. Nationalists staged large-scale demonstrations in Cairo in 1919, five years after Egypt had been declared a British protectorate. Nevertheless, this led to Egypt's independence in 1922.\nThe King Fuad I Edition of the Qur'an was first published on 10 July 1924 in Cairo under the patronage of King Fuad. The goal of the government of the newly formed Kingdom of Egypt was not to delegitimize the other variant Quranic texts (\"qira'at\"), but to eliminate errors found in Qur'anic texts used in state schools. A committee of teachers chose to preserve a single one of the canonical qira'at \"readings\", namely that of the \"\u1e24af\u1e63\" version, an 8th-century Kufic recitation. This edition has become the standard for modern printings of the Quran for much of the Islamic world. The publication has been called a \"terrific success\", and the edition has been described as one \"now widely seen as the official text of the Qur'an\", so popular among both Sunni and Shi'a that the common belief among less well-informed Muslims is \"that the Qur'an has a single, unambiguous reading\". Minor amendments were made later in 1924 and in 1936 - the \"Faruq edition\" in honour of then ruler, King Faruq.\nBritish occupation until 1956.\nBritish troops remained in the country until 1956. During this time, urban Cairo, spurred by new bridges and transport links, continued to expand to include the upscale neighbourhoods of Garden City, Zamalek, and Heliopolis. Between 1882 and 1937, the population of Cairo more than tripled\u2014from 347,000 to 1.3 million\u2014and its area increased from .\nThe city was devastated during the 1952 riots known as the Cairo Fire or Black Saturday, which saw the destruction of nearly 700 shops, movie theatres, casinos and hotels in downtown Cairo. The British departed Cairo following the Egyptian Revolution of 1952, but the city's rapid growth showed no signs of abating. Seeking to accommodate the increasing population, President Gamal Abdel Nasser redeveloped Tahrir Square and the Nile Corniche, and improved the city's network of bridges and highways. Meanwhile, additional controls of the Nile fostered development within Gezira Island and along the city's waterfront. The metropolis began to encroach on the fertile Nile Delta, prompting the government to build desert satellite towns and devise incentives for city-dwellers to move to them.\nAfter 1956.\nIn the second half of the 20th century Cairo continue to grow enormously in both population and area. Between 1947 and 2006 the population of Greater Cairo went from 2,986,280 to 16,292,269. The population explosion also drove the rise of \"informal\" housing (\"'ashwa'iyyat\"), meaning housing that was built without any official planning or control. The exact form of this type of housing varies considerably but usually has a much higher population density than formal housing. By 2009, over 63% of the population of Greater Cairo lived in informal neighbourhoods, even though these occupied only 17% of the total area of Greater Cairo. According to economist David Sims, informal housing has the benefits of providing affordable accommodation and vibrant communities to huge numbers of Cairo's working classes, but it also suffers from government neglect, a relative lack of services, and overcrowding.\nThe \"formal\" city was also expanded. The most notable example was the creation of Madinat Nasr, a huge government-sponsored expansion of the city to the east which officially began in 1959 but was primarily developed in the mid-1970s. Starting in 1977 the Egyptian government established the New Urban Communities Authority to initiate and direct the development of new planned cities on the outskirts of Cairo, generally established on desert land. These new satellite cities were intended to provide housing, investment, and employment opportunities for the region's growing population as well as to pre-empt the further growth of informal neighbourhoods. As of 2014, about 10% of the population of Greater Cairo lived in the new cities.\nConcurrently, Cairo established itself as a political and economic hub for North Africa and the Arab world, with many multinational businesses and organisations, including the Arab League, operating out of the city. In 1979 the historic districts of Cairo were listed as a UNESCO World Heritage Site.\nIn 1992, Cairo was hit by an earthquake causing 545 deaths, injuring 6,512 and leaving around 50,000 people homeless.\n2011 Egyptian revolution.\nCairo's Tahrir Square was the focal point of the 2011 Egyptian revolution against former president Hosni Mubarak. More than 50,000 protesters first occupied the square on 25 January, during which the area's wireless services were reported to be impaired. In the following days Tahrir Square continued to be the primary destination for protests in Cairo. The uprising was mainly a campaign of non-violent civil resistance, which featured a series of demonstrations, marches, acts of civil disobedience, and labour strikes. Millions of protesters from a variety of socio-economic and religious backgrounds demanded the overthrow of the regime of Egyptian President Hosni Mubarak. Despite being predominantly peaceful in nature, the revolution was not without violent clashes between security forces and protesters, with at least 846 people killed and 6,000 injured. The uprising took place in Cairo, Alexandria, and in other cities in Egypt, following the Tunisian revolution that resulted in the overthrow of the long-time Tunisian president Zine El Abidine Ben Ali. On 11 February, following weeks of determined popular protest and pressure, Hosni Mubarak resigned from office.\nPost-revolutionary Cairo.\nUnder the rule of President el-Sisi, in March 2015 plans were announced for another yet-unnamed planned city to be built further east of the existing satellite city of New Cairo, intended to serve as the new capital of Egypt.\nGeography.\nCairo is located in northern Egypt, known as Lower Egypt, south of the Mediterranean Sea and west of the Gulf of Suez and Suez Canal. The city lies along the Nile River, immediately south of the point where the river leaves its desert-bound valley and branches into the low-lying Nile Delta region. Although the Cairo metropolis extends away from the Nile in all directions, the city of Cairo resides only on the east bank of the river and two islands within it on a total area of . Geologically, Cairo lies on alluvium and sand dunes which date from the quaternary period.\nUntil the mid-19th century, when the river was tamed by dams, levees, and other controls, the Nile in the vicinity of Cairo was highly susceptible to changes in course and surface level. Over the years, the Nile gradually shifted westward, providing the site between the eastern edge of the river and the Mokattam highlands on which the city now stands. The land on which Cairo was established in 969 (present-day Islamic Cairo) was located underwater just over three hundred years earlier, when Fustat was first built.\nLow periods of the Nile during the 11th century continued to add to the landscape of Cairo; a new island, known as \"Geziret al-Fil\", first appeared in 1174, but eventually became connected to the mainland. Today, the site of \"Geziret al-Fil\" is occupied by the Shubra district. The low periods created another island at the turn of the 14th century that now composes Zamalek and Gezira. Land reclamation efforts by the Mamluks and Ottomans further contributed to expansion on the east bank of the river.\nBecause of the Nile's movement, the newer parts of the city\u2014Garden City, Downtown Cairo, and Zamalek\u2014are located closest to the riverbank. The areas, which are home to most of Cairo's embassies, are surrounded on the north, east, and south by the older parts of the city. Old Cairo, located south of the centre, holds the remnants of Fustat and the heart of Egypt's Coptic Christian community, Coptic Cairo. The Boulaq district, which lies in the northern part of the city, was born out of a major 16th-century port and is now a major industrial centre. The Citadel is located east of the city centre around Islamic Cairo, which dates back to the Fatimid era and the foundation of Cairo. While western Cairo is dominated by wide boulevards, open spaces, and modern architecture of European influence, the eastern half, having grown haphazardly over the centuries, is dominated by small lanes, crowded tenements, and Islamic architecture.\nNorthern and extreme eastern parts of Cairo, which include satellite towns, are among the most recent additions to the city, as they developed in the late-20th and early-21st centuries to accommodate the city's rapid growth. The western bank of the Nile is commonly included within the urban area of Cairo, but it composes the city of Giza and the Giza Governorate. Giza city has also undergone significant expansion over recent years, and today has a population of 2.7 million. The Cairo Governorate was just north of the Helwan Governorate from 2008 when some Cairo's southern districts, including Maadi and New Cairo, were split off and annexed into the new governorate, to 2011 when the Helwan Governorate was reincorporated into the Cairo Governorate.\nAccording to the World Health Organization, the level of air pollution in Cairo is nearly 12 times higher than the recommended safety level.\nClimate.\nIn Cairo, and along the Nile River Valley, the climate is a hot desert climate (\"BWh\" according to the K\u00f6ppen climate classification system).\nWind storms can be frequent, bringing Saharan dust into the city, from March to May and the air often becomes uncomfortably dry. Winters are mild to warm, while summers are long and hot. High temperatures in winter range from , while night-time lows drop to below , often to . In summer, the highs often exceed but rarely surpass , and lows drop to about . Rainfall is sparse and only happens in the colder months, but sudden showers can cause severe flooding. The summer months have high humidity due to its proximity to the Mediterranean coast. Snowfall is extremely rare; a small amount of graupel, widely believed to be snow, fell on Cairo's easternmost suburbs on 13 December 2013, the first time Cairo's area received this kind of precipitation in many decades. Dew points in the hottest months range from in June to in August.\nMetropolitan area and districts.\nThe city of Cairo forms part of Greater Cairo, the largest metropolitan area in Africa. While it has no administrative body, the Ministry of Planning considers it as an economic region consisting of Cairo Governorate, Giza Governorate, and Qalyubia Governorate. As a contiguous metropolitan area, various studies have considered Greater Cairo be composed of the administrative cities that are Cairo, Giza and Shubra al-Kheima, in addition to the satellite cities/new towns surrounding them.\nCairo is a city-state where the governor is also the head of the city. Cairo City itself differs from other Egyptian cities in that it has an extra administrative division between the city and district levels, and that is areas, which are headed by deputy governors. Cairo consists of 4 areas \"(manatiq, singl. mantiqa)\" divided into 38 districts \"(ahya', singl. hayy)\" and 46 qisms (police wards, 1-2 per district):\nThe Northern Area is divided into 8 Districts:\nThe Eastern Area divided into 9 Districts and three new cities:\nThe Western Area divided into 9 Districts:\nThe Southern Area divided into 12 Districts:\nSatellite cities.\nSince 1977 a number of new towns have been planned and built by the New Urban Communities Authority (NUCA) in the Eastern Desert around Cairo, ostensibly to accommodate additional population growth and development of the city and stem the development of self-built informal areas, especially over agricultural land. As of 2022 four new towns have been built and have residential populations: 15th of May City, Badr City, Shorouk City, and New Cairo. In addition, two more are under construction: the New Administrative Capital. And Capital Gardens, where land was allocated in 2021, and which will house most of the civil servants employed in the new capital.\nPlanned new capital.\nIn March 2015, plans were announced for a new city to be built east of Cairo, in an undeveloped area of the Cairo Governorate, which would serve as the New Administrative Capital of Egypt.\nDemographics.\nAccording to the 2017 census, Cairo had a population of 9,539,673 people, distributed across 46 qisms (police wards):\nReligion.\nThe majority of Egypt and Cairo's population is Sunni Muslim. A significant Christian minority exists, among whom Coptic Orthodox are the majority. Precise numbers for each religious community in Egypt are not available and estimates vary. Other churches that have, or had, a presence in modern Cairo include the Catholic Church (including Armenian Catholic, Coptic Catholic, Chaldean Catholic, Syrian Catholic, and Maronite), the Greek Orthodox Church, the Evangelical Church of Egypt (Synod of the Nile), and some Protestant churches. Cairo has been the seat of the Coptic Orthodox Church since the 12th century, and the seat of the Coptic Orthodox Pope is located in Saint Mark's Coptic Orthodox Cathedral.\nUntil the 20th century, Cairo had a sizeable Jewish community, but as of 2022 only three Jews were reported to be living in the city. A total of 12 synagogues in Cairo still exist.\nEconomy.\nCairo's economy has traditionally been based on governmental institutions and services, with the modern productive sector expanding in the 20th century to include developments in textiles and food processing \u2013 specifically the production of sugar cane. As of 2005, Egypt has the largest non-oil based GDP in the Arab world. \nCairo accounts for 11% of Egypt's population and 22% of its economy (PPP). The majority of the nation's commerce is generated there, or passes through the city. The great majority of publishing houses and media outlets and nearly all film studios are there, as are half of the nation's hospital beds and universities. This has fuelled rapid construction in the city, with one building in five being less than 15 years old.\nThis growth until recently surged well ahead of city services. Homes, roads, electricity, telephone and sewer services were all in short supply. Analysts trying to grasp the magnitude of the change coined terms like \"hyper-urbanization\".\nInfrastructure.\nHealth.\nCairo, as well as neighbouring Giza, has been established as Egypt's main centre for medical treatment, and despite some exceptions, has the most advanced level of medical care in the country. Cairo's hospitals include the JCI-accredited As-Salaam International Hospital, Ain Shams University Hospital, Dar Al Fouad, Nile Badrawi Hospital, 57357 Hospital, as well as Qasr El Eyni Hospital.\nEducation.\nGreater Cairo has long been the hub of education and educational services for Egypt and the region.\nToday, Greater Cairo is the centre for many government offices governing the Egyptian educational system, has the largest number of educational schools, and higher education institutes among other cities and governorates of Egypt.\nSome of the International Schools found in Cairo:\nUniversities in Greater Cairo:\nTransport.\nCairo has an extensive road network, rail system, subway system and maritime services. Road transport is facilitated by personal vehicles, taxi cabs, privately owned public buses and microbuses. Cairo International Airport is the country's largest airport and one of the busiest airports in Africa.\nPublic transportation.\nCairo, specifically Ramses Station, is the centre of almost the entire Egyptian transportation network.\nThe Cairo Transportation Authority (CTA) manages Cairo's public transit. The subway system, the Cairo Metro, is a fast and efficient way of getting around Cairo. The metro network covers Helwan and other suburbs. It can get very crowded during rush hour. Two train cars (the fourth and fifth ones) are reserved for women only, although women may ride in any car they want.\nTrams in Greater Cairo and Cairo trolleybus were used as modes of transportation, but were closed in the 1970s everywhere except Heliopolis and Helwan. These were shut down in 2014, after the Egyptian Revolution.\nIn 2017, plans to construct two monorail systems were announced, one linking 6th of October to suburban Giza, a distance of , and the other linking Nasr City to New Cairo, a distance of .\nRoads.\nTwo trans-African automobile routes originate in Cairo: the Cairo-Cape Town Highway and the Cairo-Dakar Highway. An extensive road network connects Cairo with other Egyptian cities and villages. There is a new Ring Road that surrounds the outskirts of the city, with exits that reach outer Cairo districts. There are flyovers and bridges, such as the 6th October Bridge that, when the traffic is not heavy, allow fast means of transportation from one side of the city to the other.\nCairo traffic is known to be overwhelming and overcrowded. Traffic moves at a relatively fluid pace. Drivers tend to be aggressive, but are more courteous at junctions, taking turns going, with police aiding in traffic control of some congested areas.\nCulture.\nCairo Opera House.\nPresident Mubarak inaugurated the new Cairo Opera House of the Egyptian National Cultural Centres on 10 October 1988, 17 years after the Royal Opera House had been destroyed by fire. The National Cultural Centre was built with the help of JICA, the Japan International Co-operation Agency and stands as a prominent feature for the Japanese-Egyptian co-operation and the friendship between the two nations.\nKhedivial Opera House.\nThe Khedivial Opera House, or Royal Opera House, was the original opera house in Cairo. It was dedicated on 1 November 1869 and burned down on 28 October 1971. After the original opera house was destroyed, Cairo was without an opera house for nearly two decades until the opening of the new Cairo Opera House in 1988.\nCairo International Film Festival.\nCairo held its first international film festival 16 August 1976, when the first Cairo International Film Festival was launched by the Egyptian Association of Film Writers and Critics, headed by Kamal El-Mallakh. The Association ran the festival for seven years until 1983.\nThis achievement lead to the President of the Festival again contacting the FIAPF with the request that a competition should be included at the 1991 Festival. The request was granted.\nIn 1998, the Festival took place under the presidency of one of Egypt's leading actors, Hussein Fahmy, who was appointed by the Minister of Culture, Farouk Hosni, after the death of Saad El-Din Wahba. Four years later, the journalist and writer Cherif El-Shoubashy became president.\nCairo Geniza.\nThe Cairo Geniza is an accumulation of almost 200,000 Jewish manuscripts that were found in the \"genizah\" of the Ben Ezra Synagogue (built 882) of Fustat, Egypt (now Old Cairo), the Basatin cemetery east of Old Cairo, and a number of old documents that were bought in Cairo in the later 19th century. These documents were written from about 870 to 1880 AD and have been archived in various American and European libraries. The Taylor-Schechter collection in the University of Cambridge runs to 140,000 manuscripts; a further 40,000 manuscripts are housed at the Jewish Theological Seminary of America.\nFood.\nThe majority of Cairenes make food for themselves and make use of local produce markets. The restaurant scene includes Arab cuisine and Middle Eastern cuisine, including local staples such as \"koshary\". The city's most exclusive restaurants are typically concentrated in Zamalek and around the luxury hotels lining the shore of the Nile near the Garden City district. Influence from modern western society is also evident, with American chains such as McDonald's, Arby's, Pizza Hut, Subway, and Kentucky Fried Chicken being easy to find in central areas.\nSports.\nFootball is the most popular sport in Egypt, and Cairo has sporting teams that compete in national and regional leagues, most notably Al Ahly and Zamalek SC, who were the CAF first and second African clubs of the 20th century. The annual match between Al Ahly and El Zamalek is one of the most watched sports events in Egypt. The teams form the major rivalry of Egyptian football. They play their home games at Cairo International Stadium, which is the second largest stadium in Egypt, as well as the largest in Cairo.\nThe Cairo International Stadium was built in 1960. Its multi-purpose sports complex houses the main football stadium, an indoor stadium, satellite fields that hold regional and continental games, including the African Games, U17 Football World Championship and the 2006 Africa Cup of Nations. Egypt later won the competition and the next edition in Ghana (2008) making the Egyptian and Ghanaian national teams the only to win the African Nations Cup back to back. Egypt won the title for a record six times in the history of African Continental Competition. This was followed by a third consecutive win in Angola in 2010, making Egypt the only country with a record 3-consecutive and 7-total Continental Football Competition winner. As of 2021, Egypt's national team is ranked #46 in the world by FIFA.\nCairo failed at the applicant stage when bidding for the 2008 Summer Olympics, which was hosted in Beijing. However, Cairo did host the 2007 Pan Arab Games.\nThere are other sports teams in the city that participate in several sports including Gezira Sporting Club, el Shams Club, Shooting Club, Heliopolis Sporting Club, and several smaller clubs. There are new sports clubs in the area of New Cairo (one hour far from Cairo's downtown), these are Al Zohour sporting club, Wadi Degla sporting club and Platinum Club.\nMost of the sports federations of the country are located in the city suburbs, including the Egyptian Football Association. The headquarters of the Confederation of African Football (CAF) was previously located in Cairo, before relocating to its new headquarters in 6 October City, a small city away from Cairo's crowded districts. In 2008, the Egyptian Rugby Federation was officially formed and granted membership into the International Rugby Board.\nEgypt is internationally known for the excellence of its squash players who excel in professional and junior divisions. Egypt has seven players in the top ten of the PSA men's world rankings, and three in the women's top ten. Mohamed El Shorbagy held the world number one position for more than a year. Nour El Sherbini has won the Women's World Championship twice and been women's world number one. On 30 April 2016, she became the youngest woman to win the Women's World Championship. In 2017 she retained her title.\nCairo is the official end point of Cross Egypt Challenge where its route ends yearly in the most sacred place in Egypt, under the Great Pyramids of Giza with a huge trophy-giving ceremony.\nCityscape and landmarks.\nTahrir Square.\nTahrir Square was founded during the mid 19th century with the establishment of modern downtown Cairo. It was first named Ismailia Square, after the 19th-century ruler Khedive Ismail, who commissioned the new downtown district's 'Paris on the Nile' design. After the Egyptian Revolution of 1919 the square became widely known as Tahrir (Liberation) Square, though it was not officially renamed as such until after the 1952 Revolution which eliminated the monarchy. Several notable buildings surround the square including, the American University in Cairo's downtown campus, the Mogamma governmental administrative Building, the headquarters of the Arab League, the Nile Ritz Carlton Hotel, and the Egyptian Museum. Being at the heart of Cairo, the square witnessed several major protests over the years. However, the most notable event in the square was being the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak. In 2020 the government completed the erection of a new monument in the center of the square featuring an ancient obelisk from the reign of Ramses II, originally unearthed at Tanis (San al-Hagar) in 2019, and four ram-headed sphinx statues moved from Karnak.\nEgyptian Museum.\nThe Museum of Egyptian Antiquities, known commonly as the Egyptian Museum, is home to the most extensive collection of ancient Egyptian antiquities in the world. It has 136,000 items on display, with many more hundreds of thousands in its basement storerooms. Among the collections on display are the finds from the tomb of Tutankhamun.\nGrand Egyptian Museum.\nMuch of the collection of the Museum of Egyptian Antiquities, including the Tutankhamun collection, are slated to be moved to the new Grand Egyptian Museum, under construction in Giza and was due to open by the end of 2020.\nCairo Tower.\nThe Cairo Tower is a free-standing tower with a revolving restaurant at the top. It is one of Cairo's landmarks and provides a bird's eye view of the city to the restaurant patrons. It stands in the Zamalek district on Gezira Island in the Nile River, in the city centre. At , it is higher than the Great Pyramid of Giza, which stands some to the southwest.\nOld Cairo.\nThis area of Cairo is so-named as it contains the remains of the ancient Roman fortress of Babylon and also overlaps the original site of Fustat, the first Arab settlement in Egypt (7th century AD) and the predecessor of later Cairo. The area includes Coptic Cairo, which holds a high concentration of old Christian churches such as the Hanging Church, the Greek Orthodox Church of St. George, and other Christian or Coptic buildings, most of which are located in an enclave on the site of the ancient Roman fortress. It is also the location of the Coptic Museum, which showcases the history of Coptic art from Greco-Roman to Islamic times, and of the Ben Ezra Synagogue, the oldest and best-known synagogue in Cairo, where the important collection of Geniza documents were discovered in the 19th century.\nTo the north of this Coptic enclave is the Amr ibn al-'As Mosque, the first mosque in Egypt and the most important religious centre of what was formerly Fustat, founded in 642 AD right after the Arab conquest but rebuilt many times since. A part of the former city of Fustat has also been excavated to the east of the mosque and of the Coptic enclave, although the archeological site is threatened by encroaching construction and modern development. To the northwest of Babylon Fortress and the mosque is the Monastery of Saint Mercurius (or \"Dayr Abu Sayfayn\"), an important and historic Coptic religious complex consisting of the Church of Saint Mercurius, the Church of Saint Shenute, and the Church of the Virgin (also known as \"al-Damshiriya\"). Several other historic churches are also situated to the south of Babylon Fortress.\nIslamic Cairo.\nCairo holds one of the greatest concentrations of historical monuments of Islamic architecture in the world. The areas around the old walled city and around the Citadel are characterized by hundreds of mosques, tombs, madrasas, mansions, caravanserais, and fortifications dating from the Islamic era and are often referred to as \"Islamic Cairo\", especially in English travel literature. It is also the location of several important religious shrines such as the al-Hussein Mosque (whose shrine is believed to hold the head of Husayn ibn Ali), the Mausoleum of Imam al-Shafi'i (founder of the Shafi'i \"madhhab\", one of the primary schools of thought in Sunni Islamic jurisprudence), the Tomb of Sayyida Ruqayya, the Mosque of Sayyida Nafisa, and others.\nThe first mosque in Egypt was the Mosque of Amr ibn al-As in what was formerly Fustat, the first Arab-Muslim settlement in the area. However, the Mosque of Ibn Tulun is the oldest mosque that still retains its original form and is a rare example of Abbasid architecture from the classical period of Islamic civilization. It was built in 876\u2013879 AD in a style inspired by the Abbasid capital of Samarra in Iraq. It is one of the largest mosques in Cairo and is often cited as one of the most beautiful. Another Abbasid construction, the Nilometer on Roda Island, is the oldest original structure in Cairo, built in 862 AD. It was designed to measure the level of the Nile, which was important for agricultural and administrative purposes.\nThe settlement that was formally named Cairo (Arabic: \"al-Qahira\") was founded to the northeast of Fustat in 959 AD by the victorious Fatimid army. The Fatimids built it as a separate palatial city which contained their palaces and institutions of government. It was enclosed by a circuit of walls, which were rebuilt in stone in the late 11th century AD by the vizier Badr al-Gamali, parts of which survive today at Bab Zuwayla in the south and Bab al-Futuh and Bab al-Nasr in the north. Among the extant monuments from the Fatimid era are the large Mosque of al-Hakim, the Aqmar Mosque, Juyushi Mosque, Lulua Mosque, and the Mosque of Al-Salih Tala'i.\nOne of the most important and lasting institutions founded in the Fatimid period was the Mosque of al-Azhar, founded in 970 AD, which competes with the Qarawiyyin in Fes for the title of oldest university in the world. Today, al-Azhar University is the foremost Center of Islamic learning in the world and one of Egypt's largest universities with campuses across the country. The mosque itself retains significant Fatimid elements but has been added to and expanded in subsequent centuries, notably by the Mamluk sultans Qaytbay and al-Ghuri and by Abd al-Rahman Katkhuda in the 18th century.\nThe most prominent architectural heritage of medieval Cairo, however, dates from the Mamluk period, from 1250 to 1517 AD. The Mamluk sultans and elites were eager patrons of religious and scholarly life, commonly building religious or funerary complexes whose functions could include a mosque, madrasa, khanqah (for Sufis), a sabil (water dispensary), and a mausoleum for themselves and their families. Among the best-known examples of Mamluk monuments in Cairo are the huge Mosque-Madrasa of Sultan Hasan, the Mosque of Amir al-Maridani, the Mosque of Sultan al-Mu'ayyad (whose twin minarets were built above the gate of Bab Zuwayla), the Sultan Al-Ghuri complex, the funerary complex of Sultan Qaytbay in the Northern Cemetery, and the trio of monuments in the Bayn al-Qasrayn area comprising the complex of Sultan al-Mansur Qalawun, the Madrasa of al-Nasir Muhammad, and the Madrasa of Sultan Barquq. Some mosques include spolia (often columns or capitals) from earlier buildings built by the Romans, Byzantines, or Copts.\nThe Mamluks, and the later Ottomans, also built \"wikala\"s or caravanserais to house merchants and goods due to the important role of trade and commerce in Cairo's economy. Still intact today is the Wikala al-Ghuri, which today hosts regular performances by the Al-Tannoura Egyptian Heritage Dance Troupe. The Khan al-Khalili is a commercial hub which also integrated caravanserais (also known as \"khan\"s).\nCitadel of Cairo.\nThe Citadel is a fortified enclosure begun by Salah al-Din in 1176 AD on an outcrop of the Muqattam Hills as part of a large defensive system to protect both Cairo to the north and Fustat to the southwest. It was the centre of Egyptian government and residence of its rulers until 1874, when Khedive Isma'il moved to 'Abdin Palace. It is still occupied by the military today, but is now open as a tourist attraction comprising, notably, the National Military Museum, the 14th century Mosque of al-Nasir Muhammad, and the 19th century Mosque of Muhammad Ali which commands a dominant position on Cairo's skyline.\nKhan el-Khalili.\nKhan el-Khalili is an ancient bazaar, or marketplace adjacent to the Al-Hussein Mosque. It dates back to 1385, when Amir Jarkas el-Khalili built a large caravanserai, or khan. (A caravanserai is a hotel for traders, and usually the focal point for any surrounding area.) This original caravanserai building was demolished by Sultan al-Ghuri, who rebuilt it as a new commercial complex in the early 16th century, forming the basis for the network of souqs existing today. Many medieval elements remain today, including the ornate Mamluk-style gateways. Today, the Khan el-Khalili is a major tourist attraction and popular stop for tour groups.\nSociety.\nIn the present day, Cairo is a heavily urbanized city. Because of the influx of people into the city, lone standing houses are rare, and apartment buildings accommodate for the limited space and abundance of people. Single detached houses are usually owned by the wealthy. Formal education is also seen as important, with twelve years of standard formal education. Cairenes can take a standardized test similar to the SAT to be accepted to an institution of higher learning, but most children do not finish school and opt to pick up a trade to enter the work force. Egypt still struggles with poverty, with almost half the population living on $2 or less a day.\nWomen's rights.\nThe civil rights movement for women in Cairo \u2013 and by extent, Egypt \u2013 has been a struggle for years. Women are reported to face constant discrimination, sexual harassment, and abuse throughout Cairo. A 2013 UN study found that over 99% of Egyptian women reported experiencing sexual harassment at some point in their lives. The problem has persisted in spite of new national laws since 2014 defining and criminalizing sexual harassment. The situation is so severe that in 2017, Cairo was named by one poll as the most dangerous megacity for women in the world. In 2020, the social media account \"Assault Police\" began to name and shame perpetrators of violence against women, in an effort to dissuade potential offenders. The account was founded by student Nadeen Ashraf, who is credited for instigating an iteration of the #MeToo movement in Egypt.\nPollution.\nThe air pollution in Cairo is a matter of serious concern. Greater Cairo's volatile aromatic hydrocarbon levels are higher than many other similar cities. Air quality measurements in Cairo have also been recording dangerous levels of lead, carbon dioxide, sulphur dioxide, and suspended particulate matter concentrations due to decades of unregulated vehicle emissions, urban industrial operations, and chaff and trash burning. There are over 4,500,000 cars on the streets of Cairo, 60% of which are over 10 years old, and therefore lack modern emission cutting features. Cairo has a very poor dispersion factor because of its lack of rain and its layout of tall buildings and narrow streets, which create a bowl effect.\nIn recent years, a black cloud (as Egyptians refer to it) of smog has appeared over Cairo every autumn due to temperature inversion. Smog causes serious respiratory diseases and eye irritations for the city's citizens. Tourists who are not familiar with such high levels of pollution must take extra care.\nCairo also has many unregistered lead and copper smelters which heavily pollute the city. The results of this has been a permanent haze over the city with particulate matter in the air reaching over three times normal levels. It is estimated that 10,000 to 25,000 people a year in Cairo die due to air pollution-related diseases. Lead has been shown to cause harm to the central nervous system and neurotoxicity particularly in children. In 1995, the first environmental acts were introduced and the situation has seen some improvement with 36 air monitoring stations and emissions tests on cars. Twenty thousand buses have also been commissioned to the city to improve congestion levels, which are very high.\nThe city also suffers from a high level of land pollution. Cairo produces 10,000 tons of waste material each day, 4,000 tons of which is not collected or managed. This is a huge health hazard, and the Egyptian Government is looking for ways to combat this. The Cairo Cleaning and Beautification Agency was founded to collect and recycle the waste; they work with the Zabbaleen community that has been collecting and recycling Cairo's waste since the turn of the 20th century and live in an area known locally as Manshiyat naser. Both are working together to pick up as much waste as possible within the city limits, though it remains a pressing problem.\nWater pollution is also a serious problem in the city as the sewer system tends to fail and overflow. On occasion, sewage has escaped onto the streets to create a health hazard. This problem is hoped to be solved by a new sewer system funded by the European Union, which could cope with the demand of the city. The dangerously high levels of mercury in the city's water system has global health officials concerned over related health risks.\nInternational relations.\nThe Headquarters of the Arab League is located at Tahrir Square in downtown Cairo.\nTwin towns \u2013 sister cities.\nCairo is twinned with:"}
{"id": "6295", "revid": "15534", "url": "https://en.wikipedia.org/wiki?curid=6295", "title": "Chaos theory", "text": "Chaos theory (or chaology) is an interdisciplinary area of scientific study and branch of mathematics. It focuses on underlying patterns and deterministic laws of dynamical systems that are highly sensitive to initial conditions. These were once thought to have completely random states of disorder and irregularities. Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnection, constant feedback loops, repetition, self-similarity, fractals and self-organization. The butterfly effect, an underlying principle of chaos, describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state (meaning there is sensitive dependence on initial conditions). A metaphor for this behavior is that a butterfly flapping its wings in Brazil can cause a tornado in Texas.\nSmall differences in initial conditions, such as those due to errors in measurements or due to rounding errors in numerical computation, can yield widely diverging outcomes for such dynamical systems, rendering long-term prediction of their behavior impossible in general. This can happen even though these systems are deterministic, meaning that their future behavior follows a unique evolution and is fully determined by their initial conditions, with no random elements involved. In other words, the deterministic nature of these systems does not make them predictable. This behavior is known as deterministic chaos, or simply chaos. The theory was summarized by Edward Lorenz as:\nChaotic behavior exists in many natural systems, including fluid flow, heartbeat irregularities, weather and climate. It also occurs spontaneously in some systems with artificial components, such as road traffic. This behavior can be studied through the analysis of a chaotic mathematical model or through analytical techniques such as recurrence plots and Poincar\u00e9 maps. Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, environmental science, computer science, engineering, economics, ecology, and pandemic crisis management. The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory and self-assembly processes.\nIntroduction.\nChaos theory concerns deterministic systems whose behavior can, in principle, be predicted. Chaotic systems are predictable for a while and then 'appear' to become random. The amount of time for which the behavior of a chaotic system can be effectively predicted depends on three things: how much uncertainty can be tolerated in the forecast, how accurately its current state can be measured, and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, about 1 millisecond; weather systems, a few days (unproven); the inner solar system, 4 to 5 million years. In chaotic systems, the uncertainty in a forecast increases exponentially with elapsed time. Hence, mathematically, doubling the forecast time more than squares the proportional uncertainty in the forecast. This means, in practice, a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears random.\nChaotic dynamics.\nIn common usage, \"chaos\" means \"a state of disorder\". However, in chaos theory, the term is defined more precisely. Although no universally accepted mathematical definition of chaos exists, a commonly used definition, originally formulated by Robert L. Devaney, says that to classify a dynamical system as chaotic, it must have these properties:\nIn some cases, the last two properties above have been shown to actually imply sensitivity to initial conditions. In the discrete-time case, this is true for all continuous maps on metric spaces. In these cases, while it is often the most practically significant property, \"sensitivity to initial conditions\" need not be stated in the definition.\nIf attention is restricted to intervals, the second property implies the other two. An alternative and a generally weaker definition of chaos uses only the first two properties in the above list.\nSensitivity to initial conditions.\nSensitivity to initial conditions means that each point in a chaotic system is arbitrarily closely approximated by other points that have significantly different future paths or trajectories. Thus, an arbitrarily small change or perturbation of the current trajectory may lead to significantly different future behavior.\nSensitivity to initial conditions is popularly known as the \"butterfly effect\", so-called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C., entitled \"Predictability: Does the Flap of a Butterfly's Wings in Brazil set off a Tornado in Texas?\". The flapping wing represents a small change in the initial condition of the system, which causes a chain of events that prevents the predictability of large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the overall system could have been vastly different.\nAs suggested in Lorenz's book entitled \"The Essence of Chaos\", published in 1993, \"sensitive dependence can serve as an acceptable definition of chaos\". In the same book, Lorenz defined the butterfly effect as: \"The phenomenon that a small alteration in the state of a dynamical system will cause subsequent states to differ greatly from the states that would have followed without the alteration.\" The above definition is consistent with the sensitive dependence of solutions on initial conditions (SDIC). An idealized skiing model was developed to illustrate the sensitivity of time-varying paths to initial positions. A predictability horizon can be determined before the onset of SDIC (i.e., prior to significant separations of initial nearby trajectories).\nA consequence of sensitivity to initial conditions is that if we start with a limited amount of information about the system (as is usually the case in practice), then beyond a certain time, the system would no longer be predictable. This is most prevalent in the case of weather, which is generally predictable only about a week ahead. This does not mean that one cannot assert anything about events far in the future\u2014only that some restrictions on the system are present. For example, we know that the temperature of the surface of the earth will not naturally reach or fall below on earth (during the current geologic era), but we cannot predict exactly which day will have the hottest temperature of the year.\nIn more mathematical terms, the Lyapunov exponent measures the sensitivity to initial conditions, in the form of rate of exponential divergence from the perturbed initial conditions. More specifically, given two starting trajectories in the phase space that are infinitesimally close, with initial separation formula_1, the two trajectories end up diverging at a rate given by\nwhere formula_3 is the time and formula_4 is the Lyapunov exponent. The rate of separation depends on the orientation of the initial separation vector, so a whole spectrum of Lyapunov exponents can exist. The number of Lyapunov exponents is equal to the number of dimensions of the phase space, though it is common to just refer to the largest one. For example, the maximal Lyapunov exponent (MLE) is most often used, because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.\nIn addition to the above property, other properties related to sensitivity of initial conditions also exist. These include, for example, measure-theoretical mixing (as discussed in ergodic theory) and properties of a K-system.\nNon-periodicity.\nA chaotic system may have sequences of values for the evolving variable that exactly repeat themselves, giving periodic behavior starting from any point in that sequence. However, such periodic sequences are repelling rather than attracting, meaning that if the evolving variable is outside the sequence, however close, it will not enter the sequence and in fact, will diverge from it. Thus for almost all initial conditions, the variable evolves chaotically with non-periodic behavior.\nTopological mixing.\nTopological mixing (or the weaker condition of topological transitivity) means that the system evolves over time so that any given region or open set of its phase space eventually overlaps with any other given region. This mathematical concept of \"mixing\" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.\nTopological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points eventually becomes widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 tend to positive or negative infinity.\nTopological transitivity.\nA map formula_5 is said to be topologically transitive if for any pair of non-empty open sets formula_6, there exists formula_7 such that formula_8. Topological transitivity is a weaker version of topological mixing. Intuitively, if a map is topologically transitive then given a point \"x\" and a region \"V\", there exists a point \"y\" near \"x\" whose orbit passes through \"V\". This implies that it is impossible to decompose the system into two open sets.\nAn important related theorem is the Birkhoff Transitivity Theorem. It is easy to see that the existence of a dense orbit implies topological transitivity. The Birkhoff Transitivity Theorem states that if \"X\" is a second countable, complete metric space, then topological transitivity implies the existence of a dense set of points in \"X\" that have dense orbits.\nDensity of periodic orbits.\nFor a chaotic system to have dense periodic orbits means that every point in the space is approached arbitrarily closely by periodic orbits. The one-dimensional logistic map defined by \"x\" \u2192 4 \"x\" (1 \u2013 \"x\") is one of the simplest systems with density of periodic orbits. For example, formula_9\u00a0\u2192 formula_10\u00a0\u2192 formula_9 (or approximately 0.3454915\u00a0\u2192 0.9045085\u00a0\u2192 0.3454915) is an (unstable) orbit of period 2, and similar orbits exist for periods 4, 8, 16, etc. (indeed, for all the periods specified by Sharkovskii's theorem).\nSharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any continuous one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length, as well as completely chaotic orbits.\nStrange attractors.\nSome dynamical systems, like the one-dimensional logistic map defined by \"x\" \u2192 4 \"x\" (1 \u2013 \"x\"), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions leads to orbits that converge to this chaotic region.\nAn easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor. This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it is not only one of the first, but it is also one of the most complex, and as such gives rise to a very interesting pattern that, with a little imagination, looks like the wings of a butterfly.\nUnlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as strange attractors, have great detail and complexity. Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the H\u00e9non map). Other discrete dynamical systems have a repelling structure called a Julia set, which forms at the boundary between basins of attraction of fixed points. Julia sets can be thought of as strange repellers. Both strange attractors and Julia sets typically have a fractal structure, and the fractal dimension can be calculated for them.\nCoexisting attractors.\nIn contrast to single type chaotic solutions, recent studies using Lorenz models have emphasized the importance of considering various types of solutions. For example, coexisting chaotic and non-chaotic may appear within the same model (e.g., the double pendulum system) using the same modeling configurations but different initial conditions. The findings of attractor coexistence, obtained from classical and generalized Lorenz models, suggested a revised view that \"the entirety of weather possesses a dual nature of chaos and order with distinct predictability\", in contrast to the conventional view of \"weather is chaotic\".\nMinimum complexity of a chaotic system.\nDiscrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. In contrast, for continuous dynamical systems, the Poincar\u00e9\u2013Bendixson theorem shows that a strange attractor can only arise in three or more dimensions. Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it must be either nonlinear or infinite-dimensional.\nThe Poincar\u00e9\u2013Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed below is generated by a system of three differential equations such as:\nwhere formula_13, formula_14, and formula_15 make up the system state, formula_3 is time, and formula_17, formula_18, formula_19 are the system parameters. Five of the terms on the right hand side are linear, while two are quadratic; a total of seven terms. Another well-known chaotic attractor is generated by the R\u00f6ssler equations, which have only one nonlinear term out of seven. Sprott found a three-dimensional system with just five terms, that had only one nonlinear term, which exhibits chaos for certain parameter values. Zhang and Heidel showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior. The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.\nWhile the Poincar\u00e9\u2013Bendixson theorem shows that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can still exhibit some chaotic properties. Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite dimensional. A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.\nThe above set of three ordinary differential equations has been referred to as the three-dimensional Lorenz model. Since 1963, higher-dimensional Lorenz models have been developed in numerous studies for examining the impact of an increased degree of nonlinearity, as well as its collective effect with heating and dissipations, on solution stability.\nInfinite dimensional maps.\nThe straightforward generalization of coupled discrete maps is based upon convolution integral which mediates interaction between spatially distributed maps:\nformula_20,\nwhere kernel formula_21 is propagator derived as Green function of a relevant physical system,\nformula_22 might be logistic map alike formula_23 or complex map. For examples of complex maps the Julia set formula_24 or Ikeda map\nformula_25 may serve. When wave propagation problems at distance formula_26 with wavelength formula_27 are considered the kernel formula_28 may have a form of Green function for Schr\u00f6dinger equation:.\nformula_29.\nJerk systems.\nIn physics, jerk is the third derivative of position, with respect to time. As such, differential equations of the form\nare sometimes called \"jerk equations\". It has been shown that a jerk equation, which is equivalent to a system of three first order, ordinary, non-linear differential equations, is in a certain sense the minimal setting for solutions showing chaotic behavior. This motivates mathematical interest in jerk systems. Systems involving a fourth or higher derivative are called accordingly hyperjerk systems.\nA jerk system's behavior is described by a jerk equation, and for certain jerk equations, simple electronic circuits can model solutions. These circuits are known as jerk circuits.\nOne of the most interesting properties of jerk circuits is the possibility of chaotic behavior. In fact, certain well-known chaotic systems, such as the Lorenz attractor and the R\u00f6ssler map, are conventionally described as a system of three first-order differential equations that can combine into a single (although rather complicated) jerk equation. Another example of a jerk equation with nonlinearity in the magnitude of formula_13 is:\nHere, \"A\" is an adjustable parameter. This equation has a chaotic solution for \"A\"=3/5 and can be implemented with the following jerk circuit; the required nonlinearity is brought about by the two diodes:\nIn the above circuit, all resistors are of equal value, except formula_33, and all capacitors are of equal size. The dominant frequency is formula_34. The output of op amp 0 will correspond to the x variable, the output of 1 corresponds to the first derivative of x and the output of 2 corresponds to the second derivative.\nSimilar circuits only require one diode or no diodes at all.\nSee also the well-known Chua's circuit, one basis for chaotic true random number generators. The ease of construction of the circuit has made it a ubiquitous real-world example of a chaotic system.\nSpontaneous order.\nUnder the right conditions, chaos spontaneously evolves into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.\nExamples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millennium Bridge resonance, and large arrays of Josephson junctions.\nMoreover, from the theoretical physics standpoint, dynamical chaos itself, in its most general manifestation, is a spontaneous order. The essence here is that most orders in nature arise from the spontaneous breakdown of various symmetries. This large family of phenomena includes elasticity, superconductivity, ferromagnetism, and many others. According to the supersymmetric theory of stochastic dynamics, chaos, or more precisely, its stochastic generalization, is also part of this family. The corresponding symmetry being broken is the topological supersymmetry which is hidden in all stochastic (partial) differential equations, and the corresponding order parameter is a field-theoretic embodiment of the butterfly effect.\nHistory.\nJames Clerk Maxwell first emphasized the \"butterfly effect\", and is seen as being one of the earliest to discuss chaos theory, with work in the 1860s and 1870s. An early proponent of chaos theory was Henri Poincar\u00e9. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. In 1898, Jacques Hadamard published an influential study of the chaotic motion of a free particle gliding frictionlessly on a surface of constant negative curvature, called \"Hadamard's billiards\". Hadamard was able to show that all trajectories are unstable, in that all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.\nChaos theory began in the field of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff, Andrey Nikolaevich Kolmogorov, Mary Lucy Cartwright and John Edensor Littlewood, and Stephen Smale. Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.\nDespite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple \"noise\" was considered by chaos theorists as a full component of the studied systems. In 1959 Boris Valerianovich Chirikov proposed a criterion for the emergence of classical chaos in Hamiltonian systems (Chirikov criterion). He applied this criterion to explain some experimental results on plasma confinement in open mirror traps. This is regarded as the very first physical theory of chaos, which succeeded in explaining a concrete experiment. And Boris Chirikov himself is considered as a pioneer in classical and quantum chaos.\nThe main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on November 27, 1961, what he called \"randomly transitional phenomena\". Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.\nEdward Lorenz was an early pioneer of the theory. His interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz and his collaborator Ellen Fetter and Margaret Hamilton were using a simple digital computer, a Royal McBee LGP-30, to run weather simulations. They wanted to see a sequence of data again, and to save time they started the simulation in the middle of its course. They did this by entering a printout of the data that corresponded to conditions in the middle of the original simulation. To their surprise, the weather the machine began to predict was completely different from the previous calculation. They tracked this down to the computer printout. The computer worked with 6-digit precision, but the printout rounded variables off to a 3-digit number, so a value like 0.506127 printed as 0.506. This difference is tiny, and the consensus at the time would have been that it should have no practical effect. However, Lorenz discovered that small changes in initial conditions produced large changes in long-term outcome. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modeling cannot, in general, make precise long-term weather predictions.\nIn 1963, Benoit Mandelbrot, studying information theory, discovered that noise in many phenomena (including stock prices and telephone circuits) was patterned like a Cantor set, a set of points with infinite roughness and detail Mandelbrot described both the \"Noah effect\" (in which sudden discontinuous changes can occur) and the \"Joseph effect\" (in which persistence of a value can occur for a while, yet suddenly change afterwards). In 1967, he published \"How long is the coast of Britain? Statistical self-similarity and fractional dimension\", showing that a coastline's length varies with the scale of the measuring instrument, resembles itself at all scales, and is infinite in length for an infinitesimally small measuring device. Arguing that a ball of twine appears as a point when viewed from far away (0-dimensional), a ball when viewed from fairly near (3-dimensional), or a curved strand (1-dimensional), he argued that the dimensions of an object are relative to the observer and may be fractional. An object whose irregularity is constant over different scales (\"self-similarity\") is a fractal (examples include the Menger sponge, the Sierpi\u0144ski gasket, and the Koch curve or \"snowflake\", which is infinitely long yet encloses a finite space and has a fractal dimension of circa 1.2619). In 1982, Mandelbrot published \"The Fractal Geometry of Nature\", which became a classic of chaos theory.\nIn December 1977, the New York Academy of Sciences organized the first symposium on chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term \"chaos\" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year Pierre Coullet and Charles Tresser published \"It\u00e9rations d'endomorphismes et groupe de renormalisation\", and Mitchell Feigenbaum's article \"Quantitative Universality for a Class of Nonlinear Transformations\" finally appeared in a journal, after 3 years of referee rejections. Thus Feigenbaum (1975) and Coullet &amp; Tresser (1978) discovered the universality in chaos, permitting the application of chaos theory to many different phenomena.\nIn 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh\u2013B\u00e9nard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum for their inspiring achievements.\nIn 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking dysfunction among people with schizophrenia. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.\nIn 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in \"Physical Review Letters\" describing for the first time self-organized criticality (SOC), considered one of the mechanisms by which complexity arises in nature.\nAlongside largely lab-based approaches such as the Bak\u2013Tang\u2013Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes, (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg\u2013Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of \"punctuated equilibria\" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.\nAlso in 1987 James Gleick published \"\", which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public. Initially the domain of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in \"The Structure of Scientific Revolutions\" (1962), many \"chaologists\" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.\nThe availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory remains an active area of research, involving many different disciplines such as mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, pandemic crisis management, etc.\nLorenz's pioneering contributions to chaotic modeling.\nThroughout his career, Professor Edward Lorenz authored a total of 61 research papers, out of which 58 were solely authored by him. Commencing with the 1960 conference in Japan, Lorenz embarked on a journey of developing diverse models aimed at uncovering the SDIC and chaotic features. A recent review of Lorenz's model progression spanning from 1960 to 2008 revealed his adeptness at employing varied physical systems to illustrate chaotic phenomena. These systems encompassed Quasi-geostrophic systems, the Conservative Vorticity Equation, the Rayleigh-B\u00e9nard Convection Equations, and the Shallow Water Equations. Moreover, Lorenz can be credited with the early application of the logistic map to explore chaotic solutions, a milestone he achieved ahead of his colleagues (e.g. Lorenz 1964).\nIn 1972, Lorenz coined the term \"butterfly effect\" as a metaphor to discuss whether a small perturbation could eventually create a tornado with a three-dimensional, organized, and coherent structure. While connected to the original butterfly effect based on sensitive dependence on initial conditions, its metaphorical variant carries distinct nuances. To commemorate this milestone, a reprint book containing invited papers that deepen our understanding of both butterfly effects was officially published to celebrate the 50th anniversary of the metaphorical butterfly effect.\nA popular but inaccurate analogy for chaos.\nThe sensitive dependence on initial conditions (i.e., butterfly effect) has been illustrated using the following folklore:\n&lt;poem style=\"margin-left: 2em;\"&gt;\nFor want of a nail, the shoe was lost.\nFor want of a shoe, the horse was lost.\nFor want of a horse, the rider was lost.\nFor want of a rider, the battle was lost.\nFor want of a battle, the kingdom was lost.\nAnd all for the want of a horseshoe nail.\n&lt;/poem&gt;\nBased on the above, many people mistakenly believe that the impact of a tiny initial perturbation monotonically increases with time and that any tiny perturbation can eventually produce a large impact on numerical integrations. However, in 2008, Lorenz stated that he did not feel that this verse described true chaos but that it better illustrated the simpler phenomenon of instability and that the verse implicitly suggests that subsequent small events will not reverse the outcome. Based on the analysis, the verse only indicates divergence, not boundedness. Boundedness is important for the finite size of a butterfly pattern. In a recent study, the characteristic of the aforementioned verse was recently denoted as \"finite-time sensitive dependence\".\nApplications.\nAlthough chaos theory was born from observing weather patterns, it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, biology, computer science, economics, engineering, finance, meteorology, philosophy, anthropology, physics, politics, population dynamics, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing.\nCryptography.\nChaos theory has been used for many years in cryptography. In the past few decades, chaos and nonlinear dynamics have been used in the design of hundreds of cryptographic primitives. These algorithms include image encryption algorithms, hash functions, secure pseudo-random number generators, stream ciphers, watermarking, and steganography. The majority of these algorithms are based on uni-modal chaotic maps and a big portion of these algorithms use the control parameters and the initial condition of the chaotic maps as their keys. From a wider perspective, without loss of generality, the similarities between the chaotic maps and the cryptographic systems is the main motivation for the design of chaos based cryptographic algorithms. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a way to encrypt images and other information. Many of the DNA-Chaos cryptographic algorithms are proven to be either not secure, or the technique applied is suggested to be not efficient.\nRobotics.\nRobotics is another area that has recently benefited from chaos theory. Instead of robots acting in a trial-and-error type of refinement to interact with their environment, chaos theory has been used to build a predictive model.\nChaotic dynamics have been exhibited by passive walking biped robots.\nBiology.\nFor over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are continuous, but recently scientists have been able to implement chaotic models in certain populations. For example, a study on models of Canadian lynx showed there was chaotic behavior in the population growth. Chaos can also be found in ecological systems, such as hydrology. While a chaotic model for hydrology has its shortcomings, there is still much to learn from looking at the data through the lens of chaos theory. Another biological application is found in cardiotocography. Fetal surveillance is a delicate balance of obtaining accurate information while being as noninvasive as possible. Better models of warning signs of fetal hypoxia can be obtained through chaotic modeling.\nAs Perry points out, modeling of chaotic time series in ecology is helped by constraint. There is always potential difficulty in distinguishing real chaos from chaos that is only in the model. Hence both constraint in the model and or duplicate time series data for comparison will be helpful in constraining the model to something close to the reality, for example Perry &amp; Wall 1984. Gene-for-gene co-evolution sometimes shows chaotic dynamics in allele frequencies. Adding variables exaggerates this: Chaos is more common in models incorporating additional variables to reflect additional facets of real populations. Robert M. May himself did some of these foundational crop co-evolution studies, and this in turn helped shape the entire field. Even for a steady environment, merely combining one crop and one pathogen may result in quasi-periodic- or chaotic- oscillations in pathogen population.\nEconomics.\nIt is possible that economic models can also be improved through an application of chaos theory, but predicting the health of an economic system and what factors influence it most is an extremely complex task. Economic and financial systems are fundamentally different from those in the classical natural sciences since the former are inherently stochastic in nature, as they result from the interactions of people, and thus pure deterministic models are unlikely to provide accurate representations of the data. The empirical literature that tests for chaos in economics and finance presents very mixed results, in part due to confusion between specific tests for chaos and more general tests for non-linear relationships.\nChaos could be found in economics by the means of recurrence quantification analysis. In fact, Orlando et al. by the means of the so-called recurrence quantification correlation index were able detect hidden changes in time series. Then, the same technique was employed to detect transitions from laminar (regular) to turbulent (chaotic) phases as well as differences between macroeconomic variables and highlight hidden features of economic dynamics. Finally, chaos theory could help in modeling how an economy operates as well as in embedding shocks due to external events such as COVID-19.\nFinite predictability in weather and climate.\nDue to the sensitive dependence of solutions on initial conditions (SDIC), also known as the butterfly effect, chaotic systems like the Lorenz 1963 model imply a finite predictability horizon. This means that while accurate predictions are possible over a finite time period, they are not feasible over an infinite time span. Considering the nature of Lorenz's chaotic solutions, the committee led by Charney et al. in 1966 extrapolated a doubling time of five days from a general circulation model, suggesting a predictability limit of two weeks. This connection between the five-day doubling time and the two-week predictability limit was also recorded in a 1969 report by the Global Atmospheric Research Program (GARP). To acknowledge the combined direct and indirect influences from the Mintz and Arakawa model and Lorenz's models, as well as the leadership of Charney et al., Shen et al. refer to the two-week predictability limit as the \"Predictability Limit Hypothesis,\" drawing an analogy to Moore's Law.\nAI-extended modeling framework.\nIn AI-driven large language models, responses can exhibit sensitivities to factors like alterations in formatting and variations in prompts. These sensitivities are akin to butterfly effects. Although classifying AI-powered large language models as classical deterministic chaotic systems poses challenges, chaos-inspired approaches and techniques (such as ensemble modeling) may be employed to extract reliable information from these expansive language models (see also \"Butterfly Effect in Popular Culture\").\nOther areas.\nIn chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck. In celestial mechanics, especially when observing asteroids, applying chaos theory leads to better predictions about when these objects will approach Earth and other planets. Four of the five moons of Pluto rotate chaotically. In quantum physics and electrical engineering, the study of large arrays of Josephson junctions benefitted greatly from chaos theory. Closer to home, coal mines have always been dangerous places where frequent natural gas leaks cause many deaths. Until recently, there was no reliable way to predict when they would occur. But these gas leaks have chaotic tendencies that, when properly modeled, can be predicted fairly accurately.\nChaos theory can be applied outside of the natural sciences, but historically nearly all such studies have suffered from lack of reproducibility; poor external validity; and/or inattention to cross-validation, resulting in poor predictive accuracy (if out-of-sample prediction has even been attempted). Glass and Mandell and Selz have found that no EEG study has as yet indicated the presence of strange attractors or other signs of chaotic behavior.\nRedington and Reidbord (1992) attempted to demonstrate that the human heart could display chaotic traits. They monitored the changes in between-heartbeat intervals for a single psychotherapy patient as she moved through periods of varying emotional intensity during a therapy session. Results were admittedly inconclusive. Not only were there ambiguities in the various plots the authors produced to purportedly show evidence of chaotic dynamics (spectral analysis, phase trajectory, and autocorrelation plots), but also when they attempted to compute a Lyapunov exponent as more definitive confirmation of chaotic behavior, the authors found they could not reliably do so.\nIn their 1995 paper, Metcalf and Allen maintained that they uncovered in animal behavior a pattern of period doubling leading to chaos. The authors examined a well-known response called schedule-induced polydipsia, by which an animal deprived of food for certain lengths of time will drink unusual amounts of water when the food is at last presented. The control parameter (r) operating here was the length of the interval between feedings, once resumed. The authors were careful to test a large number of animals and to include many replications, and they designed their experiment so as to rule out the likelihood that changes in response patterns were caused by different starting places for r.\nTime series and first delay plots provide the best support for the claims made, showing a fairly clear march from periodicity to irregularity as the feeding times were increased. The various phase trajectory plots and spectral analyses, on the other hand, do not match up well enough with the other graphs or with the overall theory to lead inexorably to a chaotic diagnosis. For example, the phase trajectories do not show a definite progression towards greater and greater complexity (and away from periodicity); the process seems quite muddied. Also, where Metcalf and Allen saw periods of two and six in their spectral plots, there is room for alternative interpretations. All of this ambiguity necessitate some serpentine, post-hoc explanation to show that results fit a chaotic model.\nBy adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, Amundson and Bright found that better suggestions can be made to people struggling with career decisions. Modern organizations are increasingly seen as open complex adaptive systems with fundamental natural nonlinear structures, subject to internal and external forces that may contribute chaos. For instance, team building and group development is increasingly being researched as an inherently unpredictable system, as the uncertainty of different individuals meeting for the first time makes the trajectory of the team unknowable.\nTraffic forecasting may benefit from applications of chaos theory. Better predictions of when a congestion will occur would allow measures to be taken to disperse it before it would have occurred. Combining chaos theory principles with a few other methods has led to a more accurate short-term prediction model (see the plot of the BML traffic model at right).\nChaos theory has been applied to environmental water cycle data (also hydrological data), such as rainfall and streamflow. These studies have yielded controversial results, because the methods for detecting a chaotic signature are often relatively subjective. Early studies tended to \"succeed\" in finding chaos, whereas subsequent studies and meta-analyses called those studies into question and provided explanations for why these datasets are not likely to have low-dimension chaotic dynamics.\nSee also.\nExamples of chaotic systems\nOther related topics\nPeople"}
{"id": "6298", "revid": "1108604", "url": "https://en.wikipedia.org/wiki?curid=6298", "title": "Cupola", "text": "In architecture, a cupola () is a relatively small, usually dome-like structure on top of a building often crowning a larger roof or dome. Cupolas often serve as a roof lantern to admit light and air or as a lookout. \nThe word derives, via Italian, from lower Latin \"cupula\" (classical Latin \"cupella\"), (Latin \"cupa\"), indicating a vault resembling an upside-down cup.\nThe cylindrical drum underneath a larger cupola is called a tholobate.\nBackground.\nThe cupola evolved during the Renaissance from the older oculus. Being weatherproof, the cupola was better suited to the wetter climates of northern Europe. The chhatri, seen in Indian architecture, fits the definition of a cupola when it is used atop a larger structure.\nCupolas often serve as a belfry, belvedere, or roof lantern above a main roof. In other cases they may crown a spire, tower, or turret. Barns often have cupolas for ventilation.\nCupolas can also appear as small buildings in their own right.\nThe square, dome-like segment of a North American railroad train caboose that contains the second-level or \"angel\" seats is also called a cupola.\nOn armoured vehicles.\nThe term cupola can also refer to the protrusions atop an armoured fighting vehicle due to their distinctive dome-like appearance. They allow crew or personnel to observe, offering very good all round vision, or even field weaponry, without being exposed to incoming fire. Later designs, however, became progressively flatter and less prominent as technology evolved to allow designers to reduce the profile of their vehicles. "}
{"id": "6299", "revid": "47406457", "url": "https://en.wikipedia.org/wiki?curid=6299", "title": "Chupacabra", "text": "The chupacabra or chupacabras (, literally 'goat-sucker', from , 'sucks', and , 'goats') is a legendary creature, or cryptid, in the folklore of parts of the Americas. The name comes from the animal's purported vampirism\u2014the chupacabra is said to attack and drink the blood of livestock, including goats.\nPhysical descriptions of the creature vary. In Puerto Rico and in Hispanic America it is generally described as a heavy creature, reptilian and alien-like, roughly the size of a small bear, and with a row of spines reaching from the neck to the base of the tail, while in the Southwestern United States it is depicted as more dog-like.\nInitial sightings and accompanying descriptions first occurred in Puerto Rico in 1995. The creature has since been reported as far north as Maine, as far south as Chile, and even outside the Americas in countries like Russia and the Philippines. All of the reports are anecdotal and have been disregarded as uncorroborated or lacking evidence. Sightings in northern Mexico and the Southern United States have been verified as canids afflicted by mange.\nName.\n can be literally translated as 'goat-sucker', from ('to suck') and ('goats'). It is known as both and throughout the Americas, with the former being the original name, and the latter a regularization. The name is attributed to Puerto Rican comedian Silverio P\u00e9rez, who coined the label in 1995 while commenting on the attacks as a San Juan radio deejay.\nHistory.\nIn 1975, a series of livestock killings in the small town of Moca, Puerto Rico were attributed to ('the vampire of Moca'). Initially, it was suspected that the killings were committed by a Satanic cult; later more killings were reported around the island, and many farms reported loss of animal life. Each of the animals was reported to have had its body bled dry through a series of small circular incisions.\nThe first reported attack eventually attributed to the actual chupacabras occurred in March 1995. Eight sheep were discovered dead in Puerto Rico, each with three puncture wounds in the chest area and reportedly completely drained of blood. A few months later, in August, an eyewitness named Madelyne Tolentino reported seeing the creature in the Puerto Rican town of Can\u00f3vanas, where as many as 150 farm animals and pets were reportedly killed.\nPuerto Rican comedian and entrepreneur Silverio P\u00e9rez is credited with coining the term soon after the first incidents were reported in the press. Shortly after the first reported incidents in Puerto Rico, other animal deaths were reported in other countries, such as Argentina, Bolivia, Brazil, Chile, Colombia, Dominican Republic, El Salvador, Honduras, Mexico, Nicaragua, Panama, Peru, and the United States.\nIn 2019 a video recorded by showed the results of a supposed attack on chickens in the Seburuquillo sector of Lares, Puerto Rico.\nReputed origin.\nA five-year investigation by Benjamin Radford, documented in his 2011 book \"Tracking the Chupacabra\", concluded that the description given by the original eyewitness in Puerto Rico, Madelyne Tolentino, was based on the creature Sil in the 1995 science-fiction horror film \"Species\". The alien creature Sil is nearly identical to Tolentino's chupacabra eyewitness account and she had seen the movie before her report: \"It was a creature that looked like the chupacabra, with spines on its back and all... The resemblance to the chupacabra was really impressive\", Tolentino reported. Radford revealed that Tolentino \"believed that the creatures and events she saw in \"Species\" were happening in reality in Puerto Rico at the time\", and therefore concludes that \"the most important chupacabra description cannot be trusted\". This, Radford believes, seriously undermines the credibility of the chupacabra as a real animal.\nThe reports of blood-sucking by the chupacabra were never confirmed by a necropsy, the only way to conclude that the animal was drained of blood. Dr. David Morales, a Puerto Rican veterinarian with the Department of Agriculture, analyzed 300 reported victims of the chupacabra and found that they had not been bled dry.\nRadford divided the chupacabra reports into two categories: the reports from Puerto Rico and Latin America, where animals were attacked and it is supposed their blood was extracted; and the reports in the United States of mammals, mostly dogs and coyotes with mange, that people call \"chupacabra\" due to their unusual appearance.\nIn 2010, University of Michigan biologist Barry O'Connor concluded that all the chupacabra reports in the United States were simply coyotes infected with the parasite \"Sarcoptes scabiei\", whose symptoms would explain most of the features of the chupacabra: they would be left with little fur, thickened skin, and a rank odor. O'Connor theorized that the attacks on goats occurred \"because these animals are greatly weakened, [so] they're going to have a hard time hunting. So they may be forced into attacking livestock because it's easier than running down a rabbit or a deer.\" Both dogs and coyotes can kill and not consume the prey, either because they are inexperienced, or due to injury or difficulty in killing the prey. The prey can survive the attack and die afterwards from internal bleeding or circulatory shock. The presence of two holes in the neck, corresponding with the canine teeth, are to be expected since this is the only way that most land carnivores have to catch their prey. There are reports of stray Mexican hairless dogs being mistaken for chupacabras.\nAppearance.\nThe most common description of the chupacabra is that of a reptile-like creature, said to have leathery or scaly greenish-gray skin and sharp spines or quills running down its back. It is said to be approximately high, and stands and hops in a fashion similar to that of a kangaroo. This description was the chief one given to the few Puerto Rican reports in 1995 that claimed to have sighted the creature, with similar reports in parts of Chile and Argentina following.\nAnother common description of the chupacabra is of a strange breed of wild dog. This form is mostly hairless and has a pronounced spinal ridge, unusually pronounced eye sockets, fangs, and claws. This description started to appear in the early 2000s from reports trailing north from the Yucat\u00e1n Peninsula, northern Mexico, and then into the United States; becoming the predominant description since. Unlike conventional predators, the chupacabra is said to drain all of the animal's blood (and sometimes organs) usually through three holes in the shape of a downwards-pointing triangle, but sometimes through only one or two holes.\nPlausibility of existence.\nThe chupacabra panic first started in late 1995, Puerto Rico: farmers were mass reporting the mysterious killings of various livestock. In these reports, the farmers recalled two puncture wounds on the animal carcasses. Chupacabra killings were soon associated with a seemingly untouched animal carcass other than puncture wounds which were said to be used to suck the blood out of the victim. Reports of such killings began to spread around and eventually out of the country, reaching areas such as Mexico, Brazil, Chile, and the Southern area of the United States.\nMost notably, these areas experience frequent, and extreme dry seasons; in the cases of the Puerto Rican reports of 1995 and the Mexican reports of 1996, both countries were currently experiencing or dealing with the aftermath of severe droughts. Investigations carried out in both countries at this time noted a certain dramatic violence in these killings. These environmental conditions could provide a simple explanation for the livestock killings: wild predators losing their usual prey to the drought, therefore being forced to hunt the livestock of farmers for sustenance. Thus, the same theory can be applied to many of the other 'chupacabra' attacks: that the dry weather had created a more competitive environment for native predators, leading them to prey on livestock to survive. Such an idea can also explain the increased violence in the killings; hungry and desperate predators are driven to hunt livestock to avoid starvation, causing an increase in both the number of livestock killings, and the viciousness of each one.\nEvidence of such is provided in page 179 of Benjamin Radford's book, \"Tracking the Chupacabra: The Vampire Beast in Fact, Fiction, and Folklore.\" Radford's chart highlights ten significant reports of chupacabra attacks, seven of which had a carcass recovered and examined; these autopsies concluded the causes of death as various animal attacks, as displayed though the animal DNA found on the carcasses. Radford provides further evidence in pages 161-162 of his book, displaying animals who are proven to have fallen victim to regular coyote attacks; thus, explaining that it is not unusual for an animal carcass to be left uneaten while only displaying puncture wounds and/or minimal signs of attack.\nThe plausibility of the chupacabra's existence is also discredited by the varying descriptions of the creature. Depending on the reported sighting, the creature is described with thick skin or fur, wings or no wings, a long tail or no tail, is bat-like, dog-like, or even alien-like. Evidently, the chupacabra has a wide variety of descriptions; to the point where it is hard to believe that all the sightings are of the same creature. A very likely explanation for this phenomenon is that individuals who had heard of the newly popular chupacabra had the creature's name fresh in their mind before they happened to see a strange looking animal. They then resort to make sense of their encounter by labelling it as the recently 'discovered' monster, instead of a more realistic explanation. For example, some scientists hypothesize that what many believe to be a chupacabra is a wild or domestic dog affected by mange, a disease causing a thick buildup of skin and hair loss.\nRelated legends.\nThe \"Ozark Howler\", a large bear-like animal, is the subject of a similar legend.\nThe Peuchens of Chile also share similarities in their supposed habits, but instead of being dog-like they are described as winged snakes. This legend may have originated from the vampire bat, an animal endemic to the region.\nIn the Philippines the Sigbin shares many of the chupacabra's descriptions.\n\"Grunches\" is a legend in New Orleans that gets its name from a lovers' lane called Grunch Road, between the Mississippi River and the Gulf of Mexico. The road was said to be inhabited by creatures called \"grunches\", similar in appearance to the Chupacabra. \nIn 2018 there were reports of suspected chupacabras in Manipur, India. Many domestic animals and poultry were killed in a manner similar to other chupacabra attacks, and several people reported that they had seen creatures. Forensic experts opined that street dogs were responsible for mass killing of domestic animals and poultry after studying the remnants of a corpse."}
{"id": "6302", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6302", "title": "Classical Element", "text": ""}
{"id": "6307", "revid": "491706", "url": "https://en.wikipedia.org/wiki?curid=6307", "title": "Classical Element/Ether", "text": ""}
{"id": "6309", "revid": "94900", "url": "https://en.wikipedia.org/wiki?curid=6309", "title": "Cayuga Lake", "text": "Cayuga Lake (, or ) is the longest of central New York's glacial Finger Lakes, and is the second largest in surface area (marginally smaller than Seneca Lake) and second largest in volume. It is just under long. Its average width is , and it is at its widest point, near Aurora. It is approximately at its deepest point, and has over of shoreline.\nThe lake is named after the indigenous Cayuga people.\nLocation.\nThe city of Ithaca, site of Ithaca College and Cornell University, is located at the southern end of Cayuga Lake. \nOn the Northern shore rests Seneca Falls, the historical Birthplace of Women\u2019s Rights and the Seneca Falls Convention, and what is widely accepted as the real Bedford Falls from the Frank Capra movie It's A Wonderful Life. The Town Seneca Falls, comprises 25.3 square miles and is nestled in the Finger Lakes region located at the northern tip of Cayuga Lake, and is home to approximately 8,650 residents. It is one of ten townships in Seneca County and its largest community.\nVillages and settlements along the east shore of Cayuga Lake include Myers, King Ferry, Aurora, Levanna, Union Springs, and Cayuga. Settlements along the west shore of the lake include Sheldrake, Poplar Beach, and Canoga.\nThe lake has two small islands. One is near Union Springs, called Frontenac Island (northeast); this island is not inhabited. The other island, Canoga Island (northwest), is located near the town of Canoga. This island has several camps and is inhabited during the summer months. The only other island in any of the Finger Lakes is Skenoh Island in Canandaigua Lake.\nGeographical characteristics.\nThe lake depth, with steep east and west sides and shallow north and south ends, is typical of the Finger Lakes, as they were carved by glaciers during the last ice age.\nThe water level is regulated by the Mud Lock at the north end of the lake. It is connected to Lake Ontario by the Erie Canal and Seneca Lake by the Seneca River. The lake is drawn down as winter approaches, to minimize ice damage and to maximize its capacity to store heavy spring runoff.\nThe north end is dominated by shallow mudflats. An important stopover for migratory birds, the mudflats and marsh are the location of the Montezuma National Wildlife Refuge. The southern end is also shallow and often freezes during the winter.\nHuman impact.\nCayuga Lake is very popular among recreational boaters. The Allan H. Treman State Marine Park, with a large state marina and boat launch, is located at the southern end of the lake in Ithaca. There are two yacht clubs on the western shore: Ithaca Yacht Club, a few miles north of Ithaca, and Red Jacket Yacht Club, just south of Canoga. There are several other marinas and boat launches, scattered along the lake shore.\nCayuga Lake is the source of drinking water for several communities, including Lansing, near the southern end of the lake along the east side, which draws water through the Bolton Point Water System. There are also several lake source cooling systems that are in operation on the lake, whereby cooler water is pumped from the depths of the lake, warmed, and circulated in a closed system back to the surface. One of these systems, which is operated by Cornell University and began operation in 2000, was controversial during the planning and building stages, due to its potential for having a negative environmental impact. However, all of the environmental impact reports and scientific studies have shown that the Cornell lake source cooling system has not yet had, and will not likely have any measurably significant environmental impact. Furthermore, Cornell's system pumps significantly less warm water back into the lake than others further north, which have been operating for decades, including the coal-fired power plant on the eastern shore.\nThe AES Coal Power plant was shut down in August 2019, and there are plans to convert it into a data center in the near future. The plant used to use Cayuga Lake as a cooling source. In the late 1960s, citizens successfully opposed the construction of an 830-MW nuclear power plant on the shore of Cayuga Lake.\nRod Serling named his production company Cayuga Productions, during the years of his TV series, \"The Twilight Zone\". Serling and his family had a summer home at Cayuga Lake.\nFishing.\nThe fish population is managed and substantial sport fishing is practiced, with anglers targeting smelt, lake trout and smallmouth bass. Fish species present in the lake include lake trout, landlocked salmon, brown trout, rainbow trout, smallmouth bass, smelt, alewife, atlantic salmon, black crappie, bluegill, pickerel, largemouth bass, northern pike, pumpkinseed sunfish, rock bass, and yellow perch. The round goby has been an invasive species in the lake since the 1990s. There are state owned hard surface ramps in Cayuga\u2013Seneca Canal, Lock #1 (Mud Lock), Long Point State Park, Cayuga Lake State Park, Deans Cove Boat Launch, Taughannock Falls State Park, and Allan H. Treman State Marine Park.\nTributaries.\nThe major inflows to the lake are: Fall Creek, Cayuga Inlet, Salmon Creek, Taughannock Creek, and Six Mile Creek; while the lake outflows into the Seneca River and other tributaries. Ungaged tributaries that inflow to the lake include: \nFolklore.\nThe lake is the subject of local folklore. \nAn \"Ithaca Journal\" article of 5\u00a0January 1897, reported that a sea serpent, nicknamed \"Old Greeny,\" had been sighted in Cayuga Lake annually for 69\u00a0years. A sighting in that month described the animal, from shore, as \"large and its body long\", although a \"tramp\" suggested it was a muskrat. In 1929, two creatures, about in length, were reportedly spotted along the eastern shore of the lake. Further sightings were reported in 1974 and 1979.\nCornell's alma mater makes reference to its position \"Far Above Cayuga's Waters\", while that of Ithaca College references \"Cayuga's shore\".\nA tradition at Wells College in Aurora, NY, held that if the lake completely freezes over, classes are canceled, though for only one day. According to Wells College records, this happened eight times, in \"1875, 1912, 1918, 1934, 1948, 1962, 1979 and 2015.\"\nCayuga Lake, like nearby Seneca Lake, is also the site of a phenomenon known as the Guns of the Seneca, mysterious cannon-like booms heard in the surrounding area. Many of these booms may be attributable to bird-scarers, automated cannon-like devices used by farmers to scare birds away from the many vineyards, orchards and crops. There is, however, no proof of this.\nWine.\nCayuga Lake is included in the American Viticultural Area with which it shares its name. Established in 1988, the AVA now boasts over a dozen wineries, four distilleries, a cidery, and a meadery."}
{"id": "6310", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=6310", "title": "Columbia University", "text": "Columbia University, officially Columbia University in the City of New York, is a private Ivy League research university in New York City. Established in 1754 as King's College on the grounds of Trinity Church in Manhattan, it is the oldest institution of higher education in New York and the fifth-oldest in the United States.\nColumbia was established as a colonial college by royal charter under George II of Great Britain. It was renamed Columbia College in 1784 following the American Revolution, and in 1787 was placed under a private board of trustees headed by former students Alexander Hamilton and John Jay. In 1896, the campus was moved to its current location in Morningside Heights and renamed Columbia University.\nColumbia is organized into twenty schools, including four undergraduate schools and 16 graduate schools. The university's research efforts include the Lamont\u2013Doherty Earth Observatory, the Goddard Institute for Space Studies, and accelerator laboratories with Big Tech firms such as Amazon and IBM. Columbia is a founding member of the Association of American Universities and was the first school in the United States to grant the MD degree. The university also administers and annually awards the Pulitzer Prize.\nColumbia scientists and scholars have played a pivotal role in scientific breakthroughs including brain\u2013computer interface; the laser and maser; nuclear magnetic resonance; the first nuclear pile; the first nuclear fission reaction in the Americas; the first evidence for plate tectonics and continental drift; and much of the initial research and planning for the Manhattan Project during World War II.\n, its alumni, faculty, and staff have included 7 of the Founding Fathers of the United States of America; 4 U.S. presidents; 34 foreign heads of state or government; 2 secretaries-general of the United Nations; 10 justices of the United States Supreme Court; 103 Nobel laureates; 125 National Academy of Sciences members; 53 living billionaires; 23 Olympic medalists; 33 Academy Award winners; and 125 Pulitzer Prize recipients.\nHistory.\n18th century.\nDiscussions regarding the founding of a college in the Province of New York began as early as 1704.\nClasses were initially held in July 1754 and were presided over by the college's first president, Samuel Johnson. The college was officially founded on October 31, 1754, as King's College by royal charter of George II, making it the oldest institution of higher learning in the State of New York and the fifth oldest in the United States.\nIn 1763, Johnson was succeeded in the presidency by Myles Cooper, a graduate of The Queen's College, Oxford, and an ardent Tory. In the charged political climate of the American Revolution, his chief opponent in discussions at the college was an undergraduate of the class of 1777, Alexander Hamilton. The Irish anatomist, Samuel Clossy, was appointed professor of natural philosophy in October 1765 and later the college's first professor of anatomy in 1767. The American Revolutionary War broke out in 1776, and was catastrophic for the operation of King's College, which suspended instruction for eight years beginning in 1776 with the arrival of the Continental Army. The suspension continued through the military occupation of New York City by British troops until their departure in 1783. The college's library was looted and its sole building requisitioned for use as a military hospital first by American and then British forces.\nThe legislature agreed to assist the college, and on May 1, 1784, it passed \"an Act for granting certain privileges to the College heretofore called King's College\". The Act created a board of regents to oversee the resuscitation of King's College, and, in an effort to demonstrate its support for the new Republic, the legislature stipulated that \"the College within the City of New York heretofore called King's College be forever hereafter called and known by the name of Columbia College\", a reference to Columbia, an alternative name for America which in turn comes from the name of Christopher Columbus. The Regents finally became aware of the college's defective constitution in February 1787 and appointed a revision committee, which was headed by John Jay and Alexander Hamilton. In April of that same year, a new charter was adopted for the college granted the power to a separate board of 24 trustees.\nFor a period in the 1790s, with New York City as the federal and state capital and the country under successive Federalist governments, a revived Columbia thrived under the auspices of Federalists such as Hamilton and Jay. President George Washington and Vice President John Adams, in addition to both houses of Congress attended the college's commencement on May 6, 1789, as a tribute of honor to the many alumni of the school who had been involved in the American Revolution.\n19th century.\nIn November 1813, the college agreed to incorporate its medical school with The College of Physicians and Surgeons, a new school created by the Regents of New York, forming Columbia University College of Physicians and Surgeons. In 1857, the college moved from the King's College campus at Park Place to a primarily Gothic Revival campus on 49th Street and Madison Avenue, where it remained for the next forty years.\nDuring the last half of the 19th century, under the presidency of Frederick A. P. Barnard, for whom Barnard College is named, the institution rapidly assumed the shape of a modern university. Barnard College was created in 1889 as a response to the university's refusal to accept women.\nIn 1896, university president Seth Low moved the campus from 49th\u00a0Street to its present location, a more spacious campus in the developing neighborhood of Morningside Heights. Under the leadership of Low's successor, Nicholas Murray Butler, who served for over four decades, Columbia rapidly became the nation's major institution for research, setting the multiversity model that later universities would adopt. Prior to becoming the president of Columbia University, Butler founded Teachers College, as a school to prepare home economists and manual art teachers for the children of the poor, with philanthropist Grace Hoadley Dodge. Teachers College is currently affiliated as the university's Graduate School of Education.\n20th century.\nIn the 1940s, faculty members, including John R. Dunning, I. I. Rabi, Enrico Fermi, and Polykarp Kusch, began what became the Manhattan Project, creating the first nuclear fission reactor in the Americas and researching gaseous diffusion. \nIn 1928, Seth Low Junior College was established by Columbia University in order to mitigate the number of Jewish applicants to Columbia College. The college was closed in 1936 due to the adverse effects of the Great Depression and its students were subsequently taught at Morningside Heights, although they did not belong to any college but to the university at large. There was an evening school called University Extension, which taught night classes, for a fee, to anyone willing to attend.\nIn 1947, the program was reorganized as an undergraduate college and designated the School of General Studies in response to the return of GIs after World War II. In 1995, the School of General Studies was again reorganized as a full-fledged liberal arts college for non-traditional students (those who have had an academic break of one year or more, or are pursuing dual-degrees) and was fully integrated into Columbia's traditional undergraduate curriculum. The same year, the Division of Special Programs, later called the School of Continuing Education and now the School of Professional Studies, was established to reprise the former role of University Extension. While the School of Professional Studies only offered non-degree programs for lifelong learners and high school students in its earliest stages, it now offers degree programs in a diverse range of professional and inter-disciplinary fields.\nIn the aftermath of World War II, the discipline of international relations became a major scholarly focus of the university, and in response, the School of International and Public Affairs was founded in 1946, drawing upon the resources of the faculties of political science, economics, and history. The Columbia University Bicentennial was celebrated in 1954.\nDuring the 1960s, student activism reached a climax with protests in the spring of 1968, when hundreds of students occupied buildings on campus. The incident forced the resignation of Columbia's president, Grayson Kirk, and the establishment of the University Senate.\nThough several schools in the university had admitted women for years, Columbia College first admitted women in the fall of 1983, after a decade of failed negotiations with Barnard College, the all-female institution affiliated with the university, to merge the two schools. Barnard College still remains affiliated with Columbia, and all Barnard graduates are issued diplomas signed by the presidents of Columbia University and Barnard College.\nDuring the late 20th century, the university underwent significant academic, structural, and administrative changes as it developed into a major research university. For much of the 19th century, the university consisted of decentralized and separate faculties specializing in Political Science, Philosophy, and Pure Science. In 1979, these faculties were merged into the Graduate School of Arts and Sciences. In 1991, the faculties of Columbia College, the School of General Studies, the Graduate School of Arts and Sciences, the School of the Arts, and the School of Professional Studies were merged into the Faculty of Arts and Sciences, leading to the academic integration and centralized governance of these schools.\n21st century.\nIn 2010, the School of International and Public Affairs, which was previously a part of the Faculty of Arts and Sciences, became an independent faculty.\nIn fall of 2023, pro-Palestine student activists organized protests in response to the Israel\u2013Hamas war, with counter-protests from pro-Israel activists. The students were protesting against the alleged genocide of Palestinians in Gaza by the IDF, with significant faculty support for the protests. Protestors were reported to have yelled \u201cOctober 7th is going to be every day for you,\u201d toward Jewish students.\nIn January 2024, students who were former IDF soldiers were accused of attacking pro-Palestine demonstrators with noxious chemicals in what the interim provost Dennis Mitchell said was \u201cwhat appears to have been serious crimes, possibly hate crimes\u201d. One of the students suspected in the attack was initially placed on interim suspension before later being suspended through May 2025. In April 2024, the suspended student sued Columbia, alleging that the school subjected him to \"biased misconduct proceedings\" and that he had used fart sprays such as \"Liquid Ass\" rather than harmful chemicals. Following a joint investigation by the NYPD and Columbia, the school concluded that the chemical substance was a \"non-toxic, legal, novelty item\". \nOn April 17, 2024, Columbia president Minouche Shafik was questioned by the House Committee on Education and the Workforce on the topic of antisemitism on campus. While Shafik was in Washington, DC, student activists began renewed protests, leading to what CNN described as a \"full-blown crisis\" over tensions stemming from a pro-Palestinian campus occupation. These protests at Columbia sparked similar pro-Palestinian protests at universities across the USA.\nAs the protests expanded in scale and notoriety, students and faculty, including people of Jewish heritage, pushed back against the silencing of anti-Zionist voices and accusations of anti-semitism. This sentiment was later repeated in an open letter by Columbia faculty that criticized the findings of the university's antisemitism task force.\nOn April 22, 2024 the university moved all in-person classes online, with President Shafik saying that this decision would \"deescalate the rancor and give us all a chance to consider next steps\".\nIn late April, several participants in the campus encampment occupied Hamilton Hall. While inside, these protestors overturned furniture, broke windows, and erected barricades. On April 30, Columbia University called New York Police Department to clear Hamilton Hall. Around 9 PM that night, NYPD officers in riot gear used a siege ladder to access the second floor of Hamilton Hall and subsequently removed the demonstrators occupying it, dozens of whom were arrested. The actions taken against the demonstrators by the NYPD in riot armour while clearing Hamilton Hall inspired the rap song 'Hinds Hall' by Macklemore, who described the police as \"actors in badges\" in the song. In June, the charges against most of the participants in the occupation of Hamilton Hall were dropped.\nIn mid-August 2024, three deans and Minouche Shafik, the 20th president of the university, resigned in the wake of the campus protests. \nIn late August, the university's antisemitism task force reported that the university had failed to prevent violence and hate or protect Jews in the university. According to the report, antisemitism has \"affected the entire university community\" and was carried out by both faculty and students. The task force on anti-semitism was criticised by a group of 24 Jewish faculty (as well as 16 non-Jewish faculty)\u00a0and Jewish students for misrepresentations, omission of key context and equating anti-Zionism with antisemitism.\nCampus.\nMorningside Heights.\nThe majority of Columbia's graduate and undergraduate studies are conducted in the Upper Manhattan neighborhood of Morningside Heights on Seth Low's late-19th century vision of a university campus where all disciplines could be taught at one location. The campus was designed along Beaux-Arts planning principles by the architects McKim, Mead &amp; White. Columbia's main campus occupies more than six city blocks, or , in Morningside Heights, New York City, a neighborhood that contains a number of academic institutions. The university owns over 7,800 apartments in Morningside Heights, housing faculty, graduate students, and staff. Almost two dozen undergraduate dormitories (purpose-built or converted) are located on campus or in Morningside Heights. Columbia University has an extensive tunnel system, more than a century old, with the oldest portions predating the present campus. Some of these remain accessible to the public, while others have been cordoned off.\nButler Library is the largest in the Columbia University Libraries system and one of the largest buildings on the campus. It was completed in 1934 and renamed to Butler Library in 1946. , Columbia's library system includes over 15.0 million volumes, making it the eighth largest library system and fifth largest collegiate library system in the United States.\nSeveral buildings on the Morningside Heights campus are listed on the National Register of Historic Places. Low Memorial Library, a National Historic Landmark and the centerpiece of the campus, is listed for its architectural significance. Philosophy Hall is listed as the site of the invention of FM radio. Also listed is Pupin Hall, another National Historic Landmark, which houses the physics and astronomy departments. Here the first experiments on the fission of uranium were conducted by Enrico Fermi. The uranium atom was split there ten days after the world's first atom-splitting in Copenhagen, Denmark. Other buildings listed include Casa Italiana, the Delta Psi, Alpha Chapter building of St. Anthony Hall, Earl Hall, and the buildings of the affiliated Union Theological Seminary.\nA statue by sculptor Daniel Chester French called \"Alma Mater\" is centered on the front steps of Low Memorial Library. The statue represents a personification of the traditional image of the university as an \"alma mater\", or \"nourishing mother\", draped in an academic gown and seated on a throne. She wears a laurel wreath on her head and holds in her right hand a scepter capped by a King's Crown, a traditional symbol of the university. A book, representing learning, rests on her lap. The arms of her throne end in lamps, representing \"Sapientia et Doctrina\", or \"Wisdom and Learning\"; on the back of the throne is embossed an image of the seal of the university. The small hidden owl on the sculpture is also the subject of many Columbia legends, the main legend being that the first student in the freshmen class to find the hidden owl on the statue will be valedictorian, and that any subsequent Columbia male who finds it will marry a Barnard student, given that Barnard is a women's college. \n\"The Steps\", alternatively known as \"Low Steps\" or the \"Urban Beach\", are a popular meeting area for Columbia students. The term refers to the long series of granite steps leading from the lower part of campus (South Field) to its upper terrace.\nOther campuses.\nIn April 2007, the university purchased more than two-thirds of a site for a new campus in Manhattanville, an industrial neighborhood to the north of the Morningside Heights campus. Stretching from 125th Street to 133rd Street, Columbia Manhattanville houses buildings for Columbia's Business School, School of International and Public Affairs, Columbia School of the Arts, and the Jerome L. Greene Center for Mind, Brain, and Behavior, where research will occur on neurodegenerative diseases such as Parkinson's and Alzheimer's. The $7\u00a0billion expansion plan included demolishing all buildings, except three that are historically significant (the Studebaker Building, Prentis Hall, and the Nash Building), eliminating the existing light industry and storage warehouses, and relocating tenants in 132\u00a0apartments. Replacing these buildings created of space for the university. Community activist groups in West Harlem fought the expansion for reasons ranging from property protection and fair exchange for land, to residents' rights. Subsequent public hearings drew neighborhood opposition. , the State of New York's Empire State Development Corporation approved use of eminent domain, which, through declaration of Manhattanville's \"blighted\" status, gives governmental bodies the right to appropriate private property for public use. On May 20, 2009, the New York State Public Authorities Control Board approved the Manhanttanville expansion plan.\nNewYork-Presbyterian Hospital is affiliated with the medical schools of both Columbia University and Cornell University. According to \"U.S. News &amp; World Report\"s \"2020\u201321 Best Hospitals Honor Roll and Medical Specialties Rankings\", it is ranked fourth overall and second among university hospitals. Columbia's medical school has a strategic partnership with New York State Psychiatric Institute, and is affiliated with 19 other hospitals in the U.S. and four hospitals in other countries. Health-related schools are located at the Columbia University Medical Center, a campus located in the neighborhood of Washington Heights, fifty blocks uptown. Other teaching hospitals affiliated with Columbia through the NewYork-Presbyterian network include the Payne Whitney Clinic in Manhattan, and the Payne Whitney Westchester, a psychiatric institute located in White Plains, New York. On the northern tip of Manhattan island (in the neighborhood of Inwood), Columbia owns the Baker Field, which includes the Lawrence A. Wien Stadium as well as facilities for field sports, outdoor track, and tennis. There is a third campus on the west bank of the Hudson River, the Lamont\u2013Doherty Earth Observatory and Earth Institute in Palisades, New York. A fourth is the Nevis Laboratories in Irvington, New York, for the study of particle and motion physics. A satellite site in Paris holds classes at Reid Hall.\nSustainability.\nIn 2006, the university established the Office of Environmental Stewardship to initiate, coordinate and implement programs to reduce the university's environmental footprint. The U.S. Green Building Council selected the university's Manhattanville plan for the Leadership in Energy and Environmental Design (LEED) Neighborhood Design pilot program.\n Columbia has been rated \"B+\" by the 2011 College Sustainability Report Card for its environmental and sustainability initiatives.\nAccording to the A. W. Kuchler U.S. potential natural vegetation types, Columbia University would have a dominant vegetation type of Appalachian Oak (\"104\") with a dominant vegetation form of Eastern Hardwood Forest (\"25\").\nTransportation.\nColumbia Transportation is the bus service of the university, operated by Academy Bus Lines. The buses are open to all Columbia faculty, students, Dodge Fitness Center members, and anyone else who holds a Columbia ID card. In addition, all TSC students can ride the buses.\nIn the New York City Subway, the train serves the university at 116th Street-Columbia University. The buses stop on Broadway while the stops on Amsterdam Avenue.\nThe main campus is primarily boxed off by the streets of Amsterdam Avenue, Broadway, 114th street, and 120th street, with some buildings, including Barnard College, located just outside the area. The nearest major highway is the Henry Hudson Parkway (NY 9A) to the west of the campus. It is located south of the George Washington Bridge.\nAcademics.\nUndergraduate admissions and financial aid.\nColumbia University received 60,551 applications for the class of 2025 (entering 2021) and a total of around 2,218 were admitted to the two schools for an overall acceptance rate of 3.66%. Columbia is a racially diverse school, with approximately 52% of all students identifying themselves as persons of color. Additionally, 50% of all undergraduates received grants from Columbia. The average grant size awarded to these students is $46,516. In 2015\u20132016, annual undergraduate tuition at Columbia was $50,526 with a total cost of attendance of $65,860 (including room and board). The college is need-blind for domestic applicants.\nOn April 11, 2007, Columbia University announced a $400 million donation from media billionaire alumnus John Kluge to be used exclusively for undergraduate financial aid. The donation is among the largest single gifts to higher education. However, this does not apply to international students, transfer students, visiting students, or students in the School of General Studies. In the fall of 2010, admission to Columbia's undergraduate colleges Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) began accepting the Common Application. The policy change made Columbia one of the last major academic institutions and the last Ivy League university to switch to the Common Application.\nScholarships are also given to undergraduate students by the admissions committee. Designations include John W. Kluge Scholars, John Jay Scholars, C. Prescott Davis Scholars, Global Scholars, Egleston Scholars, and Science Research Fellows. Named scholars are selected by the admission committee from first-year applicants. According to Columbia, the first four designated scholars \"distinguish themselves for their remarkable academic and personal achievements, dynamism, intellectual curiosity, the originality and independence of their thinking, and the diversity that stems from their different cultures and their varied educational experiences\".\nIn 1919, Columbia established a student application process characterized by \"The New York Times\" as \"the first modern college application\". The application required a photograph of the applicant, the maiden name of the applicant's mother, and the applicant's religious background.\nOrganization.\nColumbia University is an independent, privately supported, nonsectarian and not-for-profit institution of higher education. Its official corporate name is Trustees of Columbia University in the City of New York. \nIn 1754, the university's first charter was granted by King George II; however, its modern charter was first enacted in 1787 and last amended in 1810 by the New York State Legislature.\nColumbia has four official undergraduate colleges: Columbia College, the liberal arts college offering the Bachelor of Arts degree; the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering), the engineering and applied science school offering the Bachelor of Science degree; the School of General Studies, the liberal arts college offering the Bachelor of Arts degree to non-traditional students undertaking full- or part-time study; and Barnard College. Barnard College is a women's liberal arts college and an academic affiliate in which students receive a Bachelor of Arts degree from Columbia University. Their degrees are signed by the presidents of Columbia University and Barnard College. Barnard students are also eligible to cross-register classes that are available through the Barnard Catalogue and alumnae can join the Columbia Alumni Association.\nJoint degree programs are available through Union Theological Seminary, the Jewish Theological Seminary of America, and the Juilliard School. Teachers College and Barnard College are official faculties of the university; both colleges' presidents are deans under the university governance structure. The Columbia University Senate includes faculty and student representatives from Teachers College and Barnard College who serve two-year terms; all senators are accorded full voting privileges regarding matters impacting the entire university. Teachers College is an affiliated, financially independent graduate school with their own board of trustees. Pursuant to an affiliation agreement, Columbia is given the authority to confer \"degrees and diplomas\" to the graduates of Teachers College. The degrees are signed by presidents of Teachers College and Columbia University in a manner analogous to the university's other graduate schools. Columbia's General Studies school also has joint undergraduate programs available through University College London, Sciences Po, City University of Hong Kong, Trinity College Dublin, and the Juilliard School.\nThe university also has several Columbia Global Centers, in Amman, Beijing, Istanbul, Mumbai, Nairobi, Paris, Rio de Janeiro, Santiago, and Tunis.\nInternational partnerships.\nColumbia students can study abroad for a semester or a year at partner institutions such as Sciences Po, (EHESS), (ENS), Panth\u00e9on-Sorbonne University, King's College London, London School of Economics, University College London and the University of Warwick. Select students can study at either the University of Oxford or the University of Cambridge for a year if approved by both Columbia and either Oxford or Cambridge. Columbia also has a dual MA program with the Aga Khan University in London.\nRankings.\nColumbia University is ranked 12th in the United States and seventh globally for 2023\u20132024 by \"U.S. News &amp; World Report\". QS University Rankings listed Columbia as fifth in the United States. Ranked 15th among U.S. colleges for 2020 by \"The Wall Street Journal\" and \"Times Higher Education\", in recent years it has been ranked as high as second. Individual colleges and schools were also nationally ranked by \"U.S. News &amp; World Report\" for its 2021 edition. Columbia Law School was ranked fourth, the Mailman School of Public Health fourth, the School of Social Work tied for third, Columbia Business School eighth, the College of Physicians and Surgeons tied for sixth for research (and tied for 31st for primary care), the School of Nursing tied for 11th in the master's program and tied for first in the doctorate nursing program, and the Fu Foundation School of Engineering and Applied Science (graduate) was ranked tied for 14th.\nIn 2021, Columbia was ranked seventh in the world (sixth in the United States) by \"Academic Ranking of World Universities\", sixth in the world by \"U.S. News &amp; World Report\", 19th in the world by \"QS World University Rankings\", and 11th globally by \"Times Higher Education World University Rankings\". It was ranked in the first tier of American research universities, along with Harvard, MIT, and Stanford, in the 2019 report from the Center for Measuring University Performance. Columbia's Graduate School of Architecture, Planning and Preservation was ranked the second most admired graduate program by Architectural Record in 2020.\nIn 2011, the ranked Columbia third best university for forming CEOs in the US and 12th worldwide.\nControversies.\nIn 2022, Columbia's reporting of metrics used for university ranking was criticized by Professor of Mathematics Michael Thaddeus, who argued key data supporting the ranking was \"inaccurate, dubious or highly misleading.\" Subsequently, \"U.S. News &amp; World Report\" \"unranked\" Columbia from its 2022 list of Best Colleges saying that it could not verify the data submitted by the university. In June 2023, Columbia University announced their undergraduate schools would no longer participate in \"U.S. News &amp; World Report's\" rankings, following the lead of its law, medical and nursing schools. A press release cited concerns that such rankings unduly influence applicants and \"distill a university's profile into a composite of data categories.\"\nResearch.\nColumbia is classified among \"R1: Doctoral Universities \u2013 Very high research activity\". Columbia was the first North American site where the uranium atom was split. The College of Physicians and Surgeons played a central role in developing the modern understanding of neuroscience with the publication of \"Principles of Neural Science\", described by historian of science Katja Huenther as the \"neuroscience 'bible' \". The book was written by a team of Columbia researchers that included Nobel Prize winner Eric Kandel, James H. Schwartz, and Thomas Jessell. Columbia was the birthplace of FM radio and the laser. The first brain-computer interface capable of translating brain signals into speech was developed by neuroengineers at Columbia. The MPEG-2 algorithm of transmitting high quality audio and video over limited bandwidth was developed by Dimitris Anastassiou, a Columbia professor of electrical engineering. Biologist Martin Chalfie was the first to introduce the use of Green Fluorescent Protein (GFP) in labeling cells in intact organisms. Other inventions and products related to Columbia include Sequential Lateral Solidification (SLS) technology for making LCDs, System Management Arts (SMARTS), Session Initiation Protocol (SIP) (which is used for audio, video, chat, instant messaging and whiteboarding), pharmacopeia, Macromodel (software for computational chemistry), a new and better recipe for glass concrete, Blue LEDs, and Beamprop (used in photonics).\nColumbia scientists have been credited with about 175 new inventions in the health sciences each year. More than 30 pharmaceutical products based on discoveries and inventions made at Columbia reached the market. These include Remicade (for arthritis), Reopro (for blood clot complications), Xalatan (for glaucoma), Benefix, Latanoprost (a glaucoma treatment), shoulder prosthesis, homocysteine (testing for cardiovascular disease), and Zolinza (for cancer therapy). Columbia Technology Ventures (formerly Science and Technology Ventures), , manages some 600 patents and more than 250 active license agreements. Patent-related deals earned Columbia more than $230\u00a0million in the 2006 fiscal year, according to the university, more than any university in the world. Columbia owns many unique research facilities, such as the Columbia Institute for Tele-Information dedicated to telecommunications and the Goddard Institute for Space Studies, which is an astronomical observatory affiliated with NASA.\nMilitary and veteran enrollment.\nColumbia is a long-standing participant of the United States Department of Veterans Affairs Yellow Ribbon Program, allowing eligible veterans to pursue a Columbia undergraduate degree regardless of socioeconomic status for over 70 years. As a part of the Eisenhower Leader Development Program (ELDP) in partnership with the United States Military Academy at West Point, Columbia is the only school in the Ivy League to offer a graduate degree program in organizational psychology to aid military officers in tactical decision making and strategic management.\nAwards.\nSeveral prestigious awards are administered by Columbia University, most notably the Pulitzer Prize and the Bancroft Prize in history. Other prizes, which are awarded by the Graduate School of Journalism, include the Alfred I. duPont\u2013Columbia University Award, the National Magazine Awards, the Maria Moors Cabot Prizes, the John Chancellor Award, and the Lukas Prizes, which include the J. Anthony Lukas Book Prize and Mark Lynton History Prize. The university also administers the Louisa Gross Horwitz Prize, which is considered an important precursor to the Nobel Prize, 55 of its 117 recipients having gone on to win either a Nobel Prize in Physiology or Medicine or Nobel Prize in Chemistry as of October 2024; the W. Alden Spencer Award; the Vetlesen Prize, which is known as the Nobel Prize of geology; the Japan-U.S. Friendship Commission Prize for the Translation of Japanese Literature, the oldest such award; the Edwin Howard Armstrong award; the Calderone Prize in public health; and the Ditson Conductor's Award.\nStudent life.\nIn 2020, Columbia University's student population was 31,455 (8,842 students in undergraduate programs and 22,613 in postgraduate programs), with 45% of the student population identifying themselves as a minority. Twenty-six percent of students at Columbia have family incomes below $60,000. 16% of students at Columbia receive Federal Pell Grants, which mostly go to students whose family incomes are below $40,000. Seventeen percent of students are the first member of their family to attend a four-year college.\nOn-campus housing is guaranteed for all four years as an undergraduate. Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) share housing in the on-campus residence halls. First-year students usually live in one of the large residence halls situated around South Lawn: Carman Hall, Furnald Hall, Hartley Hall, John Jay Hall, or Wallach Hall (originally Livingston Hall). Upperclassmen participate in a room selection process, wherein students can pick to live in a mix of either corridor- or apartment-style housing with their friends. The Columbia University School of General Studies, Barnard College and graduate schools have their own apartment-style housing in the surrounding neighborhood.\nColumbia University is home to many fraternities, sororities, and co-educational Greek organizations. Approximately 10\u201315% of undergraduate students are associated with Greek life. Many Barnard women also join Columbia sororities. There has been a Greek presence on campus since the establishment in 1836 of the Delta chapter of Alpha Delta Phi.\nPublications.\nThe \"Columbia Daily Spectator\" is the nation's second-oldest continuously operating daily student newspaper. \"The Blue and White\" is a monthly literary magazine established in 1890 that discusses campus life and local politics. \"Bwog\", originally an offshoot of \"The Blue and White\" but now fully independent, is an online campus news and entertainment source. \"The Morningside Post\" is a student-run multimedia news publication.\nPolitical publications include \"The Current\", a journal of politics, culture and Jewish Affairs; the \"Columbia Political Review\", the multi-partisan political magazine of the Columbia Political Union; and \"AdHoc\", which denotes itself as the \"progressive\" campus magazine and deals largely with local political issues and arts events.\n\"Columbia Magazine\" is the alumni magazine of Columbia, serving all 340,000+ of the university's alumni. Arts and literary publications include \"The Columbia Review\", the nation's oldest college literary magazine; \"Surgam\", the literary magazine of The Philolexian Society; \"Quarto\", Columbia University's official undergraduate literary magazine; \"4x4\", a student-run alternative to \"Quarto\"; \"Columbia\", a nationally regarded literary journal; the \"Columbia Journal of Literary Criticism\"; and \"The Mobius Strip\", an online arts and literary magazine. \"Inside New York\" is an annual guidebook to New York City, written, edited, and published by Columbia undergraduates. Through a distribution agreement with Columbia University Press, the book is sold at major retailers and independent bookstores.\nColumbia is home to numerous undergraduate academic publications. The \"Columbia Undergraduate Science Journal\" prints original science research in its two annual publications. The \"Journal of Politics &amp; Society\" is a journal of undergraduate research in the social sciences; \"Publius\" is an undergraduate journal of politics established in 2008 and published biannually; the \"Columbia East Asia Review\" allows undergraduates throughout the world to publish original work on China, Japan, Korea, Tibet, and Vietnam and is supported by the Weatherhead East Asian Institute; \"The Birch\" is an undergraduate journal of Eastern European and Eurasian culture that is the first national student-run journal of its kind; the \"Columbia Economics Review\" is the undergraduate economic journal on research and policy supported by the Columbia Economics Department; and the \"Columbia Science Review\" is a science magazine that prints general interest articles and faculty profiles.\nHumor publications on Columbia's campus include \"The Fed\", a triweekly satire and investigative newspaper, and the \"Jester of Columbia.\" Other publications include \"The Columbian\", the undergraduate colleges' annually published yearbook; the \"Gadfly\", a biannual journal of popular philosophy produced by undergraduates; and \"Rhapsody in Blue\", an undergraduate urban studies magazine. Professional journals published by academic departments at Columbia University include \"Current Musicology\" and \"The Journal of Philosophy\". During the spring semester, graduate students in the Journalism School publish \"The Bronx Beat\", a bi-weekly newspaper covering the South Bronx.\nFounded in 1961 under the auspices of Columbia University's Graduate School of Journalism, the \"Columbia Journalism Review\" (CJR) examines day-to-day press performance as well as the forces that affect that performance. The magazine is published six times a year.\nFormer publications include the \"Columbia University Forum\", a review of literature and cultural affairs distributed for free to alumni.\nBroadcasting.\nColumbia is home to two pioneers in undergraduate campus radio broadcasting, WKCR-FM and CTV. Many undergraduates are also involved with Barnard's radio station, WBAR. WKCR, the student run radio station that broadcasts to the Tri-state area, claims to be the oldest FM radio station in the world, owing to the university's affiliation with Edwin Howard Armstrong. The station has its studios on the second floor of Alfred Lerner Hall on the Morningside campus with its main transmitter tower at 4 Times Square in Midtown Manhattan. Columbia Television (CTV) is the nation's second oldest student television station and the home of CTV News, a weekly live news program produced by undergraduate students.\nDebate and Model UN.\nThe Philolexian Society is a literary and debating club founded in 1802, making it the oldest student group at Columbia, as well as the third oldest collegiate literary society in the country. The society annually administers the Joyce Kilmer Memorial Bad Poetry Contest. The Columbia Parliamentary Debate Team competes in tournaments around the country as part of the American Parliamentary Debate Association, and hosts both high school and college tournaments on Columbia's campus, as well as public debates on issues affecting the university.\nThe Columbia International Relations Council and Association (CIRCA), oversees Columbia's Model United Nations activities. CIRCA hosts college and high school Model UN conferences, hosts speakers influential in international politics to speak on campus, and trains students from underprivileged schools in New York in Model UN.\nTechnology and entrepreneurship.\nColumbia is a top supplier of young engineering entrepreneurs for New York City. Over the past 20 years, graduates of Columbia established over 100 technology companies.\nThe Columbia University Organization of Rising Entrepreneurs (CORE) was founded in 1999. The student-run group aims to foster entrepreneurship on campus. Each year CORE hosts dozens of events, including talks, #StartupColumbia, a conference and venture competition for $250,000, and Ignite@CU, a weekend for undergrads interested in design, engineering, and entrepreneurship. Notable speakers include Peter Thiel, Jack Dorsey, Alexis Ohanian, Drew Houston, and Mark Cuban. As of 2006, CORE had awarded graduate and undergraduate students over $100,000 in seed capital.\nCampusNetwork, an on-campus social networking site called Campus Network that preceded Facebook, was created and popularized by Columbia engineering student Adam Goldberg in 2003. Mark Zuckerberg later asked Goldberg to join him in Palo Alto to work on Facebook, but Goldberg declined the offer. The Fu Foundation School of Engineering and Applied Science offers a minor in Technical Entrepreneurship through its Center for Technology, Innovation, and Community Engagement. SEAS' entrepreneurship activities focus on community building initiatives in New York and worldwide, made possible through partners such as Microsoft Corporation.\nOn June 14, 2010, Mayor Michael R. Bloomberg launched the NYC Media Lab to promote innovations in New York's media industry. Situated at the New York University Tandon School of Engineering, the lab is a consortium of Columbia University, New York University, and New York City Economic Development Corporation acting to connect companies with universities in new technology research. The Lab is modeled after similar ones at MIT and Stanford, and was established with a $250,000 grant from the New York City Economic Development Corporation.\nWorld Leaders Forum.\nEstablished in 2003 by university president Lee C. Bollinger, the World Leaders Forum at Columbia University provides the opportunity for students and faculty to listen to world leaders in government, religion, industry, finance, and academia.\nPast forum speakers include former president of the United States Bill Clinton, the prime minister of India Atal Bihari Vajpayee, former president of Ghana John Agyekum Kufuor, president of Afghanistan Hamid Karzai, prime minister of Russia Vladimir Putin, president of the Republic of Mozambique Joaquim Alberto Chissano, president of the Republic of Bolivia Carlos Diego Mesa Gisbert, president of the Republic of Romania Ion Iliescu, president of the Republic of Latvia Vaira V\u012b\u0137e-Freiberga, the first female president of Finland Tarja Halonen, President Yudhoyono of Indonesia, President Pervez Musharraf of the Islamic Republic of Pakistan, Iraq President Jalal Talabani, the 14th Dalai Lama, president of the Islamic Republic of Iran Mahmoud Ahmadinejad, financier George Soros, Mayor of New York City Michael R. Bloomberg, President V\u00e1clav Klaus of the Czech Republic, President Cristina Fern\u00e1ndez de Kirchner of Argentina, former Secretary-General of the United Nations Kofi Annan, and Al Gore.\nOther.\nThe Columbia University Orchestra was founded by composer Edward MacDowell in 1896, and is the oldest continually operating university orchestra in the United States. Undergraduate student composers at Columbia may choose to become involved with Columbia New Music, which sponsors concerts of music written by undergraduate students from all of Columbia's schools. The Notes and Keys, the oldest a cappella group at Columbia, was founded in 1909. There are a number of performing arts groups at Columbia dedicated to producing student theater, including the Columbia Players, King's Crown Shakespeare Troupe (KCST), Columbia Musical Theater Society (CMTS), NOMADS (New and Original Material Authored and Directed by Students), LateNite Theatre, Columbia University Performing Arts League (CUPAL), Black Theatre Ensemble (BTE), sketch comedy group Chowdah, and improvisational troupes Alfred and Fruit Paunch.\nThe Columbia Queer Alliance is the central Columbia student organization that represents the bisexual, lesbian, gay, transgender, and questioning student population. It is the oldest gay student organization in the world, founded as the Student Homophile League in 1967 by students including lifelong activist Stephen Donaldson.\nColumbia University campus military groups include the U.S. Military Veterans of Columbia University and Advocates for Columbia ROTC. In the 2005\u201306 academic year, the Columbia Military Society, Columbia's student group for ROTC cadets and Marine officer candidates, was renamed the Hamilton Society for \"students who aspire to serve their nation through the military in the tradition of Alexander Hamilton\".\nColumbia has several secret societies, including St. Anthony Hall, which was founded at the university in 1847, and two senior societies, the Nacoms and Sachems.\nAthletics.\nA member institution of the National Collegiate Athletic Association (NCAA) in Division I FCS, Columbia fields varsity teams in 29 sports and is a member of the Ivy League. The football Lions play home games at the 17,000-seat Robert K. Kraft Field at Lawrence A. Wien Stadium. The Baker Athletics Complex also includes facilities for baseball, softball, soccer, lacrosse, field hockey, tennis, track, and rowing, as well as the new Campbell Sports Center, which opened in January 2013. The basketball, fencing, swimming &amp; diving, volleyball, and wrestling programs are based at the Dodge Physical Fitness Center on the main campus.\nFormer students include Baseball Hall of Famers Lou Gehrig and Eddie Collins, football Hall of Famer Sid Luckman, Marcellus Wiley, and world champion women's weightlifter Karyn Marshall. On May 17, 1939, fledgling NBC broadcast a doubleheader between the Columbia Lions and the Princeton Tigers at Columbia's Baker Field, making it the first televised regular athletic event in history.\nColumbia University participated in multiple firsts within collegiate athletics. The football program unfortunately is best known for its record of futility set during the 1980s: between 1983 and 1988, the team lost 44 games in a row, which is still the record for the NCAA Football Championship Subdivision. The streak was broken on October 8, 1988, with a 16\u201313 victory over arch-rival Princeton University. That was the Lions' first victory at Wien Stadium, which had been opened during the losing streak and was already four years old. A new tradition has developed with the Liberty Cup. The Liberty Cup is awarded annually to the winner of the football game between Fordham and Columbia Universities, two of the only three NCAA Division I football teams in New York City.\nTraditions.\nThe Varsity Show.\nThe Varsity Show is one of the oldest traditions at Columbia. Founded in 1893 as a fundraiser for the university's fledgling athletic teams, the Varsity Show now draws together the entire Columbia undergraduate community for a series of performances every April. Dedicated to producing a unique full-length musical that skewers and satirizes many dubious aspects of life at Columbia, the Varsity Show is written and performed exclusively by university undergraduates. Various renowned playwrights, composers, authors, directors, and actors have contributed to the Varsity Show, either as writers or performers, while students at Columbia, including Richard Rodgers, Oscar Hammerstein II, Lorenz Hart, Herman J. Mankiewicz, I. A. L. Diamond, Herman Wouk, Greta Gerwig, and Kate McKinnon.\nNotable past shows include \"Fly With Me\" (1920), \"The\" \"Streets of New York\" (1948), \"The Sky's the Limit\" (1954), and \"Angels at Columbia\" (1994). In particular, \"Streets of New York\", after having been revived three times, opened off-Broadway in 1963 and was awarded a 1964 Drama Desk Award. \"The Mischief Maker\" (1903), written by Edgar Allan Woolf and Cassius Freeborn, premiered at Madison Square Garden in 1906 as \"Mam'zelle Champagne\".\nTree Lighting and Yule Log ceremonies.\nThe campus Tree Lighting ceremony was inaugurated in 1998. It celebrates the illumination of the medium-sized trees lining College Walk in front of Kent Hall and Hamilton Hall on the east end and Dodge Hall and Pulitzer Hall on the west, just before finals week in early December. The lights remain on until February 28. Students meet at the sundial for free hot chocolate, performances by \"a cappella\" groups, and speeches by the university president and a guest.\nImmediately following the College Walk festivities is one of Columbia's older holiday traditions, the lighting of the Yule Log. The Christmas ceremony dates to a period prior to the American Revolutionary War, but lapsed before being revived by President Nicholas Murray Butler in 1910. A troop of students dressed as Continental Army soldiers carry the eponymous log from the sundial to the lounge of John Jay Hall, where it is lit amid the singing of seasonal carols. The Christmas ceremony is accompanied by a reading of \"A Visit From St. Nicholas\" by Clement Clarke Moore and \"Yes, Virginia, There is a Santa Claus\" by Francis Pharcellus Church.\nNotable people.\nAlumni.\nThe university has graduated many notable alumni, including five Founding Fathers of the United States, an author of the United States Constitution and a member of the Committee of Five. Three United States presidents have attended Columbia, as well as ten Justices of the Supreme Court of the United States, including three Chief Justices. , 125 Pulitzer Prize winners and 39 Oscar winners have attended Columbia. , there were 101 National Academy members who were alumni.\nIn a 2016 ranking of universities worldwide with respect to living graduates who are billionaires, Columbia ranked second, after Harvard.\nFormer U.S. Presidents Theodore Roosevelt and Franklin Delano Roosevelt attended the law school. Other political figures educated at Columbia include former U.S. President Barack Obama, Associate Justice of the U.S. Supreme Court Ruth Bader Ginsburg, former U.S. Secretary of State Madeleine Albright, former chairman of the U.S. Federal Reserve Bank Alan Greenspan, U.S. Attorney General Eric Holder, and U.S. Solicitor General Donald Verrilli Jr. The university has also educated 29 foreign heads of state, including president of Georgia Mikheil Saakashvili, president of East Timor Jos\u00e9 Ramos-Horta, president of Estonia Toomas Hendrik Ilves and other historical figures such as Wellington Koo, Radovan Karad\u017ei\u0107, Gaston Eyskens, and T. V. Soong. One of the founding fathers of modern India and the prime architect of the Constitution of India, B. R. Ambedkar, was an alumnus.\nAlumni of Columbia have occupied top positions in Wall Street and the rest of the business world. Notable members of the Astor family attended Columbia, while other business graduates include investor Warren Buffett, former CEO of PBS and NBC Lawrence K. Grossman, chairman of Walmart S. Robson Walton, Bain Capital Co-Managing Partner, Jonathan Lavine, Thomson Reuters CEO Tom Glocer, New York Stock Exchange president Lynn Martin, and AllianceBernstein Chairman and CEO Lewis A. Sanders. CEO's of top Fortune 500 companies include James P. Gorman of Morgan Stanley, Robert J. Stevens of Lockheed Martin, Philippe Dauman of Viacom, Robert Bakish of Paramount Global, Ursula Burns of Xerox, Devin Wenig of EBay, Vikram Pandit of Citigroup, Ralph Izzo of Public Service Enterprise Group, Gail Koziara Boudreaux of Anthem, and Frank Blake of The Home Depot. Notable labor organizer and women's educator Louise Leonard McLaren received her degree of Master of Arts from Columbia.\nIn science and technology, Columbia alumni include: founder of IBM Herman Hollerith; inventor of FM radio Edwin Armstrong; Francis Mechner; integral in development of the nuclear submarine Hyman Rickover; founder of Google China Kai-Fu Lee; scientists Stephen Jay Gould, Robert Millikan, Helium\u2013neon laser inventor Ali Javan and Mihajlo Pupin; chief-engineer of the New York City Subway, William Barclay Parsons; philosophers Irwin Edman and Robert Nozick; economist Milton Friedman; psychologist Harriet Babcock; archaeologist Josephine Platner Shear; and sociologists Lewis A. Coser and Rose Laub Coser.\nMany Columbia alumni have gone on to renowned careers in the arts, including composers Richard Rodgers, Oscar Hammerstein II, Lorenz Hart, and Art Garfunkel; and painter Georgia O'Keeffe. Five United States Poet Laureates received their degrees from Columbia. Columbia alumni have made an indelible mark in the field of American poetry and literature, with such people as Jack Kerouac and Allen Ginsberg, pioneers of the Beat Generation; and Langston Hughes and Zora Neale Hurston, seminal figures in the Harlem Renaissance, all having attended the university. Other notable writers who attended Columbia include authors Isaac Asimov, J.D. Salinger, Upton Sinclair, Ursula K. Le Guin, Danielle Valore Evans, and Hunter S. Thompson. In architecture, William Lee Stoddart, a prolific architect of U.S. East Coast hotels, is an alumnus.\nUniversity alumni have also been very prominent in the film industry, with 33 alumni and former students winning a combined 43 Academy Awards (). Some notable Columbia alumni that have gone on to work in film include directors Sidney Lumet (\"12 Angry Men\") and Kathryn Bigelow (\"The Hurt Locker\"), screenwriters Howard Koch (\"Casablanca\") and Joseph L. Mankiewicz (\"All About Eve\"), and actors James Cagney, Ed Harris and Timoth\u00e9e Chalamet.\nFaculty.\nAs of 2021, Columbia employs 4,381 faculty, including 70 members of the National Academy of Sciences, 178 members of the American Academy of Arts and Sciences, and 65 members of the National Academy of Medicine. In total, the Columbia faculty has included 52 Nobel laureates, 12 National Medal of Science recipients, and 32 National Academy of Engineering members.\nColumbia University faculty played particularly important roles during World War II and the creation of the New Deal under President Franklin D. Roosevelt, who attended Columbia Law School. The three core members of Roosevelt's Brain Trust: Adolf A. Berle, Raymond Moley, and Rexford Tugwell, were law professors at Columbia. The Statistical Research Group, which used statistics to analyze military problems during World War II, was composed of Columbia researchers and faculty including George Stigler and Milton Friedman. Columbia faculty and researchers, including Enrico Fermi, Leo Szilard, Eugene T. Booth, John R. Dunning, George B. Pegram, Walter Zinn, Chien-Shiung Wu, Francis G. Slack, Harold Urey, Herbert L. Anderson, and Isidor Isaac Rabi, also played a significant role during the early phases of the Manhattan Project.\nFollowing the rise of Nazi Germany, the exiled Institute for Social Research at Goethe University Frankfurt would affiliate itself with Columbia from 1934 to 1950. It was during this period that thinkers including Theodor Adorno, Max Horkheimer, and Herbert Marcuse wrote and published some of the most seminal works of the Frankfurt School, including \"Reason and Revolution\", \"Dialectic of Enlightenment\", and \"Eclipse of Reason\". Professors Edward Said, author of \"Orientalism\", and Gayatri Spivak are generally considered as founders of the field of postcolonialism; other professors that have significantly contributed to the field include Hamid Dabashi and Joseph Massad. The works of professors Kimberl\u00e9 Crenshaw, Patricia J. Williams, and Kendall Thomas were foundational to the field of critical race theory.\nColumbia and its affiliated faculty have also made significant contributions to the study of religion. The affiliated Union Theological Seminary is a center of liberal Christianity in the United States, having served as the birthplace of Black theology through the efforts of faculty including James H. Cone and Cornel West, and Womanist theology, through the works of Katie Cannon, Emilie Townes, and Delores S. Williams. Likewise, the Jewish Theological Seminary of America was the birthplace of Conservative Judaism movement in the United States, which was founded and led by faculty members including Solomon Schechter, Alexander Kohut, and Louis Ginzberg in the early 20th century, and is a major center for Jewish studies in general.\nOther schools of thought in the humanities Columbia professors made significant contributions toward include the Dunning School, founded by William Archibald Dunning; the anthropological schools of historical particularism and cultural relativism, founded by Franz Boas; and functional psychology, whose founders and proponents include John Dewey, James McKeen Cattell, Edward L. Thorndike, and Robert S. Woodworth.\nNotable figures that have served as the president of Columbia University include 34th President of the United States Dwight D. Eisenhower, 4th Vice President of the United States George Clinton, Founding Father and U.S. Senator from Connecticut William Samuel Johnson, Nobel Peace Prize laureate Nicholas Murray Butler, and First Amendment scholar Lee Bollinger.\nNotable Columbia University faculty include Zbigniew Brzezinski, Sonia Sotomayor, Kimberl\u00e9 Crenshaw, Lee Bollinger, Franz Boas, Margaret Mead, Edward Sapir, John Dewey, Charles A. Beard, Max Horkheimer, Herbert Marcuse, Edward Said, Gayatri Chakravorty Spivak, Orhan Pamuk, Edwin Howard Armstrong, Enrico Fermi, Chien-Shiung Wu, Tsung-Dao Lee, Jack Steinberger, Joachim Frank, Joseph Stiglitz, Jeffrey Sachs, Robert Mundell, Thomas Hunt Morgan, Eric Kandel, Richard Axel, and Andrei Okounkov."}
{"id": "6311", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6311", "title": "College Football", "text": ""}
{"id": "6312", "revid": "21395606", "url": "https://en.wikipedia.org/wiki?curid=6312", "title": "Cell wall", "text": "A cell wall is a structural layer that surrounds some cell types, found immediately outside the cell membrane. It can be tough, flexible, and sometimes rigid. Primarily, it provides the cell with structural support, shape, protection, and functions as a selective barrier. Another vital role of the cell wall is to help the cell withstand osmotic pressure and mechanical stress. While absent in many eukaryotes, including animals, cell walls are prevalent in other organisms such as fungi, algae and plants, and are commonly found in most prokaryotes, with the exception of mollicute bacteria.\nThe composition of cell walls varies across taxonomic groups, species, cell type, and the cell cycle. In land plants, the primary cell wall comprises polysaccharides like cellulose, hemicelluloses, and pectin. Often, other polymers such as lignin, suberin or cutin are anchored to or embedded in plant cell walls. Algae exhibit cell walls composed of glycoproteins and polysaccharides, such as carrageenan and agar, distinct from those in land plants. Bacterial cell walls contain peptidoglycan, while archaeal cell walls vary in composition, potentially consisting of glycoprotein S-layers, pseudopeptidoglycan, or polysaccharides. Fungi possess cell walls constructed from the polymer chitin, specifically N-acetylglucosamine. Diatoms have a unique cell wall composed of biogenic silica.\nHistory.\nA plant cell wall was first observed and named (simply as a \"wall\") by Robert Hooke in 1665. However, \"the dead excrusion product of the living protoplast\" was forgotten, for almost three centuries, being the subject of scientific interest mainly as a resource for industrial processing or in relation to animal or human health.\nIn 1804, Karl Rudolphi and J.H.F. Link proved that cells had independent cell walls. Before, it had been thought that cells shared walls and that fluid passed between them this way.\nThe mode of formation of the cell wall was controversial in the 19th century. Hugo von Mohl (1853, 1858) advocated the idea that the cell wall grows by apposition. Carl N\u00e4geli (1858, 1862, 1863) believed that the growth of the wall in thickness and in area was due to a process termed intussusception. Each theory was improved in the following decades: the apposition (or lamination) theory by Eduard Strasburger (1882, 1889), and the intussusception theory by Julius Wiesner (1886).\nIn 1930, Ernst M\u00fcnch coined the term \"apoplast\" in order to separate the \"living\" symplast from the \"dead\" plant region, the latter of which included the cell wall.\nBy the 1980s, some authors suggested replacing the term \"cell wall\", particularly as it was used for plants, with the more precise term \"extracellular matrix\", as used for animal cells, but others preferred the older term.\nProperties.\nCell walls serve similar purposes in those organisms that possess them. They may give cells rigidity and strength, offering protection against mechanical stress. The chemical composition and mechanical properties of the cell wall are linked with plant cell growth and morphogenesis. In multicellular organisms, they permit the organism to build and hold a definite shape. Cell walls also limit the entry of large molecules that may be toxic to the cell. They further permit the creation of stable osmotic environments by preventing osmotic lysis and helping to retain water. Their composition, properties, and form may change during the cell cycle and depend on growth conditions.\nRigidity of cell walls.\nIn most cells, the cell wall is flexible, meaning that it will bend rather than holding a fixed shape, but has considerable tensile strength. The apparent rigidity of primary plant tissues is enabled by cell walls, but is not due to the walls' stiffness. Hydraulic turgor pressure creates this rigidity, along with the wall structure. The flexibility of the cell walls is seen when plants wilt, so that the stems and leaves begin to droop, or in seaweeds that bend in water currents. As John Howland explains\nThe apparent rigidity of the cell wall thus results from inflation of the cell contained within. This inflation is a result of the passive uptake of water.\nIn plants, a secondary cell wall is a thicker additional layer of cellulose which increases wall rigidity. Additional layers may be formed by lignin in xylem cell walls, or suberin in cork cell walls. These compounds are rigid and waterproof, making the secondary wall stiff. Both wood and bark cells of trees have secondary walls. Other parts of plants such as the leaf stalk may acquire similar reinforcement to resist the strain of physical forces.\nPermeability.\nThe primary cell wall of most plant cells is freely permeable to small molecules including small proteins, with size exclusion estimated to be 30-60 kDa. The pH is an important factor governing the transport of molecules through cell walls.\nEvolution.\nCell walls evolved independently in many groups.\nThe photosynthetic eukaryotes (so-called plant and algae) is one group with cellulose cell walls, where the cell wall is closely related to the evolution of multicellularity, terrestrialization and vascularization. The CesA cellulose synthase evolved in \"Cyanobacteria\" and was part of Archaeplastida since endosymbiosis; secondary endosymbiosis events transferred it (with the arabinogalactan proteins) further into brown algae and oomycetes. Plants later evolved various genes from CesA, including the Csl (cellulose synthase-like) family of proteins and additional Ces proteins. Combined with the various glycosyltransferases (GT), they enable more complex chemical structures to be built.\nFungi use a chitin-glucan-protein cell wall. They share the 1,3-\u03b2-glucan synthesis pathway with plants, using homologous GT48 family 1,3-Beta-glucan synthases to perform the task, suggesting that such an enzyme is very ancient within the eukaryotes. Their glycoproteins are rich in mannose. The cell wall might have evolved to deter viral infections. Proteins embedded in cell walls are variable, contained in tandem repeats subject to homologous recombination. An alternative scenario is that fungi started with a chitin-based cell wall and later acquired the GT-48 enzymes for the 1,3-\u03b2-glucans via horizontal gene transfer. The pathway leading to 1,6-\u03b2-glucan synthesis is not sufficiently known in either case.\nPlant cell walls.\nThe walls of plant cells must have sufficient tensile strength to withstand internal osmotic pressures of several times atmospheric pressure that result from the difference in solute concentration between the cell interior and external solutions. Plant cell walls vary from 0.1 to several \u03bcm in thickness.\nLayers.\nUp to three strata or layers may be found in plant cell walls:\nComposition.\nIn the primary (growing) plant cell wall, the major carbohydrates are cellulose, hemicellulose and pectin. The cellulose microfibrils are linked via hemicellulosic tethers to form the cellulose-hemicellulose network, which is embedded in the pectin matrix. The most common hemicellulose in the primary cell wall is xyloglucan. In grass cell walls, xyloglucan and pectin are reduced in abundance and partially replaced by glucuronoarabinoxylan, another type of hemicellulose. Primary cell walls characteristically extend (grow) by a mechanism called acid growth, mediated by expansins, extracellular proteins activated by acidic conditions that modify the hydrogen bonds between pectin and cellulose. This functions to increase cell wall extensibility. The outer part of the primary cell wall of the plant epidermis is usually impregnated with cutin and wax, forming a permeability barrier known as the plant cuticle.\nSecondary cell walls contain a wide range of additional compounds that modify their mechanical properties and permeability. The major polymers that make up wood (largely secondary cell walls) include:\nAdditionally, structural proteins (1-5%) are found in most plant cell walls; they are classified as hydroxyproline-rich glycoproteins (HRGP), arabinogalactan proteins (AGP), glycine-rich proteins (GRPs), and proline-rich proteins (PRPs). Each class of glycoprotein is defined by a characteristic, highly repetitive protein sequence. Most are glycosylated, contain hydroxyproline (Hyp) and become cross-linked in the cell wall. These proteins are often concentrated in specialized cells and in cell corners. Cell walls of the epidermis may contain cutin. The Casparian strip in the endodermis roots and cork cells of plant bark contain suberin. Both cutin and suberin are polyesters that function as permeability barriers to the movement of water. The relative composition of carbohydrates, secondary compounds and proteins varies between plants and between the cell type and age. Plant cells walls also contain numerous enzymes, such as hydrolases, esterases, peroxidases, and transglycosylases, that cut, trim and cross-link wall polymers.\nSecondary walls - especially in grasses - may also contain microscopic silica crystals, which may strengthen the wall and protect it from herbivores.\nCell walls in some plant tissues also function as storage deposits for carbohydrates that can be broken down and resorbed to supply the metabolic and growth needs of the plant. For example, endosperm cell walls in the seeds of cereal grasses, nasturtium\nand other species, are rich in glucans and other polysaccharides that are readily digested by enzymes during seed germination to form simple sugars that nourish the growing embryo.\nFormation.\nThe middle lamella is laid down first, formed from the cell plate during cytokinesis, and the primary cell wall is then deposited inside the middle lamella. The actual structure of the cell wall is not clearly defined and several models exist - the covalently linked cross model, the tether model, the diffuse layer model and the stratified layer model. However, the primary cell wall, can be defined as composed of cellulose microfibrils aligned at all angles. Cellulose microfibrils are produced at the plasma membrane by the cellulose synthase complex, which is proposed to be made of a hexameric rosette that contains three cellulose synthase catalytic subunits for each of the six units. Microfibrils are held together by hydrogen bonds to provide a high tensile strength. The cells are held together and share the gelatinous membrane (the middle lamella), which contains magnesium and calcium pectates (salts of pectic acid). Cells interact though plasmodesmata, which are inter-connecting channels of cytoplasm that connect to the protoplasts of adjacent cells across the cell wall.\nIn some plants and cell types, after a maximum size or point in development has been reached, a \"secondary wall\" is constructed between the plasma membrane and primary wall. Unlike the primary wall, the cellulose microfibrils are aligned parallel in layers, the orientation changing slightly with each additional layer so that the structure becomes helicoidal. Cells with secondary cell walls can be rigid, as in the gritty sclereid cells in pear and quince fruit. Cell to cell communication is possible through pits in the secondary cell wall that allow plasmodesmata to connect cells through the secondary cell walls.\nFungal cell walls.\nThere are several groups of organisms that have been called \"fungi\". Some of these groups (Oomycete and Myxogastria) have been transferred out of the Kingdom Fungi, in part because of fundamental biochemical differences in the composition of the cell wall. Most true fungi have a cell wall consisting largely of chitin and other polysaccharides. True fungi do not have cellulose in their cell walls.\nIn fungi, the cell wall is the outer-most layer, external to the plasma membrane. The fungal cell wall is a matrix of three main components:\nOther eukaryotic cell walls.\nAlgae.\nLike plants, algae have cell walls. Algal cell walls contain either polysaccharides (such as cellulose (a glucan)) or a variety of glycoproteins (Volvocales) or both. The inclusion of additional polysaccharides in algal cells walls is used as a feature for algal taxonomy.\nOther compounds that may accumulate in algal cell walls include sporopollenin and calcium ions.\nThe group of algae known as the diatoms synthesize their cell walls (also known as frustules or valves) from silicic acid. Significantly, relative to the organic cell walls produced by other groups, silica frustules require less energy to synthesize (approximately 8%), potentially a major saving on the overall cell energy budget and possibly an explanation for higher growth rates in diatoms.\nIn brown algae, phlorotannins may be a constituent of the cell walls.\nWater molds.\nThe group Oomycetes, also known as water molds, are saprotrophic plant pathogens like fungi. Until recently they were widely believed to be fungi, but structural and molecular evidence has led to their reclassification as heterokonts, related to autotrophic brown algae and diatoms. Unlike fungi, oomycetes typically possess cell walls of cellulose and glucans rather than chitin, although some genera (such as \"Achlya\" and \"Saprolegnia\") do have chitin in their walls. The fraction of cellulose in the walls is no more than 4 to 20%, far less than the fraction of glucans. Oomycete cell walls also contain the amino acid hydroxyproline, which is not found in fungal cell walls.\nSlime molds.\nThe dictyostelids are another group formerly classified among the fungi. They are slime molds that feed as unicellular amoebae, but aggregate into a reproductive stalk and sporangium under certain conditions. Cells of the reproductive stalk, as well as the spores formed at the apex, possess a cellulose wall. The spore wall has three layers, the middle one composed primarily of cellulose, while the innermost is sensitive to cellulase and pronase.\nProkaryotic cell walls.\nBacterial cell walls.\nAround the outside of the cell membrane is the bacterial cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by unusual peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of Archaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, although L-form bacteria can be produced in the laboratory that lack a cell wall. The antibiotic penicillin is able to kill bacteria by preventing the cross-linking of peptidoglycan and this causes the cell wall to weaken and lyse. The lysozyme enzyme can also damage bacterial cell walls.\nThere are broadly speaking two different types of cell wall in bacteria, called gram-positive and gram-negative. The names originate from the reaction of cells to the Gram stain, a test long-employed for the classification of bacterial species.\nGram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. \nGram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the gram-negative cell wall and only the Bacillota and Actinomycetota (previously known as the low G+C and high G+C gram-positive bacteria, respectively) have the alternative gram-positive arrangement. \nThese differences in structure produce differences in antibiotic susceptibility. The beta-lactam antibiotics (e.g. penicillin, cephalosporin) only work against gram-negative pathogens, such as \"Haemophilus influenzae\" or \"Pseudomonas aeruginosa\". The glycopeptide antibiotics (e.g. vancomycin, teicoplanin, telavancin) only work against gram-positive pathogens such as \"Staphylococcus aureus\" \nArchaeal cell walls.\nAlthough not truly unique, the cell walls of Archaea are unusual. Whereas peptidoglycan is a standard component of all bacterial cell walls, all archaeal cell walls lack peptidoglycan, though some methanogens have a cell wall made of a similar polymer called pseudopeptidoglycan. There are four types of cell wall currently known among the Archaea.\nOne type of archaeal cell wall is that composed of pseudopeptidoglycan (also called pseudomurein). This type of wall is found in some methanogens, such as \"Methanobacterium\" and \"Methanothermus\". While the overall structure of archaeal \"pseudo\"peptidoglycan superficially resembles that of bacterial peptidoglycan, there are a number of significant chemical differences. Like the peptidoglycan found in bacterial cell walls, pseudopeptidoglycan consists of polymer chains of glycan cross-linked by short peptide connections. However, unlike peptidoglycan, the sugar N-acetylmuramic acid is replaced by N-acetyltalosaminuronic acid, and the two sugars are bonded with a \"\u03b2\",1-3 glycosidic linkage instead of \"\u03b2\",1-4. Additionally, the cross-linking peptides are L-amino acids rather than D-amino acids as they are in bacteria.\nA second type of archaeal cell wall is found in \"Methanosarcina\" and \"Halococcus\". This type of cell wall is composed entirely of a thick layer of polysaccharides, which may be sulfated in the case of \"Halococcus\". Structure in this type of wall is complex and not fully investigated.\nA third type of wall among the Archaea consists of glycoprotein, and occurs in the hyperthermophiles, \"Halobacterium\", and some methanogens. In \"Halobacterium\", the proteins in the wall have a high content of acidic amino acids, giving the wall an overall negative charge. The result is an unstable structure that is stabilized by the presence of large quantities of positive sodium ions that neutralize the charge. Consequently, \"Halobacterium\" thrives only under conditions with high salinity.\nIn other Archaea, such as \"Methanomicrobium\" and \"Desulfurococcus\", the wall may be composed only of surface-layer proteins, known as an \"S-layer\". S-layers are common in bacteria, where they serve as either the sole cell-wall component or an outer layer in conjunction with polysaccharides. Most Archaea are Gram-negative, though at least one Gram-positive member is known.\nOther cell coverings.\nMany protists and bacteria produce other cell surface structures apart from cell walls, external (extracellular matrix) or internal. Many algae have a sheath or envelope of mucilage outside the cell made of exopolysaccharides. Diatoms build a frustule from silica extracted from the surrounding water; radiolarians, foraminiferans, testate amoebae and silicoflagellates also produce a skeleton from minerals, called test in some groups. Many green algae, such as \"Halimeda\" and the Dasycladales, and some red algae, the Corallinales, encase their cells in a secreted skeleton of calcium carbonate. In each case, the wall is rigid and essentially inorganic. It is the non-living component of cell. Some golden algae, ciliates and choanoflagellates produces a shell-like protective outer covering called lorica. Some dinoflagellates have a theca of cellulose plates, and coccolithophorids have coccoliths.\nAn extracellular matrix (ECM) is also present in metazoans. Its composition varies between cells, but collagens are the most abundant protein in the ECM."}
{"id": "6313", "revid": "38587278", "url": "https://en.wikipedia.org/wiki?curid=6313", "title": "Classical element", "text": "The classical elements typically refer to earth, water, air, fire, and (later) aether which were proposed to explain the nature and complexity of all matter in terms of simpler substances. Ancient cultures in Greece, Angola, Tibet, India, and Mali had similar lists which sometimes referred, in local languages, to \"air\" as \"wind\", and to \"aether\" as \"space\".\nThese different cultures and even individual philosophers had widely varying explanations concerning their attributes and how they related to observable phenomena as well as cosmology. Sometimes these theories overlapped with mythology and were personified in deities. Some of these interpretations included atomism (the idea of very small, indivisible portions of matter), but other interpretations considered the elements to be divisible into infinitely small pieces without changing their nature.\nWhile the classification of the material world in ancient India, Hellenistic Egypt, and ancient Greece into air, earth, fire, and water was more philosophical, during the Middle Ages medieval scientists used practical, experimental observation to classify materials. In Europe, the ancient Greek concept, devised by Empedocles, evolved into the systematic classifications of Aristotle and Hippocrates. This evolved slightly into the medieval system, and eventually became the object of experimental verification in the 17th century, at the start of the Scientific Revolution.\nModern science does not support the classical elements to classify types of substances. Atomic theory classifies atoms into more than a hundred chemical elements such as oxygen, iron, and mercury, which may form chemical compounds and mixtures. The modern categories roughly corresponding to the classical elements are the states of matter produced under different temperatures and pressures. Solid, liquid, gas, and plasma share many attributes with the corresponding classical elements of earth, water, air, and fire, but these states describe the similar behavior of different types of atoms at similar energy levels, not the characteristic behavior of certain atoms or substances.\nHellenistic philosophy.\nThe ancient Greek concept of four basic elements, these being earth ( ), water ( ), air ( ), and fire ( ), dates from pre-Socratic times and persisted throughout the Middle Ages and into the Early modern period, deeply influencing European thought and culture.\nPre-Socratic elements.\nWater, air, or fire?\nThe classical elements were first proposed independently by several early Pre-Socratic philosophers. Greek philosophers had debated which substance was the \"arche\" (\"first principle\"), or primordial element from which everything else was made. Thales () believed that water was this principle. Anaximander () argued that the primordial substance was not any of the known substances, but could be transformed into them, and they into each other. Anaximenes () favored air, and Heraclitus (fl.\u2009) championed fire.\nFire, earth, air, and water.\nThe Greek philosopher Empedocles () was the first to propose the four classical elements as a set: fire, earth, air, and water. He called them the four \"roots\" (, ). Empedocles also proved (at least to his own satisfaction) that air was a separate substance by observing that a bucket inverted in water did not become filled with water, a pocket of air remaining trapped inside.\nFire, earth, air, and water have become the most popular set of classical elements in modern interpretations. One such version was provided by Robert Boyle in \"The Sceptical Chymist\", which was published in 1661 in the form of a dialogue between five characters. \"Themistius,\" the Aristotelian of the party, says:\nHumorism (Hippocrates).\nAccording to Galen, these elements were used by Hippocrates () in describing the human body with an association with the four humours: yellow bile (fire), black bile (earth), blood (air), and phlegm (water). Medical care was primarily about helping the patient stay in or return to their own personal natural balanced state.\nPlato.\nPlato (428/423 \u2013 348/347 BC) seems to have been the first to use the term \"element (, )\" in reference to air, fire, earth, and water. The ancient Greek word for element, (from , \"to line up\") meant \"smallest division (of a sun-dial), a syllable\", as the composing unit of an alphabet it could denote a letter and the smallest unit from which a word is formed.\nAristotle.\nIn \"On the Heavens\" (350 BC), Aristotle defines \"element\" in general:\nIn his \"On Generation and Corruption\", Aristotle related each of the four elements to two of the four sensible qualities:\nA classic diagram has one square inscribed in the other, with the corners of one being the classical elements, and the corners of the other being the properties. The opposite corner is the opposite of these properties, \"hot\u202f\u2013\u202fcold\" and \"dry\u202f\u2013\u202fwet\".\nAether.\nAristotle added a fifth element, aether ( ), as the quintessence, reasoning that whereas fire, earth, air, and water were earthly and corruptible, since no changes had been perceived in the heavenly regions, the stars cannot be made out of any of the four elements but must be made of a different, unchangeable, heavenly substance. It had previously been believed by pre-Socratics such as Empedocles and Anaxagoras that aether, the name applied to the material of heavenly bodies, was a form of fire. Aristotle himself did not use the term \"aether\" for the fifth element, and strongly criticised the pre-Socratics for associating the term with fire. He preferred a number of other terms indicating eternal movement, thus emphasising the evidence for his discovery of a new element. These five elements have been associated since Plato's \"Timaeus\" with the five platonic solids.\nNeo-Platonism.\nThe Neoplatonic philosopher Proclus rejected Aristotle's theory relating the elements to the sensible qualities hot, cold, wet, and dry. He maintained that each of the elements has three properties. Fire is sharp (\u1f40\u03be\u03c5\u03c4\u03b7\u03c4\u03b1), subtle (\u03bb\u03b5\u03c0\u03c4\u03bf\u03bc\u03b5\u03c1\u03b5\u03b9\u03b1\u03bd), and mobile (\u03b5\u1f50\u03ba\u03b9\u03bd\u03b7\u03c3\u03b9\u03b1\u03bd) while its opposite, earth, is blunt (\u03b1\u03bc\u03b2\u03bb\u03c5\u03c4\u03b7\u03c4\u03b1), dense (\u03c0\u03b1\u03c7\u03c5\u03bc\u03b5\u03c1\u03b5\u03b9\u03b1\u03bd), and immobile (\u03b1\u03ba\u03b9\u03bd\u03b7\u03c3\u03b9\u03b1\u03bd); they are joined by the intermediate elements, air and water, in the following fashion:\nHermeticism.\nA text written in Egypt in Hellenistic or Roman times called the \"Kore Kosmou\" (\"Virgin of the World\") ascribed to Hermes Trismegistus (associated with the Egyptian god Thoth), names the four elements fire, water, air, and earth. As described in this book:\nAncient Indian philosophy.\nHinduism.\nThe system of five elements are found in Vedas, especially Ayurveda, the \"pancha mahabhuta\", or \"five great elements\", of Hinduism are:\nThey further suggest that all of creation, including the human body, is made of these five essential elements and that upon death, the human body dissolves into these five elements of nature, thereby balancing the cycle of nature.\nThe five elements are associated with the five senses, and act as the gross medium for the experience of sensations. The basest element, earth, created using all the other elements, can be perceived by all five senses\u202f\u2014\u202f(i) hearing, (ii) touch, (iii) sight, (iv) taste, and (v) smell. The next higher element, water, has no odor but can be heard, felt, seen and tasted. Next comes fire, which can be heard, felt and seen. Air can be heard and felt. \"Akasha\" (aether) is beyond the senses of smell, taste, sight, and touch; it being accessible to the sense of hearing alone.\nBuddhism.\nBuddhism has had a variety of thought about the five elements and their existence and relevance, some of which continue to this day.\nIn the Pali literature, the \"mahabhuta\" (\"great elements\") or \"catudhatu\" (\"four elements\") are earth, water, fire and air. In early Buddhism, the four elements are a basis for understanding suffering and for liberating oneself from suffering. The earliest Buddhist texts explain that the four primary material elements are solidity, fluidity, temperature, and mobility, characterized as earth, water, fire, and air, respectively.\nThe Buddha's teaching regarding the four elements is to be understood as the base of all observation of real sensations rather than as a philosophy. The four properties are cohesion (water), solidity or inertia (earth), expansion or vibration (air) and heat or energy content (fire). He promulgated a categorization of mind and matter as composed of eight types of \"kalapas\" of which the four elements are primary and a secondary group of four are colour, smell, taste, and nutriment which are derivative from the four primaries.\nThanissaro Bhikkhu (1997) renders an extract of Shakyamuni Buddha's from Pali into English thus:\nTibetan Buddhist medical literature speaks of the (five elements) or \"elemental properties\": earth, water, fire, wind, and space. The concept was extensively used in traditional Tibetan medicine. Tibetan Buddhist theology, tantra traditions, and \"astrological texts\" also spoke of them making up the \"environment, [human] bodies,\" and at the smallest or \"subtlest\" level of existence, parts of thought and the mind. Also at the subtlest level of existence, the elements exist as \"pure natures represented by the five female buddhas\", \u0100k\u0101\u015badh\u0101tvi\u015bvar\u012b, Buddhalocan\u0101, Mamak\u012b, P\u0101\u1e47\u1e0dar\u0101vasin\u012b, and Samayat\u0101r\u0101, and these pure natures \"manifest as the physical properties of earth (solidity), water (fluidity), fire (heat and light), wind (movement and energy), and\" the expanse of space. These natures exist as all \"qualities\" that are in the physical world and take forms in it.\nAncient African philosophy.\nAngola.\nIn traditional Bakongo religion, the five elements are incorporated into the Kongo cosmogram. This sacred symbol also depicts the physical world (\"Nseke\"), the spiritual world of the ancestors (\"Mp\u00e9mba\"), the Kal\u00fbnga line that runs between the two worlds, the circular void that originally formed the two worlds (\"mb\u00fbngi\"), and the path of the sun. Each element correlates to a period in the life cycle, which the Bakongo people also equate to the four cardinal directions. According to their cosmology, all living things go through this cycle.\nMali.\nIn traditional Bambara spirituality, the Supreme God created four additional essences of himself during creation. Together, these five essences of the deity correlate with the five classical elements.\nPost-classical history.\nAlchemy.\nThe elemental system used in medieval alchemy was developed primarily by the anonymous authors of the Arabic works attributed to Pseudo Apollonius of Tyana. This system consisted of the four classical elements of air, earth, fire, and water, in addition to a new theory called the sulphur-mercury theory of metals, which was based on two elements: sulphur, characterizing the principle of combustibility, \"the stone which burns\"; and mercury, characterizing the principle of metallic properties. They were seen by early alchemists as idealized expressions of irreducible components of the universe and are of larger consideration within philosophical alchemy.\nThe three metallic principles\u2014sulphur to flammability or combustion, mercury to volatility and stability, and salt to solidity\u2014became the \"tria prima\" of the Swiss alchemist Paracelsus. He reasoned that Aristotle's four element theory appeared in bodies as three principles. Paracelsus saw these principles as fundamental and justified them by recourse to the description of how wood burns in fire. Mercury included the cohesive principle, so that when it left in smoke the wood fell apart. Smoke described the volatility (the mercurial principle), the heat-giving flames described flammability (sulphur), and the remnant ash described solidity (salt).\nJapan.\nJapanese traditions use a set of elements called the (\"godai\", literally \"five great\"). These five are earth, water, fire, wind/air, and void. These came from Indian Vastu shastra philosophy and Buddhist beliefs; in addition, the classical Chinese elements (, \"wu xing\") are also prominent in Japanese culture, especially to the influential Neo-Confucianists during the medieval Edo period.\nMedieval Aristotelian philosophy.\nThe Islamic philosophers al-Kindi, Avicenna and Fakhr al-Din al-Razi followed Aristotle in connecting the four elements with the four natures heat and cold (the active force), and dryness and moisture (the recipients).\nMedicine Wheel.\nThe medicine wheel symbol is a modern invention attributed to Native American peoples dating to approximately 1972, with the following descriptions and associations being a later addition. The associations with the classical elements are not grounded in traditional Indigenous teachings and the symbol has not been adopted by all Indigenous American nations.\nModern history.\nChemical element.\nThe Aristotelian tradition and medieval alchemy eventually gave rise to modern chemistry, scientific theories and new taxonomies. By the time of Antoine Lavoisier, for example, a list of elements would no longer refer to classical elements. Some modern scientists see a parallel between the classical elements and the four states of matter: solid, liquid, gas and weakly ionized plasma.\nModern science recognizes classes of elementary particles which have no substructure (or rather, particles that are not made of other particles) and composite particles having substructure (particles made of other particles).\nWestern astrology.\nWestern astrology uses the four classical elements in connection with astrological charts and horoscopes. The twelve signs of the zodiac are divided into the four elements: Fire signs are Aries, Leo and Sagittarius, Earth signs are Taurus, Virgo and Capricorn, Air signs are Gemini, Libra and Aquarius, and Water signs are Cancer, Scorpio, and Pisces.\nCriticism.\nThe Dutch historian of science Eduard Jan Dijksterhuis writes that the theory of the classical elements \"was bound to exercise a really harmful influence. As is now clear, Aristotle, by adopting this theory as the basis of his interpretation of nature and by never losing faith in it, took a course which promised few opportunities and many dangers for science.\" Bertrand Russell says that Aristotle's thinking became imbued with almost biblical authority in later centuries. So much so that \"Ever since the beginning of the seventeenth century, almost every serious intellectual advance has had to begin with an attack on some Aristotelian doctrine\"."}
{"id": "6314", "revid": "39625739", "url": "https://en.wikipedia.org/wiki?curid=6314", "title": "Fire (classical element)", "text": "Fire is one of the four classical elements along with earth, water and air in ancient Greek philosophy and science. Fire is considered to be both hot and dry and, according to Plato, is associated with the tetrahedron.\nGreek and Roman tradition.\nFire is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with the qualities of energy, assertiveness, and passion. In one Greek myth, Prometheus stole \"fire\" from the gods to protect the otherwise helpless humans, but was punished for this charity.\nFire was one of many \"archai\" proposed by the pre-Socratics, most of whom sought to reduce the cosmos, or its creation, to a single substance. Heraclitus considered \"fire\" to be the most fundamental of all elements. He believed fire gave rise to the other three elements: \"All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods.\" He had a reputation for obscure philosophical principles and for speaking in riddles. He described how fire gave rise to the other elements as the: \"upward-downward path\", (), a \"hidden harmony\"\u2009 or series of transformations he called the \"turnings of fire\", (), first into \"sea\", and half that \"sea\" into \"earth\", and half that \"earth\" into rarefied \"air\". This is a concept that anticipates both the four classical elements of Empedocles and Aristotle's transmutation of the four elements into one another.\nThis world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out. \nHeraclitus regarded the soul as being a mixture of fire and water, with fire being the more noble part and water the ignoble aspect. He believed the goal of the soul is to be rid of water and become pure fire: the dry soul is the best and it is worldly pleasures that make the soul \"moist\". He was known as the \"weeping philosopher\" and died of hydropsy, a swelling due to abnormal accumulation of fluid beneath the skin.\nHowever, Empedocles of Akragas , is best known for having selected all elements as his \"archai\" and by the time of Plato , the four Empedoclian elements were well established. In the \"Timaeus\", Plato's major cosmological dialogue, the Platonic solid he associated with fire was the tetrahedron which is formed from four triangles and contains the least volume with the greatest surface area. This also makes fire the element with the smallest number of sides, and Plato regarded it as appropriate for the heat of fire, which he felt is sharp and stabbing, (like one of the points of a tetrahedron).\nPlato's student Aristotle did not maintain his former teacher's geometric view of the elements, but rather preferred a somewhat more naturalistic explanation for the elements based on their traditional qualities. Fire the hot and dry element, like the other elements, was an abstract principle and not identical with the normal solids, liquids and combustion phenomena we experience:\n What we commonly call fire. It is not really fire, for fire is an excess of heat and a sort of ebullition; but in reality, of what we call air, the part surrounding the earth is moist and warm, because it contains both vapour and a dry exhalation from the earth.\nAccording to Aristotle, the four elements rise or fall toward their natural place in concentric layers surrounding the center of the Earth and form the terrestrial or sublunary spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Yellow bile was the humor identified with fire, since both were hot and dry. Other things associated with fire and yellow bile in ancient and medieval medicine included the season of summer, since it increased the qualities of heat and aridity; the choleric temperament (of a person dominated by the yellow bile humour); the masculine; and the eastern point of the compass.\nIn alchemy the chemical element of sulfur was often associated with fire and its alchemical symbol and its symbol was an upward-pointing triangle. In alchemic tradition, metals are incubated by fire in the womb of the Earth and alchemists only accelerate their development.\nIndian tradition.\nAgni is a Hindu and Vedic deity. The word \"agni\" is Sanskrit for fire (noun), cognate with Latin \"ignis\" (the root of English \"ignite\"), Russian \"\u043e\u0433\u043e\u043d\u044c\" (fire), pronounced \"agon\". Agni has three forms: fire, lightning and the sun.\nAgni is one of the most important of the Vedic gods. He is the god of fire and the accepter of sacrifices. The sacrifices made to Agni go to the deities because Agni is a messenger from and to the other gods. He is ever-young, because the fire is re-lit every day, yet he is also immortal. In Indian tradition fire is also linked to Surya or the Sun and Mangala or Mars, and with the south-east direction.\nTeuk\u0101ya ekendriya is a name used in Jain tradition which refers to J\u012bvas said to be reincarnated as fire.\nCeremonial magic.\nFire and the other Greek classical elements were incorporated into the Golden Dawn system. Philosophus (4=7) is the elemental grade attributed to fire; this grade is also attributed to the Qabalistic Sephirah Netzach and the planet Venus. The elemental weapon of fire is the Wand. Each of the elements has several associated spiritual beings. The archangel of fire is Michael, the angel is Aral, the ruler is Seraph, the king is Djin, and the fire elementals (following Paracelsus) are called salamanders. Fire is considered to be active; it is represented by the symbol for Leo and it is referred to the lower right point of the pentacle in the Supreme Invoking Ritual of the Pentacle. Many of these associations have since spread throughout the occult community.\nTarot.\nFire in tarot symbolizes conversion or passion. Many references to fire in tarot are related to the usage of fire in the practice of alchemy, in which the application of fire is a prime method of conversion, and everything that touches fire is changed, often beyond recognition. The symbol of fire was a cue pointing towards transformation, the chemical variant being the symbol delta, which is also the classical symbol for fire. Conversion symbolized can be good, for example, refining raw crudities to gold, as seen in The Devil. Conversion can also be bad, as in The Tower, symbolizing a downfall due to anger. Fire is associated with the suit of rods/wands, and as such, represents passion from inspiration. As an element, fire has mixed symbolism because it represents energy, which can be helpful when controlled, but volatile if left unchecked.\nModern witchcraft.\nFire is one of the five elements that appear in most Wiccan traditions influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\nFreemasonry.\nIn freemasonry, fire is present, for example, during the ceremony of winter solstice, a symbol also of renaissance and energy. Freemasonry takes the ancient symbolic meaning of fire and recognizes its double nature: creation, light, on the one hand, and destruction and purification, on the other."}
{"id": "6315", "revid": "48993341", "url": "https://en.wikipedia.org/wiki?curid=6315", "title": "Air (classical element)", "text": "Air or Wind is one of the four classical elements along with water, earth and fire in ancient Greek philosophy and in Western alchemy.\nGreek and Roman tradition.\nAccording to Plato, it is associated with the octahedron; air is considered to be both hot and wet. The ancient Greeks used two words for air: \"aer\" meant the dim lower atmosphere, and \"aether\" meant the bright upper atmosphere above the clouds. Plato, for instance writes that \"So it is with air: there is the brightest variety which we call \"aether\", the muddiest which we call mist and darkness, and other kinds for which we have no name...\" Among the early Greek Pre-Socratic philosophers, Anaximenes (mid-6th century BCE) named air as the \"arche\". A similar belief was attributed by some ancient sources to Diogenes Apolloniates (late 5th century BCE), who also linked air with intelligence and soul (\"psyche\"), but other sources claim that his \"arche\" was a substance between air and fire. Aristophanes parodied such teachings in his play \"The Clouds\" by putting a prayer to air in the mouth of Socrates.\nAir was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BCE) selected four \"archai\" for his four roots: air, fire, water, and earth. Ancient and modern opinions differ as to whether he identified air by the divine name Hera, Aidoneus or even Zeus. Empedocles\u2019 roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BCE) took over the four elements of Empedocles. In the \"Timaeus\", his major cosmological dialogue, the Platonic solid associated with air is the octahedron which is formed from eight equilateral triangles. This places air between fire and water which Plato regarded as appropriate because it is intermediate in its mobility, sharpness, and ability to penetrate. He also said of air that its minuscule components are so smooth that one can barely feel them.\nPlato's student Aristotle (384\u2013322 BCE) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the universe to form the sublunary sphere. According to Aristotle, air is both hot and wet and occupies a place between fire and water among the elemental spheres. Aristotle definitively separated air from aether. For him, aether was an unchanging, almost divine substance that was found only in the heavens, where it formed celestial spheres.\nHumorism and temperaments.\nIn ancient Greek medicine, each of the four humours became associated with an element. Blood was the humor identified with air, since both were hot and wet. Other things associated with air and blood in ancient and medieval medicine included the season of spring, since it increased the qualities of heat and moisture; the sanguine temperament (of a person dominated by the blood humour); hermaphrodite (combining the masculine quality of heat with the feminine quality of moisture); and the northern point of the compass.\nAlchemy.\nThe alchemical symbol for air is an upward-pointing triangle, bisected by a horizontal line.\nModern reception.\nThe Hermetic Order of the Golden Dawn, founded in 1888, incorporates air and the other Greek classical elements into its teachings. The elemental weapon of air is the dagger which must be painted yellow with magical names and sigils written upon it in violet. Each of the elements has several associated spiritual beings. The archangel of air is Raphael, the angel is Chassan, the ruler is Ariel, the king is Paralda, and the air elementals (following Paracelsus) are called sylphs. Air is considerable and it is referred to the upper left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIn the Golden Dawn and many other magical systems, each element is associated with one of the cardinal points and is placed under the care of guardian Watchtowers. The Watchtowers derive from the Enochian system of magic founded by Dee. In the Golden Dawn, they are represented by the Enochian elemental tablets. Air is associated with the east, which is guarded by the First Watchtower.\nAir is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism.\nParallels in non-Western traditions.\nAir is not one of the traditional five Chinese classical elements. Nevertheless, the ancient Chinese concept of \"Qi\" or \"chi\" is believed to be close to that of air. \"Qi\" is believed to be part of every living thing that exists, as a kind of \"life force\" or \"spiritual energy\". It is frequently translated as \"energy flow\", or literally as \"air\" or \"breath\". (For example, \"ti\u0101nq\u00ec\", literally \"sky breath\", is the Chinese word for \"weather\"). The concept of qi is often reified, however no scientific evidence supports its existence.\nThe element air also appears as a concept in the Buddhist philosophy which has an ancient history in China.\nSome Western modern occultists equate the Chinese classical element of metal with \"air\", others with wood due to the elemental association of wind and wood in the bagua.\nEnlil was the god of air in ancient Sumer. Shu was the ancient Egyptian deity of air and the husband of Tefnut, goddess of moisture. He became an emblem of strength by virtue of his role in separating Nut from Geb. Shu played a primary role in the Coffin Texts, which were spells intended to help the deceased reach the realm of the afterlife safely. On the way to the sky, the spirit had to travel through the air as one spell indicates: \"I have gone up in Shu, I have climbed on the sunbeams.\"\nAccording to Jain beliefs, the element air is inhabited by one-sensed beings or spirits called v\u0101yuk\u0101ya ekendriya, sometimes said to inhabit various kinds of winds such as whirlwinds, cyclones, monsoons, west winds and trade winds. Prior to reincarnating into another lifeform, spirits can remain as v\u0101yuk\u0101ya ekendriya from anywhere between one instant to up to three-thousand years, depending on the karma of the spirits."}
{"id": "6316", "revid": "10951369", "url": "https://en.wikipedia.org/wiki?curid=6316", "title": "Water (classical element)", "text": "Water is one of the classical elements in ancient Greek philosophy along with air, earth and fire, in the Asian Indian system \"Panchamahabhuta\", and in the Chinese cosmological and physiological system \"Wu Xing\". In contemporary esoteric traditions, it is commonly associated with the qualities of emotion and intuition.\nGreek and Roman tradition.\nWater was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495 \u2013 c. 435 BC) selected four archai for his four roots: air, fire, water and earth. Empedocles roots became the four classical elements of Greek philosophy. Plato (427\u2013347 BC) took over the four elements of Empedocles. In the Timaeus, his major cosmological dialogue, the Platonic solid associated with water is the icosahedron which is formed from twenty equilateral triangles. This makes water the element with the greatest number of sides, which Plato regarded as appropriate because water flows out of one's hand when picked up, as if it is made of tiny little balls.\nPlato's student Aristotle (384\u2013322 BC) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the Universe to form the sublunary sphere. According to Aristotle, water is both cold and wet and occupies a place between air and earth among the elemental spheres.\nIn ancient Greek medicine, each of the four humours became associated with an element. Phlegm was the humor identified with water, since both were cold and wet. Other things associated with water and phlegm in ancient and medieval medicine included the season of Winter, since it increased the qualities of cold and moisture, the phlegmatic temperament, the feminine and the western point of the compass.\nIn alchemy, the chemical element of mercury was often associated with water and its alchemical symbol was a downward-pointing triangle.\nIndian tradition.\nAp (') is the Vedic Sanskrit term for water, in Classical Sanskrit occurring only in the plural is not an element.v, ' (sometimes re-analysed as a thematic singular, '), whence Hindi '. The term is from PIE \"hxap\" water.\nIn Hindu philosophy, the term refers to \nwater as an element, one of the \"Panchamahabhuta,\" or \"five great elements\". In Hinduism, it is also the name of the deva, a personification of water, (one of the Vasus in most later Puranic lists). The element water is also associated with Chandra or the moon and Shukra, who represent feelings, intuition and imagination.\nAccording to Jain tradition, water itself is inhabited by spiritual J\u012bvas called apak\u0101ya ekendriya.\nCeremonial magic.\nWater and the other Greek classical elements were incorporated into the Golden Dawn system. The elemental weapon of water is the cup. Each of the elements has several associated spiritual beings. The archangel of water is Gabriel, the angel is Taliahad, the ruler is Tharsis, the king is Nichsa and the water elementals are called Ondines. It is referred to the upper right point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nModern witchcraft.\nWater is one of the five elements that appear in most Wiccan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn."}
{"id": "6317", "revid": "43066271", "url": "https://en.wikipedia.org/wiki?curid=6317", "title": "Earth (classical element)", "text": "Earth is one of the classical elements, in some systems being one of the four along with air, fire, and water.\nEuropean tradition.\nEarth is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with qualities of heaviness, matter and the terrestrial world. Due to the hero cults, and chthonic underworld deities, the element of \"earth\" is also associated with the sensual aspects of both life and death in later occultism.\nEmpedocles of Acragas proposed four \"archai\" by which to understand the cosmos: \"fire\",\" air\", \"water\", and \"earth\". Plato (427\u2013347 BCE) believed the elements were geometric forms (the platonic solids) and he assigned the cube to the element of \"earth\" in his dialogue \"Timaeus\". Aristotle (384\u2013322 BCE) believed \"earth\" was the heaviest element, and his theory of \"natural place\" suggested that any \"earth\u2013laden\" substances, would fall quickly, straight down, towards the center of the \"cosmos\".\nIn Classical Greek and Roman myth, various goddesses \nrepresented the Earth, seasons, crops and fertility, including Demeter and Persephone; Ceres; the Horae (goddesses of the seasons), and Proserpina; and Hades (Pluto) who ruled the souls of dead in the Underworld.\nIn ancient Greek medicine, each of the four humours became associated with an element. Black bile was the humor identified with earth, since both were cold and dry. Other things associated with earth and black bile in ancient and medieval medicine included the season of fall, since it increased the qualities of cold and aridity; the melancholic temperament (of a person dominated by the black bile humour); the feminine; and the southern point of the compass.\nIn alchemy, earth was believed to be primarily dry, and secondarily cold, (as per Aristotle). Beyond those classical attributes, the chemical substance salt, was associated with earth and its alchemical symbol was a downward-pointing triangle, bisected by a horizontal line.\nIndian tradition.\nPrithvi (Sanskrit: ', also ') is the Hindu \"earth\" and mother goddess. According to one such tradition, she is the personification of the Earth itself; according to another, its actual mother, being \"Prithvi Tattwa\", the essence of the element earth.\nAs \"Prithvi Mata\", or \"Mother Earth\", she contrasts with \"Dyaus Pita\", \"father sky\". In the Rigveda, \"earth\" and sky are frequently addressed as a duality, often indicated by the idea of two complementary \"half-shells.\" In addition, the element Earth is associated with Budha or Mercury who represents communication, business, mathematics and other practical matters.\nJainism mentions one-sensed beings or spirits believed to inhabit the element earth sometimes classified as p\u1e5bthv\u012bk\u0101ya ekendriya.\nCeremonial magic.\nEarth and the other Greek classical elements were incorporated into the Golden Dawn system. Zelator is the elemental grade attributed to earth; this grade is also attributed to the Sephirot of Malkuth. The elemental weapon of earth is the Pentacle. Each of the elements has several associated spiritual beings. The archangel of earth is Uriel, the angel is Phorlakh, the ruler is Kerub, the king is Ghob, and the earth elementals (following Paracelsus) are called gnomes. Earth is considered to be passive; it is represented by the symbol for Taurus, and it is referred to the lower left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\nIt is sometimes represented by its Tattva or by a downward pointing triangle with a horizontal line through it.\nModern witchcraft.\nEarth is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism which was in turn inspired by the Golden Dawn.\nOther traditions.\n\"Earth\" is represented in the Aztec religion by a house; to the Hindus, a lotus; to the Scythians, a plough; to the Greeks, a wheel; and in Christian iconography; bulls and birds."}
{"id": "6319", "revid": "1261302934", "url": "https://en.wikipedia.org/wiki?curid=6319", "title": "Blue Jam", "text": "Blue Jam was an ambient, surreal dark comedy and horror radio programme created and directed by Chris Morris. It was broadcast on BBC Radio 1 in the early hours of the morning, for three series from 1997 to 1999.\nThe programme gained cult status due to its unique mix of surreal monologue, ambient soundtrack, synthesised voices, heavily edited broadcasts and recurring sketches. It featured vocal performances of Kevin Eldon, Julia Davis, Mark Heap, David Cann and Amelia Bullmore, with Morris himself delivering disturbing monologues, one of which was revamped and made into the BAFTA-winning short film \"My Wrongs #8245\u20138249 &amp; 117\". Writers who contributed to the programme included Graham Linehan, Arthur Mathews, Peter Baynham, David Quantick, Jane Bussmann, Robert Katz and the cast.\nThe programme was adapted into the TV series \"Jam\", which aired in 2000.\nProduction.\nOn his inspiration for making the show, Morris commented: \"It was so singular, and it came from a mood, quite a desolate mood. I had this misty, autumnal, boggy mood anyway, so I just went with that. But no doubt getting to the end of something like \"Brass Eye\", where you've been forced to be a sort of surrogate lawyer, well, that's the most creatively stifling thing you could possibly do.\" Morris also described the show as being \"like the nightmares you have when you fall asleep listening to the BBC World Service\" (a reference to the World Service also appears in one of the monologues read by Morris).\nMorris originally requested that the show be broadcast at 3 a.m. on Radio 1 \"because at that hour, on insomniac radio, the amplitude of terrible things is enormously overblown\". As a compromise, the show was broadcast at midnight without much promotion. Morris reportedly included sketches too graphic or transgressive for radio that he knew would be cut so as to make his other material seem less transgressive in comparison. During the airing of episode 6 of series one, a re-editing of the Archbishop of Canterbury's speech at Princess Diana's funeral was deemed too offensive for broadcast, and was switched with a different episode as it aired.\nFormat and style.\nEach episode opened (and closed) with a short spoken monologue (delivered by Morris) describing, in surreal, broken language, various bizarre feelings and situations (for example: \"when you sick so sad you cry, and in crying cry a whole leopard from your eye\"), set to ambient music interspersed with short clips of other songs and sounds. The introduction would always end with \"welcome in Blue Jam\", inviting the listener, who is presumably experiencing such feelings, to get lost in the program. (This format was replicated in the television adaptation \"Jam\", often reusing opening monologues from series 3 of the radio series.) The sketches within dealt with heavy and taboo topics, such as murder, suicide, missing or dead children, and rape.\nCommon recurring sketches.\nThe sketches not listed are often in the style of a documentary; characters speak as if being interviewed about a recent event. In one sketch, a character voiced by Morris describes a man attempting to commit suicide by jumping off a second-story balcony repeatedly; in another, an angry man (Eldon) shouts about how his car, after being picked up from the garage, is only four feet long.\nRadio stings.\nMorris included a series of 'radio stings', bizarre sequences of sounds and prose as a parody of modern DJs' own soundbites and self-advertising pieces. Each one revolves around a contemporary DJ, such as Chris Moyles, Jo Whiley and Mark Goodier, typically involving each DJ dying in a graphic way or going mad in some form \u2013 for example, Chris Moyles covering himself in jam and hanging himself from the top of a building.\nEpisodes.\nThree series were produced, with a total of eighteen episodes. All episodes were originally broadcast weekly on BBC Radio 1. Series 1 was broadcast from 14 November to 19 December 1997; series 2 was broadcast from 27 March to 1 May 1998; and series 3 broadcast from 21 January to 25 February 1999.\nThe first five episodes of series 1 of \"Blue Jam\" were repeated by BBC Radio 4 Extra in February and March 2014, and series 2 was rebroadcast in December.\nMusic.\n\"Blue Jam\" features songs, generally of a downtempo nature, interspersed between (and sometimes during) sketches. Artists featured includes Massive Attack, Air, Morcheeba, The Chemical Brothers, Bj\u00f6rk, Aphex Twin, Everything But the Girl and Dimitri from Paris, as well as various non-electronic artists including Sly and the Family Stone, Serge Gainsbourg, The Cardigans and Eels.\nReception.\n\"Blue Jam\" was favourably reviewed on several occasions by \"The Guardian\" and also received a positive review by \"The Independent\".\nDigital Spy wrote in 2014: \"It's a heady cocktail that provokes an odd, unsettling reaction in the listener, yet \"Blue Jam\" is still thumpingly and frequently laugh-out-loud hilarious.\" \"Hot Press\" called it \"as odd as comedy gets\".\nCD release.\nA CD of a number of \"Blue Jam\" sketches was released on 23 October 2000 by record label Warp. Although the CD claims to have 22 tracks, the last one, \"www.bishopslips.com\", is not a track, but rather a reference to the \"Bishopslips\" sketch, which was cut in the middle of a broadcast. Most of the sketches on the CD were remade for \"Jam\".\nRelated shows.\n\"Blue Jam\" was later made for television and broadcast on Channel 4 as \"Jam\". It used unusual editing techniques to achieve an unnerving ambience in keeping with the radio show. Many of the sketches were lifted from the radio version, even to the extent of simply setting images to the radio soundtrack. A subsequent \"re-mixed\" airing, called \"Jaaaaam\" was even more extreme in its use of post-production gadgetry, often heavily distorting the footage.\n\"Blue Jam\" shares parallels with early editions of a US public radio show \"Joe Frank: Work in Progress\" from the mid-1980s, that Joe Frank did on the NPR affiliate station, KCRW, in Santa Monica, California."}
{"id": "6321", "revid": "22475055", "url": "https://en.wikipedia.org/wiki?curid=6321", "title": "Channel 4", "text": "Channel 4 is a British free-to-air public broadcast television channel owned and operated by Channel Four Television Corporation. It is publicly owned but, unlike the BBC, it receives no public funding and is funded entirely by its commercial activities, including advertising. It began its transmission in 1982 and was established to provide a fourth television service in the United Kingdom. At the time, the only other channels were the licence-funded BBC1 and BBC2, and a single commercial broadcasting network, ITV.\nOriginally a subsidiary of the Independent Broadcasting Authority (IBA), the station is now owned and operated by Channel Four Television Corporation, a public corporation of the Department for Culture, Media and Sport, which was established in 1990 and came into operation in 1993. Until 2010, Channel 4 did not broadcast in Wales, but many of its programmes were re-broadcast there by the Welsh fourth channel S4C. In 2010, Channel 4 extended service into Wales and became a nationwide television channel. The network's headquarters are in London and Leeds, with creative hubs in Manchester, Glasgow and Bristol.\nHistory.\nConception.\nBefore Channel 4 and S4C, Britain had three terrestrial television services: BBC1, BBC2, and ITV, with BBC2 the last to launch in 1964. The Broadcasting Act 1980 began the process of adding a fourth; Channel 4 was formally created, along with its Welsh counterpart, by an act of Parliament in 1982.\nThe notion of a second commercial broadcaster in the United Kingdom had been around since the inception of ITV in 1954 and its subsequent launch in 1955; the idea of an \"ITV2\" was long expected and pushed for. Indeed, television sets sold throughout the 1970s and early 1980s often had a spare tuning button labelled \"ITV 2\" or \"IBA 2\". Throughout ITV's history and until Channel 4 finally became a reality, a perennial dialogue existed between the GPO, the government, the ITV companies and other interested parties, concerning the form such an expansion of commercial broadcasting would take. Most likely, politics had the biggest impact leading to a delay of almost three decades before the second commercial channel became a reality.\nOne benefit of the late arrival of the channel was that its frequency allocations at each transmitter had already been arranged in the early 1960s when the launch of an \"ITV2\" was anticipated. This led to good coverage across most of the country and few problems of interference with other UK-based transmissions; a stark contrast to the difficulties associated with Channel 5's launch almost 15 years later.\nWales.\nAt the time the fourth service was being considered, a movement in Wales lobbied for the creation of dedicated service that would air Welsh language programmes, then only catered for at off-peak times on BBC Wales and HTV. The campaign was taken so seriously by Gwynfor Evans, former president of Plaid Cymru, that he threatened the government with a hunger strike were it not to honour the plans.\nThe result was that Channel 4 as seen by the rest of the United Kingdom would be replaced in Wales by S4C (Sianel Pedwar Cymru, meaning \"Channel Four Wales\" in Welsh). Operated by a specially created authority, S4C would air programmes in Welsh made by HTV, the BBC and independent companies. Initially, limited frequency space meant that Channel 4 could not be broadcast alongside S4C, though some Channel 4 programmes would be aired at less popular times on the Welsh variant; this practice continued until the closure of S4C's analogue transmissions in 2010, at which time S4C became a fully Welsh channel. With this conversion of the Wenvoe transmitter group in Wales to digital terrestrial broadcasting on 31 March 2010, Channel 4 became a nationwide television channel for the first time.\nSince then, carriage on digital cable, satellite and digital terrestrial has introduced Channel 4 to Welsh homes where it is now universally available.\n1982\u20131992: Launch and IBA control.\nAfter some months of test broadcasts, the new broadcaster began scheduled transmissions on 2 November 1982 from Scala House, the former site of the Scala Theatre. Its initial broadcasts reached 87% of the United Kingdom.\nThe first voice heard on Channel 4's opening day of 2 November 1982 was that of continuity announcer Paul Coia who said: \"Good afternoon. It's a pleasure to be able to say to you, welcome to Channel Four.\" Following the announcement, the channel played a montage of clips from its programmes set to the station's signature tune, \"Fourscore\", written by David Dundas, which would form the basis of the station's jingles for its first decade. The first programme to air on the channel was the teatime game show \"Countdown\", produced by Yorkshire Television, at 16:45. The first person to be seen on Channel 4 was Richard Whiteley, with Ted Moult being the second. The first woman on the channel, contrary to popular belief, was not Whiteley's \"Countdown\" co-host Carol Vorderman, but a lexicographer only ever identified as Mary. Whiteley opened the show with the words: \"As the countdown to a brand new channel ends, a brand new countdown begins.\" On its first day, Channel 4 also broadcast the soap opera \"Brookside\", which often ran storylines thought to be controversial; this ran until 2003.\nAfter three days, ITV chiefs called for founding chief executive Jeremy Isaacs to resign due to poor ratings. Critics called it \"Channel Bore\" and \"Channel Snore\".\nAt its launch, Channel 4 committed itself to providing an alternative to the existing channels, an agenda in part set out by its remit which required the provision of programming to minority groups. In step with its remit, the channel became well received both by minority groups and the arts and cultural worlds during this period under Isaacs, during which the channel gained a reputation for programmes on the contemporary arts. Two programmes captured awards from the Broadcasting Press Guild in March 1983: best comedy for \"The Comic Strip Presents\u2026Five Go Mad in Dorset,\" and best on-screen performance in a non-acting role for Tom Keating in his series \"On Painters\". Channel 4 co-commissioned Robert Ashley's television opera \"Perfect Lives\", which it premiered over several episodes in 1984. The channel often did not receive mass audiences for much of this period, as might be expected for a station focusing on minority interests. During this time, Channel 4 also began the funding of independent films, such as the Merchant Ivory docudrama \"The Courtesans of Bombay\".\nIn 1987, Richard Attenborough replaced Edmund Dell as chairman. In 1988, Michael Grade became CEO.\nIn 1992, Channel 4 faced its first libel case which was brought by Jani Allan, a South African journalist, who objected to her representation in Nick Broomfield's documentary \"The Leader, His Driver and the Driver's Wife\".\n1993\u20132006: Channel Four Television Corporation.\nAfter control of the station passed from the Channel Four Television Company to the Channel Four Television Corporation in 1993, a shift in broadcasting style took place. Instead of aiming for minority tastes, it began to focus on the edges of the mainstream, and the centre of the mass market itself. It began to show many American programmes in peak viewing time, far more than it had previously done.\nIn September 1993, the channel broadcast the direct-to-TV documentary film \"Beyond Citizen Kane\", in which it displayed the dominant position of the Rede Globo (now TV Globo) television network, and discussed its influence, power, and political connections in Brazil.\nThroughout the 1990s and 2000s, Channel 4 gave many popular and influential American comedy and drama series their first exposure on British television, such as \"Friends\", \"Cheers\", \"Will &amp; Grace\", \"NYPD Blue\", \"ER\", \"Desperate Housewives\", ', \"Without a Trace\", \"Home Improvement\", \"Frasier\", \"Lost\", \"Nip/Tuck\", \"Ally McBeal\", \"Dawson's Creek\", \"Oz\", \"Sex and the City\", \"The Sopranos\", \"Scrubs,\" \"King of the Hill, Babylon 5\", \"Stargate SG-1\", ', \"Andromeda,\" \"Family Guy\", \"South Park\" and \"Futurama\".\nIn the early 2000s, Channel 4 began broadcasting reality formats such as \"Big Brother\" and obtained the rights to broadcast mass appeal sporting events like cricket and horse racing. This new direction increased ratings and revenues. The popularity of \"Big Brother\" led to the launches of other, shorter-lived new reality shows to chase the populist audience, such as \"The Salon\", \"Shattered\" and \"Space Cadets\".\nIn addition, the corporation launched several new television channels through its new 4Ventures offshoot, including Film4, At the Races, E4 and More4.\nPartially in reaction to its new \"populist\" direction, the Communications Act 2003 directed the channel to demonstrate innovation, experimentation, and creativity, appeal to the tastes and interests of a culturally diverse society, and include programmes of an educational nature which exhibit a distinctive character.\nOn 31 December 2004, Channel 4 launched a new visual identity in which the logo is disguised as different objects and the \"4\" can be seen from an angle.\nUnder the leadership of Freeview founder Andy Duncan, 2005 saw a change of direction for Channel 4's digital channels. The company made E4 free-to-air on digital terrestrial television, and launched a new free-to-air digital channel called More4. By October, Channel 4 had joined the Freeview consortium. By July 2006, Film4 had likewise become free-to-air and restarted broadcasting on digital terrestrial.\nVenturing into radio broadcasting, 2005 saw Channel 4 purchase 51% of shares in the now defunct Oneword radio station, with UBC Media holding on to the remaining shares. New programmes such as the weekly, half-hour \"The Morning Report\" news programme were among some of the new content Channel 4 provided for the station, with the name 4Radio being used. As of early 2009, however, Channel 4's future involvement in radio remained uncertain.\nSince 2006.\nBefore the digital switchover, Channel 4 raised concerns over how it might finance its public service obligations afterward. In April 2006, it was announced that Channel 4's digital switch-over costs would be paid for by licence fee revenues.\nIn July 2007, Channel 4 paid \u00a328million for a 50% stake in the TV business of British media company EMAP, which had seven music video channels. On 15 August 2008, 4Music was launched across the UK. Channel 4 announced interest in launching a high-definition version of Film4 on Freeview, to coincide with the launch of Channel 4 HD, but the fourth HD slot was given to Channel 5 instead.\nOn 2 November 2007, the station celebrated its 25th birthday. It showed the first episode of \"Countdown\", an anniversary \"Countdown\" special, and a special edition of \"The Big Fat Quiz\". It used the original multicoloured 1982\u20131996 blocks logo on presentation, and idents using the Fourscore jingle throughout the day.\nIn November 2009, Channel 4 launched a week of 3D television, broadcasting selected programmes each night using stereoscopic ColorCode 3D technology. The accompanying 3D glasses were distributed through Sainsbury's supermarkets.\nOn 29 September 2015, Channel 4 revamped its presentation for a fifth time; the new branding downplayed the \"4\" logo from most on-air usage, in favour of using the shapes from the logo in various forms. Four new idents were filmed by Jonathan Glazer, which featured the shapes in various real-world scenes depicting the \"discovery\" and \"origins\" of the shapes. The full logo was still occasionally used, but primarily for off-air marketing. Channel 4 also commissioned two new corporate typefaces, \"Chadwick\", and \"Horseferry\" (a variation of Chadwick with the aforementioned shapes incorporated into its letter forms), for use across promotional material and on-air.\nIn June 2017, it was announced that Alex Mahon would be the next chief executive, and would take over from David Abraham, who left in November 2017.\nOn 31 October 2017, Channel 4 introduced a new series of idents continuing the theme, this time depicting the logo shapes as having formed into an anthropomorphic \"giant\" character.\nOn 25 September 2021, Channel 4 and several of its sub-channels went off air after an incident at Red Bee Media's playout centre in west London. Channel 4, More4, Film4, E4, 4Music, The Box, Box Hits, Kiss, Magic and Kerrang! stopped transmitting, but 4seven was not impacted. The incident still affected a number of the channels by 30 September. The London Fire Brigade confirmed that a gas fire prevention system at the site had been activated, but firefighters found no sign of fire. Activation of the fire suppression system caused catastrophic damage to some systems, such as Channel 4's subtitles, signing, and audio description system. An emergency backup subtitling system also failed, leaving Channel 4 unable to provide access services to viewers. This situation was criticised by the National Deaf Children's Society, which complained to the broadcasting watchdog. A new subtitling, signing and audio description system had to be built from scratch. The service eventually began to return at the end of October. In June 2022 after a six-month long investigation, Ofcom found that Channel 4 had breached its broadcast licence conditions on two grounds: Missing its subtitles quota on Freesat for 2021 and failure to effectively communicate with affected audiences.\nOn 23 December 2021, Jon Snow presented \"Channel 4 News\" for the last time, after 32 years as a main presenter on the programme, making Snow one of the UK's longest-serving presenters on a national news programme.\nAbandoned privatisation.\nChannel 4's parent company, Channel Four Television Corporation, was considered for privatisation by the governments of Margaret Thatcher, John Major and Tony Blair. In 2014, the Cameron-Clegg coalition government drew up proposals to privatise the corporation but the sale was blocked by the Liberal Democrat Business Secretary Vince Cable. In 2016, the future of the channel was again being looked into by the government, with analysts suggesting several options for its future. In June 2021, the government of Boris Johnson was considering selling the channel.\nIn April 2022, the Department for Culture, Media and Sport acknowledged that ministerial discussions were taking place regarding the sale of Channel Four Television Corporation. The channel's chief executive, Alex Mahon, expressed disappointment at this, saying that its vision for the future was \"rooted in continued public ownership\".\nIn January 2023, Michelle Donelan confirmed that the plans to sell Channel 4 were scrapped and that it would remain in public ownership for the foreseeable future.\nPublic service remit.\nChannel 4 was established with, and continues to hold, a remit of public service obligations which it must fulfil. The remit changes periodically, as dictated by various broadcasting and communications acts, and is regulated by the various authorities Channel 4 has been answerable to; originally the IBA, then the ITC and now Ofcom.\nThe preamble of the remit as per the Communications Act 2003 states that:\nThe remit also involves an obligation to provide programming for schools, and a substantial amount of programming produced outside of Greater London.\n, the Media and Journalism Research Center evaluated Channel 4 to be \"Independent State Managed/Owned Media\" under its State Media Matrix.\nCarriage.\nChannel 4 was carried from its beginning on analogue terrestrial, the standard means of television broadcast in the United Kingdom. It continued to be broadcast through these means until the changeover to digital terrestrial television in the United Kingdom was complete. Since 1998, it has been universally available on digital terrestrial, and the Sky platform (initially encrypted, though encryption was dropped on 14 April 2008 and is now free of charge and available on the Freesat platform) as well as having been available from various times in various areas, on analogue and digital cable networks.\nDue to its special status as a public service broadcaster with a specific remit, it is afforded free carriage on the terrestrial platforms, in contrast with other broadcasters such as ITV.\nChannel 4 is available outside the United Kingdom; it is widely available in the Republic of Ireland, the Netherlands, Belgium and Switzerland. The channel is registered to broadcast within the European Union/EEA through the Luxembourg Broadcasting Regulator (ALIA).\nSince 2019, it has been offered by British Forces Broadcasting Service (BFBS) to members of the British Armed Forces and their families around the world, BFBS Extra having previously carried a selection of Channel 4 programmes.\nThe Channel 4 website allows people in the United Kingdom to watch Channel 4 live. Previously, some programmes (mostly international imports) were not shown. Channel 4 is also provided by Virgin Mobile's DAB mobile TV service, which has the same restrictions as the Internet live stream. Channel 4 is also carried by the Internet TV service TVCatchup and was previously carried by Zattoo until the operator removed the channel from its platform.\nChannel 4 also makes some of its programming available \"on demand\" via cable and the internet through the Channel 4 VoD service.\nFunding.\nDuring its first decade, Channel 4 was funded by subscriptions collected by the IBA from the ITV regional companies, in return for which each company had the right to sell advertisements on the fourth channel in its own region and keep the proceeds. This meant that ITV and Channel 4 were not in competition with each other, and often promoted each other's programmes.\nA change in funding came about under the Broadcasting Act 1990 when the new corporation was afforded the ability to fund itself. Originally this arrangement left a \"safety net\" guaranteed minimum income should the revenue fall too low, funded by large insurance payments made to the ITV companies. Such a subsidy was never required, however, and these premiums were phased out by the government in 1998. After the link with ITV was cut, the cross-promotion which had existed between ITV and Channel 4 also ended.\nIn 2007, owing to severe funding difficulties, the channel sought government help and was granted a payment of \u00a314\u00a0million over a six-year period. The money was to have come from the television licence fee, and would have been the first time that money from the licence fee had been given to any broadcaster other than the BBC. However, the plan was scrapped by the Secretary of State for Culture, Media and Sport, Andy Burnham, ahead of \"broader decisions about the future framework of public service broadcasting\". The broadcasting regulator Ofcom released its review in January 2009 in which it suggested that Channel 4 would preferably be funded by \"partnerships, joint ventures or mergers\".\n, it breaks even in much the same way as most privately run commercial stations through the sale of on-air advertising, programme sponsorship, and the sale of any programme content and merchandising rights it owns, such as overseas broadcasting rights and domestic video sales. For example, its total revenues were \u00a3925\u00a0million with 91% derived from sale of advertising. It also has the ability to subsidise the main network through any profits made on the corporation's other endeavours, which have in the past included subscription fees from stations such as E4 and Film4 (now no longer subscription services) and its \"video-on-demand\" sales. In practice, however, these other activities are loss-making, and are subsidised by the main network. According to Channel 4's published accounts, for 2005 the extent of this cross-subsidy was some \u00a330\u00a0million.\nProgramming.\nChannel 4 is a \"publisher-broadcaster\", meaning that it commissions or \"buys\" all of its programming from companies independent of itself. It was the first UK broadcaster to do so on a significant scale; such commissioning is a stipulation which is included in its licence to broadcast. In consequence, numerous independent production companies emerged, though external commissioning on the BBC and in ITV (where a quota of 25% minimum of total output has been imposed since the Broadcasting Act 1990 came into force) has become regular practice, as well as on the numerous stations that launched later. Although it was the first British broadcaster to commission all of its programmes from third parties, Channel 4 was the last terrestrial broadcaster to outsource its transmission and playout operations (to Red Bee Media), after 25 years in-house.\nThe requirement to obtain all content externally is stipulated in its licence. Additionally, Channel 4 also began a trend of owning the copyright and distribution rights of the programmes it aired, in a manner that is similar to the major Hollywood studios' ownership of television programmes that they did not directly produce. Thus, although Channel 4 does not produce programmes, many are seen as belonging to it.\nIt was established with a specific intention of providing programming to groups of minority interests, not catered for by its competitors, which at the time were only the BBC and ITV.\nChannel 4 also pioneered the concept of 'stranded programming', where seasons of programmes following a common theme would be aired and promoted together. Some would be very specific, and run for a fixed period of time; the \"4 Mation\" season, for example, showed innovative animation. Other, less specific strands, were (and still are) run regularly, such as \"T4\", a strand of programming aimed at teenagers, on weekend mornings (and weekdays during school/college holidays); \"Friday Night Comedy\", a slot where the channel would pioneer its style of comedy commissions, \"4Music\" (now a separate channel) and \"4Later\", an eclectic collection of offbeat programmes transmitted in the early hours of the morning.\nFor a period in the mid-1980s, some sexually explicit arthouse films would be screened with a \"red triangle\" graphic in the upper right of the screen.\nIn recent years concerns have arisen regarding a number of programmes made for Channel 4, that are believed missing from all known archives.\nMost watched programmes.\nThe following is a list of the 10 most watched shows on Channel 4 since launch, based on Live +28 data supplied by BARB, and archival data published by Channel 4.\nComedy.\nDuring the station's early days, the screenings of innovative short one-off comedy films produced by a rotating line-up of alternative comedians went under the title of \"The Comic Strip Presents\". \"The Optimist\" was the world's first dialogue-free television comedy, and one of the channel's earliest commissioned programs. \"The Tube\" and \"Saturday Live/Friday Night Live\" also launched the careers of a number of comedians and writers. Channel 4 broadcast a number of popular American imports, including \"Cheers\", \"The Cosby Show\", \"Roseanne\", \"Home Improvement\", \"Friends\", \"Sex and the City\", \"Everybody Loves Raymond\", \"South Park\", \"Family Guy\", \"Futurama\", \"Frasier\", \"Scrubs\", and \"Will &amp; Grace\". Other significant US acquisitions include \"The Simpsons\", for which the station was reported to have paid \u00a3700,000 per episode for the terrestrial television rights back in 2004, and continues to air on the channel daily.\nIn April 2010, Channel 4 became the first UK broadcaster to adapt the American comedy institution of roasting to British television, with \"A Comedy Roast\".\nIn 2010, Channel 4 organised \"Channel 4's Comedy Gala\", a comedy benefit show in aid of Great Ormond Street Children's Hospital. With over 25 comedians appearing, it billed it as \"the biggest live stand up show in United Kingdom history\". Filmed live on 30 March in front of 14,000 at The O2 Arena in London, it was broadcast on 5 April. This has continued to 2016.\nIn 2021, Channel 4 decided to revive The British Comedy Awards as part of its Stand Up To Cancer programming. The ceremony, billed as The National Comedy Awards was due to be held in the spring of 2021 but was delayed due to the Coronavirus pandemic until 15 December 2021 and then cancelled a week before it was due to be held, due to concerns over the Omicron variant.\nThe ceremony was finally held on 2 March 2022 and broadcast on Channel 4 three days later. The National Comedy Awards was not the only live comedy event that was part of the channel's Christmas schedule that was effected by these concerns as \"Joe Lycett: Mummy's Big Christmas Do!\" was also postponed, with the 22 December show due to air as a pilot for a new series called \"Mummy's House Party\" in spring 2022. Lycett's Birmingham-based extravaganza finally made it to air on 3 July 2022 as \"Joe Lycett's Big Pride Party\", with 0.29 million viewers tuning in (compared to 0.69 million for \"The Cruise\" on Channel 5).\nFactual and current affairs.\nChannel 4 has a strong reputation for history programmes and documentaries. Its news service \"Channel 4 News\" is supplied by ITN, whilst its long-standing investigative documentary series, \"Dispatches\", gains attention from other media outlets. Its live broadcast of the first public autopsy in the UK for 170 years, carried out by Gunther von Hagens in 2002 and the 2003 one-off stunt \"Derren Brown Plays Russian Roulette Live\" proved controversial.\nA season of television programmes about masturbation, called \"Wank Week\", was to be broadcast in the United Kingdom by Channel 4 in March 2007. The series came under public attack from senior television figures, and was pulled amid claims of declining editorial standards and concern for the channel's public service broadcasting credentials.\nFourDocs.\nFourDocs was an online documentary site provided by Channel 4. It allowed viewers to upload their own documentaries to the site for others to view. It focused on documentaries of between 3 and 5 minutes. The website also included an archive of classic documentaries, interviews with documentary filmmakers and short educational guides to documentary-making. It won a Peabody Award in 2006. The site also included a strand for documentaries of under 59 seconds, called \"Microdocs\".\nSchools programming.\nChannel 4 is obliged to carry schools programming as part of its remit and licence.\nITV Schools on Channel 4.\nSince 1957 ITV had produced schools programming, which became an obligation. In 1987, five years after the station was launched, the IBA afforded ITV free carriage of these programmes during Channel 4's then-unused weekday morning hours. This arrangement allowed the ITV companies to fulfil their obligation to provide schools programming, whilst allowing ITV itself to broadcast regular programmes complete with advertisements. During the times in which schools programmes were aired Central Television provided most of the continuity with play-out originating from Birmingham.\nChannel 4 Schools/4Learning.\nAfter the restructuring of the station in 1993, ITV's obligations to provide such programming on Channel 4's airtime passed to Channel 4 itself, and the new service became Channel 4 Schools, with the new corporation administering the service and commissioning its programmes, some still from ITV, others from independent producers.\nIn March 2008, the 4Learning interactive new media commission Slabovia.tv was launched. The Slabplayer online media player showing TV shows for teenagers was launched on 26 May 2008.\nThe schools programming has always had elements which differ from its normal presentational package. In 1993, the Channel 4 Schools idents featured famous people in one category, with light shining on them in front of an industrial-looking setting supplemented by instrumental calming music. This changed in 1996 with the circles look to numerous children touching the screen, forming circles of information then picked up by other children. The last child would produce the Channel 4 logo in the form of three vertical circles, with another in the middle and to the left containing the Channel 4 logo.\nA present feature of presentation was a countdown sequence featuring, in 1993 a slide with the programme name, and afterwards an extended sequence matching the channel branding. In 1996, this was an extended ident with timer in top left corner, and in 1999 following the adoption of the squares look, featured a square with timer slowly make its way across the right of the screen with people learning and having fun while doing so passing across the screen. It finished with the Channel 4 logo box on the right of the screen and the name 'Channel 4 Schools' being shown. This was adapted in 2000 when the service's name was changed to '4Learning'.\nIn 2001, this was altered to various scenes from classrooms around the world and different parts of school life. The countdown now flips over from the top, right, bottom and left with each second, and ends with four coloured squares, three of which are aligned vertically to the left of the Channel 4 logo, which is contained inside the fourth box. The tag 'Learning' is located directly beneath the logo. The final countdown sequence lasted between 2004 and 2005 and featured a background video of current controversial issues, overlaid with upcoming programming information. The video features people in the style of graffiti enacting the overuse of CCTV cameras, fox hunting, computer viruses and pirate videos, relationships, pollution of the seas and violent lifestyles. Following 2005, no branded section has been used for schools programmes.\nReligious programmes.\nFrom the outset, Channel 4 did not conform to the expectations of conventional religious broadcasting in the UK. John Ranelagh, first commissioning editor for religion, made his priority 'broadening the spectrum of religious programming' and more 'intellectual' concerns. He also ignored the religious programme advisory structure that had been put in place by the BBC, and subsequently adopted by ITV. Ranelagh's first major commission caused a furore, a three-part documentary series called \"\". The programmes, transmitted during the Easter period of 1984, seemed to advocate the idea that the Gospels were unreliable, Jesus may have indulged in witchcraft, and that he may not have even existed. The series triggered a public outcry, and marked a significant moment in the deterioration in the relationship between the UK's broadcasting and religious institutions.\nFilm.\nNumerous genres of film-making \u2013 such as comedy, drama, documentary, adventure/action, romance and horror/thriller \u2013 are represented in the channel's schedule. From the launch of Channel 4 until 1998, film presentations on C4 would often be broadcast under the \"Film on Four\" banner.\nIn March 2005, Channel 4 screened the uncut Lars von Trier film \"The Idiots\", which includes unsimulated sexual intercourse, making it the first UK terrestrial channel to do so. The channel had previously screened other films with similar material but censored and with warnings.\nSince 1 November 1998, Channel 4 has had a digital subsidiary channel dedicated to the screening of films. This channel launched as a paid subscription channel under the name \"FilmFour\", and was relaunched in July 2006 as a free-to-air channel under the current name of \"Film4\". The Film4 channel carries a wide range of film productions, including acquired and Film4-produced projects. Channel 4's general entertainment channels E4 and More4 also screen feature films at certain points in the schedule as part of their content mix.\nGlobal warming.\nOn 8 March 2007, Channel 4 screened a documentary, \"The Great Global Warming Swindle\" stating that global warming is \"a lie\" and \"the biggest scam of modern times\". The programme's accuracy were disputed on multiple points, and commentators criticised it for being one-sided, observing that the mainstream position on global warming is supported by the scientific academies of the major industrialised nations. There were 246 complaints to Ofcom as of 25 April 2007, including allegations that the programme falsified data. The programme was criticised by scientists and scientific organisations, and various scientists who participated in the documentary claimed their views had been distorted.\n\"Against Nature\": An earlier controversial Channel 4 programme made by Martin Durkin which was also critical of the environmental movement and was charged by the UK's Independent Television Commission for misrepresenting and distorting the views of interviewees by selective editing.\n\"The Greenhouse Conspiracy\": An earlier Channel 4 documentary broadcast on 12 August 1990, as part of the \"Equinox\" series, in which similar claims were made. Three of the people interviewed (Lindzen, Michaels and Spencer) were also interviewed in \"The Great Global Warming Swindle\".\nAhmadinejad's Christmas speech.\nIn the \"Alternative Christmas address\" of 2008, a Channel 4 tradition since 1993 with a different presenter each year, Iranian President Mahmoud Ahmadinejad made a thinly veiled attack on the United States by claiming that Christ would have been against \"bullying, ill-tempered and expansionist powers\".\nThe broadcast was rebuked by human rights activists, politicians and religious figures, including Peter Tatchell, Louise Ellman, Ron Prosor and Rabbi Aaron Goldstein. A spokeswoman for the Foreign and Commonwealth Office said: \"President Ahmadinejad has, during his time in office, made a series of appalling anti-Semitic statements. The British media are rightly free to make their own editorial choices, but this invitation will cause offence and bemusement not just at home but among friendly countries abroad\".\nHowever, Channel 4 was defended by Stonewall director Ben Summerskill who stated: \"In spite of his ridiculous and often offensive views, it is an important way of reminding him that there are some countries where free speech is not repressed...If it serves that purpose, then Channel 4 will have done a significant public service\". Dorothy Byrne, Channel 4's head of news and current affairs, said in response to the station's critics: \"As the leader of one of the most powerful states in the Middle East, President Ahmadinejad's views are enormously influential... As we approach a critical time in international relations, we are offering our viewers an insight into an alternative world view...Channel 4 has devoted more airtime to examining Iran than any other broadcaster and this message continues a long tradition of offering a different perspective on the world around us\".\n4Talent.\n4Talent is an editorial branch of Channel 4's commissioning wing, which co-ordinates Channel 4's various talent development schemes for film, television, radio, new media and other platforms and provides a showcasing platform for new talent.\nThere are bases in London, Birmingham, Glasgow and Belfast, serving editorial hubs known respectively as 4Talent National, 4Talent Central England, 4Talent Scotland and 4Talent Northern Ireland. These four sites include features, profiles and interviews in text, audio and video formats, divided into five zones: TV, Film, Radio, New Media and Extras, which covers other arts such as theatre, music and design. 4Talent also collates networking, showcasing and professional development opportunities, and runs workshops, masterclasses, seminars and showcasing events across the UK.\n\"4Talent Magazine\".\n\"4Talent Magazine\" is the creative industries magazine from 4Talent, which launched in 2005 as \"TEN4\" magazine under the editorship of Dan Jones. \"4Talent Magazine\" is currently edited by Nick Carson. Other staff include deputy editor Catherine Bray and production editor Helen Byrne. The magazine covers rising and established figures of interest in the creative industries, a remit including film, radio, TV, comedy, music, new media and design.\nSubjects are usually UK-based, with contributing editors based in Northern Ireland, Scotland, London and Birmingham, but the publication has been known to source international content from Australia, America, continental Europe and the Middle East. The magazine is frequently organised around a theme for the issue, for instance giving half of November 2007's pages over to profiling winners of the annual 4Talent Awards.\nAn unusual feature of the magazine's credits is the equal prominence given to the names of writers, photographers, designers and illustrators, contradicting standard industry practice of more prominent writer bylines. It is also recognisable for its 'wraparound' covers, which use the front and back as a continuous canvas \u2013 often produced by guest artists.\nAlthough \"4Talent Magazine\" is technically a newsstand title, a significant proportion of its readers are subscribers. It started life as a quarterly 100-page title, but has since doubled in size and is now published bi-annually.\nScheduling.\nSince the 2010s, Channel 4 has become the public service broadcaster most likely to amend its schedule at short notice, if programmes are not gaining sufficient viewers in their intended slots. Programmes which have been heavily promoted by the channel before launch and then have lost their slot a week later include \"Sixteen: Class of 2021\". This was a fly-on-the-wall school documentary which lost its prime 9pm slot after one episode on 31 August 2021, even after a four-star review in \"The Guardian\". Channel 4 moved the next episode to a late night (post-primetime) slot on a different day and continued to broadcast the remainder of the four-part series in this timeslot.\nAlso in 2021, the channel launched \"Epic Wales: Valleys, Mountains and Coast\", a version of its More4 documentaries \"The Pennines: Backbone of Britain\", \"The Yorkshire Dales and The Lakes\" and \"Devon and Cornwall\". set in Wales. \"Epic Wales: Valleys, Mountains and Coast\". was initially broadcast in a prime Friday night slot at 8pm, in the hour before its comedy shows, but was dumped by the channel before the series was completed and replaced by repeats. In February 2022, the channel scheduled a new version of the show under the title \"Wonderous Wales\" with a Saturday night slot at 8pm but after one episode, it decided to take this series out of its schedule, moving up a repeat of \"Matt Baker: Our Farm in the Dales\" to 8pm and putting an episode of \"Escape to the Chateau\" in Baker's slot at 7pm. Other programmes moved out of primetime in 2022, include \"Mega Mansion Hunters\", Channel 4's answer to \"Selling Sunset\", which saw its third and final episode moved past midnight with repeats put in the schedule before it, and \"Richard Hammond's Crazy Contraptions\", a primetime Friday night competitive engineering show which saw its grand final moved to 11pm on a Sunday night. Instead of Hammond's competition, Channel 4 decided to schedule the fifth series of \"Devon and Cornwall\" in its place at 8pm on Friday nights, with this documentary being put up against Channel 5's \"World's Most Scenic Railway Journeys\" in the same timeslot.\nA new series of \"Unreported World\" was due to start on 18 February 2022 with a report by Seyi Rhodes in South Sudan, but was dropped due to an extended storm report on \"Channel 4 News\". When the programme was rescheduled for following Fridays, it was dropped again as \"Channel 4 News\" was extended due to the 2022 Russian invasion of Ukraine. \"Winter Paralympics: Today in Beijing\" was due to take the \"Unreported World\" slot from 11 March 2022 though this sports programme also stood a chance of being moved around the schedule to continue the extended news programmes reporting on the conflict. The invasion of Ukraine has also prompted Channel 4 to acquire and schedule the comedy series \"Servant of the People\" as a last minute replacement. The programme stars the current President of Ukraine Volodymyr Zelenskyy as an ordinary man who gets elected to run the country, and was shown on 6 March 2022 along with the documentary \"Zelenskyy: The Man Who Took on Putin\".\nIn addition to these shows, O.T. Fagbenle's sitcom \"Maxxx\" was pulled from youth TV channel E4, after one episode from the series had been broadcast on 2 April 2020, with Channel 4 deciding to keep the series off-air until Black History Month, with the series going out on the main channel from October 2020.\nIn May 2022, the reality dating show \"Let's Make a Love Scene\" was scrapped after one episode with the second programme in the series, hosted by Ellie Taylor, pulled from the 20 May schedule and replaced with an episode of \"8 Out of 10 Cats Does Countdown\". The first edition was negatively received, with Anita Singh, the arts and entertainments editor for \"The Telegraph\" writing that the show was \"the most ill-conceived programme idea since Prince Edward dreamt up \"It's a Royal Knockout\"\".\nPresentation.\nSince its launch in 1982, Channel 4 has used the same logo which consists of a stylised numeral \"4\" made up of nine differently-shaped blocks.\nThe original version was designed by Martin Lambie-Nairn and his partner Colin Robinson and was the first UK channel ident made using advanced computer generation (the first electronically generated ident was on BBC2 in 1979, but this was two-dimensional). It was designed in conjunction with Bo Gehring Aviation of Los Angeles and originally depicted the \"4\" in red, yellow, green, blue and purple. The music accompanying the ident was called \"Fourscore\" and was composed by David Dundas; it was later released as a single alongside a B-side, \"Fourscore Two\", although neither reached the UK charts. In November 1992, \"Fourscore\" was replaced by new music.\nIn 1996, Channel 4 commissioned Tomato Films to revamp the \"4\", which resulted in the \"Circles\" idents showing four white circles forming up transparently over various scenes, with the \"4\" logo depicted in white in one of the circles.\nIn 1999, Spin redesigned the logo to feature in a single square that sat on the right-hand side of the screen, whilst various stripes would move along from left to right, often lighting the squared \"4\" up. Like the previous \"Circles\" idents from 1996 (which was made by Tomato Films), the stripes would be interspersed with various scenes potentially related to the upcoming programme.\nThe logo was made three-dimensional again in 2004 when it was depicted in filmed scenes that show the blocks forming the \"4\" logo for less than a second before the action moves away again.\nIn 2015, a new presentation package by the network's in-house agency 4Creative was introduced. Directed by filmmaker Jonathan Glazer, the \"4\" logo itself was downplayed on-air in favour of idents and bumpers featuring the individual blocks as objects, including idents depicting them as \"Kryptonite\"-like items of fascination (such as being excavated, and viewed under a microscope for scientific study) that reflect Channel 4's remit of being \"irreverent, innovative, alternative and challenging\". Musician Micachu composed music for the idents. This theme continued in 2017, with new idents by Dougal Wilson that focused on an anthropomorphic \"giant\" constructed from the blocks, and its interactions in everyday life. A new acoustic rendition of \"Fourscore\" was also composed for the idents.\nIn September 2018, Channel 4 adopted the two-dimensional version of the \"4\" logo as its main corporate logo, and introduced a rebranding of all of its digital channels by ManvsMachine and 4Creative to standardise them around variations of the Lambie-Nairn \"4\". The original 1982 ident was given a one-off revival on 28 December 2020, as a tribute to Lambie-Nairn after his death three days earlier. It was also used on 22 January 2021 as part of the 80s-themed \"takeover\" to promote the premiere of \"It's a Sin\", which was set during the 1980s AIDS crisis.\nTo mark the network's 40th anniversary, Channel 4 began to phase in another rebranding in November 2022, and announced that new idents were being produced that would be \"an unexpected and daring portrait of Britain retold\". In an effort to emphasise its digital platforms, it was announced that the \"All4\" branding would be dropped from Channel 4's video on-demand platform, in favour of marketing it under the \"Channel 4\" name with no disambiguation. The new idents, \"Modern Britain\", premiered in June 2023, featuring looping cycles of themed scenes built around the Channel 4 logo by various artists.\nRegions/international.\nRegions.\nChannel 4 has, since its inception, broadcast identical programmes and continuity throughout the United Kingdom (excluding Wales where it did not operate on analogue transmitters). At launch this made it unique, as both the BBC and ITV had long-established traditions of providing regional variations in their programming in different areas of the country. Since the launch of subsequent British television channels, Channel 4 has become typical in its lack of regional programming variations.\nA few exceptions exist to this rule for programming and continuity:\nPart of Channel 4's remit covers the commissioning of programmes from outside London. Channel 4 has a dedicated director of nations and regions, Stuart Cosgrove, who is based in a regional office in Glasgow. As his job title suggests, it is his responsibility to foster relations with independent producers based in areas of the United Kingdom (including Wales) outside London.\nInternational.\nChannel 4 is available in the Republic of Ireland, with ads tailored to the Irish market. The channel is registered with the broadcasting regulators in Luxembourg for terms of conduct and business within the EU/EEA while observing guidelines outlined by Ireland's BAI code. Irish advertising sales are managed by Media Link in Dublin. Where Channel 4 does not hold broadcasting rights within the Republic of Ireland such programming is unavailable. For example, the series \"Glee\" was not available on Channel 4 on Sky in Ireland due to it broadcasting on TV3 within Ireland. Currently, programming available on Channel 4 is available within the Republic of Ireland without restrictions. Elsewhere in Europe, the UK version of the channel is available.\nFuture possibility of regional news.\nWith ITV plc pushing for much looser requirements on the amount of regional news and other programming it is obliged to broadcast in its ITV regions, the idea of Channel 4 taking on a regional news commitment has been considered, with the corporation in talks with Ofcom and ITV over the matter. Channel 4 believes that a scaling-back of such operations on ITV's part would be detrimental to Channel 4's national news operation, which shares much of its resources with ITV through their shared news contractor ITN. At the same time, Channel 4 also believes that such an additional public service commitment would bode well in on-going negotiations with Ofcom in securing additional funding for its other public service commitments.\nChannel 4 HD.\nIn mid-2006 Channel 4 ran a six-month closed trial of HDTV, as part of the wider Freeview HD experiment via the Crystal Palace transmitter to London and parts of the home counties, including the use of \"Lost\" and \"Desperate Housewives\" as part of the experiment, as US broadcasters such as ABC already have an HDTV back catalogue.\nOn 10 December 2007, Channel 4 launched a high-definition television simulcast of Channel 4 on Sky's digital satellite platform, after Sky agreed to contribute toward the channel's satellite distribution costs. It was the first full-time high-definition channel from a terrestrial UK broadcaster.\nOn 31 July 2009, Virgin Media added Channel 4 HD on channel 146 (later on channel 142, now on channel 141) as part of the M pack. On 25 March 2010 Channel 4 HD appeared on Freeview channel 52 with a placeholding caption, ahead of a commercial launch on 30 March 2010, coinciding with the commercial launch of Freeview HD. On 19 April 2011, Channel 4 HD was added to Freesat on channel 126. As a consequence, the channel moved from being free-to-view to free-to-air on satellite during March 2011. With the closure of S4C Clirlun in Wales on 1 December 2012, on Freeview, Channel 4 HD launched in Wales on 2 December 2012.\nThe channel carries the same schedule as Channel 4, broadcasting programmes in HD when available, acting as a simulcast. Therefore, SD programming is broadcast upscaled to HD. The first true HD programme to be shown was the 1996 Adam Sandler film \"Happy Gilmore\". From launch until 2016 the presence of the 4HD logo on screen denoted true HD content.\nOn 1 July 2014, Channel 4 +1 HD, an HD simulcast of Channel 4 +1, launched on Freeview channel 110. It closed on 22 June 2020 to help make room on COM7 following the closure of COM8 on Freeview. 4Seven HD were removed from Freeview also.\nOn 20 February 2018, Channel 4 announced that Channel 4 HD and All 4 would no longer be supplied on Freesat from 22 February 2018. Channel 4 HD returned to the platform on 8 December 2021, along with the music channel portfolio of The Box Plus Network.\nOn 27 September 2022, the other 6 advertising regions of Channel 4 (South, Midlands, North, Scotland, Northern Ireland and Rep of Ireland) were made available in HD on Sky and Virgin Media. Prior to this, Channel 4 HD was only available in the London advertising region.\nVideo on demand.\nChannel 4's video on demand service, known simply as \"Channel 4\" since April 2023, launched in November 2006 as \"4oD\", and was renamed \"All 4\" in March 2015. The service offers a variety of programmes recently shown on Channel 4, E4, More4 or from their archives, though some programmes and movies are not available due to rights issues.\nTeletext services.\n4-Tel/FourText.\nChannel 4 originally licensed an ancillary teletext service to provide schedules, programme information and features. The original service was called 4-Tel, and was produced by Intelfax, a company set up especially for the purpose. It was carried in the 400s on Oracle. In 1993, with Oracle losing its franchise to Teletext Ltd, 4-Tel found a new home in the 300s, and had its name shown in the header row. Intelfax continued to produce the service and in 2002 it was renamed FourText.\nTeletext on 4.\nIn 2003, Channel 4 awarded Teletext Ltd a ten-year contract to run the channel's ancillary teletext service, named Teletext on 4. The service closed in 2008, and Teletext is no longer available on Channel 4, ITV and Channel 5."}
{"id": "6322", "revid": "4355447", "url": "https://en.wikipedia.org/wiki?curid=6322", "title": "Carolina parakeet", "text": "The Carolina parakeet (Conuropsis carolinensis), or Carolina conure, is an extinct species of small green neotropical parrot with a bright yellow head, reddish orange face, and pale beak that was native to the Eastern, Midwest, and Plains states of the United States. It was the only indigenous parrot within its range, and one of only three parrot species native to the United States. The others are the thick-billed parrot, now extirpated, and the green parakeet, still present in Texas; a fourth parrot species, the red-crowned amazon, is debated. \nThe Carolina parakeet was called \"puzzi la n\u00e9e\" (\"head of yellow\") or \"pot pot chee\" by the Seminole and \"kelinky\" in Chickasaw. Though formerly prevalent within its range, the bird had become rare by the middle of the 19th century. The last confirmed sighting in the wild was of the \"C. c. ludovicianus\" subspecies in 1910. The last known specimen, a male named Incas, perished in captivity at the Cincinnati Zoo in 1918, and the species was declared extinct in 1939.\nThe earliest reference to these parrots was in 1583 in Florida reported by Sir George Peckham in \"A True Report of the Late Discoveries of the Newfound Lands\" of expeditions conducted by English explorer Sir Humphrey Gilbert, who notes that explorers in North America \"doe testifie that they have found in those countryes;\u00a0... parrots\". They were first scientifically described in English naturalist Mark Catesby's two-volume \"Natural History of Carolina, Florida and the Bahama Islands\" published in London in 1731 and 1743.\nCarolina parakeets were probably poisonous \u2013 French-American naturalist and painter John J. Audubon noted that cats apparently died from eating them, and they are known to have eaten the toxic seeds of cockleburs.\nTaxonomy.\n\"Carolinensis\" is a species of the genus \"Conuropsis\", one of numerous genera of New World Neotropical parrots in family Psittacidae of true parrots.\nThe binomial \"Psittacus carolinensis\" was assigned by Swedish zoologist Carl Linnaeus in the 10th edition of \"Systema Naturae\" published in 1758. The species was given its own genus, \"Conuropsis\", by Italian zoologist and ornithologist Tommaso Salvadori in 1891 in his \"Catalogue of the Birds in the British Museum\", volume\u00a020. The name is derived from the Greek-ified \"conure\" (\"parrot of the genus \"Conurus\"\" an obsolete name of genus \"Aratinga\") + \"-opsis\" (\"likeness of\") and Latinized \"Carolina\" (from Carolana, an English colonial province) + \"-ensis\" (of or \"from a place\"), therefore a bird \"like a conure from Carolina\".\nTwo subspecies are recognized: The Louisiana subspecies of the Carolina parakeet, \"C. c. ludovicianus\", was slightly different in color from the nominate subspecies, being more bluish-green and generally of a somewhat subdued coloration, and became extinct in much the same way, but at a somewhat earlier date (early 1910s). The Appalachian Mountains separated these birds from the eastern \"C.\u00a0c.\u00a0carolinensis\".\nEvolution.\nAccording to a study of mitochondrial DNA recovered from museum specimens, their closest living relatives include some of the South American \"Aratinga\" parakeets: The Nanday parakeet, the sun conure, and the golden-capped parakeet. The authors note the bright yellow and orange plumage and blue wing feathers found in \"C. carolinensis\" are traits shared by another species, the jandaya parakeet (\"A.\u00a0jandaya\"), that was not sampled in the study, but is generally thought to be closely related. To help resolve the divergence time, a whole genome of a preserved specimen has now been sequenced. The Carolina parakeet colonized North America about 5.5\u00a0million years ago. This was well before North America and South America were joined by the formation of the Panama land bridge about 3.5\u00a0mya. Since the Carolina parakeets' more distant relations are geographically closer to its own historic range while its closest relatives are more geographically distant to it, these data are consistent with the generally accepted hypothesis that Central and North America were colonized at different times by distinct lineages of parrots \u2013 parrots that originally invaded South America from Antarctica some time after the breakup of Gondwana, where Neotropical parrots originated approximately 50\u00a0mya.\nThe following cladogram shows the placement of the Carolina parakeet among its closest relatives, after a DNA study by Kirchman \"et al\". (2012):\nA fossil parrot, designated \"Conuropsis fratercula\", was described based on a single humerus from the Miocene Sheep Creek Formation (possibly late Hemingfordian, c.\u00a016\u00a0mya, possibly later) of Snake River, Nebraska. It was a smaller bird, three-quarters the size of the Carolina parakeet. \"The present \"species\" is of peculiar interest as it represents the first known parrot-like bird to be described as a fossil from North America.\" (Wetmore 1926; italics added) However, it is not completely certain that the species is correctly assigned to \"Conuropsis\".\nDescription.\nThe Carolina parakeet was a small, green parrot very similar in size and coloration to the extant jenday parakeet and sun conure \u2013 the sun conure being its closest living relative.\nThe majority of the parakeets' plumage was green with lighter green underparts, a bright yellow head and orange forehead and face extending to behind the eyes and upper cheeks (lores). The shoulders were yellow, continuing down the outer edge of the wings. The primary feathers were mostly green, but with yellow edges on the outer primaries. Thighs were green towards the top and yellow towards the feet. Male and female adults were identical in plumage, however males were slightly larger than females (sexually dimorphic only in size). Their legs and feet were light brown. They share the zygodactyl feet common to all the parrot family. Their eyes were ringed by white skin and their beaks were pale flesh colored. These birds weigh about 3.5\u00a0oz., are 13\u00a0in. long, and have wingspans of 21\u201323\u00a0in.\nYoung Carolina parakeets differed slightly in coloration from adults. The face and entire body were green, with paler underparts. They lacked yellow or orange plumage on the face, wings, and thighs. Hatchlings were covered in mouse-gray down, until about 39\u201340\u00a0days old, when green wings and tails appeared. Fledglings had full adult plumage around 1\u00a0year of age.\nThese birds were fairly long-lived, at least in captivity: A pair was kept at the Cincinnati Zoo for over 35\u00a0years.\nDistribution and habitat.\nThe Carolina parakeet had the northernmost range of any known parrot. It was found from southern New York and Wisconsin to Kentucky, Tennessee, and the Gulf of Mexico, from the Atlantic Seaboard to as far west as eastern Colorado. It lived in old-growth forests along rivers and in swamps. Its range was described by early explorers thus: the 43rd parallel as the northern limit, the 26th as the most southern, the 73rd and 106th meridians as the eastern and western boundaries, respectively, the range included all or portions of at least 28 states. Its habitats were old-growth wetland forests along rivers and in swamps, especially in the Mississippi-Missouri drainage basin with large hollow trees including cypress and sycamore to use as roosting and nesting sites.\nOnly very rough estimates of the birds' former prevalence can be made, with an estimated range of 20,000 to 2.5 million km2, and population density of 0.5 to 2.0 parrots per km2, population estimates range from tens of thousands to a few million birds (though the densest populations occurred in Florida covering 170,000\u00a0km2, so hundreds of thousands of the birds may have been in that state alone).\nThe species may have appeared as a very rare vagrant in places as far north as southern Ontario in Canada. A few bones, including a pygostyle found at the Calvert Site in southern Ontario, came from the Carolina parakeet. The possibility remains open that this specimen was taken there for ceremonial purposes.\nBehavior and diet.\nThe bird lived in huge, noisy flocks of as many as 300 birds. It built its nest in a hollow tree, laying two to five (most accounts say two) round white eggs. Reportedly, multiple female parakeets could deposit their eggs into one nest, similar to nesting behavior described in the monk parakeet (\"Myiopsitta monachus\").\nIt mostly ate the seeds of forest trees and shrubs, including those of cypress, hackberry, beech, sycamore, elm, pine, maple, oak, and other plants such as thistles and sandspurs (\"Cenchrus\" species). It ate fruits, including apples, grapes, and figs (often from orchards by the time of its decline), and flower buds, and occasionally, insects. It was especially noted for its predilection for cockleburs (\"Xanthium strumarium\"), a plant which contains a toxic glucoside, and it was considered to be an agricultural pest of grain crops.\nExtinction.\nThe last captive Carolina parakeet, Incas, died at the Cincinnati Zoo on February 21, 1918, in the same cage as Martha, the last passenger pigeon, which died in 1914. There are no scientific studies or surveys of this bird by American naturalists; most information about it is from anecdotal accounts and museum specimens, so details of its prevalence and decline are unverified or speculative.\nExtensive accounts of the precolonial and early colonial have been given for prevalence of this bird. The existence of flocks of gregarious, very colorful and raucous parrots could hardly have gone unnoted by European explorers, as parrots were virtually unknown in seafaring European nations in the 16th and 17th centuries. Later accounts in the latter half of the 19th century onward noted the birds' sparseness and absence.\nGenetic evidence suggests that while populations had been in decline since the last glacial maximum, the lack of evidence of inbreeding suggests that the birds declined very quickly.\nThe birds' range collapsed from east to west with settlement and clearing of the eastern and southern deciduous forests. John J. Audubon commented as early as 1832 on the decline of the birds. The bird was rarely reported outside Florida after 1860. The last reported sighting east of the Mississippi River (except Florida) was in 1878 in Kentucky. By the turn of the century, it was restricted to the swamps of central Florida. The last known wild specimen was killed in Okeechobee County, Florida, in 1904, and the last captive bird died at the Cincinnati Zoo on February 21, 1918. This was the male specimen, Incas, that died within a year of his mate, Lady Jane. Additional reports of the bird were made in Okeechobee County, Florida, until the late 1920s, but these are not supported by specimens. However two sets of eggs purportedly taken from active nests in 1927 are in the collection of the Florida Museum of Natural History, and genetic testing could prove the species was still breeding at that time. Not until 1939, however, did the American Ornithologists' Society declare the Carolina parakeet to be extinct. The IUCN has listed the species as extinct since 1920.\nIn 1937, three parakeets resembling this species were sighted and filmed in the Okefenokee Swamp of Georgia. However, the American Ornithologists' Union analyzed the film and concluded that they had probably filmed feral parakeets. A year later, in 1938, a flock of parakeets was apparently sighted by a group of experienced ornithologists in the swamps of the Santee River basin in South Carolina, but this sighting was doubted by most other ornithologists. The birds were never seen again after this sighting, and shortly after a portion of the area was destroyed to make way for power lines, making the species' continued existence unlikely.\nAbout 720 skins and 16 skeletons are housed in museums around the world, and analyzable DNA has been extracted from them.\nReasons for extinction.\nThe evidence is indicative that humans had at least a contributory role in the extinction of the Carolina parakeet, through a variety of means. Chief was deforestation in the 18th and 19th centuries. Hunting played a significant role, both for decorative use of their colorful feathers, for example, adornment of women's hats, and for reduction of crop predation. This was partially offset by the recognition of their value in controlling invasive cockleburs. Minor roles were played by capture for the pet trade and, as noted in \"Pacific Standard\", by the introduction for crop pollination of European honeybees that competed for nest sites.\nA factor that exacerbated their decline to extinction was the flocking behavior that led them to return to the vicinity of dead and dying birds (such as birds downed by hunting), enabling wholesale slaughter.\nThe final extinction of the species in the early years of the 20th century is somewhat of a mystery, as it happened so rapidly. Vigorous flocks with many juveniles and reproducing pairs were noted as late as 1896, and the birds were long-lived in captivity, but they had virtually disappeared by 1904. Sufficient nest sites remained intact, so deforestation was not the final cause. American ornithologist Noel F. Snyder speculates that the most likely cause seems to be that the birds succumbed to poultry disease, although no recent or historical records exist of New World parrot populations being afflicted by domestic poultry diseases. The modern poultry scourge Newcastle disease was not detected until 1926 in Indonesia, and only a subacute form of it was reported in the United States in 1938. As well, genetic research on samples did not show any significant presence of bird viruses (though this does not solely rule out disease)."}
{"id": "6324", "revid": "30742403", "url": "https://en.wikipedia.org/wiki?curid=6324", "title": "Collective trauma", "text": ""}
{"id": "6325", "revid": "49065618", "url": "https://en.wikipedia.org/wiki?curid=6325", "title": "Church (building)", "text": "A church, church building, or church house is a building used for Christian worship services and other Christian religious activities. The earliest identified Christian church is a house church founded between 233 AD and 256 AD.\nSometimes, the word \"church\" is used erroneously to refer to the buildings of other religions, such as mosques and synagogues. \"Church\" is also used to describe a body or an assembly of Christian believers, while \"the Church\" may be used to refer to the worldwide Christian religious community as a whole.\nIn traditional Christian architecture, the plan view of a church often forms a Christian cross with the centre aisle and seating representing the vertical beam and the bema and altar forming the horizontal. Towers or domes may inspire contemplation of the heavens. Modern churches have a variety of architectural styles and layouts. Some buildings designed for other purposes have been converted to churches, while many original church buildings have been put to other uses. From the 11th to the 14th century, there had been a wave of church construction in Western Europe.\nMany churches worldwide are of considerable historical, national, cultural, and architectural significance, with several included in the list of UNESCO World Heritage Sites.\nEtymology.\nThe word \"church\" is derived from Old English , 'place of assemblage set aside for Christian worship', from the Common Germanic word \"kirika\". This was probably borrowed via Gothic from Ancient Greek , 'the Lord's (house)', from , 'ruler, lord'. in turn comes from the Indo-European root , meaning 'to spread out, to swell' (euphemistically: 'to prevail, to be strong').\nThe various forms of the cognates to \"church\" in various languages reflect the word's linguistic roots in Greek and Proto-Indo-European origins. For instance, in early Germanic languages such as Old High German, the word evolved into \"kirihha\", highlighting its spread through the Christianization of Germanic peoples. This etymological journey illustrates how the concept of a place of Christian worship was linguistically adapted as Christianity expanded across Europe. Additionally, the use of the word in early Christian communities emphasized the association of the building with its dedication to God.\nThe Greek , 'of the Lord', has been used of houses of Christian worship since , especially in the East, although it was less common in this sense than or .\nHistory.\nAntiquity.\nThe earliest archeologically identified Christian church is a house church (\"domus ecclesiae\"), the Dura-Europos church, founded between 233 AD and 256 AD.\nIn the second half of the third century AD, the first purpose-built halls for Christian worship (\"aula ecclesiae\") began to be constructed. Although many of these were destroyed early in the next century during the Diocletianic Persecution. Even larger and more elaborate churches began to appear during the reign of Emperor Constantine the Great.\nMedieval times.\nFrom the 11th through the 14th centuries, a wave of cathedral building and the construction of smaller parish churches occurred across Western Europe. Besides serving as a place of worship, the cathedral or parish church was frequently employed as a general gathering place by the communities in which they were located, hosting such events as guild meetings, banquets, mystery plays, and fairs. Church grounds and buildings were also used for the threshing and storage of grain.\nRomanesque architecture.\nBetween 1000 and 1200, the Romanesque style became popular across Europe. The Romanesque style is defined by large and bulky edifices typically composed of simple, compact, sparsely decorated geometric structures. Frequent features of the Romanesque church include circular arches, round or octagonal towers, and cushion capitals on pillars. In the early Romanesque era, coffering on the ceiling was fashionable, while later in the same era, groined vaults gained popularity. Interiors widened, and the motifs of sculptures took on more epic traits and themes.\nGothic architecture.\nThe Gothic style emerged around 1140 in \u00cele-de-France and subsequently spread throughout Europe. Gothic churches lost the compact qualities of the Romanesque era, and decorations often contained symbolic and allegorical features. The first pointed arches, rib vaults, and buttresses began to appear, all possessing geometric properties that reduced the need for large, rigid walls to ensure structural stability. This also permitted the size of windows to increase, producing brighter and lighter interiors. Nave ceilings rose, and pillars and steeples heightened. Many architects used these developments to push the limits of structural possibility \u2013 an inclination that resulted in the collapse of several towers whose designs had unwittingly exceeded the boundaries of soundness. In Germany, the Netherlands and Spain, it became popular to build hall churches, a style in which every vault would be built to the same height.\nGothic cathedrals were lavishly designed, as in the Romanesque era, and many share Romanesque traits. However, several also exhibit unprecedented degrees of detail and complexity in decoration. Notre-Dame de Paris and Reims Cathedral in France, as well as the church of San Francesco d'Assisi in Palermo, Salisbury Cathedral and the wool churches in England, and Santhome Church in Chennai, India, show the elaborate stylings characteristic of Gothic cathedrals.\nSome of the most well-known gothic churches remained unfinished for centuries after the style fell out of popularity. One such example is the construction of Cologne Cathedral, which began in 1248, was halted in 1473, and didn't resume until 1842.\nRenaissance.\nIn the fifteenth and sixteenth centuries, the changes in ethics and society due to the Renaissance and the Reformation also influenced the building of churches. The common style was much like the Gothic style but simplified. The basilica was not the most popular type of church anymore, but instead, hall churches were built. Typical features are columns and classical capitals.\nIn Protestant churches, where the proclamation of God's Word is of particular importance, the visitor's line of sight is directed towards the pulpit.\nBaroque architecture.\nThe Baroque style was first used in Italy around 1575. From there, it spread to the rest of Europe and the European colonies. The building industry increased heavily during the Baroque era. Buildings, even churches, were used to indicate wealth, authority, and influence. The use of forms known from the Renaissance was extremely exaggerated. Domes and capitals were decorated with moulding, and the former stucco sculptures were replaced by fresco paintings on the ceilings. For the first time, churches were seen as one connected work of art, and consistent artistic concepts were developed. Instead of long buildings, more central-plan buildings were created. The sprawling decoration with floral ornamentation and mythological motives lasted until about 1720, in the Rococo era.\nThe Protestant parishes preferred lateral churches, in which all the visitors could be as close as possible to the pulpit and the altar.\nArchitecture.\nA common trait of the architecture of many churches is the shape of a cross (a long central rectangle, with side rectangles and a rectangle in front for the altar space or sanctuary). These churches also often have a dome or other large vaulted space in the interior to represent or draw attention to the heavens. Other common shapes for churches include a circle, to represent eternity, or an octagon or similar star shape, to represent the church's bringing light to the world. Another common feature is the spire, a tall tower at the \"west\" end of the church or over the crossing.\nAnother common feature of many Christian churches is the eastwards orientation of the front altar. \nOften, the altar will not be oriented due east but toward the sunrise. This tradition originated in Byzantium in the fourth century and became prevalent in the West in the eighth and ninth centuries. The old Roman custom of having the altar at the west end and the entrance at the east was sometimes followed as late as the eleventh century, even in areas of northern Europe under Frankish rule, as seen in Petershausen (Constance), Bamberg Cathedral, Augsburg Cathedral, Regensburg Cathedral, and Hildesheim Cathedral.\nTypes.\nBasilica.\nThe Latin word \"basilica\" was initially used to describe a Roman public building usually located in the forum of a Roman town. After the Roman Empire became officially Christian, the term came by extension to refer to a large and influential church that has been given special ceremonial rights by the Pope. The word thus retains two senses today, one architectural and the other ecclesiastical.\nCathedral.\nA cathedral is a church, usually Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. The word cathedral takes its name from \"cathedra\", or Bishop's Throne (In ). The term is sometimes (improperly) used to refer to any church of great size.\nA church with a cathedral function is not necessarily a large building. It might be as small as Christ Church Cathedral in Oxford, England, Porvoo Cathedral in Porvoo, Finland, Sacred Heart Cathedral in Raleigh, United States, or Chur Cathedral in Switzerland. However, frequently, the cathedral, along with some of the abbey churches, was the largest building in any region.\nCathedrals tend to display a higher level of contemporary architectural style and the work of accomplished craftsmen, and occupy a status both ecclesiastical and social that an ordinary parish church rarely has. Such churches are generally among the finest buildings locally and a source of national and regional pride, and many are among the world's most renowned works of architecture.\nChapel.\nEither, a discrete space with an altar inside a larger cathedral, conventual, parish, or other church; or, a free standing small church building or room not connected to a larger church, to serve a particular hospital, school, university, prison, private household, palace, castle, or other institution. Often proprietary churches and small conventual churches are referred to by this term.\nCollegiate church.\nA collegiate church is a church where the daily office of worship is maintained by a college of canons, which may be presided over by a dean or provost.\nCollegiate churches were often supported by extensive lands held by the church, or by tithe income from appropriated benefices. They commonly provide distinct spaces for congregational worship and for the choir offices of their clerical community.\nConventual church.\nA conventual church (in Eastern Orthodoxy \"katholikon\") is the main church in a Christian monastery or convent, known variously as an abbey, a priory, a friary, or a preceptory.\nParish church.\nA parish church is a church built to meet the needs of people localised in a geographical area called a parish. The vast majority of Catholic, Orthodox, Anglican, and Lutheran church buildings fall into this category. A parish church may also be a basilica, a cathedral, a conventual or collegiate church, or a place of pilgrimage. The vast majority of parish churches do not however enjoy such privileges.\nIn addition to a parish church, each parish may maintain auxiliary organizations and their facilities such as a rectory, parish hall, parochial school, or convent, frequently located on the same campus or adjacent to the church.\nPilgrimage church.\nA pilgrimage church is a church to which pilgrimages are regularly made, or a church along a pilgrimage route, often located at the tomb of a saints, or holding icons or relics to which miraculous properties are ascribed, the site of Marian apparitions, etc.\nProprietary church.\nDuring the Middle Ages, a proprietary church was a church, abbey, or cloister built on the private grounds of a feudal lord, over which he retained proprietary interests.\nEvangelical church structures.\nThe architecture of evangelical places of worship is mainly characterized by its sobriety. The Latin cross is a well known Christian symbol that can usually be seen on the building of an evangelical church and that identifies the place's belonging. Some services take place in theaters, schools or multipurpose rooms, rented for Sunday only. There is usually a baptistery at the front of the church (in what is known as the chancel in historic traditions) or in a separate room for baptisms by immersion.\nWorship services take on impressive proportions in the megachurches (churches where more than 2,000 people gather every Sunday). In some of these megachurches, more than 10,000 people gather every Sunday. The term gigachurch is sometimes used. For example, Lakewood Church (United States) or Yoido Full Gospel Church (South Korea).\nHouse church.\nIn some countries of the world which apply sharia or communism, government authorizations for worship are complex for Christians. Because of persecution of Christians, Evangelical house churches have thus developed. For example, there is the Evangelical house churches in China movement. The meetings thus take place in private houses, in secret and in \"illegality\".\nAlternative buildings.\nOld and disused church buildings can be seen as an interesting proposition for developers as the architecture and location often provide for attractive homes or city centre entertainment venues. On the other hand, many newer churches have decided to host meetings in public buildings such as schools, universities, cinemas or theatres.\nThere is another trend to convert old buildings for worship rather than face the construction costs and planning difficulties of a new build. Unusual venues in the UK include a former tram power station, a former bus garage, a former cinema and bingo hall, a former Territorial Army drill hall, and a former synagogue. served as a floating church for mariners at Liverpool from 1827 until she sank in 1872. A windmill has also been converted into a church at Reigate Heath.\nThere have been increased partnerships between church management and private real estate companies to redevelop church properties into mixed uses. While it has garnered criticism, the partnership allows congregations to increase revenue while preserving the property.\nGeographical distribution.\nWith the exception of Saudi Arabia and the Maldives, all sovereign states and dependent territories worldwide have church buildings. Afghanistan has the fewest churches globally, featuring only one official church: the Our Lady of Divine Providence Chapel in Kabul. Somalia follows closely, having once housed the Mogadishu Cathedral, along with the Saint Anthony of Padua Church in Somaliland. Other countries with a limited number of churches include Bhutan and Western Sahara.\nIn contrast, some estimates suggest that the United States has the highest number of churches in the world, with around 380,000, followed by Brazil and Italy. According to the Future for Religious Heritage, there are over 500,000 churches across Europe. Several cities are commonly known as the \"City of Churches\" due to their abundance of churches. These cities include Adelaide, Ani, Ayacucho, Krak\u00f3w, Moscow, Montreal, Naples, Ohrid, Prague, Puebla, Quer\u00e9taro, Rome, Salzburg, and Vilnius. Notably, Rome and New York City are home to the highest number of churches of any city in the world.\nAlthough building churches is prohibited in Saudi Arabia, which has around 1.5 million Christians, the country contains the remnants of a historic church known as the Jubail Church, which dates back to the fourth century and was affiliated with the Church of the East. Discovered in 1986, the site was excavated by the Saudi Antiquities Department in 1987. As of 2008, the findings from this excavation had not been published, reflecting sensitivities regarding artifacts from non-Islamic religions. In the Maldives, which has approximately 1,400 Christians, building churches is prohibited. However, only foreign Christian workers are allowed to practice their religion privately. Despite the prohibition on church construction, both countries have secret home churches.\nChristianity is the world's largest and most widespread religion, with over 2.3 billion followers. Churches are found across all seven continents, which are Asia, Africa, North America, South America, Antarctica, Europe, and Oceania. Antarctica is home to eight churches, with two additional churches located south of the Antarctic Convergence.\nMany churches worldwide are of considerable historical, national, cultural, and architectural significance, with several recognized as UNESCO World Heritage Sites. According to the \"Catholic Encyclopedia\" the Cenacle (the site of the Last Supper) in Jerusalem was the \"first Christian church\". The Dura-Europos church in Syria is the oldest surviving church building in the world. Several authors have cited the Etchmiadzin Cathedral (Armenia's mother church) as the oldest cathedral in the world."}
{"id": "6326", "revid": "47692638", "url": "https://en.wikipedia.org/wiki?curid=6326", "title": "Childe's Tomb", "text": "Childe's Tomb is a granite cross on Dartmoor, Devon, England. Although not in its original form, it is more elaborate than most of the crosses on Dartmoor, being raised upon a constructed base, and it is known that a kistvaen is underneath.\nA well-known legend attached to the site, first recorded in 1630 by Tristram Risdon, concerns a wealthy hunter, Childe, who became lost in a snow storm and supposedly died there despite disembowelling his horse and climbing into its body for protection. The legend relates that Childe left a note of some sort saying that whoever found and buried his body would inherit his lands at Plymstock. After a race between the monks of Tavistock Abbey and the men of Plymstock, the Abbey won.\nThe tomb was virtually destroyed in 1812 by a man who stole most of the stones to build a house nearby, but it was partly reconstructed in 1890.\nDescription.\nChilde's Tomb is a reconstructed granite cross on the south-east edge of Foxtor Mires, about 500 metres north of Fox Tor on Dartmoor, Devon, England at . According to William Burt, in his notes to \"Dartmoor, a Descriptive Poem\" by N. T. Carrington (1826), the original tomb consisted of a pedestal of three steps, the lowest of which was built of four stones each six feet long and twelve inches square. The two upper steps were made of eight shorter but similarly shaped stones, and on top was an octagonal block about three feet high with a cross fixed upon it.\nThe tomb lies on the line of several cairns that marked the east-west route of the ancient Monks' Path between Buckfast Abbey and Tavistock Abbey and it was no doubt erected here as part of that route: it would have been particularly useful in this part of the moor with few landmarks where a traveller straying from the path could easily end up in Foxtor Mires. Tristram Risdon, writing in about 1630, said that Childe's Tomb was one of three remarkable things in the Forest of Dartmoor (the others being Crockern Tor and Wistman's Wood). Risdon also stated that the original tomb bore an inscription: \"They fyrste that fyndes and bringes mee to my grave, The priorie of Plimstoke they shall have\", but no sign of this has ever been found.\nToday the cross, which is a replacement, is about tall and across at the crosspiece, and it has its base in a socket stone which rests on a pedestal of granite blocks that raises the total height of the cross to . The original, now broken, socket stone for the cross lies nearby. The whole is surrounded by a circle of granite stones set on their edge which once surrounded the cairn\u2014the rocks of which are now scattered around\u2014that was originally built over a large kistvaen that still exists beneath the pedestal.\nDestruction.\nIn the early 19th century, there was much interest in enclosing and \"improving\" the open moorland on Dartmoor, encouraged by Sir Thomas Tyrwhitt's early successes at Tor Royal near Princetown. Enclosure was aided by the greatly enhanced access provided by the construction of the first turnpike roads over the moor: the road between Ashburton and Two Bridges opened in around 1800, for instance. In February 1809 one Thomas Windeatt, from Bridgetown, Totnes, took over the lease of a plot of land (a \"newtake\") of about 582 acres in the valley of the River Swincombe. In 1812 Windeatt started to build a farmhouse, Fox Tor Farm, on his land and his workmen robbed the nearby Childe's Tomb of most of its stones for the building and its doorsteps.\nIn 1902, William Crossing wrote that he had been told by an old moorman that some of the granite blocks from the tomb's pedestal had also been used to make a clapper bridge across a stream flowing into the River Swincombe near the farm. The moorman also said that they had lettering on their undersides. This encouraged Crossing to arrange to lift the clapper bridge, but no inscription was found. However, he did locate nine out of the twelve stones that had made up the pedestal, as well as the broken socket stone for the cross.\nReconstruction.\nCrossing rediscovered the original site of the tomb in 1882 and said that all that remained was a small mound and some half buried stones. He cleared out the kistvaen, reporting that it was long by wide and that unlike most kistvaens found on the moor, the stones lining it had apparently been shaped by man, which led him to suggest that it was less old than most. Having located most of the stones of the original tomb, Crossing thought that it could be rebuilt in its original form with little effort, but it was not to be.\nJ. Brooking Rowe, writing in 1895, states that the tomb was re-erected in 1890 under the direction of Mr. E. Fearnley Tanner, who said that he was dissatisfied with the result because several stones were missing and it was difficult to recreate the original character of the monument. Tanner was the honourable secretary of the Dartmoor Preservation Association, and this reconstruction was one of the first acts of that organisation. The replacement base and cross were made in Holne in 1885.\nChilde the Hunter.\nAccording to legend, the cross was erected over the kistvaen ('chest-stone' i.e. burial chamber) of Childe the Hunter, who was Ordulf, son of Ordgar, an Anglo-Saxon Earl of Devon in the 11th century. The name \"Childe\" is probably derived from the Old English word \"cild\" which was used as a title of honour.\nLegend has it that Childe was in a party hunting on the moor when they were caught in some changeable weather. Childe became separated from the main party and was lost. In order to save himself from dying of exposure, he killed his horse, disembowelled it and crept inside the warm carcass for shelter. He nevertheless froze to death, but before he died, he wrote a note to the effect that whoever should find him and bury him in their church should inherit his Plymstock estate.\nHis body was found by the monks of Tavistock Abbey, who started to carry it back. However, they heard of a plot to ambush them by the people of Plymstock, at a bridge over the River Tavy. They took a detour and built a new bridge over the river, just outside Tavistock. They were successful in burying the body in the grounds of the Abbey and inherited the Plymstock estate.\nThe first account of this story is to be found in Risdon's \"Survey of Devon\" which was completed in around 1632:\nFinberg pointed out, however, that a document of 1651 refers to Tavistock's guildhall as \"Guilehall\", so \"Guilebridge\" is more likely to be \"guild bridge\", probably because it was built or maintained by one of the town guilds.\nIn popular culture.\nDevon folk singer Seth Lakeman sang about Childe the Hunter on his 2006 album \"Freedom Fields\"."}
{"id": "6328", "revid": "4490355", "url": "https://en.wikipedia.org/wiki?curid=6328", "title": "Cognate", "text": "In historical linguistics, cognates or lexical cognates are sets of words that have been inherited in direct descent from an etymological ancestor in a common parent language.\nBecause language change can have radical effects on both the sound and the meaning of a word, cognates may not be obvious, and it often takes rigorous study of historical sources and the application of the comparative method to establish whether lexemes are cognate.\nCognates are distinguished from loanwords, where a word has been borrowed from another language.\nName.\nThe English term \"cognate\" derives from Latin , meaning \"blood relative\".\nExamples.\nAn example of cognates from the same Indo-European root are: \"night\" (English), \"Nacht\" (German), \"nacht\" (Dutch, Frisian), \"nag\" (Afrikaans), \"Naach\" (Colognian), \"natt\" (Swedish, Norwegian), \"nat\" (Danish), \"n\u00e1tt\" (Faroese), \"n\u00f3tt\" (Icelandic), \"noc\" (Czech, Slovak, Polish), \u043d\u043e\u0447\u044c, \"noch\" (Russian), \u043d\u043e\u045c, \"no\u0107\" (Macedonian), \u043d\u043e\u0449, \"nosht\" (Bulgarian), \"\u043d\u0456\u0447\", \"nich\" (Ukrainian), \"\u043d\u043e\u0447\", \"noch\"/\"no\u010d\" (Belarusian), \"no\u010d\" (Slovene), \"no\u0107\" (Serbo-Croatian), \"nakts\" (Latvian), \"naktis\" (Lithuanian), \"nos\" (Welsh/Cymraeg), \u03bd\u03cd\u03be, \"nyx\" (Ancient Greek), \"\u03bd\u03cd\u03c7\u03c4\u03b1\" / \"nychta\" (Modern Greek), \"nakt-\" (Sanskrit), \"nat\u00eb\" (Albanian), \"nox\", gen. sg. \"noctis\" (Latin), \"nuit\" (French), \"noche\" (Spanish), \"nochi\" (Extremaduran), \"nueche\" (Asturian), \"noite\" (Portuguese and Galician), \"notte\" (Italian), \"nit\" (Catalan), \"nuet/nit/nueit\" (Aragonese), \"nu\u00e8ch\" / \"nu\u00e8it\" (Occitan) and \"noapte\" (Romanian). These all mean 'night' and derive from the Proto-Indo-European 'night'. The Indo-European languages have hundreds of such cognate sets, though few of them are as neat as this.\nThe Arabic \"sal\u0101m\", the Hebrew \"shalom\", the Assyrian Neo-Aramaic \"shlama\" and the Amharic \"selam\" 'peace' are cognates, derived from the Proto-Semitic *\u0161al\u0101m- 'peace'.\nThe Brazilian Portuguese \"panapan\u00e3\", (flock of butterflies in flight), the Paraguayan Guarani \"panambi\", the Eastern Bolivian Guarani \"panapana\", the Cocama and Omagua \"panama\", and the Sirion\u00f3 \"ana ana\" are cognates, derived from the Old Tupi \"panapana\", 'butterfly', maintaining their original meaning in these Tupi languages.\nCharacteristics.\nCognates need not have the same meaning, as they may have undergone semantic change as the languages developed independently. For example English \"starve\" and Dutch \"sterven\" 'to die' or German \"sterben\" 'to die' all descend from the same Proto-Germanic verb, \"*sterban\u0105\" 'to die'.\nCognates also do not need to look or sound similar: English \"father\", French \"p\u00e8re\", and Armenian \u0570\u0561\u0575\u0580 (\"hayr\") all descend directly from Proto-Indo-European \"*ph\u2082t\u1e17r\". An extreme case is Armenian \u0565\u0580\u056f\u0578\u0582 (\"erku\") and English \"two\", which descend from Proto-Indo-European \"*dw\u00f3h\u2081\"; the sound change \"*dw\" &gt; \"erk\" in Armenian is regular.\nParadigms of conjugations or declensions, the correspondence of which cannot be generally due to chance, have often been used in cognacy assessment. However, beyond paradigms, morphosyntax is often excluded in the assessment of cognacy between words, mainly because structures are usually seen as more subject to borrowing. Still, very complex, non-trivial morphosyntactic structures can rarely take precedence over phonetic shapes to indicate cognates. For instance, Tangut, the language of the Xixia Empire, and one Horpa language spoken today in Sichuan, Geshiza, both display a verbal alternation indicating tense, obeying the same morphosyntactic collocational restrictions. Even without regular phonetic correspondences between the stems of the two languages, the cognatic structures indicate secondary cognacy for the stems.\nFalse cognates.\nFalse cognates are pairs of words that appear to have a common origin, but which in fact do not. For example, Latin and German both mean 'to have' and are phonetically similar. However, the words evolved from different Proto-Indo-European (PIE) roots: , like English \"have\", comes from PIE \"*kh\u2082py\u00e9-\" 'to grasp', and has the Latin cognate \"capere\" 'to seize, grasp, capture'. , on the other hand, is from PIE \"*g\u02b0ab\u02b0\" 'to give, to receive', and hence cognate with English \"give\" and German .\nLikewise, English \"much\" and Spanish look similar and have a similar meaning, but are not cognates: \"much\" is from Proto-Germanic \"*mikilaz\" &lt; PIE \"*me\u01f5-\" and is from Latin \"multum\" &lt; PIE \"*mel-\". A true cognate of \"much\" is the archaic Spanish 'big'.\nDistinctions.\nCognates are distinguished from other kinds of relationships.\nRelated terms.\nEtymon (ancestor word) and descendant words.\nAn etymon, or ancestor word, is the ultimate source word from which one or more cognates derive.\nIn other words, it is the source of related words in different languages. \nFor example, the etymon of both Welsh \"ceffyl\" and Irish \"capall\" is the Proto-Celtic *\"kaballos\" (all meaning \"horse\").\nDescendants are words inherited across a language barrier, coming from a particular etymon in an ancestor language. \nFor example, Russian \"\u043c\u043e\u0301\u0440\u0435\" and Polish \"morze\" are both descendants of Proto-Slavic *\"mo\u0159e\" (meaning \"sea\").\nRoot and derivatives.\nA root is the source of related words within a single language (no language barrier is crossed).\nSimilar to the distinction between \"etymon\" and \"root\", a nuanced distinction can sometimes be made between a \"descendant\" and a \"derivative\". \nA derivative is one of the words which have their source in a root word, and were at some time created from the root word using morphological constructs such as suffixes, prefixes, and slight changes to the vowels or to the consonants of the root word. \nFor example \"unhappy\", \"happily\", and \"unhappily\" are all derivatives of the root word \"happy\".\nThe terms \"root\" and \"derivative\" are used in the analysis of morphological derivation within a language in studies that are not concerned with historical linguistics and that do not cross the language barrier."}
{"id": "6329", "revid": "44920675", "url": "https://en.wikipedia.org/wiki?curid=6329", "title": "Chromatography", "text": "In chemical analysis, chromatography is a laboratory technique for the separation of a mixture into its components. The mixture is dissolved in a fluid solvent (gas or liquid) called the \"mobile phase\", which carries it through a system (a column, a capillary tube, a plate, or a sheet) on which a material called the \"stationary phase\" is fixed. Because the different constituents of the mixture tend to have different affinities for the stationary phase and are retained for different lengths of time depending on their interactions with its surface sites, the constituents travel at different apparent velocities in the mobile fluid, causing them to separate. The separation is based on the differential partitioning between the mobile and the stationary phases. Subtle differences in a compound's partition coefficient result in differential retention on the stationary phase and thus affect the separation.\nChromatography may be \"preparative\" or \"analytical\". The purpose of preparative chromatography is to separate the components of a mixture for later use, and is thus a form of purification. This process is associated with higher costs due to its mode of production. Analytical chromatography is done normally with smaller amounts of material and is for establishing the presence or measuring the relative proportions of analytes in a mixture. The two types are not mutually exclusive.\nEtymology and pronunciation.\nChromatography, pronounced , is derived from Greek \u03c7\u03c1\u1ff6\u03bc\u03b1 \"chr\u014dma\", which means \"color\", and \u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd \"gr\u00e1phein\", which means \"to write\". The combination of these two terms was directly inherited from the invention of the technique first used to separate biological pigments.\nHistory.\nThe method was developed by botanist Mikhail Tsvet in 1901\u20131905 in universities of Kazan and Warsaw. He developed the technique and coined the term \"chromatography\" in the first decade of the 20th century, primarily for the separation of plant pigments such as chlorophyll, carotenes, and xanthophylls. Since these components separate in bands of different colors (green, orange, and yellow, respectively) they directly inspired the name of the technique. New types of chromatography developed during the 1930s and 1940s made the technique useful for many separation processes.\nChromatography technique developed substantially as a result of the work of Archer John Porter Martin and Richard Laurence Millington Synge during the 1940s and 1950s, for which they won the 1952 Nobel Prize in Chemistry. They established the principles and basic techniques of partition chromatography, and their work encouraged the rapid development of several chromatographic methods: paper chromatography, gas chromatography, and what would become known as high-performance liquid chromatography. Since then, the technology has advanced rapidly. Researchers found that the main principles of Tsvet's chromatography could be applied in many different ways, resulting in the different varieties of chromatography described below. Advances are continually improving the technical performance of chromatography, allowing the separation of increasingly similar molecules.\nTerms.\nChromatography is based on the concept of partition coefficient. Any solute partitions between two immiscible solvents. When one make one solvent immobile (by adsorption on a solid support matrix) and another mobile it results in most common applications of chromatography. If the matrix support, or stationary phase, is polar (e.g., cellulose, silica etc.) it is forward phase chromatography. Otherwise this technique is known as reversed phase, where a non-polar stationary phase (e.g., non-polar derivative of C-18) is used.\nTechniques by chromatographic bed shape.\nColumn chromatography.\nColumn chromatography is a separation technique in which the stationary bed is within a tube. The particles of the solid stationary phase or the support coated with a liquid stationary phase may fill the whole inside volume of the tube (packed column) or be concentrated on or along the inside tube wall leaving an open, unrestricted path for the mobile phase in the middle part of the tube (open tubular column). Differences in rates of movement through the medium are calculated to different retention times of the sample.\nIn 1978, W. Clark Still introduced a modified version of column chromatography called \"flash column chromatography\" (flash). The technique is very similar to the traditional column chromatography, except that the solvent is driven through the column by applying positive pressure. This allowed most separations to be performed in less than 20 minutes, with improved separations compared to the old method. Modern flash chromatography systems are sold as pre-packed plastic cartridges, and the solvent is pumped through the cartridge. Systems may also be linked with detectors and fraction collectors providing automation. The introduction of gradient pumps resulted in quicker separations and less solvent usage.\nIn expanded bed adsorption, a fluidized bed is used, rather than a solid phase made by a packed bed. This allows omission of initial clearing steps such as centrifugation and filtration, for culture broths or slurries of broken cells.\nPhosphocellulose chromatography utilizes the binding affinity of many DNA-binding proteins for phosphocellulose. The stronger a protein's interaction with DNA, the higher the salt concentration needed to elute that protein.\nPlanar chromatography.\n\"Planar chromatography\" is a separation technique in which the stationary phase is present as or on a plane. The plane can be a paper, serving as such or impregnated by a substance as the stationary bed (paper chromatography) or a layer of solid particles spread on a support such as a glass plate (thin-layer chromatography). Different compounds in the sample mixture travel different distances according to how strongly they interact with the stationary phase as compared to the mobile phase. The specific Retention factor (Rf) of each chemical can be used to aid in the identification of an unknown substance.\nPaper chromatography.\nPaper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of \"chromatography paper\". The paper is placed in a container with a shallow layer of solvent and sealed. As the solvent rises through the paper, it meets the sample mixture, which starts to travel up the paper with the solvent. This paper is made of cellulose, a polar substance, and the compounds within the mixture travel further if they are less polar. More polar substances bond with the cellulose paper more quickly, and therefore do not travel as far.\nThin-layer chromatography (TLC).\nThin-layer chromatography (TLC) is a widely employed laboratory technique used to separate different biochemicals on the basis of their relative attractions to the stationary and mobile phases. It is similar to paper chromatography. However, instead of using a stationary phase of paper, it involves a stationary phase of a thin layer of adsorbent like silica gel, alumina, or cellulose on a flat, inert substrate. TLC is very versatile; multiple samples can be separated simultaneously on the same layer, making it very useful for screening applications such as testing drug levels and water purity.\nPossibility of cross-contamination is low since each separation is performed on a new layer. Compared to paper, it has the advantage of faster runs, better separations, better quantitative analysis, and the choice between different adsorbents. For even better resolution and faster separation that utilizes less solvent, high-performance TLC can be used. An older popular use had been to differentiate chromosomes by observing distance in gel (separation of was a separate step).\nDisplacement chromatography.\nThe basic principle of displacement chromatography is:\nA molecule with a high affinity for the chromatography matrix (the displacer) competes effectively for binding sites, and thus displaces all molecules with lesser affinities.\nThere are distinct differences between displacement and elution chromatography. In elution mode, substances typically emerge from a column in narrow, Gaussian peaks. Wide separation of peaks, preferably to baseline, is desired for maximum purification. The speed at which any component of a mixture travels down the column in elution mode depends on many factors. But for two substances to travel at different speeds, and thereby be resolved, there must be substantial differences in some interaction between the biomolecules and the chromatography matrix. Operating parameters are adjusted to maximize the effect of this difference. In many cases, baseline separation of the peaks can be achieved only with gradient elution and low column loadings. Thus, two drawbacks to elution mode chromatography, especially at the preparative scale, are operational complexity, due to gradient solvent pumping, and low throughput, due to low column loadings. Displacement chromatography has advantages over elution chromatography in that components are resolved into consecutive zones of pure substances rather than \"peaks\". Because the process takes advantage of the nonlinearity of the isotherms, a larger column feed can be separated on a given column with the purified components recovered at significantly higher concentrations.\nTechniques by physical state of mobile phase.\nGas chromatography.\nGas chromatography (GC), also sometimes known as gas-liquid chromatography, (GLC), is a separation technique in which the mobile phase is a gas. Gas chromatographic separation is always carried out in a column, which is typically \"packed\" or \"capillary\". Packed columns are the routine workhorses of gas chromatography, being cheaper and easier to use and often giving adequate performance. Capillary columns generally give far superior resolution and although more expensive are becoming widely used, especially for complex mixtures. Further, capillary columns can be split into three classes: porous layer open tubular (PLOT), wall-coated open tubular (WCOT) and support-coated open tubular (SCOT) columns. PLOT columns are unique in a way that the stationary phase is adsorbed to the column walls, while WCOT columns have a stationary phase that is chemically bonded to the walls. SCOT columns are in a way the combination of the two types mentioned in a way that they have support particles adhered to column walls, but those particles have liquid phase chemically bonded onto them. Both types of column are made from non-adsorbent and chemically inert materials. Stainless steel and glass are the usual materials for packed columns and quartz or fused silica for capillary columns.\nGas chromatography is based on a partition equilibrium of analyte between a solid or viscous liquid stationary phase (often a liquid silicone-based material) and a mobile gas (most often helium). The stationary phase is adhered to the inside of a small-diameter (commonly 0.53 \u2013 0.18mm inside diameter) glass or fused-silica tube (a capillary column) or a solid matrix inside a larger metal tube (a packed column). It is widely used in analytical chemistry; though the high temperatures used in GC make it unsuitable for high molecular weight biopolymers or proteins (heat denatures them), frequently encountered in biochemistry, it is well suited for use in the petrochemical, environmental monitoring and remediation, and industrial chemical fields. It is also used extensively in chemistry research.\nLiquid chromatography.\nLiquid chromatography (LC) is a separation technique in which the mobile phase is a liquid. It can be carried out either in a column or a plane. Present day liquid chromatography that generally utilizes very small packing particles and a relatively high pressure is referred to as high-performance liquid chromatography.\nIn HPLC the sample is forced by a liquid at high pressure (the mobile phase) through a column that is packed with a stationary phase composed of irregularly or spherically shaped particles, a porous monolithic layer, or a porous membrane. Monoliths are \"sponge-like chromatographic media\" and are made up of an unending block of organic or inorganic parts. HPLC is historically divided into two different sub-classes based on the polarity of the mobile and stationary phases. Methods in which the stationary phase is more polar than the mobile phase (e.g., toluene as the mobile phase, silica as the stationary phase) are termed normal phase liquid chromatography (NPLC) and the opposite (e.g., water-methanol mixture as the mobile phase and C18 () as the stationary phase) is termed reversed phase liquid chromatography (RPLC).\nSupercritical fluid chromatography.\nSupercritical fluid chromatography is a separation technique in which the mobile phase is a fluid above and relatively close to its critical temperature and pressure.\nTechniques by separation mechanism.\nAffinity chromatography.\nAffinity chromatography is based on selective non-covalent interaction between an analyte and specific molecules. It is very specific, but not very robust. It is often used in biochemistry in the purification of proteins bound to tags. These fusion proteins are labeled with compounds such as His-tags, biotin or antigens, which bind to the stationary phase specifically. After purification, these tags are usually removed and the pure protein is obtained.\nAffinity chromatography often utilizes a biomolecule's affinity for the cations of a metal (Zn, Cu, Fe, etc.). Columns are often manually prepared and could be designed specifically for the proteins of interest. Traditional affinity columns are used as a preparative step to flush out unwanted biomolecules, or as a primary step in analyzing a protein with unknown physical properties.\nHowever, liquid chromatography techniques exist that do utilize affinity chromatography properties. Immobilized metal affinity chromatography (IMAC) is useful to separate the aforementioned molecules based on the relative affinity for the metal. Often these columns can be loaded with different metals to create a column with a targeted affinity.\nIon exchange chromatography.\nIon exchange chromatography (usually referred to as ion chromatography) uses an ion exchange mechanism to separate analytes based on their respective charges. It is usually performed in columns but can also be useful in planar mode. Ion exchange chromatography uses a charged stationary phase to separate charged compounds including anions, cations, amino acids, peptides, and proteins. In conventional methods the stationary phase is an ion-exchange resin that carries charged functional groups that interact with oppositely charged groups of the compound to retain. There are two types of ion exchange chromatography: Cation-Exchange and Anion-Exchange. In the Cation-Exchange Chromatography the stationary phase has negative charge and the exchangeable ion is a cation, whereas, in the Anion-Exchange Chromatography the stationary phase has positive charge and the exchangeable ion is an anion. Ion exchange chromatography is commonly used to purify proteins using FPLC.\nSize-exclusion chromatography.\nSize-exclusion chromatography (SEC) is also known as \"gel permeation chromatography\" (GPC) or \"gel filtration chromatography\" and separates molecules according to their size (or more accurately according to their hydrodynamic diameter or hydrodynamic volume).\nSmaller molecules are able to enter the pores of the media and, therefore, molecules are trapped and removed from the flow of the mobile phase. The average residence time in the pores depends upon the effective size of the analyte molecules. However, molecules that are larger than the average pore size of the packing are excluded and thus suffer essentially no retention; such species are the first to be eluted. It is generally a low-resolution chromatography technique and thus it is often reserved for the final, \"polishing\" step of a purification. It is also useful for determining the tertiary structure and quaternary structure of purified proteins, especially since it can be carried out under native solution conditions.\nExpanded bed adsorption chromatographic separation.\nAn expanded bed chromatographic adsorption (EBA) column for a biochemical separation process comprises a pressure equalization liquid distributor having a self-cleaning function below a porous blocking sieve plate at the bottom of the expanded bed, an upper part nozzle assembly having a backflush cleaning function at the top of the expanded bed, a better distribution of the feedstock liquor added into the expanded bed ensuring that the fluid passed through the expanded bed layer displays a state of piston flow. The expanded bed layer displays a state of piston flow. The expanded bed chromatographic separation column has advantages of increasing the separation efficiency of the expanded bed.\nExpanded-bed adsorption (EBA) chromatography is a convenient and effective technique for the capture of proteins directly from unclarified crude sample. In EBA chromatography, the settled bed is first expanded by upward flow of equilibration buffer. The crude feed, which is a mixture of soluble proteins, contaminants, cells, and cell debris, is then passed upward through the expanded bed. Target proteins are captured on the adsorbent, while particulates and contaminants pass through. A change to elution buffer while maintaining upward flow results in desorption of the target protein in expanded-bed mode. Alternatively, if the flow is reversed, the adsorbed particles will quickly settle and the proteins can be desorbed by an elution buffer. The mode used for elution (expanded-bed versus settled-bed) depends on the characteristics of the feed. After elution, the adsorbent is cleaned with a predefined cleaning-in-place (CIP) solution, with cleaning followed by either column regeneration (for further use) or storage.\nSpecial techniques.\nReversed-phase chromatography.\nReversed-phase chromatography (RPC) is any liquid chromatography procedure in which the mobile phase is significantly more polar than the stationary phase. It is so named because in normal-phase liquid chromatography, the mobile phase is significantly less polar than the stationary phase. Hydrophobic molecules in the mobile phase tend to adsorb to the relatively hydrophobic stationary phase. Hydrophilic molecules in the mobile phase will tend to elute first. Separating columns typically comprise a C8 or C18 carbon-chain bonded to a silica particle substrate.\nHydrophobic interaction chromatography.\nHydrophobic Interaction Chromatography (HIC) is a purification and analytical technique that separates analytes, such as proteins, based on hydrophobic interactions between that analyte and the chromatographic matrix. It can provide a non-denaturing orthogonal approach to reversed phase separation, preserving native structures and potentially protein activity. In hydrophobic interaction chromatography, the matrix material is lightly substituted with hydrophobic groups. These groups can range from methyl, ethyl, propyl, butyl, octyl, or phenyl groups. At high salt concentrations, non-polar sidechains on the surface on proteins \"interact\" with the hydrophobic groups; that is, both types of groups are excluded by the polar solvent (hydrophobic effects are augmented by increased ionic strength). Thus, the sample is applied to the column in a buffer which is highly polar, which drives an association of hydrophobic patches on the analyte with the stationary phase. The eluent is typically an aqueous buffer with decreasing salt concentrations, increasing concentrations of detergent (which disrupts hydrophobic interactions), or changes in pH. Of critical importance is the type of salt used, with more kosmotropic salts as defined by the Hofmeister series providing the most water structuring around the molecule and resulting hydrophobic pressure. Ammonium sulfate is frequently used for this purpose. The addition of organic solvents or other less polar constituents may assist in improving resolution.\nIn general, Hydrophobic Interaction Chromatography (HIC) is advantageous if the sample is sensitive to pH change or harsh solvents typically used in other types of chromatography but not high salt concentrations. Commonly, it is the amount of salt in the buffer which is varied. In 2012, M\u00fcller and Franzreb described the effects of temperature on HIC using Bovine Serum Albumin (BSA) with four different types of hydrophobic resin. The study altered temperature as to effect the binding affinity of BSA onto the matrix. It was concluded that cycling temperature from 40 to 10 degrees Celsius would not be adequate to effectively wash all BSA from the matrix but could be very effective if the column would only be used a few times. Using temperature to effect change allows labs to cut costs on buying salt and saves money.\nIf high salt concentrations along with temperature fluctuations want to be avoided one can use a more hydrophobic to compete with one's sample to elute it. This so-called salt independent method of HIC showed a direct isolation of Human Immunoglobulin G (IgG) from serum with satisfactory yield and used \u03b2-cyclodextrin as a competitor to displace IgG from the matrix. This largely opens up the possibility of using HIC with samples which are salt sensitive as we know high salt concentrations precipitate proteins.\nHydrodynamic chromatography.\nHydrodynamic chromatography (HDC) is derived from the observed phenomenon that large droplets move faster than small ones. In a column, this happens because the center of mass of larger droplets is prevented from being as close to the sides of the column as smaller droplets because of their larger overall size. Larger droplets will elute first from the middle of the column while smaller droplets stick to the sides of the column and elute last. This form of chromatography is useful for separating analytes by molar mass (or molecular mass), size, shape, and structure when used in conjunction with light scattering detectors, viscometers, and refractometers. The two main types of HDC are open tube and packed column. Open tube offers rapid separation times for small particles, whereas packed column HDC can increase resolution and is better suited for particles with an average molecular mass larger than formula_1 daltons. HDC differs from other types of chromatography because the separation only takes place in the interstitial volume, which is the volume surrounding and in between particles in a packed column.\nHDC shares the same order of elution as Size Exclusion Chromatography (SEC) but the two processes still vary in many ways. In a study comparing the two types of separation, Isenberg, Brewer, C\u00f4t\u00e9, and Striegel use both methods for polysaccharide characterization and conclude that HDC coupled with multiangle light scattering (MALS) achieves more accurate molar mass distribution when compared to off-line MALS than SEC in significantly less time. This is largely due to SEC being a more destructive technique because of the pores in the column degrading the analyte during separation, which tends to impact the mass distribution. However, the main disadvantage of HDC is low resolution of analyte peaks, which makes SEC a more viable option when used with chemicals that are not easily degradable and where rapid elution is not important.\nHDC plays an especially important role in the field of microfluidics. The first successful apparatus for HDC-on-a-chip system was proposed by Chmela, et al. in 2002. Their design was able to achieve separations using an 80\u00a0mm long channel on the timescale of 3 minutes for particles with diameters ranging from 26 to 110\u00a0nm, but the authors expressed a need to improve the retention and dispersion parameters. In a 2010 publication by Jellema, Markesteijn, Westerweel, and Verpoorte, implementing HDC with a recirculating bidirectional flow resulted in high resolution, size based separation with only a 3\u00a0mm long channel. Having such a short channel and high resolution was viewed as especially impressive considering that previous studies used channels that were 80\u00a0mm in length. For a biological application, in 2007, Huh, et al. proposed a microfluidic sorting device based on HDC and gravity, which was useful for preventing potentially dangerous particles with diameter larger than 6 microns from entering the bloodstream when injecting contrast agents in ultrasounds. This study also made advances for environmental sustainability in microfluidics due to the lack of outside electronics driving the flow, which came as an advantage of using a gravity based device.\nTwo-dimensional chromatography.\nIn some cases, the selectivity provided by the use of one column can be insufficient to provide resolution of analytes in complex samples. Two-dimensional chromatography aims to increase the resolution of these peaks by using a second column with different physico-chemical (chemical classification) properties. Since the mechanism of retention on this new solid support is different from the first dimensional separation, it can be possible to separate compounds by two-dimensional chromatography that are indistinguishable by one-dimensional chromatography. Furthermore, the separation on the second dimension occurs faster than the first dimension. An example of a TDC separation is where the sample is spotted at one corner of a square plate, developed, air-dried, then rotated by 90\u00b0 and usually redeveloped in a second solvent system.\nTwo-dimensional chromatography can be applied to GC or LC separations. The heart-cutting approach selects a specific region of interest on the first dimension for separation, and the comprehensive approach uses all analytes in the second-dimension separation.\nSimulated moving-bed chromatography.\nThe simulated moving bed (SMB) technique is a variant of high performance liquid chromatography; it is used to separate particles and/or chemical compounds that would be difficult or impossible to resolve otherwise. This increased separation is brought about by a valve-and-column arrangement that is used to lengthen the stationary phase indefinitely.\nIn the moving bed technique of preparative chromatography the feed entry and the analyte recovery are simultaneous and continuous, but because of practical difficulties with a continuously moving bed, simulated moving bed technique was proposed. In the simulated moving bed technique instead of moving the bed, the sample inlet and the analyte exit positions are moved continuously, giving the impression of a moving bed.\nTrue moving bed chromatography (TMBC) is only a theoretical concept. Its simulation, SMBC is achieved by the use of a multiplicity of columns in series and a complex valve arrangement. This valve arrangement provides for sample and solvent feed and analyte and waste takeoff at appropriate locations of any column, whereby it allows switching at regular intervals the sample entry in one direction, the solvent entry in the opposite direction, whilst changing the analyte and waste takeoff positions appropriately as well.\nPyrolysis gas chromatography.\nPyrolysis\u2013gas chromatography\u2013mass spectrometry is a method of chemical analysis in which the sample is heated to decomposition to produce smaller molecules that are separated by gas chromatography and detected using mass spectrometry.\nPyrolysis is the thermal decomposition of materials in an inert atmosphere or a vacuum. The sample is put into direct contact with a platinum wire, or placed in a quartz sample tube, and rapidly heated to 600\u20131000\u00a0\u00b0C. Depending on the application even higher temperatures are used. Three different heating techniques are used in actual pyrolyzers: Isothermal furnace, inductive heating (Curie point filament), and resistive heating using platinum filaments. Large molecules cleave at their weakest points and produce smaller, more volatile fragments. These fragments can be separated by gas chromatography. Pyrolysis GC chromatograms are typically complex because a wide range of different decomposition products is formed. The data can either be used as fingerprints to prove material identity or the GC/MS data is used to identify individual fragments to obtain structural information. To increase the volatility of polar fragments, various methylating reagents can be added to a sample before pyrolysis.\nBesides the usage of dedicated pyrolyzers, pyrolysis GC of solid and liquid samples can be performed directly inside Programmable Temperature Vaporizer (PTV) injectors that provide quick heating (up to 30\u00a0\u00b0C/s) and high maximum temperatures of 600\u2013650\u00a0\u00b0C. This is sufficient for some pyrolysis applications. The main advantage is that no dedicated instrument has to be purchased and pyrolysis can be performed as part of routine GC analysis. In this case, quartz GC inlet liners have to be used. Quantitative data can be acquired, and good results of derivatization inside the PTV injector are published as well.\nFast protein liquid chromatography.\nFast protein liquid chromatography (FPLC), is a form of liquid chromatography that is often used to analyze or purify mixtures of proteins. As in other forms of chromatography, separation is possible because the different components of a mixture have different affinities for two materials, a moving fluid (the \"mobile phase\") and a porous solid (the stationary phase). In FPLC the mobile phase is an aqueous solution, or \"buffer\". The buffer flow rate is controlled by a positive-displacement pump and is normally kept constant, while the composition of the buffer can be varied by drawing fluids in different proportions from two or more external reservoirs. The stationary phase is a resin composed of beads, usually of cross-linked agarose, packed into a cylindrical glass or plastic column. FPLC resins are available in a wide range of bead sizes and surface ligands depending on the application.\nCountercurrent chromatography.\nCountercurrent chromatography (CCC) is a type of liquid-liquid chromatography, where both the stationary and mobile phases are liquids and the liquid stationary phase is held stagnant by a strong centrifugal force.\nHydrodynamic countercurrent chromatography (CCC).\nThe operating principle of CCC instrument requires a column consisting of an open tube coiled around a bobbin. The bobbin is rotated in a double-axis gyratory motion (a cardioid), which causes a variable gravity (G) field to act on the column during each rotation. This motion causes the column to see one partitioning step per revolution and components of the sample separate in the column due to their partitioning coefficient between the two immiscible liquid phases used. There are many types of CCC available today. These include HSCCC (High Speed CCC) and HPCCC (High Performance CCC). HPCCC is the latest and best-performing version of the instrumentation available currently.\nCentrifugal partition chromatography (CPC).\nIn the CPC (centrifugal partition chromatography or hydrostatic countercurrent chromatography) instrument, the column consists of a series of cells interconnected by ducts attached to a rotor. This rotor rotates on its central axis creating the centrifugal field necessary to hold the stationary phase in place. The separation process in CPC is governed solely by the partitioning of solutes between the stationary and mobile phases, which mechanism can be easily described using the partition coefficients (\"KD\") of solutes. CPC instruments are commercially available for laboratory, pilot, and industrial-scale separations with different sizes of columns ranging from some 10 milliliters to 10 liters in volume.\nPeriodic counter-current chromatography.\nIn contrast to Counter current chromatography (see above), periodic counter-current chromatography (PCC) uses a solid stationary phase and only a liquid mobile phase. It thus is much more similar to conventional affinity chromatography than to counter current chromatography. PCC uses multiple columns, which during the loading phase are connected in line. This mode allows for overloading the first column in this series without losing product, which already breaks through the column before the resin is fully saturated. The breakthrough product is captured on the subsequent column(s). In a next step the columns are disconnected from one another. The first column is washed and eluted, while the other column(s) are still being loaded. Once the (initially) first column is re-equilibrated, it is re-introduced to the loading stream, but as last column. The process then continues in a cyclic fashion.\nChiral chromatography.\nChiral chromatography involves the separation of stereoisomers. In the case of enantiomers, these have no chemical or physical differences apart from being three-dimensional mirror images. To enable chiral separations to take place, either the mobile phase or the stationary phase must themselves be made chiral, giving differing affinities between the analytes. Chiral chromatography HPLC columns (with a chiral stationary phase) in both normal and reversed phase are commercially available.\nConventional chromatography are incapable of separating racemic mixtures of enantiomers. However, in some cases \"nonracemic\" mixtures of enantiomers may be separated unexpectedly by conventional liquid chromatography (e.g. HPLC without chiral mobile phase or stationary phase ).\nAqueous normal-phase chromatography.\nAqueous normal-phase (ANP) chromatography is characterized by the elution behavior of classical normal phase mode (i.e. where the mobile phase is significantly less polar than the stationary phase) in which water is one of the mobile phase solvent system components. It is distinguished from hydrophilic interaction liquid chromatography (HILIC) in that the retention mechanism is due to adsorption rather than partitioning.\nApplications.\nChromatography is used in many fields including the pharmaceutical industry, the food and beverage industry, the chemical industry, forensic science, environment analysis, and hospitals."}
{"id": "6330", "revid": "1544984", "url": "https://en.wikipedia.org/wiki?curid=6330", "title": "Clement Martyn Doke", "text": "Clement Martyn Doke (16 May 1893 in Bristol, United Kingdom \u2013 24 February 1980 in East London, South Africa) was a South African linguist working mainly on African languages. Realizing that the grammatical structures of Bantu languages are quite different from those of European languages, he was one of the first African linguists of his time to abandon the Euro-centric approach to language description for a more locally grounded one. A most prolific writer, he published a string of grammars, several dictionaries, comparative work, and a history of Bantu linguistics.\nEarly life and career.\nThe Doke family had been engaged in missionary activity for the Baptist Church for some generations. His father, Reverend Joseph J. Doke, left England and travelled to South Africa in 1882, where he met and married Agnes Biggs. They returned to England, where Clement was born as the third of four children. The family moved to New Zealand and eventually returned to South Africa in 1903, where it later settled in Johannesburg.\nAt the age of 18, Clement received a bachelor's degree from Transvaal University College in Pretoria (now the University of Pretoria). He decided to devote his life to missionary activity. In 1913, he accompanied his father on a tour of north-western Rhodesia, to an area called Lambaland, now known as Ilamba. It is at the watershed of the Congo and Zambesi rivers. Part of the district lay in Northern Rhodesia and part of the Belgian Congo. The Cape-Cairo Railway threaded through its eastern portion; otherwise, most travel had to be on foot.\nThe Reverend William Arthur Phillips of the Nyasa Industrial Mission in Blantyre had established a Baptist mission there in 1905; it served an area of and 50,000 souls. The Dokes were supposed to investigate whether the mission in Lambaland could be taken over by the Baptist Union of South Africa. It was on that trip that Doke's father contracted enteric fever and died soon afterwards. Mahatma Gandhi attended the memorial service and addressed the congregation. Clement assumed his father's role.\nThe South African Baptists decided to take over Kafulafuta Mission, and its founder, Reverend Phillips, remained as superintendent. Clement Doke returned to Kafulafuta as missionary in 1914, followed by his sister Olive two years later.\nStudy of Lamba.\nAt first, Clement Doke was frustrated by his inability to communicate with the Lamba. The only written material available at the time was a translation of Jonah and a collection of 47 hymns. Soon, however, he mastered the language and published his first book, \"Ifintu Fyakwe Lesa\" (\"The Things of God, a Primer of Scripture Knowledge\") in 1917. He enrolled in Johannesburg as the extension of Transvaal University College for an MA degree. His thesis was published as \"The Grammar of the Lamba language\". The book is couched in traditional grammatical terms, as Doke had not yet established his innovative method to analyse and describe the Bantu languages. His later \"Textbook of Lamba Grammar\" is far superior in that respect.\nDoke was also interested in ethnology. In 1931 he compiled \"The Lambas of Northern Rhodesia\", which remains one of the outstanding ethnographic descriptions of the peoples of Central Africa. For Doke, literacy was part of evangelisation since it was required so that people to appreciate the Bible's message, but it was only after his retirement that he completed the translation of the Bible into Lamba. It was published under the title of \"Amasiwi AwaLesa\" (\"The Words of God\") in 1959.\nUniversity of the Witwatersrand.\nIn 1919, Doke married Hilda Lehmann, who accompanied him back to Lambaland. Both contracted malaria during their work, and she was forbidden to return to Lambaland. Clement Doke also realised that his field work could not continue much longer, and he left in 1921. He was recruited by the newly founded University of the Witwatersrand. So that he could secure a qualification as a lecturer, the family moved to England, where he registered at the School of Oriental and African Studies. His major languages were Lamba and Luba, but as no suitable examiner was available, he eventually had to change his language to Zulu.\nDoke took up his appointment in the new Department of Bantu Studies at the University of Witwatersrand in 1923. In 1925 he received his D.Litt. for his doctoral thesis \"The Phonetics of the Zulu Language\" and was promoted to Senior Lecturer. In 1931 he was appointed to the Chair of Bantu Studies and thus headed the Department of Bantu Studies. The department acted as a catalyst for the admission of Africans to the university. As early as 1925 a limited number were admitted to the vacation course in African Studies. Doke supported the appointment of Benedict Wallet Vilakazi as member of the staff, as he believed a native speaker was essential for acquiring a language. That provoked a storm of criticism and controversy from the public. Both of them collaborated on the \"Zulu-English Dictionary\". First published in 1948, it is still one of the best examples of lexicography for any Bantu language.\nAt the request of the government of Southern Rhodesia, Doke investigated the range of dialect diversity among the languages of the country and made recommendations for \"Unified Shona\", which formed the basis for Standard Shona. He devised a unified orthography based on the Zezuru, Karanga and Manyika dialects. However, Doke's orthography was never fully accepted, and the South African government introduced an alternative, which left Shona with two competing orthographies between 1935 and 1955.\nDuring his tenure, Doke developed and promoted a method of linguistic analysis and description of the Bantu languages that was based upon the structure of these languages. The \"Dokean model\" continues to be one of the dominant models of linguistic description in Southern and Central Africa. His classification of the Bantu languages was for many years the dominant view of the interrelations among the African languages. He was also an early describer of Khoisan and Bantu click consonants, devising phonetic symbols for a number of them.\nDoke served the University of the Witwatersrand until his retirement in 1953. He was awarded the honorary degree of Doctor of Letters by Rhodes University and the honorary degree of Doctor of Laws by the University of the Witwatersrand in 1972.\nThe former missionary always remained devoted to the Baptist Church. He was elected President of the South African Baptist Union in 1949 and spent a year visiting churches and mission stations. He used his presidential address in condemning the recently established apartheid policy: \"I solemnly warn the Government that the spirit behind their apartheid legislation, and the way in which they are introducing discriminatory measures of all types today, will bring disaster upon this fair land of ours.\""}
{"id": "6331", "revid": "1259410758", "url": "https://en.wikipedia.org/wiki?curid=6331", "title": "Carl Meinhof", "text": "Carl Friedrich Michael Meinhof (23 July 1857 \u2013 11 February 1944) was a German linguist and one of the first linguists to study African languages.\nEarly years and career.\nMeinhof was born in Barzwitz near R\u00fcgenwalde in the Province of Pomerania, Kingdom of Prussia. He studied at the University of T\u00fcbingen and at the University of Greifswald. In 1905 he became professor at the School of Oriental Studies in Berlin. On 5 May 1933 he became a member of the Nazi Party.\nWorks.\nHis most notable work was developing comparative grammar studies of the Bantu languages, building on the pioneering work of Wilhelm Bleek. In his work, Meinhof looked at the common Bantu languages such as Swahili and Zulu to determine similarities and differences.\nIn his work, Meinhof looked at noun classes with all Bantu languages having at least 10 classes and with 22 classes of nouns existing throughout the Bantu languages, though his definition of noun class differs slightly from the accepted one, considering the plural form of a word as belonging to a different class from the singular form (thus leading, for example, to consider a language like French as having four classes instead of two). While no language has all 22 (later: 23) classes active, Venda has 20, Lozi has 18, and Ganda has 16 or 17 (depending on whether the locative class 23 \"e-\" is included). All Bantu languages have a noun class specifically for humans (sometimes including other animate beings).\nMeinhof also examined other African languages, including groups classified at the time as Kordofanian, Bushman, Khoikhoi, and Hamitic.\nMeinhof developed a comprehensive classification scheme for African languages. His classification was the standard one for many years (Greenberg 1955:3). It was replaced by those of Joseph Greenberg in 1955 and in 1963.\nIn 1902, Meinhof made recordings of East African music. These are among the first recordings made of traditional African music.\nControversial views.\nIn 1912, Carl Meinhof published \"Die Sprachen der Hamiten\" (The Languages of the Hamites). He used the term Hamitic. Meinhof's system of classification of the Hamitic languages was based on a belief that \"speakers of Hamitic became largely coterminous with cattle herding peoples with essentially Caucasian origins, intrinsically different from and superior to the 'Negroes of Africa'.\" However, in the case of the so-called Nilo-Hamitic languages (a concept he introduced), it was based on the typological feature of gender and a \"fallacious theory of language mixture.\" Meinhof did this in spite of earlier work by scholars such as Lepsius and Johnston demonstrating that the languages which he would later dub \"Nilo-Hamitic\" were in fact Nilotic languages with numerous similarities in vocabulary with other Nilotic languages.\nFamily.\nCarl Meinhof was the great-uncle (the brother of the grandfather) of Ulrike Meinhof, a well known German journalist, who later became a founding member of the Red Army Faction (RAF), a left-wing militant group operating chiefly in West Germany in the 1970s and 1980s."}
{"id": "6335", "revid": "33145", "url": "https://en.wikipedia.org/wiki?curid=6335", "title": "Cucurbitaceae", "text": "The Cucurbitaceae (), also called cucurbits or the gourd family, are a plant family consisting of about 965 species in 101 genera. Those of most agricultural, commercial or nutritional value to humans include:\nThe plants in this family are grown around the tropics and in temperate areas of the world, where those with edible fruits were among the earliest cultivated plants in both the Old and New Worlds. The family Cucurbitaceae ranks among the highest of plant families for number and percentage of species used as human food. The name \"Cucurbitaceae\" comes to international scientific vocabulary from Neo-Latin, from \"Cucurbita\", the type genus, + \"-aceae\", a standardized suffix for plant family names in modern taxonomy. The genus name comes from the Classical Latin word \"\", meaning \"gourd\".\nDescription.\nMost of the plants in this family are annual vines, but some are woody lianas, thorny shrubs, or trees (\"Dendrosicyos\"). Many species have large, yellow or white flowers. The stems are hairy and pentangular. Tendrils are present at 90\u00b0 to the leaf petioles at nodes. Leaves are exstipulate, alternate, simple palmately lobed or palmately compound. The flowers are unisexual, with male and female flowers on different plants (dioecious) or on the same plant (monoecious). The female flowers have inferior ovaries. The fruit is often a kind of modified berry called a pepo.\nFossil history.\nOne of the oldest fossil cucurbits so far is \u2020\"Cucurbitaciphyllum lobatum\" from the Paleocene epoch, found at Shirley Canal, Montana. It was described for the first time in 1924 by the paleobotanist Frank Hall Knowlton. The fossil leaf is palmate, trilobed with rounded lobal sinuses and an entire or serrate margin. It has a leaf pattern similar to the members of the genera \"Kedrostis\", \"Melothria\" and \"Zehneria\".\nClassification.\nTribal classification.\nThe most recent classification of Cucurbitaceae delineates 15 tribes:\nSystematics.\nModern molecular phylogenetics suggest the following relationships:\n! style=\"background:#F0F2F5\" |Detailed Cladogram showing Cucurbitaceae phylogeny"}
{"id": "6336", "revid": "39088119", "url": "https://en.wikipedia.org/wiki?curid=6336", "title": "Chorded keyboard", "text": "A keyset or chorded keyboard (also called a chorded keyset, \"chord keyboard\" or \"chording keyboard\") is a computer input device that allows the user to enter characters or commands formed by pressing several keys together, like playing a \"chord\" on a piano. The large number of combinations available from a small number of keys allows text or commands to be entered with one hand, leaving the other hand free. A secondary advantage is that it can be built into a device (such as a pocket-sized computer or a bicycle handlebar) that is too small to contain a normal-sized keyboard.\nA chorded keyboard minus the board, typically designed to be used while held in the hand, is called a keyer. Douglas Engelbart introduced the chorded keyset as a computer interface in 1968 at what is often called \"The Mother of All Demos\".\nPrinciples of operation.\nEach key is mapped to a number and then can be mapped to a corresponding letter or command. By pressing two or more keys together the user can generate many combinations. In Engelbart's original mapping, he used five keys: 1, 2, 4, 8, 16. The keys were mapped as follows: a = 1, b = 2, c = 3, d = 4, and so on. If the user pressed keys 1 and 2 simultaneously, and then released the keys, 1 and 2 would be added to 3, and since C is the 3rd letter of the alphabet, and the letter \"c\" appeared. Unlike pressing a chord on a piano, the chord is recognized only after all the keys or mouse buttons are released. Since Engelbart introduced the keyset, several different designs have been developed based on similar concepts.\nAs a crude example, each finger might control one key which corresponds to one bit in a byte, so that using seven keys and seven fingers, one could enter any character in the ASCII set\u2014if the user could remember the binary codes. Due to the small number of keys required, chording is easily adapted from a desktop to mobile environment.\nPractical devices generally use simpler chords for common characters (\"e.g.,\" Baudot), or may have ways to make it easier to remember the chords (\"e.g.,\" Microwriter), but the same principles apply. These portable devices first became popular with the wearable computer movement in the 1980s.\nThad Starner from Georgia Institute of Technology and others published numerous studies showing that two-handed chorded text entry was faster and yielded fewer errors than on a QWERTY keyboard. Currently stenotype machines hold the record for fastest word entry. Many stenotype users can reach 300 words per minute. However, stenographers typically train for three years before reaching professional levels of speed and accuracy.\nHistory.\nThe earliest known chord keyboard was part of the \"five-needle\" telegraph operator station, designed by Wheatstone and Cooke in 1836, in which any two of the five needles could point left or right to indicate letters on a grid. It was designed to be used by untrained operators (who would determine which keys to press by looking at the grid), and was not used where trained telegraph operators were available.\nThe first widespread use of a chord keyboard was in the stenotype machine used by court reporters, which was invented in 1868 and is still in use. The output of the stenotype was originally a phonetic code that had to be transcribed later (usually by the same operator who produced the original output), rather than arbitrary text\u2014automatic conversion software is now commonplace.\nIn 1874, the five-bit Baudot telegraph code and a matching 5-key chord keyboard was designed to be used with the operator forming the codes manually. The code is optimized for speed and low wear: chords were chosen so that the most common characters used the simplest chords. But telegraph operators were already using typewriters with QWERTY keyboards to \"copy\" received messages, and at the time it made more sense to build a typewriter that could generate the codes automatically, rather than making them learn to use a new input device.\nSome early keypunch machines used a keyboard with 12 labeled keys to punch the correct holes in paper cards. The numbers 0 through 9 were represented by one punch; 26 letters were represented by combinations of two punches, and symbols were represented by combinations of two or three punches.\nBraille (a writing system for the blind) uses either 6 or 8 tactile 'points' from which all letters and numbers are formed. When Louis Braille invented it, it was produced with a needle holing successively all needed points in a cardboard sheet. In 1892, Frank Haven Hall, superintendent of the Illinois Institute for the Education of the Blind, created the Hall Braille Writer, which was like a typewriter with 6 keys, one for each dot in a braille cell. The Perkins Brailler, first manufactured in 1951, uses a 6-key chord keyboard (plus a spacebar) to produce braille output, and has been very successful as a mass market affordable product. Braille, like Baudot, uses a number symbol and a shift symbol, which may be repeated for shift lock, to fit numbers and upper case into the 63 codes that 6 bits offer.\nAfter World War II, with the arrival of electronics for reading chords and looking in tables of \"codes\", the postal sorting offices started to research chordic solutions to be able to employ people other than trained and expensive typists. In 1954, an important concept was discovered: chordic production is easier to master when the production is done at the release of the keys instead of when they are pressed.\nResearchers at IBM investigated chord keyboards for both typewriters and computer data entry as early as 1959, with the idea that it might be faster than touch-typing if some chords were used to enter whole words or parts of words. A 1975 design by IBM Fellow Nat Rochester had 14 keys that were dimpled on the edges as well as the top, so one finger could press two adjacent keys for additional combinations. Their results were inconclusive, but research continued until at least 1978.\nDoug Engelbart began experimenting with keysets to use with the mouse in the mid-1960s. In a famous 1968 demonstration, Engelbart introduced a computer human interface that included the QWERTY keyboard, a three button mouse, and a five key keyset. Engelbart used the keyset with his left hand and the mouse with his right to type text and enter commands. The mouse buttons marked selections and confirmed or aborted commands.\nUsers in Engelbart's Augmentation Research Center at SRI became proficient with the mouse and keyset. In the 1970s the funding Engelbart's group received from the Advanced Research Projects Agency (ARPA) was cut and many key members of Engelbart's team went to work for Xerox PARC where they continued to experiment with the mouse and keyset. Keychord sets were used at Xerox PARC in the early 1980s, along with mice, GUIs, on the Xerox Star and Alto workstations. A one-button version of the mouse was incorporated into the Apple Macintosh but Steve Jobs decided against incorporating the chorded keyset.\nIn the early 1980s, Philips Research labs at Redhill, Surrey did a brief study into small, cheap keyboards for entering text on a telephone. One solution used a grid of hexagonal keys with symbols inscribed into dimples in the keys that were either in the center of a key, across the boundary of two keys, or at the joining of three keys. Pressing down on one of the dimples would cause either one, two or three of the hexagonal buttons to be depressed at the same time, forming a chord that would be unique to that symbol. With this arrangement, a nine button keyboard with three rows of three hexagonal buttons could be fitted onto a telephone and could produce up to 33 different symbols. By choosing widely separated keys, one could employ one dimple as a 'shift' key to allow both letters and numbers to be produced. With eleven keys in a 3/4/4 arrangement, 43 symbols could be arranged allowing for lowercase text, numbers and a modest number of punctuation symbols to be represented along with a 'shift' function for accessing uppercase letters. While this had the advantage of being usable by untrained users via 'hunt and peck' typing and requiring one less key switch than a conventional 12 button keypad, it had the disadvantage that some symbols required three times as much force to depress them as others which made it hard to achieve any speed with the device. That solution is still alive and proposed by Fastap and Unitap among others, and a commercial phone has been produced and promoted in Canada during 2006.\nStandards.\nHistorically, the baudot and braille keyboards were standardized to some extent, but they are unable to replicate the full character set of a modern keyboard. Braille comes closest, as it has been extended to eight bits.\nThe only proposed modern standard, GKOS (or Global Keyboard Open Standard) can support most characters and functions found on a computer keyboard but has had little commercial development. There is, however, a GKOS keyboard application available for iPhone since May 8, 2010, for Android since October 3, 2010 and for MeeGo Harmattan since October 27, 2011.\nStenography.\nStenotype machines, sometimes used by court reporters, use a chording keyboard to represent sounds: on the standard keyboard, the U represents the sound and word, 'you', and the three-key trigraph KAT represents the sound and word 'cat'. The stenotype keyboard is explicitly ordered: in KAT, K, on the left, is the starting sound. P, S, and T, which are common starting sounds and also common ending sounds, are available on both sides of the keyboard: POP is a 3-key chord, using both P keys.\nOpen-source designs.\nMultiple open-source keyer/keyset designs are available, such as the pickey, a PS/2 device based on the PIC microcontroller; the spiffchorder, a USB device based on the Atmel AVR family of microcontrollers; the FeatherChorder, a BLE chorder based on the Adafruit Feather, an all-in-one board incorporating an Arduino-compatible microcontroller; and the GKOS keypad driver for Linux as well as the Gkos library for the Atmel/Arduino open-source board.\nPlover is a free, open-source, cross-platform program intended to bring real-time stenographic technology not just to stenographers, but also to hobbyists using anything from professional Stenotype machines to low-cost NKRO gaming keyboards. It is available for Linux, Windows, and macOS.\nJoy2chord is a chorded keyboard driver for Linux. With a configuration file, any joystick or gamepad can be turned into a chorded keyboard. This design philosophy was decided on to lower the cost of building devices, and in turn lower the entry barrier to becoming familiar with chorded keyboards. Macro keys, and multiple modes are also easily implemented with a user space driver.\nCommercial devices.\nOne minimal chordic keyboard example is Edgar Matias' Half-Qwerty keyboard described in patent circa 1992 that produces the letters of the missing half when the user simultaneously presses the space bar along with the mirror key. INTERCHI '93 published a study by Matias, MacKenzie and Buxton showing that people who have already learned to touch-type can quickly recover 50 to 70% of their two-handed typing speed. The loss contributes to the speed discussion above. It is implemented on two popular mobile phones, each provided with software disambiguation, which allows users to avoid using the space-bar.\n\"Multiambic\" keyers for use with wearable computers were invented in Canada in the 1970s. Multiambic keyers are similar to chording keyboards but without the board, in that the keys are grouped in a cluster for being handheld, rather than for sitting on a flat surface.\nChording keyboards are also used as portable but two handed input devices for the visually impaired (either combined with a refreshable braille display or vocal synthesis). Such keyboards use a minimum of seven keys, where each key corresponds to an individual braille point, except one key which is used as a spacebar. In some applications, the spacebar is used to produce additional chords which enable the user to issue editing commands, such as moving the cursor, or deleting words. Note that the number of points used in braille computing is not 6, but 8, as this allows the user, among other things, to distinguish between small and capital letters, as well as identify the position of the cursor. As a result, most newer chorded keyboards for braille input include at least nine keys.\nTouch screen chordic keyboards are available to smartphone users as an optional way of entering text. As the number of keys is low, the button areas can be made bigger and easier to hit on the small screen. The most common letters do not necessarily require chording as is the case with the GKOS keyboard optimised layouts (Android app) where the twelve most frequent characters only require single keys.\nThe company CharaChorder commercially sells chorded entry devices. Their first commercially available device is the CharaChorder One, which features a split design with each having access to 9 switches that can be moved in five directions (up, down, left, right, and pressed) in contrast to typical keyboards. This device allows for both chorded entry as well as traditional character entry. The set of words that can be chorded can be dynamically changed by the user in real time, but by default includes the 300 most common words in the English language. This chorded entry feature allows for potentially extremely fast typing speeds, so much so the founder of the company has been banned from online typing competitions. Additionally, they create the Charachorder Lite with a more traditional keyboard design. The manufacturer claimed that users of the Charachorder One can reach speeds of 300 words per minute, while users of the Charachorder Lite can reach 250 words per minute.\nHistorical.\nThe WriteHander, a 12-key chord keyboard from NewO Company, appeared in 1978 issues of ROM Magazine, an early microcomputer applications magazine.\nAnother early commercial model was the six-button Microwriter, designed by Cy Endfield and Chris Rainey, and first sold in 1980. Microwriting is the system of chord keying and is based on a set of mnemonics. It was designed only for right-handed use.\nIn 1982 the Octima 8 keys cord keyboard was presented by Ergoplic Kebords Ltd an Israeli Startup that was founded by Israeli researcher with intensive experience in Man Machine Interface design. The keyboard had 8 keys one for each finger and additional 3 keys that enabled the production of numbers, punctuations and control functions. The keyboard was fully compatible with the IBM PC and AT keyboards and had an Apple IIe version as well. Its key combinations were based on a mnemonic system that enabled fast and easy touch type learning. Within a few hours the user could achieve a typing speed similar to hand writing speed. The unique design also gave a relief from hand stress (Carpal Tunnel Syndrome) and allowed longer typing sessions than traditional keyboards. It was multi-lingual supporting English, German, French and Hebrew.\nThe BAT is a 7-key hand-sized device from Infogrip, and has been sold since 1985. It provides one key for each finger and three for the thumb. It is proposed for the hand which does not hold the mouse, in an exact continuation of Engelbart's vision."}
{"id": "6337", "revid": "33752928", "url": "https://en.wikipedia.org/wiki?curid=6337", "title": "Carolyn Beug", "text": "Carolyn Ann Mayer-Beug (December 11, 1952 \u2013 September 11, 2001) was a filmmaker and video producer from Santa Monica, California. She died in the September 11 attacks as a passenger of the American Airlines Flight 11.\nCareer.\nIn addition to her work as video producer, Beug also directed three music videos for country singer Dwight Yoakam: \"Ain't That Lonely Yet\", \"A Thousand Miles from Nowhere\" and \"Fast as You.\" Beug co-directed the former two videos with Yoakam and was the sole director of the latter video. She won an MTV Video Music award for the Van Halen music video of the song \"Right Now\", which she produced. She also served as senior vice president of Walt Disney Records.\nPersonal life.\nBeug lived in a Tudor-style home in the North 25th Street neighborhood. She hosted an annual backyard barbecue for the Santa Monica High School cross country and track team, which her daughters captained. Beug was a Latter-day Saint.\nDeath and legacy.\nBeug was killed at the age of 48 in the crash of American Airlines Flight 11 in the September 11, 2001 attacks. At the time of her death, Carolyn Beug was working on a children's book about Noah's Ark which was to be told from Noah's wife's point of view. On the plane with her was her mother, Mary Alice Wahlstrom. Beug was survived by her twin eighteen-year-old daughters Lauren and Lindsey Mayer-Beug, her 13-year-old son, Nick, and her husband, John Beug, a senior vice president in charge of filmed production for Warner Brothers' record division. She was returning home from taking her daughters to college at the Rhode Island School of Design.\nAt the National 9/11 Memorial, Beug is memorialized at the North Pool, on Panel N-1."}
{"id": "6339", "revid": "33625371", "url": "https://en.wikipedia.org/wiki?curid=6339", "title": "Cell biology", "text": "Cell biology (also cellular biology or cytology) is a branch of biology that studies the structure, function, and behavior of cells. All living organisms are made of cells. A cell is the basic unit of life that is responsible for the living and functioning of organisms. Cell biology is the study of the structural and functional units of cells. Cell biology encompasses both prokaryotic and eukaryotic cells and has many subtopics which may include the study of cell metabolism, cell communication, cell cycle, biochemistry, and cell composition. The study of cells is performed using several microscopy techniques, cell culture, and cell fractionation. These have allowed for and are currently being used for discoveries and research pertaining to how cells function, ultimately giving insight into understanding larger organisms. Knowing the components of cells and how cells work is fundamental to all biological sciences while also being essential for research in biomedical fields such as cancer, and other diseases. Research in cell biology is interconnected to other fields such as genetics, molecular genetics, molecular biology, medical microbiology, immunology, and cytochemistry.\nHistory.\nCells were first seen in 17th-century Europe with the invention of the compound microscope. In 1665, Robert Hooke referred to the building blocks of all living organisms as \"cells\" (published in \"Micrographia\") after looking at a piece of cork and observing a structure reminiscent of a monastic cell; however, the cells were dead. They gave no indication to the actual overall components of a cell. A few years later, in 1674, Anton Van Leeuwenhoek was the first to analyze live cells in his examination of algae. Many years later, in 1831, Robert Brown discovered the nucleus. All of this preceded the cell theory which states that all living things are made up of cells and that cells are organisms' functional and structural units. This was ultimately concluded by plant scientist Matthias Schleiden and animal scientist Theodor Schwann in 1838, who viewed live cells in plant and animal tissue, respectively. 19 years later, Rudolf Virchow further contributed to the cell theory, adding that all cells come from the division of pre-existing cells. Viruses are not considered in cell biology \u2013 they lack the characteristics of a living cell and instead are studied in the microbiology subclass of virology.\nTechniques.\nCell biology research looks at different ways to culture and manipulate cells outside of a living body to further research in human anatomy and physiology, and to derive medications. The techniques by which cells are studied have evolved. Due to advancements in microscopy, techniques and technology have allowed scientists to hold a better understanding of the structure and function of cells. Many techniques commonly used to study cell biology are listed below:\nCell types.\nThere are two fundamental classifications of cells: prokaryotic and eukaryotic. Prokaryotic cells are distinguished from eukaryotic cells by the absence of a cell nucleus or other membrane-bound organelle. Prokaryotic cells are much smaller than eukaryotic cells, making them the smallest form of life. Prokaryotic cells include Bacteria and Archaea, and lack an enclosed cell nucleus. \u00a0Eukaryotic cells are found in plants, animals, fungi, and protists. They range from 10 to 100 \u03bcm in diameter, and their DNA is contained within a membrane-bound nucleus. Eukaryotes are organisms containing eukaryotic cells. The four eukaryotic kingdoms are Animalia, Plantae, Fungi, and Protista.\nThey both reproduce through binary fission. Bacteria, the most prominent type, have several different shapes, although most are spherical or rod-shaped. Bacteria can be classed as either gram-positive or gram-negative depending on the cell wall composition. Gram-positive bacteria have a thicker peptidoglycan layer than gram-negative bacteria. Bacterial structural features include a flagellum that helps the cell to move, ribosomes for the translation of RNA to protein, and a nucleoid that holds all the genetic material in a circular structure. There are many processes that occur in prokaryotic cells that allow them to survive. In prokaryotes, mRNA synthesis is initiated at a promoter sequence on the DNA template comprising two consensus sequences that recruit RNA polymerase. The prokaryotic polymerase consists of a core enzyme of four protein subunits and a \u03c3 protein that assists only with initiation. For instance, in a process termed conjugation, the fertility factor allows the bacteria to possess a pilus which allows it to transmit DNA to another bacteria which lacks the F factor, permitting the transmittance of resistance allowing it to survive in certain environments.\nStructure and function.\nStructure of eukaryotic cells.\nEukaryotic cells are composed of the following organelles:\nEukaryotic cells may also be composed of the following molecular components:\nCell metabolism.\nCell metabolism is necessary for the production of energy for the cell and therefore its survival and includes many pathways and also sustaining the main cell organelles such as the nucleus, the mitochondria, the cell membrane etc. For cellular respiration, once glucose is available, glycolysis occurs within the cytosol of the cell to produce pyruvate. Pyruvate undergoes decarboxylation using the multi-enzyme complex to form acetyl coA which can readily be used in the TCA cycle to produce NADH and FADH2. These products are involved in the electron transport chain to ultimately form a proton gradient across the inner mitochondrial membrane. This gradient can then drive the production of ATP and during oxidative phosphorylation. Metabolism in plant cells includes photosynthesis which is simply the exact opposite of respiration as it ultimately produces molecules of glucose.\nCell signaling.\nCell signaling or cell communication is important for cell regulation and for cells to process information from the environment and respond accordingly. Signaling can occur through direct cell contact or endocrine, paracrine, and autocrine signaling. Direct cell-cell contact is when a receptor on a cell binds a molecule that is attached to the membrane of another cell. Endocrine signaling occurs through molecules secreted into the bloodstream. Paracrine signaling uses molecules diffusing between two cells to communicate. Autocrine is a cell sending a signal to itself by secreting a molecule that binds to a receptor on its surface. Forms of communication can be through:\nGrowth and development.\nEukaryotic cell cycle.\nCells are the foundation of all organisms and are the fundamental units of life. The growth and development of cells are essential for the maintenance of the host and survival of the organism. For this process, the cell goes through the steps of the cell cycle and development which involves cell growth, DNA replication, cell division, regeneration, and cell death.\nThe cell cycle is divided into four distinct phases: G1, S, G2, and M. The G phase \u2013 which is the cell growth phase \u2013 makes up approximately 95% of the cycle. The proliferation of cells is instigated by progenitors. All cells start out in an identical form and can essentially become any type of cells. Cell signaling such as induction can influence nearby cells to determinate the type of cell it will become. Moreover, this allows cells of the same type to aggregate and form tissues, then organs, and ultimately systems. The G1, G2, and S phase (DNA replication, damage and repair) are considered to be the interphase portion of the cycle, while the M phase (mitosis) is the cell division portion of the cycle. Mitosis is composed of many stages which include, prophase, metaphase, anaphase, telophase, and cytokinesis, respectively. The ultimate result of mitosis is the formation of two identical daughter cells.\nThe cell cycle is regulated in cell cycle checkpoints, by a series of signaling factors and complexes such as cyclins, cyclin-dependent kinase, and p53. When the cell has completed its growth process and if it is found to be damaged or altered, it undergoes cell death, either by apoptosis or necrosis, to eliminate the threat it can cause to the organism's survival.\nCell mortality, cell lineage immortality.\nThe ancestry of each present day cell presumably traces back, in an unbroken lineage for over 3 billion years to the origin of life. It is not actually cells that are immortal but multi-generational cell lineages. The immortality of a cell lineage depends on the maintenance of cell division potential. This potential may be lost in any particular lineage because of cell damage, terminal differentiation as occurs in nerve cells, or programmed cell death (apoptosis) during development. Maintenance of cell division potential over successive generations depends on the avoidance and the accurate repair of cellular damage, particularly DNA damage. In sexual organisms, continuity of the germline depends on the effectiveness of processes for avoiding DNA damage and repairing those DNA damages that do occur. Sexual processes in eukaryotes, as well as in prokaryotes, provide an opportunity for effective repair of DNA damages in the germ line by homologous recombination.\nCell cycle phases.\nThe cell cycle is a four-stage process that a cell goes through as it develops and divides. It includes Gap 1 (G1), synthesis (S), Gap 2 (G2), and mitosis (M). The cell either restarts the cycle from G1 or leaves the cycle through G0 after completing the cycle. The cell can progress from G0 through terminal differentiation. Finally, the interphase refers to the phases of the cell cycle that occur between one mitosis and the next, and includes G1, S, and G2. Thus, the phases are:\nPathology.\nThe scientific branch that studies and diagnoses diseases on the cellular level is called cytopathology. Cytopathology is generally used on samples of free cells or tissue fragments, in contrast to the pathology branch of histopathology, which studies whole tissues. Cytopathology is commonly used to investigate diseases involving a wide range of body sites, often to aid in the diagnosis of cancer but also in the diagnosis of some infectious diseases and other inflammatory conditions. For example, a common application of cytopathology is the Pap smear, a screening test used to detect cervical cancer, and precancerous cervical lesions that may lead to cervical cancer.\nCell cycle checkpoints and DNA damage repair system.\nThe cell cycle is composed of a number of well-ordered, consecutive stages that result in cellular division. The fact that cells do not begin the next stage until the last one is finished, is a significant element of cell cycle regulation. Cell cycle checkpoints are characteristics that constitute an excellent monitoring strategy for accurate cell cycle and divisions. Cdks, associated cyclin counterparts, protein kinases, and phosphatases regulate cell growth and division from one stage to another. The cell cycle is controlled by the temporal activation of Cdks, which is governed by cyclin partner interaction, phosphorylation by particular protein kinases, and de-phosphorylation by Cdc25 family phosphatases. In response to DNA damage, a cell's DNA repair reaction is a cascade of signaling pathways that leads to checkpoint engagement, regulates, the repairing mechanism in DNA, cell cycle alterations, and apoptosis. Numerous biochemical structures, as well as processes that detect damage in DNA, are ATM and ATR, which induce the DNA repair checkpoints\nThe cell cycle is a sequence of activities in which cell organelles are duplicated and subsequently separated into daughter cells with precision. There are major events that happen during a cell cycle. The processes that happen in the cell cycle include cell development, replication and segregation of chromosomes.\u00a0 The cell cycle checkpoints are surveillance systems that keep track of the cell cycle's integrity, accuracy, and chronology. Each checkpoint serves as an alternative cell cycle endpoint, wherein the cell's parameters are examined and only when desirable characteristics are fulfilled does the cell cycle advance through the distinct steps. The cell cycle's goal is to precisely copy each organism's DNA and afterwards equally split the cell and its components between the two new cells. Four main stages occur in the eukaryotes. In G1, the cell is usually active and continues to grow rapidly, while in G2, the cell growth continues while protein molecules become ready for separation. These are not dormant times; they are when cells gain mass, integrate growth factor receptors, establish a replicated genome, and prepare for chromosome segregation. DNA replication is restricted to a separate Synthesis in eukaryotes, which is also known as the S-phase. During mitosis, which is also known as the M-phase, the segregation of the chromosomes occur. DNA, like every other molecule, is capable of undergoing a wide range of chemical reactions. Modifications in DNA's sequence, on the other hand, have a considerably bigger impact than modifications in other cellular constituents like RNAs or proteins because DNA acts as a permanent copy of the cell genome. When erroneous nucleotides are incorporated during DNA replication, mutations can occur. The majority of DNA damage is fixed by removing the defective bases and then re-synthesizing the excised area. On the other hand, some DNA lesions can be mended by reversing the damage, which may be a more effective method of coping with common types of DNA damage. Only a few forms of DNA damage are mended in this fashion, including pyrimidine dimers caused by ultraviolet (UV) light changed by the insertion of methyl or ethyl groups at the purine ring's O6 position.\nMitochondrial membrane dynamics.\nMitochondria are commonly referred to as the cell's \"powerhouses\" because of their capacity to effectively produce ATP which is essential to maintain cellular homeostasis and metabolism. Moreover, researchers have gained a better knowledge of mitochondria's significance in cell biology because of the discovery of cell signaling pathways by mitochondria which are crucial platforms for cell function regulation such as apoptosis. Its physiological adaptability is strongly linked to the cell mitochondrial channel's ongoing reconfiguration through a range of mechanisms known as mitochondrial membrane dynamics, including endomembrane fusion and fragmentation (separation) and ultrastructural membrane remodeling. As a result, mitochondrial dynamics regulate and frequently choreograph not only metabolic but also complicated cell signaling processes such as cell pluripotent stem cells, proliferation, maturation, aging, and mortality. Mutually, post-translational alterations of mitochondrial apparatus and the development of transmembrane contact sites among mitochondria and other structures, which both have the potential to link signals from diverse routes that affect mitochondrial membrane dynamics substantially, Mitochondria are wrapped by two membranes: an inner mitochondrial membrane (IMM) and an outer mitochondrial membrane (OMM), each with a distinctive function and structure, which parallels their dual role as cellular powerhouses and signaling organelles. The inner mitochondrial membrane divides the mitochondrial lumen into two parts: the inner border membrane, which runs parallel to the OMM, and the cristae, which are deeply twisted, multinucleated invaginations that give room for surface area enlargement and house the mitochondrial respiration apparatus. The outer mitochondrial membrane, on the other hand, is soft and permeable. It, therefore, acts as a foundation for cell signaling pathways to congregate, be deciphered, and be transported into mitochondria. Furthermore, the OMM connects to other cellular organelles, such as the endoplasmic reticulum (ER), lysosomes, endosomes, and the plasma membrane. Mitochondria play a wide range of roles in cell biology, which is reflected in their morphological diversity. Ever since the beginning of the mitochondrial study, it has been well documented that mitochondria can have a variety of forms, with both their general and ultra-structural morphology varying greatly among cells, during the cell cycle, and in response to metabolic or cellular cues. Mitochondria can exist as independent organelles or as part of larger systems; they can also be unequally distributed in the cytosol through regulated mitochondrial transport and placement to meet the cell's localized energy requirements. Mitochondrial dynamics refers to the adaptive and variable aspect of mitochondria, including their shape and subcellular distribution.\nAutophagy.\nAutophagy is a self-degradative mechanism that regulates energy sources during growth and reaction to dietary stress. Autophagy also cleans up after itself, clearing aggregated proteins, cleaning damaged structures including mitochondria and endoplasmic reticulum and eradicating intracellular infections. Additionally, autophagy has antiviral and antibacterial roles within the cell, and it is involved at the beginning of distinctive and adaptive immune responses to viral and bacterial contamination. Some viruses include virulence proteins that prevent autophagy, while others utilize autophagy elements for intracellular development or cellular splitting. Macro autophagy, micro autophagy, and chaperon-mediated autophagy are the three basic types of autophagy. When macro autophagy is triggered, an exclusion membrane incorporates a section of the cytoplasm, generating the autophagosome, a distinctive double-membraned organelle. The autophagosome then joins the lysosome to create an autolysosome, with lysosomal enzymes degrading the components. In micro autophagy, the lysosome or vacuole engulfs a piece of the cytoplasm by invaginating or protruding the lysosomal membrane to enclose the cytosol or organelles. The chaperone-mediated autophagy (CMA) protein quality assurance by digesting oxidized and altered proteins under stressful circumstances and supplying amino acids through protein denaturation. Autophagy is the primary intrinsic degradative system for peptides, fats, carbohydrates, and other cellular structures. In both physiologic and stressful situations, this cellular progression is vital for upholding the correct cellular balance. Autophagy instability leads to a variety of illness symptoms, including inflammation, biochemical disturbances, aging, and neurodegenerative, due to its involvement in controlling cell integrity. The modification of the autophagy-lysosomal networks is a typical hallmark of many neurological and muscular illnesses. As a result, autophagy has been identified as a potential strategy for the prevention and treatment of various disorders. Many of these disorders are prevented or improved by consuming polyphenol in the meal. As a result, natural compounds with the ability to modify the autophagy mechanism are seen as a potential therapeutic option. The creation of the double membrane (phagophore), which would be known as nucleation, is the first step in macro-autophagy. The phagophore approach indicates dysregulated polypeptides or defective organelles that come from the cell membrane, Golgi apparatus, endoplasmic reticulum, and mitochondria. With the conclusion of the autophagocyte, the phagophore's enlargement comes to an end. The auto-phagosome combines with the lysosomal vesicles to formulate an auto-lysosome that degrades the encapsulated substances, referred to as phagocytosis."}
{"id": "6340", "revid": "45877740", "url": "https://en.wikipedia.org/wiki?curid=6340", "title": "Canadian English", "text": "Canadian English (CanE, CE, en-CA) encompasses the varieties of English used in Canada. According to the 2016 census, English was the first language of 19.4 million Canadians or 58.1% of the total population; the remainder spoke French (20.8%) or other languages (21.1%). In the Canadian province of Quebec, only 7.5% of the population speak English as their mother tongue, while most of Quebec's residents are native speakers of Quebec French.\nThe most widespread variety of Canadian English is Standard Canadian English, spoken in all the western and central provinces of Canada (varying little from Central Canada to British Columbia), plus in many other provinces among urban middle- or upper-class speakers from natively English-speaking families. Standard Canadian English is distinct from Atlantic Canadian English, its most notable subset being Newfoundland English, and from Quebec English. Accent differences can also be heard between those who live in urban centres versus those living in rural settings.\nWhile Canadian English tends to be close to American English in most regards, classifiable together as North American English, Canadian English also possesses elements from British English as well as some uniquely Canadian characteristics. The precise influence of American English, British English, and other sources on Canadian English varieties has been the ongoing focus of systematic studies since the 1950s. Standard Canadian and General American English share identical or near-identical phonemic inventories, though their exact phonetic realizations may sometimes differ.\nCanadians and Americans themselves often have trouble differentiating their own two accents, particularly since Standard Canadian and Western United States English have been undergoing a similar vowel shift since the 1980s.\nHistory.\nCanadian English as an academic field of inquiry solidified around the time of World War II. While early linguistic approaches date back to the second half of the 19th century, the first textbook to consider Canadian English in one form or another was not published until 1940. Walter S. Avis was its most forceful spokesperson after WWII until the 1970s. His team of lexicographers managed to date the term \"Canadian English\" to a speech by a Scottish Presbyterian minister, the Reverend Archibald Constable Geikie, in an address to the Canadian Institute in 1857 (see DCHP-1 Online, s.v. \"Canadian English\", Avis \"et al.,\" 1967). Geikie, a Scottish-born Canadian, reflected the Anglocentric attitude that would be prevalent in Canada for the next hundred years when he referred to the language as \"a corrupt dialect\", in comparison with what he considered the proper English spoken by immigrants from Britain.\nOne of the earliest influences on Canadian English was the French language, which was brought to Canada by the French colonists in the 17th century. French words and expressions were adopted into Canadian English, especially in the areas of cuisine, politics, and social life. For example, words like beavertail, and toque are uniquely Canadian French terms that have become part of the Canadian English lexicon.\nAn important influence on Canadian English was British English, which was brought to Canada by British settlers in the 18th and 19th centuries. Canadian English borrowed many words and expressions from British English, including words like lorry, flat, and lift. However, Canadian English also developed its own unique vocabulary, including words like tuque, chesterfield, and double-double. In the early 20th century, western Canada was largely populated by farmers from Central and Eastern Europe who were not anglophones. At the time, most anglophones there were re-settlers from Ontario or Quebec who had British, Irish, or Loyalist ancestry, or some mixture of these. Throughout the 20th century, the prairies underwent anglicization and linguistic homogenization through education and exposure to Canadian and American media.\nAmerican English also had a significant impact on Canadian English's origins as well as again in the 20th century and since then as a result of increased cultural and economic ties between the two countries. American English terms like gasoline, truck, and apartment are commonly used in Canadian English.\nThe growth of Canadian media, including television, film, and literature, has also played a role in shaping Canadian English. Chambers (1998) notes that Canadian media has helped to create new words and expressions that reflect Canadian culture and values. Canadian institutions, such as the CBC and the Canadian Oxford Dictionary, have also played a role in promoting and defining Canadian English.\nIn addition to these influences, Canadian English has also been minorly shaped by Indigenous languages. Indigenous words such as moose, toboggan, and moccasin have become part of the Canadian English lexicon.\nCanadian English is the product of five waves of immigration and settlement over a period of more than two centuries. The first large wave of permanent English-speaking settlement in Canada, and linguistically the most important, was the influx of Loyalists fleeing the American Revolution, chiefly from the Mid-Atlantic States\u2014as such, Canadian English is believed by some scholars to have derived from northern American English. Canadian English has been developing features of its own since the early 19th century. The second wave from Britain and Ireland was encouraged to settle in Canada after the War of 1812 by the governors of Canada, who were worried about American dominance and influence among its citizens. Further waves of immigration from around the globe peaking in 1910, 1960, and at the present time had a lesser influence, but they did make Canada a multicultural country, ready to accept linguistic change from around the world during the current period of globalization.\nThe languages of Aboriginal peoples in Canada started to influence European languages used in Canada even before widespread settlement took place, and the French of Lower Canada provided vocabulary, with words such as \"tuque\" and \"portage\", to the English of Upper Canada.\nOverall, the history of Canadian English is a reflection of the country's diverse linguistic and cultural heritage. While Canadian English has borrowed many words and expressions from other languages, it has also developed its own unique vocabulary and pronunciation that reflects the country's distinct identity.\nHistorical linguistics.\nStudies on earlier forms of English in Canada are rare. Yet connections with other work to historical linguistics can be forged. An overview of diachronic work on Canadian English, or diachronically relevant work, is Dollinger (2012, updated to 2017). Until the 2000s, basically all commentators on the history of CanE have argued from the \"language-external\" history, i.e. social and political history. An exception has been in the area of lexis, where Avis \"et al.\" 1967 \"Dictionary of Canadianisms on Historical Principles\" offered real-time historical data through its quotations. Starting in the 2000s, historical linguists have started to study earlier Canadian English with historical linguistic data. DCHP-1 is now available in open access. Most notably, Dollinger (2008) pioneered the historical corpus linguistic approach for English in Canada with CONTE (Corpus of Early Ontario English, 1776\u20131849) and offers a developmental scenario for 18th- and 19th-century Ontario. In 2015, Reuter confirmed the scenario laid out in Dollinger (2008), using a 19th-century newspaper corpus from Ontario.\nCanadian dainty.\n Historically, Canadian English included a class-based sociolect known as \"Canadian dainty\". Treated as a marker of upper-class prestige in the 19th and early 20th centuries, Canadian dainty was marked by the use of some features of British English pronunciation, resulting in an accent similar, but not identical, to the Mid-Atlantic accent known in the United States. This accent faded in prominence following World War II, when it became stigmatized as pretentious, and is now rare. The governor general Vincent Massey, the writer and broadcaster Peter Stursberg, the actor Lorne Greene, and the actor Christopher Plummer are examples of men who were raised in Canada but spoke with a British-influenced accent.\nSpelling.\nCanadian spelling of the English language combines British and American conventions, the two dominant varieties, and adds some domestic idiosyncrasies. For many words, American and British spelling are both acceptable. Spelling in Canadian English co-varies with regional and social variables, somewhat more so, perhaps, than in the two dominant varieties of English, yet general trends have emerged since the 1970s.\nCanadian spelling conventions can be partly explained by Canada's trade history. For instance, Canada's automobile industry has been dominated by American firms from its inception, explaining why Canadians use the American spelling of \"tire\" (hence, \"Canadian Tire\") and American terminology for automobiles and their parts (for example, \"truck\" instead of \"lorry\", \"gasoline\" instead of \"petrol\", \"trunk\" instead of \"boot\").\nCanada's political history has also had an influence on Canadian spelling. Canada's first prime minister, John A. Macdonald, once advised the Governor General of Canada to issue an order-in-council directing that government papers be written in the British style.\nA contemporary reference for formal Canadian spelling is the spelling used for Hansard transcripts of the Parliament of Canada . Many Canadian editors, though, use the \"Canadian Oxford Dictionary\", often along with the chapter on spelling in \"Editing Canadian English\", and, where necessary (depending on context), one or more other references. \nThroughout part of the 20th century, some Canadian newspapers adopted American spellings, for example, \"color\" as opposed to the British-based \"colour\". Some of the most substantial historical spelling data can be found in Dollinger (2010) and Grue (2013). The use of such spellings was the long-standing practice of the Canadian Press perhaps since that news agency's inception, but visibly the norm prior to World War II. The practice of dropping the letter \"u\" in such words was also considered a labour-saving technique during the early days of printing in which movable type was set manually. Canadian newspapers also received much of their international content from American press agencies, so it was much easier for editorial staff to leave the spellings from the wire services as provided.\nIn the 1990s, Canadian newspapers began to adopt the British spelling variants such as \"-our\" endings, notably with \"The Globe and Mail\" changing its spelling policy in October 1990. Other Canadian newspapers adopted similar changes later that decade, such as the Southam newspaper chain's conversion in September 1998. The \"Toronto Star\" adopted this new spelling policy in September 1997 after that publication's ombudsman discounted the issue earlier in 1997. The \"Star\" had always avoided using recognized Canadian spelling, citing the \"Gage Canadian Dictionary\" in their defence. Controversy around this issue was frequent. When the \"Gage Dictionary\" finally adopted standard Canadian spelling, the \"Star\" followed suit. Some publishers, e.g. \"Maclean's\", continue to prefer American spellings.\nStandardization, codification and dictionaries.\nThe first series of dictionaries of Canadian English was published by Gage Ltd. under the chief-editorships of Charles J. Lovell (1907\u20131960) and Walter S. Avis (1919\u20131979) as of 1960 and the \"Big Six\" editors plus Faith Avis. The \"Beginner's Dictionary\" (1962), the \"Intermediate Dictionary\" (1964) and, finally, the \"Senior Dictionary\" (1967) were milestones in Canadian English lexicography. In November 1967 A Dictionary of Canadianisms on Historical Principles (DCHP) was published and completed the first edition of Gage's Dictionary of Canadian English Series. The DCHP documents the historical development of Canadian English words that can be classified as \"Canadianisms\". It therefore includes words such as mukluk, Canuck, and bluff, but does not list common core words such as desk, table or car. Many secondary schools in Canada use the graded dictionaries. The dictionaries have regularly been updated since: the \"Senior Dictionary,\" edited by Robert John Gregg, was renamed \"Gage Canadian Dictionary\". Its fifth edition was printed beginning in 1997. Gage was acquired by Thomson Nelson around 2003. The latest editions were published in 2009 by HarperCollins. On 17 March 2017 a second edition of DCHP, the online Dictionary of Canadianisms on Historical Principles 2 (DCHP-2), was published. DCHP-2 incorporates the c. 10\u200a000 lexemes from DCHP-1 and adds c. 1\u200a300 novel meanings or 1\u200a002 lexemes to the documented lexicon of Canadian English.\nIn 1997, the \"ITP Nelson Dictionary of the Canadian English Language\" was another product, but has not been updated since.\nIn 1998, Oxford University Press produced a Canadian English dictionary, after five years of lexicographical research, entitled \"The Oxford Canadian Dictionary\". A second edition, retitled \"The Canadian Oxford Dictionary\", was published in 2004. Just as the older dictionaries it includes uniquely Canadian words and words borrowed from other languages, and surveyed spellings, such as whether \"colour\" or \"color\" was the more popular choice in common use. Paperback and concise versions (2005, 2006), with minor updates, are available.\nSince 2022, the Editors' Association of Canada has been leading the writing of a new \"Canadian English Dictionary\" within a national dictionary Consortium. The Consortium comprises the Editors' Association of Canada, the UBC Canadian English Lab, and Queen's University's Strategy Language Unit.\nPhonology and phonetics.\nIt is quite common for Canadian English speakers to have the cot-caught merger, the father-bother merger, the Low-Back-Merger Shift (with the vowel in words such as \"trap\" moving backwards), Canadian raising (words such as \"like\" and \"about\" pronounced with a higher first vowel in the diphthong) and no trap-bath split. Canadian raising is when the onsets of diphthongs and get raised to or before voiceless segments. There are areas in the eastern U.S. where some words are pronounced with Canadian raising.\nSome young Canadians may show Goose-fronting. U.S. southern dialects have long had goose-fronting, but this goose-fronting among young Canadians and Californians is more recent. Some young Californians also show signs of the Low-Back-Merger Shift. The cot-caught merger is perhaps not general in the U.S., but younger speakers seem more likely to have it.\nThe Canadian Oxford Dictionary lists words such as \"no\" and \"way\" as having a long monophthong vowel sound, whereas American dictionaries usually have these words ending in an upglide .\nIn terms of the major sound systems (phonologies) of English around the world, Canadian English aligns most closely to American English. Some dialectologists group Canadian and American English together under a common North American English sound system. The mainstream Canadian accent (\"Standard Canadian\") is often compared to the General American accent, a middle ground lacking in noticeable regional features.\nWestern Canada (British Columbia, Alberta, Saskatchewan, Manitoba) shows the largest dialect diversity. Northern Canada is, according to William Labov, a dialect region in formation where a homogeneous English dialect has not yet formed. Labov's research focused on urban areas, and did not survey the country, but they found similarities among the English spoken in Ottawa, Toronto, Calgary, Edmonton and Vancouver. Labov identifies an \"Inland Canada\" region that concentrates all of the defining features of the dialect centred on the Prairies (a region in Western Canada that mainly includes Alberta, Saskatchewan, and Manitoba and is known for its grasslands and plains), with more variable patterns including the metropolitan areas of Vancouver and Toronto. This dialect forms a dialect continuum with Western US English, sharply differentiated from Inland Northern US English of the central and eastern Great Lakes region where the Northern Cities Shift is sending front vowels in the opposite direction to the Low-Back-Merger Shift heard in Canada and California.\nStandard.\nStandard Canadian English is socially defined. Standard Canadian English is spoken by those who live in urban Canada, in a middle-class job (or one of their parents holds such employment), who are second generation or later (born and raised in Canada) and speak English as (one of their) dominant language(s) (Dollinger 2019a, adapted from Chambers 1998). It is the variety spoken, in Chambers' (1998: 252) definition, by Anglophone or multilingual residents, who are second generation or later (i.e. born in Canada) and who live in urban settings. Applying this definition, c. 36% of the Canadian population speak Standard Canadian English in the 2006 population, with 38% in the 2011 census.\nRegional variation.\nThe literature has for a long time conflated the notions of Standard Canadian English (StCE) and regional variation. While some regional dialects are close to Standard Canadian English, they are not identical to it. To the untrained ear, for instance, a BC middle-class speaker from a rural setting may seemingly be speaking Standard Canadian English, but, given Chambers' definition, such a person, because of the rural provenance, would not be included in the accepted definition (see the previous section). The \"Atlas of North American English\", while being the best source for US regional variation, is not a good source for Canadian regional variation, as its analysis is based on only 33 Canadian speakers. Boberg's (2005, 2008) studies offer the best data for the delimitation of dialect zones. The results for vocabulary and phonetics overlap to a great extent, which has allowed the proposal of dialect zones. Dollinger and Clarke distinguish between:\nIndigenous.\nThe words \"Aboriginal\" and \"Indigenous\" are capitalized when used in a Canadian context.\nFirst Nations and Inuit from Northern Canada speak a version of Canadian English influenced by the phonology of their first languages. Non-indigenous Canadians in these regions are relatively recent arrivals, and have not produced a dialect that is distinct from southern Canadian English.\nOverall, First Nations Canada English dialects rest between language loss and language revitalization. British Columbia has the greatest linguistic diversity, as it is home to about half of the Indigenous languages spoken in Canada. Most of the languages spoken in the province are endangered due to the small number of speakers. To some extent, the dialects reflect the historical contexts where English has been a major colonizing language. The dialects are also a result of the late stages of depidginization and decreolization, which resulted in linguistic markers of Indigenous identity and solidarity. These dialects are observed to have developed a lingua franca due to the contact between English and Indigenous populations, and eventually, the various dialects began to converge with standard English.\nCertain First Nations English have also shown to have phonological standard Canadian English, thus resulting in a more distinct dialect formation. Plains Cree, for instance, is a language that has less phonological contrasts compared to standard Canadian English. Plains Cree has no voicing contrast. The stops , , and are mostly voiceless and unaspirated, though they may vary in other phonetic environments from voiceless to voiced. Plains Cree also does not have the liquids or fricatives found in the standard form. Dene Suline, on the other hand, has more phonological contrasts, resulting in the use of features not seen in the standard form. The language has 39 phonemic consonants and a higher proportion of glottalized consonants.\nMaritimes.\nMany in the Maritime provinces\u00a0\u2013 Nova Scotia, New Brunswick and Prince Edward Island\u00a0\u2013 have an accent that sounds more like Scottish English and, in some places, Irish English than General American. Outside of major communities, dialects can vary markedly from community to community, as well as from province to province, reflecting ethnic origin as well as a past in which there were few roads and many communities, with some isolated villages. Into the 1980s, residents of villages in northern Nova Scotia could identify themselves by dialects and accents distinctive to their village. The dialects of Prince Edward Island are often considered the most distinct grouping.\nThe phonology of Maritimer English has some unique features:\nAs with many other distinct dialects, vowels are a marker of Halifax English as a distinctive variant of Canadian English. Typically, Canadian dialects have a merger of the low back vowels in palm, lot, thought and cloth. The merged vowel in question is usually /\u0251/ or sometimes the rounded variant /\u0252/. Meanwhile, in Halifax, the vowel is raised and rounded. For example, body; popped; and gone. In the homophones, caught-cot and stalk-stock, the rounding in the merged vowel is also much more pronounced here than in other Canadian varieties. The Canadian Shift is also not as evident in the traditional dialect. Instead, the front vowels are raised. For example, the vowel in had is raised to [h\u00e6ed]; and camera is raised to [k\u00e6mra].\nAlthough it has not been studied extensively, the speech of Cape Breton specifically seems to bear many similarities with the nearby island of Newfoundland, which is often why Westerners can have a hard time differentiating the two accents. For instance, they both use the fronting of the low back vowel. These similarities can be attributed to geographic proximity, the fact that about one-quarter of the Cape Breton population descends from Irish immigrants - many of whom arrived via Newfoundland - and the Scottish and Irish influences on both provinces. The speech of Cape Breton can almost be seen as a continuum between the two extremes of the Halifax variant and the Newfoundland variant. In addition, there is heavy influence of standard varieties of Canadian English on Cape Breton English, especially in the diphthongization of the goat and goose vowels and the frequent use of Canadian raising.\nNewfoundland.\nCompared to the commonly spoken English dominating neighbouring provinces, Newfoundland English is famously distinct in its dialects and accents. Newfoundland English differs in vowel pronunciation, morphology, syntax, and preservation of archaic adverbial-intensifiers. The dialect varies markedly from community to community, as well as from region to region. Its distinctiveness partly results from a European settlement history that dates back centuries, which explains Newfoundland's most notable linguistic regions: an Irish-settled area in the southeast (the southern Avalon Peninsula) and an English-settled area in the southwest.\nA well-known phonetic feature many Newfoundland speakers possess is the kit-dress merger. The mid lax /\u025b/ here is raised to the high lax stressed /\u026a/, particularly before oral stops and nasals, so consequently \"pen\" is pronounced more like \"pin\".\nAnother phonetic feature more unique to Newfoundland English is TH-stopping. Here, the voiceless dental fricative /\u03b8/ in words like \"myth\" and \"width\" are pronounced more like \"t\" or the voiced dental fricative /\u00f0/ in words like \"the\" and \"these\". TH-stopping is more common for /\u00f0/, especially in unstressed function words (e.g. that, those, their, etc.).\nOntario.\nCanadian raising is quite strong throughout the province of Ontario, except within the Ottawa Valley. The introduction of Canadian raising to Canada can be attributed to the Scottish and Irish immigrants who arrived in the 18th and 19th centuries. The origins of Canadian raising to Scotland and revealed that the Scottish dialects spoken by these immigrants had a probable impact on its development. This feature impacts the pronunciation of the sound in \"right\" and the sound in \"lout\". Canadian Raising indicates a scenario where the start of the diphthong is nearer to the destination of the glide before voiceless consonants than before voiced consonants. The Canadian Shift is also a common vowel shift found in Ontario. The retraction of was found to be more advanced for women in Ontario than for people from the Prairies or Atlantic Canada and men.\nIn the southern part of Southwestern Ontario (roughly in the line south from Sarnia to St. Catharines), despite the existence of many characteristics of West/Central Canadian English, many speakers, especially those under 30, speak a dialect influenced by the Inland Northern American English dialect (in part due to proximity to cities like Detroit and Buffalo, New York) though there are minor differences such as Canadian raising (e.g. \"ice\" vs \"my\").\nThe north and northwestern parts of Southwestern Ontario, the area consisting of the Counties of Huron, Bruce, Grey, and Perth, referred to as the \"Queen's Bush\" in the 19th century, did not experience communication with the dialects of the southern part of Southwestern Ontario and Central Ontario until the early 20th century. Thus, a strong accent similar to Central Ontarian is heard, yet many different phrasings exist. It is typical in the area to drop phonetic sounds to make shorter contractions, such as: \"prolly\" (probably), \"goin\"' (going), and \"Wuts goin' on tonight? D'ya wanna do sumthin'?\" It is particularly strong in the County of Bruce, so much that it is commonly referred to as being the Bruce Cownian (Bruce Countian) accent. Also, merge with to , with \"were\" sounding more like \"wear\".\nResidents of the Golden Horseshoe (including the Greater Toronto Area) are known to merge the second with the in \"Toronto\", pronouncing the name variously as or . This is not unique to Toronto; Atlanta is often pronounced \"Atlanna\" by residents. Sometimes is elided altogether, resulting in \"Do you want this one er'iss one?\" The word \"southern\" is often pronounced with . In the area north of the Regional Municipality of York and south of Parry Sound, notably among those who were born in the surrounding communities, the cutting down of syllables and consonants often heard, e.g. \"probably\" is reduced to \"prolly\" or \"probly\" when used as a response. In Greater Toronto, the diphthong tends to be fronted (as a result the word \"about\" is pronounced as ). The Greater Toronto Area is linguistically diverse, with 43 percent of its people having a mother tongue other than English. As a result Toronto English has distinctly more variability than Inland Canada.\nIn Eastern Ontario, Canadian raising is not as strong as it is in the rest of the province. In Prescott and Russell, parts of Stormont-Dundas-Glengarry and Eastern Ottawa, French accents are often mixed with English ones due to the high Franco-Ontarian population there. In Lanark County, Western Ottawa and Leeds-Grenville and the rest of Stormont-Dundas-Glengarry, the accent spoken is nearly identical to that spoken in Central Ontario and the Quinte area.\nA linguistic enclave has also formed in the Ottawa Valley, heavily influenced by original Scottish, Irish, and German settlers, and existing along the Ontario-Quebec boundary, which has its own distinct accent known as the Ottawa Valley twang (or brogue). Phonetically, the Ottawa Valley twang is characterized by the lack of Canadian raising as well as the cot\u2013caught merger, two common elements of mainstream Canadian English. This accent is quite rare in the region today.\nQuebec.\nEnglish is a minority language in Quebec (with French the majority), but has many speakers in Montreal, the Eastern Townships and in the Gatineau-Ottawa region. A person whose mother tongue is English and who still speaks English is called an \"Anglophone\", versus a \"Francophone\", or French speaker.\nMany people in Montreal distinguish between words like \"marry\" versus \"merry\" and \"parish\" versus \"perish\", which are homophones to most other speakers of Canadian English. Quebec Anglophones generally pronounce French street names in Montreal as French words. \"Pie IX\" Boulevard is pronounced as in French: not as \"pie nine\" but as (compare French /pi.n\u0153f/). On the other hand, Anglophones pronounce the final \"d\" as in \"Bernard\" and \"Bouchard\"; the word \"Montreal\" is pronounced as an English word and \"Rue Lambert-Closse\" is known as \"Clossy Street\" (vs French /kl\u0254s/). In the city of Montreal, especially in some of the western suburbs like C\u00f4te-St-Luc and Hampstead, there is a strong Jewish influence in the English spoken in those areas. A large wave of Jewish immigration from Eastern Europe and the former Soviet Union before and after World War II is also evident today. Their English has a strong Yiddish influence, and there are some similarities to English spoken in New York. Words used mainly in Quebec and especially in Montreal are: \"stage\" for \"apprenticeship\" or \"internship\", \"copybook\" for a notebook, \"d\u00e9panneur\" or \"dep\" for a convenience store, and \"guichet\" for an ABM/ATM. It is also common for Anglophones, particularly those of Greek or Italian descent, to use translated French words instead of common English equivalents such as \"open\" and \"close\" for \"on\" and \"off\" or \"Open the lights, please\" for \"Turn on the lights, please\".\nWest.\nWestern Canadian English describes the English spoken in the four most western provinces\u2014British Columbia, Alberta, Saskatchewan, and Manitoba. British Columbia, in particular is a sub-zone on the lexical level. Phonetically, Western Canadian English has much more raising and much less than further east, and Canadian raised is further back.\nBritish Columbia.\nBritish Columbia English shares dialect features with both Standard Canadian English and the American Pacific Northwest English. In Vancouver, speakers exhibit more vowel retraction of before nasals than people from Toronto, and this retraction may become a regional marker of West Coast English. raising (found in words such as beg, leg, and peg) and raising (found words such as bag, lag and rag), a prominent feature in Northwestern American speakers, is also found in Vancouver speakers, causing \"beg\" to sound like the first syllable of \"bagel\" and \"bag\" to be similar. In the past, the ANAE reported that Vancouverites' participation in the Canadian raising of was questionable, but nowadays they tend to raise both and . The \"o\" in such words as \"holy, goal, load, know,\" etc. is pronounced as a close-mid back rounded vowel, , but not as rounded as in the Prairies where there are strong Scandinavian, Slavic and German influences, which can lend to a more stereotypical \"Canadian\" accent.\nFinally, there is also the /t/ sound which according to Gregg (2016), \"with many [Vancouver] speakers [is] intrusive between /l/ or /n/ and /s/ in words like sense , Wilson /w\u026alts\u0259n/ [and] also /'\u0252ltso\u028a/ \".\nSaskatchewan.\nEnglish in Saskatchewan has its pool of phonetic features shared with other provinces used by certain demographics. For instance, it has the consonant variables /ntV/ and /VtV/, the latter being a common feature of North American English and is defined as the intervoicing of /t/ between vowels. Meanwhile, /ntV/ \"frequently occurs in words such as \"centre\" and \"twenty\" where /t/ follows the alveolar nasal /n/ and precedes an unstressed vowel\". According to Nylvek (1992), both variables of /t/ are generally more often used by younger male over older female speakers.\nGrammar.\nThere are a handful of syntactical practices unique to Canadian English. When writing, Canadians may start a sentence with \"As well\", in the sense of \"in addition\"; this construction is a Canadianism.\nNorth American English prefers \"have got\" to \"have\" to denote possession or obligation (as in \"I've got a car\" vs. \"I have a car\"); Canadian English differs from American English in tending to eschew plain \"got\" (\"I got a car\"), which is a common third option in informal US English.\nThe grammatical construction \"\"be done\" something\" means roughly \"\"have/has finished\" something\". For example, \"I am done my homework\" and \"The dog is done dinner\" are genuine sentences in this dialect, respectively meaning \"I have finished my homework\" and \"The dog has finished dinner\". Another example, \"Let's start after you're done all the coffee\", means \"Let's start after you've finished all the coffee\". This is not exactly the same as the standard construction \"\"to be done with\" something\", since \"She is done the computer\" can only mean \"She is done with the computer\" in one sense: \"She has finished (building) the computer\".\nDate and time notation.\nDate and time notation in Canadian English is a mixture of British and American practices. The date can be written in the form of either \"\" or \"1 July 2017\"; the latter is common in more formal writing and bilingual contexts. The Government of Canada only recommends writing all-numeric dates in the form of YYYY-MM-DD (e.g. 2017-07-01), following ISO 8601. Nonetheless, the traditional DD/MM/YY and MM/DD/YY systems remain in everyday use, which can be interpreted in multiple ways: 01/07/17 can mean either 1 July 2017 or 7 January 2017. Private members' bills have repeatedly attempted to clarify the situation. In business communication and filing systems the YYMMDD is used to assist in automatic ordering of electronic files.\nThe government also recommends use of the 24-hour clock, which is widely used in contexts such as transportation schedules, parking meters, and data transmission. Many speakers of English use the 12-hour clock in everyday speech, even when reading from a 24-hour display, similar to the use of the 24-hour clock in the United Kingdom.\nVocabulary.\nWhere Canadian English shares vocabulary with other English dialects, it tends to share most with American English, but also has many non-American terms distinctively shared instead with Britain. British and American terms also can coexist in Canadian English to various extents, sometimes with new nuances in meaning; a classic example is (British) often used interchangeably with (American), though, in Canadian speech, the latter can more narrowly mean a trip elsewhere and the former can mean general time off work. In addition, the vocabulary of Canadian English also features some words that are seldom (if ever) found elsewhere. A good resource for these and other words is \"A Dictionary of Canadianisms on Historical Principles\", which is currently being revised at the University of British Columbia in Vancouver, British Columbia. The Canadian public appears to take interest in unique \"Canadianisms\": words that are distinctively characteristic of Canadian English\u2014though perhaps not exclusive to Canada; there is some disagreement about the extent to which \"Canadianism\" means a term actually unique to Canada, with such an understanding possibly overstated by the popular media. As a member of the Commonwealth of Nations, Canada shares many items of institutional terminology and professional designations with the countries of the former British Empire\u2014for example, , for a police officer of the lowest rank, and .\nRegional variation.\nWhile Canadian English has vocabulary that distinguishes it from other varieties of English across the world, there is significant regional variation in its lexis within Canada as well. A balanced cross-continental sample of 1800 Canadians and 360 Americans the Canada and the USA is the result of Boberg's North American Regional Vocabulary Survey (NARVS), a questionnaire employed by Boberg from 1999-2007 that sought out lexical items that vary regionally within Canada. Six regions were identified in the NARVS data collection: The West, which includes British Columbia and the Prairies; Ontario; Quebec, which represents data from Montreal mostly; New Brunswick and Nova Scotia; Prince Edward Island; and Newfoundland. Many regional differences in the lexis are item-specific. For example, one of these items has to do with the nationally enjoyed meal of pizza, and more specifically, the term used to refer to a pizza that features all available toppings. While Atlantic Canada refers to this order as \u2018the works,\u2019 the majority term used from eastern Ontario to the West Coast is deluxe, and terms such as 'all-dressed' and 'everything-on-it' are used in Quebec and Toronto, respectively. Other examples include the regionally varied usage of running shoes/runners/sneakers to describe athletic shoes, and notebook/scribbler/cahier to describe any type of plain note-pad. Despite the regional variation of vocabulary items within Canada, the lexis of Canadian English still maintains greater commonality between its own regions than it does with American English or British English.\nQuebec.\nQuebec recognizes French as its primary language. As a result, English has no official status in Quebec and is not used often in the public sphere. Although, in more metropolitan areas such as Montreal or Quebec City, it is not uncommon to see English media in public, such as in advertisements and store-fronts. Also, the provincial government must officially be referred to as the \"Gouvernement du Qu\u00e9bec\", regardless of the language being used by the speaker. While the lexical catalog of Quebec English contains items influenced or borrowed by French, the influence of the dominant French language on Quebec English is marginal. The francophone dominance in Quebec makes the province a linguistic anomaly within Canada, where English maintains a negligible role in government and public domains. The French influence on Quebec English operates through five distinct processes, as identified by Charles Boberg: elective direct lexical transfer of non-English words (e.g., garderie for daycare), imposed direct lexical transfer of non-English words, for example, SAQ for \"Soci\u00e9t\u00e9 des alcools du Qu\u00e9bec\", loan translation/calques such as 'all-dressed' for the French equivalent 'toute garnie'. Semantic shifts of existing English words, like 'magasin' for 'store', in addition to syntactic influences; e.g, \"we're living here three years\" instead of the English \"we've been living here for three years\". Although Quebec English differs from other Canadian regional lexes due to its special contact with French, it still shares some similarities with the lexis of other Canadian regions. For instance, the use of lexical items such as all-dressed has been successfully transferred to most other Canadian regional lexes.\nOntario.\nSouthern Ontario was initially settled by white Protestants, with the late 19th century witnessing the migration of white Protestant settlers from Ontario to western Canada following the suppression of the M\u00e9tis opposition. This migration facilitated the transplantation of the Ontario accent and the emergence of a homogeneous Canadian English dialect. Distinctive to Ontario are Canadianisms such as concession roads, which refer to roads that transect a township, dew-worm, which refers to an earthworm, and fire-reel, which refers to a fire truck. Walter S. Avis identified several linguistic features characteristic of Ontarians, including their preference for the word vacation, rather than holiday\u2014which is considered more British English\u2014and sack over paper bag. While there may be numerous such lexical differences in the speech of provincial and national borderers, Avis asserts that these are relatively minor compared to the linguistic features held in common. Furthermore, Avis suggests that the difference between American English and Ontario English is relatively small near the border due to their close proximity. The historical settlement patterns of southern Ontario, coupled with linguistic research, indicate the existence of distinctively Ontarian lexical items. However, Ontario maintains greater similarities with other Canadian regions than it does with the neighbouring American English and its regional variations.\nNorthern Ontario English has several distinct qualities stemming from its large Franco-Ontarian population. As a result several French and English words are used interchangeably. A number of phrases and expressions may also be found in Northern Ontario that are not present in the rest of the province, such as the use of \"camp\" for a summer home where Southern Ontario speakers would idiomatically use cottage.\nIn the mid to late 90s, certain words from Jamaican Patois, Arabic and Somali were incorporated into the local variety of English by Toronto youth, especially in immigrant communities, thus giving rise to Toronto slang. These examples included words such as \"mandem\", \"styll\", \"wallahi\", \"wasteman\", and \"yute\".\nPrairies (Manitoba, Saskatchewan and Alberta).\nThe Prairies, consisting of Manitoba, Saskatchewan, and Alberta, have their own lexical features. The linguistic legacy from the settlement patterns in these regions, along with the Indigenous communities, specifically the large M\u00e9tis population in Saskatchewan and Manitoba also carry certain linguistic traits inherited from the French, Indigenous, and Celtic forebears. The linguistic features brought by Ukrainian, German, and Mennonite populations in the Saskatchewan Valley of Saskatchewan and Red River Valley of Manitoba have also influenced the lexis of the Prairies. Some terms are derived from these groups and some are formed within the region by locals throughout time. An example of the former is the high-profile variable bunnyhug, a term for a hooded sweatshirt in Saskatchewan. As discussed in The Dictionary of Canadianisms on Historical Principles, bunnyhug is purposely and commonly used by young Saskatchewan speakers to indicate a sense of provincial identity, and is referred to as a Saskatchewanism. It should be further noted that it is assumed based on circumstantial evidence that teenagers played a crucial and special role in the spread and adoption of the term bunnyhug for hooded sweatshirts. Across Saskatchewan, Alberta, and Manitoba there are other terms consistent in or throughout the 3 provinces. Biffed is a term for falling, such as \"John biffed it over there\". Pickerel is Manitoba's official fish, also known as Walleye. Play structure is used to describe a playground for children consisting of monkey bars, slides, etc.\nAtlantic Canada (New Brunswick &amp; Nova Scotia, PEI, Newfoundland).\nCanada's Atlantic provinces were the first part of North America to be explored by Europeans. The Atlantic provinces, historically and collectively called the Maritimes, consist of New Brunswick, Nova Scotia, Prince Edward Island. Newfoundland and Labrador, which is not part of the Maritimes, is also part of Atlantic Canada. The historical immigrants from Europe have shaped cultures and lexical catalogs across the regions of Atlantic Canada that reflect British, Scottish, Gaelic, and French customs. The vernacular variations of English spoken in the Atlantic region of Canada. Newfoundland and Labrador English (NLE) possesses unique vocabulary compared to standard Canadian English. The Dictionary of Newfoundland English covers the vocabulary common to Newfoundlanders, such as Newfoundland \"screech rum\", a Newfoundland-specific brand of rum; mummering, referring to a Christmas tradition; and gut-foundered, meaning starving or fastened. Nova Scotia also is home to its own vocabulary. The term \"Sobeys bag\", used to refer to a plastic grocery bag, originates from the Nova Scotian grocery store chain Sobeys. Similarly, Prince Edward Island has its own vocabulary and dictionary. For example, angishore refers to a fisherman who is too lazy to fish and likely is a lexical item originating from Irish Gaelic settlers in Newfoundland. Sarah Sawler, a writer from Halifax, highlights terms that are common to Maritimes, such as dooryard for front yard, owly for when someone is angry or irritable, and biff for throw.\nEducation.\nThe term \"college\", which refers to post-secondary education in general in the US, refers in Canada to either a post-secondary technical or vocational institution, or to one of the colleges that exist as federated schools within some Canadian universities. Most often, a \"college\" is a community college, not a university. It may also refer to a CEGEP in Quebec. In Canada, might denote someone obtaining a diploma in business management, an equivalent of this would be an associate degree in the United States. In contrast, is the term for someone earning a bachelor's degree, typically at a post-secondary university institution. Hence, the term in Canada does not have the same meaning as , unless the speaker or context clarifies the specific level of post-secondary education that is meant.\nWithin the public school system the chief administrator of a school is generally \"the principal\", as in the United States, but the term is not used preceding their name, i.e., \"Principal Smith\". The assistant to the principal is not titled as \"assistant principal\", but rather as \"vice-principal\", although the former is not unknown. This usage is identical to that in Northern Ireland.\nCanadian universities publish \"calendars\" or \"schedules\", not \"catalogs\" as in the US. Canadian students \"write\" or \"take\" exams (in the US, students generally \"take\" exams while teachers \"write\" them); they rarely \"sit\" them (standard British usage). Those who supervise students during an exam are sometimes called \"invigilators\" as in Britain, or sometimes \"proctors\" as in the US; usage may depend on the region or even the individual institution.\nSuccessive years of school are usually referred to as \"grade one\", \"grade two\", and so on. In Quebec, Francophone speakers will often say \"primary one\", \"primary two\" as a direct translation from the French, and so on; while Anglophones will say \"grade one\", \"grade two\". These terms are comparable with the American \"first grade, second grade\" (which is used in Canada, yet is rare), English/Welsh \"Year 1, Year 2\", Scottish/Northern Irish \"Primary 1, Primary 2\" or \"P1, P2\", and Southern Irish \"First Class, Second Class\" and so on. The year of school before grade 1 is usually called \"Kindergarten\", with the exception of Nova Scotia, where it is called \"grade primary\". In addition, children younger than the public school start age may attend 'pre-primary', although this is a newer addition to the Nova Scotian public-school system, and is not used frequently elsewhere.\nIn parts of the US, the four years of high school are termed the freshman, sophomore, junior, and senior years (terms also used for college years); in Canada, the specific levels are used instead, such as \"grade nine\" in lieu of freshman. As for higher education, only the term \"freshman\" (often reduced to \"frosh\") has some currency in Canada. Moreover, some Canadian public-school systems have adolescents start high-school in 'Grade 10' or, the sophomore year, although, this can depend on the province and even vary within a school-district. The American usages \"sophomore\", \"junior\" and \"senior\" are not used in Canadian university terminology, or in speech. The specific high-school grades and university years are therefore stated and individualized; for example, 'Sarah is starting Grade 10 this year', which Americans would state as 'Sarah is going to be a sophomore this year'. Similarly in the post-secondary education context, 'Francois is in second year of university' rather than the Americanism 'Francois is a sophomore in university'.\nCanadian students use the term \"marks\" (more common in England) or \"grades\" (more common in the US) to refer to their results. Usage is mixed, although \"marks\" more commonly refer to a single score whereas \"grades\" often refers to the cumulative score in that class.\nUnits of measurement.\nUnlike in the United States, use of metric units within a majority of industries is standard in Canada, as a result of the partial national adoption of the metric system during the mid-to-late 1970s that was eventually stalled; this has spawned some colloquial usages such as \"klick\" for kilometre.\nNonetheless, US units are still used in many situations. Imperial volumes are also used, albeit rarely\u2014although many Canadians and Americans mistakenly conflate the measurement systems despite their slight differences from each other (e.g. US, Canadian, and metric cups are 237ml, 227ml, and 250mL respectively).\nFor example, most English Canadians state their weight and height in pounds and feet/inches, respectively. This is also the case for many Quebec Francophones. Distances while playing golf are always marked and discussed in yards, though official scorecards may also show metres. Temperatures for cooking or pools are often given in Fahrenheit, while the weather is given in Celsius. Directions in the Prairie provinces are sometimes given using miles, because the country roads generally follow the mile-based grid of the Dominion Land Survey. Motor vehicle speed limits are measured in kilometres per hour.\nCanadians measure floor areas, both residential and commercial, in square feet or square metres. Land area is in square feet, square metres, acres or hectares. Fuel efficiency is more often discussed in the metric L/100\u00a0km than miles per US gallon. The Letter paper size of 8.5\u00a0inches \u00d7 11\u00a0inches is used instead of the international and metric equivalent A4 size of 210\u00a0mm \u00d7 297\u00a0mm. Beer cans are 355mL (12 US oz), while beer bottles are typically 341mL (12 Imperial oz), and draft beer is sold in various units; US or Imperial oz, US or Imperial pint, or occasionally mL.\nBuilding materials are used in soft conversions of imperial sizes, but often purchased in relation to the imperial sizes. For example, 8-inch concrete masonry units can be referred to as an 8-inch CMU or 190 CMU. The actual material used in the US and Canada is the same.\nTransport.\n\"Expressway\" may also refer to a limited-access road that has control of access but has at-grade junctions, railway crossings (for example, the Harbour Expressway in Thunder Bay.) Sometimes the term \"Parkway\" is also used (for example, the Hanlon Parkway in Guelph). In Saskatchewan, the term 'grid road' is used to refer to minor highways or rural roads, usually gravel, referring to the 'grid' upon which they were originally designed. In Quebec, freeways and expressways are called autoroutes.\nIn Alberta, the generic \"Trail\" is often used to describe a freeway, expressway or major urban street (for example, Deerfoot Trail, Macleod Trail or Crowchild Trail in Calgary, Yellowhead Trail, Victoria Trail or Mark Messier/St.Albert Trail in Edmonton). The British term \"motorway\" is not used. The American terms \"turnpike\" and \"tollway\" for a toll road are not common. The term \"throughway\" or \"thruway\" was used for first tolled limited-access highways (for example, the Deas Island Throughway, now Highway 99, from Vancouver, BC, to Blaine, Washington, USA or the Saint John Throughway (Highway 1) in Saint John, NB), but this term is not common anymore. In everyday speech, when a particular roadway is not being specified, the term \"highway\" is generally or exclusively used.\nLaw.\nLawyers in all parts of Canada, except Quebec, which has its own civil law system, are called \"barristers and solicitors\" because any lawyer licensed in any of the common law provinces and territories must pass bar exams for, and is permitted to engage in, both types of legal practice in contrast to other common-law jurisdictions such as England, Wales and Ireland where the two are traditionally separated (i.e., Canada has a fused legal profession). The words \"lawyer\" and \"counsel\" (not \"counsellor\") predominate in everyday contexts; the word \"attorney\" refers to any personal representative. Canadian lawyers generally do not refer to themselves as \"attorneys\", a term that is common in the United States.\nThe equivalent of an American \"district attorney\", meaning the barrister representing the state in criminal proceedings, is called a \"crown attorney\" (in Ontario), \"crown counsel\" (in British Columbia), \"crown prosecutor\" or \"the crown\", on account of Canada's status as a constitutional monarchy in which the Crown is the locus of state power.\nThe words \"advocate\" and \"notary\"\u00a0\u2013 two distinct professions in Quebec civil law\u00a0\u2013 are used to refer to that province's approximate equivalents of barrister and solicitor, respectively. It is not uncommon for English-speaking advocates in Quebec to refer to themselves in English as \"barrister(s) and solicitor(s)\", as most advocates chiefly perform what would traditionally be known as \"solicitor's work\", while only a minority of advocates actually appear in court. In Canada's common law provinces and territories, the word \"notary\" means strictly a notary public.\nWithin the Canadian legal community itself, the word \"solicitor\" is often used to refer to any Canadian lawyer in general (much like the way the word \"attorney\" is used in the United States to refer to any American lawyer in general). Despite the conceptual distinction between \"barrister\" and \"solicitor\", Canadian court documents would contain a phrase such as \"\"John Smith, \"solicitor\" for the Plaintiff\"\" even though \"John Smith\" may well himself be the barrister who argues the case in court. In a letter introducing him/herself to an opposing lawyer, a Canadian lawyer normally writes something like \"\"I am the \"solicitor\" for Mr. Tom Jones.\"\nThe word \"litigator\" is also used by lawyers to refer to a fellow lawyer who specializes in lawsuits even though the more traditional word \"barrister\" is still employed to denote the same specialization.\nJudges of Canada's superior courts, which exist at the provincial and territorial levels, are traditionally addressed as \"My Lord\" or \"My Lady\". This varies by jurisdiction, and some superior court judges prefer the titles \"Mister Justice\" or \"Madam Justice\" to \"Lordship\".\nMasters are addressed as \"Mr. Master\" or simply \"Sir.\" In British Columbia, masters are addressed as \"Your Honour.\"\nJudges of provincial or inferior courts are traditionally referred to in person as \"Your Honour\". Judges of the Supreme Court of Canada and of the federal-level courts prefer the use of \"Mister/Madam (Chief) Justice\". Justices of The Peace are addressed as \"Your Worship\". \"Your Honour\" is also the correct form of address for a Lieutenant Governor.\nA serious crime is called an indictable offence, while a less-serious crime is called a summary conviction offence. The older words felony and misdemeanour, which are still used in the United States, are not used in Canada's current \"Criminal Code\" (R.S.C. 1985, c. C-46) or by today's Canadian legal system. As noted throughout the \"Criminal Code\", a person accused of a crime is called \"the accused\" and not \"the defendant\", a term used instead in civil lawsuits.\nIn Canada, \"visible minority\" refers to a non-aboriginal person or group visibly not one of the majority race in a given population. The term comes from the \"Canadian Employment Equity Act\", which defines such people as \"persons, other than Aboriginal people, who are non-Caucasian in race or non-white in colour.\" The term is used as a demographic category by Statistics Canada. The qualifier \"visible\" is used to distinguish such minorities from the \"invisible\" minorities determined by language (English vs. French) and certain distinctions in religion (Catholics vs. Protestants).\nA county in British Columbia means only a regional jurisdiction of the courts and justice system and is not otherwise connected to governance as with counties in other provinces and in the United States. The rough equivalent to \"county\" as used elsewhere is a \"Regional District\".\nPlaces.\nDistinctive Canadianisms are:\nDaily life.\nTerms common in Canada, Britain and Ireland but less frequent or nonexistent in the United States are:\nThe following are more or less distinctively Canadian:\nApparel.\nThe following are common in Canada, but not in the United States or the United Kingdom.\nInformal speech.\nOne of the most distinctive Canadian phrases is the spoken interrogation or tag \"eh\". The only usage of \"eh\" exclusive to Canada, according to the \"Canadian Oxford Dictionary\", is for \"ascertaining the comprehension, continued interest, agreement, etc., of the person or persons addressed\" as in, \"It's four kilometres away, eh, so I have to go by bike.\" In that case, \"eh?\" is used to confirm the attention of the listener and to invite a supportive noise such as \"mm\" or \"oh\" or \"okay\". This usage is also common in Queensland, Australia and New Zealand. Other uses of \"eh\"\u00a0\u2013 for instance, in place of \"huh?\" or \"what?\" meaning \"please repeat or say again\"\u00a0\u2013 are also found in parts of the British Isles and Australia. It is common in Northern/Central Ontario, the Maritimes and the Prairie provinces. The word \"eh\" is used quite frequently in the North Central dialect, so a Canadian accent is often perceived in people from North Dakota, Michigan, Minnesota, and Wisconsin.\nA \"rubber\" in the US and Canada is slang for a condom. In Canada, it sometimes means an eraser (as in the United Kingdom and Ireland).\nThe word \"bum\" can refer either to the buttocks (as in Britain), or to a homeless person (as in the US). The \"buttocks\" sense does not have the indecent character it retains in British use, as it and \"butt\" are commonly used as a polite or childish euphemism for ruder words such as \"arse\" (commonly used in Atlantic Canada and among older people in Ontario and to the west) or \"ass\", or \"mitiss\" (used in the Prairie Provinces, especially in northern and central Saskatchewan; probably originally a Cree loanword). Older Canadians may see \"bum\" as more polite than \"butt\", which before the 1980s was often considered rude.\nSimilarly the word \"pissed\" can refer either to being drunk (as in Britain), or being angry (as in the US), though anger is more often said as \"pissed off\", while \"piss drunk\" or \"pissed up\" is said to describe inebriation (though \"piss drunk\" is sometimes also used in the US, especially in the northern states).\nThe term \"Canuck\" simply means \"Canadian\" in its demonymic form, and, as a term used even by Canadians themselves, it is not considered derogatory. (In the 19th century and early 20th century it tended to refer to French-Canadians.) The only Canadian-built version of the popular World War I-era American Curtiss JN-4 \"Jenny\" training biplane aircraft, the JN-4C, 1,260 of which were built, got the \"Canuck\" nickname; so did another aircraft, the Fleet Model 80, built from the mid-1940s until the late 1950s. The nickname Janey Canuck was used by Anglophone women's rights writer Emily Murphy in the 1920s and the \"Johnny Canuck\" comic book character of the 1940s. Throughout the 1970s, Canada's winning World Cup men's downhill ski team was called the \"Crazy Canucks\" for their fearlessness on the slopes. It is also the name of the Vancouver Canucks, the National Hockey League team of Vancouver, British Columbia.\nThe term \"hoser\", popularized by Bob &amp; Doug McKenzie, typically refers to an uncouth, beer-swilling male and is a euphemism for \"loser\" coming from the earlier days of hockey played on an outdoor rink and the losing team would have to hose down the ice after the game so it froze smooth.\nA \"Newf\" or \"Newfie\" is someone from Newfoundland and Labrador; sometimes considered derogatory. In Newfoundland, the term \"Mainlander\" refers to any Canadian (sometimes American, occasionally Labradorian) not from the island of Newfoundland. \"Mainlander\" is also occasionally used derogatorily.\nIn the Maritimes, a \"Caper\" or \"Cape Bretoner\" is someone from Cape Breton Island, a \"Bluenoser\" is someone with a thick, usually southern Nova Scotia accent or as a general term for a Nova Scotian (including Cape Bretoners), while an \"Islander\" is someone from Prince Edward Island (the same term is used in British Columbia for people from Vancouver Island, or the numerous islands along it). A \"Haligonian\" refers to someone from the city of Halifax.\nCape Bretoners and Newfies (from Newfoundland and Labrador) often have similar slang. \"Barmp\" is often used as the sound a car horn makes, example: \"He cut me off so I barmped the horn at him\". When saying \"B'y\", while sounds like the traditional farewell, it is a syncopated shortening of the word \"boy\", referring to a person, example: \"How's it goin, b'y?\". Another slang that is commonly used is \"doohickey\" which means an object, example: \"Pass me that doohickey over there\". When an individual uses the word \"biffed\", they mean that they threw something. Example: \"I got frustrated so I biffed it across the room\".\nSurvey and research methodology.\nIn language studies, there are three basic types of data collection: introspection, elicitation, and observation. Introspection relies on the idea that native speakers are the best judges of sentence structure and can provide valuable data, but it can be limiting because it only requires one native speaker. Elicitation requires more effort, but is a widespread technique used to gather linguistic structures by asking informants how they say certain things in their language. Observation is considered the \"gold standard\" by many linguists because it involves collecting utterances after the fact and systematically analyzing them. This can be done through corpora, which are collections of spoken or written text, but most corpus material today consists of written texts since they are more easily accessible. Variationist sociolinguistics aim to elicit data that is as natural and informal as possible, using techniques such as sociolinguistic interviews to gather different speech styles.\nThe use of written questionnaires (WQs) in dialectology were once popular for surveying language use, but fell out of favor before being re-examined in recent years. While they were once considered less effective than other survey methods, scholars have started to recognize their potential in social dialectology and variation studies. In the early 1950s, McDavid noted the value of using a lexical WQ for the Linguistic Atlas of Scotland, but later, Chambers and Trudgill stated that WQs were no longer the primary method of data-gathering. However, within the past 15 years, WQs have experienced renewed interest in social dialectology and variation studies. WQs can provide linguistic information about behavior and can be used for self-reporting or community reporting.\nScholars have used five types of questionnaires in sociolinguistics. Dollinger suggests a three-tiered WQ question typology. The first tier covers questions about regional language variation and social language variation. The second tier covers language perception and attitudes, while the third tier deals with acceptability judgments of grammaticality. The questions can be classified by subject area, type of reporting, and the type of information sought. This classification can help scholars better utilize WQs and understand their potential.\nWritten surveys are commonly used in dialectology as regional differences are less socially sensitive. However, they can still be used in sociolinguistics if handled properly. A survey's advantage is its quantitative approach since it is capable of collecting large amounts of data within a relatively short time. This would allow researchers to have a more robust statistical analysis and reliable or accurate conclusions about regional or social patterns. Despite its advantages, there are still disadvantages using surveys for a research study particularly in capturing natural speech patterns due to the observer's paradox. Through its unique format, surveys containing direct questions about language may not provide sufficient information on how often or in what social or linguistic contexts people use distinct language features. Therefore, by relying on systematic observations, local participants may adhere to perceived norms or expectations. While written surveys can provide valuable information about sociolinguistic variables in Canadian English, data gathered from surveys or questionnaires should not be perceived as equivalent to data gathered from the usage of actual speech. William Labov, a linguist, suggests that in order to solve this problem is to change the style of approach of surveys. Therefore, he suggests that researchers design sociolinguistic interviews that manipulate attention to speech. By comparing the speech among research participants when they are being directly questioned about language with their speech when talking about their personal experience, Labov could observe how the usage of language within different contexts or environments. This newly suggested approach allowed Labov to capture the \"vernacular\" which is the casual style of speech that people use within a day-to-day basis when they are not being observed.\nCanadian English dialectology examines Canadian English through the use of written surveys due to the vastness of the country and the difficulties of conducting face-to-face interviews on a nationwide level. The historical overview of written surveys in Canadian-English dialectology includes Avis's study of speech differences among the Ontario-United States borders through the use of questionnaires. Another example is the Survey of Canadian English directed by Scargill. A more recent example would be Nylvek's survey of Saskatchewan English and Chambers' trans-Canada dialect questionnaires.\nAttitudes.\nAn attitude study in the late 1970s revealed a positive attitude toward Canadian linguistic features. Features include front vowel merger before/r/, low-back vowel merger, Canadian Raising, and Canadian lexical items. Still, the sample group in British Columbia showed a preference for UK and US English.\nThis attitude sees a change years later. A survey about attitudes towards CE was conducted with a diverse sample group in Vancouver, BC, in 2009. Among 429 Vancouverites, 81.1% believe there is a Canadian way of speaking English, 72.9% can tell CanE speakers from American English speakers, 69.1% consider CanE a part of their Canadian identity, and 74.1% think CanE should be taught in schools. Due to the unavailability of free and easy-to-access CanE dictionaries, many Canadian opt for other non-Canadian English dictionaries today. Historically, American, British, and Irish texts are used in Canadian schools for the most part; even though Canadian reference work was written and became available in the 1960s, they were never preferred as teaching material.\nA preference change can be seen at the end of higher education in Canada. At the University of Toronto's Graduate English department, \"Canadian English\" and a \"consistent spelling\" are officially \"the standard for all Ph.D. dissertations,\" with the \"Canadian Oxford English Dictionary\" as the official guideline. However, there is no mention of which grammar guide was to be followed because there was never a solid standard developed for spelling and grammar.\nIn 2011, just under 21.5\u00a0million Canadians, representing 65% of the population, spoke English most of the time at home, while 58% declared it their mother language. English is the major language everywhere in Canada except Quebec, and most Canadians (85%) can speak English. While English is not the preferred language in Quebec, 36.1% of the Qu\u00e9b\u00e9cois can speak English. Nationally, Francophones are five times more likely to speak English than Anglophones are to speak French \u2013 44% and 9% respectively. Only 3.2% of Canada's English-speaking population resides in Quebec\u2014mostly in Montreal.\nA study conducted in 2002 inquired Canadians from Ontario and Alberta about the \"pleasantness\" and \"correctness\" of different varieties of Canadian English based on province. Albertans and Ontarians all seem to rate their English and BC English in the top three. However, both hold a low opinion of Quebec English. Unlike the assumption that Toronto or Ontario English would be the most prestigious considering these regions are the most economically robust, BC had the best public opinion regarding pleasantness and correctness among the participants.\nJaan Lilles argues in an essay for \"English Today\" that there is no variety of \"Canadian English.\" According to Lilles, Canadian English is simply not a \"useful fiction\". He goes on to argue that too often supposedly unique features of Canadian speakers, such as certain lexical terms such as \"muskeg\" are artificially exaggerated to distinguish Canadian speech primarily from that found in the United States. Lilles was heavily critiqued in the next issue of \"English Today\" by lexicographer Fraser Sutherland and others. According to Stefan Dollinger, Lilles' paper \"is not a paper based on any data or other new information but more of a pamphlet \u2013 so much so that it should not have been published without a public critique\". He continues, \"The paper is insightful for different reasons: it is a powerful testimony of personal anecdote and opinion [...]. As an opinion piece, it offers a good debating case.\" As a linguistic account, however, it \"essentializes a prior state, before Canada was an independent political entity.\"\nFurther reading.\nDollinger, Stefan (2015). The Written Questionnaire in Social Dialectology: History, Theory, Practice. Amsterdam/Philadelphia: Benjamins. The book's examples are exclusive taken from Canadian English and represent one of the more extensive collections of variables for Canadian English."}
{"id": "6343", "revid": "47532688", "url": "https://en.wikipedia.org/wiki?curid=6343", "title": "Czech language", "text": "Czech ( ; ), historically also known as Bohemian ( ; ), is a West Slavic language of the Czech\u2013Slovak group, written in Latin script. Spoken by over 12 million people including second language speakers, it serves as the official language of the Czech Republic. Czech is closely related to Slovak, to the point of high mutual intelligibility, as well as to Polish to a lesser degree. Czech is a fusional language with a rich system of morphology and relatively flexible word order. Its vocabulary has been extensively influenced by Latin and German.\nThe Czech\u2013Slovak group developed within West Slavic in the high medieval period, and the standardization of Czech and Slovak within the Czech\u2013Slovak dialect continuum emerged in the early modern period. In the later 18th to mid-19th century, the modern written standard became codified in the context of the Czech National Revival. The most widely spoken non-standard variety, known as Common Czech, is based on the vernacular of Prague, but is now spoken as an interdialect throughout most of Bohemia. The Moravian dialects spoken in Moravia and Czech Silesia are considerably more varied than the dialects of Bohemia.\nCzech has a moderately-sized phoneme inventory, comprising ten monophthongs, three diphthongs and 25 consonants (divided into \"hard\", \"neutral\" and \"soft\" categories). Words may contain complicated consonant clusters or lack vowels altogether. Czech has a raised alveolar trill, which is known to occur as a phoneme in only a few other languages, represented by the grapheme \"\u0159\".\nClassification.\nCzech is a member of the West Slavic sub-branch of the Slavic branch of the Indo-European language family. This branch includes Polish, Kashubian, Upper and Lower Sorbian and Slovak. Slovak is the most closely related language to Czech, followed by Polish and Silesian.\nThe West Slavic languages are spoken in Central Europe. Czech is distinguished from other West Slavic languages by a more-restricted distinction between \"hard\" and \"soft\" consonants (see Phonology below).\nHistory.\nMedieval/Old Czech.\nThe term \"Old Czech\" is applied to the period predating the 16th century, with the earliest records of the high medieval period also classified as \"early Old Czech\", but the term \"Medieval Czech\" is also used. The function of the written language was initially performed by Old Slavonic written in Glagolitic, later by Latin written in Latin script. \nAround the 7th century, the Slavic expansion reached Central Europe, settling on the eastern fringes of the Frankish Empire. The West Slavic polity of Great Moravia formed by the 9th century. The Christianization of Bohemia took place during the 9th and 10th centuries. The diversification of the Czech-Slovak group within West Slavic began around that time, marked among other things by its use of the voiced velar fricative consonant (/\u0263/) and consistent stress on the first syllable.\nThe Bohemian (Czech) language is first recorded in writing in glosses and short notes during the 12th to 13th centuries. Literary works written in Czech appear in the late 13th and early 14th century and administrative documents first appear towards the late 14th century. The first complete Bible translation, the Leskovec-Dresden Bible, also dates to this period. Old Czech texts, including poetry and cookbooks, were also produced outside universities.\nLiterary activity becomes widespread in the early 15th century in the context of the Bohemian Reformation. Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners (particularly in religion) and made early efforts to model written Czech after the spoken language.\nEarly Modern Czech.\nThere was no standardization distinguishing between Czech and Slovak prior to the 15th century. In the 16th century, the division between Czech and Slovak becomes apparent, marking the confessional division between Lutheran Protestants in Slovakia using Czech orthography and Catholics, especially Slovak Jesuits, beginning to use a separate Slovak orthography based on Western Slovak dialects.\nThe publication of the Kralice Bible between 1579 and 1593 (the first complete Czech translation of the Bible from the original languages) became very important for standardization of the Czech language in the following centuries as it was used as a model for the standard language.\nIn 1615, the Bohemian \"diet\" tried to declare Czech to be the only official language of the kingdom. After the Bohemian Revolt (of predominantly Protestant aristocracy) which was defeated by the Habsburgs in 1620, the Protestant intellectuals had to leave the country. This emigration together with other consequences of the Thirty Years' War had a negative impact on the further use of the Czech language. In 1627, Czech and German became official languages of the Kingdom of Bohemia and in the 18th century German became dominant in Bohemia and Moravia, especially among the upper classes.\nModern Czech.\nModern standard Czech originates in standardization efforts of the 18th century. By then the language had developed a literary tradition, and since then it has changed little; journals from that period contain no substantial differences from modern standard Czech, and contemporary Czechs can understand them with little difficulty. At some point before the 18th century, the Czech language abandoned a distinction between phonemic /l/ and /\u028e/ which survives in Slovak.\nWith the beginning of the national revival of the mid-18th century, Czech historians began to emphasize their people's accomplishments from the 15th through 17th centuries, rebelling against the Counter-Reformation (the Habsburg re-catholization efforts which had denigrated Czech and other non-Latin languages). Czech philologists studied sixteenth-century texts and advocated the return of the language to high culture. This period is known as the Czech National Revival (or Renaissance).\nDuring the national revival, in 1809 linguist and historian Josef Dobrovsk\u00fd released a German-language grammar of Old Czech entitled \"Ausf\u00fchrliches Lehrgeb\u00e4ude der b\u00f6hmischen Sprache\" ('Comprehensive Doctrine of the Bohemian Language'). Dobrovsk\u00fd had intended his book to be descriptive, and did not think Czech had a realistic chance of returning as a major language. However, Josef Jungmann and other revivalists used Dobrovsk\u00fd's book to advocate for a Czech linguistic revival. Changes during this time included spelling reform (notably, \"\u00ed\" in place of the former \"j\" and \"j\" in place of \"g\"), the use of \"t\" (rather than \"ti\") to end infinitive verbs and the non-capitalization of nouns (which had been a late borrowing from German). These changes differentiated Czech from Slovak. Modern scholars disagree about whether the conservative revivalists were motivated by nationalism or considered contemporary spoken Czech unsuitable for formal, widespread use.\nAdherence to historical patterns was later relaxed and standard Czech adopted a number of features from Common Czech (a widespread informal interdialectal variety), such as leaving some proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the language.\nGeographic distribution.\nCzech is spoken by about 10 million residents of the Czech Republic. A Eurobarometer survey conducted from January to March 2012 found that the first language of 98 percent of Czech citizens was Czech, the third-highest proportion of a population in the European Union (behind Greece and Hungary).\nAs the official language of the Czech Republic (a member of the European Union since 2004), Czech is one of the EU's official languages and the 2012 Eurobarometer survey found that Czech was the foreign language most often used in Slovakia. Economist Jonathan van Parys collected data on language knowledge in Europe for the 2012 European Day of Languages. The five countries with the greatest use of Czech were the Czech Republic (98.77 percent), Slovakia (24.86 percent), Portugal (1.93 percent), Poland (0.98 percent) and Germany (0.47 percent).\nCzech speakers in Slovakia primarily live in cities. Since it is a recognized minority language in Slovakia, Slovak citizens who speak only Czech may communicate with the government in their language in the same way that Slovak speakers in the Czech Republic also do.\nUnited States.\nImmigration of Czechs from Europe to the United States occurred primarily from 1848 to 1914. Czech is a Less Commonly Taught Language in U.S. schools, and is taught at Czech heritage centers. Large communities of Czech Americans live in the states of Texas, Nebraska and Wisconsin. In the 2000 United States Census, Czech was reported as the most common language spoken at home (besides English) in Valley, Butler and Saunders Counties, Nebraska and Republic County, Kansas. With the exception of Spanish (the non-English language most commonly spoken at home nationwide), Czech was the most common home language in more than a dozen additional counties in Nebraska, Kansas, Texas, North Dakota and Minnesota. 70,500 Americans spoke Czech as their first language (49th place nationwide, after Turkish and before Swedish).\nPhonology.\nVowels.\nStandard Czech contains ten basic vowel phonemes, and three diphthongs. The vowels are , and their long counterparts . The diphthongs are ; the last two are found only in loanwords such as \"car\" and \"euro\".\nIn Czech orthography, the vowels are spelled as follows:\nThe letter indicates that the previous consonant is palatalized (e.g. ). After a labial it represents (e.g. ); but is pronounced /m\u0272\u025b/, cf. ().\nConsonants.\nThe consonant phonemes of Czech and their equivalent letters in Czech orthography are as follows:\nCzech consonants are categorized as \"hard\", \"neutral\", or \"soft\":\nHard consonants may not be followed by \"i\" or \"\u00ed\" in writing, or soft ones by \"y\" or \"\u00fd\" (except in loanwords such as \"kilogram\"). Neutral consonants may take either character. Hard consonants are sometimes known as \"strong\", and soft ones as \"weak\". This distinction is also relevant to the declension patterns of nouns, which vary according to whether the final consonant of the noun stem is hard or soft.\nVoiced consonants with unvoiced counterparts are unvoiced at the end of a word before a pause, and in consonant clusters voicing assimilation occurs, which matches voicing to the following consonant. The unvoiced counterpart of /\u0266/ is /x/.\nThe phoneme represented by the letter \"\u0159\" (capital \"\u0158\") is very rare among languages and often claimed to be unique to Czech, though it also occurs in some dialects of Kashubian, and formerly occurred in Polish. It represents the raised alveolar non-sonorant trill (IPA: ), a sound somewhere between Czech \"r\" and \"\u017e\" (example: ), and is present in \"Dvo\u0159\u00e1k\". In unvoiced environments, /r\u031d/ is realized as its voiceless allophone [r\u031d\u030a], a sound somewhere between Czech \"r\" and \"\u0161\".\nThe consonants can be syllabic, acting as syllable nuclei in place of a vowel. \"Str\u010d prst skrz krk\" (\"Stick [your] finger through [your] throat\") is a well-known Czech tongue twister using syllabic consonants but no vowels.\nStress.\nEach word has primary stress on its first syllable, except for enclitics (minor, monosyllabic, unstressed syllables). In all words of more than two syllables, every odd-numbered syllable receives secondary stress. Stress is unrelated to vowel length; both long and short vowels can be stressed or unstressed. Vowels are never reduced (e.g. to schwa sounds) when unstressed. When a noun is preceded by a monosyllabic preposition, the stress usually moves to the preposition, e.g. \"to Prague\".\nGrammar.\nCzech grammar, like that of other Slavic languages, is fusional; its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the easily separable affixes characteristic of agglutinative languages are limited. \nCzech inflects for case, gender and number in nouns and tense, aspect, mood, person and subject number and gender in verbs.\nParts of speech include adjectives, adverbs, numbers, interrogative words, prepositions, conjunctions and interjections. Adverbs are primarily formed from adjectives by taking the final \"\u00fd\" or \"\u00ed\" of the base form and replacing it with \"e\", \"\u011b\", \"y\", or \"o\". Negative statements are formed by adding the affix \"ne-\" to the main verb of a clause, with one exception: \"je\" (he, she or it is) becomes \"nen\u00ed\".\nSentence and clause structure.\nBecause Czech uses grammatical case to convey word function in a sentence (instead of relying on word order, as English does), its word order is flexible. As a pro-drop language, in Czech an intransitive sentence can consist of only a verb; information about its subject is encoded in the verb. Enclitics (primarily auxiliary verbs and pronouns) appear in the second syntactic slot of a sentence, after the first stressed unit. The first slot can contain a subject or object, a main form of a verb, an adverb, or a conjunction (except for the light conjunctions \"a\", \"and\", \"i\", \"and even\" or \"ale\", \"but\").\nCzech syntax has a subject\u2013verb\u2013object sentence structure. In practice, however, word order is flexible and used to distinguish topic and focus, with the topic or theme (known referents) preceding the focus or rheme (new information) in a sentence; Czech has therefore been described as a topic-prominent language. Although Czech has a periphrastic passive construction (like English), in colloquial style, word-order changes frequently replace the passive voice. For example, to change \"Peter killed Paul\" to \"Paul was killed by Peter\" the order of subject and object is inverted: \"Petr zabil Pavla\" (\"Peter killed Paul\") becomes \"Paul, Peter killed\" (\"Pavla zabil Petr\"). \"Pavla\" is in the accusative case, the grammatical object of the verb.\nA word at the end of a clause is typically emphasized, unless an upward intonation indicates that the sentence is a question:\nIn parts of Bohemia (including Prague), questions such as \"J\u00ed pes bagetu?\" without an interrogative word (such as \"co\", \"what\" or \"kdo\", \"who\") are intoned in a slow rise from low to high, quickly dropping to low on the last word or phrase.\nIn modern Czech syntax, adjectives precede nouns, with few exceptions. Relative clauses are introduced by relativizers such as the adjective \"kter\u00fd\", analogous to the English relative pronouns \"which\", \"that\" and \"who\"/\"whom\". As with other adjectives, it agrees with its associated noun in gender, number and case. Relative clauses follow the noun they modify. The following is a glossed example:\nDeclension.\nIn Czech, nouns and adjectives are declined into one of seven grammatical cases which indicate their function in a sentence, two numbers (singular and plural) and three genders (masculine, feminine and neuter). The masculine gender is further divided into animate and inanimate classes.\nCase.\nA nominative\u2013accusative language, Czech marks subject nouns of transitive and intransitive verbs in the nominative case, which is the form found in dictionaries, and direct objects of transitive verbs are declined in the accusative case. The vocative case is used to address people. The remaining cases (genitive, dative, locative and instrumental) indicate semantic relationships, such as noun adjuncts (genitive), indirect objects (dative), or agents in passive constructions (instrumental). Additionally prepositions and some verbs require their complements to be declined in a certain case. The locative case is only used after prepositions. An adjective's case agrees with that of the noun it modifies. When Czech children learn their language's declension patterns, the cases are referred to by number: \nSome prepositions require the nouns they modify to take a particular case. The cases assigned by each preposition are based on the physical (or metaphorical) direction, or location, conveyed by it. For example, \"od\" (from, away from) and \"z\" (out of, off) assign the genitive case. Other prepositions take one of several cases, with their meaning dependent on the case; \"na\" means \"on to\" or \"for\" with the accusative case, but \"on\" with the locative.\nThis is a glossed example of a sentence using several cases:\nGender.\nCzech distinguishes three genders\u2014masculine, feminine, and neuter\u2014and the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in \"-a\", \"-e\", or a consonant; neuter nouns in \"-o\", \"-e\", or \"-\u00ed\", and masculine nouns in a consonant. Adjectives, participles, most pronouns, and the numbers \"one\" and \"two\" are marked for gender and agree with the gender of the noun they modify or refer to. Past tense verbs are also marked for gender, agreeing with the gender of the subject, e.g. \"d\u011blal\" (he did, or made); \"d\u011blala\" (she did, or made) and \"d\u011blalo\" (it did, or made). Gender also plays a semantic role; most nouns that describe people and animals, including personal names, have separate masculine and feminine forms which are normally formed by adding a suffix to the stem, for example \"\u010cech\" (Czech man) has the feminine form \"\u010ce\u0161ka\" (Czech woman).\nNouns of different genders follow different declension patterns. Examples of declension patterns for noun phrases of various genders follow:\nNumber.\nNouns are also inflected for number, distinguishing between singular and plural. Typical of a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five require subject and direct object noun phrases to be declined in the genitive plural instead of the nominative or accusative, and when used as subjects these phrases take singular verbs. For example:\nNumbers decline for case, and the numbers one and two are also inflected for gender. Numbers one through five are shown below as examples. The number one has declension patterns identical to those of the demonstrative pronoun \"ten\".\nAlthough Czech's grammatical numbers are singular and plural, several residuals of dual forms remain, such as the words \"dva\" (\"two\") and \"oba\" (\"both\"), which decline the same way. Some nouns for paired body parts use a historical dual form to express plural in some cases: \"ruka\" (hand)\u2014\"ruce\" (nominative); \"noha\" (leg)\u2014\"nohama\" (instrumental), \"nohou\" (genitive/locative); \"oko\" (eye)\u2014\"o\u010di\", and \"ucho\" (ear)\u2014\"u\u0161i\". While two of these nouns are neuter in their singular forms, all plural forms are considered feminine; their gender is relevant to their associated adjectives and verbs. These forms are plural semantically, used for any non-singular count, as in \"mezi \u010dty\u0159ma o\u010dima\" (face to face, lit. \"among four eyes\"). The plural number paradigms of these nouns are a mixture of historical dual and plural forms. For example, \"nohy\" (legs; nominative/accusative) is a standard plural form of this type of noun.\nVerb conjugation.\nCzech verbs agree with their subjects in person (first, second or third), number (singular or plural), and in constructions involving participles, which includes the past tense, also in gender. They are conjugated for tense (past, present or future) and mood (indicative, imperative or conditional). For example, the conjugated verb \"mluv\u00edme\" (we speak) is in the present tense and first-person plural; it is distinguished from other conjugations of the infinitive \"mluvit\" by its ending, \"-\u00edme\". The infinitive form of Czech verbs ends in \"-t\" (archaically, \"-ti\" or \"-ci\"). It is the form found in dictionaries and the form that follows auxiliary verbs (for example, \"m\u016f\u017eu t\u011b sly\u0161et\"\u2014\"I can \"hear\" you\").\nAspect.\nTypical of Slavic languages, Czech marks its verbs for one of two grammatical aspects: perfective and imperfective. Most verbs are part of inflected aspect pairs\u2014for example, \"koupit\" (perfective) and \"kupovat\" (imperfective). Although the verbs' meaning is similar, in perfective verbs the action is completed and in imperfective verbs it is ongoing or repeated. This is distinct from past and present tense. Any verb of either aspect can be conjugated into either the past or present tense, but the future tense is only used with imperfective verbs. Aspect describes the state of the action at the time specified by the tense.\nThe verbs of most aspect pairs differ in one of two ways: by prefix or by suffix. In prefix pairs, the perfective verb has an added prefix\u2014for example, the imperfective \"ps\u00e1t\" (to write, to be writing) compared with the perfective \"napsat\" (to write down). The most common prefixes are \"na-\", \"o-\", \"po-\", \"s-\", \"u-\", \"vy-\", \"z-\" and \"za-\". In suffix pairs, a different infinitive ending is added to the perfective stem; for example, the perfective verbs \"koupit\" (to buy) and \"prodat\" (to sell) have the imperfective forms \"kupovat\" and \"prod\u00e1vat\". Imperfective verbs may undergo further morphology to make other imperfective verbs (iterative and frequentative forms), denoting repeated or regular action. The verb \"j\u00edt\" (to go) has the iterative form \"chodit\" (to go regularly) and the frequentative form \"chod\u00edvat\" (to go occasionally; to tend to go).\nMany verbs have only one aspect, and verbs describing continual states of being\u2014\"b\u00fdt\" (to be), \"cht\u00edt\" (to want), \"moct\" (to be able to), \"le\u017eet\" (to lie down, to be lying down)\u2014have no perfective form. Conversely, verbs describing immediate states of change\u2014for example, \"ot\u011bhotn\u011bt\" (to become pregnant) and \"nadchnout se\" (to become enthusiastic)\u2014have no imperfective aspect.\nTense.\nThe present tense in Czech is formed by adding an ending that agrees with the person and number of the subject at the end of the verb stem. As Czech is a null-subject language, the subject pronoun can be omitted unless it is needed for clarity. The past tense is formed using a participle which ends in \"-l\" and a further ending which agrees with the gender and number of the subject. For the first and second persons, the auxiliary verb \"b\u00fdt\" conjugated in the present tense is added.\nIn some contexts, the present tense of perfective verbs (which differs from the English present perfect) implies future action; in others, it connotes habitual action. The perfective present is used to refer to completion of actions in the future and is distinguished from the imperfective future tense, which refers to actions that will be ongoing in the future. The future tense is regularly formed using the future conjugation of \"b\u00fdt\" (as shown in the table on the left) and the infinitive of an imperfective verb, for example, \"budu j\u00edst\"\u2014\"I will eat\" or \"I will be eating\". Where \"budu\" has a noun or adjective complement it means \"I will be\", for example, \"budu \u0161\u0165astn\u00fd\" (I will be happy). Some verbs of movement form their future tense by adding the prefix \"po-\" to the present tense forms instead, e.g. \"jedu\" (\"I go\") &gt; \"pojedu\" (\"I will go\").\nMood.\nCzech verbs have three grammatical moods: indicative, imperative and conditional. The imperative mood is formed by adding specific endings for each of three person\u2013number categories: \"-\u00d8/-i/-ej\" for second-person singular, \"-te/-ete/-ejte\" for second-person plural and \"-me/-eme/-ejme\" for first-person plural. Imperatives are usually expressed using perfective verbs if positive and imperfective verbs if negative. The conditional mood is formed with a conditional auxiliary verb after the participle ending in -l which is used to form the past tense. This mood indicates hypothetical events and can also be used to express wishes.\nVerb classes.\nMost Czech verbs fall into one of five classes, which determine their conjugation patterns. The future tense of \"b\u00fdt\" would be classified as a Class I verb because of its endings. Examples of the present tense of each class and some common irregular verbs follow in the tables below:\nOrthography.\nCzech has one of the most phonemic orthographies of all European languages. Its alphabet contains 42 graphemes, most of which correspond to individual phonemes, and only contains only one digraph: \"ch\", which follows \"h\" in the alphabet. The characters \"q\", \"w\" and \"x\" appear only in foreign words. The h\u00e1\u010dek (\u02c7) is used with certain letters to form new characters: \"\u0161\", \"\u017e\", and \"\u010d\", as well as \"\u0148\", \"\u011b\", \"\u0159\", \"\u0165\", and \"\u010f\" (the latter five uncommon outside Czech). The last two letters are sometimes written with a comma above (\u02bc, an abbreviated h\u00e1\u010dek) because of their height. Czech orthography has influenced the orthographies of other Balto-Slavic languages and some of its characters have been adopted for transliteration of Cyrillic.\nCzech orthography reflects vowel length; long vowels are indicated by an acute accent or, in the case of the character \"\u016f\", a ring. Long \"u\" is usually written \"\u00fa\" at the beginning of a word or morpheme (\"\u00faroda\", \"ne\u00farodn\u00fd\") and \"\u016f\" elsewhere, except for loanwords (\"sk\u00fatr\") or onomatopoeia (\"b\u00fa\"). Long vowels and \"\u011b\" are not considered separate letters in the alphabetical order. The character \"\u00f3\" exists only in loanwords and onomatopoeia.\nCzech typographical features not associated with phonetics generally resemble those of most European languages that use the Latin script, including English. Proper nouns, honorifics, and the first letters of quotations are capitalized, and punctuation is typical of other Latin European languages. Ordinal numbers (1st) use a point, as in German (1.). The Czech language uses a decimal comma instead of a decimal point. When writing a long number, spaces between every three digits, including those in decimal places, may be used for better orientation in handwritten texts. The number 1,234,567.89101 may be written as 1234567,89101 or 1 234 567,891 01. In proper noun phrases (except personal and settlement names), only the first word and proper nouns inside such phrases are capitalized (\"Pra\u017esk\u00fd hrad\", Prague Castle).\nVarieties.\nThe modern literary standard and prestige variety, known as \"Standard Czech\" () is based on the standardization during the Czech National Revival in the 1830s, significantly influenced by Josef Jungmann's Czech\u2013German dictionary published during 1834\u20131839. Jungmann used vocabulary of the Bible of Kralice (1579\u20131613) period and of the language used by his contemporaries. He borrowed words not present in Czech from other Slavic languages or created neologisms. Standard Czech is the formal register of the language which is used in official documents, formal literature, newspaper articles, education and occasionally public speeches. It is codified by the Czech Language Institute, who publish occasional reforms to the codification. The most recent reform took place in 1993. The term (lit. \"Colloquial Czech\") is sometimes used to refer to the spoken variety of standard Czech.\nThe most widely spoken vernacular form of the language is called \"Common Czech\" (), an interdialect influenced by spoken Standard Czech and the Central Bohemian dialects of the Prague region. Other Bohemian regional dialects have become marginalized, while Moravian dialects remain more widespread and diverse, with a political movement for Moravian linguistic revival active since the 1990s.\nThese varieties of the language (Standard Czech, spoken/colloquial Standard Czech, Common Czech, and regional dialects) form a stylistic continuum, in which contact between varieties of a similar prestige influences change within them.\nCommon Czech.\nThe main Czech vernacular, spoken primarily in Bohemia including the capital Prague, is known as Common Czech (\"obecn\u00e1 \u010de\u0161tina\"). This is an academic distinction; most Czechs are unaware of the term or associate it with deformed or \"incorrect\" Czech. Compared to Standard Czech, Common Czech is characterized by simpler inflection patterns and differences in sound distribution.\nCommon Czech is distinguished from spoken/colloquial Standard Czech (), which is a stylistic variety within standard Czech. Tomasz Kamusella defines the spoken variety of Standard Czech as a compromise between Common Czech and the written standard, while Miroslav Kom\u00e1rek calls Common Czech an intersection of spoken Standard Czech and regional dialects.\nCommon Czech has become ubiquitous in most parts of the Czech Republic since the later 20th century. It is usually defined as an interdialect used in common speech in Bohemia and western parts of Moravia (by about two thirds of all inhabitants of the Czech Republic). Common Czech is not codified, but some of its elements have become adopted in the written standard. Since the second half of the 20th century, Common Czech elements have also been spreading to regions previously unaffected, as a consequence of media influence. Standard Czech is still the norm for politicians, businesspeople and other Czechs in formal situations, but Common Czech is gaining ground in journalism and the mass media. The colloquial form of Standard Czech finds limited use in daily communication due to the expansion of the Common Czech interdialect. It is sometimes defined as a theoretical construct rather than an actual tool of colloquial communication, since in casual contexts, the non-standard interdialect is preferred.\nCommon Czech phonology is based on that of the Central Bohemian dialect group, which has a slightly different set of vowel phonemes to Standard Czech. The phoneme /\u025b\u02d0/ is peripheral and usually merges with /i\u02d0/, e.g. in \"mal\u00fd m\u011bsto\" (small town), \"plam\u00ednek\" (little flame) and \"l\u00edtat\" (to fly), and a second native diphthong /\u025b\u026a\u032f/ occurs, usually in places where Standard Czech has /i\u02d0/, e.g. \"malej d\u016fm\" (small house), \"mlejn\" (mill), \"plejtvat\" (to waste), \"bejt\" (to be). In addition, a prothetic \"v-\" is added to most words beginning \"o-\", such as \"votev\u0159\u00edt vokno\" (to open the window).\nNon-standard morphological features that are more or less common among all Common Czech speakers include:\nExamples of declension (Standard Czech is added in italics for comparison):\n\"mlad\u00fd \u010dlov\u011bk \u2013 young man/person, mlad\u00ed lid\u00e9 \u2013 young people, mlad\u00fd st\u00e1t \u2013 young state, mlad\u00e1 \u017eena \u2013 young woman, mlad\u00e9 zv\u00ed\u0159e \u2013 young animal\"\nBohemian dialects.\nApart from the Common Czech vernacular, there remain a variety of other Bohemian dialects, mostly in marginal rural areas. Dialect use began to weaken in the second half of the 20th century, and by the early 1990s regional dialect use was stigmatized, associated with the shrinking lower class and used in literature or other media for comedic effect. Increased travel and media availability to dialect-speaking populations has encouraged them to shift to (or add to their own dialect) Standard Czech.\nThe Czech Statistical Office in 2003 recognized the following Bohemian dialects:\nMoravian dialects.\nThe Czech dialects spoken in Moravia and Silesia are known as Moravian (\"morav\u0161tina\"). In the Austro-Hungarian Empire, \"Bohemian-Moravian-Slovak\" was a language citizens could register as speaking (with German, Polish and several others). In the 2011 census, where respondents could optionally specify up to two first languages, 62,908 Czech citizens specified Moravian as their first language and 45,561 specified both Moravian and Czech.\nBeginning in the sixteenth century, some varieties of Czech resembled Slovak; the southeastern Moravian dialects form a continuum between the Czech and Slovak languages, using the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.\nA popular misconception holds that eastern Moravian dialects are closer to Slovak than Czech, but this is incorrect; in fact, the opposite is true, and certain dialects in far western Slovakia exhibit features more akin to standard Czech than to standard Slovak.\nThe Czech Statistical Office in 2003 recognized the following Moravian dialects:\nSample.\nIn a 1964 textbook on Czech dialectology, B\u0159etislav Koudela used the following sentence to highlight phonetic differences between dialects:\nMutual intelligibility with Slovak.\nCzech and Slovak have been considered mutually intelligible; speakers of either language can communicate with greater ease than those of any other pair of West Slavic languages. Following the 1993 dissolution of Czechoslovakia, mutual intelligibility declined for younger speakers, probably because Czech speakers began to experience less exposure to Slovak and vice versa. A 2015 study involving participants with a mean age of around 23 nonetheless concluded that there remained a high degree of mutual intelligibility between the two languages. Grammatically, both languages share a common syntax.\nOne study showed that Czech and Slovak lexicons differed by 80 percent, but this high percentage was found to stem primarily from differing orthographies and slight inconsistencies in morphological formation; Slovak morphology is more regular (when changing from the nominative to the locative case, \"Praha\" becomes \"Praze\" in Czech and \"Prahe\" in Slovak). The two lexicons are generally considered similar, with most differences found in colloquial vocabulary and some scientific terminology. Slovak has slightly more borrowed words than Czech.\nThe similarities between Czech and Slovak led to the languages being considered a single language by a group of 19th-century scholars who called themselves \"Czechoslavs\" (\"\u010cechoslovan\u00e9\"), believing that the peoples were connected in a way which excluded German Bohemians and (to a lesser extent) Hungarians and other Slavs. During the First Czechoslovak Republic (1918\u20131938), although \"Czechoslovak\" was designated as the republic's official language, both Czech and Slovak written standards were used. Standard written Slovak was partially modeled on literary Czech, and Czech was preferred for some official functions in the Slovak half of the republic. Czech influence on Slovak was protested by Slovak scholars, and when Slovakia broke off from Czechoslovakia in 1938 as the Slovak State (which then aligned with Nazi Germany in World War II), literary Slovak was deliberately distanced from Czech. When the Axis powers lost the war and Czechoslovakia reformed, Slovak developed somewhat on its own (with Czech influence); during the Prague Spring of 1968, Slovak gained independence from (and equality with) Czech, due to the transformation of Czechoslovakia from a unitary state to a federation. Since the dissolution of Czechoslovakia in 1993, \"Czechoslovak\" has referred to improvised pidgins of the languages which have arisen from the decrease in mutual intelligibility.\nVocabulary.\nCzech vocabulary derives primarily from Slavic, Baltic and other Indo-European roots. Although most verbs have Balto-Slavic origins, pronouns, prepositions and some verbs have wider, Indo-European roots. Some loanwords have been restructured by folk etymology to resemble native Czech words (e.g. \"h\u0159bitov\", \"graveyard\" and \"listina\", \"list\").\nMost Czech loanwords originated in one of two time periods. Earlier loanwords, primarily from German, Greek and Latin, arrived before the Czech National Revival. More recent loanwords derive primarily from English and French, and also from Hebrew, Arabic and Persian. Many Russian loanwords, principally animal names and naval terms, also exist in Czech.\nAlthough older German loanwords were colloquial, recent borrowings from other languages are associated with high culture. During the nineteenth century, words with Greek and Latin roots were rejected in favor of those based on older Czech words and common Slavic roots; \"music\" is \"muzyka\" in Polish and \"\u043c\u0443\u0437\u044b\u043a\u0430\" (\"muzyka\") in Russian, but in Czech it is \"hudba\". Some Czech words have been borrowed as loanwords into English and other languages\u2014for example, \"robot\" (from \"robota\", \"labor\") and \"polka\" (from \"polka\", \"Polish woman\" or from \"p\u016flka\" \"half\").\nExample text.\nArticle 1 of the \"Universal Declaration of Human Rights\" in Czech:\nArticle 1 of the \"Universal Declaration of Human Rights\" in English:"}
{"id": "6344", "revid": "24565488", "url": "https://en.wikipedia.org/wiki?curid=6344", "title": "Capsid", "text": " \nA capsid is the protein shell of a virus, enclosing its genetic material. It consists of several oligomeric (repeating) structural subunits made of protein called protomers. The observable 3-dimensional morphological subunits, which may or may not correspond to individual proteins, are called capsomeres. The proteins making up the capsid are called capsid proteins or viral coat proteins (VCP). The virus genomic component inside the capsid, along with occasionally present virus core protein, is called the virus core. The capsid and core together are referred to as a nucleocapsid (cf. also virion).\nCapsids are broadly classified according to their structure. The majority of the viruses have capsids with either helical or icosahedral structure. Some viruses, such as bacteriophages, have developed more complicated structures due to constraints of elasticity and electrostatics. The icosahedral shape, which has 20 equilateral triangular faces, approximates a sphere, while the helical shape resembles the shape of a spring, taking the space of a cylinder but not being a cylinder itself. The capsid faces may consist of one or more proteins. For example, the foot-and-mouth disease virus capsid has faces consisting of three proteins named VP1\u20133.\nSome viruses are \"enveloped\", meaning that the capsid is coated with a lipid membrane known as the viral envelope. The envelope is acquired by the capsid from an intracellular membrane in the virus' host; examples include the inner nuclear membrane, the Golgi membrane, and the cell's outer membrane.\nOnce the virus has infected a cell and begins replicating itself, new capsid subunits are synthesized using the protein biosynthesis mechanism of the cell. In some viruses, including those with helical capsids and especially those with RNA genomes, the capsid proteins co-assemble with their genomes. In other viruses, especially more complex viruses with double-stranded DNA genomes, the capsid proteins assemble into empty precursor procapsids that include a specialized portal structure at one vertex. Through this portal, viral DNA is translocated into the capsid.\nStructural analyses of major capsid protein (MCP) architectures have been used to categorise viruses into lineages. For example, the bacteriophage PRD1, the algal virus \"Paramecium bursaria Chlorella virus-1\" (PBCV-1), mimivirus and the mammalian adenovirus have been placed in the same lineage, whereas tailed, double-stranded DNA bacteriophages (\"Caudovirales\") and herpesvirus belong to a second lineage.\nSpecific shapes.\nIcosahedral.\nThe icosahedral structure is extremely common among viruses. The icosahedron consists of 20 triangular faces delimited by 12 fivefold vertexes and consists of 60 asymmetric units. Thus, an icosahedral virus is made of 60N protein subunits. The number and arrangement of capsomeres in an icosahedral capsid can be classified using the \"quasi-equivalence principle\" proposed by Donald Caspar and Aaron Klug. Like the Goldberg polyhedra, an icosahedral structure can be regarded as being constructed from pentamers and hexamers. The structures can be indexed by two integers \"h\" and \"k\", with formula_1 and formula_2; the structure can be thought of as taking \"h\" steps from the edge of a pentamer, turning 60 degrees counterclockwise, then taking \"k\" steps to get to the next pentamer. The triangulation number \"T\" for the capsid is defined as:\nIn this scheme, icosahedral capsids contain 12 pentamers plus 10(\"T\"\u00a0\u2212\u00a01) hexamers. The \"T\"-number is representative of the size and complexity of the capsids. Geometric examples for many values of \"h\", \"k\", and \"T\" can be found at List of geodesic polyhedra and Goldberg polyhedra.\nMany exceptions to this rule exist: For example, the polyomaviruses and papillomaviruses have pentamers instead of hexamers in hexavalent positions on a quasi T = 7 lattice. Members of the double-stranded RNA virus lineage, including reovirus, rotavirus and bacteriophage \u03c66 have capsids built of 120 copies of capsid protein, corresponding to a T = 2 capsid, or arguably a T = 1 capsid with a dimer in the asymmetric unit. Similarly, many small viruses have a pseudo T = 3 (or P = 3) capsid, which is organized according to a T = 3 lattice, but with distinct polypeptides occupying the three quasi-equivalent positions \nT-numbers can be represented in different ways, for example \"T\"\u00a0=\u00a01 can only be represented as an icosahedron or a dodecahedron and, depending on the type of quasi-symmetry, \"T\"\u00a0=\u00a03 can be presented as a truncated dodecahedron, an icosidodecahedron, or a truncated icosahedron and their respective duals a triakis icosahedron, a rhombic triacontahedron, or a pentakis dodecahedron.\nProlate.\nAn elongated icosahedron is a common shape for the heads of bacteriophages. Such a structure is composed of a cylinder with a cap at either end. The cylinder is composed of 10 elongated triangular faces. The Q number (or Tmid), which can be any positive integer, specifies the number of triangles, composed of asymmetric subunits, that make up the 10 triangles of the cylinder. The caps are classified by the T (or Tend) number.\nThe bacterium \"E. coli\" is the host for bacteriophage T4 that has a prolate head structure. The bacteriophage encoded gp31 protein appears to be functionally homologous to \"E. coli\" chaperone protein GroES and able to substitute for it in the assembly of bacteriophage T4 virions during infection. Like GroES, gp31 forms a stable complex with GroEL chaperonin that is absolutely necessary for the folding and assembly \"in vivo\" of the bacteriophage T4 major capsid protein gp23.\nHelical.\nMany rod-shaped and filamentous plant viruses have capsids with helical symmetry. The helical structure can be described as a set of \"n\" 1-D molecular helices related by an \"n\"-fold axial symmetry. The helical transformation are classified into two categories: one-dimensional and two-dimensional helical systems. Creating an entire helical structure relies on a set of translational and rotational matrices which are coded in the protein data bank. Helical symmetry is given by the formula \"P\"\u00a0=\u00a0\"\u03bc\"\u00a0x\u00a0\"\u03c1\", where \"\u03bc\" is the number of structural units per turn of the helix, \"\u03c1\" is the axial rise per unit and \"P\" is the pitch of the helix. The structure is said to be open due to the characteristic that any volume can be enclosed by varying the length of the helix. The most understood helical virus is the tobacco mosaic virus. The virus is a single molecule of (+) strand RNA. Each coat protein on the interior of the helix bind three nucleotides of the RNA genome. Influenza A viruses differ by comprising multiple ribonucleoproteins, the viral NP protein organizes the RNA into a helical structure. The size is also different; the tobacco mosaic virus has a 16.33 protein subunits per helical turn, while the influenza A virus has a 28 amino acid tail loop.\nFunctions.\nThe functions of the capsid are to:\nThe virus must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents. These include extremes of pH or temperature and proteolytic and nucleolytic enzymes. For non-enveloped viruses, the capsid itself may be involved in interaction with receptors on the host cell, leading to penetration of the host cell membrane and internalization of the capsid. Delivery of the genome occurs by subsequent uncoating or disassembly of the capsid and release of the genome into the cytoplasm, or by ejection of the genome through a specialized portal structure directly into the host cell nucleus.\nOrigin and evolution.\nIt has been suggested that many viral capsid proteins have evolved on multiple occasions from functionally diverse cellular proteins. The recruitment of cellular proteins appears to have occurred at different stages of evolution so that some cellular proteins were captured and refunctionalized prior to the divergence of cellular organisms into the three contemporary domains of life, whereas others were hijacked relatively recently. As a result, some capsid proteins are widespread in viruses infecting distantly related organisms (e.g., capsid proteins with the jelly-roll fold), whereas others are restricted to a particular group of viruses (e.g., capsid proteins of alphaviruses).\nA computational model (2015) has shown that capsids may have originated before viruses and that they served as a means of horizontal transfer between replicator communities since these communities could not survive if the number of gene parasites increased, with certain genes being responsible for the formation of these structures and those that favored the survival of self-replicating communities. The displacement of these ancestral genes between cellular organisms could favor the appearance of new viruses during evolution."}
{"id": "6345", "revid": "5364", "url": "https://en.wikipedia.org/wiki?curid=6345", "title": "Central Dogma Of Genetics", "text": ""}
{"id": "6346", "revid": "5128741", "url": "https://en.wikipedia.org/wiki?curid=6346", "title": "Chloramphenicol", "text": "Chloramphenicol is an antibiotic useful for the treatment of a number of bacterial infections. This includes use as an eye ointment to treat conjunctivitis. By mouth or by injection into a vein, it is used to treat meningitis, plague, cholera, and typhoid fever. Its use by mouth or by injection is only recommended when safer antibiotics cannot be used. Monitoring both blood levels of the medication and blood cell levels every two days is recommended during treatment.\nCommon side effects include bone marrow suppression, nausea, and diarrhea. The bone marrow suppression may result in death. To reduce the risk of side effects treatment duration should be as short as possible. People with liver or kidney problems may need lower doses. In young infants, a condition known as gray baby syndrome may occur which results in a swollen stomach and low blood pressure. Its use near the end of pregnancy and during breastfeeding is typically not recommended. Chloramphenicol is a broad-spectrum antibiotic that typically stops bacterial growth by stopping the production of proteins.\nChloramphenicol was discovered after being isolated from \"Streptomyces venezuelae\" in 1947. Its chemical structure was identified and it was first synthesized in 1949. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication.\nMedical uses.\nThe original indication of chloramphenicol was in the treatment of typhoid, but the presence of multiple drug-resistant \"Salmonella typhi\" has meant it is seldom used for this indication except when the organism is known to be sensitive.\nIn low-income countries, the WHO no longer recommends only chloramphenicol as first-line to treat meningitis, but recognises it may be used with caution if there are no available alternatives.\nDuring the last decade chloramphenicol has been re-evaluated as an old agent with potential against systemic infections due to multidrug-resistant gram positive microorganisms (including vancomycin resistant enterococci). \"In vitro\" data have shown an activity against the majority (&gt; 80%) of vancomycin resistant \"E. faecium\" strains.\nIn the context of preventing endophthalmitis, a complication of cataract surgery, a 2017 systematic review found moderate evidence that using chloramphenicol eye drops in addition to an antibiotic injection (cefuroxime or penicillin) will likely lower the risk of endophthalmitis, compared to eye drops or antibiotic injections alone.\nSpectrum.\nChloramphenicol has a broad spectrum of activity and has been effective in treating ocular infections such as conjunctivitis, blepharitis etc. caused by a number of bacteria including \"Staphylococcus aureus, Streptococcus pneumoniae\", and Escherichia coli. It is not effective against \"Pseudomonas aeruginosa\". The following susceptibility data represent the minimum inhibitory concentration for a few medically significant organisms.\nEach of these concentrations is dependent upon the bacterial strain being targeted. Some strains of E coli, for example, show spontaneous emergence of chloramphenicol resistance.\nResistance.\nThree mechanisms of resistance to chloramphenicol are known: reduced membrane permeability, mutation of the 50S ribosomal subunit, and elaboration of chloramphenicol acetyltransferase. It is easy to select for reduced membrane permeability to chloramphenicol \"in vitro\" by serial passage of bacteria, and this is the most common mechanism of low-level chloramphenicol resistance. High-level resistance is conferred by the \"cat\"-gene; this gene codes for an enzyme called chloramphenicol acetyltransferase, which inactivates chloramphenicol by covalently linking one or two acetyl groups, derived from acetyl-\"S\"-coenzyme A, to the hydroxyl groups on the chloramphenicol molecule. The acetylation prevents chloramphenicol from binding to the ribosome. Resistance-conferring mutations of the 50S ribosomal subunit are rare.\nChloramphenicol resistance may be carried on a plasmid that also codes for resistance to other drugs. One example is the ACCoT plasmid (A=ampicillin, C=chloramphenicol, Co=co-trimoxazole, T=tetracycline), which mediates multiple drug resistance in typhoid (also called R factors).\nAs of 2014 some \"Enterococcus faecium\" and\" Pseudomonas aeruginosa\" strains are resistant to chloramphenicol. Some \"Veillonella\" spp. and \"Staphylococcus capitis\" strains have also developed resistance to chloramphenicol to varying degrees.\nSome other resistance genes beyond \"cat\" are known, such as chloramphenicol hydrolase, and chloramphenicol phosphotransferase.\nAdverse effects.\nAplastic anemia.\nThe most serious side effect of chloramphenicol treatment is aplastic anaemia ('AA'). This effect is rare but sometimes fatal. The risk of AA is high enough that alternatives should be strongly considered. Treatments are available but expensive. No way exists to predict who may or may not suffer this side effect. The effect usually occurs weeks or months after treatment has been stopped, and a genetic predisposition may be involved. It is not known whether monitoring the blood counts of patients can prevent the development of aplastic anaemia, but patients are recommended to have a baseline blood count with a repeat blood count every few days while on treatment. Chloramphenicol should be discontinued if the complete blood count drops. The highest risk is with oral chloramphenicol (affecting 1 in 24,000\u201340,000) and the lowest risk occurs with eye drops (affecting less than one in 224,716 prescriptions).\nBone marrow suppression.\nChloramphenicol may cause bone marrow suppression during treatment; this is a direct toxic effect of the drug on human mitochondria. This effect manifests first as a fall in hemoglobin levels, which occurs quite predictably once a cumulative dose of 20\u00a0g has been given. The anaemia is fully reversible once the drug is stopped and does not predict future development of aplastic anaemia. Studies in mice have suggested existing marrow damage may compound any marrow damage resulting from the toxic effects of chloramphenicol.\nLeukemia.\nLeukemia, a cancer of the blood or bone marrow, is characterized by an abnormal increase of immature white blood cells. The risk of childhood leukemia is increased, as demonstrated in a Chinese case\u2013control study, and the risk increases with length of treatment.\nGray baby syndrome.\nIntravenous chloramphenicol use has been associated with the so-called gray baby syndrome.\nThis phenomenon occurs in newborn infants because they do not yet have fully functional liver enzymes (i.e. UDP-glucuronyl transferase), so chloramphenicol remains unmetabolized in the body.\nThis causes several adverse effects, including hypotension and cyanosis. The condition can be prevented by using the drug at the recommended doses, and monitoring blood levels.\nHypersensitivity reactions.\nFever, macular and vesicular rashes, angioedema, urticaria, and anaphylaxis may occur. Herxheimer's reactions have occurred during therapy for typhoid fever.\nNeurotoxic reactions.\nHeadache, mild depression, mental confusion, and delirium have been described in patients receiving chloramphenicol. Optic and peripheral neuritis have been reported, usually following long-term therapy. If this occurs, the drug should be promptly withdrawn. It is theorized that this is caused by chloramphenicol's effects on the metabolism of B-Vitamins, specifically B-12.\nPharmacokinetics.\nChloramphenicol is extremely lipid-soluble; it remains relatively unbound to protein and is a small molecule. It has a large apparent volume of distribution and penetrates effectively into all tissues of the body, including the brain. Distribution is not uniform, with highest concentrations found in the liver and kidney, with lowest in the brain and cerebrospinal fluid. The concentration achieved in brain and cerebrospinal fluid is around 30 to 50% of the overall average body concentration, even when the meninges are not inflamed; this increases to as high as 89% when the meninges are inflamed.\nChloramphenicol increases the absorption of iron.\nUse in special populations.\nChloramphenicol is metabolized by the liver to chloramphenicol glucuronate (which is inactive). In liver impairment, the dose of chloramphenicol must therefore be reduced. No standard dose reduction exists for chloramphenicol in liver impairment, and the dose should be adjusted according to measured plasma concentrations.\nThe majority of the chloramphenicol dose is excreted by the kidneys as the inactive metabolite, chloramphenicol glucuronate. Only a tiny fraction of the chloramphenicol is excreted by the kidneys unchanged. Plasma levels should be monitored in patients with renal impairment, but this is not mandatory. Chloramphenicol succinate ester (an intravenous prodrug form) is readily excreted unchanged by the kidneys, more so than chloramphenicol base, and this is the major reason why levels of chloramphenicol in the blood are much lower when given intravenously than orally.\nDose monitoring.\nPlasma levels of chloramphenicol must be monitored in neonates and patients with abnormal liver function. Plasma levels should be monitored in all children under the age of four, the elderly, and patients with kidney failure.\nBecause efficacy and toxicity of chloramphenicol are associated with a maximum serum concentration, peak levels (one hour after the intravenous dose is given) should be 10\u201320\u00a0\u03bcg/mL with toxicity ; trough levels (taken immediately before a dose) should be 5\u201310\u00a0\u03bcg/mL.\nDrug interactions.\nAdministration of chloramphenicol concomitantly with bone marrow depressant drugs is contraindicated, although concerns over aplastic anaemia associated with ocular chloramphenicol have largely been discounted.\nChloramphenicol is a potent inhibitor of the cytochrome P450 isoforms CYP2C19 and CYP3A4 in the liver. Inhibition of CYP2C19 causes decreased metabolism and therefore increased levels of, for example, antidepressants, antiepileptics, proton-pump inhibitors, and anticoagulants if they are given concomitantly. Inhibition of CYP3A4 causes increased levels of, for example, calcium channel blockers, immunosuppressants, chemotherapeutic drugs, benzodiazepines, azole antifungals, tricyclic antidepressants, macrolide antibiotics, SSRIs, statins, cardiac antiarrhythmics, antivirals, anticoagulants, and PDE5 inhibitors.\nDrug antagonistic.\nChloramphenicol is antagonistic with most cephalosporins and using both together should be avoided in the treatment of infections.\nDrug synergism.\nChloramphenicol has been demonstrated a synergistic effect when combined with fosfomycin against clinical isolates of \"Enterococcus faecium\".\nMechanism of action.\nChloramphenicol is a bacteriostatic agent, inhibiting protein synthesis. It prevents protein chain elongation by inhibiting the peptidyl transferase activity of the bacterial ribosome. It specifically binds to A2451 and A2452 residues in the 23S rRNA of the 50S ribosomal subunit, preventing peptide bond formation. Chloramphenicol directly interferes with substrate binding in the ribosome, as compared to macrolides, which sterically block the progression of the growing peptide.\nHistory.\nChloramphenicol was first isolated from \"Streptomyces venezuelae\" in 1947 and in 1949 a team of scientists at Parke-Davis including Mildred Rebstock published their identification of the chemical structure and their synthesis.\nIn 1972, Senator Ted Kennedy combined the two examples of the Tuskegee Syphilis Study and the 1958 Los Angeles Infant Chloramphenicol experiments as initial subjects of a Senate Subcommittee investigation into dangerous medical experimentation on human subjects.\nIn 2007, the accumulation of reports associating aplastic anemia and blood dyscrasia with chloramphenicol eye drops led to the classification of \"probable human carcinogen\" according to World Health Organization criteria, based on the known published case reports and the spontaneous reports submitted to the National Registry of Drug-Induced Ocular Side Effects.\nSociety and culture.\nNames.\nChloramphenicol is available as a generic worldwide under many brandnames and also under various generic names in eastern Europe and Russia, including chlornitromycin, levomycetin, and chloromycetin; the racemate is known as synthomycetin.\nFormulations.\nChloramphenicol is available as a capsule or as a liquid. In some countries, it is sold as chloramphenicol palmitate ester (CPE). CPE is inactive, and is hydrolysed to active chloramphenicol in the small intestine. No difference in bioavailability is noted between chloramphenicol and CPE.\nManufacture of oral chloramphenicol in the U.S. stopped in 1991, because the vast majority of chloramphenicol-associated cases of aplastic anaemia are associated with the oral preparation. No oral formulation of chloramphenicol is available in the U.S. for human use.\nIntravenous.\nThe intravenous (IV) preparation of chloramphenicol is the succinate ester. This creates a problem: Chloramphenicol succinate ester is an inactive prodrug and must first be hydrolysed to chloramphenicol; however, the hydrolysis process is often incomplete, and 30% of the dose is lost and removed in the urine. Serum concentrations of IV chloramphenicol are only 70% of those achieved when chloramphenicol is given orally. For this reason, the dose needs to be increased to 75\u00a0mg/kg/day when administered IV to achieve levels equivalent to the oral dose.\nOily.\nOily chloramphenicol (or chloramphenicol oil suspension) is a long-acting preparation of chloramphenicol first introduced by Roussel in 1954; marketed as Tifomycine, it was originally used as a treatment for typhoid. Roussel stopped production of oily chloramphenicol in 1995; the International Dispensary Association Foundation has manufactured it since 1998, first in Malta and then in India from December 2004.\nOily chloramphenicol was first used to treat meningitis in 1975 and numerous studies since have demonstrated its efficacy. It is the cheapest treatment available for meningitis (US$5 per treatment course, compared to US$30 for ampicillin and US$15 for five days of ceftriaxone). It has the great advantage of requiring only a single injection, whereas ceftriaxone is traditionally given daily for five days. This recommendation may yet change, now that a single dose of ceftriaxone (cost US$3) has been shown to be equivalent to one dose of oily chloramphenicol.\nEye drops.\nChloramphenicol is used in topical preparations (ointments and eye drops) for the treatment of bacterial conjunctivitis. Isolated case reports of aplastic anaemia following use of chloramphenicol eyedrops exist, but the risk is estimated to be of the order of less than one in 224,716 prescriptions. In Mexico, this is the treatment used prophylactically in newborns for neonatal conjunctivitis.\nVeterinary uses.\nAlthough its use in veterinary medicine is highly restricted, chloramphenicol still has some important veterinary uses. It is currently considered the most useful treatment of chlamydial disease in koalas. The pharmacokinetics of chloramphenicol have been investigated in koalas.\nBiosynthesis.\nThe biosynthetic gene cluster and pathway for chloroamphenicol was characterized from \"Streptomyces venezuelae\" ISP5230 a.k.a. ATCC 17102. Currently the chloramphenicol biosynthetic gene cluster has 17 genes with assigned roles."}
{"id": "6347", "revid": "4028671", "url": "https://en.wikipedia.org/wiki?curid=6347", "title": "Cut-up technique", "text": "The cut-up technique (or \"d\u00e9coup\u00e9\" in French) is an aleatory narrative technique in which a written text is cut up and rearranged to create a new text. The concept can be traced to the Dadaists of the 1920s, but it was developed and popularized in the 1950s and early 1960s, especially by writer William Burroughs. It has since been used in a wide variety of contexts.\nTechnique.\nThe cut-up and the closely associated fold-in are the two main techniques:\nWilliam Burroughs cited T. S. Eliot's 1922 poem, \"The Waste Land\", and John Dos Passos' \"U.S.A.\" trilogy, which incorporated newspaper clippings, as early examples of the cut ups he popularized.\nGysin introduced Burroughs to the technique at the Beat Hotel. The pair later applied the technique to printed media and audio recordings in an effort to decode the material's implicit content, hypothesizing that such a technique could be used to discover the true meaning of a given text. Burroughs also suggested cut-ups may be effective as a form of divination saying, \"When you cut into the present the future leaks out.\" Burroughs also further developed the \"fold-in\" technique. In 1977, Burroughs and Gysin published \"The Third Mind\", a collection of cut-up writings and essays on the form. Jeff Nuttall's publication \"My Own Mag\" was another important outlet for the then-radical technique.\nIn an interview, Alan Burns noted that for \"Europe After The Rain\" (1965) and subsequent novels he used a version of cut-ups: \"I did not actually use scissors, but I folded pages, read across columns, and so on, discovering for myself many of the techniques Burroughs and Gysin describe\".\nHistory.\nIn literature.\nA precedent of the technique occurred during a Dadaist rally in the 1920s in which Tristan Tzara offered to create a poem on the spot by pulling words at random from a hat. Collage, which was popularized roughly contemporaneously with the Surrealist movement, sometimes incorporated texts such as newspapers or brochures. Prior to this event, the technique had been published in an issue of 391 in the poem by Tzara, \"dada manifesto on feeble love and bitter love\" under the sub-title, \"TO MAKE A DADAIST POEM\".\nIn the 1950s, painter and writer Brion Gysin more fully developed the cut-up method after accidentally rediscovering it. He had placed layers of newspapers as a mat to protect a tabletop from being scratched while he cut papers with a razor blade. Upon cutting through the newspapers, Gysin noticed that the sliced layers offered interesting juxtapositions of text and image. He began deliberately cutting newspaper articles into sections, which he randomly rearranged. The book \"Minutes to Go\" resulted from his initial cut-up experiment: unedited and unchanged cut-ups which emerged as coherent and meaningful prose. South African poet Sinclair Beiles also used this technique and co-authored \"Minutes To Go\".\nArgentine writer Julio Cort\u00e1zar used cut ups in his 1963 novel \"Hopscotch\".\nIn 1969, poets Howard W. Bergerson and J. A. Lindon developed a cut-up technique known as vocabularyclept poetry, in which a poem is formed by taking all the words of an existing poem and rearranging them, often preserving the metre and stanza lengths.\nA drama scripted for five voices by performance poet Hedwig Gorski in 1977 originated the idea of creating poetry only for performance instead of for print publication. The \"neo-verse drama\" titled \"Booby, Mama!\" written for \"guerilla theater\" performances in public places used a combination of newspaper cut-ups that were edited and choreographed for a troupe of non-professional street actors.\nKathy Acker, a literary and intermedia artist, sampled external sources and reconfigured them into the creation of shifting versions of her own constructed identity. In her late 1970s novel \"Blood and Guts in High School\", Acker explored literary cut-up and appropriation as an integral part of her method.\nIn film.\nAntony Balch and Burroughs created a collaboration film, \"The Cut-Ups\" that opened in London in 1967. This was part of an abandoned project called \"Guerrilla Conditions\" meant as a documentary on Burroughs and filmed throughout 1961\u20131965. Inspired by Burroughs' and Gysin's technique of cutting up text and rearranging it in random order, Balch had an editor cut his footage for the documentary into little pieces and impose no control over its reassembly. The film opened at Oxford Street's Cinephone cinema and had a disturbing reaction. Many audience members claimed the film made them ill, others demanded their money back, while some just stumbled out of the cinema ranting \"it's disgusting\". Other cut-up films include \"Ghost at n\u00b09 (Paris)\" (1963\u20131972), a posthumously released short film compiled from reels found at Balch's office after his death, and \"William Buys a Parrott\" (1982), \"Bill and Tony\" (1972), \"Towers Open Fire\" (1963) and \"The Junky's Christmas\" (1966).\nIn music.\nIn 1962, the satirical comedy group Bonzo Dog Doo-Dah Band, got their name after using the cut-up technique, resulting in \"Bonzo Dog Dada\": \"Bonzo Dog\", after the cartoon Bonzo the Dog, and \"Dada\" after the Dada avant-garde art movement. The group's eventual frontman, Vivian Stanshall, would quote about wanting to form a band with that name. The \"Dada\" in the phrase was eventually changed to \"Doo-Dah\".\nFrom the early 1970s, David Bowie used cut-ups to create some of his lyrics. In 1995, he worked with Ty Roberts to develop a program called \"Verbasizer\" for his Apple PowerBook that could automatically rearrange multiple sentences written into it. Thom Yorke applied a similar method in Radiohead's \"Kid A\" (2000) album, writing single lines, putting them into a hat, and drawing them out at random while the band rehearsed the songs. Perhaps indicative of Thom Yorke's influences, instructions for \"How to make a Dada poem\" appeared on Radiohead's website at this time.\nStephen Mallinder of Cabaret Voltaire reported to \"Inpress\" magazine's Andrez Bergen that \"I do think the manipulation of sound in our early days \u2013 the physical act of cutting up tapes, creating tape loops and all that \u2013 has a strong reference to Burroughs and Gysin.\" Another industrial music pioneer, Al Jourgensen of Ministry, named Burroughs and his cut-up technique as the most important influence on how he approached the use of samples.\nMany Elephant 6 bands used decoupe as well, one prominent example of this is seen in \"Pree-Sisters Swallowing A Donkey's Eye\" by Neutral Milk Hotel."}
{"id": "6348", "revid": "835", "url": "https://en.wikipedia.org/wiki?curid=6348", "title": "Congressional Medal of Honour", "text": ""}
{"id": "6352", "revid": "1266063585", "url": "https://en.wikipedia.org/wiki?curid=6352", "title": "Congenital iodine deficiency syndrome", "text": "Congenital iodine deficiency syndrome (CIDS), also called cretinism, is a medical condition present at birth marked by impaired physical and mental development, due to insufficient thyroid hormone production (hypothyroidism) often caused by insufficient dietary iodine during pregnancy. It is one cause of underactive thyroid function at birth, called congenital hypothyroidism. If untreated, it results in impairment of both physical and mental development. Symptoms may include: goiter, poor length growth in infants, reduced adult stature, thickened skin, hair loss, enlarged tongue, a protruding abdomen, delayed bone maturation and puberty in children, mental deterioration, neurological impairment, impeded ovulation, and infertility in adults.\nIn developed countries, thyroid function testing of newborns has assured that in those affected, treatment with the synthetic thyroid hormone thyroxine is begun promptly. This screening and treatment successfully cures the disease.\nSigns and symptoms.\nIodine deficiency causes gradual enlargement of the thyroid gland, referred to as a goiter. Poor length growth is apparent as early as the first year of life. Adult stature without treatment ranges from , depending on severity, sex, and other genetic factors. Other signs include thickened skin, hair loss, enlarged tongue, and a protruding abdomen. In children, bone maturation and puberty are severely delayed. In adults, ovulation is impeded and infertility is common.\nMental deterioration is common. Neurological impairment may be mild, with reduced muscle tone and motor coordination, or so severe that the person cannot stand or walk. Cognitive impairment may also range from mild to so severe that the person is nonverbal and dependent on others for basic care. Thought and reflexes are slower.\nCause.\nAround the world, the most common cause of congenital iodine deficiency syndrome (endemic cretinism) is dietary iodine deficiency.\nIodine is an essential trace element, necessary for the synthesis of thyroid hormones. Iodine deficiency is the most common preventable cause of neonatal and childhood brain damage worldwide. Although iodine is found in many foods, it is not universally present in all soils in adequate amounts. Most iodine, in iodide form, is in the oceans, where the iodide ions are reduced to elemental iodine, which then enters the atmosphere and falls to earth in rain, introducing iodine to soils. Soil deficient in iodine is most common inland, in mountainous areas, and in areas of frequent flooding. It can also occur in coastal regions, where iodine might have been removed from the soil by glaciation, as well as leaching by snow, water and heavy rainfall. Plants and animals grown in iodine-deficient soils are correspondingly deficient. Populations living in those areas without outside food sources are most at risk of iodine deficiency diseases.\nDiagnosis.\nDifferential diagnosis.\nDwarfism may also be caused by malnutrition or other hormonal deficiencies, such as insufficient growth hormone secretion, hypopituitarism, decreased secretion of growth hormone-releasing hormone, deficient growth hormone receptor activity and downstream causes, such as insulin-like growth factor 1 (IGF-1) deficiency.\nPrevention.\nThere are public health campaigns in many countries which involve iodine administration. As of December 2019, 122 countries have mandatory iodine food fortification programs.\nTreatment.\nCongenital iodine deficiency has been almost eliminated in developed countries through iodine supplementation of food and by newborn screening using a blood test for thyroid function.\nTreatment consists of lifelong administration of thyroxine (T4). Thyroxine must be dosed as tablets only, even to newborns, as the liquid oral suspensions and compounded forms cannot be depended on for reliable dosing. For infants, the T4 tablets are generally crushed and mixed with breast milk, formula milk or water. If the medication is mixed with formulas containing iron or soya products, larger doses may be required, as these substances may alter the absorption of thyroid hormone from the gut. Monitoring TSH blood levels every 2\u20133 weeks during the first months of life is recommended to ensure that affected infants are at the high end of normal range.\nHistory.\nA goiter is the most specific clinical marker of either the direct or indirect insufficient intake of iodine in the human body. There is evidence of goiter, and its medical treatment with iodine-rich algae and burnt sponges, in Chinese, Egyptian, and Roman ancient medical texts. In 1848, King Carlo Alberto of Sardinia commissioned the first epidemiological study of congenital iodine deficiency syndrome, in northern Savoy where it was frequent. In past centuries, the well reported social diseases prevalent among the poorer social classes and farmers, caused by dietary and agricultural monocultures, were: pellagra, rickets, beriberi, scurvy in long-term sailors, and the endemic goiter caused by iodine deficiency. However, this disease was less mentioned in medical books because it was erroneously considered to be an aesthetic rather than a clinical disorder.\nCongenital iodine-deficiency syndrome was especially common in areas of southern Europe around the Alps and was often described by ancient Roman writers and depicted by artists. The earliest Alpine mountain climbers sometimes came upon whole villages affected by it. The prevalence of the condition was described from a medical perspective by several travellers and physicians in the late 18th and early 19th centuries. At that time the cause was not known and it was often attributed to \"stagnant air\" in mountain valleys or \"bad water\". The proportion of people affected varied markedly throughout southern Europe and even within very small areas; it might be common in one valley and not another. The number of severely affected persons was always a minority, and most persons were only affected to the extent of having a goitre and some degree of reduced cognition and growth. The majority of such cases were still socially functional in their pastoral villages.\nMore mildly affected areas of Europe and North America in the 19th century were referred to as \"goitre belts\". The degree of iodine deficiency was milder and manifested primarily as thyroid enlargement rather than severe mental and physical impairment. In Switzerland, for example, where soil does not contain a large amount of iodine, cases of congenital iodine deficiency syndrome were very abundant and even considered genetically caused. As the variety of food sources dramatically increased in Europe and North America and the populations became less completely dependent on locally grown food, the prevalence of endemic goitre diminished. This is supported by a 1979 WHO publication which concluded that \"changes in the origin of food supplies may account for the otherwise unexplained disappearance of endemic goitre from a number of localities during the past 50 years\".\nThe early 20th century saw the discovery of the relationships of neurological impairment with hypothyroidism due to iodine deficiency. Both have been largely eliminated in the developed world.\nTerminology.\nThe term \"cretin\" was originally used to describe a person affected by this condition, but, as with words such as \"spastic\" and \"lunatic\", it underwent pejoration and is now considered derogatory and inappropriate. \"Cretin\" became a medical term in the 18th century, from an Occitan and an Alpine French expression, prevalent in a region where persons with such a condition were especially common (see below); it saw wide medical use in the 19th and early 20th centuries, and was a \"tick box\" category on Victorian-era census forms in the UK. The term spread more widely in popular English as a markedly derogatory term for a person who behaves stupidly. Because of its pejorative connotations in popular speech, current usage among health care professionals has abandoned the noun \"cretin\" referring to a person. The noun \"cretinism\", referring to the condition, still occurs in medical literature and textbooks but its use is waning.\nThe etymology of \"cretin\" is uncertain. Several hypotheses exist. The most common derivation provided in English dictionaries is from the Alpine French dialect pronunciation of the word \"Chr\u00e9tien\" (\"(a) Christian\"), which was a greeting there. According to the \"Oxford English Dictionary\", the translation of the French term into \"human creature\" implies that the label \"Christian\" is a reminder of the humanity of the affected, in contrast to brute beasts. Other sources suggest that \"Christian\" describes the person's \"Christ-like\" inability to sin, stemming, in such cases, from an incapacity to distinguish right from wrong.\nOther speculative etymologies have been offered:"}
{"id": "6353", "revid": "38132428", "url": "https://en.wikipedia.org/wiki?curid=6353", "title": "Cretin", "text": "Cretin may refer to:\nEducation.\nNamed after Joseph Cr\u00e9tin"}
{"id": "6354", "revid": "1268000130", "url": "https://en.wikipedia.org/wiki?curid=6354", "title": "Council of Trent", "text": "The Council of Trent (), held between 1545 and 1563 in Trent (or Trento), now in northern Italy, was the 19th ecumenical council of the Catholic Church. Prompted by the Protestant Reformation at the time, it has been described as the embodiment of the Counter-Reformation. It was the last time an ecumenical council was organised outside the city of Rome. \nThe Council issued key statements and clarifications of the Church's doctrine and teachings, including scripture, the biblical canon, sacred tradition, original sin, justification, salvation, the sacraments, the Mass, and the veneration of saints and also issued condemnations of what it defined to be heresies committed by proponents of Protestantism. The consequences of the council were also significant with regard to the Church's liturgy and censorship.\nThe Council met for twenty-five sessions between 13 December 1545 and 4 December 1563. Pope Paul III, who convoked the council, oversaw the first eight sessions (1545\u20131547), while the twelfth to sixteenth sessions (1551\u201352) were overseen by Pope Julius III and the seventeenth to twenty-fifth sessions (1562\u201363) by Pope Pius IV. More than three hundred years passed until the next ecumenical council, the First Vatican Council, was convened in 1869.\nBackground information.\nObstacles and events before the Council's problem area.\nOn 15 March 1517, the Fifth Council of the Lateran closed its activities with a number of reform proposals (on the selection of bishops, taxation, censorship and preaching) but not on the new major problems that confronted the Church in Germany and other parts of Europe. A few months later, on 31 October 1517, Martin Luther issued his \"95 Theses\" in Wittenberg.\nA general, free council in Germany.\nLuther's position on ecumenical councils shifted over time, but in 1520 he appealed to the German princes to oppose the papal Church at the time, if necessary with a council in Germany, open and free of the Papacy. After the Pope condemned in \"Exsurge Domine\" fifty-two of Luther's theses as heresy, German opinion considered a council the best method to reconcile existing differences. German Catholics, diminished in number, hoped for a council to clarify matters.\nIt took a generation for the council to materialise, partly due to papal fears over potentially renewing a schism over conciliarism; partly because Lutherans demanded the exclusion of the papacy from the council; partly because of ongoing political rivalries between France and the Holy Roman Empire; and partly due to the Turkish dangers in the Mediterranean. Under Pope Clement VII (1523\u201334), mutinous troops many of whom were Lutheran belonging to the Catholic Holy Roman Emperor Charles V sacked Papal Rome in 1527, \"raping, killing, burning, stealing, the like had not been seen since the Vandals\". Saint Peter's Basilica and the Sistine Chapel were used for horses. Pope Clement, fearful of the potential for more violence, delayed calling the council.\nCharles V strongly favoured a council but needed the support of King Francis I of France, who attacked him militarily. Francis I generally opposed a general council due to partial support of the Protestant cause within France. Charles' younger brother Ferdinand of Austria, who ruled a huge swath of territory in central Europe, agreed in 1532 to the Nuremberg Religious Peace granting religious liberty to the Protestants, and in 1533 he further complicated matters when suggesting a general council to include both Catholic and Protestant rulers of Europe that would devise a compromise between the two theological systems. This proposal met the opposition of the Pope for it gave recognition to Protestants and also elevated the secular Princes of Europe above the clergy on church matters. Faced with a Turkish attack, Charles held the support of the Protestant German rulers, all of whom delayed the opening of the Council of Trent.\nOccasion, sessions, and attendance.\nIn the to-and-fro of medieval politics, Pope Pius II, in his bull \"Execrabilis\" (1460) and his reply to the University of Cologne (1463), had set aside the theory of the supremacy of general councils laid down by the Council of Constance, which had also called for frequent ecumenical councils every ten years to cope with the backlog of reform and heresies.\nMartin Luther had appealed for a general council, in response to the Papal bull \"Exsurge Domine\" of Pope Leo X (1520). In 1522 German diets joined in the appeal, with Charles V seconding and pressing for a council as a means of reunifying the Church and settling the Reformation controversies. Pope Clement VII (1523\u201334) was vehemently against the idea of a council, agreeing with Francis I of France.\nSessions.\nThe history of the council is divided into three distinct periods: 1545\u20131549, 1551\u20131552 and 1562\u20131563.\nThe number of attending members in the three periods varied considerably. The council was small to begin with, opening with only about 30 bishops. It increased toward the close, but never reached the number of the First Council of Nicaea (which had 318 members) nor of the First Vatican Council (which numbered 744). The decrees were signed in 1563 by 255 members, the highest attendance of the whole council, including four papal legates, two cardinals, three patriarchs, twenty-five archbishops, and 168 bishops, two-thirds of whom were Italians. The Italian and Spanish prelates were vastly preponderant in power and numbers. At the passage of the most important decrees, not more than sixty prelates were present. Although most Protestants did not attend, ambassadors and theologians of Brandenburg, W\u00fcrttemberg, and Strasbourg attended having been granted an improved safe conduct.\nPre-council.\nPope Paul III (1534\u20131549), seeing that the Protestant Reformation was no longer confined to a few preachers, but had won over various princes, especially in Germany, to its ideas, desired a council. Yet when he proposed the idea to his cardinals, it was almost unanimously opposed. Nonetheless, he sent nuncios throughout Europe to propose the idea. Paul III issued a decree for a general council to be held in Mantua, Italy, to begin on 23 May 1537. Martin Luther wrote the Smalcald Articles in preparation for the general council. The Smalcald Articles were designed to sharply define where the Lutherans could and could not compromise. The council was ordered by the Emperor and Pope Paul III to convene in Mantua on 23 May 1537.\nIt failed to convene after another war broke out between France and Charles V, resulting in a non-attendance of French prelates. Protestants refused to attend as well. Financial difficulties in Mantua led the Pope in the autumn of 1537 to move the council to Vicenza, where participation was poor. The council was postponed indefinitely on 21 May 1539.\nPope Paul III then initiated several internal Church reforms while Emperor Charles V convened with Protestants and Cardinal Gasparo Contarini at the Diet of Regensburg, to reconcile differences. Mediating and conciliatory formulations were developed on certain topics. In particular, a two-part doctrine of \"justification\" was formulated that would later be rejected at Trent. Unity failed between Catholic and Protestant representatives \"because of different concepts of \"Church\" and \"Justification\"\".\nFirst period.\nHowever, the council was delayed until 1545 and, as it happened, convened right before Luther's death. Unable, however, to resist the urging of Charles V, the pope, after proposing Mantua as the place of meeting, convened the council at Trent (at that time ruled by a prince-bishop under the Holy Roman Empire), on 13 December 1545; the Pope's decision to transfer it to Bologna in March 1547 on the pretext of avoiding a plague failed to take effect and the council was indefinitely prorogued on 17 September 1549. None of the three popes reigning over the duration of the council ever attended, which had been a condition of Charles V. Papal legates were appointed to represent the Papacy.\nSecond period.\nReopened at Trent on 1 May 1551 by the convocation of Pope Julius III (1550\u20131555), it was broken up by the sudden victory of Maurice, Elector of Saxony over Emperor Charles V and his march into surrounding state of Tirol on 28 April 1552. There was no hope of reassembling the council while the very anti-Protestant Paul IV was Pope.\nDuring the second period, the Protestants present asked for a renewed discussion on points already defined and for bishops to be released from their oaths of allegiance to the Pope. When the last period began, all intentions of conciliating the Protestants was gone and the Jesuits had become a strong force. This last period was begun especially as an attempt to prevent the formation of a general council including Protestants, as had been demanded by some in France.\nThird period.\nThe council was reconvened by Pope Pius IV (1559\u20131565) for the last time, meeting from 18 January 1562 at Santa Maria Maggiore, and continued until its final adjournment on 4 December 1563. It closed with a series of ritual acclamations honouring the reigning Pope, the Popes who had convoked the council, the emperor and the kings who had supported it, the papal legates, the cardinals, the ambassadors present, and the bishops, followed by acclamations of acceptance of the faith of the council and its decrees, and of anathema for all heretics.\nThe French monarchy boycotted the entire council until the last minute when a delegation led by Charles de Guise, Cardinal of Lorraine finally arrived in November 1562. The first outbreak of the French Wars of Religion had occurred earlier in the year and the French Church, facing a significant and powerful Protestant minority in France, experienced iconoclasm violence regarding the use of sacred images. Such concerns were not primary in the Italian and Spanish Churches. The last-minute inclusion of a decree on sacred images was a French initiative, and the text, never discussed on the floor of the council or referred to council theologians, was based on a French draft.\nObjectives and overall results.\nThe main objectives of the council were twofold:\nSpecific issues that were discussed included:\nThe doctrinal decisions of the council were set forth in decrees (\"decreta\"), which are divided into chapters (\"capita\"), which contain the positive statement of the conciliar dogmas, and into short canons (\"canones\"), which condemn incorrect views (often a Protestant-associated notion stated in an extreme form) with the concluding \"anathema sit\" (\"let him be anathema\" i.e., excluded from the society of the faithful).\nThe consequences of the council were also significant with regard to the Church's liturgy and practices. In its decrees, the council made the Latin Vulgate the official biblical text of the Roman Church (without prejudice to the original texts in Hebrew and Greek, nor to other traditional translations of the Church, but favoring the Latin language over vernacular translations, such as the controversial English-language Tyndale Bible). In doing so, they commissioned the creation of a revised and standardized Vulgate in light of textual criticism, although this was not achieved until the 1590s. The council also officially affirmed the traditional Catholic Canon of biblical books, which was identical to the canon of Scripture issued by the Council of Rome under Pope Damasus in 382. This was in response to the increasing Protestant exclusion of the deuterocanonical books. The former dogmatic affirmation of the Canonical books was at the Council of Florence in the 1441 bull \"Cantate Domino\", as affirmed by Pope Leo XIII in his 1893 encyclical \"Providentissimus Deus\" (#20). In 1565, a year after the Council finished its work, Pius IV issued the Tridentine Creed (after \"Tridentum\", Trent's Latin name) and his successor Pius V then issued the Roman Catechism and revisions of the Breviary and Missal in, respectively, 1566, 1568 and 1570. These, in turn, led to the codification of the Tridentine Mass, which remained the Church's primary form of the Mass for the next four hundred years.\nDecrees.\nThe doctrinal acts are as follows:\nAfter reaffirming the Niceno-Constantinopolitan Creed (third session), the decree was passed (fourth session) confirming that the deuterocanonical books were on a par with the other books of the canon (against Luther's placement of these books in the Apocrypha of his edition) and coordinating church tradition with the Scriptures as a rule of faith. The Vulgate translation was affirmed to be authoritative for the text of Scripture.\nJustification (sixth session) was declared to be offered upon the basis of human cooperation with divine grace (synergism) as opposed to the typical Protestant doctrine of passive reception of grace (monergism). Understanding the Protestant \"faith alone\" doctrine to be one of simple human confidence in Divine Mercy, the Council rejected the \"vain confidence\" of the Protestants, stating that no one can know infallibly who has received the grace of final perseverance apart from receiving a special revelation. Furthermore, the Council affirmed\u2014against some Protestants\u2014that the grace of God can be forfeited through mortal sin.\nThe greatest weight in the council's decrees is given to the sacraments. The seven sacraments were reaffirmed and the Eucharist pronounced to be a true propitiatory sacrifice as well as a sacrament, in which the bread and wine were consecrated into the Eucharist (thirteenth and twenty-second sessions). The term transubstantiation was used by the council, but the specific Aristotelian explanation given by Scholasticism was not cited as dogmatic. Instead, the decree states that Christ is \"really, truly, substantially present\" in the consecrated forms. The sacrifice of the Mass was to be offered for dead and living alike and in giving to the apostles the command \"do this in remembrance of me,\" Christ conferred upon them a sacerdotal power. The practice of withholding the cup from the laity was confirmed (twenty-first session) as one which the Church Fathers had commanded for good and sufficient reasons; yet in certain cases the Pope was made the supreme arbiter as to whether the rule should be strictly maintained.\nOrdination (twenty-third session) was defined to imprint an indelible character on the soul. The priesthood of the New Testament takes the place of the Levitical priesthood. To the performance of its functions, the consent of the people is not necessary.\nIn the decrees on marriage (twenty-fourth session) the excellence of the celibate state was reaffirmed, concubinage condemned and the validity of marriage made dependent upon the wedding taking place before a priest and two witnesses, although the lack of a requirement for parental consent ended a debate that had proceeded from the 12th century. In the case of a divorce, the right of the innocent party to marry again was denied so long as the other party was alive, even if the other party had committed adultery. However the council \"refused \u2026 to assert the necessity or usefulness of clerical celibacy\".\nIn the twenty-fifth and last session, the doctrines of purgatory, the invocation of saints and the veneration of relics were reaffirmed, as was also the efficacy of indulgences as dispensed by the Church according to the power given her, but with some cautionary recommendations, and a ban on the sale of indulgences. Short and rather inexplicit passages concerning religious images, were to have great impact on the development of Catholic Church art. Much more than the Second Council of Nicaea (787), the Council fathers of Trent stressed the pedagogical purpose of Christian images.\nPractical.\nOn the language of the Mass, \"contrary to what is often said\", the council condemned the insistence that only vernacular languages must be used, while affirming on the use of Latin for the Roman rite. However, elements of the Pr\u00f4ne, the vernacular catechetical preaching service common in the medieval High Mass (and some extra-liturgical situations) became mandatory for Sundays and feast days (fifth session, chapter 2).\nThe council appointed, in 1562 (eighteenth session), a commission to prepare a list of forbidden books (\"Index Librorum Prohibitorum\"), but it later left the matter to the Pope. The preparation of a catechism and the revision of the Breviary and Missal were also left to the pope. The catechism embodied the council's far-reaching results, including reforms and definitions of the sacraments, the Scriptures, church dogma, and duties of the clergy.\nRatification and promulgation.\nOn adjourning, the Council asked the supreme pontiff to ratify all its decrees and definitions. This petition was complied with by Pope Pius IV, on 26 January 1564, in the papal bull, \"Benedictus Deus\", which enjoins strict obedience upon all Catholics and forbids, under pain of ex-communication, all unauthorised interpretation, reserving this to the Pope alone and threatens the disobedient with \"the indignation of Almighty God and of his blessed apostles, Peter and Paul.\" Pope Pius appointed a commission of cardinals to assist him in interpreting and enforcing the decrees.\nThe \"Index Librorum Prohibitorum\" was announced in 1564 and the following books were issued with the papal imprimatur: the Profession of the Tridentine Faith and the Tridentine Catechism (1566), the Breviary (1568), the Missal (1570) and the Vulgate (1590 and then 1592).\nThe decrees of the council were acknowledged in Italy, Portugal, Poland and by the Catholic princes of Germany at the Diet of Augsburg in 1566. Philip II of Spain accepted them for Spain, the Netherlands and Sicily inasmuch as they did not infringe the royal prerogative. In France, they were officially recognised by the king only in their doctrinal parts. Although the disciplinary or moral reformatory decrees were never published by the throne, they received official recognition at provincial synods and were enforced by the bishops. Holy Roman Emperors Ferdinand I and Maximilian II never recognized the existence of any of the decrees. No attempt was made to introduce it into England. Pius IV sent the decrees to Mary, Queen of Scots, with a letter dated 13 June 1564, requesting that she publish them in Scotland, but she dared not do it in the face of John Knox and the Reformation.\nThese decrees were later supplemented by the First Vatican Council of 1870.\nPublication of documents.\nA comprehensive history is found in Hubert Jedin's \"The History of the Council of Trent (Geschichte des Konzils von Trient)\" with about 2,500 pages in four volumes: \"The History of the Council of Trent: The fight for a Council\" (Vol I, 1951); \"The History of the Council of Trent: The first Sessions in Trent (1545\u20131547)\" (Vol II, 1957); \"The History of the Council of Trent: Sessions in Bologna 1547\u20131548 and Trento 1551\u20131552\" (Vol III, 1970, 1998); \"The History of the Council of Trent: Third Period and Conclusion\" (Vol IV, 1976).\nThe canons and decrees of the council have been published very often and in many languages. The first issue was by Paulus Manutius (Rome, 1564). Commonly used Latin editions are by Judocus Le Plat (Antwerp, 1779) and by Johann Friedrich von Schulte and Aemilius Ludwig Richter (Leipzig, 1853). Other editions are in vol. vii. of the \"Acta et decreta conciliorum recentiorum. Collectio Lacensis\" (7 vols., Freiburg, 1870\u201390), reissued as independent volume (1892); \"Concilium Tridentinum: Diariorum, actorum, epistularum, \u2026 collectio\", ed. Sebastianus Merkle (4 vols., Freiburg, 1901 sqq.); as well as Mansi, \"Concilia\", xxxv. 345 sqq. Note also Carl Mirbt, \"Quellen\", 2d ed, pp.\u00a0202\u2013255. An English edition is by James Waterworth (London, 1848; \"With Essays on the External and Internal History of the Council\").\nThe original acts and debates of the council, as prepared by its general secretary, Bishop Angelo Massarelli, in six large folio volumes, are deposited in the Vatican Library and remained there unpublished for more than 300 years and were brought to light, though only in part, by Augustin Theiner, priest of the oratory (d. 1874), in \"Acta genuina sancti et oecumenici Concilii Tridentini nunc primum integre edita\" (2 vols., Leipzig, 1874).\nMost of the official documents and private reports, however, which bear upon the council, were made known in the 16th century and since. The most complete collection of them is that of J. Le Plat, \"Monumentorum ad historicam Concilii Tridentini collectio\" (7 vols., Leuven, 1781\u201387). New materials (Vienna, 1872); by JJI von D\u00f6llinger (\"Ungedruckte Berichte und Tageb\u00fccher zur Geschichte des Concilii von Trient\", 2 parts, N\u00f6rdlingen, 1876); and August von Druffel, \"Monumenta Tridentina\" (Munich, 1884\u201397).\nProtestant response.\nOut of 87 books written between 1546 and 1564 attacking the Council of Trent, 41 were written by Pier Paolo Vergerio, a former papal nuncio turned Protestant Reformer. The 1565\u201373 \"Examen decretorum Concilii Tridentini\" (\"Examination of the Council of Trent\") by Martin Chemnitz was the main Lutheran response to the Council of Trent. Making extensive use of scripture and patristic sources, it was presented in response to a polemical writing which Diogo de Payva de Andrada had directed against Chemnitz. The \"Examen\" had four parts: Volume I examined sacred scripture, free will, original sin, justification, and good works. Volume II examined the sacraments, including baptism, confirmation, the sacrament of the Eucharist, communion under both kinds, the Mass, penance, extreme unction, holy orders, and matrimony. Volume III examined virginity, celibacy, purgatory, and the invocation of saints. Volume IV examined the relics of the saints, images, indulgences, fasting, the distinction of foods, and festivals.\nIn response, Andrada wrote the five-part \"Defensio Tridentin\u00e6 fidei\", which was published posthumously in 1578. However, the \"Defensio\" did not circulate as extensively as the \"Examen\", nor were full translations initially published. A French translation of the \"Examen\" by Eduard Preuss was published in 1861. German translations were published in 1861, 1884, and 1972. In English, a complete translation by Fred Kramer drawing from the original Latin and the 1861 German was published beginning in 1971."}
{"id": "6355", "revid": "43646904", "url": "https://en.wikipedia.org/wiki?curid=6355", "title": "Chloroplast", "text": "A chloroplast () is a type of organelle known as a plastid that conducts photosynthesis mostly in plant and algal cells. Chloroplasts have a high concentration of chlorophyll pigments which capture the energy from sunlight and convert it to chemical energy and release oxygen. The chemical energy created is then used to make sugar and other organic molecules from carbon dioxide in a process called the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, amino acid synthesis, and the immune response in plants. The number of chloroplasts per cell varies from one, in some unicellular algae, up to 100 in plants like \"Arabidopsis\" and wheat.\nChloroplasts are highly dynamic\u2014they circulate and are moved around within cells. Their behavior is strongly influenced by environmental factors like light color and intensity. Chloroplasts cannot be made anew by the plant cell and must be inherited by each daughter cell during cell division, which is thought to be inherited from their ancestor\u2014a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell. \nChloroplasts evolved from an ancient cyanobacterium that was engulfed by an early eukaryotic cell. Because of their endosymbiotic origins, chloroplasts, like mitochondria, contain their own DNA separate from the cell nucleus. With one exception (the amoeboid \"Paulinella chromatophora\"), all chloroplasts can be traced back to a single endosymbiotic event. Despite this, chloroplasts can be found in extremely diverse organisms that are not directly related to each other\u2014a consequence of many secondary and even tertiary endosymbiotic events.\nDiscovery and etymology.\nThe first definitive description of a chloroplast (\"Chlorophyllk\u00f6rnen\", \"grain of chlorophyll\") was given by Hugo von Mohl in 1837 as discrete bodies within the green plant cell. In 1883, Andreas Franz Wilhelm Schimper named these bodies as \"chloroplastids\" (\"Chloroplastiden\"). In 1884, Eduard Strasburger adopted the term \"chloroplasts\" (\"Chloroplasten\").\nThe word \"chloroplast\" is derived from the Greek words \"chloros\" (\u03c7\u03bb\u03c9\u03c1\u03cc\u03c2), which means green, and \"plastes\" (\u03c0\u03bb\u03ac\u03c3\u03c4\u03b7\u03c2), which means \"the one who forms\".\nEndosymbiotic origin of chloroplasts.\nChloroplasts are one of many types of organelles in photosynthetic eukaryotic cells. They evolved from cyanobacteria through a process called organellogenesis. Cyanobacteria are a diverse phylum of gram-negative bacteria capable of carrying out oxygenic photosynthesis. Like chloroplasts, they have thylakoids. The thylakoid membranes contain photosynthetic pigments, including chlorophyll \"a\". This origin of chloroplasts was first suggested by the Russian biologist Konstantin Mereschkowski in 1905 after Andreas Franz Wilhelm Schimper observed in 1883 that chloroplasts closely resemble cyanobacteria. Chloroplasts are only found in plants, algae, and some species of the amoeboid \"Paulinella\".\nMitochondria are thought to have come from a similar endosymbiosis event, where an aerobic prokaryote was engulfed. \nPrimary endosymbiosis.\nApproximately twobillion years ago, a free-living cyanobacterium entered an early eukaryotic cell, either as food or as an internal parasite, but managed to escape the phagocytic vacuole it was contained in and persist inside the cell. This event is called \"endosymbiosis\", or \"cell living inside another cell with a mutual benefit for both\". The external cell is commonly referred to as the \"host\" while the internal cell is called the \"endosymbiont\". The engulfed cyanobacteria provided an advantage to the host by providing sugar from photosynthesis. Over time, the cyanobacterium was assimilated, and many of its genes were lost or transferred to the nucleus of the host. Some of the cyanobacterial proteins were then synthesized by host cell and imported back into the chloroplast (formerly the cyanobacterium), allowing the host to control the chloroplast.\nChloroplasts which can be traced back directly to a cyanobacterial ancestor (i.e. without a subsequent endosymbiotic event) are known as primary plastids (\"plastid\" in this context means almost the same thing as chloroplast). Chloroplasts that can be traced back to another photosynthetic eukaryotic endosymbiont are called secondary plastids or tertiary plastids (discussed below).\nWhether primary chloroplasts came from a single endosymbiotic event or multiple independent engulfments across various eukaryotic lineages was long debated. It is now generally held that with one exception (the amoeboid \"Paulinella chromatophora\"), chloroplasts arose from a single endosymbiotic event around twobillion years ago and these chloroplasts all share a single ancestor. It has been proposed this the closest living relative of the ancestral engulfed cyanobacterium is \"Gloeomargarita lithophora.\" Separately, somewhere about 90\u2013140\u00a0million years ago, this process happened again in the amoeboid \"Paulinella\" with a cyanobacterium in the genus \"Prochlorococcus\". This independently evolved chloroplast is often called a \"chromatophore\" instead of a chloroplast.\nChloroplasts are believed to have arisen after mitochondria, since all eukaryotes contain mitochondria, but not all have chloroplasts. This is called \"serial endosymbiosis\"\u2014where an early eukaryote engulfed the mitochondrion ancestor, and then descendants of it then engulfed the chloroplast ancestor, creating a cell with both chloroplasts and mitochondria.\nSecondary and tertiary endosymbiosis.\nMany other organisms obtained chloroplasts from the primary chloroplast lineages through secondary endosymbiosis\u2014engulfing a red or green alga with a primary chloroplast. These chloroplasts are known as secondary plastids.\nAs a result of the secondary endosymbiotic event, secondary chloroplasts have additional membranes outside of the original two in primary chloroplasts. In secondary plastids, typically only the chloroplast, and sometimes its cell membrane and nucleus remain, forming a chloroplast with three or four membranes\u2014the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane.\nThe genes in the phagocytosed eukaryote's nucleus are often transferred to the secondary host's nucleus. Cryptomonads and chlorarachniophytes retain the phagocytosed eukaryote's nucleus, an object called a nucleomorph, located between the second and third membranes of the chloroplast.\nAll secondary chloroplasts come from green and red algae. No secondary chloroplasts from glaucophytes have been observed, probably because glaucophytes are relatively rare in nature, making them less likely to have been taken up by another eukaryote.\nStill other organisms, including the dinoflagellates \"Karlodinium\" and \"Karenia,\" obtained chloroplasts by engulfing an organism with a secondary plastid. These are called tertiary plastids.\nPrimary chloroplast lineages.\nAll primary chloroplasts belong to one of four chloroplast lineages\u2014the glaucophyte chloroplast lineage, the rhodophyte (\"red\") chloroplast lineage, and the chloroplastidan (\"green\") chloroplast lineage, the amoeboid \"Paulinella chromatophora\" lineage. The glaucophyte, rhodophyte, and chloroplastidian lineages are all descended from the same ancestral endosymbiotic event and are all within the group Archaeplastida.\nGlaucophyte chloroplasts.\nThe glaucophyte chloroplast group is the smallest of the three primary chloroplast lineages as there are only 25 described glaucophyte species. Glaucophytes diverged first before the red and green chloroplast lineages diverged. Because of this, they are sometimes considered intermediates between cyanobacteria and the red and green chloroplasts. This early divergence is supported by both phylogenetic studies and physical features present in glaucophyte chloroplasts and cyanobacteria, but not the red and green chloroplasts. First, glaucophyte chloroplasts have a peptidoglycan wall, a type of cell wall otherwise only in bacteria (including cyanobacteria). Second, glaucophyte chloroplasts contain concentric unstacked thylakoids which surround a carboxysome \u2013 an icosahedral structure that contains the enzyme RuBisCO responsible for carbon fixation. Third, starch created by the chloroplast is collected outside the chloroplast. Additionally, like cyanobacteria, both glaucophyte and rhodophyte thylakoids are studded with light collecting structures called phycobilisomes. \nRhodophyta (red chloroplasts).\nThe rhodophyte, or red algae, group is a large and diverse lineage. Rhodophyte chloroplasts are also called \"rhodoplasts\", literally \"red chloroplasts\". Rhodoplasts have a double membrane with an intermembrane space and phycobilin pigments organized into phycobilisomes on the thylakoid membranes, preventing their thylakoids from stacking. Some contain pyrenoids. Rhodoplasts have chlorophyll \"a\" and phycobilins for photosynthetic pigments; the phycobilin phycoerythrin is responsible for giving many red algae their distinctive red color. However, since they also contain the blue-green chlorophyll \"a\" and other pigments, many are reddish to purple from the combination. The red phycoerytherin pigment is an adaptation to help red algae catch more sunlight in deep water\u2014as such, some red algae that live in shallow water have less phycoerythrin in their rhodoplasts, and can appear more greenish. Rhodoplasts synthesize a form of starch called floridean starch, which collects into granules outside the rhodoplast, in the cytoplasm of the red alga.\nChloroplastida (green chloroplasts).\nThe chloroplastida group is another large, highly diverse lineage that includes both green algae and land plants. This group is also called Viridiplantae, which includes two core clades\u2014Chlorophyta and Streptophyta.\nMost green chloroplasts are green in color, though some aren't due to accessory pigments that override the green from chlorophylls, such as in the resting cells of \"Haematococcus pluvialis\". Green chloroplasts differ from glaucophyte and red algal chloroplasts in that they have lost their phycobilisomes, and contain chlorophyll \"b\". They have also lost the peptidoglycan wall between their double membrane, leaving an intermembrane space. Some plants have kept some genes required the synthesis of peptidoglycan, but have repurposed them for use in chloroplast division instead. Chloroplastida lineages also keep their starch \"inside\" their chloroplasts. In plants and some algae, the chloroplast thylakoids are arranged in grana stacks. Some green algal chloroplasts, as well as those of hornworts, contain a structure called a pyrenoid, that concentrate RuBisCO and CO in the chloroplast, functionally similar to the glaucophyte carboxysome. \nThere are some lineages of non-photosynthetic parasitic green algae that have lost their chloroplasts entirely, such as \"Prototheca,\" or have no chloroplast while retaining the separate chloroplast genome, as in \"Helicosporidium.\" Morphological and physiological similarities, as well as phylogenetics, confirm that these are lineages that ancestrally had chloroplasts but have since lost them.\n\"Paulinella chromatophora\".\nThe photosynthetic amoeboids in the genus \"Paulinella\u2014P. chromatophora, P. micropora,\" and marine \"P. longichromatophora\u2014\"have the only known independently evolved chloroplast, often called a chromatophore. While all other chloroplasts originate from a single ancient endosymbiotic event, \"Paulinella\" independently acquired an endosymbiotic cyanobacterium from the genus \"Synechococcus\" around 90 - 140 million years ago. Each \"Paulinella\" cell contains one or two sausage-shaped chloroplasts; they were first described in 1894 by German biologist Robert Lauterborn. \nThe chromatophore is highly reduced compared to its free-living cyanobacterial relatives and has limited functions. For example, it has a genome of about 1 million base pairs, one third the size of \"Synechococcus\" genomes, and only encodes around 850 proteins. However, this is still much larger than other chloroplast genomes, which are typically around 150,000 base pairs. Chromatophores have also transferred much less of their DNA to the nucleus of their hosts. About 0.3\u20130.8% of the nuclear DNA in \"Paulinella\" is from the chromatophore, compared with 11\u201314% from the chloroplast in plants. Similar to other chloroplasts, \"Paulinella\" provides specific proteins to the chromatophore using a specific targeting sequence. Because chromatophores are much younger compared to the canoncial chloroplasts, \"Paulinella chromatophora\" is studied to understand how early chloroplasts evolved.\nSecondary and tertiary chloroplast lineages.\nGreen algal derived chloroplasts.\nGreen algae have been taken up by many groups in three or four separate events. Primarily, secondary chloroplasts derived from green algae are in the euglenids and chlorarachniophytes. They are also found in one lineage of dinoflagellates and possibly the ancestor of the CASH lineage (cryptomonads, alveolates, stramenopiles and haptophytes) Many green algal derived chloroplasts contain pyrenoids, but unlike chloroplasts in their green algal ancestors, storage product collects in granules outside the chloroplast.\nEuglenophytes.\nThe euglenophytes are a group of common flagellated protists that contain chloroplasts derived from a green alga. Euglenophytes are the only group outside Diaphoretickes that have chloroplasts without performing kleptoplasty. Euglenophyte chloroplasts have three membranes. It is thought that the membrane of the primary endosymbiont host was lost (e.g. the green algal membrane), leaving the two cyanobacterial membranes and the secondary host's phagosomal membrane. Euglenophyte chloroplasts have a pyrenoid and thylakoids stacked in groups of three. The carbon fixed through photosynthesis is stored in the form of paramylon, which is contained in membrane-bound granules in the cytoplasm of the euglenophyte.\nChlorarachniophytes.\nChlorarachniophytes are a rare group of organisms that also contain chloroplasts derived from green algae, though their story is more complicated than that of the euglenophytes. The ancestor of chlorarachniophytes is thought to have been a eukaryote with a \"red\" algal derived chloroplast. It is then thought to have lost its first red algal chloroplast, and later engulfed a green alga, giving it its second, green algal derived chloroplast.\nChlorarachniophyte chloroplasts are bounded by four membranes, except near the cell membrane, where the chloroplast membranes fuse into a double membrane. Their thylakoids are arranged in loose stacks of three. Chlorarachniophytes have a form of polysaccharide called chrysolaminarin, which they store in the cytoplasm, often collected around the chloroplast pyrenoid, which bulges into the cytoplasm.\nChlorarachniophyte chloroplasts are notable because the green alga they are derived from has not been completely broken down\u2014its nucleus still persists as a nucleomorph found between the second and third chloroplast membranes\u2014the periplastid space, which corresponds to the green alga's cytoplasm.\nPrasinophyte-derived chloroplast.\nDinoflagellates in the genus \"Lepidodinium\" have lost their original peridinin chloroplast and replaced it with a green algal derived chloroplast (more specifically, a prasinophyte). \"Lepidodinium\" is the only dinoflagellate that has a chloroplast that's not from the rhodoplast lineage. The chloroplast is surrounded by two membranes and has no nucleomorph\u2014all the nucleomorph genes have been transferred to the dinophyte nucleus. The endosymbiotic event that led to this chloroplast was serial secondary endosymbiosis rather than tertiary endosymbiosis\u2014the endosymbiont was a green alga containing a primary chloroplast (making a secondary chloroplast).\nRed algal derived chloroplasts.\nSecondary chloroplasts derived from red algae appear to have only been taken up only once, which then diversified into a large group called chromists or chromalveolates. Today they are found in the haptophytes, cryptomonads, heterokonts, dinoflagellates and apicomplexans (the CASH lineage). Red algal secondary chloroplasts usually contain chlorophyll c and are surrounded by four membranes.\nHowever, chromist monophyly has been rejected, and it is considered more likely that some chromists acquired their plastids by incorporating another chromist instead of inheriting them from a common ancestor. Cryptophytinas seem to have acquired plastids from red algae, which were then transmitted from them to both the Ochrophyta and the Haptophyta, and then from these last to the Myzozoa.\nCryptophytes.\nCryptophytes, or cryptomonads, are a group of algae that contain a red-algal derived chloroplast. Cryptophyte chloroplasts contain a nucleomorph that superficially resembles that of the chlorarachniophytes. Cryptophyte chloroplasts have four membranes. The outermost membrane is continuous with the rough endoplasmic reticulum. They synthesize ordinary starch, which is stored in granules found in the periplastid space\u2014outside the original double membrane, in the place that corresponds to the ancestral red alga's cytoplasm. Inside cryptophyte chloroplasts is a pyrenoid and thylakoids in stacks of two. Cryptophyte chloroplasts do not have phycobilisomes, but they do have phycobilin pigments which they keep in the thylakoid space, rather than anchored on the outside of their thylakoid membranes.\nCryptophytes may have played a key role in the spreading of red algal based chloroplasts.\nHaptophytes.\nHaptophytes are similar and closely related to cryptophytes or heterokontophytes. Their chloroplasts lack a nucleomorph, their thylakoids are in stacks of three, and they synthesize chrysolaminarin sugar, which are stored in granules completely outside of the chloroplast, in the cytoplasm of the haptophyte.\nStramenopiles (heterokontophytes).\nThe stramenopiles, also known as heterokontophytes, are a very large and diverse group of eukaryotes. It inlcludes Ochrophyta\u2014which includes diatoms, brown algae (seaweeds), and golden algae (chrysophytes)\u2014 and Xanthophyceae (also called yellow-green algae).\nHeterokont chloroplasts are very similar to haptophyte chloroplasts. They have a pyrenoid, triplet thylakoids, and, with some exceptions, four layer plastidic envelope with the outermost membrane connected to the endoplasmic reticulum. Like haptophytes, stramenopiles store sugar in chrysolaminarin granules in the cytoplasm. Stramenopile chloroplasts contain chlorophyll \"a\" and, with a few exceptions, chlorophyll \"c\". They also have carotenoids which give them their many colors.\nApicomplexans, chromerids, and dinophytes.\nThe alveolates are a major clade of unicellular eukaryotes of both autotrophic and heterotrophic members. Many members contain a red-algal derived plastid. One notable characteristic of this diverse group is the frequent loss of photosynthesis. However, a majority of these heterotrophs continue to process a non-photosynthetic plastid.\nApicomplexans.\nApicomplexans are a group of alveolates. Like the helicosproidia, they're parasitic, and have a nonphotosynthetic chloroplast. They were once thought to be related to the helicosproidia, but it is now known that the helicosproida are green algae rather than part of the CASH lineage. The apicomplexans include \"Plasmodium\", the malaria parasite. Many apicomplexans keep a vestigial red algal derived chloroplast called an apicoplast, which they inherited from their ancestors. Apicoplasts have lost all photosynthetic function, and contain no photosynthetic pigments or true thylakoids. They are bounded by four membranes, but the membranes are not connected to the endoplasmic reticulum. Other apicomplexans like \"Cryptosporidium\" have lost the chloroplast completely. Apicomplexans store their energy in amylopectin granules that are located in their cytoplasm, even though they are nonphotosynthetic.\nThe fact that apicomplexans still keep their nonphotosynthetic chloroplast around demonstrates how the chloroplast carries out important functions other than photosynthesis. Plant chloroplasts provide plant cells with many important things besides sugar, and apicoplasts are no different\u2014they synthesize fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters, and carry out part of the heme pathway. The most important apicoplast function is isopentenyl pyrophosphate synthesis\u2014in fact, apicomplexans die when something interferes with this apicoplast function, and when apicomplexans are grown in an isopentenyl pyrophosphate-rich medium, they dump the organelle.\nChromerids.\nThe Chromerida is a newly discovered group of algae from Australian corals which comprises some close photosynthetic relatives of the apicomplexans. The first member, \"Chromera velia\", was discovered and first isolated in 2001. The discovery of \"Chromera velia\" with similar structure to the apicomplexans, provides an important link in the evolutionary history of the apicomplexans and dinophytes. Their plastids have four membranes, lack chlorophyll c and use the type II form of RuBisCO obtained from a horizontal transfer event.\nDinoflagellates.\nThe dinoflagellates are yet another very large and diverse group, around half of which are at least partially photosynthetic (i.e. mixotrophic). Dinoflagellate chloroplasts have relatively complex history. Most dinoflagellate chloroplasts are secondary red algal derived chloroplasts. Many dinoflagellates have lost the chloroplast (becoming nonphotosynthetic), some of these have replaced it though \"tertiary\" endosymbiosis. Others replaced their original chloroplast with a green algal derived chloroplast. The peridinin chloroplast is thought to be the dinophytes' \"original\" chloroplast, which has been lost, reduced, replaced, or has company in several other dinophyte lineages.\nThe most common dinophyte chloroplast is the peridinin-type chloroplast, characterized by the carotenoid pigment peridinin in their chloroplasts, along with chlorophyll \"a\" and chlorophyll \"c\"2. Peridinin is not found in any other group of chloroplasts. The peridinin chloroplast is bounded by three membranes (occasionally two), having lost the red algal endosymbiont's original cell membrane. The outermost membrane is not connected to the endoplasmic reticulum. They contain a pyrenoid, and have triplet-stacked thylakoids. Starch is found outside the chloroplast. Peridinin chloroplasts also have DNA that is highly reduced and fragmented into many small circles. Most of the genome has migrated to the nucleus, and only critical photosynthesis-related genes remain in the chloroplast. \nMost dinophyte chloroplasts contain form II RuBisCO, at least the photosynthetic pigments chlorophyll \"a\", chlorophyll \"c2\", \"beta\"-carotene, and at least one dinophyte-unique xanthophyll (peridinin, dinoxanthin, or diadinoxanthin), giving many a golden-brown color. All dinophytes store starch in their cytoplasm, and most have chloroplasts with thylakoids arranged in stacks of three.\nHaptophyte-derived chloroplasts.\nThe fucoxanthin dinophyte lineages (including \"Karlodinium\" and \"Karenia\") lost their original red algal derived chloroplast, and replaced it with a new chloroplast derived from a haptophyte endosymbiont, making these tertiary plastids. \"Karlodinium\" and \"Karenia\" probably took up different endosymbionts. Because the haptophyte chloroplast has four membranes, tertiary endosymbiosis would be expected to create a six membraned chloroplast, adding the haptophyte's cell membrane and the dinophyte's phagosomal vacuole. However, the haptophyte was heavily reduced, stripped of a few membranes and its nucleus, leaving only its chloroplast (with its original double membrane), and possibly one or two additional membranes around it.\nFucoxanthin-containing chloroplasts are characterized by having the pigment fucoxanthin (actually 19\u2032-hexanoyloxy-fucoxanthin and/or 19\u2032-butanoyloxy-fucoxanthin) and no peridinin. Fucoxanthin is also found in haptophyte chloroplasts, providing evidence of ancestry.\nDiatom-derived chloroplasts.\nSome dinophytes, like \"Kryptoperidinium\" and \"Durinskia\", have a diatom (heterokontophyte)-derived chloroplast. These chloroplasts are bounded by up to \"five\" membranes, (depending on whether the entire diatom endosymbiont is counted as the chloroplast, or just the red algal derived chloroplast inside it). The diatom endosymbiont has been reduced relatively little\u2014it still retains its original mitochondria, and has endoplasmic reticulum, ribosomes, a nucleus, and of course, red algal derived chloroplasts\u2014practically a complete cell, all inside the host's endoplasmic reticulum lumen. However the diatom endosymbiont can't store its own food\u2014its storage polysaccharide is found in granules in the dinophyte host's cytoplasm instead. The diatom endosymbiont's nucleus is present, but it probably can't be called a nucleomorph because it shows no sign of genome reduction, and might have even been \"expanded\". Diatoms have been engulfed by dinoflagellates at least three times.\nThe diatom endosymbiont is bounded by a single membrane, inside it are chloroplasts with four membranes. Like the diatom endosymbiont's diatom ancestor, the chloroplasts have triplet thylakoids and pyrenoids.\nIn some of these genera, the diatom endosymbiont's chloroplasts aren't the only chloroplasts in the dinophyte. The original three-membraned peridinin chloroplast is still around, converted to an eyespot.\nKleptoplasty.\nIn some groups of mixotrophic protists, like some dinoflagellates (e.g. \"Dinophysis\"), chloroplasts are separated from a captured alga and used temporarily. These klepto chloroplasts may only have a lifetime of a few days and are then replaced.\nCryptophyte-derived dinophyte chloroplast.\nMembers of the genus \"Dinophysis\" have a phycobilin-containing chloroplast taken from a cryptophyte. However, the cryptophyte is not an endosymbiont\u2014only the chloroplast seems to have been taken, and the chloroplast has been stripped of its nucleomorph and outermost two membranes, leaving just a two-membraned chloroplast. Cryptophyte chloroplasts require their nucleomorph to maintain themselves, and \"Dinophysis\" species grown in cell culture alone cannot survive, so it is possible (but not confirmed) that the \"Dinophysis\" chloroplast is a kleptoplast\u2014if so, \"Dinophysis\" chloroplasts wear out and \"Dinophysis\" species must continually engulf cryptophytes to obtain new chloroplasts to replace the old ones.\nChloroplast DNA.\nChloroplasts, like other endosymbiotic organelles, contain a genome separate from that in the cell nucleus. The existence of chloroplast DNA (cpDNA) was identified biochemically in 1959, and confirmed by electron microscopy in 1962. The discoveries that the chloroplast contains ribosomes and performs protein synthesis revealed that the chloroplast is genetically semi-autonomous. Chloroplast DNA was first sequenced in 1986. Since then, hundreds of chloroplast genomes from various species have been sequenced, but they are mostly those of land plants and green algae\u2014glaucophytes, red algae, and other algal groups are extremely underrepresented, potentially introducing some bias in views of \"typical\" chloroplast DNA structure and content.\nMolecular structure.\nWith few exceptions, most chloroplasts have their entire chloroplast genome combined into a single large circular DNA molecule, typically 120,000\u2013170,000 base pairs long and a mass of about 80\u2013130\u00a0million daltons. While chloroplast genomes can almost always be assembled into a circular map, the physical DNA molecules inside cells take on a variety of linear and branching forms. New chloroplasts may contain up to 100 copies of their genome, though the number of copies decreases to about 15\u201320 as the chloroplasts age.\nChloroplast DNA is usually condensed into nucleoids, which can contain multiple copies of the chloroplast genome. Many nucleoids can be found in each chloroplast. In primitive red algae, the chloroplast DNA nucleoids are clustered in the center of the chloroplast, while in green plants and green algae, the nucleoids are dispersed throughout the stroma. Chloroplast DNA is not associated with true histones, proteins that are used to pack DNA molecules tightly in eukaryote nuclei. Though in red algae, similar proteins tightly pack each chloroplast DNA ring in a nucleoid.\nMany chloroplast genomes contain two inverted repeats, which separate a long single copy section (LSC) from a short single copy section (SSC). A given pair of inverted repeats are rarely identical, but they are always very similar to each other, apparently resulting from concerted evolution. The inverted repeats vary wildly in length, ranging from 4,000 to 25,000 base pairs long each and containing as few as four or as many as over 150 genes. The inverted repeat regions are highly conserved in land plants, and accumulate few mutations.\nSimilar inverted repeats exist in the genomes of cyanobacteria and the other two chloroplast lineages (glaucophyta and rhodophyceae), suggesting that they predate the chloroplast. Some chloroplast genomes have since lost or flipped the inverted repeats (making them direct repeats). It is possible that the inverted repeats help stabilize the rest of the chloroplast genome, as chloroplast genomes which have lost some of the inverted repeat segments tend to get rearranged more.\nDNA repair and replication.\nIn chloroplasts of the moss \"Physcomitrella patens\", the DNA mismatch repair protein Msh1 interacts with the recombinational repair proteins RecA and RecG to maintain chloroplast genome stability. In chloroplasts of the plant \"Arabidopsis thaliana\" the RecA protein maintains the integrity of the chloroplast's DNA by a process that likely involves the recombinational repair of DNA damage.\nThe mechanism for chloroplast DNA (cpDNA) replication has not been conclusively determined, but two main models have been proposed. Scientists have attempted to observe chloroplast replication via electron microscopy since the 1970s. The results of the microscopy experiments led to the idea that chloroplast DNA replicates using a double displacement loop (D-loop). As the D-loop moves through the circular DNA, it adopts a theta intermediary form, also known as a Cairns replication intermediate, and completes replication with a rolling circle mechanism. Transcription starts at specific points of origin. Multiple replication forks open up, allowing replication machinery to transcribe the DNA. As replication continues, the forks grow and eventually converge. The new cpDNA structures separate, creating daughter cpDNA chromosomes.\nIn addition to the early microscopy experiments, this model is also supported by the amounts of deamination seen in cpDNA. Deamination occurs when an amino group is lost and is a mutation that often results in base changes. When adenine is deaminated, it becomes hypoxanthine. Hypoxanthine can bind to cytosine, and when the XC base pair is replicated, it becomes a GC (thus, an A \u2192 G base change).\nIn cpDNA, there are several A \u2192 G deamination gradients. DNA becomes susceptible to deamination events when it is single stranded. When replication forks form, the strand not being copied is single stranded, and thus at risk for A \u2192 G deamination. Therefore, gradients in deamination indicate that replication forks were most likely present and the direction that they initially opened (the highest gradient is most likely nearest the start site because it was single stranded for the longest amount of time). This mechanism is still the leading theory today; however, a second theory suggests that most cpDNA is actually linear and replicates through homologous recombination. It further contends that only a minority of the genetic material is kept in circular chromosomes while the rest is in branched, linear, or other complex structures.\nOne of competing model for cpDNA replication asserts that most cpDNA is linear and participates in homologous recombination and replication structures similar to the linear and circular DNA structures of bacteriophage T4. It has been established that some plants have linear cpDNA, such as maize, and that more species still contain complex structures that scientists do not yet understand. When the original experiments on cpDNA were performed, scientists did notice linear structures; however, they attributed these linear forms to broken circles. If the branched and complex structures seen in cpDNA experiments are real and not artifacts of concatenated circular DNA or broken circles, then a D-loop mechanism of replication is insufficient to explain how those structures would replicate. At the same time, homologous recombination does not expand the multiple A --&gt; G gradients seen in plastomes. Because of the failure to explain the deamination gradient as well as the numerous plant species that have been shown to have circular cpDNA, the predominant theory continues to hold that most cpDNA is circular and most likely replicates via a D loop mechanism.\nGene content and protein synthesis.\nThe ancestral cyanobacteria that led to chloroplasts probably had a genome that contained over 3000 genes, but only approximately 100 genes remain in contemporary chloroplast genomes. These genes code for a variety of things, mostly to do with the protein pipeline and photosynthesis. As in prokaryotes, genes in chloroplast DNA are organized into operons. Unlike prokaryotic DNA molecules, chloroplast DNA molecules contain introns (plant mitochondrial DNAs do too, but not human mtDNAs).\nAmong land plants, the contents of the chloroplast genome are fairly similar.\nChloroplast genome reduction and gene transfer.\nOver time, many parts of the chloroplast genome were transferred to the nuclear genome of the host, a process called \"endosymbiotic gene transfer\". As a result, the chloroplast genome is heavily reduced compared to that of free-living cyanobacteria. Chloroplasts may contain 60\u2013100 genes whereas cyanobacteria often have more than 1500 genes in their genome. Recently, a plastid without a genome was found, demonstrating chloroplasts can lose their genome during endosymbiotic the gene transfer process.\nEndosymbiotic gene transfer is how we know about the lost chloroplasts in many CASH lineages. Even if a chloroplast is eventually lost, the genes it donated to the former host's nucleus persist, providing evidence for the lost chloroplast's existence. For example, while diatoms (a heterokontophyte) now have a red algal derived chloroplast, the presence of many green algal genes in the diatom nucleus provide evidence that the diatom ancestor had a green algal derived chloroplast at some point, which was subsequently replaced by the red chloroplast.\nIn land plants, some 11\u201314% of the DNA in their nuclei can be traced back to the chloroplast, up to 18% in \"Arabidopsis\", corresponding to about 4,500 protein-coding genes. There have been a few recent transfers of genes from the chloroplast DNA to the nuclear genome in land plants.\nOf the approximately 3000 proteins found in chloroplasts, some 95% of them are encoded by nuclear genes. Many of the chloroplast's protein complexes consist of subunits from both the chloroplast genome and the host's nuclear genome. As a result, protein synthesis must be coordinated between the chloroplast and the nucleus. The chloroplast is mostly under nuclear control, though chloroplasts can also give out signals regulating gene expression in the nucleus, called \"retrograde signaling\". Recent research indicates that parts of the retrograde signaling network once considered characteristic for land plants emerged already in an algal progenitor, integrating into co-expressed cohorts of genes in the closest algal relatives of land plants.\nProtein synthesis.\nProtein synthesis within chloroplasts relies on two RNA polymerases. One is coded by the chloroplast DNA, the other is of nuclear origin. The two RNA polymerases may recognize and bind to different kinds of promoters within the chloroplast genome. The ribosomes in chloroplasts are similar to bacterial ribosomes.\nProtein targeting and import.\nBecause so many chloroplast genes have been moved to the nucleus, many proteins that would originally have been translated in the chloroplast are now synthesized in the cytoplasm of the plant cell. These proteins must be directed back to the chloroplast, and imported through at least two chloroplast membranes.\nCuriously, around half of the protein products of transferred genes aren't even targeted back to the chloroplast. Many became exaptations, taking on new functions like participating in cell division, protein routing, and even disease resistance. A few chloroplast genes found new homes in the mitochondrial genome\u2014most became nonfunctional pseudogenes, though a few tRNA genes still work in the mitochondrion. Some transferred chloroplast DNA protein products get directed to the secretory pathway, though many secondary plastids are bounded by an outermost membrane derived from the host's cell membrane, and therefore topologically outside of the cell because to reach the chloroplast from the cytosol, the cell membrane must be crossed, which signifies entrance into the extracellular space. In those cases, chloroplast-targeted proteins do initially travel along the secretory pathway.\nBecause the cell acquiring a chloroplast already had mitochondria (and peroxisomes, and a cell membrane for secretion), the new chloroplast host had to develop a unique protein targeting system to avoid having chloroplast proteins being sent to the wrong organelle.\nIn most, but not all cases, nuclear-encoded chloroplast proteins are translated with a \"cleavable transit peptide\" that's added to the N-terminus of the protein precursor. Sometimes the transit sequence is found on the C-terminus of the protein, or within the functional part of the protein.\nTransport proteins and membrane translocons.\nAfter a chloroplast polypeptide is synthesized on a ribosome in the cytosol, an enzyme specific to chloroplast proteins phosphorylates, or adds a phosphate group to many (but not all) of them in their transit sequences.\nPhosphorylation helps many proteins bind the polypeptide, keeping it from folding prematurely. This is important because it prevents chloroplast proteins from assuming their active form and carrying out their chloroplast functions in the wrong place\u2014the cytosol. At the same time, they have to keep just enough shape so that they can be recognized by the chloroplast. These proteins also help the polypeptide get imported into the chloroplast.\nFrom here, chloroplast proteins bound for the stroma must pass through two protein complexes\u2014the TOC complex, or translocon on the outer chloroplast membrane\", and the TIC translocon, or translocon on the inner chloroplast membrane translocon\". Chloroplast polypeptide chains probably often travel through the two complexes at the same time, but the TIC complex can also retrieve preproteins lost in the intermembrane space.\nStructure.\nIn land plants, chloroplasts are generally lens-shaped, 3\u201310 \u03bcm in diameter and 1\u20133 \u03bcm thick. Corn seedling chloroplasts are \u224820 \u03bcm3 in volume. Greater diversity in chloroplast shapes exists among the algae, which often contain a single chloroplast that can be shaped like a net (e.g., \"Oedogonium\"), a cup (e.g., \"Chlamydomonas\"), a ribbon-like spiral around the edges of the cell (e.g., \"Spirogyra\"), or slightly twisted bands at the cell edges (e.g., \"Sirogonium\"). Some algae have two chloroplasts in each cell; they are star-shaped in \"Zygnema\", or may follow the shape of half the cell in order Desmidiales. In some algae, the chloroplast takes up most of the cell, with pockets for the nucleus and other organelles, for example, some species of \"Chlorella\" have a cup-shaped chloroplast that occupies much of the cell.\nAll chloroplasts have at least three membrane systems\u2014the outer chloroplast membrane, the inner chloroplast membrane, and the thylakoid system. The two innermost lipid-bilayer membranes that surround all chloroplasts correspond to the outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall, and not the phagosomal membrane from the host, which was probably lost. Chloroplasts that are the product of secondary endosymbiosis may have additional membranes surrounding these three. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast's volume, and in which the thylakoid system floats.\nThere are some common misconceptions about the outer and inner chloroplast membranes. The fact that chloroplasts are surrounded by a double membrane is often cited as evidence that they are the descendants of endosymbiotic cyanobacteria. This is often interpreted as meaning the outer chloroplast membrane is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium\u2014which is not true\u2014both chloroplast membranes are homologous to the cyanobacterium's original double membranes.\nThe chloroplast double membrane is also often compared to the mitochondrial double membrane. This is not a valid comparison\u2014the inner mitochondria membrane is used to run proton pumps and carry out oxidative phosphorylation across to generate ATP energy. The only chloroplast structure that can considered analogous to it is the internal thylakoid system. Even so, in terms of \"in-out\", the direction of chloroplast H ion flow is in the opposite direction compared to oxidative phosphorylation in mitochondria. In addition, in terms of function, the inner chloroplast membrane, which regulates metabolite passage and synthesizes some materials, has no counterpart in the mitochondrion.\nOuter chloroplast membrane.\nThe outer chloroplast membrane is a semi-porous membrane that small molecules and ions can easily diffuse across. However, it is not permeable to larger proteins, so chloroplast polypeptides being synthesized in the cell cytoplasm must be transported across the outer chloroplast membrane by the TOC complex, or \"translocon on the outer chloroplast\" membrane.\nThe chloroplast membranes sometimes protrude out into the cytoplasm, forming a stromule, or stroma-containing tubule. Stromules are very rare in chloroplasts, and are much more common in other plastids like chromoplasts and amyloplasts in petals and roots, respectively. They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and tangled with the endoplasmic reticulum. When they were first observed in 1962, some plant biologists dismissed the structures as artifactual, claiming that stromules were just oddly shaped chloroplasts with constricted regions or dividing chloroplasts. However, there is a growing body of evidence that stromules are functional, integral features of plant cell plastids, not merely artifacts.\nIntermembrane space and peptidoglycan wall.\nUsually, a thin intermembrane space about 10\u201320 nanometers thick exists between the outer and inner chloroplast membranes.\nGlaucophyte algal chloroplasts have a peptidoglycan layer between the chloroplast membranes. It corresponds to the peptidoglycan cell wall of their cyanobacterial ancestors, which is located between their two cell membranes. These chloroplasts are called \"muroplasts\" (from Latin \"mura\", meaning \"wall\"). Other chloroplasts were assumed to have lost the cyanobacterial wall, leaving an intermembrane space between the two chloroplast envelope membranes, but has since been found also in moss, lycophytes and ferns.\nInner chloroplast membrane.\nThe inner chloroplast membrane borders the stroma and regulates passage of materials in and out of the chloroplast. After passing through the TOC complex in the outer chloroplast membrane, polypeptides must pass through the TIC complex \"(translocon on the inner chloroplast membrane)\" which is located in the inner chloroplast membrane.\nIn addition to regulating the passage of materials, the inner chloroplast membrane is where fatty acids, lipids, and carotenoids are synthesized.\nPeripheral reticulum.\nSome chloroplasts contain a structure called the chloroplast peripheral reticulum. It is often found in the chloroplasts of plants, though it has also been found in some angiosperms, and even some gymnosperms. The chloroplast peripheral reticulum consists of a maze of membranous tubes and vesicles continuous with the inner chloroplast membrane that extends into the internal stromal fluid of the chloroplast. Its purpose is thought to be to increase the chloroplast's surface area for cross-membrane transport between its stroma and the cell cytoplasm. The small vesicles sometimes observed may serve as transport vesicles to shuttle stuff between the thylakoids and intermembrane space.\nStroma.\nThe protein-rich, alkaline, aqueous fluid within the inner chloroplast membrane and outside of the thylakoid space is called the stroma, which corresponds to the cytosol of the original cyanobacterium. Nucleoids of chloroplast DNA, chloroplast ribosomes, the thylakoid system with plastoglobuli, starch granules, and many proteins can be found floating around in it. The Calvin cycle, which fixes CO into G3P takes place in the stroma.\nChloroplast ribosomes.\nChloroplasts have their own ribosomes, which they use to synthesize a small fraction of their proteins. Chloroplast ribosomes are about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm). They take mRNAs transcribed from the chloroplast DNA and translate them into protein. While similar to bacterial ribosomes, chloroplast translation is more complex than in bacteria, so chloroplast ribosomes include some chloroplast-unique features.\nSmall subunit ribosomal RNAs in several Chlorophyta and euglenid chloroplasts lack motifs for Shine-Dalgarno sequence recognition, which is considered essential for translation initiation in most chloroplasts and prokaryotes. Such loss is also rarely observed in other plastids and prokaryotes. An additional 4.5S rRNA with homology to the 3' tail of 23S is found in \"higher\" plants.\nPlastoglobuli.\nPlastoglobuli (singular \"plastoglobulus\", sometimes spelled \"plastoglobule(s)\"), are spherical bubbles of lipids and proteins about 45\u201360 nanometers across. They are surrounded by a lipid monolayer. Plastoglobuli are found in all chloroplasts, but become more common when the chloroplast is under oxidative stress, or when it ages and transitions into a gerontoplast. Plastoglobuli also exhibit a greater size variation under these conditions. They are also common in etioplasts, but decrease in number as the etioplasts mature into chloroplasts.\nPlastoglobuli contain both structural proteins and enzymes involved in lipid synthesis and metabolism. They contain many types of lipids including plastoquinone, vitamin E, carotenoids and chlorophylls.\nPlastoglobuli were once thought to be free-floating in the stroma, but it is now thought that they are permanently attached either to a thylakoid or to another plastoglobulus attached to a thylakoid, a configuration that allows a plastoglobulus to exchange its contents with the thylakoid network. In normal green chloroplasts, the vast majority of plastoglobuli occur singularly, attached directly to their parent thylakoid. In old or stressed chloroplasts, plastoglobuli tend to occur in linked groups or chains, still always anchored to a thylakoid.\nPlastoglobuli form when a bubble appears between the layers of the lipid bilayer of the thylakoid membrane, or bud from existing plastoglobuli\u2014though they never detach and float off into the stroma. Practically all plastoglobuli form on or near the highly curved edges of the thylakoid disks or sheets. They are also more common on stromal thylakoids than on granal ones.\nStarch granules.\nStarch granules are very common in chloroplasts, typically taking up 15% of the organelle's volume, though in some other plastids like amyloplasts, they can be big enough to distort the shape of the organelle. Starch granules are simply accumulations of starch in the stroma, and are not bounded by a membrane.\nStarch granules appear and grow throughout the day, as the chloroplast synthesizes sugars, and are consumed at night to fuel respiration and continue sugar export into the phloem, though in mature chloroplasts, it is rare for a starch granule to be completely consumed or for a new granule to accumulate.\nStarch granules vary in composition and location across different chloroplast lineages. In red algae, starch granules are found in the cytoplasm rather than in the chloroplast. In plants, mesophyll chloroplasts, which do not synthesize sugars, lack starch granules.\nRuBisCO.\nThe chloroplast stroma contains many proteins, though the most common and important is RuBisCO, which is probably also the most abundant protein on the planet. RuBisCO is the enzyme that fixes CO into sugar molecules. In plants, RuBisCO is abundant in all chloroplasts, though in plants, it is confined to the bundle sheath chloroplasts, where the Calvin cycle is carried out in plants.\nPyrenoids.\nThe chloroplasts of some hornworts and algae contain structures called pyrenoids. They are not found in higher plants. Pyrenoids are roughly spherical and highly refractive bodies which are a site of starch accumulation in plants that contain them. They consist of a matrix opaque to electrons, surrounded by two hemispherical starch plates. The starch is accumulated as the pyrenoids mature. In algae with carbon concentrating mechanisms, the enzyme RuBisCO is found in the pyrenoids. Starch can also accumulate around the pyrenoids when CO2 is scarce. Pyrenoids can divide to form new pyrenoids, or be produced \"de novo\".\nThylakoid system.\nThylakoids (sometimes spelled \"thylako\u00efds\"), are small interconnected sacks which contain the membranes that the light reactions of photosynthesis take place on. The word \"thylakoid\" comes from the Greek word \"thylakos\" which means \"sack\".\nSuspended within the chloroplast stroma is the thylakoid system, a highly dynamic collection of membranous sacks called thylakoids where chlorophyll is found and the light reactions of photosynthesis happen.\nIn most vascular plant chloroplasts, the thylakoids are arranged in stacks called grana, though in certain plant chloroplasts and some algal chloroplasts, the thylakoids are free floating.\nThylakoid structure.\nUsing a light microscope, it is just barely possible to see tiny green granules\u2014which were named grana. With electron microscopy, it became possible to see the thylakoid system in more detail, revealing it to consist of stacks of flat thylakoids which made up the grana, and long interconnecting stromal thylakoids which linked different grana.\nIn the transmission electron microscope, thylakoid membranes appear as alternating light-and-dark bands, 8.5 nanometers thick.\nThe three-dimensional structure of the thylakoid membrane system has been disputed. Many models have been proposed, the most prevalent being the helical model, in which granum stacks of thylakoids are wrapped by helical stromal thylakoids. Another model known as the 'bifurcation model', which was based on the first electron tomography study of plant thylakoid membranes, depicts the stromal membranes as wide lamellar sheets perpendicular to the grana columns which bifurcates into multiple parallel discs forming the granum-stroma assembly. The helical model was supported by several additional works, but ultimately it was determined in 2019 that features from both the helical and bifurcation models are consolidated by newly discovered left-handed helical membrane junctions. Likely for ease, the thylakoid system is still commonly depicted by older \"hub and spoke\" models where the grana are connected to each other by tubes of stromal thylakoids.\nGrana consist of a stacks of flattened circular granal thylakoids that resemble pancakes. Each granum can contain anywhere from two to a hundred thylakoids, though grana with 10\u201320 thylakoids are most common. Wrapped around the grana are multiple parallel right-handed helical stromal thylakoids, also known as frets or lamellar thylakoids. The helices ascend at an angle of ~20\u00b0, connecting to each granal thylakoid at a bridge-like slit junction.\nThe stroma lamellae extend as large sheets perpendicular to the grana columns. These sheets are connected to the right-handed helices either directly or through bifurcations that form left-handed helical membrane surfaces. The left-handed helical surfaces have a similar tilt angle to the right-handed helices (~20\u00b0), but \u00bc the pitch. Approximately 4 left-handed helical junctions are present per granum, resulting in a pitch-balanced array of right- and left-handed helical membrane surfaces of different radii and pitch that consolidate the network with minimal surface and bending energies. While different parts of the thylakoid system contain different membrane proteins, the thylakoid membranes are continuous and the thylakoid space they enclose form a single continuous labyrinth.\nThylakoid composition.\nEmbedded in the thylakoid membranes are important protein complexes which carry out the light reactions of photosynthesis. Photosystem II and photosystem I contain light-harvesting complexes with chlorophyll and carotenoids that absorb light energy and use it to energize electrons. Molecules in the thylakoid membrane use the energized electrons to pump hydrogen ions into the thylakoid space, decreasing the pH and turning it acidic. ATP synthase is a large protein complex that harnesses the concentration gradient of the hydrogen ions in the thylakoid space to generate ATP energy as the hydrogen ions flow back out into the stroma\u2014much like a dam turbine.\nThere are two types of thylakoids\u2014granal thylakoids, which are arranged in grana, and stromal thylakoids, which are in contact with the stroma. Granal thylakoids are pancake-shaped circular disks about 300\u2013600 nanometers in diameter. Stromal thylakoids are helicoid sheets that spiral around grana. The flat tops and bottoms of granal thylakoids contain only the relatively flat photosystem II protein complex. This allows them to stack tightly, forming grana with many layers of tightly appressed membrane, called granal membrane, increasing stability and surface area for light capture.\nIn contrast, photosystem I and ATP synthase are large protein complexes which jut out into the stroma. They can't fit in the appressed granal membranes, and so are found in the stromal thylakoid membrane\u2014the edges of the granal thylakoid disks and the stromal thylakoids. These large protein complexes may act as spacers between the sheets of stromal thylakoids.\nThe number of thylakoids and the total thylakoid area of a chloroplast is influenced by light exposure. Shaded chloroplasts contain larger and more grana with more thylakoid membrane area than chloroplasts exposed to bright light, which have smaller and fewer grana and less thylakoid area. Thylakoid extent can change within minutes of light exposure or removal.\nPigments and chloroplast colors.\nInside the photosystems embedded in chloroplast thylakoid membranes are various photosynthetic pigments, which absorb and transfer light energy. The types of pigments found are different in various groups of chloroplasts, and are responsible for a wide variety of chloroplast colorations. Other plastid types, such as the leucoplast and the chromoplast, contain little chlorophyll and do not carry out photosynthesis.\n box-shadow: 1px 1px 3px rgba(0,0,0,0.2);\"&gt;\nPaper chromatography of some spinach leaf extract shows the various pigments present in their chloroplasts.\nXanthophylls\nChlorophyll \"a\"\nChlorophyll \"b\"\nChlorophylls.\nChlorophyll \"a\" is found in all chloroplasts, as well as their cyanobacterial ancestors. Chlorophyll \"a\" is a blue-green pigment partially responsible for giving most cyanobacteria and chloroplasts their color. Other forms of chlorophyll exist, such as the accessory pigments chlorophyll \"b\", chlorophyll \"c\", chlorophyll \"d\", and chlorophyll \"f\".\nChlorophyll \"b\" is an olive green pigment found only in the chloroplasts of plants, green algae, any secondary chloroplasts obtained through the secondary endosymbiosis of a green alga, and a few cyanobacteria. It is the chlorophylls \"a\" and \"b\" together that make most plant and green algal chloroplasts green.\nChlorophyll \"c\" is mainly found in secondary endosymbiotic chloroplasts that originated from a red alga, although it is not found in chloroplasts of red algae themselves. Chlorophyll \"c\" is also found in some green algae and cyanobacteria.\nChlorophylls \"d\" and \"f\" are pigments found only in some cyanobacteria.\nCarotenoids.\nIn addition to chlorophylls, another group of yellow\u2013orange pigments called carotenoids are also found in the photosystems. There are about thirty photosynthetic carotenoids. They help transfer and dissipate excess energy, and their bright colors sometimes override the chlorophyll green, like during the fall, when the leaves of some land plants change color. \u03b2-carotene is a bright red-orange carotenoid found in nearly all chloroplasts, like chlorophyll \"a\". Xanthophylls, especially the orange-red zeaxanthin, are also common. Many other forms of carotenoids exist that are only found in certain groups of chloroplasts.\nPhycobilins.\nPhycobilins are a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts. Phycobilins come in all colors, though phycoerytherin is one of the pigments that makes many red algae red. Phycobilins often organize into relatively large protein complexes about 40 nanometers across called phycobilisomes. Like photosystem I and ATP synthase, phycobilisomes jut into the stroma, preventing thylakoid stacking in red algal chloroplasts. Cryptophyte chloroplasts and some cyanobacteria don't have their phycobilin pigments organized into phycobilisomes, and keep them in their thylakoid space instead.\nSpecialized chloroplasts in plants.\nTo fix carbon dioxide into sugar molecules in the process of photosynthesis, chloroplasts use an enzyme called RuBisCO. RuBisCO has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, RuBisCO starts accidentally adding oxygen to sugar precursors. This has the result of ATP energy being wasted and being released, all with no sugar being produced. This is a big problem, since O is produced by the initial light reactions of photosynthesis, causing issues down the line in the Calvin cycle which uses RuBisCO.\nplants evolved a way to solve this\u2014by spatially separating the light reactions and the Calvin cycle. The light reactions, which store light energy in ATP and NADPH, are done in the mesophyll cells of a leaf. The Calvin cycle, which uses the stored energy to make sugar using RuBisCO, is done in the bundle sheath cells, a layer of cells surrounding a vein in a leaf.\nAs a result, chloroplasts in mesophyll cells and bundle sheath cells are specialized for each stage of photosynthesis. In mesophyll cells, chloroplasts are specialized for the light reactions, so they lack RuBisCO, and have normal grana and thylakoids, which they use to make ATP and NADPH, as well as oxygen. They store in a four-carbon compound, which is why the process is called \" photosynthesis\". The four-carbon compound is then transported to the bundle sheath chloroplasts, where it drops off and returns to the mesophyll. Bundle sheath chloroplasts do not carry out the light reactions, preventing oxygen from building up in them and disrupting RuBisCO activity. Because of this, they lack thylakoids organized into grana stacks\u2014though bundle sheath chloroplasts still have free-floating thylakoids in the stroma where they still carry out cyclic electron flow, a light-driven method of synthesizing ATP to power the Calvin cycle without generating oxygen. They lack photosystem II, and only have photosystem I\u2014the only protein complex needed for cyclic electron flow. Because the job of bundle sheath chloroplasts is to carry out the Calvin cycle and make sugar, they often contain large starch grains.\nBoth types of chloroplast contain large amounts of chloroplast peripheral reticulum, which they use to get more surface area to transport stuff in and out of them. Mesophyll chloroplasts have a little more peripheral reticulum than bundle sheath chloroplasts.\nFunction and chemistry.\nGuard cell chloroplasts.\nUnlike most epidermal cells, the guard cells of plant stomata contain relatively well-developed chloroplasts. However, exactly what they do is controversial.\nPlant innate immunity.\nPlants lack specialized immune cells\u2014all plant cells participate in the plant immune response. Chloroplasts, along with the nucleus, cell membrane, and endoplasmic reticulum, are key players in pathogen defense. Due to its role in a plant cell's immune response, pathogens frequently target the chloroplast.\nPlants have two main immune responses\u2014the hypersensitive response, in which infected cells seal themselves off and undergo programmed cell death, and systemic acquired resistance, where infected cells release signals warning the rest of the plant of a pathogen's presence.\nChloroplasts stimulate both responses by purposely damaging their photosynthetic system, producing reactive oxygen species. High levels of reactive oxygen species will cause the hypersensitive response. The reactive oxygen species also directly kill any pathogens within the cell. Lower levels of reactive oxygen species initiate systemic acquired resistance, triggering defense-molecule production in the rest of the plant.\nIn some plants, chloroplasts are known to move closer to the infection site and the nucleus during an infection.\nChloroplasts can serve as cellular sensors. After detecting stress in a cell, which might be due to a pathogen, chloroplasts begin producing molecules like salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species which can serve as defense-signals. As cellular signals, reactive oxygen species are unstable molecules, so they probably don't leave the chloroplast, but instead pass on their signal to an unknown second messenger molecule. All these molecules initiate retrograde signaling\u2014signals from the chloroplast that regulate gene expression in the nucleus.\nIn addition to defense signaling, chloroplasts, with the help of the peroxisomes, help synthesize an important defense molecule, jasmonate. Chloroplasts synthesize all the fatty acids in a plant cell\u2014linoleic acid, a fatty acid, is a precursor to jasmonate.\nPhotosynthesis.\nOne of the main functions of the chloroplast is its role in photosynthesis, the process by which light is transformed into chemical energy, to subsequently produce food in the form of sugars. Water (H2O) and carbon dioxide (CO2) are used in photosynthesis, and sugar and oxygen (O2) are made, using light energy. Photosynthesis is divided into two stages\u2014the light reactions, where water is split to produce oxygen, and the dark reactions, or Calvin cycle, which builds sugar molecules from carbon dioxide. The two phases are linked by the energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+).\nLight reactions.\nThe light reactions take place on the thylakoid membranes. They take light energy and store it in NADPH, a form of NADP+, and ATP to fuel the dark reactions.\nEnergy carriers.\nATP is the phosphorylated version of adenosine diphosphate (ADP), which stores energy in a cell and powers most cellular activities. ATP is the energized form, while ADP is the (partially) depleted form. NADP+ is an electron carrier which ferries high energy electrons. In the light reactions, it gets reduced, meaning it picks up electrons, becoming NADPH.\nPhotophosphorylation.\nLike mitochondria, chloroplasts use the potential energy stored in an H+, or hydrogen ion, gradient to generate ATP energy. The two photosystems capture light energy to energize electrons taken from water, and release them down an electron transport chain. The molecules between the photosystems harness the electrons' energy to pump hydrogen ions into the thylakoid space, creating a concentration gradient, with more hydrogen ions (up to a thousand times as many) inside the thylakoid system than in the stroma. The hydrogen ions in the thylakoid space then diffuse back down their concentration gradient, flowing back out into the stroma through ATP synthase. ATP synthase uses the energy from the flowing hydrogen ions to phosphorylate adenosine diphosphate into adenosine triphosphate, or ATP. Because chloroplast ATP synthase projects out into the stroma, the ATP is synthesized there, in position to be used in the dark reactions.\nNADP+ reduction.\nElectrons are often removed from the electron transport chains to charge NADP+ with electrons, reducing it to NADPH. Like ATP synthase, ferredoxin-NADP+ reductase, the enzyme that reduces NADP+, releases the NADPH it makes into the stroma, right where it is needed for the dark reactions.\nBecause NADP+ reduction removes electrons from the electron transport chains, they must be replaced\u2014the job of photosystem II, which splits water molecules (H2O) to obtain the electrons from its hydrogen atoms.\nCyclic photophosphorylation.\nWhile photosystem II photolyzes water to obtain and energize new electrons, photosystem I simply reenergizes depleted electrons at the end of an electron transport chain. Normally, the reenergized electrons are taken by NADP+, though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP. This is termed cyclic photophosphorylation because the electrons are recycled. Cyclic photophosphorylation is common in plants, which need more ATP than NADPH.\nDark reactions.\nThe Calvin cycle, also known as the dark reactions, is a series of biochemical reactions that fixes CO2 into G3P sugar molecules and uses the energy and electrons from the ATP and NADPH made in the light reactions. The Calvin cycle takes place in the stroma of the chloroplast.\nWhile named \"the dark reactions\", in most plants, they take place in the light, since the dark reactions are dependent on the products of the light reactions.\nCarbon fixation and G3P synthesis.\nThe Calvin cycle starts by using the enzyme RuBisCO to fix CO2 into five-carbon Ribulose bisphosphate (RuBP) molecules. The result is unstable six-carbon molecules that immediately break down into three-carbon molecules called 3-phosphoglyceric acid, or 3-PGA.\nThe ATP and NADPH made in the light reactions is used to convert the 3-PGA into glyceraldehyde-3-phosphate, or G3P sugar molecules. Most of the G3P molecules are recycled back into RuBP using energy from more ATP, but one out of every six produced leaves the cycle\u2014the end product of the dark reactions.\nSugars and starches.\nGlyceraldehyde-3-phosphate can double up to form larger sugar molecules like glucose and fructose. These molecules are processed, and from them, the still larger sucrose, a disaccharide commonly known as table sugar, is made, though this process takes place outside of the chloroplast, in the cytoplasm.\nAlternatively, glucose monomers in the chloroplast can be linked together to make starch, which accumulates into the starch grains found in the chloroplast.\nUnder conditions such as high atmospheric CO2 concentrations, these starch grains may grow very large, distorting the grana and thylakoids. The starch granules displace the thylakoids, but leave them intact.\nWaterlogged roots can also cause starch buildup in the chloroplasts, possibly due to less sucrose being exported out of the chloroplast (or more accurately, the plant cell). This depletes a plant's free phosphate supply, which indirectly stimulates chloroplast starch synthesis.\nWhile linked to low photosynthesis rates, the starch grains themselves may not necessarily interfere significantly with the efficiency of photosynthesis, and might simply be a side effect of another photosynthesis-depressing factor.\nPhotorespiration.\nPhotorespiration can occur when the oxygen concentration is too high. RuBisCO cannot distinguish between oxygen and carbon dioxide very well, so it can accidentally add O2 instead of CO2 to RuBP. This process reduces the efficiency of photosynthesis\u2014it consumes ATP and oxygen, releases CO2, and produces no sugar. It can waste up to half the carbon fixed by the Calvin cycle. Several mechanisms have evolved in different lineages that raise the carbon dioxide concentration relative to oxygen within the chloroplast, increasing the efficiency of photosynthesis. These mechanisms are called carbon dioxide concentrating mechanisms, or CCMs. These include Crassulacean acid metabolism, carbon fixation, and pyrenoids. Chloroplasts in plants are notable as they exhibit a distinct chloroplast dimorphism.\npH.\nBecause of the H+ gradient across the thylakoid membrane, the interior of the thylakoid is acidic, with a pH around 4, while the stroma is slightly basic, with a pH of around 8.\nThe optimal stroma pH for the Calvin cycle is 8.1, with the reaction nearly stopping when the pH falls below 7.3.\nCO2 in water can form carbonic acid, which can disturb the pH of isolated chloroplasts, interfering with photosynthesis, even though CO2 is used in photosynthesis. However, chloroplasts in living plant cells are not affected by this as much.\nChloroplasts can pump K+ and H+ ions in and out of themselves using a poorly understood light-driven transport system.\nIn the presence of light, the pH of the thylakoid lumen can drop up to 1.5 pH units, while the pH of the stroma can rise by nearly one pH unit.\nAmino acid synthesis.\nChloroplasts alone make almost all of a plant cell's amino acids in their stroma except the sulfur-containing ones like cysteine and methionine. Cysteine is made in the chloroplast (the proplastid too) but it is also synthesized in the cytosol and mitochondria, probably because it has trouble crossing membranes to get to where it is needed. The chloroplast is known to make the precursors to methionine but it is unclear whether the organelle carries out the last leg of the pathway or if it happens in the cytosol.\nOther nitrogen compounds.\nChloroplasts make all of a cell's purines and pyrimidines\u2014the nitrogenous bases found in DNA and RNA. They also convert nitrite (NO2\u2212) into ammonia (NH3) which supplies the plant with nitrogen to make its amino acids and nucleotides.\nOther chemical products.\nThe plastid is the site of diverse and complex lipid synthesis in plants. The carbon used to form the majority of the lipid is from acetyl-CoA, which is the decarboxylation product of pyruvate. Pyruvate may enter the plastid from the cytosol by passive diffusion through the membrane after production in glycolysis. Pyruvate is also made in the plastid from phosphoenolpyruvate, a metabolite made in the cytosol from pyruvate or PGA. Acetate in the cytosol is unavailable for lipid biosynthesis in the plastid. The typical length of fatty acids produced in the plastid are 16 or 18 carbons, with 0-3 cis double bonds.\nThe biosynthesis of fatty acids from acetyl-CoA primarily requires two enzymes. Acetyl-CoA carboxylase creates malonyl-CoA, used in both the first step and the extension steps of synthesis. Fatty acid synthase (FAS) is a large complex of enzymes and cofactors including acyl carrier protein (ACP) which holds the acyl chain as it is synthesized. The initiation of synthesis begins with the condensation of malonyl-ACP with acetyl-CoA to produce ketobutyryl-ACP. 2 reductions involving the use of NADPH and one dehydration creates butyryl-ACP. Extension of the fatty acid comes from repeated cycles of malonyl-ACP condensation, reduction, and dehydration.\nOther lipids are derived from the methyl-erythritol phosphate (MEP) pathway and consist of gibberelins, sterols, abscisic acid, phytol, and innumerable secondary metabolites.\nLocation.\nDistribution in a plant.\nNot all cells in a multicellular plant contain chloroplasts. All green parts of a plant contain chloroplasts as the color comes from the chlorophyll. The plant cells which contain chloroplasts are usually parenchyma cells, though chloroplasts can also be found in collenchyma tissue. A plant cell which contains chloroplasts is known as a chlorenchyma cell. A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts.\nIn some plants such as cacti, chloroplasts are found in the stems, though in most plants, chloroplasts are concentrated in the leaves. One square millimeter of leaf tissue can contain half a million chloroplasts. Within a leaf, chloroplasts are mainly found in the mesophyll layers of a leaf, and the guard cells of stomata. Palisade mesophyll cells can contain 30\u201370 chloroplasts per cell, while stomatal guard cells contain only around 8\u201315 per cell, as well as much less chlorophyll. Chloroplasts can also be found in the bundle sheath cells of a leaf, especially in C plants, which carry out the Calvin cycle in their bundle sheath cells. They are often absent from the epidermis of a leaf.\nCellular location.\nChloroplast movement.\nThe chloroplasts of plant and algal cells can orient themselves to best suit the available light. In low-light conditions, they will spread out in a sheet\u2014maximizing the surface area to absorb light. Under intense light, they will seek shelter by aligning in vertical columns along the plant cell's cell wall or turning sideways so that light strikes them edge-on. This reduces exposure and protects them from photooxidative damage. This ability to distribute chloroplasts so that they can take shelter behind each other or spread out may be the reason why land plants evolved to have many small chloroplasts instead of a few big ones.\nChloroplast movement is considered one of the most closely regulated stimulus-response systems that can be found in plants. Mitochondria have also been observed to follow chloroplasts as they move.\nIn higher plants, chloroplast movement is run by phototropins, blue light photoreceptors also responsible for plant phototropism. In some algae, mosses, ferns, and flowering plants, chloroplast movement is influenced by red light in addition to blue light, though very long red wavelengths inhibit movement rather than speeding it up. Blue light generally causes chloroplasts to seek shelter, while red light draws them out to maximize light absorption.\nStudies of \"Vallisneria gigantea\", an aquatic flowering plant, have shown that chloroplasts can get moving within five minutes of light exposure, though they don't initially show any net directionality. They may move along microfilament tracks, and the fact that the microfilament mesh changes shape to form a honeycomb structure surrounding the chloroplasts after they have moved suggests that microfilaments may help to anchor chloroplasts in place.\nDifferentiation, replication, and inheritance.\nChloroplasts are a special type of a plant cell organelle called a plastid, though the two terms are sometimes used interchangeably. There are many other types of plastids, which carry out various functions. All chloroplasts in a plant are descended from undifferentiated proplastids found in the zygote, or fertilized egg. Proplastids are commonly found in an adult plant's apical meristems. Chloroplasts do not normally develop from proplastids in root tip meristems\u2014instead, the formation of starch-storing amyloplasts is more common.\nIn shoots, proplastids from shoot apical meristems can gradually develop into chloroplasts in photosynthetic leaf tissues as the leaf matures, if exposed to the required light. This process involves invaginations of the inner plastid membrane, forming sheets of membrane that project into the internal stroma. These membrane sheets then fold to form thylakoids and grana.\nIf angiosperm shoots are not exposed to the required light for chloroplast formation, proplastids may develop into an etioplast stage before becoming chloroplasts. An etioplast is a plastid that lacks chlorophyll, and has inner membrane invaginations that form a lattice of tubes in their stroma, called a prolamellar body. While etioplasts lack chlorophyll, they have a yellow chlorophyll precursor stocked. Within a few minutes of light exposure, the prolamellar body begins to reorganize into stacks of thylakoids, and chlorophyll starts to be produced. This process, where the etioplast becomes a chloroplast, takes several hours. Gymnosperms do not require light to form chloroplasts.\nLight, however, does not guarantee that a proplastid will develop into a chloroplast. Whether a proplastid develops into a chloroplast some other kind of plastid is mostly controlled by the nucleus and is largely influenced by the kind of cell it resides in.\nPlastid interconversion.\nPlastid differentiation is not permanent, in fact many interconversions are possible. Chloroplasts may be converted to chromoplasts, which are pigment-filled plastids responsible for the bright colors seen in flowers and ripe fruit. Starch storing amyloplasts can also be converted to chromoplasts, and it is possible for proplastids to develop straight into chromoplasts. Chromoplasts and amyloplasts can also become chloroplasts, like what happens when a carrot or a potato is illuminated. If a plant is injured, or something else causes a plant cell to revert to a meristematic state, chloroplasts and other plastids can turn back into proplastids. Chloroplast, amyloplast, chromoplast, proplastid are not absolute; state\u2014intermediate forms are common.\nDivision.\nMost chloroplasts in a photosynthetic cell do not develop directly from proplastids or etioplasts. In fact, a typical shoot meristematic plant cell contains only 7\u201320 proplastids. These proplastids differentiate into chloroplasts, which divide to create the 30\u201370 chloroplasts found in a mature photosynthetic plant cell. If the cell divides, chloroplast division provides the additional chloroplasts to partition between the two daughter cells.\nIn single-celled algae, chloroplast division is the only way new chloroplasts are formed. There is no proplastid differentiation\u2014when an algal cell divides, its chloroplast divides along with it, and each daughter cell receives a mature chloroplast.\nAlmost all chloroplasts in a cell divide, rather than a small group of rapidly dividing chloroplasts. Chloroplasts have no definite S-phase\u2014their DNA replication is not synchronized or limited to that of their host cells.\nMuch of what we know about chloroplast division comes from studying organisms like \"Arabidopsis\" and the red alga \"Cyanidioschyzon merol\u00e6\".\nThe division process starts when the proteins FtsZ1 and FtsZ2 assemble into filaments, and with the help of a protein ARC6, form a structure called a Z-ring within the chloroplast's stroma. The Min system manages the placement of the Z-ring, ensuring that the chloroplast is cleaved more or less evenly. The protein MinD prevents FtsZ from linking up and forming filaments. Another protein ARC3 may also be involved, but it is not very well understood. These proteins are active at the poles of the chloroplast, preventing Z-ring formation there, but near the center of the chloroplast, MinE inhibits them, allowing the Z-ring to form.\nNext, the two plastid-dividing rings, or PD rings form. The inner plastid-dividing ring is located in the inner side of the chloroplast's inner membrane, and is formed first. The outer plastid-dividing ring is found wrapped around the outer chloroplast membrane. It consists of filaments about 5 nanometers across, arranged in rows 6.4 nanometers apart, and shrinks to squeeze the chloroplast. This is when chloroplast constriction begins. In a few species like \"Cyanidioschyzon merol\u00e6\", chloroplasts have a third plastid-dividing ring located in the chloroplast's intermembrane space.\nLate into the constriction phase, dynamin proteins assemble around the outer plastid-dividing ring, helping provide force to squeeze the chloroplast. Meanwhile, the Z-ring and the inner plastid-dividing ring break down. During this stage, the many chloroplast DNA plasmids floating around in the stroma are partitioned and distributed to the two forming daughter chloroplasts.\nLater, the dynamins migrate under the outer plastid dividing ring, into direct contact with the chloroplast's outer membrane, to cleave the chloroplast in two daughter chloroplasts.\nA remnant of the outer plastid dividing ring remains floating between the two daughter chloroplasts, and a remnant of the dynamin ring remains attached to one of the daughter chloroplasts.\nOf the five or six rings involved in chloroplast division, only the outer plastid-dividing ring is present for the entire constriction and division phase\u2014while the Z-ring forms first, constriction does not begin until the outer plastid-dividing ring forms.\nRegulation.\nIn species of algae that contain a single chloroplast, regulation of chloroplast division is extremely important to ensure that each daughter cell receives a chloroplast\u2014chloroplasts can't be made from scratch. In organisms like plants, whose cells contain multiple chloroplasts, coordination is looser and less important. It is likely that chloroplast and cell division are somewhat synchronized, though the mechanisms for it are mostly unknown.\nLight has been shown to be a requirement for chloroplast division. Chloroplasts can grow and progress through some of the constriction stages under poor quality green light, but are slow to complete division\u2014they require exposure to bright white light to complete division. Spinach leaves grown under green light have been observed to contain many large dumbbell-shaped chloroplasts. Exposure to white light can stimulate these chloroplasts to divide and reduce the population of dumbbell-shaped chloroplasts.\nChloroplast inheritance.\nLike mitochondria, chloroplasts are usually inherited from a single parent. Biparental chloroplast inheritance\u2014where plastid genes are inherited from both parent plants\u2014occurs in very low levels in some flowering plants.\nMany mechanisms prevent biparental chloroplast DNA inheritance, including selective destruction of chloroplasts or their genes within the gamete or zygote, and chloroplasts from one parent being excluded from the embryo. Parental chloroplasts can be sorted so that only one type is present in each offspring.\nGymnosperms, such as pine trees, mostly pass on chloroplasts paternally, while flowering plants often inherit chloroplasts maternally. Flowering plants were once thought to only inherit chloroplasts maternally. However, there are now many documented cases of angiosperms inheriting chloroplasts paternally.\nAngiosperms, which pass on chloroplasts maternally, have many ways to prevent paternal inheritance. Most of them produce sperm cells that do not contain any plastids. There are many other documented mechanisms that prevent paternal inheritance in these flowering plants, such as different rates of chloroplast replication within the embryo.\nAmong angiosperms, paternal chloroplast inheritance is observed more often in hybrids than in offspring from parents of the same species. This suggests that incompatible hybrid genes might interfere with the mechanisms that prevent paternal inheritance.\nTransplastomic plants.\nRecently, chloroplasts have caught attention by developers of genetically modified crops. Since, in most flowering plants, chloroplasts are not inherited from the male parent, transgenes in these plastids cannot be disseminated by pollen. This makes plastid transformation a valuable tool for the creation and cultivation of genetically modified plants that are biologically contained, thus posing significantly lower environmental risks. This biological containment strategy is therefore suitable for establishing the coexistence of conventional and organic agriculture. While the reliability of this mechanism has not yet been studied for all relevant crop species, recent results in tobacco plants are promising, showing a failed containment rate of transplastomic plants at 3 in 1,000,000."}
{"id": "6357", "revid": "589223", "url": "https://en.wikipedia.org/wiki?curid=6357", "title": "Camp David", "text": "Camp David is a country retreat for the president of the United States. It lies in the wooded hills of Catoctin Mountain Park, in Frederick County, Maryland, near the towns of Thurmont and Emmitsburg, about north-northwest of the national capital city, Washington, D.C. It is code-named Naval Support Facility Thurmont. Technically a military installation, it is staffed primarily by the Seabees, the Civil Engineer Corps (CEC), the United States Navy, and the United States Marine Corps. Naval construction battalions are tasked with Camp David construction and send detachments as needed.\nOriginally known as Hi-Catoctin, Camp David was built as a retreat for federal government agents and their families by the Works Progress Administration. Construction started in 1935 and was completed in 1938. In 1942, President Franklin D. Roosevelt converted it to a presidential retreat and renamed it \"Shangri-La\", after the fictional Himalayan paradise. Camp David received its present name in 1953 from President Dwight D. Eisenhower, in honor of his father and his grandson, both named David.\nThe Catoctin Mountain Park does not indicate the location of Camp David on park maps due to privacy and security concerns, although it can be seen through the use of publicly accessible satellite images, and is also viewable on certain public web mapping services like Google Maps.\nPresidential use.\nCamp David has been used to host private diplomatic meetings with foreign leaders and heads of state since at least World War II. Franklin D. Roosevelt hosted Winston Churchill at Shangri-La in May 1943, during World War II. Dwight Eisenhower held his first cabinet meeting there on November 22, 1955, following hospitalization and convalescence he required after a heart attack suffered in Denver, Colorado, on September 24. Eisenhower met Nikita Khrushchev there for two days of discussions in September 1959.\nJohn F. Kennedy and his family often enjoyed riding and other recreational activities there, and Kennedy often allowed White House staff and Cabinet members to use the retreat when he or his family were not there. Lyndon B. Johnson met with advisors in this setting and hosted both Australian prime minister Harold Holt and Canadian prime minister Lester B. Pearson there. Richard Nixon was a frequent visitor. He personally directed the construction of a swimming pool and other improvements to Aspen Lodge. Gerald Ford hosted Indonesian president Suharto at Camp David.\nJimmy Carter initially favored closing Camp David in order to save money, but once he visited the retreat, he decided to keep it. Carter brokered the Camp David Accords there in September 1978 between Egyptian president Anwar al-Sadat and Israeli prime minister Menachem Begin. Ronald Reagan visited the retreat more than any other president. In 1984, Reagan hosted British prime minister Margaret Thatcher. Reagan restored the nature trails that Nixon paved over so he could horseback ride at Camp David. George H. W. Bush's daughter, Dorothy Bush Koch, was married there in 1992, in the first wedding held at Camp David. During his tenure as president, Bill Clinton spent every Thanksgiving at Camp David with his family. In July 2000, he hosted the 2000 Camp David Summit negotiations between Israeli prime minister Ehud Barak and Palestinian Authority chairman Yasser Arafat there.\nIn February 2001, George W. Bush held his first meeting with a European leader, UK prime minister Tony Blair, at Camp David, to discuss missile defense, Iraq, and NATO. After the September 11 attacks, Bush held a Cabinet meeting at Camp David to prepare the United States invasion of Afghanistan. During his two terms in office, Bush visited Camp David 149 times, for a total of 487 days, for hosting foreign visitors as well as a personal retreat. He met Blair there four times. Among the numerous other foreign leaders he hosted at Camp David were Russian president Vladimir Putin and President Musharraf of Pakistan in 2003, Danish prime minister Anders Fogh Rasmussen in June 2006, and British prime minister Gordon Brown in 2007.\nBarack Obama chose Camp David to host the 38th G8 summit in 2012. President Obama also hosted Russian prime minister Dmitry Medvedev at Camp David, as well as the GCC Summit there in 2015.\nDonald Trump hosted Senate majority leader Mitch McConnell and Speaker of the House Paul Ryan at Camp David while the Republican Party prepared to defend both houses of Congress in the 2018 midterm elections. Trump also planned to meet with the Taliban at Camp David to negotiate a peace agreement in 2019, but refrained after a suicide bombing in Kabul killed US troops. The 46th G7 summit was to be held at Camp David on June 10\u201312, 2020, but was cancelled due to health concerns during what was at the time considered the height of the COVID-19 pandemic.\nJoe Biden hosted the U.S.\u2013Japan\u2013Korea Summit with Japanese prime minister Fumio Kishida and South Korean president Yoon Suk Yeol at Camp David in August 2023, resulting in the declaration of the Camp David Principles on trilateral relations between the U.S., Japan, and South Korea.\nPractice golf facility.\nTo be able to play his favorite sport, President Eisenhower had golf course architect Robert Trent Jones design a practice golf facility at Camp David. Around 1954, Jones built one golf hole\u2014a par 3\u2014with four different tees; Eisenhower added a driving range near the helicopter landing zone.\nSecurity incidents.\nOn July 2, 2011, an F-15 intercepted a civilian aircraft approximately from Camp David, when President Obama was in the residence. The two-seater, which was out of radio communication, was escorted to nearby Hagerstown, Maryland, without incident.\nOn July 10, 2011, an F-15 intercepted another small plane near Camp David when Obama was again in the residence; a total of three were intercepted that weekend."}
{"id": "6359", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=6359", "title": "Crux", "text": "Crux () is a constellation of the southern sky that is centred on four bright stars in a cross-shaped asterism commonly known as the Southern Cross. It lies on the southern end of the Milky Way's visible band. The name \"Crux\" is Latin for cross. Even though it is the smallest of all 88 modern constellations, Crux is among the most easily distinguished as its four main stars each have an apparent visual magnitude brighter than +2.8. It has attained a high level of cultural significance in many Southern Hemisphere states and nations.\nBlue-white \u03b1 Crucis (Acrux) is the most southerly member of the constellation and, at magnitude 0.8, the brightest. The three other stars of the cross appear clockwise and in order of lessening magnitude: \u03b2 Crucis (Mimosa), \u03b3 Crucis (Gacrux), and \u03b4 Crucis (Imai). \u03b5 Crucis (Ginan) also lies within the cross asterism. Many of these brighter stars are members of the Scorpius\u2013Centaurus association, a large but loose group of hot blue-white stars that appear to share common origins and motion across the southern Milky Way.\nCrux contains four Cepheid variables, each visible to the naked eye under optimum conditions. Crux also contains the bright and colourful open cluster known as the Jewel Box (NGC 4755) on its eastern border. Nearby to the southeast is a large dark nebula spanning 7\u00b0 by 5\u00b0 known as the Coalsack Nebula, portions of which are mapped in the neighbouring constellations of Centaurus and Musca.\nHistory.\nThe bright stars in Crux were known to the Ancient Greeks, where Ptolemy regarded them as part of the constellation Centaurus. They were entirely visible as far north as Britain in the fourth millennium BC. However, the precession of the equinoxes gradually lowered the stars below the European horizon, and they were eventually forgotten by the inhabitants of northern latitudes. By 400\u00a0AD, the stars in the constellation now called Crux never rose above the horizon throughout most of Europe. Dante may have known about the constellation in the 14th century, as he describes an asterism of four bright stars in the southern sky in his \"Divine Comedy\". His description, however, may be allegorical, and the similarity to the constellation a coincidence.\nThe 15th\u00a0century Venetian navigator Alvise Cadamosto made note of what was probably the Southern Cross on exiting the Gambia River in 1455, calling it the \"carro dell'ostro\" (\"southern chariot\"). However, Cadamosto's accompanying diagram was inaccurate. Historians generally credit Jo\u00e3o Faras for being the first European to depict it correctly. Faras sketched and described the constellation (calling it \"las guardas\") in a letter written on the beaches of Brazil on 1\u00a0May 1500 to the Portuguese monarch.\nExplorer Amerigo Vespucci seems to have observed not only the Southern Cross but also the neighboring Coalsack Nebula on his second voyage in 1501\u20131502.\nAnother early modern description clearly describing Crux as a separate constellation is attributed to Andrea Corsali, an Italian navigator who from 1515 to 1517 sailed to China and the East Indies in an expedition sponsored by King Manuel\u00a0I. In 1516, Corsali wrote a letter to the monarch describing his observations of the southern sky, which included a rather crude map of the stars around the south celestial pole including the Southern Cross and the two Magellanic Clouds seen in an external orientation, as on a globe.\nEmery Molyneux and Petrus Plancius have also been cited as the first uranographers (sky mappers) to distinguish Crux as a separate constellation; their representations date from 1592, the former depicting it on his celestial globe and the latter in one of the small celestial maps on his large wall map. Both authors, however, depended on unreliable sources and placed Crux in the wrong position. Crux was first shown in its correct position on the celestial globes of Petrus Plancius and Jodocus Hondius in 1598 and 1600. Its stars were first catalogued separately from Centaurus by Frederick de Houtman in 1603. The constellation was later adopted by Jakob Bartsch in 1624 and Augustin Royer in 1679. Royer is sometimes wrongly cited as initially distinguishing Crux.\nCharacteristics.\nCrux is bordered by the constellations Centaurus (which surrounds it on three sides) on the east, north and west, and Musca to the south. Covering 68\u00a0square degrees and 0.165% of the night sky, it is the smallest of the 88 constellations. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Cru\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of four segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between \u221255.68\u00b0 and \u221264.70\u00b0. Its totality figures at least part of the year south of the 25th parallel north.\nIn tropical regions Crux can be seen in the sky from April to June. Crux is exactly opposite to Cassiopeia on the celestial sphere, and therefore it cannot appear in the sky with the latter at the same time. In this era, south of Cape Town, Adelaide, and Buenos Aires (the 34th parallel south), Crux is circumpolar and thus always appears in the sky.\nCrux is sometimes confused with the nearby False Cross asterism by stargazers. The False Cross consists of stars in Carina and Vela, is larger and dimmer, does not have a fifth star, and lacks the two prominent nearby \"Pointer Stars\". Between the two is the even larger and dimmer Diamond Cross.\nVisibility.\nCrux is easily visible from the southern hemisphere, south of 35th parallel at practically any time of year as circumpolar. It is also visible near the horizon from tropical latitudes of the northern hemisphere for a few hours every night during the northern winter and spring. For instance, it is visible from Cancun or any other place at latitude 25\u00b0 N or less at around 10 pm at the end of April. There are 5 main stars.\nDue to precession, Crux will move closer to the South Pole in the next millennia, up to 67 degrees south declination for the middle of the constellation. However, by the year 14,000, Crux will be visible for most parts of Europe and the continental United States. Its visibility will extend to North Europe by the year 18,000 when it will be less than 30 degrees south declination.\nUse in navigation.\nIn the Southern Hemisphere, the Southern Cross is frequently used for navigation in much the same way that Polaris is used in the Northern Hemisphere. Projecting a line from \u03b3 to \u03b1 Crucis (the foot of the crucifix) approximately times beyond gives a point close to the Southern Celestial Pole which is also, coincidentally, where intersects a perpendicular line taken southwards from the east\u2013west axis of Alpha Centauri to Beta Centauri, which are stars at an alike declination to Crux and of a similar width as the cross, but higher magnitude. Argentine gauchos are documented as using Crux for night orientation in the Pampas and Patagonia.\nAlpha and Beta Centauri are of similar declinations (thus distance from the pole) and are often referred as the \"Southern Pointers\" or just \"The Pointers\", allowing people to easily identify the Southern Cross, the constellation of Crux. Very few bright stars lie between Crux and the pole itself, although the constellation Musca is fairly easily recognised immediately south of Crux.\nBright stars.\nDown to apparent magnitude +2.5 are 92 stars that shine the brightest as viewed from the Earth. Three of these stars are in Crux making it the most densely populated as to those stars (this being 3.26% of these 92 stars, and in turn being 19.2 times more than the expected 0.17% that would result on a homogenous distribution of all bright stars and a randomised drawing of all 88 constellations, given its area, 0.17% of the sky).\nFeatures.\nStars.\nWithin the constellation's borders, there are 49 stars brighter than or equal to apparent magnitude 6.5. The four main stars that form the asterism are Alpha, Beta, Gamma, and Delta Crucis.\nThere is also a fifth star, that is often included with the Southern Cross.\nThere are several other naked-eye stars within the borders of Crux, especially:\nScorpius\u2013Centaurus association.\nUnusually, a total of 15 of the 23 brightest stars in Crux are spectrally blue-white B-type stars. Among the five main bright stars, Delta, and probably Alpha and Beta, are likely co-moving B-type members of the Scorpius\u2013Centaurus association, the nearest OB association to the Sun. They are among the highest-mass stellar members of the Lower Centaurus\u2013Crux subgroup of the association, with ages of roughly 10 to 20\u00a0million years. Other members include the blue-white stars Zeta, Lambda and both the components of the visual double star, Mu.\nVariable stars.\nCrux contains many variable stars. It boasts four Cepheid variables that may all reach naked eye visibility.\nOther well studied variable stars includes:\nHost star exoplanets in Crux.\nThe star HD 106906 has been found to have a planet\u2014HD 106906 b\u2014that has one of the widest orbits of any currently known planetary-mass companions.\nObjects beyond the Local Arm.\nCrux is backlit by the multitude of stars of the Scutum-Crux Arm (more commonly called the Scutum-Centaurus Arm) of the Milky Way. This is the main inner arm in the local radial quarter of the galaxy. Part-obscuring this is:\nA key feature of the Scutum-Crux Arm is:\nCultural significance.\nThe most prominent feature of Crux is the distinctive asterism known as the Southern Cross. It has great significance in the cultures of the southern hemisphere, particularly of Australia, Brazil, Chile and New Zealand.\nFlags and symbols.\nSeveral southern countries and organisations have traditionally used Crux as a national or distinctive symbol. The four or five brightest stars of Crux appear, heraldically standardised in various ways, on the flags of Australia, Brazil, New Zealand, Papua New Guinea and Samoa. They also appear on the flags of the Australian state of Victoria, the Australian Capital Territory, the Northern Territory, as well as the flag of Magallanes Region of Chile, the flag of Londrina (Brazil) and several Argentine provincial flags and emblems (for example, \"Tierra del Fuego\" and \"Santa Cruz\"). The flag of the Mercosur trading zone displays the four brightest stars. Crux also appears on the Brazilian coat of arms and, , on the cover of Brazilian passports.\nFive stars appear in the logo of the Brazilian football team Cruzeiro Esporte Clube and in the insignia of the Order of the Southern Cross, and the cross has featured as name of the Brazilian currency (the \"cruzeiro\" from 1942 to 1986 and again from 1990 to 1994). All coins of the (1998) series of the Brazilian real display the constellation.\nSongs and literature reference the Southern Cross, including the Argentine epic poem \"Mart\u00edn Fierro\". The Argentinian singer Charly Garc\u00eda says that he is \"from the Southern Cross\" in the song \"No voy en tren\".\nThe Cross gets a mention in the lyrics of the Brazilian National Anthem (1909): \"A imagem do Cruzeiro resplandece\" (\"the image of the Cross shines\").\nThe Southern Cross is mentioned in the Australian National Anthem, \"\"Beneath our radiant Southern Cross we'll toil with hearts and hands\"\nThe Southern Cross features in the coat of arms of William Birdwood, 1st Baron Birdwood, the British officer who commanded the Australian and New Zealand Army Corps during the Gallipoli Campaign of the First World War.\nThe Southern Cross is also mentioned in the Samoan\nNational Anthem.\n\"Vaai 'i na fetu o lo'u a agiagia ai: Le faailoga lea o Iesu, na maliu ai mo Samoa.\"\" (\"Look at those stars that are waving on it: This is the symbol of Jesus, who died on it for Samoa.\")\nThe 1952-53 NBC Television Series \"Victory At Sea\" contained a musical number entitled \"Beneath the Southern Cross\".\n\"Southern Cross\" is a single released by Crosby, Stills and Nash in 1981. It reached #18 on Billboard Hot 100 in late 1982.\n\"The Sign of the Southern Cross\" is a song released by Black Sabbath in 1981. The song was released on the album \"Mob Rules\".\nThe Order of the Southern Cross is a Brazilian order of chivalry awarded to \"those who have rendered significant service to the Brazilian nation\".\nIn \"O Sweet Saint Martin's Land\", the lyrics mention the Southern Cross: \"Thy Southern Cross the night\".\nA stylized version of Crux appears on the Australian Eureka Flag. The constellation was also used on the dark blue, shield-like patch worn by personnel of the U.S. Army's Americal Division, which was organized in the Southern Hemisphere, on the island of New Caledonia, and also on the blue diamond of the U.S. 1st Marine Division, which fought on the Southern Hemisphere islands of Guadalcanal and New Britain.\nThe \"Petersflagge\" flag of the German East Africa Company of 1885\u20131920, which included a constellation of five white five-pointed Crux \"stars\" on a red ground, later served as the model for symbolism associated with generic German colonial-oriented organisations: the Reichskolonialbund of 1936\u20131943 and the (1956/1983 to the present).\nSouthern Cross station is a major rail terminal in Melbourne, Australia.\nThe Personal Ordinariate of Our Lady of the Southern Cross is a personal ordinariate of the Roman Catholic Church primarily within the territory of the Australian Catholic Bishops Conference for groups of Anglicans who desire full communion with the Catholic Church in Australia and Asia.\nThe Knights of the Southern Cross (KSC) is a Catholic fraternal order throughout Australia.\nVarious cultures.\nIn India, there is a story related to the creation of Trishanku Swarga (\u0924\u094d\u0930\u093f\u0936\u0902\u0915\u0941), meaning \"Cross\" (Crux), created by Sage Vishwamitra.\nIn Chinese, (), meaning \"Cross\", refers to an asterism consisting of \u03b3 Crucis, \u03b1 Crucis, \u03b2 Crucis and \u03b4 Crucis.\nIn Australian Aboriginal astronomy, Crux and the Coalsack mark the head of the 'Emu in the Sky' (which is seen in the dark spaces rather than in the patterns of stars) in several Aboriginal cultures, while Crux itself is said to be a possum sitting in a tree (Boorong people of the Wimmera region of northwestern Victoria), a representation of the sky deity Mirrabooka (Quandamooka people of Stradbroke Island), a stingray (Yolngu people of Arnhem Land), or an eagle (Kaurna people of the Adelaide Plains). Two Pacific constellations also included Gamma Centauri. Torres Strait Islanders in modern-day Australia saw Gamma Centauri as the handle and the four stars as the left hand of Tagai, and the stars of Musca as the trident of the fishing spear he is holding. In Aranda traditions of central Australia, the four Cross stars are the talon of an eagle and Gamma Centauri as its leg.\nVarious peoples in the East Indies and Brazil viewed the four main stars as the body of a ray. In both Indonesia and Malaysia, it is known as \"Bintang Pari\" and \"Buruj Pari\", respectively (\"ray stars\"). This aquatic theme is also shared by an archaic name of the constellation in Vietnam, where it was once known as \"sao C\u00e1 Li\u1ec7t\" (the ponyfish star).\nAmong Filipino people, the southern cross have various names pertaining to tops, including \"kasing\" (Visayan languages), \"paglong\" (Bikol), and \"pasil\" (Tagalog). It is also called \"butiti\" (puffer fish) in Waray.\nThe Javanese people of Indonesia called this constellation \"Gubug p\u00e8nc\u00e8ng\" (\"raking hut\") or \"lumbung\" (\"the granary\"), because the shape of the constellation was like that of a raking hut.\nThe Southern Cross (\u03b1, \u03b2, \u03b3 and \u03b4 Crucis) together with \u03bc Crucis is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng bola k\u00e9ppang\", meaning \"incomplete house star\"\nThe M\u0101ori name for the Southern Cross is \"M\u0101hutonga\" and it is thought of as the anchor (\"Te Punga\") of Tama-rereti's \"waka\" (the Milky Way), while the Pointers are its rope. In Tonga it is known as \"Toloa\" (\"duck\"); it is depicted as a duck flying south, with one of his wings (\u03b4 Crucis) wounded because \"Ongo tangata\" (\"two men\", \u03b1 and \u03b2 Centauri) threw a stone at it. The Coalsack is known as \"Humu\" (the \"triggerfish\"), because of its shape. In Samoa the constellation is called \"Sumu\" (\"triggerfish\") because of its rhomboid shape, while \u03b1 and \u03b2 Centauri are called \"Luatagata\" (Two Men), just as they are in Tonga. The peoples of the Solomon Islands saw several figures in the Southern Cross. These included a knee protector and a net used to catch Palolo worms. Neighboring peoples in the Marshall Islands saw these stars as a fish. Peninsular Malays also see the likeness of a fish in the Crux, particularly the Scomberomorus or its local name \"Tohok\".\nIn Mapudungun, the language of Patagonian Mapuches, the name of the Southern Cross is \"Melipal\", which means \"four stars\". In Quechua, the language of the Inca civilization, Crux is known as \"Chakana\", which means literally \"stair\" (\"chaka\", bridge, link; \"hanan\", high, above), but carries a deep symbolism within Quechua mysticism. Alpha and Beta Crucis make up one foot of the Great Rhea, a constellation encompassing Centaurus and Circinus along with the two bright stars. The Great Rhea was a constellation of the Bororo of Brazil. The Mocov\u00ed people of Argentina also saw a rhea including the stars of Crux. Their rhea is attacked by two dogs, represented by bright stars in Centaurus and Circinus. The dogs' heads are marked by Alpha and Beta Centauri. The rhea's body is marked by the four main stars of Crux, while its head is Gamma Centauri and its feet are the bright stars of Musca. The Bakairi people of Brazil had a sprawling constellation representing a bird snare. It included the bright stars of Crux, the southern part of Centaurus, Circinus, at least one star in Lupus, the bright stars of Musca, Beta and the optical double star Delta1,2 Chamaeleontis: and some of the stars of Volans, and Mensa. The Kalapalo people of Mato Grosso state in Brazil saw the stars of Crux as \"Aganagi\" angry bees having emerged from the Coalsack, which they saw as the beehive.\nAmong Tuaregs, the four most visible stars of Crux are considered \"iggaren\", i.e. four \"Maerua crassifolia\" trees. The Tswana people of Botswana saw the constellation as \"Dithutlwa\", two giraffes \u2013 Alpha and Beta Crucis forming a male, and Gamma and Delta forming the female."}
{"id": "6360", "revid": "87355", "url": "https://en.wikipedia.org/wiki?curid=6360", "title": "Cepheus", "text": "Cepheus (Ancient Greek: \u039a\u03b7\u03c6\u03b5\u03cd\u03c2 \"Kephe\u00fas\") may refer to:"}
{"id": "6361", "revid": "1257251251", "url": "https://en.wikipedia.org/wiki?curid=6361", "title": "Cassiopeia", "text": "Cassiopeia or Cassiopea may refer to:"}
{"id": "6362", "revid": "49072564", "url": "https://en.wikipedia.org/wiki?curid=6362", "title": "Cetus", "text": "Cetus () is a constellation, sometimes called 'the whale' in English. The Cetus was a sea monster in Greek mythology which both Perseus and Heracles needed to slay. Cetus is in the region of the sky that contains other water-related constellations: Aquarius, Pisces and Eridanus.\nFeatures.\nEcliptic.\nCetus is not among the 12 true zodiac constellations in the J2000 epoch, nor classical 12-part zodiac. The ecliptic passes less than 0.25\u00b0 from one of its corners. Thus the moon and planets will enter Cetus (occulting any stars as a foreground object) in 50% of their successive orbits briefly and the southern part of the sun appears in Cetus for about one day each year. Many asteroids in belts have longer phases occulting the north-western part of Cetus, those with a slightly greater inclination to the ecliptic than the moon and planets.\nAs seen from Mars, the ecliptic (apparent plane of the sun and also the average plane of the planets which is almost the same) passes into it.\nStars.\nMira (\"wonderful\", named by Bayer: Omicron Ceti, a star of the neck of the asterism) was the first variable star to be discovered and the prototype of its class, Mira variables. Over a period of 332 days, it reaches a maximum apparent magnitude of 3 - visible to the naked eye - and dips to a minimum magnitude of 10, invisible to the unaided eye. Its seeming appearance and disappearance gave it its name. Mira pulsates with a minimum size of 400 solar diameters and a maximum size of 500 solar diameters. 420 light-years from Earth, it was discovered by David Fabricius in 1596.\n\u03b1 Ceti, traditionally called Menkar (\"the nose\"), is a red-hued giant star of magnitude 2.5, 220 light-years from Earth. It is a wide double star; the secondary is 93 Ceti, a blue-white hued star of magnitude 5.6, 440 light-years away. \u03b2 Ceti, also called Deneb Kaitos and Diphda is the brightest star in Cetus. It is an orange-hued giant star of magnitude 2.0, 96 light-years from Earth. The traditional name \"Deneb Kaitos\" means \"the whale's tail\". \u03b3 Ceti, Kaffaljidhma (\"head of the whale\") is a very close double star. The primary is a blue-hued star of magnitude 3.5, 82 light-years from Earth, and the secondary is an F-type star of magnitude 6.6. Tau Ceti is noted for being a near Sun-like star at a distance of 11.9 light-years. It is a yellow-hued main-sequence star of magnitude 3.5.\nAA Ceti is a triple star system; the brightest member has a magnitude of 6.2. The primary and secondary are separated by 8.4 arcseconds at an angle of 304 degrees. The tertiary is not visible in telescopes. AA Ceti is an eclipsing variable star; the tertiary star passes in front of the primary and causes the system's apparent magnitude to decrease by 0.5 magnitudes. UV Ceti is an unusual binary variable star. At 8.7 light-years from Earth, the system consists of two red dwarfs. Both of magnitude 13. One of the stars is a flare star, which are prone to sudden, random outbursts that last several minutes; these increase the pair's apparent brightness significantly - as high as magnitude 7.\nDeep-sky objects.\nCetus lies far from the galactic plane, so that many distant galaxies are visible, unobscured by dust from the Milky Way. Of these, the brightest is Messier 77 (NGC 1068), a 9th magnitude spiral galaxy near Delta Ceti. It appears face-on and has a clearly visible nucleus of magnitude 10. About 50 million light-years from Earth, M77 is also a Seyfert galaxy and thus a bright object in the radio spectrum. Recently, the galactic cluster JKCS\u00a0041 was confirmed to be the most distant cluster of galaxies yet discovered. The Pisces\u2013Cetus Supercluster Complex is a galaxy filament that is one of the largest known structures in the observable Universe; it contains the Virgo supercluster which contains the Local Group of Milky Way and other galaxies.\nThe massive cD galaxy Holmberg 15A is also found in Cetus; as are the spiral galaxy NGC 1042, the elliptical galaxy NGC 1052 and the ultra-diffuse galaxy NGC 1052-DF2.\nIC 1613 (Caldwell 51) is an irregular dwarf galaxy near the star 26 Ceti and is a member of the Local Group.\nNGC 246 (Caldwell 56), also called the \"Cetus Ring\", is a planetary nebula with a magnitude of 8.0 at 1600 light-years from Earth. Among some amateur astronomers, NGC 246 has garnered the nickname \"Pac-Man Nebula\" because of the arrangement of its central stars and the surrounding star field.\nThe Wolf\u2013Lundmark\u2013Melotte (WLM) is a barred irregular galaxy discovered in 1909 by Max Wolf, located on the outer edges of the Local Group. The discovery of the nature of the galaxy was accredited to Knut Lundmark and Philibert Jacques Melotte in 1926.\nUGC 1646, which is a spiral galaxy, also lies between the borders of the constellation. It is about 150 million light-years away from us. It can be seen near TYC 43-234-1 star.\nHistory and mythology.\nCetus may have originally been associated with a whale, which would have had mythic status amongst Mesopotamian cultures. It is often now called the Whale, though it is most strongly associated with Cetus the sea-monster, who was slain by Perseus as he saved the princess Andromeda from Poseidon's wrath. It is in the middle of \"The Sea\" recognised by mythologists, a set of water-associated constellations, its other members being Eridanus, Pisces, Piscis Austrinus and Aquarius.\nCetus has been depicted in many ways throughout its history. In the 17th century, Cetus was depicted as a \"dragon fish\" by Johann Bayer. Both Willem Blaeu and Andreas Cellarius depicted Cetus as a whale-like creature in the same century. However, Cetus has also been variously depicted with animal heads attached to a piscine body.\nIn global astronomy.\nIn Chinese astronomy, the stars of Cetus are found among two areas: the Black Tortoise of the North (\u5317\u65b9\u7384\u6b66, \"B\u011bi F\u0101ng Xu\u00e1n W\u01d4\") and the White Tiger of the West (\u897f\u65b9\u767d\u864e, \"X\u012b F\u0101ng B\u00e1i H\u01d4\").\nThe Tukano and Kobeua people of the Amazon used the stars of Cetus to create a jaguar, representing the god of hurricanes and other violent storms. Lambda, Mu, Xi, Nu, Gamma, and Alpha Ceti represented its head; Omicron, Zeta, and Chi Ceti represented its body; Eta Eri, Tau Cet, and Upsilon Cet marked its legs and feet; and Theta, Eta, and Beta Ceti delineated its tail.\nIn Hawaii, the constellation was called \"Na Kuhi\", and Mira (Omicron Ceti) may have been called \"Kane\".\nNamesakes.\nUSS Cetus (AK-77) was a United States Navy Crater class cargo ship named after the constellation."}
{"id": "6363", "revid": "47695301", "url": "https://en.wikipedia.org/wiki?curid=6363", "title": "Carina (constellation)", "text": "Carina ( ) is a constellation in the southern sky. Its name is Latin for the keel of a ship, and it was the southern foundation of the larger constellation of Argo Navis (the ship \"Argo\") until it was divided into three pieces, the other two being Puppis (the poop deck), and Vela (the sails of the ship).\nHistory and mythology.\nCarina was once a part of Argo Navis, the great ship of the mythical Jason and the Argonauts who searched for the Golden Fleece. The constellation of Argo was introduced in ancient Greece. However, due to the massive size of Argo Navis and the sheer number of stars that required separate designation, Nicolas-Louis de Lacaille divided Argo into three sections in 1763, including Carina (the hull or keel). In the 19th century, these three became established as separate constellations, and were formally included in the list of 88 modern IAU constellations in 1930. Lacaille kept a single set of Greek letters for the whole of Argo, and separate sets of Latin letter designations for each of the three sections. Therefore, Carina has the \u03b1, \u03b2 and \u03b5, Vela has \u03b3 and \u03b4, Puppis has \u03b6, and so on.\nNotable features.\nStars.\nCarina contains Canopus, a white-hued supergiant that is the second-brightest star in the night sky at magnitude \u22120.72. Alpha Carinae, as Canopus is formally designated, is 313 light-years from Earth. Its traditional name comes from the mythological Canopus, who was a navigator for Menelaus, king of Sparta.\nThere are several other stars above magnitude 3 in Carina. Beta Carinae, traditionally called Miaplacidus, is a blue-white-hued star of magnitude 1.7, 111 light-years from Earth. Epsilon Carinae is an orange-hued giant star similarly bright to Miaplacidus at magnitude 1.9; it is 630 light-years from Earth. Another fairly bright star is the blue-white-hued Theta Carinae; it is a magnitude 2.7 star 440 light-years from Earth. Theta Carinae is also the most prominent member of the cluster IC 2602. Iota Carinae is a white-hued supergiant star of magnitude 2.2, 690 light-years from Earth.\nEta Carinae is the most prominent variable star in Carina, with a mass of approximately 100 solar masses and 4 million times as bright as the Sun. It was first discovered to be unusual in 1677, when its magnitude suddenly rose to 4, attracting the attention of Edmond Halley. Eta Carinae is inside NGC 3372, commonly called the Carina Nebula. It had a long outburst in 1827, when it brightened to magnitude 1, only fading to magnitude 1.5 in 1828. Its most prominent outburst made Eta Carinae the equal of Sirius; it brightened to magnitude \u22121.5 in 1843. In the decades following 1843 it appeared relatively placid, having a magnitude between 6.5 and 7.9. However, in 1998, it brightened again, though only to magnitude 5.0, a far less drastic outburst. Eta Carinae is a binary star, with a companion that has a period of 5.5 years; the two stars are surrounded by the Homunculus Nebula, which is composed of gas that was ejected in 1843.\nThere are several less prominent variable stars in Carina. l Carinae is a Cepheid variable noted for its brightness; it is the brightest Cepheid that is variable to the unaided eye. It is a yellow-hued supergiant star with a minimum magnitude of 4.2 and a maximum magnitude of 3.3; it has a period of 35.5 days.\nV382 Carinae is a yellow hypergiant, one of the rarest types of stars. It is a slow irregular variable, with a minimum magnitude of 4.05 and a maximum magnitude of 3.77. As a hypergiant, V382 Carinae is a luminous star, with 212,000 times more luminosity than the Sun and over 480 times the Sun's size.\nTwo bright Mira variable stars are in Carina: R Carinae and S Carinae; both stars are red giants. R Carinae has a minimum magnitude of 10.0 and a maximum magnitude of 4.0. Its period is 309 days and it is 416 light-years from Earth. S Carinae is similar, with a minimum magnitude of 10.0 and a maximum magnitude of 5.0. However, S Carinae has a shorter period\u2014150 days, though it is much more distant at 1,300 light-years from Earth.\nCarina is home to several double stars and binary stars. Upsilon Carinae is a binary star with two blue-white-hued giant components, 1,600 light-years from Earth. The primary is of magnitude 3.0 and the secondary is of magnitude 6.0; the two components are distinguishable in a small amateur telescope.\nTwo asterisms are prominent in Carina. The 'Diamond Cross' is composed of the stars Beta, Theta, Upsilon and Omega Carinae. The Diamond Cross is visible south of 20\u00baN latitude, and is larger but fainter than the Southern Cross in Crux. Flanking the Diamond Cross is the False cross, composed of four stars - two stars in Carina, Iota Carinae and Epsilon Carinae, and two stars in Vela, Kappa Velorum and Delta Velorum - and is often mistaken for the Southern Cross, causing errors in astronavigation.\nDeep-sky objects.\nCarina is known for its namesake nebula, NGC 3372, discovered by French astronomer Nicolas-Louis de Lacaille in 1751, which contains several nebulae. The Carina Nebula overall is an extended emission nebula approximately 8,000 light-years away and 300 light-years wide that includes vast star-forming regions. It has an overall magnitude of 8.0 and an apparent diameter of over 2 degrees. Its central region is called the Keyhole, or the Keyhole Nebula. This was described in 1847 by John Herschel, and likened to a keyhole by Emma Converse in 1873. The Keyhole is about seven light-years wide and is composed mostly of ionized hydrogen, with two major star-forming regions. The Homunculus Nebula is a planetary nebula visible to the naked eye that is being ejected by the erratic luminous blue variable star Eta Carinae, the most massive visible star known. Eta Carinae is so massive that it has reached the theoretical upper limit for the mass of a star and is therefore unstable. It is known for its outbursts; in 1840 it briefly became one of the brightest stars in the sky due to a particularly massive outburst, which largely created the Homunculus Nebula. Because of this instability and history of outbursts, Eta Carinae is considered a prime supernova candidate for the next several hundred thousand years because it has reached the end of its estimated million-year life span.\nNGC 2516 is an open cluster that is both quite large (approximately half a degree square) and bright, visible to the unaided eye. It is located 1,100 light-years from Earth and has approximately 80 stars, the brightest of which is a red giant star of magnitude 5.2. NGC 3114 is another open cluster approximately of the same size, though it is more distant at 3,000 light-years from Earth. It is more loose and dim than NGC 2516, as its brightest stars are only 6th magnitude. The most prominent open cluster in Carina is IC 2602, also called the \"Southern Pleiades\". It contains Theta Carinae, along with several other stars visible to the unaided eye. In total, the cluster possesses approximately 60 stars. The Southern Pleiades is particularly large for an open cluster, with a diameter of approximately one degree. Like IC 2602, NGC 3532 is visible to the unaided eye and is of comparable size. It possesses approximately 150 stars that are arranged in an unusual shape, approximating an ellipse with a dark central area. Several prominent orange giants are among the cluster's bright stars, of the 7th magnitude. Superimposed on the cluster is Chi Carinae, a yellow-white-hued star of magnitude 3.9, far more distant than NGC 3532.\nCarina also contains the naked-eye globular cluster NGC 2808. Epsilon Carinae and Upsilon Carinae are double stars visible in small telescopes.\nOne noted galaxy cluster is 1E 0657-56, the Bullet Cluster. At a distance of 4 billion light-years (redshift 0.296), this galaxy cluster is named for the shock wave seen in the intracluster medium, which resembles the shock wave of a supersonic bullet. The bow shock visible is thought to be due to the smaller galaxy cluster moving through the intracluster medium at a relative speed of 3,000\u20134,000 kilometers per second to the larger cluster. Because this gravitational interaction has been ongoing for hundreds of millions of years, the smaller cluster is being destroyed and will eventually merge with the larger cluster.\nMeteors.\nCarina contains the radiant of the Eta Carinids meteor shower, which peaks around January 21 each year.\nEquivalents.\nFrom China (especially northern China), the stars of Carina can barely be seen. The star Canopus (the south polar star in Chinese astronomy) was located by Chinese astronomers in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). The rest of the stars were first classified by Xu Guanggi during the Ming dynasty, based on the knowledge acquired from western star charts, and placed among The Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\").\nPolynesian peoples had no name for the constellation in particular, though they had many names for Canopus.\nThe M\u0101ori name \"Ariki\" (\"High-born\"), and the Hawaiian \"Ke Alii-o-kona-i-ka-lewa\", \"The Chief of the southern expanse\" both attest to the star's prominence in the southern sky, while the M\u0101ori \"Atutahi\", \"First-light\" or \"Single-light\", and the Tuamotu \"Te Tau-rari\" and \"Marere-te-tavahi\", \"He who stands alone\". refer to the star's solitary nature.\nIt was also called \"Kapae-poto\" (\"Short horizon\"), because it rarely sets from the vantage point of New Zealand, and \"Kauanga\" (\"Solitary\"), when it was the last star visible before sunrise.\nFuture.\nCarina is in the southern sky quite near the south celestial pole, making it never set (circumpolar) for most of the southern hemisphere. Due to precession of Earth's axis, by the year 4700 the south celestial pole will be in Carina. Three bright stars in Carina will come within 1 degree of the southern celestial pole and take turns as the southern pole star: Omega Carinae (mag 3.29) in 5600, Upsilon Carinae (mag 2.97) in 6700, and Iota Carinae (mag 2.21) in 7900. About 13,860 CE, the bright Canopus (\u22120.7) will have a greater declination than \u221282\u00b0.\nNamesakes.\n was a United States Navy \"Crater\"-class cargo ship named after the constellation.\nthe Toyota Carina was named after it."}
{"id": "6364", "revid": "1249243641", "url": "https://en.wikipedia.org/wiki?curid=6364", "title": "Camelopardalis", "text": "Camelopardalis is a large but faint constellation of the northern sky representing a giraffe. The constellation was introduced in 1612 or 1613 by Petrus Plancius. Some older astronomy books give Camelopardalus or Camelopardus as alternative forms of the name, but the version recognized by the International Astronomical Union matches the genitive form, seen suffixed to most of its key stars.\nEtymology.\nFirst attested in English in 1785, the word \"camelopardalis\" comes from Latin, and it is the romanization of the Greek \"\u03ba\u03b1\u03bc\u03b7\u03bb\u03bf\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" meaning \"giraffe\", from \"\u03ba\u03ac\u03bc\u03b7\u03bb\u03bf\u03c2\" (\"kam\u0113los\"), \"camel\" + \"\u03c0\u03ac\u03c1\u03b4\u03b1\u03bb\u03b9\u03c2\" (\"pardalis\"), \"spotted\", because it has a long neck like a camel and spots like a leopard.\nFeatures.\nStars.\nAlthough Camelopardalis is the 18th largest constellation, it is not a particularly bright constellation, as the brightest stars are only of fourth magnitude. In fact, it only contains four stars brighter than magnitude 5.0.\nOther variable stars are U Camelopardalis, VZ Camelopardalis, and Mira variables T Camelopardalis, X Camelopardalis, and R Camelopardalis. RU Camelopardalis is one of the brighter Type II Cepheids visible in the night sky.\nIn 2011 a supernova was discovered in the constellation.\nDeep-sky objects.\nCamelopardalis is in the part of the celestial sphere facing away from the galactic plane. Accordingly, many distant galaxies are visible within its borders. \nMeteor showers.\nThe annual May meteor shower Camelopardalids from comet 209P/LINEAR have a radiant in Camelopardalis.\nHistory.\nCamelopardalis is not one of Ptolemy's 48 constellations in the \"Almagest\". It was created by Petrus Plancius in 1613. It first appeared in a globe designed by him and produced by Pieter van den Keere. One year later, Jakob Bartsch featured it in his atlas. Johannes Hevelius depicted this constellation in his works which were so influential that it was referred to as Camelopardali Hevelii or abbreviated as Camelopard. Hevel.\nPart of the constellation was hived off to form the constellation Sciurus Volans, the Flying Squirrel, by William Croswell in 1810. However this was not taken up by later cartographers.\nEquivalents.\nIn Chinese astronomy, the stars of Camelopardalis are located within a group of circumpolar stars called the Purple Forbidden Enclosure (\u7d2b\u5fae\u57a3 \"Z\u01d0 W\u0113i Yu\u00e1n\")."}
{"id": "6365", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=6365", "title": "Convention of Kanagawa", "text": "The Convention of Kanagawa, also known as the Kanagawa Treaty (, \"Kanagawa J\u014dyaku\") or the Japan\u2013US Treaty of Peace and Amity (, \"Nichibei Washin J\u014dyaku\"), was a treaty signed between the United States and the Tokugawa Shogunate on March 31, 1854. Signed under threat of force, it effectively meant the end of Japan's 220-year-old policy of national seclusion (\"sakoku\") by opening the ports of Shimoda and Hakodate to American vessels. It also ensured the safety of American castaways and established the position of an American consul in Japan. The treaty precipitated the signing of similar treaties establishing diplomatic relations with other Western powers.\nIsolation of Japan.\nSince the beginning of the 17th century, the Tokugawa Shogunate pursued a policy of isolating the country from outside influences. Foreign trade was maintained only with the Dutch and the Chinese and was conducted exclusively at Nagasaki under a strict government monopoly. This \"Pax Tokugawa\" period is largely associated with domestic peace, social stability, commercial development, and expanded literacy. This policy had two main objectives:\nBy the early 19th century, this policy of isolation was increasingly under challenge. In 1844, King William II of the Netherlands sent a letter urging Japan to end the isolation policy on its own before change would be forced from the outside. In 1846, an official American expedition led by Commodore James Biddle arrived in Japan asking for ports to be opened for trade but was sent away.\nPerry expedition.\nIn 1853, United States Navy Commodore Matthew C. Perry was sent with a fleet of warships by U.S. President Millard Fillmore to force the opening of Japanese ports to American trade, through the use of gunboat diplomacy if necessary. President Fillmore's letter shows the U.S. sought trade with Japan to open export markets for American goods like gold from California, enable U.S. ships to refuel in Japanese ports, and secure protections and humane treatment for any American sailors shipwrecked on Japan's shores. The growing commerce between America and China, the presence of American whalers in waters offshore Japan, and the increasing monopolization of potential coaling stations by the British and French in Asia were all contributing factors. The Americans were also driven by concepts of manifest destiny and the desire to impose the perceived benefits of western civilization and Christianity on what they perceived as backward Asian nations. From the Japanese perspective, increasing contacts with foreign warships and the increasing disparity between western military technology and the Japanese feudal armies fostered growing concern. The Japanese had been keeping abreast of world events via information gathered from Dutch traders in Dejima and had been forewarned by the Dutch of Perry's voyage. There was a considerable internal debate in Japan on how best to meet this potential threat to Japan's economic and political sovereignty in light of events occurring in China with the Opium Wars.\nPerry arrived with four warships at Uraga, at the mouth of Edo Bay on July 8, 1853. He blatantly refused Japanese demands that he proceed to Nagasaki, which was the designated port for foreign contact. After threatening to continue directly on to Edo, the nation's capital, and to burn it to the ground if necessary, he was allowed to land at nearby Kurihama on July 14 and to deliver his letter. Such refusal was intentional, as Perry wrote in his journal: \u201cTo show these princes how little I regarded their order for me to depart, on getting on board I immediately ordered the whole squadron underway, not to leave the bay\u2026 but to go higher up\u2026 would produce a decided influence upon the pride and conceit of the government, and cause a more favorable consideration of the President\u2019s letter.\" Perry's power front did not stop with refusing to land in Uraga, but he continued to push the boundaries of the Japanese. He ordered the squadron to survey Edo bay, which led to a stand-off between Japanese officers with swords and Americans with guns. By firing the guns into the water, Perry demonstrated their military might, which greatly affected Japanese perceptions of Perry and the United States. Namely, a perception of fear and disrespect.\nDespite years of debate on the isolation policy, Perry's letter created great controversy within the highest levels of the Tokugawa shogunate. The \"sh\u014dgun\" himself, Tokugawa Ieyoshi, died days after Perry's departure and was succeeded by his sickly young son, Tokugawa Iesada, leaving effective administration in the hands of the Council of Elders (\"r\u014dj\u016b\") led by Abe Masahiro. Abe felt that it was impossible for Japan to resist the American demands by military force and yet was reluctant to take any action on his own authority for such an unprecedented situation. Attempting to legitimize any decision taken, Abe polled all of the \"daimy\u014d\" for their opinions. This was the first time that the Tokugawa shogunate had allowed its decision-making to be a matter of public debate and had the unforeseen consequence of portraying the shogunate as weak and indecisive. The results of the poll also failed to provide Abe with an answer; of the 61 known responses, 19 were in favour of accepting the American demands and 19 were equally opposed. Of the remainder, 14 gave vague responses expressing concern of possible war, 7 suggested making temporary concessions and 2 advised that they would simply go along with whatever was decided.\nPerry returned again on February 11, 1854, with an even larger force of eight warships and made it clear that he would not be leaving until a treaty was signed. Perry continued his manipulation of the setting, such as keeping himself aloof from lower-ranking officials, implying the use of force, surveying the harbor, and refusing to meet in the designated negotiation sites. Negotiations began on March 8 and proceeded for around one month. Each party shared a performance when Perry arrived. The Americans had a technology demonstration, and the Japanese had a sumo wrestling show. While the new technology awed the Japanese people, Perry was unimpressed by the sumo wrestlers and perceived such performance as foolish and degrading: \u201cThis disgusting exhibition did not terminate until the whole twenty-five had, successively, in pairs, displayed their immense powers and savage qualities.\" The Japanese side gave in to almost all of Perry's demands, with the exception of a commercial agreement modelled after previous American treaties with China, which Perry agreed to defer to a later time. The main controversy centered on the selection of the ports to open, with Perry adamantly rejecting Nagasaki.\nThe treaty, written in English, Dutch, Chinese and Japanese, was signed on March 31, 1854, at what is now Kaik\u014d Hiroba (Port Opening Square) Yokohama, a site adjacent to the current Yokohama Archives of History. The celebratory events for the signing ceremony included a Kabuki play from the Japanese side and, from the American side, U.S. military band music and blackface minstrelsy.\nTreaty of Peace and Amity (1854).\nThe \"Japan-US Treaty of Peace and Amity\" has twelve articles: \nAt the time, \"sh\u014dgun\" Tokugawa Iesada was the de facto ruler of Japan; for the Emperor of Japan to interact in any way with foreigners was out of the question. Perry concluded the treaty with representatives of the shogun, led by plenipotentiary and the text was endorsed subsequently, albeit reluctantly, by Emperor K\u014dmei.\nThe treaty was ratified on February 21, 1855.\nConsequences of the treaty.\nIn the short term, the U.S. was content with the agreement since Perry had achieved his primary objective of breaking Japan's \"sakoku\" policy and setting the grounds for protection of American citizens and an eventual commercial agreement. On the other hand, the Japanese were forced into this trade, and many saw it as a sign of weakness. The Tokugawa shogunate could point out that the treaty was not actually signed by the shogun, or indeed any of his \"r\u014dj\u016b\", and that it had at least temporarily averted the possibility of immediate military confrontation.\nExternally, the treaty led to the United States-Japan Treaty of Amity and Commerce, the \"Harris Treaty\" of 1858, which allowed the establishment of foreign concessions, extraterritoriality for foreigners, and minimal import taxes for foreign goods. The Japanese chafed under the \"unequal treaty system\" which characterized Asian and western relations during this period. The Kanagawa treaty was also followed by similar agreements with the United Kingdom (Anglo-Japanese Friendship Treaty, October 1854), Russia (Treaty of Shimoda, February 7, 1855), and France (Treaty of Amity and Commerce between France and Japan, October 9, 1858).\nInternally, the treaty had far-reaching consequences. Decisions to suspend previous restrictions on military activities led to re-armament by many domains and further weakened the position of the shogun. Debate over foreign policy and popular outrage over perceived appeasement to the foreign powers was a catalyst for the \"sonn\u014d j\u014di\" movement and a shift in political power from Edo back to the Imperial Court in Kyoto. The opposition of Emperor K\u014dmei to the treaties further lent support to the \"t\u014dbaku\" (overthrow the shogunate) movement, and eventually to the Meiji Restoration, which affected all realms of Japanese life. Following this period came an increase in foreign trade, the rise of Japanese military might, and the later rise of Japanese economic and technological advancement. Westernization at the time was a defense mechanism, but Japan has since found a balance between Western modernity and Japanese tradition."}
{"id": "6366", "revid": "82432", "url": "https://en.wikipedia.org/wiki?curid=6366", "title": "Canis Major", "text": "Canis Major is a constellation in the southern celestial hemisphere. In the second century, it was included in Ptolemy's 48 constellations, and is counted among the 88 modern constellations. Its name is Latin for \"greater dog\" in contrast to Canis Minor, the \"lesser dog\"; both figures are commonly represented as following the constellation of Orion the hunter through the sky. The Milky Way passes through Canis Major and several open clusters lie within its borders, most notably M41.\nCanis Major contains Sirius, the brightest star in the night sky, known as the \"dog star\". It is bright because of its proximity to the Solar System and its intrinsic brightness. In contrast, the other bright stars of the constellation are stars of great distance and high luminosity. At magnitude 1.5, Epsilon Canis Majoris (Adhara) is the second-brightest star of the constellation and the brightest source of extreme ultraviolet radiation in the night sky. Next in brightness are the yellow-white supergiant Delta (Wezen) at 1.8, the blue-white giant Beta (Mirzam) at 2.0, blue-white supergiants Eta (Aludra) at 2.4 and Omicron2 at 3.0, and white spectroscopic binary Zeta (Furud), also at 3.0. The red hypergiant VY CMa is one of the largest stars known, while the neutron star RX J0720.4-3125 has a radius of a mere 5\u00a0km.\nHistory and mythology.\nIn western astronomy.\nIn ancient Mesopotamia, Sirius, named KAK.SI.SA2 by the Babylonians, was seen as an arrow aiming towards Orion, while the southern stars of Canis Major and a part of Puppis were viewed as a bow, named BAN in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later compendium of Babylonian astronomy and astrology titled \"MUL.APIN\", the arrow, Sirius, was also linked with the warrior Ninurta, and the bow with Ishtar, daughter of Enlil. Ninurta was linked to the later deity Marduk, who was said to have slain the ocean goddess Tiamat with a great bow, and worshipped as the principal deity in Babylon. The Ancient Greeks replaced the bow and arrow depiction with that of a dog.\nIn Greek Mythology, Canis Major represented the dog Laelaps, a gift from Zeus to Europa; or sometimes the hound of Procris, Diana's nymph; or the one given by Aurora to Cephalus, so famed for its speed that Zeus elevated it to the sky. It was also considered to represent one of Orion's hunting dogs, pursuing Lepus the Hare or helping Orion fight Taurus the Bull; and is referred to in this way by Aratos, Homer and Hesiod. The ancient Greeks refer only to one dog, but by Roman times, Canis Minor appears as Orion's second dog. Alternative names include Canis Sequens and Canis Alter. Canis Syrius was the name used in the 1521 \"Alfonsine tables\".\nThe Roman myth refers to Canis Major as \"Custos Europae\", the dog guarding Europa but failing to prevent her abduction by Jupiter in the form of a bull, and as \"Janitor Lethaeus\", \"the watchdog\". In medieval Arab astronomy, the constellation became \"al-Kalb al-Akbar\", \"the Greater Dog\", transcribed as \"Alcheleb Alachbar\" by 17th century writer Edmund Chilmead. Islamic scholar Ab\u016b Ray\u1e25\u0101n al-B\u012br\u016bn\u012b referred to Orion as \"Kalb al-Jabb\u0101r\", \"the Dog of the Giant\". Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Major and Canis Minor and is the herald of two weeks of hot weather.\nIn non-western astronomy.\nIn Chinese astronomy, the modern constellation of Canis Major is located in the Vermilion Bird (), where the stars were classified in several separate asterisms of stars. The Military Market () was a circular pattern of stars containing Nu3, Beta, Xi1 and Xi2, and some stars from Lepus. The Wild Cockerel () was at the centre of the Military Market, although it is uncertain which stars depicted what. Schlegel reported that the stars Omicron and Pi Canis Majoris might have been them, while Beta or Nu2 have also been proposed. Sirius was ' (), the Celestial Wolf, denoting invasion and plunder. Southeast of the Wolf was the asterism ' (), the celestial Bow and Arrow, which was interpreted as containing Delta, Epsilon, Eta and Kappa Canis Majoris and Delta Velorum. Alternatively, the arrow was depicted by Omicron2 and Eta and aiming at Sirius (the Wolf), while the bow comprised Kappa, Epsilon, Sigma, Delta and 164 Canis Majoris, and Pi and Omicron Puppis.\nBoth the M\u0101ori people and the people of the Tuamotus recognized the figure of Canis Major as a distinct entity, though it was sometimes absorbed into other constellations. ', also called ' and ', (\"The Assembly of \" or \"The Assembly of Sirius\") was a M\u0101ori constellation that included both Canis Minor and Canis Major, along with some surrounding stars. Related was ', also called ', the Mirror of , formed from an undefined group of stars in Canis Major. They called Sirius ' and ', corresponding to two of the names for the constellation, though ' was a name applied to other stars in various M\u0101ori groups and other Polynesian cosmologies. The Tuamotu people called Canis Major \"\", \"the abiding assemblage of \".\nThe Tharumba people of the Shoalhaven River saw three stars of Canis Major as ' (Bat) and his two wives ' (Mrs Brown Snake) and ' (Mrs Black Snake); bored of following their husband around, the women try to bury him while he is hunting a wombat down its hole. He spears them and all three are placed in the sky as the constellation '. To the Boorong people of Victoria, Sigma Canis Majoris was ' (which has become the official name of this star), and its flanking stars Delta and Epsilon were his two wives. The moon (', \"native cat\") sought to lure the further wife (Epsilon) away, but assaulted him and he has been wandering the sky ever since.\nCharacteristics.\nCanis Major is a constellation in the Southern Hemisphere's summer (or northern hemisphere's winter) sky, bordered by Monoceros (which lies between it and Canis Minor) to the north, Puppis to the east and southeast, Columba to the southwest, and Lepus to the west. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CMa\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a quadrilateral; in the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between \u221211.03\u00b0 and \u221233.25\u00b0. Covering 380 square degrees or 0.921% of the sky, it ranks 43rd of the 88 currently-recognized constellations in size.\nFeatures.\nStars.\nCanis Major is a prominent constellation because of its many bright stars. These include Sirius (Alpha Canis Majoris), the brightest star in the night sky, as well as three other stars above magnitude 2.0. Furthermore, two other stars are thought to have previously outshone all others in the night sky\u2014Adhara (Epsilon Canis Majoris) shone at \u22123.99 around 4.7\u00a0million years ago, and Mirzam (Beta Canis Majoris) peaked at \u22123.65 around 4.42\u00a0million years ago. Another, NR Canis Majoris, will be brightest at magnitude \u22120.88 in about 2.87\u00a0million years' time.\nThe German cartographer Johann Bayer used the Greek letters Alpha through Omicron to label the most prominent stars in the constellation, including three adjacent stars as Nu and two further pairs as Xi and Omicron, while subsequent observers designated further stars in the southern parts of the constellation that were hard to discern from Central Europe. Bayer's countryman Johann Elert Bode later added Sigma, Tau and Omega; the French astronomer Nicolas Louis de Lacaille added lettered stars a to k (though none are in use today). John Flamsteed numbered 31 stars, with 3 Canis Majoris being placed by Lacaille into Columba as Delta Columbae (Flamsteed had not recognised Columba as a distinct constellation). He also labelled two stars\u2014his 10 and 13 Canis Majoris\u2014as Kappa1 and Kappa2 respectively, but subsequent cartographers such as Francis Baily and John Bevis dropped the fainter former star, leaving Kappa2 as the sole Kappa. Flamsteed's listing of Nu1, Nu2, Nu3, Xi1, Xi2, Omicron1 and Omicron2 have all remained in use.\nSirius is the brightest star in the night sky at apparent magnitude \u22121.46 and one of the closest stars to Earth at a distance of 8.6 light-years. Its name comes from the Greek word for \"scorching\" or \"searing\". Sirius is also a binary star; its companion Sirius B is a white dwarf with a magnitude of 8.4\u201310,000 times fainter than Sirius A to observers on Earth. The two orbit each other every 50 years. Their closest approach last occurred in 1993 and they will be at their greatest separation between 2020 and 2025. Sirius was the basis for the ancient Egyptian calendar. The star marked the Great Dog's mouth on Bayer's star atlas.\nFlanking Sirius are Beta and Gamma Canis Majoris. Also called Mirzam or Murzim, Beta is a blue-white Beta Cephei variable star of magnitude 2.0, which varies by a few hundredths of a magnitude over a period of six hours. Mirzam is 500 light-years from Earth, and its traditional name means \"the announcer\", referring to its position as the \"announcer\" of Sirius, as it rises a few minutes before Sirius does. Gamma, also known as Muliphein, is a fainter star of magnitude 4.12, in reality a blue-white bright giant of spectral type B8IIe located 441 light-years from earth. Iota Canis Majoris, lying between Sirius and Gamma, is another star that has been classified as a Beta Cephei variable, varying from magnitude 4.36 to 4.40 over a period of 1.92 hours. It is a remote blue-white supergiant star of spectral type B3Ib, around 46,000 times as luminous as the sun and, at 2500 light-years distant, 300 times further away than Sirius.\nEpsilon, Omicron2, Delta, and Eta Canis Majoris were called \"Al Adzari\" \"the virgins\" in medieval Arabic tradition. Marking the dog's right thigh on Bayer's atlas is Epsilon Canis Majoris, also known as Adhara. At magnitude 1.5, it is the second-brightest star in Canis Major and the 23rd-brightest star in the sky. It is a blue-white supergiant of spectral type B2Iab, around 404 light-years from Earth. This star is one of the brightest known extreme ultraviolet sources in the sky. It is a binary star; the secondary is of magnitude 7.4. Its traditional name means \"the virgins\", having been transferred from the group of stars to Epsilon alone. Nearby is Delta Canis Majoris, also called Wezen. It is a yellow-white supergiant of spectral type F8Iab and magnitude 1.84, around 1605 light-years from Earth. With a traditional name meaning \"the weight\", Wezen is 17 times as massive and 50,000 times as luminous as the Sun. If located in the centre of the Solar System, it would extend out to Earth as its diameter is 200 times that of the Sun. Only around 10\u00a0million years old, Wezen has stopped fusing hydrogen in its core. Its outer envelope is beginning to expand and cool, and in the next 100,000 years it will become a red supergiant as its core fuses heavier and heavier elements. Once it has a core of iron, it will collapse and explode as a supernova. Nestled between Adhara and Wezen lies Sigma Canis Majoris, known as Unurgunite to the Boorong and Wotjobaluk people, a red supergiant of spectral type K7Ib that varies irregularly between magnitudes 3.43 and 3.51.\nAlso called Aludra, Eta Canis Majoris is a blue-white supergiant of spectral type B5Ia with a luminosity 176,000 times and diameter around 80 times that of the Sun. Classified as an Alpha Cygni type variable star, Aludra varies in brightness from magnitude 2.38 to 2.48 over a period of 4.7 days. It is located 1120 light-years away. To the west of Adhara lies 3.0-magnitude Zeta Canis Majoris or Furud, around 362 light-years distant from Earth. It is a spectroscopic binary, whose components orbit each other every 1.85 years, the combined spectrum indicating a main star of spectral type B2.5V.\nBetween these stars and Sirius lie Omicron1, Omicron2, and Pi Canis Majoris. Omicron2 is a massive supergiant star about 21 times as massive as the Sun. Only 7\u00a0million years old, it has exhausted the supply of hydrogen at its core and is now processing helium. It is an Alpha Cygni variable that undergoes periodic non-radial pulsations, which cause its brightness to cycle from magnitude 2.93 to 3.08 over a 24.44-day interval. Omicron1 is an orange K-type supergiant of spectral type K2.5Iab that is an irregular variable star, varying between apparent magnitudes 3.78 and 3.99. Around 18 times as massive as the Sun, it shines with 65,000 times its luminosity.\nNorth of Sirius lie Theta and Mu Canis Majoris, Theta being the most northerly star with a Bayer designation in the constellation. Around 8\u00a0billion years old, it is an orange giant of spectral type K4III that is around as massive as the Sun but has expanded to 30 times the Sun's diameter. Mu is a multiple star system located around 1244 light-years distant, its components discernible in a small telescope as a 5.3-magnitude yellow-hued and 7.1-magnitude bluish star. The brighter star is a giant of spectral type K2III, while the companion is a main sequence star of spectral type B9.5V. Nu1 Canis Majoris is a yellow-hued giant star of magnitude 5.7, 278 light-years away; it is at the threshold of naked-eye visibility. It has a companion of magnitude 8.1.\nAt the southern limits of the constellation lie Kappa and Lambda Canis Majoris. Although of similar spectra and nearby each other as viewed from Earth, they are unrelated. Kappa is a Gamma Cassiopeiae variable of spectral type B2Vne, which brightened by 50% between 1963 and 1978, from magnitude 3.96 or so to 3.52. It is around 659 light-years distant. Lambda is a blue-white B-type main sequence dwarf with an apparent magnitude of 4.48 located around 423 light-years from Earth. It is 3.7 times as wide as and 5.5 times as massive as the Sun, and shines with 940 times its luminosity.\nCanis Major is also home to many variable stars. EZ Canis Majoris is a Wolf\u2013Rayet star of spectral type WN4 that varies between magnitudes 6.71 and 6.95 over a period of 3.766 days; the cause of its variability is unknown but thought to be related to its stellar wind and rotation. VY Canis Majoris is a remote red hypergiant located approximately 3,800 light-years away from Earth. It is one of largest stars known (sometimes described as the largest known) and is also one of the most luminous with a radius varying from 1,420 to 2,200 times the Sun's radius, and a luminosity around 300,000 times greater than the Sun. Its current mass is about 17 \u00b1 8 solar masses, having shed material from an initial mass of 25\u201332 solar masses. VY CMa is also surrounded by a red reflection nebula that has been made by the material expelled by the strong stellar winds of its central star. W Canis Majoris is a type of red giant known as a carbon star\u2014a semiregular variable, it ranges between magnitudes 6.27 and 7.09 over a period of 160 days. A cool star, it has a surface temperature of around 2,900 K and a radius 234 times that of the Sun, its distance estimated at 1,444\u20131,450 light-years from Earth. At the other extreme in size is RX J0720.4-3125, a neutron star with a radius of around 5\u00a0km. Exceedingly faint, it has an apparent magnitude of 26.6. Its spectrum and temperature appear to be mysteriously changing over several years. The nature of the changes are unclear, but it is possible they were caused by an event such as the star's absorption of an accretion disc.\nTau Canis Majoris is a Beta Lyrae-type eclipsing multiple star system that varies from magnitude 4.32 to 4.37 over 1.28 days. Its four main component stars are hot O-type stars, with a combined mass 80 times that of the Sun and shining with 500,000 times its luminosity, but little is known of their individual properties. A fifth component, a magnitude 10 star, lies at a distance of . The system is only 5\u00a0million years old. UW Canis Majoris is another Beta Lyrae-type star 3000 light-years from Earth; it is an eclipsing binary that ranges in magnitude from a minimum of 5.3 to a maximum of 4.8. It has a period of 4.4 days; its components are two massive hot blue stars, one a blue supergiant of spectral type O7.5\u20138 Iab, while its companion is a slightly cooler, less evolved and less luminous supergiant of spectral type O9.7Ib. The stars are 200,000 and 63,000 times as luminous as the Sun. However the fainter star is the more massive at 19 solar masses to the primary's 16. R Canis Majoris is another eclipsing binary that varies from magnitude 5.7 to 6.34 over 1.13 days, with a third star orbiting these two every 93 years. The shortness of the orbital period and the low ratio between the two main components make this an unusual Algol-type system.\nSeven star systems have been found to have planets. Nu2 Canis Majoris is an ageing orange giant of spectral type K1III of apparent magnitude 3.91 located around 64 light-years distant. Around 1.5 times as massive and 11 times as luminous as the Sun, it is orbited over a period of 763 days by a planet 2.6 times as massive as Jupiter. HD 47536 is likewise an ageing orange giant found to have a planetary system\u2014echoing the fate of the Solar System in a few billion years as the Sun ages and becomes a giant. Conversely, HD 45364 is a star 107 light-years distant that is a little smaller and cooler than the Sun, of spectral type G8V, which has two planets discovered in 2008. With orbital periods of 228 and 342 days, the planets have a 3:2 orbital resonance, which helps stabilise the system. HD 47186 is another sunlike star with two planets; the inner\u2014HD 47186 b\u2014takes four days to complete an orbit and has been classified as a Hot Neptune, while the outer\u2014HD 47186 c\u2014has an eccentric 3.7-year period orbit and has a similar mass to Saturn. HD 43197 is a sunlike star around 183 light-years distant that has two planets: a hot Jupiter-size planet with an eccentric orbit. The other planet, HD 43197 c, is another massive Jovian planet with a slightly oblong orbit outside of its habitable zone. \nZ Canis Majoris is a star system a mere 300,000 years old composed of two pre-main-sequence stars\u2014a FU Orionis star and a Herbig Ae/Be star, which has brightened episodically by two magnitudes to magnitude 8 in 1987, 2000, 2004 and 2008. The more massive Herbig Ae/Be star is enveloped in an irregular roughly spherical cocoon of dust that has an inner diameter of and outer diameter of . The cocoon has a hole in it through which light shines that covers an angle of 5 to 10 degrees of its circumference. Both stars are surrounded by a large envelope of in-falling material left over from the original cloud that formed the system. Both stars are emitting jets of material, that of the Herbig Ae/Be star being much larger\u201411.7 light-years long. Meanwhile, FS Canis Majoris is another star with infra-red emissions indicating a compact shell of dust, but it appears to be a main-sequence star that has absorbed material from a companion. These stars are thought to be significant contributors to interstellar dust.\nDeep-sky objects.\nThe band of the Milky Way goes through Canis Major, with only patchy obscurement by interstellar dust clouds. It is bright in the northeastern corner of the constellation, as well as in a triangular area between Adhara, Wezen and Aludra, with many stars visible in binoculars. Canis Major boasts several open clusters. The only Messier object is M41 (NGC 2287), an open cluster with a combined visual magnitude of 4.5, around 2300 light-years from Earth. Located 4 degrees south of Sirius, it contains contrasting blue, yellow and orange stars and covers an area the apparent size of the full moon\u2014in reality around 25 light-years in diameter. Its most luminous stars have already evolved into giants. The brightest is a 6.3-magnitude star of spectral type K3. Located in the field is 12 Canis Majoris, though this star is only 670 light-years distant. NGC 2360, known as Caroline's Cluster after its discoverer Caroline Herschel, is an open cluster located 3.5 degrees west of Muliphein and has a combined apparent magnitude of 7.2. Around 15 light-years in diameter, it is located 3700 light-years away from Earth, and has been dated to around 2.2\u00a0billion years old. NGC 2362 is a small, compact open cluster, 5200 light-years from Earth. It contains about 60 stars, of which Tau Canis Majoris is the brightest member. Located around 3 degrees northeast of Wezen, it covers an area around 12 light-years in diameter, though the stars appear huddled around Tau when seen through binoculars. It is a very young open cluster as its member stars are only a few million years old. Lying 2 degrees southwest of NGC 2362 is NGC 2354 a fainter open cluster of magnitude 6.5, with around 15 member stars visible with binoculars. Located around 30' northeast of NGC 2360, NGC 2359 (Thor's Helmet or the Duck Nebula) is a relatively bright emission nebula in Canis Major, with an approximate magnitude of 10, which is 10,000 light-years from Earth. The nebula is shaped by HD 56925, an unstable Wolf\u2013Rayet star embedded within it.\nIn 2003, an overdensity of stars in the region was announced to be the Canis Major Dwarf, the closest satellite galaxy to Earth. However, there remains debate over whether it represents a disrupted dwarf galaxy or in fact a variation in the thin and thick disk and spiral arm populations of the Milky Way. Investigation of the area yielded only ten RR Lyrae variables\u2014consistent with the Milky Way's halo and thick disk populations rather than a separate dwarf spheroidal galaxy. On the other hand, a globular cluster in Puppis, NGC 2298\u2014which appears to be part of the Canis Major dwarf system\u2014is extremely metal-poor, suggesting it did not arise from the Milky Way's thick disk, and instead is of extragalactic origin.\nNGC 2207 and IC 2163 are a pair of face-on interacting spiral galaxies located 125\u00a0million light-years from Earth. About 40\u00a0million years ago, the two galaxies had a close encounter and are now moving farther apart; nevertheless, the smaller IC 2163 will eventually be incorporated into NGC 2207. As the interaction continues, gas and dust will be perturbed, sparking extensive star formation in both galaxies. Supernovae have been observed in NGC 2207 in 1975 (type Ia SN 1975a), 1999 (the type Ib SN 1999ec), 2003 (type 1b supernova SN 2003H), and 2013 (type II supernova SN 2013ai). Located 16\u00a0million light-years distant, ESO 489-056 is an irregular dwarf- and low-surface-brightness galaxy that has one of the lowest metallicities known."}
{"id": "6367", "revid": "3492060", "url": "https://en.wikipedia.org/wiki?curid=6367", "title": "Canis Minor", "text": "Canis Minor is a small constellation in the northern celestial hemisphere. In the second century, it was included as an asterism, or pattern, of two stars in Ptolemy's 48 constellations, and it is counted among the 88 modern constellations. Its name is Latin for \"lesser dog\", in contrast to Canis Major, the \"greater dog\"; both figures are commonly represented as following the constellation of Orion the hunter.\nCanis Minor contains only two stars brighter than the fourth magnitude, Procyon (Alpha Canis Minoris), with a magnitude of 0.34, and Gomeisa (Beta Canis Minoris), with a magnitude of 2.9. The constellation's dimmer stars were noted by Johann Bayer, who named eight stars including Alpha and Beta, and John Flamsteed, who numbered fourteen. Procyon is the eighth-brightest star in the night sky, as well as one of the closest. A yellow-white main-sequence star, it has a white dwarf companion. Gomeisa is a blue-white main-sequence star. Luyten's Star is a ninth-magnitude red dwarf and the Solar System's next closest stellar neighbour in the constellation after Procyon. Additionally, Procyon and Luyten's Star are only 1.12 light-years away from each other, and Procyon would be the brightest star in Luyten's Star's sky. The fourth-magnitude HD 66141, which has evolved into an orange giant towards the end of its life cycle, was discovered to have a planet in 2012. There are two faint deep-sky objects within the constellation's borders. The 11 Canis-Minorids are a meteor shower that can be seen in early December.\nHistory and mythology.\nThough strongly associated with the Classical Greek uranographic tradition, Canis Minor originates from ancient Mesopotamia. Procyon and Gomeisa were called \"MASH.TAB.BA\" or \"twins\" in the \"Three Stars Each\" tablets, dating to around 1100 BC. In the later \"MUL.APIN\", this name was also applied to the pairs of Pi3 and Pi4 Orionis and Zeta and Xi Orionis. The meaning of \"MASH.TAB.BA\" evolved as well, becoming the twin deities Lulal and Latarak, who are on the opposite side of the sky from \"Papsukkal\", the True Shepherd of Heaven in Babylonian mythology. Canis Minor was also given the name \"DAR.LUGAL\", its position defined as \"the star which stands behind it [Orion]\", in the \"MUL.APIN\"; the constellation represents a rooster. This name may have also referred to the constellation Lepus. \"DAR.LUGAL\" was also denoted \"DAR.MU\u0160EN\" and \"DAR.LUGAL.MU\u0160EN\" in Babylonia. Canis Minor was then called \"tarlugallu\" in Akkadian astronomy.\nCanis Minor was one of the original 48 constellations formulated by Ptolemy in his second-century Almagest, in which it was defined as a specific pattern (asterism) of stars; Ptolemy identified only two stars and hence no depiction was possible. The Ancient Greeks called the constellation \u03c0\u03c1\u03bf\u03ba\u03c5\u03c9\u03bd/\"Procyon\", \"coming before the dog\", transliterated into Latin as \"Antecanis\", \"Praecanis\", or variations thereof, by Cicero and others. Roman writers also appended the descriptors \"parvus\", \"minor\" or \"minusculus\" (\"small\" or \"lesser\", for its faintness), \"septentrionalis\" (\"northerly\", for its position in relation to Canis Major), \"primus\" (rising \"first\") or \"sinister\" (rising to the \"left\") to its name \"Canis\".\nIn Greek mythology, Canis Minor was sometimes connected with the Teumessian Fox, a beast turned into stone with its hunter, Laelaps, by Zeus, who placed them in heaven as Canis Major (Laelaps) and Canis Minor (Teumessian Fox). Eratosthenes accompanied the Little Dog with Orion, while Hyginus linked the constellation with Maera, a dog owned by Icarius of Athens. On discovering the latter's death, the dog and Icarius' daughter Erigone took their lives and all three were placed in the sky\u2014Erigone as Virgo and Icarius as Bo\u00f6tes. As a reward for his faithfulness, the dog was placed along the \"banks\" of the Milky Way, which the ancients believed to be a heavenly river, where he would never suffer from thirst.\nThe medieval Arabic astronomers maintained the depiction of Canis Minor (\"al-Kalb al-Asghar\" in Arabic) as a dog; in his Book of the Fixed Stars, Abd al-Rahman al-Sufi included a diagram of the constellation with a canine figure superimposed. There was one slight difference between the Ptolemaic vision of Canis Minor and the Arabic; al-Sufi claims Mirzam, now assigned to Orion, as part of both Canis Minor\u2014the collar of the dog\u2014and its modern home. The Arabic names for both Procyon and Gomeisa alluded to their proximity and resemblance to Sirius, though they were not direct translations of the Greek; Procyon was called \"ash-Shi'ra ash-Shamiya\", the \"Syrian Sirius\" and Gomeisa was called \"ash-Shira al-Ghamisa\", the Sirius with bleary eyes. Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called \"Merzem\", includes the stars of Canis Minor and Canis Major and is the herald of two weeks of hot weather.\nThe ancient Egyptians thought of this constellation as Anubis, the jackal god.\nAlternative names have been proposed: Johann Bayer in the early 17th century termed the constellation \"Fovea\" \"The Pit\", and \"Morus\" \"Sycamine Tree\". Seventeenth-century German poet and author Philippus Caesius linked it to the dog of Tobias from the Apocrypha. Richard A. Proctor gave the constellation the name \"Felis\" \"the Cat\" in 1870 (contrasting with Canis Major, which he had abbreviated to \"Canis\" \"the Dog\"), explaining that he sought to shorten the constellation names to make them more manageable on celestial charts. Occasionally, Canis Minor is confused with Canis Major and given the name \"Canis Orionis\" (\"Orion's Dog\").\nIn non-Western astronomy.\nIn Chinese astronomy, the stars corresponding to Canis Minor lie in the Vermilion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"). Procyon, Gomeisa and Eta Canis Minoris form an asterism known as N\u00e1nh\u00e9, the Southern River. With its counterpart, the Northern River Beihe (Castor and Pollux), N\u00e1nh\u00e9 was also associated with a gate or sentry. Along with Zeta and 8 Cancri, 6 Canis Minoris and 11 Canis Minoris formed the asterism \"Shuiwei\", which literally means \"water level\". Combined with additional stars in Gemini, Shuiwei represented an official who managed floodwaters or a marker of the water level. Neighboring Korea recognized four stars in Canis Minor as part of a different constellation, \"the position of the water\". This constellation was located in the Red Bird, the southern portion of the sky.\nPolynesian peoples often did not recognize Canis Minor as a constellation, but they saw Procyon as significant and often named it; in the Tuamotu Archipelago it was known as \"Hiro\", meaning \"twist as a thread of coconut fiber\", and \"Kopu-nui-o-Hiro\" (\"great paunch of Hiro\"), which was either a name for the modern figure of Canis Minor or an alternative name for Procyon. Other names included \"Vena\" (after a goddess), on Mangaia and \"Puanga-hori\" (false \"Puanga\", the name for Rigel), in New Zealand. In the Society Islands, Procyon was called \"Ana-tahua-vahine-o-toa-te-manava\", literally \"Aster the priestess of brave heart\", figuratively the \"pillar for elocution\". The Wardaman people of the Northern Territory in Australia gave Procyon and Gomeisa the names \"Magum\" and \"Gurumana\", describing them as humans who were transformed into gum trees in the dreamtime. Although their skin had turned to bark, they were able to speak with a human voice by rustling their leaves.\nThe Aztec calendar was related to their cosmology. The stars of Canis Minor were incorporated along with some stars of Orion and Gemini into an asterism associated with the day called \"Water\".\nCharacteristics.\nLying directly south of Gemini's bright stars Castor and Pollux, Canis Minor is a small constellation bordered by Monoceros to the south, Gemini to the north, Cancer to the northeast, and Hydra to the east. It does not border Canis Major; Monoceros is in between the two. Covering 183 square degrees, Canis Minor ranks seventy-first of the 88 constellations in size. It appears prominently in the southern sky during the Northern Hemisphere's winter. The constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . Most visible in the evening sky from January to March, Canis Minor is most prominent at 10 p.m. during mid-February. It is then seen earlier in the evening until July, when it is only visible after sunset before setting itself, and rising in the morning sky before dawn. The constellation's three-letter abbreviation, as adopted by the International Astronomical Union in 1922, is \"CMi\".\nFeatures.\nStars.\nCanis Minor contains only two stars brighter than fourth magnitude. At magnitude 0.34, Procyon, or Alpha Canis Minoris, is the eighth-brightest star in the night sky, as well as one of the closest. Its name means \"before the dog\" or \"preceding the dog\" in Greek, as it rises an hour before the \"Dog Star\", Sirius, of Canis Major. It is a binary star system, consisting of a yellow-white main-sequence star of spectral type F5\u00a0IV-V, named Procyon\u00a0A, and a faint white dwarf companion of spectral type DA, named Procyon\u00a0B. Procyon\u00a0B, which orbits the more massive star every 41 years, is of magnitude 10.7. Procyon\u00a0A is 1.4 times the Sun's mass, while its smaller companion is 0.6 times as massive as the Sun. The system is from Earth, the shortest distance to a northern-hemisphere star of the first magnitude. Gomeisa, or Beta Canis Minoris, with a magnitude of 2.89, is the second-brightest star in Canis Minor. Lying from the Solar System, it is a blue-white main-sequence star of spectral class B8\u00a0Ve. Although fainter to Earth observers, it is much brighter than Procyon, and is 250 times as luminous and three times as massive as the Sun. Although its variations are slight, Gomeisa is classified as a shell star (Gamma Cassiopeiae variable), with a maximum magnitude of 2.84 and a minimum magnitude of 2.92. It is surrounded by a disk of gas which it heats and causes to emit radiation.\nJohann Bayer used the Greek letters Alpha to Eta to label the most prominent eight stars in the constellation, designating two stars as Delta (named Delta1 and Delta2). John Flamsteed numbered fourteen stars, discerning a third star he named Delta3; his star 12 Canis Minoris was not found subsequently. In Bayer's 1603 work \"Uranometria\", Procyon is located on the dog's belly, and Gomeisa on its neck. Gamma, Epsilon and Eta Canis Minoris lie nearby, marking the dog's neck, crown and chest, respectively. Although it has an apparent magnitude of 4.34, Gamma Canis Minoris is an orange K-type giant of spectral class K3-III C, which lies away. Its colour is obvious when seen through binoculars. It is a multiple system, consisting of the spectroscopic binary Gamma A and three optical companions, Gamma B, magnitude 13; Gamma C, magnitude 12; and Gamma D, magnitude 10. The two components of Gamma A orbit each other every 389.2 days, with an eccentric orbit that takes their separation between 2.3 and 1.4 astronomical units (AU). Epsilon Canis Minoris is a yellow bright giant of spectral class G6.5IIb of magnitude of 4.99. It lies from Earth, with 13 times the diameter and 750 times the luminosity of the Sun. Eta Canis Minoris is a giant of spectral class F0III of magnitude 5.24, which has a yellowish hue when viewed through binoculars as well as a faint companion of magnitude 11.1. Located 4 arcseconds from the primary, the companion star is actually around 440 AU from the main star and takes around 5,000 years to orbit it.\nNear Procyon, three stars share the name Delta Canis Minoris. Delta1 is a yellow-white F-type giant of magnitude 5.25 located around from Earth. About 360 times as luminous and 3.75 times as massive as the Sun, it is expanding and cooling as it ages, having spent much of its life as a main sequence star of spectrum B6V. Also known as 8 Canis Minoris, Delta2 is an F-type main-sequence star of spectral type F2V and magnitude 5.59 which is distant. The last of the trio, Delta3 (also known as 9 Canis Minoris), is a white main sequence star of spectral type A0Vnn and magnitude 5.83 which is distant. These stars mark the paws of the Lesser Dog's left hind leg, while magnitude 5.13 Zeta marks the right. A blue-white bright giant of spectral type B8II, Zeta lies around away from the Solar System.\nLying 222 \u00b1 7 light-years away with an apparent magnitude of 4.39, HD 66141 is 6.8\u00a0billion years old and has evolved into an orange giant of spectral type K2III with a diameter around 22 times that of the Sun, and weighing 1.1 solar masses. It is 174 times as luminous as the Sun, with an absolute magnitude of \u22120.15. HD 66141 was mistakenly named 13 Puppis, as its celestial coordinates were recorded incorrectly when catalogued and hence mistakenly thought to be in the constellation of Puppis; Bode gave it the name Lambda Canis Minoris, which is now obsolete. The orange giant is orbited by a planet, HD 66141b, which was detected in 2012 by measuring the star's radial velocity. The planet has a mass around 6 times that of Jupiter and a period of 480 days.\nA red giant of spectral type M4III, BC Canis Minoris lies around distant from the Solar System. It is a semiregular variable star that varies between a maximum magnitude of 6.14 and minimum magnitude of 6.42. Periods of 27.7, 143.3 and 208.3 days have been recorded in its pulsations. AZ, AD and BI Canis Minoris are Delta Scuti variables\u2014short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. AZ is of spectral type A5IV, and ranges between magnitudes 6.44 and 6.51 over a period of 2.3 hours. AD has a spectral type of F2III, and has a maximum magnitude of 9.21 and minimum of 9.51, with a period of approximately 2.95 hours. BI is of spectral type F2 with an apparent magnitude varying around 9.19 and a period of approximately 2.91 hours.\nAt least three red giants are Mira variables in Canis Minor. S Canis Minoris, of spectral type M7e, is the brightest, ranging from magnitude 6.6 to 13.2 over a period of 332.94 days. V Canis Minoris ranges from magnitude 7.4 to 15.1 over a period of 366.1 days. Similar in magnitude is R Canis Minoris, which has a maximum of 7.3, but a significantly brighter minimum of 11.6. An S-type star, it has a period of 337.8 days.\nYZ Canis Minoris is a red dwarf of spectral type M4.5V and magnitude 11.2, roughly three times the size of Jupiter and from Earth. It is a flare star, emitting unpredictable outbursts of energy for mere minutes, which might be much more powerful analogues of solar flares. Luyten's Star (GJ 273) is a red dwarf star of spectral type M3.5V and close neighbour of the Solar System. Its visual magnitude of 9.9 renders it too faint to be seen with the naked eye, even though it is only away. Fainter still is PSS 544-7, an eighteenth-magnitude red dwarf around 20 per cent the mass of the Sun, located from Earth. First noticed in 1991, it is thought to be a cannonball star, shot out of a star cluster and now moving rapidly through space directly away from the galactic disc.\nThe WZ Sagittae-type dwarf nova DY Canis Minoris (also known as VSX J074727.6+065050) flared up to magnitude 11.4 over January and February 2008 before dropping eight magnitudes to around 19.5 over approximately 80 days. It is a remote binary star system where a white dwarf and low-mass star orbit each other close enough for the former star to draw material off the latter and form an accretion disc. This material builds up until it erupts dramatically.\nDeep-sky objects.\nThe Milky Way passes through much of Canis Minor, yet it has few deep-sky objects. William Herschel recorded four objects in his 1786 work \"Catalogue of Nebulae and Clusters of Stars\", including two he mistakenly believed were star clusters. NGC 2459 is a group of five thirteenth- and fourteenth-magnitude stars that appear to lie close together in the sky but are not related. A similar situation has occurred with NGC 2394, also in Canis Minor. This is a collection of fifteen unrelated stars of ninth magnitude and fainter.\nHerschel also observed three faint galaxies, two of which are interacting with each other. NGC 2508 is a lenticular galaxy of thirteenth magnitude, estimated at 205 million light-years' distance (63 million parsecs) with a diameter of . Named as a single object by Herschel, NGC 2402 is actually a pair of near-adjacent galaxies that appear to be interacting with each other. Only of fourteenth and fifteenth magnitudes, respectively, the elliptical and spiral galaxy are thought to be approximately 245\u00a0million light-years distant, and each measure 55,000 light-years in diameter.\nMeteor showers.\nThe 11 Canis-Minorids, also called the Beta Canis Minorids, are a meteor shower that arise near the fifth-magnitude star 11 Canis Minoris and were discovered in 1964 by Keith Hindley, who investigated their trajectory and proposed a common origin with the comet D/1917 F1 Mellish. However, this conclusion has been refuted subsequently as the number of orbits analysed was low and their trajectories too disparate to confirm a link. They last from 4 to 15 December, peaking over 10 and 11 December."}
{"id": "6368", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=6368", "title": "Choshu", "text": ""}
{"id": "6371", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6371", "title": "Centaurus", "text": "Centaurus is a bright constellation in the southern sky. One of the largest constellations, Centaurus was included among the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. In Greek mythology, Centaurus represents a centaur; a creature that is half human, half horse (another constellation named after a centaur is one from the zodiac: Sagittarius). Notable stars include Alpha Centauri, the nearest star system to the Solar System, its neighbour in the sky Beta Centauri, and HR 5171, one of the largest stars yet discovered. The constellation also contains Omega Centauri, the brightest globular cluster as visible from Earth and the largest identified in the Milky Way, possibly a remnant of a dwarf galaxy.\nNotable features.\nStars.\nCentaurus contains several very bright stars. Its alpha and beta stars are used as \"pointer stars\" to help observers find the constellation Crux. Centaurus has 281 stars above magnitude 6.5, meaning that they are visible to the unaided eye, the most of any constellation. Alpha Centauri, the closest star system to the Sun, has a high proper motion; it will be a mere half-degree from Beta Centauri in approximately 4000 years.\nAlpha Centauri is a triple star system composed of a binary system orbited by Proxima Centauri, currently the nearest star to the Sun. Traditionally called Rigil Kentaurus (from Arabic \u0631\u062c\u0644 \u0642\u0646\u0637\u0648\u0631\u0633, meaning \"foot of the centaur\") or Toliman (from Arabic \u0627\u0644\u0638\u0644\u064a\u0645\u064a\u0646 meaning \"two male ostriches\"), the system has an overall magnitude of \u22120.28 and is 4.4 light-years from Earth. The primary and secondary are both yellow-hued stars; the first is of magnitude \u22120.01 and the second: 1.35. Proxima, the tertiary star, is a red dwarf of magnitude 11.0; it appears almost 2 degrees away from the close pairing of Alpha and has a period of approximately one million years. Also a flare star, Proxima has minutes-long outbursts where it brightens by over a magnitude. The Alpha couple revolve in 80-year periodicity and will next appear closest as seen from Earth's telescopes in 2037 and 2038, together as they appear to the naked eye they present the third-brightest \"star\" in the night sky.\nOne other first magnitude star Beta Centauri is in the constellation in a position beyond Proxima and toward the narrow axis of Crux, thus with Alpha forming a far-south limb of the constellation. Also called Hadar and Agena, it is a double star; the primary is a blue-hued giant star of magnitude 0.6, 525 light-years from Earth. The secondary is of magnitude 4.0 and has a modest separation, appearing only under intense magnification due to its distance.\nThe northerly star Theta Centauri, officially named Menkent, is an orange giant star of magnitude 2.06. It is the only bright star of Centaurus that is easily visible from mid-northern latitudes.\nThe next bright object is Gamma Centauri, a binary star which appears to the naked eye at magnitude 2.2. The primary and secondary are both blue-white hued stars of magnitude 2.9; their period is 84 years.\nCentaurus also has many dimmer double stars and binary stars. 3 Centauri is a double star with a blue-white hued primary of magnitude 4.5 and a secondary of magnitude 6.0. The primary is 344 light-years away.\nCentaurus is home to many variable stars. R Centauri is a Mira variable star with a minimum magnitude of 11.8 and a maximum magnitude of 5.3; it is about 1,250 light-years from Earth and has a period of 18 months. V810 Centauri is a semiregular variable.\nBPM 37093 is a white dwarf star whose carbon atoms are thought to have formed a crystalline structure. Since diamond also consists of carbon arranged in a crystalline lattice (though of a different configuration), scientists have nicknamed this star \"Lucy\" after the Beatles song \"\"Lucy in the Sky with Diamonds\".\"\nPDS 70, (V1032 Centauri) a low mass T Tauri star is found in the constellation Centaurus. In July 2018 astronomers captured the first conclusive image of a protoplanetary disk containing a nascent exoplanet, named PDS 70b.\nDeep-sky objects.\n\u03c9 Centauri (NGC 5139), despite being listed as the constellation's \"omega\" star, is in fact a naked-eye globular cluster, 17,000 light-years away with a diameter of 150 light-years. It is the largest and brightest globular cluster in the Milky Way; at ten times the size of the next-largest cluster, it has a magnitude of 3.7. It is also the most luminous globular cluster in the Milky Way, at over one million solar luminosities. Omega Centauri is classified as a Shapley class VIII cluster, which means that its center is loosely concentrated. It is also one of only two globular clusters to be given a stellar designation; in its case a Bayer letter. The other is 47 Tucanae (Xi Tucanae), which has a Flamsteed number. Omega Centauri contains several million stars, most of which are yellow dwarf stars, but also possesses red giants and blue-white stars; the stars have an average age of 12 billion years. This has prompted suspicion that Omega Centauri was the core of a dwarf galaxy that had been absorbed by the Milky Way. Omega Centauri was determined to be nonstellar in 1677 by the English astronomer Edmond Halley, though it was visible as a star to the ancients. Its status as a globular cluster was determined by James Dunlop in 1827. To the unaided eye, Omega Centauri appears fuzzy and is obviously non-circular; it is approximately half a degree in diameter, the same size as the full Moon.\nCentaurus is also home to open clusters. NGC 3766 is an open cluster 6,300 light-years from Earth that is visible to the unaided eye. It contains approximately 100 stars, the brightest of which are 7th magnitude. NGC 5460 is another naked-eye open cluster, 2,300 light-years from Earth, that has an overall magnitude of 6 and contains approximately 40 stars.\nThere is one bright planetary nebula in Centaurus, NGC 3918, also known as the Blue Planetary. It has an overall magnitude of 8.0 and a central star of magnitude 11.0; it is 2600 light-years from Earth. The Blue Planetary was discovered by John Herschel and named for its color's similarity to Uranus, though the nebula is apparently three times larger than the planet.\nCentaurus is rich in galaxies as well. NGC 4622 is a face-on spiral galaxy located 200 million light-years from Earth (redshift 0.0146). Its spiral arms wind in both directions, which makes it nearly impossible for astronomers to determine the rotation of the galaxy. Astronomers theorize that a collision with a smaller companion galaxy near the core of the main galaxy could have led to the unusual spiral structure. NGC 5253, a peculiar irregular galaxy, is located near the border with Hydra and M83, with which it likely had a close gravitational interaction 1\u20132 billion years ago. This may have sparked the galaxy's high rate of star formation, which continues today and contributes to its high surface brightness. NGC 5253 includes a large nebula and at least 12 large star clusters. In the eyepiece, it is a small galaxy of magnitude 10 with dimensions of 5 arcminutes by 2 arcminutes and a bright nucleus. NGC 4945 is a spiral galaxy seen edge-on from Earth, 13 million light-years away. It is visible with any amateur telescope, as well as binoculars under good conditions; it has been described as \"shaped like a candle flame\", being long and thin (16' by 3'). In the eyepiece of a large telescope, its southeastern dust lane becomes visible. Another galaxy is NGC 5102, found by star-hopping from Iota Centauri. In the eyepiece, it appears as an elliptical object 9 arcminutes by 2.5 arcminutes tilted on a southwest\u2013northeast axis.\nOne of the closest active galaxies to Earth is the Centaurus A galaxy, NGC 5128, at 11 million light-years away (redshift 0.00183). It has a supermassive black hole at its core, which expels massive jets of matter that emit radio waves due to synchrotron radiation. Astronomers posit that its dust lanes, not common in elliptical galaxies, are due to a previous merger with another galaxy, probably a spiral galaxy. NGC 5128 appears in the optical spectrum as a fairly large elliptical galaxy with a prominent dust lane. Its overall magnitude is 7.0 and it has been seen under perfect conditions with the naked eye, making it one of the most distant objects visible to the unaided observer. In equatorial and southern latitudes, it is easily found by star hopping from Omega Centauri. In small telescopes, the dust lane is not visible; it begins to appear with about 4 inches of aperture under good conditions. In large amateur instruments, above about 12 inches in aperture, the dust lane's west-northwest to east-southeast direction is easily discerned. Another dim dust lane on the east side of the 12-arcminute-by-15-arcminute galaxy is also visible. ESO 270-17, also called the Fourcade-Figueroa Object, is a low-surface brightness object believed to be the remnants of a galaxy; it does not have a core and is very difficult to observe with an amateur telescope. It measures 7 arcminutes by 1 arcminute. It likely originated as a spiral galaxy and underwent a catastrophic gravitational interaction with Centaurus A around 500 million years ago, stopping its rotation and destroying its structure.\nNGC 4650A is a polar-ring galaxy 136 million light-years from Earth (redshift 0.01). It has a central core made of older stars that resembles an elliptical galaxy, and an outer ring of young stars that orbits around the core. The plane of the outer ring is distorted, which suggests that NGC 4650A is the result of a galaxy collision about a billion years ago. This galaxy has also been cited in studies of dark matter, because the stars in the outer ring orbit too quickly for their collective mass. This suggests that the galaxy is surrounded by a dark matter halo, which provides the necessary mass.\nOne of the closest galaxy clusters to Earth is the Centaurus Cluster at 160 million light-years away, having redshift 0.0114. It has a cooler, denser central region of gas and a hotter, more diffuse outer region. The intracluster medium in the Centaurus Cluster has a high concentration of metals (elements heavier than helium) due to a large number of supernovae. This cluster also possesses a plume of gas whose origin is unknown.\nHistory.\nWhile Centaurus now has a high southern latitude, at the dawn of civilization it was an equatorial constellation. Precession has been slowly shifting it southward for millennia, and it is now close to its maximal southern declination. In a little over 7000 years it will be at maximum visibility for those in the northern hemisphere, visible at times in the year up to quite a high northern latitude.\nThe figure of Centaurus can be traced back to a Babylonian constellation known as the Bison-man (MUL.GUD.ALIM). This being was depicted in two major forms: firstly, as a 4-legged bison with a human head, and secondly, as a being with a man's head and torso attached to the rear legs and tail of a bull or bison. It has been closely associated with the Sun god Utu-Shamash from very early times.\nThe Greeks depicted the constellation as a centaur and gave it its current name. It was mentioned by Eudoxus in the 4th century BC and Aratus in the 3rd century BC. In the 2nd century AD, Claudius Ptolemy catalogued 37 stars in Centaurus, including Alpha Centauri. Large as it is now, in earlier times it was even larger, as the constellation Lupus was treated as an asterism within Centaurus, portrayed in illustrations as an unspecified animal either in the centaur's grasp or impaled on its spear. The Southern Cross, which is now regarded as a separate constellation, was treated by the ancients as a mere asterism formed of the stars composing the centaur's legs. Additionally, what is now the minor constellation Circinus was treated as undefined stars under the centaur's front hooves.\nAccording to the Roman poet Ovid (\"Fasti\" v.379), the constellation honors the centaur Chiron, who was tutor to many of the earlier Greek heroes including Heracles (Hercules), Theseus, and Jason, the leader of the Argonauts. It is not to be confused with the more warlike centaur represented by the zodiacal constellation Sagittarius. The legend associated with Chiron says that he was accidentally poisoned with an arrow shot by Hercules, and was subsequently placed in the heavens.\nEquivalents.\nIn Chinese astronomy, the stars of Centaurus are found in three areas: the Azure Dragon of the East (\u6771\u65b9\u9752\u9f8d, \"D\u014dng F\u0101ng Q\u012bng L\u00f3ng\"), the Vermillion Bird of the South (\u5357\u65b9\u6731\u96c0, \"N\u00e1n F\u0101ng Zh\u016b Qu\u00e8\"), and the Southern Asterisms (\u8fd1\u5357\u6975\u661f\u5340, \"J\u00ecnn\u00e1nj\u00edx\u012bng\u014du\"). Not all of the stars of Centaurus can be seen from China, and the unseen stars were classified among the Southern Asterisms by Xu Guangqi, based on his study of western star charts. However, most of the brightest stars of Centaurus, including \u03b1 Centauri, \u03b8 Centauri (or Menkent), \u03b5 Centauri and \u03b7 Centauri, can be seen in the Chinese sky.\nSome Polynesian peoples considered the stars of Centaurus to be a constellation as well. On Pukapuka, Centaurus had two names: \"Na Mata-o-te-tokolua\" and \"Na Lua-mata-o-Wua-ma-Velo\". In Tonga, the constellation was called by four names: \"O-nga-tangata\", \"Tautanga-ufi\", \"Mamangi-Halahu\", and \"Mau-kuo-mau\". Alpha and Beta Centauri were not named specifically by the people of Pukapuka or Tonga, but they were named by the people of Hawaii and the Tuamotus. In Hawaii, the name for Alpha Centauri was either \"Melemele\" or \"Ka Maile-hope\" and the name for Beta Centauri was either \"Polapola\" or \"Ka Maile-mua\". In the Tuamotu islands, Alpha was called \"Na Kuhi\" and Beta was called \"Tere\".\nThe Pointer (\u03b1 Centauri and \u03b2 Centauri) is one of the asterisms used by Bugis sailors for navigation, called \"binto\u00e9ng balu\u00e9\", meaning \"the widowed-before-marriage\". It is also called \"binto\u00e9ng sallatang\" meaning \"southern star\".\nNamesakes.\nTwo United States Navy ships, and , were named after Centaurus, the constellation."}
{"id": "6416", "revid": "7911044", "url": "https://en.wikipedia.org/wiki?curid=6416", "title": "Impact crater", "text": "An impact crater is a depression in the surface of a solid astronomical body formed by the hypervelocity impact of a smaller object. In contrast to volcanic craters, which result from explosion or internal collapse, impact craters typically have raised rims and floors that are lower in elevation than the surrounding terrain. Impact craters are typically circular, though they can be elliptical in shape or even irregular due to events such as landslides. Impact craters range in size from microscopic craters seen on lunar rocks returned by the Apollo Program to simple bowl-shaped depressions and vast, complex, multi-ringed impact basins. Meteor Crater is a well-known example of a small impact crater on Earth.\nImpact craters are the dominant geographic features on many solid Solar System objects including the Moon, Mercury, Callisto, Ganymede, and most small moons and asteroids. On other planets and moons that experience more active surface geological processes, such as Earth, Venus, Europa, Io, Titan, and Triton, visible impact craters are less common because they become eroded, buried, or transformed by tectonic and volcanic processes over time. Where such processes have destroyed most of the original crater topography, the terms impact structure or astrobleme are more commonly used. In early literature, before the significance of impact cratering was widely recognised, the terms cryptoexplosion or cryptovolcanic structure were often used to describe what are now recognised as impact-related features on Earth.\nThe cratering records of very old surfaces, such as Mercury, the Moon, and the southern highlands of Mars, record a period of intense early bombardment in the inner Solar System around 3.9 billion years ago. The rate of crater production on Earth has since been considerably lower, but it is appreciable nonetheless. Earth experiences, on average, from one to three impacts large enough to produce a crater every million years. This indicates that there should be far more relatively young craters on the planet than have been discovered so far. The cratering rate in the inner solar system fluctuates as a consequence of collisions in the asteroid belt that create a family of fragments that are often sent cascading into the inner solar system. Formed in a collision 80 million years ago, the Baptistina family of asteroids is thought to have caused a large spike in the impact rate. The rate of impact cratering in the outer Solar System could be different from the inner Solar System.\nAlthough Earth's active surface processes quickly destroy the impact record, about 190 terrestrial impact craters have been identified. These range in diameter from a few tens of meters up to about , and they range in age from recent times (e.g. the Sikhote-Alin craters in Russia whose creation was witnessed in 1947) to more than two billion years, though most are less than 500 million years old because geological processes tend to obliterate older craters. They are also selectively found in the stable interior regions of continents. Few undersea craters have been discovered because of the difficulty of surveying the sea floor, the rapid rate of change of the ocean bottom, and the subduction of the ocean floor into Earth's interior by processes of plate tectonics.\nHistory.\nDaniel M. Barringer, a mining engineer, was convinced already in 1903 that the crater he owned, Meteor Crater, was of cosmic origin. Most geologists at the time assumed it formed as the result of a volcanic steam eruption.\nIn the 1920s, the American geologist Walter H. Bucher studied a number of sites now recognized as impact craters in the United States. He concluded they had been created by some great explosive event, but believed that this force was probably volcanic in origin. However, in 1936, the geologists John D. Boon and Claude C. Albritton Jr. revisited Bucher's studies and concluded that the craters that he studied were probably formed by impacts.\nGrove Karl Gilbert suggested in 1893 that the Moon's craters were formed by large asteroid impacts. Ralph Baldwin in 1949 wrote that the Moon's craters were mostly of impact origin. Around 1960, Gene Shoemaker revived the idea. According to David H. Levy, Shoemaker \"saw the craters on the Moon as logical impact sites that were formed not gradually, in eons, but explosively, in seconds.\" For his PhD degree at Princeton University (1960), under the guidance of Harry Hammond Hess, Shoemaker studied the impact dynamics of Meteor Crater. Shoemaker noted that Meteor Crater had the same form and structure as two explosion craters created from atomic bomb tests at the Nevada Test Site, notably Jangle U in 1951 and Teapot Ess in 1955. In 1960, Edward C. T. Chao and Shoemaker identified coesite (a form of silicon dioxide) at Meteor Crater, proving the crater was formed from an impact generating extremely high temperatures and pressures. They followed this discovery with the identification of coesite within suevite at N\u00f6rdlinger Ries, proving its impact origin.\nArmed with the knowledge of shock-metamorphic features, Carlyle S. Beals and colleagues at the Dominion Astrophysical Observatory in Victoria, British Columbia, Canada and Wolf von Engelhardt of the University of T\u00fcbingen in Germany began a methodical search for impact craters. By 1970, they had tentatively identified more than 50. Although their work was controversial, the American Apollo Moon landings, which were in progress at the time, provided supportive evidence by recognizing the rate of impact cratering on the Moon. Because the processes of erosion on the Moon are minimal, craters persist. Since the Earth could be expected to have roughly the same cratering rate as the Moon, it became clear that the Earth had suffered far more impacts than could be seen by counting evident craters.\nCrater formation.\nImpact cratering involves high velocity collisions between solid objects, typically much greater than the speed of sound in those objects. Such hyper-velocity impacts produce physical effects such as melting and vaporization that do not occur in familiar sub-sonic collisions. On Earth, ignoring the slowing effects of travel through the atmosphere, the lowest impact velocity with an object from space is equal to the gravitational escape velocity of about 11\u00a0km/s. The fastest impacts occur at about 72\u00a0km/s in the \"worst case\" scenario in which an object in a retrograde near-parabolic orbit hits Earth. The median impact velocity on Earth is about 20\u00a0km/s.\nHowever, the slowing effects of travel through the atmosphere rapidly decelerate any potential impactor, especially in the lowest 12 kilometres where 90% of the Earth's atmospheric mass lies. Meteors of up to 7,000\u00a0kg lose all their cosmic velocity due to atmospheric drag at a certain altitude (retardation point), and start to accelerate again due to Earth's gravity until the body reaches its terminal velocity of 0.09 to 0.16\u00a0km/s. The larger the meteoroid (i.e. asteroids and comets) the more of its initial cosmic velocity it preserves. While an object of 9,000\u00a0kg maintains about 6% of its original velocity, one of 900,000\u00a0kg already preserves about 70%. Extremely large bodies (about 100,000 tonnes) are not slowed by the atmosphere at all, and impact with their initial cosmic velocity if no prior disintegration occurs.\nImpacts at these high speeds produce shock waves in solid materials, and both impactor and the material impacted are rapidly compressed to high density. Following initial compression, the high-density, over-compressed region rapidly depressurizes, exploding violently, to set in train the sequence of events that produces the impact crater. Impact-crater formation is therefore more closely analogous to cratering by high explosives than by mechanical displacement. Indeed, the energy density of some material involved in the formation of impact craters is many times higher than that generated by high explosives. Since craters are caused by explosions, they are nearly always circular \u2013 only very low-angle impacts cause significantly elliptical craters.\nThis describes impacts on solid surfaces. Impacts on porous surfaces, such as that of Hyperion, may produce internal compression without ejecta, punching a hole in the surface without filling in nearby craters. This may explain the 'sponge-like' appearance of that moon.\nIt is convenient to divide the impact process conceptually into three distinct stages: (1) initial contact and compression, (2) excavation, (3) modification and collapse. In practice, there is overlap between the three processes with, for example, the excavation of the crater continuing in some regions while modification and collapse is already underway in others.\nContact and compression.\nIn the absence of atmosphere, the impact process begins when the impactor first touches the target surface. This contact accelerates the target and decelerates the impactor. Because the impactor is moving so rapidly, the rear of the object moves a significant distance during the short-but-finite time taken for the deceleration to propagate across the impactor. As a result, the impactor is compressed, its density rises, and the pressure within it increases dramatically. Peak pressures in large impacts exceed 1 T Pa to reach values more usually found deep in the interiors of planets, or generated artificially in nuclear explosions.\nIn physical terms, a shock wave originates from the point of contact. As this shock wave expands, it decelerates and compresses the impactor, and it accelerates and compresses the target. Stress levels within the shock wave far exceed the strength of solid materials; consequently, both the impactor and the target close to the impact site are irreversibly damaged. Many crystalline minerals can be transformed into higher-density phases by shock waves; for example, the common mineral quartz can be transformed into the higher-pressure forms coesite and stishovite. Many other shock-related changes take place within both impactor and target as the shock wave passes through, and some of these changes can be used as diagnostic tools to determine whether particular geological features were produced by impact cratering.\nAs the shock wave decays, the shocked region decompresses towards more usual pressures and densities. The damage produced by the shock wave raises the temperature of the material. In all but the smallest impacts this increase in temperature is sufficient to melt the impactor, and in larger impacts to vaporize most of it and to melt large volumes of the target. As well as being heated, the target near the impact is accelerated by the shock wave, and it continues moving away from the impact behind the decaying shock wave.\nExcavation.\nContact, compression, decompression, and the passage of the shock wave all occur within a few tenths of a second for a large impact. The subsequent excavation of the crater occurs more slowly, and during this stage the flow of material is largely subsonic. During excavation, the crater grows as the accelerated target material moves away from the point of impact. The target's motion is initially downwards and outwards, but it becomes outwards and upwards. The flow initially produces an approximately hemispherical cavity that continues to grow, eventually producing a paraboloid (bowl-shaped) crater in which the centre has been pushed down, a significant volume of material has been ejected, and a topographically elevated crater rim has been pushed up. When this cavity has reached its maximum size, it is called the transient cavity.\nThe depth of the transient cavity is typically a quarter to a third of its diameter. Ejecta thrown out of the crater do not include material excavated from the full depth of the transient cavity; typically the depth of maximum excavation is only about a third of the total depth. As a result, about one third of the volume of the transient crater is formed by the ejection of material, and the remaining two thirds is formed by the displacement of material downwards, outwards and upwards, to form the elevated rim. For impacts into highly porous materials, a significant crater volume may also be formed by the permanent compaction of the pore space. Such compaction craters may be important on many asteroids, comets and small moons.\nIn large impacts, as well as material displaced and ejected to form the crater, significant volumes of target material may be melted and vaporized together with the original impactor. Some of this impact melt rock may be ejected, but most of it remains within the transient crater, initially forming a layer of impact melt coating the interior of the transient cavity. In contrast, the hot dense vaporized material expands rapidly out of the growing cavity, carrying some solid and molten material within it as it does so. As this hot vapor cloud expands, it rises and cools much like the archetypal mushroom cloud generated by large nuclear explosions. In large impacts, the expanding vapor cloud may rise to many times the scale height of the atmosphere, effectively expanding into free space.\nMost material ejected from the crater is deposited within a few crater radii, but a small fraction may travel large distances at high velocity, and in large impacts it may exceed escape velocity and leave the impacted planet or moon entirely. The majority of the fastest material is ejected from close to the center of impact, and the slowest material is ejected close to the rim at low velocities to form an overturned coherent flap of ejecta immediately outside the rim. As ejecta escapes from the growing crater, it forms an expanding curtain in the shape of an inverted cone. The trajectory of individual particles within the curtain is thought to be largely ballistic.\nSmall volumes of un-melted and relatively un-shocked material may be spalled at very high relative velocities from the surface of the target and from the rear of the impactor. Spalling provides a potential mechanism whereby material may be ejected into inter-planetary space largely undamaged, and whereby small volumes of the impactor may be preserved undamaged even in large impacts. Small volumes of high-speed material may also be generated early in the impact by jetting. This occurs when two surfaces converge rapidly and obliquely at a small angle, and high-temperature highly shocked material is expelled from the convergence zone with velocities that may be several times larger than the impact velocity.\nModification and collapse.\nIn most circumstances, the transient cavity is not stable and collapses under gravity. In small craters, less than about 4\u00a0km diameter on Earth, there is some limited collapse of the crater rim coupled with debris sliding down the crater walls and drainage of impact melts into the deeper cavity. The resultant structure is called a simple crater, and it remains bowl-shaped and superficially similar to the transient crater. In simple craters, the original excavation cavity is overlain by a lens of collapse breccia, ejecta and melt rock, and a portion of the central crater floor may sometimes be flat.\nAbove a certain threshold size, which varies with planetary gravity, the collapse and modification of the transient cavity is much more extensive, and the resulting structure is called a complex crater. The collapse of the transient cavity is driven by gravity, and involves both the uplift of the central region and the inward collapse of the rim. The central uplift is not the result of elastic rebound, which is a process in which a material with elastic strength attempts to return to its original geometry; rather the collapse is a process in which a material with little or no strength attempts to return to a state of gravitational equilibrium.\nComplex craters have uplifted centers, and they have typically broad flat shallow crater floors, and terraced walls. At the largest sizes, one or more exterior or interior rings may appear, and the structure may be labeled an impact basin rather than an impact crater. Complex-crater morphology on rocky planets appears to follow a regular sequence with increasing size: small complex craters with a central topographic peak are called central peak craters, for example Tycho; intermediate-sized craters, in which the central peak is replaced by a ring of peaks, are called peak-ring craters, for example Schr\u00f6dinger; and the largest craters contain multiple concentric topographic rings, and are called multi-ringed basins, for example Orientale. On icy (as opposed to rocky) bodies, other morphological forms appear that may have central pits rather than central peaks, and at the largest sizes may contain many concentric rings. Valhalla on Callisto is an example of this type.\nSubsequent modification.\nLong after an impact event, a crater may be further modified by erosion, mass wasting processes, viscous relaxation, or erased entirely. These effects are most prominent on geologically and meteorologically active bodies such as Earth, Titan, Triton, and Io. However, heavily modified craters may be found on more primordial bodies such as Callisto, where many ancient craters flatten into bright ghost craters, or palimpsests.\nIdentifying impact craters.\nNon-explosive volcanic craters can usually be distinguished from impact craters by their irregular shape and the association of volcanic flows and other volcanic materials. Impact craters produce melted rocks as well, but usually in smaller volumes with different characteristics.\nThe distinctive mark of an impact crater is the presence of rock that has undergone shock-metamorphic effects, such as shatter cones, melted rocks, and crystal deformations. The problem is that these materials tend to be deeply buried, at least for simple craters. They tend to be revealed in the uplifted center of a complex crater, however.\nImpacts produce distinctive shock-metamorphic effects that allow impact sites to be distinctively identified. Such shock-metamorphic effects can include:\nEconomic importance.\nOn Earth, impact craters have resulted in useful minerals. Some of the ores produced from impact related effects on Earth include ores of iron, uranium, gold, copper, and nickel. It is estimated that the value of materials mined from impact structures is five billion dollars/year just for North America. The eventual usefulness of impact craters depends on several factors, especially the nature of the materials that were impacted and when the materials were affected. In some cases, the deposits were already in place and the impact brought them to the surface. These are called \"progenetic economic deposits.\" Others were created during the actual impact. The great energy involved caused melting. Useful minerals formed as a result of this energy are classified as \"syngenetic deposits.\" The third type, called \"epigenetic deposits,\" is caused by the creation of a basin from the impact. Many of the minerals that our modern lives depend on are associated with impacts in the past. The Vredeford Dome in the center of the Witwatersrand Basin is the largest goldfield in the world, which has supplied about 40% of all the gold ever mined in an impact structure (though the gold did not come from the bolide). The asteroid that struck the region was wide. The Sudbury Basin was caused by an impacting body over in diameter. This basin is famous for its deposits of nickel, copper, and platinum group elements. An impact was involved in making the Carswell structure in Saskatchewan, Canada; it contains uranium deposits.\nHydrocarbons are common around impact structures. Fifty percent of impact structures in North America in hydrocarbon-bearing sedimentary basins contain oil/gas fields.\nLists of craters.\nImpact craters on Earth.\nOn Earth, the recognition of impact craters is a branch of geology, and is related to planetary geology in the study of other worlds. Out of many proposed craters, relatively few are confirmed. The following twenty are a sample of articles of confirmed and well-documented impact sites.\nSee the Earth Impact Database, a website concerned with 190 () scientifically confirmed impact craters on Earth.\nLargest named craters in the Solar System.\nThere are approximately twelve more impact craters/basins larger than 300\u00a0km on the Moon, five on Mercury, and four on Mars. Large basins, some unnamed but mostly smaller than 300\u00a0km, can also be found on Saturn's moons Dione, Rhea and Iapetus."}
{"id": "6417", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=6417", "title": "Corvus (disambiguation)", "text": "Corvus is a genus of birds commonly known as crows and ravens.\nCorvus may also refer to:"}
{"id": "6420", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6420", "title": "Corona Borealis", "text": "Corona Borealis is a small constellation in the Northern Celestial Hemisphere. It is one of the 48\u00a0constellations listed by the 2nd-century astronomer Ptolemy, and remains one of the 88 modern constellations. Its brightest stars form a semicircular arc. Its Latin name, inspired by its shape, means \"northern crown\". In classical mythology Corona Borealis generally represented the crown given by the god Dionysus to the Cretan princess Ariadne and set by her in the heavens. Other cultures likened the pattern to a circle of elders, an eagle's nest, a bear's den or a smokehole. Ptolemy also listed a southern counterpart, Corona Australis, with a similar pattern.\nThe brightest star is the magnitude\u00a02.2 Alpha Coronae Borealis. The yellow supergiant R Coronae Borealis is the prototype of a rare class of giant stars\u2014the R Coronae Borealis variables\u2014that are extremely hydrogen deficient, and thought to result from the merger of two white dwarfs. T Coronae Borealis, also known as the Blaze Star, is another unusual type of variable star known as a recurrent nova. Normally of magnitude\u00a010, it last flared up to magnitude\u00a02 in 1946, and is predicted to do the same in 2025. ADS 9731 and Sigma Coronae Borealis are multiple star systems with six and five components respectively. Five stars in the constellation host Jupiter-sized exoplanets. Abell 2065 is a highly concentrated galaxy cluster one billion light-years from the Solar System containing more than 400 members, and is itself part of the larger Corona Borealis Supercluster.\nCharacteristics.\nCovering 179 square degrees and hence 0.433% of the sky, Corona Borealis ranks 73rd of the IAU designated constellations by area. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 50\u00b0S. It is bordered by Bo\u00f6tes to the north and west, Serpens Caput to the south, and Hercules to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"CrB\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of eight segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 39.71\u00b0 and 25.54\u00b0. It has a counterpart\u2014Corona Australis\u2014in the Southern Celestial Hemisphere.\nFeatures.\nStars.\nThe seven stars that make up the constellation's distinctive crown-shaped pattern are all 4th-magnitude stars except for the brightest of them, Alpha Coronae Borealis. The other six stars are Theta, Beta, Gamma, Delta, Epsilon and Iota Coronae Borealis. The German cartographer Johann Bayer gave twenty stars in Corona Borealis Bayer designations from Alpha to Upsilon in his 1603 star atlas \"Uranometria\". Zeta Coronae Borealis was noted to be a double star by later astronomers and its components designated Zeta1 and Zeta2. John Flamsteed did likewise with Nu Coronae Borealis; classed by Bayer as a single star, it was noted to be two close stars by Flamsteed. He named them 20 and 21 Coronae Borealis in his catalogue, alongside the designations Nu1 and Nu2 respectively. Chinese astronomers deemed nine stars to make up the asterism, adding Pi and Rho Coronae Borealis. Within the constellation's borders, there are 37 stars brighter than or equal to apparent magnitude\u00a06.5.\nAlpha Coronae Borealis (officially named Alphecca by the IAU, but sometimes also known as Gemma) appears as a blue-white star of magnitude\u00a02.2. In fact, it is an Algol-type eclipsing binary that varies by 0.1\u00a0magnitude with a period of 17.4\u00a0days. The primary is a white main-sequence star of spectral type A0V that is 2.91\u00a0times the mass of the Sun () and 57 times as luminous (), and is surrounded by a debris disk out to a radius of around 60\u00a0astronomical units (AU). The secondary companion is a yellow main-sequence star of spectral type G5V that is a little smaller (0.9 times) the diameter of the Sun. Lying 75\u00b10.5\u00a0light-years from Earth, Alphecca is believed to be a member of the Ursa Major Moving Group of stars that have a common motion through space.\nLocated 112\u00b13\u00a0light-years away, Beta Coronae Borealis or Nusakan is a spectroscopic binary system whose two components are separated by 10\u00a0AU and orbit each other every 10.5 years. The brighter component is a rapidly oscillating Ap star, pulsating with a period of 16.2\u00a0minutes. Of spectral type A5V with a surface temperature of around 7980\u00a0K, it has around , 2.6\u00a0solar radii (), and . The smaller star is of spectral type F2V with a surface temperature of around 6750\u00a0K, and has around , , and between 4 and . Near Nusakan is Theta Coronae Borealis, a binary system that shines with a combined magnitude of 4.13 located 380\u00b120 light-years distant. The brighter component, Theta Coronae Borealis A, is a blue-white star that spins extremely rapidly\u2014at a rate of around 393\u00a0km per second. A Be star, it is surrounded by a debris disk.\nFlanking Alpha to the east is Gamma Coronae Borealis, yet another binary star system, whose components orbit each other every 92.94\u00a0years and are roughly as far apart from each other as the Sun and Neptune. The brighter component has been classed as a Delta Scuti variable star, though this view is not universal. The components are main sequence stars of spectral types B9V and A3V. Located 170\u00b12\u00a0light-years away, 4.06-magnitude Delta Coronae Borealis is a yellow giant star of spectral type G3.5III that is around and has swollen to . It has a surface temperature of 5180\u00a0K. For most of its existence, Delta Coronae Borealis was a blue-white main-sequence star of spectral type B before it ran out of hydrogen fuel in its core. Its luminosity and spectrum suggest it has just crossed the Hertzsprung gap, having finished burning core hydrogen and just begun burning hydrogen in a shell that surrounds the core.\nZeta Coronae Borealis is a double star with two blue-white components 6.3\u00a0arcseconds apart that can be readily separated at 100x\u00a0magnification. The primary is of magnitude\u00a05.1 and the secondary is of magnitude\u00a06.0. Nu Coronae Borealis is an optical double, whose components are a similar distance from Earth but have different radial velocities, hence are assumed to be unrelated. The primary, Nu1 Coronae Borealis, is a red giant of spectral type M2III and magnitude 5.2, lying 640\u00b130 light-years distant, and the secondary, Nu2 Coronae Borealis, is an orange-hued giant star of spectral type K5III and magnitude 5.4, estimated to be 590\u00b130\u00a0light-years away. Sigma Coronae Borealis, on the other hand, is a true multiple star system divisible by small amateur telescopes. It is actually a complex system composed of two stars around as massive as the Sun that orbit each other every 1.14\u00a0days, orbited by a third Sun-like star every 726\u00a0years. The fourth and fifth components are a binary red dwarf system that is 14,000\u00a0AU distant from the other three stars. ADS 9731 is an even rarer multiple system in the constellation, composed of six stars, two of which are spectroscopic binaries.\nCorona Borealis is home to two remarkable variable stars. T Coronae Borealis is a cataclysmic variable star also known as the Blaze Star. Normally placid around magnitude 10\u2014it has a minimum of 10.2 and maximum of 9.9\u2014it brightens to magnitude 2 in a period of hours, caused by a nuclear chain reaction and the subsequent explosion. T Coronae Borealis is one of a handful of stars called recurrent novae, which include T Pyxidis and U Scorpii. An outburst of T Coronae Borealis was first recorded in 1866; its second recorded outburst was in February 1946. T Coronae Borealis started dimming in March 2023 and it is known that before it goes nova it dims for about a year; for this reason it is expected to go nova at any time between March and September, 2024. T Coronae Borealis is a binary star with a red-hued giant primary and a white dwarf secondary, the two stars orbiting each other over a period of approximately 8 months. R Coronae Borealis is a yellow-hued variable supergiant star, over 7000 light-years from Earth, and prototype of a class of stars known as R Coronae Borealis variables. Normally of magnitude 6, its brightness periodically drops as low as magnitude 15 and then slowly increases over the next several months. These declines in magnitude come about as dust that has been ejected from the star obscures it. Direct imaging with the Hubble Space Telescope shows extensive dust clouds out to a radius of around 2000\u00a0AU from the star, corresponding with a stream of fine dust (composed of grains 5\u00a0nm in diameter) associated with the star's stellar wind and coarser dust (composed of grains with a diameter of around 0.14\u00a0\u03bcm) ejected periodically.\nThere are several other variables of reasonable brightness for amateur astronomer to observe, including three Mira-type long period variables: S Coronae Borealis ranges between magnitudes 5.8 and 14.1 over a period of 360\u00a0days. Located around 1946\u00a0light-years distant, it shines with a luminosity 16,643\u00a0times that of the Sun and has a surface temperature of 3033 K. One of the reddest stars in the sky, V Coronae Borealis is a cool star with a surface temperature of 2877\u00a0K that shines with a luminosity 102,831 times that of the Sun and is a remote 8810\u00a0light-years distant from Earth. Varying between magnitudes 6.9 and 12.6 over a period of 357\u00a0days, it is located near the junction of the border of Corona Borealis with Hercules and Bootes. Located 1.5\u00b0 northeast of Tau Coronae Borealis, W Coronae Borealis ranges between magnitudes 7.8 and 14.3 over a period of 238\u00a0days. Another red giant, RR Coronae Borealis is a M3-type semiregular variable star that varies between magnitudes 7.3 and 8.2 over 60.8 days. RS Coronae Borealis is yet another semiregular variable red giant, which ranges between magnitudes 8.7 to 11.6 over 332 days. It is unusual in that it is a red star with a high proper motion (greater than 50 milliarcseconds a year). Meanwhile, U Coronae Borealis is an Algol-type eclipsing binary star system whose magnitude varies between 7.66 and 8.79 over a period of 3.45 days\nTY Coronae Borealis is a pulsating white dwarf (of ZZ Ceti) type, which is around 70% as massive as the Sun, yet has only 1.1% of its diameter. Discovered in 1990, UW Coronae Borealis is a low-mass X-ray binary system composed of a star less massive than the Sun and a neutron star surrounded by an accretion disk that draws material from the companion star. It varies in brightness in an unusually complex manner: the two stars orbit each other every 111 minutes, yet there is another cycle of 112.6 minutes, which corresponds to the orbit of the disk around the degenerate star. The beat period of 5.5 days indicates the time the accretion disk\u2014which is asymmetrical\u2014takes to precess around the star.\nExtrasolar planetary systems.\nExtrasolar planets have been confirmed in five star systems, four of which were found by the radial velocity method. The spectrum of Epsilon Coronae Borealis was analysed for seven years from 2005 to 2012, revealing a planet around 6.7\u00a0times as massive as Jupiter () orbiting every 418\u00a0days at an average distance of around 1.3\u00a0AU. Epsilon itself is a orange giant of spectral type K2III that has swollen to and . Kappa Coronae Borealis is a spectral type K1IV orange subgiant nearly twice as massive as the Sun; around it lies a dust debris disk, and one planet with a period of 3.4\u00a0years. This planet's mass is estimated at . The dimensions of the debris disk indicate it is likely there is a second substellar companion. Omicron Coronae Borealis is a K-type clump giant with one confirmed planet with a mass of that orbits every 187\u00a0days\u2014one of the two least massive planets known around clump giants. HD 145457 is an orange giant of spectral type K0III found to have one planet of . Discovered by the Doppler method in 2010, it takes 176\u00a0days to complete an orbit. XO-1 is a magnitude 11 yellow main-sequence star located approximately light-years away, of spectral type G1V with a mass and radius similar to the Sun. In 2006 the hot Jupiter exoplanet XO-1b was discovered orbiting XO-1 by the transit method using the XO Telescope. Roughly the size of Jupiter, it completes an orbit around its star every three days.\nThe discovery of a Jupiter-sized planetary companion was announced in 1997 via analysis of the radial velocity of Rho Coronae Borealis, a yellow main sequence star and Solar analog of spectral type G0V, around 57 light-years distant from Earth. More accurate measurement of data from the Hipparcos satellite subsequently showed it instead to be a low-mass star somewhere between 100 and 200 times the mass of Jupiter. Possible stable planetary orbits in the habitable zone were calculated for the binary star Eta Coronae Borealis, which is composed of two stars\u2014yellow main sequence stars of spectral type G1V and G3V respectively\u2014similar in mass and spectrum to the Sun. No planet has been found, but a brown dwarf companion about 63 times as massive as Jupiter with a spectral type of L8 was discovered at a distance of 3640\u00a0AU from the pair in 2001.\nDeep-sky objects.\nCorona Borealis contains few galaxies observable with amateur telescopes. NGC 6085 and 6086 are a faint spiral and elliptical galaxy respectively close enough to each other to be seen in the same visual field through a telescope. Abell 2142 is a huge (six million light-year diameter), X-ray luminous galaxy cluster that is the result of an ongoing merger between two galaxy clusters. It has a redshift of 0.0909 (meaning it is moving away from us at 27,250\u00a0km/s) and a visual magnitude of 16.0. It is about 1.2 billion light-years away. Another galaxy cluster in the constellation, RX\u00a0J1532.9+3021, is approximately 3.9 billion light-years from Earth. At the cluster's center is a large elliptical galaxy containing one of the most massive and most powerful supermassive black holes yet discovered. Abell 2065 is a highly concentrated galaxy cluster containing more than 400 members, the brightest of which are 16th magnitude; the cluster is more than one billion light-years from Earth. On a larger scale still, Abell\u00a02065, along with Abell 2061, Abell 2067, Abell 2079, Abell 2089, and Abell 2092, make up the Corona Borealis Supercluster. Another galaxy cluster, Abell 2162, is a member of the Hercules Superclusters.\nMythology.\nIn Greek mythology, Corona Borealis was linked to the legend of Theseus and the minotaur. It was generally considered to represent a crown given by Dionysus to Ariadne, the daughter of Minos of Crete, after she had been abandoned by the Athenian prince Theseus. When she wore the crown at her marriage to Dionysus, he placed it in the heavens to commemorate their wedding. An alternative version has the besotted Dionysus give the crown to Ariadne, who in turn gives it to Theseus after he arrives in Crete to kill the minotaur that the Cretans have demanded tribute from Athens to feed. The hero uses the crown's light to escape the labyrinth after disposing of the creature, and Dionysus later sets it in the heavens. , attributed to Hyginus, linked it to a crown or wreath worn by Bacchus (Dionysus) to disguise his appearance when first approaching Mount Olympus and revealing himself to the gods, having been previously hidden as yet another child of Jupiter's trysts with a mortal, in this case Semele. Its proximity to the constellations Hercules (which reports was once attributed to Theseus, among others) and Lyra (Theseus' lyre in one account), could indicate that the three constellations were invented as a group. Corona Borealis was one of the 48 constellations mentioned in the \"Almagest\" of classical astronomer Ptolemy.\nIn Mesopotamia, Corona Borealis was associated with the goddess Nanaya.\nIn Welsh mythology, it was called Caer Arianrhod, \"the Castle of the Silver Circle\", and was the heavenly abode of the Lady Arianrhod. To the ancient Balts, Corona Borealis was known as \"Dar\u017eelis\", the \"flower garden\".\nThe Arabs called the constellation Alphecca (a name later given to Alpha Coronae Borealis), which means \"separated\" or \"broken up\" ( '), a reference to the resemblance of the stars of Corona Borealis to a loose string of jewels. This was also interpreted as a broken dish. Among the Bedouins, the constellation was known as ' (), or \"the dish/bowl of the poor people\".\nThe Skidi people of Native Americans saw the stars of Corona Borealis representing a council of stars whose chief was Polaris. The constellation also symbolised the smokehole over a fireplace, which conveyed their messages to the gods, as well as how chiefs should come together to consider matters of importance. The Shawnee people saw the stars as the \"Heavenly Sisters\", who descended from the sky every night to dance on earth. Alphecca signifies the youngest and most comely sister, who was seized by a hunter who transformed into a field mouse to get close to her. They married though she later returned to the sky, with her heartbroken husband and son following later. The Mi'kmaq of eastern Canada saw Corona Borealis as \"Mskegw\u01d2m\", the den of the celestial bear (Alpha, Beta, Gamma and Delta Ursae Majoris).\nPolynesian peoples often recognized Corona Borealis; the people of the Tuamotus named it \"Na Kaua-ki-tokerau\" and probably \"Te Hetu\". The constellation was likely called \"Kaua-mea\" in Hawaii, \"Rangawhenua\" in New Zealand, and \"Te Wale-o-Awitu\" in the Cook Islands atoll of Pukapuka. Its name in Tonga was uncertain; it was either called \"Ao-o-Uvea\" or \"Kau-kupenga\".\nIn Australian Aboriginal astronomy, the constellation is called \"womera\" (\"the boomerang\") due to the shape of the stars. The Wailwun people of northwestern New South Wales saw Corona Borealis as \"mullion wollai\" \"eagle's nest\", with Altair and Vega\u2014each called \"mullion\"\u2014the pair of eagles accompanying it. The Wardaman people of northern Australia held the constellation to be a gathering point for Men's Law, Women's Law and Law of both sexes come together and consider matters of existence.\nLater references.\nCorona Borealis was renamed Corona Firmiana in honour of the Archbishop of Salzburg in the 1730 Atlas \"Mercurii Philosophicii Firmamentum Firminianum Descriptionem\" by Corbinianus Thomas, but this was not taken up by subsequent cartographers. The constellation was featured as a main plot ingredient in the short story \"Hypnos\" by H. P. Lovecraft, published in 1923; it is the object of fear of one of the protagonists in the short story. Finnish band Cadacross released an album titled \"Corona Borealis\" in 2002."}
{"id": "6421", "revid": "2395584", "url": "https://en.wikipedia.org/wiki?curid=6421", "title": "Cygnus (constellation)", "text": "Cygnus is a northern constellation on the plane of the Milky Way, deriving its name from the Latinized Greek word for swan. Cygnus is one of the most recognizable constellations of the northern summer and autumn, and it features a prominent asterism known as the Northern Cross (in contrast to the Southern Cross). Cygnus was among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations.\nCygnus contains Deneb (\u0630\u0646\u0628, translit. \"\u1e0fanab,\" tail)one of the brightest stars in the night sky and the most distant first-magnitude staras its \"tail star\" and one corner of the Summer Triangle the constellation forming an east pointing altitude of the triangle. It also has some notable X-ray sources and the giant stellar association of Cygnus OB2. One of the stars of this association, NML Cygni, is one of the largest stars currently known. The constellation is also home to Cygnus X-1, a distant X-ray binary containing a supergiant and unseen massive companion that was the first object widely held to be a black hole.\nMany star systems in Cygnus have known planets as a result of the Kepler Mission observing one patch of the sky, an area around Cygnus.\nMost of the east has part of the Hercules\u2013Corona Borealis Great Wall in the deep sky, a giant galaxy filament that is the largest known structure in the observable universe, covering most of the northern sky.\nHistory and mythology.\nIn Eastern and World astronomy.\nIn Polynesia, Cygnus was often recognized as a separate constellation. In Tonga it was called \"Tuula-lupe\", and in the Tuamotus it was called \"Fanui-tai\". In New Zealand it was called \"Mara-tea\", in the Society Islands it was called \"Pirae-tea\" or \"Taurua-i-te-haapa-raa-manu\", and in the Tuamotus it was called \"Fanui-raro\". Beta Cygni was named in New Zealand; it was likely called \"Whetu-kaupo\". Gamma Cygni was called \"Fanui-runga\" in the Tuamotus.\nDeneb was also often a given name, in the Islamic world of astronomy. The name \"Deneb\" comes from the Arabic name \"dhaneb\", meaning \"tail\", from the phrase \"Dhanab ad-Daj\u0101jah\", which means \"the tail of the hen\".\nIn Western astronomy.\nIn Greek mythology, Cygnus has been identified with several different legendary swans. Zeus disguised himself as a swan to seduce Leda, Spartan king Tyndareus's wife, who gave birth to the Gemini, Helen of Troy, and Clytemnestra; Orpheus was transformed into a swan after his murder, and was said to have been placed in the sky next to his lyre (Lyra); and a man named Cygnus (Greek for \"swan\") was transformed into his namesake.\nLater Romans also associated this constellation with the tragic story of Phaethon, the son of Helios the sun god, who demanded to ride his father's sun chariot for a day. Phaethon, however, was unable to control the reins, forcing Zeus to destroy the chariot (and Phaethon) with a thunderbolt, causing it to plummet to the earth into the river Eridanus. According to the myth, Phaethon's close friend or lover, Cygnus of Liguria, grieved bitterly and spent many days diving into the river to collect Phaethon's bones to give him a proper burial. The gods were so touched by Cygnus's devotion that they turned him into a swan and placed him among the stars.\nIn Ovid's \"Metamorphoses\", there are three people named Cygnus, all of whom are transformed into swans. Alongside Cygnus, noted above, he mentions a boy from Aetolia who throws himself off a cliff when his companion Phyllius refuses to give him a tamed bull that he demands, but he is transformed into a swan and flies away. He also mentions a son of Poseidon, an invulnerable warrior in the Trojan War who is eventually killed by Achilles, but Poseidon saves him by transforming him into a swan.\nTogether with other avian constellations near the summer solstice, Vultur cadens and Aquila, Cygnus may be a significant part of the origin of the myth of the Stymphalian Birds, one of The Twelve Labours of Hercules.\nCharacteristics.\nA very large constellation, Cygnus is bordered by Cepheus to the north and east, Draco to the north and west, Lyra to the west, Vulpecula to the south, Pegasus to the southeast and Lacerta to the east. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is \"Cyg\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined as a polygon of 28 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 27.73\u00b0 and 61.36\u00b0. Covering 804 square degrees and around 1.9% of the night sky, Cygnus ranks 16th of the 88 constellations in size.\nCygnus culminates at midnight on 29 June, and is most visible in the evening from the early summer to mid-autumn in the Northern Hemisphere.\nNormally, Cygnus is depicted with Delta and Epsilon Cygni as its wings. Deneb, the brightest in the constellation is at its tail, and Albireo as the tip of its beak.\nThere are several asterisms in Cygnus. In the 17th-century German celestial cartographer Johann Bayer's star atlas the \"Uranometria\", Alpha, Beta and Gamma Cygni form the pole of a cross, while Delta and Epsilon form the cross beam. The nova P Cygni was then considered to be the body of Christ.\nFeatures.\nThere is an abundance of deep-sky objects, with many open clusters, nebulae of various types and supernova remnants found in Cygnus due to its position on the Milky Way.\nIts molecular clouds form the Cygnus Rift dark nebula constellation, comprising one end of the Great Rift along the Milky Way's galactic plane. The rift begins around the Northern Coalsack, and partially obscures the larger Cygnus\u00a0molecular cloud complex behind it, which the North America Nebula is part of.\nStars.\nBayer catalogued many stars in the constellation, giving them the Bayer designations from Alpha to Omega and then using lowercase Roman letters to g. John Flamsteed added the Roman letters h, i, k, l and m (these stars were considered \"informes\" by Bayer as they lay outside the asterism of Cygnus), but were dropped by Francis Baily.\nThere are several bright stars in Cygnus. \u03b1 Cygni, called Deneb, is the brightest star in Cygnus. It is a white supergiant star of spectral type A2Iae that varies between magnitudes 1.21 and 1.29, one of the largest and most luminous A-class stars known. It is located about 2600 light-years away. Its traditional name means \"tail\" and refers to its position in the constellation. Albireo, designated \u03b2 Cygni, is a celebrated binary star among amateur astronomers for its contrasting hues. The primary is an orange-hued giant star of magnitude 3.1 and the secondary is a blue-green hued star of magnitude 5.1. The system is 430 light-years away and is visible in large binoculars and all amateur telescopes. \u03b3 Cygni, traditionally named Sadr, is a yellow-tinged supergiant star of magnitude 2.2, 1800 light-years away. Its traditional name means \"breast\" and refers to its position in the constellation. \u03b4 Cygni (the proper name is Fawaris) is another bright binary star in Cygnus, 166 light-years with a period of 800 years. The primary is a blue-white hued giant star of magnitude 2.9, and the secondary is a star of magnitude 6.6. The two components are visible in a medium-sized amateur telescope. The fifth star in Cygnus above magnitude 3 is Aljanah, designated \u03b5 Cygni. It is an orange-hued giant star of magnitude 2.5, 72 light-years from Earth.\nThere are several other dimmer double and binary stars in Cygnus. \u03bc Cygni is a binary star with an optical tertiary component. The binary system has a period of 790 years and is 73 light-years from Earth. The primary and secondary, both white stars, are of magnitude 4.8 and 6.2, respectively. The unrelated tertiary component is of magnitude 6.9. Though the tertiary component is visible in binoculars, the primary and secondary currently require a medium-sized amateur telescope to split, as they will through the year 2020. The two stars will be closest between 2043 and 2050, when they will require a telescope with larger aperture to split. The stars 30 and 31 Cygni form a contrasting double star similar to the brighter Albireo. The two are visible in binoculars. The primary, 31 Cygni, is an orange-hued star of magnitude 3.8, 1400 light-years from Earth. The secondary, 30 Cygni, appears blue-green. It is of spectral type A5IIIn and magnitude 4.83, and is around 610 light-years from Earth. 31 Cygni itself is a binary star; the tertiary component is a blue star of magnitude 7.0. \u03c8 Cygni is a binary star visible in small amateur telescopes, with two white components. The primary is of magnitude 5.0 and the secondary is of magnitude 7.5. 61 Cygni is a binary star visible in large binoculars or a small amateur telescope. It is 11.4 light-years from Earth and has a period of 750 years. Both components are orange-hued dwarf (main sequence) stars; the primary is of magnitude 5.2 and the secondary is of magnitude 6.1. 61 Cygni is significant because Friedrich Wilhelm Bessel determined its parallax in 1838, the first star to have a known parallax.\nLocated near \u03b7 Cygni is the X-ray source Cygnus X-1, which is now thought to be caused by a black hole accreting matter in a binary star system. This was the first X-ray source widely believed to be a black hole. It is located approximately 2.2 kiloparsecs from the Sun. There is also supergiant variable star in the system which is known as HDE 226868.\nCygnus also contains several other noteworthy X-ray sources. Cygnus X-3 is a microquasar containing a Wolf\u2013Rayet star in orbit around a very compact object, with a period of only 4.8 hours. The system is one of the most intrinsically luminous X-ray sources observed. The system undergoes periodic outbursts of unknown nature, and during one such outburst, the system was found to be emitting muons, likely caused by neutrinos. While the compact object is thought to be a neutron star or possibly a black hole, it is possible that the object is instead a more exotic stellar remnant, possibly the first discovered quark star, hypothesized due to its production of cosmic rays that cannot be explained if the object is a normal neutron star. The system also emits cosmic rays and gamma rays, and has helped shed insight on to the formation of such rays. Cygnus X-2 is another X-ray binary, containing an A-type giant in orbit around a neutron star with a 9.8-day period. The system is interesting due to the rather small mass of the companion star, as most millisecond pulsars have much more massive companions. Another black hole in Cygnus is V404 Cygni, which consists of a K-type star orbiting around a black hole of around 12 solar masses. The black hole, similar to that of Cygnus X-3, has been hypothesized to be a quark star. 4U 2129+ 47 is another X-ray binary containing a neutron star which undergoes outbursts, as is EXO 2030+ 375.\nCygnus is also home to several variable stars. SS Cygni is a dwarf nova which undergoes outbursts every 7\u20138 weeks. The system's total magnitude varies from 12th magnitude at its dimmest to 8th magnitude at its brightest. The two objects in the system are incredibly close together, with an orbital period of less than 0.28 days. \u03c7 Cygni is a red giant and the second-brightest Mira variable star at its maximum. It ranges between magnitudes 3.3 and 14.2, and spectral types S6,2e to S10,4e (MSe) over a period of 408 days; it has a diameter of 300 solar diameters and is 350 light-years from Earth. P Cygni is a luminous blue variable that brightened suddenly to 3rd magnitude in 1600 AD. Since 1715, the star has been of 5th magnitude, despite being more than 5000 light-years from Earth. The star's spectrum is unusual in that it contains very strong emission lines resulting from surrounding nebulosity. W Cygni is a semi-regular variable red giant star, 618 light-years from Earth.It has a maximum magnitude of 5.10 and a minimum magnitude 6.83; its period of 131 days. It is a red giant ranging between spectral types M4e-M6e(Tc:)III, NML Cygni is a red hypergiant semi-regular variable star located at 5,300 light-years away from Earth. It is one of largest stars currently known in the galaxy with a radius exceeding 1,000 solar radii. Its magnitude is around 16.6, its period is about 940 days.\nThe star KIC 8462852 (Tabby's Star) has received widespread press coverage because of unusual light fluctuations.\nExoplanets.\nCygnus is one of the constellations that the Kepler satellite surveyed in its search for exoplanets, and as a result, there are about a hundred stars in Cygnus with known planets, the most of any constellation. One of the most notable systems is the Kepler-11 system, containing six transiting planets, all within a plane of approximately one degree. It was the system with six exoplanets to be discovered. With a spectral type of G6V, the star is somewhat cooler than the Sun. The planets are very close to the star; all but the last planet are closer to Kepler-11 than Mercury is to the Sun, and all the planets are more massive than Earth, and have low densities. The planets have low densities. The naked-eye star 16 Cygni, a triple star approximately 70 light-years from Earth composed two Sun-like stars and a red dwarf, contains a planet orbiting one of the sun-like stars, found due to variations in the star's radial velocity. Gliese 777, another naked-eye multiple star system containing a yellow star and a red dwarf, also contains a planet. The planet is somewhat similar to Jupiter, but with slightly more mass and a more eccentric orbit. The Kepler-22 system is also notable for having the most Earth-like exoplanet when it was discovered in 2011.\nStar clusters.\nThe rich background of stars of Cygnus can make it difficult to make out open cluster.\nM39 (NGC 7092) is an open cluster 950 light-years from Earth that are visible to the unaided eye under dark skies. It is loose, with about 30 stars arranged over a wide area; their conformation appears triangular. The brightest stars of M39 are of the 7th magnitude. Another open cluster in Cygnus is NGC 6910, also called the Rocking Horse Cluster, possessing 16 stars with a diameter of 5 arcminutes visible in a small amateur instrument; it is of magnitude 7.4. The brightest of these are two gold-hued stars, which represent the bottom of the toy it is named for. A larger amateur instrument reveals 8 more stars, nebulosity to the east and west of the cluster, and a diameter of 9 arcminutes. The nebulosity in this region is part of the Gamma Cygni Nebula. The other stars, approximately 3700 light-years from Earth, are mostly blue-white and very hot.\nOther open clusters in Cygnus include Dolidze 9, Collinder 421, Dolidze 11, and Berkeley 90. Dolidze 9, 2800 light-years from Earth and relatively young at 20 million light-years old, is a faint open cluster with up to 22 stars visible in small and medium-sized amateur telescopes. Nebulosity is visible to the north and east of the cluster, which is 7 arcminutes in diameter. The brightest star appears in the eastern part of the cluster and is of the 7th magnitude; another bright star has a yellow hue. Dolidze 11 is an open cluster 400 million years old, farthest away of the three at 3700 light-years. More than 10 stars are visible in an amateur instrument in this cluster, of similar size to Dolidze 9 at 7 arcminutes in diameter, whose brightest star is of magnitude 7.5. It, too, has nebulosity in the east. Collinder 421 is a particularly old open cluster at an age of approximately 1 billion years; it is of magnitude 10.1. 3100 light-years from Earth, more than 30 stars are visible in a diameter of 8 arcseconds. The prominent star in the north of the cluster has a golden color, whereas the stars in the south of the cluster appear orange. Collinder 421 appears to be embedded in nebulosity, which extends past the cluster's borders to its west. Berkeley 90 is a smaller open cluster, with a diameter of 5 arcminutes. More than 16 members appear in an amateur telescope.\nMolecular clouds.\nNGC 6826, the Blinking Planetary Nebula, is a planetary nebula with a magnitude of 8.5, 3200 light-years from Earth. It appears to \"blink\" in the eyepiece of a telescope because its central star is unusually bright (10th magnitude). When an observer focuses on the star, the nebula appears to fade away. Less than one degree from the Blinking Planetary is the double star 16 Cygni.\nThe North America Nebula (NGC 7000) is one of the most well-known nebulae in Cygnus, because it is visible to the unaided eye under dark skies, as a bright patch in the Milky Way. However, its characteristic shape is only visible in long-exposure photographs \u2013 it is difficult to observe in telescopes because of its low surface brightness. It has low surface brightness because it is so large; at its widest, the North America Nebula is 2 degrees across. Illuminated by a hot embedded star of magnitude 6, NGC 7000 is 1500 light-years from Earth.\nTo the south of Epsilon Cygni is the Veil Nebula (NGC 6960, 6979, 6992, and 6995), a 5,000-year-old supernova remnant covering approximately 3 degrees of the sky - it is over 50 light-years long. Because of its appearance, it is also called the Cygnus Loop. The Loop is only visible in long-exposure astrophotographs. However, the brightest portion, NGC 6992, is faintly visible in binoculars, and a dimmer portion, NGC 6960, is visible in wide-angle telescopes.\nThe DR 6 cluster is also nicknamed the \"Galactic Ghoul\" because of the nebula's resemblance to a human face;\nThe Gamma Cygni Nebula (IC 1318) includes both bright and dark nebulae in an area of over 4 degrees. DWB 87 is another of the many bright emission nebulae in Cygnus, 7.8 by 4.3 arcminutes. It is in the Gamma Cygni area. Two other emission nebulae include Sharpless 2-112 and Sharpless 2-115. When viewed in an amateur telescope, Sharpless 2\u2013112 appears to be in a teardrop shape. More of the nebula's eastern portion is visible with an O III (doubly ionized oxygen) filter. There is an orange star of magnitude 10 nearby and a star of magnitude 9 near the nebula's northwest edge. Further to the northwest, there is a dark rift and another bright patch. The whole nebula measures 15 arcminutes in diameter. Sharpless 2\u2013115 is another emission nebula with a complex pattern of light and dark patches. Two pairs of stars appear in the nebula; it is larger near the southwestern pair. The open cluster Berkeley 90 is embedded in this large nebula, which measures 30 by 20 arcminutes.\nAlso of note is the Crescent Nebula (NGC 6888), located between Gamma and Eta Cygni, which was formed by the Wolf\u2013Rayet star HD 192163.\nIn recent years, amateur astronomers have made some notable Cygnus discoveries. The \"Soap bubble nebula\" (PN G75.5+1.7), near the Crescent nebula, was discovered on a digital image by Dave Jurasevich in 2007. In 2011, Austrian amateur Matthias Kronberger discovered a planetary nebula (Kronberger 61, now nicknamed \"The Soccer Ball\") on old survey photos, confirmed recently in images by the Gemini Observatory; both of these are likely too faint to be detected by eye in a small amateur scope.\nBut a much more obscure and relatively 'tiny' object\u2014one which is readily seen in dark skies by amateur telescopes, under good conditions\u2014is the newly discovered nebula (likely reflection type) associated with the star 4 Cygni (HD 183056): an approximately fan-shaped glowing region of several arcminutes' diameter, to the south and west of the fifth-magnitude star. It was first discovered visually near San Jose, California and publicly reported by amateur astronomer Stephen Waldee in 2007, and was confirmed photographically by Al Howard in 2010. California amateur astronomer Dana Patchick also says he detected it on the Palomar Observatory survey photos in 2005 but had not published it for others to confirm and analyze at the time of Waldee's first official notices and later 2010 paper.\nCygnus X is the largest star-forming region in the solar neighborhood and includes not only some of the brightest and most massive stars known (such as Cygnus OB2-12), but also Cygnus OB2, a massive stellar association classified by some authors as a young globular cluster.\nDeep space objects.\nCygnus A is the first radio galaxy discovered; at a distance of 730 million light-years from Earth, it is the closest powerful radio galaxy. In the visible spectrum, it appears as an elliptical galaxy in a small cluster. It is classified as an active galaxy because the supermassive black hole at its nucleus is accreting matter, which produces two jets of matter from the poles. The jets' interaction with the interstellar medium creates radio lobes, one source of radio emissions.\nOther features.\nCygnus is also the apparent source of the WIMP-wind due to the orientation of the solar system's rotation through the galactic halo.\nThe local Orion-Cygnus Arm and the distant Cygnus Arm are two minor galactic arms named after Cygnus for lying in its background."}
{"id": "6422", "revid": "1265592293", "url": "https://en.wikipedia.org/wiki?curid=6422", "title": "Communion", "text": "Communion may refer to:"}
{"id": "6423", "revid": "8565473", "url": "https://en.wikipedia.org/wiki?curid=6423", "title": "Calorie", "text": "The calorie is a unit of energy that originated from the caloric theory of heat. The large calorie, food calorie, dietary calorie, kilocalorie, or kilogram calorie is defined as the amount of heat needed to raise the temperature of one liter of water by one degree Celsius (or one kelvin). The small calorie or gram calorie is defined as the amount of heat needed to cause the same increase in one milliliter of water. Thus, 1 large calorie is equal to 1,000 small calories. \nIn nutrition and food science, the term \"calorie\" and the symbol \"cal\" may refer to the large unit or to the small unit in different regions of the world. It is generally used in publications and package labels to express the energy value of foods in per serving or per weight, recommended dietary caloric intake, metabolic rates, etc. Some authors recommend the spelling \"Calorie\" and the symbol \"Cal\" (both with a capital C) if the large calorie is meant, to avoid confusion; however, this convention is often ignored.\nIn physics and chemistry, the word \"calorie\" and its symbol usually refer to the small unit, the large one being called \"kilocalorie\" (kcal). However, the kcal is not officially part of the International System of Units (SI), and is regarded as obsolete, having been replaced in many uses by the SI derived unit of energy, the joule (J), or the kilojoule (kJ) for 1000 joules.\nThe precise equivalence between calories and joules has varied over the years, but in thermochemistry and nutrition it is now generally assumed that one (small) calorie (thermochemical calorie) is equal to exactly 4.184\u00a0J, and therefore one kilocalorie (one large calorie) is 4184\u00a0J or 4.184\u00a0kJ.\nHistory.\nThe term \"calorie\" comes . It was first introduced by Nicolas Cl\u00e9ment, as a unit of heat energy, in lectures on experimental calorimetry during the years 1819\u20131824. This was the \"large\" calorie. The term (written with lowercase \"c\") entered French and English dictionaries between 1841 and 1867.\nThe same term was used for the \"small\" unit by Pierre Antoine Favre (chemist) and Johann T. Silbermann (physicist) in 1852.\nIn 1879, Marcellin Berthelot distinguished between gram-calorie and kilogram-calorie, and proposed using \"Calorie\", with capital \"C\", for the large unit. This usage was adopted by Wilbur Olin Atwater, a professor at Wesleyan University, in 1887, in an influential article on the energy content of food.\nThe smaller unit was used by U.S. physician Joseph Howard Raymond, in his classic 1894 textbook \"A Manual of Human Physiology\". He proposed calling the \"large\" unit \"kilocalorie\", but the term did not catch on until some years later.\nThe small calorie (cal) was recognized as a unit of the CGS system in 1896, alongside the already-existing CGS unit of energy, the erg (first suggested by Clausius in 1864, under the name \"ergon\", and officially adopted in 1882).\nIn 1928, there were already serious complaints about the possible confusion arising from the two main definitions of the calorie and whether the notion of using the capital letter to distinguish them was sound.\nThe joule was the officially adopted SI unit of energy at the ninth General Conference on Weights and Measures in 1948. The calorie was mentioned in the 7th edition of the SI brochure as an example of a non-SI unit.\nThe alternate spelling is a less-common, non-standard variant.\nDefinitions.\nThe \"small\" calorie is broadly defined as the amount of energy needed to increase the temperature of 1\u00a0gram of water by 1\u00a0\u00b0C (or 1\u00a0K, which is the same increment, a gradation of one percent of the interval between the melting point and the boiling point of water). The actual amount of energy required to accomplish this temperature increase depends on the atmospheric pressure and the starting temperature; different choices of these parameters have resulted in several different precise definitions of the unit.\nThe two definitions most common in older literature appear to be the \"15\u00a0\u00b0C calorie\" and the \"thermochemical calorie\". Until 1948, the latter was defined as 4.1833 international joules; the current standard of 4.184\u00a0J was chosen to have the new thermochemical calorie represent the same quantity of energy as before.\nUsage.\nNutrition.\nIn the United States, in a nutritional context, the \"large\" unit is used almost exclusively. It is generally written \"calorie\" with lowercase \"c\" and symbol \"cal\", even in government publications. The SI unit kilojoule (kJ) may be used instead, in legal or scientific contexts. Most American nutritionists prefer the unit kilocalorie to the unit kilojoules, whereas most physiologists prefer to use kilojoules. In the majority of other countries, nutritionists prefer the kilojoule to the kilocalorie.\nIn the European Union, on nutrition facts labels, energy is expressed in both kilojoules and kilocalories, abbreviated as \"kJ\" and \"kcal\" respectively.\nIn China, only kilojoules are given.\nFood energy.\nThe unit is most commonly used to express food energy, namely the specific energy (energy per mass) of metabolizing different types of food. For example, fat (triglyceride lipids) contains 9\u00a0kilocalories per gram (kcal/g), while carbohydrates (sugar and starch) and protein contain approximately 4\u00a0kcal/g. Alcohol in food contains 7\u00a0kcal/g. The \"large\" unit is also used to express recommended nutritional intake or consumption, as in \"calories per day\".\nDieting is the practice of eating food in a regulated way to decrease, maintain, or increase body weight, or to prevent and treat diseases such as diabetes and obesity. As weight loss depends on reducing caloric intake, different kinds of calorie-reduced diets have been shown to be generally effective.\nChemistry and physics.\nIn other scientific contexts, the term \"calorie\" and the symbol \"cal\" almost always refers to the small unit; the \"large\" unit being generally called \"kilocalorie\" with symbol \"kcal\". It is mostly used to express the amount of energy released in a chemical reaction or phase change, typically per mole of substance, as in kilocalories per mole. It is also occasionally used to specify other energy quantities that relate to reaction energy, such as enthalpy of formation and the size of activation barriers. However, it is increasingly being superseded by the SI unit, the joule (J); and metric multiples thereof, such as the kilojoule (kJ).\nThe lingering use in chemistry is largely due to the fact that the energy released by a reaction in aqueous solution, expressed in kilocalories per mole of reagent, is numerically close to the concentration of the reagent in moles per liter multiplied by the change in the temperature of the solution in kelvins or degrees Celsius. However, this estimate assumes that the volumetric heat capacity of the solution is 1\u00a0kcal/(L\u22c5K), which is not exact even for pure water."}
