{"id": "7738", "revid": "2576398", "url": "https://en.wikipedia.org/wiki?curid=7738", "title": "Chiropractic", "text": "Chiropractic () is a form of alternative medicine concerned with the diagnosis, treatment and prevention of mechanical disorders of the musculoskeletal system, especially of the spine. It is based on several pseudoscientific ideas.\nMany chiropractors (often known informally as chiros), especially those in the field's early history, have proposed that mechanical disorders of the joints, especially of the spine, affect general health, and that regular manipulation of the spine (spinal adjustment) improves general health. The main chiropractic treatment technique involves manual therapy, especially manipulation of the spine, other joints, and soft tissues, but may also include exercises and health and lifestyle counseling. A chiropractor may have a Doctor of Chiropractic (D.C.) degree and be referred to as \"doctor\" but is not a Doctor of Medicine (M.D.) or a Doctor of Osteopathic Medicine (D.O.). While many chiropractors view themselves as primary care providers, chiropractic clinical training does not meet the requirements for that designation.\nSystematic reviews of controlled clinical studies of treatments used by chiropractors have found no evidence that chiropractic manipulation is effective, with the possible exception of treatment for back pain. A 2011 critical evaluation of 45 systematic reviews concluded that the data included in the study \"fail[ed] to demonstrate convincingly that spinal manipulation is an effective intervention for any condition.\" Spinal manipulation may be cost-effective for sub-acute or chronic low back pain, but the results for acute low back pain were insufficient. No compelling evidence exists to indicate that maintenance chiropractic care adequately prevents symptoms or diseases.\nThere is not sufficient data to establish the safety of chiropractic manipulations. It is frequently associated with mild to moderate adverse effects, with serious or fatal complications in rare cases. There is controversy regarding the degree of risk of vertebral artery dissection, which can lead to stroke and death, from cervical manipulation. Several deaths have been associated with this technique and it has been suggested that the relationship is causative, a claim which is disputed by many chiropractors.\nChiropractic is well established in the United States, Canada, and Australia. It overlaps with other manual-therapy professions such as osteopathy and physical therapy. Most who seek chiropractic care do so for low back pain. Back and neck pain are considered the specialties of chiropractic, but many chiropractors treat ailments other than musculoskeletal issues. Chiropractic has two main groups: \"straights\", now the minority, emphasize vitalism, \"Innate Intelligence\", and consider vertebral subluxations to be the cause of all disease; and \"mixers\", the majority, are more open to mainstream views and conventional medical techniques, such as exercise, massage, and ice therapy.\nD. D. Palmer founded chiropractic in the 1890s, claiming that he had received it from \"the other world\". Palmer maintained that the tenets of chiropractic were passed along to him by a doctor who had died 50 years previously. His son B. J. Palmer helped to expand chiropractic in the early 20th century. Throughout its history, chiropractic has been controversial. Its foundation is at odds with evidence-based medicine, and is underpinned by pseudoscientific ideas such as vertebral subluxation and Innate Intelligence. Despite the overwhelming evidence that vaccination is an effective public health intervention, there are significant disagreements among chiropractors over the subject, which has led to negative impacts on both public vaccination and mainstream acceptance of chiropractic. The American Medical Association called chiropractic an \"unscientific cult\" in 1966 and boycotted it until losing an antitrust case in 1987. Chiropractic has had a strong political base and sustained demand for services. In the last decades of the twentieth century, it gained more legitimacy and greater acceptance among conventional physicians and health plans in the United States. During the COVID-19 pandemic, chiropractic professional associations advised chiropractors to adhere to CDC, WHO, and local health department guidance. Despite these recommendations, a small but vocal and influential number of chiropractors spread vaccine misinformation.\nConceptual basis.\nPhilosophy.\nChiropractic is generally categorized as complementary and alternative medicine (CAM), which focuses on manipulation of the musculoskeletal system, especially the spine. Its founder, D.D. Palmer, called it \"a science of healing without drugs\".\nChiropractic's origins lie in the folk medicine of bonesetting, and as it evolved it incorporated vitalism, spiritual inspiration and rationalism. Its early philosophy was based on deduction from irrefutable doctrine, which helped distinguish chiropractic from medicine, provided it with legal and political defenses against claims of practicing medicine without a license, and allowed chiropractors to establish themselves as an autonomous profession. This \"straight\" philosophy, taught to generations of chiropractors, rejects the inferential reasoning of the scientific method, and relies on deductions from vitalistic first principles rather than on the materialism of science. However, most practitioners tend to incorporate scientific research into chiropractic, and most practitioners are \"mixers\" who attempt to combine the materialistic reductionism of science with the metaphysics of their predecessors and with the holistic paradigm of wellness. A 2008 commentary proposed that chiropractic actively divorce itself from the straight philosophy as part of a campaign to eliminate untestable dogma and engage in critical thinking and evidence-based research.\nAlthough a wide diversity of ideas exist among chiropractors, they share the belief that the spine and health are related in a fundamental way, and that this relationship is mediated through the nervous system. Some chiropractors claim spinal manipulation can have an effect on a variety of ailments such as irritable bowel syndrome and asthma.\nChiropractic philosophy includes the following perspectives:\nHolism assumes that health is affected by everything in an individual's environment; some sources also include a spiritual or existential dimension. In contrast, reductionism in chiropractic reduces causes and cures of health problems to a single factor, vertebral subluxation. Homeostasis emphasizes the body's inherent self-healing abilities. Chiropractic's early notion of innate intelligence can be thought of as a metaphor for homeostasis.\nA large number of chiropractors fear that if they do not separate themselves from the traditional vitalistic concept of innate intelligence, chiropractic will continue to be seen as a fringe profession. A variant of chiropractic called naprapathy originated in Chicago in the early twentieth century. It holds that manual manipulation of soft tissue can reduce \"interference\" in the body and thus improve health.\nStraights and mixers.\n\"Straight\" chiropractors adhere to the philosophical principles set forth by D.D. and B.J. Palmer, and retain metaphysical definitions and vitalistic qualities. Straight chiropractors believe that vertebral subluxation leads to interference with an \"innate intelligence\" exerted via the human nervous system and is a primary underlying risk factor for many diseases. Straights view the medical diagnosis of patient complaints, which they consider to be the \"secondary effects\" of subluxations, to be unnecessary for chiropractic treatment. Thus, straight chiropractors are concerned primarily with the detection and correction of vertebral subluxation via adjustment and do not \"mix\" other types of therapies into their practice style. Their philosophy and explanations are metaphysical in nature and they prefer to use traditional chiropractic lexicon terminology such as \"perform spinal analysis\", \"detect subluxation\", \"correct with adjustment\". They prefer to remain separate and distinct from mainstream health care. Although considered the minority group, \"they have been able to transform their status as purists and heirs of the lineage into influence dramatically out of proportion to their numbers.\"\n\"Mixer\" chiropractors \"mix\" diagnostic and treatment approaches from chiropractic, medical or osteopathic viewpoints and make up the majority of chiropractors. Unlike straight chiropractors, mixers believe subluxation is one of many causes of disease, and hence they tend to be open to mainstream medicine. Many of them incorporate mainstream medical diagnostics and employ conventional treatments including techniques of physical therapy such as exercise, stretching, massage, ice packs, electrical muscle stimulation, therapeutic ultrasound, and moist heat. Some mixers also use techniques from alternative medicine, including nutritional supplements, acupuncture, homeopathy, herbal remedies, and biofeedback.\nAlthough mixers are the majority group, many of them retain belief in vertebral subluxation as shown in a 2003 survey of 1,100 North American chiropractors, which found that 88 percent wanted to retain the term \"vertebral subluxation complex\", and that when asked to estimate the percent of disorders of internal organs that subluxation significantly contributes to, the mean response was 62 percent. A 2008 survey of 6,000 American chiropractors demonstrated that most chiropractors seem to believe that a subluxation-based clinical approach may be of limited utility for addressing visceral disorders, and greatly favored non-subluxation-based clinical approaches for such conditions. The same survey showed that most chiropractors generally believed that the majority of their clinical approach for addressing musculoskeletal/biomechanical disorders such as back pain was based on subluxation. Chiropractors often offer conventional therapies such as physical therapy and lifestyle counseling, and it may for the lay person be difficult to distinguish the unscientific from the scientific.\nVertebral subluxation.\nIn science-based medicine, the term \"subluxation\" refers to an incomplete or partial dislocation of a joint, from the Latin \"luxare\" for 'dislocate'. While medical doctors use the term exclusively to refer to physical dislocations, Chiropractic founder D. D. Palmer imbued the word \"subluxation\" with a metaphysical and philosophical meaning drawn from pseudoscientific traditions such as Vitalism.\nPalmer claimed that \"vertebral subluxations\" interfered with the body's function and its inborn ability to heal itself. D. D. Palmer repudiated his earlier theory that vertebral subluxations caused pinched nerves in the intervertebral spaces in favor of subluxations causing altered nerve vibration, either too tense or too slack, affecting the tone (health) of the end organ. He qualified this by noting that knowledge of innate intelligence was not essential to the competent practice of chiropractic. This concept was later expanded upon by his son, B. J. Palmer, and was instrumental in providing the legal basis of differentiating chiropractic from conventional medicine. In 1910, D. D. Palmer theorized that the nervous system controlled health:\nVertebral subluxation, a core concept of traditional chiropractic, remains unsubstantiated and largely untested, and a debate about whether to keep it in the chiropractic paradigm has been ongoing for decades. In general, critics of traditional subluxation-based chiropractic (including chiropractors) are skeptical of its clinical value, dogmatic beliefs and metaphysical approach. While straight chiropractic still retains the traditional vitalistic construct espoused by the founders, evidence-based chiropractic suggests that a mechanistic view will allow chiropractic care to become integrated into the wider health care community. This is still a continuing source of debate within the chiropractic profession as well, with some schools of chiropractic still teaching the traditional/straight subluxation-based chiropractic, while others have moved towards an evidence-based chiropractic that rejects metaphysical foundings and limits itself to primarily neuromusculoskeletal conditions.\nIn 2005, the chiropractic subluxation was defined by the World Health Organization as \"a lesion or dysfunction in a joint or motion segment in which alignment, movement integrity and/or physiological function are altered, although contact between joint surfaces remains intact. It is essentially a functional entity, which may influence biomechanical and neural integrity.\" This differs from the medical definition of subluxation as a significant structural displacement, which can be seen with static imaging techniques such as X-rays. The use of X-ray imaging in the case of vertebral subluxation exposes patients to harmful ionizing radiation for no evidentially supported reason. The 2008 book \"Trick or Treatment\" states \"X-rays can reveal neither the subluxations nor the innate intelligence associated with chiropractic philosophy, because they do not exist.\" Attorney David Chapman-Smith, Secretary-General of the World Federation of Chiropractic, has stated that \"Medical critics have asked how there can be a subluxation if it cannot be seen on X-ray. The answer is that the chiropractic subluxation is essentially a functional entity, not structural, and is therefore no more visible on static X-ray than a limp or headache or any other functional problem.\" The General Chiropractic Council, the statutory regulatory body for chiropractors in the United Kingdom, states that the chiropractic vertebral subluxation complex \"is not supported by any clinical research evidence that would allow claims to be made that it is the cause of disease.\"\nAs of 2014, the US National Board of Chiropractic Examiners states \"The specific focus of chiropractic practice is known as the chiropractic subluxation or joint dysfunction. A subluxation is a health concern that manifests in the skeletal joints, and, through complex anatomical and physiological relationships, affects the nervous system and may lead to reduced function, disability or illness.\"\nPseudoscience versus spinal manipulation therapy.\nWhile some chiropractors limit their practice to short-term treatment of musculoskeletal conditions, many falsely claim to be able treat a myriad of other conditions. Some dissuade patients from seeking medical care, others have pretended to be qualified to act as a family doctor.\nQuackwatch, an alternative medicine watchdog, cautions against seeing chiropractors who:\nWriting for the \"Skeptical Inquirer\", one physician cautioned against seeing even chiropractors who solely claim to treat musculoskeletal conditions: \nScope of practice.\nChiropractors emphasize the conservative management of the neuromusculoskeletal system without the use of medicines or surgery, with special emphasis on the spine. Back and neck pain are the specialties of chiropractic but many chiropractors treat ailments other than musculoskeletal issues. There is a range of opinions among chiropractors: some believed that treatment should be confined to the spine, or back and neck pain; others disagreed. For example, while one 2009 survey of American chiropractors had found that 73% classified themselves as \"back pain/musculoskeletal specialists\", the label \"back and neck pain specialists\" was regarded by 47% of them as a \"least\" desirable description in a 2005 international survey. Chiropractic combines aspects from mainstream and alternative medicine, and there is no agreement about how to define the profession: although chiropractors have many attributes of primary care providers, chiropractic has more attributes of a medical specialty like dentistry or podiatry. It has been proposed that chiropractors specialize in nonsurgical spine care, instead of attempting to also treat other problems, but the more expansive view of chiropractic is still widespread.\nMainstream health care and governmental organizations such as the World Health Organization consider chiropractic to be complementary and alternative medicine (CAM); and a 2008 study reported that 31% of surveyed chiropractors categorized chiropractic as CAM, 27% as integrated medicine, and 12% as mainstream medicine. Many chiropractors believe they are primary care providers, including US and UK chiropractors, but the length, breadth, and depth of chiropractic clinical training do not support the requirements to be considered primary care providers, so their role on primary care is limited and disputed.\nChiropractic overlaps with several other forms of manual therapy, including massage therapy, osteopathy, physical therapy, and sports medicine. Chiropractic is autonomous from and competitive with mainstream medicine, and osteopathy outside the US remains primarily a manual medical system; physical therapists work alongside and cooperate with mainstream medicine, and osteopathic medicine in the U.S. has merged with the medical profession. Practitioners may distinguish these competing approaches through claims that, compared to other therapists, chiropractors heavily emphasize spinal manipulation, tend to use firmer manipulative techniques, and promote maintenance care; that osteopaths use a wider variety of treatment procedures; and that physical therapists emphasize machinery and exercise.\nChiropractic diagnosis may involve a range of methods including skeletal imaging, observational and tactile assessments, and orthopedic and neurological evaluation. A chiropractor may also refer a patient to an appropriate specialist, or co-manage with another health care provider. Common patient management involves spinal manipulation (SM) and other manual therapies to the joints and soft tissues, rehabilitative exercises, health promotion, electrical modalities, complementary procedures, and lifestyle advice.\nChiropractors are not normally licensed to write medical prescriptions or perform major surgery in the United States (although New Mexico has become the first US state to allow \"advanced practice\" trained chiropractors to prescribe certain medications). In the US, their scope of practice varies by state, based on inconsistent views of chiropractic care: some states, such as Iowa, broadly allow treatment of \"human ailments\"; some, such as Delaware, use vague concepts such as \"transition of nerve energy\" to define scope of practice; others, such as New Jersey, specify a severely narrowed scope. US states also differ over whether chiropractors may conduct laboratory tests or diagnostic procedures, dispense dietary supplements, or use other therapies such as homeopathy and acupuncture; in Oregon they can become certified to perform minor surgery and to deliver children via natural childbirth. A 2003 survey of North American chiropractors found that a slight majority favored allowing them to write prescriptions for over-the-counter drugs. A 2010 survey found that 72% of Swiss chiropractors considered their ability to prescribe nonprescription medication as an advantage for chiropractic treatment.\nA related field, veterinary chiropractic, applies manual therapies to animals and is recognized in many US states, but is not recognized by the American Chiropractic Association as being chiropractic. It remains controversial within certain segments of the veterinary and chiropractic professions.\nNo single profession \"owns\" spinal manipulation and there is little consensus as to which profession should administer SM, raising concerns by chiropractors that other medical physicians could \"steal\" SM procedures from chiropractors. A focus on evidence-based SM research has also raised concerns that the resulting practice guidelines could limit the scope of chiropractic practice to treating backs and necks. Two US states (Washington and Arkansas) prohibit physical therapists from performing SM, some states allow them to do it only if they have completed advanced training in SM, and some states allow only chiropractors to perform SM, or only chiropractors and physicians. Bills to further prohibit non-chiropractors from performing SM are regularly introduced into state legislatures and are opposed by physical therapist organizations.\nTreatments.\nSpinal manipulation, which chiropractors call \"spinal adjustment\" or \"chiropractic adjustment\", is the most common treatment used in chiropractic care. Spinal manipulation is a passive manual maneuver during which a three-joint complex is taken past the normal range of movement, but not so far as to dislocate or damage the joint. Its defining factor is a dynamic thrust, which is a sudden force that causes an audible release and attempts to increase a joint's range of motion. High-velocity, low-amplitude spinal manipulation (HVLA-SM) thrusts have physiological effects that signal neural discharge from paraspinal muscle tissues, depending on duration and amplitude of the thrust are factors of the degree in paraspinal muscle spindles activation. Clinical skill in employing HVLA-SM thrusts depends on the ability of the practitioner to handle the duration and magnitude of the load. More generally, spinal manipulative therapy (SMT) describes techniques where the hands are used to manipulate, massage, mobilize, adjust, stimulate, apply traction to, or otherwise influence the spine and related tissues.\nThere are several schools of chiropractic adjustive techniques, although most chiropractors mix techniques from several schools. The following adjustive procedures were received by more than 10% of patients of licensed US chiropractors in a 2003 survey: Diversified technique (full-spine manipulation, employing various techniques), extremity adjusting, Activator technique (which uses a spring-loaded tool to deliver precise adjustments to the spine), Thompson Technique (which relies on a drop table and detailed procedural protocols), Gonstead (which emphasizes evaluating the spine along with specific adjustment that avoids rotational vectors), Cox/flexion-distraction (a gentle, low-force adjusting procedure which mixes chiropractic with osteopathic principles and utilizes specialized adjusting tables with movable parts), adjustive instrument, Sacro-Occipital Technique (which models the spine as a torsion bar), Nimmo Receptor-Tonus Technique, applied kinesiology (which emphasises \"muscle testing\" as a diagnostic tool), and cranial. Chiropractic biophysics technique uses inverse functions of rotations during spinal manipulation. Koren Specific Technique (KST) may use their hands, or they may use an electric device known as an \"ArthroStim\" for assessment and spinal manipulations. Insurers in the US and UK that cover other chiropractic techniques exclude KST from coverage because they consider it to be \"experimental and investigational\". Medicine-assisted manipulation, such as manipulation under anesthesia, involves sedation or local anesthetic and is done by a team that includes an anesthesiologist; a 2008 systematic review did not find enough evidence to make recommendations about its use for chronic low back pain.\nMany other procedures are used by chiropractors for treating the spine, other joints and tissues, and general health issues. The following procedures were received by more than one-third of patients of licensed US chiropractors in a 2003 survey: Diversified technique (full-spine manipulation; mentioned in previous paragraph), physical fitness/exercise promotion, corrective or therapeutic exercise, ergonomic/postural advice, self-care strategies, activities of daily living, changing risky/unhealthy behaviors, nutritional/dietary recommendations, relaxation/stress reduction recommendations, ice pack/cryotherapy, extremity adjusting (also mentioned in previous paragraph), trigger point therapy, and disease prevention/early screening advice.\nA 2010 study describing Belgian chiropractors and their patients found chiropractors in Belgium mostly focus on neuromusculoskeletal complaints in adult patients, with emphasis on the spine. The diversified technique is the most often applied technique at 93%, followed by the Activator mechanical-assisted technique at 41%. A 2009 study assessing chiropractic students giving or receiving spinal manipulations while attending a United States chiropractic college found Diversified, Gonstead, and upper cervical manipulations are frequently used methods.\nPractice guidelines.\nReviews of research studies within the chiropractic community have been used to generate practice guidelines outlining standards that specify which chiropractic treatments are legitimate (i.e. supported by evidence) and conceivably reimbursable under managed care health payment systems. Evidence-based guidelines are supported by one end of an ideological continuum among chiropractors; the other end employs antiscientific reasoning and makes unsubstantiated claims. Chiropractic remains at a crossroads, and that in order to progress it would need to embrace science; the promotion by some for it to be a cure-all was both \"misguided and irrational\". A 2007 survey of Alberta chiropractors found that they do not consistently apply research in practice, which may have resulted from a lack of research education and skills. Specific guidelines concerning the treatment of nonspecific (i.e., unknown cause) low back pain are inconsistent between countries.\nEffectiveness.\nNumerous controlled clinical studies of treatments used by chiropractors have been conducted, with varied results. There is no conclusive evidence that chiropractic manipulative treatment is effective for the treatment of any medical condition, except perhaps for certain kinds of back pain.\nGenerally, the research carried out into the effectiveness of chiropractic has been of poor quality. Research published by chiropractors is distinctly biased: reviews of SM for back pain tended to find positive conclusions when authored by chiropractors, while reviews by mainstream authors did not.\nThere is a wide range of ways to measure treatment outcomes. Chiropractic care benefits from the placebo response, but it is difficult to construct a trustworthy placebo for clinical trials of spinal manipulative therapy (SMT). The efficacy of maintenance care in chiropractic is unknown.\nAvailable evidence covers the following conditions:\nSafety.\nThe World Health Organization found chiropractic care in general is safe when employed skillfully and appropriately. There is not sufficient data to establish the safety of chiropractic manipulations. Manipulation is regarded as relatively safe but complications can arise, and it has known adverse effects, risks and contraindications. Absolute contraindications to spinal manipulative therapy are conditions that should not be manipulated; these contraindications include rheumatoid arthritis and conditions known to result in unstable joints. Relative contraindications are conditions where increased risk is acceptable in some situations and where low-force and soft-tissue techniques are treatments of choice; these contraindications include osteoporosis. Although most contraindications apply only to manipulation of the affected region, some neurological signs indicate referral to emergency medical services; these include sudden and severe headache or neck pain unlike that previously experienced. Indirect risks of chiropractic involve delayed or missed diagnoses through consulting a chiropractor.\nSpinal manipulation is associated with frequent, mild and temporary adverse effects, including new or worsening pain or stiffness in the affected region. They have been estimated to occur in 33% to 61% of patients, and frequently occur within an hour of treatment and disappear within 24 to 48 hours; adverse reactions appear to be more common following manipulation than mobilization. The most frequently stated adverse effects are mild headache, soreness, and briefly elevated pain fatigue. Chiropractic is correlated with a very high incidence of minor adverse effects. Rarely, spinal manipulation, particularly on the upper spine, can also result in complications that can lead to permanent disability or death; these can occur in adults and children. Estimates vary widely for the incidence of these complications, and the actual incidence is unknown, due to high levels of underreporting and to the difficulty of linking manipulation to adverse effects such as stroke, which is a particular concern. Adverse effects are poorly reported in recent studies investigating chiropractic manipulations. A 2016 systematic review concludes that the level of reporting is unsuitable and unacceptable. Reports of serious adverse events have occurred, resulting from spinal manipulation therapy of the lumbopelvic region. Estimates for serious adverse events vary from 5 strokes per 100,000 manipulations to 1.46 serious adverse events per 10 million manipulations and 2.68 deaths per 10 million manipulations, though it was determined that there was inadequate data to be conclusive. Several case reports show temporal associations between interventions and potentially serious complications. The published medical literature contains reports of 26 deaths since 1934 following chiropractic manipulations and many more seem to remain unpublished.\nVertebrobasilar artery stroke (VAS) is statistically associated with chiropractic services in persons under 45 years of age, but it is similarly associated with general practitioner services, suggesting that these associations are likely explained by preexisting conditions. Weak to moderately strong evidence supports causation (as opposed to statistical association) between cervical manipulative therapy (CMT) and VAS. There is insufficient evidence to support a strong association or no association between cervical manipulation and stroke. While the biomechanical evidence is not sufficient to support the statement that CMT causes cervical artery dissection (CD), clinical reports suggest that mechanical forces have a part in a substantial number of CDs and the majority of population controlled studies found an association between CMT and VAS in young people. It is strongly recommended that practitioners consider the plausibility of CD as a symptom, and people can be informed of the association between CD and CMT before administering manipulation of the cervical spine. There is controversy regarding the degree of risk of stroke from cervical manipulation. Many chiropractors state that, the association between chiropractic therapy and vertebral arterial dissection is not proven. However, it has been suggested that the causality between chiropractic cervical manipulation beyond the normal range of motion and vascular accidents is probable or definite. There is very low evidence supporting a small association between internal carotid artery dissection and chiropractic neck manipulation. The incidence of internal carotid artery dissection following cervical spine manipulation is unknown. The literature infrequently reports helpful data to better understand the association between cervical manipulative therapy, cervical artery dissection and stroke. The limited evidence is inconclusive that chiropractic spinal manipulation therapy is not a cause of intracranial hypotension. Cervical intradural disc herniation is very rare following spinal manipulation therapy.\nChiropractors sometimes employ diagnostic imaging techniques such as X-rays and CT scans that rely on ionizing radiation. Although there is no clear evidence to justify the practice, some chiropractors still X-ray a patient several times a year. Practice guidelines aim to reduce unnecessary radiation exposure, which increases cancer risk in proportion to the amount of radiation received. Research suggests that radiology instruction given at chiropractic schools worldwide seem to be evidence-based. Although, there seems to be a disparity between some schools and available evidence regarding the aspect of radiography for patients with acute low back pain without an indication of a serious disease, which may contribute to chiropractic overuse of radiography for low back pain.\nRisk-benefit.\nA 2012 systematic review concluded that no accurate assessment of risk-benefit exists for cervical manipulation. A 2010 systematic review stated that there is no good evidence to assume that neck manipulation is an effective treatment for any medical condition and suggested a precautionary principle in healthcare for chiropractic intervention even if a causality with vertebral artery dissection after neck manipulation were merely a remote possibility. The same review concluded that the risk of death from manipulations to the neck outweighs the benefits. Chiropractors have criticized this conclusion, claiming that the author did not evaluate the potential benefits of spinal manipulation. Edzard Ernst stated \"This detail was not the subject of my review. I do, however, refer to such evaluations and should add that a report recently commissioned by the General Chiropractic Council did not support many of the outlandish claims made by many chiropractors across the world.\" A 1999 review of 177 previously reported cases published between 1925 and 1997 in which injuries were attributed to manipulation of the cervical spine (MCS) concluded that \"The literature does not demonstrate that the benefits of MCS outweigh the risks.\" The professions associated with each injury were assessed. Physical therapists (PT) were involved in less than 2% of all cases, with no deaths caused by PTs. Chiropractors were involved in a little more than 60% of all cases, including 32 deaths.&lt;ref name=\"Di_Fabio_1/1/1999\"&gt;&lt;/ref&gt;\nA 2009 review evaluating maintenance chiropractic care found that spinal manipulation is associated with considerable harm and no compelling evidence exists to indicate that it adequately prevents symptoms or diseases, thus the risk-benefit is not evidently favorable.\nCost-effectiveness.\nA 2012 systematic review suggested that the use of spine manipulation in clinical practice is a cost-effective treatment when used alone or in combination with other treatment approaches. A 2011 systematic review found evidence supporting the cost-effectiveness of using spinal manipulation for the treatment of sub-acute or chronic low back pain; the results for acute low back pain were insufficient.\nA 2006 systematic cost-effectiveness review found that the reported cost-effectiveness of spinal manipulation in the United Kingdom compared favorably with other treatments for back pain, but that reports were based on data from clinical trials without placebo controls and that the specific cost-effectiveness of the treatment (as opposed to non-specific effects) remains uncertain. A 2005 American systematic review of economic evaluations of conservative treatments for low back pain found that significant quality problems in available studies meant that definite conclusions could not be drawn about the most cost-effective intervention. The cost-effectiveness of maintenance chiropractic care is unknown.\nAnalysis of a clinical and cost utilization data from the years 2003 to 2005 by an integrative medicine independent physician association (IPA) which looked the chiropractic services utilization found that the clinical and cost utilization of chiropractic services based on 70,274 member-months over a 7-year period decreased patient costs associate with the following use of services by 60% for in-hospital admissions, 59% for hospital days, 62% for outpatient surgeries and procedures, and 85% for pharmaceutical costs when compared with conventional medicine (visit to a medical doctor primary care provider) IPA performance for the same health maintenance organization product in the same geography and time frame.\nEducation, licensing, and regulation.\nRequirements vary between countries. In the U.S. chiropractors obtain a non-medical accredited diploma in the field of chiropractic. Chiropractic education in the U.S. has been criticized for failing to meet generally accepted standards of evidence-based medicine. The curriculum content of North American chiropractic and medical colleges with regard to basic and clinical sciences has little similarity, both in the kinds of subjects offered and in the time assigned to each subject. Accredited chiropractic programs in the U.S. require that applicants have 90 semester hours of undergraduate education with a grade point average of at least 3.0 on a 4.0 scale. Many programs require at least three years of undergraduate education, and more are requiring a bachelor's degree. Canada requires a minimum three years of undergraduate education for applicants, and at least 4200 instructional hours (or the equivalent) of full-time chiropractic education for matriculation through an accredited chiropractic program. Graduates of the Canadian Memorial Chiropractic College (CMCC) are formally recognized to have at least 7\u20138 years of university level education. The World Health Organization (WHO) guidelines suggest three major full-time educational paths culminating in either a DC, DCM, BSc, or MSc degree. Besides the full-time paths, they also suggest a conversion program for people with other health care education and limited training programs for regions where no legislation governs chiropractic.\nUpon graduation, there may be a requirement to pass national, state, or provincial board examinations before being licensed to practice in a particular jurisdiction. Depending on the location, continuing education may be required to renew these licenses. Specialty training is available through part-time postgraduate education programs such as chiropractic orthopedics and sports chiropractic, and through full-time residency programs such as radiology or orthopedics.\nIn the U.S., chiropractic schools are accredited through the Council on Chiropractic Education (CCE) while the General Chiropractic Council (GCC) is the statutory governmental body responsible for the regulation of chiropractic in the UK. The U.S. CCE requires a mixing curriculum, which means a straight-educated chiropractor may not be eligible for licensing in states requiring CCE accreditation. CCEs in the U.S., Canada, Australia and Europe have joined to form CCE-International (CCE-I) as a model of accreditation standards with the goal of having credentials portable internationally. Today, there are 18 accredited Doctor of Chiropractic programs in the U.S., 2 in Canada, 6 in Australasia, and 5 in Europe. All but one of the chiropractic colleges in the U.S. are privately funded, but in several other countries they are in government-sponsored universities and colleges. Of the two chiropractic colleges in Canada, one is publicly funded (UQTR) and one is privately funded (CMCC). In 2005, CMCC was granted the privilege of offering a professional health care degree under the Post-secondary Education Choice and Excellence Act, which sets the program within the hierarchy of education in Canada as comparable to that of other primary contact health care professions such as medicine, dentistry and optometry.\nRegulatory colleges and chiropractic boards in the U.S., Canada, Mexico, and Australia are responsible for protecting the public, standards of practice, disciplinary issues, quality assurance and maintenance of competency. There are an estimated 49,000 chiropractors in the U.S. (2008), 6,500 in Canada (2010), 2,500 in Australia (2000), and 1,500 in the UK (2000).\nChiropractors often argue that this education is as good as or better than medical physicians', but most chiropractic training is confined to classrooms with much time spent learning theory, adjustment, and marketing. The fourth year of chiropractic education persistently showed the highest stress levels. Every student, irrespective of year, experienced different ranges of stress when studying. The chiropractic leaders and colleges have had internal struggles. Rather than cooperation, there has been infighting between different factions. A number of actions were posturing due to the confidential nature of the chiropractic colleges in an attempt to enroll students.\nIn 2024, Oregon Public Broadcasting reported on the high debt burden of students who pursued degrees in alternative medicine. Ten different chiropractic programs were ranked among the 47 US graduate programs with highest debt to earnings ratios. Analyses by Quackwatch and the Sunlight Foundation found high rates of default on Health Education Assistance Loan (HEAL) student loans used for chiropractic programs. Among health professionals who were listed as in default on HEAL loans in 2012, 53% were chiropractors.\nEthics.\nThe chiropractic oath is a modern variation of the classical Hippocratic Oath historically taken by physicians and other healthcare professionals swearing to practice their professions ethically. The American Chiropractic Association (ACA) has an ethical code \"based upon the acknowledgement that the social contract dictates the profession's responsibilities to the patient, the public, and the profession; and upholds the fundamental principle that the paramount purpose of the chiropractic doctor's professional services shall be to benefit the patient.\" The International Chiropractor's Association (ICA) also has a set of professional canons.\nA 2008 commentary proposed that the chiropractic profession actively regulate itself to combat abuse, fraud, and quackery, which are more prevalent in chiropractic than in other health care professions, violating the social contract between patients and physicians. According to a 2015 Gallup poll of U.S. adults, the perception of chiropractors is generally favorable; two-thirds of American adults agree that chiropractors have their patient's best interest in mind and more than half also agree that most chiropractors are trustworthy. Less than 10% of US adults disagreed with the statement that chiropractors were trustworthy.\nChiropractors, especially in America, have a reputation for unnecessarily treating patients. In many circumstances the focus seems to be put on economics instead of health care. Sustained chiropractic care is promoted as a preventive tool, but unnecessary manipulation could possibly present a risk to patients. Some chiropractors are concerned by the routine unjustified claims chiropractors have made. A 2010 analysis of chiropractic websites found the majority of chiropractors and their associations made claims of effectiveness not supported by scientific evidence, while 28% of chiropractor websites advocate lower back pain care, which has some sound evidence.\nThe US Office of the Inspector General (OIG) estimated that for calendar year 2013, 82% of payments to chiropractors under Medicare Part B, a total of $359 million, did not comply with Medicare requirements. There have been at least 15 OIG reports about chiropractic billing irregularities since 1986.\nIn 2009, a backlash to the libel suit filed by the British Chiropractic Association (BCA) against Simon Singh inspired the filing of formal complaints of false advertising against more than 500 individual chiropractors within one 24-hour period, prompting the McTimoney Chiropractic Association to write to its members advising them to remove leaflets that make claims about whiplash and colic from their practice, to be wary of new patients and telephone inquiries, and telling their members: \"If you have a website, take it down NOW\" and \"Finally, we strongly suggest you do NOT discuss this with others, especially patients.\" An editorial in \"Nature\" suggested that the BCA may have been trying to suppress debate and that this use of English libel law was a burden on the right to freedom of expression, which is protected by the European Convention on Human Rights. The libel case ended with the BCA withdrawing its suit in 2010.\nReception.\nChiropractic is established in the U.S., Canada, and Australia, and is present to a lesser extent in many other countries. It is viewed as a marginal and non-clinically\u2013proven attempt at complementary and alternative medicine, which has not integrated into mainstream medicine.\nAustralia.\nIn Australia, there are approximately 2488 chiropractors, or one chiropractor for every 7980 people. Most private health insurance funds in Australia cover chiropractic care, and the federal government funds chiropractic care when the patient is referred by a medical practitioner. In 2014, the chiropractic profession had a registered workforce of 4,684 practitioners in Australia represented by two major organizations \u2013 the Chiropractors' Association of Australia (CAA) and the Chiropractic and Osteopathic College of Australasia (COCA). Annual expenditure on chiropractic care (alone or combined with osteopathy) in Australia is estimated to be between AUD$750\u2013988 million with musculoskeletal complaints such as back and neck pain making up the bulk of consultations; and proportional expenditure is similar to that found in other countries. While Medicare (the Australian publicly funded universal health care system) coverage of chiropractic services is limited to only those directed by a medical referral to assist chronic disease management, most private health insurers in Australia do provide partial reimbursement for a wider range of chiropractic services in addition to limited third party payments for workers compensation and motor vehicle accidents.\nOf the 2,005 chiropractors who participated in a 2015 survey, 62.4% were male and the average age was 42.1 (SD\u2009=\u200912.1) years. Nearly all chiropractors (97.1%) had a bachelor's degree or higher, with the majority of chiropractor's highest professional qualification being a bachelor or double bachelor's degree (34.6%), followed by a master's degree (32.7%), Doctor of Chiropractic (28.9%) or PhD (0.9%). Only a small number of chiropractor's highest professional qualification was a diploma (2.1%) or advanced diploma (0.8%).\nGermany.\nIn Germany, chiropractic may be offered by medical doctors and alternative practitioners. Chiropractors qualified abroad must obtain a German non-medical practitioner license. Authorities have routinely required a comprehensive knowledge test for this, but in the recent past, some administrative courts have ruled that training abroad should be recognised.\nSwitzerland.\nIn Switzerland, only trained medical professionals are allowed to offer chiropractic. There are 300 chiropractors in Switzerland.\nUnited Kingdom.\nIn the United Kingdom, there are over 2,000 chiropractors, representing one chiropractor per 29,206 people. Chiropractic is available on the National Health Service in some areas, such as Cornwall, where the treatment is only available for neck or back pain.\nA 2010 study by questionnaire presented to UK chiropractors indicated only 45% of chiropractors disclosed to patients the serious risk associated with manipulation of the cervical spine and that 46% believed there was possibility patients would refuse treatment if the risks were correctly explained. However 80% acknowledged the ethical/moral responsibility to disclose risk to patients.\nUnited States and Canada.\nThe percentage of the population that utilizes chiropractic care at any given time generally falls into a range from 6% to 12% in the U.S. and Canada, with a global high of 20% in Alberta in 2006. In 2008, chiropractors were reported to be the most common CAM providers for children and adolescents, these patients representing up to 14% of all visits to chiropractors.\nThere were around 50,330 chiropractors practicing in North America in 2000. In 2008, this has increased by almost 20% to around 60,000 chiropractors. In 2002\u201303, the majority of those who sought chiropractic did so for relief from back and neck pain and other neuromusculoskeletal complaints; most do so specifically for low back pain. The majority of U.S. chiropractors participate in some form of managed care. Although the majority of U.S. chiropractors view themselves as specialists in neuromusculoskeletal conditions, many also consider chiropractic as a type of primary care. In the majority of cases, the care that chiropractors and physicians provide divides the market, however for some, their care is complementary.\nIn the U.S., chiropractors perform over 90% of all manipulative treatments. Satisfaction rates are typically higher for chiropractic care compared to medical care, with a 1998 U.S. survey reporting 83% of respondents satisfied or very satisfied with their care; quality of communication seems to be a consistent predictor of patient satisfaction with chiropractors.\nUtilization of chiropractic care is sensitive to the costs incurred by the co-payment by the patient. The use of chiropractic declined from 9.9% of U.S. adults in 1997 to 7.4% in 2002; this was the largest relative decrease among CAM professions, which overall had a stable use rate. As of 2007 7% of the U.S. population is being reached by chiropractic. They were the third largest medical profession in the US in 2002, following physicians and dentists. Employment of U.S. chiropractors was expected to increase 14% between 2006 and 2016, faster than the average for all occupations.\nIn the U.S., most states require insurers to cover chiropractic care, and most HMOs cover these services.\nHistory.\nChiropractic's origins lie in the folk medicine practice of bonesetting, in which untrained practitioners engaged in joint manipulation or resetting fractured bones. \nChiropractic was founded in 1895 by Daniel David (D. D.) Palmer in Davenport, Iowa. Palmer, a magnetic healer, hypothesized that manual manipulation of the spine could cure disease. The first chiropractic patient of D. D. Palmer was Harvey Lillard, a worker in the building where Palmer's office was located. He claimed that he had severely reduced hearing for 17 years, which started shortly following a \"pop\" in his spine. A few days following his adjustment, Lillard claimed his hearing was almost completely restored. Another of Palmer's patients, Samuel Weed, coined the term \"chiropractic\", from Greek 'hand' (itself from 'hand') and 'practical'. Chiropractic is classified as a field of pseudomedicine.\nChiropractic competed with its predecessor osteopathy, another medical system based on magnetic healing; both systems were founded by charismatic midwesterners in opposition to the conventional medicine of the day, and both postulated that manipulation improved health. Although initially keeping chiropractic a family secret, in 1898 Palmer began teaching it to a few students at his new Palmer School of Chiropractic. One student, his son Bartlett Joshua (B. J.) Palmer, became committed to promoting chiropractic, took over the Palmer School in 1906, and rapidly expanded its enrollment.\nEarly chiropractors believed that all disease was caused by interruptions in the flow of innate intelligence, a vitalistic nervous energy or life force that represented God's presence in man; chiropractic leaders often invoked religious imagery and moral traditions. D. D. Palmer said he \"received chiropractic from the other world\". D. D. and B. J. both seriously considered declaring chiropractic a religion, which might have provided legal protection under the U.S. constitution, but decided against it partly to avoid confusion with Christian Science. Early chiropractors also tapped into the Populist movement, emphasizing craft, hard work, competition, and advertisement, aligning themselves with the common man against intellectuals and trusts, among which they included the American Medical Association (AMA).\nChiropractic has seen considerable controversy and criticism. Although D. D. and B. J. were \"straight\" and disdained the use of instruments, some early chiropractors, whom B. J. scornfully called \"mixers\", advocated the use of instruments. In 1910, B. J. changed course and endorsed X-rays as necessary for diagnosis; this resulted in a significant exodus from the Palmer School of the more conservative faculty and students. The mixer camp grew until by 1924 B. J. estimated that only 3,000 of the United States' 25,000 chiropractors remained straight. That year, B. J.'s invention and promotion of the neurocalometer, a temperature-sensing device, was highly controversial among B. J.'s fellow straights. By the 1930s, chiropractic was the largest alternative healing profession in the U.S.\nChiropractors faced heavy opposition from organized medicine. D. D. Palmer was jailed in 1907 for practicing medicine without a license. Thousands of chiropractors were prosecuted for practicing medicine without a license, and D. D. and many other chiropractors were jailed. To defend against medical statutes, B. J. argued that chiropractic was separate and distinct from medicine, asserting that chiropractors \"analyzed\" rather than \"diagnosed\", and \"adjusted\" subluxations rather than \"treated\" disease. B. J. cofounded the Universal Chiropractors' Association (UCA) to provide legal services to arrested chiropractors. Although the UCA won their first test case in Wisconsin in 1907, prosecutions instigated by state medical boards became increasingly common and in many cases were successful. In response, chiropractors conducted political campaigns to secure separate licensing statutes, eventually succeeding in all fifty states, from Kansas in 1913 through Louisiana in 1974. The longstanding feud between chiropractors and medical doctors continued for decades. \nRestraint of trade decision 1989.\nThe AMA labeled chiropractic an \"unscientific cult\" in 1966, and until 1980 advised its members that it was unethical for medical doctors to associate with \"unscientific practitioners\". This culminated in a landmark 1987 decision, \"Wilk v. AMA\", in which the court found that the AMA had engaged in unreasonable restraint of trade and conspiracy, and which ended the AMA's de facto boycott of chiropractic.\nGrowing scholarly interest.\nSerious research to test chiropractic theories did not begin until the 1970s, and is continuing to be hampered by antiscientific and pseudoscientific ideas that sustained the profession in its long battle with organized medicine. By the mid-1990s there was a growing scholarly interest in chiropractic, which helped efforts to improve service quality and establish clinical guidelines that recommended manual therapies for acute low back pain.\nIn recent decades chiropractic gained legitimacy and greater acceptance by medical physicians and health plans, and enjoyed a strong political base and sustained demand for services. However, its future seemed uncertain: as the number of practitioners grew, evidence-based medicine insisted on treatments with demonstrated value, managed care restricted payment, and competition grew from massage therapists and other health professions. The profession responded by marketing natural products and devices more aggressively, and by reaching deeper into alternative medicine and primary care.\nPublic health.\nSome chiropractors oppose vaccination and water fluoridation, which are common public health practices. Within the chiropractic community there are significant disagreements about vaccination, one of the most cost-effective public health interventions available. Most chiropractic writings on vaccination focus on its negative aspects, claiming that it is hazardous, ineffective, and unnecessary. Some chiropractors have embraced vaccination, but a significant portion of the profession rejects it, as original chiropractic philosophy traces diseases to causes in the spine and states that vaccines interfere with healing. The extent to which anti-vaccination views perpetuate the current chiropractic profession is uncertain. The American Chiropractic Association and the International Chiropractors Association support individual exemptions to compulsory vaccination laws, and a 1995 survey of U.S. chiropractors found that about a third believed there was no scientific proof that immunization prevents disease. The Canadian Chiropractic Association supports vaccination; a survey in Alberta in 2002 found that 25% of chiropractors advised patients for, and 27% against, vaccinating themselves or their children.\nEarly opposition to water fluoridation included chiropractors, some of whom continue to oppose it as being incompatible with chiropractic philosophy and an infringement of personal freedom. Other chiropractors have actively promoted fluoridation, and several chiropractic organizations have endorsed scientific principles of public health. In addition to traditional chiropractic opposition to water fluoridation and vaccination, chiropractors' attempts to establish a positive reputation for their public health role are also compromised by their reputation for recommending repetitive lifelong chiropractic treatment.\nControversy.\nThroughout its history chiropractic has been the subject of internal and external controversy and criticism. According to Daniel D. Palmer, the founder of chiropractic, subluxation is the sole cause of disease and manipulation is the cure for all diseases of the human race. A 2003 profession-wide survey found \"most chiropractors (whether 'straights' or 'mixers') still hold views of innate intelligence and of the cause and cure of disease (not just back pain) consistent with those of the Palmers.\" A critical evaluation stated \"Chiropractic is rooted in mystical concepts. This led to an internal conflict within the chiropractic profession, which continues today.\" Chiropractors, including D. D. Palmer, were jailed for practicing medicine without a license. For most of its existence, chiropractic has battled with mainstream medicine, sustained by antiscientific and pseudoscientific ideas such as subluxation. Collectively, systematic reviews have not demonstrated that spinal manipulation, the main treatment method employed by chiropractors, is effective for any medical condition, with the possible exception of treatment for back pain. Chiropractic remains controversial, though to a lesser extent than in past years."}
{"id": "7739", "revid": "1130897", "url": "https://en.wikipedia.org/wiki?curid=7739", "title": "Carbide", "text": "In chemistry, a carbide usually describes a compound composed of carbon and a metal. In metallurgy, carbiding or carburizing is the process for producing carbide coatings on a metal piece.\nInterstitial / Metallic carbides.\nThe carbides of the group 4, 5 and 6 transition metals (with the exception of chromium) are often described as interstitial compounds. These carbides have metallic properties and are refractory. Some exhibit a range of stoichiometries, being a non-stoichiometric mixture of various carbides arising due to crystal defects. Some of them, including titanium carbide and tungsten carbide, are important industrially and are used to coat metals in cutting tools.\nThe long-held view is that the carbon atoms fit into octahedral interstices in a close-packed metal lattice when the metal atom radius is greater than approximately 135\u00a0pm:\nThe following table shows structures of the metals and their carbides. (N.B. the body centered cubic structure adopted by vanadium, niobium, tantalum, chromium, molybdenum and tungsten is not a close-packed lattice.) The notation \"h/2\" refers to the M2C type structure described above, which is only an approximate description of the actual structures. The simple view that the lattice of the pure metal \"absorbs\" carbon atoms can be seen to be untrue as the packing of the metal atom lattice in the carbides is different from the packing in the pure metal, although it is technically correct that the carbon atoms fit into the octahedral interstices of a close-packed metal lattice.\nFor a long time the non-stoichiometric phases were believed to be disordered with a random filling of the interstices, however short and longer range ordering has been detected.\nIron forms a number of carbides, , and . The best known is cementite, Fe3C, which is present in steels. These carbides are more reactive than the interstitial carbides; for example, the carbides of Cr, Mn, Fe, Co and Ni are all hydrolysed by dilute acids and sometimes by water, to give a mixture of hydrogen and hydrocarbons. These compounds share features with both the inert interstitials and the more reactive salt-like carbides.\nSome metals, such as lead and tin, are believed not to form carbides under any circumstances. There exists however a mixed titanium-tin carbide, which is a two-dimensional conductor.\nChemical classification of carbides.\nCarbides can be generally classified by the chemical bonds type as follows: \nExamples include calcium carbide (CaC2), silicon carbide (SiC), tungsten carbide (WC; often called, simply, \"carbide\" when referring to machine tooling), and cementite (Fe3C), each used in key industrial applications. The naming of ionic carbides is not systematic.\nSalt-like / saline / ionic carbides.\nSalt-like carbides are composed of highly electropositive elements such as the alkali metals, alkaline earth metals, lanthanides, actinides, and group 3 metals (scandium, yttrium, and lutetium). Aluminium from group 13 forms carbides, but gallium, indium, and thallium do not. These materials feature isolated carbon centers, often described as \"C4\u2212\", in the methanides or methides; two-atom units, \", in the acetylides; and three-atom units, \", in the allylides. The graphite intercalation compound KC8, prepared from vapour of potassium and graphite, and the alkali metal derivatives of C60 are not usually classified as carbides.\nMethanides.\nMethanides are a subset of carbides distinguished by their tendency to decompose in water producing methane. Three examples are aluminium carbide , magnesium carbide and beryllium carbide .\nTransition metal carbides are not saline: their reaction with water is very slow and is usually neglected. For example, depending on surface porosity, 5\u201330 atomic layers of titanium carbide are hydrolyzed, forming methane within 5 minutes at ambient conditions, following by saturation of the reaction.\nNote that methanide in this context is a trivial historical name. According to the IUPAC systematic naming conventions, a compound such as NaCH3 would be termed a \"methanide\", although this compound is often called methylsodium. See Methyl group#Methyl anion for more information about the anion.\nAcetylides/ethynides.\nSeveral carbides are assumed to be salts of the acetylide anion (also called percarbide, by analogy with peroxide), which has a triple bond between the two carbon atoms. Alkali metals, alkaline earth metals, and lanthanoid metals form acetylides, for example, sodium carbide Na2C2, calcium carbide CaC2, and LaC2. Lanthanides also form carbides (sesquicarbides, see below) with formula M2C3. Metals from group 11 also tend to form acetylides, such as copper(I) acetylide and silver acetylide. Carbides of the actinide elements, which have stoichiometry MC2 and M2C3, are also described as salt-like derivatives of .\nThe C\u2013C triple bond length ranges from 119.2\u00a0pm in CaC2 (similar to ethyne), to 130.3\u00a0pm in LaC2 and 134\u00a0pm in UC2. The bonding in LaC2 has been described in terms of LaIII with the extra electron delocalised into the antibonding orbital on , explaining the metallic conduction.\nAllylides.\nThe polyatomic ion , sometimes called allylide, is found in and . The ion is linear and is isoelectronic with . The C\u2013C distance in Mg2C3 is 133.2\u00a0pm. yields methylacetylene, CH3CCH, and propadiene, CH2CCH2, on hydrolysis, which was the first indication that it contains .\nCovalent carbides.\nThe carbides of silicon and boron are described as \"covalent carbides\", although virtually all compounds of carbon exhibit some covalent character. Silicon carbide has two similar crystalline forms, which are both related to the diamond structure. Boron carbide, B4C, on the other hand, has an unusual structure which includes icosahedral boron units linked by carbon atoms. In this respect boron carbide is similar to the boron rich borides. Both silicon carbide (also known as \"carborundum\") and boron carbide are very hard materials and refractory. Both materials are important industrially. Boron also forms other covalent carbides, such as B25C.\nMolecular carbides.\nMetal complexes containing C are known as metal carbido complexes. Most common are carbon-centered octahedral clusters, such as (where \"Ph\" represents a phenyl group) and [Fe6C(CO)6]2\u2212. Similar species are known for the metal carbonyls and the early metal halides. A few terminal carbides have been isolated, such as .\nMetallocarbohedrynes (or \"met-cars\") are stable clusters with the general formula where M is a transition metal (Ti, Zr, V, etc.).\nRelated materials.\nIn addition to the carbides, other groups of related carbon compounds exist:"}
{"id": "7740", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=7740", "title": "Charles C. Krulak", "text": "Charles Chandler Krulak (born March 4, 1942) is a retired United States Marine Corps four-star general who served as the 31st Commandant of the Marine Corps from July 1, 1995, to June 30, 1999. He is the son of Lieutenant General Victor H. \"Brute\" Krulak, who served in World War II, Korea, and Vietnam. He was the 13th President of Birmingham-Southern College after his stint as a non-executive director of English association football club Aston Villa.\nEarly life and education.\nKrulak was born in Quantico, Virginia, on March 4, 1942, the son of Amy ( Chandler) and Victor H. Krulak. He graduated from Phillips Exeter Academy in Exeter, New Hampshire, in 1960, where he was classmates with novelist John Irving. Krulak then attended the United States Naval Academy, graduating in 1964 with a bachelor's degree. Krulak also holds a master's degree in labor relations from George Washington University (1973). He is a graduate of the Amphibious Warfare School (1968); the Army Command and General Staff College (1976); and the National War College (1982).\nMarine career.\nAfter his commissioning and graduation from The Basic School at Marine Corps Base Quantico, Krulak held a variety of command and staff positions. His command positions included: commanding officer of a platoon and two rifle companies during two tours of duty in Vietnam; commanding officer of Special Training Branch and Recruit Series at Marine Corps Recruit Depot San Diego, California (1966\u20131968); commanding officer of Counter-Guerilla Warfare School, Northern Training Area on Okinawa (1970), Company officer at the United States Naval Academy (1970\u20131973); commanding officer of the Marine Barracks at Naval Air Station North Island, California (1973\u20131976), and commanding officer, 3rd Battalion, 3rd Marines (1983\u20131985).\nKrulak's staff assignments included: operations officer, 2nd Battalion, 9th Marines (1977\u20131978); chief of the Combat Arms Monitor Section at Headquarters Marine Corps, Washington, D.C. (1978\u20131979); executive assistant to the Director of Personnel Management, Headquarters Marine Corps (1979\u20131981); Plans Office, Fleet Marine Forces Pacific, Camp H.M. Smith, Hawaii (1982\u20131983); executive officer, 3rd Marine Regiment, 1st Marine Expeditionary Brigade; assistant chief of staff, maritime pre-positioning ships, 1st MEB; assistant chief of staff for operations, 1st Marine Expeditionary Brigade; and the military assistant to the assistant secretary of defense for command, control, communications and intelligence, Office of the Secretary of Defense.\nKrulak was assigned duty as the deputy director of the White House Military Office in September 1987. While serving in this capacity, he was selected for promotion to brigadier general in November 1988. He was advanced to that grade on June 5, 1989, and assigned duties as the commanding general, 10th MEB/Assistant division commander, 2nd Marine Division, Fleet Marine Force Atlantic, at Marine Corps Base Camp Lejeune, North Carolina on July 10, 1989. On June 1, 1990, he assumed duties as the commanding general, 2nd Force Service Support Group Group/Commanding general, 6th Marine Expeditionary Brigade, Fleet Marine Force Atlantic and commanded the 2d FSSG during the Gulf War. He served in this capacity until July 12, 1991, and was assigned duty as assistant deputy chief of staff for manpower and reserve affairs (personnel Management/Personnel Procurement), Headquarters Marine Corps on August 5, 1991. He was advanced to major general on March 20, 1992. Krulak was assigned as commanding general, Marine Corps Combat Development Command, Quantico, on August 24, 1992, and was promoted to lieutenant general on September 1, 1992. On July 22, 1994, he was assigned as commander of Marine Forces Pacific/commanding general, Fleet Marine Force Pacific, and in March 1995 he was nominated to serve as the Commandant of the Marine Corps.\nOn June, 29, he was promoted to general and assumed duties as the 31st commandant on June 30, 1995. He was relieved on June 30, 1999, by General James L. Jones.\nIn 1997, Krulak became a Life Member of the Sons of the Revolution in the State of California.\nSilver Star citation.\nCitation:\nThe President of the United States of America takes pleasure in presenting the Silver Star to Captain Charles Chandler Krulak, United States Marine Corps, for conspicuous gallantry and intrepidity in action while serving as Commanding Officer of Company L, Third Battalion, Third Marines, Third Marine Division, during combat operations against the enemy in the Republic of Vietnam. On 3 June 1969, during Operation Virginia Ridge, Company L was occupying ambush positions near the Demilitarized Zone west of Con Thien when the Marines came under a heavy volume of mortar fire and sustained several casualties. Although seriously wounded himself, Captain Krulak unhesitatingly left his covered position and, thinking only of the welfare of his men, fearlessly maneuvered across the fire-swept terrain to ensure that his Marines were in effective defensive locations and capable of repelling an expected ground attack. Shortly after the initial mortar attack, the Company was subjected to a second intense mortar barrage. Realizing that the determined enemy soldiers had accurate range on the Marine emplacements, and unwilling to incur additional casualties, he commenced maneuvering his men to an alternate location. Simultaneously, undaunted by the fierce barrage, Captain Krulak fearlessly moved to a dangerously exposed vantage point from which he pinpointed the principal sources of hostile fire and skillfully coordinated fixed-wing air strikes and supporting artillery fire on the enemy positions, silencing the fire. By this time, both the platoon commander and a platoon sergeant of one of his platoons had been seriously wounded. After repeatedly exposing himself to the relentless fire to supervise the evacuation of the casualties, he then personally led the platoon back to the main body of his Company across 3,000 meters of rugged mountain terrain to another patrol base and, although weak from loss of blood and the pain of his injuries, steadfastly refused medical evacuation until the arrival of another officer on the following morning. By his courage, dynamic leadership, and inspiring devotion to duty in the face of grave personal danger, Captain Krulak minimized Marine casualties and upheld the highest traditions of the Marine Corps and of the United States Naval Service.\nPersonal life.\nKrulak received the Golden Plate Award of the American Academy of Achievement in 1996. The Golden Plate was presented by Awards Council member and Chairman of the Joint Chiefs of Staff, General John M. Shalikashvili, USA.\nKrulak joined MBNA America in September 1999 as chief administrative officer, responsible for personnel, benefits, compensation, education, and other administrative services. Krulak has served as the Senior Vice Chairman and Chief Executive Officer of MBNA Europe (2001\u20132005) and was based at the Chester campus in the UK. He was the executive vice chairman and chief administration officer of MBNA Corporation (2004\u20132005). He retired from MBNA in 2005.\nFollowing the takeover of English football club Aston Villa by MBNA Chairman Randy Lerner in August 2006 and as of September 19, 2006, Krulak joined the board of Aston Villa as non-executive director where he posted on several fans forums. Krulak was generally referred to as \"The General\" by fans on these boards.\nKrulak also serves on the boards of ConocoPhillips, Freeport-McMoran (formerly known as Phelps Dodge Corporation) and Union Pacific Corporation. In addition, he serves on the advisory council of Hope For The Warriors, a national non-profit dedicated to provide a full cycle of non-medical care to combat wounded service members, their families, and families of the fallen from each military branch.\nKrulak was elected as the 13th President of Birmingham\u2013Southern College in Birmingham, Alabama on March 21, 2011, and retired June 1, 2015. He received an honorary doctorate of Humane Letters from Birmingham-Southern College. The Krulak Institute for Leadership, Experiential Learning, and Civic Engagement at Birmingham-Southern College is named for him.\nKrulak was the Vice Chair of the Sweet Briar College Board of Directors. He joined the Board in the Summer of 2015.\nAwards and decorations.\nGeneral Krulak's decorations and medals include: \nLegacy.\nKrulak famously referred to the \"Strategic Corporal\" and the Three Block War as two of the key lessons identified from the deployments in Somalia, Haiti and Bosnia. These concepts are still considered vital in understanding the increasing complexity of modern battlefields.\nKrulak explained some of his warfighting philosophy in an interview with Tom Clancy in Clancy's nonfiction book \"Marine\". Clancy referred to Krulak as \"Warrior Prince of the Corps.\" Krulak also rewrote the Marine Corps' basic combat study text, \"\", incorporating his theories on operations in the modern battlefield.\nFamily.\nKrulak is married to Zandi Meyers from Annapolis. They have two sons: CAPT David C. Krulak, the former Commanding Officer for Naval Hospital Okinawa, Japan and Dr. Todd C. Krulak, PhD., a retired freelance rave DJ who is now a professor at Samford University; and five grandchildren: Capt Brian Krulak (USMC), Katie, Mary, Matthew, and Charles.\nHe is the son of Lieutenant General Victor H. Krulak Sr., and the younger brother of Commander Victor H. Krulak Jr, Navy Chaplain Corps and Colonel William Krulak, United States Marine Corps Reserve. Krulak's godfather was USMC general Holland McTyeire \"Howlin' Mad\" Smith.\nExternal links.\n \n "}
{"id": "7742", "revid": "42783819", "url": "https://en.wikipedia.org/wiki?curid=7742", "title": "Compaq", "text": "Compaq Computer Corporation was an American information technology company founded in 1982 that developed, sold, and supported computers and related products and services. Compaq produced some of the first IBM PC compatible computers, being the second company after Columbia Data Products to legally reverse engineer the BIOS of the IBM Personal Computer. It rose to become the largest supplier of PC systems during the 1990s. The company was initially based in Harris County, Texas.\nThe company was formed by Rod Canion, Jim Harris, and Bill Murto, all of whom were former Texas Instruments senior managers. All three had left by 1991 under a shakeup, which saw Eckhard Pfeiffer appointed president and CEO, serving through the 1990s. Ben Rosen provided the venture capital financing for the fledgling company and served as chairman of the board for 17 years from 1983 until September 28, 2000, when he retired and was succeeded by Michael Capellas, who served as its last chairman and CEO until its merger.\nCompaq was overtaken by Dell as the top global PC maker in 1999. Compaq briefly regained the top spot in 2000 before being overtaken again by Dell in 2001. Struggling to keep up in the price wars against Dell, as well as with a risky acquisition of DEC in 1998, Compaq was acquired by Hewlett-Packard (HP) for US$25 billion in 2002. The Compaq brand remained in use by HP for lower-end systems until 2013 when it was discontinued.\n, the Compaq brand is currently licensed to third parties outside of the United States for use on electronics in Brazil and India.\nHistory.\nFounding.\nCompaq was founded in February 1982 by Rod Canion, Jim Harris, and Bill Murto, three senior managers from semiconductor manufacturer Texas Instruments. The three of them had left due to lack of faith and loss of confidence in TI's management, and initially considered but ultimately decided against starting a chain of Mexican restaurants. Each invested $1,000 to form the company, which was founded with the temporary name Gateway Technology. The name \"COMPAQ\" was said to be derived from \"Compatibility and Quality\" but this explanation was an afterthought. The name was chosen from many suggested by Ogilvy &amp; Mather, it being the name least rejected. The first Compaq PC was sketched out on a placemat by Ted Papajohn while dining with the founders in a pie shop, (named House of Pies in Houston). Their first venture capital came from Benjamin M. Rosen and Sevin Rosen Funds, who helped the fledgling company secure to produce their initial computer. Overall, the founders managed to raise $25 million from venture capitalists, as this gave stability to the new company as well as providing assurances to the dealers or middlemen.\nCompaq differentiated its offerings from other IBM PC clones by not focusing mainly on price, but instead concentrating on new features such as portability and better technology, at prices comparable to those of IBM's PCs. In contrast to Dell and Gateway 2000, Compaq hired veteran engineers with an average of 15 years experience, which lent credibility to Compaq's reputation of reliability among customers. Due to its partnership with Intel, Compaq was able to maintain a technological lead in the market place as it was the first one to come out with computers containing the next generation of each Intel x86 processors.\nUnder Canion's direction, Compaq sold computers only through dealers to avoid potential competition that a direct sales channel would foster, which helped foster loyalty among resellers. By giving dealers considerable leeway in pricing Compaq's offerings, either a significant markup for more profits or discount for more sales, dealers had a major incentive to advertise Compaq.\nDuring its first year of sales (second year of operation), the company sold 53,000 PCs for sales of , the first start-up to hit the mark that fast. Compaq went public in 1983 on the NYSE and raised . In 1986, it enjoyed record sales of from 150,000 PCs, and became the youngest-ever firm to make the Fortune 500. In 1985, sales reached $504 million. In 1987, Compaq hit the revenue mark, taking the least amount of time to reach that milestone. By 1991, Compaq held the fifth place spot in the PC market with in sales that year. \nTwo key marketing executives in Compaq's early years, Jim D'Arezzo and Sparky Sparks, had come from IBM's PC Group. Other key executives responsible for the company's meteoric growth in the late 1980s and early 1990s were Ross A. Cooley, another former IBM associate, who served for many years as SVP of GM North America; Michael Swavely, who was the company's chief marketing officer in the early years, and eventually ran the North America organization, later passing along that responsibility to Cooley when Swavely retired. In the United States, Brendan A. \"Mac\" McLoughlin (another long time IBM executive) led the company's field sales organization after starting up the Western U.S. Area of Operations. These executives, along with other key contributors, including Kevin Ellington, Douglas Johns, Steven Flannigan, and Gary Stimac, helped the company compete against the IBM Corporation in all personal computer sales categories, after many predicted that none could compete with the behemoth.\nThe soft-spoken Canion was popular with employees and the culture that he built helped Compaq to attract the best talent. Instead of headquartering the company in a downtown Houston skyscraper, Canion chose a West Coast-style campus surrounded by forests, where every employee had similar offices and no-one (not even the CEO) had a reserved parking spot. At semi-annual meetings, turnout was high as any employee could ask questions to senior managers.\nIn 1987, company co-founder Bill Murto resigned to study at a religious education program at the University of St. Thomas. Murto had helped to organize the company's marketing and authorized-dealer distribution strategy, and held the post of senior vice president of sales since June 1985. Murto was succeeded by Ross A. Cooley, director of corporate sales. Cooley would report to Michael S. Swavely, vice president for marketing, who was given increased responsibility and the title of vice president for sales and marketing.\nIntroduction of Compaq Portable.\nIn November 1982, Compaq announced their first product, the Compaq Portable, a portable IBM PC compatible personal computer. It was released in March 1983 at . The Compaq Portable was one of the progenitors of today's laptop; some called it a \"suitcase computer\" for its size and the look of its case. It was the second IBM PC compatible, being capable of running all software that would run on an IBM PC. It was a commercial success, selling 53,000 units in its first year and generating in sales revenue. The Compaq Portable was the first in the range of the Compaq Portable series. Compaq was able to market a legal IBM clone because IBM mostly used \"off the shelf\" parts for their PC. Furthermore, Microsoft had kept the right to license MS-DOS, the most popular and de facto standard operating system for the IBM PC, to other computer manufacturers. The only part which had to be duplicated was the BIOS, which Compaq did legally by using clean room design at a cost of .\nUnlike other companies, Compaq did not bundle application software with its computers. Vice President of Sales and Service H. L. Sparks said in early 1984:\nCompaq instead emphasized PC compatibility, of which Future Computing in May 1983 ranked Compaq as among the \"Best\" examples. \"Many industry observers think [Compaq] is poised for meteoric growth\", \"The New York Times\" reported in March of that year. By October, when the company announced the Compaq Plus with a hard drive, \"PC Magazine\" wrote of \"the reputation for compatibility it built with its highly regarded floppy disk portable\". Compaq computers remained the most compatible PC clones into 1984, and maintained its reputation for compatibility for years, even as clone BIOSes became available from Phoenix Technologies and other companies that also reverse engineered IBM's design, then sold their version to clone manufacturers.\nCompaq Deskpro.\nOn June 28, 1984, Compaq released the Deskpro, a 16-bit desktop computer using an Intel 8086 microprocessor running at . It was considerably faster than an IBM PC and was, like the original Compaq Portable, also capable of running IBM software. It was Compaq's first non-portable computer and began the Deskpro line of computers.\nCompaq DeskPro 386.\nIn 1986, Compaq introduced the Deskpro 386, the first PC based on Intel's new 80386 microprocessor. Bill Gates of Microsoft later said\nThe Compaq 386 computer marked the first CPU change to the PC platform that was not initiated by IBM. Compaq had concluded, according to \"PC\", that it could do so because \"IBM's DOS standard is now bigger than IBM\"; IBM could not make changes to the PC architecture it had created to hurt Compaq, without also obsoleting millions of real IBM PCs. An IBM-made 386 machine reached the market almost a year later, but by that time Compaq was the leading 386 supplier with 28% market share, compared to IBM's 16%.\nFor the first three months after announcement, the Deskpro 386 shipped with Windows/386. This was a version of Windows 2.1 adapted for the 80386 processor. Support for the virtual 8086 mode was added by Compaq engineers. (Windows, running on top of the MS-DOS operating system, would not become a popular \"operating environment\" until at least the release of Windows 3.0 in 1990.)\nCompaq SystemPro.\nCompaq's technical leadership and the rivalry with IBM was emphasized when the SystemPro server was launched in late 1989 \u2013 this was a true server product with standard support for a second CPU and RAID, but also the first product to feature the EISA bus, designed in reaction to IBM's MCA (Micro Channel Architecture) which was incompatible with the original AT bus.\nAlthough Compaq had become successful by being 100 percent IBM-compatible, it decided to continue with the original AT bus\u2014which it renamed ISA\u2014instead of licensing IBM's MCA. Prior to developing EISA Compaq had invested significant resources into reverse engineering MCA, but its executives correctly calculated that the $80 billion already spent by corporations on IBM-compatible technology would make it difficult for even IBM to force manufacturers to adopt the new MCA design. Instead of cloning MCA, Compaq led an alliance with Hewlett Packard and seven other major manufacturers, known collectively as the \"Gang of Nine\", to develop EISA.\nCompaq SLT and LTE.\nDevelopment of a truly mobile successor to the Portable line began in 1986, the company releasing two stopgap products in the meantime, the SLT (Compaq's first laptop) and the Compaq Portable III (a lighter-weight, lunchbox-sized entry in the Portable line). In 1989, they introduced the LTE, their first notebook-sized laptop which competed with NEC's UltraLite and Zenith Data Systems's MinisPort. However, whereas the UltraLite and MinisPort failed to gain much uptake due to their novel but nonstandard data storage technologies, the LTE succeeded on account of its use of the conventional floppy drive and spinning hard drive, allowing users to transfer data to and from their desktop computers without any hassle. As well, Compaq began offering docking stations with the release of the LTE/386s in 1990, providing performance comparable to then-current desktop machines. Thus, the LTE was the first commercially successful notebook computer, helping launch the burgeoning industry. It was a direct influence on both Apple and IBM for the development of their own notebook computers, the PowerBook and ThinkPad, respectively.\n1990s.\nBy 1989, \"The New York Times\" wrote that being the first to release a 80386-based personal computer made Compaq the leader of the industry and \"hurt no company more - in prestige as well as dollars - than\" IBM. The company was so influential that observers and its executives spoke of \"Compaq compatible\". \"InfoWorld\" reported that \"In the [ISA market] Compaq is already IBM's equal in being seen as a safe bet\", quoting a sell-side analyst describing it as \"now \"the\" safe choice in personal computers\". Even rival Tandy Corporation acknowledged Compaq's leadership, stating that within the Gang of Nine \"when you have 10 people sit down before a table to write a letter to the president, someone has to write the letter. Compaq is sitting down at the typewriter\".\nOuster of co-founders.\nMichael S. Swavely, president of Compaq's North American division since May 1989, took a six-month sabbatical in January 1991 (which would eventually become retirement effective on July 12, 1991). Eckhard Pfeiffer, then president of Compaq International, was named to succeed him. Pfeiffer also received the title of chief operating officer, with responsibility for the company's operations on a worldwide basis, so that Canion could devote more time to strategy. Swavely's abrupt departure in January led to rumors of turmoil in Compaq's executive suite, including friction between Canion and Swavely, likely as Swavely's rival Pfeiffer had received the number two leadership position. Swavely's U.S. marketing organization was losing ground with only 4% growth for Compaq versus 7% in the market, likely due to short supplies of the LTE 386s from component shortages, rivals that undercut Compaq's prices by as much as 35%, and large customers who did not like Compaq's dealer-only policy. Pfeiffer became president and CEO of Compaq later that year, as a result of a boardroom coup led by board chairman Ben Rosen that forced co-founder Rod Canion to resign as president and CEO.\nPfeiffer had joined Compaq from Texas Instruments, and established operations from scratch in both Europe and Asia. Pfeiffer was given US$20,000 to start up Compaq Europe He started up Compaq's first overseas office in Munich in 1984. By 1990, Compaq Europe was a $2 billion business and number two behind IBM in that region, and foreign sales contributed 54 percent of Compaq's revenues. Pfeiffer, while transplanting Compaq's U.S. strategy of dealer-only distribution to Europe, was more selective in signing up dealers than Compaq had been in the U. S. such that European dealers were more qualified to handle its increasingly complex products.\nDuring the 1980s, under Canion's direction Compaq had focused on engineering, research, and quality control, producing high-end, high-performance machines with high profit margins that allowed Compaq to continue investing in engineering and next-generation technology. This strategy was successful as Compaq was considered a trusted brand, while many other IBM clones were untrusted due to being plagued by poor reliability. However, by the end of the eighties many manufacturers had improved their quality and were able to produce inexpensive PCs with off-the-shelf components, incurring none of the R&amp;D costs which allowed them to undercut Compaq's expensive computers. Faced with lower-cost rivals such as Dell, AST Research, and Gateway 2000, Compaq suffered a $71 million loss for that quarter, their first loss as a company, while the stock had dropped by over two-thirds. An analyst stated that \"Compaq has made a lot of tactical errors in the last year and a half. They were trend-setters, now they are lagging\". Canion initially believed that the 1990s recession was responsible for Compaq's declining sales but insisted that they would recover once the economy improved, however Pfeiffer's observation of the European market noted that it was competition as rivals could match Compaq at a fraction of the cost. Under pressure from Compaq's board to control costs as staff was ballooning at their Houston headquarters despite falling U.S. sales, while the number of non-U.S. employees had stayed constant, Compaq made its first-ever layoffs (1400 employees which was 12% of its workforce) while Pfeiffer was promoted to EVP and COO.\nRosen and Canion had disagreed about how to counter the cheaper Asian PC imports, as Canion wanted Compaq to build lower cost PCs with components developed in-house in order to preserve Compaq's reputation for engineering and quality, while Rosen believed that Compaq needed to buy standard components from suppliers and reach the market faster. While Canion developed an 18-month plan to create a line of low-priced computers, Rosen sent his own Compaq engineering team to Comdex without Canion's knowledge and discovered that a low-priced PC could be made in half the time and at lower cost than Canion's initiative.\nRosen initiated a 14-hour board meeting, and the directors also interviewed Pfeiffer for several hours without informing Canion. At the conclusion, the board was unanimous in picking Pfeiffer over Canion. As Canion was popular with company workers, 150 employees staged an impromptu protest with signs stating \"We love you, Rod.\" and taking out a newspaper ad saying \"Rod, you are the wind beneath our wings. We love you.\" Canion declined an offer to remain on Compaq's board and was bitter about his ouster as he did not speak to Rosen for years, although their relationship became cordial again. In 1999, Canion admitted that his ouster was justified, saying \"I was burned out. I needed to leave. He [Rosen] felt I didn't have a strong sense of urgency\". Two weeks after Canion's ouster, five other senior executives resigned, including remaining company founder James Harris as SVP of Engineering. These departures were motivated by an enhanced severance or early retirement, as well as an imminent demotion as their functions were to be shifted to vice presidents.\nMarket ascension.\nUnder Pfeiffer's tenure as chief executive, Compaq entered the retail computer market with the Compaq Presario as one of the first manufacturers in the mid-1990s to market a sub-$1000 PC. In order to maintain the prices it wanted, Compaq became the first first-tier computer manufacturer to utilize CPUs from AMD and Cyrix. The two price wars resulting from Compaq's actions ultimately drove numerous competitors from the market, such as Packard Bell and AST Research. From third place in 1993, Compaq had overtaken Apple Computer and even surpassed IBM as the top PC manufacturer in 1994, as both IBM and Apple were struggling considerably during that time. Compaq's inventory and gross margins were better than that of its rivals which enabled it to wage the price wars.\nCompaq had decided to make a foray into printers in 1989, and the first models were released to positive reviews in 1992. However, Pfeiffer saw that the prospects of taking on market leader Hewlett-Packard (who had 60% market share) was tough, as that would force Compaq to devote more funds and people to that project than originally budgeted. Compaq ended up selling the printer business to Xerox and took a charge of $50 million.\nIn 1994, Compaq formed a joint venture with ADI Corporation, a Taiwanese manufacturer who produced the bulk of Compaq's monitors, to raise multiple factories in Mexico, Brazil, and Europe to assemble and store ADI's monitors. Compaq sold many of the monitors that they offered to customers of their Deskpro and Presario lines as standalone units to third-party resellers, including their popular 171FS monitor.\nOn June 26, 1995, Compaq reached an agreement with Cisco Systems, Inc., in order to get into networking, including digital modems, routers, and switches favored by small businesses and corporate departments, which was now a $4 billion business and the fastest-growing part of the computer hardware market. Compaq also built up a network engineering and marketing staff.\nManagement shuffle.\nIn 1996, despite record sales and profits at Compaq, Pfeiffer initiated a major management shakeup in the senior ranks. John T. Rose, who previously ran Compaq's desktop PC division, took over the corporate server business from SVP Gary Stimac who had resigned. Rose had joined Compaq in 1993 from Digital Equipment Corporation where he oversaw the personal computer division and worldwide engineering, while Stimac had been with Compaq since 1982 and was one of the longest-serving executives. Senior Vice-president for North America Ross Cooley announced his resignation effective at the end of 1996. CFO Daryl J. White, who joined the company in January, 1983 resigned in May, 1996 after 8 years as CFO. Michael Winkler, who joined Compaq in 1995 to run its portable computer division, was promoted to general manager of the new PC products group. Earl Mason, hired from Inland Steel effective in May 1996, immediately made an impact as the new CFO. Under Mason's guidance, Compaq utilized its assets more efficiently instead of focusing just on income and profits, which increased Compaq's cash from to nearly in one year. Additionally, Compaq's return on invested capital (after-tax operating profit divided by operating assets) doubled to 50 percent from 25 percent in that period.\nCompaq had been producing the PC chassis at its plant in Shenzhen, China to cut costs. In 1996, instead of expanding its own plant, Compaq asked a Taiwanese supplier to set up a new factory nearby to produce the mechanicals, with the Taiwanese supplier owning the inventory until it reached Compaq in Houston. Pfeiffer also introduced a new distribution strategy, to build PCs made-to-order which would eliminate the stockpile of computers in warehouses and cut the components inventory down to two weeks, with the supply chain from supplier to dealer linked by complex software.\nVice-president for Corporate Development Kenneth E. Kurtzman assembled five teams to examine Compaq's businesses and assess each unit's strategy and that of key rivals. Kurtzman's teams recommended to Pfeiffer that each business unit had to be first or second in its market within three years\u2014or else Compaq should exit that line. Also, the company should no longer use profits from high-margin businesses to carry marginally profitable ones, as instead each unit must show a return on investment. Pfeiffer's vision was to make Compaq a full-fledged computer company, moving beyond its main business of manufacturing retail PCs and into the more lucrative business services and solutions that IBM did well at, such as computer servers which would also require more \"customer handholding\" from either the dealers or Compaq staff themselves. Unlike IBM and HP, Compaq would not build up field technicians and programmers in-house as those could be costly assets, instead Compaq would leverage its partnerships (including those with Andersen Consulting and software maker SAP) to install and maintain corporate systems. This allowed Compaq to compete in the \"big-iron market\" without incurring the costs of running its own services or software businesses.\nMost of Compaq's server sales were for systems that would be running Microsoft's Windows NT operating system, and indeed Compaq was the largest hardware supplier for Windows NT. However, some 20\u00a0percent of Compaq servers went for systems that would be running the Unix operating system. This was exemplified by a strategic alliance formed in 1997 between Compaq and the Santa Cruz Operation (SCO), which was known for its server Unix operating system products on Intel-architecture-based hardware. Compaq was also the largest hardware supplier for SCO's Unix products, and some 10\u00a0percent of Compaq's ProLiant servers ran SCO's UnixWare.\nIn January 1998, Compaq was at its height. CEO Pfeiffer boldly predicted that the Microsoft/Intel \"Wintel\" duopoly would be replaced by \"Wintelpaq\".\nAcquisitions.\nPfeiffer also made several major and some minor acquisitions. In 1997, Compaq bought Tandem Computers, known for their NonStop server line. This acquisition instantly gave Compaq a presence in the higher end business computing market. The alliance between Compaq and SCO took advantage of this to put out the UnixWare NonStop Clusters product in 1998.\nMinor acquisitions centered around building a networking arm and included NetWorth (1998) based in Irving, Texas and Thomas-Conrad (1998) based in Austin, Texas. In 1997, Microcom was also acquired, based in Norwood, MA, which brought a line of modems, Remote Access Servers (RAS) and the popular Carbon Copy software.\nIn 1998, Compaq acquired Digital Equipment Corporation for a then-industry record of $9.6 billion. The merger made Compaq, at the time, the world's second largest computer maker in the world in terms of revenue behind IBM. Digital Equipment, which had nearly twice as many employees as Compaq while generating half the revenue, had been a leading computer company during the 1970s and early 1980s. However, Digital had struggled during the 1990s, with high operating costs. For nine years, the company had lost money or barely broke even, and had recently refocused itself as a \"network solutions company\". In 1995, Compaq had considered a bid for Digital but only became seriously interested in 1997 after Digital's major divestments and refocusing on the Internet. At the time of the acquisition, services accounted for 45 percent of Digital's revenues (about $6 billion) and their gross margins on services averaged 34 percent, considerably higher than Compaq's 25% margins on PC sales and also satisfying customers who had demanded more services from Compaq for years. Compaq had originally wanted to purchase only Digital's services business but that was turned down. When the announcement was made, it was initially viewed as a master stroke as it immediately gave Compaq a 22,000 person global service operation to help corporations handle major technological purchases (by 2001 services made up over 20% of Compaq's revenues, largely due to the Digital employees inherited from the merger), in order to compete with IBM. However it was also risky merger, as the combined company would have to lay off 2,000 employees from Compaq and 15,000 from Digital which would potentially hurt morale. Furthermore, Compaq fell behind schedule in integrating Digital's operations, which also distracted the company from its strength in low-end PCs where it used to lead the market in rolling out next-generation systems which let rival Dell grab market share. Reportedly Compaq had three consulting firms working to integrate Digital alone.\nHowever, Pfeiffer had little vision for what the combined companies should do, or indeed how the three dramatically different cultures could work as a single entity, and Compaq struggled from strategy indecisiveness and lost focus, as a result being caught in between the low end and high end of the market. Mark Anderson, president of Strategic News Service, a research firm based in Friday Harbor, Wash. was quoted as saying, \"The kind of goals he had sounded good to shareholders \u2013 like being a $50 billion company by the year 2000, or to beat I.B.M. \u2013 but they didn't have anything to do with customers. The new C.E.O. should look at everything Eckhard acquired and ask: did the customer benefit from that. If the answer isn't yes, they should get rid of it.\" On one hand, Compaq had previously dominated the PC market with its price war but was now struggling against Dell, which sold directly to buyers, avoiding the dealer channel and its markup, and built each machine to order to keep inventories and costs at a minimum. At the same time, Compaq, through its acquisitions of the Digital Equipment Corporation in 1998 and Tandem Computers in 1997, had tried to become a major systems company, like IBM and Hewlett-Packard. While IBM and HP were able generate repeat business from corporate customers to drive sales of their different divisions, Compaq had not yet managed to make its newly acquired sales and services organizations work as seamlessly.\nOuster of Pfeiffer.\nIn early 1998, Compaq had the problem of bloated PC inventories. By summer 1998, Compaq was suffering from product-quality problems. Robert W. Stearns, SVP of Business Development, said \"In [Pfeiffer's] quest for bigness, he lost an understanding of the customer and built what I call empty market share\u2014large but not profitable\", while Jim Moore, a technology strategy consultant with GeoPartners Research in Cambridge, Mass., says Pfeiffer \"raced to scale without having economies of scale.\" The \"colossus\" that Pfeiffer built up was not nimble enough to adapt to the fast-changing computer industry. That year Compaq forecast demand poorly and shipped too many PCs, causing resellers to dump them at fire sale prices, and since Compaq protected resellers from heavy losses it cost them two quarters of operating profits.\nPfeiffer also refused to develop a potential successor, rebuffing Rosen's suggestion to recruit a few executives to create the separate position of Compaq president. The board complained that Pfeiffer was too removed from management and the rank-and-file, as he surrounded himself with a \"clique\" of Chief Financial Officer Earl Mason, Senior Vice-President John T. Rose, and Senior Vice-President of Human Resources Hans Gutsch. Current and former Compaq employees complained that Gutsch was part of a group of senior executives, dubbed the \"A team\", who controlled access to Pfeiffer. Gutsch was said to be a \"master of corporate politics, pitting senior vice presidents against each other and inserting himself into parts of the company that normally would not be under his purview\". Gutsch, who oversaw security, had an extensive security system and guard station installed on the eight floor of CCA-11, where the company's senior vice presidents worked. There were accusations that Gutsch and others sought to divide top management, although this was regarded by others as sour grapes on the part of executives who were shut out of planning that involved the acquisitions of Tandem Computers and Digital Equipment Corp. Pfeiffer reduced the size of the group working on the deal due to news leaks, saying \"We cut the team down to the minimum number of people\u2014those who would have to be directly involved, and not one person more\". Robert W. Stearns, Compaq's senior vice president for business development, with responsibility for mergers and acquisitions, had opposed the acquisition of Digital as the cultural differences between both companies were too great, and complained that he was placed on the \"B team\" as a result.\nCompaq entered 1999 with strong expectations. Fourth-quarter 1998 earnings reported in January 1999 beat expectations by six cents a share with record 48 percent growth. The company launched \"Compaq.com\" as the key for its new direct sales strategy, and planned an IPO for AltaVista toward the end of 1999 in order to capitalize on the dotcom bubble. However, by February 1999, analysts were sceptical of Compaq's plan to sell both direct and to resellers. Compaq was hit with two class-action lawsuits, as a result of CFO Earl Mason, SVP John Rose, and other executives selling of stock before a conference call with analysts, where they noted that demand for PCs was slowing down.\nOn April 17, 1999, just nine days after Compaq reported first-quarter profit being at half of what analysts had expected, the latest in a string of earnings disappointments, Pfeiffer was forced to resign as CEO in a coup led by board chairman Ben Rosen. Reportedly, at the special board meeting held on April 15, 1999, the directors were unanimous in dismissing Pfeiffer. The company's stock had fallen 50 percent since its all-time high in January 1999. Compaq shares, which traded as high as early in 1999, dropped 23 percent on April 12, 1999, the first day of trading after the first-quarter announcement and closed the following Friday at . During three out of the last six quarters of Pfeiffer's tenure, the company's revenues or earnings had missed expectations. While rival Dell had 55% growth in U.S. PC sales in the first quarter of 1999, Compaq could only manage 10%. Rosen suggested that the accelerating change brought about by the Internet had overtaken Compaq's management team, saying \"As a company engaged in transforming its industry for the Internet era, we must have the organizational flexibility necessary to move at Internet speed.\" In a statement, Pfeiffer said \"Compaq has come a long way since I joined the company in 1983\" and \"under Ben's guidance, I know this company will realize its potential.\" Rosen's priority was to have Compaq catchup as an E-commerce competitor, and he also moved to streamline operations and reduce the indecision that plagued the company.\nRoger Kay, an analyst at International Data Corporation, observed that Compaq's behavior at times seemed like a personal vendetta, noting that \"Eckhard has been so obsessed with staying ahead of Dell that they focused too hard on market share and stopped paying attention to profitability and liquidity. They got whacked in a price war that they started.\" Subsequent earnings releases from Compaq's rivals, Dell, Gateway, IBM, and Hewlett-Packard suggested that the problems were not affecting the whole PC industry as Pfeiffer had suggested. Dell and Gateway sold direct, which helped them to avoid Compaq's inventory problems and compete on price without dealer markups, plus Gateway sold web access and a broad range of software tailored to small businesses. Hewlett-Packard's PC business had similar challenges like Compaq but this was offset by HP's extremely lucrative printer business, while IBM sold PCs at a loss but used them to lock in multi-year services contracts with customers.\nAfter Pfeiffer's resignation, the board established an office of the CEO with a triumvirate of directors; Rosen as interim CEO and vice chairmen Frank P. Doyle and Robert Ted Enloe III. They began \"cleaning house\", as shortly afterward many of Pfeiffer's top executives resigned or were pushed out, including John J. Rando, Earl L. Mason, and John T. Rose. Rando, senior vice president and general manager of Compaq Services, was a key player during the merger discussions and the most senior executive from Digital to remain with Compaq after the acquisition closed and had been touted by some as the heir-apparent to Pfeiffer. Rando's division had performed strongly as it had sales of for the first quarter compared to in 1998, which met expectations and was anticipated to post accelerated and profitable growth going forward. At the time of Rando's departure, Compaq Services ranked third behind those of IBM and EDS, while slightly ahead of Hewlett-Packard's and Andersen Consulting, however customers switched from Digital technology-based workstations to those of HP, IBM, and Sun Microsystems. Mason, senior vice president and chief financial officer, had previously been offered the job of chief executive of Alliant Foodservice, Inc., a foodservice distributor based in Chicago, and he informed Compaq's board that he accepted the offer. Rose, senior vice president and general manager of Compaq's Enterprise Computing group, resigned effective as of June 3 and was succeeded by Tandem veteran Enrico Pesatori. Rose was reportedly upset that he was not considered for the CEO vacancy, which became apparent once Michael Capellas was named COO. While Enterprise Computing, responsible for engineering and marketing of network servers, workstations and data-storage products, reportedly accounted for one third of Compaq's revenues and likely the largest part of its profits, it was responsible for the earnings shortfall in Q1 of 1999. In addition, Rose was part of the \"old guard\" close to former CEO Pfeiffer, and he and other Compaq executives had been criticized at the company's annual meeting for selling stock before reporting the sales slowdown. Rose was succeeded by SVP Enrico Pesatori, who had previously worked as a senior executive at Olivetti, Zenith Data Systems, Digital Equipment Corporation, and Tandem Computers. Capellas was appointed COO after pressure mounted on Rosen to find a permanent CEO, however it was reported that potential candidates did not want to work under Rosen as chairman. Around the same time Pesatori was placed in charge of the newly created Enterprise Solutions and Services Group, making him Compaq's second most powerful executive in operational responsibility after Capellas.\nPfeiffer's permanent replacement was Michael Capellas, who had been serving as Compaq's SVP and CIO for under a year. A couple months after Pfeiffer's ouster, Capellas was elevated to interim chief operating officer on June 2, 2000, and was soon appointed president and CEO. Capellas also assumed the title of chairman on September 28, 2000, when Rosen stepped down from the board of directors. At his retirement, Rosen proclaimed \"These are great achievements\u2014to create 65,000 jobs, in sales and in market value, all starting with a sketch and a dream\".\nLate 1990s\u20132000s.\nIn 1998, Compaq signed new sales and equipment alliance with NaviSite. Under the pact, Compaq agreed to promote and sell NaviSite Web hosting services. In return, NaviSite took Compaq as a preferred provider for its storage and Intel-based servers.\nDuring November 1999, Compaq began to work with Microsoft to create the first in a line of small-scale, web-based computer systems called MSN Companions.\nStruggles.\nCapellas was able to restore some of the luster lost in the latter part of the Pfeiffer era and he repaired the relationship with Microsoft which had deteriorated under his predecessor's tenure.\nHowever Compaq still struggled against lower-cost competitors with direct sales channels such as Dell who took over the top spot of PC manufacturer from Compaq in 2001. Compaq relied significantly on reseller channels, so their criticism caused Compaq to retreat from its proposed direct sales plan, although Capellas maintained that he would use the middlemen to provide value-added services. Despite falling to No. 2 among PC manufacturers, Capellas proclaimed \"We are No. 2 in the traditional PC market, but we're focused on industry leadership in the next generation of Internet access devices and wireless mobility. That's where the growth and the profitability will be.\" The company's longer-term strategy involved extending its services to servers and storage products, as well as handheld computers such as the iPAQ PocketPC which accounted for 11 percent of total unit volume.\nCompaq struggled as a result of the collapse of the dot-com bubble, which hurt sales of their high-end systems in 2001 and 2002, and they managed only a small profit in a few quarters during these years. They also accumulated $1.7 billion in short-term debt around this time. The stock price of Compaq, which was around $25 when Capellas became CEO, was trading at half that by 2002.\nAcquisition by Hewlett-Packard.\nIn 2002, Compaq signed a merger agreement with Hewlett-Packard for , including for goodwill, where each Compaq share would be exchanged for 0.6325 of a Hewlett-Packard share. There would be a termination fee of that either company would have to pay the other to break the merger. Compaq shareholders would own 36% of the combined company while HP's would have 64%. Hewlett-Packard had reported yearly revenues of , while Compaq's was , and the combined company would have been close to IBM's revenues. It was projected to have in annual cost savings by mid-2004. The expected layoffs at Compaq and HP, 8500 and 9000 jobs respectively, would leave the combined company with a workforce of 145,000. The companies would dole out a combined in bonuses to prevent key employees from leaving if shareholders approve the proposed merger, with for HP employees and for Compaq employees.\nBoth companies had to seek approval from their shareholders through separate special meetings. While Compaq shareholders unanimously approved the deal, there was a public proxy battle within HP as the deal was strongly opposed by numerous large HP shareholders, including the sons of the company founders, Walter Hewlett and David W. Packard, as well as the California Public Employees\u2019 Retirement System (CalPERS) and the Ontario Teachers' Pension Plan. Walter Hewlett only reluctantly approved the merger, in his duty as a member of the board of directors, since the merger agreement \"called for unanimous board approval in order to ensure the best possible shareholder reception\". While supporters of the merger argued that there would be economies of scale and that the sales of PCs would drive sales of printers and cameras, Walter Hewlett was convinced that PCs were a low-margin but risky business that would not contribute and would likely dilute the old HP's traditionally profitable Imaging and Printing division. David W. Packard in his opposition to the deal \"[cited] massive layoffs as an example of this departure from HP\u2019s core values...[arguing] that although the founders never guaranteed job security, 'Bill and Dave never developed a premeditated business strategy that treated HP employees as expendable.'\" Packard further stated that \"[Carly] Fiorina\u2019s high-handed management and her efforts to reinvent the company ran counter to the company\u2019s core values as established by the founders\". The founders' families who controlled a significant amount of HP shares were further irked because Fiorina had made no attempt to reach out to them and consult about the merger, instead they received the same standard roadshow presentation as other investors.\nAnalysts on Wall Street were generally critical of the merger, as both companies had been struggling before the announcement, and the stock prices of both companies dropped in the months after the merger agreement was made public. Particularly rival Dell made gains from defecting HP and Compaq customers who were wary of the merger. Carly Fiorina, initially seen as HP's savior when she was hired as CEO back in 1999, had seen the company's stock price drop to less than half since she assumed the position, and her job was said to be on shaky ground before the merger announcement. HP's offer was regarded by analysts to be overvaluing Compaq, due to Compaq's shaky financial performance in the past recent years (there were rumors that it could run out of money in 12 months and be forced to cease business operations had it stayed independent), as well as Compaq's own more conservative valuation of its assets. Detractors of the deal noted that buying Compaq was a \"distraction\" that would not directly help HP take on IBM's breadth or Dell Computer's direct sales model. Plus there were significant cultural differences between HP and Compaq; which made decisions by consensus and rapid autocratic styles, respectively. One of Compaq's few bright spots was its services business, which was outperforming HP's own services division.\nThe merger was approved by HP shareholders only after the narrowest of margins, and allegations of vote buying (primarily involving an alleged last-second back-room deal with Deutsche Bank) haunted the new company. It was subsequently disclosed that HP had retained Deutsche Bank's investment banking division in January 2002 to assist in the merger. HP had agreed to pay Deutsche Bank guaranteed, and another contingent upon approval of the merger. On August 19, 2003, the U.S. SEC charged Deutsche Bank with failing to disclose a material conflict of interest in its voting of client proxies for the merger and imposed a civil penalty of . Deutsche Bank consented without admitting or denying the findings.\nHewlett-Packard announced the completion of merger on May 3, 2002, and the merged HP-Compaq company was officially launched on May 7. Compaq's pre-merger ticker symbol was CPQ. This was combined with Hewlett-Packard's ticker symbol (HWP) to create the current ticker symbol (HPQ), which was announced on May 6.\nPost-merger.\nCapellas, Compaq's last chairman and CEO, became president of the post-merger Hewlett-Packard, under chairman and CEO Carly Fiorina, to ease the integration of the two companies. However, Capellas was reported not to be happy with his role, being said not to be utilized and being unlikely to become CEO as the board supported Fiorina. Capellas stepped down as HP president on November 12, 2002, after just six months on the job, to become CEO of MCI Worldcom where he would lead its acquisition by Verizon. Capellas' former role of president was not filled as the executives who reported to him then reported directly to the CEO.\nFiorina helmed the post-merger HP for nearly three years after Capellas left. HP laid off thousands of former Compaq, DEC, HP, and Tandem employees, its stock price generally declined and profits did not perk up. Several senior executives from the Compaq side including Jeff Clarke and Peter Blackmore would resign or be ousted from the post-merger HP. Though the combination of both companies' PC manufacturing capacity initially made the post-merger HP number one, it soon lost the lead and further market share to Dell which squeezed HP on low end PCs. HP was also unable to compete effectively with IBM in the high-end server market. In addition, the merging of the stagnant Compaq computer assembly business with HP's lucrative printing and imaging division was criticized for obstructing the profitability of the printing/imaging segment. Overall, it has been suggested that the purchase of Compaq was not a good move for HP, due to the narrow profit margins in the commoditized PC business, especially in light of IBM's 2004 announcement to sell its PC division to Lenovo. \"The Inquirer\" noted that the continued low return on investment and small margins of HP's personal computer manufacturing business, now named the Personal Systems Group, \"continues to be what it was in the individual companies, not much more than a job creation scheme for its employees\". One of the few positives was Compaq's sales approach and enterprise focus that influenced the newly combined company's strategy and philosophy.\nIn February 2005, the board of directors ousted Fiorina, with CFO Robert Wayman being named interim CEO. Former Compaq CEO Capellas was mentioned by some as a potential successor, but several months afterwards, Mark Hurd was hired as president and CEO of HP. Hurd separated the PC division from the imaging and printing division and renamed it the Personal Systems Group, placing it under the leadership of EVP Todd R. Bradley. Hewlett Packard's PC business has since been reinvigorated by Hurd's restructuring and now generates more revenue than the traditionally more profitable printers. By late 2006, HP had retaken the #1 sales position of PCs from Dell, which struggled with missed estimates and poor quality, and held that rank until supplanted in the mid-2010s by Lenovo.\nMost Compaq products have been re-branded with the HP nameplate, such as the company's market leading ProLiant server line (now owned by Hewlett Packard Enterprise, which spun off from HP in 2015), while the Compaq brand was repurposed for some of HP's consumer-oriented and budget products, notably Compaq Presario PCs. HP's business computers line was discontinued in favour of the Compaq Evo line, which was initially rebranded HP Compaq but now use brands such as EliteBook and ProBook, among others. HP's Jornada PDAs were replaced by Compaq iPAQ PDAs, which were renamed HP iPAQ. Following the merger, all Compaq computers were shipped with HP software.\nIn May 2007, HP announced in a press release a new logo for their Compaq Division to be placed on the new model Compaq Presarios.\nIn 2008, HP reshuffled its business line notebooks. The \"Compaq\" name from its \"HP Compaq\" series was originally used for all of HP's business and budget notebooks. However, the HP EliteBook line became the top of the business notebook lineup while the HP Compaq B series became its middle business line. As of early 2009, the \"HP ProBook\" filled out HP's low end business lineup.\nIn 2009, HP sold part of Compaq's former headquarters to the Lone Star College System.\nOn August 18, 2011, then-CEO of HP L\u00e9o Apotheker announced plans for a partial or full spinoff of the Personal Systems Group. The PC unit had the lowest profit margin although it accounted for nearly a third of HP's overall revenues in 2010. HP was still selling more PCs than any other vendor, shipping 14.9 million PCs in the second quarter of 2011 (17.5% of the market according to Gartner), while Dell and Lenovo were tied for second place, each with more than a 12% share of the market and shipments of over 10 million units. However, the announcement of the PC spinoff (concurrent with the discontinuation of WebOS, and the purchase of Autonomy Corp. for $10 billion) was poorly received by the market, and after Apotheker's ouster, plans for a divestiture were cancelled. In March 2012, the printing and imaging division was merged into the PC unit. In October 2012, according to Gartner, Lenovo took the lead as the number one PC manufacturer from HP, while IDC ranked Lenovo just right behind HP. In Q2 2013, \"Forbes\" reported that Lenovo ranked ahead of HP as the world's number-one PC supplier.\nThe Compaq brand name was discontinued in the United States by HP in 2013. That same year, Globalk (a Brazilian-based retailer and licensing management firm) started a partnership with HP to re-introduce the brand with a new line of desktop and laptop computers. The brand has since been relicensed to Positivo Tecnologia (a Brazilian-based computer technology company) starting on April 13, 2021.\nIn 2015, Grupo Newsan (an Argentinian-based company) acquired the brand's license, along with a $3 million investment, and developed two new lines of Presario notebooks for the local market over the course of the year. Compaq's Argentine web site went offline in March 2019, with the last archived copy of the site being made in October 2018. It featured the same models that were introduced in 2016.\nIn 2018, Ossify Industries (an Indian-based company) entered a licensing agreement with HP to use the Compaq brand name for the distribution and manufacturing of Smart TV sets.\nHeadquarters.\nThe Compaq World Headquarters campus consisted of of land which contained 15 office buildings, 7 manufacturing buildings, a product conference center, an employee cafeteria, mechanical laboratories, warehouses, and chemical handling facilities.\nInstead of headquartering the company in a downtown Houston skyscraper, then-CEO and co-founder Rod Canion chose a West Coast-style campus surrounded by forests, where every employee had similar offices and no-one (not even the CEO) had a reserved parking spot. As it grew, Compaq became so important to Houston that it negotiated the expansion of SH\u00a0249 in the late 1980s, and many other technology companies appeared in what became known as the \"249 Corridor\".\nAfter Canion's ouster, senior vice-president of human resources, Hans W. Gutsch, oversaw the company's facilities and security. Gutsch had an extensive security system and guard station installed on the eight floor of CCA-1, where the company's senior vice presidents had their offices. Eckhard Pfeiffer, president and CEO, introduced a whole series of executive perks to a company that had always had an egalitarian culture; for instance, he oversaw the construction of an executive parking garage, previously parking places had never been reserved.\nOn August 31, 1998, the Compaq Commons was opened in the headquarters campus, which featured a conference center, an employee convenience store, a wellness center, and an employee cafeteria.\nCompaq's former headquarters then became HP's United States campus after Compaq was acquired by HP in 2002. From May 2002 to April 2022, the site was one of HP's largest campuses, with 7,000 employees in all six of HP's divisions. In 2009, HP sold part of Compaq's former headquarters to the Lone Star College System, which became Lone Star College\u2013University Park in 2010. Hewlett Packard Buildings #7 &amp; #8, which consisted of two eight-story reinforced concrete buildings totaling 450,000 square feet plus a 1,200-car parking garage and a central chiller plant, were all deemed by the college to be too robust and costly to maintain, and so were subsequently demolished by implosion on September 18, 2011 to make way for a new green space where the buildings once stood.\nThe campus was later inherited by Hewlett Packard Enterprise, one of the successor companies when HP split into two in November 2015. In 2018, Hewlett Packard Enterprise announced the sale of the entire former Compaq headquarters, which was subsequently sold to Mexican beverage distributor Mexcor in April 2022. In March 2024, a major portion of Compaq's former headquarters and HP/HPE campus was then rebranded as Viva Center by the property owner, Morales Capital Group, which plans to turn the campus into a mixed-use tech hub featuring public gathering areas, events and apartments.\nCompetitors.\nCompaq originally competed directly against IBM, manufacturing computer systems equivalent with the IBM PC, as well as Apple Computer. In the 1990s, as IBM's own PC division declined, Compaq faced other IBM PC Compatible manufacturers like Dell, Packard Bell, AST Research, and Gateway 2000.\nBy the mid-1990s, Compaq's price war had enabled it to overtake IBM and Apple, while other IBM PC Compatible manufacturers such as Packard Bell and AST were driven out from the market. Dell overtook Compaq and became the number-one supplier of PCs in 1999, which Compaq briefly regained in 2000 before being overtaken again by Dell in 2001.\nAt the time of their 2002 merger, Compaq and HP were the second and third largest PC manufacturers, so their combination made them number one. However, the combined HP-Compaq struggled and fell to second place behind Dell from 2003 to 2006. Due to Dell's struggles in late 2006, HP has led all PC vendors from 2007 to 2012.\nDuring its existence as a division of HP, Compaq primarily competed against other budget-oriented personal computer series from manufacturers including Acer, Lenovo, and Toshiba. Most of Compaq's competitors except Dell were later acquired by bigger rivals like Acer (Gateway 2000 and Packard Bell) and Lenovo absorbing IBM's PC division. Since 2013, Lenovo has been the world leader for PCs.\nSponsorship.\nCompaq sponsored Queens Park Rangers F.C. for the 1994\u201395 and 1995\u201396 seasons.\nPrior to its merger with HP in 2002, Compaq sponsored the Williams Racing Formula One team (then known as WilliamsF1 at the time) beginning in January 2000, which also coincided with the team's first use of BMW engines for their cars as part of a then-partnership with BMW at the time. The company sponsored the 2000 and 2001 British Grand Prix, with all of their cars and team equipment featuring prominent Compaq branding throughout among other brands. After Compaq was acquired by HP in 2002, HP inherited and continued the sponsorship deal for a few more years, replacing the Compaq branding on all cars and team equipment with the HP branding following the 2002 merger. HP then sponsored the 2002 British Grand Prix up until the 2005 British Grand Prix, the latter of which also marked the last time the team used BMW engines for their cars before switching over to Cosworth engines the following season."}
{"id": "7743", "revid": "107439", "url": "https://en.wikipedia.org/wiki?curid=7743", "title": "Cell Incubator", "text": ""}
{"id": "7744", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7744", "title": "Cell incubator", "text": ""}
{"id": "7751", "revid": "1094363112", "url": "https://en.wikipedia.org/wiki?curid=7751", "title": "CPSU (disambiguation)", "text": "CPSU is the Communist Party of the Soviet Union, the sole governing party of the Soviet Union until 1990.\nCPSU may also refer to:"}
{"id": "7755", "revid": "1808194", "url": "https://en.wikipedia.org/wiki?curid=7755", "title": "Cluny", "text": "Cluny () is a commune in the eastern French department of Sa\u00f4ne-et-Loire, in the region of Bourgogne-Franche-Comt\u00e9. It is northwest of M\u00e2con.\nThe town grew up around the Benedictine Abbey of Cluny, founded by Duke William I of Aquitaine in 910. The height of Cluniac influence was from the second half of the 10th century through the early 12th. The abbey was sacked by the Huguenots in 1562, and many of its valuable manuscripts were destroyed or removed.\nGeography.\nThe river Grosne flows northward through the commune and crosses the town."}
{"id": "7756", "revid": "7108688", "url": "https://en.wikipedia.org/wiki?curid=7756", "title": "Chet Atkins", "text": "Chester Burton Atkins (June 20, 1924\u00a0\u2013 June 30, 2001), also known as \"Mister Guitar\" and \"the Country Gentleman\", was an American musician who, along with Owen Bradley and Bob Ferguson, helped create the Nashville sound, the country music style which expanded its appeal to adult pop music fans. He was primarily a guitarist, but he also played the mandolin, fiddle, banjo, and ukulele, and occasionally sang.\nAtkins's signature picking style was inspired by Merle Travis. Other major guitar influences were Django Reinhardt, George Barnes, Les Paul, and, later, Jerry Reed. His distinctive picking style and musicianship brought him admirers inside and outside the country scene, both in the United States and abroad. Atkins spent most of his career at RCA Victor and produced records for the Browns, Hank Snow, Porter Wagoner, Norma Jean, Dolly Parton, Dottie West, Perry Como, Floyd Cramer, Elvis Presley, the Everly Brothers, Eddy Arnold, Don Gibson, Jim Reeves, Jerry Reed, Skeeter Davis, Waylon Jennings, Roger Whittaker, Ann-Margret and many others.\n\"Rolling Stone\" credited Atkins with inventing the \"popwise 'Nashville sound' that rescued country music from a commercial slump\" and ranked him number 21 on their list of \"The 100 Greatest Guitarists of All Time\". In 2023, Atkins was named the 39th best guitarist of all time. Among many other honors, Atkins received 14 Grammy Awards and the Grammy Lifetime Achievement Award. He also received nine Country Music Association awards for Instrumentalist of the Year. He was inducted into the Rock and Roll Hall of Fame, the Country Music Hall of Fame and Museum, and the Musicians Hall of Fame and Museum. George Harrison was also inspired by Chet Atkins; early Beatles songs such as \"All My Loving\" show the influence.\nBiography.\nChildhood and early life.\nAtkins was born on June 20, 1924, in Luttrell, Tennessee, near Clinch Mountain. His parents divorced when he was six years old, after which he was raised by his mother. He was the youngest of three boys and a girl. He started out on the ukulele, later moving on to the fiddle, but he made a swap with his brother Lowell when he was nine: an old pistol and some chores for a guitar. He stated in his 1974 autobiography, \"We were so poor and everybody around us was so poor that it was the forties before anyone even knew there had been a depression.\" Forced to relocate to Fortson, Georgia, outside of Columbus to live with his father because of a critical asthma condition, Atkins was a sensitive youth who became obsessed with music. Because of his illness, he was forced to sleep in a straight-back chair to breathe comfortably. On those nights, he played his guitar until he fell asleep holding it, a habit that lasted his whole life. While living in Fortson, Atkins attended the historic Mountain Hill School. He returned in the 1990s to play a series of charity concerts to save the school from demolition.\nStories have been told about the very young Chet who, when a friend or relative would come to visit and play guitar, crowded the musician and put his ear so close to the instrument that it became difficult for the visitor to play.\nAtkins became an accomplished guitarist while he was in high school. He used the restroom in the school to practice, because it had good acoustics. His first guitar had a nail for a nut and was so bowed that only the first few frets could be used. He later purchased a semi-acoustic electric guitar and amplifier, but he had to travel many miles to find an electrical outlet, since his home didn't have electricity.\nLater in life, he lightheartedly gave himself (along with John Knowles, Tommy Emmanuel, Steve Wariner, and Jerry Reed) the honorary degree CGP (\"Certified Guitar Player\").\nIn 2011, his daughter Merle Atkins Russell bestowed the CGP degree on his longtime sideman Paul Yandell. She then declared no more CGPs would be allowed by the Atkins estate.\nHis half-brother Jim was a successful guitarist who worked with the Les Paul Trio in New York.\nAtkins did not have a strong style of his own until 1939 when (while still living in Georgia) he heard Merle Travis picking over WLW radio. This early influence dramatically shaped his unique playing style. Whereas Travis used his index finger on his right hand for the melody and his thumb for the bass notes, Atkins expanded his right-hand style to include picking with his first three fingers, with the thumb on bass. He also listened closely to the single-string playing of George Barnes and Les Paul.\nChet Atkins was an amateur radio general class licensee. Formerly using the call sign WA4CZD, he obtained the vanity call sign W4CGP in 1998 to include the CGP designation, which supposedly stood for \"Certified Guitar Picker\". He was a member of the American Radio Relay League.\nEarly musical career.\nAfter dropping out of high school in 1942, Atkins landed a job at WNOX (AM) (now WNML) radio in Knoxville, where he played fiddle and guitar with the singer Bill Carlisle and the comic Archie Campbell and became a member of the station's Dixieland Swingsters, a small swing instrumental combo. After three years, he moved to WLW-AM in Cincinnati, Ohio, where Merle Travis had formerly worked.\nAfter six months, he moved to Raleigh and worked with Johnnie and Jack before heading for Richmond, Virginia, where he performed with Sunshine Sue Workman. Atkins's shy personality worked against him, as did the fact that his sophisticated style led many to doubt he was truly \"country\". He was fired often but was soon able to land another job at another radio station on account of his unique playing ability.\nAtkins and Jethro Burns (of Homer and Jethro) married twin sisters Leona and Lois Johnson, who sang as Laverne and Fern Johnson, the Johnson Sisters. Leona Atkins outlived her husband by eight years, dying in 2009 at the age of 85.\nTravelling to Chicago, Atkins auditioned for Red Foley, who was leaving his star position on WLS-AM's \"National Barn Dance\" to join the Grand Ole Opry. Atkins made his first appearance at the Opry in 1946 as a member of Foley's band. He also recorded a single for Nashville-based Bullet Records that year. That single, \"Guitar Blues\", was fairly progressive, including a clarinet solo by the Nashville dance band musician Dutch McMillin and produced by Jim Bulleit, founder of Bullet Records. He had a solo spot on the Opry, but when that was cut, Atkins moved on to KWTO in Springfield, Missouri. Despite the support of executive Si Siman, however, he soon was fired for not sounding \"country enough\".\nSigning with RCA Victor.\nWhile working with a Western band in Denver, Colorado, Atkins came to the attention of RCA Victor. Siman had been encouraging Steve Sholes to sign Atkins, as his style (with the success of Merle Travis as a hit recording artist) was suddenly in vogue. Sholes, A&amp;R director of country music at RCA, tracked Atkins down in Denver.\nHe made his first RCA Victor recordings in Chicago in 1947, but they did not sell. He did some studio work for RCA that year, but had relocated to Knoxville again where he worked with Homer and Jethro on WNOX's new Saturday night radio show \"The Tennessee Barn Dance\" and the popular \"Midday Merry Go Round\".\nIn 1949, he left WNOX to join June Carter with Mother Maybelle and the Carter Sisters on KWTO. This incarnation of the Carter Family featured Maybelle Carter and daughters June, Helen, and Anita. Their work soon attracted attention from the Grand Ole Opry. The group relocated to Nashville in the mid-1950s. Atkins began working on recording sessions and performing on WSM-AM and the Opry. Atkins became a member of the Opry in the 1950s.\nWhile he had not yet had a hit record for RCA Victor, his stature was growing. He began assisting Sholes as a session leader when the New York\u2013based producer needed help organizing Nashville sessions for RCA Victor artists. Atkins's first hit single was \"Mr. Sandman\", followed by \"Silver Bell\", which he recorded as a duet with Hank Snow. His albums also became more popular. He was featured on ABC-TV's \"The Eddy Arnold Show\" in the summer of 1956 and on \"Country Music Jubilee\" in 1957 and 1958 (by then renamed \"Jubilee USA\").\nIn addition to recording, Atkins was a design consultant for Gretsch, which manufactured a popular Chet Atkins line of electric guitars from 1955 to 1980. He became manager of RCA Victor's Nashville studios, eventually inspiring and seeing the completion of the legendary RCA Studio B, the first studio built specifically for the purpose of recording on the now-famous Music Row. Also later on, Chet and Owen Bradley would become instrumental in the creation of studio B's adjacent building RCA Studio A as well.\nPerformer and producer.\nWhen Sholes took over pop production in 1957\u2014a result of his success with Elvis Presley\u2014he put Atkins in charge of RCA Victor's Nashville division. With country music record sales declining as rock and roll became more popular, Atkins took his cue from Owen Bradley and eliminated fiddles and steel guitar from many recordings, though not all, as a means of making country singers appeal to pop fans, many of whom disliked the \"twang\" elements of country. This became known as the Nashville Sound, which Atkins said was a label created by the media for a style of recording during that period intended to keep country (and their jobs) viable.\nAtkins used the Jordanaires and a rhythm section on hits such as Jim Reeves's \"Four Walls\" and \"He'll Have to Go\" and Don Gibson's \"Oh Lonesome Me\" and \"Blue Blue Day\". The once-rare phenomenon of having a country hit cross over to pop success became more common. He and Bradley had essentially put the producer in the driver's seat, guiding an artist's choice of material and the musical background. Other Nashville producers quickly copied this successful formula, which resulted in certain country hits \"crossing over\" to find success in the pop field.\nAtkins made his own records, which usually visited pop standards and jazz, in a sophisticated home studio, often recording the rhythm tracks at RCA and adding his solo parts at home, refining the tracks until the results satisfied him. Guitarists of all styles came to admire various Atkins albums for their unique musical ideas and in some cases experimental electronic ideas. In this period, he became known internationally as \"Mister Guitar\", inspiring an album, \"Mister Guitar\", engineered by both Bob Ferris and Bill Porter, Ferris's replacement.\nAt the end of March 1959, Porter took over as chief engineer at what was at the time RCA Victor's only Nashville studio, in the space that would become known as Studio B after the opening of a second studio in 1965. (At the time, RCA's sole Nashville studio had no letter designation.) Porter soon helped Atkins get a better reverberation sound from the studio's German effects device, an EMT 140 plate reverb. With his golden ear, Porter found the studio's acoustics to be problematic, and he devised a set of acoustic baffles to hang from the ceiling, then selected positions for microphones based on resonant room modes. The sound of the recordings improved significantly, and the studio achieved a string of successes. The Nashville sound became more dynamic. In later years, when Bradley asked how he achieved his sound, Atkins told him \"it was Porter.\" Porter described Atkins as respectful of musicians when recording\u2014if someone was out of tune, he would not single that person out by name. Instead, he would say something like, \"we got a little tuning problem\u00a0... Everybody check and see what's going on.\" If that did not work, Atkins would instruct Porter to turn the offending player down in the mix. When Porter left RCA in late-1964, Atkins said, \"the sound was never the same, never as great.\"\nAtkins's trademark \"Atkins style\" of playing uses the thumb and first two or sometimes three fingers of the right hand. He developed this style from listening to Merle Travis, occasionally on a primitive radio. He was sure no one could play that articulately with just the thumb and index finger (which was exactly how Travis played), and he assumed it required the thumb and two fingers\u2014and that was the style he pioneered and mastered.\nHe enjoyed jamming with fellow studio musicians, and they were asked to perform at the Newport Jazz Festival in 1960. That performance was cancelled because of rioting, but a live recording of the group (\"After the Riot at Newport\") was released. Atkins performed by invitation at the White House for every U.S. president from John F. Kennedy through to George H. W. Bush. Atkins was a member of the Million Dollar Band during the 1980s. He is also well known for his song \"Yankee Doodle Dixie\", in which he played \"Yankee Doodle\" and \"Dixie\" simultaneously, on the same guitar.\nBefore his mentor Sholes died in 1968, Atkins had become vice president of RCA's country division. In 1987, he told \"Nine-O-One Network\" magazine that he was \"ashamed\" of his promotion: \"I wanted to be known as a guitarist and I know, too, that they give you titles like that in lieu of money. So beware when they want to make you vice president.\" He had brought Waylon Jennings, Willie Nelson, Connie Smith, Bobby Bare, Dolly Parton, Jerry Reed, and John Hartford to the label in the 1960s and inspired and helped countless others. He took a considerable risk during the mid-1960s, when the civil rights movement sparked violence throughout the South, by signing country music's first African-American singer, Charley Pride, who sang rawer country than the smoother music Atkins had pioneered.\nAtkins's biggest hit single came in 1965, with \"Yakety Axe\", an adaptation of \"Yakety Sax\", by his friend, the saxophonist Boots Randolph. He rarely performed in those days and eventually hired other RCA producers, such as Bob Ferguson and Felton Jarvis, to lessen his workload.\nLater career.\nIn the 1970s, Atkins became increasingly stressed by his executive duties. He produced fewer records, but could still turn out hits such as Perry Como's 1973 pop hit \"And I Love You So\". He recorded extensively with close friend and fellow picker Jerry Reed, who had become a hit artist in his own right. A 1973 diagnosis of colon cancer, however, led Atkins to redefine his role at RCA Records, to allow others to handle administration while he went back to his first love, the guitar, often recording with Reed or even Jethro Burns from Homer and Jethro (his brother-in-law) after Homer died in 1971. Atkins would turn over his administrative duties to Jerry Bradley, son of Owen, in 1973 at RCA.\nAtkins did little production work at RCA after stepping down and in fact, had hired producers at the label in the 1960s, among them Bob Ferguson and Felton Jarvis. As a recording artist, Atkins grew disillusioned with RCA in the late 1970s. He felt stifled because the record company would not let him branch into jazz. He had also produced late '60s jazz recordings by Canadian guitarist Lenny Breau, a friend and protege. His mid-1970s collaborations with one of his influences, Les Paul, \"Chester &amp; Lester\" and \"Guitar Monsters\", had already reflected that interest; \"Chester &amp; Lester\" was one of the best-selling recordings of Atkins's career. At the same time, he grew dissatisfied with the direction Gretsch (no longer family-owned) was going and withdrew his authorization for them to use his name and began designing guitars with Gibson. In 1982, Atkins ended his 35-year association with RCA Records and signed with rival Columbia Records. He produced his first album for Columbia in 1983.\nAtkins had always been an ardent lover of jazz and throughout his career he was often criticized by \"pure\" country musicians for his jazz influences. He also said on many occasions that he did not like being referred to as a \"country guitarist\", insisting that he was \"a guitarist, period.\" Although he played by ear and was a masterful improviser, he was able to read music and even performed some classical guitar pieces. When Roger C. Field, a friend, suggested to him in 1991 that he record and perform with a female singer, he did so with Suzy Bogguss.\nAtkins returned to his country roots for albums he recorded with Mark Knopfler and Jerry Reed. Knopfler had long mentioned Atkins as one of his earliest influences. Atkins also collaborated with Australian guitar legend Tommy Emmanuel. On being asked to name the ten most influential guitarists of the twentieth century, he named Django Reinhardt to the first position, and also placed himself on the list.\nIn later years, he returned to radio, appearing on Garrison Keillor's \"Prairie Home Companion\" program, on American Public Media radio, even picking up a fiddle from time to time, and performing songs such as Bob Wills's \"Corrina, Corrina\" and Willie Nelson's \"Seven Spanish Angels\" with Nelson on a 1985 broadcast of the show at the Bridges Auditorium on the campus of Pomona College.\nDeath and legacy.\nAtkins continued performing in the 1990s, but his health declined after he was again diagnosed with colon cancer in 1996. He died on June 30, 2001, at his home in Nashville, Tennessee, at age 77. His memorial service was held at Ryman Auditorium in Nashville. He was buried at Harpeth Hills Memory Gardens in Nashville.\nAtkins received numerous awards, including 14 Grammy awards and nine Country Music Association awards for Instrumentalist of the Year. In 1993, he was honored with the Grammy Lifetime Achievement Award. \"Billboard\" magazine awarded him its Century Award, its \"highest honor for distinguished creative achievement\", in December 1997. In 2002, Atkins was posthumously inducted into the Rock and Roll Hall of Fame. His award was presented by Marty Stuart and Brian Setzer and accepted by Atkins's grandson, Jonathan Russell. The following year, Atkins ranked number 28 in Country Music Television's \"40 Greatest Men of Country Music\". In November 2011, \"Rolling Stone\" ranked Atkins number 21 on their list of the \"100 Greatest Guitarists of All Time\".\nAtkins is notable for his broad influence. His love for numerous styles of music can be traced from his early recording of the stride pianist James P. Johnson's \"Johnson Rag\", all the way to the rock stylings of Eric Johnson, an invited guest on Atkins's recording sessions, who, when Atkins attempted to copy his influential rocker \"Cliffs of Dover\", led to Atkins's creation of a unique arrangement of \"Londonderry Air (Danny Boy)\".\nThe classical guitar selections included on almost all his albums were, for many American artists working in the field today, the first classical guitar they ever heard. He recorded smooth jazz guitar still played on American airwaves.\nA stretch of Interstate 185 in southwest Georgia (between LaGrange and Columbus) is named \"Chet Atkins Parkway\". This stretch of interstate runs through Fortson, where Atkins spent much of his childhood.\nAt the age of 13, the future jazz guitarist Earl Klugh was captivated watching Atkins perform on \"The Perry Como Show.\" He was also a big influence on Doyle Dykes, and inspired Tommy Emmanuel. Johnny Winter's thumb-picking style came from Atkins' playing. Steve Howe called Atkins his favorite \"all round guitarist\", adding that \"there are those in different areas of music who are better than him, but nobody had the same ability when it comes to being across the board. For me, it was an education to listen to what he did.\"\nClint Black's album \"Nothin' but the Taillights\" includes the song \"Ode to Chet\", which includes the lyrics \"'Cause I can win her over like Romeo did Juliet, if I can only show her I can almost pick that legato lick like Chet\" and \"It'll take more than Mel Bay 1, 2, &amp; 3 if I'm ever gonna play like CGP.\" Atkins played guitar on the track. At the end of the song, Black and Atkins had a brief conversation.\nAtkins' song \"Jam Man\" is currently used in commercials for Esurance.\nIn 1967, a tribute song, \"Chet's Tune\", was produced for Atkins' birthday, with contributions by a long list of RCA Victor artists, including Eddy Arnold, Connie Smith, Jerry Reed, Willie Nelson, Hank Snow, and others. The song was written by the Nashville songwriter Cy Coben, a friend of Atkins. The single reached number 38 on the country charts.\nIn 2009, Steve Wariner released an album titled \"My Tribute to Chet Atkins\". One song from that record, \"Producer's Medley\", featured Wariner's recreation of several famous songs that Atkins both produced and performed. \"Producer's Medley\" won the Grammy for Best Country Instrumental Performance in 2010.\nIndustry awards.\nCountry Music Association\nCountry Music Hall of Fame and Museum\nGrammy Awards\nRock and Roll Hall of Fame"}
{"id": "7757", "revid": "494861", "url": "https://en.wikipedia.org/wiki?curid=7757", "title": "Conrad II (disambiguation)", "text": "Conrad II or Konrad II may refer to:"}
{"id": "7765", "revid": "19199855", "url": "https://en.wikipedia.org/wiki?curid=7765", "title": "Cahiers du Cin\u00e9ma", "text": " (, ) is a French film magazine co-founded in 1951 by Andr\u00e9 Bazin, Jacques Doniol-Valcroze, and Joseph-Marie Lo Duca. It developed from the earlier magazine \"Revue du Cin\u00e9ma\" ( established in 1928) involving members of two Paris film clubsObjectif 49 (Robert Bresson, Jean Cocteau, and Alexandre Astruc, among others; ) and Cin\u00e9-Club du Quartier Latin ().\nInitially edited by Doniol-Valcroze and, after 1957, by \u00c9ric Rohmer (aka, Maurice Scherer), it included amongst its writers Jacques Rivette, Jean-Luc Godard, Claude Chabrol, and Fran\u00e7ois Truffaut, who went on to become highly influential filmmakers. It is the oldest French-language film magazine in publication.\nHistory.\nThe first issue of \"Cahiers\" appeared in April 1951. Much of its head staff, including Bazin, Doniol-Valcroze, Lo Duca, and the various younger, less-established critics, had met and shared their beliefs about film through their involvement in the publication of \"Revue du Cin\u00e9ma\" from 1946 until its final issue in 1948; \"Cahiers\" was created as a successor to this earlier magazine.\nEarly issues of \"Cahiers\" were small journals of thirty pages which bore minimalist covers, distinctive for their lack of headlines in favor of film stills on a distinctive bright yellow background. Each issue contained four or five articles (with at least one piece by Bazin in most issues), most of which were reviews of specific films or appreciations of directors, supplemented on occasion by longer theoretical essays. The first few years of the magazine's publication were dominated by Bazin, who was the \"de facto\" head of the editorial board.\nBazin intended \"Cahiers\" to be a continuation of the intellectual form of criticism that \"Revue\" had printed, which prominently featured his articles advocating for realism as the most valuable quality of cinema. As more issues of \"Cahiers\" were published, however, Bazin found that a group of young proteges and critics serving as editors underneath him were beginning to disagree with him in the pages of the magazine. Godard would voice his discontent with Bazin as early as 1952, when he challenged Bazin's views on editing in an article for the September issue of \"Cahiers.\" Gradually, the tastes of these young critics drifted away from those of Bazin, as members of the group began to write critical appreciations of more commercial American filmmakers such as Alfred Hitchcock and Howard Hawks rather than the canonized French and Italian filmmakers that interested Bazin.\nThe younger critics broke completely with Bazin by 1954, when an article in the January issue by Truffaut attacked what he called \"La qualit\u00e9 fran\u00e7aise\" (, usually translated as \"The Tradition of Quality\"), denouncing many critically respected French films of the time as being unimaginative, oversimplified, and even immoral adaptations of literary works. The article became the manifesto for the \"politique des auteurs\" (), which became the label for \"Cahiers\" younger critics' emphasis on the importance of the director in the creation of a filmas a film's \"author\"and their re-evaluation of Hollywood films and directors such as Hitchcock, Hawks, Jerry Lewis, Robert Aldrich, Nicholas Ray, and Fritz Lang. Subsequently, American critic Andrew Sarris latched onto the word, \"auteur\", and paired it with the English word, \"theory\"; hence coining the phrase the \"auteur theory\" by which this critical approach is known in English-language film criticism.\nAfter the publication of Truffaut's article, Doniol-Valcroze and most of the \"Cahiers\" editors besides Bazin and Lo Duca rallied behind the rebellious authors; Lo Duca left \"Cahiers\" a year later, while Bazin, in failing health, gave editorial control of the magazine to Rohmer and largely left Paris, though he continued to write for the magazine. Now with control over the magazine's ideological approaches to film, the younger critics (minus Godard, who had left Paris in 1952, not to return until 1956) changed the format of \"Cahiers\" somewhat, frequently conducting interviews with directors deemed \"auteurs\" and voting on films in a \"Council\" of ten core critics. These critics came to champion non-American directors as well, writing on the \"mise en sc\u00e8ne\" (the \"dominant object of study\" at the magazine) of such filmmakers as Jean Renoir, Roberto Rossellini, Kenji Mizoguchi, Max Oph\u00fcls, and Jean Cocteau, many of whom Bazin had introduced them to.\nBy the end of the 1950s, many of the remaining editors of \"Cahiers\", however, were becoming increasingly dissatisfied with the mere act of writing film criticism. Spurred on by the return of Godard to Paris in 1956 (who in the interim had made a short film himself), many of the younger critics became interested in making films themselves. Godard, Truffaut, Chabrol, Doniol-Valcroze, and even Rohmer, who had officially succeeded Doniol-Valcroze as head editor in 1958, began to divide their time between making films and writing about them. The films that these critics made were experimental explorations of various theoretical, artistic, and ideological aspects of the film form, and would, along with the films of young French filmmakers outside the \"Cahiers\" circle, form the basis for the cinematic movement known as the French New Wave. Meanwhile, \"Cahiers\" underwent staff changes, as Rohmer hired new editors such as Jean Douchet to fill the roles of those editors who were now making films, while other existing editors, particularly Jacques Rivette, began to write even more for the magazine. Many of the newer critical voices (except for Rivette) largely ignored the films of the New Wave for Hollywood when they were not outright criticizing them, creating friction between much of the directorial side of the younger critics and the head editor Rohmer. A group of five \"Cahiers\" editors, including Godard and Doniol-Valcroze and led by Rivette, urged Rohmer to refocus the magazine's content on newer films such as their own. When he refused, the \"gang of five\" forced Rohmer out and installed Rivette as his replacement in 1963.\nRivette shifted political and social concerns farther to the left, and began a trend in the magazine of paying more attention to non-Hollywood films. The style of the journal moved through literary modernism in the early 1960s to radicalism and dialectical materialism by 1970. Moreover, during the mid-1970s the magazine was run by a Maoist editorial collective. In the mid-1970s, a review of the American film \"Jaws\" marked the magazine's return to more commercial perspectives, and an editorial turnover: (Serge Daney, Serge Toubiana, Thierry Jousse, Antoine de Baecque, and Charles Tesson). It led to the rehabilitation of some of the old \"Cahiers\" favourites, as well as some new film makers like Manoel de Oliveira, Raoul Ruiz, Hou Hsiao-hsien, Youssef Chahine, and Maurice Pialat. Recent writers have included Daney, Andr\u00e9 T\u00e9chin\u00e9, L\u00e9os Carax, Olivier Assayas, Dani\u00e8le Dubroux, and Serge Le P\u00e9ron.\nIn 1998, the Editions de l'Etoile (the company publishing \"Cahiers\") was acquired by the press group . Traditionally losing money, the magazine attempted a make-over in 1999 to gain new readers, leading to a first split among writers and resulting in a magazine addressing all visual arts in a post-modernist approach. This version of the magazine printed ill-received opinion pieces on reality TV or video games that confused the traditional readership of the magazine.\n took full editorial control of the magazine in 2003, appointing Jean-Michel Frodon as editor-in-chief. In February 2009, \"Cahiers\" was acquired from by Richard Schlagman, also owner of Phaidon Press, a worldwide publishing group which specialises in books on the visual arts. In July 2009, St\u00e9phane Delorme and Jean-Philippe Tess\u00e9 were promoted respectively to the positions of editor-in-chief and deputy chief editor.\nIn February 2020, the magazine was bought by several French entrepreneurs, including Xavier Niel and Alain Weill. The entire editorial staff resigned, saying the change posed a threat to their editorial independence.\nAnnual top 10 films list.\nThe magazine has compiled a list of the top 10 films of each year for much of its existence."}
{"id": "7766", "revid": "76", "url": "https://en.wikipedia.org/wiki?curid=7766", "title": "Cartzonna", "text": ""}
{"id": "7767", "revid": "41295437", "url": "https://en.wikipedia.org/wiki?curid=7767", "title": "Circuit Zandvoort", "text": "Circuit Zandvoort (), known for sponsorship reasons as CM.com Circuit Zandvoort, previously known as Circuit Park Zandvoort until 2017, is a motorsport race track located in the dunes north of Zandvoort, the Netherlands, near the North Sea coast line and west of Amsterdam. It returned to the Formula One calendar in 2021 as the location of the revived Dutch Grand Prix. This partnership with Formula One will end in 2026.\nHistory.\n1930s to mid 1980s.\nThere were plans for races at Zandvoort before World War II: the first street race was held on 3 June 1939. However, a permanent race track was not constructed until after the war, using communications roads built by the occupying German army. Contrary to popular belief John Hugenholtz cannot be credited with the design of the Zandvoort track, although he was involved as the chairman of the Nederlandse Automobiel Ren Club (Dutch Auto Racing Club) before becoming the first track director in 1949. Instead, it was 1927 Le Mans winner, S. C. H. \"Sammy\" Davis who was brought in as a track design advisor in July 1946 although the layout was partly dictated by the existing roads.\nThe first race on the circuit, the \"Prijs van Zandvoort\", took place on 7 August 1948. The race was renamed the \"Grote Prijs van Zandvoort\" (Zandvoort Grand Prix) in 1949, then the \"Grote Prijs van Nederland\" (Dutch Grand Prix) in 1950. The 1952 race was the first to be run as a round of the World Championship, albeit to Formula Two regulations rather than Formula One regulations like all the European rounds of the championship that year; a similar situation also applied to the 1953. There was no Dutch Grand Prix in 1954, 1956 or 1957, but 1955 saw the first true Formula One race as part of the Drivers' Championship. The Dutch Grand Prix returned in 1958 and remained a permanent fixture on the F1 calendar (with the exception of 1972) through , when it was held for the last time in the 20th century.\nSince 1985.\nTo solve a number of problems that had made it impossible to develop and upgrade the circuit, most importantly noise pollution for Zandvoort inhabitants living closest to the track, the track management developed and adopted a plan to move the most southern part of the track away from the nearby housing estate, and rebuild a more compact track in the remaining former 'infield'. In January 1987 this plan got the necessary 'green light' when it was formally approved by the Provincial Council of North Holland. However, only a couple of months later a new problem arose: the company that commercially ran the circuit (CENAV), called in the receiver and went out of business, marking the end of 'Circuit Zandvoort'. Again the track, owned by the municipality of Zandvoort, was in danger of being permanently lost for motorsports. However, a new operating foundation, the \"Stichting Exploitatie Circuit Park\", was formed and started work at the realization of the track's reconstruction plans. Circuit Park Zandvoort was born and in the summer of 1989 the track was remodeled to an interim Club Circuit of , while the disposed southern part of the track was used to build a Vendorado Bungalow Park and new premises for the local football and field-hockey clubs.\nIn 1995, CPZ (\"Circuit Park Zandvoort\") got the \"A Status\" of the government of the Netherlands and began building an international Grand Prix Circuit. This project was finished in 2001 when, after the track was redesigned to a long circuit and a new pits building was realized (by HPG, the development company of John Hugenholtz Jr., son of the former director), a new grandstand was situated along the long straight. One of the major events that is held at the circuit, along with DTM and A1GP, is the RTL Masters of Formula 3, where Formula Three cars of several national racing series compete with each other (originally called Marlboro Masters, before tobacco advertising ban). A noise restriction order was responsible for this event moving to the Belgian Circuit Zolder for 2007 and 2008. However, the race returned to its historical home in 2009.\nCircuit Park Zandvoort played host to the first race in the 2006/07 season of A1 Grand Prix from 29 September\u20131 October 2006. On 21 August 2008, the official A1GP site reported that the 2008/09 season's first race has moved from the Mugello Circuit, Italy to Zandvoort on 4\u20135 October 2008 due to the delay in the building the new chassis for the new race cars. The Dutch round moved to TT Circuit Assen in 2010. A1GP bankrupted before its fifth season and the Dutch round was replaced with Superleague Formula.\nIn November 2018 reported that Formula One Management (FOM) had invited the owners of the Zandvoort race track to make a proposal to stage a Grand Prix race in 2020. In March 2019, it was confirmed that a letter of intent had been signed between Zandvoort and FOM to stage the Dutch Grand Prix, dependent on private funding being secured to cover the cost of hosting the race. A deadline of 31 March 2019 was set for a final decision to be made. On 14 May 2019 it was confirmed that Zandvoort would host the Dutch Grand Prix for 2020 and beyond for a duration of at least three years, with the option to host another two years beyond that. \nSeveral alterations were made to the track by to bring it up to date with F1 standards, including adding banking to turn 14 (Arie Luyendijkbocht) and turn 3 (Hugenholtzbocht), but the layout as a whole remained the same. The municipality of Zandvoort invested four million euros into the infrastructure around the circuit to improve the accessibility to the track. On 29 August 2019, the 2020 Dutch Grand Prix at Zandvoort was included as the fifth race on the provisional schedule, listed on 3 May 2020, between the Chinese Grand Prix and Spanish Grand Prix. The 2020 scheduled appearance was canceled due to the COVID-19 pandemic, however F1 racing did finally return to the circuit on 5 September 2021. On 17 September 2019, it was announced that Zandvoort would host the FIA Formula 2 Championship and FIA Formula 3 Championship, replacing the series' support races at Circuit Paul Ricard.\nThe circuit.\nThe circuit gained popularity because of its fast, sweeping corners such as Scheivlak as well as the \"Tarzanbocht\" (Tarzan corner) hairpin at the end of the start/finish straight. Tarzanbocht is the most famous corner in the circuit. Since there is a camber in the corner, it provides excellent overtaking opportunities. It is possible to pass around the outside as well as the easier inside lane. This corner is reportedly named after a local character who had earned the nickname of Tarzan and only wanted to give up his vegetable garden in the dunes if the track's designers named a nearby corner after him. On the other hand, many different stories about Tarzan Corner are known.\nThe circuit design has been modified and altered several times:\nTrack configurations.\nThe corners are named as follows (the numbers correspond to the present map, starting at the start/finish line):\nThe elevation difference is .\nTurns 3 and 13/14 are extremely cambered corners; turn 3 has a 19-degree bank while turns 13/14 have an 18-degree bank.\nLap records.\nThe official lap record for the current circuit layout is 1:11.097, set by Lewis Hamilton driving for Mercedes in the 2021 Dutch Grand Prix. The all-time fastest official track record set during a race weekend for the current Grand Prix Circuit layout is 1:08.885, set by Max Verstappen during qualifying for the aforementioned Grand Prix. As of June 2024, the fastest official race lap records at the Circuit Zandvoort are listed as:\nFatal accidents.\nIn the history of the circuit, several fatal accidents have occurred.\nCycling and running competitions.\nMotor racer Willy Koppen was the first woman to participate in motor trials in the early fifties on the circuit. In August 1959 the UCI Road World Championships men's race was held at Zandvoort. Andr\u00e9 Darrigade of France won the race, Tom Simpson (Britain) was 4th.\nIn 1994 a large interregional amateur race cycling race was organised by HSV De Kampioen in Haarlem. \nSince 2008, the course has been used as the venue for the Runner's World Zandvoort Circuit Run, a 5-kilometre road running competition. The 2010 edition of the race attracted Lornah Kiplagat, a multiple world champion, who won the ladies 5\u00a0km race.\nThe Cycling Zandvoort 24h race was first held on 25\u201326 May 2013. It is open for public for soloists and teams up to 8 riders. A 6-hours was added to the event in 2016. On 13./14. June 2015 (12:00) the Cycling Zandvoort \u2013 24 hour race over 4307-m-laps took place."}
{"id": "7768", "revid": "286968", "url": "https://en.wikipedia.org/wiki?curid=7768", "title": "Crete Senesi", "text": "The Crete Senesi refers to an area of the Italian region of Tuscany immediately to the south of Siena. It consists of a range of hills and woods among villages and includes the \"comuni\" of Asciano, Buonconvento, Monteroni d'Arbia, Rapolano Terme and San Giovanni d'Asso, all within the province of Siena. They border to the north with the Chianti Senese area, to the east with Val di Chiana and to the south-west with Val d'Orcia. Nearby is also the semi-arid area known as the Accona Desert.\n\"Crete Senesi\" are literally the \"clays of Siena\": the distinctive grey colouration of the soil gives the landscape an appearance often described as lunar. This characteristic clay, known as \"mattaione\", represents the sediments of the Pliocene sea which covered the area between 2.5 and 4.5 million years ago. The landscape is characterized by barren and gently undulating hills, solitary oaks and cypresses, isolated farms at the top of the heights, stretches of wood and ponds of rainwater (commonly referred as \"fontoni,\" literally \"big springs\") in the valleys\".\" Badlands and are typical conformations of the land. \nPerhaps the most notable edifice of this area is the Abbey of Monte Oliveto Maggiore, located 10\u00a0km south of Asciano.\nThe region is known for its production of white truffles, and hosts a festival and a museum dedicated to the rare fungus (genus Tuber)."}
{"id": "7770", "revid": "445772", "url": "https://en.wikipedia.org/wiki?curid=7770", "title": "Christmas tree", "text": "A Christmas tree is a decorated tree, usually an evergreen conifer, such as a spruce, pine or fir, associated with the celebration of Christmas. It may also consist of an artificial tree of similar appearance.\nThe custom was developed in Central Europe, particularly Germany and Livonia (now Estonia and Latvia), where Protestant Christians brought decorated trees into their homes. The tree was traditionally decorated with \"roses made of colored paper, tinsel, apples, wafers, and confectionery\". Moravian Christians began to illuminate Christmas trees with candles, which were often replaced by Christmas lights after the advent of electrification. Today, there is a wide variety of traditional and modern ornaments, such as garlands, baubles, tinsel, and candy canes. An angel or star might be placed at the top of the tree to represent the Angel Gabriel or the Star of Bethlehem, respectively, from the Nativity. Edible items such as gingerbread, chocolate, and other sweets are also popular and are tied to or hung from the tree's branches with ribbons. The Christmas tree has been historically regarded as a custom of the Lutheran Churches and only in 1982 did the Catholic Church erect the Vatican Christmas Tree.\nIn the Western Christian tradition, Christmas trees are variously erected on days such as the first day of Advent, or even as late as Christmas Eve, depending on the country; customs of the same faith hold that it is unlucky to remove Christmas decorations, such as the Christmas tree, before Twelfth Night and, if they are not taken down on that day, it is appropriate to do so on Candlemas, the latter of which ends the Christmas-Epiphany season in some denominations.\nThe Christmas tree is sometimes compared with the \"Yule-tree\", especially in discussions of its folkloric origins. Mount Ingino Christmas Tree in Gubbio, Italy, is the tallest Christmas tree in the world.\nHistory.\nOrigin of the modern Christmas tree.\nModern Christmas trees originated in Central Europe and the Baltic states, particularly Estonia, Germany and Livonia (now Latvia) during the Renaissance in early modern Europe. Its 16th-century origins are sometimes associated with Protestant Christian reformer Martin Luther, who is said to have first added lighted candles to an evergreen tree. The Christmas tree was first recorded to be used by German Lutherans in the 16th century, with records indicating that a Christmas tree was placed in the Cathedral of Strasbourg in 1539 under the leadership of the Protestant Reformer Martin Bucer. The Moravian Christians put lighted candles on those trees.\" The earliest known firmly dated representation of a Christmas tree is on the keystone sculpture of a private home in Turckheim, Alsace (then part of the Holy Roman Empire of the German Nation, today part of France), with the date 1576.\nPossible predecessors.\nModern Christmas trees have been related to the \"tree of paradise\" of medieval mystery plays that were given on 24 December, the commemoration and name day of Adam and Eve in various countries. In such plays, a tree decorated with apples (representing fruit from the tree of the knowledge of good and evil and thus to the original sin that Christ took away) and round white wafers (to represent the Eucharist and redemption) was used as a setting for the play. Like the Christmas crib, the Paradise tree was later placed in homes. The apples were replaced by round objects such as shiny red baubles.\nFir trees decorated with apples served as the central prop for the paradise play, a kind of folk religious drama often performed on December 24. These props were called paradise trees, and some researchers believe they were the forerunners of the Christmas tree.\nAt the end of the Middle Ages, an early predecessor appears referred in the 15th century Regiment of the Cistercian Alcoba\u00e7a Monastery in Portugal. The Regiment of the local \"high-Sacristans\" of the Cistercian Order refers to what may be considered the oldest references to the Christmas tree: \"Note on how to put the Christmas branch, \"scilicet\": On the Christmas eve, you will look for a large Branch of green laurel, and you shall reap many red oranges, and place them on the branches that come of the laurel, specifically as you have seen, and in every orange you shall put a candle, and hang the Branch by a rope in the pole, which shall be by the candle of the high altar.\"\nOther sources have offered a connection between the symbolism of the first documented Christmas trees in Germany around 1600 and the trees of pre-Christian traditions. According to the \"Encyclop\u00e6dia Britannica\", \"The use of evergreen trees, wreaths, and garlands to symbolize eternal life was a custom of the ancient Egyptians, Chinese, and Hebrews. Tree worship was common among the pagan Europeans and survived their conversion to Christianity in the Scandinavian customs of decorating the house and barn with evergreens at the New Year to scare away the devil and of setting up a tree for the birds during Christmas time.\"\nIt is commonly believed that ancient Romans used to decorate their houses with evergreen trees to celebrate Saturnalia. In the poem \"Epithalamium\" by Catullus, he tells of the gods decorating the home of Peleus with trees, including laurel and cypress. Later Libanius, Tertullian, and Chrysostom speak of the use of evergreen trees to adorn Christian houses.\nThe Vikings and Saxons worshiped trees. The story of Saint Boniface cutting down Donar's Oak illustrates the pagan practices in 8th century among the Germans. A later folk version of the story adds the detail that an evergreen tree grew in place of the felled oak, telling them about how its triangular shape reminds humanity of the Trinity and how it points to heaven.\nHistorical practices by region.\nEstonia, Latvia, and Germany.\nCustoms of erecting decorated trees in winter time can be traced to Christmas celebrations in Renaissance-era guilds in Northern Germany and Livonia. The first evidence of decorated trees associated with Christmas Day are trees in guildhalls decorated with sweets to be enjoyed by the apprentices and children. In Livonia (present-day Estonia and Latvia), in 1441, 1442, 1510, and 1514, the Brotherhood of Blackheads erected a tree for the holidays in their guild houses in Reval (now Tallinn) and Riga. On the last night of the celebrations leading up to the holidays, the tree was taken to the Town Hall Square, where the members of the brotherhood danced around it.\nA Bremen guild chronicle of 1570 reports that a small tree decorated with \"apples, nuts, dates, pretzels, and paper flowers\" was erected in the guild-house for the benefit of the guild members' children, who collected the dainties on Christmas Day. In 1584, the pastor and chronicler Balthasar Russow in his (1584) wrote of an established tradition of setting up a decorated spruce at the market square, where the young men \"went with a flock of maidens and women, first sang and danced there and then set the tree aflame\".\nAfter the Protestant Reformation, such trees are seen in the houses of upper-class Protestant families as a counterpart to the Catholic Christmas cribs. This transition from the guild hall to bourgeois family homes in the Protestant parts of Germany ultimately gives rise to the modern tradition as it developed in the 18th and 19th centuries. In the present-day, the churches and homes of Protestants and Catholics feature both Christmas cribs and Christmas trees.\nPoland.\nIn Poland, there is a folk tradition dating back to an old Slavic pre-Christian custom of suspending a branch of fir, spruce, or pine from the ceiling rafters, called , during the time of the Koliada winter festival. The branches were decorated with apples, nuts, acorns, and stars made of straw. In more recent times, the decorations also included colored paper cutouts (), wafers, cookies, and Christmas baubles. According to old pagan beliefs, the powers of the branch were linked to good harvest and prosperity.\nThe custom was practiced by the peasants until the early 20th century, particularly in the regions of Lesser Poland and Upper Silesia. Most often the branches were hung above the dinner table on Christmas Eve. Beginning in the mid-19th century, the tradition over time was almost completely replaced by the later German practice of decorating a standing Christmas tree.\n18th to early 20th centuries.\nAdoption by European nobility.\nIn the early 19th century, the custom became popular among the nobility and spread to royal courts as far as Russia. Introduced by Fanny von Arnstein and popularized by Princess Henrietta of Nassau-Weilburg, the Christmas tree reached Vienna in 1814, during the Congress of Vienna, and the custom spread across Austria in the following years. In France, the first Christmas tree was introduced in 1840 by the duchesse d'Orl\u00e9ans. In Denmark, a newspaper company claims that the first attested Christmas tree was lit in 1808 by Countess Wilhemine of Holsteinborg. It was the aging countess who told the story of the first Danish Christmas tree to Danish writer Hans Christian Andersen in 1865. He had published a fairy tale called \"The Fir-Tree\" in 1844, recounting the fate of a fir tree being used as a Christmas tree.\nAdoption by country or region.\n\"Germany\".\nBy the early 18th century, the custom had become common in towns of the upper Rhineland, but it had not yet spread to rural areas. Wax candles, expensive items at the time, are found in attestations from the late 18th century.\nAlong the Lower Rhine, an area of Roman Catholic majority, the Christmas tree was largely regarded as a Protestant custom. As a result, it remained confined to the upper Rhineland for a relatively long period of time. The custom did eventually gain wider acceptance beginning around 1815 by way of Prussian officials who emigrated there following the Congress of Vienna.\nIn the 19th century, the Christmas tree was taken to be an expression of German culture and of , especially among emigrants overseas.\nA decisive factor in winning general popularity was the German army's decision to place Christmas trees in its barracks and military hospitals during the Franco-Prussian War. Only at the start of the 20th century did Christmas trees appear inside churches, this time in a new brightly lit form.\n\"Slovenia\".\nEarly Slovenian custom, dating back to around the 17th century, was to suspend the tree either upright or upside-down above the well, a corner of the dinner table, in the backyard, or from the fences, modestly decorated with fruits or not decorated at all. German brewer Peter Luelsdorf brought the first Christmas tree of the current tradition to Slovenia in 1845. He set it up in his small brewery inn in Ljubljana, the Slovenian capital. German officials, craftsmen and merchants quickly spread the tradition among the bourgeois population. The trees were typically decorated with walnuts, golden apples, carobs, and candles. At first, the Catholic majority rejected this custom because they considered it a typical Protestant tradition. However, this tradition was almost unknown to the rural population until World War I, after which the decorating of trees became common. The first decorated Christmas market was organized in Ljubljana in 1859.\nAfter World War II, during the Yugoslavia period, spruce trees set in the public places (towns, squares, and markets) were, for political reasons, replaced with fir trees, a symbol of socialism and Slavic mythology, strongly associated with loyalty, courage, and dignity. However, spruce retained its popularity in Slovenian homes during those years and came back to public places after independence.\n\"Italy\".\nChristmas in Italy begins on 8 December with the Feast of the Immaculate Conception, the day on which traditionally Christmas trees are erected, and ends on 6 January of the following year with Epiphany.\nThe tradition of the Christmas tree was widely adopted in Italy during the 20th century despite its Germanic origins. It appears that the first Christmas tree in Italy was erected at the Quirinal Palace towards the end of the 19th century at the behest of Queen Margherita.\nDuring Fascism, this custom was opposed because it was considered to be an imitation of a foreign tradition, as opposed to the typically Italian nativity scene. In 1991, the Gubbio Christmas Tree, tall and decorated with over 700 lights, entered the Guinness Book of Records as the tallest Christmas tree in the world.\n\"Britain\".\nAlthough the tradition of decorating churches and homes with evergreens at Christmas was long established, the custom of decorating an entire small tree was unknown in Britain until the 19th century. The German-born Queen Charlotte introduced a Christmas tree at a party she gave for children in 1800. The custom did not at first spread much beyond the royal family. Queen Victoria, as a child, was familiar with it and a tree was placed in her room every Christmas. In her journal for Christmas Eve 1832, the delighted 13-year-old princess wrote:\nIn the year following Victoria's marriage to her German cousin Prince Albert, in 1841, the custom became even more widespread as wealthier middle-class families followed the fashion. In 1842, a newspaper advertisement for Christmas trees makes clear their smart cachet, German origins and association with children and gift-giving. An illustrated book, \"The Christmas Tree\", describing their use and origins in detail, was on sale in December 1844.\nOn 2January 1846, Elizabeth Fielding (n\u00e9e Fox Strangways) wrote from Lacock Abbey to William Henry Fox-Talbot: \"Constance is extremely busy preparing the Bohemian Xmas Tree. It is made from Caroline's description of those she saw in Germany\".\nIn 1847, Prince Albert wrote: \"I must now seek in the children an echo of what Ernest [his brother] and I were in the old time, of what we felt and thought; and their delight in the Christmas trees is not less than ours used to be\".\nA boost to the trend was given in 1848 when \"The Illustrated London News\", in a report picked up by other papers, described the trees in Windsor Castle in detail and showed the main tree, surrounded by the royal family, on its cover. In fewer than ten years, the adoption of the tradition in middle and upper-class homes was widespread. By 1856, a northern provincial newspaper contained an advert alluding casually to them, as well as reporting the accidental death of a woman whose dress caught fire as she lit the tapers on a Christmas tree. They had not yet spread down the social scale though, as a report from Berlin in 1858 contrasts the situation there where \"Every family has its own\" with that of Britain, where Christmas trees were still the preserve of the wealthy or the \"romantic\".\nTheir use at public entertainments, charity bazaars and in hospitals made them increasingly familiar however, and in 1906 a charity was set up specifically to ensure even poor children in London slums \"who had never seen a Christmas tree\" would enjoy one that year. Anti-German sentiment after World WarI briefly reduced their popularity but the effect was short-lived, and by the mid-1920s the use of Christmas trees had spread to all classes. In 1933, a restriction on the importation of foreign trees led to the \"rapid growth of a new industry\" as the growing of Christmas trees within Britain became commercially viable due to the size of demand. By 2013, the number of trees grown in Britain for the Christmas market was approximately eight million and their display in homes, shops and public spaces a normal part of the Christmas season.\n\"Georgia\".\nGeorgians have their own traditional Christmas tree called Chichilaki, made from dried up hazelnut or walnut branches that are shaped to form a small coniferous tree. These pale-colored ornaments differ in height from to . Chichilakis are most common in the Guria and Samegrelo regions of Georgia near the Black Sea, but they can also be found in some stores around the capital of Tbilisi.\nGeorgians believe that Chichilaki resembles the famous beard of St. Basil the Great, because Eastern Orthodox Church commemorates St. Basil on 1 January.\n\"The Bahamas\".\nThe earliest reference of Christmas trees being used in The Bahamas dates to January 1864 and is associated with the Anglican Sunday Schools in Nassau, New Providence: \"After prayers and a sermon from the Rev. R. Swann, the teachers and children of St. Agnes', accompanied by those of St. Mary's, marched to the Parsonage of Rev. J. H. Fisher, in front of which a large Christmas tree had been planted for their gratification. The delighted little ones formed a circle around it singing 'Come follow me to the Christmas tree.'\" The gifts decorated the trees as ornaments and the children were given tickets with numbers that matched the gifts. This appears to be the typical way of decorating the trees in 1860s Bahamas. In the Christmas of 1864, there was a Christmas tree put up in the Ladies Saloon in the Royal Victoria Hotel for the respectable children of the neighbourhood. The tree was ornamented with gifts for the children who formed a circle about it and sang the song \"Oats and Beans\". The gifts were later given to the children in the name of Santa Claus.\n\"North America\".\nThe tradition was introduced to North America in the winter of 1781 by Hessian soldiers stationed in the Province of Qu\u00e9bec (1763\u20131791) to garrison the colony against American attack. General Friedrich Adolf Riedesel and his wife, the Baroness von Riedesel, held a Christmas party for the officers at Sorel, Quebec, delighting their guests with a fir tree decorated with candles and fruits.\nThe Christmas tree became very common in the United States of America in the early 19th century. Dating from late 1812 or early 1813, the watercolor sketchbooks of John Lewis Krimmel contain perhaps the earliest depictions of a Christmas tree in American art, representing a family celebrating Christmas Eve in the Moravian tradition. The first published image of a Christmas tree appeared in 1836 as the frontispiece to \"The Stranger's Gift\" by Hermann Bokum. The first mention of the Christmas tree in American literature was in a story in the 1836 edition of \"The Token and Atlantic Souvenir\", titled \"New Year's Day\", by Catherine Maria Sedgwick, where she tells the story of a German maid decorating her mistress' tree. Also, a woodcut of the British royal family with their Christmas tree at Windsor Castle, initially published in \"The Illustrated London News\" in December 1848, was copied in the United States at Christmas 1850, in \"Godey's Lady's Book\". \"Godey's\" copied it exactly, except for the removal of the Queen's tiara and Prince Albert's moustache, to remake the engraving into an American scene. The republished \"Godey's\" image became the first widely circulated picture of a decorated evergreen Christmas tree in America. Art historian Karal Ann Marling called Queen Victoria and Prince Albert, shorn of their royal trappings, \"the first influential American Christmas tree\". Folk-culture historian Alfred Lewis Shoemaker states, \"In all of America there was no more important medium in spreading the Christmas tree in the decade 1850\u201360 than \"Godey's Lady's Book\"\". The image was reprinted in 1860, and by the 1870s, putting up a Christmas tree had become even more common in America.\nPresident Benjamin Harrison and his wife Caroline put up the first White House Christmas tree in 1889.\nSeveral cities in the United States with German connections lay claim to that country's first Christmas tree. Windsor Locks, Connecticut, claims that a Hessian soldier put up a Christmas tree in 1777 while imprisoned at the Noden-Reed House, while the \"First Christmas Tree in America\" is also claimed by Easton, Pennsylvania, where German settlers purportedly erected a Christmas tree in 1816. In his diary, Matthew Zahm of Lancaster, Pennsylvania, recorded the use of a Christmas tree in 1821, leading Lancaster to also lay claim to the first Christmas tree in America. Other accounts credit Charles Follen, a German immigrant to Boston, for being the first to introduce to America the custom of decorating a Christmas tree. In 1847, August Imgard, a German immigrant living in Wooster, Ohio cut a blue spruce tree from a woods outside town, had the Wooster village tinsmith construct a star, and placed the tree in his house, decorating it with paper ornaments, gilded nuts and Kuchen. German immigrant Charles Minnigerode accepted a position as a professor of humanities at the College of William &amp; Mary in Williamsburg, Virginia, in 1842, where he taught Latin and Greek. Entering into the social life of the Virginia Tidewater, Minnigerode introduced the German custom of decorating an evergreen tree at Christmas at the home of law professor St. George Tucker, thereby becoming another of many influences that prompted Americans to adopt the practice at about that time. An 1853 article on Christmas customs in Pennsylvania defines them as mostly \"German in origin\", including the Christmas tree, which is \"planted in a flower pot filled with earth, and its branches are covered with presents, chiefly of confectionary, for the younger members of the family.\" The article distinguishes between customs in different states, however, claiming that in New England generally \"Christmas is not much celebrated\", whereas in Pennsylvania and New York it is.\nWhen Edward H. Johnson was vice president of the Edison Electric Light Company, a predecessor of General Electric, he created the first known electrically illuminated Christmas tree at his home in New York City in 1882. Johnson became the \"Father of Electric Christmas Tree Lights\".\nThe lyrics sung in the United States to the German tune begin \"O Christmas tree...\", giving rise to the mistaken idea that the German word (fir tree) means \"Christmas tree\", the German word for which is instead .\n1935 to present.\nUnder the state atheism of the Soviet Union, the Christmas tree\u2014along with the entire celebration of the Christian holiday\u2014was banned in the country after the October Revolution. However, the government then introduced a \"New-year spruce\" () in 1935 for the New Year holiday. It became a fully secular icon of the New Year holiday: for example, the crowning star was regarded not as a symbol of the Bethlehem Star, but as the Red star. Decorations, such as figurines of airplanes, bicycles, space rockets, cosmonauts, and characters of Russian fairy tales, were produced. This tradition persists after the fall of the USSR, with the New Year holiday outweighing the Christmas (7 January) for a wide majority of Russian people.\nThe \"Peanuts\" TV special \"A Charlie Brown Christmas\" (1965) was influential on the pop culture surrounding the Christmas tree. Aluminum Christmas trees were popular during the early 1960s in the US. They were satirized in the TV special and came to be seen as symbolizing the commercialization of Christmas. The term \"Charlie Brown Christmas tree,\" describing any poor-looking or malformed little tree, also derives from the 1965 TV special, based on the appearance of Charlie Brown's Christmas tree.\nPublic Christmas trees.\nSince the early 20th century, it has become common in many cities, towns, and department stores to put up public Christmas trees outdoors, such as the Macy's Great Tree in Atlanta (since 1948), the Rockefeller Center Christmas Tree in New York City, and the large Christmas tree at Victoria Square in Adelaide.\nThe use of fire retardant allows many indoor public areas to place real trees and be compliant with code. Licensed applicants of fire retardant solution spray the tree, tag the tree, and provide a certificate for inspection.\nThe United States' National Christmas Tree has been lit each year since 1923 on the South Lawn of the White House, becoming part of what evolved into a major holiday event at the White House. President Jimmy Carter lit only the crowning star atop the tree in 1979 in honor of the Americans being held hostage in Iran. This was repeated in 1980, except the tree was fully lit for 417 seconds, one second for each day the hostages had been in captivity.\nDuring most of the 1970s and 1980s, the largest decorated Christmas tree in the world was put up every year on the property of the \"National Enquirer\" in Lantana, Florida. This tradition grew into one of the most spectacular and celebrated events in the history of southern Florida, but was discontinued on the death of the paper's founder in the late 1980s.\nIn some cities, a charity event called the Festival of Trees is organized, in which multiple trees are decorated and displayed.\nThe giving of Christmas trees has also often been associated with the end of hostilities. After the signing of the Armistice in 1918, the city of Manchester, England, sent a tree, and \u00a3500 to buy chocolate and cakes, for the children of the much-bombarded town of Lille in northern France.\nIn some cases, the trees represent special commemorative gifts, such as in Trafalgar Square in London, where the City of Oslo, Norway, presents a tree to the people of London as a token of appreciation for the British support of Norwegian resistance during World War II; in Boston, United States, where the tree is a gift from the province of Nova Scotia, in thanks for rapid deployment of supplies and rescuers to the 1917 ammunition ship explosion that leveled the city of Halifax; and in Newcastle upon Tyne, England, where the main civic Christmas tree is an annual gift from the city of Bergen, Norway, in thanks for the part played by soldiers from Newcastle in liberating Bergen from Nazi occupation. Norway also annually gifts a Christmas tree to Washington, D.C., as a symbol of friendship between Norway and the US and as an expression of gratitude from Norway for the help received from the US during World War II.\nCustoms and traditions.\nSetting up and taking down.\nBoth setting up and taking down a Christmas tree are associated with specific dates; liturgically, this is done through the hanging of the greens ceremony. In many areas, it has become customary to set up one's Christmas tree on Advent Sunday, the first day of the Advent season. Traditionally, however, Christmas trees were not brought in and decorated until the evening of Christmas Eve (24 December), the end of the Advent season and the start of the twelve days of Christmastide. It is customary for Christians in many localities to remove their Christmas decorations on the last day of the twelve days of Christmastide that falls on 5 January\u2014Epiphany Eve (Twelfth Night), although those in other Christian countries remove them on Candlemas, the conclusion of the extended Christmas-Epiphany season (Epiphanytide). According to the first tradition, those who fail to remember to remove their Christmas decorations on Epiphany Eve must leave them untouched until Candlemas, the second opportunity to remove them; failure to observe this custom is considered inauspicious.\nDecorations.\nChristmas ornaments are decorations (usually made of glass, metal, wood, or ceramics) that are used to decorate a Christmas tree. The first decorated trees were adorned with apples, white candy canes and pastries in the shapes of stars, hearts and flowers. Glass baubles were first made in Lauscha, Germany in 1847, and also garlands of glass beads and tin figures that could be hung on trees. The popularity of these decorations fueled the production of glass figures made by highly skilled artisans with clay molds.\nTinsel and several types of garland or ribbon are commonly used as Christmas tree decorations. Silvered saran-based tinsel was introduced later. Delicate mold-blown and painted colored glass Christmas ornaments were a specialty of the glass factories in the Thuringian Forest, especially in Lauscha in the late 19th century, and have since become a large industry, complete with famous-name designers. Baubles are another common decoration, consisting of small hollow glass or plastic spheres coated with a thin metallic layer to make them reflective, with a further coating of a thin pigmented polymer in order to provide coloration.\nLighting with electric lights (Christmas lights or, in the United Kingdom, fairy lights) is commonly done. A tree-topper, typically an angel or star, completes the decoration.\nIn the late 1800s, home-made white Christmas trees were made by wrapping strips of cotton batting around leafless branches creating the appearance of a snow-laden tree.\nIn the 1940s and 1950s, popularized by Hollywood films in the late 1930s, flocking was very popular on the West Coast of the United States. There were home flocking kits that could be used with vacuum cleaners. In the 1980s, some trees were sprayed with fluffy white flocking to simulate snow.\nSymbolism and interpretations.\nThe earliest legend of the origin of a fir tree becoming a Christian symbol dates back to 723 AD, involving Saint Boniface as he was evangelizing Germany. It is said that at a pagan gathering in Geismar, where a group of people dancing under a decorated oak tree were about to sacrifice a baby in the name of Thor, Saint Boniface took an axe and called on the name of Jesus. In one swipe, he managed to take down the entire oak tree, to the crowd's astonishment. Behind the fallen tree was a baby fir tree. Boniface said, \"let this tree be the symbol of the true God, its leaves are ever green and will not die.\" The tree's needles pointed heavenward and it was shaped triangularly, representing the Holy Trinity.\nWhen decorating the Christmas tree, many individuals place a star at the top of the tree, symbolizing the Star of Bethlehem. It became popular for people to also use an angel to top the Christmas tree in order to symbolize the angels mentioned in the accounts of the Nativity of Jesus. Additionally, in the context of a Christian celebration of Christmas, the evergreen Christmas tree symbolizes eternal life; the candles or lights on the tree represent Christ as the light of the world.\nProduction.\nEach year, 33 to 36 million Christmas trees are produced in America, and 50 to 60 million are produced in Europe. In 1998, there were about 15,000 growers in America (a third of them \"choose and cut\" farms). In that same year, it was estimated that Americans spent $1.5billion on Christmas trees. By 2016, that had climbed to $2.04billion for natural trees and a further $1.86billion for artificial trees. In Europe, 75 million trees worth \u20ac2.4billion ($3.2 billion) are harvested annually.\nNatural trees.\nThe most commonly used species are fir (\"Abies\"), which have the benefit of not shedding their needles when they dry out, as well as retaining good foliage color and scent; but species in other genera are also used.\nIn northern Europe most commonly used are:\nIn North America, Central America, South America and Australia most commonly used are:\nSeveral other species are used to a lesser extent. Less-traditional conifers are sometimes used, such as giant sequoia, Leyland cypress, Monterey cypress, and eastern juniper. Various types of spruce tree are also used for Christmas trees (including the blue spruce and, less commonly, the white spruce); but spruces begin to lose their needles rapidly upon being cut, and spruce needles are often sharp, making decorating uncomfortable. Virginia pine is still available on some tree farms in the southeastern United States; however, its winter color is faded. The long-needled eastern white pine is also used there, though it is an unpopular Christmas tree in most parts of the country, owing also to its faded winter coloration and limp branches, making decorating difficult with all but the lightest ornaments. Norfolk Island pine is sometimes used, particularly in Oceania, and in Australia, some species of the genera \"Casuarina\" and \"Allocasuarina\" are also occasionally used as Christmas trees. But, by far, the most common tree is the Pinus radiata Monterey pine. \"Adenanthos sericeus\" or Albany woolly bush is commonly sold in southern Australia as a potted living Christmas tree. Hemlock species are generally considered unsuitable as Christmas trees due to their poor needle retention and inability to support the weight of lights and ornaments.\nSome trees, frequently referred to as \"living Christmas trees\", are sold live with roots and soil, often from a plant nursery, to be stored at nurseries in planters or planted later outdoors and enjoyed (and often decorated) for years or decades. Others are produced in a container and sometimes as topiary for a porch or patio. However, when done improperly, the combination of root loss caused by digging, and the indoor environment of high temperature and low humidity is very detrimental to the tree's health; additionally, the warmth of an indoor climate will bring the tree out of its natural winter dormancy, leaving it little protection when put back outside into a cold outdoor climate. Often Christmas trees are a large attraction for living animals, including mice and spiders. Thus, the survival rate of these trees is low. However, when done properly, replanting provides higher survival rates.\nEuropean tradition prefers the open aspect of naturally grown, unsheared trees, while in North America (outside western areas where trees are often wild-harvested on public lands) there is a preference for close-sheared trees with denser foliage, but less space to hang decorations.\nIn the past, Christmas trees were often harvested from wild forests, but now almost all are commercially grown on tree farms. Almost all Christmas trees in the United States are grown on Christmas tree farms where they are cut after about ten years of growth and new trees planted. According to the United States Department of Agriculture's agriculture census for 2007, 21,537 farms were producing conifers for the cut Christmas tree market in America, were planted in Christmas trees.\nThe life cycle of a Christmas tree from the seed to a tree takes, depending on species and treatment in cultivation, between eight and twelve years. First, the seed is extracted from cones harvested from older trees. These seeds are then usually grown in nurseries and then sold to Christmas tree farms at an age of three to four years. The remaining development of the tree greatly depends on the climate, soil quality, as well as the cultivation and how the trees are tended by the Christmas tree farmer. One issue that farmers face is the destruction of pine trees by pests, such as \"T. piniperda.\"\nArtificial trees.\nThe first artificial Christmas trees were developed in Germany during the 19th century, though earlier examples exist. These \"trees\" were made using goose feathers that were dyed green, as one response by Germans to continued deforestation. Feather Christmas trees ranged widely in size, from a small tree to a large tree sold in department stores during the 1920s. Often, the tree branches were tipped with artificial red berries which acted as candle holders.\nOver the years, other styles of artificial Christmas trees have evolved and become popular. In 1930, the U.S.-based Addis Brush Company created the first artificial Christmas tree made from brush bristles. Another type of artificial tree is the aluminum Christmas tree, first manufactured in Chicago in 1958, and later in Manitowoc, Wisconsin, where the majority of the trees were produced. Most modern artificial Christmas trees are made from plastic recycled from used packaging materials, such as polyvinyl chloride (PVC). Approximately 10% of artificial Christmas trees are using virgin suspension PVC resin; despite being plastic most artificial trees are not recyclable or biodegradable.\nTrends developed in the early 2000s included optical fiber Christmas trees, which come in two major varieties; one resembling a traditional Christmas tree. One Dallas-based company offers \"holographic mylar\" trees in many hues. Tree-shaped objects made from such materials as cardboard, glass, ceramic or other materials can be found in use as tabletop decorations. Upside-down artificial Christmas trees became popular for a short time and were originally introduced as a marketing gimmick; they allowed consumers to get closer to ornaments for sale in retail stores and opened up floor space for more products.\nArtificial trees became increasingly popular during the late 20th century. Users of artificial Christmas trees assert that they are more convenient, and, because they are reusable, much cheaper than their natural alternative. They are also considered much safer, as natural trees can be a significant fire hazard. Between 2001 and 2007, artificial Christmas tree sales in the U.S. jumped from 7.3 million to 17.4 million. Currently, it is estimated that around 58% of Christmas trees used in the United States are artificial, while numbers in the United Kingdom are indicated to be around 66%.\nEnvironmental issues.\nThe debate about the environmental impact of artificial trees is ongoing. Generally, natural tree growers contend that artificial trees are more environmentally harmful than their natural counterparts. However, trade groups such as the American Christmas Tree Association, claim that the PVC used in Christmas trees is chemically and mechanically stable, does not affect human health, and has excellent recyclable properties.\nLive trees are typically grown as a crop and replanted in rotation after cutting, often providing suitable habitat for wildlife. Alternately, live trees can be donated to livestock farmers who find that such trees uncontaminated by chemical additives are excellent fodder. In some cases, management of Christmas tree crops can result in poor habitat since it sometimes involves heavy input of pesticides.\nConcerns have been raised by arborists about people cutting down old and rare conifers, such as the \"Keteleeria evelyniana\" for Christmas trees.\nReal or cut trees are used only for a short time, but can be recycled and used as mulch, wildlife habitat, or used to prevent erosion. Real trees are carbon-neutral, they emit no more carbon dioxide by being cut down and disposed of than they absorb while growing. However, emissions can occur from farming activities and transportation. An independent life-cycle assessment study, conducted by a firm of experts in sustainable development, states that a natural tree will generate of greenhouse gases every year (based on purchasing from home) whereas the artificial tree will produce over its lifetime. Some people use living Christmas or potted trees for several seasons, providing a longer life cycle for each tree. Living Christmas trees can be purchased or rented from local market growers. Rentals are picked up after the holidays, while purchased trees can be planted by the owner after use or donated to local tree adoption or urban reforestation services. Smaller and younger trees may be replanted after each season, with the following year running up to the next Christmas allowing the tree to carry out further growth.\nThe use of lead stabilizer in Chinese imported trees has been an issue of concern among politicians and scientists over recent years. A 2004 study found that while in general artificial trees pose little health risk from lead contamination, there do exist \"worst-case scenarios\" where major health risks to young children exist. A 2008 United States Environmental Protection Agency report found that as the PVC in artificial Christmas trees aged it began to degrade. The report determined that of the fifty million artificial trees in the United States approximately twenty million were nine or more years old, the point where dangerous lead contamination levels are reached. A professional study on the life-cycle assessment of both real and artificial Christmas trees revealed that one must use an artificial Christmas tree at least twenty years to leave an environmental footprint as small as the natural Christmas tree.\nReligious issues.\nUnder the Marxist-Leninist doctrine of state atheism in the Soviet Union, after its foundation in 1917, Christmas celebrations\u2014along with other religious holidays\u2014were prohibited as a result of the Soviet anti-religious campaign. The League of Militant Atheists encouraged school pupils to campaign against Christmas traditions, among them being the Christmas tree, as well as other Christian holidays, including Easter; the League established an anti-religious holiday to be the 31st of each month as a replacement. With the Christmas tree being prohibited in accordance with Soviet anti-religious legislation, people supplanted the former Christmas custom with New Year's trees. In 1935, the tree was brought back as New Year tree and became a secular, not a religious holiday.\nPope John Paul II introduced the Christmas tree custom to the Vatican in 1982. Although at first disapproved of by some as out of place at the centre of the Roman Catholic Church, the Vatican Christmas Tree has become an integral part of the Vatican Christmas celebrations, and in 2005 Pope Benedict XVI spoke of it as part of the normal Christmas decorations in Catholic homes. In 2004, Pope John Paul called the Christmas tree a symbol of Christ. This very ancient custom, he said, exalts the value of life, as in winter what is evergreen becomes a sign of undying life, and it reminds Christians of the \"tree of life\", an image of Christ, the supreme gift of God to humanity. In the previous year he said: \"Beside the crib, the Christmas tree, with its twinkling lights, reminds us that with the birth of Jesus the tree of life has blossomed anew in the desert of humanity. The crib and the tree: precious symbols, which hand down in time the true meaning of Christmas.\" The Catholic Church's official \"Book of Blessings\" has a service for the blessing of the Christmas tree in a home. The Episcopal Church in \"The Anglican Family Prayer Book\", which has the imprimatur of The Rt. Rev. Catherine S. Roskam of the Anglican Communion, has long had a ritual titled \"Blessing of a Christmas Tree\", as well as \"Blessing of a Cr\u00e8che\", for use in the church and the home; family services and public liturgies for the blessing of Christmas trees are common in other Christian denominations as well.\nChrismon trees, which find their origin in the Lutheran Christian tradition though now used in many Christian denominations such as the Catholic Church and Methodist Church, are used to decorate churches during the liturgical season of Advent; during the period of Christmastide, Christian churches display the traditional Christmas tree in their sanctuaries.\nIn 2005, the city of Boston renamed the spruce tree used to decorate the Boston Common a \"Holiday Tree\" rather than a \"Christmas Tree\". The name change was reversed after the city was threatened with several lawsuits."}
{"id": "7772", "revid": "44973490", "url": "https://en.wikipedia.org/wiki?curid=7772", "title": "Carrier battle group", "text": "A carrier battle group (CVBG) is a naval fleet consisting of an aircraft carrier capital ship and its large number of escorts, together defining the group. The \"CV\" in \"CVBG\" (Cruiser \"Voler\") is the United States Navy hull classification code for an aircraft carrier.\nThe first naval task forces built around carriers appeared just prior to and during World War II. The Imperial Japanese Navy (IJN) was the first to assemble many carriers into a single task force, known as the \"Kido Butai\". This task force was used with devastating effect in the Japanese attack on Pearl Harbor. The Kido Butai operated as the IJN's main carrier battle group until four of its carriers were sunk at the Battle of Midway. In contrast, the United States Navy deployed its large carriers in separate formations, with each carrier assigned its own cruiser and destroyer escorts. These single-carrier formations would often be paired or grouped together for certain assignments, most notably the Battle of the Coral Sea and Midway. By 1943, however, large numbers of fleet and light carriers became available, which required larger formations of three or four carriers. These groups eventually formed the Fast Carrier Task Force, which became the primary battle unit of the U.S. Third and Fifth Fleets.\nWith the construction of the large \"supercarriers\" of the Cold War era, the practice of operating each carrier in a single formation was revived. During the Cold War, the main role of the CVBG in case of conflict with the Soviet Union would have been to protect Atlantic supply routes between the United States and its NATO allies in Europe, while the role of the Soviet Navy would have been to interrupt these sea lanes, a fundamentally easier task. Because the Soviet Union had no large carriers of its own, a situation of dueling aircraft carriers would have been unlikely. However, a primary mission of the Soviet Navy's attack submarines was to track every allied battle group and, on the outbreak of hostilities, sink the carriers. Understanding this threat, the CVBG expended enormous resources in its own anti-submarine warfare mission.\nCarrier battle groups in crises.\nIn the late 20th and early 21st centuries, most uses of carrier battle groups by the United States as well as that of other Western nations have been in situations where their use has been uncontested by other comparable forces. During the Cold War, an important battle scenario was an attack against a CVBG using numerous anti-ship missiles.\n1956 Suez Crisis.\nBritish and French carrier battle groups were involved in the 1956 Suez Crisis.\n1971 Indo-Pakistan war.\nDuring the Indo-Pakistani War of 1971, India used its carrier strike group centered on to impose a naval blockade on East Pakistan. Air strikes were carried out initially on shipping in the harbors of Chittagong and Cox's Bazar, sinking or incapacitating most ships there. Further strikes were carried out on Cox's Bazar from 60 nautical miles (110\u00a0km) offshore. On the evening of 4 December, the air group again struck Chittagong harbor. Later strikes targeted Khulna and the Port of Mongla. Air strikes continued until 10 December 1971.\n1982 Falklands War.\nThe first attempted use of anti-ship missiles against a carrier battle group was part of Argentina's efforts against British armed forces during the Falklands War. This was the last conflict so far in which opposing belligerents employed aircraft carriers, although Argentina made little use of its sole carrier, , which was originally built in the United Kingdom as HMS \"Venerable\" and later served with the Royal Netherlands Navy (1948\u20131968).\nLebanon.\nThe United States Sixth Fleet assembled a force of three carrier battle groups and a battleship during the Lebanese Civil War in 1983. Daily reconnaissance flights were flown over the Bekaa Valley and a strike was flown against targets in the area resulting in loss of an A-6 Intruder and an A-7 Corsair.\nGulf of Sidra.\nCarrier battle groups routinely operated in the Gulf of Sidra inside the \"Line of Death\" proclaimed by Libya resulting in aerial engagements in 1981, 1986 and 1989 between U.S. Navy Tomcats and Libyan Su-22 aircraft, SA-5 surface-to-air missiles and MiG-23 fighters. During the 1986 clashes, three carrier battle groups deployed to the Gulf of Sidra and ultimately two of them conducted strikes against Libya in Operation El Dorado Canyon.\n2011 military intervention in Libya.\nDuring the international military intervention in the 2011 Libyan civil war, the French Navy deployed its aircraft carrier, , off Libya. The \"Charles de Gaulle\" was accompanied by several frigates as , , , the replenishment tanker \"Meuse\" and two nuclear attack submarines.\nApplications.\nChina.\nChina plans to set up several carrier battle groups in the future. At present China's two aircraft carriers, the \"Liaoning\" and \"Shandong\", use Type 055 destroyers for area air defence with anti-submarine warfare, Type 052C or Type 052D destroyers for air defense, Type 054A frigates for anti-submarine and anti-ship warfare, 1\u20132 Type 093 nuclear attack submarines, and 1 Type 901 supply ship. China is currently building a third carrier, as well as a nuclear-powered fourth carrier planned for construction and expected to be completed by the late 2020s. China is also building a new larger class of air defense destroyers, the Type 055.\nFrance.\nThe only serving French carrier is the , which also serves as the flagship of the Marine Nationale. The carrier battle group of the Force d'Action Navale is known as the \"Groupe A\u00e9ronaval\" (GAN) and is usually composed, in addition to the aircraft carrier, of:\nThis group is commanded by a rear admiral (contre-amiral, in French) on board the aircraft carrier. The commanding officer of the air group (usually a \u2014equivalent to commander) is subordinate to the commanding officer of the aircraft carrier, a senior captain. The escort destroyers (called frigates in the French denomination) are commanded by more junior captains.\nFrance also operates three s. While incapable of operating fixed-winged aircraft, they function as helicopter carriers and form the backbone of France's amphibious force. These ships are typically escorted by the same escorts the \"Charles De Gaulle\" uses.\nIndia.\nIndian Navy has operated all types of aircraft carriers including CATOBAR configured \"Vikrant\", STOVL configured \"Viraat\" and STOBAR configured \"Vikramaditya\" and \"Vikrant\" (2013) and CBGs centered on them. The Indian Navy has been operating carrier battle groups since 1961, with its first carrier battle group formed around the now decommissioned . was an updated \"Centaur\"-class light carrier originally built for the Royal Navy as , which was laid down in 1944 and commissioned in 1959. It was purchased by India in May 1987, and was decommissioned in March 2017. India commissioned in 2013 followed by the new in 2022. INS \"Vikramaditya\" is the modified , INS \"Vikrant\" is the first indigenous aircraft carrier built in India. India plans to have three carrier battle groups by 2035, each centered on \"Vikrant\", \"Vikramaditya\" and , another planned carrier. As of 2023, the Indian Navy operates two carrier battle groups centred on INS Vikramaditya and INS Vikrant.\nThe Indian Navy's carrier battle group centred on \"Viraat\" consisted of two destroyers, usually of the (previously s), two or more frigates, usually of the , \"Godavari\" or \"Nilgiri\" classes, and one support ship.\nThe Carrier Battle Group (CBG) led by INS \"Vikramaditya\" includes Kolkata-class destroyers, Talwar-class frigates and INS Deepak among others. While the independent CBG of INS \"Vikrant\" is expected to consist of Visakhapatnam-class destroyers, Nilgiri-class frigates and \"Kamorta\"-class corvettes and INS Shakti.\nItaly.\nThe CVS\u2013ASW (Aircraft Carrier with Anti-Submarine Warfare) is Italy's first carrier. The battle group based in Taranto called COMFORAL is formed by the carrier \"Giuseppe Garibaldi\", two s, two support ships \"Etna\" and \"Elettra\", and three amphibious/support ships (\"San Giusto\", \"San Marco\" and \"San Giorgio\").\nAfter 2010, the Italian battle group will be formed by the new , 5\u20136 new warships (including destroyers \"Horizon\" and frigates FREMM), one new support ship, some minehunters and new submarines (the COMFORAL will be a reserve group).\nRussia.\n\"Admiral Kuznetsov\" has been observed sailing together with a (CBGN), (CG), (ASuW), (ASW) and \"Krivak\" I/II FFG (ASW). These escorts, especially the heavily armed \"Kirov\"-class battlecruiser, use advanced sensors and carry a variety of weaponry. During \"Admiral Kuznetsov\"s deployment to Syria in November 2016 on her first combat tour, the carrier was escorted by a pair of Udaloy-class destroyers and a Kirov-class battlecruiser en route, while additional Russian Navy warships met her off Syria.\n\"Admiral Kuznetsov\" is designed specifically to sail alone and carries greater firepower than her U.S. counterparts. This includes 12x SS-N-19 'Shipwreck' (long range, high speed, sea-skimming) SSMs, 24x VLS units loaded with 192 SA-N-9 'Gauntlet' SAMs, and 8x Kashtan CIWS with dual 30\u00a0mm guns, and 8x AK-630 CIWS. Compared to the 4x Phalanx CIWS and 4x Sea Sparrow launchers, each with 8 missiles carried by the \"Nimitz\"-class, \"Admiral Kuznetsov\" is well armed for both air-defence and offensive operations against hostile shipping.\nUnited Kingdom.\nAs one of the pioneers of aircraft carriers, the Royal Navy has maintained a carrier strike capability since the commissioning of in 1918. However, the capability was temporarily lost between 2010 and 2018, following the retirement of the and Harrier GR9s. During this period, the Royal Navy worked to regenerate its carrier strike capability based on the Carrier-Enabled Power Projection (CEPP) concept by ordering two \"Queen Elizabeth\"-class aircraft carriers and the F-35B Lightning to operate from them. To maintain its skills and experience, the Royal Navy embedded personnel and ships with partner navies, in particular the United States Navy.\nIn 2017, the first \"Queen Elizabeth\"-class aircraft carrier entered service followed by her sister ship in 2019. The first carrier strike group took to sea in September 2019 as part of an exercise known as \"Westlant 19\". HMS \"Queen Elizabeth\" and her air group of F-35B Lightning jets operated alongside two surface escorts and a fleet tanker off the east coast of the United States. The deployment was in preparation for the first operational deployment in 2021, which is expected to involve HMS \"Queen Elizabeth\" alongside four Royal Navy escorts, two support ships and a submarine.\nUnder current plans, a Royal Navy carrier strike group will typically comprise a \"Queen Elizabeth\"-class aircraft carrier, two air defence destroyers, two anti-submarine frigates, a submarine, solid stores ship and a fleet tanker, however the composition varies depending on the operational tasking. While \"Queen Elizabeth\"'s initial deployment will be as part of an all-British carrier group, it is envisaged in the longer term that the UK's carriers will usually form the centre of a multi-national operation \u2013 in 2018, it was announced that the British and Dutch governments had come to an agreement that would see escort vessels of the Royal Netherlands Navy operating as part of the UK Carrier Strike Group. Command of the UK carrier strike group is the responsibility of Commander United Kingdom Carrier Strike Group. A June 2020 National Audit Office report however provided a critical review of the forthcoming Carrier Strike Group, especially noting the delay to the Crowsnest system.\nUnited States.\nCarrier strike group.\nIn modern United States Navy carrier air operations, a carrier strike group (CSG) normally consists of 1 aircraft carrier, 1 guided missile cruiser (for air defense), 2 LAMPS-capable warships (focusing on anti-submarine and surface warfare), and 1\u20132 anti-submarine destroyers or frigates. The large number of CSGs used by the United States reflects, in part, a division of roles and missions allotted during the Cold War, in which the United States assumed primary responsibility for blue-water operations and for safeguarding supply lines between the United States and Europe, while the NATO allies assumed responsibility for less costly brown- and green-water operations. The CSG has replaced the old term of carrier battle group (CVBG or CARBATGRU). The US Navy maintains 11 carrier strike groups, 10 of which are based in the United States and one that is forward deployed in Yokosuka, Japan.\nExpeditionary strike group.\nAn expeditionary strike group is composed of an amphibious assault ship (LHA/LHD), a dock landing ship (LSD), an amphibious transport dock (LPD), a Marine expeditionary unit, AV-8B Harrier II or, more recently Lockheed Martin F-35B Lightning II aircraft, CH-53E Super Stallion and CH-46E Sea Knight helicopters or, more recently, MV-22B tiltrotors. Cruisers, destroyers and attack submarines are deployed with either an Expeditionary Strike Group or a Carrier Strike Group.\nBattleship battle group.\nDuring the period when the American navy recommissioned all four of its s, it sometimes used a similar formation centered on a battleship, referred to as a battleship battle group. It was alternately referred to as a surface action group.\nThe battleship battle group typically consisted of one modernized battleship, one , one or , one , three s and one auxiliary ship such as a replenishment oiler.\nSurface action group.\nA surface action group is \"a temporary or standing organization of combatant ships, other than carriers, tailored for a specific tactical mission\".\nUnderway replenishment.\nSince its origins, the viability of the carrier battle group has been dependent on its ability to remain at sea for extended periods. Specialized ships were developed to provide underway replenishment of fuel (for the carrier and its aircraft), ordnance, and other supplies necessary to sustain operations. Carrier battle groups devote a great deal of planning to efficiently conduct underway replenishment to minimize the time spent conducting replenishment. The carrier can also provide replenishment on a limited basis to its escorts, but typically a replenishment ship such as a fast combat support ship (AOE) or replenishment oiler (AOR) pulls alongside a carrier and conducts simultaneous operations with the carrier on its port side and one of the escorts on its starboard side. The advent of the helicopter provides the ability to speed replenishment by lifting supplies at the same time that fueling hoses and lines are delivering other goods.\nDebate on future viability.\nThere is debate in naval warfare circles as to the viability of carrier battle groups in 21st century naval warfare. Proponents of the CVBG argue that it provides unmatched firepower and force projection capabilities. Opponents argue that CVBGs are increasingly vulnerable to arsenal ships and cruise missiles, especially those with supersonic or even hypersonic flight and the ability to perform radical trajectory changes to avoid anti-missile systems. It is also noted that CVBGs were designed for Cold War scenarios, and are less useful in establishing control of areas close to shore. It is argued however that such missiles and arsenal ships pose no serious threat as they would be eliminated due to increasing improvement in ship defenses such as Cooperative Engagement Capability (CEC), DEW technology and missile technology.\nAdditionally, carrier battle groups proved to be vulnerable to diesel-electric submarines owned by many smaller naval forces. Examples are the German \"U24\" of the conventional 206 class which in 2001 \"sank\" USS \"Enterprise\" during the exercise JTFEX 01-2 in the Caribbean Sea by firing flares and taking a photograph through its periscope or the Swedish \"Gotland\" which managed the same feat in 2006 during JTFEX 06-2 by penetrating the defensive measures of Carrier Strike Group 7 undetected and snap several pictures of .\nHowever, carriers have been called upon to be first responders even when conventional land-based aircraft were employed. During Desert Shield, the U.S. Navy sortied additional carriers to augment the on-station assets, eventually maintaining six carriers for Desert Storm. Although the U.S. Air Force sent fighters such as the F-16 to theater in Desert Shield, they had to carry bombs with them as no stores were in place for sustained operations, whereas the carriers arrived on scene with full magazines and had support ships to allow them to conduct strikes indefinitely.\nThe Global War on Terror has shown the flexibility and responsiveness of the carrier on multiple occasions when land-based air was not feasible or able to respond in a timely fashion. After the 11 September terrorist attacks on the U.S., carriers immediately headed to the Arabian Sea to support Operation Enduring Freedom and took up station, building to a force of three carriers. Their steaming location was closer to the targets in Afghanistan than any land-based assets and thereby more responsive. The was adapted to be a support base for special operations helicopters. Carriers were used again in Operation Iraqi Freedom and even provided aircraft to be based ashore on occasion and have done so periodically when special capabilities are needed. This precedent was established during World War II in the Battle of Guadalcanal.\nRegardless of the debate over viability, the United States has made a major investment in the development of a new carrier class\u2014the s (formerly designated CVN-X, or the X Carrier)\u2014to replace the existing s. The new \"Ford\"-class carriers are designed to be modular and are easily adaptable as technology and equipment needed on board changes."}
{"id": "7773", "revid": "237572", "url": "https://en.wikipedia.org/wiki?curid=7773", "title": "Boeing Vertol CH-46 Sea Knight", "text": "The Boeing Vertol CH-46 Sea Knight is an American medium-lift tandem-rotor transport helicopter powered by twin turboshaft engines. It was designed by Vertol and manufactured by Boeing Vertol following Vertol's acquisition by Boeing.\nDevelopment of the Sea Knight, which was originally designated by the firm as the Vertol Model 107, commenced during 1956. It was envisioned as a successor to the first generation of rotorcraft, such as the H-21 \"Flying Banana\", that had been powered by piston engines; in its place, the V-107 made use of the emergent turboshaft engine. On 22 April 1958, the V-107 prototype performed its maiden flight. During June 1958, the US Army awarded a contract for the construction of ten production-standard aircraft, designated as the YHC-1A, based on the V-107; this initial order was later cut down to three YHC-1As. During 1961, the US Marine Corps (USMC), which had been studying its requirements for a medium-lift, twin-turbine cargo/troop assault helicopter, selected Boeing Vertol's Model 107M as the basis from which to manufacture a suitable rotorcraft to meet their needs. Known colloquially as the \"Phrog\" and formally as the \"Sea Knight\", it was operated across all US Marine Corps' operational environments between its introduction during the Vietnam War and its frontline retirement during 2014.\nThe Sea Knight was operated by the USMC to provide all-weather, day-or-night assault transport of combat troops, supplies and equipment until it was replaced by the MV-22 Osprey during the 2010s. The USMC also used the helicopter for combat support, search and rescue (SAR), casualty evacuation and Tactical Recovery of Aircraft and Personnel (TRAP). The Sea Knight also functioned as the US Navy's standard medium-lift utility helicopter prior to the type being phased out of service in favor of the MH-60S Knighthawk during the early 2000s. Several overseas operators acquired the rotorcraft as well. Canada operated the Sea Knight, designated as CH-113; the type was used predominantly in the SAR role until 2004. Other export customers for the type included Japan, Sweden, and Saudi Arabia. The commercial version of the rotorcraft is the BV 107-II, commonly referred to simply as the \"Vertol\". The Sea Knight is an amphibious helicopter, able to land directly on calm water and float, but only for a few hours.\nDevelopment.\nOrigins.\nDuring the 1940s and 1950s, American rotorcraft manufacturer Piasecki Helicopter emerged as a pioneering developer of tandem-rotor helicopters; perhaps the most famous of these being the piston-powered H-21 \"Flying Banana\", an early utility and transport helicopter. During 1955, Piasecki was officially renamed as Vertol Corporation (standing for vertical take-off and landing); it was around this time that work commenced on the development of a new generation of tandem rotor helicopter. During 1956, the new design received the internal company designation of \"Vertol Model 107\", or simply \"V-107\"; this rotorcraft differed from its predecessors by harnessing the newly developed turboshaft engine instead of piston-based counterparts. During that year, construction of a prototype, powered by a pair of Lycoming T53 turboshaft engines, each one being capable of producing 877 shp (640\u00a0kW), commenced.\nOn 22 April 1958, the V-107 prototype performed its maiden flight. In order to garner publicity for the newly developed rotorcraft, it was decided to use the prototype to conduct a series of publicised flight demonstrations during a tour across the United States and several overseas nations. During June 1958, it was announced that the U.S. Army had awarded a contract to Vertol for the construction of ten production-standard aircraft based on the V-107, which were designated \"YHC-1A\". However, this order was later decreased to three helicopters; according to aviation author Jay P. Spenser, the cutback had been enacted in order that the U.S. Army would be able to divert funds for the development of the rival \"V-114\" helicopter, which was also a turbine-powered tandem rotor design but substantially larger than the V-107. All of the U.S. Army's three YHC-1As were powered by pairs of GE-T-58 engines. During August 1959, the first YHC-1A-model rotorcraft conducted its first flight; independently, it was shortly followed by the maiden flight of an improved model intended for the commercial and export markets, designated \"107-II\".\nDuring 1960, the U.S. Marine Corps evolved a requirement for a medium-lift, twin-turbine troop/cargo assault helicopter to replace the various piston-engined types that were then in widespread use with the service. That same year, American aviation company Boeing acquired Vertol, after which the group was consequently renamed Boeing Vertol. Following a competition between several competing designs, during early 1961, it was announced that Boeing Vertol had been selected to manufacture its model 107M for the U.S. Marine Corps, where it was designated \"HRB-1\". During 1962, the U.S. Air Force placed its own order for 12 \"XCH-46B Sea Knight\" helicopters, which used the \"XH-49A\" designation; however, the service later decided to cancel the order due to delays in its delivery; instead, the U.S. Air Force opted to procure the rival Sikorsky S-61R in its place.\nFollowing the Sea Knight's first flight in August 1962, the military designation was changed to \"CH-46A\". During November 1964, the introduction of the Marines' CH-46A and the Navy's UH-46As commenced. The UH-46A variant was a modified version of the rotorcraft to perform the vertical replenishment mission. The CH-46A was equipped with a pair of T58-GE8-8B turboshaft engines, each being rated at 1,250 shp (930\u00a0kW); these allowed the Sea Knight to carry up to 17 passengers or a maximum of 4,000 pounds (1,815\u00a0kg) of cargo.\nFurther developments.\nDuring 1966, production of the improved \"CH-46D\" commenced with deliveries following shortly thereafter. This model featured various improvements, including modified rotor blades and the adoption of more powerful T58-GE-10 turboshaft engines, rated at each. The increased power of these new engines allowed the CH-46D to carry an increased payload, such as up to 25 troops or a maximum of of cargo. During late 1967, the improved model was introduced to the Vietnam theater, where it supplemented the U.S. Marine Corps' existing CH-46A fleet, which had proven to be relatively unreliable and problematic in service. Along with the USMC's CH-46Ds, the U.S. Navy also acquired a small number of UH-46Ds for ship resupply purposes. In addition, approximately 33 CH-46As were progressively re-manufactured to the CH-46D standard.\nBetween 1968 and 1971, the U.S. Marine Corps received a number of CH-46F standard rotorcraft. This model retained the T58-GE-10 engines used on the CH-46D while featuring revised avionics and featured a number of other modifications. The CH-46F was the final production model of the type. During its service life, the Sea Knight received a variety of upgrades and modifications. Over time, the majority of the U.S. Marine Corps' Sea Knights were upgraded to the improved CH-46E standard. This model featured fiberglass rotor blades, reinforcement measures throughout the airframe, along with the refitting of further uprated T58-GE-16 engines, capable of producing each; in addition, several CH-46Es were modified to double their maximum fuel capacity. Starting in the mid-1990s, the Dynamic Component Upgrade (DCU) programmes was enacted, focusing on the implementation of strengthened drive systems and modified rotor controls.\nThe commercial variant, the \"BV 107-II\", was first ordered by New York Airways during 1960. During July 1962, they took delivery of their first three aircraft, which was configured to seat up to 25 passengers. During 1965, Boeing Vertol sold the manufacturing rights of the 107 to Japanese conglomerate Kawasaki Heavy Industries. Under this arrangement, all Model 107 civilian and military aircraft built in Japan were referred to by the \"KV 107\" designation. On 15 December 2006, Columbia Helicopters, Inc acquired the type certificate for the BV 107-II, and with the help of Piasecki eventually developed an original design, the \"Model 107-III\", remanufactured from older airframes. This model features new manufactured CT58-GE-16 engines, the commercial version of the upgraded engines used for the CH-46E as well as modernized avionics including a glass cockpit.\nDesign.\nThe \"Boeing Vertol CH-46 Sea Knight\" is a medium-lift tandem-rotor transport helicopter, furnished with a set of counter-rotating main rotors in a tandem-rotor configuration. It was typically powered by a pair of General Electric T58 turboshaft engines, which were mounted on each side of the rear rotor pedestal; power to the forward rotor was transferred from the rear-mounted engines via a drive shaft. For redundancy, both engines are coupled so that either one would be capable of powering both of the main rotors in the event of a single engine failure or a similar emergency situation. Each of the rotors feature three blades, which can be folded to better facilitate storage and naval operations. The CH-46 features a fixed tricycle landing gear, complete with twin wheels on all three legs of the landing gear; this configuration results in a nose-up stance, helping to facilitate cargo loading and unloading. Two of the main landing gear were installed within protruding rear sponsons; the free interior space of the sponsons are also used to house fuel tanks, possessing a total capacity of 350 US gallons (1,438 L).\nThe interior of the CH-46 was largely taken up by its cargo bay, complete with a rear loading ramp that could be removed or left open in flight for the carriage of extended cargoes or for parachute drops. Various furnishings were normally provided to aid in its use as a utility rotorcraft, such as an internal winch mounted within the forward cabin, which can be used to assisting loading by pulling external cargo on pallets into the aircraft via the ramp and rollers, and an optionally-attached belly-mounted cargo hook, which would be usually rated at for carrying cargoes externally underneath the Sea Knight; despite the hook having been rated at , this was safety restricted to less payload as they got older. When operated in a typical configuration, the CH-46 would usually be operated by a crew of three; a larger crew could be accommodated when required, which would be dependent upon mission specifics. For example, a search and rescue (SAR) variant would usually carry a crew of five (Pilot, Co-Pilot, Crew Chief, Swimmer, and Medic) to facilitate all aspects of such operations. For self-defense, a pintle-mounted 0.50 in (12.7\u00a0mm) M2 Browning machine gun could be mounted on each side of the helicopter. Service in southeast Asia resulted in the addition of armor along with the machine guns.\nThe CH-46 was a partially amphibious helicopter, and could land directly on water and rest for up to two hours in calm water. The rear sponsons hold two of the three landing gear units as well as self-sealing fuel tanks.\nOperational history.\nUnited States.\nKnown colloquially as the \"Phrog\", the Sea Knight was used in all U.S. Marine operational environments between its introduction during the Vietnam War and its retirement in 2015. The type's longevity and reputation for reliability led to mantras such as \"phrogs phorever\" and \"never trust a helicopter under 30\". CH-46s transported personnel, evacuated wounded, supplied forward arming and refueling points (FARP), performed vertical replenishment, search and rescue, recovered downed aircraft and crews and other tasks.\nVietnam War.\nDuring the Vietnam War, the CH-46 was one of the prime US Marine troop transport helicopters in the theater, slotting between the smaller Bell UH-1 Iroquois and larger Sikorsky CH-53 Sea Stallion and progressively replacing the UH-34. CH-46 operations were plagued by major technical problems; the engines, being prone to foreign object damage (FOD) from debris being ingested when hovering close to the ground and subsequently suffering a compressor stall, had a lifespan as low as 85 flight hours; on 21 July 1966, all CH-46s were grounded until more efficient filters had been fitted.\nOn 3 May 1967, a CH-46D at Marine Corps Air Facility Santa Ana crashed, killing all four members of the crew. Within three days the accident investigators had determined that the mounting brackets of the main transmission had failed, allowing the front and rear overlapping rotors to intermesh. All CH-46s were temporarily grounded for inspection. On 13 May, a CH-46A crashed off the coast of Vietnam when the tail pylon containing the engines, main transmission and aft rotors broke off in flight. All four crew members were killed. On 20 June, another CH-46A crashed, though two of the four-man crew survived. Once again, even though the aircraft was not recovered from the water, failure of some sort in the rear pylon was suspected. On 30 June a CH-46D at Santa Ana crashed when a rotor blade separated from the aircraft, all three of the crew survived. As a result of this latest accident, all CH-46Ds were immediately grounded, but the CH-46As continued flying. On 3 July another CH-46A crashed in Vietnam, killing all four Marines of its crew. The cause of the crash again was traced to failure of the main transmission.\nOn 31 August 1967, a CH-46A on a medical evacuation mission to disintegrated in midair killing all its occupants. The following day another CH-46A experienced a similar incident at Marble Mountain Air Facility leading to the type being grounded for all except emergency situations and cutting Marine airlift capacity in half. An investigation conducted by a joint Naval Air Systems Command/Boeing Vertol accident investigation team revealed that structural failures were occurring in the area of the rear pylon resulting in the rear rotor tearing off in flight and may have been the cause of several earlier losses. The team recommended structural and systems modifications to reinforce the rear rotor mount as well as installation of an indicator to detect excessive strain on critical parts of the aircraft. 80 CH-46As were shipped to Marine Corps Air Station Futenma, Okinawa where they received the necessary modifications by a combined force of Marine and Boeing Vertol personnel. The modified CH-46As began returning to service in December 1967 and all had been returned to service by February 1968.\nDuring the 1972 Easter Offensive, Sea Knights saw heavy use to convey US and South Vietnamese ground forces to and around the front lines. Marine CH-46s participated in Operation Frequent Wind, the evacuation of Saigon, in April 1975 and the last helicopter to leave the roof of the US embassy was a CH-46 of HMM-164. By the end of US military operations in Vietnam, over a hundred Sea Knights had been lost to enemy fire.\nPost-Vietnam.\nIn February 1968 the Marine Corps Development and Education Command obtained several CH-46s to perform herbicide dissemination tests using HIDAL (Helicopter, Insecticide Dispersal Apparatus, Liquid) systems; testing indicated the need for redesign and further study. Tandem-rotor helicopters were often used to transport nuclear warheads; the CH-46A was evaluated to deploy Naval Special Forces with the Special Atomic Demolition Munition (SADM). Nuclear Weapon Accident Exercise 1983 (NUWAX-83), simulating the crash of a Navy CH-46E carrying 3 nuclear warheads, was conducted at the Nevada Test Site on behalf of several federal agencies; the exercise, which used real radiological agents, was depicted in a Defense Nuclear Agency-produced documentary.\nU.S. Marine CH-46s were used to deploy the 8th Marine Regiment into Grenada during Operation Urgent Fury, evacuated the surviving crewmember of a downed AH-1 Cobra, and then carried infantry from the 75th Ranger Regiment to secure and evacuate U.S. students at St. George's University, though one crashed after colliding with a palm tree.\nCH-46E Sea Knights were also used by the U.S. Marine Corps during the 2003 invasion of Iraq. In one incident on 1 April 2003, Marine CH-46Es and CH-53Es carried U.S. Army Rangers and Special Operations troops on an extraction mission for captured Army Private Jessica Lynch from an Iraqi hospital. During the subsequent occupation of Iraq and counter-insurgency operations, the CH-46E was heavily used in the CASEVAC role, being required to maintain 24/7 availability regardless of conditions. According to authors Williamson Murray and Robert H Scales, the Sea Knight displayed serious reliability and maintenance problems during its deployment to Iraq, as well as \"limited lift capabilities\". Following the loss of numerous US helicopters in the Iraqi theatre, the Marines opted to equip their CH-46s with more advanced anti-missile countermeasures.\nThe U.S. Navy retired the type on 24 September 2004, replacing it with the MH-60S Seahawk; the Marine Corps maintained its fleet as the MV-22 Osprey was fielded. In March 2006 Marine Medium Helicopter Squadron 263 (HMM-263) was deactivated and redesignated VMM-263 to serve as the first MV-22 squadron. The replacement process continued through the other medium helicopter squadrons into 2014. On 5 October 2014, the Sea Knight performed its final service flight with the U.S. Marine Corps at Marine Corps Air Station Miramar. HMM-364 was the last squadron to use it outside the United States, landing it aboard on her maiden transit. On 9 April 2015, the CH-46 was retired by the Marine Medium Helicopter Training Squadron 164, the last Marine Corps squadron to transition to the MV-22. The USMC retired the CH-46 on 1 August 2015 in a ceremony at the Udvar-Hazy Center near Washington DC.\nBeginning in April 2011 the Navy's Fleet Readiness Center East began refurbishing retired USMC CH-46Es for service with the United States Department of State Air Wing. A number of CH-46s from HMX-1 were transferred to the Air Wing in late 2014. In Afghanistan the CH-46s were used by Embassy Air for secure transport of State Department personnel. The CH-46s were equipped with missile warning sensors and flare dispensers and could be armed with M240D or M2 Browning machine guns. A report in September 2019 by the State Department Inspector General found that a seat on a CH-46 for a seven-minute flight cost US$1,500 (~$ in ).\nEvacuation of Afghanistan.\nSeven of the State Department Air Wing CH-46s took part in the 2021 Kabul Airlift. Prior to the complete withdrawal of U.S. forces, all seven were rendered unusable and abandoned at Kabul International Airport and are seen in many videos and pictures online. One of the CH-46s that was abandoned (BuNo 154038, c/n 2389) also took part in Operation Frequent Wind 46 years earlier. The U.S. State Department drew criticism for leaving behind the aircraft. Commenting on the issue, the U.S. State Department claimed that the helicopters were already being phased out of State Department Air Wing due to their age and the inability to support them. The seven CH-46s left behind were the only U.S. State Department aircraft left behind at Kabul International Airport.\nCanada.\nThe Royal Canadian Air Force procured six CH-113 Labrador helicopters for the SAR role and the Canadian Army acquired 12 of the similar CH-113A Voyageur for the medium-lift transport role. The RCAF Labradors were delivered first with the first one entering service on 11 October 1963. When the larger CH-147 Chinook was procured by the Canadian Forces in the mid-1970s, the Voyageur fleet was converted to Labrador specifications to undertake SAR missions. The refurbished Voyageurs were re-designated as CH-113A Labradors, thus a total of 15 Labradors were ultimately in service.\nThe Labrador was fitted with a watertight hull for marine landings, a 5,000 kilogram cargo hook and an external rescue hoist mounted over the right front door. It featured a 1,110 kilometer flying range, emergency medical equipment and an 18-person passenger capacity. In multiple instances throughout the 1970s and 1980s, this increased range provided the capability of the CH-113 to provide assistance to U.S. Coast Guard (USCG) missions or perform long range medevacs over distances the USCG helicopters at the time simply could not reach.\nIn 1981, a mid-life upgrade of the fleet was carried out by Boeing Canada in Arnprior, Ontario. Known as the SAR-CUP (Search and Rescue Capability Upgrade Program), the refit scheme included new instrumentation, a nose-mounted weather radar, a tail-mounted auxiliary power unit, a new high-speed rescue hoist mounted over the side door and front-mounted searchlights. A total of six CH-113s and five CH-113As were upgraded with the last delivered in 1984. Nonetheless, as a search and rescue helicopter it endured heavy use and hostile weather conditions; which had begun to take their toll on the Labrador fleet by the 1990s, resulting in increasing maintenance costs and the need for prompt replacement.\nIn 1992, it was announced that the Labradors were to be replaced by 15 new helicopters, a variant of the AgustaWestland EH101, designated \"CH-149 Chimo\". The order was subsequently cancelled by the Jean Chr\u00e9tien Liberal government in 1993, resulting in cancellation penalties, as well as extending the service life of the Labrador fleet. However, in 1998, a CH-113 from CFB Greenwood crashed on Quebec's Gasp\u00e9 Peninsula while returning from a SAR mission, resulting in the deaths of all crewmembers on board. The crash placed pressure upon the government to procure a replacement, thus an order was placed with the manufacturers of the EH101 for 15 aircraft to perform the search-and-rescue mission, designated \"CH-149 Cormorant\". CH-149 deliveries began in 2003, allowing the last CH-113 to be retired in 2004. In October 2005 Columbia Helicopters of Aurora, Oregon purchased eight of the retired CH-113 Labradors to add to their fleet of 15 Vertol 107-II helicopters.\nSweden.\nIn 1963, Sweden procured ten UH-46Bs from the US as a transport and anti-submarine helicopter for the Swedish Armed Forces, designated Hkp 4A. In 1973, a further eight Kawasaki-built KV-107s, which were accordingly designated Hkp 4B, were acquired to replace the older Piasecki H-21. During the Cold War, the fleet's primary missions were anti-submarine warfare and troop transportation. They were also frequently employed in the search and rescue role, most famously during the rescue operation of the MS \"Estonia\" after it sank in the Baltic Sea on 28 September 1994. In the 1980s, the Hkp 4A was phased out, having been replaced by the Eurocopter AS332 Super Puma; the later Kawasaki-built Sea Knights continued in operational service until 2011, they were replaced by the UH-60 Black Hawk and NH90.\nArgentina.\nOn 15 September 2023, Argentina's Air Force chief Gen. Xavier Issac briefed the media that Argentina had sent a letter requesting the US to approve the refurbishment of surplus CH-46s currently stored with the 309th Aerospace Maintenance and Regeneration Group in Arizona. The availability of civilian-operated CH-46s was also being explored. They would be used to support Argentina's Antarctic bases. The CH-46s would replace two Mil Mi-171E helicopters acquired in 2010, but now not able to be repaired by Russia due to sanctions from the Russian invasion of Ukraine.\nCivilian and others.\nThe civilian version, designated as the BV 107-II \"Vertol\", was developed prior to the military CH-46. It was operated commercially by New York Airways, Pan American World Airways and later on by Columbia Helicopters. Among the diversity of tasks was commuter service in the mid-1960s from the roof of the Pan Am skyscraper in Manhattan to JFK Airport in Queens, pulling a hover barge, and constructing transmission towers for overhead power lines.\nIn December 2006, Columbia Helicopters purchased the type certificate of the Model 107 from Boeing, with the aim of eventually producing new-build aircraft themselves. In 2023, Columbia Helicopters began a program of purchasing older Model 107-II and CH-46E airframes, and refurbishing them into Model 107-IIs for sale. Columbia Helicopters has also updated old airframes into the \"Model 107-III\".\nAircraft on display.\nA variety of CH-46 are on display at museums in Canada, Japan, Sweden, and the USA."}
{"id": "7774", "revid": "1256182408", "url": "https://en.wikipedia.org/wiki?curid=7774", "title": "Chief of Naval Operations", "text": "The chief of naval operations (CNO) is the highest-ranking officer of the United States Navy. The position is a statutory office () held by an admiral who is a military adviser and deputy to the secretary of the Navy. The CNO is also a member of the Joint Chiefs of Staff () and in this capacity, a military adviser to the National Security Council, the Homeland Security Council, the secretary of defense, and the president.\nDespite the title, the CNO does not have operational command authority over naval forces. The CNO is an administrative position based in the Pentagon, and exercises supervision of Navy organizations as the designee of the secretary of the Navy. Operational command of naval forces falls within the purview of the combatant commanders who report to the secretary of defense.\nThe current chief of naval operations is Lisa Franchetti, who was sworn in on November 2, 2023.\nAppointment, rank, and responsibilities.\nThe chief of naval operations (CNO) is typically the highest-ranking officer on active duty in the U.S. Navy unless the chairman and/or the vice chairman of the Joint Chiefs of Staff are naval officers. The CNO is nominated for appointment by the president, for a four-year term of office, and must be confirmed by the Senate. A requirement for being Chief of Naval Operations is having significant experience in joint duty assignments, which includes at least one full tour of duty in a joint duty assignment as a flag officer. However, the president may waive those requirements if he determines that appointing the officer is necessary for the national interest. The chief can be reappointed to serve one additional term, but only during times of war or national emergency declared by Congress. By statute, the CNO is appointed as a four-star admiral.\nAs per , whenever there is a vacancy for the chief of naval operations or during the absence or disability of the chief of naval operations, and unless the president directs otherwise, the vice chief of naval operations performs the duties of the chief of naval operations until a successor is appointed or the absence or disability ceases.\nDepartment of the Navy.\nThe CNO also performs all other functions prescribed under , such as presiding over the Office of the Chief of Naval Operations (OPNAV), exercising supervision of Navy organizations, and other duties assigned by the secretary or higher lawful authority, or the CNO delegates those duties and responsibilities to other officers in OPNAV or in organizations below.\nActing for the secretary of the Navy, the CNO also designates naval personnel and naval forces available to the commanders of unified combatant commands, subject to the approval of the secretary of defense.\nJoint Chiefs of Staff.\nThe CNO is a member of the Joint Chiefs of Staff as prescribed by and . Like the other members of the Joint Chiefs of Staff, the CNO is an administrative position, with no operational command authority over the United States Navy forces.\nMembers of the Joint Chiefs of Staff, individually or collectively, in their capacity as military advisers, shall provide advice to the president, the National Security Council (NSC), or the secretary of defense (SECDEF) on a particular matter when the president, the NSC, or SECDEF requests such advice. Members of the Joint Chiefs of Staff (other than the chairman of the Joint Chiefs of Staff) may submit to the chairman advice or an opinion in disagreement with, or advice or an opinion in addition to, the advice presented by the chairman to the president, NSC, or SECDEF.\nWhen performing her JCS duties, the CNO is responsible directly to the SECDEF, but keeps SECNAV fully informed of significant military operations affecting the duties and responsibilities of the SECNAV, unless SECDEF orders otherwise.\nHistory.\nEarly attempts and the Aide for Naval Operations (1900\u20131915).\nIn 1900, administrative and operational authority over the Navy was concentrated in the secretary of the Navy and bureau chiefs, with the General Board holding only advisory powers. Critics of the lack of military command authority included Charles J. Bonaparte, Navy secretary from 1905 to 1906, then-Captain Reginald R. Belknap and future admiral William Sims.\nRear Admiral George A. Converse, commander of the Bureau of Navigation (BuNav) from 1905 to 1906, reported:\nHowever, reorganization attempts were opposed by Congress due to fears of a Prussian-style general staff and inadvertently increasing the powers of the Navy secretary, which risked infringing on legislative authority. Senator Eugene Hale, chairman of the Senate Committee on Naval Affairs, disliked reformers like Sims and persistently blocked attempts to bring such ideas to debate.\nTo circumvent the opposition, George von Lengerke Meyer, Secretary of the Navy under William Howard Taft implemented a system of \"aides\" on 18 November 1909. These aides lacked command authority and instead served as principal advisors to the Navy secretary. The aide for operations was deemed by Meyer to be the most important one, responsible for devoting \"his entire attention and study to the operations of the fleet,\" and drafting orders for the movement of ships on the advice of the General Board and approval of the secretary in times of war or emergency.\nThe successes of Meyer's first operations aide, Rear Admiral Richard Wainwright, factored into Meyer's decision to make his third operations aide, Rear Admiral Bradley A. Fiske his \"de facto\" principal advisor on 10 February 1913. Fiske retained his post under Meyer's successor, Josephus Daniels, becoming the most prominent advocate for what would become the office of CNO.\nCreating the position of Chief of Naval Operations (1915).\nIn 1914, Fiske, frustrated at Daniels' ambivalence towards his opinion that the Navy was unprepared for the possibility of entry into World War I, bypassed the secretary to collaborate with Representative Richmond P. Hobson, a retired Navy admiral, to draft legislation providing for the office of \"a chief of naval operations\". The preliminary proposal (passed off as Hobson's own to mask Fiske's involvement), in spite of Daniels' opposition, passed Hobson's subcommittee unanimously on 4 January 1915, and passed the full House Committee on Naval Affairs on 6 January.\nFiske's younger supporters expected him to be named the first chief of naval operations, and his versions of the bill provided for the minimum rank of the officeholder to be a two-star rear admiral.\nIn contrast, Daniels' version, included in the final bill, emphasized the office's subordination to the Navy secretary, allowed for the selection of the CNO from officers of the rank of captain, and denied it authority over the Navy's general direction:\nFiske's \"end-running\" of Daniels eliminated any possibility of him being named the first CNO. Nevertheless, satisfied with the change he had helped enact, Fiske made a final contribution: elevating the statutory rank of the CNO to admiral with commensurate pay. The Senate passed the appropriations bill creating the CNO position and its accompanying office on 3 March 1915, simultaneously abolishing the aides system promulgated under Meyer.\nBenson, the first CNO (1915\u20131919).\nCaptain William S. Benson was promoted to the temporary rank of rear admiral and became the first CNO on 11 May 1915. He further assumed the rank of admiral after the passage of the 1916 Naval Appropriations Bill with Fiske's amendments, second only to Admiral of the Navy George Dewey and explicitly senior to the commanders-in-chief of the Atlantic, Pacific and Asiatic Fleets.\nUnlike Fiske, who had campaigned for a powerful, aggressive CNO sharing authority with the Navy secretary, Benson demonstrated personal loyalty to Secretary Daniels and subordinated himself to civilian control, yet maintained the CNO's autonomy where necessary. While alienating reformers like Sims and Fiske (who retired in 1916), Benson's conduct gave Daniels immense trust in his new CNO, and Benson was delegated greater resources and authority.\nAchievements.\nAmong the organizational efforts initiated or recommended by Benson included an advisory council to coordinate high-level staff activities, composed of himself, the SECNAV and the bureau chiefs which \"worked out to the great satisfaction\" of Daniels and Benson; the reestablishment of the Joint Army and Navy Board in 1918 with Benson as its Navy member; and the consolidation of all matters of naval aviation under the authority of the CNO.\nBenson also revamped the structure of the naval districts, transferring authority for them from SECNAV to the Office of the Chief of Naval Operations under the Operations, Plans, Naval Districts division. This enabled closer cooperation between naval district commanders and the uniformed leadership, who could more easily handle communications between the former and the Navy's fleet commanders.\nIn the waning years of his tenure, Benson set regulations for officers on shore duty to have temporary assignments with the Office of the Chief of Naval Operations to maintain cohesion between the higher-level staff and the fleet.\nEstablishing OPNAV.\nUntil 1916, the CNO's office was chronically understaffed. The formal establishment of the CNO's \"general staff\", the Office of the Chief of Naval Operations (OPNAV), originally called the Office for Operations, was exacerbated by Eugene Hale's retirement from politics in 1911, and skepticism of whether the CNO's small staff could implement President Wilson's policy of \"preparedness\" without violating American neutrality in World War I.\nBy June 1916, OPNAV was organized into eight divisions: Operations, Plans, Naval Districts; Regulations; Ship Movements; Communications; Publicity; and Materiel. Operations provided a link between fleet commanders and the General Board, Ship Movements coordinated the movement of Navy vessels and oversaw navy yard overhauls, Communications accounted for the Navy's developing radio network, Publicity conducted the Navy's public affairs, and the Materiel section coordinated the work of the naval bureaus.\nNumbering only 75 staffers in January 1917, OPNAV increased in size following the American entry into World War I, as it was deemed of great importance to manage the rapid mobilization of forces to fight in the war. By war's end, OPNAV employed over 1462 people. The CNO and OPNAV thus gained influence over Navy administration but at the expense of the Navy secretary and bureau chiefs.\nAdvisor to the president.\nIn 1918, Benson became a military advisor to Edward M. House, an advisor and confidant of President Wilson, joining him on a trip to Europe as the 1918 armistice with Germany was signed. His stance that the United States remain equal to Great Britain in naval power was very useful to House and Wilson, enough for Wilson to insist Benson remain in Europe until after the Treaty of Versailles was signed in July 1919.\nEnd of tenure.\nBenson's tenure as CNO was slated to end on 10 May 1919, but this was delayed by the president at Secretary Daniels' insistence; Benson instead retired on 25 September 1919. Admiral Robert Coontz replaced Benson as CNO on 1 November 1919.\nInterwar period (1919\u20131939).\nThe CNO's office faced no significant changes in authority during the interwar period, largely due to the Navy secretaries opting to keep executive authority within their own office. Innovations during this period included encouraging coordination in war planning process, and compliance with the Washington Naval Treaty while still keeping to the shipbuilding plan authorized by the Naval Act of 1916. and implementing the concept of naval aviation into naval doctrine.\nCNO Pratt, relationship with the General Board and Army-Navy relations.\nWilliam V. Pratt became the fifth Chief of Naval Operations on 17 September 1930, after the resignation of Charles F. Hughes. He had previously served as assistant chief of naval operations under CNO Benson. A premier naval policymaker and supporter of arms control under the Washington Naval Treaty, Pratt, despite otherwise good relations, clashed with President Herbert Hoover over building up naval force strength to treaty levels, with Hoover favoring restrictions in spending due to financial difficulties caused by the Great Depression. Under Pratt, such a \"treaty system\" was needed to maintain a compliant peacetime navy.\nPratt opposed centralized management of the Navy, and encouraged diversity of opinion between the offices of the Navy secretary, CNO and the Navy's General Board. To this effect, Pratt removed the CNO as an \"ex officio\" member of the General Board, concerned that the office's association with the Board could hamper diversities of opinion between the former and counterparts within the offices of the Navy secretary and OPNAV. Pratt's vision of a less powerful CNO also clashed with Representative Carl Vinson of Georgia, chair of the House Naval Affairs Committee from 1931 to 1947, a proponent of centralizing power within OPNAV. Vinson deliberately delayed many of his planned reorganization proposals until Pratt's replacement by William H. Standley to avoid the unnecessary delays that would otherwise have happened with Pratt.\nPratt also enjoyed a good working relationship with Army chief of staff Douglas MacArthur, and negotiated several key agreements with him over coordinating their services' radio communications networks, mutual interests in coastal defense, and authority over Army and Navy aviation.\nCNO Standley and the Vinson-Trammell act.\nWilliam H. Standley, who succeeded Pratt in 1933, had a weaker relationship with President Franklin D. Roosevelt than Pratt enjoyed with Hoover. Often in direct conflict with Navy secretary Claude A. Swanson and assistant secretary Henry L. Roosevelt, Standley's hostility to the latter was described as \"poisonous\".\nConversely, Standley successfully improved relations with Congress, streamlining communications between the Department of the Navy and the naval oversight committees by appointing the first naval legislative liaisons, the highest-ranked of which reported to the judge advocate general. Standley also worked with Representative Vinson to pass the Vinson-Trammell Act, considered by Standley to be his most important achievement as CNO. The Act authorized the President:\nThis effectively provided security for all Navy vessels under construction; even if new shipbuilding projects could not be initiated, shipbuilders with new classes under construction could not legally be obliged to cease operations, allowing the Navy to prepare for World War II without breaking potential limits from future arms control conferences. The Act also granted the CNO \"soft oversight power\" of the naval bureaus which nominally lay with the secretary of the Navy, as Standley gradually inserted OPNAV into the ship design process. Under Standley, the \"treaty system\" created by Pratt was abandoned.\nCNO Leahy.\nOutgoing commander, Battle Force William D. Leahy succeeded Standley as CNO on 2 January 1937. Leahy's close personal friendship with President Roosevelt since his days as Navy assistant secretary, as well as good relationships with Representative Vinson and Secretary Swanson brought him to the forefront of potential candidates for the post. Unlike Standley, who tried to dominate the bureaus, Leahy preferred to let the bureau chiefs function autonomously as per convention, with the CNO acting as a \"primus inter pares\". Leahy's views of the CNO's authority led to clashes with his predecessor; Standley even attempted to block Leahy from being assigned a fleet command in retaliation. Leahy, on his part, continued Standley's efforts to insert the CNO into the ship design process.\nSwanson's ill health and assistant secretary Henry Roosevelt's death on 22 February 1936 gave Leahy unprecedented influence. Leahy had private lunches with the President frequently; during his tenure as CNO, Roosevelt had 52 meetings with him, compared with 12 with his Army counterpart, General Malin Craig, none of which were private lunches.\nLeahy retired from the Navy on 1 August 1939 to become Governor of Puerto Rico, a month before the invasion of Poland.\nOfficial residence.\nNumber One Observatory Circle, located on the northeast grounds of the United States Naval Observatory in Washington, DC, was built in 1893 for its superintendent. The chief of naval operations liked the house so much that in 1923 he took over the house as his own official residence. It remained the residence of the CNO until 1974, when Congress authorized its transformation to an official residence for the vice president. The chief of naval operations currently resides in Quarters A in the Washington Naval Yard.\nOffice of the Chief of Naval Operations.\nThe chief of naval operations presides over the Navy Staff, formally known as the Office of the Chief of Naval Operations (OPNAV). \nThe Office of the Chief of Naval Operations is a statutory organization within the executive part of the Department of the Navy, and its purpose is to furnish professional assistance to the secretary of the Navy (SECNAV) and the CNO in carrying out their responsibilities.\nUnder the authority of the CNO, the director of the Navy Staff (DNS) is responsible for day-to-day administration of the Navy Staff and coordination of the activities of the deputy chiefs of naval operations, who report directly to the CNO. The office was previously known as the assistant vice chief of naval operations (AVCNO) until 1996, when CNO Jeremy Boorda ordered its redesignation to its current name. Previously held by a three-star vice admiral, the position became a civilian's billet in 2018. The present DNS is a Vice Admiral Michael Boyle, a former 3rd Fleet commander."}
{"id": "7775", "revid": "40943757", "url": "https://en.wikipedia.org/wiki?curid=7775", "title": "Clara Petacci", "text": "Clara \"Claretta\" Petacci (; 28 February 1912 \u2013 28 April 1945) was a mistress of the Italian dictator Benito Mussolini. She was killed by Italian partisans during Mussolini's summary execution.\nEarly life.\nDaughter of Giuseppina Persichetti (1888\u20131962) and the physician Francesco Saverio Petacci (1883\u20131970), Clara Petacci was born into a privileged and religious family in Rome in 1912. Her father, a physician of the Holy Apostolic Palaces, became a supporter of fascism. A child when Mussolini rose to power in the 1920s, Clara Petacci idolised him from an early age. After Violet Gibson attempted to assassinate the dictator in April 1926, the 14-year-old Petacci wrote to him commenting \"O, Duce, why was I not with you?\u00a0... Could I not have strangled that murderous woman?\"\nRelationship with Mussolini.\nPetacci had a long-standing relationship with Mussolini while he was married to Rachele Mussolini. Petacci was 28 years younger than Mussolini. They met for the first time in April 1932 when Mussolini, driving with an aide to Ostia, overtook a car occupied by the twenty-year-old Petacci and family members. She called out, \"Duce! Duce!\" and when he stopped, told him that she had been writing to him since her early teens. \nIn 1934, Petacci married Italian Air Force officer Riccardo Federici, but she parted ways with her husband when he was sent to Tokyo as Air Attach\u00e9 in 1936. Petacci then became the mistress of the fifty-three-year-old Mussolini, visiting his headquarters in the , where a small apartment was reserved for her. Her infatuation with Mussolini appears to have been genuine and permanent. The affair became widely known and members of the Petacci family, notably her brother, Marcello, were able to benefit financially and professionally by influence-selling. \nPart of Petacci and Mussolini's correspondence has not been released on the grounds of privacy.\nDeath.\nOn 27 April 1945, Mussolini and Petacci were captured by partisans while traveling with a \"Luftwaffe\" convoy retreating to Germany. The German column included a number of Italian Social Republic members.\nOn 28 April, she and Mussolini were taken to Mezzegra and executed. One source alleges Petacci's execution was not planned and that she died throwing herself on Mussolini in a vain attempt to protect him from the bullets. On the following day, the bodies of Mussolini and Petacci were taken to Piazzale Loreto in Milan and hung upside down in front of a petrol station. The bodies were photographed as a crowd vented their rage upon them. On the same day, Clara's brother, Marcello Petacci, was also killed in Dongo by the partisans, along with fifteen other people complicit in Mussolini's escape. \nAfter the war, the family of Petacci began civil and criminal court cases against Walter Audisio for Petacci's unlawful killing. After a lengthy legal process, an investigating judge eventually closed the case in 1967. Audisio was acquitted of murder and embezzlement on the grounds that the actions complained of occurred as an act of war against the Germans and the fascists during a period of enemy occupation."}
{"id": "7778", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7778", "title": "CVBG", "text": ""}
{"id": "7780", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=7780", "title": "Costa Smeralda", "text": "The Costa Smeralda (, ; ; ) is a coastal area and tourist destination in northern Sardinia, Italy, with a length of some 20\u00a0km, although the term originally designated only a small stretch in the commune of Arzachena. \nWith white sand beaches, golf clubs, private jet and helicopter services, and exclusive hotels, the area has drawn celebrities, business and political leaders, and other affluent visitors. Costa Smeralda is one of the most expensive locations in Europe. House prices reach up to 300,000 euros ($392,200) per square meter.\nThe main towns and villages in the area, built according to a detailed urban plan, are Porto Cervo, Liscia di Vacca, Capriccioli, and Romazzino. Archaeological sites include the necropolis of Li Muri. \nEach September the Sardinia Cup sailing regatta is held off the coast. Polo matches are held between April and October at Gershan near Arzachena. \nDevelopment of the area started in 1961, and was financed by a consortium of companies led by Prince Karim Aga Khan. Spiaggia del Principe, one of the beaches along the Costa Smeralda, was named after this Ishmaelite prince. Architects involved in the project included Michele Busiri Vici, Jacques Cou\u00eblle, Savin Cou\u00eblle, and Vietti."}
{"id": "7781", "revid": "1251212342", "url": "https://en.wikipedia.org/wiki?curid=7781", "title": "Chianti", "text": "Chianti is an Italian red wine produced in the Chianti region of central Tuscany, principally from the Sangiovese grape. It was historically associated with a squat bottle enclosed in a straw basket, called a \"fiasco\" (\"flask\"; : \"fiaschi\"). However, the \"fiasco\" is now only used by a few makers of the wine; most Chianti is bottled in more standard-shaped wine bottles. In the latter nineteenth century, Baron Bettino Ricasoli (later Prime Minister of the Kingdom of Italy) helped establish Sangiovese as the blend's dominant grape variety, creating the blueprint for today's Chianti wines.\nThe first definition of a wine area called \"Chianti\" was made in 1716. It described the area near the villages of Gaiole, Castellina and Radda; the so-called \"Lega del Chianti\" and later \"Provincia del Chianti\" (Chianti province). In 1932 the Chianti area was completely redrawn and divided into seven sub-areas: Classico, Colli Aretini, Colli Fiorentini, Colline Pisane, Colli Senesi, Montalbano and R\u00f9fina. Most of the villages that in 1932 were added to the newly defined Chianti Classico region added \"in Chianti\" to their names, for example Greve in Chianti, which amended its name in 1972. Wines labelled Chianti Classico come from the largest sub-area of Chianti, which includes the original Chianti heartland. Only Chianti from this sub-zone may display the black rooster (\"gallo nero\") seal on the neck of the bottle, which indicates that the producer of the wine is a member of the Chianti Classico Consortium, the local association of producers. Other variants, with the exception of Rufina north-east of Florence and Montalbano south of Pistoia, originate in the named provinces: Siena for the Colli Senesi, Florence for the Colli Fiorentini, Arezzo for the Colli Aretini and Pisa for the Colline Pisane. In 1996 part of the Colli Fiorentini sub-area was renamed \"Montespertoli\".\nDuring the 1970s producers started to reduce the quantity of white grapes in Chianti. In 1995 it became legal to produce a Chianti with 100% Sangiovese. For a wine to retain the name of Chianti it must be produced with at least 80% Sangiovese grapes. Aged Chianti (at least 6 months in barrel and 3 more in bottle before release, instead of 6 months aging without barreling necessary) may be labelled as Riserva. Chianti that meets more stringent requirements (lower yield, higher alcohol content and dry extract) may be labelled as Chianti Superiore, although Chianti from the Classico sub-area is not allowed in any event to be labelled as Superiore.\nHistory.\nThe earliest documentation of a \"Chianti wine\" dates back to the 14th century, when viticulture was known to flourish in the \"Chianti Mountains\" around Florence. A military league called \"Lega del Chianti\" (League of Chianti) was formed around 1250 between the townships of Castellina, Gaiole and Radda, which would lead to the wine from this area taking on a similar name. In 1398 the earliest-known record notes Chianti as a white wine, though the red wines of Chianti were also discussed around the same time in similar documents. \nThe first attempt to classify Chianti wine in any way came in 1427, when Florence developed a tariff system for the wines of the surrounding countryside, including an area referred to as \"Chianti and its entire province\". In 1716 Cosimo III de' Medici, Grand Duke of Tuscany, issued an edict legislating that the three villages of the \"Lega del Chianti\" (Castellina in Chianti, Gaiole in Chianti and Radda in Chianti) as well as the village of Greve and a of hillside north of Greve near as the only officially recognised producers of Chianti. This delineation existed until July 1932, when the Italian government expanded the Chianti zone to include the outlying areas of Barberino Val d'Elsa, Chiocchio, , San Casciano in Val di Pesa and . Subsequent expansions in 1967 would eventually result in the Chianti zone covering a very large area all over central Tuscany.\nBy the 18th century Chianti was widely recognised as a red wine, but the exact composition and grape varieties used to make Chianti at this point is unknown. Ampelographers find clues about which grape varieties were popular at the time in the writings of Italian writer Cosimo Villifranchi, who noted that Canaiolo was a widely planted variety in the area along with Sangiovese, Mammolo and Marzemino. It was not until the work of the Italian statesman Bettino Ricasoli that the modern Chianti recipe as a Sangiovese-based wine would take shape. \nPrior to Ricasoli, Canaiolo was emerging as the dominant variety in the Chianti blend with Sangiovese and Malvasia Bianca Lunga playing supporting roles. In the mid-19th century, Ricasoli developed a recipe for Chianti that was based primarily on Sangiovese. Though he is often credited with creating and disseminating a specific formula (typically reported as 70% Sangiovese, 20% Canaiolo, 10% Malvasia Bianca Lunga), a review of his correspondence of the time does not corroborate this. In addition, his efforts were quickly corrupted by other local winemakers (for example, replacing Malvasia with Trebbiano Toscano, or relying too heavily on the latter), leading to further misunderstanding of the \"Ricasoli formula\". In 1967, the \"Denominazione di origine controllata\" (DOC) regulation set by the Italian government was based on a loose interpretation of Ricasoli's \"recipe\", calling for a Sangiovese-based blend with 10\u201330% Malvasia and Trebbiano.\nThe late 19th century saw a period of economic and political upheaval. First came oidium and then the phylloxera epidemic would take its toll on the vineyards of Chianti just as they had ravaged vineyards across the rest of Europe. The chaos and poverty following the \"Risorgimento\" heralded the beginning of the Italian diaspora that would take Italian vineyard workers and winemakers abroad as immigrants to new lands. Those that stayed behind and replanted choose high-yielding varieties like Trebbiano and Sangiovese clones such as the \"Sangiovese di Romagna\" from the nearby Romagna region. Following the Second World War, the general trend in the world wine market for cheap, easy-drinking wine saw a brief boom for the region. With over-cropping and an emphasis on quantity over quality, the reputation of Chianti among consumers eventually plummeted. By the 1950s, Trebbiano (which is known for its neutral flavours) made up to 30% of many mass-market Chiantis. \nBy the late 20th century, Chianti was often associated with basic Chianti sold in a squat bottle enclosed in a straw basket, called a \"fiasco\". However, during the same period, a group of ambitious producers began working outside the boundaries of DOC regulations to make what they believed would be a higher-quality wine. These wines eventually became known as the \"Super Tuscans\".\nMany of the producers behind the Super Tuscan movement were originally Chianti producers who were rebelling against what they felt were antiquated DOC regulations. Some of these producers wanted to make Chiantis that were 100% varietal Sangiovese. Others wanted the flexibility to experiment with blending French grape varieties such as Cabernet Sauvignon and Merlot or to not be required to blend in any white grape varieties. The late 20th century saw a flurry of creativity and innovation in the Chianti zones as producers experimented with new grape varieties and introduced modern wine-making techniques such as the use of new oak barrels. The prices and wine ratings of some Super Tuscans would regularly eclipse those of DOC-sanctioned Chiantis. The success of the Super Tuscans encouraged government officials to reconsider the DOC regulations in order to bring some of these wines back into the fold labelled as Chianti.\nChianti subregions.\nThe Chianti region covers a vast area of Tuscany and includes within its boundaries several overlapping \"Denominazione di origine controllata\" (DOC) and \"Denominazione di Origine Controllata e Garantita\" (DOCG) regions. Other well known Sangiovese-based Tuscan wines such as Brunello di Montalcino and Vino Nobile di Montepulciano could be bottled and labelled under the most basic designation of \"Chianti\" if their producers chose to do so. Within the collective Chianti region more than 8 million cases of wines classified as DOC-level or above are produced each year. Today, most Chianti falls under two major designations of Chianti DOCG, which includes basic level Chianti, as well as that from seven designated sub-zones, and Chianti Classico DOCG. Together, these two Chianti zones produce the largest volume of DOC/G wines in Italy.\nThe Chianti DOCG covers all the Chianti wine and includes a large stretch of land encompassing the western reaches of the province of Pisa near the coast of the Tyrrhenian Sea, the Florentine hills in the province of Florence to the north, to the province of Arezzo in the east and the Siena hills to the south. Within this regions are vineyards that overlap the DOCG regions of Brunello di Montalcino, Vino Nobile di Montepulciano and Vernaccia di San Gimignano. Any Sangiovese-based wine made according to the Chianti guidelines from these vineyards can be labelled and marked under the basic Chianti DOCG should the producer wish to use the designation.\nWithin the Chianti DOCG there are eight defined sub-zones that are permitted to affix their name to the wine label. Wines that are labelled as simply Chianti are made either from a blend from these sub-zones or include grapes from peripheral areas not within the boundaries of a sub-zone. The sub-zones are (clockwise from the north): the Colli Fiorentini which is located south of the city of Florence; Chianti Rufina in the northeastern part of the zone located around the commune of Rufina; Classico in the centre of Chianti, across the provinces of Florence and Siena; Colli Aretini in the Arezzo province to the east; Colli Senesi south of Chianti Classico in the Siena hills, which is the largest of the sub-zones and includes the Brunello di Montalcino and Vino Nobile di Montepulciano areas; Colline Pisane, the westernmost sub-zone in the province of Pisa; Montespertoli located within the Colli Fiorentini around the commune of Montespertoli; Montalbano in the north-west part of the zone which includes the Carmignano DOCG. \n, there were under production in Montalbano, in the Colli Fiorentini, in Montespertoli, in Rufina, in the Colli Senesi, in Colline Pisane, in the Colli Aretini, and an additional in the peripheral areas that do not fall within one of the sub-zone classifications. Wines produced from these vineyards are labelled simply \"Chianti\".\nChianti Classico.\nThe original area dictated by the edict of Cosimo III de' Medici would eventually be considered the heart of the modern \"Chianti Classico\" subregion. , there were of vineyards in the Chianti Classico subregion. The Chianti Classico subregion covers an area of approximate between the city of Florence to the north and Siena to the south. The four communes of Castellina in Chianti, Gaiole in Chianti, Greve in Chianti and Radda in Chianti are located entirely within the boundaries of the Classico area with parts of Barberino Val d'Elsa, San Casciano in Val di Pesa and Tavarnelle Val di Pesa in the province of Florence as well as Castelnuovo Berardenga and Poggibonsi in the province of Siena included within the permitted boundaries of Chianti Classico.\nThe soil and geography of this subregion can be quite varied, with altitudes ranging from , and rolling hills producing differing macroclimates. There are two main soil types in the area: a weathered sandstone known as \"alberese\" and a bluish-gray chalky marlstone known as \"galestro\". The soil in the north is richer and more fertile with more \"galestro\", with the soil gradually becoming harder and stonier with more \"albarese\" in the south. In the north, the Arno River can have an influence on the climate, keeping the temperatures slightly cooler, an influence that diminishes further south in the warmer Classico territory towards Castelnuovo Berardenga.\nChianti Classico are premium Chianti wines that tend to be medium-bodied with firm tannins and medium-high to high acidity. Floral, cherry and light nutty notes are characteristic aromas with the wines expressing more notes on the mid-palate and finish than at the front of the mouth. As with Bordeaux, the different zones of Chianti Classico have unique characteristics that can be exemplified and perceived in some wines from those areas. According to Master of Wine Mary Ewing-Mulligan, Chianti Classico wines from the Castellina area tend to have a very delicate aroma and flavour, Castelnuovo Berardegna wines tend to be the most ripe and richest tasting, wines from Gaiole tend to have been characterised by their structure and firm tannins while wines from the Greve area tend to have very concentrated flavours.\nThe production of Chianti Classico is realised under the supervision of , a union of producers in the Chianti Classico subregion. The Consorzio was founded with the aim of promoting the wines of the subregion, improving quality and preventing wine fraud. Since the 1980s, the foundation has sponsored extensive research into the viticultural and winemaking practice of the Chianti Classico area, particularly in the area of clonal research. In the last three decades, more than 50% of the vineyards in the Chianti Classico subregion have been replanted with improved Sangiovese clones and modern vineyard techniques as part of the Consorzio Chianti Classico's project \"Chianti 2000\".\nIn 2014, a new category of Chianti Classico was introduced: Chianti Classico Gran Selezione. Gran Selezione is made exclusively from a winery's own grapes grown according to stricter regulations compared to regular Chianti Classico. Gran Selezione is granted to a Chianti Classico after it passes a suitability test conducted by authorised laboratories, and after it is approved by a special tasting committee. The creation of the Chianti Classico Gran Selezione DOCG has been criticized, with some describing it as being \"Needless; an extra layer of confusion created by marketing people hoping to help Chianti Classico out of a sales crisis.\"\nGreater Chianti region.\nOutside of the Chianti Classico area, the wines of the Chianti sub-zone of Rufina are among the most widely recognised and exported from the Chianti region. Located in the Arno valley near the town of Pontassieve, the Rufina region includes much area in the Pomino region, an area that has a long history of wine production. The area is noted for the cool climate of its elevated vineyards located up to . The vineyard soils of the area are predominantly marl and chalk. The Florentine merchant families of the Antinori and Frescobaldi own the majority of the vineyards in Rufina. Chianti from the Rufina area is characterised by its multi-layered complexity and elegance.\nThe Colli Fiorentini subregion has seen an influx of activity and new vineyard development in recent years as wealthy Florentine business people move to the country to plant vineyards and open wineries. Many foreign \"flying winemakers\" have had a hand in this development, bringing global viticulture and wine-making techniques to the Colli Fiorentini. Located in the hills between the Chianti Classico area and Arno valley, the wines of the Colli Fiorentini vary widely depending on producer, but tend to have a simple structure with strong character and fruit notes. The Montespertoli sub-zone was part of the Colli Fiorentini sub-zone until 2002 when it became its own tiny enclave.\nThe Montalbano subregion is located in the shadow of the Carmignano DOCG, with much of the best Sangiovese going to that wine. A similar situation exists in the Colli Senesi which includes the well known DOCG region of Vino Nobile di Montepulciano. Both regions rarely appear on wine labels that are exported out of Tuscany. The Colli Pisane area produces typical Chiantis with the lightest body and color. The Colli Aretini is a relatively new and emerging area that has seen an influx of investment and new winemaking in recent years.\nGrapes and classification.\nSince 1996 the blend for Chianti and Chianti Classico has been 75\u2013100% Sangiovese, up to 10% Canaiolo and up to 20% of any other approved red grape variety such as Cabernet Sauvignon, Merlot or Syrah. Since 2006, the use of white grape varieties such as Malvasia and Trebbiano have been prohibited in Chianti Classico. Chianti Classico must have a minimum alcohol level of 12% with a minimum of 7 months aging in oak, while Chianti Classicos labeled \"riserva\" must be aged at least 24 months at the winery, with a minimum alcohol level of 12.5%. The harvest yields for Chianti Classico are restricted to no more than . For basic Chianti, the minimum alcohol level is 11.5% with yields restricted to .\nThe aging for basic Chianti DOCG is much less stringent with most varieties allowed to be released to the market on 1 March following the vintage year. The sub-zones of Colli Fiorentini, Montespertoli and Rufina must be aged for a further three months and not released until 1 June. All Chianti Classicos must be held back until 1 October in the year following the vintage.\nJancis Robinson notes that Chianti is sometimes called the \"Bordeaux of Italy\" but the structure of the wines is very different from any French wine. The flexibility in the blending recipe for Chianti accounts for some of the variability in styles among Chiantis. Lighter-bodied styles will generally have a higher proportion of white grape varieties blended in, while Chiantis that have only red grape varieties will be fuller and richer. While only 15% of Cabernet Sauvignon is permitted in the blend, the nature of the grape variety can have a dominant personality in the Chianti blend and be a strong influence in the wine.\nChianti Classico wines are characterised in their youth by their predominantly floral and cinnamon spicy bouquet. As the wine ages, aromas of tobacco and leather can emerge. Chiantis tend to have medium-high acidity and medium tannins. Basic level Chianti is often characterised by its juicy fruit notes of cherry, plum and raspberry and can range from simple quaffing wines to those approaching the level of Chianti Classico. Wine expert Tom Stevenson notes that these basic everyday-drinking Chiantis are at their peak drinking qualities often between three and five years after vintage, with premium examples having the potential to age for four to eight years. Well-made examples of Chianti Classico often have the potential to age and improve in the bottle for six to twenty years.\nChianti Superiore.\nChianti Superiore is an Italian DOCG wine produced in the provinces of Arezzo, Florence, Pisa, Pistoia, Prato and Siena, in Tuscany. Superiore is a specification for wines produced with a stricter rule of production than other Chianti wines. Chianti Superiore has been authorised since 1996. Chianti Superiore wines can be produced only from grapes cultivated in the Chianti wine areas except from those vineyards that are registered in the Chianti Classico sub-zone. Vineyards registered in Chianti sub-zones other than Classico can produce Chianti Superiore wines but must omit the sub-zone name on the label. Aging is calculated from 1 January after the picking. Chianti Superiore cannot be sold to the consumer before nine months of aging, of which three must be in the bottle. Therefore, it cannot be bottled before the June after picking or sold to consumers before the next September.\nSpecial editions.\nChianti Classico was promoted as the \"Official wine of the 2013 UCI Road World Championships\" and sold bottles dedicated to the Championships with special labels."}
{"id": "7783", "revid": "9448321", "url": "https://en.wikipedia.org/wiki?curid=7783", "title": "Coriolis force", "text": "In physics, the Coriolis force is a fictitious force that acts on objects in motion within a frame of reference that rotates with respect to an inertial frame. In a reference frame with clockwise rotation, the force acts to the left of the motion of the object. In one with anticlockwise (or counterclockwise) rotation, the force acts to the right. Deflection of an object due to the Coriolis force is called the Coriolis effect. Though recognized previously by others, the mathematical expression for the Coriolis force appeared in an 1835 paper by French scientist Gaspard-Gustave de Coriolis, in connection with the theory of water wheels. Early in the 20th century, the term \"Coriolis force\" began to be used in connection with meteorology.\nNewton's laws of motion describe the motion of an object in an inertial (non-accelerating) frame of reference. When Newton's laws are transformed to a rotating frame of reference, the Coriolis and centrifugal accelerations appear. When applied to objects with masses, the respective forces are proportional to their masses. The magnitude of the Coriolis force is proportional to the rotation rate, and the magnitude of the centrifugal force is proportional to the square of the rotation rate. The Coriolis force acts in a direction perpendicular to two quantities: the angular velocity of the rotating frame relative to the inertial frame and the velocity of the body relative to the rotating frame, and its magnitude is proportional to the object's speed in the rotating frame (more precisely, to the component of its velocity that is perpendicular to the axis of rotation). The centrifugal force acts outwards in the radial direction and is proportional to the distance of the body from the axis of the rotating frame. These additional forces are termed inertial forces, fictitious forces, or \"pseudo forces\". By introducing these fictitious forces to a rotating frame of reference, Newton's laws of motion can be applied to the rotating system as though it were an inertial system; these forces are correction factors that are not required in a non-rotating system.\nIn popular (non-technical) usage of the term \"Coriolis effect\", the rotating reference frame implied is almost always the Earth. Because the Earth spins, Earth-bound observers need to account for the Coriolis force to correctly analyze the motion of objects. The Earth completes one rotation for each sidereal day, so for motions of everyday objects the Coriolis force is imperceptible; its effects become noticeable only for motions occurring over large distances and long periods of time, such as large-scale movement of air in the atmosphere or water in the ocean, or where high precision is important, such as artillery or missile trajectories. Such motions are constrained by the surface of the Earth, so only the horizontal component of the Coriolis force is generally important. This force causes moving objects on the surface of the Earth to be deflected to the right (with respect to the direction of travel) in the Northern Hemisphere and to the left in the Southern Hemisphere. The horizontal deflection effect is greater near the poles, since the effective rotation rate about a local vertical axis is largest there, and decreases to zero at the equator. Rather than flowing directly from areas of high pressure to low pressure, as they would in a non-rotating system, winds and currents tend to flow to the right of this direction north of the equator (\"clockwise\") and to the left of this direction south of it (\"anticlockwise\"). This effect is responsible for the rotation and thus formation of cyclones .\nHistory.\nItalian scientist Giovanni Battista Riccioli and his assistant Francesco Maria Grimaldi described the effect in connection with artillery in the 1651 \"Almagestum Novum\", writing that rotation of the Earth should cause a cannonball fired to the north to deflect to the east. In 1674, Claude Fran\u00e7ois Milliet Dechales described in his \"Cursus seu Mundus Mathematicus\" how the rotation of the Earth should cause a deflection in the trajectories of both falling bodies and projectiles aimed toward one of the planet's poles. Riccioli, Grimaldi, and Dechales all described the effect as part of an argument against the heliocentric system of Copernicus. In other words, they argued that the Earth's rotation should create the effect, and so failure to detect the effect was evidence for an immobile Earth. The Coriolis acceleration equation was derived by Euler in 1749, and the effect was described in the tidal equations of Pierre-Simon Laplace in 1778.\nGaspard-Gustave de Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. That paper considered the supplementary forces that are detected in a rotating frame of reference. Coriolis divided these supplementary forces into two categories. The second category contained a force that arises from the cross product of the angular velocity of a coordinate system and the projection of a particle's velocity into a plane perpendicular to the system's axis of rotation. Coriolis referred to this force as the \"compound centrifugal force\" due to its analogies with the centrifugal force already considered in category one. The effect was known in the early 20th century as the \"acceleration of Coriolis\", and by 1920 as \"Coriolis force\".\nIn 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes with air being deflected by the Coriolis force to create the prevailing westerly winds.\nThe understanding of the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Late in the 19th century, the full extent of the large scale interaction of pressure-gradient force and deflecting force that in the end causes air masses to move along isobars was understood.\nFormula.\nIn Newtonian mechanics, the equation of motion for an object in an inertial reference frame is:\nwhere formula_2 is the vector sum of the physical forces acting on the object, formula_3 is the mass of the object, and formula_4 is the acceleration of the object relative to the inertial reference frame.\nTransforming this equation to a reference frame rotating about a fixed axis through the origin with angular velocity formula_5 having variable rotation rate, the equation takes the form:\nwhere the \"prime\" (') variables denote coordinates of the rotating reference frame (not a derivative) and:\nThe fictitious forces as they are perceived in the rotating frame act as additional forces that contribute to the apparent acceleration just like the real external forces. The fictitious force terms of the equation are, reading from left to right:\nAs seen in these formulas the Euler and centrifugal forces depend on the position vector formula_9 of the object, while the Coriolis force depends on the object's velocity formula_10 as measured in the rotating reference frame. As expected, for a non-rotating inertial frame of reference formula_17 the Coriolis force and all other fictitious forces disappear.\nDirection of Coriolis force for simple cases.\nAs the Coriolis force is proportional to a cross product of two vectors, it is perpendicular to both vectors, in this case the object's velocity and the frame's rotation vector. It therefore follows that:\nIntuitive explanation.\nFor an intuitive explanation of the origin of the Coriolis force, consider an object, constrained to follow the Earth's surface and moving northward in the Northern Hemisphere. Viewed from outer space, the object does not appear to go due north, but has an eastward motion (it rotates around toward the right along with the surface of the Earth). The further north it travels, the smaller the \"radius of its parallel (latitude)\" (the minimum distance from the surface point to the axis of rotation, which is in a plane orthogonal to the axis), and so the slower the eastward motion of its surface. As the object moves north it has a tendency to maintain the eastward speed it started with (rather than slowing down to match the reduced eastward speed of local objects on the Earth's surface), so it veers east (i.e. to the right of its initial motion).\nThough not obvious from this example, which considers northward motion, the horizontal deflection occurs equally for objects moving eastward or westward (or in any other direction). However, the theory that the effect determines the rotation of draining water in a household bathtub, sink or toilet has been repeatedly disproven by modern-day scientists; the force is negligibly small compared to the many other influences on the rotation.\nLength scales and the Rossby number.\nThe time, space, and velocity scales are important in determining the importance of the Coriolis force. Whether rotation is important in a system can be determined by its Rossby number (Ro), which is the ratio of the velocity, \"U\", of a system to the product of the Coriolis parameter, formula_18, and the length scale, \"L\", of the motion:\nHence, it is the ratio of inertial to Coriolis forces; a small Rossby number indicates a system is strongly affected by Coriolis forces, and a large Rossby number indicates a system in which inertial forces dominate. For example, in tornadoes, the Rossby number is large, so in them the Coriolis force is negligible, and balance is between pressure and centrifugal forces. In low-pressure systems the Rossby number is low, as the centrifugal force is negligible; there, the balance is between Coriolis and pressure forces. In oceanic systems the Rossby number is often around 1, with all three forces comparable.\nAn atmospheric system moving at \"U\"\u00a0=\u00a0 occupying a spatial distance of \"L\"\u00a0=\u00a0, has a Rossby number of approximately 0.1.\nA baseball pitcher may throw the ball at \"U\"\u00a0=\u00a0 for a distance of \"L\"\u00a0=\u00a0. The Rossby number in this case would be 32,000 (at latitude 31\u00b047'46.382\").\nBaseball players don't care about which hemisphere they're playing in. However, an unguided missile obeys exactly the same physics as a baseball, but can travel far enough and be in the air long enough to experience the effect of Coriolis force. Long-range shells in the Northern Hemisphere landed close to, but to the right of, where they were aimed until this was noted. (Those fired in the Southern Hemisphere landed to the left.) In fact, it was this effect that first drew the attention of Coriolis himself.\nSimple cases.\nTossed ball on a rotating carousel.\nThe figures illustrate a ball tossed from 12:00\u00a0o'clock toward the center of a counter-clockwise rotating carousel. In the first figure, the ball is seen by a stationary observer above the carousel, and the ball travels in a straight line slightly to the right of the center, because it had an initial tangential velocity given by the rotation (blue arrow) and a radial velocity given by the thrower (green arrow). The resulting combined velocity is shown as a solid red line, and the trajectory is shown as a dotted red line. In the second figure, the ball is seen by an observer rotating with the carousel, so the ball-thrower appears to stay at 12:00\u00a0o'clock, and the ball trajectory has a slight curve.\nBounced ball.\nThe figure describes a more complex situation where the tossed ball on a turntable bounces off the edge of the carousel and then returns to the tosser, who catches the ball. The effect of Coriolis force on its trajectory is shown again as seen by two observers: an observer (referred to as the \"camera\") that rotates with the carousel, and an inertial observer. The figure shows a bird's-eye view based upon the same ball speed on forward and return paths. Within each circle, plotted dots show the same time points. In the left panel, from the camera's viewpoint at the center of rotation, the tosser (smiley face) and the rail both are at fixed locations, and the ball makes a very considerable arc on its travel toward the rail, and takes a more direct route on the way back. From the ball tosser's viewpoint, the ball seems to return more quickly than it went (because the tosser is rotating toward the ball on the return flight).\nOn the carousel, instead of tossing the ball straight at a rail to bounce back, the tosser must throw the ball toward the right of the target and the ball then seems to the camera to bear continuously to the left of its direction of travel to hit the rail (\"left\" because the carousel is turning \"clockwise\"). The ball appears to bear to the left from direction of travel on both inward and return trajectories. The curved path demands this observer to recognize a leftward net force on the ball. (This force is \"fictitious\" because it disappears for a stationary observer, as is discussed shortly.) For some angles of launch, a path has portions where the trajectory is approximately radial, and Coriolis force is primarily responsible for the apparent deflection of the ball (centrifugal force is radial from the center of rotation, and causes little deflection on these segments). When a path curves away from radial, however, centrifugal force contributes significantly to deflection.\nThe ball's path through the air is straight when viewed by observers standing on the ground (right panel). In the right panel (stationary observer), the ball tosser (smiley face) is at 12\u00a0o'clock and the rail the ball bounces from is at position\u00a01. From the inertial viewer's standpoint, positions\u00a01, 2, and 3 are occupied in sequence. At position\u00a02, the ball strikes the rail, and at position\u00a03, the ball returns to the tosser. Straight-line paths are followed because the ball is in free flight, so this observer requires that no net force is applied.\nApplied to the Earth.\nThe acceleration affecting the motion of air \"sliding\" over the Earth's surface is the horizontal component of the Coriolis term\nThis component is orthogonal to the velocity over the Earth surface and is given by the expression\nwhere\nIn the northern hemisphere, where the latitude is positive, this acceleration, as viewed from above, is to the right of the direction of motion. Conversely, it is to the left in the southern hemisphere.\nRotating sphere.\nConsider a location with latitude \"\u03c6\" on a sphere that is rotating around the north\u2013south axis. A local coordinate system is set up with the \"x\" axis horizontally due east, the \"y\" axis horizontally due north and the \"z\" axis vertically upwards. The rotation vector, velocity of movement and Coriolis acceleration expressed in this local coordinate system [listing components in the order east (e), north (n) and upward (u)] are:\nWhen considering atmospheric or oceanic dynamics, the vertical velocity is small, and the vertical component of the Coriolis acceleration (formula_27) is small compared with the acceleration due to gravity (g, approximately near Earth's surface). For such cases, only the horizontal (east and north) components matter. The restriction of the above to the horizontal plane is (setting \"vu\"\u00a0=\u00a00):\nwhere formula_18 is called the Coriolis parameter.\nBy setting \"v\"n = 0, it can be seen immediately that (for positive \"\u03c6\" and \"\u03c9\") a movement due east results in an acceleration due south; similarly, setting \"v\"e = 0, it is seen that a movement due north results in an acceleration due east. In general, observed horizontally, looking along the direction of the movement causing the acceleration, the acceleration always is turned 90\u00b0 to the right (for positive \"\u03c6\") and of the same size regardless of the horizontal orientation.\nIn the case of equatorial motion, setting \"\u03c6\" = 0\u00b0 yields:\n\u03a9 in this case is parallel to the north-south axis.\nAccordingly, an eastward motion (that is, in the same direction as the rotation of the sphere) provides an upward acceleration known as the E\u00f6tv\u00f6s effect, and an upward motion produces an acceleration due west.\nMeteorology and oceanography.\nPerhaps the most important impact of the Coriolis effect is in the large-scale dynamics of the oceans and the atmosphere. In meteorology and oceanography, it is convenient to postulate a rotating frame of reference wherein the Earth is stationary. In accommodation of that provisional postulation, the centrifugal and Coriolis forces are introduced. Their relative importance is determined by the applicable Rossby numbers. Tornadoes have high Rossby numbers, so, while tornado-associated centrifugal forces are quite substantial, Coriolis forces associated with tornadoes are for practical purposes negligible.\nBecause surface ocean currents are driven by the movement of wind over the water's surface, the Coriolis force also affects the movement of ocean currents and cyclones as well. Many of the ocean's largest currents circulate around warm, high-pressure areas called gyres. Though the circulation is not as significant as that in the air, the deflection caused by the Coriolis effect is what creates the spiralling pattern in these gyres. The spiralling wind pattern helps the hurricane form. The stronger the force from the Coriolis effect, the faster the wind spins and picks up additional energy, increasing the strength of the hurricane.\nAir within high-pressure systems rotates in a direction such that the Coriolis force is directed radially inwards, and nearly balanced by the outwardly radial pressure gradient. As a result, air travels clockwise around high pressure in the Northern Hemisphere and anticlockwise in the Southern Hemisphere. Air around low-pressure rotates in the opposite direction, so that the Coriolis force is directed radially outward and nearly balances an inwardly radial pressure gradient.\nFlow around a low-pressure area.\nIf a low-pressure area forms in the atmosphere, air tends to flow in towards it, but is deflected perpendicular to its velocity by the Coriolis force. A system of equilibrium can then establish itself creating circular movement, or a cyclonic flow. Because the Rossby number is low, the force balance is largely between the pressure-gradient force acting towards the low-pressure area and the Coriolis force acting away from the center of the low pressure.\nInstead of flowing down the gradient, large scale motions in the atmosphere and ocean tend to occur perpendicular to the pressure gradient. This is known as geostrophic flow. On a non-rotating planet, fluid would flow along the straightest possible line, quickly eliminating pressure gradients. The geostrophic balance is thus very different from the case of \"inertial motions\" (see below), which explains why mid-latitude cyclones are larger by an order of magnitude than inertial circle flow would be.\nThis pattern of deflection, and the direction of movement, is called Buys-Ballot's law. In the atmosphere, the pattern of flow is called a cyclone. In the Northern Hemisphere the direction of movement around a low-pressure area is anticlockwise. In the Southern Hemisphere, the direction of movement is clockwise because the rotational dynamics is a mirror image there. At high altitudes, outward-spreading air rotates in the opposite direction. Cyclones rarely form along the equator due to the weak Coriolis effect present in this region.\nInertial circles.\nAn air or water mass moving with speed formula_34 subject only to the Coriolis force travels in a circular trajectory called an \"inertial circle\". Since the force is directed at right angles to the motion of the particle, it moves with a constant speed around a circle whose radius formula_35 is given by:\nwhere formula_37 is the Coriolis parameter formula_38, introduced above (where formula_39 is the latitude). The time taken for the mass to complete a full circle is therefore formula_40. The Coriolis parameter typically has a mid-latitude value of about 10\u22124\u00a0s\u22121; hence for a typical atmospheric speed of , the radius is with a period of about 17\u00a0hours. For an ocean current with a typical speed of , the radius of an inertial circle is . These inertial circles are clockwise in the northern hemisphere (where trajectories are bent to the right) and anticlockwise in the southern hemisphere.\nIf the rotating system is a parabolic turntable, then formula_37 is constant and the trajectories are exact circles. On a rotating planet, formula_37 varies with latitude and the paths of particles do not form exact circles. Since the parameter formula_37 varies as the sine of the latitude, the radius of the oscillations associated with a given speed are smallest at the poles (latitude of \u00b190\u00b0), and increase toward the equator.\nOther terrestrial effects.\nThe Coriolis effect strongly affects the large-scale oceanic and atmospheric circulation, leading to the formation of robust features like jet streams and western boundary currents. Such features are in geostrophic balance, meaning that the Coriolis and \"pressure gradient\" forces balance each other. Coriolis acceleration is also responsible for the propagation of many types of waves in the ocean and atmosphere, including Rossby waves and Kelvin waves. It is also instrumental in the so-called Ekman dynamics in the ocean, and in the establishment of the large-scale ocean flow pattern called the Sverdrup balance.\nE\u00f6tv\u00f6s effect.\nThe practical impact of the \"Coriolis effect\" is mostly caused by the horizontal acceleration component produced by horizontal motion.\nThere are other components of the Coriolis effect. Westward-traveling objects are deflected downwards, while eastward-traveling objects are deflected upwards. This is known as the E\u00f6tv\u00f6s effect. This aspect of the Coriolis effect is greatest near the equator. The force produced by the E\u00f6tv\u00f6s effect is similar to the horizontal component, but the much larger vertical forces due to gravity and pressure suggest that it is unimportant in the hydrostatic equilibrium. However, in the atmosphere, winds are associated with small deviations of pressure from the hydrostatic equilibrium. In the tropical atmosphere, the order of magnitude of the pressure deviations is so small that the contribution of the E\u00f6tv\u00f6s effect to the pressure deviations is considerable.\nIn addition, objects traveling upwards (i.e. \"out\") or downwards (i.e. \"in\") are deflected to the west or east respectively. This effect is also the greatest near the equator. Since vertical movement is usually of limited extent and duration, the size of the effect is smaller and requires precise instruments to detect. For example, idealized numerical modeling studies suggest that this effect can directly affect tropical large-scale wind field by roughly 10% given long-duration (2 weeks or more) heating or cooling in the atmosphere. Moreover, in the case of large changes of momentum, such as a spacecraft being launched into orbit, the effect becomes significant. The fastest and most fuel-efficient path to orbit is a launch from the equator that curves to a directly eastward heading.\nIntuitive example.\nImagine a train that travels through a frictionless railway line along the equator. Assume that, when in motion, it moves at the necessary speed to complete a trip around the world in one day (465\u00a0m/s). The Coriolis effect can be considered in three cases: when the train travels west, when it is at rest, and when it travels east. In each case, the Coriolis effect can be calculated from the rotating frame of reference on Earth first, and then checked against a fixed inertial frame. The image below illustrates the three cases as viewed by an observer at rest in a (near) inertial frame from a fixed point above the North Pole along the Earth's axis of rotation; the train is denoted by a few red pixels, fixed at the left side in the leftmost picture, moving in the others formula_44\nThis also explains why high-speed projectiles that travel west are deflected down, and those that travel east are deflected up. This vertical component of the Coriolis effect is called the E\u00f6tv\u00f6s effect.\nThe above example can be used to explain why the E\u00f6tv\u00f6s effect starts diminishing when an object is traveling westward as its tangential speed increases above Earth's rotation (465\u00a0m/s). If the westward train in the above example increases speed, part of the force of gravity that pushes against the track accounts for the centripetal force needed to keep it in circular motion on the inertial frame. Once the train doubles its westward speed at that centripetal force becomes equal to the force the train experiences when it stops. From the inertial frame, in both cases it rotates at the same speed but in the opposite directions. Thus, the force is the same cancelling completely the E\u00f6tv\u00f6s effect. Any object that moves westward at a speed above experiences an upward force instead. In the figure, the E\u00f6tv\u00f6s effect is illustrated for a object on the train at different speeds. The parabolic shape is because the centripetal force is proportional to the square of the tangential speed. On the inertial frame, the bottom of the parabola is centered at the origin. The offset is because this argument uses the Earth's rotating frame of reference. The graph shows that the E\u00f6tv\u00f6s effect is not symmetrical, and that the resulting downward force experienced by an object that travels west at high velocity is less than the resulting upward force when it travels east at the same speed.\nDraining in bathtubs and toilets.\nContrary to popular misconception, bathtubs, toilets, and other water receptacles do not drain in opposite directions in the Northern and Southern Hemispheres. This is because the magnitude of the Coriolis force is negligible at this scale. Forces determined by the initial conditions of the water (e.g. the geometry of the drain, the geometry of the receptacle, preexisting momentum of the water, etc.) are likely to be orders of magnitude greater than the Coriolis force and hence will determine the direction of water rotation, if any. For example, identical toilets flushed in both hemispheres drain in the same direction, and this direction is determined mostly by the shape of the toilet bowl.\nUnder real-world conditions, the Coriolis force does not influence the direction of water flow perceptibly. Only if the water is so still that the effective rotation rate of the Earth is faster than that of the water relative to its container, and if externally applied torques (such as might be caused by flow over an uneven bottom surface) are small enough, the Coriolis effect may indeed determine the direction of the vortex. Without such careful preparation, the Coriolis effect will be much smaller than various other influences on drain direction such as any residual rotation of the water and the geometry of the container.\nLaboratory testing of draining water under atypical conditions.\nIn 1962, Ascher Shapiro performed an experiment at MIT to test the Coriolis force on a large basin of water, across, with a small wooden cross above the plug hole to display the direction of rotation, covering it and waiting for at least 24 hours for the water to settle. Under these precise laboratory conditions, he demonstrated the effect and consistent counterclockwise rotation. The experiment required extreme precision, since the acceleration due to Coriolis effect is only formula_45 that of gravity. The vortex was measured by a cross made of two slivers of wood pinned above the draining hole. It takes 20 minutes to drain, and the cross starts turning only around 15 minutes. At the end it is turning at 1 rotation every 3 to 4 seconds.\nHe reported that,\nLloyd Trefethen reported clockwise rotation in the Southern Hemisphere at the University of Sydney in five tests with settling times of 18 h or more.\nBallistic trajectories.\nThe Coriolis force is important in external ballistics for calculating the trajectories of very long-range artillery shells. The most famous historical example was the Paris gun, used by the Germans during World War I to bombard Paris from a range of about . The Coriolis force minutely changes the trajectory of a bullet, affecting accuracy at extremely long distances. It is adjusted for by accurate long-distance shooters, such as snipers. At the latitude of Sacramento, California, a northward shot would be deflected to the right. There is also a vertical component, explained in the E\u00f6tv\u00f6s effect section above, which causes westward shots to hit low, and eastward shots to hit high.\nThe effects of the Coriolis force on ballistic trajectories should not be confused with the curvature of the paths of missiles, satellites, and similar objects when the paths are plotted on two-dimensional (flat) maps, such as the Mercator projection. The projections of the three-dimensional curved surface of the Earth to a two-dimensional surface (the map) necessarily results in distorted features. The apparent curvature of the path is a consequence of the sphericity of the Earth and would occur even in a non-rotating frame.\nThe Coriolis force on a moving projectile depends on velocity components in all three directions, latitude, and azimuth. The directions are typically downrange (the direction that the gun is initially pointing), vertical, and cross-range.\nwhere\nVisualization.\nTo demonstrate the Coriolis effect, a parabolic turntable can be used.\nOn a flat turntable, the inertia of a co-rotating object forces it off the edge. However, if the turntable surface has the correct paraboloid (parabolic bowl) shape (see the figure) and rotates at the corresponding rate, the force components shown in the figure make the component of gravity tangential to the bowl surface exactly equal to the centripetal force necessary to keep the object rotating at its velocity and radius of curvature (assuming no friction). (See .) This carefully contoured surface allows the Coriolis force to be displayed in isolation.\nDiscs cut from cylinders of dry ice can be used as pucks, moving around almost frictionlessly over the surface of the parabolic turntable, allowing effects of Coriolis on dynamic phenomena to show themselves. To get a view of the motions as seen from the reference frame rotating with the turntable, a video camera is attached to the turntable so as to co-rotate with the turntable, with results as shown in the figure. In the left panel of the figure, which is the viewpoint of a stationary observer, the gravitational force in the inertial frame pulling the object toward the center (bottom ) of the dish is proportional to the distance of the object from the center. A centripetal force of this form causes the elliptical motion. In the right panel, which shows the viewpoint of the rotating frame, the inward gravitational force in the rotating frame (the same force as in the inertial frame) is balanced by the outward centrifugal force (present only in the rotating frame). With these two forces balanced, in the rotating frame the only unbalanced force is Coriolis (also present only in the rotating frame), and the motion is an \"inertial circle\". Analysis and observation of circular motion in the rotating frame is a simplification compared with analysis and observation of elliptical motion in the inertial frame.\nBecause this reference frame rotates several times a minute rather than only once a day like the Earth, the Coriolis acceleration produced is many times larger and so easier to observe on small time and spatial scales than is the Coriolis acceleration caused by the rotation of the Earth.\nIn a manner of speaking, the Earth is analogous to such a turntable. The rotation has caused the planet to settle on a spheroid shape, such that the normal force, the gravitational force and the centrifugal force exactly balance each other on a \"horizontal\" surface. (See equatorial bulge.)\nThe Coriolis effect caused by the rotation of the Earth can be seen indirectly through the motion of a Foucault pendulum.\nIn other areas.\nCoriolis flow meter.\nA practical application of the Coriolis effect is the mass flow meter, an instrument that measures the mass flow rate and density of a fluid flowing through a tube. The operating principle involves inducing a vibration of the tube through which the fluid passes. The vibration, though not completely circular, provides the rotating reference frame that gives rise to the Coriolis effect. While specific methods vary according to the design of the flow meter, sensors monitor and analyze changes in frequency, phase shift, and amplitude of the vibrating flow tubes. The changes observed represent the mass flow rate and density of the fluid.\nMolecular physics.\nIn polyatomic molecules, the molecule motion can be described by a rigid body rotation and internal vibration of atoms about their equilibrium position. As a result of the vibrations of the atoms, the atoms are in motion relative to the rotating coordinate system of the molecule. Coriolis effects are therefore present, and make the atoms move in a direction perpendicular to the original oscillations. This leads to a mixing in molecular spectra between the rotational and vibrational levels, from which Coriolis coupling constants can be determined.\nGyroscopic precession.\nWhen an external torque is applied to a spinning gyroscope along an axis that is at right angles to the spin axis, the rim velocity that is associated with the spin becomes radially directed in relation to the external torque axis. This causes a \"torque-induced\" force to act on the rim in such a way as to tilt the gyroscope at right angles to the direction that the external torque would have tilted it. This tendency has the effect of keeping spinning bodies in their rotational frame.\nInsect flight.\nFlies (Diptera) and some moths (Lepidoptera) exploit the Coriolis effect in flight with specialized appendages and organs that relay information about the angular velocity of their bodies. Coriolis forces resulting from linear motion of these appendages are detected within the rotating frame of reference of the insects' bodies. In the case of flies, their specialized appendages are dumbbell shaped organs located just behind their wings called \"halteres\".\nThe fly's halteres oscillate in a plane at the same beat frequency as the main wings so that any body rotation results in lateral deviation of the halteres from their plane of motion.\nIn moths, their antennae are known to be responsible for the \"sensing\" of Coriolis forces in the similar manner as with the halteres in flies. In both flies and moths, a collection of mechanosensors at the base of the appendage are sensitive to deviations at the beat frequency, correlating to rotation in the pitch and roll planes, and at twice the beat frequency, correlating to rotation in the yaw plane.\nLagrangian point stability.\nIn astronomy, Lagrangian points are five positions in the orbital plane of two large orbiting bodies where a small object affected only by gravity can maintain a stable position relative to the two large bodies. The first three Lagrangian points (L1, L2, L3) lie along the line connecting the two large bodies, while the last two points (L4 and L5) each form an equilateral triangle with the two large bodies. The L4 and L5 points, although they correspond to maxima of the effective potential in the coordinate frame that rotates with the two large bodies, are stable due to the Coriolis effect. The stability can result in orbits around just L4 or L5, known as tadpole orbits, where trojans can be found. It can also result in orbits that encircle L3, L4, and L5, known as horseshoe orbits."}
{"id": "7786", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7786", "title": "Challenger Deep", "text": "The Challenger Deep is the deepest known point of the seabed of Earth, located in the western Pacific Ocean at the southern end of the Mariana Trench, in the ocean territory of the Federated States of Micronesia.\nThe GEBCO Gazetteer of Undersea Feature Names indicates that the feature is situated at and has a maximum depth of below sea level. A subsequent study revised the value to at a 95% confidence interval. However, both the precise geographic location and depth remain ambiguous, with contemporary measurements ranging from .\nThe depression is named after the British Royal Navy survey ships , whose expedition of 1872\u20131876 first located it, and HMS \"Challenger II\", whose expedition of 1950\u20131952 established its record-setting depth. The first descent by any vehicle was conducted by the United States Navy using the bathyscaphe \"Trieste\" in January 1960. , there were 27 people who have descended to the Challenger Deep.\nTopography.\nThe Challenger Deep is a relatively small slot-shaped depression in the bottom of a considerably larger crescent-shaped oceanic trench, which itself is an unusually deep feature in the ocean floor. The Challenger Deep consists of three basins, each long, wide, and over in depth, oriented in echelon from west to east, separated by mounds between the basins higher. The three basins feature extends about west to east if measured at the isobath. Both the western and eastern basins have recorded depths (by sonar bathymetry) in excess of , while the center basin is slightly less deep. The closest land to the Challenger Deep is Fais Island (one of the outer islands of Yap), southwest, and Guam, to the northeast.\nDetailed sonar mapping of the western, center and eastern basins in June 2020 by the DSSV \"Pressure Drop\" combined with manned descents revealed that they undulate with slopes and piles of rocks above a bed of pelagic ooze. This conforms with the description of Challenger Deep as consisting of an elongated seabed section with distinct sub-basins or sediment-filled pools.\nSurveys and bathymetry.\nOver many years, the search for, and investigation of, the location of the maximum depth of the world's oceans has involved many different vessels, and continues into the twenty-first century.\nThe accuracy of determining geographical location, and the beamwidth of (multibeam) echosounder systems, limits the horizontal and vertical bathymetric sensor resolution that hydrographers can obtain from onsite data. This is especially important when sounding in deep water, as the resulting footprint of an acoustic pulse gets large once it reaches a distant sea floor. Further, sonar operation is affected by variations in sound speed, particularly in the vertical plane. The speed is determined by the water's bulk modulus, mass, and density. The bulk modulus is affected by temperature, pressure, and dissolved impurities (usually salinity).\n1875 \u2013 HMS \"Challenger\".\nIn 1875, during her transit from the Admiralty Islands in the Bismarck Archipelago to Yokohama in Japan, the three-masted sailing corvette HMS \"\"Challenger\" \"attempted to make landfall at Spanish Marianas (now Guam), but was set to the west by \"baffling winds\" preventing her crew from \"visiting either the Carolines or the Ladrones.\" Their altered path took them over the undersea canyon which later became known as the Challenger Deep. Depth soundings were taken by Baillie-weighted marked rope, and geographical locations were determined by celestial navigation (to an estimated accuracy of two nautical miles). One of their samples was taken within fifteen miles of the deepest spot in all of Earth's oceans. On 23 March 1875, at sample station number #225, HMS \"Challenger\" recorded the bottom at deep, (the deepest sounding of her three-plus-year eastward circumnavigation of the Earth) at \u2013 and confirmed it with a second sounding at the same location. The serendipitous discovery of Earth's deepest depression by history's first major scientific expedition devoted entirely to the emerging science of oceanography, was incredibly good fortune, and especially notable when compared to the Earth's third deepest site (the Sirena Deep only 150 nautical miles east of the Challenger Deep), which would remain undiscovered for another 122 years.\n1951 \u2013 SV HMS \"Challenger II\".\nSeventy-five years later, the 1,140-ton British survey vessel HMS \"Challenger II\", on her three-year westward circumnavigation of Earth, investigated the extreme depths southwest of Guam reported in 1875 by her predecessor, HMS \"Challenger\". On her southbound track from Japan to New Zealand (May\u2013July 1951), \"Challenger II\" conducted a survey of the Marianas Trench between Guam and Ulithi atoll, using seismic-sized bomb-soundings and recorded a maximum depth of . The depth was beyond \"Challenger II\" echo sounder capability to verify, so they resorted to using a taut wire with \"140\u00a0lbs of scrap iron\", and documented a depth of . The Senior Scientist aboard \"Challenger II\", Thomas Gaskell, recalled: [I]t took from ten past five in the evening until twenty to seven, that is an hour and a half, for the iron weight to fall to the sea-bottom.\u00a0It was almost dark by the time the weight struck, but great excitement greeted the reading...In New Zealand, the \"Challenger II\" team gained the assistance of the Royal New Zealand Dockyard, \"who managed to boost the echo sounder to record at the greatest depths\". They returned to the \"Marianas Deep\" (sic) in October 1951. Using their newly improved echo sounder, they ran survey lines at right angles to the axis of the trench and discovered \"a considerable area of a depth greater than \" \u2013 later identified as the Challenger Deep's \"western\" basin. The greatest depth recorded was , at . Navigational accuracy of several hundred meters was attained by celestial navigation and LORAN-A. As Gaskell explained, the measurement was not more than 50 miles from the spot where the nineteenth-century \"Challenger\" found her deepest depth [...] and it may be thought fitting that a ship with the name \"Challenger\" should put the seal on the work of that great pioneering expedition of oceanography.The term \"Challenger Deep\" came into use after this 1951\u201352 \"Challenger\" circumnavigation, and commemorates both British ships of that name involved with the discovery of the deepest basin of the world's oceans.\n1957\u20131958 \u2013 RV \"Vityaz\".\nIn August 1957, the Soviet 3,248-ton Vernadsky Institute of Geochemistry research vessel recorded a maximum depth of at in the western basin of the Challenger Deep during a brief transit of the area on Cruise #25. She returned in 1958, Cruise #27, to conduct a detailed single beam bathymetry survey involving over a dozen transects of the Deep, with an extensive examination of the western basin and a quick peek into the eastern basin. Fisher records a total of three \"Vityaz\" sounding locations on Fig.2 \"Trenches\" (1963), one within yards of the 142\u00b011.5' E location, and a third at , all with depth. The depths were considered statistical outliers, and a depth greater than 11,000 m has never been proven. Taira reports that if \"Vityaz\" depth was corrected with the same methodology used by the Japanese RV \"Hakuho Maru\" expedition of December 1992, it would be presented as , as opposed to modern depths from multibeam echosounder systems greater than with the NOAA accepted maximum of in the western basin.\n1959 \u2013 RV \"Stranger\".\nThe first definitive verification of both the depth and location of the Challenger Deep (western basin) was determined by Dr. R. L. Fisher from the Scripps Institution of Oceanography, aboard the 325-ton research vessel \"Stranger\". Using explosive soundings, they recorded at/near in July 1959. \"Stranger\" used celestial and LORAN-C for navigation. LORAN-C navigation provided geographical accuracy of or better. According to another source RV \"Stranger\" using bomb-sounding surveyed a maximum depth of at . Discrepancies between the geographical location (lat/long) of \"Stranger\" deepest depths and those from earlier expeditions (\"Challenger II\" 1951; \"Vityaz\" 1957 and 1958) \"are probably due to uncertainties in fixing the ships' positions\". \"Stranger\" north-south zig-zag survey passed well to the east of the eastern basin southbound, and well to the west of the eastern basin northbound, thus failed to discover the eastern basin of the Challenger Deep. The maximum depth measured near longitude 142\u00b030'E was , about 10\u00a0km west of the eastern basin's deepest point. This was an important gap in information, as the eastern basin was later reported as deeper than the other two basins.\n\"Stranger\" crossed the center basin twice, measuring a maximum depth of in the vicinity of 142\u00b022'E. At the western end of the central basin (approximately 142\u00b018'E), they recorded a depth of .\nThe western basin received four transects by \"Stranger\", recording depths of toward the central basin, near where \"Trieste\" dived in 1960 (vicinity , and where \"Challenger II\", in 1950, recorded . At the far western end of the \"western\" basin (about 142\u00b011'E), the \"Stranger\" recorded , some 6\u00a0km south of the location where \"Vityaz\" recorded in 1957\u20131958. Fisher stated: \"differences in the \"Vitiaz\" [sic] and \"Stranger\"\u2013\"Challenger II\" depths can be attributed to the [sound] velocity correction function used\". \nAfter investigating the Challenger Deep, \"Stranger\" proceeded to the Philippine Trench and transected the trench over twenty times in August 1959, finding a maximum depth of , and thus established that the Challenger Deep was about deeper than the Philippine Trench. The 1959 \"Stranger\" surveys of the Challenger Deep and of the Philippine Trench informed the U.S. Navy as to the appropriate site for \"Trieste\" record dive in 1960.\n1962 \u2013 RV \"Spencer F. Baird\".\nThe \"Proa Expedition, Leg 2\", returned Fisher to the Challenger Deep on 12\u201313 April 1962 aboard the Scripps research vessel \"Spencer F. Baird\" (formerly the steel-hulled US Army large tug \"LT-581\") and employed a Precision Depth Recorder (PDR) to verify the extreme depths previously reported. They recorded a maximum depth of (location not available). Additionally, at location \"H-4\" in the Challenger Deep, the expedition cast three taut-wire soundings: on 12 April, the first cast was to 5,078 fathoms (corrected for wire angle) at in the central basin (Up until 1965, US research vessels recorded soundings in fathoms). The second cast, also on 12 April, was to 5,000+ fathoms at in the central basin. On 13 April, the final cast recorded 5,297 fathoms (corrected for wire angle) at (the western basin). They were chased off by a hurricane after only two days on-site. Once again, Fisher entirely missed the eastern basin of the Challenger Deep, which later proved to contain the deepest depths.\n1975\u20131980 \u2013 RV \"Thomas Washington\".\nThe Scripps Institution of Oceanography deployed the 1,490-ton Navy-owned, civilian-crewed research vessel \"Thomas Washington\" (AGOR-10) to the Mariana Trench on several expeditions from 1975 to 1986. The first of these was the \"Eurydice Expedition, Leg 8\" which brought Fisher back to the Challenger Deep's western basin from 28\u201331 March 1975. \"Thomas Washington\" established geodetic positioning by (SATNAV) with Autolog Gyro and EM Log. Bathymetrics were by a 12\u00a0kHz Precision Depth Recorder (PDR) with a single 60\u00b0 beam. They mapped one, \"possibly two\", axial basins with a depth of . Five dredges were hauled 27\u201331 March, all into or slightly north of the deepest depths of the western basin. Fisher noted that this survey of the Challenger Deep (western basin) had \"provided nothing to support and much to refute recent claims of depths there greater than .\" While Fisher missed the eastern basin of the Challenger Deep (for the third time), he did report a deep depression about 150 nautical miles east of the western basin. The 25 March dredge haul at encountered , which pre-shadowed by 22 years the discovery of HMRG Deep/Sirena Deep in 1997. The deepest waters of the HMRG Deep/Sirena Deep at are centered at/near , approximately 2.65\u00a0km from Fisher's 25 March 1975 dredge haul.\nOn Scripps Institution of Oceanography's \"INDOPAC Expedition Leg 3\", the chief scientist, Dr. Joseph L. Reid, and oceanographer Arnold W. Mantyla made a hydrocast of a free vehicle (a special-purpose benthic lander (or \"baited camera\") for measurements of water temperature and salinity) on 27 May 1976 into the western basin of the Challenger Deep, \"Station 21\", at at about depth. On \"INDOPAC Expedition Leg 9\", under chief scientist A. Aristides Yayanos, \"Thomas Washington\" spent nine days from 13\u201321 January 1977 conducting an extensive and detailed investigation of the Challenger Deep, mainly with biological objectives. \"Echo soundings were carried out primarily with a 3.5 kHz single-beam system, with a 12 kHz echosounder operated in addition some of the time\" (the 12\u00a0kHz system was activated for testing on 16 January). A benthic lander was put into the western basin () on 13 January, bottoming at and recovered 50 hours later in damaged condition. Quickly repaired, it was again put down on the 15th to depth at . It was recovered on the 17th with excellent photography of amphipods (shrimp) from the Challenger Deep's western basin. The benthic lander was put down for the third and last time on the 17th, at , in the central basin at a depth of . The benthic lander was not recovered and may remain on the bottom in the vicinity of . Free traps and pressure-retaining traps were put down at eight locations from 13 to 19 January into the western basin, at depths ranging from . Both the free traps and the pressure-retaining traps brought up good sample amphipods for study. While the ship briefly visited the area of the eastern basin, the expedition did not recognize it as potentially the deepest of the three Challenger Deep basins.\n\"Thomas Washington\" returned briefly to the Challenger Deep on 17\u201319 October 1978 during \"Mariana Expedition Leg 5\" under chief scientist James W. Hawkins. The ship tracked to the south and west of the eastern basin, and recorded depths between . Another miss. On \"Mariana Expedition Leg 8\", under chief scientist Yayanos, \"Thomas Washington\" was again involved, from 12\u201321 December 1978, with an intensive biological study of the western and central basins of the Challenger Deep. Fourteen traps and pressure-retaining traps were put down to depths ranging from ; the greatest depth was at . All of the 10,900-plus m recordings were in the western basin. The depth was furthest east at 142\u00b026.4' E (in the central basin), about 17\u00a0km west of the eastern basin. Again, focused efforts on the known areas of extreme depths (the western and central basins) were so tight that the eastern basin again was missed by this expedition.\nFrom 20 to 30 November 1980, \"Thomas Washington\" was on site at the western basin of the Challenger Deep, as part of \"Rama Expedition Leg 7\", again with chief-scientist Dr. A. A. Yayanos. Yayanos directed \"Thomas Washington\" in arguably the most extensive and wide-ranging of all single-beam bathymetric examinations of the Challenger Deep ever undertaken, with dozens of transits of the western basin, and ranging far into the backarc of the Challenger Deep (northward), with significant excursions into the Pacific Plate (southward) and along the trench axis to the east. They hauled eight dredges in the western basin to depths ranging from , and between hauls, cast thirteen free vertical traps. The dredging and traps were for biological investigation of the bottom. In the first successful retrieval of a live animal from the Challenger Deep, on 21 November 1980 in the western basin at , Yayanos recovered a live amphipod from about 10,900 meters depth with a pressurized trap. Once again, other than a brief look into the eastern basin, all bathymetric and biological investigations were into the western basin.\n1976\u20131977 \u2013 RV \"Kana Keoki\".\nOn Leg 3 of the Hawaii Institute of Geophysics' (HIG) expedition 76010303, the research vessel \"Kana Keoki\" departed Guam primarily for a seismic investigation of the Challenger Deep area, under chief scientist Donald M. Hussong. The ship was equipped with air guns (for seismic reflection soundings deep into the Earth's mantle), magnetometer, gravimeter, 3.5\u00a0kHz and 12\u00a0kHz sonar transducers, and precision depth recorders. They ran the Deep from east to west, collecting single beam bathymetry, magnetic and gravity measurements, and employed the air guns along the trench axis, and well into the backarc and forearc, from 13 to 15 March 1976. Thence they proceeded south to the Ontong Java Plateau. All three deep basins of the Challenger Deep were covered, but \"Kana Keoki\" recorded a maximum depth of . Seismic information developed from this survey was instrumental in gaining an understanding of the subduction of the Pacific Plate under the Philippine Sea Plate. In 1977, \"Kana Keoki\" returned to the Challenger Deep area for wider coverage of the forearc and backarc.\n1984 \u2013 SV \"Takuyo\".\nThe Hydrographic Department, Maritime Safety Agency, Japan (JHOD) deployed the newly commissioned 2,600-ton survey vessel \"Takuyo\" (HL 02) to the Challenger Deep 17\u201319 February 1984. \"Takuyo\" was the first Japanese ship to be equipped with the new narrowbeam SeaBeam multi-beam sonar echosounder, and was the first survey ship with multi-beam capability to survey the Challenger Deep. The system was so new that JHOD had to develop their own software for drawing bathymetric charts based on the SeaBeam digital data. In just three days, they tracked 500 miles of sounding lines, and covered about 140\u00a0km of the Challenger Deep with multibeam ensonification. Under chief scientist Hideo Nishida, they used CTD temperature and salinity data from the top of the water column to correct depth measurements, and later conferred with Scripps Institution of Oceanography (including Fisher), and other GEBCO experts to confirm their depth correction methodology. They employed a combination of NAVSAT, LORAN-C and OMEGA systems for geodetic positioning with accuracy better than . The deepest location recorded was at ; for the first time documenting the eastern basin as the deepest of the three en echelon pools. In 1993, GEBCO recognized the report as the deepest depth of the world's oceans. Technological advances such as improved multi-beam sonar would be the driving force in uncovering the mysteries of the Challenger Deep into the future.\n1986 \u2013 RV \"Thomas Washington\".\nThe Scripps research vessel \"Thomas Washington\" returned to the Challenger Deep in 1986 during the \"Papatua Expedition, Leg 8\", mounting one of the first commercial multi-beam echosounders capable of reaching into the deepest trenches, i.e. the 16-beam Seabeam \"Classic\". This allowed chief scientist Yayanos an opportunity to transit the Challenger Deep with the most modern depth-sounding equipment available. During the pre-midnight hours of 21 April 1986, the multibeam echosounder produced a map of the Challenger Deep bottom with a swath of about 5\u20137 miles wide. The maximum depth recorded was (location of depth is not available). Yayanos noted: \"The lasting impression from this cruise comes from the thoughts of the revolutionary things that Seabeam data can do for deep biology.\"\n1988 \u2013 RV \"Moana Wave\".\nOn 22 August 1988, the U.S. Navy-owned 1,000-ton research vessel \"Moana Wave\" (AGOR-22), operated by the Hawaii Institute of Geophysics (HIG), University of Hawaii, under the direction of chief scientist Robert C. Thunell from the University of South Carolina, transited northwesterly across the central basin of the Challenger Deep, conducting a single-beam bathymetry track by their 3.5\u00a0kHz narrow (30-degs) beam echosounder with a Precision Depth Recorder. In addition to sonar bathymetry, they took 44 gravity cores and 21 box cores of bottom sediments. The deepest echosoundings recorded were , with the greatest depth at 11\u00b022\u2032N 142\u00b025\u2032E in the central basin. This was the first indication that all three basins contained depths in excess of .\n1992 \u2013 RV \"Hakuh\u014d Maru\".\nThe 3,987-ton Japanese research vessel \"Hakuh\u014d Maru\", an Ocean Research Institute \u2013 University of Tokyo sponsored ship, on cruise KH-92-5 cast three Sea-Bird SBE-9 ultra-deep CTD (conductivity-temperature-depth) profilers in a transverse line across the Challenger Deep on 1 December 1992. The center CTD was located at , in the eastern basin, at by the SeaBeam depth recorder and by the CTD. The other two CTDs were cast 19.9\u00a0km to the north and 16.1\u00a0km to the south. \"Hakuh\u014d Maru\" was equipped with a narrow beam SeaBeam 500 multi-beam echosounder for depth determination, and had an Auto-Nav system with inputs from NAVSAT/NNSS, GPS, Doppler Log, EM log and track display, with a geodetic positioning accuracy approaching . When conducting CTD operations in the Challenger deep, they used the SeaBeam as a single beam depth recorder. At the corrected depth was , and at the depth was ; both in the \"eastern\" basin. This may demonstrate that the basins might not be flat sedimentary pools but rather undulate with a difference of or more. Taira revealed, \"We considered that a trough deeper that \"Vitiaz\" record by was detected. There is a possibility that a depth exceeding with a horizontal scale less than the beam width of measurements exists in the Challenger Deep. Since each SeaBeam 2.7-degree beam width sonar ping expands to cover a circular area about in diameter at depth, dips in the bottom that are less than that size would be difficult to detect from a sonar-emitting platform seven miles above.\n1996 \u2013 RV \"Yokosuka\".\nFor most of 1995 and into 1996, the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) employed the 4,439-ton Research Vessel \"Yokosuka\" to conduct the testing and workup of the 11,000-meter remotely-operated vehicle (ROV) \"Kaik\u014d\", and the 6,500 meter ROV \"Shinkai.\" It was not until February 1996, during \"Yokosuka\" cruise Y96-06, that \"Kaik\u014d\" was ready for its first full depth dives. On this cruise, JAMSTEC established an area of the Challenger Deep (11\u00b010'N to 11\u00b030'N, by 141\u00b050'E to 143\u00b000'Ewhich later was recognized as containing three separate pools/basins en echelon, each with depths in excess of ) toward which JAMSTEC expeditions would concentrate their investigations for the next two decades. The Yokosuka employed a 151-beam SeaBeam 2112 12\u00a0kHz multibeam echosounder, allowing search swaths 12\u201315\u00a0km in width at depth. The depth accuracy of \"Yokosuka\" Seabeam was about 0.1% of water depth (i.e. \u00b1 for depth). The ship's dual GPS systems attained geodetic positioning within double digit meter ( or better) accuracy.\n1998, 1999 and 2002 \u2013 RV \"Kairei\".\nCruise KR98-01 sent JAMSTEC's two-year-old 4,517-ton Deep Sea Research Vessel RV \"Kairei\" south for a quick but thorough depth survey of the Challenger Deep, 11\u201313 January 1998, under chief scientist Kantaro Fujioka. Tracking largely along the trench axis of 070\u2013250\u00b0 they made five 80-km bathymetric survey tracks, spaced about 15 km apart, overlapping their SeaBeam 2112-004 (which now allowed sub-bottom profiling penetrating as much as 75 m below the bottom) while gaining gravity and magnetic data covering the entire Challenger Deep: western, central, and eastern basins.\n\"Kairei\" returned in May 1998, cruise KR98-05, with ROV \"Kaik\u014d\", under the direction of chief scientist Jun Hashimoto with both geophysical and biological goals. Their bathymetric survey from 14\u201326 May was the most intensive and thorough depth and seismic survey of the Challenger Deep performed to date. Each evening, \"Kaik\u014d\" deployed for about four hours of bottom time for biological-related sampling, plus about seven hours of vertical transit time. When \"Kaik\u014d\" was onboard for servicing, \"Kairei\" conducted bathymetric surveys and observations. \"Kairei\" gridded a survey area about 130\u00a0km N\u2013S by 110\u00a0km E\u2013W. \"Kaik\u014d\" made six dives (#71\u201375) all to the same location, (11\u00b020.8' N, 142\u00b012.35' E), near the bottom contour line in the western basin.\nThe regional bathymetric map made from the data obtained in 1998 shows that the greatest depths in the eastern, central, and western depressions are , , and , respectively, making the eastern depression the deepest of the three.\nIn 1999, \"Kairei\" revisited the Challenger Deep during cruise KR99-06. The results of the 1998\u20131999 surveys include the first recognition that the Challenger Deep consists of three \"right-stepping en echelon individual basins bounded by the depth contour line. The size of [each of] the deeps are almost identical, 14\u201320 km long, 4\u00a0km wide\". They concluded with the proposal \"that these three individual elongated deeps constitute the 'Challenger Deep', and [we] identify them as the East, Central and West Deep. The deepest depth we obtained during the swath mapping is in the West Deep (11\u00b020.34' N, 142\u00b013.20 E).\" The depth was \"obtained during swath mapping\u00a0... confirmed in both N\u2013S and E-W swaths.\" Speed of sound corrections were from XBT to , and CTD below .\nThe cross track survey of the 1999 \"Kairei\" cruise shows that the greatest depths in the eastern, central, and western depressions are , , and , respectively, which supports the results of the previous survey.\nIn 2002 \"Kairei\" revisited the Challenger Deep 16\u201325 October 2002, as cruise KR02-13 (a cooperative Japan-US-South Korea research program) with chief scientist Jun Hashimoto in charge; again with Kazuyoshi Hirata managing the ROV \"Kaik\u014d\" team. On this survey, the size of each of the three basins was refined to 6\u201310\u00a0km long by about 2\u00a0km wide and in excess of deep. In marked contrast to the \"Kairei\" surveys of 1998 and 1999, the detailed survey in 2002 determined that the deepest point in the Challenger Deep is located in the eastern basin around , with a depth of , located about southeast of the deepest site determined by the survey vessel \"Takuyo\" in 1984. The 2002 surveys of both the western and eastern basins were tight, with especially meticulous cross-gridding of the eastern basin with ten parallel tracks N\u2013S and E\u2013W less than 250 meters apart. On the morning of 17 October, ROV \"Kaik\u014d\" dive #272 began and recovered over 33 hours later, with the ROV working at the bottom of the western basin for 26 hours (vicinity of 11\u00b020.148' N, 142\u00b011.774 E at ). Five \"Kaik\u014d\" dives followed on a daily basis into the same area to service benthic landers and other scientific equipment, with dive #277 recovered on 25 October. Traps brought up large numbers of amphipods (sea fleas), and cameras recorded holothurians (sea cucumbers), White polychaetes (bristle worms), tube worms, and other biological species. During its 1998, 1999 surveys, \"Kairei\" was equipped with a GPS satellite-based radionavigation system. The United States government lifted the GPS selective availability in 2000, so during its 2002 survey, \"Kairei\" had access to non-degraded GPS positional services and achieved single-digit meter accuracy in geodetic positioning.\n2001 \u2013 RV \"Melville\".\nThe 2.516-ton research vessel \"Melville\", at the time operated by the Scripps Institution of Oceanography, took the Cook Expedition, Leg 6 with chief scientist Patricia Fryer of the University of Hawaii from Guam on 10 February 2001 to the Challenger Deep for a survey titled \"Subduction Factory Studies in the Southern Mariana\", including HMR-1 sonar mapping, magnetics, gravity measurements, and dredging in the Mariana arc region. They covered all three basins, then tracked lines of bathymetry East-West, stepping northward from the Challenger Deep in sidesteps, covering more than north into the backarc with overlapping swaths from their SeaBeam 2000 12\u00a0kHz multi-beam echosounder and MR1 towed system. They also gathered magnetic and gravity information, but no seismic data. Their primary survey instrument was the MR1 towed sonar, a shallow-towed 11/12\u00a0kHz bathymetric sidescan sonar developed and operated by the Hawaii Mapping Research Group (HMRG), a research and operational group within University of Hawaii's School of Ocean and Earth Science and Technology (SOEST) and the Hawaii Institute of Geophysics and Planetology (HIGP). The MR1 is full-ocean-depth capable, providing both bathymetry and sidescan data.\nLeg 7 of the Cook Expedition continued the MR-1 survey of the Mariana Trench backarc from 4 March to 12 April 2001 under chief scientist Sherman Bloomer of Oregon State University.\n2009 \u2013 RV \"Kilo Moana\".\nIn May/June 2009, the US Navy-owned 3,064-ton twin-hulled research vessel \"Kilo Moana\" (T-AGOR 26) was sent to the Challenger Deep area to conduct research. \"Kilo Moana\" is civilian-crewed and operated by SOEST. It is equipped with two multibeam echosounders with sub-bottom profiler add-ons (the 191-beam 12\u00a0kHz Kongsberg Simrad EM120 with SBP-1200, capable of accuracies of 0.2\u20130.5% of water depth across the entire swath), gravimeter, and magnetometer. The EM-120 uses 1 by 1 degree sonar-emissions at the sea surface. Each 1 degree beam width sonar ping expands to cover a circular area about in diameter at depth. Whilst mapping the Challenger Deep the sonar equipment indicated a maximum depth of at an undisclosed position.&lt;ref name=\"Daily Reports for R/V KILO MOANA\"&gt;&lt;/ref&gt;&lt;ref name=\"Scientic Equipment aboard the R/V KILO MOANA\"&gt;&lt;/ref&gt; Navigation equipment includes the Applanix POS MV320 V4, rated at accuracies of 0.5\u20132\u00a0m. RV \"Kilo Moana\" was also used as the support ship of the hybrid remotely operated underwater vehicle (HROV) \"Nereus\" that dived three times to the Challenger Deep bottom during the May/June 2009 cruise and did not confirm the sonar established maximum depth by its support ship.\n2009 \u2013 RV \"Yokosuka\".\nCruise YK09-08 brought the JAMSTEC 4,429-ton research vessel \"Yokosuka\" back to the Mariana Trough and to the Challenger Deep June\u2013July 2009. Their mission was a two-part program: surveying three hydrothermal vent sites in the southern Mariana Trough backarc basin near 12\u00b057'N, 143\u00b037'E about 130 nmi northeast of the central basin of the Challenger Deep, using the autonomous underwater vehicle \"Urashima\". AUV \"Urashima\" dives #90\u201394, were to a maximum depth of 3500 meters, and were successful in surveying all three sites with a Reson SEABAT7125AUV multibeam echosounder for bathymetry, and multiple water testers to detect and map trace elements spewed into the water from hydrothermal vents, white smokers, and hot spots. Kyoko OKINO from the Ocean Research Institute, University of Tokyo, was principal investigator for this aspect of the cruise.\nThe second goal of the cruise was to deploy a new \"10K free fall camera system\" called \"Ashura\", to sample sediments and biologics at the bottom of the Challenger Deep. The principal investigator at the Challenger Deep was Taishi Tsubouchi of JAMSTEC. The lander \"Ashura\" made two descents: on the first, 6 July 2009, \"Ashura\" bottomed at at . The second descent (on 10 July 2009) was to at . The 270\u00a0kg \"Ashura\" was equipped with multiple baited traps, a HTDV video camera, and devices to recover sediment, water, and biological samples (mostly amphipods at the bait, and bacteria and fungus from the sediment and water samples).\n2010 \u2013 USNS \"Sumner\".\nOn 7 October 2010, further sonar mapping of the Challenger Deep area was conducted by the US Center for Coastal &amp; Ocean Mapping/Joint Hydrographic Center (CCOM/JHC) aboard the 4.762-ton \"Sumner\". The results were reported in December 2011 at the annual American Geophysical Union fall meeting. Using a Kongsberg Maritime EM 122 multi-beam echosounder system coupled to positioning equipment that can determine latitude and longitude up to accuracy, from thousands of individual soundings around the deepest part the CCOM/JHC team preliminary determined that the Challenger Deep has a maximum depth of at , with an estimated vertical uncertainty of \u00b1 at two standard deviations (i.e. \u2248 95.4%) confidence level. A secondary deep with a depth of was located at approximately to the east at in the eastern basin of the Challenger Deep.\n2010 \u2013 RV \"Yokosuka\".\nJAMSTEC returned \"Yokosuka\" to the Challenger Deep with cruise YK10-16, 21\u201328 November 2010. The chief scientist of this joint Japanese-Danish expedition was Hiroshi Kitazato of the Institute of Biogeosciences, JAMSTEC. The cruise was titled \"Biogeosciences at the Challenger Deep: relict organisms and their relations to biogeochemical cycles\". The Japanese teams made five deployments of their 11,000-meter camera system (three to 6,000 meters \u2013 two into the central basin of the Challenger Deep) which returned with 15 sediment cores, video records and 140 scavenging amphipod specimens. The Danish Ultra Deep Lander System was employed by Ronnie Glud et al on four casts, two into the central basin of the Challenger Deep and two to 6,000 m some 34 nmi west of the central basin. The deepest depth recorded was on 28 November 2010 \u2013 camera cast CS5 \u2013 }, at a corrected depth of (the central basin).\n2013 \u2013 RV \"Yokosuka\".\nWith JAMSTEC Cruises YK13-09 and YK13-12, \"Yokosuka\" hosted chief scientist Hidetaka Nomaki for a trip to New Zealand waters (YK13-09), with the return cruise identified as YK13-12. The project name was QUELLE2013; and the cruise title was: \"In situ experimental &amp; sampling study to understand abyssal biodiversity and biogeochemical cycles\". They spent one day on the return trip at the Challenger Deep to obtain DNA/RNA on the large amphipods inhabiting the Deep (\"Hirondellea gigas\"). Hideki Kobayashi (Biogeos, JAMSTEC) and the team deployed a benthic lander on 23 November 2013 with eleven baited traps (three bald, five covered by insulating materials, and three automatically sealed after nine hours) into the central basin of the Challenger Deep at , depth . After an eight-hour, 46-minute stay at the bottom, they recovered some 90 individual \"Hirondellea gigas\".\n2014 \u2013 RV \"Kairei\".\nJAMSTEC deployed \"Kairei\" to the Challenger Deep again 11\u201317 January 2014, under the leadership of chief scientist Takuro Nunora. The cruise identifier was KR14-01, titled: \"Trench biosphere expedition for the Challenger Deep, Mariana Trench\". The expedition sampled at six stations transecting the central basin, with only two deployments of the \"11-K camera system\" lander for sediment cores and water samples to \"Station C\" at the deepest depth, i.e. , at . The other stations were investigated with the \"Multi-core\" lander, both to the backarc northward, and to the Pacific Plate southward. The 11,000-meter capable crawler-driven ROV \"ABIMSO\" was sent to 7,646 m depth about 20 nmi due north of the central basin (ABISMO dive #21) specifically to identify possible hydrothermal activity on the north slope of the Challenger Deep, as suggested by findings from \"Kairei\" cruise KR08-05 in 2008. \"AMISMO\" dives #20 and #22 were to 7,900 meters about 15 nmi north of the deepest waters of the central basin. Italian researchers under the leadership of Laura Carugati from the Polytechnic University of Marche, Italy (UNIVPM) were investigating the dynamics in virus/prokaryotes interactions in the Mariana Trench.\n2014 \u2013 RV \"Falkor\".\nFrom 16\u201319 December 2014, the Schmidt Ocean Institute's 2,024-ton research vessel \"Falkor\", under chief scientist Douglas Bartlett from the Scripps Institution of Oceanography, deployed four different untethered instruments into the Challenger Deep for seven total releases. Four landers were deployed on 16 December into the central basin: the baited video-equipped lander \"Leggo\" for biologics; the lander \"ARI\" to for water chemistry; and the probes \"Deep Sound 3\" and \"Deep Sound 2\". Both Deep Sound probes recorded acoustics floating at depth, until \"Deep Sound 3\" imploded at the depth of (about above the bottom) at . The \"Deep Sound 2\" recorded the implosion of \"Deep Sound 3\", providing a unique recording of an implosion within the Challenger Deep depression. In addition to the loss of the \"Deep Sound 3\" by implosion, the lander \"ARI\" failed to respond upon receiving its instruction to drop weights, and was never recovered. On 16/17 December, \"Leggo\" was returned to the central basin baited for amphipods. On the 17th, RV \"Falkor\" relocated 17 nms eastward to the eastern basin, where they again deployed both the \"Leggo\" (baited and with its full camera load), and the \"Deep Sound 2\". \"Deep Sound 2\" was programmed to drop to and remain at that depth during its recording of sounds within the trench. On 19 December \"Leggo\" landed at at a uncorrected depth of according to its pressure sensor readings. This reading was corrected to depth. \"Leggo\" returned with good photography of amphipods feeding on the lander's mackerel bait and with sample amphipods. \"Falknor\" departed the Challenger Deep on 19 December en route the Marianas Trench Marine National Monument to the Sirena Deep. RV \"Falkor\" had both a Kongsberg EM302 and EM710 multibeam echosounder for bathymetry, and an Oceaneering C-Nav 3050 global navigation satellite system receiver, capable of calculating geodetic positioning with an accuracy better than horizontally and vertically.\n2015 \u2013 USCGC \"Sequoia\".\nFrom 10 to 13 July 2015, the Guam-based 1,930-ton US Coast Guard Cutter \"Sequoia\" (WLB 215) hosted a team of researchers, under chief scientist Robert P. Dziak, from the NOAA Pacific Marine Environmental Laboratory (PMEL), the University of Washington, and Oregon State University, in deploying PMEL's \"Full-Ocean Depth Mooring\", a 45-meter-long moored deep-ocean hydrophone and pressure sensor array into the western basin of the Challenger Deep. A 6-hour descent into the western basin anchored the array at of water depth, at , about 1\u00a0km northeast of \"Sumner\" deepest depth, recorded in 2010. After 16 weeks, the moored array was recovered on 2\u20134 November 2015. \"Observed sound sources included earthquake signals (T phases), baleen and odontocete cetacean vocalizations, ship propeller sounds, airguns, active sonar and the passing of a Category 4 typhoon.\" The science team described their results as \"the first multiday, broadband record of ambient sound at Challenger Deep, as well as only the fifth direct depth measurement\".\n2016 \u2013 RV \"Xiangyanghong 09\".\nThe 3,536-ton research vessel \"Xiangyanghong 09\" deployed on Leg II of the 37th China Cruise Dayang (DY37II) sponsored by the National Deep Sea Center, Qingdao and the Institute of Deep-Sea Science and Engineering, Chinese Academy of Sciences (Sanya, Hainan), to the Challenger Deep western basin area (11\u00b022' N, 142\u00b025' E) 4 June \u2013 12 July 2016. As the mother ship for China's manned deep submersible \"Jiaolong\", the expedition carried out an exploration of the Challenger Deep to investigate the geological, biological, and chemical characteristics of the hadal zone. The diving area for this leg was on the southern slope of the Challenger Deep, at depths from about . The submersible completed nine piloted dives on the northern backarc and south area (Pacific plate) of the Challenger Deep to depths from . During the cruise, \"Jiaolong\" regularly deployed gas-tight samplers to collect water near the sea bottom. In a test of navigational proficiency, \"Jiaolong\" used an Ultra-Short Base Line (USBL) positioning system at a depth more than to retrieve sampling bottles.\n2016 \u2013 RV \"Tansuo 01\".\nFrom 22 June to 12 August 2016 (cruises 2016S1 and 2016S2), the Chinese Academy of Sciences' 6,250-ton submersible support ship \"Tansuo 1\" (meaning: to explore) on her maiden voyage deployed to the Challenger Deep from her home port of Sanya, Hainan Island. On 12 July 2016, the ROV \"Haidou-1\" dived to a depth of in the Challenger Deep area. They also cast a free-drop lander, rated free-drop ocean-floor seismic instruments (deployed to ), obtained sediment core samples, and collected over 2000 biological samples from depths ranging from . The \"Tansuo 01\" operated along the 142\u00b030.00' longitude line, about 30 nmi east of the earlier DY37II cruise survey (see \"Xiangyanghong 09\" above).\n2016 \u2013 RV \"Sonne\".\nIn November 2016 sonar mapping of the Challenger Deep area was conducted by the Royal Netherlands Institute for Sea Research (NIOZ)/GEOMAR Helmholtz Centre for Ocean Research Kiel aboard the 8,554-ton Deep Ocean Research Vessel \"Sonne\". The results were reported in 2017. Using a Kongsberg Maritime EM 122 multi-beam echosounder system coupled to positioning equipment that can determine latitude and longitude the team determined that the Challenger Deep has a maximum depth of at (), with an estimated vertical uncertainty of \u00b1 at one standard deviation (\u2248 68.3%) confidence level. The analysis of the sonar survey offered a grid resolution at bottom depth, so small dips in the bottom that are less than that size would be difficult to detect from the 0.5 by 1 degree sonar-emissions at the sea surface. Each 0.5-degree beam width sonar ping expands to cover a circular area about in diameter at depth. The horizontal position of the grid point has an uncertainty of \u00b1, depending on along-track or across-track direction. This depth () and position (about to the northeast) measurements differ significantly from the deepest point determined by the Gardner et al. (2014) study. The observed depth discrepancy with the 2010 sonar mapping and Gardner et al 2014 study are related to the application of differing sound velocity profiles, which are essential for accurate depth determination. \"Sonne\" used CTD casts about 1.6\u00a0km west of the deepest sounding to near the bottom of the Challenger Deep that were used for sound velocity profile calibration and optimization. Likewise, the impact of using different projections, datum and ellipsoids during data acquisition can cause positional discrepancies between surveys.\n2016 \u2013 RV \"Shyian 3\".\nIn December 2016, the CAS 3,300-ton research vessel \"Shiyan 3\" deployed 33 broadband seismometers onto both the backarc northwest of the Challenger Deep, and onto the near southern Pacific Plate to the southeast, at depths of up to . This cruise was part of a $12 million Chinese-U.S. initiative, led by co-leader Jian Lin of the Woods Hole Oceanographic Institution; a 5-year effort (2017\u20132021) to image in fine detail the rock layers in and around the Challenger Deep.\n2016 \u2013 RV \"Zhang Jian\".\nThe newly launched 4,800-ton research vessel (and mothership for the \"Rainbow Fish\" series of deep submersibles), the \"Zhang Jian\" departed Shanghai on 3 December. Their cruise was to test three new deep-sea landers, one uncrewed search submersible and the new \"Rainbow Fish\" 11,000-meter manned deep submersible, all capable of diving to 10,000 meters. From 25 to 27 December, three deep-sea landing devices descended into the trench. The first Rainbow Fish lander took photographs, the second took sediment samples, and the third took biological samples. All three landers reached over 10,000 meters, and the third device brought back 103 amphipods. Cui Weicheng, director of Hadal Life Science Research Center at Shanghai Ocean University, led the team of scientists to carry out research at the Challenger Deep in the Mariana Trench. The ship is part of China's national marine research fleet but is owned by a Shanghai marine technology company.\n2017 \u2013 RV \"Tansuo-1\".\nCAS' Institute of Deep-sea Science and Engineering sponsored \"Tansuo-1\" return to the Challenger Deep 20 January \u2013 5 February 2017 (cruise TS03) with baited traps for the capture of fish and other macrobiology near the Challenger and Sirena Deeps. On 29 January they recovered photography and samples of a new species of snailfish from the Northern slope of the Challenger Deep at , newly designated \"Pseudoliparis swirei\". They also placed four or more CTD casts into the \"central\" and \"eastern\" basins of the Challenger Deep, as part of the World Ocean Circulation Experiment (WOCE).\n2017 \u2013 RV \"Shinyo Maru\".\nTokyo University of Marine Science and Technology dispatched the research vessel \"Shinyo Maru\" to the Mariana Trench from 20 January to 5 February 2017 with baited traps for the capture of fish and other macrobiology near the Challenger and Sirena Deeps. On 29 January they recovered photography and samples of a new species of snailfish from the Northern slope of the Challenger Deep at , which has been newly designated \"Pseudoliparis swirei\".\n2017 \u2013 RV \"Kexue 3\".\nWater samples were collected at Challenger Deep from 11 layers of the Mariana Trench in March 2017. Seawater samples from 4 to 4,000 m were collected by Niskin bottles mounted to a Seabird SBE25 CTDs; whereas water samples at depths from 6,050 m to 8,320 m were collected by a self-designed acoustic-controlled full ocean depth water samplers. In this study, scientists studied the RNA of pico- and nano-plankton from the surface to the hadal zone.\n2017 \u2013 RV \"Kairei\".\nJAMSTEC deployed \"Kairei\" to the Challenger Deep in May 2017 for the express purpose of testing the new full-ocean depth ROV \"UROV11K\" (Underwater ROV 11,000-meter-capable), as cruise KR 17-08C, under chief scientist Takashi Murashima. The cruise title was: \"Sea trial of a full depth ROV \"UROV11K\" system in the Mariana Trench\". \"UROV11K\" carried a new 4K High Definition video camera system, and new sensors to monitor the hydrogen-sulfide, methane, oxygen, and hydrogen content of the water. Unfortunately, on \"UROV11K\" ascent from (at about 11\u00b022.30'N 142\u00b035.8 E, in the \"eastern\" basin) on 14 May 2017, the ROV's buoyancy failed at depth, and all efforts to retrieve the ROV were unsuccessful. The rate of descent and drift is not available, but the ROV bottomed to the east of the deepest waters of the eastern basin as revealed by the ship's maneuvering on 14 May. Murashima then directed the Kairei to a location about 35 nmi east of the eastern basin of the Challenger Deep to test a new \"Compact Hadal Lander\" which made three descents to depths from 7,498 to 8,178 m for testing the Sony 4K camera and for photography of fish and other macro-biologics.\n2018 \u2013 RV \"Shen Kuo\".\nOn its maiden voyage, the 2,150-ton twin-hulled scientific research vessel \"Shen Kuo\" (also \"Shengkuo\", \"Shen Ko\", or \"Shen Quo\"), departed Shanghai on 25 November 2018 and returned on 8 January 2019. They operated in the Mariana Trench area, and on 13 December tested a system of underwater navigation at a depth exceeding 10,000 metres, during a field trial of the \"Tsaihungyuy\" (ultra-short baseline) system. Project leader Tsui Veichen stated that, with the Tsaihungyuy equipment at depth, it was possible to obtain a signal and determine exact geolocations. The research team from Shanghai Ocean University and Westlake University was led by Cui Weicheng, director of Shanghai Ocean University's Hadal Science and Technology Research Center (HSRC).\nThe equipment to be tested included a piloted submersible (not full ocean depth \u2013 depth achieved not available) and two deep-sea landers, all capable of diving to depths of 10,000 meters, as well as an ROV that can go to 4,500 meters. They took photographs and obtained samples from the trench, including water, sediment, macro-organisms and micro-organisms. Cui says, \"If we can take photos of fish more than 8,145 meters under water, ... we will break the current world record. We will test our new equipment including the landing devices. They are second generation. The first generation could only take samples in one spot per dive, but this new second generation can take samples at different depths in one dive. We also tested the ultra short baseline acoustic positioning system on the manned submersible, the future of underwater navigation.\"\n2019 \u2013 RV \"Sally Ride\".\nIn November 2019, as cruise SR1916, a NIOZ team led by chief scientist Hans van Haren, with Scripps technicians, deployed to the Challenger Deep aboard the 2,641-ton research vessel , to recover a mooring line from the western basin of the Challenger Deep. The long mooring line in the Challenger Deep consisted of top-floatation positioned around depth, two sections of Dyneema neutrally buoyant line, two Benthos acoustic releases and two sections of self-contained instrumentation to measure and store current, salinity and temperature. Around the depth position two current meters were mounted below a long array of 100 high-resolution temperature sensors. In the lower position starting above the sea floor 295 specially designed high-resolution temperature sensors were mounted, the lowest of which was above the trench floor. The mooring line was deployed and left by the NIOZ team during the November 2016 RV \"Sonne\" expedition with the intention to be recovered in late 2018 by \"Sonne\". The acoustic commanded release mechanism near the bottom of the Challenger Deep failed at the 2018 attempt. RV \"Sally Ride\" was made available exclusively for a final attempt to retrieve the mooring line before the release mechanism batteries expired. \"Sally Ride\" arrived at the Challenger Deep on 2 November. This time a 'deep release unit' lowered by one of \"Sally Ride\" winch-cables to around 1,000 m depth pinged release commands and managed to contact the near-bottom releases. After being submerged for nearly three years, mechanical problems occurred in 15 of the 395 temperature sensors. The first results indicate the occurrence of internal waves in the Challenger Deep.\nStudy of the depth and location of the Challenger Deep.\nSince May 2000, with the help of non-degraded signal satellite navigation, civilian surface vessels equipped with professional dual-frequency capable satellite navigation equipment can measure and establish their geodetic position with an accuracy in the order of meters to tens of meters whilst the western, central and eastern basins are kilometers apart.\nIn 2014, a study was conducted regarding the determination of the depth and location of the Challenger Deep based on data collected previous to and during the 2010 sonar mapping of the Mariana Trench with a Kongsberg Maritime EM 122 multibeam echosounder system aboard USNS \"Sumner\". This study by James. V. Gardner et al. of the Center for Coastal &amp; Ocean Mapping-Joint Hydrographic Center (CCOM/JHC), Chase Ocean Engineering Laboratory of the University of New Hampshire splits the measurement attempt history into three main groups: early single-beam echo sounders (1950s\u20131970s), early multibeam echo sounders (1980s \u2013 21st century), and modern (i.e., post-GPS, high-resolution) multibeam echo sounders. Taking uncertainties in depth measurements and position estimation into account, the raw data of the 2010 bathymetry of the Challenger Deep vicinity consisting of 2,051,371 soundings from eight survey lines was analyzed. The study concludes that with the best of 2010 multibeam echosounder technologies after the analysis a depth uncertainty of \u00b1 (95% confidence level) on 9 degrees of freedom and a positional uncertainty of \u00b1 (2drms) remain and the location of the deepest depth recorded in the 2010 mapping is at . The depth measurement uncertainty is a composite of measured uncertainties in the spatial variations in sound-speed through the water volume, the ray-tracing and bottom-detection algorithms of the multibeam system, the accuracies and calibration of the motion sensor and navigation systems, estimates of spherical spreading, attenuation throughout the water volume, and so forth.\nBoth the RV \"Sonne\" expedition in 2016, and the RV \"Sally Ride\" expedition in 2019 expressed strong reservations concerning the depth corrections applied by the Gardner et al. study of 2014, and serious doubt concerning the accuracy of the deepest depth calculated by Gardner (in the \"western\" basin), of after analysis of their multibeam data on a grid. Dr. Hans van Haren, chief scientist on the RV \"Sally Ride\" cruise SR1916, indicated that Gardner's calculations were too deep due to the \"sound velocity profiling by Gardner et al. (2014).\"\nIn 2018-2019, the deepest points of each ocean were mapped using a full-ocean depth Kongsberg EM 124 multibeam echosounder aboard \"DSSV Pressure Drop\". In 2021, a data paper was published by Cassandra Bongiovanni, Heather A. Stewart and Alan J. Jamieson regarding the gathered data donated to GEBCO. The deepest depth recorded in the 2019 Challenger Deep sonar mapping was \u00b1 at in the eastern basin. This depth closely agrees with the deepest point ( \u00b1) determined by the Van Haren et al. sonar bathymetry. The geodetic position of the deepest depth according to the Van Haren et al. significantly differs (about to the west) with the 2021 paper. After post-processing the initial depth estimates by application of a full-ocean depth sound velocity profile Bongiovanni et al. report an (almost) as deep point at in the western basin that geodetically differs about with the deepest point position determined by Van Haren et al. ( in the western basin). After analysis of their multibeam data on a grid, the Bongiovanni et al. 2021 paper states the technological accuracy does not currently exist on low-frequency ship-mounted sonars required to determine which location was truly the deepest, nor does it currently exist on deep-sea pressure sensors.\nIn 2021, a study by Samuel F. Greenaway, Kathryn D. Sullivan, Samuel H. Umfress, Alice B. Beittel and Karl D. Wagner was published presenting a revised estimate of the maximum depth of the Challenger Deep based on a series of submersible dives conducted in June 2020. These depth estimates are derived from acoustic echo sounding profiles referenced to in-situ direct pressure measurements and corrected for observed oceanographic properties of the water-column, atmospheric pressure, gravity and gravity-gradient anomalies, and water-level effects. The study concludes according to their calculations the deepest observed seafloor depth was \u00b1 below mean sea level at a 95% confidence level at in the eastern basin. For this estimate, the error term is dominated by the uncertainty of the employed pressure sensor, but Greenaway et al. show that the gravity correction is also substantial. The Greenaway et al. study compares its results with other recent acoustic and pressure-based measurements for the Challenger Deep and concludes the deepest depth in the western basin is very nearly as deep as the eastern basin. The disagreement between the maximum depth estimates and their geodetic positions between post-2000 published depths however exceed the accompanying margins of uncertainty, raising questions regarding the measurements or the reported uncertainties.\nAnother 2021 paper by Scott Loranger, David Barclay and Michael Buckingham, besides a December 2014 implosion shock wave based depth estimate of , which is among the deepest estimated depths, also treatises the differences between various maximum depth estimates and their geodetic positions.\nDirect measurements.\nThe 2010 maximal sonar mapping depths reported by Gardner et.al. in 2014 and Greenaway et al. study in 2021 have not been confirmed by direct descent (pressure gauge/manometer) measurements at full-ocean depth. Expeditions have reported direct measured maximal depths in a narrow range.\nDescents.\nManned descents.\n1960 \u2013 \"Trieste\".\nOn 23 January 1960, the Swiss-designed \"Trieste\", originally built in Italy and acquired by the U.S. Navy, supported by the USS \"Wandank\" (ATF 204) and escorted by the USS \"Lewis\" (DE 535), descended to the ocean floor in the trench piloted by Jacques Piccard (who co-designed the submersible along with his father, Auguste Piccard) and USN Lieutenant Don Walsh. Their crew compartment was inside a spherical pressure vessel \u2013 measuring 2.16 metres in diameter suspended beneath a buoyancy tank 18.4 metres in length \u2013 which was a heavy-duty replacement (of the Italian original) built by Krupp Steel Works of Essen, Germany. The steel walls were thick and designed to withstand pressure of up to .\nTheir descent took almost five hours and the two men spent barely twenty minutes on the ocean floor before undertaking the three-hour-and-fifteen-minute ascent. Their early departure from the ocean floor was due to their concern over a crack in the outer window caused by the temperature differences during their descent.\n\"Trieste\" dived at/near , bottoming at \u00b1 into the Challenger Deep's \"western\" basin, as measured by an onboard manometer. Another source states the measured depth at the bottom was measured with a manometer at \u00b1.\nNavigation of the support ships was by celestial and LORAN-C with an accuracy of or less. Fisher noted that the \"Trieste\"'s reported depth \"agrees well with the sonic sounding.\"\n2012 \u2013 \"Deepsea Challenger\".\nOn 26 March 2012 (local time), Canadian film director James Cameron made a solo descent in the DSV \"Deepsea Challenger\" to the bottom of the Challenger Deep.\nAt approximately 05:15 ChST on 26 March (19:15 UTC on 25 March), the descent began.\nAt 07:52 ChST (21:52 UTC), \"Deepsea Challenger\" arrived at the bottom. The descent lasted 2 hours and 36 minutes and the recorded depth was when \"Deepsea Challenger\" touched down.\nCameron had planned to spend about six hours near the ocean floor exploring but decided to start the ascent to the surface after only 2 hours and 34 minutes. The time on the bottom was shortened because a hydraulic fluid leak in the lines controlling the manipulator arm obscured the visibility out the only viewing port. It also caused the loss of the submersible's starboard thrusters. At around 12:00 ChST (02:00 UTC on 26 March), the Deepsea Challenger website says the sub resurfaced after a 90-minute ascent, although Paul Allen's tweets indicate the ascent took only about 67 minutes. During a post-dive press conference Cameron said: \"I landed on a very soft, almost gelatinous flat plain. Once I got my bearings, I drove across it for quite a distance ... and finally worked my way up the slope.\" The whole time, Cameron said, he didn't see any fish, or any living creatures more than an inch (2.54\u00a0cm) long: \"The only free swimmers I saw were small amphipods\" \u2013 shrimplike bottom-feeders.\n2019 \u2013 \"Five Deeps Expedition / DSV Limiting Factor\".\nThe Five Deeps Expedition's objective was to thoroughly map and visit the deepest points of all five of the world's oceans by the end of September 2019. On 28 April 2019, explorer Victor Vescovo descended to the \"Eastern Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\" (a Triton 36000/2 model submersible). Between 28 April and 4 May 2019, the \"Limiting Factor\" completed four dives to the bottom of Challenger Deep. The fourth dive descended to the slightly less deep \"Central Pool\" of the Challenger Deep (crew: Patrick Lahey, Pilot; John Ramsay, Sub Designer). The Five Deeps Expedition estimated maximum depths of \u00b1 and \u00b1 at () by direct CTD pressure measurements and a survey of the operating area by the support ship, the Deep Submersible Support Vessel \"DSSV \"Pressure Drop\"\", with a Kongsberg SIMRAD EM124 multibeam echosounder system. The CTD measured pressure at of seawater depth was . Due to a technical problem the (uncrewed) ultra-deep-sea lander \"Skaff\" used by the Five Deeps Expedition stayed on the bottom for two and half days before it was salvaged by the \"Limiting Factor\" (crew: Patrick Lahey, Pilot; Jonathan Struwe, DNV GL Specialist) from an estimated depth of . The gathered data was published with the caveat that it was subject to further analysis and could possibly be revised in the future. The data will be donated to the GEBCO Seabed 2030 initiative. Later in 2019, following a review of bathymetric data, and multiple sensor recordings taken by the DSV \"Limiting Factor\" and the ultra-deep-sea landers \"Closp\", \"Flere\" and \"Skaff\", the Five Deeps Expedition revised the maximum depth to \u00b1.\n2020 \u2013 \"Ring of Fire Expedition / DSV Limiting Factor\".\nCaladan Oceanic's \"Ring of Fire\" expedition in the Pacific included six manned descents and twenty-five lander deployments into all three basins of the Challenger Deep all piloted by Victor Vescovo and further topographical and marine life survey of the entire Challenger Deep. The expedition craft used are the Deep Submersible Support Vessel DSSV \"Pressure Drop\", Deep-Submergence Vehicle DSV \"Limiting Factor\" and the ultra-deep-sea landers \"Closp\", \"Flere\" and \"Skaff\".\nDuring the first manned dive on 7 June 2020 Victor Vescovo and former US astronaut (and former NOAA Administrator) Kathryn D. Sullivan descended to the \"Eastern Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\".\nOn 12 June 2020, Victor Vescovo and mountaineer and explorer Vanessa O'Brien descended to the \"Eastern Pool\" of the Challenger Deep spending three hours mapping the bottom. O'Brien said her dive scanned about a mile of desolate bottom terrain, finding that the surface is not flat, as once was thought, but sloping by about per mile, subject to verification.\nOn 14 June 2020, Victor Vescovo and John Rost descended to the \"Eastern Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\" spending four hours at depth and transiting the bottom for nearly 2 miles.\nOn 20 June 2020, Victor Vescovo and Kelly Walsh descended to the \"Western Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\" spending four hours at the bottom. They reached a maximum depth of . Kelly Walsh is the son of the \"Trieste's\" captain Don Walsh who descended there in 1960 with Jacques Piccard.\nOn 21 June 2020, Victor Vescovo and Woods Hole Oceanographic Institution researcher Ying-Tsong Lin descended to the \"Central Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\". They reached a maximum depth of \u00b1.\nOn 26 June 2020 Victor Vescovo and Jim Wigginton descended to the \"Eastern Pool\" of the Challenger Deep in the Deep-Submergence Vehicle \"Limiting Factor\".\n2020 \u2013 \"Fendouzhe\".\n\"Fendouzhe\" (\u594b\u6597\u8005, \"Striver\") is a manned Chinese deep-sea submersible developed by the China Ship Scientific Research Center (CSSRC). Between 10 October and 28 November, 2020, it carried out thirteen dives in the Mariana Trench as part of a test programme. Of these, eight led to depths of more than . On 10 November 2020, the bottom of the Challenger Deep was reached by \"Fendouzhe\" with three Chinese scientists (Zh\u0101ng W\u011bi \u5f20\u4f1f [pilot], Zh\u00e0o Y\u00e1ng \u8d75\u6d0b, and W\u00e1ng Zh\u00ecqi\u00e1ng \u738b\u6cbb\u5f3a) onboard whilst live-streaming the descent to a reported depth of . This makes the \" Fendouzhe \" the fourth manned submersible vehicle achieving a successful descent. The pressure hull of \"Fendouzhe\", made from a newly developed titanium alloy, offers space for three people in addition to technical equipment. \"Fendouzhe\" is equipped with cameras made by the Norwegian manufacturer Imenco.\nAccording to Ye Cong \u53f6\u806a, the chief designer of the submersible, China's goals for the dive aren't just scientific investigation but also the future use of deep-sea seabed resources.\n2021 \u2013 \"Ring of Fire 2 Expedition / DSV Limiting Factor\".\nOn 28 February 2021 Caladan Oceanic's \"Ring of Fire 2\" expedition arrived over the Challenger Deep and conducted manned descents and lander deployments into the Challenger Deep. At the start the (uncrewed) ultra-deep-sea lander \"Skaff\" was deployed to collect water column data by CTD for the expedition. The effects of the Pacific subducting plate crashing into the Philippine Plate was among the things researched onsite.\nOn 1 March 2021, the first manned descent to the eastern pool was made by Victor Vescovo and Richard Garriott. Garriott became the 17th person to descend to the bottom.\nOn 2 March 2021, a descent to the eastern pool was made by Victor Vescovo and Michael Dubno.\nOn 5 March a descent to the eastern pool was made by Victor Vescovo and Hamish Harding. They traversed the bottom of Challenger Deep.\nOn 11 March 2021 a descent to the Western Pool was made by Victor Vescovo and marine botanist Nicole Yamase.\nOn 13 April 2021 a descent was made by deep water submersible operations expert Rob McCallum and Tim Macdonald who piloted the dive.\nA 2021 descent with a Japanese citizen is planned.\nAll manned descents were conducted in the Deep-Submergence Vehicle \"DSV Limiting Factor\".\n2022 - \"Ring of Fire 3 Expedition / DSV Limiting Factor\".\nIn July 2022 for the fourth consecutive year, Caladan Oceanic's deep submergence system, consisting of the deep submersible DSV \"Limiting Factor\" supported by the mother ship DSSV \"Pressure Drop\", returned to the Challenger Deep for dives into the Challenger Deep.\nIn early July 2022, Victor Vescovo was joined by Aaron Newman as a mission specialist for a dive into the Central pool. On 5 July 2022, Tim Macdonald as pilot and Jim Kitchen as mission specialist for a dive into the Eastern pool. On 8 July 2022 Victor Vescovo was joined by Dylan Taylor as mission specialist for a dive into the Eastern pool.\nVictor Vescovo (for his 15th dive into the Challenger Deep) was joined by geographer and oceanographer Dawn Wright as mission specialist on the 12 July 2022 dive to in the Western Pool. Wright operated the world's first sidescan sonar to ever operate at full-ocean depth to capture detailed imagery along short transects of the southern wall of the Western Pool.\nUncrewed descents by ROVs.\n1996 and 1998 \u2013 \"Kaik\u014d\".\nThe remotely operated vehicle (ROV) \"Kaik\u014d\" made many uncrewed descents to the Mariana Trench from its support ship RV \"Yokosuka\" during two expeditions in 1996 and 1998.\nFrom 29 February to 4 March the ROV \"Kaiko\" made three dives into the \"central\" basin, \"Kaiko\" #21 \u2013 \"Kaiko\" #23, . Depths ranged from at , to at ; dives #22 &amp; #23 to the north, and dive #21 northeast of the deepest waters of the \"central\" basin. During the 1996 measurements the temperature (water temperature increases at great depth due to adiabatic compression), salinity and water pressure at the sampling station was , 34.7\u2030 and , respectively at depth. The Japanese robotic deep-sea probe \"Kaik\u014d\" broke the depth record for uncrewed probes when it reached close to the surveyed bottom of the Challenger Deep. Created by the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), it was one of the few uncrewed deep-sea probes in operation that could dive deeper than . The manometer measured depth of \u00b1 at for the Challenger Deep is believed to be the most accurate measurement taken up to then.\nAnother source states the greatest depth measured by \"Kaik\u014d\" in 1996 was at and at in 1998.\nThe ROV \"Kaiko\" was the first vehicle to visit to the bottom of the Challenger Deep since the bathyscaph \"Trieste\"'s dive in 1960, and the first success in sampling the trench bottom sediment/mud, from which \"Kaiko\" obtained over 360 samples. Approximately 3,000 different microbes were identified in the samples.\n\"Kaik\u014d\" was lost at sea off Shikoku Island during Typhoon Chan-Hom on 29 May 2003.\n2009 \u2013 \"Nereus\".\nFrom 2 May to 5 June 2009, the RV \"Kilo Moana\" hosted the Woods Hole Oceanographic Institution (WHOI) hybrid remotely operated vehicle (HROV) \"Nereus\" team for the first operational test of the \"\" in its 3-ton tethered ROV mode. The \"Nereus\" team was headed by the Expedition Leader Andy Bowen of WHOI, Louis Whitcomb of Johns Hopkins University, and Dana Yoerger, also of WHOI. The expedition had co-chief scientists: biologist Tim Shank of WHOI, and geologist Patricia Fryer of the University of Hawaii, to head the science team exploiting the ship's bathymetry and organizing the science experiments deployed by the \"Nereus\". From \"Nereus\" dive #007ROV to just south of Guam, to dive #010ROV into the Nero Deep at , the testing gradually increased depths and complexities of activities at the bottom.\nDive #011ROV, on 31 May 2009, saw the \"Nereus\" piloted on a 27.8-hour underwater mission, with about ten hours transversing the \"eastern\" basin of the Challenger Deep \u2013 from the south wall, northwest to the north wall \u2013 streaming live video and data back to its mothership. A maximum depth of was registered at . The \"\" then relocated to the \"western\" basin, where a 19.3-hour underwater dive found a maximum depth of on dive #012ROV, and on dive #014ROV in the same area (11\u00b019.59 N, 142\u00b012.99 E) encountered a maximum depth of . The \"Nereus\" was successful in recovering both sediment and rock samples from the \"eastern\" and the \"western\" basins with its manipulator arm for further scientific analysis. The HROV's final dive was about to the north of the Challenger Deep, in the backarc, where they dived at the TOTO Caldera (12\u00b042.00 N, 143\u00b031.5 E). Nereus thus became the first vehicle to reach the Mariana Trench since 1998 and the deepest-diving vehicle then in operation. Project manager and developer Andy Bowen heralded the achievement as \"the start of a new era in ocean exploration\". \"Nereus\", unlike \"Kaik\u014d\", did not need to be powered or controlled by a cable connected to a ship on the ocean surface.&lt;ref name=\"Daily Reports for R/V KILO MOANA April and May 2009\"&gt;&lt;/ref&gt;\nThe HROV \"Nereus\" was lost on 10 May 2014 while conducting a dive at in depth in the Kermadec Trench.\nUncrewed descents near the Challenger Deep.\n2008 \u2013 \"ABISMO\".\nIn June 2008, the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) deployed the research vessel \"Kairei\" to the area of Guam for cruise KR08-05 Leg 1 and Leg 2.\nOn 1\u20133 June 2008, during Leg 1, the Japanese robotic deep-sea probe \"ABISMO\" (Automatic Bottom Inspection and Sampling Mobile) on dives 11\u201313 almost reached the bottom about east of the Challenger Deep: \"Unfortunately, we were unable to dive to the sea floor because the legacy primary cable of the Kaiko system was a little bit short. The 2-m long gravity core sampler was dropped in free fall, and sediment samples of 1.6m length were obtained. Twelve bottles of water samples were also obtained at various depths...\" ABISMO's dive #14 was into the TOTO caldera (12\u00b042.7777 N, 143\u00b032.4055 E), about 60 nmi northeast of the deepest waters of the \"central\" basin of the Challenger Deep, where they obtained videos of the hydrothermal plume. Upon successful testing to , JAMSTEC' ROV \"ABISMO\" became, briefly, the only full-ocean-depth rated ROV in existence. On 31 May 2009, the ABISMO was joined by the Woods Hole Oceanographic Institution's HROV \"Nereus\" as the only two operational full ocean depth capable remotely operated vehicles in existence. During the ROV \"ABISMO's\" deepest sea trails dive its manometer measured a depth of \u00b1 in \"Area 1\" (vicinity of 12\u00b043' N, 143\u00b033' E).\nLeg 2, under chief scientist Takashi Murashima, operated at the Challenger Deep 8\u20139 June 2008, testing JAMSTEC's new full ocean depth \"Free Fall Mooring System,\" i.e. a lander. The lander was successfully tested twice to depth, taking video images and sediment samplings at , in the \"central\" basin of the Challenger Deep.\n2016 \u2013 \"Haidou-1\".\nOn 23 May 2016, the Chinese submersible \"Haidou-1\" dived to a depth of at an undisclosed position in the Mariana Trench, making China the third country after Japan (ROV \"Kaik\u014d\"), and the US (HROV \"Nereus\"), to deploy a full-ocean-depth ROV. This autonomous and remotely operated vehicle has a design depth of .\n2020 \u2013 \"Vityaz-D\".\nOn 8 May 2020, the Russian submersible \"Vityaz-D\" dived to a depth of at an undisclosed position in the Mariana Trench.\nLifeforms.\nThe summary report of the expedition lists unicellular life forms from the two dredged samples taken when the Challenger Deep was first discovered. These (\"Nassellaria\" and \"Spumellaria\") were reported in the Report on Radiolaria (1887) written by Ernst Haeckel.\nOn their 1960 descent, the crew of the \"Trieste\" noted that the floor consisted of diatomaceous ooze and reported observing \"some type of flatfish\" lying on the seabed.\nMany marine biologists are now skeptical of this supposed sighting, and it is suggested that the creature may instead have been a sea cucumber. The video camera on board the \"Kaiko\" probe spotted a sea cucumber, a scale worm and a shrimp at the bottom. At the bottom of the Challenger Deep, the \"Nereus\" probe spotted one polychaete worm (a multi-legged predator) about an inch long.\nAn analysis of the sediment samples collected by \"Kaiko\" found large numbers of simple organisms at . While similar lifeforms have been known to exist in shallower ocean trenches (&gt; 7,000 m) and on the abyssal plain, the lifeforms discovered in the Challenger Deep possibly represent taxa distinct from those in shallower ecosystems.\nMost of the organisms collected were simple, soft-shelled foraminifera (432 species according to National Geographic), with four of the others representing species of the complex, multi-chambered genera \"Leptohalysis\" and \"Reophax\". Eighty-five per cent of the specimens were organic, soft-shelled allogromiids, which is unusual compared to samples of sediment-dwelling organisms from other deep-sea environments, where the percentage of organic-walled foraminifera ranges from 5% to 20%. As small organisms with hard, calcareous shells have trouble growing at extreme depths because of the high solubility of calcium carbonate in the pressurized water, scientists theorize that the preponderance of soft-shelled organisms in the Challenger Deep may have resulted from the typical biosphere present when the Challenger Deep was shallower than it is now. Over the course of six to nine million years, as the Challenger Deep grew to its present depth, many of the species present in the sediment died out or were unable to adapt to the increasing water pressure and changing environment.\nOn 17 March 2013, researchers reported data that suggested piezophilic microorganisms thrive in the Challenger Deep. Other researchers reported related studies that microbes thrive inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States. According to one of the researchers, \"You can find microbes everywherethey're extremely adaptable to conditions, and survive wherever they are.\""}
{"id": "7787", "revid": "48379342", "url": "https://en.wikipedia.org/wiki?curid=7787", "title": "Claude Louis Berthollet", "text": "Claude Louis Berthollet (, 9 December 1748 \u2013 6 November 1822) was a Savoyard-French chemist who became vice president of the French Senate in 1804. He is known for his scientific contributions to the theory of chemical equilibria via the mechanism of reverse chemical reactions, and for his contribution to modern chemical nomenclature. On a practical basis, Berthollet was the first to demonstrate the bleaching action of chlorine gas, and was first to develop a solution of sodium hypochlorite as a modern bleaching agent.\nBiography.\nClaude Louis Berthollet was born in Talloires, near Annecy, then part of the Duchy of Savoy, in 1749.\nHe started his studies at Chamb\u00e9ry and then in Turin where he graduated in medicine. Berthollet's great new developments in works regarding chemistry made him, in a short period of time, an active participant of the Academy of Science in 1780.\nBerthollet, along with Antoine Lavoisier and others, devised a chemical nomenclature, or a system of names, which serves as the basis of the modern system of naming chemical compounds.\nHe also carried out research into dyes and bleaches, being first to introduce the use of chlorine gas as a commercial bleach in 1785. He first produced a modern bleaching liquid in 1789 in his laboratory on the quay Javel in Paris, France, by passing chlorine gas through a solution of sodium carbonate. The resulting liquid, known as \"Eau de Javel\" (\"Javel water\"), was a weak solution of sodium hypochlorite. Another strong chlorine oxidant and bleach which he investigated and was the first to produce, potassium chlorate (KClO3), is known as \"Berthollet's Salt\".\nBerthollet first determined the elemental composition of the gas ammonia, in 1785.\nBerthollet was one of the first chemists to recognize the characteristics of a reverse reaction, and hence, chemical equilibrium.\nBerthollet was engaged in a long-term battle with another French chemist, Joseph Proust, on the validity of the law of definite proportions. While Proust believed that chemical compounds are composed of a fixed ratio of their constituent elements irrespective of the methods of production, Berthollet believed that this ratio can change according to the ratio of the reactants initially taken. Although Proust proved his theory by accurate measurements, his theory was not immediately accepted partially due to Berthollet's authority. His law was finally accepted when Berzelius confirmed it in 1811, but it was found later that Berthollet was not completely wrong because there exists a class of compounds that do not obey the law of definite proportions. These non-stoichiometric compounds are also named \"berthollides\" in his honor.\nBerthollet was one of several scientists who went with Napoleon to Egypt and was a member of the physics and natural history section of the Institut d'\u00c9gypte.\nAwards and honours.\nIn April, 1789 Berthollet was elected a Fellow of the Royal Society of London. In 1801, he was elected a foreign member of the Royal Swedish Academy of Sciences. In 1809, Berthollet was elected an associate member first class of the Royal Institute of the Netherlands, predecessor of the Royal Netherlands Academy of Arts and Sciences. He was elected an Honorary Fellow of the Royal Society of Edinburgh in 1820 and a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.\nClaude-Louis Berthollet's 1788 publication entitled \"M\u00e9thode de Nomenclature Chimique\", published with colleagues Antoine Lavoisier, Louis Bernard Guyton de Morveau, and Antoine Fran\u00e7ois, comte de Fourcroy, was honored by a Citation for Chemical Breakthrough Award from the Division of History of Chemistry of the American Chemical Society, presented at the Acad\u00e9mie des Sciences (Paris) in 2015.\nA French High School located in Annecy is named after him (Lyc\u00e9e Claude Louis Berthollet).\nPersonal life.\nBerthollet married Marie Marguerite Baur in 1788. Their son, Am\u00e9d\u00e9e-Barth\u00e9l\u00e9my Berthollet, died in 1811 of carbon monoxide poisoning via charcoal-burning suicide in which he had recorded his physiological and psychological experiences as a final scientific contribution before losing consciousness and succumbing to the fumes.\nBerthollet was accused of being an atheist.\nHe died in Arcueil, France in 1822."}
{"id": "7788", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7788", "title": "C. L. Berthollet", "text": ""}
{"id": "7790", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7790", "title": "Chasidic Judaism", "text": ""}
{"id": "7791", "revid": "19861826", "url": "https://en.wikipedia.org/wiki?curid=7791", "title": "Chilean Constitution of 1980", "text": "The Political Constitution of the Republic of Chile of 1980 () is the fundamental law in force in Chile. It was approved and promulgated under the military dictatorship headed by Augusto Pinochet, being ratified by the Chilean citizenry through a referendum on September 11, 1980, although being held under restrictions and without electoral registers. While 69% of the population was reported to have voted yes, the vote was questioned by hundreds of denunciations of irregularities and fraud. The constitutional text took effect, in a transitory regime, on March 11, 1981, and then entered into full force on March 11, 1990, with the return to electoral democracy. It was amended for the first time in 1989 (through a referendum), and afterward in 1991, 1994, 1997, each year from 1999 to 2001, 2003, each year from 2007 to 2015, and each year from 2017 to 2021, with the last three amendments concerning the constituent process of 2020\u20132022. In September 2005, under Ricardo Lagos's presidency, a large amendment of the Constitution was approved by parliamentarians, removing from the text some of the less democratic dispositions coming from Pinochet's regime, such as senators-for-life and appointed senators, as well as the armed forces' warranty of the democratic regime.\nOn November 15, 2019, following a series of popular protests in October 2019, a political agreement between parties with parliamentary representation called for a national referendum on the proposal of writing a new Constitution and on the mechanism to draft it. A plebiscite held on October 25, 2020, approved drafting a new fundamental charter, as well as choosing by popular vote delegates to a Constitutional Convention which was to fulfill this objective. The members of the convention were elected in May 2021, and first convened on July 4, 2021. However, on September 4, 2022, voters rejected the new constitution in the constitutional referendum. Following the rejection, the Expert Commission drafted another new constitution for the Constitutional Council to amend. However, on December 15, 2023, voters rejected the constitution in the 2023 Chilean constitutional referendum.\nBackground.\nThe Commission for the Study of the New Political Constitution of the Republic of Chile', commonly known as the Ort\u00fazar Commission', was a body established in 1973 by the Military Government Junta that ruled the country during the military dictatorship of Augusto Pinochet, following the coup against the Socialist President Salvador Allende. Its purpose was to draft the preliminary project for the 1980 Constitution. It met from September 24, 1973, to October 5, 1978. The name \"Ort\u00fazar Commission\" is due to its chairman, Enrique Ort\u00fazar Escobar, who previously served as Minister of Justice and Minister of Foreign Affairs during the administration of Jorge Alessandri.\nThe following people were part of the commision: Rafael Eyzaguirre Echeverr\u00eda (secretary), Sergio Diez Urz\u00faa, Enrique Evans de la Cuadra, Jaime Guzm\u00e1n Err\u00e1zuriz, Gustavo Lorca Rojas, Jorge Ovalle Quiroz, Alejandro Silva Bascu\u00f1\u00e1n, Alicia Romo Rom\u00e1n, Ra\u00fal Gormaz Molina and later on Luz Bulnes Aldunate, Ra\u00fal Bertelsen Repetto, Juan de Dios Carmona.\nDespite what is commonly believed, the Ort\u00fazar Commission was not a constituent assembly and did not draft the 1980 Constitution; rather, it merely prepared a preliminary draft that was subsequently reviewed by the Council of State and the Government Junta before being formally submitted for popular approval via a plebiscite.\nNevertheless, there is no denying the importance of the discussion carried out by the Ort\u00fazar Commission regarding the final text of the 1980 Constitution. Although many of the commission\u2019s proposals were not adopted by the Council of State and the Government Junta, a large portion of the new Constitution\u2019s text was analyzed and debated within the commission.\nLegitimacy.\nAccording to the law professor Camel Cazor Aliste, the Constitution of 1980 has problems of legitimacy stemming from two facts. First, the constitutional commission was not representative of the political spectrum of Chile: its members had been handpicked by the Pinochet dictatorship, and opponents of the regime had been deliberately excluded. Secondly, the constitution's approval was achieved by the government in a controversial and tightly controlled referendum in 1980. Campaigning for the referendum was irregular, with the government calling people to vote positively on the reform, and also using radio and television commercial spots, while the opposition urging people to vote negatively were only able of doing small public demonstrations, without access to television time and limited radio access. There was no electoral roll for this vote, as the register had been burned during the dictatorship. There were multiple cases of double voting, with at least 3000 CNI agents doing so.\nSince the return to democracy, the constitution has been amended nearly 60 times.\nA document from September 13, 1973, shows that Jaime Guzm\u00e1n had by then already been tasked by the Junta to study the creation of a new constitution.\nIt has been argued the 1980 Constitution was designed to favor the election of right-wing legislative majorities. Several rounds of constitutional amendments have been enacted since 1989 to address this concern.\nA referendum held in 2020 after waves of popular protests approved the drafting of a new constitution. In September 2022, a proposed left-wing replacement constitution was rejected, 62% to 38%. Following a second process, in December 2023, a proposed right-wing replacement was also rejected, 55.8% to 44.2%. These outcomes effectively granted the 1980 charter democratic legitimacy.\nReplacement.\nIn July 2022, a proposed replacement constitution was submitted for national debate and general referendum, but it was rejected on September 4 despite having had the support of left-leaning President Gabriel Boric. The document had faced intense criticism that it was \"too long, too left-wing and too radical\", and was rejected by a margin of 62% to 38%.\nOn March 6, 2023, a group of experts appointed by Congress began a second attempt to prepare a preliminary draft of a new constitution. The group, with lawyer Veronica Undurraga serving as its president, was scheduled to work for three months on 12 institutional bases agreed to by lawmakers, after which the draft would be given to an elected Constitutional Council, whose members would be voted upon on May 7, 2023. At the same time, a 14-member Technical Admissibility Committee began serving as arbitrator.\nOn December 17, 2023, Chileans voted 55.8% to 44.2% against the second proposed constitution. President Boric stated that he would not seek a third referendum; this outcome effectively guaranteed the 1980 charter would remain in effect."}
{"id": "7793", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7793", "title": "Cave Tetra", "text": ""}
{"id": "7794", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=7794", "title": "Crystallography", "text": "Crystallography is the branch of science devoted to the study of molecular and crystalline structure and properties. The word \"crystallography\" is derived from the Ancient Greek word (; \"clear ice, rock-crystal\"), and (; \"to write\"). In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming 2014 the International Year of Crystallography.\nCrystallography is a broad topic, and many of its subareas, such as X-ray crystallography, are themselves important scientific topics. Crystallography ranges from the fundamentals of crystal structure to the mathematics of crystal geometry, including those that are not periodic or quasicrystals. At the atomic scale it can involve the use of X-ray diffraction to produce experimental data that the tools of X-ray crystallography can convert into detailed positions of atoms, and sometimes electron density. At larger scales it includes experimental tools such as orientational imaging to examine the relative orientations at the grain boundary in materials. Crystallography plays a key role in many areas of biology, chemistry, and physics, as well new developments in these fields.\nHistory and timeline.\nBefore the 20th century, the study of crystals was based on physical measurements of their geometry using a goniometer. This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.\nThe discovery of X-rays and electrons in the last decade of the 19th century enabled the determination of crystal structures on the atomic scale, which brought about the modern era of crystallography. The first X-ray diffraction experiment was conducted in 1912 by Max von Laue, while electron diffraction was first realized in 1927 in the Davisson\u2013Germer experiment and parallel work by George Paget Thomson and Alexander Reid. These developed into the two main branches of crystallography, X-ray crystallography and electron diffraction. The quality and throughput of solving crystal structures greatly improved in the second half of the 20th century, with the developments of customized instruments and phasing algorithms. Nowadays, crystallography is an interdisciplinary field, supporting theoretical and experimental discoveries in various domains. Modern-day scientific instruments for crystallography vary from laboratory-sized equipment, such as diffractometers and electron microscopes, to dedicated large facilities, such as photoinjectors, synchrotron light sources and free-electron lasers.\nMethodology.\nCrystallographic methods depend mainly on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. Crystallographers often explicitly state the type of beam used, as in the terms \"X-ray diffraction, neutron diffraction\" and \"electron diffraction\". These three types of radiation interact with the specimen in different ways.\nIt is hard to focus x-rays or neutrons, but since electrons are charged they can be focused and are used in electron microscope to produce magnified images. There are many ways that transmission electron microscopy and related techniques such as scanning transmission electron microscopy, high-resolution electron microscopy can be used to obtain images with in many cases atomic resolution from which crystallographic information can be obtained. There are also other methods such as low-energy electron diffraction, low-energy electron microscopy and reflection high-energy electron diffraction which can be used to obtain crystallographic information about surfaces.\nApplications in various areas.\nMaterials science.\nCrystallography is used by materials scientists to characterize different materials. In single crystals, the effects of the crystalline arrangement of atoms is often easy to see macroscopically because the natural shapes of crystals reflect the atomic structure. In addition, physical properties are often controlled by crystalline defects. The understanding of crystal structures is an important prerequisite for understanding crystallographic defects. Most materials do not occur as a single crystal, but are poly-crystalline in nature (they exist as an aggregate of small crystals with different orientations). As such, powder diffraction techniques, which take diffraction patterns of samples with a large number of crystals, play an important role in structural determination.\nOther physical properties are also linked to crystallography. For example, the minerals in clay form small, flat, platelike structures. Clay can be easily deformed because the platelike particles can slip along each other in the plane of the plates, yet remain strongly connected in the direction perpendicular to the plates. Such mechanisms can be studied by crystallographic texture measurements. Crystallographic studies help elucidate the relationship between a material's structure and its properties, aiding in developing new materials with tailored characteristics. This understanding is crucial in various fields, including metallurgy, geology, and materials science. Advancements in crystallographic techniques, such as electron diffraction and X-ray crystallography, continue to expand our understanding of material behavior at the atomic level.\nIn another example, iron transforms from a body-centered cubic (bcc) structure called ferrite to a face-centered cubic (fcc) structure called austenite when it is heated. The fcc structure is a close-packed structure unlike the bcc structure; thus the volume of the iron decreases when this transformation occurs.\nCrystallography is useful in phase identification. When manufacturing or using a material, it is generally desirable to know what compounds and what phases are present in the material, as their composition, structure and proportions will influence the material's properties. Each phase has a characteristic arrangement of atoms. X-ray or neutron diffraction can be used to identify which structures are present in the material, and thus which compounds are present. Crystallography covers the enumeration of the symmetry patterns which can be formed by atoms in a crystal and for this reason is related to group theory.\nBiology.\nX-ray crystallography is the primary method for determining the molecular conformations of biological macromolecules, particularly protein and nucleic acids such as DNA and RNA. The double-helical structure of DNA was deduced from crystallographic data. The first crystal structure of a macromolecule was solved in 1958, a three-dimensional model of the myoglobin molecule obtained by X-ray analysis. The Protein Data Bank (PDB) is a freely accessible repository for the structures of proteins and other biological macromolecules. Computer programs such as RasMol, Pymol or VMD can be used to visualize biological molecular structures.\nNeutron crystallography is often used to help refine structures obtained by X-ray methods or to solve a specific bond; the methods are often viewed as complementary, as X-rays are sensitive to electron positions and scatter most strongly off heavy atoms, while neutrons are sensitive to nucleus positions and scatter strongly even off many light isotopes, including hydrogen and deuterium.\nElectron diffraction has been used to determine some protein structures, most notably membrane proteins and viral capsids.\nReference literature.\nThe \"International Tables for Crystallography\" is an eight-book series that outlines the standard notations for formatting, describing and testing crystals. The series contains books that covers analysis methods and the mathematical procedures for determining organic structure through x-ray crystallography, electron diffraction, and neutron diffraction. The International tables are focused on procedures, techniques and descriptions and do not list the physical properties of individual crystals themselves. Each book is about 1000 pages and the titles of the books are:"}
{"id": "7796", "revid": "7609619", "url": "https://en.wikipedia.org/wiki?curid=7796", "title": "Claude Auchinleck", "text": "Field Marshal Sir Claude John Eyre Auchinleck ( ) (21 June 1884 \u2013 23 March 1981), was a British Indian Army commander who saw active service during the world wars. A career soldier who spent much of his military career in India, he rose to become commander-in-chief of the Indian Army by early 1941 during the Second World War. In July 1941 he was appointed commander-in-chief of the Middle East Theatre, but after initial successes the war in North Africa turned against the British-led forces under his command and he was relieved of the post in August 1942 during the North African campaign.\nIn June 1943, he was once again appointed Commander-in-Chief, India, where his support through the organisation of supply, maintenance and training for General William Slim's Fourteenth Army played an important role in its success. He served as commander-in-chief, India, until the Partition in 1947, when he assumed the role of supreme commander of all British forces in India and Pakistan until late 1948.\nEarly life and career.\nBorn at 89 Victoria Road in Aldershot, Hampshire, the son of John Claud Alexander Auchinleck and Mary Eleanor (Eyre) Auchinleck. His father, a colonel in the Royal Horse Artillery of the British Army, was posted to Bangalore in British India, with his family accompanying him, while Claude was very young. It was from here that he developed a love for the country that would last for most of his life. Returning to England after the death of his father in 1892, Auchinleck attended Eagle House School at Crowthorne and then Wellington College on scholarships. From there he went on to the Royal Military College, Sandhurst and was commissioned as an unattached second lieutenant in the Indian Army on 21 January 1903, and joined the 62nd Punjabis in April 1904. He soon learned several Indian languages, and, able to speak fluently with his soldiers, he absorbed a knowledge of local dialects and customs: this familiarity engendered a lasting mutual respect, enhanced by his own personality.\nHe was promoted to lieutenant on 21 April 1905, and then spent the next two years in Tibet and Sikkim before moving to Benares in 1907 where he caught diphtheria. After briefly serving with the Royal Inniskilling Fusiliers at Aldershot he returned to Benares in 1909 and became adjutant of the 62nd Punjabis with promotion to captain on 21 January 1912. Auchinleck was an active freemason.\nFirst World War.\nAuchinleck saw active service in the First World War and was deployed with his regiment to defend the Suez Canal: in February 1915 he was in action against the Turks at Ismailia. His regiment moved into Aden to counter the Turkish threat there in July 1915. The 6th Indian Division, of which the 62nd Punjabis were a part, was landed at Basra on 31 December 1915 for the Mesopotamian campaign. In July 1916 Auchinleck was promoted acting major and made second in command of his battalion. He took part in a series of fruitless attacks on the Turks at the Battle of Hanna in January 1916 and was one of the few British officers in his regiment to survive these actions.\nHe became acting commanding officer of his battalion in February 1917 and led his regiment at the Second Battle of Kut in February 1917 and the Fall of Baghdad in March 1917. Having been mentioned in despatches and having received the Distinguished Service Order in 1917 for his service in Mesopotamia, he was promoted to the substantive rank of major on 21 January 1918, to temporary lieutenant-colonel on 23 May 1919 and to brevet lieutenant-colonel on 15 November 1919 for his \"distinguished service in Southern and Central Kurdistan\" on the recommendation of the Commander-in-Chief of the Mesopotamia Expeditionary Force.\nBetween the world wars.\nAuchinleck attended the Staff College, Quetta, between 1920 and 1921. As a lieutenant colonel, he outranked most of his fellow students and even some members of the staff. Despite performing well there \u2013 passing the course and being among the top ten students \u2013 he was critical of many aspects of the college, which he believed to be too theoretical and with little emphasis being placed on matters such as supply and administration, both of which he thought had been mishandled in the campaign in Mesopotamia. He married Jessie Stewart in 1921. Jessie had been born in 1900 in Tacoma, Washington, to Alexander Stewart, head of the Blue Funnel Line that plied the west coast of the United States. When he died about 1919, their mother took her, her twin brother Alan and her younger brother Hepburne back to Bun Rannoch, the family estate at Innerhadden in Perthshire. Holidaying at Grasse on the French Riviera, Auchinleck, who was on leave from India at the time, met Jessie on the tennis courts. She was a high-spirited, blue-eyed beauty. Things moved quickly, and they were married within five months. Sixteen years younger than Auchinleck, Jessie became known as 'the little American girl' in India, but adapted readily to life there. They had no children.\nAuchinleck became temporary Deputy Assistant Quartermaster-General at Army Headquarters in February 1923 and then second-in-command of his regiment, which in the 1923 reorganisation of the Indian Army had become the 1st Punjab Regiment, in September 1925. He attended the Imperial Defence College in 1927 and, having been promoted to the permanent rank of lieutenant-colonel on 21 January 1929 he was appointed to command his regiment. Promoted to full colonel on 1 February 1930 with seniority from 15 November 1923, he became an instructor at the Staff College, Quetta in February 1930 where he remained until April 1933.\nHe was promoted to temporary brigadier on 1 July 1933 and given command of the Peshawar Brigade, which was active in the pacification of the adjacent tribal areas during the Mohmand and Bajaur Operations between July and October 1933: during his period of command he was mentioned in despatches. He led a second punitive expedition during the Second Mohmand Campaign in August 1935 for which he was again mentioned in despatches, promoted to major-general on 30 November 1935 and appointed a Companion of the Order of the Star of India on 8 May 1936.\nOn leaving his brigade command in April 1936, Auchinleck was on the unemployed list (on half pay) until September 1936 when he was appointed Deputy Chief of the General Staff and Director of Staff Duties in Delhi. He was then appointed to command the Meerut District in India in July 1938. In 1938 Auchinleck was appointed to chair a committee to consider the modernisation, composition and re-equipment of the British Indian Army: the committee's recommendations formed the basis of the 1939 Chatfield Report which outlined the transformation of the Indian Army \u2013 it grew from 183,000 in 1939 to over 2,250,000 men by the end of the war.\nSecond World War.\nNorway 1940.\nOn the outbreak of war, Auchinleck was appointed to command the Indian 3rd Infantry Division, but in January 1940 was summoned to the United Kingdom to command IV Corps, the only time in the war that a wholly British corps was commanded by an Indian Army officer. He received promotion to acting lieutenant general on 1 February 1940 and to the substantive rank of lieutenant general on 16 March 1940. In May 1940 Auchinleck took over command of the Anglo-French ground forces during the Norwegian campaign, a military operation that was doomed to fail.\nAuchinleck arrived in Greenock, after the fall of Norway, on 12 June, by which time the Battle of France was nearing its end, with the majority of the BEF in France having been evacuated from the port of Dunkirk, with the French surrender only a few days away. Due to these reasons, all attention was now given to the defence of the UK which many believed would soon be invaded by the Germans (see Operation Sea Lion). In mid-June he was given command of the recently established V Corps, then serving in Southern Command under Lieutenant General Sir Alan Brooke. His stay was not to be for very long, however, as, just a few weeks later, Brooke succeeded General Sir Edmund Ironside as Commander-in-Chief, Home Forces, with Auchinleck succeeding Brooke as GOC-in-C of Southern Command, responsible for the defence of Southern England, where the expected invasion would come from. The recently vacated V Corps was taken over by Lieutenant General Bernard Montgomery, who disliked Auchinleck intensely, possibly due to his disdain for the Indian Army and its officers. The relationship between the two future field marshals was not easy, with Montgomery later writing:\nMany of Montgomery's actions in the next few weeks and months could be considered as insubordination, with one incident in particular standing out, when Montgomery went over Auchinleck's head directly to the Adjutant-General on issues related to officers and men being transferred to and from Montgomery's V Corps. Auchinleck was not to deal with this behaviour for long as in December he was ordered to succeed his friend, General Sir Robert Cassels, as Commander-in-Chief, India. By now known throughout the army as \"the Auk\", he was destined to encounter Montgomery again, although the circumstances there would not be at all pleasant.\nIndia and Iraq January\u2013May 1941.\nPromoted to full general on 26 December, Auchinleck returned to India in January 1941 to assume his new appointment, in which position he was also appointed to the Executive Council of the Viceroy of India and appointed ADC General to the King, a ceremonial position he was to hold until after the end of the war.\nIn April 1941, RAF Habbaniya was threatened by the new pro-Axis regime of Rashid Ali. This large Royal Air Force station was west of Baghdad in Iraq and General Archibald Wavell, Commander-in-Chief Middle East Command, was reluctant to intervene, despite the urgings of Winston Churchill, because of his pressing commitments in the Western Desert and Greece. Auchinleck, however, acted decisively, sending the 1st Battalion of the King's Own Royal Regiment (Lancaster) by air to Habbaniya and shipping the 10th Indian Infantry Division by sea to Basra. Wavell was prevailed upon by London to send \"Habforce\", a relief column, from the British Mandate of Palestine but by the time it arrived in Habbaniya on 18 May the Anglo-Iraqi War was virtually over.\nNorth Africa July 1941 \u2013 August 1942.\nFollowing the see-saw of Allied and Axis successes and reverses in North Africa, Auchinleck was appointed to succeed General Sir Archibald Wavell as Commander-in-Chief Middle East Command in July 1941; Wavell took up Auchinleck's post as Commander-in-Chief of the Indian Army, swapping jobs with him.\nAs Commander-in-Chief Middle East, Auchinleck, based in Cairo, held responsibility not just for North Africa but also for Persia and the Middle East. He launched an offensive in the Western Desert, Operation Crusader, in November 1941: despite some tactical reverses during the fighting which resulted in Auchinleck replacing the Eighth Army commander Alan Cunningham with Neil Ritchie, by the end of December the besieged garrison of Tobruk had been relieved and Rommel obliged to withdraw to El Agheila. Auchinleck appears to have believed that the enemy had been defeated, writing on 12 January 1942 that the Axis forces were \"beginning to feel the strain\" and were \"hard pressed\".\nIn fact the Axis forces had managed to withdraw in good order and a few days after Auchinleck's optimistic appreciation, having reorganised and been reinforced, struck at the dispersed and weakened British forces, driving them back to the Gazala positions near Tobruk. The British Chief of the Imperial General Staff (CIGS), General Sir Alan Brooke, wrote in his diary that it was \"nothing less than bad generalship on the part of Auchinleck. He has been overconfident and has believed everything his overoptimistic [DMI] Shearer has told him\". Brooke commented that Auchinleck \"could have been one of the finest of commanders\" but lacked the ability to select the men to serve him. Brooke sent him one of his best armoured division commanders Richard McCreery, whose advice was ignored in favour of that of Auchinleck's controversial chief of operations, Major-General Dorman-Smith.\nRommel's attack at the Battle of Gazala of 26 May 1942 resulted in a significant defeat for the British. Auchinleck's appreciation of the situation written to Ritchie on 20 May had suggested that the armoured reserves be concentrated in a position suitable to meet both a flanking attack around the south of the front or a direct attack through the centre (which was the likelihood more favoured by Auchinleck). In the event, Ritchie chose a more dispersed and rearward positioning of his two armoured divisions and when the attack in the centre came, it proved to be a diversion and the main attack, by Rommel's armoured formations, came round the southern flank. Poor initial positioning and subsequent handling and coordination of Allied formations by Ritchie and his corps commanders resulted in their heavy defeat and the Eighth Army retreating into Egypt; Tobruk fell to the Axis on 21 June 1942.\nOn 24 June Auchinleck stepped in to take direct command of the Eighth Army, having lost confidence in Neil Ritchie's ability to control and direct his forces. Auchinleck discarded Ritchie's plan to stand at Mersa Matruh, deciding to fight only a delaying action there, while withdrawing to the more easily defendable position at El Alamein. Here Auchinleck tailored a defence that took advantage of the terrain and the fresh troops at his disposal, stopping the exhausted German/Italian advance in the First Battle of El Alamein. Enjoying a considerable superiority of material and men over the weak German/Italian forces, Auchinleck organised a series of counter-attacks. Poorly conceived and badly coordinated, these attacks achieved little.\n\"The Auk\", as he was known, appointed a number of senior commanders who proved to be unsuitable for their positions, and command arrangements were often characterised by bitter personality clashes. Auchinleck was an Indian Army officer and was criticised for apparently having little direct experience or understanding of British and Dominion troops. Dorman-Smith was regarded with considerable distrust by many of the senior commanders in Eighth Army. By July 1942 Auchinleck had lost the confidence of Dominion commanders and relations with his British commanders had become strained.\nLike his foe Rommel (and his predecessor Wavell and successor Montgomery), Auchinleck was subjected to constant political interference, having to weather a barrage of hectoring telegrams and instructions from Prime Minister Churchill throughout late 1941 and the spring and summer of 1942. Churchill constantly sought an offensive from Auchinleck, and was downcast at the military reverses in Egypt and Cyrenaica. Churchill was desperate for some sort of British victory before the planned Allied landings in North Africa, Operation Torch, scheduled for November 1942. He badgered Auchinleck immediately after the Eighth Army had all but exhausted itself after the first battle of El Alamein. Churchill and the Chief of the Imperial General Staff, Sir Alan Brooke, flew to Cairo in early August 1942 to meet Auchinleck, where it emerged he had lost the confidence of both men. He was replaced as Commander-in-Chief Middle East Command by General Sir Harold Alexander (later Field Marshal The Earl Alexander of Tunis).\nJoseph M. Horodyski and Maurice Remy both praise Auchinleck as an underrated military leader who contributed the most to the successful defence of El Alamein and consequently the final defeat of Rommel in Africa. The two historians also criticize Churchill for the unreasonable decision to put the blame on Auchinleck and to relieve him.\nIndia 1942\u20131945.\nChurchill offered Auchinleck command of the newly created Persia and Iraq Command (this having been separated from Alexander's command), but Auchinleck declined this post, as he believed that separating the area from the Middle East Command was not good policy and the new arrangements would not be workable. He set his reasons out in his letter to the Chief of the Imperial General Staff dated 14 August 1942. Instead he returned to India, where he spent almost a year \"unemployed\" before in June 1943 being again appointed Commander-in-Chief of the Indian Army,\nGeneral Wavell meanwhile having been appointed Viceroy, on this appointment it was announced that responsibility for the prosecution of the war with Japan would move from the Commander-in-Chief India to a newly created South East Asia Command. However, the appointment of the new command's Supreme Commander, Acting Vice Admiral Lord Louis Mountbatten, was not announced until August 1943 and until Mountbatten could set up his headquarters and assume control (in November), Auchinleck retained responsibility for operations in India and Burma while conducting a review and revision of Allied plans based on the decisions taken by the Allied Combined Chiefs of Staff at the Quadrant Conference, which ended in August.\nFollowing Mountbatten's arrival, Auchinleck, as Commander-in-Chief India once more, was responsible for the internal security of India, the defence of the North West Frontier and the buildup of India as a base, including most importantly the reorganisation of the Indian Army, the training of forces destined for SEAC and the lines of communication carrying men and material to the forward areas and to China. Auchinleck made the supply of Fourteenth Army, with probably the worst lines of communication of the war, his immediate priority; as Sir William Slim, commander of the Fourteenth Army, was later to write:\nDivorce.\nAuchinleck suffered a personal disappointment when his wife Jessie left him for his friend, Air Chief Marshal Sir Richard Peirse. Peirse and Auchinleck had been students together at the Imperial Defence College, but that was long before. Peirse was now Allied Air Commander-in-Chief, South-East Asia, and also based in India. The affair became known to Mountbatten in early 1944, and he passed the information to the Chief of the RAF, Sir Charles Portal, hoping that Peirse would be recalled. The affair was common knowledge by September 1944, and Peirse was neglecting his duties. Mountbatten sent Peirse and Lady Auchinleck back to England on 28 November 1944, where they lived together at a Brighton hotel. Peirse had his marriage dissolved, and Auchinleck obtained a divorce in 1946. Auchinleck was reportedly very badly affected. According to his sister, he was never the same after the break-up. He always carried a photograph of Jessie in his wallet even after the divorce.\nThere is scholarly dispute whether Auchinleck was homosexual. His biographer, Philip Warner, addressed the rumours but dismissed them; however historian Ronald Hyam has alleged that \"sexually based moral-revulsion\" was the reason for Montgomery's inability to get on with Auchinleck, and further, that Auchinleck was \"let off with a high-level warning\" over his relationships with Indian boys.\nPartition of India and later years.\nAuchinleck continued as Commander-in-Chief of the Indian Army after the end of the war helping, though much against his own convictions, to prepare the future Indian and Pakistani armies for the Partition of India: in November 1945 he was forced to commute the more serious judicial sentences awarded against officers of the Indian National Army in face of growing unease and unrest both within the Indian population, and the British Indian Army. On 1 June 1946 he was promoted to field marshal, but he refused to accept a peerage, lest he be thought associated with a policy (i.e. Partition) that he thought fundamentally dishonourable.\nSending a report to the British Government on 28 September 1947, Field Marshal Auchinleck wrote: \"I have no hesitation, whatever, in affirming that the present Indian Cabinet are implacably determined to do all in their power to prevent the establishment of the Dominion of Pakistan on firm basis.\" He stated in the second, political part of his assessment, \"Since 15th August, the situation has steadily deteriorated and the Indian leaders, cabinet ministers, civil officials and others have persistently tried to obstruct the work of partition of the armed forces.\"\nWhen partition was effected in August 1947, Auchinleck was appointed Supreme Commander of all British forces remaining in India and Pakistan and remained in this role until the winding up and closure of the Supreme H.Q. at the end of November 1947. This marked his effective retirement from the army (although technically field marshals in the British Army never retire, remaining on the active list on half pay). He left India on 1 December.\nAfter a brief period in Italy in connection with an unsuccessful business project, Auchinleck retired to London, where he occupied himself with a number of charitable and business interests and became a respectably skilled watercolour painter. In 1960 he settled in Beccles in the county of Suffolk, remaining there for seven years until, at the age of eighty-four, he decided to emigrate and set up home in Marrakesh, where he died on 23 March 1981.\nMemorials.\nAuchinleck is buried in Ben M'Sik European Cemetery, Casablanca, in the Commonwealth War Graves Commission plot in the cemetery, next to the grave of Raymond Steed who was the second youngest non-civilian Commonwealth casualty of the Second World War.\nA memorial plaque was erected in the crypt of St Paul's Cathedral. A bronze statue of Auchinleck can be seen on Broad Street adjacent to Auchinleck House, Five Ways, Birmingham.\nExternal links.\n \n \n \n "}
{"id": "7797", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=7797", "title": "Camilla Hall", "text": "Camilla Christine Hall (March 24, 1945 \u2013 May 17, 1974) was a member of the Symbionese Liberation Army (SLA), a small, far-left militant group that committed violent acts between 1973 and 1975. They assassinated Marcus Foster, Superintendent of the Oakland Public Schools and the first black superintendent of any major school system, kidnapped heiress Patty Hearst, and committed armed robbery of banks. \nHall, one of the majority of white members in the group, died on May 17, 1974, with five other SLA members in a shootout with the Los Angeles Police Department in that city. During this, the house where the SLA members were making their stand caught fire. Police fatally shot both Hall and Nancy Ling Perry as they left the house, firing their own pistols.\nEarly life.\nOn March 24, 1945, Camilla Christine Hall was born in Saint Peter, Minnesota. Both her parents, George Fridolph Hall (1908\u20132000) and Lorena (Daeschner) Hall (1911\u20131995), were academics with positions at Gustavus Adolphus College in Saint Peter from 1938 to 1952. In addition, her father was a minister in the Augustana Evangelical Lutheran Church and later the Evangelical Lutheran Church in America. Her mother, Lorena (Daeschner) Hall, helped found Gustavus Adolphus College's Art Department and served as the department head. \nCamilla Hall was the only surviving child of four. Firstborn son Terry died of congenital heart disease in 1948; Peter died in 1951, and Nan died in 1962, both of a congenital kidney disease. The family seemed burdened by grief.\nIn 1952, the Hall family moved to what is now Tanzania in East Africa. George and Lorena Hall taught in schools and did mission work, while Camilla and Nan played with the native children. In 1954, when Camilla was nine, the family returned to Saint Peter because of seven-year-old Nan's poor health. While Camilla attended elementary school in Minnesota and lived with relatives, her birth family moved to Montclair, New Jersey. \nIn Minnesota, Hall attended Washburn High School in Minneapolis, where she was involved in many activities. The 1963 Washburn Yearbook states, \"Candy was a member of Blue Tri, Class Play, Poplars Staff, Quill Club, Forensics, Pep Club, and Hall of Fame\". Blue Tri club was an organization that encouraged Christian ideals and put together service projects. In addition, Camilla Hall was voted class clown in high school. In 1963, she graduated from Washburn High School.\nEducation.\nHall attended Gustavus Adolphus College in St. Peter, Minnesota. She transferred to the University of Minnesota after her freshman year. On June 10, 1967, Hall graduated with a humanities degree. \nPost-college.\nAfter graduation, Hall moved to Duluth, Minnesota, where she started as a caseworker for social services in St. Louis County. She also began to participate in Democratic Party activities. In early 1968, she was elected to carry the Eugene McCarthy banner for the St. Louis County precinct, in support of McCarthy's presidential campaign that year. \nAlthough Hall enjoyed helping people in her work, she found it difficult to keep distance from some of their problems while being a caseworker. For her job in Duluth, Hall used her musical and poetic talents in an advertising campaign.\nIn June 1968, Hall returned to Minneapolis, where she was a caseworker for the Hennepin County, Minnesota welfare office. Co-workers and friends of Hall described her as witty, sympathetic, helpful, and compassionate. She had an outgoing personality and had a passion for literature. At the same time, Hall frequently talked with family and friends about philosophy and how she was disappointed with the state of welfare. In 1968, Hall was 23 years old. She carefully monitored the political situation in America, including the 1968 Democratic National Convention in Chicago where there was so much violence. She was active in the peace movement and food boycotts, including the Mobilization Committee to End the War in Vietnam. Despite Hall's participating in political activities, urging social change, and working to aid individuals and families, her mother could see that Camilla became dissatisfied with her work.\nMove to California.\nIn November 1969, Hall moved to Topanga, a northern suburb of Los Angeles, California. In March, she moved into Los Angeles proper in west Los Angeles. According to Rachael Hanel, \"She lived off her savings, interest income from a trust, money from her parents, and selling her simple, Rubenesque line drawings.\" Although Hall didn't express dissatisfaction at being an artist, she decided to move again.\nHall moved to Berkeley in northern California in February 1971, which had become a center of political activism and social movements. In May 1971, Hall moved into an apartment complex on Channing Way where she met Patricia Soltysik. The two women began a lesbian relationship, which was the first time Hall had done so publicly. Hall wrote about Soltysik in a love poem named \"Mizmoon\", and nicknamed her that.\nIn Berkeley, Hall continued being politically active. She participated in the People's Park reoccupation during the summer of 1972, following the shootings there the year before. She and Soltysik became involved with the Venceremos prison outreach project, through which they became associates of two white men, Russ Little and Willie Wolfe, who were also assisting in prisoner outreach. \nIn October 1972, Hall traveled to Europe. She stayed with friends while she traveled for three months. Once she returned to California, she continued being politically active. Through her association with Soltysik, Little, and Wolfe, she became a founding member of the Symbionese Liberation Army, a small, radical leftist group. Joe Remiro and Thero Wheeler trained the other members in handling weapons and explosives. Remiro was a veteran of Vietnam.\nThe SLA gained notoriety in November 1973 by claiming credit for the assassination of Marcus Foster, Superintendent of the Oakland Public Schools and the first black to be superintendent of any major city's school district. Three \"soldiers\" also wounded his deputy. In January 1974 the SLA base was moved to Concord, California, where Nancy Ling Perry rented a house under an assumed name. Russ Little and Joe Remiro were arrested after a police stop and confrontation, convicted and sentenced to prison.\nIn February 1974 the SLA kidnapped heiress Patty Hearst. They indoctrinated her and she said she chose to join them. Hall and Hearst were identified from security camera images as participants in the April 15, 1974, armed robbery of the Hibernia Bank in San Francisco. Two civilians were shot during the robbery.\nLA shootout.\nThe police kept up pressure on the group, which moved to a house in Los Angeles. There Hall died in a shootout (May 17, 1974) with police in which five other SLA members also died. As their hideout burned, Hall and Nancy Ling Perry exited from the back door. Police claimed that Perry came out firing a revolver and Hall was firing an automatic pistol. Police shot them immediately, killing both. Perry was shot twice. One shot hit her right lung, the other shot severed her spine. Hall was shot once in the forehead. Angela Atwood, another SLA member, pulled Hall's body back into the burning house. Atwood died in the fire. \nInvestigators working for Hall's parents claimed that Perry had walked out of the house intending to surrender.\nFuneral.\nHall's parents held a funeral for their daughter on May 23, 1974, at St. John's Lutheran Church, in Lincolnwood, Illinois, a Chicago suburb, where he was pastor. Seven of his fellow Lutheran ministers conducted the service. Camilla Hall's name was not mentioned. Her ashes were buried on August 19, 1974, in a small country graveyard where her late siblings were buried, who each died before she was 16. Her parents also have plots there."}
{"id": "7800", "revid": "11630810", "url": "https://en.wikipedia.org/wiki?curid=7800", "title": "Clone", "text": "Clone or Clones or Cloning or Cloned or The Clone may refer to:"}
{"id": "7801", "revid": "1258414759", "url": "https://en.wikipedia.org/wiki?curid=7801", "title": "Critical psychology", "text": "Critical psychology is a perspective on psychology that draws extensively on critical theory. Critical psychology challenges the assumptions, theories and methods of mainstream psychology and attempts to apply psychological understandings in different ways.\nThe field of critical psychology does not fall under a monolithic category. One\u00a0can observe different starting points of critiques, similarities,\u00a0as well as substantial differences. Thus, critical psychology should be perceived as an \u201cumbrella term\u201d that includes\u00a0various critiques against the status quo of mainstream psychology. A common theme of critical approaches in psychology is the assessment of the social effects of psychological theories and practices. Critical psychology is a movement that challenges psychology to work towards emancipation and social justice, and that opposes the uses of psychology to perpetuate oppression and injustice.\nCritical psychologists believe that mainstream psychology fails to consider how power differences and discrimination between social classes and groups can impact an individual's or a group's mental and physical well-being. Mainstream psychology does this only in part by attempting to explain behavior at the individual level. However, it largely ignores institutional racism, postcolonialism and deficits in social justice for minority groups based on differences in observable characteristics such as gender, ethnicity, religious minority, sexual orientation, or disability.\nOrigins.\nPsychology, draws a history filled with theoretical and political conflict. Within its history various stream of critiques have emerged, some of them sharing similarities, as well as different starting points and substantial differences. Criticisms of mainstream psychology consistent with current critical psychology usage have existed since psychology's modern development in the late 19th century. Use of the term \"critical psychology\" started in the 1970s at the Freie Universit\u00e4t Berlin. The German branch of critical psychology predates and has developed largely separately from the rest of the field. As of May 2007, only a few works have been translated into English. The German Critical Psychology movement is rooted in the post-war student revolt of the late 1960s; see German student movement. Marx's \"Critique of Political Economy\" played an important role in the German branch of the student revolt, which was centered in West Berlin. At that time, the capitalist city of West Berlin was surrounded by communist-ruled East Germany, and represented a \"hot spot\" of political and ideological controversy for the revolutionary German students. The sociological foundations of critical psychology are decidedly Marxist.\nKlaus Holzkamp.\nOne of the most important and sophisticated books in the German development of the field is the (\"Foundations of Psychology\") by Klaus Holzkamp, who might be considered the theoretical founder of German critical psychology. Holzkamp wrote two books on theory of science and one on sensory perception before publishing the in 1983. Holzkamp believed his work provided a solid paradigm for psychological research because he viewed psychology as a pre-paradigmatic scientific discipline (T.S. Kuhn had used the term \"pre-paradigmatic\" for social science).\nHolzkamp mostly based his sophisticated attempt to provide a comprehensive and integrated set of categories defining the field of psychological research on Aleksey Leontyev's approach to cultural\u2013historical psychology and activity theory. Leontyev had seen human action as a result of biological as well as cultural evolution and, drawing on Marx's materialist conception of culture, stressed that individual cognition is always part of social action which in turn is mediated by man-made tools (cultural artifacts), language and other man-made systems of symbols, which he viewed as a major distinguishing feature of human culture and, thus, human cognition. Another important source was Lucien S\u00e9ve's theory of personality, which provided the concept of \"social activity matrices\" as mediating structure between individual and social reproduction. At the same time, the systematically integrated previous specialized work done at Free University of Berlin in the 1970s by critical psychologists who also had been influenced by Marx, Leontyev, and Seve. This included books on animal behavior/ethology, sensory perception, motivation and cognition. He also incorporated ideas from Freud's psychoanalysis and Merleau-Ponty's phenomenology into his approach.\nOne core result of Holzkamp's historical and comparative analysis of human reproductive action, perception and cognition is a very specific concept of meaning that identifies symbolic meaning as historically and culturally constructed, purposeful conceptual structures that humans create in close relationship to material culture and within the context of historically specific formations of social reproduction.\nComing from this phenomenological perspective on culturally mediated and socially situated action, Holzkamp launched a methodological attack on behaviorism (which he termed S\u2013R (stimulus\u2013response) psychology) based on linguistic analysis, showing in minute detail the rhetorical patterns by which this approach to psychology creates the illusion of \"scientific objectivity\" while at the same time losing relevance for understanding culturally situated, intentional human actions. Against this approach, he developed his own approach to generalization and objectivity, drawing on ideas from Kurt Lewin in Chapter 9 of \"\".\nHis last major publication before his death in 1995 was about learning. It appeared in 1993 and contained a phenomenological theory of learning from the standpoint of the subject. One important concept Holzkamp developed was \"reinterpretation\" of theories developed by conventional psychology. This meant to look at these concepts from the standpoint of the paradigm of critical psychology, thereby integrating their useful insights into critical psychology while at the same time identifying and criticizing their limiting implications, which in the case of S\u2013R psychology were the rhetorical elimination of the subject and intentional action, and in the case of cognitive psychology which did take into account subjective motives and intentional actions, methodological individualism.\nThe first part of the book thus contains an extensive look at the history of psychological theories of learning and a minute re-interpretation of those concepts from the perspective of critical psychology, which focuses on intentional action situated in specific socio-historical/cultural contexts. The conceptions of learning he found most useful in his own detailed analysis of \"classroom learning\" came from cognitive anthropologists Jean Lave (situated learning) and Edwin Hutchins (distributed cognition).\nThe book's second part contained an extensive analysis on the modern state's institutionalized forms of \"classroom learning\" as the cultural\u2013historical context that shapes much of modern learning and socialization. In this analysis, he heavily drew upon Michel Foucault's \"Discipline and Punish\". Holzkamp felt that classroom learning as the historically specific form of learning does not make full use of student's potentials, but rather limits her or his learning potentials by a number of \"teaching strategies.\" Part of his motivation for the book was to look for alternative forms of learning that made use of the enormous potential of the human psyche in more fruitful ways. Consequently, in the last section of the book, Holzkamp discusses forms of \"expansive learning\" that seem to avoid the limitations of classroom learning, such as apprenticeship and learning in contexts other than classrooms.\nThis search culminated in plans to write a major work on \"life leadership\" in the specific historical context of modern (capitalist) society. Due to his death in 1995, this work never got past the stage of early (and premature) conceptualizations, some of which were published in the journals \"Forum Kritische Psychologie\" and \"Argument\".\n1960s\u20131970s.\nIn the 1960s and 1970s the term \"radical psychology\" was used by psychologists internationally to denote a branch of the field which rejected mainstream psychology's focus on the individual as the basic unit of analysis and sole source of psychopathology. Instead, radical psychologists examined the role of society in causing and treating problems and looked towards social change as an alternative to therapy to treat mental illness and as a means of preventing psychopathology. Within psychiatry the term \"anti-psychiatry\" was often used and now British activists prefer the term \"critical psychiatry\". \"Critical psychology\" is currently the preferred term for the discipline of psychology keen to find alternatives to the way the discipline of psychology reduces human experience to the level of the individual and thereby strips away possibilities for radical social change.\n1990s.\nStarting in the 1990s a new wave of books started to appear on critical psychology, the most influential being the edited book \"Critical Psychology\" by Dennis Fox and Isaac Prilleltensky. Various introductory texts to critical psychology written in the United Kingdom have tended to focus on discourse, but this has been seen by some proponents of critical psychology as a reduction of human experience to language which is as politically dangerous as the way mainstream psychology reduces experience to the individual mind. Attention to language and ideological processes, others would argue, is essential to effective critical psychology \u2013 it is not simply a matter of applying mainstream psychological concepts to issues of social change.\nIan Parker.\nIn 1999 Ian Parker published an influential manifesto in both the online journal \"Radical Psychology\" and the \"Annual Review of Critical Psychology\". This manifesto argues that critical psychology should include the following four components:\nCritical psychology today.\nThere are a few international journals devoted to critical psychology and critical discussions in Psychology, including \"Psychology in Society\", \"Theory &amp; Psychology\", \"Culture &amp; Psychology\", \"Feminism &amp; Psychology\", \"Human Development\", \"Annual Review of Critical Psychology and\" the no longer published \"International Journal of Critical Psychology\" (continued in the journal \"Subjectivity\") and \"Radical Psychology Journal\" (published for ten years until its final issue in 2011). The journals still tend to be directed to an academic audience, though the \"Annual Review of Critical Psychology\" and \"Psychology in Society\" runs as an open-access online journal. There are close links between critical psychologists and critical psychiatrists in Britain through the Asylum Collective. David Smail was one of the founders of The Midlands Psychology Group, a critical psychology collective who produced a manifesto for a social materialist psychology of distress. Critical psychology courses and research concentrations are available at Manchester Metropolitan University, York St John University, the University of East London, the University of Edinburgh, the University of KwaZulu Natal, the City University of New York Graduate Center, the University of West Georgia, Point Park University, University of Guelph, York University, and Prescott College. Undergraduate concentrations can also be found at the California Institute of Integral Studies, Prescott College, and at the University of Notre Dame Australia (Fremantle).\nExtensions.\nLike many critical applications, critical psychology has expanded beyond Marxist and feminist roots to benefit from other critical approaches. Consider ecopsychology and transpersonal psychology. Critical psychology and related work has also sometimes been labelled \"radical psychology\" and \"liberation psychology\". In the field of developmental psychology, the work of Erica Burman has been influential.\nVarious sub-disciplines within psychology have begun to establish their own critical orientations. Perhaps the most extensive are critical health psychology, community psychology, and social psychology.\nAims of Critical Psychology.\nCentral themes of critical psychology is the concept of \u201coppression\u201d and \u201cemancipation\u201d. Critical psychology reflects not only on the connection of mainstream psychology with power, but also work toward emancipation (or liberation). Oppression refers to\u00a0 \u201ca state of asymmetric power relations characterized by domination, subordination, and resistance, where the dominating persons or groups exercise their power by restricting access to material resources and by implanting in the subordinated persons or groups fear or self-deprecating views about themselves\u201d. Emancipation (or liberation) refer to the possibilities of individuals within the social inequalities, doing justice to both, individual and societal domains. Consequently, the aims of critical psychology is the understanding of \u201coppression\u201d and \u201cliberation\u201d in relation with \u201cPower\u201d.\nThe spectrum through which the aims of critical psychology is expressed is divided into three different levels of intervention : The micro-level, meso-level, and macro level. Micro-level context refer to the relation of psychology with individuals and groups, the meso-level context refer to the critical reflections of critical psychology on psychology and the re-formation of a psychology not \"about\" but \"for\" the people, and the macro-level context refer to interventions of critical psychology\u00a0 to create a more equitable society, inviting larger social-agents. A similar reflection is the one that divides possibilities of liberation in relation with power into: aesthetic, interaction, and labor dimension. Aesthetic dimension refer to very personal and individual possibility of liberation through self-expression, the dimension of interaction refer to the deconstruction of oppression in the symbolic and communicative dimension of power (e.g. books, \u00a0texts, media) and labor refer to liberation from larger socio-political expressions of power (schools, work, health-care). To sum-up, power is practiced in a spectrum from individual- to larger societal level, and thus oppression and possibilities of liberation is also identified within this spectrum. Thus, the aims of critical psychology toward emancipation exceeds from the individual, to the larger societal level of reflection and action.\nForms of Critical Psychology.\nUnderstanding and action, is an ongoing debate in the field of critical psychology. The understanding of oppression and the \"praxis\" of emancipation is two different domains, which is the domain of theory and the domain of action. For this reason it is proposed to divide Critical Psychology into four different forms : (a) critical theoretical psychology, (b) critical theoretical psychology with a practical emancipatory intention, (c) critical empirical psychology, and (d) critical applied psychology. Critical theoretical psychology (a), and critical empirical psychology (c) refers to the theoretical understanding and development of the field, while critical theoretical psychology with practical emancipatory intention, (b) and critical applied psychology (d), has to do with practice and move toward a social change.\nInternationally.\nAn early international overview of critical psychology perspectives can be found in \"Critical Psychology: Voices for Change\", edited by Tod Sloan (Macmillan, 2000). In 2015, Ian Parker edited the \"Handbook of Critical Psychology\".\nGermany.\nAt FU-Berlin, critical psychology was not really seen as a division of psychology and followed its own methodology, trying to reformulate traditional psychology on an unorthodox Marxist base and drawing from Soviet ideas of cultural\u2013historical psychology, particularly Aleksey Leontyev. Some years ago the department of critical psychology at FU-Berlin was merged into the traditional psychology department.\nAn April 2009 issue of the journal \"Theory &amp; Psychology\" (edited by Desmond Painter, Athanasios Marvakis, and Leendert Mos) is devoted to an examination of German critical psychology.\nSouth Africa.\nThe complex sociopolitical history of South Africa, and its relationship with mainstream psychology, created a setting in which critical psychology could be impactful. South Africa is a good example of a context in which mainstream psychology positioned itself alongside neo-colonialism, racism, and capitalist exploitation - during the country's Apartheid era - which led to the need for critical alternatives within the field that could challenge ideological complicities. During apartheid, mainstream psychology supported the oppressive political system - some psychologists actively and others passively. In the early 1980s, at the height of apartheid, progressive white psychologists and a growing number of black psychologists began to research and practice alternative programmes to critique and resist mainstream psychology's role in perpetuating apartheid in South Africa. In this way, critical psychology started to develop in South Africa.\nAs is the case in other parts of the world, critical psychology in South Africa was born from interrogating psychology in relation to politics. Firstly, psychology was accused of being a product of, and supporter of, an oppressive political system in which its supposed neutrality and scientific objectivity were informed by the sectors of society that benefited from the ideological and economic dominance that it upheld. Secondly, once critical psychologists in South Africa revealed the ideological flaws in mainstream psychology within the country's context, work began to reconfigure the field as a progressive and socially relevant practice with theoretical and methodological approaches that could benefit all members of South African society.\nThe establishment of critical psychology in South Africa took various forms between 1980 and 1994. Although the field was not necessarily fully formalised during this time, spaces and organisations were created for its ideas to be expressed and developed: such as in the University of Cape Town's (UCT) psychology department, the formation of the Organisation for Appropriate Social Services in South Africa (OASSSA), Psychologists Against Apartheid, the South African Health and Social Services Organisation (SAHSSO), and the establishment of the academic journal \"Psychology in Society (PINS)\". Some of the main theoretical and practical achievements of these developments were: the forging of a way to critique the categories of class, race, gender, and other structural factors impacting the discipline of psychology, the encouragement of students to think critically about the politics of psychology, and rebuilding international links as well as relationships with other social and health sciences in South Africa.\nHowever, not all these initiatives continued after the end of political struggle and the transition to democracy. After 1994, professional psychology in South Africa was reorganised through the establishment of the Professional Board for Psychology that exists within the Health Professions Council of South Africa (HPCSA). This statutory body regulates the profession with its systems of licensing and certification. Within these systems, critical psychology is more of an approach to the field than it is a professional category on its own. From the 2000s until recent times, critical psychology moved more toward studying certain domains, such as gender or race, and in the process, the overarching project of establishing a formalised field of critical psychology has either been discarded or broadened to refer to anything that is 'non-mainstream' in psychology. Critical psychology in South Africa is therefore mostly applied as a theoretical approach.\nUnited States and Canada.\nThe doctoral program in Critical Social/Personality Psychology and Environmental Psychology at the CUNY Graduate Center and the doctoral program in Critical Psychology at Point Park University, in Pittsburgh, PA are the only critical psychology specific doctoral programs in the United States. Prescott College in Prescott, Arizona offers an online Master's program in Critical Psychology and Human Services and has a critically oriented undergraduate program. The California Institute of Integral Studies in San Francisco also offers the Bachelor's Completion Program with a minor in Critical Psychology, and critical perspectives are sometimes encountered in traditional universities, perhaps especially within community psychology programs. The University of West Georgia offers a Ph.D. in Consciousness and Society with critical psychology being one of the main three theoretical orientations. North American efforts include the 1993 founding of RadPsyNet, the 1997 publication of \"Critical Psychology: An Introduction\" (edited by Dennis Fox and Isaac Prilleltensky; expanded 2009 edition edited by Dennis Fox, Isaac Prilleltensky, and Stephanie Austin), the 2001 Monterey Conference on Critical Psychology, and in underlying themes of many contributions to the \"Journal of Social Action in Counseling and Psychology\"."}
{"id": "7803", "revid": "23939382", "url": "https://en.wikipedia.org/wiki?curid=7803", "title": "Crossfire", "text": "A crossfire (also known as interlocking fire) is a military term for the siting of weapons (often automatic weapons such as assault rifles or sub-machine guns) so that their arcs of fire overlap. This tactic came to prominence in World War I.\nSiting weapons this way is an example of the application of the defensive principle of \"mutual support\". The advantage of siting weapons that mutually support one another is that it is difficult for an attacker to find a covered approach to any one defensive position. Use of armour, air support, indirect fire support, and stealth are tactics that may be used to assault a defensive position. However, when combined with land mines, snipers, barbed wire, and air cover, crossfire became a difficult tactic to counter in the early 20th century.\nEarly modern warfare.\nThe concept of overlapping arcs of fire drove major developments in the use of cannon in early modern Europe. The star fort forced attackers approaching the walls into the overlapping enfilade of the protruding bastions; attempts to achieve a similar effect through maneuver on the battlefield were limited by the weight and size of the artillery of the time. The earliest experiments in mobile artillery, such as the leather cannon, were generally flawed due to the limitations of the materials science of the period, but eventually gave rise to the regimental gun.\nPerhaps the most famous example of crossfire tactics in early modern warfare occurred in the final stages of the First Battle of Breitenfeld. Swedish cavalry under Gustavus Adolphus outflanked and seized the artillery pieces of the Imperial army. As the battle had progressed, the Imperial guns were now well-positioned to fire upon the bulk of the Imperial army, and the crossfire of Swedish and captured cannon shattered the Imperial forces.\nTrench warfare.\nThe tactic of using overlapping arcs of fire came to prominence during World War I where it was a feature of trench warfare. Machine guns were placed in groups, called machine-gun nests, and they protected the front of the trenches. Many people died in futile attempts to charge across the no man's land where these crossfires were set up. After these attacks many bodies could be found in the no man's land. \n\"Caught in the crossfire\".\nTo be \"caught in the crossfire\" is an expression that often refers to unintended casualties (bystanders, etc.) who were killed or wounded by being exposed to the gunfire of a battle or gun fight, such as in a position to be hit by bullets of either side. The phrase has come to mean any injury, damage or harm (physical or otherwise) caused to a third party due to the action of belligerents (collateral damage)."}
{"id": "7805", "revid": "47799596", "url": "https://en.wikipedia.org/wiki?curid=7805", "title": "CNO", "text": "CNO may refer to:"}
{"id": "7806", "revid": "18872885", "url": "https://en.wikipedia.org/wiki?curid=7806", "title": "Cruising (maritime)", "text": "Cruising is a maritime activity that involves staying aboard a watercraft for extended periods of time when the vessel is traveling on water at a steady speed. Cruising generally refers to leisurely trips on yachts and luxury cruiseships, with durations varying from day-trips to months-long round-the-world voyages.\nHistory.\nBoats were almost exclusively used for working purposes prior to the nineteenth century. In 1857, the philosopher Henry David Thoreau, with his book \"Canoeing in Wilderness\" chronicling his canoe voyaging in the wilderness of Maine, is considered the first to convey the enjoyment of spiritual and lifestyle aspects of cruising.\nThe modern conception of cruising for pleasure was first popularised by the Scottish explorer and sportsman John MacGregor. He was introduced to the canoes and kayaks of the Native Americans on a camping trip in 1858, and on his return to the United Kingdom constructed his own 'double-ended' canoe in Lambeth. The boat, nicknamed 'Rob Roy' after a famous relative of his, was built of lapstrake oak planking, decked in cedar covered with rubberized canvas with an open cockpit in the center. He cruised around the waterways of Britain, Europe and the Middle East and wrote a popular book about his experiences, \"A Thousand Miles in the Rob Roy Canoe\".\nIn 1866, Macgregor was a moving force behind the establishment of the Royal Canoe Club, the first club in the world to promote pleasure cruising. The first recorded regatta was held on April 27, 1867, and it received Royal patronage in 1873. The latter part of the century saw cruising for leisure being enthusiastically taken up by the middle class. The author Robert Louis Stevenson wrote \"An Inland Voyage\" in 1877 as a travelogue on his canoeing trip through France and Belgium. Stevenson and his companion, Sir Walter Grindlay Simpson travelled in two 'Rob Roys' along the Oise River and witnessed the Romantic beauty of rural Europe.\nThe Canadian-American Joshua Slocum was one of the first people to carry out a long-distance sailing voyage for pleasure, circumnavigating the world between 1895 and 1898. Despite opinion that such a voyage was impossible, Slocum rebuilt a derelict sloop \"Spray\" and sailed her single-handed around the world. His book \"Sailing Alone Around the World\" was a classic adventure, and inspired many others to take to the seas.\nOther cruising authors have provided both inspiration and instruction to prospective cruisers. Key among these during the post World War II period are Electa and Irving Johnson, Miles and Beryl Smeeton, Bernard Moitessier, Peter Pye, and Eric and Susan Hiscock. During the 1970s - 1990s Robin Lee Graham, Lin and Larry Pardey, Annie Hill, Herb Payson, Linda and Steve Dashew, Margaret and Hal Roth, and Beth Leonard &amp; Evans Starzinger have provided inspiration for people to set off voyaging.\nThe development of ocean crossing rallies, most notably the ARC (Atlantic Rally for Cruisers), have encouraged less experienced sailors to undertake ocean crossings. These rallies provide a group of sailors crossing the same ocean at the same time with safety inspections, weather information and social functions.\nTypes of boats used.\nCruising is done on both sail and power boats, monohulls and multihulls although sail predominates over longer distances, as ocean-going power boats are considerably more expensive to purchase and operate. The size of the typical cruising boat has increased over the years and is currently in the range of 10 to 15 metres (33 to 50 feet) although smaller boats have been used in around-the-world trips, but are generally not recommended given the dangers involved. Many cruisers are \"long term\" and travel for many years, the most adventurous among them circle the globe over a period of three to ten years. Many others take a year or two off from work and school for shorter trips and the chance to experience the cruising lifestyle.\nTypes.\nBlue-water and coastal cruising.\nBlue-water cruising which is defined as long term open sea cruising is more involved and inherently more dangerous than coastal cruising. \nBefore embarking on an open-ocean voyage, planning and preparation will include studying charts, weather reports/warnings, almanacs and navigation books of the route to be followed. In addition, supplies need to be stocked (including fresh water and fuel), navigation instruments checked and the ship itself needs to be inspected and the crew needs to be given exact instruction on the jobs are expected to perform (e.g. the watch, which is generally 4 hours on and 4 hours off, navigation, steering, rigging sails, ...). In addition, the crew needs to be well trained at working together and with the ship in question. Finally, the sailor must be mentally prepared for dealing with harsh situations. There have been many well-documented cases where sailors had to be rescued simply because they were not sufficiently prepared (the sailors as well as the ship) or lacked experience for their venture and ran into serious trouble.\nSailing near the coast (coastal cruising) gives a certain amount of safety. A ship is always granted 'innocent passage' through the country (most countries usually claim up to off the coast). When this method is practiced however, if the ship needs to stop (e.g. for repairs), a trip to a customs checkpoint to have passports checked would be required.\nRiver cruising.\nVoyage along inland waterways are called river cruises, which often involved stopping at multiple ports along the way. As many cities and towns are built around rivers and historically have relied on maritime transport, river cruise docks are frequently located in the center of cities and towns.\nAccording to Douglas Ward, \"A river cruise represents life in the slow lane, sailing along at a gentle pace, soaking up the scenery, with plentiful opportunities to explore riverside towns and cities en route. It is a supremely calming experience, an antidote to the pressures of life in a fast-paced world, in surroundings that are comfortable without being fussy or pretentious, with good food and enjoyable company.\"\nRiver cruising is a major component of the tourist industry in many parts of the world.\nEquipment.\nCruisers use a variety of equipment and techniques to make their voyages possible, or simply more comfortable. \nThe use of wind vane self-steering was common on long-distance cruising yachts but is increasingly being supplemented or replaced by electrical auto-pilots.\nThough in the past many cruisers had no means of generating electricity on board and depended on kerosene and dry-cell batteries, today electrical demands are much higher and nearly all cruisers have electrical devices such as lights, communications equipment and refrigeration. Although most boats can generate power from their inboard engines, an increasing number carry auxiliary generators. Carrying sufficient fuel to power engine and generator over a long voyage can be a problem, so many cruising boats are equipped with other ancillary generating devices such as solar panels, wind turbines and towed turbines. Cruisers choosing to spend extended time in very remote locations with minimal access to marinas can opt to equip their vessels with watermakers (reverse-osmosis seawater desalination units) used to convert sea water to potable fresh water.\nSatellite communications are becoming more common on cruising boats. Many boats are now equipped with satellite telephone systems; however, these systems can be expensive to use, and may operate only in certain areas. Many cruisers still use short wave maritime SSB and amateur radio, which has no running costs. These radios provide two-way voice communications, can receive weather fax graphics or GRIB files via a laptop computer, and with a compatible modem (e.g. PACTOR) can send and receive email at very slow speed. Such emails are usually limited to basic communication using plain text, without HTML formatting or attachments.\nAwareness of impending weather conditions is particularly important to cruising sailors who are often far from safe harbours and need to steer clear of dangerous weather conditions. Most cruising boats are equipped with a barometer or a weather station that records barometric pressure as well as temperature and provides rudimentary forecasting. For more sophisticated weather forecasting, cruisers rely on their ability to receive forecasts by radio, phone or satellite.\nIn order to avoid collisions with other vessels, cruisers rely on a maintaining a regular watch schedule. At night, color-coded running lights help determine the position and orientation of vessels. Radar and AIS systems are often employed to detect vessels positions and movement in all conditions (day, night, rain and fog).\nCruisers navigate using paper charts and radar. Modern yachts are often also equipped with a chartplotter which enables the use of electronic charts and is linked to GPS satellites that provide position reports. Some chartplotters have the ability to interface charts and radar images. Those that still wish to work with traditional charts as well as with GPS may do so using a Yeoman Plotter. Certain advanced sailing vessels have a completely automated sailing system which includes a plotter, as well as course correcting through a link with the ship's steering organs (e.g. sails, propeller). One such device can be found at the Maltese Falcon.\nThere are also sails made with cruising in mind. Sailing downwind is always enjoyable, but there is a vast difference as to how easy it is to manage - especially short-handed. This is where furling sails come into play, and these vary from the more specialized types of furling spinnakers to combined products such as the blue water runner-type of sails.\nExpense.\nPurchasing and maintaining a yacht can be costly. Most cruising sailors do not own a house and consider their boat their home during the duration of their cruise. Many cruisers find they spend, on average, 4% of their boat's purchase price annually on boat maintenance.\nLike living a conventional life on land, the cost of cruising is variable. How much a person ends up spending depends largely on their spending habits (for example, eating out a lot and frequenting marinas vs. preparing local foods aboard and anchoring out) and the type of boat (fancy modern production boats are very expensive to purchase and maintain, while low-key cruising boats often involve much lower expenses). Most long-term cruisers prefer to live a simple life, usually with far lower expenses than people who live ashore.\nAn alternative solution is to sail on someone else's yacht. Those who know how to sail can sometimes find boats looking for an extra crewmember for a long trip, while some non-sailors are also able to find boats willing to carry a hitch-hiker. Crew-finding websites exist to help match-up people looking for a crossing with yachts with a berth available or looking for a temporary crewmember, Find a Crew for example. Another common tactic for finding a yacht is to visit local yacht clubs and marinas and get to know the sailors there, in the hope that one of them will be able to provide a berth.\nSafety.\nTravel by water brings hazards: collision, weather, and equipment failure can lead to dangerous situations such as a sinking or severely disabled and dangerous vessel. For this reason many long-distance cruising yachts carry with them emergency equipment such as SARTs, EPIRBs and liferafts or proactive lifeboats. Medical emergencies are also of concern, as a medical emergency can occur on a long passage when the closest port is over a week away. For this reason before going cruising many people go through first aid training and carry medical kits. In some parts of the world (e.g., near the Horn of Africa) piracy can be a problem."}
{"id": "7807", "revid": "21857263", "url": "https://en.wikipedia.org/wiki?curid=7807", "title": "Cavitation", "text": "Cavitation in fluid mechanics and engineering normally is the phenomenon in which the static pressure of a liquid reduces to below the liquid's vapor pressure, leading to the formation of small vapor-filled cavities in the liquid. When subjected to higher pressure, these cavities, called \"bubbles\" or \"voids\", collapse and can generate shock waves that may damage machinery. These shock waves are strong when they are very close to the imploded bubble, but rapidly weaken as they propagate away from the implosion. Cavitation is a significant cause of wear in some engineering contexts. Collapsing voids that implode near to a metal surface cause cyclic stress through repeated implosion. This results in surface fatigue of the metal, causing a type of wear also called \"cavitation\". The most common examples of this kind of wear are to pump impellers, and bends where a sudden change in the direction of liquid occurs. \nCavitation is usually divided into two classes of behavior. \"Inertial (or transient) cavitation\" is the process in which a void or bubble in a liquid rapidly collapses, producing a shock wave. It occurs in nature in the strikes of mantis shrimp and pistol shrimp, as well as in the vascular tissues of plants. In manufactured objects, it can occur in control valves, pumps, propellers and impellers.\n\"Non-inertial cavitation\" is the process in which a bubble in a fluid is forced to oscillate in size or shape due to some form of energy input, such as an acoustic field. The gas in the bubble may contain a portion of a different gas than the vapor phase of the liquid. Such cavitation is often employed in ultrasonic cleaning baths and can also be observed in pumps, propellers, etc.\nSince the shock waves formed by collapse of the voids are strong enough to cause significant damage to parts, cavitation is typically an undesirable phenomenon in machinery. It may be desirable if intentionally used, for example, to sterilize contaminated surgical instruments, break down pollutants in water purification systems, emulsify tissue for cataract surgery or kidney stone lithotripsy, or homogenize fluids. It is very often specifically prevented in the design of machines such as turbines or propellers, and eliminating cavitation is a major field in the study of fluid dynamics. However, it is sometimes useful and does not cause damage when the bubbles collapse away from machinery, such as in supercavitation.\nPhysics.\nInertial cavitation.\nInertial cavitation was first observed in the late 19th century, considering the collapse of a spherical void within a liquid. When a volume of liquid is subjected to a sufficiently low pressure, it may rupture and form a cavity. This phenomenon is coined \"cavitation inception\" and may occur behind the blade of a rapidly rotating propeller or on any surface vibrating in the liquid with sufficient amplitude and acceleration. A fast-flowing river can cause cavitation on rock surfaces, particularly when there is a drop-off, such as on a waterfall.\nVapor gases evaporate into the cavity from the surrounding medium; thus, the cavity is not a vacuum at all, but rather a low-pressure vapor (gas) bubble. Once the conditions which caused the bubble to form are no longer present, such as when the bubble moves downstream, the surrounding liquid begins to implode due its higher pressure, building up momentum as it moves inward. As the bubble finally collapses, the inward momentum of the surrounding liquid causes a sharp increase of pressure and temperature of the vapor within. The bubble eventually collapses to a minute fraction of its original size, at which point the gas within dissipates into the surrounding liquid via a rather violent mechanism which releases a significant amount of energy in the form of an acoustic shock wave and as visible light. At the point of total collapse, the temperature of the vapor within the bubble may be several thousand Kelvin, and the pressure several hundred atmospheres.\nThe physical process of cavitation inception is similar to boiling. The major difference between the two is the thermodynamic paths that precede the formation of the vapor. Boiling occurs when the local temperature of the liquid reaches the saturation temperature, and further heat is supplied to allow the liquid to sufficiently phase change into a gas. Cavitation inception occurs when the local pressure falls sufficiently far below the saturated vapor pressure, a value given by the tensile strength of the liquid at a certain temperature.\nIn order for cavitation inception to occur, the cavitation \"bubbles\" generally need a surface on which they can nucleate. This surface can be provided by the sides of a container, by impurities in the liquid, or by small undissolved microbubbles within the liquid. It is generally accepted that hydrophobic surfaces stabilize small bubbles. These pre-existing bubbles start to grow unbounded when they are exposed to a pressure below the threshold pressure, termed Blake's threshold. The presence of an incompressible core inside a cavitation nucleus substantially lowers the cavitation threshold below the Blake threshold.\nThe vapor pressure here differs from the meteorological definition of vapor pressure, which describes the partial pressure of water in the atmosphere at some value less than 100% saturation. Vapor pressure as relating to cavitation refers to the vapor pressure in equilibrium conditions and can therefore be more accurately defined as the equilibrium (or saturated) vapor pressure.\nNon-inertial cavitation is the process in which small bubbles in a liquid are forced to oscillate in the presence of an acoustic field, when the intensity of the acoustic field is insufficient to cause total bubble collapse. This form of cavitation causes significantly less erosion than inertial cavitation, and is often used for the cleaning of delicate materials, such as silicon wafers.\nOther ways of generating cavitation voids involve the local deposition of energy, such as an intense focused laser pulse (optic cavitation) or with an electrical discharge through a spark. These techniques have been used to study the evolution of the bubble that is actually created by locally boiling the liquid with a local increment of temperature.\nHydrodynamic cavitation.\nHydrodynamic cavitation is the process of vaporisation, bubble generation and bubble implosion which occurs in a flowing liquid as a result of a decrease and subsequent increase in local pressure. Cavitation will only occur if the local pressure declines to some point below the saturated vapor pressure of the liquid and subsequent recovery above the vapor pressure. If the recovery pressure is not above the vapor pressure then flashing is said to have occurred. In pipe systems, cavitation typically occurs either as the result of an increase in the kinetic energy (through an area constriction) or an increase in the pipe elevation.\nHydrodynamic cavitation can be produced by passing a liquid through a constricted channel at a specific flow velocity or by mechanical rotation of an object through a liquid. In the case of the constricted channel and based on the specific (or unique) geometry of the system, the combination of pressure and kinetic energy can create the hydrodynamic cavitation cavern downstream of the local constriction generating high energy cavitation bubbles.\nBased on the thermodynamic phase change diagram, an increase in temperature could initiate a known phase change mechanism known as boiling. However, a decrease in static pressure could also help one pass the multi-phase diagram and initiate another phase change mechanism known as cavitation. On the other hand, a local increase in flow velocity could lead to a static pressure drop to the critical point at which cavitation could be initiated (based on Bernoulli's principle). The critical pressure point is vapor saturated pressure. In a closed fluidic system where no flow leakage is detected, a decrease in cross-sectional area would lead to velocity increment and hence static pressure drop. This is the working principle of many hydrodynamic cavitation based reactors for different applications such as water treatment, energy harvesting, heat transfer enhancement, food processing, etc.\nThere are different flow patterns detected as a cavitation flow progresses: inception, developed flow, supercavitation, and choked flow. Inception is the first moment that the second phase (gas phase) appears in the system. This is the weakest cavitating flow captured in a system corresponding to the highest cavitation number. When the cavities grow and becomes larger in size in the orifice or venturi structures, developed flow is recorded. The most intense cavitating flow is known as supercavitation where theoretically all the nozzle area of an orifice is filled with gas bubbles. This flow regime corresponds to the lowest cavitation number in a system. After supercavitation, the system is not capable of passing more flow. Hence, velocity does not change while the upstream pressure increase. This would lead to an increase in cavitation number which shows that choked flow occurred.\nThe process of bubble generation, and the subsequent growth and collapse of the cavitation bubbles, results in very high energy densities and in very high local temperatures and local pressures at the surface of the bubbles for a very short time. The overall liquid medium environment, therefore, remains at ambient conditions. When uncontrolled, cavitation is damaging; by controlling the flow of the cavitation, however, the power can be harnessed and non-destructive. Controlled cavitation can be used to enhance chemical reactions or propagate certain unexpected reactions because free radicals are generated in the process due to disassociation of vapors trapped in the cavitating bubbles.\nOrifices and venturi are reported to be widely used for generating cavitation. A venturi has an inherent advantage over an orifice because of its smooth converging and diverging sections, such that it can generate a higher flow velocity at the throat for a given pressure drop across it. On the other hand, an orifice has an advantage that it can accommodate a greater number of holes (larger perimeter of holes) in a given cross sectional area of the pipe.\nThe cavitation phenomenon can be controlled to enhance the performance of high-speed marine vessels and projectiles, as well as in material processing technologies, in medicine, etc. Controlling the cavitating flows in liquids can be achieved only by advancing the mathematical foundation of the cavitation processes. These processes are manifested in different ways, the most common ones and promising for control being bubble cavitation and supercavitation. The first exact classical solution should perhaps be credited to the well-known solution by Hermann von Helmholtz in 1868. The earliest distinguished studies of academic type on the theory of a cavitating flow with free boundaries and supercavitation were published in the book \"Jets, wakes and cavities\" followed by \"Theory of jets of ideal fluid\". Widely used in these books was the well-developed theory of conformal mappings of functions of a complex variable, allowing one to derive a large number of exact solutions of plane problems. Another venue combining the existing exact solutions with approximated and heuristic models was explored in the work \"Hydrodynamics of Flows with Free Boundaries\" that refined the applied calculation techniques based on the principle of cavity expansion independence, theory of pulsations and stability of elongated axisymmetric cavities, etc. and in \"Dimensionality and similarity methods in the problems of the hydromechanics of vessels\".\nA natural continuation of these studies was recently presented in \"The Hydrodynamics of Cavitating Flows\" \u2013 an encyclopedic work encompassing all the best advances in this domain for the last three decades, and blending the classical methods of mathematical research with the modern capabilities of computer technologies. These include elaboration of nonlinear numerical methods of solving 3D cavitation problems, refinement of the known plane linear theories, development of asymptotic theories of axisymmetric and nearly axisymmetric flows, etc. As compared to the classical approaches, the new trend is characterized by expansion of the theory into the 3D flows. It also reflects a certain correlation with current works of an applied character on the hydrodynamics of supercavitating bodies.\nHydrodynamic cavitation can also improve some industrial processes. For instance, cavitated corn slurry shows higher yields in ethanol production compared to uncavitated corn slurry in dry milling facilities.\nThis is also used in the mineralization of bio-refractory compounds which otherwise would need extremely high temperature and pressure conditions since free radicals are generated in the process due to the dissociation of vapors trapped in the cavitating bubbles, which results in either the intensification of the chemical reaction or may even result in the propagation of certain reactions not possible under otherwise ambient conditions.\nAcoustic cavitation and ultrasonic cavitation.\nInertial cavitation can also occur in the presence of an acoustic field. Microscopic gas bubbles that are generally present in a liquid will be forced to oscillate due to an applied acoustic field. If the acoustic intensity is sufficiently high, the bubbles will first grow in size and then rapidly collapse. Hence, inertial cavitation can occur even if the rarefaction in the liquid is insufficient for a Rayleigh-like void to occur.\nUltrasonic cavitation inception will occur when the acceleration of the ultrasound source is enough to produce the needed pressure drop. This pressure drop depends on the value of the acceleration and the size of the affected volume by the pressure wave. The dimensionless number that predicts ultrasonic cavitation is the Garcia-Atance number. High power ultrasonic horns produce accelerations high enough to create a cavitating region that can be used for homogenization, dispersion, deagglomeration, erosion, cleaning, milling, emulsification, extraction, disintegration, and sonochemistry.\nAerodyamic cavitation.\nAlthough predominant in liquids, cavitation exists to an extent in gas as it has fluid dynamics at high speeds. For example, a bullet with a flat tip moves faster underwater as it creates cavitation compared to a bullet with a sharp tip. An ideal shape for aerodynamic cavitation is a dune. It has such a form that provides minimal resistance to the wind. A surface with small dunes installed on aircraft and various high speed vehicles, the total friction against the air will decrease several times. The dune surface pushes the air upwards, underneath and behind the air pressure drops reducing friction. The dune may increase frontal resistance, but it will be compensated by a decrease in the total friction area, as it happens in an underwater bullet. As a result, the speed of the aircraft or vehicle will increase significantly.\nApplications.\nChemical engineering.\nIn industry, cavitation is often used to homogenize, or mix and break down, suspended particles in a colloidal liquid compound such as paint mixtures or milk. Many industrial mixing machines are based upon this design principle. It is usually achieved through impeller design or by forcing the mixture through an annular opening that has a narrow entrance orifice with a much larger exit orifice. In the latter case, the drastic decrease in pressure as the liquid accelerates into a larger volume induces cavitation. This method can be controlled with hydraulic devices that control inlet orifice size, allowing for dynamic adjustment during the process, or modification for different substances. The surface of this type of mixing valve, against which surface the cavitation bubbles are driven causing their implosion, undergoes tremendous mechanical and thermal localized stress; they are therefore often constructed of extremely strong and hard materials such as stainless steel, Stellite, or even polycrystalline diamond (PCD).\nCavitating water purification devices have also been designed, in which the extreme conditions of cavitation can break down pollutants and organic molecules. Spectral analysis of light emitted in sonochemical reactions reveal chemical and plasma-based mechanisms of energy transfer. The light emitted from cavitation bubbles is termed sonoluminescence.\nUse of this technology has been tried successfully in alkali refining of vegetable oils.\nHydrophobic chemicals are attracted underwater by cavitation as the pressure difference between the bubbles and the liquid water forces them to join. This effect may assist in protein folding.\nBiomedical.\nCavitation plays an important role for the destruction of kidney stones in shock wave lithotripsy. Currently, tests are being conducted as to whether cavitation can be used to transfer large molecules into biological cells (sonoporation). Nitrogen cavitation is a method used in research to lyse cell membranes while leaving organelles intact.\nCavitation plays a key role in non-thermal, non-invasive fractionation of tissue for treatment of a variety of diseases and can be used to open the blood-brain barrier to increase uptake of neurological drugs in the brain.\nCavitation also plays a role in HIFU, a thermal non-invasive treatment methodology for cancer.\nIn wounds caused by high velocity impacts (like for example bullet wounds) there are also effects due to cavitation. The exact wounding mechanisms are not completely understood yet as there is temporary cavitation, and permanent cavitation together with crushing, tearing and stretching. Also the high variance in density within the body makes it hard to determine its effects.\nUltrasound sometimes is used to increase bone formation, for instance in post-surgical applications.\nIt has been suggested that the sound of \"cracking\" knuckles derives from the collapse of cavitation in the synovial fluid within the joint.\nCavitation can also form Ozone micro-nanobubbles which shows promise in dental applications.\nCleaning.\nIn industrial cleaning applications, cavitation has sufficient power to overcome the particle-to-substrate adhesion forces, loosening contaminants. The threshold pressure required to initiate cavitation is a strong function of the pulse width and the power input. This method works by generating acoustic cavitation in the cleaning fluid, picking up and carrying contaminant particles away in the hope that they do not reattach to the material being cleaned (which is a possibility when the object is immersed, for example in an ultrasonic cleaning bath). The same physical forces that remove contaminants also have the potential to damage the target being cleaned.\nFood and beverage.\nEggs.\nCavitation has been applied to egg pasteurization. A hole-filled rotor produces cavitation bubbles, heating the liquid from within. Equipment surfaces stay cooler than the passing liquid, so eggs do not harden as they did on the hot surfaces of older equipment. The intensity of cavitation can be adjusted, making it possible to tune the process for minimum protein damage.\nVegetable oil production.\nCavitation has been applied to vegetable oil degumming and refining since 2011 and is considered a proven and standard technology in this application. The implementation of hydrodynamic cavitation in the degumming and refining process allows for a significant reduction in process aid, such as chemicals, water and bleaching clay, use.\nBiofuels.\nBiodiesel.\nCavitation has been applied to Biodiesel production since 2011 and is considered a proven and standard technology in this application. The implementation of hydrodynamic cavitation in the transesterification process allows for a significant reduction in catalyst use, quality improvement and production capacity increase.\nCavitation damage.\nCavitation is usually an undesirable occurrence. In devices such as propellers and pumps, cavitation causes a great deal of noise, damage to components, vibrations, and a loss of efficiency. Noise caused by cavitation can be particularly undesirable in naval vessels where such noise may render them more easily detectable by passive sonar. Cavitation has also become a concern in the renewable energy sector as it may occur on the blade surface of tidal stream turbines.\nWhen the cavitation bubbles collapse, they force energetic liquid into very small volumes, thereby creating spots of high temperature and emitting shock waves, the latter of which are a source of noise. The noise created by cavitation is a particular problem for military submarines, as it increases the chances of being detected by passive sonar.\nAlthough the collapse of a small cavity is a relatively low-energy event, highly localized collapses can erode metals, such as steel, over time. The pitting caused by the collapse of cavities produces great wear on components and can dramatically shorten a propeller's or pump's lifetime.\nAfter a surface is initially affected by cavitation, it tends to erode at an accelerating pace. The cavitation pits increase the turbulence of the fluid flow and create crevices that act as nucleation sites for additional cavitation bubbles. The pits also increase the components' surface area and leave behind residual stresses. This makes the surface more prone to stress corrosion.\nPumps and propellers.\nMajor places where cavitation occurs are in pumps, on propellers, or at restrictions in a flowing liquid.\nAs an impeller's (in a pump) or propeller's (as in the case of a ship or submarine) blades move through a fluid, low-pressure areas are formed as the fluid accelerates around and moves past the blades. The faster the blade moves, the lower the pressure can become around it. As it reaches vapor pressure, the fluid vaporizes and forms small bubbles of gas. This is cavitation. When the bubbles collapse later, they typically cause very strong local shock waves in the fluid, which may be audible and may even damage the blades.\nCavitation in pumps may occur in two different forms:\nSuction cavitation.\nSuction cavitation occurs when the pump suction is under a low-pressure/high-vacuum condition where the liquid turns into a vapor at the eye of the pump impeller. This vapor is carried over to the discharge side of the pump, where it no longer sees vacuum and is compressed back into a liquid by the discharge pressure. This imploding action occurs violently and attacks the face of the impeller. An impeller that has been operating under a suction cavitation condition can have large chunks of material removed from its face or very small bits of material removed, causing the impeller to look spongelike. Both cases will cause premature failure of the pump, often due to bearing failure. Suction cavitation is often identified by a sound like gravel or marbles in the pump casing.\nCommon causes of suction cavitation can include clogged filters, pipe blockage on the suction side, poor piping design, pump running too far right on the pump curve, or conditions not meeting NPSH (net positive suction head) requirements.\nIn automotive applications, a clogged filter in a hydraulic system (power steering, power brakes) can cause suction cavitation making a noise that rises and falls in synch with engine RPM. It is fairly often a high pitched whine, like set of nylon gears not quite meshing correctly.\nDischarge cavitation.\nDischarge cavitation occurs when the pump discharge pressure is extremely high, normally occurring in a pump that is running at less than 10% of its best efficiency point. The high discharge pressure causes the majority of the fluid to circulate inside the pump instead of being allowed to flow out the discharge. As the liquid flows around the impeller, it must pass through the small clearance between the impeller and the pump housing at extremely high flow velocity. This flow velocity causes a vacuum to develop at the housing wall (similar to what occurs in a venturi), which turns the liquid into a vapor. A pump that has been operating under these conditions shows premature wear of the impeller vane tips and the pump housing. In addition, due to the high pressure conditions, premature failure of the pump's mechanical seal and bearings can be expected. Under extreme conditions, this can break the impeller shaft.\nDischarge cavitation in joint fluid is thought to cause the popping sound produced by bone joint cracking, for example by deliberately cracking one's knuckles.\nCavitation solutions.\nSince all pumps require well-developed inlet flow to meet their potential, a pump may not perform or be as reliable as expected due to a faulty suction piping layout such as a close-coupled elbow on the inlet flange. When poorly developed flow enters the pump impeller, it strikes the vanes and is unable to follow the impeller passage. The liquid then separates from the vanes causing mechanical problems due to cavitation, vibration and performance problems due to turbulence and poor filling of the impeller. This results in premature seal, bearing and impeller failure, high maintenance costs, high power consumption, and less-than-specified head and/or flow.\nTo have a well-developed flow pattern, pump manufacturer's manuals recommend about (10 diameters?) of straight pipe run upstream of the pump inlet flange. Unfortunately, piping designers and plant personnel must contend with space and equipment layout constraints and usually cannot comply with this recommendation. Instead, it is common to use an elbow close-coupled to the pump suction which creates a poorly developed flow pattern at the pump suction.\nWith a double-suction pump tied to a close-coupled elbow, flow distribution to the impeller is poor and causes reliability and performance shortfalls. The elbow divides the flow unevenly with more channeled to the outside of the elbow. Consequently, one side of the double-suction impeller receives more flow at a higher flow velocity and pressure while the starved side receives a highly turbulent and potentially damaging flow. This degrades overall pump performance (delivered head, flow and power consumption) and causes axial imbalance which shortens seal, bearing and impeller life.\nTo overcome cavitation:\nIncrease suction pressure if possible.\nDecrease liquid temperature if possible.\nThrottle back on the discharge valve to decrease flow-rate.\nVent gases off the pump casing.\nControl valves.\nCavitation can occur in control valves. If the actual pressure drop across the valve as defined by the upstream and downstream pressures in the system is greater than the sizing calculations allow, pressure drop flashing or cavitation may occur. The change from a liquid state to a vapor state results from the increase in flow velocity at or just downstream of the greatest flow restriction which is normally the valve port. To maintain a steady flow of liquid through a valve the flow velocity must be greatest at the vena contracta or the point where the cross sectional area is the smallest. This increase in flow velocity is accompanied by a substantial decrease in the fluid pressure which is partially recovered downstream as the area increases and flow velocity decreases. This pressure recovery is never completely to the level of the upstream pressure. If the pressure at the vena contracta drops below the vapor pressure of the fluid bubbles will form in the flow stream. If the pressure recovers after the valve to a pressure that is once again above the vapor pressure, then the vapor bubbles will collapse and cavitation will occur.\nSpillways.\nWhen water flows over a dam spillway, the irregularities on the spillway surface will cause small areas of flow separation in a high-speed flow, and, in these regions, the pressure will be lowered. If the flow velocities are high enough the pressure may fall to below the local vapor pressure of the water and vapor bubbles will form. When these are carried downstream into a high pressure region the bubbles collapse giving rise to high pressures and possible cavitation damage.\nExperimental investigations show that the damage on concrete chute and tunnel spillways can start at clear water flow velocities of between , and, up to flow velocities of , it may be possible to protect the surface by streamlining the boundaries, improving the surface finishes or using resistant materials.\nWhen some air is present in the water the resulting mixture is compressible and this damps the high pressure caused by the bubble collapses. If the flow velocities near the spillway invert are sufficiently high, aerators (or aeration devices) must be introduced to prevent cavitation. Although these have been installed for some years, the mechanisms of air entrainment at the aerators and the slow movement of the air away from the spillway surface are still challenging.\nThe spillway aeration device design is based upon a small deflection of the spillway bed (or sidewall) such as a ramp and offset to deflect the high flow velocity flow away from the spillway surface. In the cavity formed below the nappe, a local subpressure beneath the nappe is produced by which air is sucked into the flow. The complete design includes the deflection device (ramp, offset) and the air supply system.\nEngines.\nSome larger diesel engines suffer from cavitation due to high compression and undersized cylinder walls. Vibrations of the cylinder wall induce alternating low and high pressure in the coolant against the cylinder wall. The result is pitting of the cylinder wall, which will eventually let cooling fluid leak into the cylinder and combustion gases to leak into the coolant.\nIt is possible to prevent this from happening with the use of chemical additives in the cooling fluid that form a protective layer on the cylinder wall. This layer will be exposed to the same cavitation, but rebuilds itself. Additionally a regulated overpressure in the cooling system (regulated and maintained by the coolant filler cap spring pressure) prevents the forming of cavitation.\nFrom about the 1980s, new designs of smaller gasoline engines also displayed cavitation phenomena. One answer to the need for smaller and lighter engines was a smaller coolant volume and a correspondingly higher coolant flow velocity. This gave rise to rapid changes in flow velocity and therefore rapid changes of static pressure in areas of high heat transfer. Where resulting vapor bubbles collapsed against a surface, they had the effect of first disrupting protective oxide layers (of cast aluminium materials) and then repeatedly damaging the newly formed surface, preventing the action of some types of corrosion inhibitor (such as silicate based inhibitors). A final problem was the effect that increased material temperature had on the relative electrochemical reactivity of the base metal and its alloying constituents. The result was deep pits that could form and penetrate the engine head in a matter of hours when the engine was running at high load and high speed. These effects could largely be avoided by the use of organic corrosion inhibitors or (preferably) by designing the engine head in such a way as to avoid certain cavitation inducing conditions.\nIn nature.\nGeology.\nSome hypotheses relating to diamond formation posit a possible role for cavitation\u2014namely cavitation in the kimberlite pipes providing the extreme pressure needed to change pure carbon into the rare allotrope that is diamond. The loudest three sounds ever recorded, during the 1883 eruption of Krakatoa, are now understood as the bursts of three huge cavitation bubbles, each larger than the last, formed in the volcano's throat. Rising magma, filled with dissolved gasses and under immense pressure, encountered a different magma that compressed easily, allowing bubbles to grow and combine.\nVascular plants.\nCavitation can occur in the xylem of vascular plants. The sap vaporizes locally so that either the vessel elements or tracheids are filled with water vapor. Plants are able to repair cavitated xylem in a number of ways. For plants less than 50\u00a0cm tall, root pressure can be sufficient to redissolve the vapor. Larger plants direct solutes into the xylem via \"ray cells\", or in tracheids, via osmosis through bordered pits. Solutes attract water, the pressure rises and vapor can redissolve. In some trees, the sound of the cavitation is audible, particularly in summer, when the rate of evapotranspiration is highest. Some deciduous trees have to shed leaves in the autumn partly because cavitation increases as temperatures decrease.\nSpore dispersal in plants.\nCavitation plays a role in the spore dispersal mechanisms of certain plants. In ferns, for example, the fern sporangium acts as a catapult that launches spores into the air. The charging phase of the catapult is driven by water evaporation from the annulus cells, which triggers a pressure decrease. When the compressive pressure reaches approximately 9MPa, cavitation occurs. This rapid event triggers spore dispersal due to the elastic energy released by the annulus structure. The initial spore acceleration is extremely large \u2013 up to 10 times the gravitational acceleration.\nMarine life.\nJust as cavitation bubbles form on a fast-spinning boat propeller, they may also form on the tails and fins of aquatic animals. This primarily occurs near the surface of the ocean, where the ambient water pressure is low.\nCavitation may limit the maximum swimming speed of powerful swimming animals like dolphins and tuna. Dolphins may have to restrict their speed because collapsing cavitation bubbles on their tail are painful. Tuna have bony fins without nerve endings and do not feel pain from cavitation. They are slowed down when cavitation bubbles create a vapor film around their fins. Lesions have been found on tuna that are consistent with cavitation damage.\nSome sea animals have found ways to use cavitation to their advantage when hunting prey. The pistol shrimp snaps a specialized claw to create cavitation, which can kill small fish. The mantis shrimp (of the \"smasher\" variety) uses cavitation as well in order to stun, smash open, or kill the shellfish that it feasts upon.\nThresher sharks use 'tail slaps' to debilitate their small fish prey and cavitation bubbles have been seen rising from the apex of the tail arc.\nCoastal erosion.\nIn the last half-decade, coastal erosion in the form of inertial cavitation has been generally accepted. Bubbles in an incoming wave are forced into cracks in the cliff being eroded. Varying pressure decompresses some vapor pockets which subsequently implode. The resulting pressure peaks can blast apart fractions of the rock.\nHistory.\nAs early as 1754, the Swiss mathematician Leonhard Euler (1707\u20131783) speculated about the possibility of cavitation. In 1859, the English mathematician William Henry Besant (1828\u20131917) published a solution to the problem of the dynamics of the collapse of a spherical cavity in a fluid, which had been presented by the Anglo-Irish mathematician George Stokes (1819\u20131903) as one of the Cambridge [University] Senate-house problems and riders for the year 1847. In 1894, Irish fluid dynamicist Osborne Reynolds (1842\u20131912) studied the formation and collapse of vapor bubbles in boiling liquids and in constricted tubes.\nThe term \"cavitation\" first appeared in 1895 in a paper by John Isaac Thornycroft (1843\u20131928) and Sydney Walker Barnaby (1855\u20131925)\u2014son of Sir Nathaniel Barnaby (1829 \u2013 1915), who had been Chief Constructor of the Royal Navy\u2014to whom it had been suggested by the British engineer Robert Edmund Froude (1846\u20131924), third son of the English hydrodynamicist William Froude (1810\u20131879). Early experimental studies of cavitation were conducted in 1894\u20135 by Thornycroft and Barnaby and by the Anglo-Irish engineer Charles Algernon Parsons (1854\u20131931), who constructed a stroboscopic apparatus to study the phenomenon. Thornycroft and Barnaby were the first researchers to observe cavitation on the back sides of propeller blades.\nIn 1917, the British physicist Lord Rayleigh (1842\u20131919) extended Besant's work, publishing a mathematical model of cavitation in an incompressible fluid (ignoring surface tension and viscosity), in which he also determined the pressure in the fluid. The mathematical models of cavitation which were developed by British engineer Stanley Smith Cook (1875\u20131952) and by Lord Rayleigh revealed that collapsing bubbles of vapor could generate very high pressures, which were capable of causing the damage that had been observed on ships' propellers. Experimental evidence of cavitation causing such high pressures was initially collected in 1952 by Mark Harrison (a fluid dynamicist and acoustician at the U.S. Navy's David Taylor Model Basin at Carderock, Maryland, USA) who used acoustic methods and in 1956 by Wernfried G\u00fcth (a physicist and acoustician of G\u00f6ttigen University, Germany) who used optical Schlieren photography.\nIn 1944, Soviet scientists Mark Iosifovich Kornfeld (1908\u20131993) and L. Suvorov of the Leningrad Physico-Technical Institute (now: the Ioffe Physical-Technical Institute of the Russian Academy of Sciences, St. Petersburg, Russia) proposed that during cavitation, bubbles in the vicinity of a solid surface do not collapse symmetrically; instead, a dimple forms on the bubble at a point opposite the solid surface and this dimple evolves into a jet of liquid. This jet of liquid damages the solid surface. This hypothesis was supported in 1951 by theoretical studies by Maurice Rattray Jr., a doctoral student at the California Institute of Technology. Kornfeld and Suvorov's hypothesis was confirmed experimentally in 1961 by Charles F. Naud\u00e9 and Albert T. Ellis, fluid dynamicists at the California Institute of Technology.\nA series of experimental investigations of the propagation of strong shock wave (SW) in a liquid with gas bubbles, which made it possible to establish the basic laws governing the process, the mechanism for the transformation of the energy of the SW, attenuation of the SW, and the formation of the structure, and experiments on the analysis of the attenuation of waves in bubble screens with different acoustic properties were begun by pioneer works of Soviet scientist prof.V.F. Minin at the Institute of Hydrodynamics (Novosibirsk, Russia) in 1957\u20131960, who examined also the first convenient model of a screen - a sequence of alternating flat one-dimensional liquid and gas layers. In an experimental investigations of the dynamics of the form of pulsating gaseous cavities and interaction of SW with bubble clouds in 1957\u20131960 V.F. Minin discovered that under the action of SW a bubble collapses asymmetrically with the formation of a cumulative jet, which forms in the process of collapse and causes fragmentation of the bubble."}
{"id": "7808", "revid": "1241083781", "url": "https://en.wikipedia.org/wiki?curid=7808", "title": "Cyprinodontiformes", "text": "Cyprinodontiformes is an order of ray-finned fish, comprising mostly small, freshwater fish. Many popular aquarium fish, such as killifish and live-bearers, are included. They are closely related to the Atheriniformes and are occasionally included with them. A colloquial term for the order as a whole is toothcarps, though they are not actually close relatives of the true carps \u2013 the latter belong to the superorder Ostariophysi, while the toothcarps are Acanthopterygii.\nThe families of Cyprinodontiformes can be informally divided into three groups based on reproductive strategy: viviparous and ovoviviparous (all species give live birth), and oviparous (all species are egg-laying). The live-bearing groups differ in whether the young are carried to term within (ovoviviparous) or without (viviparous) an enclosing eggshell. Phylogenetically however, one of the two suborders \u2013 the Aplocheiloidei \u2013 contains oviparous species exclusively, as do two of the four superfamilies of the other suborder (the Cyprinodontoidea and Valencioidea of the Cyprinodontoidei). Vivipary and ovovivipary have evolved independently from oviparous ancestors, the latter possibly twice.\nDescription.\nSome members of this order are notable for inhabiting extreme environments, such as saline or very warm waters, heavily polluted waters, rain water pools devoid of minerals and made acidic by decaying vegetation, or isolated situations where no other types of fish occur.\nThey are typically carnivores, and often live near the surface, where the oxygen-rich water compensates for environmental disadvantages. Scheel (1968) observed the gut contents were invariably ants, others have reported insects, worms and aquatic crustaceans. Aquarium specimens are invariably seen eating protozoans from the water column and the surfaces of leaves, however these are not apparent as stomach contents. Many members of the family Cyprinodontidae (the pupfishes) eat plant material as well and some have adapted to a diet very high in algae to the point where one, the American Flag Fish, is a renowned algae eater in the aquarium, in spite of belonging to an order of fishes that do not generally consume any plant material. In addition, killifish derive some of the carotenoids and other chemicals required to make their body pigments from pollen grains on the surface of and in the gut of insects they eat from the surface of the water; this can be simulated in culture by the use of special color enhancing foods that contain these compounds.\nAlthough the Cyprinodontiformes are a diverse group, most species contained within are small to medium-sized fish, with small mouths, large eyes, a single dorsal fin, and a rounded caudal fin. The largest species is the \"cuatro ojos\" (\"Anableps dowei\"), which measures in length, while the smallest, the least killifish (\"Heterandria formosa\"), is just long as an adult.\nSystematics.\nCYPRINODONTIFORMES\nThe family Aplocheilidae has been expanded by some authorities to include all the killifishes with three subfamilies, Aplocheilinae, Cynolebiinae and Nothobranchiinae, but this is not the classification adopted in the 5th Edition of \"Fishes of the World\"."}
{"id": "7810", "revid": "1271138089", "url": "https://en.wikipedia.org/wiki?curid=7810", "title": "Church of the Holy Sepulchre", "text": "The Church of the Holy Sepulchre, also known as the Church of the Resurrection, is a fourth-century church in the Christian Quarter of the Old City of Jerusalem. The church is the seat of the Greek Orthodox Patriarchate of Jerusalem. Some consider it the holiest site in Christianity and it has been an important pilgrimage site for Christians since the fourth century.\nAccording to traditions dating to the fourth century, the church contains both the site where Jesus was crucified at Calvary, or Golgotha, and the location of Jesus's empty tomb, where he was buried and resurrected. Both locations are considered immensely holy sites by Christians. In earlier times, the site was used as a Jewish burial ground, upon which a pagan temple was built. The church and rotunda was built under Constantine in the 4th century and destroyed by al-Hakim in 1009. Al-Hakim's son allowed Emperor Constantine IX Monomachos to reconstruct the church, which was completed in 1048. After it was captured by the Crusaders in 1099, it continued to undergo modifications, resulting in a significant departure from the original structure. Several renovations and restorations were made under the Ottomans. The tomb itself is enclosed by a 19th-century shrine called the Aedicule.\nWithin the church proper are the last four stations of the Cross of the Via Dolorosa, representing the final episodes of the Passion of Jesus. The church has been a major Christian pilgrimage destination since its creation in the fourth century, as the traditional site of the resurrection of Christ, thus its original Greek name, Church of the Anastasis ('Resurrection').\nThe Status Quo, an understanding between religious communities dating to 1757, applies to the site. Control of the church itself is shared among several Christian denominations and secular entities in complicated arrangements essentially unchanged for over 160 years, and some for much longer. The main denominations sharing property over parts of the church are the Roman Catholic, Greek Orthodox, Armenian Apostolic, Coptic, Syriac, and Ethiopian Orthodox churches. Directly adjacent to the Church of the Holy Sepulchre is the Church of the Redeemer, marking a Lutheran presence at the site.\nName.\nThe church was named either for the Resurrection of Jesus, or for his tomb, which is at its focal point.\nThe Church of the Holy Sepulchre is also known as the Basilica of the Holy Sepulchre and the Holy Sepulchre.\nEastern Christians also call it the Church of the Resurrection and the Church of the Anastasis, Anastasis being Greek for Resurrection.\nHistory.\nBackground (1st\u20134th centuries).\nAfter the siege of Jerusalem in AD 70 during the First Jewish\u2013Roman War, Jerusalem had been reduced to ruins. In AD\u00a0130, the Roman emperor Hadrian began the building of a Roman colony, the new city of , on the site. About AD\u00a0135, he ordered that a cave containing a rock-cut tomb be filled in to make a flat foundation for a temple dedicated to Jupiter or Venus. The temple remained until the early fourth century.\nConstantine and Macarius: context for the first sanctuary.\nAfter seeing a vision of a cross in the sky in 312, Constantine the Great began to favour Christianity and signed the Edict of Milan legalizing the religion. The Bishop of Jerusalem Macarius asked Constantine for permission to dig for the tomb. With the help of Eusebius (a Bishop of Caesarea) and Macarius, three crosses were found near a tomb; one, which was said to have cured people of death, was presumed to be the True Cross, on which Jesus was crucified, leading the Romans to believe that they had found Calvary.\nAbout 326, Constantine ordered that the temple to Jupiter or Venus be replaced by a church. After the temple was torn down and its ruins removed, the soil was removed from the cave, revealing a rock-cut tomb that Macarius identified as the burial site of Jesus.\nFirst sanctuary (4th century).\nA shrine was built on the site of the tomb Macarius had identified as that of Jesus, enclosing the rock tomb walls within its own.\nThe Church of the Holy Sepulchre, planned by the architect Zenobius, was built as separate constructs over two holy sites:\nThe Church of the Holy Sepulchre site has been recognized since early in the fourth century as the place where Jesus was crucified, buried, and rose from the dead. The church was consecrated on 13 September 335.\nIn 327, Constantine and Helena separately commissioned the Church of the Nativity in Bethlehem to commemorate the birth of Jesus.\nDamage and destruction (614\u20131009).\nThe Constantinian sanctuary in Jerusalem was destroyed by a fire in May of 614, when the Sassanid Empire, under Khosrau II, invaded Jerusalem and captured the True Cross. In 630, the Emperor Heraclius rebuilt the church after recapturing the city.\nAfter Jerusalem came under Islamic rule, it remained a Christian church, with the early Muslim rulers protecting the city's Christian sites, prohibiting their destruction or use as living quarters. A story reports that the caliph Umar ibn al-Khattab visited the church and stopped to pray on the balcony, but at the time of prayer, turned away from the church and prayed outside. He feared that future generations would misinterpret this gesture, taking it as a pretext to turn the church into a mosque. Eutychius of Alexandria adds that Umar wrote a decree saying that Muslims would not inhabit this location. The building suffered severe damage from an earthquake in 746.\nEarly in the ninth century, another earthquake damaged the dome of the Anastasis. The damage was repaired in 810 by Patriarch Thomas I. In 841, the church suffered a fire. In 935, the Christians prevented the construction of a Muslim mosque adjacent to the Church. In 938, a new fire damaged the inside of the basilica and came close to the rotunda. In 966, due to a defeat of Muslim armies in the region of Syria, a riot broke out, which was followed by reprisals. The basilica was burned again. The doors and roof were burnt, and Patriarch John VII was murdered.\nOn 18 October 1009, Fatimid caliph al-Hakim bi-Amr Allah ordered the complete destruction of the church as part of a more general campaign against Christian places of worship in Palestine and Egypt. The damage was extensive, with few parts of the early church remaining, and the roof of the rock-cut tomb damaged; the original shrine was destroyed. Some partial repairs followed. Christian Europe reacted with shock: it was a spur to expulsions of Jews and, later on, the Crusades.\nReconstruction (11th century).\nIn wide-ranging negotiations between the Fatimids and the Byzantine Empire in 1027\u20131028, an agreement was reached whereby the new Caliph Ali az-Zahir (al-Hakim's son) agreed to allow the rebuilding and redecoration of the church. The rebuilding was finally completed during the tenures of Emperor Constantine IX Monomachos and Patriarch Nicephorus of Jerusalem in 1048. As a concession, the mosque in Constantinople was reopened and the khutba sermons were to be pronounced in az-Zahir's name. Muslim sources say a by-product of the agreement was the renunciation of Islam by many Christians who had been forced to convert under al-Hakim's persecutions. In addition, the Byzantines, while releasing 5,000 Muslim prisoners, made demands for the restoration of other churches destroyed by al-Hakim and the reestablishment of a patriarch in Jerusalem. Contemporary sources credit the emperor with spending vast sums in an effort to restore the Church of the Holy Sepulchre after this agreement was made. Still, \"a total replacement was far beyond available resources. The new construction was concentrated on the rotunda and its surrounding buildings: the great basilica remained in ruins.\"\nThe rebuilt church site consisted of \"a court open to the sky, with five small chapels attached to it.\" The chapels were east of the court of resurrection (when reconstructed, the location of the tomb was under open sky), where the western wall of the great basilica had been. They commemorated scenes from the passion, such as the location of the prison of Christ and his flagellation, and presumably were so placed because of the difficulties of free movement among shrines in the city streets. The dedication of these chapels indicates the importance of the pilgrims' devotion to the suffering of Christ. They have been described as \"a sort of Via Dolorosa in miniature\" since little or no rebuilding took place on the site of the great basilica. Western pilgrims to Jerusalem during the 11th century found much of the sacred site in ruins. Control of Jerusalem, and thereby the Church of the Holy Sepulchre, continued to change hands several times between the Fatimids and the Seljuk Turks (loyal to the Abbasid caliph in Baghdad) until the Crusaders' arrival in 1099.\nCrusader period (1099\u20131244).\nBackground.\nMany historians maintain that the main concern of Pope Urban II, when calling for the First Crusade, was the threat to Constantinople from the Seljuk invasion of Asia Minor in response to the appeal of Byzantine Emperor Alexios I Komnenos. Historians agree that the fate of Jerusalem and thereby the Church of the Holy Sepulchre was also of concern, if not the immediate goal of papal policy in 1095. The idea of taking Jerusalem gained more focus as the Crusade was underway. The rebuilt church site was taken from the Fatimids (who had recently taken it from the Abbasids) by the knights of the First Crusade on 15 July 1099.\nThe First Crusade was envisioned as an armed pilgrimage, and no crusader could consider his journey complete unless he had prayed as a pilgrim at the Holy Sepulchre. The classical theory is that Crusader leader Godfrey of Bouillon, who became the first Latin ruler of Jerusalem, decided not to use the title \"king\" during his lifetime, and declared himself ('Protector [or Defender] of the Holy Sepulchre').\nAccording to the German priest and pilgrim Ludolf von Sudheim, the keys of the Chapel of the Holy Sepulchre were in hands of the \"ancient Georgians\", and the food, alms, candles and oil for lamps were given to them by the pilgrims at the south door of the church.\nCrusaders: reconstruction (12th century) and ownership.\nBy the Crusader period, a cistern under the former basilica was rumoured to have been where Helena had found the True Cross, and began to be venerated as such; the cistern later became the , but there is no evidence of the site's identification before the 11th century, and modern archaeological investigation has now dated the cistern to 11th-century repairs by Monomachos.\nWilliam of Tyre, chronicler of the Crusader Kingdom of Jerusalem, reports on the rebuilding of the church in the mid-12th century. The Crusaders investigated the eastern ruins on the site, occasionally excavating through the rubble, and while attempting to reach the cistern, they discovered part of the original ground level of Hadrian's temple enclosure; they transformed this space into a chapel dedicated to Helena, widening their original excavation tunnel into a proper staircase.\nThe Crusaders began to refurnish the church in Romanesque style and added a bell tower. These renovations unified the small chapels on the site and were completed during the reign of Queen Melisende in 1149, placing all the holy places under one roof for the first time.\nThe church became the seat of the first Latin patriarchs and the site of the kingdom's scriptorium.\nEight 11th- and 12th-century Crusader leaders (Godfrey, Baldwin I, Baldwin II, Fulk, Baldwin III, Amalric, Baldwin IV and Baldwin V \u2013 the first eight rulers of the Kingdom of Jerusalem) were buried in the south transept and inside the Chapel of Adam. \nThe royal tombs were looted during the Khwarizmian sack of Jerusalem in 1244 but probably remained mostly intact until 1808 when a fire damaged the church. The tombs may have been destroyed by the fire, or during renovations by the Greek Orthodox custodians of the church in 1809\u20131810. The remains of the kings may still be in unmarked pits under the church's pavement.\nThe church was lost to Saladin, along with the rest of the city, in 1187, although the treaty established after the Third Crusade allowed Christian pilgrims to visit the site. Emperor Frederick II (r. 1220\u201350) regained the city and the church by treaty in the 13th century while under a ban of excommunication, with the consequence that the holiest church in Christianity was laid under interdict. The church seems to have been largely in the hands of Greek Orthodox patriarch Athanasius II of Jerusalem (c.\u00a01231\u201347) during the last period of Latin control over Jerusalem. Both city and church were captured by the Khwarezmians in 1244.\nOttoman period.\nThere was certainly a recognisable Nestorian (Church of the East) presence at the Holy Sepulchre from the years 1348 through 1575, as contemporary Franciscan accounts indicate. The Franciscan friars renovated the church in 1555, as it had been neglected despite increased numbers of pilgrims. The Franciscans rebuilt the Aedicule, extending the structure to create an antechamber. A marble shrine commissioned by Friar Boniface of Ragusa was placed to envelop the remains of Christ's tomb, probably to prevent pilgrims from touching the original rock or taking small pieces as souvenirs. A marble slab was placed over the limestone burial bed where Jesus's body is believed to have lain.\nAfter the renovation of 1555, control of the church oscillated between the Franciscans and the Orthodox, depending on which community could obtain a favourable \"firman\" from the \"Sublime Porte\" at a particular time, often through outright bribery. Violent clashes were not uncommon. There was no agreement about this question, although it was discussed at the negotiations to the Treaty of Karlowitz in 1699. During the Holy Week of 1757, Orthodox Christians reportedly took over some of the Franciscan-controlled church. This may have been the cause of the sultan's \"firman\" (decree) later developed into the Status Quo.\nA fire severely damaged again in 1808, causing the dome of the rotunda to collapse and smashing the Aedicule's exterior decoration. The rotunda and the Aedicule's exterior were rebuilt in 1809\u201310 by architect Nikolaos Ch. Komnenos of Mytilene in the contemporary Ottoman Baroque style. The interior of the antechamber, now known as the , was partly rebuilt to a square ground plan in place of the previously semicircular western end.\nAnother decree in 1853 from the sultan solidified the existing territorial division among the communities and solidified the Status Quo for arrangements to \"remain in their present state\", requiring consensus to make even minor changes.\nThe dome was restored by Catholics, Greeks, and Turks in 1868, being made of iron ever since.\nBritish Mandate period.\nBy the time of the British Mandate for Palestine following the end of World War I, the cladding of red limestone applied to the Aedicule by Komnenos had deteriorated badly and was detaching from the underlying structure; from 1947 until restoration work in 2016\u201317, it was held in place with an exterior scaffolding of iron girders installed by the British authorities.\nAfter the care of the British Empire, the Church of England had an important role in the appropriation of the Holy Sepulcher, such as funds for the maintenance of external infrastructures, and the abolition of territorial claims near the Temple of the Holy Sepulcher, the Protestant Church allowed to carry out the elimination of taxes from the Holy Sepulcher, currently the Anglican and Lutheran dioceses of Jerusalem are allowed to attend Armenian cults.\nJordanian and Israeli periods.\nIn 1948, Jerusalem was divided between Israel and Jordan and where the church was located, in the Old City, were made part of Jordan. In 1967, Israeli forces captured East Jerusalem in the Six Day War, and that area has remained under Israeli control ever since. Under Israeli rule, legal arrangements relating to the churches of East Jerusalem were maintained in coordination with the Jordanian government. The dome at the Church of the Holy Sepulchre was restored again in 1994\u201397 as part of extensive modern renovations that have been ongoing since 1959. During the 1970\u201378 restoration works and excavations inside the building, and under the nearby Muristan bazaar, it was found that the area was originally a quarry, from which white \"meleke\" limestone was struck.\nChapel of St. Vartan.\nEast of the Chapel of Saint Helena, the excavators discovered a void containing a second-century drawing of a Roman pilgrim ship, two low walls supporting the platform of Hadrian's second-century temple, and a higher fourth-century wall built to support Constantine's basilica. After the excavations of the early 1970s, the Armenian authorities converted this archaeological space into the Chapel of Saint Vartan, and created an artificial walkway over the quarry on the north of the chapel, so that the new chapel could be accessed (by permission) from the Chapel of Saint Helena.\nAedicule restoration.\nAfter seven decades of being held together by steel girders, the Israel Antiquities Authority (IAA) declared the visibly deteriorating Aedicule structure unsafe. A restoration of the Aedicule was agreed upon and executed from May 2016 to March 2017. Much of the $4 million project was funded by the World Monuments Fund, as well as $1.3 million from Mica Erteg\u00fcn and a significant sum from King Abdullah II of Jordan. The existence of the original limestone cave walls within the Aedicule was confirmed, and a window was created to view this from the inside. The presence of moisture led to the discovery of an underground shaft resembling an escape tunnel carved into the bedrock, seeming to lead from the tomb. For the first time since at least 1555, on 26 October 2016, marble cladding that protects the supposed burial bed of Jesus was removed. Members of the National Technical University of Athens were present. Initially, only a layer of debris was visible. This was cleared in the next day, and a partially broken marble slab with a Crusader-style cross carved was revealed. By the night of 28 October, the original limestone burial bed was shown to be intact. The tomb was resealed shortly thereafter. Mortar from just above the burial bed was later dated to the mid-fourth century.\n2020 pandemic.\nOn 25 March 2020, Israeli health officials ordered the site closed to the public due to the COVID-19 pandemic. According to the keeper of the keys, it was the first such closure since 1349, during the Black Death. Clerics continued regular prayers inside the building, and it reopened to visitors two months later, on 24 May.\nCrusader altar slab discovered (2022).\nDuring church renovations in 2022, a stone slab covered in modern graffiti was moved from a wall, revealing Cosmatesque-style decoration on one face. According to an IAA archaeologist, the decoration was once inlaid with pieces of glass and fine marble; it indicates that the relic was the front of the church's high altar from the Crusader era (c.\u00a01149), which was later used by the Greek Orthodox until being damaged in the 1808 fire.\nDescription.\nParvis (courtyard).\n facing the entrance to the church is known as the parvis. Two streets open into the parvis: (west) and (east). Around the parvis are a few smaller structures.\nSouth of the parvis, opposite the church:\nOn the eastern side of the parvis, south to north:\nNorth of the parvis, in front of the church fa\u00e7ade or against it:\nA borders the parvis on its west side. They originally formed the baptistery complex of the Constantinian church. The southernmost chapel was the vestibule, the middle chapel the baptistery, and the north chapel the chamber in which the patriarch chrismated the newly baptized before leading them into the rotunda north of this complex. Now they are dedicated as (from south to north)\nBell tower.\nThe 12th-century Crusader is just south of the Rotunda, to the left of the entrance. Its upper level was lost in a 1545 collapse. In 1719, another two storeys were lost.\nFa\u00e7ade and entrance.\nThe wooden doors that compose the main entrance are the original, highly carved arched doors. Today, only the left-hand entrance is currently accessible, as the right doorway has long since been bricked up. The entrance to the church leads to the south transept, through the crusader fa\u00e7ade in the parvis of a larger courtyard. This is found past a group of streets winding through the outer Via Dolorosa by way of a souq in the Muristan. This narrow way of access to such a large structure has proven to be hazardous at times. For example, when a fire broke out in 1840, dozens of pilgrims were trampled to death.\nAccording to their own family lore, the Muslim Nuseibeh family has been responsible for opening the door as an impartial party to the church's denominations already since the seventh century. However, they themselves admit that the documents held by various Christian denominations only mention their role since the 12th century, in the time of Saladin, which is the date more generally accepted. After retaking Jerusalem from the Crusaders in 1187, Saladin entrusted the Joudeh family with the key to the church, which is made of iron and long; the Nuseibehs either became or remained its doorkeepers.\nThe 'immovable ladder' stands beneath a window on the fa\u00e7ade.\nCalvary (Golgotha).\nJust inside the church entrance is a stairway leading up to Calvary (Golgotha), traditionally regarded as the site of Jesus's crucifixion and the most lavishly decorated part of the church. The exit is via another stairway opposite the first, leading down to the ambulatory. Golgotha and its chapels are just south of the main altar of the catholicon.\nCalvary is split into two chapels: one Greek Orthodox and one Catholic, each with its own altar. On the left (north) side, the Greek Orthodox chapel's altar is placed over the supposed rock of Calvary (the of the Cross), which can be touched through a hole in the floor beneath the altar. The rock can be seen under protective glass on both sides of the altar. The softer surrounding stone was removed when the church was built. The Roman Catholic (Franciscan) Chapel of the Nailing of the Cross (the of the Cross) stretches to the south. \nBetween the Catholic Altar of the Nailing to the Cross and the Orthodox altar is the Catholic Altar of the Stabat Mater, which has a statue of Mary with an 18th-century bust; this middle altar marks the of the Cross.\nOn the ground floor, just underneath the Golgotha chapel, is the . According to tradition, Jesus was crucified over the place where Adam's skull was buried. According to some, the blood of Christ ran down the cross and through the rocks to fill Adam's skull. Through a window at the back of the 11th-century apse, the rock of Calvary can be seen with a crack traditionally held to be caused by the earthquake that followed Jesus's death; some scholars claim it is the result of quarrying against a natural flaw in the rock.\nBehind the Chapel of Adam is the (Treasury of the Greek Patriarch). Some of its relics, such as a 12th-century crystal mitre, were transferred to the Greek Orthodox Patriarchate Museum (the Patriarchal Museum) on .\nStone of Anointing.\nJust inside the entrance to the church is the (also Stone of the Anointing or Stone of Unction), which tradition holds to be where Jesus's body was prepared for burial by Joseph of Arimathea, though this tradition is only attested since the crusader era (notably by the Italian Dominican pilgrim Riccoldo da Monte di Croce in 1288), and the present stone was only added in the 1810 reconstruction.\nThe wall behind the stone is defined by its striking blue balconies and -bearing red banners (depicting the insignia of the Brotherhood of the Holy Sepulchre), and is decorated with lamps. along the wall depicts the anointing of Jesus's body, preceded on the right by the Descent from the Cross, and succeeded on the left by the Burial of Jesus.\nThe wall was a temporary addition to support the arch above it, which had been weakened after the damage in the 1808 fire; it blocks the view of the rotunda, separates the entrance from the catholicon, sits on top of four of the now empty and desecrated Crusader graves and is no longer structurally necessary. Opinions differ as to whether it is to be seen as the 13th Station of the Cross, which others identify as the lowering of Jesus from the cross and located between the 11th and 12th stations on Calvary.\nThe lamps that hang over the Stone of Unction, adorned with cross-bearing chain links, are contributed by Armenians, Copts, Greeks and Latins.\nImmediately inside and to the left of the entrance is (formerly a divan) that has traditionally been used by the church's Muslim doorkeepers, along with some Christian clergy, as well as electrical wiring. To the right of the entrance is a wall along the ambulatory containing the staircase leading to Golgotha. Further along the same wall is the entrance to the Chapel of Adam.\nRotunda and Aedicule.\nThe is the building of the larger dome located on the far west side. In the centre of the rotunda is a small chapel called the in English, from the Latin , in reference to a small shrine. The Aedicule has two rooms: the first holds a relic called the Angel's Stone, which is believed to be a fragment of the large stone that sealed the tomb; the second, smaller room contains the tomb of Jesus. Possibly to prevent pilgrims from removing bits of the original rock as souvenirs, by 1555, a surface of marble cladding was placed on the tomb to prevent further damage to the tomb. In October 2016, the top slab was pulled back to reveal an older, partially broken marble slab with a Crusader-style cross carved in it. Beneath it, the limestone burial bed was revealed to be intact.\nUnder the Status Quo, the Eastern Orthodox, Roman Catholic, and Armenian Apostolic Churches all have rights to the interior of the tomb, and all three communities celebrate the Divine Liturgy or Holy Mass there daily. It is also used for other ceremonies on special occasions, such as the Holy Saturday ceremony of the Holy Fire led by the Greek Orthodox patriarch (with the participation of the Coptic and Armenian patriarchs). To its rear, in the , constructed of iron latticework, lies the altar used by the Coptic Orthodox. Historically, the Georgians also retained the key to the Aedicule.\nTo the right of the sepulchre on the northwestern edge of the rotunda is the Chapel of the Apparition, which is reserved for Roman Catholic use.\nThough not within the Church of the Holy Sepulchre compound, directly adjacent to it is the Church of the Redeemer, marking a Lutheran presence at the site.\nCatholicon.\nIn the central nave of the Crusader-era church, just east of the larger rotunda, is the Crusader structure housing the main altar of the Church, today the Greek Orthodox \"catholicon\". Its dome is in diameter, and is set directly over the centre of the transept crossing of the choir where the \"compas\" is situated, an omphalos (\"navel\") stone once thought to be the center of the world and still venerated as such by Orthodox Christians (associated with the site of the Crucifixion and the Resurrection).\nSince 1996 this dome is topped by the monumental Golgotha Crucifix, which the Greek Patriarch Diodoros I of Jerusalem consecrated. It was at the initiative of Israeli professor Gustav K\u00fchnel to erect a new crucifix at the church that would not only be worthy of the singularity of the site, but that would also become a symbol of the efforts of unity in the community of Christian faith.\nThe catholicon's iconostasis demarcates the Orthodox sanctuary behind it, to its east.\nThe iconostasis is flanked to the front by two episcopal thrones: the southern seat (cathedra) is the patriarchal throne of the Greek Orthodox patriarch of Jerusalem, and the northern seat is for an archbishop or bishop. (There is also a popular claim that both are patriarchal thrones, with the northern one being for the patriarch of Antioch \u2013 which has been described as a misstatement, however.)\nArmenian monastery south of the Aedicule.\nSouth of the Aedicule is the \"Place of the Three Marys\", marked by a stone canopy (the ) and a large modern . From here one can enter the Armenian monastery, which stretches over the ground and first upper floor of the church's southeastern part.\nSyriac Chapel with Tomb of Joseph of Arimathea.\nWest of the Aedicule, to the rear of the Rotunda, is the with the Tomb of Joseph of Arimathea, located in a Constantinian apse and containing an opening to an ancient Jewish rock-cut tomb. This chapel is where the Syriac Orthodox celebrate their Liturgy on Sundays.\nThe Syriac Orthodox Chapel of Saint Joseph of Arimathea and Saint Nicodemus. On Sundays and feast days it is furnished for the celebration of Mass. It is accessed from the Rotunda, by a door west of the Aedicule.\nFirst-century tomb.\nOn the far side of the chapel is the low entrance to an almost complete first-century Jewish tomb, initially holding six \"kokh\"-type funeral shafts radiating from a central chamber, two of which are still exposed. Although this space was discovered relatively recently and contains no identifying marks, some believe that Joseph of Arimathea and Nicodemus were buried here. Since Jews always buried their dead outside the city, the presence of this tomb seems to prove that the Holy Sepulchre site was outside the city walls at the time of the crucifixion.\nArches of the Virgin.\nThe are seven arches (an arcade) at the northern end of the north transept, which is to the catholicon's north. \nDisputed by the Orthodox and the Latin, the area is used to store ladders. \nOver the years the Greek-Orthodox patriarchate placed several icons along the arcade. Dating mostly to the 19th century and designed in Orthodox Post-Byzantine style, they were restored in 2021.\nPrison of Christ.\nIn the northeast side of the complex, there is the , alleged to be where Jesus was held. The Greek Orthodox are showing pilgrims yet another place where Jesus was allegedly held, the similarly named Prison of Christ in their , located near the Church of Ecce Homo, between the Second and Third Stations of the Via Dolorosa. The Armenians regard a recess in the Monastery of the Flagellation at the Second Station of the Via Dolorosa as the Prison of Christ. A cistern among the ruins beneath the Church of St. Peter in Gallicantu on Mount Zion is also alleged to have been the Prison of Christ. To reconcile the traditions, some allege that Jesus was held in the Mount Zion cell in connection with his trial by the Jewish high priest, at the Praetorium in connection with his trial by the Roman governor Pilate, and near the Golgotha before crucifixion.\nAmbulatory.\nThe chapels in the ambulatory are, from north to south: the Greek (named after Longinus), the Armenian , the entrance to the Chapel of Saint Helena, and the Greek .\nStatus Quo.\nOttoman decrees.\nAn Ottoman decree of 1757 helped establish a \"status quo\" upholding the state of affairs for various Holy Land sites.\nThe \"status quo\" was upheld in Sultan Abd\u00fclmecid\u00a0I's \"firman\" (decree) of 1852/53, which pinned down the now-permanent statutes of property and the regulations concerning the roles of the different denominations and other custodians.\nThe primary custodians are the Roman Catholic, Greek Orthodox and Armenian Apostolic churches. The Greek Orthodox act through the Greek Orthodox Patriarchate as well as through the Brotherhood of the Holy Sepulchre. Roman Catholics act through the Franciscan Custody of the Holy Land. In the 19th century, the Coptic Orthodox, the Ethiopian Orthodox and the Syriac Orthodox also acquired lesser responsibilities, which include shrines and other structures in and around the building.\nNone of these controls the main entrance. In 1192, Saladin assigned door-keeping responsibilities to the Muslim Nusaybah family. The wooden doors that compose the main entrance are the original, highly carved doors. The Joudeh al-Goudia (al-Ghodayya) family were entrusted as custodian to the keys of the Holy Sepulchre by Saladin in 1187. Despite occasional disagreements, religious services take place in the Church with regularity and coexistence is generally peaceful. An example of concord between the Church custodians is the full restoration of the Aedicule from 2016 to 2017.\nInterdenominational issues.\nThe establishment of the modern Status Quo in 1853 did not halt controversy and occasional violence. \nIn 1902, 18 friars were hospitalized and some monks were jailed after the Franciscans and Greeks disagreed over who could clean the lowest step of the Chapel of the Franks. In the aftermath, the Greek patriarch, Franciscan custos, Ottoman governor and French consul general signed a convention that both denominations could sweep it.\nOn a hot summer day in 2002, a Coptic monk moved his chair from its agreed spot into the shade. This was interpreted as a hostile move by the Ethiopians and eleven were hospitalized after the resulting fight. In another incident in 2004, during Orthodox celebrations of the Exaltation of the Holy Cross, a door to the Franciscan chapel was left open. This was taken as a sign of disrespect by the Orthodox and a fistfight broke out. Some people were arrested, but no one was seriously injured.\nOn Palm Sunday, in April 2008, a brawl broke out when a Greek monk was ejected from the building by a rival faction. Police were called to the scene but were also attacked by the enraged brawlers. On Sunday, 9 November 2008, a clash erupted between Armenian and Greek monks during celebrations for the Feast of the Cross.\nIssues with Israeli authorities.\nTax and land disputes.\nIn February 2018, the church was closed following a tax dispute over 152 million euros of uncollected taxes on church properties. The city hall stressed that the Church of the Holy Sepulchre and all other churches are exempt from the taxes, with the changes only affecting establishments like \"hotels, halls and businesses\" owned by the churches. \nThere was a lock-in protest against an Israeli legislative proposal which would expropriate church lands that had been sold to private companies since 2010, a measure which church leaders assert constitutes a serious violation of their property rights and the Status Quo. In a joint official statement the church authorities protested what they considered to be the peak of a systematic campaign in:\nThe 2018 taxation affair does not cover any church buildings or religious related facilities (because they are exempt by law), but commercial facilities such as the Notre Dame Hotel which was not paying the municipal property tax, and any land which is owned and used as a commercial land. The church holds the rights to land where private homes have been constructed, and some of the disagreement had been raised after the Knesset had proposed a bill that will make it harder for a private company not to extend a lease for land used by homeowners. The church leaders have said that such a bill will make it harder for them to sell church-owned lands. According to \"The Jerusalem Post\":\nLand sale to Israeli settlers.\nIn 2017, NPR reported that the Greek Orthodox Church owns many properties across Jerusalem, Israel and the West Bank. It owns some 30% of the land in the Old City. But, due to property sales, these properties are diminishing every year. The decision to sell is made by Greek leaders, even though most local followers of the church are Arab Palestinians. The Palestinian Christians have raised concerns about selling these properties to Israeli settler-affiliated organizations.\nIn June 2019, a number of Christian denominations in Jerusalem raised their voice against the Supreme Court's decision to uphold the sale of three properties by the Greek Orthodox Patriarchate to Ateret Cohanim \u2013 an organization that seeks to increase the number of Jews living in the Old City and East Jerusalem. The church leaders warned that if the organization gets to control the sites, Christians could lose access to the Church of the Holy Sepulchre. In June 2022, the Supreme Court upheld the sale and ended the legal battle.\nConnection to Roman temple.\nThe site of the church had been a temple to Jupiter or Venus built by Hadrian before Constantine's edifice was built. Hadrian's temple had been located there because it was the junction of the main north\u2013south road with one of the two main east\u2013west roads and directly adjacent to the forum (now the location of the Muristan, which is smaller than the former forum). The forum itself had been placed, as is traditional in Roman towns, at the junction of the main north\u2013south road with the other main east\u2013west road (which is now El-Bazar/David Street). The temple and forum together took up the entire space between the two main east\u2013west roads (a few above-ground remains of the east end of the temple precinct still survive in the Alexander Nevsky Church complex of the \"Russian Mission in Exile\").\nFrom the archaeological excavations in the 1970s, it is clear that construction took over most of the site of the earlier temple enclosure and that the \"Triportico\" and \"Rotunda\" roughly overlapped with the temple building itself; the excavations indicate that the temple extended at least as far back as the Aedicule, and the temple enclosure would have reached back slightly further. Virgilio Canio Corbo, a Franciscan priest and archaeologist, who was present at the excavations, estimated from the archaeological evidence that the western retaining wall of the temple itself would have passed extremely close to the east side of the supposed tomb; if the wall had been any further west any tomb would have been crushed under the weight of the wall (which would be immediately above it) if it had not already been destroyed when foundations for the wall were made.\nOther archaeologists have criticized Corbo's reconstructions. Dan Bahat, the former city archaeologist of Jerusalem, regards them as unsatisfactory, as there is no known temple of Aphrodite (Venus) matching Corbo's design, and no archaeological evidence for Corbo's suggestion that the temple building was on a platform raised high enough to avoid including anything sited where the Aedicule is now; indeed Bahat notes that many temples to Aphrodite have a rotunda-like design, and argues that there is no archaeological reason to assume that the present rotunda was not based on a rotunda in the temple previously on the site.\nLocation.\nThe New Testament describes Jesus's tomb as being outside the city wall, as was normal for burials across the ancient world, which were regarded as unclean. Today, the site of the Church is within the current walls of the old city of Jerusalem. It has been well documented by archaeologists that in the time of Jesus, the walled city was smaller and the wall then was to the east of the current site of the Church. In other words, the city had been much narrower in Jesus's time, with the site then having been outside the walls; since Herod Agrippa (41\u201344) is recorded by history as extending the city to the north (beyond the present northern walls), the required repositioning of the western wall is traditionally attributed to him as well.\nThe area immediately to the south and east of the sepulchre was a quarry and outside the city during the early first century as excavations under the Lutheran Church of the Redeemer across the street demonstrated.\nThe church is a part of the UNESCO World Heritage Site Old City of Jerusalem.\nThe Christian Quarter and the (also Christian) Armenian Quarter of the Old City of Jerusalem are both located in the northwestern and western part of the Old City, due to the fact that the Holy Sepulchre is located close to the northwestern corner of the walled city. The adjacent neighbourhood within the Christian Quarter is called the Muristan, a term derived from the Persian word for hospital \u2013 Christian pilgrim hospices have been maintained in this area near the Holy Sepulchre since at least the time of Charlemagne.\nInfluence.\nFrom the ninth century onward, the construction of churches inspired by the Anastasis was extended across Europe. One example is Santo Stefano in Bologna, Italy, an agglomeration of seven churches recreating shrines of Jerusalem.\nSeveral churches and monasteries in Europe, for instance, in Germany and Russia, and at least one church in the United States have been wholly or partially modelled on the Church of the Resurrection, some even reproducing other holy places for the benefit of pilgrims who could not travel to the Holy Land. They include the (\"Holy Tomb\") of G\u00f6rlitz, constructed between 1481 and 1504, the New Jerusalem Monastery in Moscow Oblast, constructed by Patriarch Nikon between 1656 and 1666, and Mount St. Sepulchre Franciscan Monastery built by the Franciscans in Washington, DC in 1898.\nAuthor Andrew Holt writes that the church is the most important in all Christendom.\nExternal links.\nCustodians\nVirtual tours"}
{"id": "7811", "revid": "34892992", "url": "https://en.wikipedia.org/wiki?curid=7811", "title": "Cernunnos", "text": "Cernunnos is a Celtic god whose name is only clearly attested once, on the 1st-century CE Pillar of the Boatmen from Paris, where it is associated with an image of an aged, antlered figure with torcs around his horns.\nThrough the Pillar of the Boatmen, the name \"Cernunnos\" has been used to identify the members of an iconographic cluster, consisting of depictions of an antlered god (often aged and with crossed legs) associated with torcs, ram-horned (or ram-headed) serpents, symbols of fertility, and wild beasts (especially deer). The use of the name this way is common, though not uncontroversial. As many as 25 depictions of the Cernunnos-type have been identified. Though this iconographic group is best attested in north-eastern Gaul, depictions of the god have been identified as far off as Italy (Val Camonica) and Denmark (Gundestrup). \nCernunnos has been variously interpreted as a god of fertility, of the underworld, and of bi-directionality. His cult (attested as early as the 4th century BCE) seems to have been largely unaffected by the Roman conquest of Gaul, during which he remained unassimilated to the Roman pantheon. Cernunnos has been tentatively linked with Conall Cernach, a hero of medieval Irish mythology, and some later depictions of cross-legged and horned figures in medieval art.\nName.\nPillar of the Boatmen.\nThe Pillar of the Boatmen is a Gallo-Roman carved pillar discovered in 1711 under the choir of Notre-Dame de Paris. It is a religious monument, with depictions of Roman gods (Jupiter, Vulcan, and Castor and Pollux) alongside native Gaulish deities (such as Esus and Smertrios), dedicated by a corporation of boatmen from the city of Lutetia (Roman Paris). The dedication dates it to the reign of Tiberius (14-37 CE). Legends below the images identify the Roman and Gaulish deities by name. In fact, this is the only monument on which Celtic deities are identified by name with captions.\nOn one block from the pillar, a frowning, bearded figure is depicted from the shoulder up. His face is human, but his upper head is animal-like: hairless and bulging. Atop his head is a pair of bifid deer's antlers, with two short, pointed extrusions (perhaps ears or bull's horns) between them. A torc hangs on each of his antlers. The lower half of the block is lost, but given its original height, the figure could not have been standing. Therefore (in line with other figures identified as Cernunnos) the panel is often believed to have originally shown him cross-legged.\nAbove the antlered figure is a one-word legend. When information about the pillar was published in 1711, this legend was reported as \"Cernunnos\". However, the block is now badly damaged. Many of the letters are only partially visible; the letter \"C\" is entirely gone. Joshua Whatmough has gone as far as to say that in its present state \"only 'nn' is certain\". The reading from 1711 has sometimes been mistrusted. Joseph Vendryes and Whatmough argue (following the Dacia inscription) that it read \"Cernennos\". was sceptical about the existence of the final \"s\".\nPossible other attestations.\nA capital found in Aumes, France is inscribed with a short Gaulish text in Greek letters. Michel Lejeune has interpreted this inscription as a dedication to a god (translit. ; in English, \"Carnonos\"), whom he tentatively connects with the god Cernunnos. However, both Lejeune's reading and his interpretation of this inscription have been contested. Whatmough and D. Ellis Evans prefer the reading (translit. ); and Emmanuel Dupraz has argued that the inscription states that an object (translit. ) is being offered, rather than giving the name of a god.\nA wax tablet from Dacia records a decree of 167 CE dissolving one (\"collegium of Jupiter Cernenus\"), a funerary association. David Fickett-Wilbar identifies this as a reference to Cernunnos, though he comments that it \"tells us nothing about the deity other than his name\". Theodor Mommsen suggested the byname derived from the name of nearby Korna, a hypothesis that has been followed my Michael Altjohann. Le Roux is also sceptical that it is a reference to Cernunnos, as she thinks the \"interpretatio\" of Cernunnos as the Roman god Jupiter is unlikely.\nA bronze tabula ansata from Steinsel, Luxembourg, dating between the late 2nd and early 3rd century CE, is dedicated to one (\"god Cerunincus\"). Though close in name to Cernunnos, the editors of \"L'Ann\u00e9e \u00e9pigraphique\" argue that the form of the name entails that it must be another (probably Treverian) god.\nEtymology.\nThe earliest etymology, proposed by Alfred Holder, connected Cernunnos's name with a Celtic word for horn, a reflex of proto-Indo-European * (\"horn, hoof\"). Hence, Holder analysed the name as \"The Horned God\". This etymology has the advantage of a close link with Cernunnos's iconography. However, Ernst Windisch and Leo Weisgerber pointed out that ablaut form of the proto-Indo-European root in Celtic is rather than . \nWeisgerber proposed that the theonym derived from proto-Celtic (\"angle, excrescence\"), a reflex of the same proto-Indo-European root. Le Roux concurred with Weisgerber; she associated proto-Celtic with the meaning \"top of the head\", and argued that Cernunnos's name should be interpreted as \"the one who has the top of his head like a deer\". Vendryes suggested that the name was cognate with the Old Irish word (\"hero\").\nIconography.\nA large number of images of an antlered figure, similar to that depicted on the Pillar of the Boatmen, have been found. These depict a male figure, often aged, with crossed legs, with antlers atop his head, who is associated with ram-horned (or ram-headed) serpents, torcs, symbols of fertility, and wild beasts (especially deer). It is conventional to apply to the name of \"Cernunnos\" to images which fit within this cluster of attributes. At least twenty-five images have been connected with Cernunnos in this way. Some, such as William Sayers and T. G. E. Powell, have questioned whether the name given on the Pillar (which is so rare in epigraphy) is appropriate to apply to these images. Pierre Lambrechts and Michael Altjohann have even argued that no such well-defined cluster of attributes exists in the archaeological record.\nDistribution and history.\nThe majority of the images identified as of Cernunnos have been found in Gaul, clustered around Paris and Reims. A rock drawing in Valcamonica (Lombardy, Italy) and the figure on Plate A of the Gundestrup cauldron (found in Himmerland, Denmark) are conspicuous geographic exceptions. Engraved onto a rock at the prehistoric site of Val Camonica is a tall figure with antlers atop is head, arms in orans position, and a torc around his right arm. Besides him, on his right, are a ram-horned serpent and a smaller man (ithyphallic, arms in orans position). The detailed scene on Plate A of the Gundestrup cauldron has Cernunnos cross-legged, wielding a torc in one hand and a ram-horned serpent in the other. Around him are many animals: two bulls, a stag, a dolphin with a rider, griffins, and a hyena. The provenance and date of the Gundestrup cauldron have been the subject of much debate. Cernunnos has been tentatively connected with images over a large geographical range, including Britain, Spain, Austria, Slovenia, and Romania.\nThe earliest datable representations of Cernunnos in Gaul date, like the Pillar of the Boatmen, to the reign of Tiberius (i.e., 14-37 CE); the latest to the 3rd century CE. The archaeological evidence for images of deities in Gaul is scant before the Roman conquest. The God of Bouray, a bronze statuette probably produced not long before the Roman conquest, depicts a Gaulish god with crossed legs and hooves. The relationship of this god with Cernunnos is uncertain.\nOutside of Gaul, much earlier representations of Cernunnos are known. The drawing from Valcamonica dates to 4th century BCE. Jos\u00e9 Maria Bl\u00e1zquez has argued that a painted vase, dating to the 2nd century BCE, from the Celtiberian site of Numantia, gives another early representation of Cernunnos. The Gundestrup cauldron, of either Thracian or Celtic work, has been assigned to dates within a large range (from 200 BCE to 300 CE). \nAfter Christianisation, images of Cernunnos were the subject of iconoclastic destruction. A statue of Cernunnos from Verteuil (Charente, France) was beheaded and the horns of Cernunnos on the Reims altar seem to have been purposefully chipped off. \nSome scholars (such as Duval and Bober) have suggested that Cernunnos's distinctive iconography persisted into the medieval period. Cernunnos has been seen on Christian monuments from Ireland, such as the north cross at Clonmacnoise, the market cross at Kells, and a stele at Carndonagh. The figure identified as Cernunnos on the 9th-century Clonmacnoise north cross appears to have horns and crossed legs; Fickett-Wilbar argues that these are misidentified ornamental motifs. On the Continent, Cernunnos has been seen in the Stuttgart Psalter and on a capital of Parma Cathedral. A leaf from the Stuttgart Psalter depicts the Descent into Limbo, with a devil figure (perhaps Hades) whom Bober identifies as of the Cernunnos-type, \"complete with cross-legged posture, antlers, and even a ram-headed serpent\", though J. R. M. Galpern identifies the features on the devil's head as wings, and connects them with motifs from Late Antique and Roman funerary art.\nAttributes and associations.\nThe cross-legged pose of Cernunnos has occasioned much comment. Elaborate diffusionist theories have been proposed to explain the origin of this particular motif. A popular theory proposes that the pose represents the transmission of a Buddhist motif (the lotus pose) from India via Greco-Egyptian work. Against a diffusionist hypothesis, Robert Mowat argued that this pose reflected the normal sitting position of the Gauls; he cited the testimony of Strabo and Diodorus that the Gauls sat on the floor for meals. In religious iconography, the position does not seem to have been exclusively associated with Cernunnos. Statues from the pre-Roman Gaulish sanctuary of Roquepertuse assume the same pose; though clearly of religious significance, they are not representations of Cernunnos. Representations of Cernunnos standing are known (such as the early example from Val Camonica).\nCernunnos is often depicted with torcs adorning his body. Most commonly he grasps one, and wears another around his neck. Sometimes he holds another on his chest. The torc is a ubiquitous feature of Celtic art and garb. They seem to have been a symbol of religious significance in Celtic art and, after the Roman conquest, perhaps a symbol of native identity.\nThe ram-horned (or ram-headed) serpent is a hybrid beast peculiar to the Celts. The creature, which is associated with Cernunnos early as Val Camonica, appears to have had a significance independent of Cernunnos. In Gaul, ram-horned serpents are depicted alone or accompanying Mars or Mercury. Ram-horned serpents also feature on two other plates of the Gundestrup cauldron (C and E). Cernunnos is also sometimes accompanied by serpents without the attributes of a ram, as on the Vend\u0153uvres relief. The ram-horned serpent has been suggested to have a chthonic significance.\nSome scholars, such as Miranda Green, have connected Cernunnos with the Lord of the Animals motif through such depictions as the Gundestrup cauldron, where Cernunnos is placed centrally around a number of animals. The closest parallel to the Gundestrup scene is given on the Lyon cup, where Cernunnos is surrounded by a deer, a hound, and a (hornless) snake. \nOn various depictions, Cernunnos is associated with other deities. The significance of these associations is unclear. On three depictions, Cernunnos is paired with Mercury and Apollo; on the Lyon cup, he is paired with Mercury alone. Cernunnos is also depicted twice with Abundantia, Roman god of prosperity, and twice with Hercules. Three images of Cernunnos (among them, the Condat tricephal and \u00c9tang-sur-Arroux statuette) give Cernunnos three heads or faces. Bober argued that these images represent the syncretisation of Cernunnos with the (poorly understood) tricephalic god of Gaul.\nInterpretation.\nBecause of his persistent association with the natural world (for example, on the Gundestrup cauldron, where he is surrounded by various beasts), some scholars describe Cernunnos as the lord of animals or wild things. Miranda Green describes him as a \"peaceful god of nature and fruitfulness\". \nCernunnos is also associated with fertility and fecundity. Blazquez points out that the stag is a symbol of fertility across the Mediterranean. The association of Cernunnos with fertility is emphasised by other attributes. He is variously provided with a basket of fruit (as on the \u00c9tang-sur-Arroux statuette), a cornucopia (as on the Lyon cup), and a bag of coins (as on the Reims altar).\nIt has been suggested that Cernunnos carried a chthonic significance. Bober's study of the god concluded that Cernunnos was god of the underworld. She analyses the ram-horned serpent as the synthesis of two animals (the snake and the ram) of chthonic significance to the Celts. The rat above Cernunnos on the Reims altar and the association of Cernunnos with Mercury (guide of souls to the underworld) on several representations have also been thought to suggest an association with the underworld.\nFickett-Wilbar, in a recent study, has proposed that Cernunnos was a god of bi-directionality and mediator between opposites.\nCernunnos and \"interpretatio romana\".\nThe process of \"interpretatio romana\", by which the Romans identified and syncretised gods of foreign cults with gods of their own pantheon, is one which Cernunnos seems to have been peculiarly resistant to. He has been compared in this respect with Epona and Sucellus, other Gallo-Roman gods with distinctive iconographies, though unlike them his iconography predates the Roman conquest. Cernunnos is not paired with any Greco-Roman god in epigraphy, with the possible exception of the Dacia inscription. The iconography of Cernunnos occasionally borrows from that of Mercury, and the representation of Cernunnos on the Vend\u0153uvres relief seems to have been influenced by depictions of Jupiter Dolichenus. However, even when paired with Roman deities (as on the Reims altar), Cernunnos's iconography is distinctly Celtic. It has been suggested that this was because there was no clear Roman equivalent to Cernunnos.\nCernunnos does not appear in any ancient sources under his native name. Some passages from ancient authors referring to Celtic gods under Greek or Roman names (per the usual \"interpretatio romana\" or \"graeca\") have been tentatively connected with Cernunnos. Caesar's remark that the Gauls regarded themselves as descendants of Dis Pater (Roman god of the underworld) has occasioned much comment. Though Sucellus is the Gaulish god most commonly identified as behind Dis Pater in this passage, Cernunnos has also been considered as a candidate. Bober has argued that Cernunnos was a \"chthonic-fertility\" god, like Dis Pater, and therefore that this was a natural identification to make. A story about the Roman general Sertorius (reported by Plutarch, among others) describes Sertorius's attempts to take advantage of local Lusitanian religious feeling by declaring a white doe a gift of Artemis (Greek goddess of the hunt) and pretending he could use it for divination. The Lusitanians were Celts, and it has been suggested by David Rankin that the god behind this Lusitanian Artemis was Cernunnos. Rankin has also suggested that Cernunnos and Smertrios lay behind the Greek historian Timaeus's description of a cult of the Dioscuri among the oceanic Celts, though Andreas Hofeneder regards this as unprovable.\nCernunnos and later mythology.\nConall Cernach.\nConall is a hero of the Ulster Cycle of Irish mythology. The companion and foster brother of C\u00fachulainn, he appears in such stories as \"T\u00e1in B\u00f3 C\u00faailnge\", and several tales involving Fra\u00edch (such as \"T\u00e1in B\u00f3 Fra\u00edch\" and \"Fled Bricrenn\"). Conall's byname \"Cernach\" has been linked with Old Irish word (with the meanings of \"excrescence, angle\", \"plate\", and \"victory\"). Through this root, there have been attempts to connect Conall with Cernunnos.\nA brief passage involving Conall in the \"T\u00e1in B\u00f3 Fra\u00edch\" (\"The Cattle Raid on Fra\u00edch\") has been taken by Anne Ross as evidence that Conall bore a connection with Cernunnos. In this episode, Conall assists the protagonist Fra\u00edch in rescuing his wife and son, and reclaiming his cattle. The fort that Conall must penetrate is guarded by a mighty serpent. This fearsome serpent, instead of attacking Conall, darts to Conall's waist and girdles him as a belt. Rather than killing the serpent, Conall allows it to live, and then proceeds to attack and rob the fort of its great treasures the serpent previously protected. Ross explains the serpent's anticlimactic behaviour with reference to the images of Cernunnos with ram-horned serpents curled around him (as on the \u00c9tang-sur-Arroux statuette).\nOther mythologies.\nCernunnos has also been suggested to have survived in other legends. Justin Favrod suggests that a fertility festival (perhaps involving deer costumes), held on the 1 January in some Celtic countries and suppressed by the church after Christianisation, represented a festival to Cernunnos. Gwilherm Berthou equated Cernunnos with the mythical Breton , protector of cattle. R. Lowe Thompson suggested that Herne the Hunter, an antlered ghost of English folklore first attested in Shakespeare, was cognate with Cernunnos.\nNeopaganism and Wicca.\nWithin Neopaganism, specifically the Wiccan tradition, the Horned God is a deity that is believed to be the equal to the Great Goddess and syncretizes various horned or antlered gods from various cultures. The name Cernunnos became associated with the Wiccan Horned God through the adoption of the writings of Margaret Murray, an Egyptologist and folklorist of the early 20th century. Murray, through her Witch-cult hypothesis, believed that the various horned deities found in Europe were expressions of a \"proto-horned god\" and in 1931 published her theory in \"The God of the Witches\". Her work was considered highly controversial at the time, but was adopted by Gerald Gardner in his development of the religious movement of Wicca.\nWithin the Wiccan tradition, the Horned God reflects the seasons of the year in an annual cycle of life, death and rebirth and his imagery is a blend of the Gaulish god Cernunnos, the Greek god Pan, The Green Man motif, and various other horned spirit imagery."}
{"id": "7816", "revid": "24880629", "url": "https://en.wikipedia.org/wiki?curid=7816", "title": "Click consonant", "text": "Click consonants, or clicks, are speech sounds that occur as consonants in many languages of Southern Africa and in three languages of East Africa. Examples familiar to English-speakers are the \"tut-tut\" (British spelling) or \"tsk! tsk!\" (American spelling) used to express disapproval or pity (IPA ), the \"tchick!\" used to spur on a horse (IPA ), and the \"clip-clop!\" sound children make with their tongue to imitate a horse trotting (IPA ). However, these paralinguistic sounds in English are not full click consonants, as they only involve the front of the tongue, without the release of the back of the tongue that is required for clicks to combine with vowels and form syllables.\nAnatomically, clicks are obstruents articulated with two closures (points of contact) in the mouth, one forward and one at the back. The enclosed pocket of air is rarefied by a sucking action of the tongue (in technical terminology, clicks have a lingual ingressive airstream mechanism). The forward closure is then released, producing what may be the loudest consonants in the language, although in some languages such as Hadza and Sandawe, clicks can be more subtle and may even be mistaken for ejectives.\nPhonetics and IPA notation.\nClick consonants occur at six principal places of articulation. The International Phonetic Alphabet (IPA) provides five letters for these places (there is as yet no dedicated symbol for the sixth). \nThe above clicks sound like affricates, in that they involve a lot of friction. The next two families of clicks are more abrupt sounds that do not have this friction.\nTechnically, these IPA letters transcribe only the forward articulation of the click, not the entire consonant. As the \"Handbook\" states, \nThus technically is not a consonant, but only one part of the articulation of a consonant, and one may speak of \"\u01c2-clicks\" to mean any of the various click consonants that share the place of articulation. In practice, however, the simple letter has long been used as an abbreviation for , and in that role it is sometimes seen combined with diacritics for voicing (e.g. for ), nasalization (e.g. for ), etc. These differing transcription conventions may reflect differing theoretical analyses of the nature of click consonants, or attempts to address common misunderstandings of clicks.\nLanguages with clicks.\nSouthern Africa.\nClicks occur in all three Khoisan language families of southern Africa, where they may be the most numerous consonants. To a lesser extent they occur in three neighbouring groups of Bantu languages\u2014which borrowed them, directly or indirectly, from Khoisan. In the southeast, in eastern South Africa, Eswatini, Lesotho, Zimbabwe and southern Mozambique, they were adopted from a Tuu language (or languages) by the languages of the Nguni cluster (especially Zulu, Xhosa and Phuthi, but also to a lesser extent Swazi and Ndebele), and spread from them in a reduced fashion to the Zulu-based pidgin Fanagalo, Sesotho, Tsonga, Ronga, the Mzimba dialect of Tumbuka and more recently to Ndau and urban varieties of Pedi, where the spread of clicks continues. The second point of transfer was near the Caprivi Strip and the Okavango River where, apparently, the Yeyi language borrowed the clicks from a West Kalahari Khoe language; a separate development led to a smaller click inventory in the neighbouring Mbukushu, Kwangali, Gciriku, Kuhane and Fwe languages in Angola, Namibia, Botswana and Zambia. These sounds occur not only in borrowed vocabulary, but have spread to native Bantu words as well, in the case of Nguni at least partially due to a type of word taboo called hlonipha. Some creolised varieties of Afrikaans, such as Oorlams, retain clicks in Khoekhoe words.\nEast Africa.\nThree languages in East Africa use clicks: Sandawe and Hadza of Tanzania, and Dahalo, an endangered South Cushitic language of Kenya that has clicks in only a few dozen words. It is thought the latter may remain from an episode of language shift.\nDamin.\nThe only non-African language known to have clicks as regular speech sounds is Damin, a ritual code once used by speakers of Lardil in Australia. In addition, one consonant in Damin is the egressive equivalent of a click, using the tongue to compress the air in the mouth for an outward (egressive) \"spurt\".\nUse.\nSpread of clicks from loanwords.\nOnce clicks are borrowed into a language as regular speech sounds, they may spread to native words, as has happened due to \"hlonipa\" word-taboo in the Nguni languages. In Gciriku, for example, the European loanword \"tomate\" (tomato) appears as \"cum\u00e1te\" with a click , though it begins with a \"t\" in all neighbouring languages. It has also been argued that click phonemes have been adopted into some languages through the process of \"hlonipha\", women refraining from saying certain words and sounds that were similar to the name of their husband, sometimes replacing local sounds by borrowing clicks from a nearby language.\nMarginal usage of clicks.\nScattered clicks are found in ideophones and mimesis in other languages, such as Kongo , Mijikenda and Hadza (Hadza does not otherwise have labial clicks). Ideophones often use phonemic distinctions not found in normal vocabulary.\nEnglish and many other languages may use bare click releases in interjections, without an accompanying rear release or transition into a vowel, such as the dental \"tsk-tsk\" sound used to express disapproval, or the lateral \"tchick\" used with horses. In a number of languages ranging from the central Mediterranean to Iran, a bare dental click release accompanied by tipping the head upwards signifies \"no\". Libyan Arabic apparently has three such sounds. A voiceless nasal back-released velar click is used throughout Africa for backchanneling. This sound starts off as a typical click, but the action is reversed and it is the rear velar or uvular closure that is released, drawing in air from the throat and nasal passages. \nClicks occasionally turn up elsewhere, as in the special registers twins sometimes develop with each other. In West Africa, clicks have been reported allophonically, and similarly in French and German, faint clicks have been recorded in rapid speech where consonants such as and overlap between words. In Rwanda, the sequence may be pronounced either with an epenthetic vowel, , or with a light bilabial click, \u2014often by the same speaker.\nSpeakers of Gan Chinese from Ningdu county, as well as speakers of Mandarin from Beijing and Jilin and presumably people from other parts of the country, produce flapped nasal clicks in nursery rhymes with varying degrees of competence, in the words for 'goose' and 'duck', both of which begin with in Gan and until recently began with in Mandarin as well. In Gan, the nursery rhyme is,\nwhere the onsets are all pronounced .\nOccasionally other languages are claimed to have click sounds in general vocabulary. This is usually a misnomer for ejective consonants, which are found across much of the world.\nPosition in word.\nFor the most part, the Southern African Khoisan languages only use root-initial clicks. Hadza, Sandawe and several Bantu languages also allow syllable-initial clicks within roots. In no language does a click close a syllable or end a word, but since the languages of the world that happen to have clicks consist mostly of CV syllables and allow at most only a limited set of consonants (such as a nasal or a glottal stop) to close a syllable or end a word, \"most\" consonants share the distribution of clicks in these languages.\nNumber of click-types in languages.\nMost languages of the Khoesan families (Tuu, Kx\u02bca and Khoe) have four click types: } or variants thereof, though a few have three or five, the last supplemented with either bilabial } or retroflex }. Hadza and Sandawe in Tanzania have three, }. Yeyi is the only Bantu language with four, }, while Xhosa and Zulu have three, }, and most other Bantu languages with clicks have fewer.\nTypes of clicks.\nLike other consonants, clicks can be described using four parameters: place of articulation, manner of articulation, phonation (including glottalisation) and airstream mechanism. As noted above, clicks necessarily involve at least two closures, which in some cases operate partially independently: an anterior articulation traditionally represented by the special click symbol in the IPA\u2014and a posterior articulation traditionally transcribed for convenience as oral or nasal, voiced or voiceless, though such features actually apply to the entire consonant. The literature also describes a contrast between velar and uvular rear articulations for some languages.\nIn some languages that have been reported to make this distinction, such as N\u01c1ng, all clicks have a uvular rear closure, and the clicks explicitly described as uvular are in fact cases where the uvular closure is independently audible: contours of a click into a pulmonic or ejective component, in which the click has two release bursts, the forward (click-type) and then the rearward (uvular) component. \"Velar\" clicks in these languages have only a single release burst, that of the forward release, and the release of the rear articulation isn't audible. However, in other languages all clicks are velar, and a few languages, such as Taa, have a true velar\u2013uvular distinction that depends on the place rather than the timing of rear articulation and that is audible in the quality of the vowel.\nRegardless, in most of the literature the stated place of the click is the anterior articulation (called the \"release\" or \"influx),\" whereas the manner is ascribed to the posterior articulation (called the \"accompaniment\" or \"efflux).\" The anterior articulation defines the \"click type\" and is written with the IPA letter for the click (dental , alveolar , etc.), whereas the traditional term 'accompaniment' conflates the categories of manner (nasal, affricated), phonation (voiced, aspirated, breathy voiced, glottalised), as well as any change in the airstream with the release of the posterior articulation (pulmonic, ejective), all of which are transcribed with additional letters or diacritics, as in the \"nasal alveolar click\", or or\u2014to take an extreme example\u2014the \"voiced (uvular) ejective alveolar click\", .\nThe size of click inventories ranges from as few as three (in Sesotho) or four (in Dahalo), to dozens in the Kx\u02bca and Tuu (Northern and Southern Khoisan) languages. Taa, the last vibrant language in the latter family, has 45 to 115 click phonemes, depending on analysis (clusters vs. contours), and over 70% of words in the dictionary of this language begin with a click.\nClicks appear more stop-like (sharp/abrupt) or affricate-like (noisy) depending on their place of articulation: In southern Africa, clicks involving an apical alveolar or laminal postalveolar closure are acoustically abrupt and sharp, like stops, whereas labial, dental and lateral clicks typically have longer and acoustically noisier click types that are superficially more like affricates. In East Africa, however, the alveolar clicks tend to be flapped, whereas the lateral clicks tend to be more sharp.\nTranscription.\nThe five click places of articulation with dedicated symbols in the International Phonetic Alphabet (IPA) are labial , dental , palatal (\"palato-alveolar\") , (post)alveolar (\"retroflex\") and lateral . In most languages, the alveolar and palatal types are abrupt; that is, they are sharp popping sounds with little frication (turbulent airflow). The labial, dental and lateral types, on the other hand, are typically noisy: they are longer, lip- or tooth-sucking sounds with turbulent airflow, and are sometimes called affricates. (This applies to the forward articulation; both may also have either an affricate or non-affricate rear articulation as well.) The apical places, and , are sometimes called \"grave\", because their pitch is dominated by low frequencies; whereas the laminal places, and , are sometimes called \"acute\", because they are dominated by high frequencies. (At least in the N\u01c1ng language and Ju\u01c0\u02bchoan, this is associated with a difference in the placement of the rear articulation: \"grave\" clicks are uvular, whereas \"acute\" clicks are pharyngeal.) Thus the alveolar click sounds something like a cork pulled from a bottle (a low-pitch pop), at least in Xhosa; whereas the dental click is like English \"tsk! tsk!,\" a high-pitched sucking on the incisors. The lateral clicks are pronounced by sucking on the molars of one or both sides. The labial click is different from what many people associate with a kiss: the lips are pressed more-or-less flat together, as they are for a or an , not rounded as they are for a .\nThe most populous languages with clicks, Zulu and Xhosa, use the letters \"c, q, x,\" by themselves and in digraphs, to write click consonants. Most Khoisan languages, on the other hand (with the notable exceptions of Naro and Sandawe), use a more iconic system based on the pipe . (The exclamation point for the \"retroflex\" click was originally a pipe with a subscript dot, along the lines of \"\u1e6d, \u1e0d, \u1e47\" used to transcribe the retroflex consonants of India.) There are also two main conventions for the second letter of the digraph as well: voicing may be written with \"g\" and uvular affrication with \"x\", or voicing with \"d\" and affrication with \"g\" (a convention of Afrikaans). In two orthographies of Ju\u01c0\u02bchoan, for example, voiced is written \"g!\" or \"dq\", and \"!x\" or \"qg\". In languages without , such as Zulu, may be written \"gq\".\nThere are a few less-well-attested articulations. A reported subapical retroflex articulation in Grootfontein !Kung turns out to be alveolar with lateral release, ; Ekoka !Kung has a fricated alveolar click with an s-like release, provisionally transcribed ; and Sandawe has a \"slapped\" alveolar click, provisionally transcribed (in turn, the lateral clicks in Sandawe are more abrupt and less noisy than in southern Africa). However, the Khoisan languages are poorly attested, and it is quite possible that, as they become better described, more click articulations will be found.\nFormerly when a click consonant was transcribed, two symbols were used, one for each articulation, and connected with a tie bar. This is because a click such as was analysed as a voiced uvular rear articulation pronounced simultaneously with the forward ingressive release . The symbols may be written in either order, depending on the analysis: or . However, a tie bar was not often used in practice, and when the manner is tenuis (a simple ), it was often omitted as well. That is, = = = = . Regardless, elements that do not overlap with the forward release are usually written according to their temporal order: Prenasalisation is always written first ( = = ), and the non-lingual part of a contour is always written second ( = = ).\nHowever, it is common to analyse clicks as simplex segments, despite the fact that the front and rear articulations are independent, and to use diacritics to indicate the rear articulation and the accompaniment. At first this tended to be for , based on the belief that the rear articulation was velar; but as it has become clear that the rear articulation is often uvular or even pharyngeal even when there is no velar\u2013uvular contrast, voicing and nasalisation diacritics more in keeping with the IPA have started to appear: for .\nIn practical orthography, the voicing or nasalisation is sometimes given the anterior place of articulation: \"dc\" for and \"m\u0298\" for , for example.\nIn the literature on Damin, the clicks are transcribed by adding to the homorganic nasal: .\nPlaces of articulation.\nPlaces of articulation are often called click \"types, releases,\" or \"influxes,\" though 'release' is also used for the accompaniment/efflux. There are seven or eight known places of articulation, not counting slapped or egressive clicks. These are \"(bi)labial affricated\" , or \"bilabial\"; \"laminal denti-alveolar affricated\" , or \"dental\"; \"apical (post)alveolar plosive\" , or \"alveolar\"; \"laminal palatal plosive\" , or \"palatal\"; \"laminal palatal affricated\" (known only from Ekoka !Kung); \"subapical postalveolar\" , or \"retroflex\" (only known from Central !Kung and possibly Damin); and \"apical (post)alveolar lateral\" , or \"lateral\".\nLanguages illustrating each of these articulations are listed below. Given the poor state of documentation of Khoisan languages, it is quite possible that additional places of articulation will turn up. No language is known to contrast more than five.\nExtra-linguistically, Coatl\u00e1n Zapotec of Mexico uses a linguolabial click, , as mimesis for a pig drinking water, and several languages, such as Wolof, use a velar click , long judged to be physically impossible, for backchanneling and to express approval. An extended dental click with lip pursing or compression (\"sucking-teeth\"), variable in sound and sometimes described as intermediate between and , is found across West Africa, the Caribbean and into the United States.\nThe exact place of the alveolar clicks varies between languages. The lateral, for example, is alveolar in Khoekhoe but postalveolar or even palatal in Sandawe; the central is alveolar in N\u01c0uu but postalveolar in Ju\u01c0\u02bchoan.\nNames found in the literature.\nThe terms for the click types were originally developed by Bleek in 1862. Since then there has been some conflicting variation. However, apart from \"cerebral\" (retroflex), which was found to be an inaccurate label when true retroflex clicks were discovered, Bleek's terms are still considered normative today. Here are the terms used in some of the main references.\nThe dental, lateral and bilabial clicks are rarely confused, but the palatal and alveolar clicks frequently have conflicting names in older literature, and non-standard terminology is fossilized in Unicode. However, since Ladefoged &amp; Traill (1984) clarified the places of articulation, the terms listed under Vosser (2013) in the table above have become standard, apart from such details as whether in a particular language and are alveolar or postalveolar, or whether the rear articulation is velar, uvular or pharyngeal, which again varies between languages (or may even be contrastive within a language).\nManners of articulation.\nClick manners are often called click \"accompaniments\" or \"effluxes\", but both terms have met with objections on theoretical grounds.\nThere is a great variety of click manners, both simplex and complex, the latter variously analysed as consonant clusters or contours. With so few click languages, and so little study of them, it is also unclear to what extent clicks in different languages are equivalent. For example, the of Khoekhoe, of Sandawe and of Hadza may be essentially the same phone; no language distinguishes them, and the differences in transcription may have more to do with the approach of the linguist than with actual differences in the sounds. Such suspected allophones/allographs are listed on a common row in the table below.\nSome Khoisan languages are typologically unusual in allowing mixed voicing in non-click consonant clusters/contours, such as , so it is not surprising that they would allow mixed voicing in clicks as well. This may be an effect of epiglottalised voiced consonants, because voicing is incompatible with epiglottalisation.\nPhonation.\nAs do other consonants, clicks vary in phonation. Oral clicks are attested with four phonations: tenuis, aspirated, voiced and breathy voiced (murmured). Nasal clicks may also vary, with plain voiced, breathy voiced / murmured nasal, aspirated and unaspirated voiceless clicks attested (the last only in Taa). The aspirated nasal clicks are often said to have 'delayed aspiration'; there is nasal airflow throughout the click, which may become voiced between vowels, though the aspiration itself is voiceless. A few languages also have pre-glottalised nasal clicks, which have very brief prenasalisation but have not been phonetically analysed to the extent that other types of clicks have.\nAll languages have nasal clicks, and all but Dahalo and Damin also have oral clicks. All languages but Damin have at least one phonation contrast as well.\nComplex clicks.\nClicks may be pronounced with a third place of articulation, glottal. A glottal stop is made during the hold of the click; the (necessarily voiceless) click is released, and then the glottal hold is released into the vowel. Glottalised clicks are very common, and they are generally nasalised as well. The nasalisation cannot be heard during the click release, as there is no pulmonic airflow, and generally not at all when the click occurs at the beginning of an utterance, but it has the effect of nasalising preceding vowels, to the extent that the glottalised clicks of Sandawe and Hadza are often described as prenasalised when in medial position. Two languages, G\u01c0wi and Yeyi, contrast plain and nasal glottalised clicks, but in languages without such a contrast, the glottalised click is nasal. Miller (2011) analyses the glottalisation as phonation, and so considers these to be simple clicks.\nVarious languages also have prenasalised clicks, which may be analysed as consonant sequences. Sotho, for example, allows a syllabic nasal before its three clicks, as in \"nnqane\" 'the other side' (prenasalised nasal) and \"seqhenqha\" 'hunk'.\nThere is ongoing discussion as to how the distinction between what were historically described as 'velar' and 'uvular' clicks is best described. The 'uvular' clicks are only found in some languages, and have an extended pronunciation that suggests that they are more complex than the simple ('velar') clicks, which are found in all. Nakagawa (1996) describes the extended clicks in G\u01c0wi as consonant clusters, sequences equivalent to English \"st\" or \"pl\", whereas Miller (2011) analyses similar sounds in several languages as click\u2013non-click contours, where a click transitions into a pulmonic or ejective articulation within a single segment, analogous to how English \"ch\" and \"j\" transition from occlusive to fricative but still behave as unitary sounds. With ejective clicks, for example, Miller finds that although the ejective release follows the click release, it is the rear closure of the click that is ejective, not an independently articulated consonant. That is, in a simple click, the release of the rear articulation is not audible, whereas in a contour click, the rear (uvular) articulation is audibly released after the front (click) articulation, resulting in a double release.\nThese contour clicks may be \"linguo-pulmonic\", that is, they may transition from a click (lingual) articulation to a normal pulmonic consonant like (e.g. ); or \"linguo-glottalic\" and transition from lingual to an ejective consonant like (e.g. ): that is, a sequence of ingressive (lingual) release + egressive (pulmonic or glottalic) release. In some cases there is a shift in place of articulation as well, and instead of a uvular release, the uvular click transitions to a velar or epiglottal release (depending on the description, or ). Although homorganic does not contrast with heterorganic in any known language, they are phonetically quite distinct (Miller 2011).\nImplosive clicks, i.e. velar , uvular , and \"de facto\" front-closed palatal are not only possible but easier to produce than modally voiced clicks. However, they are not attested in any language.\nApart from Dahalo, Damin and many of the Bantu languages (Yeyi and Xhosa being exceptions), 'click' languages have glottalized nasal clicks. Contour clicks are restricted to southern Africa, but are very common there: they are found in all members of the Tuu, Kx\u02bca and Khoe families, as well as in the Bantu language Yeyi.\nVariation among languages.\nIn a comparative study of clicks across various languages, using her own field work as well as phonetic descriptions and data by other field researchers, Miller (2011) posits 21 types of clicks that contrast in manner or airstream. The homorganic and heterorganic affricated ejective clicks do not contrast in any known language, but are judged dissimilar enough to keep separate. Miller's conclusions differ from those of the primary researcher of a language; see the individual languages for details.\nEach language below is illustrated with \ua7b0 as a placeholder for the different click types. Under each language are the orthography (in italics, with old forms in parentheses), the researchers' transcription (in ), or allophonic variation (in [brackets]). Some languages also have labialised or prenasalised clicks in addition to those listed below.\nYeyi also has prenasalised . The original researchers believe that and are allophones.\nA DoBeS (2008) study of the Western \u01c3Xoo dialect of Taa found several new manners: creaky voiced (the voiced equivalent of glottalised oral), breathy-voiced nasal, prenasalised glottalised (the voiced equivalent of glottalised) and a (pre)voiced ejective. These extra voiced clicks reflect Western \u01c3Xoo morphology, where many nouns form their plural by voicing their initial consonant. DoBeS analyses most Taa clicks as clusters, leaving nine basic manners (marked with asterisks in the table). This comes close to Miller's distinction between simple and contour clicks, shaded light and medium grey in the table.\nPhonotactics.\nLanguages of the southern African Khoisan families only permit clicks at the beginning of a word root. However, they also restrict other classes of consonant, such as ejectives and affricates, to root-initial position. The Bantu languages, Hadza and Sandawe allow clicks within roots.\nIn some languages, all click consonants within known roots are the same phoneme, as in Hadza \"cikiringcingca\" 'pinkie finger', which has three tenuis dental clicks. Other languages are known to have the occasional root with different clicks, as in Xhosa \"ugqwanxa\" 'black ironwood', which has a slack-voiced alveolar click and a nasal lateral click.\nNo natural language allows clicks at the ends of syllables or words, but then no languages with clicks allows many consonants at all in those positions. Similarly, clicks are not found in underlying consonant clusters apart from /Cw/ (and, depending on the analysis, /C\u03c7/), as languages with clicks do not have other consonant clusters than that. Due to vowel elision, however, there are cases where clicks are pronounced in cross-linguistically common types of consonant clusters, such as Xhosa \"Snqobile\", from \"Sinqobile\" (a name), and \"isXhosa\", from \"isiXhosa\" (the Xhosa language).\nLike other articulatorily complex consonants, clicks tend to be found in lexical words rather than in grammatical words, but this is only a tendency. In N\u01c1ng, for example, there are two sets of personal pronouns, a full one without clicks and a partial set with clicks (\"\u0144g\" 'I', \"\u00e1\" 'thou', \"\u00ed\" 'we all', \"\u00fa\" 'you', vs. \"n\u01c0\u01f9g\" 'I', \"g\u01c0\u00e0\" 'thou', \"g\u01c0\u00ec\" 'we all', \"g\u01c0\u00f9\" 'you'), as well as other grammatical words with clicks such as \"\u01c1u\" 'not' and \"n\u01c0a\" 'with, and'.\nThe back-vowel constraint.\nIn several languages, including Nama and Ju\u01c0\u02bchoan, the alveolar click types and only occur, or preferentially occur, before back vowels, whereas the dental and palatal clicks occur before any vowel. The effect is most noticeable with the high front vowel . In Nama, for example, the diphthong is common but is rare after alveolar clicks, whereas the opposite is true after dental and palatal clicks. This is a common effect of uvular or uvularised consonants on vowels in both click and non-click languages. In Taa, for example, the back-vowel constraint is triggered by both alveolar clicks and uvular stops, but not by palatal clicks or velar stops: sequences such as and are rare to non-existent, whereas sequences such as and are common. The back-vowel constraint is also triggered by labial clicks, though not by labial stops. Clicks subject to this constraint involve a sharp retraction of the tongue during release.\nMiller and colleagues (2003) used ultrasound imaging to show that the rear articulation of the alveolar clicks () in Nama is substantially different from that of palatal and dental clicks. Specifically, the shape of the body of the tongue in palatal clicks is very similar to that of the vowel , and involves the same tongue muscles, so that sequences such as involved a simple and quick transition. The rear articulation of the alveolar clicks, however, is several centimetres further back, and involves a different set of muscles in the uvular region. The part of the tongue required to approach the palate for the vowel is deeply retracted in , as it lies at the bottom of the air pocket used to create the vacuum required for click airstream. This makes the transition required for much more complex and the timing more difficult than the shallower and more forward tongue position of the palatal clicks. Consequently, takes 50 ms longer to pronounce than , the same amount of time required to pronounce .\nLanguages do not all behave alike. In N\u01c0uu, the simple clicks trigger the and allophones of and , whereas do not. All of the affricated contour clicks, such as , do as well, as do the uvular stops . However, the occlusive contour clicks pattern like the simple clicks, and does not trigger the back-vowel constraint. This is because they involve tongue-root raising rather than tongue-root retraction in the uvular-pharyngeal region. However, in G\u01c0wi, which is otherwise largely similar, both and trigger the back-vowel constraint (Miller 2009).\nClick genesis and click loss.\nOne genetic study concluded that clicks, which occur in the languages of the genetically divergent populations Hadza and !Kung, may be an ancient element of human language. However, this conclusion relies on several dubious assumptions (see Hadza language), and most linguists assume that clicks, being quite complex consonants, arose relatively late in human history. How they arose is not known, but it is generally assumed that they developed from sequences of non-click consonants, as they are found allophonically for doubly articulated consonants in West Africa, for sequences that overlap at word boundaries in German, and for the sequence in Ndau and Tonga. Such developments have also been posited in historical reconstruction. For example, the Sandawe word for 'horn', , with a lateral affricate, may be a cognate with the root found throughout the Khoe family, which has a lateral click. This and other words suggests that at least some Khoe clicks may have formed from consonant clusters when the first vowel of a word was lost; in this instance * &gt; * &gt; .\nOn the other side of the equation, several non-endangered languages in vigorous use demonstrate click loss. For example, the East Kalahari languages have lost clicks from a large percentage of their vocabulary, presumably due to Bantu influence. As a rule, a click is replaced by a consonant with close to the manner of articulation of the click and the place of articulation of the forward release: alveolar click releases (the family) tend to mutate into a velar stop or affricate, such as ; palatal clicks (the family) tend to mutate into a palatal stop such as , or a post-alveolar affricate ; and dental clicks (the family) tend to mutate into an alveolar affricate .\nDifficulty.\nClicks are often presented as difficult sounds to articulate within words. However, children acquire them readily; a two-year-old, for example, may be able to pronounce a word with a lateral click with no problem, but still be unable to pronounce . Lucy Lloyd reported that after long contact with the Khoi and San, it was difficult for her to refrain from using clicks when speaking English."}
{"id": "7817", "revid": "1221315234", "url": "https://en.wikipedia.org/wiki?curid=7817", "title": "The Cider House Rules", "text": "The Cider House Rules (1985) is a novel by American writer John Irving, a \"Bildungsroman\" that was later adapted into a 1999 film and a stage play by Peter Parnell. The story, set in the pre\u2013 and post\u2013World War II era, tells of a young man, Homer Wells, growing up under the guidance of Dr. Wilbur Larch, an obstetrician and abortion provider. The story relates his early life at Larch's orphanage in Maine and follows Homer as he eventually leaves the nest and comes of age.\nPlot.\nHomer Wells is shown growing up in an orphanage where he spends his childhood trying to be \"of use\" as a medical assistant to director Dr. Wilbur Larch, whose history is told in flashbacks: After a traumatic misadventure with a prostitute as a young man, Wilbur turns his back on sex and love, choosing instead to help women with unwanted pregnancies give birth and then keeping the babies in an orphanage.\nHe makes a point of maintaining an emotional distance from the orphans, so that they can more easily make the transition into an adoptive family, but when it becomes clear that Homer is going to spend his childhood at the orphanage, Wilbur trains the orphan as an obstetrician and comes to love him like a son.\nWilbur's and Homer's lives are complicated by the abortions Wilbur provides. Wilbur came to this work reluctantly, but is driven by having seen the horrors of back-alley operations. Homer, upon learning Wilbur's secret, considers it morally wrong.\nAs a young man, Homer befriends a young couple, Candy Kendall and Wally Worthington, who come to St. Cloud's for an abortion. Homer leaves the orphanage, and returns with them to Wally's family's orchard in Heart's Rock, near the Maine coast. Wally and Homer become best friends and Homer develops a secret love for Candy. Wally goes off to serve in the Second World War and his plane is shot down over Burma. He is declared missing by the military, but Homer and Candy both believe he is dead and move on with their lives, which includes beginning a romantic relationship. When Candy becomes pregnant, they go back to St. Cloud's Orphanage, where their son is born and named Angel.\nSubsequently, Wally is found in Burma and returns home, paralyzed from the waist down. He is still able to have sexual intercourse but is sterile due to an infection caught in Burma. Homer and Candy lie to the family about Angel's parentage, claiming that Homer had adopted him. Wally and Candy marry shortly afterward, but Candy and Homer maintain a secret affair that lasts some 15 years.\nMany years later, teenaged Angel falls in love with Rose, the daughter of the head migrant worker at the apple orchard. Rose becomes pregnant by her father, and Homer aborts her fetus. Homer decides to return to the orphanage after Wilbur's death, to work as the new director. Though he maintains his distaste for abortions, he continues Dr. Larch's legacy of performing the procedure for those in need, and he dreams of the day when abortions are legal.\nThe name \"The Cider House Rules\" refers to the list of rules that migrant workers are supposed to follow at the Ocean View Orchards. However, none of them can read, and they are completely unaware of the rules \u2013 which have been posted for years.\nA subplot follows the character Melony, who grew up alongside Homer in the orphanage. She was Homer's first girlfriend. After Homer leaves the orphanage, so does she in an effort to find him. She eventually becomes an electrician and takes a female lover, Lorna. Melony is stoic, who refuses to press charges against a man who brutally broke her nose and arm. She intends to later take revenge. She is the catalyst that transforms Homer from his comfortable, but not entirely admirable position, at the apple orchard into Dr. Larch's replacement.\nBackground.\nWally's experience getting shot down over Burma was based in part on that of Irving's biological father (whom he never met), who was shot down over Burma and survived.\nFilm adaptation.\nThe novel was adapted into a film of the same name released in 1999 directed by Lasse Hallstr\u00f6m. It starred Tobey Maguire as Homer Wells."}
{"id": "7818", "revid": "48886176", "url": "https://en.wikipedia.org/wiki?curid=7818", "title": "Consumer", "text": "A consumer is a person or a group who intends to order, or use purchased goods, products, or services primarily for personal, social, family, household and similar needs, who is not directly related to entrepreneurial or business activities. The term most commonly refers to a person who purchases goods and services for personal use.\nRights.\n\"Consumers, by definition, include us all\", said President John F. Kennedy, offering his definition to the United States Congress on March 15, 1962. This speech became the basis for the creation of World Consumer Rights Day, now celebrated on March 15. In his speech, John Fitzgerald Kennedy outlined the integral responsibility to consumers from their respective governments to help exercise consumers' rights, including:\nEconomics and marketing.\nIn an economy, a consumer buys goods or services primarily for consumption and not for resale or for commercial purposes. Consumers pay some amount of money (or equivalent) for goods or services.) then consume (use up). As such, consumers play a vital role in the economic system of a capitalist system\nand form a fundamental part of any economy.\nWithout consumer demand, producers would lack one of the key motivations to produce: to sell to consumers. The consumer also forms one end of the chain of distribution.\nRecently in marketing, instead of marketers generating broad demographic profiles and Fisio-graphic profiles of market segments, marketers have started to engage in personalized marketing, permission marketing, and mass customization to target potential consumers.\nLargely due to the rise of the Internet, consumers are shifting more and more toward becoming prosumers, consumers who are also producers (often of information and media on the social web) - they influence the products created (e.g. by customization, crowdfunding or publishing their preferences), actively participate in the production process, or use interactive products.\nLaw and politics.\nThe law primarily uses a notion of the consumer in relation to consumer protection laws, and the definition of consumer is often restricted to living persons (not corporations or businesses) and excludes commercial users. A typical legal rationale for protecting the consumer is based on the notion of policing market failures and inefficiencies, such as inequalities of bargaining power between a consumer and a business. As all potential voters are also consumers, consumer protection has a clear political significance.\nConcern over the interests of consumers has spawned consumer activism, where organized activists do research, education and advocacy to improve the offer of products and services. Consumer education has been incorporated into some school curricula. There are also various non-profit publications, such as \"Which?\", \"Consumer Reports\" and \"Choice magazine\", dedicated to assist in consumer education and decision making.\nIn India, the Consumer Protection Act of 1986 differentiates the consumption of a commodity or service for personal use or to earn a livelihood. Only consumers are protected per this act and any person, entity or organization purchasing a commodity for commercial reasons are exempted from any benefits of this act."}
{"id": "7819", "revid": "34630307", "url": "https://en.wikipedia.org/wiki?curid=7819", "title": "Cactus", "text": "A cactus (: cacti, cactuses, or less commonly, cactus) is a member of the plant family Cactaceae (), a family of the order Caryophyllales comprising about 127 genera with some 1,750 known species. The word \"cactus\" derives, through Latin, from the Ancient Greek word (\"k\u00e1ktos\"), a name originally used by Theophrastus for a spiny plant whose identity is now not certain. Cacti occur in a wide range of shapes and sizes. They are native to the Americas, ranging from Patagonia in the south to parts of western Canada in the north, with the exception of \"Rhipsalis baccifera\", which is also found in Africa and Sri Lanka. Cacti are adapted to live in very dry environments, including the Atacama Desert, one of the driest places on Earth. Because of this, cacti show many adaptations to conserve water. For example, almost all cacti are succulents, meaning they have thickened, fleshy parts adapted to store water. Unlike many other succulents, the stem is the only part of most cacti where this vital process takes place. Most species of cacti have lost true leaves, retaining only spines, which are highly modified leaves. As well as defending against herbivores, spines help prevent water loss by reducing air flow close to the cactus and providing some shade. In the absence of true leaves, cacti's enlarged stems carry out photosynthesis.\nCactus spines are produced from specialized structures called areoles, a kind of highly reduced branch. Areoles are an identifying feature of cacti. As well as spines, areoles give rise to flowers, which are usually tubular and multipetaled. Many cacti have short growing seasons and long dormancies and are able to react quickly to any rainfall, helped by an extensive but relatively shallow root system that quickly absorbs any water reaching the ground surface. Cactus stems are often ribbed or fluted with a number of ribs which corresponds to a number in the Fibonacci numbers (2, 3, 5, 8, 13, 21, 34 etc.). This allows them to expand and contract easily for quick water absorption after rain, followed by retention over long drought periods. Like other succulent plants, most cacti employ a special mechanism called \"crassulacean acid metabolism\" (CAM) as part of photosynthesis. Transpiration, during which carbon dioxide enters the plant and water escapes, does not take place during the day at the same time as photosynthesis, but instead occurs at night. The plant stores the carbon dioxide it takes in as malic acid, retaining it until daylight returns, and only then using it in photosynthesis. Because transpiration takes place during the cooler, more humid night hours, water loss is significantly reduced.\nMany smaller cacti have globe-shaped stems, combining the highest possible volume for water storage with the lowest possible surface area for water loss from transpiration. The tallest free-standing cactus is \"Pachycereus pringlei\", with a maximum recorded height of , and the smallest is \"Blossfeldia liliputiana\", only about in diameter at maturity. A fully grown saguaro (\"Carnegiea gigantea\") is said to be able to absorb as much as of water during a rainstorm. A few species differ significantly in appearance from most of the family. At least superficially, plants of the genera \"Leuenbergeria\", \"Rhodocactus\" and \"Pereskia\" resemble other trees and shrubs growing around them. They have persistent leaves, and when older, bark-covered stems. Their areoles identify them as cacti, and in spite of their appearance, they, too, have many adaptations for water conservation. \"Leuenbergeria\" is considered close to the ancestral species from which all cacti evolved. In tropical regions, other cacti grow as forest climbers and epiphytes (plants that grow on trees). Their stems are typically flattened, almost leaf-like in appearance, with fewer or even no spines, such as the well-known Christmas cactus or Thanksgiving cactus (in the genus \"Schlumbergera\").\nCacti have a variety of uses: many species are used as ornamental plants, others are grown for fodder or forage, and others for food (particularly their fruit). Cochineal is the product of an insect that lives on some cacti.\nMany succulent plants in both the Old and New World \u2013 such as some Euphorbiaceae (euphorbias) \u2013 are also spiny stem succulents and because of this are sometimes incorrectly referred to as \"cactus\".\nMorphology.\nThe 1,500 to 1,800 species of cacti mostly fall into one of two groups of \"core cacti\": opuntias (subfamily Opuntioideae) and \"cactoids\" (subfamily Cactoideae). Most members of these two groups are easily recognizable as cacti. They have fleshy succulent stems that are major organs of photosynthesis. They have absent, small, or transient leaves. They have flowers with ovaries that lie below the sepals and petals, often deeply sunken into a fleshy receptacle (the part of the stem from which the flower parts grow). All cacti have areoles\u2014highly specialized short shoots with extremely short internodes that produce spines, normal shoots, and flowers.\nThe remaining cacti fall into only two groups: three tree-like genera, \"Leuenbergeria\", \"Pereskia\" and \"Rhodocactus\" (all formerly placed in \"Pereskia\"), and the much smaller \"Maihuenia\". These two groups are rather different from other cacti, which means any description of cacti as a whole must frequently make exceptions for them. Species of the first three genera superficially resemble other tropical forest trees. When mature, they have woody stems that may be covered with bark and long-lasting leaves that provide the main means of photosynthesis. Their flowers may have superior ovaries (i.e., above the points of attachment of the sepals and petals) and areoles that produce further leaves. The two species of \"Maihuenia\" have succulent but non-photosynthetic stems and prominent succulent leaves.\nGrowth habit.\nCacti show a wide variety of growth habits, which are difficult to divide into clear, simple categories.\nCacti can be tree-like (arborescent), meaning they typically have a single more-or-less woody trunk topped by several to many branches. In the genera \"Leuenbergeria\", \"Pereskia\" and \"Rhodocactus\", the branches are covered with leaves, so the species of these genera may not be recognized as cacti. In most other cacti, the branches are more typically cactus-like, bare of leaves and bark and covered with spines, as in \"Pachycereus pringlei\" or the larger opuntias. Some cacti may become tree-sized but without branches, such as larger specimens of \"Echinocactus platyacanthus\". Cacti may also be described as shrubby, with several stems coming from the ground or from branches very low down, such as in \"Stenocereus thurberi\".\nSmaller cacti may be described as columnar. They consist of erect, cylinder-shaped stems, which may or may not branch, without a very clear division into trunk and branches. The boundary between columnar forms and tree-like or shrubby forms is difficult to define. Smaller and younger specimens of \"Cephalocereus senilis\", for example, are columnar, whereas older and larger specimens may become tree-like. In some cases, the \"columns\" may be horizontal rather than vertical. Thus, \"Stenocereus eruca\" can be described as columnar even though it has stems growing along the ground, rooting at intervals.\nCacti whose stems are even smaller may be described as globular (or globose). They consist of shorter, more ball-shaped stems than columnar cacti. Globular cacti may be solitary, such as \"Ferocactus latispinus\", or their stems may form clusters that can create large mounds. All or some stems in a cluster may share a common root.\nOther cacti have a quite different appearance. In tropical regions, some grow as forest climbers and epiphytes. Their stems are typically flattened and almost leaf-like in appearance, with few or even no spines. Climbing cacti can be very large; a specimen of \"Hylocereus\" was reported as long from root to the most distant stem. Epiphytic cacti, such as species of \"Rhipsalis\" or \"Schlumbergera\", often hang downwards, forming dense clumps where they grow in trees high above the ground.\nStems.\nThe leafless, spiny stem is the characteristic feature of the majority of cacti (all belonging to the largest subfamily, the Cactoideae). The stem is typically succulent, meaning it is adapted to store water. The surface of the stem may be smooth (as in some species of \"Opuntia\") or covered with protuberances of various kinds, which are usually called tubercles. These vary from small \"bumps\" to prominent, nipple-like shapes in the genus \"Mammillaria\" and outgrowths almost like leaves in \"Ariocarpus\" species. The stem may also be ribbed or fluted in shape. The prominence of these ribs depends on how much water the stem is storing: when full (up to 90% of the mass of a cactus may be water), the ribs may be almost invisible on the swollen stem, whereas when the cactus is short of water and the stems shrink, the ribs may be very visible.\nThe stems of most cacti are some shade of green, often bluish or brownish green. Such stems contain chlorophyll and are able to carry out photosynthesis; they also have stomata (small structures that can open and close to allow passage of gases). Cactus stems are often visibly waxy.\nAreoles.\nAreoles are structures unique to cacti. Although variable, they typically appear as woolly or hairy areas on the stems from which spines emerge. Flowers are also produced from areoles. In the genus \"Leuenbergeria\", believed similar to the ancestor of all cacti, the areoles occur in the axils of leaves (i.e. in the angle between the leaf stalk and the stem). In leafless cacti, areoles are often borne on raised areas on the stem where leaf bases would have been.\nAreoles are highly specialized and very condensed shoots or branches. In a normal shoot, nodes bearing leaves or flowers would be separated by lengths of stem (internodes). In an areole, the nodes are so close together, they form a single structure. The areole may be circular, elongated into an oval shape, or even separated into two parts; the two parts may be visibly connected in some way (e.g. by a groove in the stem) or appear entirely separate (a dimorphic areole). The part nearer the top of the stem then produces flowers, the other part spines. Areoles often have multicellular hairs (trichomes) that give the areole a hairy or woolly appearance, sometimes of a distinct color such as yellow or brown.\nIn most cacti, the areoles produce new spines or flowers only for a few years and then become inactive. This results in a relatively fixed number of spines, with flowers being produced only from the ends of stems, which are still growing and forming new areoles. In \"Pereskia\", a genus close to the ancestor of cacti, areoles remain active for much longer; this is also the case in \"Opuntia\" and \"Neoraimondia\".\nLeaves.\nThe great majority of cacti have no visible leaves; photosynthesis takes place in the stems (which may be flattened and leaflike in some species). Exceptions occur in three (taxonomically, four) groups of cacti. All the species of \"Leuenbergeria\", \"Pereskia\" and \"Rhodocactus\" are superficially like normal trees or shrubs and have numerous leaves with a midrib and a flattened blade (lamina) on either side. This group is paraphyletic, forming two taxonomic clades. Many cacti in the opuntia group (subfamily Opuntioideae) also have visible leaves, which may be long-lasting (as in \"Pereskiopsis\" species) or produced only during the growing season and then lost (as in many species of \"Opuntia\"). The small genus \"Maihuenia\" also relies on leaves for photosynthesis. The structure of the leaves varies somewhat between these groups. Opuntioids and \"Maihuenia\" have leaves that appear to consist only of a midrib.\nEven those cacti without visible photosynthetic leaves do usually have very small leaves, less than long in about half of the species studied and almost always less than long. The function of such leaves cannot be photosynthesis; a role in the production of plant hormones, such as auxin, and in defining axillary buds has been suggested.\nSpines.\nBotanically, \"spines\" are distinguished from \"thorns\": spines are modified leaves, and thorns are modified branches. Cacti produce spines, always from areoles as noted above. Spines are present even in those cacti with leaves, such as \"Pereskia\", \"Pereskiopsis\" and \"Maihuenia\", so they clearly evolved before complete leaflessness. Some cacti only have spines when young, possibly only when seedlings. This is particularly true of tree-living cacti, such as \"Rhipsalis\" and \"Schlumbergera\", but also of some ground-living cacti, such as \"Ariocarpus\".\nThe spines of cacti are often useful in identification, since they vary greatly between species in number, color, size, shape and hardness, as well as in whether all the spines produced by an areole are similar or whether they are of distinct kinds. Most spines are straight or at most slightly curved, and are described as hair-like, bristle-like, needle-like or awl-like, depending on their length and thickness. Some cacti have flattened spines (e.g. \"Sclerocactus papyracanthus\"). Other cacti have hooked spines. Sometimes, one or more central spines are hooked, while outer spines are straight (e.g., \"Mammillaria rekoi\").\nIn addition to normal-length spines, members of the subfamily Opuntioideae have relatively short spines, called glochids, that are barbed along their length and easily shed. These enter the skin and are difficult to remove due to being very fine and easily broken, causing long-lasting irritation.\nRoots.\nMost ground-living cacti have only fine roots, which spread out around the base of the plant for varying distances, close to the surface. Some cacti have taproots; in genera such as \"Ariocarpus\", these are considerably larger and of a greater volume than the body. Taproots may aid in stabilizing the larger columnar cacti. Climbing, creeping and epiphytic cacti may have only adventitious roots, produced along the stems where these come into contact with a rooting medium.\nFlowers.\nLike their spines, cactus flowers are variable. Typically, the ovary is surrounded by material derived from stem or receptacle tissue, forming a structure called a pericarpel. Tissue derived from the petals and sepals continues the pericarpel, forming a composite tube\u2014the whole may be called a floral tube, although strictly speaking only the part furthest from the base is floral in origin. The outside of the tubular structure often has areoles that produce wool and spines. Typically, the tube also has small scale-like bracts, which gradually change into sepal-like and then petal-like structures, so the sepals and petals cannot be clearly differentiated (and hence are often called \"tepals\"). Some cacti produce floral tubes without wool or spines (e.g. \"Gymnocalycium\") or completely devoid of any external structures (e.g. \"Mammillaria\"). Unlike the flowers of most other cacti, \"Pereskia\" flowers may be borne in clusters.\nCactus flowers usually have many stamens, but only a single style, which may branch at the end into more than one stigma. The stamens usually arise from all over the inner surface of the upper part of the floral tube, although in some cacti, the stamens are produced in one or more distinct \"series\" in more specific areas of the inside of the floral tube.\nThe flower as a whole is usually radially symmetrical (actinomorphic), but may be bilaterally symmetrical (zygomorphic) in some species. Flower colors range from white through yellow and red to magenta.\nAdaptations for water conservation.\nAll cacti have some adaptations to promote efficient water use. Most cacti\u2014opuntias and cactoids\u2014specialize in surviving in hot and dry environments (i.e. are xerophytes), but the first ancestors of modern cacti were already adapted to periods of intermittent drought. A small number of cactus species in the tribes Hylocereeae and Rhipsalideae have become adapted to life as climbers or epiphytes, often in tropical forests, where water conservation is less important.\nLeaves and spines.\nThe absence of visible leaves is one of the most striking features of most cacti. \"Pereskia\" (which is close to the ancestral species from which all cacti evolved) does have long-lasting leaves, which are, however, thickened and succulent in many species. Other species of cactus with long-lasting leaves, such as the opuntioid \"Pereskiopsis\", also have succulent leaves. A key issue in retaining water is the ratio of surface area to volume. Water loss is proportional to surface area, whereas the amount of water present is proportional to volume. Structures with a high surface area-to-volume ratio, such as thin leaves, necessarily lose water at a higher rate than structures with a low area-to-volume ratio, such as thickened stems.\nSpines, which are modified leaves, are present on even those cacti with true leaves, showing the evolution of spines preceded the loss of leaves. Although spines have a high surface area-to-volume ratio, at maturity they contain little or no water, being composed of fibers made up of dead cells. Spines provide protection from herbivores and camouflage in some species, and assist in water conservation in several ways. They trap air near the surface of the cactus, creating a moister layer that reduces evaporation and transpiration. They can provide some shade, which lowers the temperature of the surface of the cactus, also reducing water loss. When sufficiently moist air is present, such as during fog or early morning mist, spines can condense moisture, which then drips onto the ground and is absorbed by the roots.\nStems.\nThe majority of cacti are stem succulents, i.e., plants in which the stem is the main organ used to store water. Water may form up to 90% of the total mass of a cactus. Stem shapes vary considerably among cacti. The cylindrical shape of columnar cacti and the spherical shape of globular cacti produce a low surface area-to-volume ratio, thus reducing water loss, as well as minimizing the heating effects of sunlight. The ribbed or fluted stems of many cacti allow the stem to shrink during periods of drought and then swell as it fills with water during periods of availability. A mature saguaro (\"Carnegiea gigantea\") is said to be able to absorb as much as of water during a rainstorm. The outer layer of the stem usually has a tough cuticle, reinforced with waxy layers, which reduce water loss. These layers are responsible for the grayish or bluish tinge to the stem color of many cacti.\nThe stems of most cacti have adaptations to allow them to conduct photosynthesis in the absence of leaves. This is discussed further below under Metabolism.\nRoots.\nMany cacti have roots that spread out widely, but only penetrate a short distance into the soil. In one case, a young saguaro only tall had a root system with a diameter of , but no more than deep. Cacti can also form new roots quickly when rain falls after a drought. The concentration of salts in the root cells of cacti is relatively high. All these adaptations enable cacti to absorb water rapidly during periods of brief or light rainfall. Thus, \"Ferocactus cylindraceus\" reportedly can take up a significant amount of water within 12 hours from as little as of rainfall, becoming fully hydrated in a few days.\nAlthough in most cacti, the stem acts as the main organ for storing water, some cacti have in addition large taproots. These may be several times the length of the above-ground body in the case of species such as \"Copiapoa atacamensis\", which grows in one of the driest places in the world, the Atacama Desert in northern Chile.\nMetabolism.\nPhotosynthesis requires plants to take in carbon dioxide gas (). As they do so, they lose water through transpiration. Like other types of succulents, cacti reduce this water loss by the way in which they carry out photosynthesis. \"Normal\" leafy plants use the C3 mechanism: during daylight hours, is continually drawn out of the air present in spaces inside leaves and converted first into a compound containing three carbon atoms (3-phosphoglycerate) and then into products such as carbohydrates. The access of air to internal spaces within a plant is controlled by stomata, which are able to open and close. The need for a continuous supply of during photosynthesis means the stomata must be open, so water vapor is continuously being lost. Plants using the C3 mechanism lose as much as 97% of the water taken up through their roots in this way. A further problem is that as temperatures rise, the enzyme that captures starts to capture more and more oxygen instead, reducing the efficiency of photosynthesis by up to 25%.\nCrassulacean acid metabolism (CAM) is a mechanism adopted by cacti and other succulents to avoid the problems of the C3 mechanism. In full CAM, the stomata open only at night, when temperatures and water loss are lowest. enters the plant and is captured in the form of organic acids stored inside cells (in vacuoles). The stomata remain closed throughout the day, and photosynthesis uses only this stored . CAM uses water much more efficiently at the price of limiting the amount of carbon fixed from the atmosphere and thus available for growth. CAM-cycling is a less water-efficient system whereby stomata open in the day, just as in plants using the C3 mechanism. At night, or when the plant is short of water, the stomata close and the CAM mechanism is used to store produced by respiration for use later in photosynthesis. CAM-cycling is present in \"Pereskia\" species.\nBy studying the ratio of 14C to 13C incorporated into a plant\u2014its isotopic signature\u2014it is possible to deduce how much is taken up at night and how much in the daytime. Using this approach, most of the \"Pereskia\" species investigated exhibit some degree of CAM-cycling, suggesting this ability was present in the ancestor of all cacti. \"Pereskia\" leaves are claimed to only have the C3 mechanism with CAM restricted to stems. More recent studies show that \"it is highly unlikely that significant carbon assimilation occurs in the stem\"; \"Pereskia\" species are described as having \"C3 with inducible CAM.\" Leafless cacti carry out all their photosynthesis in the stem, using full CAM. , it is not clear whether stem-based CAM evolved once only in the core cacti, or separately in the opuntias and cactoids; CAM is known to have evolved convergently many times.\nTo carry out photosynthesis, cactus stems have undergone many adaptations. Early in their evolutionary history, the ancestors of modern cacti (other than \"Leuenbergeria\" species) developed stomata on their stems and began to delay developing bark. However, this alone was not sufficient; cacti with only these adaptations appear to do very little photosynthesis in their stems. Stems needed to develop structures similar to those normally found only in leaves. Immediately below the outer epidermis, a hypodermal layer developed made up of cells with thickened walls, offering mechanical support. Air spaces were needed between the cells to allow carbon dioxide to diffuse inwards. The center of the stem, the cortex, developed \"chlorenchyma\" \u2013 a plant tissue made up of relatively unspecialized cells containing chloroplasts, arranged into a \"spongy layer\" and a \"palisade layer\" where most of the photosynthesis occurs.\nTaxonomy and classification.\nNaming and classifying cacti has been both difficult and controversial since the first cacti were discovered for science. The difficulties began with Carl Linnaeus. In 1737, he placed the cacti he knew into two genera, \"Cactus\" and \"Pereskia\". However, when he published \"Species Plantarum\" in 1753\u2014the starting point for modern botanical nomenclature\u2014he relegated them all to one genus, \"Cactus\". The word \"cactus\" is derived through Latin from the Ancient Greek (\"kaktos\"), a name used by Theophrastus for a spiny plant, which may have been the cardoon (\"Cynara cardunculus\").\nLater botanists, such as Philip Miller in 1754, divided cacti into several genera, which, in 1789, Antoine Laurent de Jussieu placed in his newly created family Cactaceae. By the early 20th century, botanists came to feel Linnaeus's name \"Cactus\" had become so confused as to its meaning (was it the genus or the family?) that it should not be used as a genus name. The 1905 Vienna botanical congress rejected the name \"Cactus\" and instead declared \"Mammillaria\" was the type genus of the family Cactaceae. It did, however, conserve the name Cactaceae, leading to the unusual situation in which the family Cactaceae no longer contains the genus after which it was named.\nThe difficulties continued, partly because giving plants scientific names relies on \"type specimens\". Ultimately, if botanists want to know whether a particular plant is an example of, say, \"Mammillaria mammillaris\", they should be able to compare it with the type specimen to which this name is permanently attached. Type specimens are normally prepared by compression and drying, after which they are stored in herbaria to act as definitive references. However, cacti are very difficult to preserve in this way; they have evolved to resist drying and their bodies do not easily compress. A further difficulty is that many cacti were given names by growers and horticulturalists rather than botanists; as a result, the provisions of the \"International Code of Nomenclature for algae, fungi, and plants\" (which governs the names of cacti, as well as other plants) were often ignored. Curt Backeberg, in particular, is said to have named or renamed 1,200 species without one of his names ever being attached to a specimen, which, according to David Hunt, ensured he \"left a trail of nomenclatural chaos that will probably vex cactus taxonomists for centuries.\"\nClassification.\nIn 1984, it was decided that the Cactaceae Section of the International Organization for Succulent Plant Study should set up a working party, now called the International Cactaceae Systematics Group (ICSG), to produce consensus classifications down to the level of genera. Their system has been used as the basis of subsequent classifications. Detailed treatments published in the 21st century have divided the family into around 125\u2013130 genera and 1,400\u20131,500 species, which are then arranged into a number of tribes and subfamilies. The ICSG classification of the cactus family recognized four subfamilies, the largest of which was divided into nine tribes. The subfamilies were:\nMolecular phylogenetic studies have supported the monophyly of three of these subfamilies (not Pereskioideae), but have not supported all of the tribes or even genera below this level; indeed, a 2011 study found only 39% of the genera in the subfamily Cactoideae sampled in the research were monophyletic. Classification of the cacti currently remains uncertain and is likely to change.\nPhylogeny and evolution.\nPhylogeny.\nA 2005 study suggested the genus \"Pereskia\" as then circumscribed (\"Pereskia\" sensu lato) was basal within the Cactaceae, but confirmed earlier suggestions it was not monophyletic, i.e., did not include all the descendants of a common ancestor. The Bayesian consensus cladogram from this study is shown below with subsequent generic changes added.\nA 2011 study using fewer genes but more species also found that \"Pereskia\" s.l. was divided into the same clades, but was unable to resolve the members of the \"core cacti\" clade. It was accepted that the relationships shown above are \"the most robust to date.\"\n\"Leuenbergeria\" species (\"Pereskia\" s.l. Clade A) always lack two key features of the stem present in most of the remaining \"caulocacti\": like most non-cacti, their stems begin to form bark early in the plants' life and also lack stomata\u2014structures that control admission of air into a plant and hence control photosynthesis. By contrast, caulocacti, including species of \"Rhodocactus\" and the remaining species of \"Pereskia\" s.s., typically delay forming bark and have stomata on their stems, thus giving the stem the potential to become a major organ for photosynthesis. (The two highly specialized species of \"Maihuenia\" are something of an exception.)\nThe first cacti are thought to have been only slightly succulent shrubs or small trees whose leaves carried out photosynthesis. They lived in tropical areas that experienced periodic drought. If \"Leuenbergeria\" is a good model of these early cacti, then, although they would have appeared superficially similar to other trees growing nearby, they had already evolved strategies to conserve water (some of which are present in members of other families in the order Caryophyllales). These strategies included being able to respond rapidly to periods of rain, and keeping transpiration low by using water very efficiently during photosynthesis. The latter was achieved by tightly controlling the opening of stomata. Like \"Pereskia\" species today, early ancestors may have been able to switch from the normal C3 mechanism, where carbon dioxide is used continuously in photosynthesis, to CAM cycling, in which when the stomata are closed, carbon dioxide produced by respiration is stored for later use in photosynthesis.\nThe clade containing \"Rhodocactus\" and \"Pereskia\" s.s. marks the beginnings of an evolutionary switch to using stems as photosynthetic organs. Stems have stomata and the formation of bark takes place later than in normal trees. The \"core cacti\" show a steady increase in both stem succulence and photosynthesis accompanied by multiple losses of leaves, more-or-less complete in the Cactoideae. One evolutionary question at present unanswered is whether the switch to full CAM photosynthesis in stems occurred only once in the core cacti, in which case it has been lost in \"Maihuenia\", or separately in Opuntioideae and Cactoideae, in which case it never evolved in \"Maihuenia\".\nUnderstanding evolution within the core cacti clade is difficult , since phylogenetic relationships are still uncertain and not well related to current classifications. Thus, a 2011 study found \"an extraordinarily high proportion of genera\" were not monophyletic, so were not all descendants of a single common ancestor. For example, of the 36 genera in the subfamily Cactoideae sampled in the research, 22 (61%) were found not monophyletic. Nine tribes are recognized within Cactoideae in the International Cactaceae Systematics Group (ICSG) classification; one, Calymmantheae, comprises a single genus, \"Calymmanthium\". Only two of the remaining eight \u2013 Cacteae and Rhipsalideae \u2013 were shown to be monophyletic in a 2011 study by Hern\u00e1ndez-Hern\u00e1ndez et al. For a more detailed discussion of the phylogeny of the cacti, see Classification of the Cactaceae.\nEvolutionary history.\nNo known fossils of cacti exist to throw light on their evolutionary history. However, the geographical distribution of cacti offers some evidence. Except for a relatively recent spread of \"Rhipsalis baccifera\" to parts of the Old World, cacti are plants of South America and mainly southern regions of North America. This suggests the family must have evolved after the ancient continent of Gondwana split into South America and Africa, which occurred during the Early Cretaceous, around . Precisely when after this split cacti evolved is less clear. Older sources suggest an early origin around 90 \u2013 66 million years ago, during the Late Cretaceous. More recent molecular studies suggest a much younger origin, perhaps in very Late Eocene to early Oligocene periods, around 35\u201330\u00a0million years ago. Based on the phylogeny of the cacti, the earliest diverging group (\"Leuenbergeria\") may have originated in Central America and northern South America, whereas the caulocacti, those with more-or-less succulent stems, evolved later in the southern part of South America, and then moved northwards. Core cacti, those with strongly succulent stems, are estimated to have evolved around 25\u00a0million years ago. A possible stimulus to their evolution may have been uplifting in the central Andes, some 25\u201320\u00a0million years ago, which was associated with increasing and varying aridity. However, the current species diversity of cacti is thought to have arisen only in the last 10\u20135\u00a0million years (from the late Miocene into the Pliocene). Other succulent plants, such as the Aizoaceae in South Africa, the Didiereaceae in Madagascar and the genus \"Agave\" in the Americas, appear to have diversified at the same time, which coincided with a global expansion of arid environments.\nDistribution.\nCacti inhabit diverse regions, from coastal plains to high mountain areas. With one exception, they are native to the Americas, where their range extends from Patagonia to British Columbia and Alberta in western Canada. A number of centers of diversity exist. For cacti adapted to drought, the three main centers are Mexico and the southwestern United States; the southwestern Andes, where they are found in Peru, Bolivia, Chile and Argentina; and eastern Brazil, away from the Amazon Basin. Tree-living epiphytic and climbing cacti necessarily have different centers of diversity, as they require moister environments. They are mainly found in the coastal mountains and Atlantic forests of southeastern Brazil; in Bolivia, which is the center of diversity for the subfamily Rhipsalideae; and in forested regions of Central America, where the climbing Hylocereeae are most diverse.\n\"Rhipsalis baccifera\" is the exception; it is native to both the Americas and the Old World, where it is found in tropical Africa, Madagascar, and Sri Lanka. One theory is it was spread by being carried as seeds in the digestive tracts of migratory birds; the seeds of \"Rhipsalis\" are adapted for bird distribution. Old World populations are polyploid, and regarded as distinct subspecies, supporting the idea that the spread was not recent. The alternative theory is the species initially crossed the Atlantic on European ships trading between South America and Africa, after which birds may have spread it more widely.\nNaturalized species.\nMany other species have become naturalized outside the Americas after having been introduced by people, especially in Australia, Hawaii, and the Mediterranean region. In Australia, species of \"Opuntia\", particularly \"Opuntia stricta\", were introduced in the 19th century for use as natural agricultural fences and in an attempt to establish a cochineal industry. They rapidly became a major weed problem, but are now controlled by biological agents, particularly the moth \"Cactoblastis cactorum\". The weed potential of \"Opuntia\" species in Australia continues however, leading to all opuntioid cacti except \"O. ficus-indica\" being declared Weeds of National Significance by the Australian Weeds Committee in April 2012.\nThe Arabian Peninsula has a wide variety of ever-increasing, introduced cactus populations. Some of these are cultivated, some are escapes from cultivation, and some are invasives that are presumed to be ornamental escapes.\nReproductive ecology.\nCactus flowers are pollinated by insects, birds and bats. None are known to be wind-pollinated and self-pollination occurs in only a very few species; for example the flowers of some species of \"Frailea\" do not open (cleistogamy). The need to attract pollinators has led to the evolution of pollination syndromes, which are defined as groups of \"floral traits, including rewards, associated with the attraction and utilization of a specific group of animals as pollinators.\"\nBees are the most common pollinators of cacti; bee-pollination is considered to have been the first to evolve. Day-flying butterflies and nocturnal moths are associated with different pollination syndromes. Butterfly-pollinated flowers are usually brightly colored, opening during the day, whereas moth-pollinated flowers are often white or pale in color, opening only in the evening and at night. As an example, \"Lophocereus schottii\" is pollinated by a particular species of moth, \"Upiga virescens\", which also lays its eggs among the developing seeds its caterpillars later consume. The flowers of this cactus are funnel-shaped, white to deep pink, up to long, and open at night.\nHummingbirds are significant pollinators of cacti. Species showing the typical hummingbird-pollination syndrome have flowers with colors towards the red end of the spectrum, anthers and stamens that protrude from the flower, and a shape that is not radially symmetrical, with a lower lip that bends downwards; they produce large amounts of nectar with a relatively low sugar content. \"Schlumbergera\" species, such as \"S. truncata\", have flowers that correspond closely to this syndrome. Other hummingbird-pollinated genera include \"Cleistocactus\" and \"Disocactus\".\nBat-pollination is relatively uncommon in flowering plants, but about a quarter of the genera of cacti are known to be pollinated by bats\u2014an unusually high proportion, exceeded among eudicots by only two other families, both with very few genera. Columnar cacti growing in semidesert areas are among those most likely to be bat-pollinated; this may be because bats are able to travel considerable distances, so are effective pollinators of plants growing widely separated from one another. The pollination syndrome associated with bats includes a tendency for flowers to open in the evening and at night, when bats are active. Other features include a relatively dull color, often white or green; a radially symmetrical shape, often tubular; a smell described as \"musty\"; and the production of a large amount of sugar-rich nectar. \"Carnegiea gigantea\" is an example of a bat-pollinated cactus, as are many species of \"Pachycereus\" and \"Pilosocereus\".\nThe fruits produced by cacti after the flowers have been fertilized vary considerably; many are fleshy, although some are dry. All contain a large number of seeds. Fleshy, colorful and sweet-tasting fruits are associated with seed dispersal by birds. The seeds pass through their digestive systems and are deposited in their droppings. Fruit that falls to the ground may be eaten by other animals; giant tortoises are reported to distribute \"Opuntia\" seeds in the Gal\u00e1pagos Islands. Ants appear to disperse the seeds of a few genera, such as \"Blossfeldia\". Drier spiny fruits may cling to the fur of mammals or be moved around by the wind.\nUses.\nEarly history.\n, there is still controversy as to the precise dates when humans first entered those areas of the New World where cacti are commonly found, and hence when they might first have used them. An archaeological site in Chile has been dated to around 15,000 years ago, suggesting cacti would have been encountered before then. Early evidence of the use of cacti includes cave paintings in the Serra da Capivara in Brazil, and seeds found in ancient middens (waste dumps) in Mexico and Peru, with dates estimated at 12,000\u20139,000 years ago. Hunter-gatherers likely collected cactus fruits in the wild and brought them back to their camps.\nIt is not known when cacti were first cultivated. Opuntias (prickly pears) were used for a variety of purposes by the Aztecs, whose empire, lasting from the 14th to the 16th century, had a complex system of horticulture. Their capital from the 15th century was Tenochtitlan (now Mexico City); one explanation for the origin of the name is that it includes the Nahuatl word \"n\u014dchtli\", referring to the fruit of an opuntia. The coat of arms of Mexico shows an eagle perched on a cactus while holding a snake, an image at the center of the myth of the founding of Tenochtitlan. The Aztecs symbolically linked the ripe red fruits of an opuntia to human hearts; just as the fruit quenches thirst, so offering human hearts to the sun god ensured the sun would keep moving.\nEuropeans first encountered cacti when they arrived in the New World late in the 15th century. Their first landfalls were in the West Indies, where relatively few cactus genera are found; one of the most common is the genus \"Melocactus\". Thus, melocacti were possibly among the first cacti seen by Europeans. \"Melocactus\" species were present in English collections of cacti before the end of the 16th century (by 1570 according to one source,) where they were called \"Echinomelocactus\", later shortened to \"Melocactus\" by Joseph Pitton de Tourneville in the early 18th century. Cacti, both purely ornamental species and those with edible fruit, continued to arrive in Europe, so Carl Linnaeus was able to name 22 species by 1753. One of these, his \"Cactus opuntia\" (now part of \"Opuntia ficus-indica\"), was described as \"\" (with larger fruit ... now in Spain and Portugal), indicative of its early use in Europe.\nFood.\nThe plant now known as \"Opuntia ficus-indica\", or the Indian fig cactus, has long been an important source of food. The original species is thought to have come from central Mexico, although this is now obscure because the indigenous people of southern North America developed and distributed a range of horticultural varieties (cultivars), including forms of the species and hybrids with other opuntias. Both the fruit and pads are eaten, the former often under the Spanish name \"tuna\", the latter under the name \"nopal\". Cultivated forms are often significantly less spiny or even spineless. The nopal industry in Mexico was said to be worth US$150\u00a0million in 2007. The Indian fig cactus was probably already present in the Caribbean when the Spanish arrived, and was soon after brought to Europe. It spread rapidly in the Mediterranean area, both naturally and by being introduced\u2014so much so, early botanists assumed it was native to the area. Outside the Americas, the Indian fig cactus is an important commercial crop in Sicily, Algeria and other North African countries. Fruits of other opuntias are also eaten, generally under the same name, \"tuna\". Flower buds, particularly of \"Cylindropuntia\" species, are also consumed.\nAlmost any fleshy cactus fruit is edible. The word \"pitaya\" or \"pitahaya\" (usually considered to have been taken into Spanish from Haitian creole) can be applied to a range of \"scaly fruit\", particularly those of columnar cacti. The fruit of the saguaro (\"Carnegiea gigantea\") has long been important to the indigenous peoples of northwestern Mexico and the southwestern United States, including the Sonoran Desert. It can be preserved by boiling to produce syrup and by drying. The syrup can also be fermented to produce an alcoholic drink. Fruits of \"Stenocereus\" species have also been important food sources in similar parts of North America; \"Stenocereus queretaroensis\" is cultivated for its fruit. In more tropical southern areas, the climber \"Selenicereus undatus\" provides \"pitahaya orejona\", now widely grown in Asia under the name dragon fruit. Other cacti providing edible fruit include species of \"Echinocereus\", \"Ferocactus\", \"Mammillaria\", \"Myrtillocactus\", \"Pachycereus\", \"Peniocereus\" and \"Selenicereus\". The bodies of cacti other than opuntias are less often eaten, although Anderson reported that \"Neowerdermannia vorwerkii\" is prepared and eaten like potatoes in upland Bolivia.\nPsychoactive agents.\nA number of species of cacti have been shown to contain psychoactive agents, chemical compounds that can cause changes in mood, perception and cognition through their effects on the brain. Two species have a long history of use by the indigenous peoples of the Americas: peyote, \"Lophophora williamsii\", in North America, and the San Pedro cactus, \"Trichocereus macrogonus\" var. \"pachanoi\", in South America. Both contain mescaline.\n\"L. williamsii\" is native to northern Mexico and southern Texas. Individual stems are about high with a diameter of , and may be found in clumps up to wide. A large part of the stem is usually below ground. Mescaline is concentrated in the photosynthetic portion of the stem above ground. The center of the stem, which contains the growing point (the apical meristem), is sunken. Experienced collectors of peyote remove a thin slice from the top of the plant, leaving the growing point intact, thus allowing the plant to regenerate. Evidence indicates peyote was in use more than 5,500 years ago; dried peyote buttons presumed to be from a site on the Rio Grande, Texas, were radiocarbon dated to around 3780\u20133660 BC. Peyote is perceived as a means of accessing the spirit world. Attempts by the Roman Catholic church to suppress its use after the Spanish conquest were largely unsuccessful, and by the middle of the 20th century, peyote was more widely used than ever by indigenous peoples as far north as Canada. It is now used formally by the Native American Church.\n\"Trichocereus macrogonus\" var. \"pachanoi\" (syn. \"Echinopsis pachanoi\") is native to Ecuador and Peru. It is very different in appearance from \"L.\u00a0williamsii\". It has tall stems, up to high, with a diameter of , which branch from the base, giving the whole plant a shrubby or tree-like appearance. Archaeological evidence of the use of this cactus appears to date back to 2,000\u20132,300 years ago, with carvings and ceramic objects showing columnar cacti. Although church authorities under the Spanish attempted to suppress its use, this failed, as shown by the Christian element in the common name \"San Pedro cactus\"\u2014Saint Peter cactus. Anderson attributes the name to the belief that just as St Peter holds the keys to heaven, the effects of the cactus allow users \"to reach heaven while still on earth.\" It continues to be used for its psychoactive effects, both for spiritual and for healing purposes, often combined with other psychoactive agents, such as \"Datura ferox\" and tobacco. Several other species of \"Echinopsis\", including \"E. peruviana\" and \"E. lageniformis\", also contain mescaline.\nOrnamental plants.\nCacti were cultivated as ornamental plants from the time they were first brought from the New World. By the early 1800s, enthusiasts in Europe had large collections (often including other succulents alongside cacti). Rare plants were sold for very high prices. Suppliers of cacti and other succulents employed collectors to obtain plants from the wild, in addition to growing their own. In the late 1800s, collectors turned to orchids, and cacti became less popular, although never disappearing from cultivation.\nCacti are often grown in greenhouses, particularly in regions unsuited to the cultivation of cacti outdoors, such the northern parts of Europe and North America. Here, they may be kept in pots or grown in the ground. Cacti are also grown as houseplants, many being tolerant of the often dry atmosphere. Cacti in pots may be placed outside in the summer to ornament gardens or patios, and then kept under cover during the winter. Less drought-resistant epiphytes, such as epiphyllum hybrids, \"Schlumbergera\" (the Thanksgiving or Christmas cactus) and \"Hatiora\" (the Easter cactus), are widely cultivated as houseplants.\nCacti may also be planted outdoors in regions with suitable climates. Concern for water conservation in arid regions has led to the promotion of gardens requiring less watering (xeriscaping). For example, in California, the East Bay Municipal Utility District sponsored the publication of a book on plants and landscapes for summer-dry climates. Cacti are one group of drought-resistant plants recommended for dry landscape gardening.\nOther uses.\nCacti have many other uses. They are used for human food and as fodder for animals, usually after burning off their spines. In addition to their use as psychoactive agents, some cacti are employed in herbal medicine. The practice of using various species of \"Opuntia\" in this way has spread from the Americas, where they naturally occur, to other regions where they grow, such as India.\nCochineal is a red dye produced by a scale insect that lives on species of \"Opuntia\". Long used by the peoples of Central and North America, demand fell rapidly when European manufacturers began to produce synthetic dyes in the middle of the 19th century. Commercial production has now increased following a rise in demand for natural dyes.\nCacti are used as construction materials. Living cactus fences are employed as barricades around buildings to prevent people breaking in. They also used to corral animals. The woody parts of cacti, such as \"Cereus repandus\" and \"Echinopsis atacamensis\", are used in buildings and in furniture. The frames of wattle and daub houses built by the Seri people of Mexico may use parts of the saguaro (\"Carnegiea gigantea\"). The very fine spines and hairs (trichomes) of some cacti were used as a source of fiber for filling pillows and in weaving.\nConservation.\nAll cacti are included in Appendix II of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), which \"lists species that are not necessarily now threatened with extinction but that may become so unless trade is closely controlled.\" Control is exercised by making international trade in most specimens of cacti illegal unless permits have been issued, at least for exports. Some exceptions are allowed, e.g., for \"naturalized or artificially propagated plants\". Some cacti, such as all \"Ariocarpus\" and \"Discocactus\" species, are included in the more restrictive Appendix I, used for the \"most endangered\" species. These may only be moved between countries for non-commercial purposes, and only then when accompanied by both export and import permits.\nThe three main threats to cacti in the wild are development, grazing and over-collection. Development takes many forms. The construction of a dam near Zimapan, Mexico, caused the destruction of a large part of the natural habitat of \"Echinocactus grusonii\". Urban development and highways have destroyed cactus habitats in parts of Mexico, New Mexico and Arizona, including the Sonoran Desert. The conversion of land to agriculture has affected populations of \"Ariocarpus kotschoubeyanus\" in Mexico, where dry plains were plowed for maize cultivation, and of \"Copiapoa\" and \"Eulychnia\" in Chile, where valley slopes were planted with vines. Grazing, in many areas by introduced animals, such as goats, has caused serious damage to populations of cacti (as well as other plants); two examples cited by Anderson are the Gal\u00e1pagos Islands generally and the effect on \"Browningia candelaris\" in Peru. Over-collection of cacti for sale has greatly affected some species. For example, the type locality of \"Pelecyphora strobiliformis\" near Miquihuana, Mexico, was virtually denuded of plants, which were dug up for sale in Europe. Illegal collecting of cacti from the wild continues to pose a threat.\nConservation of cacti can be \"in situ\" or \"ex situ\". \"In situ\" conservation involves preserving habits through enforcement of legal protection and the creation of specially protected areas such as national parks and reserves. Examples of such protected areas in the United States include Big Bend National Park, Texas; Joshua Tree National Park, California; and Saguaro National Park, Arizona. Latin American examples include Parque Nacional del Pinacate, Sonora, Mexico and Pan de Az\u00facar National Park, Chile. \"Ex situ\" conservation aims to preserve plants and seeds outside their natural habitats, often with the intention of later reintroduction. Botanical gardens play an important role in \"ex situ\" conservation; for example, seeds of cacti and other succulents are kept in long-term storage at the Desert Botanical Garden, Arizona.\nCultivation.\nThe popularity of cacti means many books are devoted to their cultivation. Cacti naturally occur in a wide range of habitats and are then grown in many countries with different climates, so precisely replicating the conditions in which a species normally grows is usually not practical. A broad distinction can be made between semidesert cacti and epiphytic cacti, which need different conditions and are best grown separately. This section is primarily concerned with the cultivation of semidesert cacti in containers and under protection, such as in a greenhouse or in the home, rather than cultivation outside in the ground in those climates that permit it. For the cultivation of epiphytic cacti, see Cultivation of \"Schlumbergera\" (Christmas or Thanksgiving cacti), and Cultivation of epiphyllum hybrids.\nGrowing medium.\nThe purpose of the growing medium is to provide support and to store water, oxygen and dissolved minerals to feed the plant. In the case of cacti, there is general agreement that an open medium with a high air content is important. When cacti are grown in containers, recommendations as to how this should be achieved vary greatly; Miles Anderson says that if asked to describe a perfect growing medium, \"ten growers would give 20 different answers\". Roger Brown suggests a mixture of two parts commercial soilless growing medium, one part hydroponic clay and one part coarse pumice or perlite, with the addition of soil from earthworm castings. The general recommendation of 25\u201375% organic-based material, the rest being inorganic such as pumice, perlite or grit, is supported by other sources. However, the use of organic material is rejected altogether by others; Hecht says that cacti (other than epiphytes) \"want soil that is low in or free of humus\", and recommends coarse sand as the basis of a growing medium.\nWatering.\nSemi-desert cacti need careful watering. General advice is hard to give, since the frequency of watering required depends on where the cacti are being grown, the nature of the growing medium, and the original habitat of the cacti. Brown says that more cacti are lost through the \"untimely application of water than for any other reason\" and that even during the dormant winter season, cacti need some water. Other sources say that water can be withheld during winter (November to March in the Northern Hemisphere). Another issue is the hardness of the water; where it is necessary to use hard water, regular re-potting is recommended to avoid the build up of salts. The general advice given is that during the growing season, cacti should be allowed to dry out between thorough waterings. A water meter can help in determining when the soil is dry.\nLight and temperature.\nAlthough semi-desert cacti may be exposed to high light levels in the wild, they may still need some shading when subjected to the higher light levels and temperatures of a greenhouse in summer. Allowing the temperature to rise above is not recommended. The minimum winter temperature required depends very much on the species of cactus involved. For a mixed collection, a minimum temperature of between and is often suggested, except for cold-sensitive genera such as \"Melocactus\" and \"Discocactus\". Some cacti, particularly those from the high Andes, are fully frost-hardy when kept dry (e.g. \"Rebutia minuscula\" survives temperatures down to in cultivation) and may flower better when exposed to a period of cold.\nPropagation.\nCacti can be propagated by seed, cuttings or grafting. Seed sown early in the year produces seedlings that benefit from a longer growing period. Seed is sown in a moist growing medium and then kept in a covered environment, until 7\u201310 days after germination, to avoid drying out. A very wet growing medium can cause both seeds and seedlings to rot. A temperature range of is suggested for germination; soil temperatures of around promote the best root growth. Low light levels are sufficient during germination, but afterwards semi-desert cacti need higher light levels to produce strong growth, although acclimatization is needed to conditions in a greenhouse, such as higher temperatures and strong sunlight.\nReproduction by cuttings makes use of parts of a plant that can grow roots. Some cacti produce \"pads\" or \"joints\" that can be detached or cleanly cut off. Other cacti produce offsets that can be removed. Otherwise, stem cuttings can be made, ideally from relatively new growth. It is recommended that any cut surfaces be allowed to dry for a period of several days to several weeks until a callus forms over the cut surface. Rooting can then take place in an appropriate growing medium at a temperature of around .\nGrafting is used for species difficult to grow well in cultivation or that cannot grow independently, such as some chlorophyll-free forms with white, yellow or red bodies, or some forms that show abnormal growth (e.g., cristate or forms). For the host plant (the stock), growers choose one that grows strongly in cultivation and is compatible with the plant to be propagated: the scion. The grower makes cuts on both stock and scion and joins the two, binding them together while they unite. Various kinds of graft are used\u2014flat grafts, where both scion and stock are of similar diameters, and cleft grafts, where a smaller scion is inserted into a cleft made in the stock.\nCommercially, huge numbers of cacti are produced annually. For example, in 2002 in Korea alone, 49 million plants were propagated, with a value of almost US$9\u00a0million. Most of them (31 million plants) were propagated by grafting.\nPests and diseases.\nA range of pests attack cacti in cultivation. Those that feed on sap include mealybugs, living on both stems and roots; scale insects, generally only found on stems; whiteflies, which are said to be an \"infrequent\" pest of cacti; red spider mites, which are very small but can occur in large numbers, constructing a fine web around themselves and badly marking the cactus via their sap sucking, even if they do not kill it; and thrips, which particularly attack flowers. Some of these pests are resistant to many insecticides, although there are biological controls available. Roots of cacti can be eaten by the larvae of sciarid flies and fungus gnats. Slugs and snails also eat cacti.\nFungi, bacteria and viruses attack cacti, the first two particularly when plants are over-watered. Fusarium rot can gain entry through a wound and cause rotting accompanied by red-violet mold. \"\"Helminosporium\" rot\" is caused by \"Bipolaris cactivora\" ( \"Helminosporium cactivorum\"); \"Phytophthora\" species also cause similar rotting in cacti. Fungicides may be of limited value in combating these diseases. Several viruses have been found in cacti, including cactus virus X. These appear to cause only limited visible symptoms, such as chlorotic (pale green) spots and mosaic effects (streaks and patches of paler color). However, in an \"Agave\" species, cactus virus X has been shown to reduce growth, particularly when the roots are dry. There are no treatments for virus diseases."}
{"id": "7820", "revid": "43912531", "url": "https://en.wikipedia.org/wiki?curid=7820", "title": "CCC", "text": "CCC may refer to:"}
{"id": "7821", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7821", "title": "Civilian Conservation Corps", "text": "The Civilian Conservation Corps (CCC) was a voluntary government work relief program that ran from 1933 to 1942 in the United States for unemployed, unmarried men ages 18\u201325 and eventually expanded to ages 17\u201328. The CCC was a major part of President Franklin D. Roosevelt's New Deal that supplied manual labor jobs related to the conservation and development of natural resources in rural lands owned by federal, state, and local governments. The CCC was designed to supply jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States. There was eventually a smaller counterpart program for unemployed women called the She-She-She Camps, which were championed by Eleanor Roosevelt.\nRobert Fechner was the first director of this agency, succeeded by James McEntee following Fechner's death. The largest enrollment at any one time was 300,000. Through the course of its nine years in operation, three million young men took part in the CCC, which provided them with shelter, clothing, and food, together with a monthly wage of $30 (), $25 of which () had to be sent home to their families.\nThe American public made the CCC the most popular of all the New Deal programs. Sources written at the time claimed an individual's enrollment in the CCC led to improved physical condition, heightened morale, and increased employability. The CCC also led to a greater public awareness and appreciation of the outdoors and the nation's natural resources, and the continued need for a carefully planned, comprehensive national program for the protection and development of natural resources.\nThe CCC operated separate programs for veterans and Native Americans. Approximately 15,000 Native Americans took part in the program, helping them weather the Great Depression.\nBy 1942, with World War II raging and the draft in effect, the need for work relief declined, and Congress voted to close the program.\nFounding.\nAs governor of New York, Franklin D. Roosevelt had run a similar program on a much smaller scale, known as the Temporary Emergency Relief Administration (TERA). It was started in early 1932 to \"use men from the lists of the unemployed to improve our existing reforestation areas.\" In its first year alone, more than 25,000 unemployed New Yorkers were active in its paid conservation work. Long interested in conservation, as president Roosevelt proposed a full-scale national program to Congress on March 21, 1933:\nHe promised this law would provide 250,000 young men with meals, housing, workwear, and medical care in exchange for their work in the national forests and other government properties. The Emergency Conservation Work (ECW) Act was introduced to Congress the same day and enacted by voice vote on March 31. Roosevelt issued Executive Order 6101 on April 5, 1933, which established the CCC organization and appointed a director, Robert Fechner, a former labor union official who served until 1939. The organization and administration of the CCC was a new experiment in operations for a federal government agency. The order directed that the program be supervised jointly by four government departments: Labor, which recruited the young men; War, which operated the camps; the Agriculture; and Interior, which organized and supervised the work projects. A CCC Advisory Council was composed of a representative from each of those departments. In addition, the Office of Education and Veterans Administration participated in the program. To overcome opposition from labor unions, which wanted no training programs started when so many of their members were unemployed, Roosevelt chose Robert Fechner, vice president of the International Association of Machinists and Aerospace Workers, as director of the Corps. William Green, head of the American Federation of Labor, was taken to the first camp to see that there was no job training involved beyond simple manual labor.\nU.S. Army.\nOfficers from the U.S. Army were in charge of the camps, but there was no military training. The Chief of Staff of the United States Army, General Douglas MacArthur, was placed in charge of the program. Initially, about 3,800 of the Regular Army's 13,000 officers and 4,600 of its 120,000 enlisted men were assigned in the spring of 1933 to administer the CCC. The troops were pulled from just about every source possible, but usually from the Army\u2019s combat regiments and battalions, and Army instructors on duty with ROTC, Organized Reserve, and National Guard organizations. In at least one case each, district personnel were drawn from an engineer regiment and an Air Corps group. MacArthur soon said that the number of Regular Army personnel assigned to the CCC was affecting military readiness. \nOnly 575 Organized Reserve officers initially received orders for CCC duty. CCC tours were initially six months long, but were later lengthened to one year. In July 1933, the War Department ordered that Regular Army officers assigned as instructors with ROTC and Organized Reserve units be returned to their former duties. By the end of September 1933, the number of Regular officers on CCC duty had dropped to about 2,000 and the number of Reservists had increased to 2,200. By June 1934, only 400 Regular officers remained on CCC duty, and by October, Reserve officers had assumed command of almost all CCC companies and sub-districts. Effective on 1 January 1938, the War Department limited the number of Regular officers assigned to CCC duty to only 117. \nDue to a ruling that Reserve officers on CCC duty had to have the same housing and subsistence benefits as Regular officers, President Roosevelt directed that all Reservists be relieved from CCC duty effective 1 July 1939. The changeover was complete by September 1939, but it was a change largely in name only because many of the Reservists merely took off their uniforms and continued their jobs with the CCC as civilians, albeit with lower pay.\nThe Army found numerous benefits in the program. Through the CCC, the Regular Army could assess the leadership performance of both Regular and Reserve officers. In mobilizing, clothing, feeding, and controlling thousands of men, the CCC provided lessons which the Army used in developing its wartime mobilization plans for training camps. When the draft began in 1940, the policy was to make CCC alumni corporals and sergeants. The CCC also provided command experience to Reserve officers, who normally interacted almost exclusively with other officers during training and did not have the chance to lead large numbers of enlisted men. Future Chief of Staff of the Army General George C. Marshall \"embraced\" the CCC, unlike many of his brother officers.\nHistory.\nAn implicit goal of the CCC was to restore morale in an era of 25% unemployment for all men and much higher rates for poorly educated teenagers. Jeffrey Suzik argues in \"'Building Better Men':\nThe CCC Boy and the Changing Social Ideal of Manliness\" that the CCC provided an ideology of manly outdoor work to counter the Depression, as well as cash to help the family budget. Through a regime of heavy manual labor, civic and political education, and an all-male living and working environment, the CCC tried to build \"better men\" who would be economically independent and self-reliant. By 1939, there was a shift in the ideal from the hardy manual worker to the highly trained citizen soldier ready for war.\nEarly years, 1933\u20131937.\nThe legislation and mobilization of the program occurred quite rapidly. Roosevelt made his request to Congress on March 21, 1933; the legislation was submitted to Congress the same day; Congress passed it by voice vote on March 31; Roosevelt signed it the same day, then issued an executive order on April 5 creating the agency, appointing Fechner its director, and assigning War Department corps area commanders to begin enrollment. The first CCC enrollee was selected April 8, and lists of unemployed men were subsequently supplied by state and local welfare and relief agencies for immediate enrollment. On April 17, the first camp, NF-1, Camp Roosevelt, was established at George Washington National Forest near Luray, Virginia. On June 18, the first of 161 soil erosion control camps was opened in Clayton, Alabama. By July 1, 1933, there were 1,463 working camps with 250,000 junior enrollees 18\u201325 years of age; 28,000 veterans; 14,000 Native Americans; and 25,000 adults in the Local Experienced Men (LEM) program.\nEnrollees.\nThe typical CCC enrollee was a U.S. citizen, unmarried, unemployed male, 18\u201325 years of age. Normally his family was on local relief. Each enrollee volunteered and, upon passing a physical exam and/or a period of conditioning, was required to serve a minimum six-month period, with the option to serve as many as four periods, or up to two years if employment outside the Corps was not possible. Enrollees worked 40 hours per week over five days, sometimes including Saturdays if poor weather dictated. In return they received $30 per month () with a compulsory allotment of $25 (about ) sent to a family dependent, as well as housing, food, clothing, and medical care.\nVeterans Conservation Corps.\nFollowing the second Bonus Army march on Washington, D.C., President Roosevelt amended the CCC program on May 11, 1933, to include work opportunities for veterans. Veteran qualifications differed from the junior enrollee; one needed to be certified by the Veterans Administration by an application. They could be any age, and married or single as long as they were in need of work. Veterans were generally assigned to entire veteran camps. Enrollees were eligible for the following \"rated\" positions to help with camp administration: senior leader, mess steward, storekeeper and two cooks; assistant leader, company clerk, assistant educational advisor and three second cooks. These men received additional pay ranging from $36 to $45 per month depending on their rating.\nCamps.\nEach CCC camp was located in the area of particular conservation work to be performed and organized around a complement of up to 200 civilian enrollees in a designated numbered \"company\" unit. The CCC camp was a temporary community in itself, structured to have barracks (initially Army tents) for 50 enrollees each, officer/technical staff quarters, medical dispensary, mess hall, recreation hall, educational building, lavatory and showers, technical/administrative offices, tool room/blacksmith shop and motor pool garages.\nThe company organization of each camp had a dual-authority supervisory staff: firstly, Department of War personnel or Reserve officers (until July 1, 1939), a \"company commander\" and junior officer, who were responsible for overall camp operation, logistics, education and training; and secondly, ten to fourteen technical service civilians, including a camp \"superintendent\" and \"foreman\", employed by either the Departments of Interior or Agriculture, responsible for the particular fieldwork. Also included in camp operation were several non-technical supervisor LEMs, who provided knowledge of the work at hand, \"lay of the land,\" and paternal guidance for inexperienced enrollees. Enrollees were organized into work detail units called \"sections\" of 25 men each, according to the barracks they resided in. Each section had an enrollee \"senior leader\" and \"assistant leader\" who were accountable for the men at work and in the barracks.\nWork classifications.\nThe CCC performed 300 types of work projects in nine approved general classifications:\nThe responses to this seven-month experimental conservation program were enthusiastic. On October 1, 1933, Director Fechner was directed to arrange for the second period of enrollment. By January 1934, 300,000 men were enrolled. In July 1934, this cap was increased by 50,000 to include men from Midwest states that had been affected by drought. The temporary tent camps had also developed to include wooden barracks. An education program had been established, emphasizing job training and literacy.\nApproximately 55% of enrollees were from rural communities, a majority of which were non-farm; 45% came from urban areas. Level of education for the enrollee averaged 3% illiterate; 38% had less than eight years of school; 48% did not complete high school; and 11% were high school graduates. At the time of entry, 70% of enrollees were malnourished and poorly clothed. Few had work experience beyond occasional odd jobs. Peace was maintained by the threat of \"dishonorable discharge\". \"This is a training station; we're going to leave morally and physically fit to lick 'Old Man Depression,'\" boasted the newsletter, \"Happy Days,\" of a North Carolina camp.\nAfrican American people.\nBecause of the power of conservative Solid South white Democrats in Congress, who insisted on racial segregation, most New Deal programs were racially segregated; African American and white people rarely worked alongside each other. At this time, all the states of the South had passed legislation imposing racial segregation and, since the turn of the century, laws and constitutional provisions that disenfranchised most African Americans; they were excluded from formal politics. Because of discrimination by white officials at the local and state levels, African Americans in the South did not receive as many benefits as white people from New Deal programs.\nIn the first few weeks of operation, CCC camps in the North were integrated. By July 1935, however, all camps in the United States were segregated. Enrollment peaked at the end of 1935, when there were 500,000 men in 2,600 camps in operation in every state. All received equal pay and housing. Black leaders lobbied to secure leadership roles. Adult white men held the major leadership roles in all the camps. Director Fechner refused to appoint Black adults to any supervisory positions except that of education director in the all-Black camps.\nIndian Division.\nThe CCC operated a separate division for members of federally recognized tribes: the \"Indian Emergency Conservation Work Division\" (IECW or CCC-ID). Native men from reservations worked on roads, bridges, clinics, shelters, and other public works near their reservations. Although they were organized as groups classified as camps, no permanent camps were established for Native Americans. Instead, organized groups moved with their families from project to project and were provided with an additional rental allowance. The CCC often provided the only paid work, as many reservations were in remote rural areas. Enrollees had to be between the ages of 17 and 35.\nDuring 1933, about half the male heads of households on the Sioux reservations in South Dakota were employed by the CCC-ID. With grants from the Public Works Administration (PWA), the Indian Division built schools and conducted a road-building program in and around many reservations to improve infrastructure. The mission was to reduce erosion and improve the value of Indian lands. Crews built dams of many types on creeks, then sowed grass on the eroded areas from which the damming material had been taken. They built roads and planted shelter-belts on federal lands. The steady income helped participants regain self-respect, and many used the funds to improve their lives. John Collier, the federal Commissioner of Indian Affairs and Daniel Murphy, the director of the CCC-ID, both based the program on Indian self-rule and the restoration of tribal lands, governments, and cultures. The next year, Congress passed the Indian Reorganization Act of 1934, which ended allotments and helped preserve tribal lands, and encouraged tribes to re-establish self-government.\nCollier said of the CCC-Indian Division, \"no previous undertaking in Indian Service has so largely been the Indians' own undertaking\". Educational programs trained participants in gardening, stock raising, safety, native arts, and some academic subjects. IECW differed from other CCC activities in that it explicitly trained men in skills to be carpenters, truck drivers, radio operators, mechanics, surveyors, and technicians. With the passage of the National Defense Vocational Training Act of 1941, enrollees began participating in defense-oriented training. The government paid for the classes and after students completed courses and passed a competency test, guaranteed automatic employment in defense work. A total of 85,000 Native Americans were enrolled in this training. This proved valuable social capital for the 24,000 alumni who later served in the military and the 40,000 who left the reservations for city jobs supporting the war effort.\nExpansion, 1935\u20131936.\nResponding to public demand to alleviate unemployment, Congress approved the Emergency Relief Appropriation Act of 1935, on April 8, 1935, which included continued funding for the CCC program through March 31, 1937. The age limit was expanded to 17\u201328 to include more men. April 1, 1935, to March 31, 1936, was the period of greatest activity and work accomplished by the CCC program. Enrollment peaked at 505,782 in about 2,900 camps by August 31, 1935, followed by a reduction to 350,000 enrollees in 2,019 camps by June 30, 1936. During this period the public response to the CCC program was overwhelmingly popular. A Gallup poll of April 18, 1936, asked: \"Are you in favor of the CCC camps?\"; 82% of respondents said \"yes\", including 92% of Democrats and 67% of Republicans.\nChange of purpose, 1937\u20131938.\nOn June 28, 1937, the Civilian Conservation Corps was legally established and transferred from its original designation as the Emergency Conservation Work program. Funding was extended for three more years by Public Law No. 163, 75th Congress, effective July 1, 1937. Congress changed the age limits to 17\u201323 years old and changed the requirement that enrollees be on relief to \"not regularly in attendance at school, or possessing full-time employment.\" The 1937 law mandated the inclusion of vocational and academic training for a minimum of 10 hours per week. Students in school were allowed to enroll during summer vacation. During this period, the CCC forces contributed to disaster relief following 1937 floods in New York, Vermont, and the Ohio and Mississippi river valleys, and response and clean-up after the 1938 hurricane in New England.\nFrom conservation to defense, 1939\u20131940.\nIn 1939 Congress ended the independent status of the CCC, transferring it to the control of the Federal Security Agency. The National Youth Administration, U.S. Employment Service, the Office of Education, and the Works Progress Administration also had some responsibilities. About 5,000 reserve officers serving in the camps were affected, as they were transferred to federal Civil Service, and military ranks and titles were eliminated. Despite the loss of overt military leadership in the camps by July 1940, with war underway in Europe and Asia, the government directed an increasing number of CCC projects to resources for national defense. It developed infrastructure for military training facilities and forest protection. By 1940 the CCC was no longer wholly a relief agency, was rapidly losing its non-military character, and it was becoming a system for work-training, as its ranks had become increasingly younger and inexperienced.\nDecline and disbandment 1941\u20131942.\nAlthough the CCC was probably the most popular New Deal program, it never was authorized as a permanent agency. The program was reduced in scale as the Depression waned and employment opportunities improved. After conscription began in 1940, fewer eligible young men were available. Following the attack on Pearl Harbor in December 1941, the Roosevelt administration directed all federal programs to emphasize the war effort. Most CCC work, except for wildland firefighting, was shifted onto U.S. military bases to help with construction.\nThe CCC disbanded one year earlier than planned, as the 77th United States Congress ceased funding it. Operations were formally concluded at the end of the federal fiscal year on June 30, 1942. The end of the CCC program and closing of the camps involved arrangements to leave the incomplete work projects in the best possible state, the separation of about 1,800 appointed employees, the transfer of CCC property to the War and Navy Departments and other agencies, and the preparation of final accountability records. Liquidation of the CCC was ordered by Congress by the Labor-Federal Security Appropriation Act (56 Stat. 569) on July 2, 1942, and virtually completed on June 30, 1943. Liquidation appropriations for the CCC continued through April 20, 1948.\nSome former CCC sites in good condition were reactivated from 1941 to 1947 as Civilian Public Service camps where conscientious objectors performed \"work of national importance\" as an alternative to military service. Other camps were used to hold Japanese, German and Italian Americans interned under the Western Defense Command's Enemy Alien Control Program, as well as Axis prisoners of war. Most of the Japanese American internment camps were built by the people held there. After the CCC disbanded, the federal agencies responsible for public lands organized their own seasonal fire crews, modeled after the CCC. These have performed a firefighting function formerly done by the CCC and provided the same sort of outdoor work experience for young people. Approximately 47 young men have died while in this line of duty.\nStatues.\nIn several cities where CCC workers worked, statues were erected to commemorate them.\nInspired programs.\nThe CCC program was never officially terminated. Congress provided funding for closing the remaining camps in 1942 with the equipment being reallocated. It became a model for conservation programs that were implemented in the period after World War II. Present-day corps are national, state, and local programs that engage primarily youth and young adults (ages 16\u201325) in community service, training, and educational activities. The nation's approximately 113 corps programs operate in 41 of the 50 states and Washington, D.C. During 2004, they enrolled more than 23,000 young people. The Corps Network, known originally as the National Association of Service and Conservation Corps (NASCC), works to expand and enhance corps-type programs throughout the country. The Corps Network began in 1985 when the nation's first 24 Corps directors banded together to secure an advocate at the federal level and a repository of information on how best to start and manage a corps. Early financial assistance from the Ford, Hewlett and Mott Foundations was critical to establishing the association.\nSimilar active programs in the United States are: the National Civilian Community Corps, part of the AmeriCorps program, a team-based national service program in which young adults ages 18\u201326 spend 10 months working for non-profit and government organizations; and the Civilian Conservation Corps, USA, (CCCUSA) managed by its president, Thomas Hark, in 2016. Hark, his co-founder Mike Rama, currently the Deputy Director of the Corporate Eco Forum (CEF) founded by M. R. Rangaswami, and their team of strategic advisors have reimagined the federal Civilian Conservation Corps program of the 1930s as a private, locally governed, national social franchise. The goal of this recently established CCCUSA is to enroll a million young people annually, building a core set of values in each enrollee, who will then become the catalyst in their own communities and states to create a more civil society and stronger nation.\nStudent Conservation Association.\nThe CCC program became a model for the creation of team-based national service youth conservation programs such as the Student Conservation Association (SCA). The SCA, founded in 1959, is a nonprofit organization that offers conservation internships and summer trail crew opportunities to more than 4,000 people each year.\nCalifornia Conservation Corps.\nIn 1976, Governor of California Jerry Brown established the California Conservation Corps. This program had many similar characteristics - residential centers, high expectations for participation, and emphasis on hard work on public lands. Young adults from different backgrounds were recruited for a term of one year. Corps members attended a training session called the Corpsmember Orientation Motivation Education and Training (COMET) program before being assigned to one of the various centers. Project work is also similar to the original CCC of the 1930s - work on public forests, state and federal parks.\nNevada Conservation Corps.\nThe Nevada Conservation Corps is a non-profit organization that partners with public land management agencies such as the Bureau of Land Management, United States Forest Service, National Park Service, and Nevada State Parks to complete conservation and restoration projects throughout Nevada. Conservation work includes fuel reductions through thinning, constructing and maintaining trails, invasive species removal, and performing biological surveys. The Nevada Conservation Corps was created through the Great Basin Institute and is part of the AmeriCorps program.\nMinnesota Conservation Corps.\nConservation Corps Minnesota &amp; Iowa provides environmental stewardship and service-learning opportunities to youth and young adults while accomplishing conservation, natural resource management projects and emergency response work through its Young Adult Program and the Summer Youth Program. These programs emphasize the development of job and life skills by conservation and community service work.\nMontana Conservation Corps.\nThe Montana Conservation Corps (MCC) is a non-profit organization with a mission to equip young people with the skills and values to be vigorous citizens who improve their communities and environment. Collectively, MCC crews contribute more than 90,000 work hours each year. The MCC was established in 1991 by Montana's Human Resource Development Councils in Billings, Bozeman and Kalispell. Originally, it was a summer program for disadvantaged youth, although it has grown into an AmeriCorps-sponsored non-profit organization with six regional offices that serve Montana, Idaho, Wyoming, North Dakota, and South Dakota. All regions also offer Montana YES (Youth Engaged in Service) summer programs for teenagers who are 14 to 17 years old.\nTexas Conservation Corps.\nEstablished in 1995, Environmental Corps, now Texas Conservation Corps (TxCC), is an American YouthWorks program which allows youth, ages 17 to 28, to contribute to the restoration and preservation of parks and public lands in Texas. The only conservation corps in Texas, TxcC is a nonprofit corporation based in Austin, Texas, which serves the entire state. Their work ranges from disaster relief to trail building to habitat restoration. TxCC has done projects in national, state, and city parks.\nWashington Conservation Corps.\nThe Washington Conservation Corps (WCC) is a sub-agency of the Washington State Department of Ecology. It employs men and women 18 to 25 years old in a program to protect and enhance Washington's natural resources. WCC is a part of the AmeriCorps program.\nVermont Youth Conservation Corps.\nThe Vermont Youth Conservation Corps (VYCC) is a non-profit, youth service and education organization that hires Corps Members, aged 16\u201324, to work on high-priority conservation projects in Vermont. Through these work projects, Corps Members develop a strong work ethic, strengthen their leadership skills, and learn how to take personal responsibility for their actions. VYCC Crews work at VT State Parks, U.S. Forest Service Campgrounds, in local communities, and throughout the state's backcountry. The VYCC has also given aid to a similar program in North Carolina, which is currently in its infancy.\nYouth Conservation Corps.\nThe Youth Conservation Corps is a youth conservation program present in federal lands around the country. The program gives youth aged 13\u201317 the opportunity to participate in conservation projects in a team setting. YCC programs are available in land managed by the National Park Service, the Forest Service, and the Fish and Wildlife Service. Projects can last up to 10 weeks and typically run over the summer. Some YCC programs are residential, meaning the participants are given housing on the land they work on. Projects may necessitate youth to camp in backcountry settings in order to work on trails or campsites. Most require youth to commute daily or house youth for only a few days a week. Youth are typically paid for their work. YCC programs contribute to the maintenance of public lands and instill a value for hard work and the outdoors in those who participate.\nConservation Legacy.\nConservation Legacy is a non-profit employment, job training, and education organization with locations across the United States including Arizona Conservation Corps in Tucson and Flagstaff, Arizona; Conservation Corps New Mexico in Las Cruces, New Mexico; Southwest Conservation Corps in Durango and Salida, Colorado; and Southeast Conservation Corps in Chattanooga, Tennessee. Conservation Legacy also operates an AmeriCorps VISTA team serving to improve the environment and economies of historic mining communities in the American West and Appalachia. Conservation Legacy also hosts the Environmental Stewards Program - providing internships with federal, state, municipal and NGO land management agencies nationwide. Conservation Legacy formed as a merger of the Southwest Youth Corps, San Luis Valley Youth Corps, The Youth Corps of Southern Arizona, and Coconino Rural Environmental Corps.\nConservation Legacy engages young adults ages 14 to 26 and U.S. military veterans of all ages in personal and professional development experiences involving conservation projects on public lands. Corp members live, work, and learn in teams of six to eight for terms of service ranging from 3 months to 1 year.\nSea Ranger Service.\nThe Sea Ranger Service is a social enterprise, based in Netherlands, that has taken its inspiration from the Civilian Conservation Corps in running a permanent youth training program, supported by veterans, to manage ocean areas and carry out underwater landscape restoration. Unemployed youths are trained up as Sea Rangers during a bootcamp and subsequently offered full-time employment to manage and regenerate Marine Protected Areas and aid ocean conservation. The Sea Ranger Service works in close cooperation with the Dutch government and national maritime authorities.\nAina Corps.\nThe Aina Corps performed environmental restoration work in Hawaii in 2020, funded by the CARES Act.\nAmerican Climate Corps.\nThe American Climate Corps is an organization created by the Joe Biden administration. It was inspired by the Civilian Conservation Corps and aims to mobilize young people to stop climate change, while giving them a job at the same time. It is financed from the Inflation Reduction Act and the federal budget. It should have 9,000 members by the end of June 2024. Later, the number of participants should rise to 20,000."}
{"id": "7822", "revid": "1544984", "url": "https://en.wikipedia.org/wiki?curid=7822", "title": "Caribbean Sea", "text": "The Caribbean Sea is a sea of the North Atlantic Ocean in the tropics of the Western Hemisphere, located south of the Gulf of Mexico and southwest of the Sargasso Sea. It is bounded by the Greater Antilles to the north from Cuba to Puerto Rico, the Lesser Antilles to the east from the Virgin Islands to Trinidad and Tobago, South America to the south from the Venezuelan coastline to the Colombian coastline, and Central America and the Yucat\u00e1n Peninsula to the west from Panama to Mexico. The geopolitical region around the Caribbean Sea, including the numerous islands of the West Indies and adjacent coastal areas in the mainland of the Americas, is known as the Caribbean.\nThe Caribbean Sea is one of the largest seas on Earth and has an area of about . The sea's deepest point is the Cayman Trough, between the Cayman Islands and Jamaica, at below sea level. The Caribbean coastline has many gulfs and bays: the Gulf of Gon\u00e2ve, the Gulf of Venezuela, the Gulf of Dari\u00e9n, Golfo de los Mosquitos, the Gulf of Paria and the Gulf of Honduras.\nThe Caribbean Sea has the world's second-largest barrier reef, the Mesoamerican Barrier Reef. It runs along the Mexico, Belize, Guatemala, and Honduras coasts.\nHistory.\nThe name \"Caribbean\" derives from the Caribs, one of the region's dominant native people at the time of European contact during the late-15th century. After Christopher Columbus landed in The Bahamas in 1492 and later discovered some of the islands in the Caribbean, the Spanish term \"Antillas\" applied to the lands; stemming from this, the \"Sea of the Antilles\" became a common alternative name for the \"Caribbean Sea\" in various European languages. Spanish dominance in the region remained undisputed during the first century of European colonization.\nFrom the 16th century, Europeans visiting the Caribbean region distinguished the \"South Sea\" (the Pacific Ocean south of the isthmus of Panama) from the \"North Sea\" (the Caribbean Sea north of the same isthmus).\nThe Caribbean Sea had been unknown to the populations of Eurasia until after 1492, when Christopher Columbus sailed into Caribbean waters to find a sea route to Asia. At that time, the Americas were generally unknown to most Europeans, although they had been visited in the 10th century by the Vikings. After Columbus's discovery of the islands, the area was quickly colonized by several Western cultures (initially Spain, then later England, the Dutch Republic, France, Courland and Denmark). After colonization of the Caribbean islands, the Caribbean Sea became a busy area for European-based marine trading and transports. The commerce eventually attracted pirates such as Samuel Bellamy and Blackbeard.\n the area is home to 22 island territories and borders 12 continental countries.\nExtent.\nThe International Hydrographic Organization defines the limits of the Caribbean Sea as follows:\nAlthough Trinidad and Tobago and Barbados are on the same continental shelf, they are considered to be in the Atlantic Ocean rather than in the Caribbean Sea.\nGeology.\nThe Caribbean Sea is an oceanic sea on the Caribbean Plate. The Caribbean Sea is separated from the ocean by several island arcs of various ages. The youngest stretches from the Lesser Antilles to the Virgin Islands to north of Trinidad and Tobago, which is in the Atlantic. This arc was formed by a collision of the South American Plate with the Caribbean Plate. It included active and extinct volcanoes such as Mount Pelee, the Quill on Sint Eustatius in the Caribbean Netherlands, La Soufri\u00e8re in Saint Vincent and the Grenadines and Morne Trois Pitons on Dominica. The larger islands in the northern part of the sea Cuba, Hispaniola, Jamaica and Puerto Rico lie on an older island arc.\nThe geological age of the Caribbean Sea is estimated to be 160 million to 180\u00a0million years and was formed by a horizontal fracture called Pangaea that split the supercontinent in the Mesozoic Era. It is assumed the proto-Caribbean basin existed in the Devonian period and, in the early Carboniferous movement of Gondwana to the north and its convergence with the Euramerica basin, decreased in size. The next stage of the Caribbean Sea's formation began in the Triassic. Powerful rifting led to the formation of narrow troughs, stretching from modern Newfoundland to the Gulf of Mexico's west coast, forming siliciclastic sedimentary rocks. In the early Jurassic due to powerful marine transgression, water broke into the current area of the Gulf of Mexico, creating a vast shallow pool. Deep basins emerged in the Caribbean during the Middle Jurassic rifting. The emergence of the basins marked the beginning of the Atlantic Ocean and contributed to the destruction of Pangaea at the end of the late Jurassic. During the Cretaceous, the Caribbean acquired a shape close to today's. In the early Paleogene, due to marine regression, the Caribbean became separated from the Gulf of Mexico and the Atlantic Ocean by the lands of Cuba and Haiti. The Caribbean remained like this for most of the Cenozoic until the Holocene, when rising water levels of the oceans restored communication with the Atlantic Ocean.\nThe Caribbean's floor is composed of suboceanic sediments of deep red clay in the deep basins and troughs. On continental slopes and ridges, calcareous silts are found. Clay minerals have likely been deposited by the mainland river Orinoco and the Magdalena River. Deposits on the bottom of the Caribbean Sea and the Gulf of Mexico have thicknesses of about . Upper sedimentary layers relate to the period from the Mesozoic to the Cenozoic (250 million years ago) and the lower layers from the Paleozoic to the Mesozoic.\nThe Caribbean seafloor is divided into five basins separated from one another by underwater ridges and mountain ranges. Atlantic Ocean water enters the Caribbean through the \"Anegada Passage\" between the Lesser Antilles and the Virgin Islands and the \"Windward Passage\" between Cuba and Haiti. The Yucat\u00e1n Channel between Mexico and Cuba links the Gulf of Mexico with the Caribbean. The deepest points of the sea lie in Cayman Trough, with depths reaching approximately . Despite that, the Caribbean Sea is considered a relatively shallow sea compared with other bodies of water. The pressure of the South American Plate to the east of the Caribbean causes the region of the Lesser Antilles to have high volcanic activity, and a very serious eruption of Mount Pel\u00e9e in 1902 caused many casualties.\nThe Caribbean seafloor is also the home of two oceanic trenches: the Cayman Trench and the Puerto Rico Trench, which put the area at a high risk of earthquakes. Underwater earthquakes pose a threat of generating tsunamis, which could have devastating effects on the Caribbean islands. Scientific data reveals that during the past 500 years, the area has seen a dozen earthquakes above 7.5 magnitude. Most recently, a 7.1-magnitude earthquake struck Haiti, on January 12, 2010.\nOceanography.\nThe hydrology of the sea has a high level of homogeneity. Annual variations in monthly average water temperatures at the surface do not exceed . In the past 50 years, the Caribbean has gone through three stages: cooling until 1974, a cold phase with peaks during 1974\u20131976 and 1984\u20131986, and, finally, a warming phase with an increase in temperature of per year. Virtually all temperature extremes were associated with the phenomena of El Ni\u00f1o and La Ni\u00f1a. The salinity of the seawater is about 3.6%, and its density is . The surface water color is blue-green to green.\nThe Caribbean's depth in its wider basins and deep-water temperatures are similar to those of the Atlantic Ocean. Atlantic deepwater is thought to spill into the Caribbean and contribute to the general deepwater of its sea. The surface water (30\u00a0m; 100\u00a0ft) acts as an extension of the northern Atlantic as the Guiana Current and part of the North Equatorial Current enter the sea on the east. On the western side of the sea, the trade winds influence a northerly current, which causes an upwelling and a rich fishery near Yucat\u00e1n.\nEcology.\nThe Caribbean is the home of about 9% of the world's coral reefs, covering about , most of which are located off the Caribbean islands and the Central American coast. Among them, the Belize Barrier Reef stands out, with an area of , which was declared a World Heritage Site in 1996. It forms part of the Great Mayan Reef (also known as the MBRS) and, being more than in length, is the world's second longest. It runs along the Caribbean coasts of Mexico, Belize, Guatemala and Honduras.\nSince 2005, unusually warm Caribbean waters have been increasingly threatening the coral reefs. Coral reefs support some of the most diverse marine habitats in the world, but they are fragile ecosystems. When tropical waters become unusually warm for extended periods of time, microscopic plants called zooxanthellae, which are symbiotic partners living within the coral polyp tissues, die off. These plants provide food for the corals and give them their color. The result of the death and dispersal of these tiny plants is called coral bleaching and can lead to the devastation of large areas of reef. More than 42% of corals are completely bleached, and 95% are experiencing some type of whitening. Historically, the Caribbean is thought to contain 14% of the world's coral reefs.\nThe habitats supported by the reefs are critical to such tourist activities as fishing and scuba diving, and they provide an annual economic value to Caribbean nations of US$3.1\u20134.6\u00a0billion. Continued destruction of the reefs could severely damage the region's economy. The \"Convention for the Protection and Development of the Marine Environment of the Wider Caribbean Region\" came into effect in 1986 to protect the various endangered marine life of the Caribbean by forbidding human activities that would advance the continued destruction of such marine life in various areas. Currently, the convention has been ratified by 15 countries. Also, several charitable organizations have been formed to preserve Caribbean marine life, such as Sea Turtle Conservancy, which seeks to study and protect sea turtles while educating about them.\nIn connection with the foregoing, the Institute of Marine Sciences and Limnology of the National Autonomous University of Mexico conducted a regional study funded by the Department of Technical Cooperation of the International Atomic Energy Agency, in which specialists from 11 Latin American countries (Colombia, Costa Rica, Cuba, the Dominican Republic, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Panama, and Venezuela) plus Jamaica participated. The study's findings indicate that heavy metals such as mercury, arsenic, and lead have been identified in the coastal zone of the Caribbean Sea. Analysis of toxic metals and hydrocarbons is based on investigation of coastal sediments that have accumulated less than 50 meters deep during the past 150 years. Project results were presented in Vienna at the forum \"Water Matters\", and the 2011 General Conference of that multilateral organization.\nAfter the Mediterranean Sea, the Caribbean Sea is the second-most-polluted sea. Pollution in the form of up to 300,000 tonnes of solid garbage dumped into the Caribbean Sea each year is progressively endangering marine ecosystems, wiping out species, and harming the livelihoods of local people, who rely primarily on tourism and fishing.\nClimate.\nThe climate of the Caribbean is driven by the low latitude and tropical ocean currents that run through it. The principal ocean current is the North Equatorial Current, which enters the region from the tropical Atlantic. The climate of the area is tropical, varying from tropical rainforest in some areas to tropical savanna in others. There are also some locations that are arid climates with considerable drought in some years.\nRainfall varies with elevation, size, and water currents (cool upwelling keep the ABC islands arid). Warm, moist trade winds blow consistently from the east, creating both rainforest and semi-arid climates across the region. The tropical rainforest climates include lowland areas near the Caribbean Sea from Costa Rica north to Belize, as well as the Dominican Republic and Puerto Rico, while the more seasonal dry tropical savanna climates are found in Cuba, northern Venezuela, and southern Yucat\u00e1n, Mexico. Arid climates are found along the extreme northern coast of Venezuela out to the islands including Aruba and Cura\u00e7ao, as well as the northern tip of Yucat\u00e1n\nTropical cyclones are a threat to the nations that rim the Caribbean Sea. While landfalls are infrequent, the resulting loss of life and property damage makes them a significant hazard to life in the Caribbean. Tropical cyclones that impact the Caribbean often develop off the West coast of Africa and make their way west across the Atlantic Ocean toward the Caribbean, while other storms develop in the Caribbean itself. The Caribbean hurricane season as a whole lasts from June through November, with the majority of hurricanes occurring during August and September. On average around nine tropical storms form each year, with five reaching hurricane strength. According to the National Hurricane Center 385 hurricanes occurred in the Caribbean between 1494 and 1900.\nFlora and fauna.\nThe region has a high level of biodiversity and many species are endemic to the Caribbean.\nVegetation.\nThe vegetation of the region is mostly tropical but differences in topography, soil and climatic conditions increase species diversity. Where there are porous limestone terraced islands these are generally poor in nutrients. It is estimated that 13,000 species of plants grow in the Caribbean of which 6,500 are endemic. For example, guaiac wood (\"Guaiacum officinale\"), the flower of which is the national flower of Jamaica and the Bayahibe rose (\"Pereskia quisqueyana\") which is the national flower of the Dominican Republic and the ceiba which is the national tree of both Puerto Rico and Guatemala. The mahogany is the national tree of the Dominican Republic and Belize. The caimito (\"Chrysophyllum cainito\") grows throughout the Caribbean. In coastal zones there are coconut palms and in lagoons and estuaries are found thick areas of black mangrove and red mangrove (\"Rhizophora mangle\").\nIn shallow water flora and fauna is concentrated around coral reefs where there is little variation in water temperature, purity and salinity. Leeward sides of lagoons provide areas of growth for sea grasses. Turtle grass (\"Thalassia testudinum\") is common in the Caribbean as is manatee grass (\"Syringodium filiforme\") which can grow together as well as in fields of single species at depths up to . Another type shoal grass (\"Halodule wrightii\") grows on sand and mud surfaces at depths of up to . In brackish water of harbours and estuaries at depths less than widgeongrass (\"Ruppia maritima\") grows. Representatives of three species belonging to the genus \"Halophila\", (\"Halophila baillonii\", \"Halophila engelmannii\" and \"Halophila decipiens\") are found at depths of up to except for \"Halophila engelmani\" which does not grow below and is confined to the Bahamas, Florida, the Greater Antilles and the western part of the Caribbean. \"Halophila baillonii\" has been found only in the Lesser Antilles.\nFauna.\nMarine biota in the region have representatives of both the Indian and Pacific oceans which were caught in the Caribbean before the emergence of the Isthmus of Panama four million years ago. In the Caribbean Sea there are around 1,000 documented species of fish, including sharks (bull shark, tiger shark, silky shark and Caribbean reef shark), flying fish, giant oceanic manta ray, angel fish, spotfin butterflyfish, parrotfish, Atlantic Goliath grouper, tarpon and moray eels. Throughout the Caribbean there is industrial catching of lobster and sardines (off the coast of Yucat\u00e1n Peninsula).\nThere are 90 species of mammals in the Caribbean including sperm whales, humpback whales and dolphins. The island of Jamaica is home to seals and manatees. The Caribbean monk seal which lived in the Caribbean is considered extinct. Solenodons and hutias are mammals found only in the Caribbean; only one extant species is not endangered.\nThere are 500 species of reptiles (94% of which are endemic). Islands are inhabited by some endemic species such as rock iguanas and American crocodile. The blue iguana, endemic to the island of Grand Cayman, is endangered. The green iguana is invasive to Grand Cayman. The Mona ground iguana which inhabits the island of Mona, Puerto Rico, is endangered. The rhinoceros iguana from the island of Hispaniola which is shared between Haiti and the Dominican Republic is also endangered. The region has several types of sea turtle (loggerhead, green turtle, hawksbill, leatherback turtle, Atlantic ridley and olive ridley). Some species are threatened with extinction. Their populations have been greatly reduced since the 17th century \u2013 the number of green turtles has declined from 91\u00a0million to 300,000 and hawksbill turtles from 11\u00a0million to less than 30,000 by 2006.\nAll 170 of the amphibian species that live in the region are endemic. The habitats of almost all members of the toad family, poison dart frogs, tree frogs and leptodactylidae (a type of frog) are limited to only one island. The golden coqui is in serious threat of extinction.\nIn the Caribbean, 600 species of birds have been recorded, of which 163 are endemic such as todies, Fernandina's flicker and palmchat. The American yellow warbler is found in many areas, as is the green heron. Of the endemic species 48 are threatened with extinction including the Puerto Rican amazon, and the Zapata wren. According to BirdLife International in 2006 in Cuba 29 species of bird were in danger of extinction and two species officially extinct. The black-fronted piping guan is endangered. The Antilles along with Central America lie in the flight path of migrating birds from North America so the size of populations is subject to seasonal fluctuations. Parrots and bananaquits are found in forests. Over the open sea can be seen frigatebirds and tropicbirds.\nEconomy and human activity.\nThe Caribbean region has seen a significant increase in human activity since the colonization period. The sea is one of the largest oil production areas in the world, producing approximately 170\u00a0million per year. The area also generates a large fishing industry for the surrounding countries, accounting for of fish a year.\nHuman activity in the area also accounts for a significant amount of pollution. The Pan American Health Organization estimated in 1993 that only about 10% of the sewage from the Central American and Caribbean Island countries is properly treated before being released into the sea.\nThe region has been famous for its rum production - the drink is first mentioned in records from Barbados in around 1650, although it was likely to have been produced beforehand across the other islands.\nThe Caribbean region supports a large tourism industry. The Caribbean Tourism Organization calculates that about 12\u00a0million people a year visit the area, including (in 1991\u20131992) about 8\u00a0million cruise ship tourists. Tourism based upon scuba diving and snorkeling on coral reefs of many Caribbean islands makes a major contribution to their economies."}
{"id": "7824", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=7824", "title": "Colin Maclaurin", "text": "Colin Maclaurin (; ; February 1698\u00a0\u2013 14 June 1746) was a Scottish mathematician who made important contributions to geometry and algebra. He is also known for being a child prodigy and holding the record for being the youngest professor. The Maclaurin series, a special case of the Taylor series, is named after him.\nOwing to changes in orthography since that time (his name was originally rendered as M'Laurine), his surname is alternatively written MacLaurin.\nEarly life.\nMaclaurin was born in Kilmodan, Argyll. His father, John Maclaurin, minister of Glendaruel, died when Maclaurin was in infancy, and his mother died before he reached nine years of age. He was then educated under the care of his uncle, Daniel Maclaurin, minister of Kilfinan. A child prodigy, he entered university at age 11.\nAcademic career.\nAt eleven, Maclaurin, a child prodigy at the time, entered the University of Glasgow. He graduated Master of Arts three years later by defending a thesis on \"the Power of Gravity,\" and remained at Glasgow to study divinity until he was 19, when he was elected professor of mathematics in a ten-day competition at Marischal College and University in Aberdeen. This record as the world's youngest professor endured until March 2008, when the record was officially given to Alia Sabur.\nIn the vacations of 1719 and 1721, Maclaurin went to London, where he became acquainted with Isaac Newton, Benjamin Hoadly, Samuel Clarke, Martin Folkes, and other philosophers. He was admitted as a member of the Royal Society.\nIn 1722, having provided a locum for his class at Aberdeen, he travelled on the Continent as tutor to George Hume, the son of Alexander Hume, 2nd Earl of Marchmont. During their time in Lorraine, he wrote his essay on the percussion of bodies (\"Demonstration des loix du choc des corps\"), which gained the prize of the Royal Academy of Sciences in 1724. Upon the death of his pupil at Montpellier, Maclaurin returned to Aberdeen.\nIn 1725, Maclaurin was appointed deputy to the mathematical professor at the University of Edinburgh, James Gregory (brother of David Gregory and nephew of the esteemed James Gregory), upon the recommendation of Isaac Newton. On 3 November of that year Maclaurin succeeded Gregory, and went on to raise the character of that university as a school of science. Newton was so impressed with Maclaurin that he had offered to pay his salary himself.\nContributions to mathematics.\nMaclaurin used Taylor series to characterize maxima, minima, and points of inflection for infinitely differentiable functions in his \"Treatise of Fluxions\". Maclaurin attributed the series to Brook Taylor, though the series was known before to Newton and Gregory, and in special cases to Madhava of Sangamagrama in fourteenth century India.\nNevertheless, Maclaurin received credit for his use of the series, and the Taylor series expanded around 0 is sometimes known as the \"Maclaurin series\".\nMaclaurin also made significant contributions to the gravitation attraction of ellipsoids, a subject that furthermore attracted the attention of d'Alembert, A.-C. Clairaut, Euler, Laplace, Legendre, Poisson and Gauss. Maclaurin showed that an oblate spheroid was a possible equilibrium in Newton's theory of gravity. The subject continues to be of scientific interest, and Nobel Laureate Subramanyan Chandrasekhar dedicated a chapter of his book \"Ellipsoidal Figures of Equilibrium\" to Maclaurin spheroids. Maclaurin corresponded extensively with Clairaut, Maupertuis, and d'Ortous de Mairan.\nIndependently from Euler and using the same methods, Maclaurin discovered the Euler\u2013Maclaurin formula. He used it to sum powers of arithmetic progressions, derive Stirling's formula, and to derive the Newton\u2013Cotes numerical integration formulas which includes Simpson's rule as a special case.\nMaclaurin contributed to the study of elliptic integrals, reducing many intractable integrals to problems of finding arcs for hyperbolas. His work was continued by d'Alembert and Euler, who gave a more concise approach.\nIn his \"Treatise of Algebra\" (Ch. XII, Sect 86), published in 1748 two years after his death, Maclaurin proved a rule for solving square linear systems in the cases of 2 and 3 unknowns, and discussed the case of 4 unknowns. This publication preceded by two years Cramer's publication of a generalization of the rule to \"n\" unknowns, now commonly known as Cramer's rule.\nPersonal life.\nIn 1733, Maclaurin married Anne Stewart, the daughter of Walter Stewart, the Solicitor General for Scotland, by whom he had seven children. His eldest son John Maclaurin studied law, was a Senator of the College of Justice, and became Lord Dreghorn; he was also joint founder of the Royal Society of Edinburgh.\nMaclaurin actively opposed the Jacobite rising of 1745 and superintended the operations necessary for the defence of Edinburgh against the Highland army. Maclaurin compiled a diary of his exertions against the Jacobites, both within and without the city. When the Highland army entered the city, however, he fled to York, where he was invited to stay by the Archbishop of York.\nOn his journey south, Maclaurin fell from his horse, and the fatigue, anxiety, and cold to which he was exposed on that occasion laid the foundations of dropsy. He returned to Edinburgh after the Jacobite army marched south, but died soon after his return.\nHe is buried at Greyfriars Kirkyard, Edinburgh. The simple table stone is inscribed simply \"C. M. Nat MDCXCVIII Ob MDCCXLVI\" and stands close to the south-west corner of the church but is supplemented by a more wordy memorial on the outer wall of the church.\nThe mathematician and former MIT President Richard Cockburn Maclaurin was from the same family.\nThe Maclaurin Society (MacSoc), the Mathematics and Statistics Society at Glasgow University, is named in his honour.\nColin MacLaurin Road within Edinburgh University's King's Buildings complex is named in his honour.\nNotable works.\nSome of his important works are:\nColin Maclaurin was the name used for the new Mathematics and Actuarial Mathematics and Statistics Building at Heriot-Watt University, Edinburgh."}
{"id": "7825", "revid": "48219523", "url": "https://en.wikipedia.org/wiki?curid=7825", "title": "Celestial globe", "text": "Celestial globes show the apparent positions of the stars in the sky. They omit the Sun, Moon, and planets because the positions of these bodies vary relative to those of the stars, but the ecliptic, along which the Sun moves, is indicated.\nThere is an issue regarding the \"handedness\" of celestial globes. If the globe is constructed so that the stars are in the positions they actually occupy on the imaginary celestial sphere, then the star field will appear reversed on the surface of the globe (all the constellations will appear as their mirror images). This is because the view from Earth, positioned at the centre of the celestial sphere, is of the gnomonic projection inside of the celestial sphere, whereas the celestial globe is orthographic projection as viewed from the outside. For this reason, celestial globes are often produced in mirror image, so that at least the constellations appear as viewed from earth. This ambiguity is famously evident in the astronomical ceiling of New York City's Grand Central Terminal, whose inconsistency was deliberately left uncorrected though it was noticed shortly after installation.\nSome modern celestial globes address this problem by making the surface of the globe transparent. The stars can then be placed in their proper positions and viewed through the globe, so that the view is of the inside of the celestial sphere. However, the proper position from which to view the sphere would be from its centre, but the viewer of a transparent globe must be outside it, far from its centre. Viewing the inside of the sphere from the outside, through its transparent surface, produces serious distortions. Opaque celestial globes that are made with the constellations correctly placed, so they appear as mirror images when directly viewed from outside the globe, are often viewed in a mirror, so the constellations have their familiar appearances. Written material on the globe, e.g., constellation names, is printed in reverse, so it can easily be read in the mirror.\nBefore Copernicus's 16th-century discovery that the solar system is \"heliocentric rather than geocentric and geostatic\" (that the earth orbits the sun and not the other way around) \"the stars have been commonly, though perhaps not universally, perceived as though attached to the inside of a hollow sphere enclosing and rotating about the earth\". Working under the incorrect assumption that the cosmos was geocentric the second-century Greek astronomer Ptolemy composed the Almagest in which \"the movements of the planets could be accurately represented by means of techniques involving the use of epicycles, deferents, eccentrics (whereby planetary motion is conceived as circular with respect to a point displaced from Earth), and equants (a device that posits a constant angular rate of rotation with respect to a point displaced from Earth)\". Guided by these ideas astronomers of the Middle Ages, Muslim and Christian alike, created celestial globes to \"represent in a model the arrangement and movement of the stars\". In their most basic form celestial globes represent the stars as if the viewer were looking down upon the sky as a globe that surrounds the earth.\nHistory.\nAncient Greece.\nThe Roman writer Cicero reported the statements of the Roman astronomer Gaius Sulpicius Gallus of the second century BC, the first globe was constructed by Thales of Miletus. This could indicate that celestial globes were in production throughout antiquity however, without any celestial globes surviving from this time, it is difficult to say for sure. What is known is that in book VIII, chapter 3 of Ptolemy's Almagest he outlines ideas for the design and production of a celestial globe. This includes some notes on how the globe should be decorated, suggesting \u2018the sphere a dark colour resembling the night sky\u2019.\nThe Farnese Atlas, a 2nd-century AD Roman marble sculpture of Atlas which probably copies an earlier work of the Hellenistic era, is holding a celestial globe in diameter, which for many years was the only known celestial globe from the ancient world. No stars are depicted on the globe, but it shows over 40 classical Greek constellations in substantial detail. In the 1990s, two smaller celestial globes from antiquity became public: one from brass measuring held by the R\u00f6misch-Germanisches Zentralmuseum, and one from gilt silver measuring privately held by the Kugel family.\nAl-Sufi's\u00a0\"The Book of Fixed Stars\".\nAbd al-Rahman al-Sufi was an important 10th-century astronomer whose works were instrumental in the Islamic development of the celestial globe. His book, \"The Book of Fixed Stars\", designed for accuracy for the year 964, was a \"description of the constellations that combines Greek/ Ptolemaic traditions with Arabic/Bedouin ones\". \"The Book of Fixed Stars\" then served as an important source of star coordinates for makers of astrolabes and globes across the Islamic world. Similarly, it was \"instrumental in displacing the traditional Bedouin constellation imagery and replacing it with the Greek/Ptolemaic system which ultimately came to dominate all astronomy\".\n11th century.\nThe earliest surviving celestial globe was made between 1080 and 1085 C.E. by Ibrahim ibn Said al-Sahli, a well-known astrolabe maker working in Valencia, Spain. Although the imagery on this globe appears to be unrelated to that in al-Sufi's The Book of the Constellations al-Wazzan does seem to have been aware of this work, as all forty-eight of the classical Greek constellations are illustrated on the globe, just as in al-Sufi's treatise, with the stars indicated by circles.\n13th century.\nIn the 13th century, a celestial globe, now housed in the Mathematisch-Physikalischer Salon in Dresden, was produced at one of the most important centres of astronomy in intellectual history, the Ilkhanid observatory at Maragha in north-western Iran constructed in 1259 and headed by Nasir al-Dln TusT (d. 1274), the renowned polymath. This particular scientific instrument was made by the son of the renowned scientist Mu'ayyad al-'Urdi al-Dimashqi, Muhammad b. Mu'ayyad al-'Urdl in 1288. This globe is an interesting example of how celestial globes demonstrate both the scientific and the artistic talents of those who make them. All forty-eight classical constellations used in Ptolemy's Almagest are represented on the globe, meaning it could then be used in calculations for astronomy and astrology, such as navigation, time-keeping or determining a horoscope.\u00a0Artistically, this globe is an insight into thirteenth century Iranian illustration as the thirteenth century was a period when inlaid brass became a premier medium for figural imagery and so the globes from this period are duly exceptional for the detail and clarity of their engraved figures.\n17th century.\nA 17th-century celestial globe was made by Diya' ad-din Muhammad in Lahore, 1668 (now in Pakistan). It is now housed at the National Museum of Scotland. It is encircled by a meridian ring and a horizon ring. The latitude angle of 32\u00b0 indicates that the globe was made in the Lahore workshop. This specific \"workshop claims 21 signed globes\u2014the largest number from a single shop\" making this globe a good example of celestial globe production at its peak. The globe itself has been manufactured in one piece, so as to be seamless.\nThere are grooves which encircle the surface of the globe that create 12 sections of 30\u00b0 which pass through the ecliptic poles. While they are no longer used in astronomy today, they are called \"ecliptic latitude circles\" and help astronomers of the Arabic and Greek worlds find the co-ordinates of a particular star. Each of the 12 sections corresponds to a house in the zodiac."}
{"id": "7827", "revid": "6278814", "url": "https://en.wikipedia.org/wiki?curid=7827", "title": "Covenant-breaker", "text": "Covenant-breaker is a term used in the Bah\u00e1\u02bc\u00ed Faith to refer to a person who has been excommunicated from the Bah\u00e1\u02bc\u00ed community for breaking the Covenant of Bah\u00e1\u02bcu'll\u00e1h, meaning actively promoting schism in the religion or otherwise opposing the legitimacy of the chain of succession of leadership. Excommunication among Bah\u00e1\u02bc\u00eds is rare and not used for transgressions of community standards, intellectual dissent, or conversion to other religions. Instead, it is the most severe punishment, reserved for suppressing organized dissent that threatens the unity of believers.\nCurrently, the Universal House of Justice has the sole authority to declare a person a Covenant-breaker, and once identified, all Bah\u00e1\u02bc\u00eds are expected to shun them, even if they are family members. According to \u02bbAbdu'l-Bah\u00e1, Covenant-breaking is a contagious disease. The Bah\u00e1\u02bc\u00ed writings forbid association with Covenant-breakers and Bah\u00e1\u02bc\u00eds are urged to avoid their literature, thus providing an exception to the Bah\u00e1\u02bc\u00ed principle of \"independent investigation of truth\". Most Bah\u00e1\u02bc\u00eds are unaware of the small Bah\u00e1\u02bc\u00ed divisions that exist.\nDr. Mikhail Sergeev wrote about the Bah\u00e1\u02bc\u00ed practice of excommunication,\nThe three largest attempts at alternative leadership\u2014whose followers are considered Covenant-breakers\u2014were from Subh-i-Azal, M\u00edrz\u00e1 Muhammad \u02bbAl\u00ed, and Charles Mason Remey. Others were declared Covenant-breakers for actively opposing or disobeying the head of the religion, or maliciously attacking the Bah\u00e1\u02bc\u00ed administration after leaving it.\nDefinition.\nCovenant-breaking does not refer to attacks from non-Bah\u00e1\u02bc\u00eds or former Bah\u00e1\u02bc\u00eds. Rather, it is in reference to internal campaigns of opposition where the Covenant-breaker is seen as challenging the unity of the Bah\u00e1\u02bc\u00ed Faith, causing internal division, or by claiming or supporting an alternate succession of authority or administrative structure. The central purpose of the covenant is to prevent schism and dissension.\nIn a letter to an individual dated 23 March 1975, the Universal House of Justice wrote:\nThe term Covenant-breaker (Arabic: \u0646\u0627\u0642\u0636\u064a\u0646) was first used by \u02bbAbdu'l-Bah\u00e1 during his ministry to describe partisans of his half-brother M\u00edrz\u00e1 Muhammad \u02bbAl\u00ed, who challenged his leadership, although the concept of expulsion from the community of believers and avoidance of contact with them is rooted in the direct instruction and practices of Bah\u00e1\u02bcu'll\u00e1h. In \u02bbAbdu'l-Bah\u00e1's Will and Testament, he appointed Shoghi Effendi as the first \"Guardian\", defined it as an institution, and also called for the election of the Universal House of Justice. \u02bbAbdul-Bah\u00e1 defined in the same manner opposition to these two institutions as Covenant-breaking and advised all Bah\u00e1\u02bc\u00eds to shun anyone opposing the Covenant: \"...one of the greatest and most fundamental principles of the Cause of God is to shun and avoid entirely the Covenant-breakers, for they will utterly destroy the Cause of God, exterminate His Law and render of no account all efforts exerted in the past.\" \nCategorization.\nIncluded categories of people.\nMost Covenant-breakers are involved in schismatic groups, but not always. For example, a Bah\u00e1\u02bc\u00ed who refuses to follow guidance on treatment of Covenant-breakers is at risk of being named one. One article originally written for the Bah\u00e1\u02bc\u00ed Encyclopedia, characterized Covenant-breakers that have emerged in the course of Bah\u00e1\u02bc\u00ed history as belonging to one of four categories:\nExcluded categories of people.\nShoghi Effendi wrote to the National Spiritual Assembly of Canada in 1957:\nBeyond this, many other relationships to the Bah\u00e1\u02bc\u00ed Faith exist, both positive and negative. Covenant-breaking does not apply to most of them. The following is a partial list of those who could not rightly be termed Covenant-breakers:\nB\u00e1b\u00eds.\nB\u00e1b\u00eds are generally regarded as another religion altogether. Since Covenant-breaking presumes that one has submitted oneself to a covenant and then broken it, and B\u00e1b\u00eds never recognized or swore allegiance to Bah\u00e1\u02bcu'll\u00e1h, they are not Covenant-breakers.\nFollowers of Subh-i-Azal, Bah\u00e1\u02bcu'll\u00e1h's half-brother who tried to poison him, engaged in active opposition to Bah\u00e1\u02bc\u00eds, and Shoghi Effendi did inform Bah\u00e1\u02bc\u00eds that they should avoid contact with his descendants, writing that \"No intelligent and loyal Baha'i would associate with a descendant of Azal, if he traced the slightest breath of criticism of our Faith, in any aspect, from that person. In fact these people should be strenuously avoided as having an inherited spiritual disease -- the disease of Covenant-breaking!\".\nShoghi Effendi's immediate family.\nThrough the influence of Bah\u00edyyih Kh\u00e1num, the eldest daughter of Bah\u00e1\u02bcu'll\u00e1h, everyone in the household initially rallied around Shoghi Effendi after the death of \u02bbAbdu'l-Bah\u00e1. For several years his brother Husayn and several cousins served him as secretaries. The only ones publicly opposing him were M\u00edrz\u00e1 Muhammad \u02bbAl\u00ed and his followers, who were declared Covenant-breakers by \u02bbAbdu'l-Bah\u00e1. Contrary to \u02bbAbdu'l-Bah\u00e1's specific instruction, certain family members established illicit links with those whom \u02bbAbdu'l-Bah\u00e1 had declared Covenant-breakers. After Bah\u00edyyih Kh\u00e1num died in 1932, Shoghi Effendi's eldest sister \u2013 Ruhangiz \u2013 married Nayyer Effendi Afnan, a son of Siyyid Ali Afnan, stepson of Bah\u00e1\u02bcu'll\u00e1h though Furughiyyih. The children of Furughiyyih sided with Muhammad \u02bbAl\u00ed and opposed \u02bbAbdu'l-Bah\u00e1, leaving only \u02bbAbdu'l-Bah\u00e1's own children as faithful among the descendants of Bah\u00e1\u02bcu'll\u00e1h. Moojan Momen describes these events as follows:\nThese marriages caused Ruhangiz, Mehrangiz, and Thurayy\u00e1 to be declared Covenant-breakers by Shoghi Effendi, though there was some delay and concealment initially in order to avoid public degradation of the family. On 2 November 1941 Shoghi Effendi sent two cables announcing the expulsion of T\u00fab\u00e1 and her children Ruhi, Suhayl, and Fu'ad for consenting to the marriage of Thurayy\u00e1 to Faydi. There was also mention that Ruhi's visit to America and Fu'ad's visit to England were without approval. In December 1941 he announced the expulsion of his sister Mehrangiz.\nExpulsions.\nIn 1944 Shoghi Effendi announced the expulsion of Munib Shahid, the grandson of \u02bbAbdu'l-Bah\u00e1's through Ruha, for marrying into the family of an enemy of the Bah\u00e1\u02bc\u00eds. In April 1945, he announced the expulsion of Husayn Ali, his brother, for joining the other Covenant-breakers. In a 1950 Shoghi Effendi sent another cable expelling the family of Ruha, another daughter of \u02bbAbdu'l-Bah\u00e1 for showing \"open defiance\", and in December 1951 he announced a \"fourth alliance\" of members of the family of Siyyid Ali marrying into Ruha's family, and that his brother Riaz was included among the Covenant-breakers.\nIn 1953 he cabled about Ruhi Afnan corresponding with Mirza Ahmad Sohrab, selling property of Bah\u00e1\u02bcu'll\u00e1h, and publicly \"misrepresenting the teachings and deliberately causing confusion in minds of authorities and the local population\".\nResultant groups.\nMost of the groups regarded by the larger group of Bah\u00e1\u02bc\u00eds as Covenant-breakers originated in the claims of Charles Mason Remey to the Guardianship in 1960. The \"Will and Testament of \u02bbAbdu'l-Bah\u00e1\" states that Guardians should be lineal descendants of Bah\u00e1\u02bcu'll\u00e1h, that each Guardian must select his successor during his lifetime, and that the nine Hands of the Cause of God permanently stationed in the Holy Land must approve the appointment by majority vote. Bah\u00e1\u02bc\u00eds interpret lineal descendency to mean physical familial relation to Bah\u00e1\u02bcu'll\u00e1h, of which Mason Remey was not.\nAlmost all of Bah\u00e1\u02bc\u00eds accepted the determination of the Hands of the Cause that upon the death of Shoghi Effendi, he died \"without having appointed his successor\". There was an absence of a valid descendant of Bah\u00e1\u02bcu'll\u00e1h who could qualify under the terms of \u02bbAbdu'l-Bah\u00e1's will. Later the Universal House of Justice, initially elected in 1963, made a ruling on the subject that it was not possible for another Guardian to be appointed.\nIn 1960 Remey, a Hand of the Cause himself, retracted his earlier position, and claimed to have been coerced. He claimed to be the successor to Shoghi Effendi. He and the small number of people who followed him were expelled from the mainstream Bah\u00e1\u02bc\u00ed community by the Hands of the Cause. Those close to Remey claimed that he went senile in old age, and by the time of his death he was largely abandoned, with his most prominent followers fighting amongst themselves for leadership.\nThe largest group of the remaining followers of Remey, members of the \"Orthodox Bah\u00e1\u02bc\u00ed Faith\", believe that legitimate authority passed from Shoghi Effendi to Mason Remey to Joel Marangella. They, therefore, regard the Universal House of Justice in Haifa, Israel to be illegitimate, and its members and followers to be Covenant-breakers.\nIn 2009, Jeffery Goldberg and Janice Franco, both from the mainstream Bah\u00e1\u02bc\u00ed community, joined the Orthodox Bah\u00e1\u02bc\u00ed Faith. Both of them were declared as Covenant-breakers and shunned. Goldberg's wife was told to divorce her husband.\nThe present descendants of expelled members of Bah\u00e1\u02bcu'll\u00e1h's family have not specifically been declared Covenant-breakers, though they mostly do not associate themselves with the Bah\u00e1\u02bc\u00ed religion.\nA small group of Bah\u00e1\u02bc\u00eds in Northern New Mexico believe that these descendants are eligible for appointment to the Guardianship and are waiting for such a direct descendant of Bah\u00e1\u02bcu'll\u00e1h to arise as the rightful Guardian.\nEnayatullah (Zabih) Yazdani was designated a Covenant-breaker in June 2005, after many years of insisting on his views that Mason Remey was the legitimate successor to Shoghi Effendi and of accepting Donald Harvey as the third guardian. He is now the fifth guardian of a small group of Bah\u00e1\u02bc\u00eds and resides in Australia.\nThere is also a small group in Montana, originally inspired by Leland Jensen, who claimed a status higher than that of the Guardian. His failed apocalyptic predictions and unsuccessful efforts to reestablish the Guardianship and the administration were apparent by his death in 1996. A dispute among Jensen's followers over the identity of the Guardian resulted in another division in 2001.\nAmerican opposition.\nJuan Cole, an American professor of Middle Eastern history who had been a Bah\u00e1\u02bc\u00ed for 25 years, left the religion in 1996 after being approached by a Continental Counselor about his involvement in a secret email list that was organizing opposition to certain Bah\u00e1\u02bc\u00ed institutions and policies. Cole was never labeled a Covenant-breaker, because he claimed to be a Unitarian-Universalist upon leaving. He went on to publish three papers in journals in 1998, 2000, and 2002. These heavily criticized the Bah\u00e1\u02bc\u00ed administration in the United States and suggested cult-like tendencies, particularly regarding the requirement of pre-publication review and the practice of shunning Covenant-breakers. For example, Cole wrote in 1998, \"Baha\u2019is, like members of The Watchtower and other cults, shun those who are excommunicated.\" In 2000, he wrote: \"Baha'i authorities... keep believers in line by appealing to the welfare and unity of the community, and if these appeals fail then implicit or explicit threats of disfellowshipping and even shunning are invoked. ... Shunning is the central control mechanism in the Baha'i system\" In 2002, he wrote: \"Opportunistic sectarian-minded officials may have seen this... as a time when they could act arbitrarily and harshly against intellectuals and liberals, using summary expulsion and threats of shunning\".\nMoojan Momen, a Bah\u00e1\u02bc\u00ed author, reviewed 66 exit narratives of former Bah\u00e1\u02bc\u00eds, and identified 1996 (Cole's departure) to 2002 as a period of \"articulate and well-educated\" apostates that used the newly available Internet to connect with each other and form a community with its own \"mythology, creed and salvation stories becoming what could perhaps be called an anti-religion\". According to Momen, the narrative among these apostates of a \"fiercely aggressive religion where petty dictators rule\" is the opposite experience of most members, who see \"peace as a central teaching\", \"consultative decision-making\", and \"mechanisms to guard against individuals attacking the central institutions of the Bah\u00e1'\u00ed Faith or creating schisms.\" On the practice of shunning, Momen writes that it is \"rarely used and is only applied after prolonged negotiations fail to resolve the situation. To the best knowledge of the present author it has been used against no more than a handful of individuals in over two decades and to only the first of the apostates described below [Francesco Ficicchia] more than twenty-five years ago - although it is regularly mentioned in the literature produced by the apostates as though it were a frequent occurrence.\""}
{"id": "7828", "revid": "46977059", "url": "https://en.wikipedia.org/wiki?curid=7828", "title": "Concord, Michigan", "text": "Concord is a village in Jackson County in the U.S. state of Michigan. The population was 1,050 at the 2010 census. The village is within Concord Township.\nSettled in 1831, much of the village's downtown area is designated as part of the Concord Village Historic District. The village is located along M-60 about southwest of Jackson.\nHistory.\nConcord first received a post office in 1836. It was incorporated as a village in 1871.\nThe Michigan Historical Center operates a museum in Concord called the Mann House. The Mann House is an excellent example of typical middle-class domestic architecture of the early 1880s and features the family's sleigh and buggy as well as Jackson's Michigan State Prison made furniture.\nGovernment.\nConcord is a general-law village incorporated within the Concord Township.\nGeography.\nAccording to the United States Census Bureau, the village has a total area of , of which is land and (7.41%) is water.\nThe village is located within the T3S R3W survey township.\nDemographics.\nConcord Community Schools (Enrollment 900) participate in Class C and Division 4 of MHSAA athletics. Their teams are known as the Yellow Jackets and play in the Big 8 Conference. The schools' colors are purple and gold. The boys' cross country and track &amp; field teams both claimed MHSAA State Championships during the 2009\u201310 school year, as well as back to back MHSAA State Championships in the 2014 and 2015 school years. In 2011 and 2012, the boys cross country team won back to back MHSAA State Championships.\n2010 census.\nAs of the census of 2010, there were 1,050 people, 412 households, and 293 families living in the village. The population density was . There were 484 housing units at an average density of . The racial makeup of the village was 99.0% White, 0.3% African American, 0.1% Native American, 0.1% Asian, 0.1% from other races, and 0.4% from two or more races. Hispanic or Latino of any race were 1.8% of the population.\nThere were 412 households, of which 33.7% had children under the age of 18 living with them, 54.6% were married couples living together, 10.4% had a female householder with no husband present, 6.1% had a male householder with no wife present, and 28.9% were non-families. 25.7% of all households were made up of individuals, and 12.6% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.02.\nThe median age in the village was 40.9 years. 26% of residents were under the age of 18; 8.3% were between the ages of 18 and 24; 21.4% were from 25 to 44; 28.7% were from 45 to 64; and 15.6% were 65 years of age or older. The gender makeup of the village was 48.9% male and 51.1% female.\n2000 census.\nAs of the census of 2000, there were 1,101 people, 428 households, and 308 families living in the village. The population density was . There were 499 housing units at an average density of . The racial makeup of the village was 97.91% White, 0.09% Black or African American, 0.27% Native American, 0.73% Asian, 0.64% from other races, and 0.36% from two or more races. 0.82% of the population were Hispanic or Latino of any race.\nThere were 428 households, out of which 34.3% had children under the age of 18 living with them, 57.9% were married couples living together, 10.7% had a female householder with no husband present, and 28.0% were non-families. 25.0% of all households were made up of individuals, and 10.5% had someone living alone who was 65 years of age or older. The average household size was 2.57 and the average family size was 3.09.\nIn the village, the population was spread out, with 28.1% under the age of 18, 7.5% from 18 to 24, 28.2% from 25 to 44, 21.7% from 45 to 64, and 14.5% who were 65 years of age or older. The median age was 37 years. For every 100 females, there were 92.8 males. For every 100 females age 18 and over, there were 87.7 males.\nThe median income for a household in the village was $46,500, and the median income for a family was $54,531. Males had a median income of $39,167 versus $23,594 for females. The per capita income for the village was $19,348. About 4.8% of families and 5.2% of the population were below the poverty line, including 3.1% of those under age 18 and 7.1% of those age 65 or over."}
{"id": "7829", "revid": "45138366", "url": "https://en.wikipedia.org/wiki?curid=7829", "title": "Chaos Computer Club", "text": "The Chaos Computer Club (CCC) is Europe's largest association of hackers with 7,700 registered members. Founded in 1981, the association is incorporated as an \"eingetragener Verein\" in Germany, with local chapters (called \"Erfa-Kreise\") in various cities in Germany and the surrounding countries, particularly where there are German-speaking communities.\nSince 1985, some chapters in Switzerland have organized an independent sister association called the (CCC-CH) instead.\nThe CCC describes itself as \"a galactic community of life forms, independent of age, sex, race or societal orientation, which strives across borders for freedom of information\u2026\". In general, the CCC advocates more transparency in government, freedom of information, and the human right to communication. Supporting the principles of the hacker ethic, the club also fights for free universal access to computers and technological infrastructure as well as the use of open-source software. The CCC spreads an entrepreneurial vision refusing capitalist control. It has been characterised as \"\u2026one of the most influential digital organisations anywhere, the centre of German digital culture, hacker culture, hacktivism, and the intersection of any discussion of democratic and digital rights\".\nMembers of the CCC have demonstrated and publicized a number of important information security problems.\nThe CCC frequently criticizes new legislation and products with weak information security which endanger citizen rights or the privacy of users.\nNotable members of the CCC regularly function as expert witnesses for the German constitutional court, organize lawsuits and campaigns, or otherwise influence the political process.\nActivities.\nRegular events.\nThe CCC hosts the annual Chaos Communication Congress, Europe's biggest hacker gathering.\nWhen the event was held in the Hamburg congress center in 2013, it drew 9,000 guests.\nFor the 2016 installment, 11,000 guests were expected, with additional viewers following the event via live streaming.\nEvery four years, the Chaos Communication Camp is the outdoor alternative for hackers worldwide.\nThe CCC also held, from 2009 to 2013, a yearly conference called SIGINT in Cologne which focused on the impact of digitisation on society. The SIGINT conference was discontinued in 2014.\nThe four-day conference \"Gulaschprogrammiernacht\" in Karlsruhe is with more than 1,500 participants the second largest annual event.\nAnother yearly CCC event taking place on the Easter weekend is the Easterhegg, which is more workshop oriented than the other events.\nThe CCC often uses the c-base station located in Berlin as an event location or as function rooms.\nPublications and outreach.\nThe CCC publishes the irregular magazine \"Datenschleuder\" (\"data slingshot\") since 1984.\nThe Berlin chapter produces a monthly radio show called which picks up various technical and political topics in a two-hour talk radio show. The program is aired on a local radio station called and on the internet.\nOther programs have emerged in the context of Chaosradio, including radio programs offered by some regional Chaos Groups and the podcast spin-off \"CRE\" by Tim Pritlove.\nMany of the chapters of CCC participate in the volunteer project \"Chaos macht Schule\" which supports teaching in local schools. Its aims are to improve technology and media literacy of pupils, parents, and teachers.\nCCC members are present in big tech companies and in administrative instances. One of the spokespersons of the CCC, as of 1986, Andy M\u00fcller-Maguhn, was a member of the executive committee of the ICANN (Internet Corporation for Assigned Names and Numbers) between 2000 and 2002.\nCryptoParty.\nThe CCC sensitises and introduces people to the questions of data privacy. Some of its local chapters support or organize so called CryptoParties to introduce people to the basics of practical cryptography and internet anonymity.\nHistory.\nFounding.\nThe CCC was founded in West Berlin on 12 September 1981 at a table which had previously belonged to the Kommune 1 in the rooms of the newspaper Die Tageszeitung by Wau Holland and others in anticipation of the prominent role that information technology would play in the way people live and communicate.\nBTX-Hack.\nThe CCC became world-famous in 1984 when they drew public attention to the security flaws of the German Bildschirmtext computer network by causing it to debit DM 134,000 () in a Hamburg bank in favor of the club. The money was returned the next day in front of the press. Prior to the incident, the system provider had failed to react to proof of the security flaw provided by the CCC, claiming to the public that their system was safe. Bildschirmtext was the biggest commercially available online system targeted at the general public in its region at that time, run and heavily advertised by the German telecommunications agency Deutsche Bundespost which also strove to keep up-to-date alternatives out of the market.\nKarl Koch.\nIn 1987, the CCC was peripherally involved in the first cyberespionage case to make international headlines. A group of German hackers led by Karl Koch, who was loosely affiliated with the CCC, was arrested for breaking into US government and corporate computers, and then selling operating-system source code to the Soviet KGB.\nThis incident was portrayed in the movie \"23\".\nGSM-Hack.\nIn April 1998, the CCC successfully demonstrated the cloning of a GSM customer card, breaking the COMP128 encryption algorithm used at that time by many GSM SIMs.\nProject Blinkenlights.\nIn 2001, the CCC celebrated its twentieth birthday with an interactive light installation dubbed \"Project Blinkenlights\" that turned the building Haus des Lehrers in Berlin into a giant computer screen. A follow-up installation, \"Arcade\", was created in 2002 by the CCC for the Biblioth\u00e8que nationale de France. Later in October 2008 CCC's Project Blinkenlights went to Toronto, Ontario, Canada with project Stereoscope.\nSch\u00e4uble fingerprints.\nIn March 2008, the CCC acquired and published the fingerprints of German Minister of the Interior Wolfgang Sch\u00e4uble. The magazine also included the fingerprint on a film that readers could use to fool fingerprint readers. This was done to protest the use of biometric data in German identity devices such as e-passports.\nStaatstrojaner affair.\nThe Staatstrojaner (\"Federal Trojan horse\") is a computer surveillance program installed secretly on a suspect's computer, which the German police uses to wiretap Internet telephony. This \"source wiretapping\" is the only feasible way to wiretap in this case, since Internet telephony programs will usually encrypt the data when it leaves the computer. The Federal Constitutional Court of Germany has ruled that the police may only use such programs for telephony wiretapping, and for no other purpose, and that this restriction should be enforced through technical and legal means.\nOn 8 October 2011, the CCC published an analysis of the Staatstrojaner software. The software was found to have the ability to remote control the target computer, to capture screenshots, and to fetch and run arbitrary extra code. The CCC says that having this functionality built in is in direct contradiction to the ruling of the constitutional court.\nIn addition, there were a number of security problems with the implementation. The software was controllable over the Internet, but the commands were sent completely unencrypted, with no checks for authentication or integrity. This leaves any computer under surveillance using this software vulnerable to attack. The captured screenshots and audio files were encrypted, but so incompetently that the encryption was ineffective. All captured data was sent over a proxy server in the United States, which is problematic since the data is then temporarily outside the German jurisdiction.\nThe CCC's findings were widely reported in the German press. This trojan has also been nicknamed R2-D2 because the string \"C3PO-r2d2-POE\" was found in its code; another alias for it is 0zapftis (\"It's tapped!\" in Bavarian, a sardonic reference to Oktoberfest). According to a Sophos analysis, the trojan's behavior matches that described in a confidential memo between the German Landeskriminalamt and a software firm called \"\"; the memo was leaked on WikiLeaks in 2008. Among other correlations is the dropper's file name , short for Skype Capture Unit Installer. The 64-bit Windows version installs a digitally signed driver, but signed by the non-existing certificate authority \"Goose Cert\". DigiTask later admitted selling spy software to governments.\nThe Federal Ministry of the Interior released a statement in which they denied that R2-D2 has been used by the Federal Criminal Police Office (BKA); this statement however does not eliminate the possibility that it has been used by state-level German police forces. The BKA had previously announced however (in 2007) that they had somewhat similar trojan software that can inspect a computer's hard drive.\nDomscheit-Berg affair.\nFormer WikiLeaks spokesman Daniel Domscheit-Berg was expelled from the national CCC (but not the Berlin chapter) in August 2011. This decision was revoked in February 2012.\nAs a result of his role in the expulsion, board member Andy M\u00fcller-Maguhn was not reelected for another term.\nPhone authentication systems.\nThe CCC has repeatedly warned phone users of the weakness of biometric identification in the wake of the 2008 Sch\u00e4uble fingerprints affair. In their \"hacker ethics\" the CCC includes \"protect people data\", but also \"Computers can change your life for the better\". The club regards privacy as an individual right: the CCC does not discourage people from sharing or storing personal information on their phones, but advocates better privacy protection, and the use of specific browsing and sharing techniques by users.\nApple TouchID.\nFrom a photograph of the user's fingerprint on a glass surface, using \"easy everyday means\", the biometrics hacking team of the CCC was able to unlock an iPhone 5S.\nSamsung S8 iris recognition.\nThe Samsung Galaxy S8's iris recognition system claims to be \"one of the safest ways to keep your phone locked and the contents private\" as \"patterns in your irises are unique to you and are virtually impossible to replicate\", as quoted in official Samsung content. However, in some cases, using a high resolution photograph of the phone owner's iris and a lens, the CCC claimed to be able to trick the authentication system.\nFake Chaos Computer Club France.\nThe Chaos Computer Club France (CCCF) was a fake hacker organisation created in 1989 in Lyon (France) by Jean-Bernard Condat, under the command of Jean-Luc Delacour, an agent of the Direction de la surveillance du territoire governmental agency. The primary goal of the CCCF was to watch and to gather information about the French hacker community, identifying the hackers who could harm the country. Journalist said that this organization also worked with the French National Gendarmerie.\nThe CCCF had an electronic magazine called \"Chaos Digest (ChaosD)\". Between 4 January 1993 and 5 August 1993, seventy-three issues were published ()."}
{"id": "7830", "revid": "48768739", "url": "https://en.wikipedia.org/wiki?curid=7830", "title": "Convention (norm)", "text": "A convention influences a set of agreed, stipulated, or generally accepted standards, social norms, or other criteria, often taking the form of a custom.\nIn physical sciences, numerical values (such as constants, quantities, or scales of measurement) are called conventional if they do not represent a measured property of nature, but originate in a convention, for example an average of many measurements, agreed between the scientists working with these values.\nGeneral.\nA convention is a selection from among two or more alternatives, where the rule or alternative is agreed upon among participants. Often the word refers to unwritten customs shared throughout a community. For instance, it is conventional in many societies that strangers being introduced shake hands. Some conventions are explicitly legislated; for example, it is conventional in the United States and in Germany that motorists drive on the right side of the road, whereas in Australia, New Zealand, Japan, Nepal, India and the United Kingdom motorists drive on the left. The standardization of time is a human convention based on the solar cycle or calendar. The extent to which justice is conventional (as opposed to natural or objective) is historically an important debate among philosophers.\nThe nature of conventions has raised long-lasting philosophical discussion. Quine, Davidson, and David Lewis published influential writings on the subject. Lewis's account of convention received an extended critique in Margaret Gilbert's \"On Social Facts\" (1989), where an alternative account is offered. Another view of convention comes from Ruth Millikan's \"Language: A Biological Model\" (2005), once more against Lewis.\nAccording to David Kalupahana, The Buddha described conventions\u2014whether linguistic, social, political, moral, ethical, or even religious\u2014as arising dependent on specific conditions. According to his paradigm, when conventions are considered absolute realities, they contribute to dogmatism, which in turn leads to conflict. This does not mean that conventions should be absolutely ignored as unreal and therefore useless. Instead, according to Buddhist thought, a wise person adopts a Middle Way without holding conventions to be ultimate or ignoring them when they are fruitful.\nCustomary or social conventions.\nSocial.\nIn sociology, a \"social rule\" refers to any social convention commonly adhered to in a society. These \"rules\" are not written in law or otherwise formalized. In social constructionism, there is a great focus on social rules. It is argued that these rules are socially constructed, that these rules act upon every member of a society, but at the same time, are re-produced by the individuals.\nSociologists representing symbolic interactionism argue that social rules are created through the interaction between the members of a society. The focus on active interaction highlights the fluid, shifting character of social rules. These are specific to the social context, a context that varies through time and place. That means a social rule changes over time within the same society. What was acceptable in the past may no longer be the case. Similarly, rules differ across space: what is acceptable in one society may not be so in another.\nSocial rules reflect what is \"acceptable\" or \"normal\" behaviour in any situation. Michel Foucault's concept of discourse is closely related to social rules as it offers a possible explanation how these rules are shaped and change. It is the social rules that tell people what is \"normal\" behaviour for any specific category. Thus, social rules tell a woman how to behave in a womanly manner, and a man, how to be manly. Other such rules are as follows:\nGovernment.\nIn government, convention is a set of unwritten rules that participants in the government must follow. These rules can be ignored only if justification is clear, or can be provided. Otherwise, consequences follow. Consequences may include ignoring some other convention that has until now been followed. According to the traditional doctrine (Dicey), conventions cannot be enforced in courts, because they are non-legal sets of rules. Convention is particularly important in the Westminster System of government, where many of the rules are unwritten."}
{"id": "7831", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7831", "title": "Cous cous", "text": ""}
{"id": "7832", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7832", "title": "Complete metric space", "text": "In mathematical analysis, a metric space is called complete (or a Cauchy space) if every Cauchy sequence of points in has a limit that is also in .\nIntuitively, a space is complete if there are no \"points missing\" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. formula_1 is \"missing\" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it (see further examples below). It is always possible to \"fill all the holes\", leading to the \"completion\" of a given space, as explained below.\nDefinition.\nCauchy sequence\nA sequence formula_2 of elements from formula_3 of a metric space formula_4 is called Cauchy if for every positive real number formula_5 there is a positive integer formula_6 such that for all positive integers formula_7 formula_8 \nComplete space\nA metric space formula_4 is complete if any of the following equivalent conditions are satisfied:\nExamples.\nThe space formula_22 of rational numbers, with the standard metric given by the absolute value of the difference, is not complete. \nConsider for instance the sequence defined by \nThis is a Cauchy sequence of rational numbers, but it does not converge towards any rational limit: If the sequence did have a limit formula_25 then by solving formula_26 necessarily formula_27 yet no rational number has this property. \nHowever, considered as a sequence of real numbers, it does converge to the irrational number formula_1.\nThe open interval , again with the absolute difference metric, is not complete either. \nThe sequence defined by formula_29 is Cauchy, but does not have a limit in the given space. \nHowever the closed interval is complete; for example the given sequence does have a limit in this interval, namely zero.\nThe space formula_30 of real numbers and the space formula_31 of complex numbers (with the metric given by the absolute difference) are complete, and so is Euclidean space formula_32, with the usual distance metric. \nIn contrast, infinite-dimensional normed vector spaces may or may not be complete; those that are complete are Banach spaces. \nThe space C of continuous real-valued functions on a closed and bounded interval is a Banach space, and so a complete metric space, with respect to the supremum norm. \nHowever, the supremum norm does not give a norm on the space C of continuous functions on , for it may contain unbounded functions. \nInstead, with the topology of compact convergence, C can be given the structure of a Fr\u00e9chet space: a locally convex topological vector space whose topology can be induced by a complete translation-invariant metric.\nThe space Q\"p\" of \"p\"-adic numbers is complete for any prime number formula_33 \nThis space completes Q with the \"p\"-adic metric in the same way that R completes Q with the usual metric.\nIf formula_34 is an arbitrary set, then the set of all sequences in formula_34 becomes a complete metric space if we define the distance between the sequences formula_36 and formula_37 to be formula_38 where formula_6 is the smallest index for which formula_40 is distinct from formula_41 or formula_42 if there is no such index. \nThis space is homeomorphic to the product of a countable number of copies of the discrete space formula_43\nRiemannian manifolds which are complete are called geodesic manifolds; completeness follows from the Hopf\u2013Rinow theorem.\nSome theorems.\nEvery compact metric space is complete, though complete spaces need not be compact. In fact, a metric space is compact if and only if it is complete and totally bounded. This is a generalization of the Heine\u2013Borel theorem, which states that any closed and bounded subspace formula_34 of is compact and therefore complete.\nLet formula_4 be a complete metric space. If formula_46 is a closed set, then formula_47 is also complete. Let formula_4 be a metric space. If formula_46 is a complete subspace, then formula_47 is also closed.\nIf formula_3 is a set and formula_52 is a complete metric space, then the set formula_53 of all bounded functions from to formula_52 is a complete metric space. Here we define the distance in formula_53 in terms of the distance in formula_52 with the supremum norm\nformula_57\nIf formula_3 is a topological space and formula_52 is a complete metric space, then the set formula_60 consisting of all continuous bounded functions formula_61 is a closed subspace of formula_53 and hence also complete.\nThe Baire category theorem says that every complete metric space is a Baire space. That is, the union of countably many nowhere dense subsets of the space has empty interior.\nThe Banach fixed-point theorem states that a contraction mapping on a complete metric space admits a fixed point. The fixed-point theorem is often used to prove the inverse function theorem on complete metric spaces such as Banach spaces.\nCompletion.\nFor any metric space \"M\", it is possible to construct a complete metric space \"M\u2032\" (which is also denoted as formula_63), which contains \"M\" as a dense subspace. It has the following universal property: if \"N\" is any complete metric space and \"f\" is any uniformly continuous function from \"M\" to \"N\", then there exists a unique uniformly continuous function \"f\u2032\" from \"M\u2032\" to \"N\" that extends \"f\". The space \"M\"' is determined up to isometry by this property (among all complete metric spaces isometrically containing \"M\"), and is called the \"completion\" of \"M\".\nThe completion of \"M\" can be constructed as a set of equivalence classes of Cauchy sequences in \"M\". For any two Cauchy sequences formula_64 and formula_65 in \"M\", we may define their distance as\nformula_66\n(This limit exists because the real numbers are complete.) This is only a pseudometric, not yet a metric, since two different Cauchy sequences may have the distance 0. But \"having distance 0\" is an equivalence relation on the set of all Cauchy sequences, and the set of equivalence classes is a metric space, the completion of \"M\". The original space is embedded in this space via the identification of an element \"x\" of \"M\"' with the equivalence class of sequences in \"M\" converging to \"x\" (i.e., the equivalence class containing the sequence with constant value \"x\"). This defines an isometry onto a dense subspace, as required. Notice, however, that this construction makes explicit use of the completeness of the real numbers, so completion of the rational numbers needs a slightly different treatment.\nCantor's construction of the real numbers is similar to the above construction; the real numbers are the completion of the rational numbers using the ordinary absolute value to measure distances. The additional subtlety to contend with is that it is not logically permissible to use the completeness of the real numbers in their own construction. Nevertheless, equivalence classes of Cauchy sequences are defined as above, and the set of equivalence classes is easily shown to be a field that has the rational numbers as a subfield. This field is complete, admits a natural total ordering, and is the unique totally ordered complete field (up to isomorphism). It is \"defined\" as the field of real numbers (see also Construction of the real numbers for more details). One way to visualize this identification with the real numbers as usually viewed is that the equivalence class consisting of those Cauchy sequences of rational numbers that \"ought\" to have a given real limit is identified with that real number. The truncations of the decimal expansion give just one choice of Cauchy sequence in the relevant equivalence class.\nFor a prime formula_67 the -adic numbers arise by completing the rational numbers with respect to a different metric.\nIf the earlier completion procedure is applied to a normed vector space, the result is a Banach space containing the original space as a dense subspace, and if it is applied to an inner product space, the result is a Hilbert space containing the original space as a dense subspace.\nTopologically complete spaces.\nCompleteness is a property of the \"metric\" and not of the \"topology\", meaning that a complete metric space can be homeomorphic to a non-complete one. An example is given by the real numbers, which are complete but homeomorphic to the open interval , which is not complete.\nIn topology one considers \"completely metrizable spaces\", spaces for which there exists at least one complete metric inducing the given topology. Completely metrizable spaces can be characterized as those spaces that can be written as an intersection of countably many open subsets of some complete metric space. Since the conclusion of the Baire category theorem is purely topological, it applies to these spaces as well.\nCompletely metrizable spaces are often called \"topologically complete\". However, the latter term is somewhat arbitrary since metric is not the most general structure on a topological space for which one can talk about completeness (see the section Alternatives and generalizations). Indeed, some authors use the term \"topologically complete\" for a wider class of topological spaces, the completely uniformizable spaces.\nA topological space homeomorphic to a separable complete metric space is called a Polish space.\nAlternatives and generalizations.\nSince Cauchy sequences can also be defined in general topological groups, an alternative to relying on a metric structure for defining completeness and constructing the completion of a space is to use a group structure. This is most often seen in the context of topological vector spaces, but requires only the existence of a continuous \"subtraction\" operation. In this setting, the distance between two points formula_68 and formula_69 is gauged not by a real number formula_70 via the metric formula_71 in the comparison formula_72 but by an open neighbourhood formula_6 of formula_42 via subtraction in the comparison formula_75\nA common generalisation of these definitions can be found in the context of a uniform space, where an entourage is a set of all pairs of points that are at no more than a particular \"distance\" from each other.\nIt is also possible to replace Cauchy \"sequences\" in the definition of completeness by Cauchy \"nets\" or Cauchy filters. If every Cauchy net (or equivalently every Cauchy filter) has a limit in formula_15 then formula_3 is called complete. One can furthermore construct a completion for an arbitrary uniform space similar to the completion of metric spaces. The most general situation in which Cauchy nets apply is Cauchy spaces; these too have a notion of completeness and completion just like uniform spaces."}
{"id": "7833", "revid": "45227015", "url": "https://en.wikipedia.org/wiki?curid=7833", "title": "The Amazing Criswell", "text": "Jeron Criswell King (August 18, 1907\u00a0\u2013 October 4, 1982), known by his stage-name The Amazing Criswell (), was an American psychic known for wildly inaccurate predictions. In person, he went by Charles Criswell King, and was sometimes credited as Jeron King Criswell.\nCriswell was flamboyant, with spit curled hair, a stentorian style of speaking, and a sequined tuxedo. He owned a coffin in which he claimed to sleep. He grew up in a troubled family in Indiana with relatives who owned a funeral home, and frequently stated he became comfortable with sleeping in caskets in the storeroom. \nHe appeared in two films directed by Ed Wood\u2014\"Plan 9 from Outer Space\" (1957) and \"Night of the Ghouls\" (1959)\u2014and also appeared in \"Orgy of the Dead\" (1965), which was written by Wood.\nEarly life.\nCriswell claimed he never actually talked until the age of four. During a thunderstorm he first spoke, making his first prediction, \"the rain will stop.\" From this point on he was talkative, often placing himself center stage at any opportunity.\nCareer.\nCriswell said he had once worked as a radio announcer and news broadcaster. He began buying time on a local Los Angeles television station in the early 1950s to run infomercials for his Criswell Family Vitamins. To fill the time, he began his \"Criswell Predicts\" part of the show. This made him a minor off-beat celebrity in Los Angeles and around Hollywood, and his friendship with old show-business people such as Mae West and rising fringe celebrities such as Korla Pandit made Criswell an entertaining presence at parties. His fame brought him appearances on \"Tonight Starring Jack Paar\" (1957\u20131962). \nHe published predictions in three issues of \"Spaceway\" magazine (February 1955, April 1955, and June 1955), as well as in a weekly syndicated newspaper article starting on September 6, 1951. He later published three books of predictions; \"From Now to the Year 2000\", \"Your Next Ten Years\", and \"Forbidden Predictions\". \nHe also recorded a long playing record, \"Your Incredible Future\" (which was later released on CD), featuring 84 minutes of his predictions in his own voice. \nCriswell appeared in the movies of writer and director Ed Wood. \nAfter Criswell's death, his longtime friend Paul Marco released Criswell's song \"Someone Walked Over My Grave\" on a 7\" record which was recorded by Criswell as a memorial song he only wanted released posthumously.\nPredictions.\nCriswell's predictions were nationally syndicated and he appeared on the television show \"Criswell Predicts\" on KLAC Channel 13 (now KCOP-13) in Los Angeles as well as being recorded for syndication. His announcer was Bob Shields, who later played the judge on \"The Judge\". Criswell wore heavy makeup in public after his live program was broadcast in Los Angeles. Only selected people were allowed in the KCOP studio during his broadcast.\nCriswell wrote several books of predictions, including 1968's \"Criswell Predicts: From Now to the Year 2000.\" In it, he claimed that Denver, Colorado, would be struck by a ray from space that would cause all metal to adopt the qualities of rubber, leading to horrific accidents at amusement parks. He predicted mass cannibalism and the end of planet Earth, which he set as happening on August 18, 1999 (which would have been his 92nd birthday).\nCriswell was a student of history. He believed history repeated itself, that the United States were the \"modern Romans\". Each day, he read the \"St. Louis Post-Dispatch\" looking for clues for his predictions.\nSome sources claim Criswell's most famous prediction was on \"The Jack Paar Program\" (1962\u201365) in March 1963, when he predicted US President John F. Kennedy would not run for reelection in 1964 because something was going to happen to him in November 1963.\nSources say that Criswell never claimed to be a real psychic; however, those who knew him, including actress and fellow \"Plan 9\" alumna Maila Nurmi (\"Vampira\"), believed he was. According to writer Charles A. Coulombe, whose family rented an apartment from him, Criswell told Coulombe's father had the gift, but [I] lost it when I started taking money for it.\"\nPrivate life.\nCriswell married a former speakeasy dancer named Halo Meadows, who once appeared on \"You Bet Your Life\", and whom Coulombe describes as \"quite mad\": \"Mrs Criswell had a huge standard poodle (named \"Buttercup\") which she was convinced was the reincarnation of her cousin Thomas. She spent a great deal of time sunbathing\u00a0... which, given her size, was not too pleasing a sight.\"\nMae West used Criswell as her personal psychic; he once predicted her rise to President of the United States, whereupon she, Criswell and George Liberace, the brother of showman Liberace, would take a rocket to the Moon. Criswell and West were great friends and she would lavish him with home-cooked food which she had delivered to the studio that he shared with Maila Nurmi (\"Vampira\"). It is said that West sold Criswell her old luxury cars for five dollars.\nCriswell died on October 4, 1982, at the age of 75; he was cremated days later."}
{"id": "7834", "revid": "1239452736", "url": "https://en.wikipedia.org/wiki?curid=7834", "title": "Chain reaction", "text": "A chain reaction is a sequence of reactions where a reactive product or by-product causes additional reactions to take place. In a chain reaction, positive feedback leads to a self-amplifying chain of events.\nChain reactions are one way that systems which are not in thermodynamic equilibrium can release energy or increase entropy in order to reach a state of higher entropy. For example, a system may not be able to reach a lower energy state by releasing energy into the environment, because it is hindered or prevented in some way from taking the path that will result in the energy release. If a reaction results in a small energy release making way for more energy releases in an expanding chain, then the system will typically collapse explosively until much or all of the stored energy has been released.\nA macroscopic metaphor for chain reactions is thus a snowball causing a larger snowball until finally an avalanche results (\"snowball effect\"). This is a result of stored gravitational potential energy seeking a path of release over friction. Chemically, the equivalent to a snow avalanche is a spark causing a forest fire. In nuclear physics, a single stray neutron can result in a prompt critical event, which may finally be energetic enough for a nuclear reactor meltdown or (in a bomb) a nuclear explosion.\nAnother metaphor for a chain reaction is the domino effect, named after the act of domino toppling, where the simple action of toppling one domino leads to all dominoes eventually toppling, even if they are significantly larger. \nNumerous chain reactions can be represented by a mathematical model based on Markov chains.\nChemical chain reactions.\nHistory.\nIn 1913, the German chemist Max Bodenstein first put forth the idea of chemical chain reactions. If two molecules react, not only molecules of the final reaction products are formed, but also some unstable molecules which can further react with the parent molecules with a far larger probability than the initial reactants. (In the new reaction, further unstable molecules are formed besides the stable products, and so on.)\nIn 1918, Walther Nernst proposed that the photochemical reaction between hydrogen and chlorine is a chain reaction in order to explain what is known as the \"quantum yield\" phenomena. This means that one photon of light is responsible for the formation of as many as 106 molecules of the product HCl. Nernst suggested that the photon dissociates a Cl2 molecule into two Cl atoms which each initiate a long chain of reaction steps forming HCl.\nIn 1923, Danish and Dutch scientists J. A. Christiansen and Hendrik Anthony Kramers, in an analysis of the formation of polymers, pointed out that such a chain reaction need not start with a molecule excited by light, but could also start with two molecules colliding violently due to thermal energy as previously proposed for initiation of chemical reactions by van' t Hoff.\nChristiansen and Kramers also noted that if, in one link of the reaction chain, two or more unstable molecules are produced, the reaction chain would branch and grow. The result is in fact an exponential growth, thus giving rise to explosive increases in reaction rates, and indeed to chemical explosions themselves. This was the first proposal for the mechanism of chemical explosions.\nA quantitative chain chemical reaction theory was created later on by Soviet physicist Nikolay Semyonov in 1934. Semyonov shared the Nobel Prize in 1956 with Sir Cyril Norman Hinshelwood, who independently developed many of the same quantitative concepts.\nTypical steps.\nThe main types of steps in chain reaction are of the following types.\nThe \"chain length\" is defined as the average number of times the propagation cycle is repeated, and equals the overall reaction rate divided by the initiation rate.\nSome chain reactions have complex rate equations with fractional order or mixed order kinetics.\nDetailed example: the hydrogen-bromine reaction.\nThe reaction H2 + Br2 \u2192 2 HBr proceeds by the following mechanism:\nAs can be explained using the steady-state approximation, the thermal reaction has an initial rate of fractional order (3/2), and a complete rate equation with a two-term denominator (mixed-order kinetics).\nAcetaldehyde pyrolysis and rate equation.\nThe pyrolysis (thermal decomposition) of acetaldehyde, CH3CHO (g) \u2192 CH4 (g) + CO (g), proceeds via the Rice-Herzfeld mechanism:\nThe methyl and CHO groups are free radicals.\nThis reaction step provides methane, which is one of the two main products.\nThe product \u2022CH3CO (g) of the previous step gives rise to carbon monoxide (CO), which is the second main product.\nThe sum of the two propagation steps corresponds to the overall reaction CH3CHO (g) \u2192 CH4 (g) + CO (g), catalyzed by a methyl radical \u2022CH3.\n This reaction is the only source of ethane (minor product) and it is concluded to be the main chain ending step.\nAlthough this mechanism explains the principal products, there are others that are formed in a minor degree, such as acetone (CH3COCH3) and propanal (CH3CH2CHO).\nApplying the Steady State Approximation for the intermediate species CH3(g) and CH3CO(g), the rate law for the formation of methane and the order of reaction are found:\nThe rate of formation of the product methane is\nformula_1\nFor the intermediates\nformula_2 and\nformula_3\nAdding (2) and (3), we obtain formula_4\nso that formula_5\nUsing (4) in (1) gives the rate law formula_6, which is order 3/2 in the reactant CH3CHO.\nNuclear chain reactions.\nA \"nuclear\" chain reaction was proposed by Leo Szilard in 1933, shortly after the neutron was discovered, yet more than five years before nuclear fission was first discovered. Szil\u00e1rd knew of \"chemical\" chain reactions, and he had been reading about an energy-producing nuclear reaction involving high-energy protons bombarding lithium, demonstrated by John Cockcroft and Ernest Walton, in 1932. Now, Szil\u00e1rd proposed to use neutrons theoretically produced from certain nuclear reactions in lighter isotopes, to induce further reactions in light isotopes that produced more neutrons. This would in theory produce a chain reaction at the level of the nucleus. He did not envision fission as one of these neutron-producing reactions, since this reaction was not known at the time. Experiments he proposed using beryllium and indium failed.\nLater, after fission was discovered in 1938, Szil\u00e1rd immediately realized the possibility of using neutron-induced fission as the particular nuclear reaction necessary to create a chain-reaction, so long as fission also produced neutrons. In 1939, with Enrico Fermi, Szil\u00e1rd proved this neutron-multiplying reaction in uranium. In this reaction, a neutron plus a fissionable atom causes a fission resulting in a larger number of neutrons than the single one that was consumed in the initial reaction. Thus was born the practical nuclear chain reaction by the mechanism of neutron-induced nuclear fission.\nSpecifically, if one or more of the produced neutrons themselves interact with other fissionable nuclei, and these also undergo fission, then there is a possibility that the macroscopic overall fission reaction will not stop, but continue throughout the reaction material. This is then a self-propagating and thus self-sustaining chain reaction. This is the principle for nuclear reactors and atomic bombs.\nDemonstration of a self-sustaining nuclear chain reaction was accomplished by Enrico Fermi and others, in the successful operation of Chicago Pile-1, the first artificial nuclear reactor, in late 1942.\nElectron avalanche in gases.\nAn electron avalanche happens between two unconnected electrodes in a gas when an electric field exceeds a certain threshold. Random thermal collisions of gas atoms may result in a few free electrons and positively charged gas ions, in a process called impact ionization. Acceleration of these free electrons in a strong electric field causes them to gain energy, and when they impact other atoms, the energy causes release of new free electrons and ions (ionization), which fuels the same process. If this process happens faster than it is naturally quenched by ions recombining, the new ions multiply in successive cycles until the gas breaks down into a plasma and current flows freely in a discharge.\nElectron avalanches are essential to the dielectric breakdown process within gases. The process can culminate in corona discharges, streamers, leaders, or in a spark or continuous electric arc that completely bridges the gap. The process may extend huge sparks \u2014 streamers in lightning discharges propagate by formation of electron avalanches created in the high potential gradient ahead of the streamers' advancing tips. Once begun, avalanches are often intensified by the creation of photoelectrons as a result of ultraviolet radiation emitted by the excited medium's atoms in the aft-tip region. The extremely high temperature of the resulting plasma cracks the surrounding gas molecules and the free ions recombine to create new chemical compounds.\nThe process can also be used to detect radiation that initiates the process, as the passage of a single particles can be amplified to large discharges. This is the mechanism of a Geiger counter and also the visualization possible with a spark chamber and other wire chambers.\nAvalanche breakdown in semiconductors.\nAn avalanche breakdown process can happen in semiconductors, which in some ways conduct electricity analogously to a mildly ionized gas. Semiconductors rely on free electrons knocked out of the crystal by thermal vibration for conduction. Thus, unlike metals, semiconductors become better conductors the higher the temperature. This sets up conditions for the same type of positive feedback\u2014heat from current flow causes temperature to rise, which increases charge carriers, lowering resistance, and causing more current to flow. This can continue to the point of complete breakdown of normal resistance at a semiconductor junction, and failure of the device (this may be temporary or permanent depending on whether there is physical damage to the crystal). Certain devices, such as avalanche diodes, deliberately make use of the effect.\nLiving organisms.\nExamples of chain reactions in living organisms include excitation of neurons in epilepsy and lipid peroxidation. In peroxidation, a lipid radical reacts with oxygen to form a peroxyl radical (L\u2022 + O2 \u2192 LOO\u2022). The peroxyl radical then oxidises another lipid, thus forming another lipid radical (LOO\u2022 + L\u2013H \u2192 LOOH + L\u2022). A chain reaction in glutamatergic synapses is the cause of synchronous discharge in some epileptic seizures."}
{"id": "7837", "revid": "48422902", "url": "https://en.wikipedia.org/wiki?curid=7837", "title": "Caddie", "text": "In golf, a caddie (or caddy) is a companion to the player, providing both practical support and strategic guidance on the course. Caddies are responsible for carrying the player\u2019s bag, managing clubs, and assisting with basic course maintenance like repairing divots and raking bunkers. However, their role extends well beyond these physical tasks, going into emotional and behavioural moral support. In the general golf environment\u2014whether at local clubs, public courses, or prestigious tournaments\u2014caddies offer valuable insight on course strategy, advising on everything from club selection to reading greens and evaluating weather conditions. They often serve as a steadying presence, offering encouragement and helping players maintain focus under pressure.\nCaddies are trusted for their course knowledge, adaptability, and close understanding of a player\u2019s game, and their role is integral at every level of play. In professional and amateur golf alike, caddies often build lasting partnerships with players, developing a rapport that contributes to overall performance.\nOther nicknames for the position is a looper or jock. \nEtymology.\nThe Scots word \"caddie\" or \"\" was derived in the 17th century from the French word \"cadet\" and originally meant a student military officer. It later came to refer to someone who did odd jobs. By the 19th century, it had come to mean someone who carried clubs for a golfer, or in its shortened form, cad, a man of disreputable behaviour.\nHistory.\nThe first recorded use of a caddie was in Edinburgh in 1681 by the future James VII of Scotland when taking part in the first international golf contest.\nEarnings.\nCaddies pay is variable and is usually based on an allocated percentage share of prize money. At a professional level, caddies work in a high level partnership with golfers, some work as contractors to individual players in events. In 2020, caddies on the PGA European Tour became eligible to earn bonuses through sponsors' logos on their gear.\nIn 2024, Golf Digest reported that Scottie Scheffler\u2019s caddie Ted Scott earned $2.6 million over the season with the world number 1.\nCaddying fees range throughout courses across the world, however is a popular role for low handicap golfers which can provide opportunities to work with a variety of people. \nIn popular culture.\nCaddies have been depicted in television, films, and books, including:"}
{"id": "7838", "revid": "35277463", "url": "https://en.wikipedia.org/wiki?curid=7838", "title": "Compound turbine", "text": "A compound turbine is a steam turbine in which there are two casings, a high-pressure casing and a low-pressure casing, operating in concert to extract work from a single source of steam. The steam is partially expanded in the high-pressure casing, then exhausted to the low-pressure casing.\nTandem compound or cross compound.\nThe rotor arrangement can be either tandem-compound in which the two axles are joined end to end, or cross-compound in which the two turbines have separate axles. In the cross-compound case two separate generators are usually supplied, although a gearbox can reduce this to one.\nAdvantages.\nThe principal advantages of compound turbines are the reduction in size of any one casing, the confinement of the highest pressure to the smaller casing (which may be made of stronger and more expensive materials) and the possibility of divided flow in the low-pressure casing for the purpose of equalizing end thrusts."}
{"id": "7839", "revid": "41235142", "url": "https://en.wikipedia.org/wiki?curid=7839", "title": "Stellar corona", "text": "A corona (: coronas or coronae) is the outermost layer of a star's atmosphere. It is a hot but relatively dim region of plasma populated by intermittent coronal structures known as solar prominences or filaments.\nThe Sun's corona lies above the chromosphere and extends millions of kilometres into outer space. Coronal light is typically obscured by diffuse sky radiation and glare from the solar disk, but can be easily seen by the naked eye during a total solar eclipse or with a specialized coronagraph. Spectroscopic measurements indicate strong ionization in the corona and a plasma temperature in excess of , much hotter than the surface of the Sun, known as the photosphere.\n is, in turn, derived .\nHistory.\nIn 1724, French-Italian astronomer Giacomo F. Maraldi recognized that the aura visible during a solar eclipse belongs to the Sun, not to the Moon. In 1809, Spanish astronomer Jos\u00e9 Joaqu\u00edn de Ferrer coined the term 'corona'. Based on his own observations of the 1806 solar eclipse at Kinderhook (New York), de Ferrer also proposed that the corona was part of the Sun and not of the Moon. English astronomer Norman Lockyer identified the first element unknown on Earth in the Sun's chromosphere, which was called helium (from Greek 'sun'). French astronomer Jules Jenssen noted, after comparing his readings between the 1871 and 1878 eclipses, that the size and shape of the corona changes with the sunspot cycle. In 1930, Bernard Lyot invented the \"coronograph\" (now \"coronagraph\"), which allows viewing the corona without a total eclipse. In 1952, American astronomer Eugene Parker proposed that the solar corona might be heated by myriad tiny 'nanoflares', miniature brightenings resembling solar flares that would occur all over the surface of the Sun.\nHistorical theories.\nThe high temperature of the Sun's corona gives it unusual spectral features, which led some in the 19th century to suggest that it contained a previously unknown element, \"coronium\". Instead, these spectral features have since been explained by highly ionized iron (Fe-XIV, or Fe13+). Bengt Edl\u00e9n, following the work of Walter Grotrian in 1939, first identified the coronal spectral lines in 1940 (observed since 1869) as transitions from low-lying metastable levels of the ground configuration of highly ionised metals (the green Fe-XIV line from Fe13+ at , but also the red Fe-X line from Fe9+ at ).\nObservable components.\nThe solar corona has three recognized, and distinct, sources of light that occupy the same volume: the \"F-corona\" (for \"Fraunhofer\"), the \"K-corona\" (for \"Kontinuierlich\"), and the \"E-corona\" (for \"emission\").\nThe \"F-corona\" is named for the Fraunhofer spectrum of absorption lines in ordinary sunlight, which are preserved by reflection off small material objects. The F-corona is faint near the Sun itself, but drops in brightness only gradually far from the Sun, extending far across the sky and becoming the zodiacal light. The F-corona is recognized to arise from small dust grains orbiting the Sun; these form a tenuous cloud that extends through much of the solar system.\nThe \"K-corona\" is named for the fact that its spectrum is a continuum, with no major spectral features. It is sunlight that is Thomson-scattered by free electrons in the hot plasma of the Sun's outer atmosphere. The continuum nature of the spectrum arises from Doppler broadening of the Sun's Fraunhofer absorption lines in the reference frame of the (hot and therefore fast-moving) electrons. Although the K-corona is a phenomenon of the electrons in the plasma, the term is frequently used to describe the plasma itself (as distinct from the dust that gives rise to the F-corona).\nThe \"E-corona\" is the component of the corona with an emission-line spectrum, either inside or outside the wavelength band of visible light. It is a phenomenon of the ion component of the plasma, as individual ions are excited by collision with other ions or electrons, or by absorption of ultraviolet light from the Sun.\nPhysical features.\nThe Sun's corona is much hotter (by a factor from 150 to 450) than the visible surface of the Sun: the corona's temperature is 1 to 3 million kelvin compared to the photosphere's average temperature \u2013 around . The corona is far less dense than the photosphere, and produces about one-millionth as much visible light. The corona is separated from the photosphere by the relatively shallow chromosphere. The exact mechanism by which the corona is heated is still the subject of some debate, but likely possibilities include episodic energy releases from the pervasive magnetic field and magnetohydrodynamic waves from below. The outer edges of the Sun's corona are constantly being transported away, creating the \"open\" magnetic flux entrained in the solar wind.\nThe corona is not always evenly distributed across the surface of the Sun. During periods of quiet, the corona is more or less confined to the equatorial regions, with coronal holes covering the polar regions. However, during the Sun's active periods, the corona is evenly distributed over the equatorial and polar regions, though it is most prominent in areas with sunspot activity. The solar cycle spans approximately 11 years, from one solar minimum to the following minimum. Since the solar magnetic field is continually wound up due to the faster rotation of mass at the Sun's equator (differential rotation), sunspot activity is more pronounced at solar maximum where the magnetic field is more twisted. Associated with sunspots are coronal loops, loops of magnetic flux, upwelling from the solar interior. The magnetic flux pushes the hotter photosphere aside, exposing the cooler plasma below, thus creating the relatively dark sun spots.\nHigh-resolution X-ray images of the Sun's corona photographed by Skylab in 1973, by Yohkoh in 1991\u20132001, and by subsequent space-based instruments revealed the structure of the corona to be quite varied and complex, leading astronomers to classify various zones on the coronal disc.\nAstronomers usually distinguish several regions, as described below.\nActive regions.\nActive regions are ensembles of loop structures connecting points of opposite magnetic polarity in the photosphere, the so-called coronal loops. They generally distribute in two zones of activity, which are parallel to the solar equator. The average temperature is between two and four million kelvin, while the density goes from 109 to 1010 particles per cubic centimetre.\nActive regions involve all the phenomena directly linked to the magnetic field, which occur at different heights above the Sun's surface: sunspots and faculae occur in the photosphere; spicules, H\u03b1 filaments and plages in the chromosphere; prominences in the chromosphere and transition region; and flares and coronal mass ejections (CME) happen in the corona and chromosphere. If flares are very violent, they can also perturb the photosphere and generate a Moreton wave. On the contrary, quiescent prominences are large, cool, dense structures which are observed as dark, \"snake-like\" H\u03b1 ribbons (appearing like filaments) on the solar disc. Their temperature is about \u2013, and so they are usually considered as chromospheric features.\nIn 2013, images from the High Resolution Coronal Imager revealed never-before-seen \"magnetic braids\" of plasma within the outer layers of these active regions.\nCoronal loops.\nCoronal loops are the basic structures of the magnetic solar corona. These loops are the closed-magnetic flux cousins of the open-magnetic flux that can be found in coronal holes and the solar wind. Loops of magnetic flux well up from the solar body and fill with hot solar plasma. Due to the heightened magnetic activity in these coronal loop regions, coronal loops can often be the precursor to solar flares and CMEs.\nThe solar plasma that feeds these structures is heated from under to well over 106\u00a0K from the photosphere, through the transition region, and into the corona. Often, the solar plasma will fill these loops from one point and drain to another, called foot points (siphon flow due to a pressure difference, or asymmetric flow due to some other driver).\nWhen the plasma rises from the foot points towards the loop top, as always occurs during the initial phase of a compact flare, it is defined as chromospheric evaporation. When the plasma rapidly cools and falls toward the photosphere, it is called chromospheric condensation. There may also be symmetric flow from both loop foot points, causing a build-up of mass in the loop structure. The plasma may cool rapidly in this region (for a thermal instability), its dark filaments obvious against the solar disk or prominences off the Sun's limb.\nCoronal loops may have lifetimes in the order of seconds (in the case of flare events), minutes, hours or days. Where there is a balance in loop energy sources and sinks, coronal loops can last for long periods of time and are known as \"steady state\" or \"quiescent\" coronal loops ().\nCoronal loops are very important to our understanding of the current \"coronal heating problem\". Coronal loops are highly radiating sources of plasma and are therefore easy to observe by instruments such as \"TRACE\". An explanation of the coronal heating problem remains as these structures are being observed remotely, where many ambiguities are present (i.e., radiation contributions along the line-of-sight propagation). \"In-situ\" measurements are required before a definitive answer can be determined, but due to the high plasma temperatures in the corona, \"in-situ\" measurements are, at present, impossible. The next mission of the NASA Parker Solar Probe will approach the Sun very closely, allowing more direct observations.\nLarge-scale structures.\nLarge-scale structures are very long arcs which can cover over a quarter of the solar disk but contain plasma less dense than in the coronal loops of the active regions.\nThey were first detected in the June 8, 1968, flare observation during a rocket flight.\nThe large-scale structure of the corona changes over the 11-year solar cycle and becomes particularly simple during the minimum period, when the magnetic field of the Sun is almost similar to a dipolar configuration (plus a quadrupolar component).\nInterconnections of active regions.\nThe interconnections of active regions are arcs connecting zones of opposite magnetic field, of different active regions. Significant variations of these structures are often seen after a flare.\nSome other features of this kind are helmet streamers \u2013 large, cap-like coronal structures with long, pointed peaks that usually overlie sunspots and active regions. Coronal streamers are considered to be sources of the slow solar wind.\nFilament cavities.\nFilament cavities are zones which look dark in the X-rays and are above the regions where H\u03b1 filaments are observed in the chromosphere. They were first observed in the two 1970 rocket flights which also detected \"coronal holes\".\nFilament cavities are cooler clouds of plasma suspended above the Sun's surface by magnetic forces. The regions of intense magnetic field look dark in images because they are empty of hot plasma. In fact, the sum of the magnetic pressure and plasma pressure must be constant everywhere on the heliosphere in order to have an equilibrium configuration: where the magnetic field is higher, the plasma must be cooler or less dense. The plasma pressure formula_1 can be calculated by the state equation of a perfect gas: formula_2, where formula_3 is the particle number density, formula_4 the Boltzmann constant and formula_5 the plasma temperature. It is evident from the equation that the plasma pressure lowers when the plasma temperature decreases with respect to the surrounding regions or when the zone of intense magnetic field empties. The same physical effect renders sunspots apparently dark in the photosphere.\nBright points.\nBright points are small active regions found on the solar disk. X-ray bright points were first detected on April 8, 1969, during a rocket flight.\nThe fraction of the solar surface covered by bright points varies with the solar cycle. They are associated with small bipolar regions of the magnetic field. Their average temperature ranges from 1.1\u00a0MK to 3.4\u00a0MK. The variations in temperature are often correlated with changes in the X-ray emission.\nCoronal holes.\nCoronal holes are unipolar regions which look dark in the X-rays since they do not emit much radiation. These are wide zones of the Sun where the magnetic field is unipolar and opens towards the interplanetary space. The high speed solar wind arises mainly from these regions.\nIn the UV images of the coronal holes, some small structures, similar to elongated bubbles, are often seen as they were suspended in the solar wind. These are the coronal plumes. More precisely, they are long thin streamers that project outward from the Sun's north and south poles.\nThe quiet Sun.\nThe solar regions which are not part of active regions and coronal holes are commonly identified as the quiet Sun.\nThe equatorial region has a faster rotation speed than the polar zones. The result of the Sun's differential rotation is that the active regions always arise in two bands parallel to the equator and their extension increases during the periods of maximum of the solar cycle, while they almost disappear during each minimum. Therefore, the quiet Sun always coincides with the equatorial zone and its surface is less active during the maximum of the solar cycle. Approaching the minimum of the solar cycle (also named butterfly cycle), the extension of the quiet Sun increases until it covers the whole disk surface excluding some bright points on the hemisphere and the poles, where there are coronal holes.\nAlfv\u00e9n surface.\nThe Alfv\u00e9n surface is the boundary separating the corona from the solar wind defined as where the coronal plasma's Alfv\u00e9n speed and the large-scale solar wind speed are equal.\nResearchers were unsure exactly where the Alfv\u00e9n critical surface of the Sun lay. Based on remote images of the corona, estimates had put it somewhere between 10 and 20 solar radii from the surface of the Sun. On April 28, 2021, during its eighth flyby of the Sun, NASA's Parker Solar Probe encountered the specific magnetic and particle conditions at 18.8 solar radii that indicated that it penetrated the Alfv\u00e9n surface.\nVariability of the corona.\nA portrait, as diversified as the one already pointed out for the coronal features, is emphasized by the analysis of the dynamics of the main structures of the corona, which evolve at differential times. Studying coronal variability in its complexity is not easy because the times of evolution of the different structures can vary considerably: from seconds to several months. The typical sizes of the regions where coronal events take place vary in the same way, as it is shown in the following table.\nFlares.\nFlares take place in active regions and are characterized by a sudden increase of the radiative flux emitted from small regions of the corona. They are very complex phenomena, visible at different wavelengths; they involve several zones of the solar atmosphere and many physical effects, thermal and not thermal, and sometimes wide reconnections of the magnetic field lines with material expulsion.\nFlares are impulsive phenomena, of average duration of 15 minutes, and the most energetic events can last several hours. Flares produce a high and rapid increase of the density and temperature.\nAn emission in white light is only seldom observed: usually, flares are only seen at extreme UV wavelengths and into the X-rays, typical of the chromospheric and coronal emission.\nIn the corona, the morphology of flares is described by observations in the UV, soft and hard X-rays, and in H\u03b1 wavelengths, and is very complex. However, two kinds of basic structures can be distinguished:\nAs for temporal dynamics, three different phases are generally distinguished, whose duration are not comparable. The durations of those periods depend on the range of wavelengths used to observe the event:\nSometimes also a phase preceding the flare can be observed, usually called as \"pre-flare\" phase.\nCoronal mass ejections.\nOften accompanying large solar flares and prominences are coronal mass ejections (CME). These are enormous emissions of coronal material and magnetic field that travel outward from the Sun at up to 3000 km/s,&lt;ref name=\"NOAA / NWS Space Weather Prediction Center 2024 x766\"&gt;&lt;/ref&gt; containing roughly 10 times the energy of the solar flare or prominence that accompanies them. Some larger CMEs can propel hundreds of millions of tons of material into interplanetary space at roughly 1.5 million kilometers an hour.\nStellar coronae.\nCoronal stars are ubiquitous among the stars in the cool half of the Hertzsprung\u2013Russell diagram. These coronae can be detected using X-ray telescopes. Some stellar coronae, particularly in young stars, are much more luminous than the Sun's. For example, FK Comae Berenices is the prototype for the FK Com class of variable star. These are giants of spectral types G and K with an unusually rapid rotation and signs of extreme activity. Their X-ray coronae are among the most luminous (\"L\"x \u2265 1032 erg\u00b7s\u22121 or 1025W) and the hottest known with dominant temperatures up to 40 MK.\nThe astronomical observations planned with the Einstein Observatory by Giuseppe Vaiana and his group showed that F-, G-, K- and M-stars have chromospheres and often coronae much like the Sun.\nThe \"O-B stars\", which do not have surface convection zones, have a strong X-ray emission. However these stars do not have coronae, but the outer stellar envelopes emit this radiation during shocks due to thermal instabilities in rapidly moving gas blobs.\nAlso A-stars do not have convection zones but they do not emit at the UV and X-ray wavelengths. Thus they appear to have neither chromospheres nor coronae.\nPhysics of the corona.\nThe matter in the external part of the solar atmosphere is in the state of plasma, at very high temperature (a few million kelvin) and at very low density (of the order of 1015 particles/m3).\nAccording to the definition of plasma, it is a quasi-neutral ensemble of particles which exhibits a collective behaviour.\nThe composition is similar to that in the Sun's interior, mainly hydrogen, but with much greater ionization of its heavier elements than that found in the photosphere. Heavier metals, such as iron, are partially ionized and have lost most of the external electrons. The ionization state of a chemical element depends strictly on the temperature and is regulated by the Saha equation in the lowest atmosphere, but by collisional equilibrium in the optically thin corona. Historically, the presence of the spectral lines emitted from highly ionized states of iron allowed determination of the high temperature of the coronal plasma, revealing that the corona is much hotter than the internal layers of the chromosphere.\nThe corona behaves like a gas which is very hot but very light at the same time: the pressure in the corona is usually only 0.1 to 0.6 Pa in active regions, while on the Earth the atmospheric pressure is about 100 kPa, approximately a million times higher than on the solar surface. However it is not properly a gas, because it is made of charged particles, basically protons and electrons, moving at different velocities. Supposing that they have the same kinetic energy on average\n(for the equipartition theorem), electrons have a mass roughly times smaller than protons, therefore they acquire more velocity. Metal ions are always slower. This fact has relevant physical consequences either on radiative processes (that are very different from the photospheric radiative processes), or on thermal conduction.\nFurthermore, the presence of electric charges induces the generation of electric currents and high magnetic fields.\nMagnetohydrodynamic waves (MHD waves) can also propagate in this plasma, even though it is still not clear how they can be transmitted or generated in the corona.\nRadiation.\nCoronal plasma is optically thin and therefore transparent to the electromagnetic radiation that it emits and to that coming from lower layers. The plasma is very rarefied and the photon mean free path overcomes by far all the other length-scales, including the typical sizes of common coronal features.\nElectromagnetic radiation from the corona has been identified coming from three main sources, located in the same volume of space: \nThermal conduction.\nIn the corona thermal conduction occurs from the external hotter atmosphere towards the inner cooler layers. Responsible for the diffusion process of the heat are the electrons, which are much lighter than ions and move faster, as explained above.\nWhen there is a magnetic field the thermal conductivity of the plasma becomes higher in the direction which is parallel to the field lines rather than in the perpendicular direction.\nA charged particle moving in the direction perpendicular to the magnetic field line is subject to the Lorentz force which is normal to the plane individuated by the velocity and the magnetic field. This force bends the path of the particle. In general, since particles also have a velocity component along the magnetic field line, the Lorentz force constrains them to bend and move along spirals around the field lines at the cyclotron frequency.\nIf collisions between the particles are very frequent, they are scattered in every direction. This happens in the photosphere, where the plasma carries the magnetic field in its motion. In the corona, on the contrary, the mean free-path of the electrons is of the order of kilometres and even more, so each electron can do a helicoidal motion long before being scattered after a collision. Therefore, the heat transfer is enhanced along the magnetic field lines and inhibited in the perpendicular direction.\nIn the direction longitudinal to the magnetic field, the thermal conductivity of the corona is\nformula_6\nwhere formula_7 is the Boltzmann constant, formula_5 is the temperature in kelvin, formula_9 is the electron mass, formula_10 is the electric charge of the electron,\nformula_11\nis the Coulomb logarithm, and\nformula_12\nis the Debye length of the plasma with particle density formula_3. The Coulomb logarithm formula_14 is roughly 20 in the corona, with a mean temperature of 1 MK and a density of 1015 particles/m3, and about 10 in the chromosphere, where the temperature is approximately 10kK and the particle density is of the order of 1018 particles/m3, and in practice it can be assumed constant.\nThence, if we indicate with formula_15 the heat for a volume unit, expressed in J m\u22123, the Fourier equation of heat transfer, to be computed only along the direction formula_16 of the field line, becomes\nformula_17\nNumerical calculations have shown that the thermal conductivity of the corona is comparable to that of copper.\nCoronal seismology.\nCoronal seismology is a method of studying the plasma of the solar corona with the use of magnetohydrodynamic (MHD) waves. MHD studies the dynamics of electrically conducting fluids \u2013 in this case, the fluid is the coronal plasma. Philosophically, coronal seismology is similar to the Earth's seismology, the Sun's helioseismology, and MHD spectroscopy of laboratory plasma devices. In all these approaches, waves of various kinds are used to probe a medium. The potential of coronal seismology in the estimation of the coronal magnetic field, density scale height, fine structure and heating has been demonstrated by different research groups.\nCoronal heating problem.\nThe coronal heating problem in solar physics relates to the question of why the temperature of the Sun's corona is millions of kelvins greater than the thousands of kelvins of the surface. Several theories have been proposed to explain this phenomenon, but it is still challenging to determine which is correct. The problem first emerged after the identification of unknown spectral lines in the solar spectrum with highly ionized iron and calcium atoms. The comparison of the coronal and the photospheric temperatures of , leads to the question of how the 200-times-hotter coronal temperature can be maintained. The problem is primarily concerned with how the energy is transported up into the corona and then converted into heat within a few solar radii.\nThe high temperatures require energy to be carried from the solar interior to the corona by non-thermal processes, because the second law of thermodynamics prevents heat from flowing directly from the solar photosphere (surface), which is at about , to the much hotter corona at about 1 to 3 MK (parts of the corona can even reach ).\nBetween the photosphere and the corona, the thin region through which the temperature increases is known as the transition region. It ranges from only tens to hundreds of kilometers thick. Energy cannot be transferred from the cooler photosphere to the corona by conventional heat transfer as this would violate the second law of thermodynamics. An analogy of this would be a light bulb raising the temperature of the air surrounding it to something greater than its glass surface. Hence, some other manner of energy transfer must be involved in the heating of the corona.\nThe amount of power required to heat the solar corona can easily be calculated as the difference between coronal radiative losses and heating by thermal conduction toward the chromosphere through the transition region. It is about 1 kilowatt for every square meter of surface area on the Sun's chromosphere, or 1/ of the amount of light energy that escapes the Sun.\nMany coronal heating theories have been proposed, but two theories have remained as the most likely candidates: wave heating and magnetic reconnection (or nanoflares). Through most of the past 50 years, neither theory has been able to account for the extreme coronal temperatures.\nIn 2012, high resolution (&lt;0.2\u2033) soft X-ray imaging with the High Resolution Coronal Imager aboard a sounding rocket revealed tightly wound braids in the corona. It is hypothesized that the reconnection and unravelling of braids can act as primary sources of heating of the active solar corona to temperatures of up to 4 million kelvin. The main heat source in the quiescent corona (about 1.5 million kelvin) is assumed to originate from MHD waves.\nNASA's Parker Solar Probe is intended to approach the Sun to a distance of approximately 9.5 solar radii to investigate coronal heating and the origin of the solar wind. It was successfully launched on August 12, 2018 and by late 2022 had completed the first 13 of more than 20 planned close approaches to the Sun.\nWave heating theory.\nThe wave heating theory, proposed in 1949 by \u00c9vry Schatzman, proposes that waves carry energy from the solar interior to the solar chromosphere and corona. The Sun is made of plasma rather than ordinary gas, so it supports several types of waves analogous to sound waves in air. The most important types of wave are magneto-acoustic waves and Alfv\u00e9n waves. Magneto-acoustic waves are sound waves that have been modified by the presence of a magnetic field, and Alfv\u00e9n waves are similar to ultra low frequency radio waves that have been modified by interaction with matter in the plasma. Both types of waves can be launched by the turbulence of granulation and super granulation at the solar photosphere, and both types of waves can carry energy for some distance through the solar atmosphere before turning into shock waves that dissipate their energy as heat.\nOne problem with wave heating is delivery of the heat to the appropriate place. Magneto-acoustic waves cannot carry sufficient energy upward through the chromosphere to the corona, both because of the low pressure present in the chromosphere and because they tend to be reflected back to the photosphere. Alfv\u00e9n waves can carry enough energy, but do not dissipate that energy rapidly enough once they enter the corona. Waves in plasmas are notoriously difficult to understand and describe analytically, but computer simulations, carried out by Thomas Bogdan and colleagues in 2003, seem to show that Alfv\u00e9n waves can transmute into other wave modes at the base of the corona, providing a pathway that can carry large amounts of energy from the photosphere through the chromosphere and transition region and finally into the corona where it dissipates it as heat.\nAnother problem with wave heating has been the complete absence, until the late 1990s, of any direct evidence of waves propagating through the solar corona. The first direct observation of waves propagating into and through the solar corona was made in 1997 with the Solar and Heliospheric Observatory space-borne solar observatory, the first platform capable of observing the Sun in the extreme ultraviolet (EUV) for long periods of time with stable photometry. Those were magneto-acoustic waves with a frequency of about 1 millihertz (mHz, corresponding to a wave period), that carry only about 10% of the energy required to heat the corona. Many observations exist of localized wave phenomena, such as Alfv\u00e9n waves launched by solar flares, but those events are transient and cannot explain the uniform coronal heat.\nIt is not yet known exactly how much wave energy is available to heat the corona. Results published in 2004 using data from the TRACE spacecraft seem to indicate that there are waves in the solar atmosphere at frequencies as high as (10 second period). Measurements of the temperature of different ions in the solar wind with the UVCS instrument aboard SOHO give strong indirect evidence that there are waves at frequencies as high as , well into the range of human hearing. These waves are very difficult to detect under normal circumstances, but evidence collected during solar eclipses by teams from Williams College suggest the presences of such waves in the 1\u2013 range.\nRecently, Alfv\u00e9nic motions have been found in the lower solar atmosphere and also in the quiet Sun, in coronal holes and in active regions using observations with AIA on board the Solar Dynamics Observatory.\nThese Alfv\u00e9nic oscillations have significant power, and seem to be connected to the chromospheric Alfv\u00e9nic oscillations previously reported with the Hinode spacecraft.\nSolar wind observations with the \"Wind\" spacecraft have recently shown evidence to support theories of Alfv\u00e9n-cyclotron dissipation, leading to local ion heating.\nMagnetic reconnection theory.\nThe magnetic reconnection theory relies on the solar magnetic field to induce electric currents in the solar corona. The currents then collapse suddenly, releasing energy as heat and wave energy in the corona. This process is called \"reconnection\" because of the peculiar way that magnetic fields behave in plasma (or any electrically conductive fluid such as mercury or seawater). In a plasma, magnetic field lines are normally tied to individual pieces of matter, so that the topology of the magnetic field remains the same: if a particular north and south magnetic pole are connected by a single field line, then even if the plasma is stirred or if the magnets are moved around, that field line will continue to connect those particular poles. The connection is maintained by electric currents that are induced in the plasma. Under certain conditions, the electric currents can collapse, allowing the magnetic field to \"reconnect\" to other magnetic poles and release heat and wave energy in the process.\nMagnetic reconnection is hypothesized to be the mechanism behind solar flares, the largest explosions in the Solar System. Furthermore, the surface of the Sun is covered with millions of small magnetized regions 50\u2013 across. These small magnetic poles are buffeted and churned by the constant granulation. The magnetic field in the solar corona must undergo nearly constant reconnection to match the motion of this \"magnetic carpet\", so the energy released by the reconnection is a natural candidate for the coronal heat, perhaps as a series of \"microflares\" that individually provide very little energy but together account for the required energy.\nThe idea that nanoflares might heat the corona was proposed by Eugene Parker in the 1980s but is still controversial. In particular, ultraviolet telescopes such as TRACE and SOHO/EIT can observe individual micro-flares as small brightenings in extreme ultraviolet light, but there seem to be too few of these small events to account for the energy released into the corona. The additional energy not accounted for could be made up by wave energy, or by gradual magnetic reconnection that releases energy more smoothly than micro-flares and therefore does not appear well in the TRACE data. Variations on the micro-flare hypothesis use other mechanisms to stress the magnetic field or to release the energy, and are a subject of active research in 2005.\nSpicules (type II).\nFor decades, researchers believed spicules could send heat into the corona. However, following observational research in the 1980s, it was found that spicule plasma did not reach coronal temperatures, and so the theory was discounted.\nAs per studies performed in 2010 at the \"National Center for Atmospheric Research\" in Colorado, in collaboration with the \"Lockheed Martin's Solar and Astrophysics Laboratory\" (LMSAL) and the \"Institute of Theoretical Astrophysics\" of the University of Oslo, a new class of spicules (TYPE II) discovered in 2007, which travel faster (up to 100\u00a0km/s) and have shorter lifespans, can account for the problem. These jets insert heated plasma into the Sun's outer atmosphere.\nThus, a much greater understanding of the corona and improvement in the knowledge of the Sun's subtle influence on the Earth's upper atmosphere can be expected henceforth. The Atmospheric Imaging Assembly on NASA's recently launched Solar Dynamics Observatory and NASA's Focal Plane Package for the Solar Optical Telescope on the Japanese Hinode satellite which was used to test this hypothesis. The high spatial and temporal resolutions of the newer instruments reveal this coronal mass supply.\nThese observations reveal a one-to-one connection between plasma that is heated to millions of degrees and the spicules that insert this plasma into the corona."}
{"id": "7840", "revid": "1256414923", "url": "https://en.wikipedia.org/wiki?curid=7840", "title": "Chrono Cross", "text": " is a 1999 role-playing video game developed and published by Square for the PlayStation video game console. It is set in the same world as \"Chrono Trigger\", which was released in 1995 for the Super Nintendo Entertainment System. \"Chrono Cross\" was designed primarily by scenarist and director Masato Kato, who had help from other designers who also worked on \"Chrono Trigger\", including art director Yasuyuki Honne and composer Yasunori Mitsuda. Nobuteru Y\u016bki designed the characters of the game.\nThe story of \"Chrono Cross\" focuses on a teenage boy named Serge and a theme of parallel worlds. Faced with an alternate reality in which he died as a child, Serge endeavors to discover the truth of the two worlds' divergence. The flashy thief Kid and many other characters assist him in his travels around the tropical archipelago El Nido. Struggling to uncover his past and find the mysterious Frozen Flame, Serge is chiefly challenged by Lynx, a shadowy antagonist working to apprehend him.\nUpon its release in Japan in 1999 and North America in 2000, \"Chrono Cross\" received widespread acclaim, earning a perfect 10.0 score from \"GameSpot\". The game shipped copies worldwide by 2003, leading to a Greatest Hits re-release and continued life in Japan as part of the Ultimate Hits series. \"Chrono Cross\" was later re-released for the PlayStation Network in Japan in July 2011, and in North America four months later. A remaster of the game, titled was released on April 7, 2022, for Nintendo Switch, PlayStation 4, Windows, and Xbox One.\nGameplay.\n\"Chrono Cross\" features standard role-playing video game gameplay with some differences. Players advance the game by controlling the protagonist Serge through the game's world, primarily by foot and boat. Navigation between areas is conducted via an overworld map, much like \"Chrono Trigger's\", depicting the landscape from a scaled-down overhead view. Around the island world are villages, outdoor areas, and dungeons, through which the player moves in three dimensions. Locations such as cities and forests are represented by more realistically scaled field maps, in which players can converse with locals to procure items and services, solve puzzles and challenges, or encounter enemies. Like \"Chrono Trigger\", the game features no random encounters; enemies are openly visible on field maps or lie in wait to ambush the party. Touching the monster switches perspectives to a battle screen, in which players can physically attack, use \"Elements\", defend, or run away from the enemy. Battles are turn-based, allowing the player unlimited time to select an action from the available menu. For both the playable characters and the computer-controlled enemies, each attack reduces their number of hit points (a numerically based life bar), which can be restored through some Elements. When a playable character loses all hit points, he or she faints. If all the player's characters fall in battle, the game ends and must be restored from a previously saved chapter\u2014except for specific storyline-related battles that allow the player to lose. \"Chrono Cross\"'s developers aimed to break new ground in the genre, and the game features several innovations. For example, players can run away from all conflicts, including boss fights and the final battle.\nBattle and Elements.\nThe Element system of \"Chrono Cross\" handles all magic, consumable items, and character-specific abilities. Elements unleash magic effects upon the enemy or party and must be equipped for use, much like the materia of 1997's \"Final Fantasy\u00a0VII\". Elements can be purchased from shops or found in treasure chests littered throughout areas. Once acquired, they are allocated to a grid whose size and shape are unique to each character. They are ranked according to eight tiers; certain high level Elements can only be assigned on equivalent tiers in a character's grid. As the game progresses, the grid expands, allowing more Elements to be equipped and higher tiers to be accessed. Elements are divided into six paired oppositional types, or \"colors,\" each with a natural effect. Red (fire/magma) opposes Blue (water/ice), Green (wind/flora) opposes Yellow (earth/lightning), and White (light/cosmos) opposes Black (darkness/gravity). Each character and enemy has an innate color, enhancing the power of using same-color Elements while also making them weak against elements of the opposite color. \"Chrono Cross\" also features a \"field effect\", which keeps track of Element color used in the upper corner of the battle screen. If the field is purely one color, characters are able to unleash a powerful summon element at the cost of one of the player's stars. The field will also enhance the power of Elements of the colors present, while weakening Elements of the opposite colors. Characters also innately learn some special techniques (\"Techs\") that are unique to each character but otherwise act like Elements. Like \"Chrono Trigger\", characters can combine certain Techs to make more powerful Double or Triple Techs. Consumable Elements may be used to restore hit points or heal status ailments during or after battle.\nAnother innovative aspect of \"Chrono Cross\" is its stamina bar. At the beginning of a battle, each character has seven points of stamina. When a character attacks or uses an Element, stamina is decreased proportionally to the potency of the attack. Stamina slowly recovers when the character defends or when other characters perform actions in battle. Characters with stamina below one point must wait to take action. Use of an Element reduces the user's stamina bar by seven stamina points; this often means that the user's stamina gauge falls into the negative and the character must wait longer than usual to recover. With each battle, players can enhance statistics such as strength and defense. However, no system of experience points exists; after four or five upgrades, statistics remain static until players defeat a boss. This adds a star to a running count shown on the status screen, which allows for another few rounds of statistical increases. Players can equip characters with weapons, armor, helmets, and accessories for use in battle; for example, the \"Power Seal\" upgrades attack power. Items and equipment may be purchased or found on field maps, often in treasure chests. Unlike Elements, weapons and armor cannot merely be purchased with money; instead, the player must obtain base materials\u2014such as copper, bronze, or bone\u2014for a blacksmith to forge for a fee. The items can later be disassembled into their original components at no cost.\nParallel dimensions.\nThe existence of two major parallel dimensions, like time periods in \"Chrono Trigger\", plays a significant role in the game. Players must go back and forth between the worlds to recruit party members, obtain items, and advance the plot. Much of the population of either world have counterparts in the other; some party members can even visit their other versions. The player must often search for items or places found exclusively in one world. Events in one dimension sometimes have an impact in the other\u2014for instance, cooling scorched ground on an island in one world allows vegetation to grow in the other world. This system assists the presentation of certain themes, including the questioning of the importance of one's past decisions and humanity's role in destroying the environment. Rounding out the notable facets of \"Chrono Cross\"'s gameplay are the New Game+ option and multiple endings. As in \"Chrono Trigger\", players who have completed the game may choose to start the game over using data from the previous session. Character levels, learned techniques, equipment, and items gathered copy over, while acquired money and some story-related items are discarded. On a New Game+, players can access twelve endings. Scenes viewed depend on players' progress in the game before the final battle, which can be fought at any time in a New Game+ file.\nPlot.\nCharacters.\n\"Chrono Cross\" features a diverse cast of 45 party members. Each character is outfitted with an innate Element affinity and three unique special abilities that are learned over time. If taken to the world opposite their own, characters react to their counterparts (if available). Many characters tie in to crucial plot events. Since it is impossible to obtain all 45 characters in one playthrough, players must replay the game to witness everything. Through use of the New Game+ feature, players can ultimately obtain all characters on one save file.\nSerge, the game's protagonist, is a 17-year-old boy who lives in the fishing village of Arni. One day, he slips into an alternate world in which he drowned ten years before. Determined to find the truth behind the incident, he follows a predestined course that leads him to save the world. He is assisted by Kid, a feisty, skilled thief who seeks the mythical Frozen Flame. Portrayed as willful and tomboyish due to her rough, thieving past, she helps Serge sneak into Viper Manor in order to obtain the Frozen Flame. Kid vows to find and defeat Lynx, an anthropomorphic panther who burned down her adopted mother's orphanage.\nLynx, a cruel agent of the supercomputer FATE, is bent on finding Serge and using his body as part of a greater plan involving the Frozen Flame. Lynx travels with Harle, a mysterious, playful girl dressed like a harlequin. Harle was sent by the Dragon God to shadow Lynx and one day steal the Frozen Flame from Chronopolis, a task she painfully fulfills despite being smitten with Serge.\nTo accomplish this goal, Harle helps Lynx manipulate the Acacia Dragoons, the powerful militia governing the islands of El Nido. As the Dragoons maintain order, they contend with Fargo, a former Dragoon turned pirate captain who holds a grudge against their leader, General Viper. Though tussling with Serge initially, the Acacia Dragoons\u2014whose ranks include the fierce warriors Karsh, Zoah, Marcy, and Glenn\u2014later assist him when the militaristic nation of Porre invades the archipelago. The invasion brings Norris and Grobyc to the islands, a heartful commander of an elite force and a prototype cyborg soldier, respectively, as they too seek the Frozen Flame.\nStory.\nThe game begins with Serge located in El Nido, a tropical archipelago inhabited by ancient natives, mainland colonists, and beings called Demi-humans. Serge slips into an alternate dimension in which he drowned on the beach ten years prior, and meets the thief, \"Kid\". As his adventure proceeds from here, Serge is able to recruit a multitude of allies to his cause. While assisting Kid in a heist at Viper Manor to steal the Frozen Flame, he learns that ten years before the present, the universe split into two dimensions\u2014one in which Serge lived, and one in which he perished. Through Kid's Astral Amulet charm, Serge travels between the dimensions. At Fort Dragonia, with the use of a Dragonian artifact called the Dragon Tear, Lynx switches bodies with Serge. Unaware of the switch, Kid confides in Lynx, who stabs her as the real Serge helplessly watches. Lynx boasts of his victory and banishes Serge to a strange realm called the Temporal Vortex. He takes Kid under his wing, brainwashing her to believe the real Serge (in Lynx's body) is her enemy. Serge escapes with help from Harle, although his new body turns him into a stranger in his own world, with all the allies he had gained up to that point abandoning him due to his new appearance. Discovering that his new body prevents him from traveling across the dimensions, he sets out to regain his former body and learn more of the universal split that occurred ten years earlier, gaining a new band of allies along the way. He travels to a forbidden lagoon known as the Dead Sea\u2014a wasteland frozen in time, dotted with futuristic ruins. At the center, he locates a man named Miguel and presumably \"Home\" world's Frozen Flame. Charged with guarding the Dead Sea by an entity named FATE, Miguel and three visions of Crono, Marle, and Lucca from \"Chrono Trigger\" explain that Serge's existence dooms \"Home\" world's future to destruction at the hands of Lavos. To prevent Serge from obtaining the Frozen Flame, FATE destroys the Dead Sea.\nAble to return to \"Another\" world, Serge allies with the Acacia Dragoons against Porre and locates that dimension's Dragon Tear, allowing him to return to his human form. He then enters the Sea of Eden, \"Another\" world's physical equivalent of the Dead Sea, finding a temporal research facility from the distant future called Chronopolis. Lynx and Kid are inside; Serge defeats Lynx and the supercomputer FATE, allowing the six Dragons of El Nido to steal the Frozen Flame and retire to Terra Tower, a massive structure raised from the sea floor. Kid falls into a coma, and Harle bids the party goodbye to fly with the Dragons. Serge regroups his party and tends to Kid, who remains comatose. Continuing his adventure, he obtains and cleanses the corrupted Masamune sword from \"Chrono Trigger\". He then uses the Dragon relics and shards of the Dragon Tears to create the mythic Element Chrono Cross. The spiritual power of the Masamune later allows him to lift Kid from her coma. At Terra Tower, the prophet of time, revealed to be Belthasar from \"Chrono Trigger\", visits him with visions of Crono, Marle, and Lucca. Serge learns that the time research facility Chronopolis created El Nido thousands of years ago after a catastrophic experimental failure drew it to the past. The introduction of a temporally foreign object in history caused the planet to pull in a counterbalance from a different dimension. This was Dinopolis, a city of Dragonians\u2014parallel universe descendants of \"Chrono Trigger\"'s Reptites. The institutions warred and Chronopolis subjugated the Dragonians. Humans captured their chief creation\u2014the Dragon God, an entity capable of controlling nature.\nChronopolis divided this entity into six pieces and created an Elements system. FATE then terraformed an archipelago, erased the memories of most of Chronopolis's staff, and sent them to inhabit and populate its new paradise. Thousands of years later, a panther demon attacked a three-year-old Serge. His father took him to find assistance at Marbule, but Serge's boat blew off course due to a raging magnetic storm caused by Schala. Schala, the princess of the Kingdom of Zeal, had long ago accidentally fallen to a place known as the Darkness Beyond Time and began merging with Lavos, the chief antagonist of \"Chrono Trigger\". Schala's storm nullified Chronopolis's defenses and allowed Serge to contact the Frozen Flame; approaching it healed Serge but corrupted his father, turning him into Lynx. A circuit in Chronopolis then designated Serge \"Arbiter\", simultaneously preventing FATE from using the Frozen Flame by extension. The Dragons were aware of this situation, creating a seventh Dragon under the storm's cover named Harle, who manipulated Lynx to steal the Frozen Flame for the Dragons.\nAfter Serge returned home, FATE sent Lynx to kill Serge, hoping that it would release the Arbiter lock. Ten years after Serge drowned, the thief Kid\u2014presumably on Belthasar's orders\u2014went back in time to save Serge and split the dimensions. FATE, locked out of the Frozen Flame again, knew that Serge would one day cross to \"Another\" world and prepared to apprehend him. Lynx switched bodies with Serge to dupe the biological check of Chronopolis on the Frozen Flame. Belthasar then reveals that these events were part of a plan he had orchestrated named Project Kid. Serge continues to the top of Terra Tower and defeats the Dragon God. Continuing to the beach where the split in dimensions had occurred, Serge finds apparitions of Crono, Marle, and Lucca once more. They reveal that Belthasar's plan was to empower Serge to free Schala from melding with Lavos, lest they evolve into the \"Time Devourer\", a creature capable of destroying spacetime. Lucca explains that Kid is Schala's clone, sent to the modern age to take part in Project Kid. Serge uses a Time Egg\u2014given to him by Belthasar\u2014to enter the Darkness Beyond Time and vanquish the Time Devourer, separating Schala from Lavos and restoring the dimensions to one. Thankful, Schala muses on evolution and the struggle of life and returns Serge to his home, noting that he will forget the entire adventure. She then seemingly records the experience in her diary, noting she will always be searching for Serge in this life and beyond, signing the entry as Schala \"Kid\" Zeal, implying that she and Kid have merged and became whole again. A wedding photo of Kid and an obscured male sits on the diary's desk. Scenes then depict a real-life Kid searching for someone in a modern city, intending to make players entertain the possibility that their own Kid is searching for them. The ambiguous ending leaves the events of the characters' lives following the game up to interpretation.\nRelation to \"Radical Dreamers\".\n\"Chrono Cross\" employs story arcs, characters, and themes from \"\", a Satellaview side story to \"Chrono Trigger\" released in Japan. \"Radical Dreamers\" is an illustrated text adventure which was created to wrap up an unresolved plot line of \"Chrono Trigger\". Though it borrows from \"Radical Dreamers\" in its exposition, \"Chrono Cross\" is not a remake of \"Radical Dreamers\", but a larger effort to fulfill that game's purpose; the plots of the games are irreconcilable. To resolve continuity issues and acknowledge \"Radical Dreamers\", the developers of \"Chrono Cross\" suggested the game happened in a parallel dimension. A notable difference between the two games is that Magus\u2014present in \"Radical Dreamers\" as Gil\u2014is absent from \"Chrono Cross\". Director Masato Kato originally planned for Magus to appear in disguise as Guile, but scrapped the idea due to plot difficulties. Kato specifically felt that the game's large number of characters, as well as the difficult production schedule, did not allow him to develop the relationship between Magus and Kid. In the DS version of \"Chrono Trigger\", Kato teases the possibility of an amnesiac Magus.\nDevelopment.\nSquare began planning \"Chrono Cross\" immediately after the release of \"Xenogears\" in 1998 (which itself was originally conceived as a sequel to the SNES game). \"Chrono Trigger\"'s scenario director Masato Kato had brainstormed ideas for a sequel as early as 1996, following the release of \"\". Square's managers selected a team, appointed Hiromichi Tanaka producer, and asked Kato to direct and develop a new \"Chrono\" game in the spirit of \"Radical Dreamers\". Kato thought \"Dreamers\" was released in a \"half-finished state\", and wanted to continue the story of the character Kid. Kato and Tanaka decided to produce an indirect sequel. They acknowledged that Square would soon re-release \"Chrono Trigger\" as part of \"Final Fantasy Chronicles\", which would give players a chance to catch up on the story of \"Trigger\" before playing \"Cross\". Kato thought that using a different setting and cast for \"Chrono Cross\" would allow players unfamiliar with \"Chrono Trigger\" to play \"Cross\" without becoming confused. The \"Chrono Cross\" team decided against integrating heavy use of time travel into the game, as they thought it would be \"rehashing and cranking up the volume of the last game\". Masato Kato cited the belief, \"there's no use in making something similar to before \", and noted, \"we're not so weak nor cheap as to try to make something exactly the same as \"Trigger\"\u00a0... Accordingly, \"Chrono Cross\" is not \"Chrono Trigger 2\". It doesn't simply follow on from \"Trigger\", but is another, different \"Chrono\" that interlaces with \"Trigger\".\" Kato and Tanaka further explained their intentions after the game's release:\nFull production began on \"Chrono Cross\" in mid-1998. The \"Chrono Cross\" team reached 80 members at its peak, with additional personnel of 10\u201320 cut-scene artists and 100 quality assurance testers. The team felt pressure to live up to the work of \"Chrono Trigger\"'s \"Dream Team\" development group, which included famous Japanese manga artist Akira Toriyama. Kato and Tanaka hired Nobuteru Y\u016bki for character design and Yasuyuki Honne for art direction and concept art. The event team originally envisioned a short game, and planned a system by which players would befriend any person in a town for alliance in battle. Developers brainstormed traits and archetypes during the character-creation process, originally planning 64 characters with unique endings that could vary in three different ways per character. Kato described the character creation process: \"Take Pierre, for example: we started off by saying we wanted a wacko fake hero like Tata from \"Trigger\". We also said things like 'we need at least one powerful mom', 'no way we're gonna go without a twisted brat', and so on so forth.\"\nAs production continued, the length of \"Cross\" increased, leading the event team to reduce the number of characters to 45 and scrap most of the alternate endings. Developers humorously named the character Pip \"Tsumaru\" in Japanese (which means \"packed\") as a pun on their attempts to pack as much content into the game as possible. To avoid the burden of writing unique, accented dialogue for several characters, team member Kiyoshi Yoshii coded a system that produces accents by modifying basic text for certain characters. Art director Nobuteru Yuuki initially wanted the characters to appear in a more \"chibi\" format with diminutive proportions. The game world's fusion of high technology and ethnic, tribal atmospheres proved challenging at first. He later recalled striving to harmonize the time period's level of technology, especially as reflected in characters' garb. The demands of the art style led to Square merging the \"Final Fantasy VIII\" team into that of \"Chrono Cross\" two months before the Japanese release.\nThe \"Chrono Cross\" team devised an original battle system using a stamina bar and Elements. Kato planned the system around allowing players to avoid repetitive gameplay (also known as \"grinding\") to gain combat experience. Elements were developed while planning the final battle (during which a sequence of specific Elements must be triggered), and then applied in reverse to the rest of the game. Hiromichi Tanaka likened the Elements system to card games, hoping players would feel a sense of complete control in battle. The team programmed each battle motion manually instead of performing motion capture. Developers strove to include tongue-in-cheek humor in the battle system's techniques and animations to distance the game from the \"Final Fantasy\" franchise. Masato Kato planned for the game's setting to feature a small archipelago, for fear that players would become confused traveling in large areas with respect to parallel worlds. He hoped El Nido would still impart a sense of grand scale, and the development team pushed hardware limitations in creating the game's world. To create field maps, the team modeled locations in 3D, then chose the best angle for 2D rendering. The programmers of \"Chrono Cross\" did not use any existing Square programs or routines to code the game, instead writing new, proprietary systems. Other innovations included variable-frame rate code for fast-forward and slow-motion gameplay (awarded as a bonus for completing the game) and a \"CD-read swap\" system to allow quick data retrieval.\nMasato Kato directed and wrote the main story, leaving sub-plots and minor character events to other staff. The event team sometimes struggled to mesh their work on the plot due to the complexity of the parallel worlds concept. Masato Kato confirmed that \"Cross\" featured a central theme of parallel worlds, as well as the fate of Schala, which he was previously unable to expound upon in \"Chrono Trigger\". Concerning the ending sequences showing Kid searching for someone in a modern city, he hoped to make players realize that alternate futures and possibilities may exist in their own lives, and that this realization would \"not\u00a0... stop with the game\". He later added, \"Paraphrasing one novelist's favorite words, what's important is not the message or theme, but how it is portrayed as a game. Even in Cross, it was intentionally made so that the most important question was left unanswered.\" Kato described the finished story as \"ole' boy-meets-girl type of story\" with sometimes-shocking twists. Kato rode his motorcycle to relieve the stress of the game's release schedule. He continued refining event data during the final stages of development while the rest of the team undertook debugging and quality control work. Square advertised the game by releasing a short demo of the first chapter with purchases of \"Legend of Mana\". The North American version of \"Cross\" required three months of translation and two months of debugging before release. Richard Honeywood translated, working with Kato to rewrite certain dialogue for ease of comprehension in English. He also added instances of wordplay and alliteration to compensate for difficult Japanese jokes. To streamline translation for all 45 playable characters, Honeywood created his own version of the accent generator which needed to be more robust than the simple verbal tics of the Japanese cast. Although the trademark \"Chrono Cross\" was registered in the European Union, the game was not released in Europe.\nAfter the game was done, the team was merged with those behind \"Parasite Eve II\", \"Brave Fencer Musashi\" and \"Mana\" to make \"Final Fantasy XI\". The programming for the game endured as the basis for the engine of \"Final Fantasy XI\".\nMusic.\n\"Chrono Cross\" was scored by freelance video game music composer Yasunori Mitsuda, who previously worked on \"Chrono Trigger\". Director Masato Kato personally commissioned Mitsuda's involvement, citing a need for the \"Chrono sound\". Kato envisioned a \"Southeast Asian feel, mixed with the foreign tastes and the tones of countries such as Greece\"; Mitsuda centered his work around old world cultural influences, including Mediterranean, Fado, Celtic, and percussive African music. Mitsuda cited visual inspiration for songs: \"All of my subjects are taken from scenery. I love artwork.\" To complement the theme of parallel worlds, he gave \"Another\" and \"Home\" respectively dark and bright moods, and hoped players would feel the emotions of \"'burning soul,' 'lonely world,' and 'unforgettable memories'\". Mitsuda and Kato planned music samples and sound effects with the philosophy of \"a few sounds with a lot of content\".\n\"Xenogears\" contributor Tomohiko Kira played guitar on the beginning and ending themes. Noriko Mitose, as selected by Masato Kato, sang the ending song\u2014\"Radical Dreamers \u2013 The Unstolen Jewel\". Ryo Yamazaki, a synthesizer programmer for Square Enix, helped Mitsuda transfer his ideas to the PlayStation's sound capabilities; Mitsuda was happy to accomplish even half of what he envisioned. Certain songs were ported from the score of \"\", such as \"Gale\", \"Frozen Flame\", and \"Viper Mansion\". Other entries in the soundtrack contain leitmotifs from \"Chrono Trigger\" and \"Radical Dreamers\". The melody of \"Far Promise ~ Dream Shore\" features prominently in \"Dreams of the Ages\" and \"Sailing (Another World)\". Masato Kato faced internal opposition in hiring Noriko Mitose:\nProduction required six months of work. After wrapping, Mitsuda and Kato played \"Chrono Cross\" to record their impressions and observe how the tracks intermingled with scenes; the ending theme brought Kato to tears. Players who preordered the game received a sampler disc of five songs, and Square released a three-CD official soundtrack in Japan after the game's debut. The soundtrack won the Gold Prize for the PlayStation Awards of 2000. In 2005, Square Enix reissued the soundtrack due to popular demand. Earlier that year, Mitsuda announced a new arranged \"Chrono Cross\" album, scheduled for release in July 2005. Mitsuda's contract with Square gave him ownership and full rights to the soundtrack of \"Chrono Cross\". It was delayed, and at a Play! A Video Game Symphony concert in May 2006, he revealed it would feature acoustic music and would be \"out within the year\", later backtracking and alleging a 2007 release date. Mitsuda posted a streaming sample of a finished track on his personal website in January 2009, and has stated the album will be released to coincide with the 10th anniversary of the Japanese debut of \"Cross\". Music from \"Chrono Cross\" has been featured in the September 2009 \"Symphonic Fantasies\" concerts, part of the Symphonic Game Music Concert series conducted by Arnie Roth. That same year, the \"Chrono Cross\" theme \"Scars of Time\" was voted first place in Hardcore Gaming 101's \"Best Video Game Music of All Time\" poll. \"Scars of Time\" was also featured in 2012 by NPR in a program about classically arranged video game scores.\nRelease and reception.\n\"Chrono Cross\" received critical acclaim, it shipped 850,000 units in Japan and 650,000 abroad by 2003. It was re-released once in the United States as a Sony Greatest Hits title and again as part of the Japanese Ultimate Hits series. \"Chrono Cross\" was also released on the PlayStation Network in Japan on July 6, 2011, and in North America on November 8, 2011, but a PAL region release has not been announced. Critics praised the game's complex plot, innovative battle system, varied characters, moving score, vibrant graphics, and success in breaking convention with its predecessor. \"Electronic Gaming Monthly\" gave \"Chrono Cross\" a Gold Award, scoring it 10/10/9.5 in their three reviewer format with the first review declaring the game to be \"a masterpiece, plain and simple\". GameSpot awarded the game a perfect 10, one of only sixteen games in the 40,000 games listed on GameSpot to have been given the score, and its Console Game of the Year Award for 2000. It also received the annual Best Role-Playing Game, Best Game Music and Best PlayStation Game awards, and nominations for Best Game Story and Best Graphics, Artistic. IGN gave the game a score of 9.7, and \"Cross\" appeared 89th in its 2008 Top 100 games list. \"Famitsu\" rated the game 36 out of 40 from four reviewers.\nFan reaction was largely positive, though certain fans complained that the game was a far departure from its predecessor, \"Chrono Trigger\"; \"Chrono Cross\" broke convention by featuring more characters, fewer double and triple techs, fewer instances of time travel, and few appearances of \"Trigger\" characters and locations. Producer Hiromichi Tanaka and director Masato Kato were aware of the changes in development, specifically intending to provide an experience different from \"Chrono Trigger\". Kato anticipated and rebuffed this discontent before the game's release, wondering what the \"Chrono\" title meant to these fans and whether his messages ever \"really got through to them\". He continued, \"\"Cross\" is undoubtedly the highest quality \"Chrono\" that we can create right now. (I won't say the 'best' \"Chrono\", but) If you can't accept that, then I'm sorry to say this but I guess your \"Chrono\" and my \"Chrono\" have taken totally different paths. But I would like to say, thank you for falling in love with \"Trigger\" so much.\" Tanaka added, \"Of course, the fans of the original are very important, but what innovation can come about when you're bound to the past? I believe that gameplay should evolve with the hardware.\" Kato later acknowledged that he could have \"shown more empathy to the player\" by making the story less complex, and acknowledged fans who felt the game was a departure from \"Chrono Trigger\", noting that one can still \"equally enjoy the game.\" He later reflected in 2015 that \"the bashing was terrible\" in reference to fans' push-back on featuring so many playable characters, acknowledging the complaint that recruiting all characters required several playthroughs.\nDuring the 4th Annual Interactive Achievement Awards, the Academy of Interactive Arts &amp; Sciences nominated \"Chrono Cross\" for the \"Game of the Year\", \"Console Game of the Year\", and \"Console Role-Playing\" awards.\nLegacy.\nOn December 9, 2021, a cross-over event between \"Chrono Cross\" and the free-to-play RPG \"Another Eden\" was released. A collaborative effort between \"Chrono\" writer Kato and composer Mitsuda, the game features elements similar to the \"Chrono\" series, such as talking frog protagonists and time-travel elements. Titled \"Complex Dream\", the event introduces several \"Chrono Cross\" characters, including Serge, Kid, and Harle, as well as gameplay elements from the series such as element magic and combo techs.\nRemaster.\nPublications began discussion of a possible remastered version of \"Chrono Cross\" in September 2021, when a security flaw allowed for a web developer to see an internal listing of current and upcoming video games in Nvidia's GeForce Now database, which included a never-announced \"Chrono Cross Remastered\". Nvidia later confirmed that the list was real, but that the games listed were speculative, and may or may not end up getting a final release. A second Nvidia leak occurred the following November, which again listed \"Chrono Cross Remastered\", this time with a December 2021 release date. Further comments on the game's existence also arose in November; Video Games Chronicle reported Nick Baker of the XboxEra podcast could confirm prior reports of its existence, and game website \"Gematsu\" separately confirmed the game's existence. On December 4, 2021, Square Enix announced a cross over event between \"Chrono Cross\" and mobile game \"Another Eden\"; the announcement spurred more discussion on a remaster, considering Square was reviving the game for the first time in 20 years, and writer Masato Kato worked on both games.\nA remaster of the game, titled \"Chrono Cross: The Radical Dreamers Edition,\" was announced on February 9, 2022, during a Nintendo Direct presentation, being slated for release on April 7, 2022, for Nintendo Switch, PlayStation 4, Windows, and Xbox One. The remaster of the title includes quality-of-life updates such as the ability to disable encounters, in addition to an enhanced OST. The remaster is also bundled with the text adventure game \"Radical Dreamers\", previously only available to Japanese players through the Satellaview peripheral for the Super Famicom. Masato Kato, Yasunori Mitsuda, Nobuteru Yuuki, and Hiromichi Tanaka were brought in to lightly polish the game's dialogue, music, character art, and mechanics, respectively. Tanaka revealed that the game's assets, stored on magnetic tape after development ceased in 1999, were lost in the intervening years, causing him to rely on a personal backup he had maintained for certain aspects of his polishing work. Producer Koichiro Sakamoto further explained that creating the remaster required teams to painstakingly upscale the game's original location art and remap each 3D field map, sometimes relying on AI to improve the resolution. The work demanded close scrutiny to ensure no original details were missed.\nWhile \"Chrono Cross: The Radical Dreamers Edition\" was received well by critics, it received a negative reaction from players in part due to how it performed as compared to its PlayStation 1 counterpart. Analysis showed that the remastered version had its frame rate dropping quite frequently, and was also unable to cross the threshold of 30 FPS. This issue has been noticed across all the platforms it was released on.\nOn February 22, 2023, Square-Enix released an update patch for the remaster on all systems it released for which has fixed some of the various gameplay issues with the remaster, as well as updating several performance aspects of the game including increasing the game's framerate to 60fps.\nSequel.\nIn 2001, Hironobu Sakaguchi revealed the company's staff wanted to develop a new game and were discussing script ideas. Although Kato was interested in a new title, the project had not been greenlighted. Square then registered a trademark for \"Chrono Break\" worldwide, causing speculation concerning a new sequel. Nothing materialized, and the trademark was dropped in the United States on November 13, 2003, though it still stands in Japan and the European Union. Kato later returned to Square Enix as a freelancer to work on \"Children of Mana\" and \"Dawn of Mana\". Mitsuda also expressed interest in scoring a new \"Chrono\" series game. In 2005, Kato and Mitsuda teamed up to do a game called \"Deep Labyrinth\", and again in 2008 for \"Sands of Destruction\", both for the Nintendo DS. The February 2008 issue of \"Game Informer\" ranked the \"Chrono\" series eighth among the \"Top Ten Sequels in Demand\", naming the games \"steadfast legacies in the Square Enix catalogue\" and asking \"what's the damn holdup?!\" In \"Electronic Gaming Monthly\"'s June 2008 \"Retro Issue\", writer Jeremy Parish cited \"Chrono\" as the franchise video game fans would be most thrilled to see a sequel to. In the May 1, 2009, issue of \"Famitsu\", \"Chrono Trigger\" placed 14th out of 50 in a vote of most-wanted sequels by the magazine's readers. At E3 2009, SE Senior Vice President Shinji Hashimoto remarked, \"If people want a sequel, they should buy more!\""}
{"id": "7841", "revid": "286305", "url": "https://en.wikipedia.org/wiki?curid=7841", "title": "Curl Contents Language", "text": ""}
{"id": "7843", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7843", "title": "Planned economy", "text": "A planned economy is a type of economic system where investment, production and the allocation of capital goods takes place according to economy-wide economic plans and production plans. A planned economy may use centralized, decentralized, participatory or Soviet-type forms of economic planning. The level of centralization or decentralization in decision-making and participation depends on the specific type of planning mechanism employed.\nSocialist states based on the Soviet model have used central planning, although a minority such as the former Socialist Federal Republic of Yugoslavia have adopted some degree of market socialism. Market abolitionist socialism replaces factor markets with direct calculation as the means to coordinate the activities of the various socially owned economic enterprises that make up the economy. More recent approaches to socialist planning and allocation have come from some economists and computer scientists proposing planning mechanisms based on advances in computer science and information technology.\nPlanned economies contrast with unplanned economies, specifically market economies, where autonomous firms operating in markets make decisions about production, distribution, pricing and investment. Market economies that use indicative planning are variously referred to as planned market economies, mixed economies and mixed market economies. A command economy follows an administrative-command system and uses Soviet-type economic planning which was characteristic of the former Soviet Union and Eastern Bloc before most of these countries converted to market economies. This highlights the central role of hierarchical administration and public ownership of production in guiding the allocation of resources in these economic systems.\nOverview.\nIn the Hellenistic and post-Hellenistic world, \"compulsory state planning was the most characteristic trade condition for the Egyptian countryside, for Hellenistic India, and to a lesser degree the more barbaric regions of the Seleucid, the Pergamenian, the southern Arabian, and the Parthian empires\". Scholars have argued that the Incan economy was a flexible type of command economy, centered around the movement and utilization of labor instead of goods. One view of mercantilism sees it as involving planned economies.\nThe Soviet-style planned economy in Soviet Russia evolved in the wake of a continuing existing World War I war-economy as well as other policies, known as war communism (1918\u20131921), shaped to the requirements of the Russian Civil War of 1917\u20131923. These policies began their formal consolidation under an official organ of government in 1921, when the Soviet government founded Gosplan. However, the period of the New Economic Policy ( to ) intervened before the planned system of regular five-year plans started in 1928. Leon Trotsky was one of the earliest proponents of economic planning during the NEP period. Trotsky argued that specialization, the concentration of production and the use of planning could \"raise in the near future the coefficient of industrial growth not only two, but even three times higher than the pre-war rate of 6% and, perhaps, even higher\". According to historian Sheila Fitzpatrick, the scholarly consensus was that Stalin appropriated the position of the Left Opposition on such matters as industrialisation and collectivisation.\nAfter World War II (1939\u20131945) France and Great Britain practiced dirigisme \u2013 government direction of the economy through non-coercive means. The Swedish government planned public-housing models in a similar fashion as urban planning in a project called Million Programme, implemented from 1965 to 1974. Some decentralized participation in economic planning occurred across Revolutionary Spain, most notably in Catalonia, during the Spanish Revolution of 1936.\nRelationship with socialism.\nIn the May 1949 issue of the \"Monthly Review\" titled \"Why Socialism?\", Albert Einstein wrote:\nI am convinced there is only one way to eliminate these grave evils, namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilized in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child. The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow-men in place of the glorification of power and success in our present society.\nWhile socialism is not equivalent to economic planning or to the concept of a planned economy, an influential conception of socialism involves the replacement of capital markets with some form of economic planning in order to achieve \"ex-ante\" coordination of the economy. The goal of such an economic system would be to achieve conscious control over the economy by the population, specifically so that the use of the surplus product is controlled by the producers. The specific forms of planning proposed for socialism and their feasibility are subjects of the socialist calculation debate.\nComputational economic planning.\nIn 1959 Anatoly Kitov proposed a distributed computing system (Project \"Red Book\", ) with a focus on the management of the Soviet economy. Opposition from the Defence Ministry killed Kitov's plan.\nIn 1971 the socialist Allende administration of Chile launched Project Cybersyn to install a telex machine in every corporation and organization in the economy for the communication of economic data between firms and the government. The data was also fed into a computer-simulated economy for forecasting. A control room was built for real-time observation and management of the overall economy. The prototype-stage of the project showed promise when it was used to redirect supplies around a trucker's strike, but after CIA-backed Augusto Pinochet led a coup in 1973 that established a military dictatorship under his rule the program was abolished and Pinochet moved Chile towards a more liberalized market economy.\nIn their book \"Towards a New Socialism\" (1993), the computer scientist Paul Cockshott from the University of Glasgow and the economist Allin Cottrell from Wake Forest University claim to demonstrate how a democratically planned economy built on modern computer technology is possible and drives the thesis that it would be both economically more stable than the free-market economies and also morally desirable.\nCybernetics.\nThe use of computers to coordinate production in an optimal fashion has been variously proposed for socialist economies. The Polish economist Oskar Lange (1904\u20131965) argued that the computer is more efficient than the market process at solving the multitude of simultaneous equations required for allocating economic inputs efficiently (either in terms of physical quantities or monetary prices).\nIn the Soviet Union, Anatoly Kitov had proposed to the Central Committee of the Communist Party of the Soviet Union a detailed plan for the re-organization of the control of the Soviet armed forces and of the Soviet economy on the basis of a network of computing centers in 1959. Kitov's proposal was rejected, as later was the 1962 OGAS economy management network project. Soviet cybernetician, Viktor Glushkov argued that his OGAS information network would have delivered a fivefold savings return for the Soviet economy over the first fifteen-year investment.\nSalvador Allende's socialist government pioneered the 1970 Chilean distributed decision support system Project Cybersyn in an attempt to move towards a decentralized planned economy with the experimental viable system model of computed organisational structure of autonomous operative units through an algedonic feedback setting and bottom-up participative decision-making in the form of participative democracy by the Cyberfolk component.\nPortrayals in Fiction.\nThe 1888 novel \"Looking Backward\" by Edward Bellamy depicts a fictional planned economy in a United States around the year 2000 which has become a socialist utopia. Other literary portrayals of planned economies include Yevgeny Zamyatin's \"We\" (1924). \nCentral planning.\nAdvantages.\nThe government can harness land, labor, and capital to serve the economic objectives of the state. Consumer demand can be restrained in favor of greater capital investment for economic development in a desired pattern. In international comparisons, state-socialist nations have compared favorably with capitalist nations in health indicators such as infant mortality and life expectancy. However, according to Michael Ellman, the reality of this, at least regarding infant mortality, varies depending on whether official Soviet or WHO definitions are used.\nThe state can begin building massive heavy industries at once in an underdeveloped economy without waiting years for capital to accumulate through the expansion of light industry and without reliance on external financing. This is what happened in the Soviet Union during the 1930s when the government forced the share of gross national income dedicated to private consumption down from 80% to 50%. As a result of this development, the Soviet Union experienced massive growth in heavy industry, with a concurrent massive contraction of its agricultural sector due to the labor shortage.\nDisadvantages.\nEconomic instability.\nStudies of command economies of the Eastern Bloc in the 1950s and 1960s by both American and Eastern European economists found that contrary to the expectations of both groups they showed greater fluctuations in output than market economies during the same period.\nInefficient resource distribution.\nCritics of planned economies argue that planners cannot detect consumer preferences, shortages and surpluses with sufficient accuracy and therefore cannot efficiently co-ordinate production (in a market economy, a free price system is intended to serve this purpose). This difficulty was notably written about by economists Ludwig von Mises and Friedrich Hayek, who referred to subtly distinct aspects of the problem as the economic calculation problem and local knowledge problem, respectively. These distinct aspects were also present in the economic thought of Michael Polanyi.\nWhereas the former stressed the theoretical underpinnings of a market economy to subjective value theory while attacking the labor theory of value, the latter argued that the only way to satisfy individuals who have a constantly changing hierarchy of needs and are the only ones to possess their particular individual's circumstances is by allowing those with the most knowledge of their needs to have it in their power to use their resources in a competing marketplace to meet the needs of the most consumers most efficiently. This phenomenon is recognized as spontaneous order. Additionally, misallocation of resources would naturally ensue by redirecting capital away from individuals with direct knowledge and circumventing it into markets where a coercive monopoly influences behavior, ignoring market signals. According to Tibor Machan, \"[w]ithout a market in which allocations can be made in obedience to the law of supply and demand, it is difficult or impossible to funnel resources with respect to actual human preferences and goals\".\nHistorian Robert Vincent Daniels regarded the Stalinist period to represent an abrupt break with Lenin's government in terms of economic planning in which an deliberated, scientific system of planning that featured former Menshevik economists at Gosplan had been replaced with a hasty version of planning with unrealistic targets, bureaucratic waste, bottlenecks and shortages. Stalin's formulations of national plans in terms of physical quantity of output was also attributed by Daniels as a source for the stagnant levels of efficiency and quality.\nSuppression of economic democracy and self-management.\nEconomist Robin Hahnel, who supports participatory economics, a form of socialist decentralized planned economy, notes that even if central planning overcame its inherent inhibitions of incentives and innovation, it would nevertheless be unable to maximize economic democracy and self-management, which he believes are concepts that are more intellectually coherent, consistent and just than mainstream notions of economic freedom. Furthermore, Hahnel states:\nCombined with a more democratic political system, and redone to closer approximate a best case version, centrally planned economies no doubt would have performed better. But they could never have delivered economic self-management, they would always have been slow to innovate as apathy and frustration took their inevitable toll, and they would always have been susceptible to growing inequities and inefficiencies as the effects of differential economic power grew. Under central planning neither planners, managers, nor workers had incentives to promote the social economic interest. Nor did impeding markets for final goods to the planning system enfranchise consumers in meaningful ways. But central planning would have been incompatible with economic democracy even if it had overcome its information and incentive liabilities. And the truth is that it survived as long as it did only because it was propped up by unprecedented totalitarian political power.\nCommand economy.\nPlanned economies contrast with command economies in that a planned economy is \"an economic system in which the government controls and regulates production, distribution, prices, etc.\" whereas a command economy necessarily has substantial public ownership of industry while also having this type of regulation. In command economies, important allocation decisions are made by government authorities and are imposed by law.\nThis is contested by some Marxists. Decentralized planning has been proposed as a basis for socialism and has been variously advocated by anarchists, council communists, libertarian Marxists and other democratic and libertarian socialists who advocate a non-market form of socialism, in total rejection of the type of planning adopted in the economy of the Soviet Union.\nMost of a command economy is organized in a top-down administrative model by a central authority, where decisions regarding investment and production output requirements are decided upon at the top in the chain of command, with little input from lower levels. Advocates of economic planning have sometimes been staunch critics of these command economies. Leon Trotsky believed that those at the top of the chain of command, regardless of their intellectual capacity, operated without the input and participation of the millions of people who participate in the economy and who understand/respond to local conditions and changes in the economy. Therefore, they would be unable to effectively coordinate all economic activity.\nHistorians have associated planned economies with Marxist\u2013Leninist states and the Soviet economic model. Since the 1980s, it has been contested that the Soviet economic model did not actually constitute a planned economy in that a comprehensive and binding plan did not guide production and investment. The further distinction of an administrative-command system emerged as a new designation in some academic circles for the economic system that existed in the former Soviet Union and Eastern Bloc, highlighting the role of centralized hierarchical decision-making in the absence of popular control over the economy. The possibility of a digital planned economy was explored in Chile between 1971 and 1973 with the development of Project Cybersyn and by Aleksandr Aleksandrovich Kharkevich, head of the Department of Technical Physics in Kiev in 1962.\nWhile both economic planning and a planned economy can be either authoritarian or democratic and participatory, democratic socialist critics argue that command economies under modern-day communism is highly undemocratic and totalitarian in practice. Indicative planning is a form of economic planning in market economies that directs the economy through incentive-based methods. Economic planning can be practiced in a decentralized manner through different government authorities. In some predominantly market-oriented and Western mixed economies, the state utilizes economic planning in strategic industries such as the aerospace industry. Mixed economies usually employ macroeconomic planning while micro-economic affairs are left to the market and price system.\nDecentralized planning.\nA decentralized-planned economy, occasionally called horizontally planned economy due to its horizontalism, is a type of planned economy in which the investment and allocation of consumer and capital goods is explicated accordingly to an economy-wide plan built and operatively coordinated through a distributed network of disparate economic agents or even production units itself. Decentralized planning is usually held in contrast to centralized planning, in particular the Soviet-type economic planning of the Soviet Union's command economy, where economic information is aggregated and used to formulate a plan for production, investment and resource allocation by a single central authority. Decentralized planning can take shape both in the context of a mixed economy as well as in a post-capitalist economic system. This form of economic planning implies some process of democratic and participatory decision-making within the economy and within firms itself in the form of industrial democracy. Computer-based forms of democratic economic planning and coordination between economic enterprises have also been proposed by various computer scientists and radical economists. Proponents present decentralized and participatory economic planning as an alternative to market socialism for a post-capitalist society.\nDecentralized planning has been a feature of anarchist and socialist economics. Variations of decentralized planning such as economic democracy, industrial democracy and participatory economics have been promoted by various political groups, most notably anarchists, democratic socialists, guild socialists, libertarian Marxists, libertarian socialists, revolutionary syndicalists and Trotskyists. During the Spanish Revolution, some areas where anarchist and libertarian socialist influence through the CNT and UGT was extensive, particularly rural regions, were run on the basis of decentralized planning resembling the principles laid out by anarcho-syndicalist Diego Abad de Santillan in the book \"After the Revolution\". Trotsky had urged economic decentralisation between the state, oblast regions and factories during the NEP period to counter structural inefficiency and the problem of bureaucracy.\nModels.\nNegotiated coordination.\nEconomist Pat Devine has created a model of decentralized economic planning called \"negotiated coordination\" which is based upon social ownership of the means of production by those affected by the use of the assets involved, with the allocation of consumer and capital goods made through a participatory form of decision-making by those at the most localized level of production. Moreover, organizations that utilize modularity in their production processes may distribute problem solving and decision making.\nParticipatory planning.\nThe planning structure of a decentralized planned economy is generally based on a consumers council and producer council (or jointly, a distributive cooperative) which is sometimes called a consumers' cooperative. Producers and consumers, or their representatives, negotiate the quality and quantity of what is to be produced. This structure is central to guild socialism, participatory economics and the economic theories related to anarchism.\nPractice.\nKerala.\nSome decentralized participation in economic planning has been implemented in various regions and states in India, most notably in Kerala. Local level planning agencies assess the needs of people who are able to give their direct input through the Gram Sabhas (village-based institutions) and the planners subsequently seek to plan accordingly.\nRevolutionary Catalonia.\nSome decentralized participation in economic planning has been implemented across Revolutionary Spain, most notably in Catalonia, during the Spanish Revolution of 1936.\nSimilar concepts in practice.\nCommunity participatory planning.\nThe United Nations has developed local projects that promote participatory planning on a community level, requiring opportunities for all people to be politically involved and share in the community development process."}
{"id": "7844", "revid": "44218489", "url": "https://en.wikipedia.org/wiki?curid=7844", "title": "Chimpanzee", "text": "The chimpanzee (; Pan troglodytes), also simply known as the chimp, is a species of great ape native to the forests and savannahs of tropical Africa. It has four confirmed subspecies and a fifth proposed one. When its close relative the bonobo was more commonly known as the pygmy chimpanzee, this species was often called the common chimpanzee or the robust chimpanzee. The chimpanzee and the bonobo are the only species in the genus \"Pan\". Evidence from fossils and DNA sequencing shows that \"Pan\" is a sister taxon to the human lineage and is thus humans' closest living relative.\nThe chimpanzee is covered in coarse black hair but has a bare face, fingers, toes, palms of the hands, and soles of the feet. It is larger and more robust than the bonobo, weighing for males and for females and standing .\nThe chimpanzee lives in groups that range in size from 15 to 150 members, although individuals travel and forage in much smaller groups during the day. The species lives in a strict male-dominated hierarchy, where disputes are generally settled without the need for violence. Nearly all chimpanzee populations have been recorded using tools, modifying sticks, rocks, grass and leaves and using them for hunting and acquiring honey, termites, ants, nuts and water. The species has also been found creating sharpened sticks to spear small mammals. Its gestation period is eight months. The infant is weaned at about three years old but usually maintains a close relationship with its mother for several years more.\nThe chimpanzee is listed on the IUCN Red List as an endangered species. Between 170,000 and 300,000 individuals are estimated across its range. The biggest threats to the chimpanzee are habitat loss, poaching, and disease. Chimpanzees appear in Western popular culture as stereotyped clown-figures and have featured in entertainments such as chimpanzees' tea parties, circus acts and stage shows. Although chimpanzees have been kept as pets, their strength, aggressiveness, and unpredictability makes them dangerous in this role. Some hundreds have been kept in laboratories for research, especially in the United States. Many attempts have been made to teach languages such as American Sign Language to chimpanzees, with limited success.\nEtymology.\nThe English word \"chimpanzee\" is first recorded in 1738. It is derived from Vili \"ci-mpenze\" or Tshiluba language \"chimpenze\", with a meaning of \"ape\", or \"mockman\". The colloquialism \"chimp\" was most likely coined some time in the late 1870s. The genus name \"Pan\" derives from the Greek god, while the specific name \"troglodytes\" was taken from the Troglodytae, a mythical race of cave-dwellers.\nTaxonomy.\nThe first great ape known to Western science in the 17th century was the \"orang-outang\" (genus \"Pongo\"), the local Malay name being recorded in Java by the Dutch physician Jacobus Bontius. In 1641, the Dutch anatomist Nicolaes Tulp applied the name to a chimpanzee or bonobo brought to the Netherlands from Angola. Another Dutch anatomist, Peter Camper, dissected specimens from Central Africa and Southeast Asia in the 1770s, noting the differences between the African and Asian apes. The German naturalist Johann Friedrich Blumenbach classified the chimpanzee as \"Simia troglodytes\" by 1775. Another German naturalist, Lorenz Oken, coined the genus \"Pan\" in 1816. The bonobo was recognised as distinct from the chimpanzee by 1933.\nEvolution.\nDespite a large number of \"Homo\" fossil finds, \"Pan\" fossils were not described until 2005. Existing chimpanzee populations in West and Central Africa do not overlap with the major human fossil sites in East Africa, but chimpanzee fossils have now been reported from Kenya. This indicates that both humans and members of the \"Pan\" clade were present in the East African Rift Valley during the Middle Pleistocene.\nAccording to studies published in 2017 by researchers at George Washington University, bonobos, along with chimpanzees, split from the human line about 8 million years ago; then bonobos split from the common chimpanzee line about 2 million years ago. Another 2017 genetic study suggests ancient gene flow (introgression) between 200,000 and 550,000 years ago from the bonobo into the ancestors of central and eastern chimpanzees.\nSubspecies and population status.\nFour subspecies of the chimpanzee have been recognised, with the possibility of a fifth:\nGenome.\nA draft version of the chimpanzee genome was published in 2005 and encodes 18,759 proteins, (compared to 20,383 in the human proteome). The DNA sequences of humans and chimpanzees are very similar and the difference in protein number mostly arises from incomplete sequences in the chimpanzee genome. Both species differ by about 35 million single-nucleotide changes, five million insertion/deletion events and various chromosomal rearrangements. Typical human and chimpanzee protein homologs differ in an average of only two amino acids. About 30% of all human proteins are identical in sequence to the corresponding chimpanzee protein. Duplications of small parts of chromosomes have been the major source of differences between human and chimpanzee genetic material; about 2.7% of the corresponding modern genomes represent differences, produced by gene duplications or deletions, since humans and chimpanzees diverged from their common evolutionary ancestor.\nCharacteristics.\nAdult chimpanzees have an average standing height of . Wild adult males weigh between , and females weigh between . In exceptional cases, certain individuals may considerably exceed these measurements, standing over on two legs and weighing up to in captivity.\nThe chimpanzee is more robustly built than the bonobo but less than the gorilla. The arms of a chimpanzee are longer than its legs and can reach below the knees. The hands have long fingers with short thumbs and flat fingernails. The feet are adapted for grasping, and the big toe is opposable. The pelvis is long with an extended ilium. A chimpanzee's head is rounded with a prominent and prognathous face and a pronounced brow ridge. It has forward-facing eyes, a small nose, rounded non-lobed ears and a long mobile upper lip. Additionally, adult males have sharp canine teeth. Like all great apes, it has a dental formula of , that is, two incisors, one canine, two premolars, and three molars on both halves of each jaw. Chimpanzees lack the prominent sagittal crest and associated head and neck musculature of gorillas.\nChimpanzee bodies are covered by coarse hair, except for the face, fingers, toes, palms of the hands, and soles of the feet. Chimpanzees lose more hair as they age and develop bald spots. The hair of a chimpanzee is typically black but can be brown or ginger. As they get older, white or grey patches may appear, particularly on the chin and lower region. Chimpanzee skin that is covered with body hair is white, while exposed areas vary: white which ages into a dark muddy colour in eastern chimpanzees, freckled on white which ages to a heavily mottled muddy colour in central chimpanzees, and black with a butterfly-shaped white mask that darkens with age in western chimpanzees. Facial pigmentation increases with age and exposure to ultraviolet light. Females develop swelling pink skin when in oestrus. Like bonobos, male chimpanzees have a long filiform penis with a small baculum, but without a glans.\nChimpanzees are adapted for both arboreal and terrestrial locomotion. Arboreal locomotion consists of vertical climbing and brachiation. On the ground, chimpanzees move both quadrupedally and bipedally. These movements appear to have similar energy costs. As with bonobos and gorillas, chimpanzees move quadrupedally by knuckle-walking, which probably evolved independently in \"Pan\" and \"Gorilla\". Their muscles are 50% stronger per weight than those of humans due to higher content of fast twitch muscle fibres, one of the chimpanzee's adaptations for climbing and swinging. According to Japan's Asahiyama Zoo, the grip strength of an adult chimpanzee is estimated to be , while other sources claim figures of up to .\nEcology.\nThe chimpanzee is a highly adaptable species. It lives in a variety of habitats, including dry savanna, evergreen rainforest, montane forest, swamp forest, and dry woodland-savanna mosaic. In Gombe, the chimpanzee mostly uses semideciduous and evergreen forest as well as open woodland. At Bossou, the chimpanzee inhabits multistage secondary deciduous forest, which has grown after shifting cultivation, as well as primary forest and grassland. At Ta\u00ef, it is found in the last remaining tropical rain forest in Ivory Coast. The chimpanzee has an advanced cognitive map of its home range and can repeatedly find food. The chimpanzee builds a sleeping nest in a tree in a different location each night, never using the same nest more than once. Chimpanzees sleep alone in separate nests except for infants or juvenile chimpanzees, which sleep with their mothers.\nDiet.\nThe chimpanzee is an omnivorous frugivore. It prefers fruit above all other food, but it also eats leaves, leaf buds, seeds, blossoms, stems, pith, bark, and resin. A study in Budongo Forest, Uganda found that 64.5% of their feeding time concentrated on fruits (84.6% of which being ripe), particularly those from two species of \"Ficus\", \"Maesopsis eminii\", and \"Celtis gomphophylla\". In addition, 19% of feeding time was spent on arboreal leaves, mostly \"Broussonetia papyrifera\" and \"Celtis mildbraedii\". While the chimpanzee is mostly herbivorous, it does eat honey, soil, insects, birds and their eggs, and small to medium-sized mammals, including other primates. Insect species consumed include the weaver ant \"Oecophylla longinoda\", \"Macrotermes\" termites, and honey bees. The red colobus ranks at the top of preferred mammal prey. Other mammalian prey include red-tailed monkeys, infant and juvenile yellow baboons, bush babies, blue duikers, bushbucks, and common warthogs.\nDespite the fact that chimpanzees are known to hunt and to collect both insects and other invertebrates, such food actually makes up a very small portion of their diet, from as little as 2% yearly to as much as 65 grams of animal flesh per day for each adult chimpanzee in peak hunting seasons. This also varies from troop to troop and year to year. However, in all cases, the majority of their diet consists of fruits, leaves, roots, and other plant matter. Female chimpanzees appear to consume much less animal flesh than males, according to several studies. Jane Goodall documented many occasions within Gombe Stream National Park of chimpanzees and western red colobus monkeys ignoring each other despite close proximity.\nChimpanzees do not appear to directly compete with gorillas in areas where they overlap. When fruit is abundant, gorilla and chimpanzee diets converge, but when fruit is scarce gorillas resort to vegetation. The two apes may also feed on different species, whether fruit or insects. Interactions between them can range from friendly and even stable social bonding, to avoidance, to aggression and even predation of infants on the part of chimpanzees.\nMortality and health.\nThe average lifespan of a wild chimpanzee is relatively short. They usually live less than 15 years, although individuals that reach 12 years may live an additional 15 years. On rare occasions, wild chimpanzees may live nearly 60 years. Captive chimpanzees tend to live longer than most wild ones, with median lifespans of 31.7 years for males and 38.7 years for females. The oldest-known male captive chimpanzee to have been documented lived to 66 years, and the oldest female, Little Mama, was nearly 80 years old.\nLeopards prey on chimpanzees in some areas. It is possible that much of the mortality caused by leopards can be attributed to individuals that have specialised in killing chimpanzees. Chimpanzees may react to a leopard's presence with loud vocalising, branch shaking, and throwing objects. There is at least one record of chimpanzees killing a leopard cub after mobbing it and its mother in their den. Four chimpanzees could have fallen prey to lions at Mahale Mountains National Park. Although no other instances of lion predation on chimpanzees have been recorded, lions likely do kill chimpanzees occasionally, and the larger group sizes of savanna chimpanzees may have developed as a response to threats from these big cats. Chimpanzees may react to lions by fleeing up trees, vocalising, or hiding in silence.\nChimpanzees and humans share only 50% of their parasite and microbe species. This is due to the differences in environmental and dietary adaptations; human internal parasite species overlap more with omnivorous, savanna-dwelling baboons. The chimpanzee is host to the louse species \"Pediculus schaeffi\", a close relative of \"P. humanus\", which infests human head and body hair. By contrast, the human pubic louse \"Pthirus pubis\" is closely related to \"Pthirus gorillae\", which infests gorillas. A 2017 study of gastrointestinal parasites of wild chimpanzees in degraded forest in Uganda found nine species of protozoa, five nematodes, one cestode, and one trematode. The most prevalent species was the protozoan \"Troglodytella abrassarti\".\nBehaviour.\nRecent studies have suggested that human observers influence chimpanzee behaviour. One suggestion is that drones, camera traps, and remote microphones should be used to record and monitor chimpanzees rather than direct human observation.\nGroup structure.\nChimpanzees live in communities that typically range from around 15 to more than 150 members but spend most of their time traveling in small, temporary groups consisting of a few individuals. These groups may consist of any combination of age and sexes. Both males and females sometimes travel alone. This fission\u2013fusion society may include groups of four types: all-male, adult females and offspring, adults of both sexes, or one female and her offspring. These smaller groups emerge in a variety of types, for a variety of purposes. For example, an all-male troop may be organised to hunt for meat, while a group consisting of lactating females serves to act as a \"nursery group\" for the young.\nAt the core of social structures are males, which patrol the territory, protect group members, and search for food. Males remain in their natal communities, while females generally emigrate at adolescence. Males in a community are more likely to be related to one another than females are to each other. Among males, there is generally a dominance hierarchy, and males are dominant over females. However, this unusual fission-fusion social structure, \"in which portions of the parent group may on a regular basis separate from and then rejoin the rest,\" is highly variable in terms of which particular individual chimpanzees congregate at a given time. This is caused mainly by the large measure of individual autonomy that individuals have within their fission-fusion social groups. As a result, individual chimpanzees often forage for food alone, or in smaller groups, as opposed to the much larger \"parent\" group, which encompasses all the chimpanzees which regularly come into contact with each other and congregate into parties in a particular area.\nMale chimpanzees exist in a linear dominance hierarchy. Top-ranking males tend to be aggressive even during dominance stability. This is probably due to the chimpanzee's fission-fusion society, with male chimpanzees leaving groups and returning after extended periods of time. With this, a dominant male is unsure if any \"political maneuvering\" has occurred in his absence and must re-establish his dominance. Thus, a large amount of aggression occurs within five to fifteen minutes after a reunion. During these encounters, displays of aggression are generally preferred over physical attacks.\nMales maintain and improve their social ranks by forming coalitions, which have been characterised as \"exploitative\" and based on an individual's influence in agonistic interactions. Being in a coalition allows males to dominate a third individual when they could not by themselves, as politically apt chimpanzees can exert power over aggressive interactions regardless of their rank. Coalitions can also give an individual male the confidence to challenge a dominant or larger male. The more allies a male has, the better his chance of becoming dominant. However, most changes in hierarchical rank are caused by dyadic interactions. Chimpanzee alliances can be very fickle, and one member may suddenly turn on another if it is to his advantage.\nLow-ranking males frequently switch sides in disputes between more dominant individuals. Low-ranking males benefit from an unstable hierarchy and often find increased sexual opportunities if a dispute or conflict occurs. In addition, conflicts between dominant males cause them to focus on each other rather than the lower-ranking males. Social hierarchies among adult females tend to be weaker. Nevertheless, the status of an adult female may be important for her offspring. Females in Ta\u00ef have also been recorded to form alliances. While chimpanzee social structure is often referred to as patriarchal, it is not entirely unheard of for females to forge coalitions against males. There is also at least one recorded case of females securing a dominant position over males in their respective troop, albeit in a captive environment. Social grooming appears to be important in the formation and maintenance of coalitions. It is more common among adult males than either between adult females or between males and females.\nChimpanzees have been described as highly territorial and will frequently kill other chimpanzees, although Margaret Power wrote in her 1991 book \"The Egalitarians\" that the field studies from which the aggressive data came, Gombe and Mahale, used artificial feeding systems that increased aggression in the chimpanzee populations studied. Thus, the behaviour may not reflect innate characteristics of the species as a whole. In the years following her artificial feeding conditions at Gombe, Jane Goodall described groups of male chimpanzees patrolling the borders of their territory, brutally attacking chimpanzees that had split off from the Gombe group. A study published in 2010 found that the chimpanzees wage wars over territory, not mates. Patrols from smaller groups are more likely to avoid contact with their neighbours. Patrols from large groups even take over a smaller group's territory, gaining access to more resources, food, and females. While it was traditionally accepted that only female chimpanzees immigrate and males remain in their natal troop for life, there are confirmed cases of adult males safely integrating themselves into new communities among West African chimpanzees, suggesting they are less territorial than other subspecies.\nMating and parenting.\nChimpanzees mate throughout the year, although the number of females in oestrus varies seasonally in a group. Female chimpanzees are more likely to come into oestrus when food is readily available. Oestrous females exhibit sexual swellings. Chimpanzees are promiscuous: during oestrus, females mate with several males in their community, while males have large testicles for sperm competition. Other forms of mating also exist. A community's dominant males sometimes restrict reproductive access to females. A male and female can form a consortship and mate outside their community. In addition, females sometimes leave their community and mate with males from neighboring communities. These alternative mating strategies give females more mating opportunities without losing the support of the males in their community. Infanticide has been recorded in chimpanzee communities in some areas, and the victims are often consumed. Male chimpanzees practice infanticide on unrelated young to shorten the interbirth intervals in the females. Females sometimes practice infanticide. This may be related to the dominance hierarchy in females or may simply be pathological.\nInbreeding was studied in a relatively undisturbed eastern chimpanzee community that displayed substantial bisexual philopatry. Despite an increased inbreeding risk incurred by females who do not disperse before reaching reproductive age, these females were still able to avoid producing inbred offspring.\nCopulation is brief, lasting approximately seven seconds. The gestation period is eight months. Care for the young is provided mostly by their mothers. The survival and emotional health of the young is dependent on maternal care. Mothers provide their young with food, warmth, and protection, and teach them certain skills. In addition, a chimpanzee's future rank may be dependent on its mother's status. Male chimpanzees continue to associate with the females they impregnated and interact with and support their offspring. Newborn chimpanzees are helpless. For example, their grasping reflex is not strong enough to support them for more than a few seconds. For their first 30 days, infants cling to their mother's bellies. Infants are unable to support their own weight for their first two months and need their mothers' support.\nWhen they reach five to six months, infants ride on their mothers' backs. They remain in continual contact for the rest of their first year. When they reach two years of age, they are able to move and sit independently and start moving beyond the arms' reach of their mothers. By four to six years, chimpanzees are weaned and infancy ends. The juvenile period for chimpanzees lasts from their sixth to ninth years. Juveniles remain close to their mothers, but interact an increasing amount with other members of their community. Adolescent females move between groups and are supported by their mothers in agonistic encounters. Adolescent males spend time with adult males in social activities like hunting and boundary patrolling. A captive study suggests males can safely immigrate to a new group if accompanied by immigrant females who have an existing relationship with this male. This gives the resident males reproductive advantages with these females, as they are more inclined to remain in the group if their male friend is also accepted.\nCommunication.\nChimpanzees use facial expressions, postures, and sounds to communicate with each other. Chimpanzees have expressive faces that are important in close-up communications. When frightened, a \"full closed grin\" causes nearby individuals to be fearful, as well. Playful chimpanzees display an open-mouthed grin. Chimpanzees may also express themselves with the \"pout\", which is made in distress, the \"sneer\", which is made when threatening or fearful, and \"compressed-lips face\", which is a type of display. When submitting to a dominant individual, a chimpanzee crunches, bobs, and extends a hand. When in an aggressive mode, a chimpanzee swaggers bipedally, hunched over and arms waving, in an attempt to exaggerate its size. While travelling, chimpanzees keep in contact by beating their hands and feet against the trunks of large trees, an act that is known as \"drumming\". They also do this when encountering individuals from other communities.\nVocalisations are also important in chimpanzee communication. The most common call in adults is the \"pant-hoot\", which may signal social rank and bond along with keeping groups together. Pant-hoots are made of four parts, starting with soft \"hoos\", the introduction; that gets louder and louder, the build-up; and climax into screams and sometimes barks; these die down back to soft \"hoos\" during the letdown phase as the call ends. Grunting is made in situations like feeding and greeting. Submissive individuals make \"pant-grunts\" towards their superiors. Whimpering is made by young chimpanzees as a form of begging or when lost from the group. Chimpanzees use distance calls to draw attention to danger, food sources, or other community members. \"Barks\" may be made as \"short barks\" when hunting and \"tonal barks\" when sighting large snakes.\nHunting.\nWhen hunting small monkeys such as the red colobus, chimpanzees hunt where the forest canopy is interrupted or irregular. This allows them to easily corner the monkeys when chasing them in the appropriate direction. Chimpanzees may also hunt as a coordinated team, so that they can corner their prey even in a continuous canopy. During an arboreal hunt, each chimpanzee in the hunting groups has a role. \"Drivers\" serve to keep the prey running in a certain direction and follow them without attempting to make a catch. \"Blockers\" are stationed at the bottom of the trees and climb up to block prey that takes off in a different direction. \"Chasers\" move quickly and try to make a catch. Finally, \"ambushers\" hide and rush out when a monkey nears. While both adults and infants are taken, adult male colobus monkeys will attack the hunting chimps. When caught and killed, the meal is distributed to all hunting party members and even bystanders.\nMale chimpanzees hunt in groups more than females. Female chimpanzees tend to hunt solitarily. If a female chimpanzee were to participate in the hunting group and catch a Red Colobus, it would likely immediately be taken by an adult male. Female chimpanzees are estimated to hunt \u2248 10-15% of a community's vertebrates.\nIntelligence.\nChimpanzees display numerous signs of intelligence, from the ability to remember symbols to cooperation, tool use, and varied language capabilities. They are among species that have passed the mirror test, suggesting self-awareness. In one study, two young chimpanzees showed retention of mirror self-recognition after one year without access to mirrors. Chimpanzees have been observed to use insects to treat their own wounds and those of others. They catch them and apply them directly to the injury. Chimpanzees also display signs of culture among groups, with the learning and transmission of variations in grooming, tool use and foraging techniques leading to localized traditions.\nA 30-year study at Kyoto University's Primate Research Institute has shown that chimpanzees are able to learn to recognise the numbers 1 to 9 and their values. The chimpanzees further show an aptitude for eidetic memory, demonstrated in experiments in which the jumbled digits are flashed onto a computer screen for less than a quarter of a second. One chimpanzee, Ayumu, was able to correctly and quickly point to the positions where they appeared in ascending order. Ayumu performed better than human adults who were given the same test.\nIn controlled experiments on cooperation, chimpanzees show a basic understanding of cooperation, and recruit the best collaborators. In a group setting with a device that delivered food rewards only to cooperating chimpanzees, cooperation first increased, then, due to competitive behaviour, decreased, before finally increasing to the highest level through punishment and other arbitrage behaviours.\nGreat apes show laughter-like vocalisations in response to physical contact, such as wrestling, play chasing, or tickling. This is documented in wild and captive chimpanzees. Chimpanzee laughter is not readily recognisable to humans as such, because it is generated by alternating inhalations and exhalations that sound more like breathing and panting. Instances in which nonhuman primates have expressed joy have been reported. Humans and chimpanzees share similar ticklish areas of the body, such as the armpits and belly. The enjoyment of tickling in chimpanzees does not diminish with age.\nChimpanzees have displayed different behaviours in response to a dying or dead group member. When witnessing a sudden death, the other group members act in frenzy, with vocalisations, aggressive displays, and touching of the corpse. In one case chimpanzees cared for a dying elder, then attended and cleaned the corpse. Afterward, they avoided the spot where the elder died and behaved in a more subdued manner. Mothers have been reported to carry around and groom their dead infants for several days.\nExperimenters now and then witness behaviour that cannot be readily reconciled with chimpanzee intelligence or theory of mind. Wolfgang K\u00f6hler, for instance, reported insightful behaviour in chimpanzees, but he likewise often observed that they experienced \"special difficulty\" in solving simple problems. Researchers also reported that, when faced with a choice between two persons, chimpanzees were just as likely to beg food from a person who could see the begging gesture as from a person who could not, thereby raising the possibility that chimpanzees lack theory of mind.\nTool use.\nNearly all chimpanzee populations have been recorded using tools. They modify sticks, rocks, grass, and leaves and use them when foraging for termites and ants, nuts, honey, algae or water. Despite the lack of complexity, forethought and skill are apparent in making these tools. Chimpanzees have used stone tools since at least 4,300 years ago.\nA chimpanzee from the Kasakela chimpanzee community was the first nonhuman animal reported making a tool, by modifying a twig to use as an instrument for extracting termites from their mound. At Ta\u00ef, chimpanzees simply use their hands to extract termites. When foraging for honey, chimpanzees use modified short sticks to scoop the honey out of the hive if the bees are stingless. For hives of the dangerous African honeybees, chimpanzees use longer and thinner sticks to extract the honey.\nChimpanzees also fish for ants using the same tactic. Ant dipping is difficult and some chimpanzees never master it. West African chimpanzees crack open hard nuts with stones or branches. Some forethought in this activity is apparent, as these tools are not found together or where the nuts are collected. Nut cracking is also difficult and must be learned. Chimpanzees also use leaves as sponges or spoons to drink water.\nWest African chimpanzees in Senegal were found to sharpen sticks with their teeth, which were then used to spear Senegal bushbabies out of small holes in trees. An eastern chimpanzee has been observed using a modified branch as a tool to capture a squirrel.\nWhilst experimental studies on captive chimpanzees have found that many of their species-typical tool-use behaviours can be individually learnt by each chimpanzees, a 2021 study on their abilities to make and use stone flakes, in a similar way as hypothesised for early hominins, did not find this behaviour across two populations of chimpanzees\u2014suggesting that this behaviour is outside the chimpanzee species-typical range.\nLanguage.\nScientists have attempted to teach human language to several species of great ape. One early attempt by Allen and Beatrix Gardner in the 1960s involved spending 51 months teaching American Sign Language to a chimpanzee named Washoe. The Gardners reported that Washoe learned 151 signs, and had spontaneously taught them to other chimpanzees, including her adopted son, Loulis. Over a longer period of time, Washoe was reported to have learned over 350 signs.\nDebate is ongoing among scientists such as David Premack about chimpanzees' ability to learn language. Since the early reports on Washoe, numerous other studies have been conducted, with varying levels of success. One involved a chimpanzee jokingly named Nim Chimpsky (in allusion to the theorist of language Noam Chomsky), trained by Herbert Terrace of Columbia University. Although his initial reports were quite positive, in November 1979, Terrace and his team, including psycholinguist Thomas Bever, re-evaluated the videotapes of Nim with his trainers, analyzing them frame by frame for signs, as well as for exact context (what was happening both before and after Nim's signs). In the reanalysis, Terrace and Bever concluded that Nim's utterances could be explained merely as prompting on the part of the experimenters, as well as mistakes in reporting the data. \"Much of the apes' behaviour is pure drill\", he said. \"Language still stands as an important definition of the human species.\" In this reversal, Terrace now argued Nim's use of ASL was not like human language acquisition. Nim never initiated conversations himself, rarely introduced new words, and mostly imitated what the humans did. More importantly, Nim's word strings varied in their ordering, suggesting that he was incapable of syntax. Nim's sentences also did not grow in length, unlike human children whose vocabulary and sentence length show a strong positive correlation.\nHuman relations.\nIn culture.\nChimpanzees are rarely represented in African culture, as people find them \"too close for comfort\". The Gio people of Liberia and the Hemba people of the Congo make chimpanzee masks. Gio masks are crude and blocky, and worn when teaching young people how not to behave. The Hemba masks have a smile that suggests drunken anger, insanity or horror and are worn during rituals at funerals, representing the \"awful reality of death\". The masks may also serve to guard households and protect both human and plant fertility. Stories have been told of chimpanzees kidnapping and raping women.\nIn Western popular culture, chimpanzees have occasionally been stereotyped as childlike companions, sidekicks or clowns. They are especially suited for the latter role on account of their prominent facial features, long limbs and fast movements, which humans often find amusing. Accordingly, entertainment acts featuring chimpanzees dressed up as humans with lip-synchronised human voices have been traditional staples of circuses, stage shows and TV shows like \"Lancelot Link, Secret Chimp\" (1970\u20131972) and \"The Chimp Channel\" (1999). From 1926 until 1972, London Zoo, followed by several other zoos around the world, held a chimpanzees' tea party daily, inspiring a long-running series of advertisements for PG Tips tea featuring such a party. Animal rights groups have urged a stop to such acts, considering them abusive.\nChimpanzees in media include Judy on the television series \"Daktari\" in the 1960s and Darwin on \"The Wild Thornberrys\" in the 1990s. In contrast to the fictional depictions of other animals, such as dogs (as in \"Lassie\"), dolphins (\"Flipper\"), horses (\"The Black Stallion\") or even other great apes (\"King Kong\"), chimpanzee characters and actions are rarely relevant to the plot. Depictions of chimpanzees as individuals rather than stock characters, and as central rather than incidental to the plot can be found in science fiction. Robert A. Heinlein's 1947 short story \"Jerry Was a Man\" concerns a genetically enhanced chimpanzee suing for better treatment. The 1972 film \"Conquest of the Planet of the Apes\", the third sequel of the 1968 film \"Planet of the Apes\", portrays a futuristic revolt of enslaved apes led by the only talking chimpanzee, Caesar, against their human masters.\nAs pets.\nChimpanzees have traditionally been kept as pets in a few African villages, especially in the Democratic Republic of Congo. In Virunga National Park in the east of the country, the park authorities regularly seize chimpanzees from people keeping them as pets. Outside their range, chimpanzees are popular as exotic pets despite their strength and aggression. Even in places where keeping non-human primates as pets is illegal, the exotic pet trade continues to prosper, leading to injuries from attacks.\nUse in research.\nHundreds of chimpanzees have been kept in laboratories for research. Most such laboratories either conduct or make the animals available for invasive research, defined as \"inoculation with an infectious agent, surgery or biopsy conducted for the sake of research and not for the sake of the chimpanzee, and/or drug testing\". Research chimpanzees tend to be used repeatedly over decades for up to 40 years, unlike the pattern of use of most laboratory animals. Two federally funded American laboratories use chimpanzees: the Yerkes National Primate Research Center at Emory University in Atlanta, Georgia, and the Southwest National Primate Center in San Antonio, Texas. Five hundred chimpanzees have been retired from laboratory use in the US and live in animal sanctuaries in the US or Canada.\nA five-year moratorium was imposed by the US National Institutes of Health in 1996, because too many chimpanzees had been bred for HIV research, and it has been extended annually since 2001. With the publication of the chimpanzee genome, plans to increase the use of chimpanzees in America were reportedly increasing in 2006, some scientists arguing that the federal moratorium on breeding chimpanzees for research should be lifted. However, in 2007, the NIH made the moratorium permanent.\nOther researchers argue that chimpanzees either should not be used in research, or should be treated differently, for instance with legal status as persons. Pascal Gagneux, an evolutionary biologist and primate expert at the University of California, San Diego, argues, given chimpanzees' sense of self, tool use, and genetic similarity to human beings, studies using chimpanzees should follow the ethical guidelines used for human subjects unable to give consent. A recent study suggests chimpanzees which are retired from labs exhibit a form of post-traumatic stress disorder. Stuart Zola, director of the Yerkes laboratory, disagrees. He told \"National Geographic\": \"I don't think we should make a distinction between our obligation to treat humanely any species, whether it's a rat or a monkey or a chimpanzee. No matter how much we may wish it, chimps are not human.\"\nOnly one European laboratory, the Biomedical Primate Research Centre in Rijswijk, the Netherlands, used chimpanzees in research. It formerly held 108 chimpanzees among 1,300 non-human primates. The Dutch ministry of science decided to phase out research at the centre from 2001. Trials already under way were however allowed to run their course. Chimpanzees including the female Ai have been studied at the Primate Research Institute of Kyoto University, Japan, formerly directed by Tetsuro Matsuzawa, since 1978. 12 chimpanzees are currently held at the facility.\nTwo chimpanzees have been sent into outer space as NASA research subjects. Ham, the first great ape in space, was launched in the Mercury-Redstone 2 capsule on 31 January 1961, and survived the suborbital flight. Enos, the third primate to orbit Earth after Soviet cosmonauts Yuri Gagarin and Gherman Titov, flew on Mercury-Atlas 5 on 29 November of the same year.\nField study.\nJane Goodall undertook the first long-term field study of the chimpanzee, begun in Tanzania at Gombe Stream National Park in 1960. Other long-term studies begun in the 1960s include Adriaan Kortlandt's in the eastern Democratic Republic of the Congo and Toshisada Nishida's in Mahale Mountains National Park in Tanzania. Current understanding of the species' typical behaviours and social organisation has been formed largely from Goodall's ongoing 60-year Gombe research study.\nAttacks.\nChimpanzees have attacked humans. In Uganda, several attacks on children have happened, some of them fatal. Some of these attacks may have been due to the chimpanzees being intoxicated (from alcohol obtained from rural brewing operations) and becoming aggressive towards humans. Human interactions with chimpanzees may be especially dangerous if the chimpanzees perceive humans as potential rivals. At least six cases of chimpanzees snatching and eating human babies are documented.\nA chimpanzee's strength and sharp teeth mean that attacks, even on adult humans, can cause severe injuries. This was evident after the attack and near death of former NASCAR driver St. James Davis, who was mauled by two escaped chimpanzees while he and his wife were celebrating the birthday of their former pet chimpanzee. Another example of chimpanzees being aggressive toward humans occurred in 2009 in Stamford, Connecticut, when a , 13-year-old pet chimpanzee named Travis attacked his owner's friend, who lost her hands, eyes, nose, and part of her maxilla from the attack.\nHuman immunodeficiency virus.\nTwo primary classes of human immunodeficiency virus (HIV) infect humans: HIV-1 and HIV-2. HIV-1 is the more virulent and easily transmitted, and is the source of the majority of HIV infections throughout the world; HIV-2 occurs mostly in west Africa. Both types originated in west and central Africa, jumping from other primates to humans. HIV-1 has evolved from a simian immunodeficiency virus (SIVcpz) found in the subspecies \"P. t. troglodytes\" of southern Cameroon. Kinshasa, in the Democratic Republic of Congo, has the greatest genetic diversity of HIV-1 so far discovered, suggesting the virus has been there longer than anywhere else. HIV-2 crossed species from a different strain of HIV, found in the sooty mangabey monkeys in Guinea-Bissau.\nConservation.\nThe chimpanzee is on the IUCN Red List as an endangered species. Chimpanzees are legally protected in most of their range and are found both in and outside national parks. Between 172,700 and 299,700 individuals are thought to be living in the wild, a decrease from about a million chimpanzees in the early 1900s. Chimpanzees are listed in Appendix I of the Convention on International Trade in Endangered Species (CITES), meaning that commercial international trade in wild-sourced specimens is prohibited and all other international trade (including in parts and derivatives) is regulated by the CITES permitting system.\nThe biggest threats to the chimpanzee are habitat destruction, poaching, and disease. Chimpanzee habitats have been limited by deforestation in both West and Central Africa. Road building has caused habitat degradation and fragmentation of chimpanzee populations and may allow poachers more access to areas that had not been seriously affected by humans. Although deforestation rates are low in western Central Africa, selective logging may take place outside national parks.\nChimpanzees are a common target for poachers. In Ivory Coast, chimpanzees make up 1\u20133% of bushmeat sold in urban markets. They are also taken, often illegally, for the pet trade and are hunted for medicinal purposes in some areas. Farmers sometimes kill chimpanzees that threaten their crops; others are unintentionally maimed or killed by snares meant for other animals.\nInfectious diseases are a main cause of death for chimpanzees. They succumb to many diseases that afflict humans because the two species are so similar. As the human population grows, so does the risk of disease transmission between humans and chimpanzees."}
{"id": "7845", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7845", "title": "Charcot\u2013Marie\u2013Tooth disease", "text": "Charcot\u2013Marie\u2013Tooth disease (CMT) is a hereditary motor and sensory neuropathy of the peripheral nervous system characterized by progressive loss of muscle tissue and touch sensation across various parts of the body. This disease is the most commonly inherited neurological disorder, affecting about one in 2,500 people. It is named after those who classically described it: the Frenchman Jean-Martin Charcot (1825\u20131893), his pupil Pierre Marie (1853\u20131940), and the Briton Howard Henry Tooth (1856\u20131925).\nThere is no known cure. Care focuses on maintaining function. CMT was previously classified as a subtype of muscular dystrophy.\nSigns and symptoms.\nSymptoms of CMT usually begin in early childhood or early adulthood but can begin later. Some people do not experience symptoms until their early 30s or 40s. Usually, the initial symptom is foot drop or high arches early in the course of the disease. This can be accompanied by hammertoe, where the toes are always curled. Wasting atrophy of muscle tissue of the lower parts of the legs may give rise to a \"stork leg\" or \"inverted champagne bottle\" appearance. Weakness in the hands and forearms occurs in many people as the disease progresses.\nHigh-arched feet (pes cavus) or flat-arched feet (pes planus) are classically associated with the disorder. Loss of touch sensation in the feet, ankles, and legs as well as in the hands, wrists, and arms occurs with various types of the disease. Early- and late-onset forms occur with 'on and off' painful spasmodic muscular contractions that can be disabling when the disease activates. Sensory and proprioceptive nerves in the hands and feet are often damaged, while unmyelinated pain nerves are left intact. Overuse of an affected hand or limb can activate symptoms including numbness, spasm, and painful cramping.\nSymptoms and progression of the disease can vary. Involuntary grinding of teeth and squinting are prevalent and often go unnoticed by the person affected. Breathing can be affected in some, as can hearing, vision, and neck and shoulder muscles. Scoliosis is common, causing hunching and loss of height. Hip sockets can be malformed. Gastrointestinal problems can be part of CMT, as can difficulty chewing, swallowing, and speaking (due to atrophy of vocal cords). A tremor can develop as muscles waste. Pregnancy has been known to exacerbate CMT, as well as severe emotional stress. Patients with CMT must avoid periods of prolonged immobility such as when recovering from a secondary injury, as prolonged periods of limited mobility can drastically accelerate symptoms of CMT.\nPain due to postural changes, skeletal deformations, muscle fatigue, and cramping is fairly common in people with CMT. It can be mitigated or treated by physical therapies, surgeries, and corrective or assistive devices. Analgesic medications may also be needed if other therapies do not provide relief from pain. Neuropathic pain is often a symptom of CMT, though, like other symptoms of CMT, its presence and severity vary from case to case. For some people, pain can be significant to severe and interfere with daily life activities. However, pain is not experienced by all people with CMT. When neuropathic pain is present as a symptom of CMT, it is comparable to that seen in other peripheral neuropathies, as well as postherpetic neuralgia and complex regional pain syndrome, among other diseases.\nAtypical presentations of CMT can also lead to leg muscles, specifically the calves, enlarging. This hypertrophic type of CMT is not caused by the muscles enlarging directly, but by pseudohypertrophy of the legs as fatty tissue enters the leg muscles.\nCauses.\nCharcot\u2013Marie\u2013Tooth disease is caused by genetic mutations that cause defects in neuronal proteins. Nerve signals are conducted by an axon with a myelin sheath wrapped around it. Most mutations in CMT affect the myelin sheath, but some affect the axon.\nChromosome 17\nThe most common cause of CMT (70\u201380% of the cases) is the duplication of a large region on the short arm of chromosome 17 that includes the gene \"PMP22\".\nChromosome 1\nSome mutations affect the gene \"MFN2\", on chromosome 1, which codes for a mitochondrial protein. Mutated \"MFN2\" causes the mitochondria to form large clusters, or clots, which are unable to travel down the axon towards the synapses. This prevents the synapses from functioning.\nClassification.\nCMT is a heterogeneous disease and the mutations linked to it may occur in many different genes. Based on the affected gene, CMT is categorized into several types and subtypes.\nGARS1-Related Axonal Neuropathy (CMT2).\nCMT2 variants are typically referred to as axonal neuropathies due to the axonal degeneration observed. CMT2 variants are a result of damage to the nerve axons, rather than damage to the myelin sheath (as is the case with CMT1). Damaged axons cause slowed transmission of signals to the muscles and brain, causing symptoms including muscle atrophy, weakness, decreased sensitivity, and foot deformity. Symptoms of CMT2 variants typically appear between the ages of 5 and 25. CMT2D is one of 31 CMT2 variants, and is only diagnosed if sensory deficits (such as loss of sensation due to the degradation of sensory axons) are observed along with motor deficits; otherwise, distal hereditary motor neuropathy type V is diagnosed. It is unknown why sensory involvement is so varied between GARS1 neuropathy patients. Symptoms of CMT2D include foot deformity, muscle weakness and cramping, compromised reflexes, loss of sensation, and muscle atrophy, and are similar to the symptoms of both CMT1 and CMT2 variants. Symptoms and severity vary from patient to patient.\nMice are often used to model CMT2D, and typically demonstrate aberrant neuromuscular function at the neuromuscular junction (NMJ). The neuromuscular junction is abnormal in CMT2D mice, with subjects showing neuromuscular junction degeneration in hind muscles. The dorsal root ganglia (DRG) are also affected via aberrant sensory neuron fate, meaning that sensory neuron cell fates are abnormally determined. CMT2D mice have fewer proprioceptive and mechanosensitive neurons, but have more nociceptive neurons, possibly due to mutant GlyRS aberrantly interacting with the extracellular region of tropomyosin receptor kinase, or Trk, receptors. Trk receptors are crucial to the survival and development of sensory neurons; when disrupted, nerve development and survival is disrupted as well, possibly leading to the abnormal sensory neuron counts observed in CMT2D mice.\nCMT2D is a result of autosomal dominant mutations in the human GARS1 gene located at 7p14.3 and is thought to be caused by aberrant gain-of-function missense mutations. The GARS1 gene is a protein-coding gene responsible for the encoding of glycyl-tRNA synthetase (GlyRS). Glycyl-tRNA synthetase is a class II aminoacyl-tRNA synthetase and acts as the catalyst for the synthesis of glycyl-tRNA by covalently bonding amino acids with their corresponding cognate tRNAs for protein translation. Glycyl-tRNA synthetase is integral to protein translation and attaches glycine to its cognate tRNA.\nMany different mutations have been found in CMT2D patients, and it remains unclear how mutations in GARS1 cause CMT2D. However, it is thought that mutant glycyl-tRNA synthetase (GlyRS) interferes with transmembrane receptors, causing motor disease, and that mutations in the gene could disrupt the ability of GlyRS to interact with its cognate RNA, disrupting protein production. The GARS1 mutations present in CMT2D cause a deficient amount of glycyl-tRNA in cells, preventing the elongation phase of protein synthesis. Elongation is a key step in protein production, so when there is a deficiency of glycyl-tRNA, protein synthesis is unable to continue at glycine sites. GARS1 mutations also stall initiation of translation due to a stress response that is induced by glycine addition failure. By stalling elongation and initiation of translation, CMT2D mutations in the GARS1 gene cause translational repression, meaning that overall translation is inhibited.\nGARS1-associated axonal neuropathy is progressive, meaning that it worsens over time. Unknown mechanisms are thought to cause the chronic neurodegeneration resulting from the aberrant GlyRS; however, one theory on the mechanism for the disease is VEGF deficiency. Mutant GlysRS interferes with neuronal transmembrane receptors, including neuropilin 1 (Nrp1) and vascular endothelial growth factor (VEGF), causing neuropathy. GARS-CMT2D mutations alter GlyRS and allow it to bind to the Nrp1 receptor, interfering with the normal binding of Nrp1 to VEGF. While enhanced expression of VEGF improves motor function, reduced expression of Nrp1 worsens CMT2D; because Nrp1 binds to mutant GlyRS in mutant GARS1-CMT2D individuals, Nrp1 expression is reduced, in turn worsening motor function. Mice with deficient VEGF demonstrate motor neuron disease over time. Thus, the VEGF/Nrp1 pathway is considered to be targetable for CMT2D treatment.\nX-linked CMT.\nCMT can also be produced by X-linked mutations, in which case it is called X-linked CMT (CMTX). In CMTX, mutated connexons create nonfunctional gap junctions that interrupt molecular exchange and signal transport. The mutation can appear in the \"GJB1\" gene coding for the connexin 32 protein, a gap junction protein expressed in Schwann cells. Because this protein is also present in oligodendrocytes, demyelination can appear in the CNS as well.\nSchwann cells create the myelin sheath by wrapping their plasma membranes around the axon. These Schwann cells work together with neurons and fibroblasts to create a functional nerve. Schwann cells and neurons exchange molecular signals by way of gap junctions that regulate survival and differentiation\nDemyelinating Schwann cells cause abnormal axon structure and function. They may cause axon degeneration, or they may simply cause axons to malfunction. The myelin sheath allows nerve cells to conduct signals faster. When the myelin sheath is damaged, however, nerve signals are slower. This can be measured by a common neurological test, electromyography. When the axon is damaged, the result is a reduced compound muscle action potential.\nDiagnosis.\nCMT can be diagnosed through three different forms of tests: measurement of the speed of nerve impulses (nerve conduction studies), a biopsy of the nerve, and DNA testing. DNA testing can give a definitive diagnosis, but not all the genetic markers for CMT are known. CMT is first most noticed when someone develops lower leg weakness, such as foot drop, or foot deformities, including hammertoes and high arches, but signs alone do not lead to diagnosis. Patients must be referred to a physician specialising in neurology or rehabilitation medicine. To see signs of muscle weakness, the neurologist may ask patients to walk on their heels or to move part of their leg against an opposing force. To identify sensory loss, the neurologist tests for deep-tendon reflexes, such as the knee jerk, which are reduced or absent in CMT. The doctor may also ask about the patient's family history since CMT is hereditary. The lack of family history does not rule out CMT but is helpful to rule out other causes of neuropathy, such as diabetes or exposure to certain chemicals or drugs.\nIn 2010, CMT was one of the first diseases where the genetic cause of a particular patient's disease was precisely determined by sequencing the whole genome of an affected individual. This was done by the scientists employed by the Charcot Marie Tooth Association (CMTA). Two mutations were identified in a gene, \"SH3TC2\", known to cause CMT. Researchers then compared the affected patient's genome to the genomes of the patient's mother, father, and seven siblings with and without the disease. The mother and father each had one normal and one mutant copy of this gene and had mild or no symptoms. The offspring who inherited two mutant genes presented fully with the disease.\nHistology.\nThe constant cycle of demyelination and remyelination, which occurs in CMT, can lead to the formation of layers of myelin around some nerves, termed an \"onion bulb\". These are also seen in chronic inflammatory demyelinating polyneuropathy. Muscles show fiber type grouping, a similarly nonspecific finding that indicates a cycle of denervation/reinnervation. Normally, type I and type II muscle fibers show a checkerboard-like random distribution. However, when reinnervation occurs, the group of fibers associated with one nerve are of the same type. The standard for indicating fiber type is histoenzymatic adenosine triphosphatase (ATPase at pH 9.4).\nManagement.\nOften, the most important goal for patients with CMT is to maintain movement, muscle strength, and flexibility. Therefore, an interprofessional team approach with occupational therapy (OT), physical therapy (PT), orthotist, podiatrist, and or orthopedic surgeon is recommended.\nAppropriate footwear is also very important for people with CMT, but they often have difficulty finding well-fitting shoes because of their high-arched feet and hammertoes. Due to the lack of good sensory reception in the feet, CMT patients may also need to see a podiatrist for assistance in trimming nails or removing calluses that develop on the pads of the feet. Lastly, patients can also decide to have surgery performed by a podiatrist or an orthopedic surgeon. Surgery may help to stabilize the patients' feet or correct progressive problems. These procedures include straightening and pinning the toes, lowering the arch, and sometimes, fusing the ankle joint to provide stability. CMT patients must take extra care to avoid falling as fractures take longer to heal in someone with an underlying disease process. Additionally, the resulting inactivity may cause the CMT to worsen. The Charcot\u2013Marie\u2013Tooth Association classifies the chemotherapy drug vincristine as a \"definite high risk\" and states, \"vincristine has been proven hazardous and should be avoided by all CMT patients, including those with no symptoms.\" Several corrective surgical procedures can be done to improve the physical condition of the affected individuals.\nOrthotics.\nIf the muscles of the lower extremities are weak, it makes sense to prescribe custom-fabricated orthotics. Depending on which muscle groups are affected, the correct orthoses with appropriate functional elements should be prescribed. A weakness of the tibialis anterior muscle, which lifts the feet, is usually accompanied by an atrophy of the gastrocnemius muscle which, together with the soleus muscle, forms the triceps surae muscles (distal calf muscles), occurs causing the known \"stork leg deformity\". In most cases, ankle-foot orthoses that have functional elements for the foot lifting and adjustable control of the lowering of the forefoot make sense. Weak calf muscles lead to insufficient activation of the forefoot lever. This leads to an additional increasing uncertainty when standing and walking. If the calf muscles are weak, an orthosis should therefore be equipped with functional elements to activate the forefoot lever. An orthotic joint with an adjustable dynamic dorsiflexion stop with a strong spring in combination with a lower leg shell in front of the shin is recommended for this. Such orthoses help to control foot drop, and instability of the foot and ankle and offer the patient a better sense of balance when standing and walking without restricting mobility and the dynamics of the ankle joint. Studies confirm the positive effect of orthoses with adjustable functional elements in patients with paralysis of these muscle groups. It is of great advantage if the resistances of the two functional elements can be set separately from one another in the two directions of movement, dorsiflexion and plantar flexion.\nPrognosis.\nThe severity of symptoms varies widely even for the same type of CMT. Cases of monozygotic twins with varying levels of disease severity have been reported, showing that identical genotypes are associated with different levels of severity (see penetrance). Some patients can live a normal life and are almost or entirely asymptomatic. A 2007 review stated that \"life expectancy is not known to be altered in the majority of cases.\"\nHistory.\nThe disease is named after those who classically described it: the Frenchman Jean-Martin Charcot (1825\u20131893), his pupil Pierre Marie (1853\u20131940), and the Briton Howard Henry Tooth (1856\u20131925)."}
{"id": "7846", "revid": "38627444", "url": "https://en.wikipedia.org/wiki?curid=7846", "title": "Central pontine myelinolysis", "text": "Central pontine myelinolysis is a neurological condition involving severe damage to the myelin sheath of nerve cells in the \"pons\" (an area of the brainstem). It is predominately iatrogenic (treatment-induced), and is characterized by acute paralysis, dysphagia (difficulty swallowing), dysarthria (difficulty speaking), and other neurological symptoms.\nCentral pontine myelinolysis was first described as a disorder in 1959. The original paper described four cases with fatal outcomes, and the findings on autopsy. The disease was described as a disease of alcoholics and malnutrition. 'Central pontine' indicated the site of the lesion and 'myelinolysis' was used to emphasise that myelin was affected. The authors intentionally avoided the term 'demyelination' to describe the condition, in order to differentiate this condition from multiple sclerosis and other neuroinflammatory disorders.\nSince this original description, demyelination in other areas of the central nervous system associated with osmotic stress has been described outside the pons (extrapontine). Osmotic demyelination syndrome is the term used for both central pontine myelinolysis and extrapontine myelinolysis.\nCentral pontine myelinolysis, and osmotic demyelination syndrome, present most commonly as a complication of treatment of patients with profound hyponatremia (low sodium), which can result from a varied spectrum of conditions, based on different mechanisms. It occurs as a consequence of a rapid rise in serum tonicity following treatment in individuals with chronic, severe hyponatremia who have made intracellular adaptations to the prevailing hypotonicity.\nSigns and symptoms.\nSymptoms depend on the regions of the brain involved. Prior to its onset, patients may present with the neurological signs and symptoms of hyponatraemic encephalopathy such as nausea and vomiting, confusion, headache and seizures. These symptoms may resolve with normalisation of the serum sodium concentration. Three to five days later, a second phase of neurological manifestations occurs correlating with the onset of myelinolysis. Observable immediate precursors may include seizures, disturbed consciousness, gait changes, and decrease or cessation of respiratory function.\nThe classical clinical presentation is the progressive development of spastic quadriparesis, pseudobulbar palsy, and emotional lability (pseudobulbar affect), with other more variable neurological features associated with brainstem damage. These result from a rapid myelinolysis of the corticobulbar and corticospinal tracts in the brainstem.\nIn about ten per cent of people with central pontine myelinolysis, extrapontine myelinolysis is also found. In these cases symptoms of Parkinson's disease may be generated.\nCauses.\nThe most common cause is overly-rapid correction of low blood sodium levels (hyponatremia). Apart from rapid correction of hyponatraemia, there are case reports of central pontine myelinolysis in association with hypokalaemia, anorexia nervosa when feeding is started, patients undergoing dialysis and burn victims. There is a case report of central pontine myelinolysis occurring in the context of refeeding syndrome, in the absence of hyponatremia.\nIt has also been known to occur in patients suffering withdrawal symptoms of chronic alcoholism. In these instances, occurrence may be entirely unrelated to hyponatremia or rapid correction of hyponatremia. It could affect patients who take some prescription medicines that are able to cross the blood-brain barrier and cause abnormal thirst reception - in this scenario the central pontine myelinolysis is caused by polydipsia leading to low blood sodium levels (hyponatremia).\nIn schizophrenic patients with psychogenic polydipsia, inadequate thirst reception leads to excessive water intake, severely diluting serum sodium. With this excessive thirst combined with psychotic symptoms, brain damage such as central pontine myelinolysis may result from hyperosmolarity caused by excess intake of fluids, (primary polydipsia) although this is difficult to determine because such patients are often institutionalised and have a long history of mental health conditions.\nIt has been observed following hematopoietic stem cell transplantation.\nCentral pontine myelinolysis may also occur in patients prone to hyponatremia affected by:\nPathophysiology.\nThe currently accepted theory states that the brain cells adjust their osmolarities by changing levels of certain osmolytes like inositol, betaine, and glutamine in response to varying serum osmolality. In the context of chronic low plasma sodium (hyponatremia), the brain compensates by decreasing the levels of these osmolytes within the cells, so that they can remain relatively isotonic with their surroundings and not absorb too much fluid. The reverse is true in hypernatremia, in which the cells increase their intracellular osmolytes so as not to lose too much fluid to the extracellular space.\nWith correction of the hyponatremia with intravenous fluids, the extracellular tonicity increases, followed by an increase in intracellular tonicity. When the correction is too rapid, not enough time is allowed for the brain's cells to adjust to the new tonicity, namely by increasing the intracellular osmoles mentioned earlier. If the serum sodium levels rise too rapidly, the increased extracellular tonicity will continue to drive water out of the brain's cells. This can lead to cellular dysfunction and central pontine myelinolysis.\nDiagnosis.\nIt can be diagnosed clinically in the appropriate context, but may be difficult to confirm radiologically using conventional imaging techniques. Changes are more prominent on MRI than on CT, but often take days or weeks after acute symptom onset to develop. Imaging by MRI typically demonstrates areas of hyperintensity on T2-weighted images.\nTreatment.\nTo minimise the risk of this condition developing from its most common cause, overly rapid reversal of hyponatremia, the hyponatremia should be corrected at a rate not exceeding 10\u00a0mmol/L/24\u00a0h or 0.5\u00a0mEq/L/h; or 18 mEq/L/48hrs; thus avoiding demyelination. No large clinical trials have been performed to examine the efficacy of therapeutic re-lowering of serum sodium, or other interventions sometimes advocated such as steroids or plasma exchange.\nAlcoholic patients should receive vitamin supplementation and a formal evaluation of their nutritional status.\nOnce osmotic demyelination has begun, there is no cure or specific treatment. Care is mainly supportive. Alcoholics are usually given vitamins to correct for other deficiencies. The favourable factors contributing to the good outcome in central pontine myelinolysis without hyponatremia were: concurrent treatment of all electrolyte disturbances, early intensive care unit involvement at the advent of respiratory complications, early introduction of feeding including thiamine supplements with close monitoring of the electrolyte changes and input.\nResearch has led to improved outcomes. Animal studies suggest that inositol reduces the severity of osmotic demyelination syndrome if given before attempting to correct chronic hyponatraemia. Further study is required before using inositol in humans for this purpose.\nPrognosis.\nThough traditionally the prognosis is considered poor, a good functional recovery is possible. All patients at risk of developing refeeding syndrome should have their electrolytes closely monitored, including sodium, potassium, magnesium, glucose and phosphate.\nRecent data indicate that the prognosis of critically ill patients may even be better than what is generally considered, despite severe initial clinical manifestations and a tendency by the intensivists to underestimate a possible favorable evolution.\nWhile some patients die, most survive and of the survivors, approximately one-third recover; one-third are disabled but are able to live independently; one-third are severely disabled. Permanent disabilities range from minor tremors and ataxia to signs of severe brain damage, such as spastic quadriparesis and locked-in syndrome. Some improvements may be seen over the course of the first several months after the condition stabilizes.\nThe degree of recovery depends on the extent of the original axonal damage."}
{"id": "7849", "revid": "45173454", "url": "https://en.wikipedia.org/wiki?curid=7849", "title": "Crystallographic defect", "text": "A crystallographic defect is an interruption of the regular patterns of arrangement of atoms or molecules in crystalline solids. The positions and orientations of particles, which are repeating at fixed distances determined by the unit cell parameters in crystals, exhibit a periodic crystal structure, but this is usually imperfect. Several types of defects are often characterized: point defects, line defects, planar defects, bulk defects. Topological homotopy establishes a mathematical method of characterization.\nPoint defects.\nPoint defects are defects that occur only at or around a single lattice point. They are not extended in space in any dimension. Strict limits for how small a point defect is are generally not defined explicitly. However, these defects typically involve at most a few extra or missing atoms. Larger defects in an ordered structure are usually considered dislocation loops. For historical reasons, many point defects, especially in ionic crystals, are called \"centers\": for example a vacancy in many ionic solids is called a luminescence center, a color center, or F-center. These dislocations permit ionic transport through crystals leading to electrochemical reactions. These are frequently specified using Kr\u00f6ger\u2013Vink notation.\nLine defects.\nLine defects can be described by gauge theories.\nDislocations are linear defects, around which the atoms of the crystal lattice are misaligned.\nThere are two basic types of dislocations, the \"edge\" dislocation and the \"screw\" dislocation. \"Mixed\" dislocations, combining aspects of both types, are also common. \nEdge dislocations are caused by the termination of a plane of atoms in the middle of a crystal. In such a case, the adjacent planes are not straight, but instead bend around the edge of the terminating plane so that the crystal structure is perfectly ordered on either side. The analogy with a stack of paper is apt: if a half a piece of paper is inserted in a stack of paper, the defect in the stack is only noticeable at the edge of the half sheet.\nThe screw dislocation is more difficult to visualise, but basically comprises a structure in which a helical path is traced around the linear defect (dislocation line) by the atomic planes of atoms in the crystal lattice.\nThe presence of dislocation results in lattice strain (distortion). The direction and magnitude of such distortion is expressed in terms of a Burgers vector (b). For an edge type, b is perpendicular to the dislocation line, whereas in the cases of the screw type it is parallel. In metallic materials, b is aligned with close-packed crystallographic directions and its magnitude is equivalent to one interatomic spacing.\nDislocations can move if the atoms from one of the surrounding planes break their bonds and rebond with the atoms at the terminating edge.\nIt is the presence of dislocations and their ability to readily move (and interact) under the influence of stresses induced by external loads that leads to the characteristic malleability of metallic materials.\nDislocations can be observed using transmission electron microscopy, field ion microscopy and atom probe techniques.\nDeep-level transient spectroscopy has been used for studying the electrical activity of dislocations in semiconductors, mainly silicon.\nDisclinations are line defects corresponding to \"adding\" or \"subtracting\" an angle around a line. Basically, this means that if you track the crystal orientation around the line defect, you get a rotation. Usually, they were thought to play a role only in liquid crystals, but recent developments suggest that they might have a role also in solid materials, e.g. leading to the self-healing of cracks.\nMathematical classification methods.\nA successful mathematical classification method for physical lattice defects, which works not only with the theory of dislocations and other defects in crystals but also, e.g., for disclinations in liquid crystals and for excitations in superfluid 3He, is the topological homotopy theory.\nComputer simulation methods.\nDensity functional theory, classical molecular dynamics and kinetic Monte Carlo\nsimulations are widely used to study the properties of defects in solids with computer simulations. \nSimulating jamming of hard spheres of different sizes and/or in containers with non-commeasurable sizes using the Lubachevsky\u2013Stillinger algorithm\ncan be an effective technique for demonstrating some types of crystallographic defects."}
{"id": "7850", "revid": "48320297", "url": "https://en.wikipedia.org/wiki?curid=7850", "title": "Chomsky normal form", "text": "In formal language theory, a context-free grammar, \"G\", is said to be in Chomsky normal form (first described by Noam Chomsky) if all of its production rules are of the form:\nwhere \"A\", \"B\", and \"C\" are nonterminal symbols, the letter \"a\" is a terminal symbol (a symbol that represents a constant value), \"S\" is the start symbol, and \u03b5 denotes the empty string. Also, neither \"B\" nor \"C\" may be the start symbol, and the third production rule can only appear if \u03b5 is in \"L\"(\"G\"), the language produced by the context-free grammar \"G\".\nEvery grammar in Chomsky normal form is context-free, and conversely, every context-free grammar can be transformed into an equivalent one which is in Chomsky normal form and has a size no larger than the square of the original grammar's size.\nConverting a grammar to Chomsky normal form.\nTo convert a grammar to Chomsky normal form, a sequence of simple transformations is applied in a certain order; this is described in most textbooks on automata theory.\nThe presentation here follows Hopcroft, Ullman (1979), but is adapted to use the transformation names from Lange, Lei\u00df (2009). Each of the following transformations establishes one of the properties required for Chomsky normal form.\nSTART: Eliminate the start symbol from right-hand sides.\nIntroduce a new start symbol \"S\"0, and a new rule \nwhere \"S\" is the previous start symbol.\nThis does not change the grammar's produced language, and \"S\"0 will not occur on any rule's right-hand side.\nTERM: Eliminate rules with nonsolitary terminals.\nTo eliminate each rule \nwith a terminal symbol \"a\" being not the only symbol on the right-hand side, introduce, for every such terminal, a new nonterminal symbol \"N\"\"a\", and a new rule \nChange every rule \nto \nIf several terminal symbols occur on the right-hand side, simultaneously replace each of them by its associated nonterminal symbol.\nThis does not change the grammar's produced language.\nBIN: Eliminate right-hand sides with more than 2 nonterminals.\nReplace each rule \nwith more than 2 nonterminals \"X\"1...,\"X\"\"n\" by rules \nwhere \"A\"\"i\" are new nonterminal symbols.\nAgain, this does not change the grammar's produced language.\nDEL: Eliminate \u03b5-rules.\nAn \u03b5-rule is a rule of the form \nwhere \"A\" is not \"S\"0, the grammar's start symbol.\nTo eliminate all rules of this form, first determine the set of all nonterminals that derive \u03b5.\nHopcroft and Ullman (1979) call such nonterminals \"nullable\", and compute them as follows:\nObtain an intermediate grammar by replacing each rule \nby all versions with some nullable \"X\"\"i\" omitted.\nBy deleting in this grammar each \u03b5-rule, unless its left-hand side is the start symbol, the transformed grammar is obtained.\nFor example, in the following grammar, with start symbol \"S\"0,\nthe nonterminal \"A\", and hence also \"B\", is nullable, while neither \"C\" nor \"S\"0 is.\nHence the following intermediate grammar is obtained:\nIn this grammar, all \u03b5-rules have been \"inlined at the call site\".\nIn the next step, they can hence be deleted, yielding the grammar:\nThis grammar produces the same language as the original example grammar, viz. {\"ab\",\"aba\",\"abaa\",\"abab\",\"abac\",\"abb\",\"abc\",\"b\",\"ba\",\"baa\",\"bab\",\"bac\",\"bb\",\"bc\",\"c\"}, but has no \u03b5-rules.\nUNIT: Eliminate unit rules.\nA unit rule is a rule of the form \nwhere \"A\", \"B\" are nonterminal symbols.\nTo remove it, for each rule \nwhere \"X\"1 ... \"X\"\"n\" is a string of nonterminals and terminals, add rule \nunless this is a unit rule which has already been (or is being) removed. The skipping of nonterminal symbol \"B\" in the resulting grammar is possible due to \"B\" being a member of the unit closure of nonterminal symbol \"A\".\nOrder of transformations.\nWhen choosing the order in which the above transformations are to be applied, it has to be considered that some transformations may destroy the result achieved by other ones. For example, START will re-introduce a unit rule if it is applied after UNIT. The table shows which orderings are admitted.\nMoreover, the worst-case bloat in grammar size depends on the transformation order. Using |\"G\"| to denote the size of the original grammar \"G\", the size blow-up in the worst case may range from |\"G\"|2 to 22 |G|, depending on the transformation algorithm used. The blow-up in grammar size depends on the order between DEL and BIN. It may be exponential when DEL is done first, but is linear otherwise. UNIT can incur a quadratic blow-up in the size of the grammar. The orderings START,TERM,BIN,DEL,UNIT and START,BIN,DEL,UNIT,TERM lead to the least (i.e. quadratic) blow-up.\nExample.\nThe following grammar, with start symbol \"Expr\", describes a simplified version of the set of all syntactical valid arithmetic expressions in programming languages like C or Algol60. Both \"number\" and \"variable\" are considered terminal symbols here for simplicity, since in a compiler front end their internal structure is usually not considered by the parser. The terminal symbol \"^\" denoted exponentiation in Algol60.\nIn step \"START\" of the above conversion algorithm, just a rule \"S\"0\u2192\"Expr\" is added to the grammar.\nAfter step \"TERM\", the grammar looks like this:\nAfter step \"BIN\", the following grammar is obtained:\nSince there are no \u03b5-rules, step \"DEL\" does not change the grammar.\nAfter step \"UNIT\", the following grammar is obtained, which is in Chomsky normal form:\nThe \"N\"\"a\" introduced in step \"TERM\" are \"PowOp\", \"Open\", and \"Close\".\nThe \"A\"\"i\" introduced in step \"BIN\" are \"AddOp_Term\", \"MulOp_Factor\", \"PowOp_Primary\", and \"Expr_Close\".\nAlternative definition.\nChomsky reduced form.\nAnother way to define the Chomsky normal form is:\nA formal grammar is in Chomsky reduced form if all of its production rules are of the form:\nwhere formula_3, formula_4 and formula_5 are nonterminal symbols, and formula_6 is a terminal symbol. When using this definition, formula_4 or formula_5 may be the start symbol. Only those context-free grammars which do not generate the empty string can be transformed into Chomsky reduced form.\nFloyd normal form.\nIn a letter where he proposed a term Backus\u2013Naur form (BNF), Donald E. Knuth implied a BNF \"syntax in which all definitions have such a form may be said to be in 'Floyd Normal Form'\",\nwhere formula_12, formula_13 and formula_14 are nonterminal symbols, and formula_6 is a terminal symbol,\nbecause Robert W. Floyd found any BNF syntax can be converted to the above one in 1961. But he withdrew this term, \"since doubtless many people have independently used this simple fact in their own work, and the point is only incidental to the main considerations of Floyd's note.\" While Floyd's note cites Chomsky's original 1959 article, Knuth's letter does not.\nApplication.\nBesides its theoretical significance, CNF conversion is used in some algorithms as a preprocessing step, e.g., the CYK algorithm, a bottom-up parsing for context-free grammars, and its variant probabilistic CKY."}
{"id": "7851", "revid": "47814048", "url": "https://en.wikipedia.org/wiki?curid=7851", "title": "Comprehensive Nuclear-Test-Ban Treaty", "text": "The Comprehensive Nuclear-Test-Ban Treaty (CTBT) is a multilateral treaty to ban nuclear weapons test explosions and any other nuclear explosions, for both civilian and military purposes, in all environments. It was adopted by the United Nations General Assembly on 10 September 1996, but has not entered into force, as nine specific nations have not ratified the treaty.\nHistory.\nThe movement for international control of nuclear weapons began in 1945, with a call from Canada and the United Kingdom for a conference on the subject. In June 1946, Bernard Baruch, an emissary of President Harry S. Truman, proposed the Baruch Plan before the United Nations Atomic Energy Commission, which called for an international system of controls on the production of atomic energy. The plan, which would serve as the basis for U.S. nuclear policy into the 1950s, was rejected by the Soviet Union as a US ploy to cement its nuclear dominance.\nBetween the Trinity nuclear test of 16 July 1945 and the signing of the Partial Test Ban Treaty (PTBT) on 5 August 1963, 499 nuclear tests were conducted. Much of the impetus for the PTBT, the precursor to the CTBT, was rising public concern surrounding the size and resulting nuclear fallout from underwater and atmospheric nuclear tests, particularly tests of powerful thermonuclear weapons (hydrogen bombs). The Castle Bravo test of 1 March 1954, in particular, attracted significant attention as the detonation resulted in fallout that spread over inhabited areas and sickened a group of Japanese fishermen. Between 1945 and 1963, the US conducted 215 atmospheric tests, the Soviet Union conducted 219, the UK conducted 21, and France conducted 4.\nIn 1954, following the Castle Bravo test, Prime Minister Jawaharlal Nehru of India issued the first appeal for a \"standstill agreement\" on testing, which was soon echoed by the British Labour Party. Negotiations on a comprehensive test ban, primarily involving the US, UK, and the Soviet Union, began in 1955 following a proposal by Soviet leader Nikita Khrushchev. Of primary concern throughout the negotiations, which would stretch\u2014with some interruptions\u2014to July 1963, was the system of verifying compliance with the test ban and detecting illicit tests. On the Western side, there were concerns that the Soviet Union would be able to circumvent any test ban and secretly leap ahead in the nuclear arms race. These fears were amplified following the US \"Rainier\" shot of 19 September 1957, which was the first contained underground test of a nuclear weapon. Though the US held a significant advantage in underground testing capabilities, there was worry that the Soviet Union would be able to covertly conduct underground tests during a test ban, as underground detonations were more challenging to detect than above-ground tests. On the Soviet side, conversely, the on-site compliance inspections demanded by the US and UK were seen as amounting to espionage. Disagreement over verification would lead to the Anglo-American and Soviet negotiators abandoning a comprehensive test ban (i.e., a ban on all tests, including those underground) in favor of a partial ban, which would be finalized on 25 July 1963. The PTBT, joined by 123 states following the original three parties, banned detonations for military and civilian purposes underwater, in the atmosphere, and outer space.\nThe PTBT had mixed results. On the one hand, enactment of the treaty was followed by a substantial drop in the atmospheric concentration of radioactive particles. On the other hand, nuclear proliferation was not halted entirely (though it may have been slowed) and nuclear testing continued at a rapid clip. Compared to the 499 tests from 1945 to the signing of the PTBT, 436 tests were conducted over the ten years following the PTBT. Furthermore, US and Soviet underground testing continued \"venting\" radioactive gas into the atmosphere. Additionally, though underground testing was generally safer than above-ground testing, underground tests continued to risk the leaking of radionuclides, including plutonium, into the ground. From 1964 through 1996, the year of the CTBT's adoption, an estimated 1,377 underground nuclear tests were conducted. The final non-underground (atmospheric or underwater) test was conducted by China in 1980.\nThe PTBT has been seen as a step towards the Nuclear Non-proliferation Treaty (NPT) of 1968, which directly referenced the PTBT. Under the NPT, non-nuclear weapon states were prohibited from possessing, manufacturing, and acquiring nuclear weapons or other nuclear explosive devices. All signatories, including nuclear weapon states, were committed to the goal of total nuclear disarmament. However, India, Pakistan, and Israel have declined to sign the NPT on the grounds that such a treaty is fundamentally discriminatory as it places limitations on states that do not have nuclear weapons while making no efforts to curb weapons development by declared nuclear weapons states.\nIn 1974, a step towards a comprehensive test ban was made with the Threshold Test Ban Treaty (TTBT), ratified by the US and Soviet Union, which banned underground tests with yields above 150 kilotons. In April 1976, the two states reached agreement on the Peaceful Nuclear Explosions Treaty (PNET), which concerns nuclear detonations outside the weapons sites discussed in the TTBT. As in the TTBT, the US and Soviet Union agreed to bar peaceful nuclear explosions (PNEs) at these other locations with yields above 150 kilotons, as well as group explosions with total yields over 1,500 kilotons. To verify compliance, the PNET requires that states rely on national technical means of verification, share information on explosions, and grant on-site access to counterparties. The TTBT and PNET entered into force on 11 December 1990.\nIn October 1977, the US, UK, and Soviet Union returned to negotiations over a test ban. These three nuclear powers made notable progress in the late 1970s, agreeing to terms on a ban on all testing, including a temporary prohibition on PNEs, but continued disagreements over the compliance mechanisms led to an end to negotiations ahead of Ronald Reagan's inauguration as president in 1981. In 1985, Soviet leader Mikhail Gorbachev announced a unilateral testing moratorium, and in December 1986, Reagan reaffirmed US commitment to pursue the long-term goal of a comprehensive test ban. In November 1987, negotiations on a test ban restarted, followed by a joint US-Soviet program to research underground-test detection in December 1987.\nIn October 2023, Russian president Vladimir Putin stated that since the United States had not ratified the CTBT, consideration could be given to withdrawing Russia's ratification of the treaty. Later in the month, a law revoking ratification of the CTBT was passed by the Russian parliament. On 2 November, Putin officially signed into law the withdrawal of ratification of the treaty.\nNegotiations.\nGiven the political situation prevailing in the subsequent decades, little progress was made in nuclear disarmament until the end of the Cold War in 1991. Parties to the PTBT held an amendment conference that year to discuss a proposal to convert the Treaty into an instrument banning all nuclear-weapon tests. With strong support from the UN General Assembly, negotiations for a comprehensive test-ban treaty began in 1993.\nAdoption.\nExtensive efforts were made over the next three years to draft the Treaty text and its two annexes. However, the Conference on Disarmament, in which negotiations were being held, did not succeed in reaching consensus on the adoption of the text. Under the direction of Prime Minister John Howard and Foreign Minister Alexander Downer, Australia then sent the text to the United Nations General Assembly in New York, where it was submitted as a draft resolution. On 10 September 1996, the Comprehensive Test-Ban Treaty (CTBT) was adopted by a large majority, exceeding two-thirds of the General Assembly's Membership.\nObligations.\n(Article I):\nStatus.\nThe Treaty was adopted by the United Nations General Assembly on 10 September 1996. It opened for signature in New York on 24 September 1996, when it was signed by 71 states, including five of the eight then nuclear-capable states. , 178 states have ratified the CTBT and another nine states have signed but not ratified it.\nThe treaty will enter into force 180 days after the 44 states listed in Annex 2 of the treaty have ratified it. These \"Annex 2 states\" are states that participated in the CTBT's negotiations between 1994 and 1996 and possessed nuclear power reactors or research reactors at that time. , nine Annex 2 states have not ratified the treaty: China, Egypt, Iran, Israel and the United States have signed but not ratified the Treaty; India, North Korea and Pakistan have not signed it; while Russia signed and ratified the treaty but subsequently withdrew its ratification prior to its entry into force.\nMonitoring.\nGeophysical and other technologies are used to monitor for compliance with the Treaty: forensic seismology, hydroacoustics, infrasound, and radionuclide monitoring. The first three forms of monitoring are known as wave-form measurements. Seismic monitoring is performed with a system of 50 primary stations located throughout the world, with 120 auxiliary stations in signatory states. Hydroacoustic monitoring is performed with a system of 11 stations that consist of hydrophone triads to monitor for underwater explosions. Hydroacoustic stations can use seismometers to measure T-waves from possible underwater explosions instead of hydrophones. The best measurement of hydroacoustic waves has been found to be at a depth of 1000 m. Infrasound monitoring relies on changes in atmospheric pressure caused by a possible nuclear explosion, with 41 stations certified as of August 2019. One of the biggest concerns with infrasound measurements is noise due to exposure from wind, which can affect the sensor's ability to measure if an event occurred. Together, these technologies are used to monitor the ground, water, and atmosphere for any sign of a nuclear explosion.\nRadionuclide monitoring takes the form of either monitoring for radioactive particulates or noble gases as a product of a nuclear explosion. Radioactive particles emit radiation that can be measured by any of the 80 stations located throughout the world. They are created from nuclear explosions that can collect onto the dust that is moved from the explosion. If a nuclear explosion took place underground, noble gas monitoring can be used to verify whether or not a possible nuclear explosion took place. Noble gas monitoring relies on measuring increases in radioactive xenon gas. Different isotopes of xenon include 131mXe, 133Xe, 133mXe, and 135Xe. All four monitoring methods make up the International Monitoring System (IMS). Statistical theories and methods are integral to CTBT monitoring providing confidence in verification analysis. Once the Treaty enters into force, on-site inspections will be conducted where concerns about compliance arise.\nThe Preparatory Commission for the Comprehensive Test Ban Treaty Organization (CTBTO), an international organization headquartered in Vienna, Austria, was created to build the verification framework, including establishment and provisional operation of the network of monitoring stations, the creation of an international data centre (IDC), and development of the on-site Inspection capability. The CTBTO is responsible for collecting information from the IMS and distribute the analyzed and raw data to member states to judge whether or not a nuclear explosion occurred through the IDC. Parameters such as determining the location where a nuclear explosion or test took place is one of the things that the IDC can accomplish. If a member state chooses to assert that another state had violated the CTBT, they can request an on-site inspection to take place to verify.\nThe monitoring network consists of 337 facilities located all over the globe. As of May 2012, more than 260 facilities have been certified. The monitoring stations register data that is transmitted to the international data centre in Vienna for processing and analysis. The data are sent to states that have signed the Treaty.\nSubsequent nuclear testing.\nThree countries have tested nuclear weapons since the CTBT opened for signature in 1996. India and Pakistan both carried out two sets of tests in 1998. North Korea carried out six announced tests, one each in 2006, 2009, 2013, two in 2016 and one in 2017. All six North Korean tests were picked up by the International Monitoring System set up by the Comprehensive Nuclear-Test-Ban Treaty Organization Preparatory Commission. A North Korean test is believed to have taken place in January 2016, evidenced by an \"artificial earthquake\" measured as a magnitude 5.1 by the U.S. Geological Survey. The first successful North Korean hydrogen bomb test supposedly took place in September 2017. It was estimated to have an explosive yield of 120 kilotons."}
{"id": "7852", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=7852", "title": "DisRuption", "text": ""}
{"id": "7853", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7853", "title": "DonegalFiddleTradition", "text": ""}
{"id": "7854", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7854", "title": "DoubleStops", "text": ""}
{"id": "7855", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=7855", "title": "DirectRealism", "text": ""}
{"id": "7856", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=7856", "title": "DefinitionofBibleTerms", "text": ""}
{"id": "7858", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7858", "title": "DanCe", "text": ""}
{"id": "7859", "revid": "4842600", "url": "https://en.wikipedia.org/wiki?curid=7859", "title": "DeconstructionIsm", "text": ""}
{"id": "7861", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=7861", "title": "DavidHume", "text": ""}
{"id": "7862", "revid": "11191612", "url": "https://en.wikipedia.org/wiki?curid=7862", "title": "DagnyTaggart", "text": ""}
{"id": "7863", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7863", "title": "DataEncryptionStandard", "text": ""}
{"id": "7866", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7866", "title": "DefinitioN", "text": ""}
{"id": "7867", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7867", "title": "DefinitionOfPhilosophy", "text": ""}
{"id": "7868", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7868", "title": "DefinitionOfLogic", "text": ""}
{"id": "7870", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=7870", "title": "DualIsm", "text": ""}
{"id": "7871", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=7871", "title": "DaoDeJing", "text": ""}
{"id": "7872", "revid": "40812388", "url": "https://en.wikipedia.org/wiki?curid=7872", "title": "DualisticInteractionism", "text": ""}
{"id": "7875", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=7875", "title": "DrewBarrymore", "text": ""}
{"id": "7876", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7876", "title": "DianeticS", "text": ""}
{"id": "7877", "revid": "4626", "url": "https://en.wikipedia.org/wiki?curid=7877", "title": "DesigningExperiments", "text": ""}
{"id": "7880", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7880", "title": "DataSeT", "text": ""}
{"id": "7882", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7882", "title": "DramaFilm", "text": ""}
{"id": "7883", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=7883", "title": "DeweyDecimalSystem", "text": ""}
{"id": "7884", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=7884", "title": "DeniseRichards", "text": ""}
